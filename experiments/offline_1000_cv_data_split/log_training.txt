Initialize prior
Initialize generative model
function [run_morpheus] finished in 1363 ms
function [run_morpheus] finished in 1289 ms
Initialize amortizer
Initialize trainer
function [run_morpheus] finished in 1377 ms
function [run_morpheus] finished in 1331 ms
Initialization finished
Start reading data
Finished reading data
Start training
Training epoch 1:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 1:   0%|          | 0/112 [00:05<?, ?it/s, Epoch: 1, Batch: 1,Loss: 2.849,Avg.Loss: 2.849,LR: 5.00E-04]Training epoch 1:   1%|          | 1/112 [00:05<10:59,  5.94s/it, Epoch: 1, Batch: 1,Loss: 2.849,Avg.Loss: 2.849,LR: 5.00E-04]Training epoch 1:   1%|          | 1/112 [00:05<10:59,  5.94s/it, Epoch: 1, Batch: 2,Loss: 2.709,Avg.Loss: 2.779,LR: 5.00E-04]Training epoch 1:   2%|▏         | 2/112 [00:05<10:53,  5.94s/it, Epoch: 1, Batch: 3,Loss: 2.849,Avg.Loss: 2.802,LR: 5.00E-04]Training epoch 1:   3%|▎         | 3/112 [00:06<10:47,  5.94s/it, Epoch: 1, Batch: 4,Loss: 2.819,Avg.Loss: 2.807,LR: 5.00E-04]Training epoch 1:   4%|▎         | 4/112 [00:06<10:41,  5.94s/it, Epoch: 1, Batch: 5,Loss: 2.904,Avg.Loss: 2.826,LR: 5.00E-04]Training epoch 1:   4%|▍         | 5/112 [00:06<10:35,  5.94s/it, Epoch: 1, Batch: 6,Loss: 2.807,Avg.Loss: 2.823,LR: 5.00E-04]Training epoch 1:   5%|▌         | 6/112 [00:06<01:19,  1.34it/s, Epoch: 1, Batch: 6,Loss: 2.807,Avg.Loss: 2.823,LR: 5.00E-04]Training epoch 1:   5%|▌         | 6/112 [00:06<01:19,  1.34it/s, Epoch: 1, Batch: 7,Loss: 2.814,Avg.Loss: 2.822,LR: 5.00E-04]Training epoch 1:   6%|▋         | 7/112 [00:06<01:18,  1.34it/s, Epoch: 1, Batch: 8,Loss: 2.984,Avg.Loss: 2.842,LR: 5.00E-04]Training epoch 1:   7%|▋         | 8/112 [00:06<01:17,  1.34it/s, Epoch: 1, Batch: 9,Loss: 2.955,Avg.Loss: 2.855,LR: 5.00E-04]Training epoch 1:   8%|▊         | 9/112 [00:06<01:17,  1.34it/s, Epoch: 1, Batch: 10,Loss: 2.790,Avg.Loss: 2.848,LR: 5.00E-04]Training epoch 1:   9%|▉         | 10/112 [00:06<01:16,  1.34it/s, Epoch: 1, Batch: 11,Loss: 2.926,Avg.Loss: 2.855,LR: 5.00E-04]Training epoch 1:  10%|▉         | 11/112 [00:06<01:15,  1.34it/s, Epoch: 1, Batch: 12,Loss: 2.658,Avg.Loss: 2.839,LR: 5.00E-04]Training epoch 1:  11%|█         | 12/112 [00:06<00:31,  3.22it/s, Epoch: 1, Batch: 12,Loss: 2.658,Avg.Loss: 2.839,LR: 5.00E-04]Training epoch 1:  11%|█         | 12/112 [00:06<00:31,  3.22it/s, Epoch: 1, Batch: 13,Loss: 2.816,Avg.Loss: 2.837,LR: 5.00E-04]Training epoch 1:  12%|█▏        | 13/112 [00:06<00:30,  3.22it/s, Epoch: 1, Batch: 14,Loss: 2.740,Avg.Loss: 2.830,LR: 5.00E-04]Training epoch 1:  12%|█▎        | 14/112 [00:06<00:30,  3.22it/s, Epoch: 1, Batch: 15,Loss: 2.815,Avg.Loss: 2.829,LR: 5.00E-04]Training epoch 1:  13%|█▎        | 15/112 [00:06<00:30,  3.22it/s, Epoch: 1, Batch: 16,Loss: 2.688,Avg.Loss: 2.820,LR: 5.00E-04]Training epoch 1:  14%|█▍        | 16/112 [00:06<00:29,  3.22it/s, Epoch: 1, Batch: 17,Loss: 2.608,Avg.Loss: 2.808,LR: 5.00E-04]Training epoch 1:  15%|█▌        | 17/112 [00:06<00:29,  3.22it/s, Epoch: 1, Batch: 18,Loss: 2.641,Avg.Loss: 2.798,LR: 5.00E-04]Training epoch 1:  16%|█▌        | 18/112 [00:06<00:16,  5.69it/s, Epoch: 1, Batch: 18,Loss: 2.641,Avg.Loss: 2.798,LR: 5.00E-04]Training epoch 1:  16%|█▌        | 18/112 [00:06<00:16,  5.69it/s, Epoch: 1, Batch: 19,Loss: 2.530,Avg.Loss: 2.784,LR: 5.00E-04]Training epoch 1:  17%|█▋        | 19/112 [00:06<00:16,  5.69it/s, Epoch: 1, Batch: 20,Loss: 2.526,Avg.Loss: 2.771,LR: 5.00E-04]Training epoch 1:  18%|█▊        | 20/112 [00:06<00:16,  5.69it/s, Epoch: 1, Batch: 21,Loss: 2.421,Avg.Loss: 2.755,LR: 5.00E-04]Training epoch 1:  19%|█▉        | 21/112 [00:06<00:15,  5.69it/s, Epoch: 1, Batch: 22,Loss: 2.648,Avg.Loss: 2.750,LR: 5.00E-04]Training epoch 1:  20%|█▉        | 22/112 [00:06<00:15,  5.69it/s, Epoch: 1, Batch: 23,Loss: 2.355,Avg.Loss: 2.733,LR: 5.00E-04]Training epoch 1:  21%|██        | 23/112 [00:06<00:15,  5.69it/s, Epoch: 1, Batch: 24,Loss: 2.595,Avg.Loss: 2.727,LR: 5.00E-04]Training epoch 1:  21%|██▏       | 24/112 [00:06<00:09,  8.83it/s, Epoch: 1, Batch: 24,Loss: 2.595,Avg.Loss: 2.727,LR: 5.00E-04]Training epoch 1:  21%|██▏       | 24/112 [00:06<00:09,  8.83it/s, Epoch: 1, Batch: 25,Loss: 2.417,Avg.Loss: 2.715,LR: 5.00E-04]Training epoch 1:  22%|██▏       | 25/112 [00:06<00:09,  8.83it/s, Epoch: 1, Batch: 26,Loss: 2.182,Avg.Loss: 2.694,LR: 5.00E-04]Training epoch 1:  23%|██▎       | 26/112 [00:06<00:09,  8.83it/s, Epoch: 1, Batch: 27,Loss: 2.337,Avg.Loss: 2.681,LR: 5.00E-04]Training epoch 1:  24%|██▍       | 27/112 [00:06<00:09,  8.83it/s, Epoch: 1, Batch: 28,Loss: 2.261,Avg.Loss: 2.666,LR: 5.00E-04]Training epoch 1:  25%|██▌       | 28/112 [00:06<00:09,  8.83it/s, Epoch: 1, Batch: 29,Loss: 2.230,Avg.Loss: 2.651,LR: 5.00E-04]Training epoch 1:  26%|██▌       | 29/112 [00:06<00:09,  8.83it/s, Epoch: 1, Batch: 30,Loss: 2.019,Avg.Loss: 2.630,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 30/112 [00:06<00:06, 12.65it/s, Epoch: 1, Batch: 30,Loss: 2.019,Avg.Loss: 2.630,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 30/112 [00:06<00:06, 12.65it/s, Epoch: 1, Batch: 31,Loss: 2.400,Avg.Loss: 2.622,LR: 5.00E-04]Training epoch 1:  28%|██▊       | 31/112 [00:06<00:06, 12.65it/s, Epoch: 1, Batch: 32,Loss: 2.378,Avg.Loss: 2.615,LR: 5.00E-04]Training epoch 1:  29%|██▊       | 32/112 [00:06<00:06, 12.65it/s, Epoch: 1, Batch: 33,Loss: 2.294,Avg.Loss: 2.605,LR: 5.00E-04]Training epoch 1:  29%|██▉       | 33/112 [00:06<00:06, 12.65it/s, Epoch: 1, Batch: 34,Loss: 2.132,Avg.Loss: 2.591,LR: 5.00E-04]Training epoch 1:  30%|███       | 34/112 [00:06<00:06, 12.65it/s, Epoch: 1, Batch: 35,Loss: 2.271,Avg.Loss: 2.582,LR: 5.00E-04]Training epoch 1:  31%|███▏      | 35/112 [00:06<00:04, 15.81it/s, Epoch: 1, Batch: 35,Loss: 2.271,Avg.Loss: 2.582,LR: 5.00E-04]Training epoch 1:  31%|███▏      | 35/112 [00:06<00:04, 15.81it/s, Epoch: 1, Batch: 36,Loss: 2.272,Avg.Loss: 2.573,LR: 5.00E-04]Training epoch 1:  32%|███▏      | 36/112 [00:06<00:04, 15.81it/s, Epoch: 1, Batch: 37,Loss: 2.265,Avg.Loss: 2.565,LR: 5.00E-04]Training epoch 1:  33%|███▎      | 37/112 [00:06<00:04, 15.81it/s, Epoch: 1, Batch: 38,Loss: 2.139,Avg.Loss: 2.554,LR: 5.00E-04]Training epoch 1:  34%|███▍      | 38/112 [00:06<00:04, 15.81it/s, Epoch: 1, Batch: 39,Loss: 2.002,Avg.Loss: 2.540,LR: 5.00E-04]Training epoch 1:  35%|███▍      | 39/112 [00:06<00:04, 15.81it/s, Epoch: 1, Batch: 40,Loss: 1.973,Avg.Loss: 2.526,LR: 5.00E-04]Training epoch 1:  36%|███▌      | 40/112 [00:06<00:04, 15.81it/s, Epoch: 1, Batch: 41,Loss: 2.475,Avg.Loss: 2.524,LR: 5.00E-04]Training epoch 1:  37%|███▋      | 41/112 [00:06<00:03, 20.51it/s, Epoch: 1, Batch: 41,Loss: 2.475,Avg.Loss: 2.524,LR: 5.00E-04]Training epoch 1:  37%|███▋      | 41/112 [00:06<00:03, 20.51it/s, Epoch: 1, Batch: 42,Loss: 2.043,Avg.Loss: 2.513,LR: 5.00E-04]Training epoch 1:  38%|███▊      | 42/112 [00:06<00:03, 20.51it/s, Epoch: 1, Batch: 43,Loss: 1.704,Avg.Loss: 2.494,LR: 5.00E-04]Training epoch 1:  38%|███▊      | 43/112 [00:06<00:03, 20.51it/s, Epoch: 1, Batch: 44,Loss: 2.005,Avg.Loss: 2.483,LR: 5.00E-04]Training epoch 1:  39%|███▉      | 44/112 [00:06<00:03, 20.51it/s, Epoch: 1, Batch: 45,Loss: 1.942,Avg.Loss: 2.471,LR: 5.00E-04]Training epoch 1:  40%|████      | 45/112 [00:06<00:03, 20.51it/s, Epoch: 1, Batch: 46,Loss: 1.888,Avg.Loss: 2.458,LR: 5.00E-04]Training epoch 1:  41%|████      | 46/112 [00:06<00:02, 24.48it/s, Epoch: 1, Batch: 46,Loss: 1.888,Avg.Loss: 2.458,LR: 5.00E-04]Training epoch 1:  41%|████      | 46/112 [00:06<00:02, 24.48it/s, Epoch: 1, Batch: 47,Loss: 1.671,Avg.Loss: 2.441,LR: 5.00E-04]Training epoch 1:  42%|████▏     | 47/112 [00:06<00:02, 24.48it/s, Epoch: 1, Batch: 48,Loss: 2.614,Avg.Loss: 2.445,LR: 5.00E-04]Training epoch 1:  43%|████▎     | 48/112 [00:06<00:02, 24.48it/s, Epoch: 1, Batch: 49,Loss: 2.090,Avg.Loss: 2.438,LR: 5.00E-04]Training epoch 1:  44%|████▍     | 49/112 [00:06<00:02, 24.48it/s, Epoch: 1, Batch: 50,Loss: 1.905,Avg.Loss: 2.427,LR: 5.00E-04]Training epoch 1:  45%|████▍     | 50/112 [00:06<00:02, 24.48it/s, Epoch: 1, Batch: 51,Loss: 1.895,Avg.Loss: 2.417,LR: 5.00E-04]Training epoch 1:  46%|████▌     | 51/112 [00:06<00:02, 24.48it/s, Epoch: 1, Batch: 52,Loss: 1.725,Avg.Loss: 2.403,LR: 5.00E-04]Training epoch 1:  46%|████▋     | 52/112 [00:06<00:02, 29.65it/s, Epoch: 1, Batch: 52,Loss: 1.725,Avg.Loss: 2.403,LR: 5.00E-04]Training epoch 1:  46%|████▋     | 52/112 [00:06<00:02, 29.65it/s, Epoch: 1, Batch: 53,Loss: 2.034,Avg.Loss: 2.396,LR: 5.00E-04]Training epoch 1:  47%|████▋     | 53/112 [00:07<00:01, 29.65it/s, Epoch: 1, Batch: 54,Loss: 2.306,Avg.Loss: 2.395,LR: 5.00E-04]Training epoch 1:  48%|████▊     | 54/112 [00:07<00:01, 29.65it/s, Epoch: 1, Batch: 55,Loss: 2.020,Avg.Loss: 2.388,LR: 5.00E-04]Training epoch 1:  49%|████▉     | 55/112 [00:07<00:01, 29.65it/s, Epoch: 1, Batch: 56,Loss: 1.647,Avg.Loss: 2.375,LR: 5.00E-04]Training epoch 1:  50%|█████     | 56/112 [00:07<00:01, 29.65it/s, Epoch: 1, Batch: 57,Loss: 1.982,Avg.Loss: 2.368,LR: 5.00E-04]Training epoch 1:  51%|█████     | 57/112 [00:07<00:01, 29.65it/s, Epoch: 1, Batch: 58,Loss: 2.402,Avg.Loss: 2.368,LR: 5.00E-04]Training epoch 1:  52%|█████▏    | 58/112 [00:07<00:01, 34.36it/s, Epoch: 1, Batch: 58,Loss: 2.402,Avg.Loss: 2.368,LR: 5.00E-04]Training epoch 1:  52%|█████▏    | 58/112 [00:07<00:01, 34.36it/s, Epoch: 1, Batch: 59,Loss: 1.887,Avg.Loss: 2.360,LR: 5.00E-04]Training epoch 1:  53%|█████▎    | 59/112 [00:07<00:01, 34.36it/s, Epoch: 1, Batch: 60,Loss: 2.005,Avg.Loss: 2.354,LR: 5.00E-04]Training epoch 1:  54%|█████▎    | 60/112 [00:07<00:01, 34.36it/s, Epoch: 1, Batch: 61,Loss: 1.981,Avg.Loss: 2.348,LR: 5.00E-04]Training epoch 1:  54%|█████▍    | 61/112 [00:07<00:01, 34.36it/s, Epoch: 1, Batch: 62,Loss: 1.825,Avg.Loss: 2.340,LR: 5.00E-04]Training epoch 1:  55%|█████▌    | 62/112 [00:07<00:01, 34.36it/s, Epoch: 1, Batch: 63,Loss: 1.840,Avg.Loss: 2.332,LR: 5.00E-04]Training epoch 1:  56%|█████▋    | 63/112 [00:07<00:01, 34.36it/s, Epoch: 1, Batch: 64,Loss: 1.681,Avg.Loss: 2.322,LR: 5.00E-04]Training epoch 1:  57%|█████▋    | 64/112 [00:07<00:01, 38.74it/s, Epoch: 1, Batch: 64,Loss: 1.681,Avg.Loss: 2.322,LR: 5.00E-04]Training epoch 1:  57%|█████▋    | 64/112 [00:07<00:01, 38.74it/s, Epoch: 1, Batch: 65,Loss: 2.254,Avg.Loss: 2.321,LR: 5.00E-04]Training epoch 1:  58%|█████▊    | 65/112 [00:07<00:01, 38.74it/s, Epoch: 1, Batch: 66,Loss: 1.898,Avg.Loss: 2.314,LR: 5.00E-04]Training epoch 1:  59%|█████▉    | 66/112 [00:07<00:01, 38.74it/s, Epoch: 1, Batch: 67,Loss: 1.594,Avg.Loss: 2.304,LR: 5.00E-04]Training epoch 1:  60%|█████▉    | 67/112 [00:07<00:01, 38.74it/s, Epoch: 1, Batch: 68,Loss: 1.730,Avg.Loss: 2.295,LR: 5.00E-04]Training epoch 1:  61%|██████    | 68/112 [00:07<00:01, 38.74it/s, Epoch: 1, Batch: 69,Loss: 2.236,Avg.Loss: 2.294,LR: 5.00E-04]Training epoch 1:  62%|██████▏   | 69/112 [00:07<00:01, 38.74it/s, Epoch: 1, Batch: 70,Loss: 2.158,Avg.Loss: 2.292,LR: 5.00E-04]Training epoch 1:  62%|██████▎   | 70/112 [00:07<00:00, 42.23it/s, Epoch: 1, Batch: 70,Loss: 2.158,Avg.Loss: 2.292,LR: 5.00E-04]Training epoch 1:  62%|██████▎   | 70/112 [00:07<00:00, 42.23it/s, Epoch: 1, Batch: 71,Loss: 1.442,Avg.Loss: 2.280,LR: 5.00E-04]Training epoch 1:  63%|██████▎   | 71/112 [00:07<00:00, 42.23it/s, Epoch: 1, Batch: 72,Loss: 1.816,Avg.Loss: 2.274,LR: 5.00E-04]Training epoch 1:  64%|██████▍   | 72/112 [00:07<00:00, 42.23it/s, Epoch: 1, Batch: 73,Loss: 1.948,Avg.Loss: 2.269,LR: 5.00E-04]Training epoch 1:  65%|██████▌   | 73/112 [00:07<00:00, 42.23it/s, Epoch: 1, Batch: 74,Loss: 1.708,Avg.Loss: 2.262,LR: 5.00E-04]Training epoch 1:  66%|██████▌   | 74/112 [00:07<00:00, 42.23it/s, Epoch: 1, Batch: 75,Loss: 1.979,Avg.Loss: 2.258,LR: 5.00E-04]Training epoch 1:  67%|██████▋   | 75/112 [00:07<00:00, 42.23it/s, Epoch: 1, Batch: 76,Loss: 1.811,Avg.Loss: 2.252,LR: 5.00E-04]Training epoch 1:  68%|██████▊   | 76/112 [00:07<00:00, 45.02it/s, Epoch: 1, Batch: 76,Loss: 1.811,Avg.Loss: 2.252,LR: 5.00E-04]Training epoch 1:  68%|██████▊   | 76/112 [00:07<00:00, 45.02it/s, Epoch: 1, Batch: 77,Loss: 1.566,Avg.Loss: 2.243,LR: 5.00E-04]Training epoch 1:  69%|██████▉   | 77/112 [00:07<00:00, 45.02it/s, Epoch: 1, Batch: 78,Loss: 1.818,Avg.Loss: 2.238,LR: 5.00E-04]Training epoch 1:  70%|██████▉   | 78/112 [00:07<00:00, 45.02it/s, Epoch: 1, Batch: 79,Loss: 1.740,Avg.Loss: 2.231,LR: 5.00E-04]Training epoch 1:  71%|███████   | 79/112 [00:07<00:00, 45.02it/s, Epoch: 1, Batch: 80,Loss: 2.020,Avg.Loss: 2.229,LR: 5.00E-04]Training epoch 1:  71%|███████▏  | 80/112 [00:07<00:00, 45.02it/s, Epoch: 1, Batch: 81,Loss: 1.670,Avg.Loss: 2.222,LR: 5.00E-04]Training epoch 1:  72%|███████▏  | 81/112 [00:07<00:00, 45.02it/s, Epoch: 1, Batch: 82,Loss: 2.068,Avg.Loss: 2.220,LR: 5.00E-04]Training epoch 1:  73%|███████▎  | 82/112 [00:07<00:00, 47.13it/s, Epoch: 1, Batch: 82,Loss: 2.068,Avg.Loss: 2.220,LR: 5.00E-04]Training epoch 1:  73%|███████▎  | 82/112 [00:07<00:00, 47.13it/s, Epoch: 1, Batch: 83,Loss: 2.000,Avg.Loss: 2.217,LR: 5.00E-04]Training epoch 1:  74%|███████▍  | 83/112 [00:07<00:00, 47.13it/s, Epoch: 1, Batch: 84,Loss: 1.636,Avg.Loss: 2.211,LR: 5.00E-04]Training epoch 1:  75%|███████▌  | 84/112 [00:07<00:00, 47.13it/s, Epoch: 1, Batch: 85,Loss: 1.682,Avg.Loss: 2.204,LR: 5.00E-04]Training epoch 1:  76%|███████▌  | 85/112 [00:07<00:00, 47.13it/s, Epoch: 1, Batch: 86,Loss: 1.653,Avg.Loss: 2.198,LR: 5.00E-04]Training epoch 1:  77%|███████▋  | 86/112 [00:07<00:00, 47.13it/s, Epoch: 1, Batch: 87,Loss: 2.128,Avg.Loss: 2.197,LR: 5.00E-04]Training epoch 1:  78%|███████▊  | 87/112 [00:07<00:00, 47.13it/s, Epoch: 1, Batch: 88,Loss: 1.592,Avg.Loss: 2.190,LR: 5.00E-04]Training epoch 1:  79%|███████▊  | 88/112 [00:07<00:00, 48.66it/s, Epoch: 1, Batch: 88,Loss: 1.592,Avg.Loss: 2.190,LR: 5.00E-04]Training epoch 1:  79%|███████▊  | 88/112 [00:07<00:00, 48.66it/s, Epoch: 1, Batch: 89,Loss: 1.744,Avg.Loss: 2.185,LR: 5.00E-04]Training epoch 1:  79%|███████▉  | 89/112 [00:07<00:00, 48.66it/s, Epoch: 1, Batch: 90,Loss: 1.692,Avg.Loss: 2.180,LR: 5.00E-04]Training epoch 1:  80%|████████  | 90/112 [00:07<00:00, 48.66it/s, Epoch: 1, Batch: 91,Loss: 2.255,Avg.Loss: 2.181,LR: 5.00E-04]Training epoch 1:  81%|████████▏ | 91/112 [00:07<00:00, 48.66it/s, Epoch: 1, Batch: 92,Loss: 1.793,Avg.Loss: 2.176,LR: 5.00E-04]Training epoch 1:  82%|████████▏ | 92/112 [00:07<00:00, 48.66it/s, Epoch: 1, Batch: 93,Loss: 1.857,Avg.Loss: 2.173,LR: 5.00E-04]Training epoch 1:  83%|████████▎ | 93/112 [00:07<00:00, 48.66it/s, Epoch: 1, Batch: 94,Loss: 1.649,Avg.Loss: 2.167,LR: 5.00E-04]Training epoch 1:  84%|████████▍ | 94/112 [00:07<00:00, 49.88it/s, Epoch: 1, Batch: 94,Loss: 1.649,Avg.Loss: 2.167,LR: 5.00E-04]Training epoch 1:  84%|████████▍ | 94/112 [00:07<00:00, 49.88it/s, Epoch: 1, Batch: 95,Loss: 2.039,Avg.Loss: 2.166,LR: 5.00E-04]Training epoch 1:  85%|████████▍ | 95/112 [00:07<00:00, 49.88it/s, Epoch: 1, Batch: 96,Loss: 1.651,Avg.Loss: 2.161,LR: 5.00E-04]Training epoch 1:  86%|████████▌ | 96/112 [00:07<00:00, 49.88it/s, Epoch: 1, Batch: 97,Loss: 1.593,Avg.Loss: 2.155,LR: 5.00E-04]Training epoch 1:  87%|████████▋ | 97/112 [00:07<00:00, 49.88it/s, Epoch: 1, Batch: 98,Loss: 1.809,Avg.Loss: 2.151,LR: 5.00E-04]Training epoch 1:  88%|████████▊ | 98/112 [00:07<00:00, 49.88it/s, Epoch: 1, Batch: 99,Loss: 2.050,Avg.Loss: 2.150,LR: 5.00E-04]Training epoch 1:  88%|████████▊ | 99/112 [00:07<00:00, 49.88it/s, Epoch: 1, Batch: 100,Loss: 2.258,Avg.Loss: 2.151,LR: 5.00E-04]Training epoch 1:  89%|████████▉ | 100/112 [00:07<00:00, 50.95it/s, Epoch: 1, Batch: 100,Loss: 2.258,Avg.Loss: 2.151,LR: 5.00E-04]Training epoch 1:  89%|████████▉ | 100/112 [00:07<00:00, 50.95it/s, Epoch: 1, Batch: 101,Loss: 1.767,Avg.Loss: 2.148,LR: 5.00E-04]Training epoch 1:  90%|█████████ | 101/112 [00:07<00:00, 50.95it/s, Epoch: 1, Batch: 102,Loss: 1.509,Avg.Loss: 2.141,LR: 5.00E-04]Training epoch 1:  91%|█████████ | 102/112 [00:07<00:00, 50.95it/s, Epoch: 1, Batch: 103,Loss: 1.975,Avg.Loss: 2.140,LR: 5.00E-04]Training epoch 1:  92%|█████████▏| 103/112 [00:07<00:00, 50.95it/s, Epoch: 1, Batch: 104,Loss: 2.014,Avg.Loss: 2.138,LR: 5.00E-04]Training epoch 1:  93%|█████████▎| 104/112 [00:07<00:00, 50.95it/s, Epoch: 1, Batch: 105,Loss: 2.277,Avg.Loss: 2.140,LR: 5.00E-04]Training epoch 1:  94%|█████████▍| 105/112 [00:08<00:00, 50.95it/s, Epoch: 1, Batch: 106,Loss: 1.791,Avg.Loss: 2.136,LR: 5.00E-04]Training epoch 1:  95%|█████████▍| 106/112 [00:08<00:00, 51.28it/s, Epoch: 1, Batch: 106,Loss: 1.791,Avg.Loss: 2.136,LR: 5.00E-04]Training epoch 1:  95%|█████████▍| 106/112 [00:08<00:00, 51.28it/s, Epoch: 1, Batch: 107,Loss: 1.606,Avg.Loss: 2.131,LR: 5.00E-04]Training epoch 1:  96%|█████████▌| 107/112 [00:08<00:00, 51.28it/s, Epoch: 1, Batch: 108,Loss: 1.528,Avg.Loss: 2.126,LR: 5.00E-04]Training epoch 1:  96%|█████████▋| 108/112 [00:08<00:00, 51.28it/s, Epoch: 1, Batch: 109,Loss: 1.722,Avg.Loss: 2.122,LR: 5.00E-04]Training epoch 1:  97%|█████████▋| 109/112 [00:08<00:00, 51.28it/s, Epoch: 1, Batch: 110,Loss: 1.670,Avg.Loss: 2.118,LR: 5.00E-04]Training epoch 1:  98%|█████████▊| 110/112 [00:08<00:00, 51.28it/s, Epoch: 1, Batch: 111,Loss: 1.888,Avg.Loss: 2.116,LR: 5.00E-04]Training epoch 1:  99%|█████████▉| 111/112 [00:12<00:00, 51.28it/s, Epoch: 1, Batch: 112,Loss: 1.591,Avg.Loss: 2.111,LR: 5.00E-04]Training epoch 1: 100%|██████████| 112/112 [00:12<00:00,  4.02it/s, Epoch: 1, Batch: 112,Loss: 1.591,Avg.Loss: 2.111,LR: 5.00E-04]Training epoch 1: 100%|██████████| 112/112 [00:12<00:00,  8.83it/s, Epoch: 1, Batch: 112,Loss: 1.591,Avg.Loss: 2.111,LR: 5.00E-04]
Training epoch 2:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 2:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 2, Batch: 1,Loss: 1.642,Avg.Loss: 1.642,LR: 5.00E-04]Training epoch 2:   1%|          | 1/112 [00:00<00:04, 24.19it/s, Epoch: 2, Batch: 2,Loss: 2.042,Avg.Loss: 1.842,LR: 5.00E-04]Training epoch 2:   2%|▏         | 2/112 [00:00<00:03, 33.46it/s, Epoch: 2, Batch: 3,Loss: 1.925,Avg.Loss: 1.870,LR: 5.00E-04]Training epoch 2:   3%|▎         | 3/112 [00:00<00:02, 38.55it/s, Epoch: 2, Batch: 4,Loss: 1.579,Avg.Loss: 1.797,LR: 5.00E-04]Training epoch 2:   4%|▎         | 4/112 [00:00<00:02, 38.06it/s, Epoch: 2, Batch: 5,Loss: 1.926,Avg.Loss: 1.823,LR: 5.00E-04]Training epoch 2:   4%|▍         | 5/112 [00:00<00:02, 47.49it/s, Epoch: 2, Batch: 5,Loss: 1.926,Avg.Loss: 1.823,LR: 5.00E-04]Training epoch 2:   4%|▍         | 5/112 [00:00<00:02, 47.49it/s, Epoch: 2, Batch: 6,Loss: 1.526,Avg.Loss: 1.773,LR: 5.00E-04]Training epoch 2:   5%|▌         | 6/112 [00:00<00:02, 47.49it/s, Epoch: 2, Batch: 7,Loss: 1.569,Avg.Loss: 1.744,LR: 5.00E-04]Training epoch 2:   6%|▋         | 7/112 [00:00<00:02, 47.49it/s, Epoch: 2, Batch: 8,Loss: 1.565,Avg.Loss: 1.722,LR: 5.00E-04]Training epoch 2:   7%|▋         | 8/112 [00:00<00:02, 47.49it/s, Epoch: 2, Batch: 9,Loss: 1.694,Avg.Loss: 1.719,LR: 5.00E-04]Training epoch 2:   8%|▊         | 9/112 [00:00<00:02, 47.49it/s, Epoch: 2, Batch: 10,Loss: 1.537,Avg.Loss: 1.701,LR: 5.00E-04]Training epoch 2:   9%|▉         | 10/112 [00:00<00:02, 47.49it/s, Epoch: 2, Batch: 11,Loss: 1.727,Avg.Loss: 1.703,LR: 5.00E-04]Training epoch 2:  10%|▉         | 11/112 [00:00<00:02, 47.49it/s, Epoch: 2, Batch: 12,Loss: 1.861,Avg.Loss: 1.716,LR: 5.00E-04]Training epoch 2:  11%|█         | 12/112 [00:00<00:01, 55.24it/s, Epoch: 2, Batch: 12,Loss: 1.861,Avg.Loss: 1.716,LR: 5.00E-04]Training epoch 2:  11%|█         | 12/112 [00:00<00:01, 55.24it/s, Epoch: 2, Batch: 13,Loss: 1.936,Avg.Loss: 1.733,LR: 5.00E-04]Training epoch 2:  12%|█▏        | 13/112 [00:00<00:01, 55.24it/s, Epoch: 2, Batch: 14,Loss: 1.806,Avg.Loss: 1.738,LR: 5.00E-04]Training epoch 2:  12%|█▎        | 14/112 [00:00<00:01, 55.24it/s, Epoch: 2, Batch: 15,Loss: 1.714,Avg.Loss: 1.737,LR: 5.00E-04]Training epoch 2:  13%|█▎        | 15/112 [00:00<00:01, 55.24it/s, Epoch: 2, Batch: 16,Loss: 1.569,Avg.Loss: 1.726,LR: 5.00E-04]Training epoch 2:  14%|█▍        | 16/112 [00:00<00:01, 55.24it/s, Epoch: 2, Batch: 17,Loss: 2.715,Avg.Loss: 1.784,LR: 5.00E-04]Training epoch 2:  15%|█▌        | 17/112 [00:00<00:01, 55.24it/s, Epoch: 2, Batch: 18,Loss: 2.784,Avg.Loss: 1.840,LR: 5.00E-04]Training epoch 2:  16%|█▌        | 18/112 [00:00<00:01, 52.56it/s, Epoch: 2, Batch: 18,Loss: 2.784,Avg.Loss: 1.840,LR: 5.00E-04]Training epoch 2:  16%|█▌        | 18/112 [00:00<00:01, 52.56it/s, Epoch: 2, Batch: 19,Loss: 2.354,Avg.Loss: 1.867,LR: 5.00E-04]Training epoch 2:  17%|█▋        | 19/112 [00:00<00:01, 52.56it/s, Epoch: 2, Batch: 20,Loss: 2.166,Avg.Loss: 1.882,LR: 5.00E-04]Training epoch 2:  18%|█▊        | 20/112 [00:00<00:01, 52.56it/s, Epoch: 2, Batch: 21,Loss: 1.523,Avg.Loss: 1.865,LR: 5.00E-04]Training epoch 2:  19%|█▉        | 21/112 [00:00<00:01, 52.56it/s, Epoch: 2, Batch: 22,Loss: 1.686,Avg.Loss: 1.857,LR: 5.00E-04]Training epoch 2:  20%|█▉        | 22/112 [00:00<00:01, 52.56it/s, Epoch: 2, Batch: 23,Loss: 1.699,Avg.Loss: 1.850,LR: 5.00E-04]Training epoch 2:  21%|██        | 23/112 [00:00<00:01, 52.56it/s, Epoch: 2, Batch: 24,Loss: 2.127,Avg.Loss: 1.861,LR: 5.00E-04]Training epoch 2:  21%|██▏       | 24/112 [00:00<00:01, 52.15it/s, Epoch: 2, Batch: 24,Loss: 2.127,Avg.Loss: 1.861,LR: 5.00E-04]Training epoch 2:  21%|██▏       | 24/112 [00:00<00:01, 52.15it/s, Epoch: 2, Batch: 25,Loss: 2.424,Avg.Loss: 1.884,LR: 5.00E-04]Training epoch 2:  22%|██▏       | 25/112 [00:00<00:01, 52.15it/s, Epoch: 2, Batch: 26,Loss: 1.796,Avg.Loss: 1.880,LR: 5.00E-04]Training epoch 2:  23%|██▎       | 26/112 [00:00<00:01, 52.15it/s, Epoch: 2, Batch: 27,Loss: 1.796,Avg.Loss: 1.877,LR: 5.00E-04]Training epoch 2:  24%|██▍       | 27/112 [00:00<00:01, 52.15it/s, Epoch: 2, Batch: 28,Loss: 1.510,Avg.Loss: 1.864,LR: 5.00E-04]Training epoch 2:  25%|██▌       | 28/112 [00:00<00:01, 52.15it/s, Epoch: 2, Batch: 29,Loss: 2.463,Avg.Loss: 1.885,LR: 5.00E-04]Training epoch 2:  26%|██▌       | 29/112 [00:00<00:01, 52.15it/s, Epoch: 2, Batch: 30,Loss: 2.412,Avg.Loss: 1.902,LR: 5.00E-04]Training epoch 2:  27%|██▋       | 30/112 [00:00<00:01, 51.80it/s, Epoch: 2, Batch: 30,Loss: 2.412,Avg.Loss: 1.902,LR: 5.00E-04]Training epoch 2:  27%|██▋       | 30/112 [00:00<00:01, 51.80it/s, Epoch: 2, Batch: 31,Loss: 3.390,Avg.Loss: 1.950,LR: 5.00E-04]Training epoch 2:  28%|██▊       | 31/112 [00:00<00:01, 51.80it/s, Epoch: 2, Batch: 32,Loss: 4.303,Avg.Loss: 2.024,LR: 5.00E-04]Training epoch 2:  29%|██▊       | 32/112 [00:00<00:01, 51.80it/s, Epoch: 2, Batch: 33,Loss: 1.915,Avg.Loss: 2.021,LR: 5.00E-04]Training epoch 2:  29%|██▉       | 33/112 [00:00<00:01, 51.80it/s, Epoch: 2, Batch: 34,Loss: 1.531,Avg.Loss: 2.006,LR: 5.00E-04]Training epoch 2:  30%|███       | 34/112 [00:00<00:01, 51.80it/s, Epoch: 2, Batch: 35,Loss: 1.724,Avg.Loss: 1.998,LR: 5.00E-04]Training epoch 2:  31%|███▏      | 35/112 [00:00<00:01, 51.80it/s, Epoch: 2, Batch: 36,Loss: 1.560,Avg.Loss: 1.986,LR: 5.00E-04]Training epoch 2:  32%|███▏      | 36/112 [00:00<00:01, 51.52it/s, Epoch: 2, Batch: 36,Loss: 1.560,Avg.Loss: 1.986,LR: 5.00E-04]Training epoch 2:  32%|███▏      | 36/112 [00:00<00:01, 51.52it/s, Epoch: 2, Batch: 37,Loss: 1.745,Avg.Loss: 1.979,LR: 5.00E-04]Training epoch 2:  33%|███▎      | 37/112 [00:00<00:01, 51.52it/s, Epoch: 2, Batch: 38,Loss: 1.877,Avg.Loss: 1.977,LR: 5.00E-04]Training epoch 2:  34%|███▍      | 38/112 [00:00<00:01, 51.52it/s, Epoch: 2, Batch: 39,Loss: 1.536,Avg.Loss: 1.965,LR: 5.00E-04]Training epoch 2:  35%|███▍      | 39/112 [00:00<00:01, 51.52it/s, Epoch: 2, Batch: 40,Loss: 1.543,Avg.Loss: 1.955,LR: 5.00E-04]Training epoch 2:  36%|███▌      | 40/112 [00:00<00:01, 51.52it/s, Epoch: 2, Batch: 41,Loss: 1.401,Avg.Loss: 1.941,LR: 5.00E-04]Training epoch 2:  37%|███▋      | 41/112 [00:00<00:01, 51.52it/s, Epoch: 2, Batch: 42,Loss: 1.682,Avg.Loss: 1.935,LR: 5.00E-04]Training epoch 2:  38%|███▊      | 42/112 [00:00<00:01, 51.53it/s, Epoch: 2, Batch: 42,Loss: 1.682,Avg.Loss: 1.935,LR: 5.00E-04]Training epoch 2:  38%|███▊      | 42/112 [00:00<00:01, 51.53it/s, Epoch: 2, Batch: 43,Loss: 1.603,Avg.Loss: 1.927,LR: 5.00E-04]Training epoch 2:  38%|███▊      | 43/112 [00:00<00:01, 51.53it/s, Epoch: 2, Batch: 44,Loss: 1.429,Avg.Loss: 1.916,LR: 5.00E-04]Training epoch 2:  39%|███▉      | 44/112 [00:00<00:01, 51.53it/s, Epoch: 2, Batch: 45,Loss: 1.397,Avg.Loss: 1.905,LR: 5.00E-04]Training epoch 2:  40%|████      | 45/112 [00:00<00:01, 51.53it/s, Epoch: 2, Batch: 46,Loss: 1.688,Avg.Loss: 1.900,LR: 5.00E-04]Training epoch 2:  41%|████      | 46/112 [00:00<00:01, 51.53it/s, Epoch: 2, Batch: 47,Loss: 1.715,Avg.Loss: 1.896,LR: 5.00E-04]Training epoch 2:  42%|████▏     | 47/112 [00:00<00:01, 51.53it/s, Epoch: 2, Batch: 48,Loss: 1.328,Avg.Loss: 1.884,LR: 5.00E-04]Training epoch 2:  43%|████▎     | 48/112 [00:00<00:01, 49.98it/s, Epoch: 2, Batch: 48,Loss: 1.328,Avg.Loss: 1.884,LR: 5.00E-04]Training epoch 2:  43%|████▎     | 48/112 [00:00<00:01, 49.98it/s, Epoch: 2, Batch: 49,Loss: 1.325,Avg.Loss: 1.873,LR: 5.00E-04]Training epoch 2:  44%|████▍     | 49/112 [00:00<00:01, 49.98it/s, Epoch: 2, Batch: 50,Loss: 1.592,Avg.Loss: 1.867,LR: 5.00E-04]Training epoch 2:  45%|████▍     | 50/112 [00:00<00:01, 49.98it/s, Epoch: 2, Batch: 51,Loss: 1.312,Avg.Loss: 1.856,LR: 5.00E-04]Training epoch 2:  46%|████▌     | 51/112 [00:01<00:01, 49.98it/s, Epoch: 2, Batch: 52,Loss: 1.908,Avg.Loss: 1.857,LR: 5.00E-04]Training epoch 2:  46%|████▋     | 52/112 [00:01<00:01, 49.98it/s, Epoch: 2, Batch: 53,Loss: 1.550,Avg.Loss: 1.851,LR: 5.00E-04]Training epoch 2:  47%|████▋     | 53/112 [00:01<00:01, 49.98it/s, Epoch: 2, Batch: 54,Loss: 1.217,Avg.Loss: 1.840,LR: 5.00E-04]Training epoch 2:  48%|████▊     | 54/112 [00:01<00:01, 49.10it/s, Epoch: 2, Batch: 54,Loss: 1.217,Avg.Loss: 1.840,LR: 5.00E-04]Training epoch 2:  48%|████▊     | 54/112 [00:01<00:01, 49.10it/s, Epoch: 2, Batch: 55,Loss: 1.794,Avg.Loss: 1.839,LR: 5.00E-04]Training epoch 2:  49%|████▉     | 55/112 [00:01<00:01, 49.10it/s, Epoch: 2, Batch: 56,Loss: 1.539,Avg.Loss: 1.833,LR: 5.00E-04]Training epoch 2:  50%|█████     | 56/112 [00:01<00:01, 49.10it/s, Epoch: 2, Batch: 57,Loss: 1.198,Avg.Loss: 1.822,LR: 5.00E-04]Training epoch 2:  51%|█████     | 57/112 [00:01<00:01, 49.10it/s, Epoch: 2, Batch: 58,Loss: 1.316,Avg.Loss: 1.814,LR: 5.00E-04]Training epoch 2:  52%|█████▏    | 58/112 [00:01<00:01, 49.10it/s, Epoch: 2, Batch: 59,Loss: 1.173,Avg.Loss: 1.803,LR: 5.00E-04]Training epoch 2:  53%|█████▎    | 59/112 [00:01<00:01, 48.15it/s, Epoch: 2, Batch: 59,Loss: 1.173,Avg.Loss: 1.803,LR: 5.00E-04]Training epoch 2:  53%|█████▎    | 59/112 [00:01<00:01, 48.15it/s, Epoch: 2, Batch: 60,Loss: 1.290,Avg.Loss: 1.794,LR: 5.00E-04]Training epoch 2:  54%|█████▎    | 60/112 [00:01<00:01, 48.15it/s, Epoch: 2, Batch: 61,Loss: 1.824,Avg.Loss: 1.795,LR: 5.00E-04]Training epoch 2:  54%|█████▍    | 61/112 [00:01<00:01, 48.15it/s, Epoch: 2, Batch: 62,Loss: 1.436,Avg.Loss: 1.789,LR: 5.00E-04]Training epoch 2:  55%|█████▌    | 62/112 [00:01<00:01, 48.15it/s, Epoch: 2, Batch: 63,Loss: 2.087,Avg.Loss: 1.794,LR: 5.00E-04]Training epoch 2:  56%|█████▋    | 63/112 [00:01<00:01, 48.15it/s, Epoch: 2, Batch: 64,Loss: 1.531,Avg.Loss: 1.790,LR: 5.00E-04]Training epoch 2:  57%|█████▋    | 64/112 [00:01<00:01, 45.57it/s, Epoch: 2, Batch: 64,Loss: 1.531,Avg.Loss: 1.790,LR: 5.00E-04]Training epoch 2:  57%|█████▋    | 64/112 [00:01<00:01, 45.57it/s, Epoch: 2, Batch: 65,Loss: 1.535,Avg.Loss: 1.786,LR: 5.00E-04]Training epoch 2:  58%|█████▊    | 65/112 [00:01<00:01, 45.57it/s, Epoch: 2, Batch: 66,Loss: 1.931,Avg.Loss: 1.788,LR: 5.00E-04]Training epoch 2:  59%|█████▉    | 66/112 [00:01<00:01, 45.57it/s, Epoch: 2, Batch: 67,Loss: 2.011,Avg.Loss: 1.791,LR: 5.00E-04]Training epoch 2:  60%|█████▉    | 67/112 [00:01<00:00, 45.57it/s, Epoch: 2, Batch: 68,Loss: 1.658,Avg.Loss: 1.789,LR: 5.00E-04]Training epoch 2:  61%|██████    | 68/112 [00:01<00:00, 45.57it/s, Epoch: 2, Batch: 69,Loss: 1.205,Avg.Loss: 1.781,LR: 5.00E-04]Training epoch 2:  62%|██████▏   | 69/112 [00:01<00:00, 45.57it/s, Epoch: 2, Batch: 70,Loss: 1.838,Avg.Loss: 1.782,LR: 5.00E-04]Training epoch 2:  62%|██████▎   | 70/112 [00:01<00:00, 47.42it/s, Epoch: 2, Batch: 70,Loss: 1.838,Avg.Loss: 1.782,LR: 5.00E-04]Training epoch 2:  62%|██████▎   | 70/112 [00:01<00:00, 47.42it/s, Epoch: 2, Batch: 71,Loss: 1.654,Avg.Loss: 1.780,LR: 5.00E-04]Training epoch 2:  63%|██████▎   | 71/112 [00:01<00:00, 47.42it/s, Epoch: 2, Batch: 72,Loss: 2.385,Avg.Loss: 1.788,LR: 5.00E-04]Training epoch 2:  64%|██████▍   | 72/112 [00:01<00:00, 47.42it/s, Epoch: 2, Batch: 73,Loss: 1.749,Avg.Loss: 1.788,LR: 5.00E-04]Training epoch 2:  65%|██████▌   | 73/112 [00:01<00:00, 47.42it/s, Epoch: 2, Batch: 74,Loss: 1.874,Avg.Loss: 1.789,LR: 5.00E-04]Training epoch 2:  66%|██████▌   | 74/112 [00:01<00:00, 47.42it/s, Epoch: 2, Batch: 75,Loss: 2.783,Avg.Loss: 1.802,LR: 5.00E-04]Training epoch 2:  67%|██████▋   | 75/112 [00:01<00:00, 47.42it/s, Epoch: 2, Batch: 76,Loss: 2.230,Avg.Loss: 1.808,LR: 5.00E-04]Training epoch 2:  68%|██████▊   | 76/112 [00:01<00:00, 48.79it/s, Epoch: 2, Batch: 76,Loss: 2.230,Avg.Loss: 1.808,LR: 5.00E-04]Training epoch 2:  68%|██████▊   | 76/112 [00:01<00:00, 48.79it/s, Epoch: 2, Batch: 77,Loss: 2.542,Avg.Loss: 1.817,LR: 5.00E-04]Training epoch 2:  69%|██████▉   | 77/112 [00:01<00:00, 48.79it/s, Epoch: 2, Batch: 78,Loss: 1.664,Avg.Loss: 1.815,LR: 5.00E-04]Training epoch 2:  70%|██████▉   | 78/112 [00:01<00:00, 48.79it/s, Epoch: 2, Batch: 79,Loss: 1.683,Avg.Loss: 1.814,LR: 5.00E-04]Training epoch 2:  71%|███████   | 79/112 [00:01<00:00, 48.79it/s, Epoch: 2, Batch: 80,Loss: 2.062,Avg.Loss: 1.817,LR: 5.00E-04]Training epoch 2:  71%|███████▏  | 80/112 [00:01<00:00, 48.79it/s, Epoch: 2, Batch: 81,Loss: 3.009,Avg.Loss: 1.831,LR: 5.00E-04]Training epoch 2:  72%|███████▏  | 81/112 [00:01<00:00, 48.90it/s, Epoch: 2, Batch: 81,Loss: 3.009,Avg.Loss: 1.831,LR: 5.00E-04]Training epoch 2:  72%|███████▏  | 81/112 [00:01<00:00, 48.90it/s, Epoch: 2, Batch: 82,Loss: 2.372,Avg.Loss: 1.838,LR: 5.00E-04]Training epoch 2:  73%|███████▎  | 82/112 [00:01<00:00, 48.90it/s, Epoch: 2, Batch: 83,Loss: 2.642,Avg.Loss: 1.848,LR: 5.00E-04]Training epoch 2:  74%|███████▍  | 83/112 [00:01<00:00, 48.90it/s, Epoch: 2, Batch: 84,Loss: 2.091,Avg.Loss: 1.851,LR: 5.00E-04]Training epoch 2:  75%|███████▌  | 84/112 [00:01<00:00, 48.90it/s, Epoch: 2, Batch: 85,Loss: 1.217,Avg.Loss: 1.843,LR: 5.00E-04]Training epoch 2:  76%|███████▌  | 85/112 [00:01<00:00, 48.90it/s, Epoch: 2, Batch: 86,Loss: 1.574,Avg.Loss: 1.840,LR: 5.00E-04]Training epoch 2:  77%|███████▋  | 86/112 [00:01<00:00, 48.30it/s, Epoch: 2, Batch: 86,Loss: 1.574,Avg.Loss: 1.840,LR: 5.00E-04]Training epoch 2:  77%|███████▋  | 86/112 [00:01<00:00, 48.30it/s, Epoch: 2, Batch: 87,Loss: 2.247,Avg.Loss: 1.845,LR: 5.00E-04]Training epoch 2:  78%|███████▊  | 87/112 [00:01<00:00, 48.30it/s, Epoch: 2, Batch: 88,Loss: 2.122,Avg.Loss: 1.848,LR: 5.00E-04]Training epoch 2:  79%|███████▊  | 88/112 [00:01<00:00, 48.30it/s, Epoch: 2, Batch: 89,Loss: 2.100,Avg.Loss: 1.851,LR: 5.00E-04]Training epoch 2:  79%|███████▉  | 89/112 [00:01<00:00, 48.30it/s, Epoch: 2, Batch: 90,Loss: 1.517,Avg.Loss: 1.847,LR: 5.00E-04]Training epoch 2:  80%|████████  | 90/112 [00:01<00:00, 48.30it/s, Epoch: 2, Batch: 91,Loss: 1.442,Avg.Loss: 1.842,LR: 5.00E-04]Training epoch 2:  81%|████████▏ | 91/112 [00:01<00:00, 48.30it/s, Epoch: 2, Batch: 92,Loss: 2.088,Avg.Loss: 1.845,LR: 5.00E-04]Training epoch 2:  82%|████████▏ | 92/112 [00:01<00:00, 49.41it/s, Epoch: 2, Batch: 92,Loss: 2.088,Avg.Loss: 1.845,LR: 5.00E-04]Training epoch 2:  82%|████████▏ | 92/112 [00:01<00:00, 49.41it/s, Epoch: 2, Batch: 93,Loss: 1.972,Avg.Loss: 1.847,LR: 5.00E-04]Training epoch 2:  83%|████████▎ | 93/112 [00:01<00:00, 49.41it/s, Epoch: 2, Batch: 94,Loss: 2.672,Avg.Loss: 1.855,LR: 5.00E-04]Training epoch 2:  84%|████████▍ | 94/112 [00:01<00:00, 49.41it/s, Epoch: 2, Batch: 95,Loss: 2.071,Avg.Loss: 1.858,LR: 5.00E-04]Training epoch 2:  85%|████████▍ | 95/112 [00:01<00:00, 49.41it/s, Epoch: 2, Batch: 96,Loss: 1.640,Avg.Loss: 1.855,LR: 5.00E-04]Training epoch 2:  86%|████████▌ | 96/112 [00:01<00:00, 49.41it/s, Epoch: 2, Batch: 97,Loss: 1.261,Avg.Loss: 1.849,LR: 5.00E-04]Training epoch 2:  87%|████████▋ | 97/112 [00:01<00:00, 49.43it/s, Epoch: 2, Batch: 97,Loss: 1.261,Avg.Loss: 1.849,LR: 5.00E-04]Training epoch 2:  87%|████████▋ | 97/112 [00:01<00:00, 49.43it/s, Epoch: 2, Batch: 98,Loss: 1.527,Avg.Loss: 1.846,LR: 5.00E-04]Training epoch 2:  88%|████████▊ | 98/112 [00:01<00:00, 49.43it/s, Epoch: 2, Batch: 99,Loss: 1.716,Avg.Loss: 1.845,LR: 5.00E-04]Training epoch 2:  88%|████████▊ | 99/112 [00:02<00:00, 49.43it/s, Epoch: 2, Batch: 100,Loss: 1.550,Avg.Loss: 1.842,LR: 5.00E-04]Training epoch 2:  89%|████████▉ | 100/112 [00:02<00:00, 49.43it/s, Epoch: 2, Batch: 101,Loss: 1.821,Avg.Loss: 1.841,LR: 5.00E-04]Training epoch 2:  90%|█████████ | 101/112 [00:02<00:00, 49.43it/s, Epoch: 2, Batch: 102,Loss: 1.330,Avg.Loss: 1.836,LR: 5.00E-04]Training epoch 2:  91%|█████████ | 102/112 [00:02<00:00, 49.43it/s, Epoch: 2, Batch: 103,Loss: 1.473,Avg.Loss: 1.833,LR: 5.00E-04]Training epoch 2:  92%|█████████▏| 103/112 [00:02<00:00, 50.25it/s, Epoch: 2, Batch: 103,Loss: 1.473,Avg.Loss: 1.833,LR: 5.00E-04]Training epoch 2:  92%|█████████▏| 103/112 [00:02<00:00, 50.25it/s, Epoch: 2, Batch: 104,Loss: 1.656,Avg.Loss: 1.831,LR: 5.00E-04]Training epoch 2:  93%|█████████▎| 104/112 [00:02<00:00, 50.25it/s, Epoch: 2, Batch: 105,Loss: 1.773,Avg.Loss: 1.831,LR: 5.00E-04]Training epoch 2:  94%|█████████▍| 105/112 [00:02<00:00, 50.25it/s, Epoch: 2, Batch: 106,Loss: 1.638,Avg.Loss: 1.829,LR: 5.00E-04]Training epoch 2:  95%|█████████▍| 106/112 [00:02<00:00, 50.25it/s, Epoch: 2, Batch: 107,Loss: 1.437,Avg.Loss: 1.825,LR: 5.00E-04]Training epoch 2:  96%|█████████▌| 107/112 [00:02<00:00, 50.25it/s, Epoch: 2, Batch: 108,Loss: 1.363,Avg.Loss: 1.821,LR: 5.00E-04]Training epoch 2:  96%|█████████▋| 108/112 [00:02<00:00, 50.25it/s, Epoch: 2, Batch: 109,Loss: 1.886,Avg.Loss: 1.821,LR: 5.00E-04]Training epoch 2:  97%|█████████▋| 109/112 [00:02<00:00, 51.02it/s, Epoch: 2, Batch: 109,Loss: 1.886,Avg.Loss: 1.821,LR: 5.00E-04]Training epoch 2:  97%|█████████▋| 109/112 [00:02<00:00, 51.02it/s, Epoch: 2, Batch: 110,Loss: 2.459,Avg.Loss: 1.827,LR: 5.00E-04]Training epoch 2:  98%|█████████▊| 110/112 [00:02<00:00, 51.02it/s, Epoch: 2, Batch: 111,Loss: 2.643,Avg.Loss: 1.835,LR: 5.00E-04]Training epoch 2:  99%|█████████▉| 111/112 [00:02<00:00, 51.02it/s, Epoch: 2, Batch: 112,Loss: 4.973,Avg.Loss: 1.863,LR: 5.00E-04]Training epoch 2: 100%|██████████| 112/112 [00:02<00:00, 49.90it/s, Epoch: 2, Batch: 112,Loss: 4.973,Avg.Loss: 1.863,LR: 5.00E-04]
Training epoch 3:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 3:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 3, Batch: 1,Loss: 2.346,Avg.Loss: 2.346,LR: 5.00E-04]Training epoch 3:   1%|          | 1/112 [00:00<00:04, 23.57it/s, Epoch: 3, Batch: 2,Loss: 1.824,Avg.Loss: 2.085,LR: 4.99E-04]Training epoch 3:   2%|▏         | 2/112 [00:00<00:03, 34.27it/s, Epoch: 3, Batch: 3,Loss: 1.532,Avg.Loss: 1.901,LR: 4.99E-04]Training epoch 3:   3%|▎         | 3/112 [00:00<00:02, 41.23it/s, Epoch: 3, Batch: 4,Loss: 2.434,Avg.Loss: 2.034,LR: 4.99E-04]Training epoch 3:   4%|▎         | 4/112 [00:00<00:02, 45.92it/s, Epoch: 3, Batch: 5,Loss: 2.468,Avg.Loss: 2.121,LR: 4.99E-04]Training epoch 3:   4%|▍         | 5/112 [00:00<00:02, 47.10it/s, Epoch: 3, Batch: 6,Loss: 2.762,Avg.Loss: 2.228,LR: 4.99E-04]Training epoch 3:   5%|▌         | 6/112 [00:00<00:01, 56.43it/s, Epoch: 3, Batch: 6,Loss: 2.762,Avg.Loss: 2.228,LR: 4.99E-04]Training epoch 3:   5%|▌         | 6/112 [00:00<00:01, 56.43it/s, Epoch: 3, Batch: 7,Loss: 4.258,Avg.Loss: 2.518,LR: 4.99E-04]Training epoch 3:   6%|▋         | 7/112 [00:00<00:01, 56.43it/s, Epoch: 3, Batch: 8,Loss: 2.673,Avg.Loss: 2.537,LR: 4.99E-04]Training epoch 3:   7%|▋         | 8/112 [00:00<00:01, 56.43it/s, Epoch: 3, Batch: 9,Loss: 1.849,Avg.Loss: 2.461,LR: 4.99E-04]Training epoch 3:   8%|▊         | 9/112 [00:00<00:01, 56.43it/s, Epoch: 3, Batch: 10,Loss: 1.474,Avg.Loss: 2.362,LR: 4.99E-04]Training epoch 3:   9%|▉         | 10/112 [00:00<00:01, 56.43it/s, Epoch: 3, Batch: 11,Loss: 1.676,Avg.Loss: 2.300,LR: 4.99E-04]Training epoch 3:  10%|▉         | 11/112 [00:00<00:01, 56.43it/s, Epoch: 3, Batch: 12,Loss: 1.711,Avg.Loss: 2.251,LR: 4.99E-04]Training epoch 3:  11%|█         | 12/112 [00:00<00:01, 56.43it/s, Epoch: 3, Batch: 13,Loss: 1.453,Avg.Loss: 2.189,LR: 4.99E-04]Training epoch 3:  12%|█▏        | 13/112 [00:00<00:01, 62.27it/s, Epoch: 3, Batch: 13,Loss: 1.453,Avg.Loss: 2.189,LR: 4.99E-04]Training epoch 3:  12%|█▏        | 13/112 [00:00<00:01, 62.27it/s, Epoch: 3, Batch: 14,Loss: 1.623,Avg.Loss: 2.149,LR: 4.99E-04]Training epoch 3:  12%|█▎        | 14/112 [00:00<00:01, 62.27it/s, Epoch: 3, Batch: 15,Loss: 1.439,Avg.Loss: 2.101,LR: 4.99E-04]Training epoch 3:  13%|█▎        | 15/112 [00:00<00:01, 62.27it/s, Epoch: 3, Batch: 16,Loss: 1.318,Avg.Loss: 2.053,LR: 4.99E-04]Training epoch 3:  14%|█▍        | 16/112 [00:00<00:01, 62.27it/s, Epoch: 3, Batch: 17,Loss: 1.440,Avg.Loss: 2.016,LR: 4.99E-04]Training epoch 3:  15%|█▌        | 17/112 [00:00<00:01, 62.27it/s, Epoch: 3, Batch: 18,Loss: 1.552,Avg.Loss: 1.991,LR: 4.99E-04]Training epoch 3:  16%|█▌        | 18/112 [00:00<00:01, 62.27it/s, Epoch: 3, Batch: 19,Loss: 1.273,Avg.Loss: 1.953,LR: 4.99E-04]Training epoch 3:  17%|█▋        | 19/112 [00:00<00:01, 62.27it/s, Epoch: 3, Batch: 20,Loss: 1.653,Avg.Loss: 1.938,LR: 4.99E-04]Training epoch 3:  18%|█▊        | 20/112 [00:00<00:01, 58.58it/s, Epoch: 3, Batch: 20,Loss: 1.653,Avg.Loss: 1.938,LR: 4.99E-04]Training epoch 3:  18%|█▊        | 20/112 [00:00<00:01, 58.58it/s, Epoch: 3, Batch: 21,Loss: 1.548,Avg.Loss: 1.919,LR: 4.99E-04]Training epoch 3:  19%|█▉        | 21/112 [00:00<00:01, 58.58it/s, Epoch: 3, Batch: 22,Loss: 1.705,Avg.Loss: 1.910,LR: 4.99E-04]Training epoch 3:  20%|█▉        | 22/112 [00:00<00:01, 58.58it/s, Epoch: 3, Batch: 23,Loss: 1.327,Avg.Loss: 1.884,LR: 4.99E-04]Training epoch 3:  21%|██        | 23/112 [00:00<00:01, 58.58it/s, Epoch: 3, Batch: 24,Loss: 1.673,Avg.Loss: 1.875,LR: 4.99E-04]Training epoch 3:  21%|██▏       | 24/112 [00:00<00:01, 58.58it/s, Epoch: 3, Batch: 25,Loss: 1.320,Avg.Loss: 1.853,LR: 4.99E-04]Training epoch 3:  22%|██▏       | 25/112 [00:00<00:01, 58.58it/s, Epoch: 3, Batch: 26,Loss: 1.694,Avg.Loss: 1.847,LR: 4.99E-04]Training epoch 3:  23%|██▎       | 26/112 [00:00<00:01, 57.07it/s, Epoch: 3, Batch: 26,Loss: 1.694,Avg.Loss: 1.847,LR: 4.99E-04]Training epoch 3:  23%|██▎       | 26/112 [00:00<00:01, 57.07it/s, Epoch: 3, Batch: 27,Loss: 1.370,Avg.Loss: 1.829,LR: 4.99E-04]Training epoch 3:  24%|██▍       | 27/112 [00:00<00:01, 57.07it/s, Epoch: 3, Batch: 28,Loss: 1.408,Avg.Loss: 1.814,LR: 4.99E-04]Training epoch 3:  25%|██▌       | 28/112 [00:00<00:01, 57.07it/s, Epoch: 3, Batch: 29,Loss: 1.186,Avg.Loss: 1.793,LR: 4.99E-04]Training epoch 3:  26%|██▌       | 29/112 [00:00<00:01, 57.07it/s, Epoch: 3, Batch: 30,Loss: 1.385,Avg.Loss: 1.779,LR: 4.99E-04]Training epoch 3:  27%|██▋       | 30/112 [00:00<00:01, 57.07it/s, Epoch: 3, Batch: 31,Loss: 1.178,Avg.Loss: 1.760,LR: 4.99E-04]Training epoch 3:  28%|██▊       | 31/112 [00:00<00:01, 57.07it/s, Epoch: 3, Batch: 32,Loss: 1.455,Avg.Loss: 1.750,LR: 4.99E-04]Training epoch 3:  29%|██▊       | 32/112 [00:00<00:01, 56.13it/s, Epoch: 3, Batch: 32,Loss: 1.455,Avg.Loss: 1.750,LR: 4.99E-04]Training epoch 3:  29%|██▊       | 32/112 [00:00<00:01, 56.13it/s, Epoch: 3, Batch: 33,Loss: 1.297,Avg.Loss: 1.736,LR: 4.99E-04]Training epoch 3:  29%|██▉       | 33/112 [00:00<00:01, 56.13it/s, Epoch: 3, Batch: 34,Loss: 1.280,Avg.Loss: 1.723,LR: 4.99E-04]Training epoch 3:  30%|███       | 34/112 [00:00<00:01, 56.13it/s, Epoch: 3, Batch: 35,Loss: 1.195,Avg.Loss: 1.708,LR: 4.99E-04]Training epoch 3:  31%|███▏      | 35/112 [00:00<00:01, 56.13it/s, Epoch: 3, Batch: 36,Loss: 1.198,Avg.Loss: 1.694,LR: 4.99E-04]Training epoch 3:  32%|███▏      | 36/112 [00:00<00:01, 56.13it/s, Epoch: 3, Batch: 37,Loss: 1.217,Avg.Loss: 1.681,LR: 4.99E-04]Training epoch 3:  33%|███▎      | 37/112 [00:00<00:01, 56.13it/s, Epoch: 3, Batch: 38,Loss: 1.338,Avg.Loss: 1.672,LR: 4.99E-04]Training epoch 3:  34%|███▍      | 38/112 [00:00<00:01, 55.54it/s, Epoch: 3, Batch: 38,Loss: 1.338,Avg.Loss: 1.672,LR: 4.99E-04]Training epoch 3:  34%|███▍      | 38/112 [00:00<00:01, 55.54it/s, Epoch: 3, Batch: 39,Loss: 1.571,Avg.Loss: 1.669,LR: 4.99E-04]Training epoch 3:  35%|███▍      | 39/112 [00:00<00:01, 55.54it/s, Epoch: 3, Batch: 40,Loss: 1.371,Avg.Loss: 1.662,LR: 4.99E-04]Training epoch 3:  36%|███▌      | 40/112 [00:00<00:01, 55.54it/s, Epoch: 3, Batch: 41,Loss: 1.273,Avg.Loss: 1.652,LR: 4.99E-04]Training epoch 3:  37%|███▋      | 41/112 [00:00<00:01, 55.54it/s, Epoch: 3, Batch: 42,Loss: 1.707,Avg.Loss: 1.654,LR: 4.99E-04]Training epoch 3:  38%|███▊      | 42/112 [00:00<00:01, 55.54it/s, Epoch: 3, Batch: 43,Loss: 1.199,Avg.Loss: 1.643,LR: 4.99E-04]Training epoch 3:  38%|███▊      | 43/112 [00:00<00:01, 55.54it/s, Epoch: 3, Batch: 44,Loss: 1.032,Avg.Loss: 1.629,LR: 4.99E-04]Training epoch 3:  39%|███▉      | 44/112 [00:00<00:01, 55.06it/s, Epoch: 3, Batch: 44,Loss: 1.032,Avg.Loss: 1.629,LR: 4.99E-04]Training epoch 3:  39%|███▉      | 44/112 [00:00<00:01, 55.06it/s, Epoch: 3, Batch: 45,Loss: 1.437,Avg.Loss: 1.625,LR: 4.99E-04]Training epoch 3:  40%|████      | 45/112 [00:00<00:01, 55.06it/s, Epoch: 3, Batch: 46,Loss: 2.517,Avg.Loss: 1.644,LR: 4.99E-04]Training epoch 3:  41%|████      | 46/112 [00:00<00:01, 55.06it/s, Epoch: 3, Batch: 47,Loss: 1.946,Avg.Loss: 1.651,LR: 4.99E-04]Training epoch 3:  42%|████▏     | 47/112 [00:00<00:01, 55.06it/s, Epoch: 3, Batch: 48,Loss: 1.400,Avg.Loss: 1.646,LR: 4.99E-04]Training epoch 3:  43%|████▎     | 48/112 [00:00<00:01, 55.06it/s, Epoch: 3, Batch: 49,Loss: 1.364,Avg.Loss: 1.640,LR: 4.99E-04]Training epoch 3:  44%|████▍     | 49/112 [00:00<00:01, 55.06it/s, Epoch: 3, Batch: 50,Loss: 1.518,Avg.Loss: 1.637,LR: 4.99E-04]Training epoch 3:  45%|████▍     | 50/112 [00:00<00:01, 54.92it/s, Epoch: 3, Batch: 50,Loss: 1.518,Avg.Loss: 1.637,LR: 4.99E-04]Training epoch 3:  45%|████▍     | 50/112 [00:00<00:01, 54.92it/s, Epoch: 3, Batch: 51,Loss: 1.357,Avg.Loss: 1.632,LR: 4.99E-04]Training epoch 3:  46%|████▌     | 51/112 [00:00<00:01, 54.92it/s, Epoch: 3, Batch: 52,Loss: 1.109,Avg.Loss: 1.622,LR: 4.99E-04]Training epoch 3:  46%|████▋     | 52/112 [00:00<00:01, 54.92it/s, Epoch: 3, Batch: 53,Loss: 1.339,Avg.Loss: 1.616,LR: 4.99E-04]Training epoch 3:  47%|████▋     | 53/112 [00:00<00:01, 54.92it/s, Epoch: 3, Batch: 54,Loss: 1.288,Avg.Loss: 1.610,LR: 4.99E-04]Training epoch 3:  48%|████▊     | 54/112 [00:00<00:01, 54.92it/s, Epoch: 3, Batch: 55,Loss: 1.413,Avg.Loss: 1.607,LR: 4.99E-04]Training epoch 3:  49%|████▉     | 55/112 [00:01<00:01, 54.92it/s, Epoch: 3, Batch: 56,Loss: 1.879,Avg.Loss: 1.612,LR: 4.99E-04]Training epoch 3:  50%|█████     | 56/112 [00:01<00:01, 54.74it/s, Epoch: 3, Batch: 56,Loss: 1.879,Avg.Loss: 1.612,LR: 4.99E-04]Training epoch 3:  50%|█████     | 56/112 [00:01<00:01, 54.74it/s, Epoch: 3, Batch: 57,Loss: 1.821,Avg.Loss: 1.615,LR: 4.99E-04]Training epoch 3:  51%|█████     | 57/112 [00:01<00:01, 54.74it/s, Epoch: 3, Batch: 58,Loss: 1.213,Avg.Loss: 1.608,LR: 4.99E-04]Training epoch 3:  52%|█████▏    | 58/112 [00:01<00:00, 54.74it/s, Epoch: 3, Batch: 59,Loss: 1.080,Avg.Loss: 1.599,LR: 4.99E-04]Training epoch 3:  53%|█████▎    | 59/112 [00:01<00:00, 54.74it/s, Epoch: 3, Batch: 60,Loss: 2.299,Avg.Loss: 1.611,LR: 4.99E-04]Training epoch 3:  54%|█████▎    | 60/112 [00:01<00:00, 54.74it/s, Epoch: 3, Batch: 61,Loss: 1.746,Avg.Loss: 1.613,LR: 4.99E-04]Training epoch 3:  54%|█████▍    | 61/112 [00:01<00:00, 54.74it/s, Epoch: 3, Batch: 62,Loss: 1.513,Avg.Loss: 1.612,LR: 4.99E-04]Training epoch 3:  55%|█████▌    | 62/112 [00:01<00:00, 54.77it/s, Epoch: 3, Batch: 62,Loss: 1.513,Avg.Loss: 1.612,LR: 4.99E-04]Training epoch 3:  55%|█████▌    | 62/112 [00:01<00:00, 54.77it/s, Epoch: 3, Batch: 63,Loss: 1.243,Avg.Loss: 1.606,LR: 4.99E-04]Training epoch 3:  56%|█████▋    | 63/112 [00:01<00:00, 54.77it/s, Epoch: 3, Batch: 64,Loss: 1.224,Avg.Loss: 1.600,LR: 4.99E-04]Training epoch 3:  57%|█████▋    | 64/112 [00:01<00:00, 54.77it/s, Epoch: 3, Batch: 65,Loss: 1.754,Avg.Loss: 1.602,LR: 4.99E-04]Training epoch 3:  58%|█████▊    | 65/112 [00:01<00:00, 54.77it/s, Epoch: 3, Batch: 66,Loss: 2.692,Avg.Loss: 1.619,LR: 4.99E-04]Training epoch 3:  59%|█████▉    | 66/112 [00:01<00:00, 54.77it/s, Epoch: 3, Batch: 67,Loss: 2.372,Avg.Loss: 1.630,LR: 4.99E-04]Training epoch 3:  60%|█████▉    | 67/112 [00:01<00:00, 54.77it/s, Epoch: 3, Batch: 68,Loss: 2.524,Avg.Loss: 1.643,LR: 4.99E-04]Training epoch 3:  61%|██████    | 68/112 [00:01<00:00, 54.58it/s, Epoch: 3, Batch: 68,Loss: 2.524,Avg.Loss: 1.643,LR: 4.99E-04]Training epoch 3:  61%|██████    | 68/112 [00:01<00:00, 54.58it/s, Epoch: 3, Batch: 69,Loss: 1.462,Avg.Loss: 1.641,LR: 4.99E-04]Training epoch 3:  62%|██████▏   | 69/112 [00:01<00:00, 54.58it/s, Epoch: 3, Batch: 70,Loss: 1.096,Avg.Loss: 1.633,LR: 4.99E-04]Training epoch 3:  62%|██████▎   | 70/112 [00:01<00:00, 54.58it/s, Epoch: 3, Batch: 71,Loss: 0.849,Avg.Loss: 1.622,LR: 4.99E-04]Training epoch 3:  63%|██████▎   | 71/112 [00:01<00:00, 54.58it/s, Epoch: 3, Batch: 72,Loss: 1.420,Avg.Loss: 1.619,LR: 4.99E-04]Training epoch 3:  64%|██████▍   | 72/112 [00:01<00:00, 54.58it/s, Epoch: 3, Batch: 73,Loss: 1.279,Avg.Loss: 1.614,LR: 4.99E-04]Training epoch 3:  65%|██████▌   | 73/112 [00:01<00:00, 54.58it/s, Epoch: 3, Batch: 74,Loss: 1.849,Avg.Loss: 1.617,LR: 4.99E-04]Training epoch 3:  66%|██████▌   | 74/112 [00:01<00:00, 54.10it/s, Epoch: 3, Batch: 74,Loss: 1.849,Avg.Loss: 1.617,LR: 4.99E-04]Training epoch 3:  66%|██████▌   | 74/112 [00:01<00:00, 54.10it/s, Epoch: 3, Batch: 75,Loss: 1.147,Avg.Loss: 1.611,LR: 4.99E-04]Training epoch 3:  67%|██████▋   | 75/112 [00:01<00:00, 54.10it/s, Epoch: 3, Batch: 76,Loss: 1.044,Avg.Loss: 1.604,LR: 4.99E-04]Training epoch 3:  68%|██████▊   | 76/112 [00:01<00:00, 54.10it/s, Epoch: 3, Batch: 77,Loss: 1.230,Avg.Loss: 1.599,LR: 4.99E-04]Training epoch 3:  69%|██████▉   | 77/112 [00:01<00:00, 54.10it/s, Epoch: 3, Batch: 78,Loss: 0.917,Avg.Loss: 1.590,LR: 4.99E-04]Training epoch 3:  70%|██████▉   | 78/112 [00:01<00:00, 54.10it/s, Epoch: 3, Batch: 79,Loss: 0.871,Avg.Loss: 1.581,LR: 4.99E-04]Training epoch 3:  71%|███████   | 79/112 [00:01<00:00, 54.10it/s, Epoch: 3, Batch: 80,Loss: 1.109,Avg.Loss: 1.575,LR: 4.99E-04]Training epoch 3:  71%|███████▏  | 80/112 [00:01<00:00, 53.95it/s, Epoch: 3, Batch: 80,Loss: 1.109,Avg.Loss: 1.575,LR: 4.99E-04]Training epoch 3:  71%|███████▏  | 80/112 [00:01<00:00, 53.95it/s, Epoch: 3, Batch: 81,Loss: 1.039,Avg.Loss: 1.568,LR: 4.99E-04]Training epoch 3:  72%|███████▏  | 81/112 [00:01<00:00, 53.95it/s, Epoch: 3, Batch: 82,Loss: 1.178,Avg.Loss: 1.564,LR: 4.99E-04]Training epoch 3:  73%|███████▎  | 82/112 [00:01<00:00, 53.95it/s, Epoch: 3, Batch: 83,Loss: 1.138,Avg.Loss: 1.559,LR: 4.99E-04]Training epoch 3:  74%|███████▍  | 83/112 [00:01<00:00, 53.95it/s, Epoch: 3, Batch: 84,Loss: 0.951,Avg.Loss: 1.551,LR: 4.99E-04]Training epoch 3:  75%|███████▌  | 84/112 [00:01<00:00, 53.95it/s, Epoch: 3, Batch: 85,Loss: 0.844,Avg.Loss: 1.543,LR: 4.99E-04]Training epoch 3:  76%|███████▌  | 85/112 [00:01<00:00, 53.95it/s, Epoch: 3, Batch: 86,Loss: 0.737,Avg.Loss: 1.534,LR: 4.99E-04]Training epoch 3:  77%|███████▋  | 86/112 [00:01<00:00, 53.84it/s, Epoch: 3, Batch: 86,Loss: 0.737,Avg.Loss: 1.534,LR: 4.99E-04]Training epoch 3:  77%|███████▋  | 86/112 [00:01<00:00, 53.84it/s, Epoch: 3, Batch: 87,Loss: 0.865,Avg.Loss: 1.526,LR: 4.99E-04]Training epoch 3:  78%|███████▊  | 87/112 [00:01<00:00, 53.84it/s, Epoch: 3, Batch: 88,Loss: 0.748,Avg.Loss: 1.517,LR: 4.99E-04]Training epoch 3:  79%|███████▊  | 88/112 [00:01<00:00, 53.84it/s, Epoch: 3, Batch: 89,Loss: 0.747,Avg.Loss: 1.508,LR: 4.99E-04]Training epoch 3:  79%|███████▉  | 89/112 [00:01<00:00, 53.84it/s, Epoch: 3, Batch: 90,Loss: 1.174,Avg.Loss: 1.505,LR: 4.99E-04]Training epoch 3:  80%|████████  | 90/112 [00:01<00:00, 53.84it/s, Epoch: 3, Batch: 91,Loss: 0.959,Avg.Loss: 1.499,LR: 4.99E-04]Training epoch 3:  81%|████████▏ | 91/112 [00:01<00:00, 53.84it/s, Epoch: 3, Batch: 92,Loss: 0.813,Avg.Loss: 1.491,LR: 4.99E-04]Training epoch 3:  82%|████████▏ | 92/112 [00:01<00:00, 53.65it/s, Epoch: 3, Batch: 92,Loss: 0.813,Avg.Loss: 1.491,LR: 4.99E-04]Training epoch 3:  82%|████████▏ | 92/112 [00:01<00:00, 53.65it/s, Epoch: 3, Batch: 93,Loss: 1.127,Avg.Loss: 1.487,LR: 4.99E-04]Training epoch 3:  83%|████████▎ | 93/112 [00:01<00:00, 53.65it/s, Epoch: 3, Batch: 94,Loss: 0.968,Avg.Loss: 1.482,LR: 4.99E-04]Training epoch 3:  84%|████████▍ | 94/112 [00:01<00:00, 53.65it/s, Epoch: 3, Batch: 95,Loss: 0.842,Avg.Loss: 1.475,LR: 4.99E-04]Training epoch 3:  85%|████████▍ | 95/112 [00:01<00:00, 53.65it/s, Epoch: 3, Batch: 96,Loss: 0.749,Avg.Loss: 1.468,LR: 4.99E-04]Training epoch 3:  86%|████████▌ | 96/112 [00:01<00:00, 53.65it/s, Epoch: 3, Batch: 97,Loss: 0.656,Avg.Loss: 1.459,LR: 4.99E-04]Training epoch 3:  87%|████████▋ | 97/112 [00:01<00:00, 53.65it/s, Epoch: 3, Batch: 98,Loss: 0.544,Avg.Loss: 1.450,LR: 4.99E-04]Training epoch 3:  88%|████████▊ | 98/112 [00:01<00:00, 53.50it/s, Epoch: 3, Batch: 98,Loss: 0.544,Avg.Loss: 1.450,LR: 4.99E-04]Training epoch 3:  88%|████████▊ | 98/112 [00:01<00:00, 53.50it/s, Epoch: 3, Batch: 99,Loss: 0.698,Avg.Loss: 1.442,LR: 4.99E-04]Training epoch 3:  88%|████████▊ | 99/112 [00:01<00:00, 53.50it/s, Epoch: 3, Batch: 100,Loss: 0.930,Avg.Loss: 1.437,LR: 4.99E-04]Training epoch 3:  89%|████████▉ | 100/112 [00:01<00:00, 53.50it/s, Epoch: 3, Batch: 101,Loss: 0.555,Avg.Loss: 1.428,LR: 4.99E-04]Training epoch 3:  90%|█████████ | 101/112 [00:01<00:00, 53.50it/s, Epoch: 3, Batch: 102,Loss: 0.693,Avg.Loss: 1.421,LR: 4.99E-04]Training epoch 3:  91%|█████████ | 102/112 [00:01<00:00, 53.50it/s, Epoch: 3, Batch: 103,Loss: 1.201,Avg.Loss: 1.419,LR: 4.99E-04]Training epoch 3:  92%|█████████▏| 103/112 [00:01<00:00, 53.50it/s, Epoch: 3, Batch: 104,Loss: 0.826,Avg.Loss: 1.413,LR: 4.99E-04]Training epoch 3:  93%|█████████▎| 104/112 [00:01<00:00, 53.42it/s, Epoch: 3, Batch: 104,Loss: 0.826,Avg.Loss: 1.413,LR: 4.99E-04]Training epoch 3:  93%|█████████▎| 104/112 [00:01<00:00, 53.42it/s, Epoch: 3, Batch: 105,Loss: 0.614,Avg.Loss: 1.406,LR: 4.99E-04]Training epoch 3:  94%|█████████▍| 105/112 [00:01<00:00, 53.42it/s, Epoch: 3, Batch: 106,Loss: 0.588,Avg.Loss: 1.398,LR: 4.99E-04]Training epoch 3:  95%|█████████▍| 106/112 [00:01<00:00, 53.42it/s, Epoch: 3, Batch: 107,Loss: 0.546,Avg.Loss: 1.390,LR: 4.99E-04]Training epoch 3:  96%|█████████▌| 107/112 [00:01<00:00, 53.42it/s, Epoch: 3, Batch: 108,Loss: 0.494,Avg.Loss: 1.382,LR: 4.99E-04]Training epoch 3:  96%|█████████▋| 108/112 [00:01<00:00, 53.42it/s, Epoch: 3, Batch: 109,Loss: 0.712,Avg.Loss: 1.376,LR: 4.99E-04]Training epoch 3:  97%|█████████▋| 109/112 [00:02<00:00, 53.42it/s, Epoch: 3, Batch: 110,Loss: 0.328,Avg.Loss: 1.366,LR: 4.99E-04]Training epoch 3:  98%|█████████▊| 110/112 [00:02<00:00, 53.38it/s, Epoch: 3, Batch: 110,Loss: 0.328,Avg.Loss: 1.366,LR: 4.99E-04]Training epoch 3:  98%|█████████▊| 110/112 [00:02<00:00, 53.38it/s, Epoch: 3, Batch: 111,Loss: 0.598,Avg.Loss: 1.359,LR: 4.99E-04]Training epoch 3:  99%|█████████▉| 111/112 [00:02<00:00, 53.38it/s, Epoch: 3, Batch: 112,Loss: 0.160,Avg.Loss: 1.348,LR: 4.99E-04]Training epoch 3: 100%|██████████| 112/112 [00:02<00:00, 54.64it/s, Epoch: 3, Batch: 112,Loss: 0.160,Avg.Loss: 1.348,LR: 4.99E-04]
Training epoch 4:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 4:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 4, Batch: 1,Loss: 0.429,Avg.Loss: 0.429,LR: 4.99E-04]Training epoch 4:   1%|          | 1/112 [00:00<00:04, 26.92it/s, Epoch: 4, Batch: 2,Loss: 0.302,Avg.Loss: 0.365,LR: 4.99E-04]Training epoch 4:   2%|▏         | 2/112 [00:00<00:02, 38.30it/s, Epoch: 4, Batch: 3,Loss: 0.549,Avg.Loss: 0.427,LR: 4.99E-04]Training epoch 4:   3%|▎         | 3/112 [00:00<00:02, 43.62it/s, Epoch: 4, Batch: 4,Loss: 0.479,Avg.Loss: 0.440,LR: 4.99E-04]Training epoch 4:   4%|▎         | 4/112 [00:00<00:02, 47.55it/s, Epoch: 4, Batch: 5,Loss: 0.841,Avg.Loss: 0.520,LR: 4.99E-04]Training epoch 4:   4%|▍         | 5/112 [00:00<00:02, 50.75it/s, Epoch: 4, Batch: 6,Loss: 1.080,Avg.Loss: 0.613,LR: 4.99E-04]Training epoch 4:   5%|▌         | 6/112 [00:00<00:01, 53.23it/s, Epoch: 4, Batch: 7,Loss: 0.704,Avg.Loss: 0.626,LR: 4.99E-04]Training epoch 4:   6%|▋         | 7/112 [00:00<00:01, 62.02it/s, Epoch: 4, Batch: 7,Loss: 0.704,Avg.Loss: 0.626,LR: 4.99E-04]Training epoch 4:   6%|▋         | 7/112 [00:00<00:01, 62.02it/s, Epoch: 4, Batch: 8,Loss: 0.411,Avg.Loss: 0.599,LR: 4.99E-04]Training epoch 4:   7%|▋         | 8/112 [00:00<00:01, 62.02it/s, Epoch: 4, Batch: 9,Loss: 0.350,Avg.Loss: 0.572,LR: 4.99E-04]Training epoch 4:   8%|▊         | 9/112 [00:00<00:01, 62.02it/s, Epoch: 4, Batch: 10,Loss: 0.768,Avg.Loss: 0.591,LR: 4.99E-04]Training epoch 4:   9%|▉         | 10/112 [00:00<00:01, 62.02it/s, Epoch: 4, Batch: 11,Loss: 0.436,Avg.Loss: 0.577,LR: 4.99E-04]Training epoch 4:  10%|▉         | 11/112 [00:00<00:01, 62.02it/s, Epoch: 4, Batch: 12,Loss: 0.669,Avg.Loss: 0.585,LR: 4.99E-04]Training epoch 4:  11%|█         | 12/112 [00:00<00:01, 62.02it/s, Epoch: 4, Batch: 13,Loss: 0.441,Avg.Loss: 0.574,LR: 4.99E-04]Training epoch 4:  12%|█▏        | 13/112 [00:00<00:01, 62.02it/s, Epoch: 4, Batch: 14,Loss: 0.709,Avg.Loss: 0.583,LR: 4.99E-04]Training epoch 4:  12%|█▎        | 14/112 [00:00<00:01, 63.44it/s, Epoch: 4, Batch: 14,Loss: 0.709,Avg.Loss: 0.583,LR: 4.99E-04]Training epoch 4:  12%|█▎        | 14/112 [00:00<00:01, 63.44it/s, Epoch: 4, Batch: 15,Loss: 0.502,Avg.Loss: 0.578,LR: 4.99E-04]Training epoch 4:  13%|█▎        | 15/112 [00:00<00:01, 63.44it/s, Epoch: 4, Batch: 16,Loss: 0.473,Avg.Loss: 0.571,LR: 4.99E-04]Training epoch 4:  14%|█▍        | 16/112 [00:00<00:01, 63.44it/s, Epoch: 4, Batch: 17,Loss: 0.336,Avg.Loss: 0.558,LR: 4.99E-04]Training epoch 4:  15%|█▌        | 17/112 [00:00<00:01, 63.44it/s, Epoch: 4, Batch: 18,Loss: 0.424,Avg.Loss: 0.550,LR: 4.99E-04]Training epoch 4:  16%|█▌        | 18/112 [00:00<00:01, 63.44it/s, Epoch: 4, Batch: 19,Loss: 0.384,Avg.Loss: 0.541,LR: 4.99E-04]Training epoch 4:  17%|█▋        | 19/112 [00:00<00:01, 63.44it/s, Epoch: 4, Batch: 20,Loss: 0.023,Avg.Loss: 0.515,LR: 4.99E-04]Training epoch 4:  18%|█▊        | 20/112 [00:00<00:01, 63.44it/s, Epoch: 4, Batch: 21,Loss: 0.092,Avg.Loss: 0.495,LR: 4.99E-04]Training epoch 4:  19%|█▉        | 21/112 [00:00<00:01, 57.99it/s, Epoch: 4, Batch: 21,Loss: 0.092,Avg.Loss: 0.495,LR: 4.99E-04]Training epoch 4:  19%|█▉        | 21/112 [00:00<00:01, 57.99it/s, Epoch: 4, Batch: 22,Loss: 0.267,Avg.Loss: 0.485,LR: 4.99E-04]Training epoch 4:  20%|█▉        | 22/112 [00:00<00:01, 57.99it/s, Epoch: 4, Batch: 23,Loss: 0.375,Avg.Loss: 0.480,LR: 4.99E-04]Training epoch 4:  21%|██        | 23/112 [00:00<00:01, 57.99it/s, Epoch: 4, Batch: 24,Loss: 0.653,Avg.Loss: 0.487,LR: 4.99E-04]Training epoch 4:  21%|██▏       | 24/112 [00:00<00:01, 57.99it/s, Epoch: 4, Batch: 25,Loss: 0.563,Avg.Loss: 0.490,LR: 4.99E-04]Training epoch 4:  22%|██▏       | 25/112 [00:00<00:01, 57.99it/s, Epoch: 4, Batch: 26,Loss: 0.080,Avg.Loss: 0.475,LR: 4.99E-04]Training epoch 4:  23%|██▎       | 26/112 [00:00<00:01, 57.99it/s, Epoch: 4, Batch: 27,Loss: 0.194,Avg.Loss: 0.464,LR: 4.99E-04]Training epoch 4:  24%|██▍       | 27/112 [00:00<00:01, 56.10it/s, Epoch: 4, Batch: 27,Loss: 0.194,Avg.Loss: 0.464,LR: 4.99E-04]Training epoch 4:  24%|██▍       | 27/112 [00:00<00:01, 56.10it/s, Epoch: 4, Batch: 28,Loss: 0.213,Avg.Loss: 0.455,LR: 4.99E-04]Training epoch 4:  25%|██▌       | 28/112 [00:00<00:01, 56.10it/s, Epoch: 4, Batch: 29,Loss: 0.163,Avg.Loss: 0.445,LR: 4.99E-04]Training epoch 4:  26%|██▌       | 29/112 [00:00<00:01, 56.10it/s, Epoch: 4, Batch: 30,Loss: -0.113,Avg.Loss: 0.427,LR: 4.99E-04]Training epoch 4:  27%|██▋       | 30/112 [00:00<00:01, 56.10it/s, Epoch: 4, Batch: 31,Loss: 0.132,Avg.Loss: 0.417,LR: 4.99E-04] Training epoch 4:  28%|██▊       | 31/112 [00:00<00:01, 56.10it/s, Epoch: 4, Batch: 32,Loss: -0.017,Avg.Loss: 0.403,LR: 4.99E-04]Training epoch 4:  29%|██▊       | 32/112 [00:00<00:01, 56.10it/s, Epoch: 4, Batch: 33,Loss: 0.122,Avg.Loss: 0.395,LR: 4.99E-04] Training epoch 4:  29%|██▉       | 33/112 [00:00<00:01, 55.02it/s, Epoch: 4, Batch: 33,Loss: 0.122,Avg.Loss: 0.395,LR: 4.99E-04]Training epoch 4:  29%|██▉       | 33/112 [00:00<00:01, 55.02it/s, Epoch: 4, Batch: 34,Loss: -0.063,Avg.Loss: 0.381,LR: 4.99E-04]Training epoch 4:  30%|███       | 34/112 [00:00<00:01, 55.02it/s, Epoch: 4, Batch: 35,Loss: -0.008,Avg.Loss: 0.370,LR: 4.99E-04]Training epoch 4:  31%|███▏      | 35/112 [00:00<00:01, 55.02it/s, Epoch: 4, Batch: 36,Loss: 0.132,Avg.Loss: 0.364,LR: 4.99E-04] Training epoch 4:  32%|███▏      | 36/112 [00:00<00:01, 55.02it/s, Epoch: 4, Batch: 37,Loss: -0.236,Avg.Loss: 0.348,LR: 4.99E-04]Training epoch 4:  33%|███▎      | 37/112 [00:00<00:01, 55.02it/s, Epoch: 4, Batch: 38,Loss: 0.781,Avg.Loss: 0.359,LR: 4.99E-04] Training epoch 4:  34%|███▍      | 38/112 [00:00<00:01, 55.02it/s, Epoch: 4, Batch: 39,Loss: 0.606,Avg.Loss: 0.365,LR: 4.99E-04]Training epoch 4:  35%|███▍      | 39/112 [00:00<00:01, 54.41it/s, Epoch: 4, Batch: 39,Loss: 0.606,Avg.Loss: 0.365,LR: 4.99E-04]Training epoch 4:  35%|███▍      | 39/112 [00:00<00:01, 54.41it/s, Epoch: 4, Batch: 40,Loss: 0.209,Avg.Loss: 0.361,LR: 4.99E-04]Training epoch 4:  36%|███▌      | 40/112 [00:00<00:01, 54.41it/s, Epoch: 4, Batch: 41,Loss: 0.220,Avg.Loss: 0.358,LR: 4.99E-04]Training epoch 4:  37%|███▋      | 41/112 [00:00<00:01, 54.41it/s, Epoch: 4, Batch: 42,Loss: 0.875,Avg.Loss: 0.370,LR: 4.99E-04]Training epoch 4:  38%|███▊      | 42/112 [00:00<00:01, 54.41it/s, Epoch: 4, Batch: 43,Loss: 0.668,Avg.Loss: 0.377,LR: 4.99E-04]Training epoch 4:  38%|███▊      | 43/112 [00:00<00:01, 54.41it/s, Epoch: 4, Batch: 44,Loss: -0.276,Avg.Loss: 0.362,LR: 4.99E-04]Training epoch 4:  39%|███▉      | 44/112 [00:00<00:01, 54.41it/s, Epoch: 4, Batch: 45,Loss: 2.111,Avg.Loss: 0.401,LR: 4.99E-04] Training epoch 4:  40%|████      | 45/112 [00:00<00:01, 53.99it/s, Epoch: 4, Batch: 45,Loss: 2.111,Avg.Loss: 0.401,LR: 4.99E-04]Training epoch 4:  40%|████      | 45/112 [00:00<00:01, 53.99it/s, Epoch: 4, Batch: 46,Loss: 3.764,Avg.Loss: 0.474,LR: 4.99E-04]Training epoch 4:  41%|████      | 46/112 [00:00<00:01, 53.99it/s, Epoch: 4, Batch: 47,Loss: 4.363,Avg.Loss: 0.557,LR: 4.99E-04]Training epoch 4:  42%|████▏     | 47/112 [00:00<00:01, 53.99it/s, Epoch: 4, Batch: 48,Loss: 2.571,Avg.Loss: 0.599,LR: 4.99E-04]Training epoch 4:  43%|████▎     | 48/112 [00:00<00:01, 53.99it/s, Epoch: 4, Batch: 49,Loss: 0.270,Avg.Loss: 0.592,LR: 4.99E-04]Training epoch 4:  44%|████▍     | 49/112 [00:00<00:01, 53.99it/s, Epoch: 4, Batch: 50,Loss: 0.898,Avg.Loss: 0.598,LR: 4.99E-04]Training epoch 4:  45%|████▍     | 50/112 [00:00<00:01, 53.99it/s, Epoch: 4, Batch: 51,Loss: 1.861,Avg.Loss: 0.623,LR: 4.99E-04]Training epoch 4:  46%|████▌     | 51/112 [00:00<00:01, 53.66it/s, Epoch: 4, Batch: 51,Loss: 1.861,Avg.Loss: 0.623,LR: 4.99E-04]Training epoch 4:  46%|████▌     | 51/112 [00:00<00:01, 53.66it/s, Epoch: 4, Batch: 52,Loss: 2.127,Avg.Loss: 0.652,LR: 4.99E-04]Training epoch 4:  46%|████▋     | 52/112 [00:00<00:01, 53.66it/s, Epoch: 4, Batch: 53,Loss: 0.638,Avg.Loss: 0.652,LR: 4.99E-04]Training epoch 4:  47%|████▋     | 53/112 [00:00<00:01, 53.66it/s, Epoch: 4, Batch: 54,Loss: 0.011,Avg.Loss: 0.640,LR: 4.99E-04]Training epoch 4:  48%|████▊     | 54/112 [00:00<00:01, 53.66it/s, Epoch: 4, Batch: 55,Loss: 0.782,Avg.Loss: 0.642,LR: 4.98E-04]Training epoch 4:  49%|████▉     | 55/112 [00:01<00:01, 53.66it/s, Epoch: 4, Batch: 56,Loss: 0.105,Avg.Loss: 0.633,LR: 4.98E-04]Training epoch 4:  50%|█████     | 56/112 [00:01<00:01, 53.66it/s, Epoch: 4, Batch: 57,Loss: -0.059,Avg.Loss: 0.621,LR: 4.98E-04]Training epoch 4:  51%|█████     | 57/112 [00:01<00:01, 53.46it/s, Epoch: 4, Batch: 57,Loss: -0.059,Avg.Loss: 0.621,LR: 4.98E-04]Training epoch 4:  51%|█████     | 57/112 [00:01<00:01, 53.46it/s, Epoch: 4, Batch: 58,Loss: -0.113,Avg.Loss: 0.608,LR: 4.98E-04]Training epoch 4:  52%|█████▏    | 58/112 [00:01<00:01, 53.46it/s, Epoch: 4, Batch: 59,Loss: -0.095,Avg.Loss: 0.596,LR: 4.98E-04]Training epoch 4:  53%|█████▎    | 59/112 [00:01<00:00, 53.46it/s, Epoch: 4, Batch: 60,Loss: 0.814,Avg.Loss: 0.600,LR: 4.98E-04] Training epoch 4:  54%|█████▎    | 60/112 [00:01<00:00, 53.46it/s, Epoch: 4, Batch: 61,Loss: 1.845,Avg.Loss: 0.620,LR: 4.98E-04]Training epoch 4:  54%|█████▍    | 61/112 [00:01<00:00, 53.46it/s, Epoch: 4, Batch: 62,Loss: 0.993,Avg.Loss: 0.626,LR: 4.98E-04]Training epoch 4:  55%|█████▌    | 62/112 [00:01<00:00, 53.46it/s, Epoch: 4, Batch: 63,Loss: -0.121,Avg.Loss: 0.614,LR: 4.98E-04]Training epoch 4:  56%|█████▋    | 63/112 [00:01<00:00, 53.35it/s, Epoch: 4, Batch: 63,Loss: -0.121,Avg.Loss: 0.614,LR: 4.98E-04]Training epoch 4:  56%|█████▋    | 63/112 [00:01<00:00, 53.35it/s, Epoch: 4, Batch: 64,Loss: 0.592,Avg.Loss: 0.614,LR: 4.98E-04] Training epoch 4:  57%|█████▋    | 64/112 [00:01<00:00, 53.35it/s, Epoch: 4, Batch: 65,Loss: 1.273,Avg.Loss: 0.624,LR: 4.98E-04]Training epoch 4:  58%|█████▊    | 65/112 [00:01<00:00, 53.35it/s, Epoch: 4, Batch: 66,Loss: 0.968,Avg.Loss: 0.629,LR: 4.98E-04]Training epoch 4:  59%|█████▉    | 66/112 [00:01<00:00, 53.35it/s, Epoch: 4, Batch: 67,Loss: -0.033,Avg.Loss: 0.619,LR: 4.98E-04]Training epoch 4:  60%|█████▉    | 67/112 [00:01<00:00, 53.35it/s, Epoch: 4, Batch: 68,Loss: 0.433,Avg.Loss: 0.617,LR: 4.98E-04] Training epoch 4:  61%|██████    | 68/112 [00:01<00:00, 53.35it/s, Epoch: 4, Batch: 69,Loss: 1.293,Avg.Loss: 0.627,LR: 4.98E-04]Training epoch 4:  62%|██████▏   | 69/112 [00:01<00:00, 53.23it/s, Epoch: 4, Batch: 69,Loss: 1.293,Avg.Loss: 0.627,LR: 4.98E-04]Training epoch 4:  62%|██████▏   | 69/112 [00:01<00:00, 53.23it/s, Epoch: 4, Batch: 70,Loss: 0.938,Avg.Loss: 0.631,LR: 4.98E-04]Training epoch 4:  62%|██████▎   | 70/112 [00:01<00:00, 53.23it/s, Epoch: 4, Batch: 71,Loss: -0.223,Avg.Loss: 0.619,LR: 4.98E-04]Training epoch 4:  63%|██████▎   | 71/112 [00:01<00:00, 53.23it/s, Epoch: 4, Batch: 72,Loss: -0.087,Avg.Loss: 0.609,LR: 4.98E-04]Training epoch 4:  64%|██████▍   | 72/112 [00:01<00:00, 53.23it/s, Epoch: 4, Batch: 73,Loss: 0.443,Avg.Loss: 0.607,LR: 4.98E-04] Training epoch 4:  65%|██████▌   | 73/112 [00:01<00:00, 53.23it/s, Epoch: 4, Batch: 74,Loss: -0.025,Avg.Loss: 0.598,LR: 4.98E-04]Training epoch 4:  66%|██████▌   | 74/112 [00:01<00:00, 53.23it/s, Epoch: 4, Batch: 75,Loss: -0.223,Avg.Loss: 0.587,LR: 4.98E-04]Training epoch 4:  67%|██████▋   | 75/112 [00:01<00:00, 53.20it/s, Epoch: 4, Batch: 75,Loss: -0.223,Avg.Loss: 0.587,LR: 4.98E-04]Training epoch 4:  67%|██████▋   | 75/112 [00:01<00:00, 53.20it/s, Epoch: 4, Batch: 76,Loss: 0.439,Avg.Loss: 0.585,LR: 4.98E-04] Training epoch 4:  68%|██████▊   | 76/112 [00:01<00:00, 53.20it/s, Epoch: 4, Batch: 77,Loss: 1.154,Avg.Loss: 0.593,LR: 4.98E-04]Training epoch 4:  69%|██████▉   | 77/112 [00:01<00:00, 53.20it/s, Epoch: 4, Batch: 78,Loss: 0.862,Avg.Loss: 0.596,LR: 4.98E-04]Training epoch 4:  70%|██████▉   | 78/112 [00:01<00:00, 53.20it/s, Epoch: 4, Batch: 79,Loss: -0.085,Avg.Loss: 0.588,LR: 4.98E-04]Training epoch 4:  71%|███████   | 79/112 [00:01<00:00, 53.20it/s, Epoch: 4, Batch: 80,Loss: -0.026,Avg.Loss: 0.580,LR: 4.98E-04]Training epoch 4:  71%|███████▏  | 80/112 [00:01<00:00, 53.20it/s, Epoch: 4, Batch: 81,Loss: 0.060,Avg.Loss: 0.574,LR: 4.98E-04] Training epoch 4:  72%|███████▏  | 81/112 [00:01<00:00, 52.69it/s, Epoch: 4, Batch: 81,Loss: 0.060,Avg.Loss: 0.574,LR: 4.98E-04]Training epoch 4:  72%|███████▏  | 81/112 [00:01<00:00, 52.69it/s, Epoch: 4, Batch: 82,Loss: 0.208,Avg.Loss: 0.569,LR: 4.98E-04]Training epoch 4:  73%|███████▎  | 82/112 [00:01<00:00, 52.69it/s, Epoch: 4, Batch: 83,Loss: -0.253,Avg.Loss: 0.559,LR: 4.98E-04]Training epoch 4:  74%|███████▍  | 83/112 [00:01<00:00, 52.69it/s, Epoch: 4, Batch: 84,Loss: 0.213,Avg.Loss: 0.555,LR: 4.98E-04] Training epoch 4:  75%|███████▌  | 84/112 [00:01<00:00, 52.69it/s, Epoch: 4, Batch: 85,Loss: 0.500,Avg.Loss: 0.554,LR: 4.98E-04]Training epoch 4:  76%|███████▌  | 85/112 [00:01<00:00, 52.69it/s, Epoch: 4, Batch: 86,Loss: 0.471,Avg.Loss: 0.553,LR: 4.98E-04]Training epoch 4:  77%|███████▋  | 86/112 [00:01<00:00, 52.69it/s, Epoch: 4, Batch: 87,Loss: -0.079,Avg.Loss: 0.546,LR: 4.98E-04]Training epoch 4:  78%|███████▊  | 87/112 [00:01<00:00, 52.93it/s, Epoch: 4, Batch: 87,Loss: -0.079,Avg.Loss: 0.546,LR: 4.98E-04]Training epoch 4:  78%|███████▊  | 87/112 [00:01<00:00, 52.93it/s, Epoch: 4, Batch: 88,Loss: -0.144,Avg.Loss: 0.538,LR: 4.98E-04]Training epoch 4:  79%|███████▊  | 88/112 [00:01<00:00, 52.93it/s, Epoch: 4, Batch: 89,Loss: 0.372,Avg.Loss: 0.536,LR: 4.98E-04] Training epoch 4:  79%|███████▉  | 89/112 [00:01<00:00, 52.93it/s, Epoch: 4, Batch: 90,Loss: 0.056,Avg.Loss: 0.531,LR: 4.98E-04]Training epoch 4:  80%|████████  | 90/112 [00:01<00:00, 52.93it/s, Epoch: 4, Batch: 91,Loss: 0.125,Avg.Loss: 0.527,LR: 4.98E-04]Training epoch 4:  81%|████████▏ | 91/112 [00:01<00:00, 52.93it/s, Epoch: 4, Batch: 92,Loss: 0.043,Avg.Loss: 0.521,LR: 4.98E-04]Training epoch 4:  82%|████████▏ | 92/112 [00:01<00:00, 52.93it/s, Epoch: 4, Batch: 93,Loss: 0.409,Avg.Loss: 0.520,LR: 4.98E-04]Training epoch 4:  83%|████████▎ | 93/112 [00:01<00:00, 53.10it/s, Epoch: 4, Batch: 93,Loss: 0.409,Avg.Loss: 0.520,LR: 4.98E-04]Training epoch 4:  83%|████████▎ | 93/112 [00:01<00:00, 53.10it/s, Epoch: 4, Batch: 94,Loss: 1.074,Avg.Loss: 0.526,LR: 4.98E-04]Training epoch 4:  84%|████████▍ | 94/112 [00:01<00:00, 53.10it/s, Epoch: 4, Batch: 95,Loss: -0.079,Avg.Loss: 0.520,LR: 4.98E-04]Training epoch 4:  85%|████████▍ | 95/112 [00:01<00:00, 53.10it/s, Epoch: 4, Batch: 96,Loss: -0.103,Avg.Loss: 0.513,LR: 4.98E-04]Training epoch 4:  86%|████████▌ | 96/112 [00:01<00:00, 53.10it/s, Epoch: 4, Batch: 97,Loss: 0.326,Avg.Loss: 0.511,LR: 4.98E-04] Training epoch 4:  87%|████████▋ | 97/112 [00:01<00:00, 53.10it/s, Epoch: 4, Batch: 98,Loss: 0.304,Avg.Loss: 0.509,LR: 4.98E-04]Training epoch 4:  88%|████████▊ | 98/112 [00:01<00:00, 53.10it/s, Epoch: 4, Batch: 99,Loss: 0.042,Avg.Loss: 0.504,LR: 4.98E-04]Training epoch 4:  88%|████████▊ | 99/112 [00:01<00:00, 53.22it/s, Epoch: 4, Batch: 99,Loss: 0.042,Avg.Loss: 0.504,LR: 4.98E-04]Training epoch 4:  88%|████████▊ | 99/112 [00:01<00:00, 53.22it/s, Epoch: 4, Batch: 100,Loss: 0.266,Avg.Loss: 0.502,LR: 4.98E-04]Training epoch 4:  89%|████████▉ | 100/112 [00:01<00:00, 53.22it/s, Epoch: 4, Batch: 101,Loss: 0.686,Avg.Loss: 0.504,LR: 4.98E-04]Training epoch 4:  90%|█████████ | 101/112 [00:01<00:00, 53.22it/s, Epoch: 4, Batch: 102,Loss: 0.137,Avg.Loss: 0.500,LR: 4.98E-04]Training epoch 4:  91%|█████████ | 102/112 [00:01<00:00, 53.22it/s, Epoch: 4, Batch: 103,Loss: -0.097,Avg.Loss: 0.495,LR: 4.98E-04]Training epoch 4:  92%|█████████▏| 103/112 [00:01<00:00, 53.22it/s, Epoch: 4, Batch: 104,Loss: 0.538,Avg.Loss: 0.495,LR: 4.98E-04] Training epoch 4:  93%|█████████▎| 104/112 [00:01<00:00, 53.22it/s, Epoch: 4, Batch: 105,Loss: 0.270,Avg.Loss: 0.493,LR: 4.98E-04]Training epoch 4:  94%|█████████▍| 105/112 [00:01<00:00, 53.48it/s, Epoch: 4, Batch: 105,Loss: 0.270,Avg.Loss: 0.493,LR: 4.98E-04]Training epoch 4:  94%|█████████▍| 105/112 [00:01<00:00, 53.48it/s, Epoch: 4, Batch: 106,Loss: 0.284,Avg.Loss: 0.491,LR: 4.98E-04]Training epoch 4:  95%|█████████▍| 106/112 [00:01<00:00, 53.48it/s, Epoch: 4, Batch: 107,Loss: -0.157,Avg.Loss: 0.485,LR: 4.98E-04]Training epoch 4:  96%|█████████▌| 107/112 [00:01<00:00, 53.48it/s, Epoch: 4, Batch: 108,Loss: -0.224,Avg.Loss: 0.478,LR: 4.98E-04]Training epoch 4:  96%|█████████▋| 108/112 [00:02<00:00, 53.48it/s, Epoch: 4, Batch: 109,Loss: 0.153,Avg.Loss: 0.475,LR: 4.98E-04] Training epoch 4:  97%|█████████▋| 109/112 [00:02<00:00, 53.48it/s, Epoch: 4, Batch: 110,Loss: 0.211,Avg.Loss: 0.473,LR: 4.98E-04]Training epoch 4:  98%|█████████▊| 110/112 [00:02<00:00, 53.48it/s, Epoch: 4, Batch: 111,Loss: 0.120,Avg.Loss: 0.470,LR: 4.98E-04]Training epoch 4:  99%|█████████▉| 111/112 [00:02<00:00, 53.57it/s, Epoch: 4, Batch: 111,Loss: 0.120,Avg.Loss: 0.470,LR: 4.98E-04]Training epoch 4:  99%|█████████▉| 111/112 [00:02<00:00, 53.57it/s, Epoch: 4, Batch: 112,Loss: -0.511,Avg.Loss: 0.461,LR: 4.98E-04]Training epoch 4: 100%|██████████| 112/112 [00:02<00:00, 54.11it/s, Epoch: 4, Batch: 112,Loss: -0.511,Avg.Loss: 0.461,LR: 4.98E-04]
Training epoch 5:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 5:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 5, Batch: 1,Loss: -0.243,Avg.Loss: -0.243,LR: 4.98E-04]Training epoch 5:   1%|          | 1/112 [00:00<00:03, 29.80it/s, Epoch: 5, Batch: 2,Loss: -0.299,Avg.Loss: -0.271,LR: 4.98E-04]Training epoch 5:   2%|▏         | 2/112 [00:00<00:02, 40.48it/s, Epoch: 5, Batch: 3,Loss: -0.223,Avg.Loss: -0.255,LR: 4.98E-04]Training epoch 5:   3%|▎         | 3/112 [00:00<00:02, 44.36it/s, Epoch: 5, Batch: 4,Loss: -0.238,Avg.Loss: -0.251,LR: 4.98E-04]Training epoch 5:   4%|▎         | 4/112 [00:00<00:02, 48.64it/s, Epoch: 5, Batch: 5,Loss: -0.192,Avg.Loss: -0.239,LR: 4.98E-04]Training epoch 5:   4%|▍         | 5/112 [00:00<00:02, 49.84it/s, Epoch: 5, Batch: 6,Loss: -0.370,Avg.Loss: -0.261,LR: 4.98E-04]Training epoch 5:   5%|▌         | 6/112 [00:00<00:01, 59.71it/s, Epoch: 5, Batch: 6,Loss: -0.370,Avg.Loss: -0.261,LR: 4.98E-04]Training epoch 5:   5%|▌         | 6/112 [00:00<00:01, 59.71it/s, Epoch: 5, Batch: 7,Loss: -0.148,Avg.Loss: -0.245,LR: 4.98E-04]Training epoch 5:   6%|▋         | 7/112 [00:00<00:01, 59.71it/s, Epoch: 5, Batch: 8,Loss: -0.186,Avg.Loss: -0.237,LR: 4.98E-04]Training epoch 5:   7%|▋         | 8/112 [00:00<00:01, 59.71it/s, Epoch: 5, Batch: 9,Loss: -0.473,Avg.Loss: -0.264,LR: 4.98E-04]Training epoch 5:   8%|▊         | 9/112 [00:00<00:01, 59.71it/s, Epoch: 5, Batch: 10,Loss: -0.211,Avg.Loss: -0.258,LR: 4.98E-04]Training epoch 5:   9%|▉         | 10/112 [00:00<00:01, 59.71it/s, Epoch: 5, Batch: 11,Loss: -0.370,Avg.Loss: -0.268,LR: 4.98E-04]Training epoch 5:  10%|▉         | 11/112 [00:00<00:01, 59.71it/s, Epoch: 5, Batch: 12,Loss: -0.609,Avg.Loss: -0.297,LR: 4.98E-04]Training epoch 5:  11%|█         | 12/112 [00:00<00:01, 59.71it/s, Epoch: 5, Batch: 13,Loss: -0.372,Avg.Loss: -0.303,LR: 4.98E-04]Training epoch 5:  12%|█▏        | 13/112 [00:00<00:01, 62.11it/s, Epoch: 5, Batch: 13,Loss: -0.372,Avg.Loss: -0.303,LR: 4.98E-04]Training epoch 5:  12%|█▏        | 13/112 [00:00<00:01, 62.11it/s, Epoch: 5, Batch: 14,Loss: -0.387,Avg.Loss: -0.309,LR: 4.98E-04]Training epoch 5:  12%|█▎        | 14/112 [00:00<00:01, 62.11it/s, Epoch: 5, Batch: 15,Loss: -0.611,Avg.Loss: -0.329,LR: 4.98E-04]Training epoch 5:  13%|█▎        | 15/112 [00:00<00:01, 62.11it/s, Epoch: 5, Batch: 16,Loss: 0.100,Avg.Loss: -0.302,LR: 4.98E-04] Training epoch 5:  14%|█▍        | 16/112 [00:00<00:01, 62.11it/s, Epoch: 5, Batch: 17,Loss: 0.137,Avg.Loss: -0.276,LR: 4.98E-04]Training epoch 5:  15%|█▌        | 17/112 [00:00<00:01, 62.11it/s, Epoch: 5, Batch: 18,Loss: -0.352,Avg.Loss: -0.280,LR: 4.98E-04]Training epoch 5:  16%|█▌        | 18/112 [00:00<00:01, 62.11it/s, Epoch: 5, Batch: 19,Loss: -0.551,Avg.Loss: -0.295,LR: 4.98E-04]Training epoch 5:  17%|█▋        | 19/112 [00:00<00:01, 62.11it/s, Epoch: 5, Batch: 20,Loss: -0.271,Avg.Loss: -0.293,LR: 4.98E-04]Training epoch 5:  18%|█▊        | 20/112 [00:00<00:01, 57.22it/s, Epoch: 5, Batch: 20,Loss: -0.271,Avg.Loss: -0.293,LR: 4.98E-04]Training epoch 5:  18%|█▊        | 20/112 [00:00<00:01, 57.22it/s, Epoch: 5, Batch: 21,Loss: -0.419,Avg.Loss: -0.299,LR: 4.98E-04]Training epoch 5:  19%|█▉        | 21/112 [00:00<00:01, 57.22it/s, Epoch: 5, Batch: 22,Loss: -0.711,Avg.Loss: -0.318,LR: 4.98E-04]Training epoch 5:  20%|█▉        | 22/112 [00:00<00:01, 57.22it/s, Epoch: 5, Batch: 23,Loss: -0.030,Avg.Loss: -0.306,LR: 4.98E-04]Training epoch 5:  21%|██        | 23/112 [00:00<00:01, 57.22it/s, Epoch: 5, Batch: 24,Loss: 0.242,Avg.Loss: -0.283,LR: 4.98E-04] Training epoch 5:  21%|██▏       | 24/112 [00:00<00:01, 57.22it/s, Epoch: 5, Batch: 25,Loss: -0.645,Avg.Loss: -0.297,LR: 4.98E-04]Training epoch 5:  22%|██▏       | 25/112 [00:00<00:01, 57.22it/s, Epoch: 5, Batch: 26,Loss: -0.586,Avg.Loss: -0.308,LR: 4.98E-04]Training epoch 5:  23%|██▎       | 26/112 [00:00<00:01, 55.20it/s, Epoch: 5, Batch: 26,Loss: -0.586,Avg.Loss: -0.308,LR: 4.98E-04]Training epoch 5:  23%|██▎       | 26/112 [00:00<00:01, 55.20it/s, Epoch: 5, Batch: 27,Loss: -0.333,Avg.Loss: -0.309,LR: 4.98E-04]Training epoch 5:  24%|██▍       | 27/112 [00:00<00:01, 55.20it/s, Epoch: 5, Batch: 28,Loss: -0.237,Avg.Loss: -0.307,LR: 4.98E-04]Training epoch 5:  25%|██▌       | 28/112 [00:00<00:01, 55.20it/s, Epoch: 5, Batch: 29,Loss: -0.581,Avg.Loss: -0.316,LR: 4.98E-04]Training epoch 5:  26%|██▌       | 29/112 [00:00<00:01, 55.20it/s, Epoch: 5, Batch: 30,Loss: -0.424,Avg.Loss: -0.320,LR: 4.98E-04]Training epoch 5:  27%|██▋       | 30/112 [00:00<00:01, 55.20it/s, Epoch: 5, Batch: 31,Loss: -0.418,Avg.Loss: -0.323,LR: 4.98E-04]Training epoch 5:  28%|██▊       | 31/112 [00:00<00:01, 55.20it/s, Epoch: 5, Batch: 32,Loss: -0.427,Avg.Loss: -0.326,LR: 4.98E-04]Training epoch 5:  29%|██▊       | 32/112 [00:00<00:01, 54.21it/s, Epoch: 5, Batch: 32,Loss: -0.427,Avg.Loss: -0.326,LR: 4.98E-04]Training epoch 5:  29%|██▊       | 32/112 [00:00<00:01, 54.21it/s, Epoch: 5, Batch: 33,Loss: -0.058,Avg.Loss: -0.318,LR: 4.98E-04]Training epoch 5:  29%|██▉       | 33/112 [00:00<00:01, 54.21it/s, Epoch: 5, Batch: 34,Loss: -0.406,Avg.Loss: -0.321,LR: 4.98E-04]Training epoch 5:  30%|███       | 34/112 [00:00<00:01, 54.21it/s, Epoch: 5, Batch: 35,Loss: 0.074,Avg.Loss: -0.309,LR: 4.98E-04] Training epoch 5:  31%|███▏      | 35/112 [00:00<00:01, 54.21it/s, Epoch: 5, Batch: 36,Loss: -0.377,Avg.Loss: -0.311,LR: 4.98E-04]Training epoch 5:  32%|███▏      | 36/112 [00:00<00:01, 54.21it/s, Epoch: 5, Batch: 37,Loss: -0.494,Avg.Loss: -0.316,LR: 4.98E-04]Training epoch 5:  33%|███▎      | 37/112 [00:00<00:01, 54.21it/s, Epoch: 5, Batch: 38,Loss: -0.691,Avg.Loss: -0.326,LR: 4.98E-04]Training epoch 5:  34%|███▍      | 38/112 [00:00<00:01, 54.02it/s, Epoch: 5, Batch: 38,Loss: -0.691,Avg.Loss: -0.326,LR: 4.98E-04]Training epoch 5:  34%|███▍      | 38/112 [00:00<00:01, 54.02it/s, Epoch: 5, Batch: 39,Loss: -0.380,Avg.Loss: -0.327,LR: 4.98E-04]Training epoch 5:  35%|███▍      | 39/112 [00:00<00:01, 54.02it/s, Epoch: 5, Batch: 40,Loss: -0.832,Avg.Loss: -0.340,LR: 4.98E-04]Training epoch 5:  36%|███▌      | 40/112 [00:00<00:01, 54.02it/s, Epoch: 5, Batch: 41,Loss: 0.362,Avg.Loss: -0.323,LR: 4.98E-04] Training epoch 5:  37%|███▋      | 41/112 [00:00<00:01, 54.02it/s, Epoch: 5, Batch: 42,Loss: 1.182,Avg.Loss: -0.287,LR: 4.98E-04]Training epoch 5:  38%|███▊      | 42/112 [00:00<00:01, 54.02it/s, Epoch: 5, Batch: 43,Loss: 0.248,Avg.Loss: -0.275,LR: 4.98E-04]Training epoch 5:  38%|███▊      | 43/112 [00:00<00:01, 54.02it/s, Epoch: 5, Batch: 44,Loss: 0.353,Avg.Loss: -0.260,LR: 4.98E-04]Training epoch 5:  39%|███▉      | 44/112 [00:00<00:01, 53.94it/s, Epoch: 5, Batch: 44,Loss: 0.353,Avg.Loss: -0.260,LR: 4.98E-04]Training epoch 5:  39%|███▉      | 44/112 [00:00<00:01, 53.94it/s, Epoch: 5, Batch: 45,Loss: 1.010,Avg.Loss: -0.232,LR: 4.98E-04]Training epoch 5:  40%|████      | 45/112 [00:00<00:01, 53.94it/s, Epoch: 5, Batch: 46,Loss: 0.555,Avg.Loss: -0.215,LR: 4.98E-04]Training epoch 5:  41%|████      | 46/112 [00:00<00:01, 53.94it/s, Epoch: 5, Batch: 47,Loss: -0.016,Avg.Loss: -0.211,LR: 4.98E-04]Training epoch 5:  42%|████▏     | 47/112 [00:00<00:01, 53.94it/s, Epoch: 5, Batch: 48,Loss: 0.448,Avg.Loss: -0.197,LR: 4.98E-04] Training epoch 5:  43%|████▎     | 48/112 [00:00<00:01, 53.94it/s, Epoch: 5, Batch: 49,Loss: 0.042,Avg.Loss: -0.192,LR: 4.98E-04]Training epoch 5:  44%|████▍     | 49/112 [00:00<00:01, 53.94it/s, Epoch: 5, Batch: 50,Loss: -0.338,Avg.Loss: -0.195,LR: 4.98E-04]Training epoch 5:  45%|████▍     | 50/112 [00:00<00:01, 53.79it/s, Epoch: 5, Batch: 50,Loss: -0.338,Avg.Loss: -0.195,LR: 4.98E-04]Training epoch 5:  45%|████▍     | 50/112 [00:00<00:01, 53.79it/s, Epoch: 5, Batch: 51,Loss: 0.148,Avg.Loss: -0.188,LR: 4.98E-04] Training epoch 5:  46%|████▌     | 51/112 [00:00<00:01, 53.79it/s, Epoch: 5, Batch: 52,Loss: -0.388,Avg.Loss: -0.192,LR: 4.98E-04]Training epoch 5:  46%|████▋     | 52/112 [00:00<00:01, 53.79it/s, Epoch: 5, Batch: 53,Loss: -0.356,Avg.Loss: -0.195,LR: 4.98E-04]Training epoch 5:  47%|████▋     | 53/112 [00:00<00:01, 53.79it/s, Epoch: 5, Batch: 54,Loss: 0.255,Avg.Loss: -0.187,LR: 4.98E-04] Training epoch 5:  48%|████▊     | 54/112 [00:01<00:01, 53.79it/s, Epoch: 5, Batch: 55,Loss: -0.653,Avg.Loss: -0.196,LR: 4.98E-04]Training epoch 5:  49%|████▉     | 55/112 [00:01<00:01, 53.79it/s, Epoch: 5, Batch: 56,Loss: 0.377,Avg.Loss: -0.185,LR: 4.98E-04] Training epoch 5:  50%|█████     | 56/112 [00:01<00:01, 53.97it/s, Epoch: 5, Batch: 56,Loss: 0.377,Avg.Loss: -0.185,LR: 4.98E-04]Training epoch 5:  50%|█████     | 56/112 [00:01<00:01, 53.97it/s, Epoch: 5, Batch: 57,Loss: 0.315,Avg.Loss: -0.177,LR: 4.97E-04]Training epoch 5:  51%|█████     | 57/112 [00:01<00:01, 53.97it/s, Epoch: 5, Batch: 58,Loss: -0.081,Avg.Loss: -0.175,LR: 4.97E-04]Training epoch 5:  52%|█████▏    | 58/112 [00:01<00:01, 53.97it/s, Epoch: 5, Batch: 59,Loss: -0.702,Avg.Loss: -0.184,LR: 4.97E-04]Training epoch 5:  53%|█████▎    | 59/112 [00:01<00:00, 53.97it/s, Epoch: 5, Batch: 60,Loss: -0.204,Avg.Loss: -0.184,LR: 4.97E-04]Training epoch 5:  54%|█████▎    | 60/112 [00:01<00:00, 53.97it/s, Epoch: 5, Batch: 61,Loss: -0.562,Avg.Loss: -0.190,LR: 4.97E-04]Training epoch 5:  54%|█████▍    | 61/112 [00:01<00:00, 53.97it/s, Epoch: 5, Batch: 62,Loss: -0.472,Avg.Loss: -0.195,LR: 4.97E-04]Training epoch 5:  55%|█████▌    | 62/112 [00:01<00:00, 53.24it/s, Epoch: 5, Batch: 62,Loss: -0.472,Avg.Loss: -0.195,LR: 4.97E-04]Training epoch 5:  55%|█████▌    | 62/112 [00:01<00:00, 53.24it/s, Epoch: 5, Batch: 63,Loss: -0.306,Avg.Loss: -0.197,LR: 4.97E-04]Training epoch 5:  56%|█████▋    | 63/112 [00:01<00:00, 53.24it/s, Epoch: 5, Batch: 64,Loss: -0.496,Avg.Loss: -0.201,LR: 4.97E-04]Training epoch 5:  57%|█████▋    | 64/112 [00:01<00:00, 53.24it/s, Epoch: 5, Batch: 65,Loss: -0.420,Avg.Loss: -0.205,LR: 4.97E-04]Training epoch 5:  58%|█████▊    | 65/112 [00:01<00:00, 53.24it/s, Epoch: 5, Batch: 66,Loss: -0.450,Avg.Loss: -0.208,LR: 4.97E-04]Training epoch 5:  59%|█████▉    | 66/112 [00:01<00:00, 53.24it/s, Epoch: 5, Batch: 67,Loss: -0.748,Avg.Loss: -0.216,LR: 4.97E-04]Training epoch 5:  60%|█████▉    | 67/112 [00:01<00:00, 53.24it/s, Epoch: 5, Batch: 68,Loss: -0.330,Avg.Loss: -0.218,LR: 4.97E-04]Training epoch 5:  61%|██████    | 68/112 [00:01<00:00, 53.23it/s, Epoch: 5, Batch: 68,Loss: -0.330,Avg.Loss: -0.218,LR: 4.97E-04]Training epoch 5:  61%|██████    | 68/112 [00:01<00:00, 53.23it/s, Epoch: 5, Batch: 69,Loss: -0.461,Avg.Loss: -0.222,LR: 4.97E-04]Training epoch 5:  62%|██████▏   | 69/112 [00:01<00:00, 53.23it/s, Epoch: 5, Batch: 70,Loss: -0.197,Avg.Loss: -0.221,LR: 4.97E-04]Training epoch 5:  62%|██████▎   | 70/112 [00:01<00:00, 53.23it/s, Epoch: 5, Batch: 71,Loss: -0.446,Avg.Loss: -0.224,LR: 4.97E-04]Training epoch 5:  63%|██████▎   | 71/112 [00:01<00:00, 53.23it/s, Epoch: 5, Batch: 72,Loss: -0.175,Avg.Loss: -0.224,LR: 4.97E-04]Training epoch 5:  64%|██████▍   | 72/112 [00:01<00:00, 53.23it/s, Epoch: 5, Batch: 73,Loss: -0.179,Avg.Loss: -0.223,LR: 4.97E-04]Training epoch 5:  65%|██████▌   | 73/112 [00:01<00:00, 53.23it/s, Epoch: 5, Batch: 74,Loss: -0.757,Avg.Loss: -0.230,LR: 4.97E-04]Training epoch 5:  66%|██████▌   | 74/112 [00:01<00:00, 53.15it/s, Epoch: 5, Batch: 74,Loss: -0.757,Avg.Loss: -0.230,LR: 4.97E-04]Training epoch 5:  66%|██████▌   | 74/112 [00:01<00:00, 53.15it/s, Epoch: 5, Batch: 75,Loss: -0.434,Avg.Loss: -0.233,LR: 4.97E-04]Training epoch 5:  67%|██████▋   | 75/112 [00:01<00:00, 53.15it/s, Epoch: 5, Batch: 76,Loss: -0.541,Avg.Loss: -0.237,LR: 4.97E-04]Training epoch 5:  68%|██████▊   | 76/112 [00:01<00:00, 53.15it/s, Epoch: 5, Batch: 77,Loss: 0.178,Avg.Loss: -0.232,LR: 4.97E-04] Training epoch 5:  69%|██████▉   | 77/112 [00:01<00:00, 53.15it/s, Epoch: 5, Batch: 78,Loss: -0.352,Avg.Loss: -0.233,LR: 4.97E-04]Training epoch 5:  70%|██████▉   | 78/112 [00:01<00:00, 53.15it/s, Epoch: 5, Batch: 79,Loss: -0.721,Avg.Loss: -0.239,LR: 4.97E-04]Training epoch 5:  71%|███████   | 79/112 [00:01<00:00, 53.15it/s, Epoch: 5, Batch: 80,Loss: 0.067,Avg.Loss: -0.236,LR: 4.97E-04] Training epoch 5:  71%|███████▏  | 80/112 [00:01<00:00, 53.28it/s, Epoch: 5, Batch: 80,Loss: 0.067,Avg.Loss: -0.236,LR: 4.97E-04]Training epoch 5:  71%|███████▏  | 80/112 [00:01<00:00, 53.28it/s, Epoch: 5, Batch: 81,Loss: 1.457,Avg.Loss: -0.215,LR: 4.97E-04]Training epoch 5:  72%|███████▏  | 81/112 [00:01<00:00, 53.28it/s, Epoch: 5, Batch: 82,Loss: -0.138,Avg.Loss: -0.214,LR: 4.97E-04]Training epoch 5:  73%|███████▎  | 82/112 [00:01<00:00, 53.28it/s, Epoch: 5, Batch: 83,Loss: -1.089,Avg.Loss: -0.224,LR: 4.97E-04]Training epoch 5:  74%|███████▍  | 83/112 [00:01<00:00, 53.28it/s, Epoch: 5, Batch: 84,Loss: -0.267,Avg.Loss: -0.225,LR: 4.97E-04]Training epoch 5:  75%|███████▌  | 84/112 [00:01<00:00, 53.28it/s, Epoch: 5, Batch: 85,Loss: -0.966,Avg.Loss: -0.234,LR: 4.97E-04]Training epoch 5:  76%|███████▌  | 85/112 [00:01<00:00, 53.28it/s, Epoch: 5, Batch: 86,Loss: 0.250,Avg.Loss: -0.228,LR: 4.97E-04] Training epoch 5:  77%|███████▋  | 86/112 [00:01<00:00, 53.37it/s, Epoch: 5, Batch: 86,Loss: 0.250,Avg.Loss: -0.228,LR: 4.97E-04]Training epoch 5:  77%|███████▋  | 86/112 [00:01<00:00, 53.37it/s, Epoch: 5, Batch: 87,Loss: 0.092,Avg.Loss: -0.224,LR: 4.97E-04]Training epoch 5:  78%|███████▊  | 87/112 [00:01<00:00, 53.37it/s, Epoch: 5, Batch: 88,Loss: -0.428,Avg.Loss: -0.227,LR: 4.97E-04]Training epoch 5:  79%|███████▊  | 88/112 [00:01<00:00, 53.37it/s, Epoch: 5, Batch: 89,Loss: -0.539,Avg.Loss: -0.230,LR: 4.97E-04]Training epoch 5:  79%|███████▉  | 89/112 [00:01<00:00, 53.37it/s, Epoch: 5, Batch: 90,Loss: -0.285,Avg.Loss: -0.231,LR: 4.97E-04]Training epoch 5:  80%|████████  | 90/112 [00:01<00:00, 53.37it/s, Epoch: 5, Batch: 91,Loss: -0.644,Avg.Loss: -0.235,LR: 4.97E-04]Training epoch 5:  81%|████████▏ | 91/112 [00:01<00:00, 53.37it/s, Epoch: 5, Batch: 92,Loss: -0.243,Avg.Loss: -0.235,LR: 4.97E-04]Training epoch 5:  82%|████████▏ | 92/112 [00:01<00:00, 53.43it/s, Epoch: 5, Batch: 92,Loss: -0.243,Avg.Loss: -0.235,LR: 4.97E-04]Training epoch 5:  82%|████████▏ | 92/112 [00:01<00:00, 53.43it/s, Epoch: 5, Batch: 93,Loss: 0.054,Avg.Loss: -0.232,LR: 4.97E-04] Training epoch 5:  83%|████████▎ | 93/112 [00:01<00:00, 53.43it/s, Epoch: 5, Batch: 94,Loss: -0.700,Avg.Loss: -0.237,LR: 4.97E-04]Training epoch 5:  84%|████████▍ | 94/112 [00:01<00:00, 53.43it/s, Epoch: 5, Batch: 95,Loss: -0.472,Avg.Loss: -0.240,LR: 4.97E-04]Training epoch 5:  85%|████████▍ | 95/112 [00:01<00:00, 53.43it/s, Epoch: 5, Batch: 96,Loss: 0.123,Avg.Loss: -0.236,LR: 4.97E-04] Training epoch 5:  86%|████████▌ | 96/112 [00:01<00:00, 53.43it/s, Epoch: 5, Batch: 97,Loss: -0.782,Avg.Loss: -0.241,LR: 4.97E-04]Training epoch 5:  87%|████████▋ | 97/112 [00:01<00:00, 53.43it/s, Epoch: 5, Batch: 98,Loss: -0.215,Avg.Loss: -0.241,LR: 4.97E-04]Training epoch 5:  88%|████████▊ | 98/112 [00:01<00:00, 53.44it/s, Epoch: 5, Batch: 98,Loss: -0.215,Avg.Loss: -0.241,LR: 4.97E-04]Training epoch 5:  88%|████████▊ | 98/112 [00:01<00:00, 53.44it/s, Epoch: 5, Batch: 99,Loss: 0.259,Avg.Loss: -0.236,LR: 4.97E-04] Training epoch 5:  88%|████████▊ | 99/112 [00:01<00:00, 53.44it/s, Epoch: 5, Batch: 100,Loss: -0.704,Avg.Loss: -0.241,LR: 4.97E-04]Training epoch 5:  89%|████████▉ | 100/112 [00:01<00:00, 53.44it/s, Epoch: 5, Batch: 101,Loss: -0.436,Avg.Loss: -0.243,LR: 4.97E-04]Training epoch 5:  90%|█████████ | 101/112 [00:01<00:00, 53.44it/s, Epoch: 5, Batch: 102,Loss: 0.326,Avg.Loss: -0.237,LR: 4.97E-04] Training epoch 5:  91%|█████████ | 102/112 [00:01<00:00, 53.44it/s, Epoch: 5, Batch: 103,Loss: -0.632,Avg.Loss: -0.241,LR: 4.97E-04]Training epoch 5:  92%|█████████▏| 103/112 [00:01<00:00, 53.44it/s, Epoch: 5, Batch: 104,Loss: -0.553,Avg.Loss: -0.244,LR: 4.97E-04]Training epoch 5:  93%|█████████▎| 104/112 [00:01<00:00, 53.40it/s, Epoch: 5, Batch: 104,Loss: -0.553,Avg.Loss: -0.244,LR: 4.97E-04]Training epoch 5:  93%|█████████▎| 104/112 [00:01<00:00, 53.40it/s, Epoch: 5, Batch: 105,Loss: 0.031,Avg.Loss: -0.241,LR: 4.97E-04] Training epoch 5:  94%|█████████▍| 105/112 [00:01<00:00, 53.40it/s, Epoch: 5, Batch: 106,Loss: -0.767,Avg.Loss: -0.246,LR: 4.97E-04]Training epoch 5:  95%|█████████▍| 106/112 [00:01<00:00, 53.40it/s, Epoch: 5, Batch: 107,Loss: 0.052,Avg.Loss: -0.244,LR: 4.97E-04] Training epoch 5:  96%|█████████▌| 107/112 [00:01<00:00, 53.40it/s, Epoch: 5, Batch: 108,Loss: 0.045,Avg.Loss: -0.241,LR: 4.97E-04]Training epoch 5:  96%|█████████▋| 108/112 [00:02<00:00, 53.40it/s, Epoch: 5, Batch: 109,Loss: -0.746,Avg.Loss: -0.246,LR: 4.97E-04]Training epoch 5:  97%|█████████▋| 109/112 [00:02<00:00, 53.40it/s, Epoch: 5, Batch: 110,Loss: -0.449,Avg.Loss: -0.247,LR: 4.97E-04]Training epoch 5:  98%|█████████▊| 110/112 [00:02<00:00, 53.34it/s, Epoch: 5, Batch: 110,Loss: -0.449,Avg.Loss: -0.247,LR: 4.97E-04]Training epoch 5:  98%|█████████▊| 110/112 [00:02<00:00, 53.34it/s, Epoch: 5, Batch: 111,Loss: -0.051,Avg.Loss: -0.246,LR: 4.97E-04]Training epoch 5:  99%|█████████▉| 111/112 [00:02<00:00, 53.34it/s, Epoch: 5, Batch: 112,Loss: -0.707,Avg.Loss: -0.250,LR: 4.97E-04]Training epoch 5: 100%|██████████| 112/112 [00:02<00:00, 53.96it/s, Epoch: 5, Batch: 112,Loss: -0.707,Avg.Loss: -0.250,LR: 4.97E-04]
Training epoch 6:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 6:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 6, Batch: 1,Loss: -0.691,Avg.Loss: -0.691,LR: 4.97E-04]Training epoch 6:   1%|          | 1/112 [00:00<00:04, 27.71it/s, Epoch: 6, Batch: 2,Loss: -0.736,Avg.Loss: -0.713,LR: 4.97E-04]Training epoch 6:   2%|▏         | 2/112 [00:00<00:02, 38.30it/s, Epoch: 6, Batch: 3,Loss: -0.498,Avg.Loss: -0.642,LR: 4.97E-04]Training epoch 6:   3%|▎         | 3/112 [00:00<00:02, 41.41it/s, Epoch: 6, Batch: 4,Loss: -0.586,Avg.Loss: -0.628,LR: 4.97E-04]Training epoch 6:   4%|▎         | 4/112 [00:00<00:02, 45.51it/s, Epoch: 6, Batch: 5,Loss: -0.769,Avg.Loss: -0.656,LR: 4.97E-04]Training epoch 6:   4%|▍         | 5/112 [00:00<00:02, 47.75it/s, Epoch: 6, Batch: 6,Loss: -0.061,Avg.Loss: -0.557,LR: 4.97E-04]Training epoch 6:   5%|▌         | 6/112 [00:00<00:01, 57.20it/s, Epoch: 6, Batch: 6,Loss: -0.061,Avg.Loss: -0.557,LR: 4.97E-04]Training epoch 6:   5%|▌         | 6/112 [00:00<00:01, 57.20it/s, Epoch: 6, Batch: 7,Loss: -0.294,Avg.Loss: -0.519,LR: 4.97E-04]Training epoch 6:   6%|▋         | 7/112 [00:00<00:01, 57.20it/s, Epoch: 6, Batch: 8,Loss: -0.597,Avg.Loss: -0.529,LR: 4.97E-04]Training epoch 6:   7%|▋         | 8/112 [00:00<00:01, 57.20it/s, Epoch: 6, Batch: 9,Loss: 0.045,Avg.Loss: -0.465,LR: 4.97E-04] Training epoch 6:   8%|▊         | 9/112 [00:00<00:01, 57.20it/s, Epoch: 6, Batch: 10,Loss: 1.915,Avg.Loss: -0.227,LR: 4.97E-04]Training epoch 6:   9%|▉         | 10/112 [00:00<00:01, 57.20it/s, Epoch: 6, Batch: 11,Loss: 0.578,Avg.Loss: -0.154,LR: 4.97E-04]Training epoch 6:  10%|▉         | 11/112 [00:00<00:01, 57.20it/s, Epoch: 6, Batch: 12,Loss: -0.598,Avg.Loss: -0.191,LR: 4.97E-04]Training epoch 6:  11%|█         | 12/112 [00:00<00:01, 57.20it/s, Epoch: 6, Batch: 13,Loss: 1.781,Avg.Loss: -0.039,LR: 4.97E-04] Training epoch 6:  12%|█▏        | 13/112 [00:00<00:01, 64.46it/s, Epoch: 6, Batch: 13,Loss: 1.781,Avg.Loss: -0.039,LR: 4.97E-04]Training epoch 6:  12%|█▏        | 13/112 [00:00<00:01, 64.46it/s, Epoch: 6, Batch: 14,Loss: 4.220,Avg.Loss: 0.265,LR: 4.97E-04] Training epoch 6:  12%|█▎        | 14/112 [00:00<00:01, 64.46it/s, Epoch: 6, Batch: 15,Loss: 3.636,Avg.Loss: 0.490,LR: 4.97E-04]Training epoch 6:  13%|█▎        | 15/112 [00:00<00:01, 64.46it/s, Epoch: 6, Batch: 16,Loss: 1.069,Avg.Loss: 0.526,LR: 4.97E-04]Training epoch 6:  14%|█▍        | 16/112 [00:00<00:01, 64.46it/s, Epoch: 6, Batch: 17,Loss: -0.288,Avg.Loss: 0.478,LR: 4.97E-04]Training epoch 6:  15%|█▌        | 17/112 [00:00<00:01, 64.46it/s, Epoch: 6, Batch: 18,Loss: -0.602,Avg.Loss: 0.418,LR: 4.97E-04]Training epoch 6:  16%|█▌        | 18/112 [00:00<00:01, 64.46it/s, Epoch: 6, Batch: 19,Loss: -0.216,Avg.Loss: 0.385,LR: 4.97E-04]Training epoch 6:  17%|█▋        | 19/112 [00:00<00:01, 64.46it/s, Epoch: 6, Batch: 20,Loss: 0.200,Avg.Loss: 0.375,LR: 4.97E-04] Training epoch 6:  18%|█▊        | 20/112 [00:00<00:01, 57.95it/s, Epoch: 6, Batch: 20,Loss: 0.200,Avg.Loss: 0.375,LR: 4.97E-04]Training epoch 6:  18%|█▊        | 20/112 [00:00<00:01, 57.95it/s, Epoch: 6, Batch: 21,Loss: 0.209,Avg.Loss: 0.367,LR: 4.97E-04]Training epoch 6:  19%|█▉        | 21/112 [00:00<00:01, 57.95it/s, Epoch: 6, Batch: 22,Loss: -0.041,Avg.Loss: 0.349,LR: 4.97E-04]Training epoch 6:  20%|█▉        | 22/112 [00:00<00:01, 57.95it/s, Epoch: 6, Batch: 23,Loss: 0.406,Avg.Loss: 0.351,LR: 4.97E-04] Training epoch 6:  21%|██        | 23/112 [00:00<00:01, 57.95it/s, Epoch: 6, Batch: 24,Loss: -0.064,Avg.Loss: 0.334,LR: 4.97E-04]Training epoch 6:  21%|██▏       | 24/112 [00:00<00:01, 57.95it/s, Epoch: 6, Batch: 25,Loss: -0.684,Avg.Loss: 0.293,LR: 4.97E-04]Training epoch 6:  22%|██▏       | 25/112 [00:00<00:01, 57.95it/s, Epoch: 6, Batch: 26,Loss: -0.552,Avg.Loss: 0.261,LR: 4.97E-04]Training epoch 6:  23%|██▎       | 26/112 [00:00<00:01, 54.73it/s, Epoch: 6, Batch: 26,Loss: -0.552,Avg.Loss: 0.261,LR: 4.97E-04]Training epoch 6:  23%|██▎       | 26/112 [00:00<00:01, 54.73it/s, Epoch: 6, Batch: 27,Loss: 0.391,Avg.Loss: 0.266,LR: 4.97E-04] Training epoch 6:  24%|██▍       | 27/112 [00:00<00:01, 54.73it/s, Epoch: 6, Batch: 28,Loss: 1.465,Avg.Loss: 0.308,LR: 4.97E-04]Training epoch 6:  25%|██▌       | 28/112 [00:00<00:01, 54.73it/s, Epoch: 6, Batch: 29,Loss: 0.353,Avg.Loss: 0.310,LR: 4.97E-04]Training epoch 6:  26%|██▌       | 29/112 [00:00<00:01, 54.73it/s, Epoch: 6, Batch: 30,Loss: 0.433,Avg.Loss: 0.314,LR: 4.97E-04]Training epoch 6:  27%|██▋       | 30/112 [00:00<00:01, 54.73it/s, Epoch: 6, Batch: 31,Loss: 0.292,Avg.Loss: 0.313,LR: 4.97E-04]Training epoch 6:  28%|██▊       | 31/112 [00:00<00:01, 54.73it/s, Epoch: 6, Batch: 32,Loss: -0.036,Avg.Loss: 0.302,LR: 4.97E-04]Training epoch 6:  29%|██▊       | 32/112 [00:00<00:01, 54.11it/s, Epoch: 6, Batch: 32,Loss: -0.036,Avg.Loss: 0.302,LR: 4.97E-04]Training epoch 6:  29%|██▊       | 32/112 [00:00<00:01, 54.11it/s, Epoch: 6, Batch: 33,Loss: -0.552,Avg.Loss: 0.277,LR: 4.97E-04]Training epoch 6:  29%|██▉       | 33/112 [00:00<00:01, 54.11it/s, Epoch: 6, Batch: 34,Loss: -0.544,Avg.Loss: 0.252,LR: 4.97E-04]Training epoch 6:  30%|███       | 34/112 [00:00<00:01, 54.11it/s, Epoch: 6, Batch: 35,Loss: -0.475,Avg.Loss: 0.232,LR: 4.97E-04]Training epoch 6:  31%|███▏      | 35/112 [00:00<00:01, 54.11it/s, Epoch: 6, Batch: 36,Loss: -0.077,Avg.Loss: 0.223,LR: 4.97E-04]Training epoch 6:  32%|███▏      | 36/112 [00:00<00:01, 54.11it/s, Epoch: 6, Batch: 37,Loss: -0.148,Avg.Loss: 0.213,LR: 4.97E-04]Training epoch 6:  33%|███▎      | 37/112 [00:00<00:01, 54.11it/s, Epoch: 6, Batch: 38,Loss: 0.143,Avg.Loss: 0.211,LR: 4.96E-04] Training epoch 6:  34%|███▍      | 38/112 [00:00<00:01, 53.76it/s, Epoch: 6, Batch: 38,Loss: 0.143,Avg.Loss: 0.211,LR: 4.96E-04]Training epoch 6:  34%|███▍      | 38/112 [00:00<00:01, 53.76it/s, Epoch: 6, Batch: 39,Loss: -0.454,Avg.Loss: 0.194,LR: 4.96E-04]Training epoch 6:  35%|███▍      | 39/112 [00:00<00:01, 53.76it/s, Epoch: 6, Batch: 40,Loss: -0.713,Avg.Loss: 0.171,LR: 4.96E-04]Training epoch 6:  36%|███▌      | 40/112 [00:00<00:01, 53.76it/s, Epoch: 6, Batch: 41,Loss: -0.498,Avg.Loss: 0.155,LR: 4.96E-04]Training epoch 6:  37%|███▋      | 41/112 [00:00<00:01, 53.76it/s, Epoch: 6, Batch: 42,Loss: -0.627,Avg.Loss: 0.137,LR: 4.96E-04]Training epoch 6:  38%|███▊      | 42/112 [00:00<00:01, 53.76it/s, Epoch: 6, Batch: 43,Loss: -0.613,Avg.Loss: 0.119,LR: 4.96E-04]Training epoch 6:  38%|███▊      | 43/112 [00:00<00:01, 53.76it/s, Epoch: 6, Batch: 44,Loss: -0.886,Avg.Loss: 0.096,LR: 4.96E-04]Training epoch 6:  39%|███▉      | 44/112 [00:00<00:01, 53.54it/s, Epoch: 6, Batch: 44,Loss: -0.886,Avg.Loss: 0.096,LR: 4.96E-04]Training epoch 6:  39%|███▉      | 44/112 [00:00<00:01, 53.54it/s, Epoch: 6, Batch: 45,Loss: -0.798,Avg.Loss: 0.076,LR: 4.96E-04]Training epoch 6:  40%|████      | 45/112 [00:00<00:01, 53.54it/s, Epoch: 6, Batch: 46,Loss: -0.525,Avg.Loss: 0.063,LR: 4.96E-04]Training epoch 6:  41%|████      | 46/112 [00:00<00:01, 53.54it/s, Epoch: 6, Batch: 47,Loss: -0.333,Avg.Loss: 0.055,LR: 4.96E-04]Training epoch 6:  42%|████▏     | 47/112 [00:00<00:01, 53.54it/s, Epoch: 6, Batch: 48,Loss: -0.596,Avg.Loss: 0.041,LR: 4.96E-04]Training epoch 6:  43%|████▎     | 48/112 [00:00<00:01, 53.54it/s, Epoch: 6, Batch: 49,Loss: -0.228,Avg.Loss: 0.036,LR: 4.96E-04]Training epoch 6:  44%|████▍     | 49/112 [00:00<00:01, 53.54it/s, Epoch: 6, Batch: 50,Loss: -0.340,Avg.Loss: 0.028,LR: 4.96E-04]Training epoch 6:  45%|████▍     | 50/112 [00:00<00:01, 53.37it/s, Epoch: 6, Batch: 50,Loss: -0.340,Avg.Loss: 0.028,LR: 4.96E-04]Training epoch 6:  45%|████▍     | 50/112 [00:00<00:01, 53.37it/s, Epoch: 6, Batch: 51,Loss: -0.421,Avg.Loss: 0.019,LR: 4.96E-04]Training epoch 6:  46%|████▌     | 51/112 [00:00<00:01, 53.37it/s, Epoch: 6, Batch: 52,Loss: -0.432,Avg.Loss: 0.011,LR: 4.96E-04]Training epoch 6:  46%|████▋     | 52/112 [00:00<00:01, 53.37it/s, Epoch: 6, Batch: 53,Loss: -0.344,Avg.Loss: 0.004,LR: 4.96E-04]Training epoch 6:  47%|████▋     | 53/112 [00:00<00:01, 53.37it/s, Epoch: 6, Batch: 54,Loss: -0.688,Avg.Loss: -0.009,LR: 4.96E-04]Training epoch 6:  48%|████▊     | 54/112 [00:01<00:01, 53.37it/s, Epoch: 6, Batch: 55,Loss: -0.576,Avg.Loss: -0.019,LR: 4.96E-04]Training epoch 6:  49%|████▉     | 55/112 [00:01<00:01, 53.37it/s, Epoch: 6, Batch: 56,Loss: -0.714,Avg.Loss: -0.031,LR: 4.96E-04]Training epoch 6:  50%|█████     | 56/112 [00:01<00:01, 53.14it/s, Epoch: 6, Batch: 56,Loss: -0.714,Avg.Loss: -0.031,LR: 4.96E-04]Training epoch 6:  50%|█████     | 56/112 [00:01<00:01, 53.14it/s, Epoch: 6, Batch: 57,Loss: -0.885,Avg.Loss: -0.046,LR: 4.96E-04]Training epoch 6:  51%|█████     | 57/112 [00:01<00:01, 53.14it/s, Epoch: 6, Batch: 58,Loss: -0.012,Avg.Loss: -0.046,LR: 4.96E-04]Training epoch 6:  52%|█████▏    | 58/112 [00:01<00:01, 53.14it/s, Epoch: 6, Batch: 59,Loss: 0.090,Avg.Loss: -0.044,LR: 4.96E-04] Training epoch 6:  53%|█████▎    | 59/112 [00:01<00:00, 53.14it/s, Epoch: 6, Batch: 60,Loss: -0.805,Avg.Loss: -0.056,LR: 4.96E-04]Training epoch 6:  54%|█████▎    | 60/112 [00:01<00:00, 53.14it/s, Epoch: 6, Batch: 61,Loss: 0.036,Avg.Loss: -0.055,LR: 4.96E-04] Training epoch 6:  54%|█████▍    | 61/112 [00:01<00:00, 53.14it/s, Epoch: 6, Batch: 62,Loss: 1.220,Avg.Loss: -0.034,LR: 4.96E-04]Training epoch 6:  55%|█████▌    | 62/112 [00:01<00:00, 53.06it/s, Epoch: 6, Batch: 62,Loss: 1.220,Avg.Loss: -0.034,LR: 4.96E-04]Training epoch 6:  55%|█████▌    | 62/112 [00:01<00:00, 53.06it/s, Epoch: 6, Batch: 63,Loss: 0.041,Avg.Loss: -0.033,LR: 4.96E-04]Training epoch 6:  56%|█████▋    | 63/112 [00:01<00:00, 53.06it/s, Epoch: 6, Batch: 64,Loss: -0.492,Avg.Loss: -0.040,LR: 4.96E-04]Training epoch 6:  57%|█████▋    | 64/112 [00:01<00:00, 53.06it/s, Epoch: 6, Batch: 65,Loss: -0.382,Avg.Loss: -0.045,LR: 4.96E-04]Training epoch 6:  58%|█████▊    | 65/112 [00:01<00:00, 53.06it/s, Epoch: 6, Batch: 66,Loss: -0.929,Avg.Loss: -0.059,LR: 4.96E-04]Training epoch 6:  59%|█████▉    | 66/112 [00:01<00:00, 53.06it/s, Epoch: 6, Batch: 67,Loss: 0.585,Avg.Loss: -0.049,LR: 4.96E-04] Training epoch 6:  60%|█████▉    | 67/112 [00:01<00:00, 53.06it/s, Epoch: 6, Batch: 68,Loss: 0.492,Avg.Loss: -0.041,LR: 4.96E-04]Training epoch 6:  61%|██████    | 68/112 [00:01<00:00, 53.04it/s, Epoch: 6, Batch: 68,Loss: 0.492,Avg.Loss: -0.041,LR: 4.96E-04]Training epoch 6:  61%|██████    | 68/112 [00:01<00:00, 53.04it/s, Epoch: 6, Batch: 69,Loss: -0.873,Avg.Loss: -0.053,LR: 4.96E-04]Training epoch 6:  62%|██████▏   | 69/112 [00:01<00:00, 53.04it/s, Epoch: 6, Batch: 70,Loss: -0.179,Avg.Loss: -0.055,LR: 4.96E-04]Training epoch 6:  62%|██████▎   | 70/112 [00:01<00:00, 53.04it/s, Epoch: 6, Batch: 71,Loss: 1.036,Avg.Loss: -0.040,LR: 4.96E-04] Training epoch 6:  63%|██████▎   | 71/112 [00:01<00:00, 53.04it/s, Epoch: 6, Batch: 72,Loss: 0.039,Avg.Loss: -0.039,LR: 4.96E-04]Training epoch 6:  64%|██████▍   | 72/112 [00:01<00:00, 53.04it/s, Epoch: 6, Batch: 73,Loss: -0.448,Avg.Loss: -0.044,LR: 4.96E-04]Training epoch 6:  65%|██████▌   | 73/112 [00:01<00:00, 53.04it/s, Epoch: 6, Batch: 74,Loss: -0.371,Avg.Loss: -0.049,LR: 4.96E-04]Training epoch 6:  66%|██████▌   | 74/112 [00:01<00:00, 53.09it/s, Epoch: 6, Batch: 74,Loss: -0.371,Avg.Loss: -0.049,LR: 4.96E-04]Training epoch 6:  66%|██████▌   | 74/112 [00:01<00:00, 53.09it/s, Epoch: 6, Batch: 75,Loss: -1.122,Avg.Loss: -0.063,LR: 4.96E-04]Training epoch 6:  67%|██████▋   | 75/112 [00:01<00:00, 53.09it/s, Epoch: 6, Batch: 76,Loss: 0.958,Avg.Loss: -0.050,LR: 4.96E-04] Training epoch 6:  68%|██████▊   | 76/112 [00:01<00:00, 53.09it/s, Epoch: 6, Batch: 77,Loss: 1.653,Avg.Loss: -0.027,LR: 4.96E-04]Training epoch 6:  69%|██████▉   | 77/112 [00:01<00:00, 53.09it/s, Epoch: 6, Batch: 78,Loss: 0.772,Avg.Loss: -0.017,LR: 4.96E-04]Training epoch 6:  70%|██████▉   | 78/112 [00:01<00:00, 53.09it/s, Epoch: 6, Batch: 79,Loss: -0.498,Avg.Loss: -0.023,LR: 4.96E-04]Training epoch 6:  71%|███████   | 79/112 [00:01<00:00, 53.09it/s, Epoch: 6, Batch: 80,Loss: 0.625,Avg.Loss: -0.015,LR: 4.96E-04] Training epoch 6:  71%|███████▏  | 80/112 [00:01<00:00, 53.27it/s, Epoch: 6, Batch: 80,Loss: 0.625,Avg.Loss: -0.015,LR: 4.96E-04]Training epoch 6:  71%|███████▏  | 80/112 [00:01<00:00, 53.27it/s, Epoch: 6, Batch: 81,Loss: 1.464,Avg.Loss: 0.003,LR: 4.96E-04] Training epoch 6:  72%|███████▏  | 81/112 [00:01<00:00, 53.27it/s, Epoch: 6, Batch: 82,Loss: 0.638,Avg.Loss: 0.011,LR: 4.96E-04]Training epoch 6:  73%|███████▎  | 82/112 [00:01<00:00, 53.27it/s, Epoch: 6, Batch: 83,Loss: -0.752,Avg.Loss: 0.002,LR: 4.96E-04]Training epoch 6:  74%|███████▍  | 83/112 [00:01<00:00, 53.27it/s, Epoch: 6, Batch: 84,Loss: 1.363,Avg.Loss: 0.018,LR: 4.96E-04] Training epoch 6:  75%|███████▌  | 84/112 [00:01<00:00, 53.27it/s, Epoch: 6, Batch: 85,Loss: 5.801,Avg.Loss: 0.086,LR: 4.96E-04]Training epoch 6:  76%|███████▌  | 85/112 [00:01<00:00, 53.27it/s, Epoch: 6, Batch: 86,Loss: 7.688,Avg.Loss: 0.174,LR: 4.96E-04]Training epoch 6:  77%|███████▋  | 86/112 [00:01<00:00, 53.32it/s, Epoch: 6, Batch: 86,Loss: 7.688,Avg.Loss: 0.174,LR: 4.96E-04]Training epoch 6:  77%|███████▋  | 86/112 [00:01<00:00, 53.32it/s, Epoch: 6, Batch: 87,Loss: 2.748,Avg.Loss: 0.204,LR: 4.96E-04]Training epoch 6:  78%|███████▊  | 87/112 [00:01<00:00, 53.32it/s, Epoch: 6, Batch: 88,Loss: -0.352,Avg.Loss: 0.198,LR: 4.96E-04]Training epoch 6:  79%|███████▊  | 88/112 [00:01<00:00, 53.32it/s, Epoch: 6, Batch: 89,Loss: 1.674,Avg.Loss: 0.214,LR: 4.96E-04] Training epoch 6:  79%|███████▉  | 89/112 [00:01<00:00, 53.32it/s, Epoch: 6, Batch: 90,Loss: 2.408,Avg.Loss: 0.239,LR: 4.96E-04]Training epoch 6:  80%|████████  | 90/112 [00:01<00:00, 53.32it/s, Epoch: 6, Batch: 91,Loss: 1.836,Avg.Loss: 0.256,LR: 4.96E-04]Training epoch 6:  81%|████████▏ | 91/112 [00:01<00:00, 53.32it/s, Epoch: 6, Batch: 92,Loss: 0.816,Avg.Loss: 0.262,LR: 4.96E-04]Training epoch 6:  82%|████████▏ | 92/112 [00:01<00:00, 53.26it/s, Epoch: 6, Batch: 92,Loss: 0.816,Avg.Loss: 0.262,LR: 4.96E-04]Training epoch 6:  82%|████████▏ | 92/112 [00:01<00:00, 53.26it/s, Epoch: 6, Batch: 93,Loss: -0.215,Avg.Loss: 0.257,LR: 4.96E-04]Training epoch 6:  83%|████████▎ | 93/112 [00:01<00:00, 53.26it/s, Epoch: 6, Batch: 94,Loss: 1.027,Avg.Loss: 0.265,LR: 4.96E-04] Training epoch 6:  84%|████████▍ | 94/112 [00:01<00:00, 53.26it/s, Epoch: 6, Batch: 95,Loss: 3.063,Avg.Loss: 0.295,LR: 4.96E-04]Training epoch 6:  85%|████████▍ | 95/112 [00:01<00:00, 53.26it/s, Epoch: 6, Batch: 96,Loss: 2.890,Avg.Loss: 0.322,LR: 4.96E-04]Training epoch 6:  86%|████████▌ | 96/112 [00:01<00:00, 53.26it/s, Epoch: 6, Batch: 97,Loss: 0.872,Avg.Loss: 0.327,LR: 4.96E-04]Training epoch 6:  87%|████████▋ | 97/112 [00:01<00:00, 53.26it/s, Epoch: 6, Batch: 98,Loss: -0.808,Avg.Loss: 0.316,LR: 4.96E-04]Training epoch 6:  88%|████████▊ | 98/112 [00:01<00:00, 53.30it/s, Epoch: 6, Batch: 98,Loss: -0.808,Avg.Loss: 0.316,LR: 4.96E-04]Training epoch 6:  88%|████████▊ | 98/112 [00:01<00:00, 53.30it/s, Epoch: 6, Batch: 99,Loss: -0.543,Avg.Loss: 0.307,LR: 4.96E-04]Training epoch 6:  88%|████████▊ | 99/112 [00:01<00:00, 53.30it/s, Epoch: 6, Batch: 100,Loss: -0.849,Avg.Loss: 0.296,LR: 4.96E-04]Training epoch 6:  89%|████████▉ | 100/112 [00:01<00:00, 53.30it/s, Epoch: 6, Batch: 101,Loss: -0.825,Avg.Loss: 0.285,LR: 4.96E-04]Training epoch 6:  90%|█████████ | 101/112 [00:01<00:00, 53.30it/s, Epoch: 6, Batch: 102,Loss: -0.584,Avg.Loss: 0.276,LR: 4.96E-04]Training epoch 6:  91%|█████████ | 102/112 [00:01<00:00, 53.30it/s, Epoch: 6, Batch: 103,Loss: -0.743,Avg.Loss: 0.266,LR: 4.96E-04]Training epoch 6:  92%|█████████▏| 103/112 [00:01<00:00, 53.30it/s, Epoch: 6, Batch: 104,Loss: -0.616,Avg.Loss: 0.258,LR: 4.96E-04]Training epoch 6:  93%|█████████▎| 104/112 [00:01<00:00, 53.58it/s, Epoch: 6, Batch: 104,Loss: -0.616,Avg.Loss: 0.258,LR: 4.96E-04]Training epoch 6:  93%|█████████▎| 104/112 [00:01<00:00, 53.58it/s, Epoch: 6, Batch: 105,Loss: -0.529,Avg.Loss: 0.250,LR: 4.96E-04]Training epoch 6:  94%|█████████▍| 105/112 [00:01<00:00, 53.58it/s, Epoch: 6, Batch: 106,Loss: -0.649,Avg.Loss: 0.242,LR: 4.96E-04]Training epoch 6:  95%|█████████▍| 106/112 [00:01<00:00, 53.58it/s, Epoch: 6, Batch: 107,Loss: -0.708,Avg.Loss: 0.233,LR: 4.96E-04]Training epoch 6:  96%|█████████▌| 107/112 [00:02<00:00, 53.58it/s, Epoch: 6, Batch: 108,Loss: -0.755,Avg.Loss: 0.224,LR: 4.96E-04]Training epoch 6:  96%|█████████▋| 108/112 [00:02<00:00, 53.58it/s, Epoch: 6, Batch: 109,Loss: -0.781,Avg.Loss: 0.214,LR: 4.96E-04]Training epoch 6:  97%|█████████▋| 109/112 [00:02<00:00, 53.58it/s, Epoch: 6, Batch: 110,Loss: -0.624,Avg.Loss: 0.207,LR: 4.96E-04]Training epoch 6:  98%|█████████▊| 110/112 [00:02<00:00, 52.70it/s, Epoch: 6, Batch: 110,Loss: -0.624,Avg.Loss: 0.207,LR: 4.96E-04]Training epoch 6:  98%|█████████▊| 110/112 [00:02<00:00, 52.70it/s, Epoch: 6, Batch: 111,Loss: -0.564,Avg.Loss: 0.200,LR: 4.96E-04]Training epoch 6:  99%|█████████▉| 111/112 [00:02<00:00, 52.70it/s, Epoch: 6, Batch: 112,Loss: -1.254,Avg.Loss: 0.187,LR: 4.96E-04]Training epoch 6: 100%|██████████| 112/112 [00:02<00:00, 53.74it/s, Epoch: 6, Batch: 112,Loss: -1.254,Avg.Loss: 0.187,LR: 4.96E-04]
Training epoch 7:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 7:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 7, Batch: 1,Loss: -0.874,Avg.Loss: -0.874,LR: 4.96E-04]Training epoch 7:   1%|          | 1/112 [00:00<00:03, 28.65it/s, Epoch: 7, Batch: 2,Loss: -0.738,Avg.Loss: -0.806,LR: 4.96E-04]Training epoch 7:   2%|▏         | 2/112 [00:00<00:02, 37.49it/s, Epoch: 7, Batch: 3,Loss: -0.724,Avg.Loss: -0.779,LR: 4.96E-04]Training epoch 7:   3%|▎         | 3/112 [00:00<00:02, 43.96it/s, Epoch: 7, Batch: 4,Loss: -0.882,Avg.Loss: -0.804,LR: 4.96E-04]Training epoch 7:   4%|▎         | 4/112 [00:00<00:02, 48.69it/s, Epoch: 7, Batch: 5,Loss: -0.837,Avg.Loss: -0.811,LR: 4.96E-04]Training epoch 7:   4%|▍         | 5/112 [00:00<00:02, 51.77it/s, Epoch: 7, Batch: 6,Loss: -0.892,Avg.Loss: -0.824,LR: 4.95E-04]Training epoch 7:   5%|▌         | 6/112 [00:00<00:02, 51.72it/s, Epoch: 7, Batch: 7,Loss: -0.523,Avg.Loss: -0.781,LR: 4.95E-04]Training epoch 7:   6%|▋         | 7/112 [00:00<00:01, 60.26it/s, Epoch: 7, Batch: 7,Loss: -0.523,Avg.Loss: -0.781,LR: 4.95E-04]Training epoch 7:   6%|▋         | 7/112 [00:00<00:01, 60.26it/s, Epoch: 7, Batch: 8,Loss: -0.169,Avg.Loss: -0.705,LR: 4.95E-04]Training epoch 7:   7%|▋         | 8/112 [00:00<00:01, 60.26it/s, Epoch: 7, Batch: 9,Loss: -0.615,Avg.Loss: -0.695,LR: 4.95E-04]Training epoch 7:   8%|▊         | 9/112 [00:00<00:01, 60.26it/s, Epoch: 7, Batch: 10,Loss: -0.293,Avg.Loss: -0.655,LR: 4.95E-04]Training epoch 7:   9%|▉         | 10/112 [00:00<00:01, 60.26it/s, Epoch: 7, Batch: 11,Loss: -0.595,Avg.Loss: -0.649,LR: 4.95E-04]Training epoch 7:  10%|▉         | 11/112 [00:00<00:01, 60.26it/s, Epoch: 7, Batch: 12,Loss: -0.470,Avg.Loss: -0.634,LR: 4.95E-04]Training epoch 7:  11%|█         | 12/112 [00:00<00:01, 60.26it/s, Epoch: 7, Batch: 13,Loss: -0.349,Avg.Loss: -0.612,LR: 4.95E-04]Training epoch 7:  12%|█▏        | 13/112 [00:00<00:01, 60.26it/s, Epoch: 7, Batch: 14,Loss: -0.526,Avg.Loss: -0.606,LR: 4.95E-04]Training epoch 7:  12%|█▎        | 14/112 [00:00<00:01, 63.52it/s, Epoch: 7, Batch: 14,Loss: -0.526,Avg.Loss: -0.606,LR: 4.95E-04]Training epoch 7:  12%|█▎        | 14/112 [00:00<00:01, 63.52it/s, Epoch: 7, Batch: 15,Loss: 0.191,Avg.Loss: -0.553,LR: 4.95E-04] Training epoch 7:  13%|█▎        | 15/112 [00:00<00:01, 63.52it/s, Epoch: 7, Batch: 16,Loss: 0.221,Avg.Loss: -0.505,LR: 4.95E-04]Training epoch 7:  14%|█▍        | 16/112 [00:00<00:01, 63.52it/s, Epoch: 7, Batch: 17,Loss: -0.504,Avg.Loss: -0.505,LR: 4.95E-04]Training epoch 7:  15%|█▌        | 17/112 [00:00<00:01, 63.52it/s, Epoch: 7, Batch: 18,Loss: -0.340,Avg.Loss: -0.496,LR: 4.95E-04]Training epoch 7:  16%|█▌        | 18/112 [00:00<00:01, 63.52it/s, Epoch: 7, Batch: 19,Loss: 1.202,Avg.Loss: -0.406,LR: 4.95E-04] Training epoch 7:  17%|█▋        | 19/112 [00:00<00:01, 63.52it/s, Epoch: 7, Batch: 20,Loss: 0.269,Avg.Loss: -0.372,LR: 4.95E-04]Training epoch 7:  18%|█▊        | 20/112 [00:00<00:01, 63.52it/s, Epoch: 7, Batch: 21,Loss: -0.668,Avg.Loss: -0.387,LR: 4.95E-04]Training epoch 7:  19%|█▉        | 21/112 [00:00<00:01, 58.15it/s, Epoch: 7, Batch: 21,Loss: -0.668,Avg.Loss: -0.387,LR: 4.95E-04]Training epoch 7:  19%|█▉        | 21/112 [00:00<00:01, 58.15it/s, Epoch: 7, Batch: 22,Loss: -0.352,Avg.Loss: -0.385,LR: 4.95E-04]Training epoch 7:  20%|█▉        | 22/112 [00:00<00:01, 58.15it/s, Epoch: 7, Batch: 23,Loss: -1.022,Avg.Loss: -0.413,LR: 4.95E-04]Training epoch 7:  21%|██        | 23/112 [00:00<00:01, 58.15it/s, Epoch: 7, Batch: 24,Loss: -0.016,Avg.Loss: -0.396,LR: 4.95E-04]Training epoch 7:  21%|██▏       | 24/112 [00:00<00:01, 58.15it/s, Epoch: 7, Batch: 25,Loss: 0.214,Avg.Loss: -0.372,LR: 4.95E-04] Training epoch 7:  22%|██▏       | 25/112 [00:00<00:01, 58.15it/s, Epoch: 7, Batch: 26,Loss: -0.204,Avg.Loss: -0.365,LR: 4.95E-04]Training epoch 7:  23%|██▎       | 26/112 [00:00<00:01, 58.15it/s, Epoch: 7, Batch: 27,Loss: 0.330,Avg.Loss: -0.339,LR: 4.95E-04] Training epoch 7:  24%|██▍       | 27/112 [00:00<00:01, 54.80it/s, Epoch: 7, Batch: 27,Loss: 0.330,Avg.Loss: -0.339,LR: 4.95E-04]Training epoch 7:  24%|██▍       | 27/112 [00:00<00:01, 54.80it/s, Epoch: 7, Batch: 28,Loss: -0.176,Avg.Loss: -0.334,LR: 4.95E-04]Training epoch 7:  25%|██▌       | 28/112 [00:00<00:01, 54.80it/s, Epoch: 7, Batch: 29,Loss: -0.760,Avg.Loss: -0.348,LR: 4.95E-04]Training epoch 7:  26%|██▌       | 29/112 [00:00<00:01, 54.80it/s, Epoch: 7, Batch: 30,Loss: -0.252,Avg.Loss: -0.345,LR: 4.95E-04]Training epoch 7:  27%|██▋       | 30/112 [00:00<00:01, 54.80it/s, Epoch: 7, Batch: 31,Loss: 0.132,Avg.Loss: -0.330,LR: 4.95E-04] Training epoch 7:  28%|██▊       | 31/112 [00:00<00:01, 54.80it/s, Epoch: 7, Batch: 32,Loss: -0.637,Avg.Loss: -0.339,LR: 4.95E-04]Training epoch 7:  29%|██▊       | 32/112 [00:00<00:01, 54.80it/s, Epoch: 7, Batch: 33,Loss: -0.770,Avg.Loss: -0.352,LR: 4.95E-04]Training epoch 7:  29%|██▉       | 33/112 [00:00<00:01, 53.83it/s, Epoch: 7, Batch: 33,Loss: -0.770,Avg.Loss: -0.352,LR: 4.95E-04]Training epoch 7:  29%|██▉       | 33/112 [00:00<00:01, 53.83it/s, Epoch: 7, Batch: 34,Loss: 0.291,Avg.Loss: -0.333,LR: 4.95E-04] Training epoch 7:  30%|███       | 34/112 [00:00<00:01, 53.83it/s, Epoch: 7, Batch: 35,Loss: -0.676,Avg.Loss: -0.343,LR: 4.95E-04]Training epoch 7:  31%|███▏      | 35/112 [00:00<00:01, 53.83it/s, Epoch: 7, Batch: 36,Loss: -0.417,Avg.Loss: -0.345,LR: 4.95E-04]Training epoch 7:  32%|███▏      | 36/112 [00:00<00:01, 53.83it/s, Epoch: 7, Batch: 37,Loss: 0.205,Avg.Loss: -0.330,LR: 4.95E-04] Training epoch 7:  33%|███▎      | 37/112 [00:00<00:01, 53.83it/s, Epoch: 7, Batch: 38,Loss: -0.677,Avg.Loss: -0.340,LR: 4.95E-04]Training epoch 7:  34%|███▍      | 38/112 [00:00<00:01, 53.83it/s, Epoch: 7, Batch: 39,Loss: -0.229,Avg.Loss: -0.337,LR: 4.95E-04]Training epoch 7:  35%|███▍      | 39/112 [00:00<00:01, 53.87it/s, Epoch: 7, Batch: 39,Loss: -0.229,Avg.Loss: -0.337,LR: 4.95E-04]Training epoch 7:  35%|███▍      | 39/112 [00:00<00:01, 53.87it/s, Epoch: 7, Batch: 40,Loss: 0.237,Avg.Loss: -0.322,LR: 4.95E-04] Training epoch 7:  36%|███▌      | 40/112 [00:00<00:01, 53.87it/s, Epoch: 7, Batch: 41,Loss: -0.698,Avg.Loss: -0.332,LR: 4.95E-04]Training epoch 7:  37%|███▋      | 41/112 [00:00<00:01, 53.87it/s, Epoch: 7, Batch: 42,Loss: -0.758,Avg.Loss: -0.342,LR: 4.95E-04]Training epoch 7:  38%|███▊      | 42/112 [00:00<00:01, 53.87it/s, Epoch: 7, Batch: 43,Loss: -0.395,Avg.Loss: -0.343,LR: 4.95E-04]Training epoch 7:  38%|███▊      | 43/112 [00:00<00:01, 53.87it/s, Epoch: 7, Batch: 44,Loss: -0.890,Avg.Loss: -0.355,LR: 4.95E-04]Training epoch 7:  39%|███▉      | 44/112 [00:00<00:01, 53.87it/s, Epoch: 7, Batch: 45,Loss: -0.544,Avg.Loss: -0.360,LR: 4.95E-04]Training epoch 7:  40%|████      | 45/112 [00:00<00:01, 53.59it/s, Epoch: 7, Batch: 45,Loss: -0.544,Avg.Loss: -0.360,LR: 4.95E-04]Training epoch 7:  40%|████      | 45/112 [00:00<00:01, 53.59it/s, Epoch: 7, Batch: 46,Loss: 0.139,Avg.Loss: -0.349,LR: 4.95E-04] Training epoch 7:  41%|████      | 46/112 [00:00<00:01, 53.59it/s, Epoch: 7, Batch: 47,Loss: -0.255,Avg.Loss: -0.347,LR: 4.95E-04]Training epoch 7:  42%|████▏     | 47/112 [00:00<00:01, 53.59it/s, Epoch: 7, Batch: 48,Loss: -0.880,Avg.Loss: -0.358,LR: 4.95E-04]Training epoch 7:  43%|████▎     | 48/112 [00:00<00:01, 53.59it/s, Epoch: 7, Batch: 49,Loss: -0.476,Avg.Loss: -0.360,LR: 4.95E-04]Training epoch 7:  44%|████▍     | 49/112 [00:00<00:01, 53.59it/s, Epoch: 7, Batch: 50,Loss: -0.869,Avg.Loss: -0.370,LR: 4.95E-04]Training epoch 7:  45%|████▍     | 50/112 [00:00<00:01, 53.59it/s, Epoch: 7, Batch: 51,Loss: -0.532,Avg.Loss: -0.374,LR: 4.95E-04]Training epoch 7:  46%|████▌     | 51/112 [00:00<00:01, 53.57it/s, Epoch: 7, Batch: 51,Loss: -0.532,Avg.Loss: -0.374,LR: 4.95E-04]Training epoch 7:  46%|████▌     | 51/112 [00:00<00:01, 53.57it/s, Epoch: 7, Batch: 52,Loss: 0.044,Avg.Loss: -0.366,LR: 4.95E-04] Training epoch 7:  46%|████▋     | 52/112 [00:00<00:01, 53.57it/s, Epoch: 7, Batch: 53,Loss: -0.608,Avg.Loss: -0.370,LR: 4.95E-04]Training epoch 7:  47%|████▋     | 53/112 [00:00<00:01, 53.57it/s, Epoch: 7, Batch: 54,Loss: -0.652,Avg.Loss: -0.375,LR: 4.95E-04]Training epoch 7:  48%|████▊     | 54/112 [00:01<00:01, 53.57it/s, Epoch: 7, Batch: 55,Loss: 0.044,Avg.Loss: -0.368,LR: 4.95E-04] Training epoch 7:  49%|████▉     | 55/112 [00:01<00:01, 53.57it/s, Epoch: 7, Batch: 56,Loss: -1.137,Avg.Loss: -0.382,LR: 4.95E-04]Training epoch 7:  50%|█████     | 56/112 [00:01<00:01, 53.57it/s, Epoch: 7, Batch: 57,Loss: -0.103,Avg.Loss: -0.377,LR: 4.95E-04]Training epoch 7:  51%|█████     | 57/112 [00:01<00:01, 53.56it/s, Epoch: 7, Batch: 57,Loss: -0.103,Avg.Loss: -0.377,LR: 4.95E-04]Training epoch 7:  51%|█████     | 57/112 [00:01<00:01, 53.56it/s, Epoch: 7, Batch: 58,Loss: 0.112,Avg.Loss: -0.368,LR: 4.95E-04] Training epoch 7:  52%|█████▏    | 58/112 [00:01<00:01, 53.56it/s, Epoch: 7, Batch: 59,Loss: -0.652,Avg.Loss: -0.373,LR: 4.95E-04]Training epoch 7:  53%|█████▎    | 59/112 [00:01<00:00, 53.56it/s, Epoch: 7, Batch: 60,Loss: -0.914,Avg.Loss: -0.382,LR: 4.95E-04]Training epoch 7:  54%|█████▎    | 60/112 [00:01<00:00, 53.56it/s, Epoch: 7, Batch: 61,Loss: -0.102,Avg.Loss: -0.377,LR: 4.95E-04]Training epoch 7:  54%|█████▍    | 61/112 [00:01<00:00, 53.56it/s, Epoch: 7, Batch: 62,Loss: -0.603,Avg.Loss: -0.381,LR: 4.95E-04]Training epoch 7:  55%|█████▌    | 62/112 [00:01<00:00, 53.56it/s, Epoch: 7, Batch: 63,Loss: -0.579,Avg.Loss: -0.384,LR: 4.95E-04]Training epoch 7:  56%|█████▋    | 63/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 63,Loss: -0.579,Avg.Loss: -0.384,LR: 4.95E-04]Training epoch 7:  56%|█████▋    | 63/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 64,Loss: 0.052,Avg.Loss: -0.377,LR: 4.95E-04] Training epoch 7:  57%|█████▋    | 64/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 65,Loss: -0.782,Avg.Loss: -0.384,LR: 4.95E-04]Training epoch 7:  58%|█████▊    | 65/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 66,Loss: -1.056,Avg.Loss: -0.394,LR: 4.95E-04]Training epoch 7:  59%|█████▉    | 66/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 67,Loss: -0.372,Avg.Loss: -0.393,LR: 4.95E-04]Training epoch 7:  60%|█████▉    | 67/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 68,Loss: -0.975,Avg.Loss: -0.402,LR: 4.95E-04]Training epoch 7:  61%|██████    | 68/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 69,Loss: -0.784,Avg.Loss: -0.408,LR: 4.95E-04]Training epoch 7:  62%|██████▏   | 69/112 [00:01<00:00, 53.51it/s, Epoch: 7, Batch: 69,Loss: -0.784,Avg.Loss: -0.408,LR: 4.95E-04]Training epoch 7:  62%|██████▏   | 69/112 [00:01<00:00, 53.51it/s, Epoch: 7, Batch: 70,Loss: -0.247,Avg.Loss: -0.405,LR: 4.95E-04]Training epoch 7:  62%|██████▎   | 70/112 [00:01<00:00, 53.51it/s, Epoch: 7, Batch: 71,Loss: -0.953,Avg.Loss: -0.413,LR: 4.95E-04]Training epoch 7:  63%|██████▎   | 71/112 [00:01<00:00, 53.51it/s, Epoch: 7, Batch: 72,Loss: -0.674,Avg.Loss: -0.417,LR: 4.95E-04]Training epoch 7:  64%|██████▍   | 72/112 [00:01<00:00, 53.51it/s, Epoch: 7, Batch: 73,Loss: -0.335,Avg.Loss: -0.415,LR: 4.95E-04]Training epoch 7:  65%|██████▌   | 73/112 [00:01<00:00, 53.51it/s, Epoch: 7, Batch: 74,Loss: -0.769,Avg.Loss: -0.420,LR: 4.95E-04]Training epoch 7:  66%|██████▌   | 74/112 [00:01<00:00, 53.51it/s, Epoch: 7, Batch: 75,Loss: -0.493,Avg.Loss: -0.421,LR: 4.95E-04]Training epoch 7:  67%|██████▋   | 75/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 75,Loss: -0.493,Avg.Loss: -0.421,LR: 4.95E-04]Training epoch 7:  67%|██████▋   | 75/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 76,Loss: -0.113,Avg.Loss: -0.417,LR: 4.95E-04]Training epoch 7:  68%|██████▊   | 76/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 77,Loss: -0.737,Avg.Loss: -0.421,LR: 4.95E-04]Training epoch 7:  69%|██████▉   | 77/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 78,Loss: -0.619,Avg.Loss: -0.424,LR: 4.94E-04]Training epoch 7:  70%|██████▉   | 78/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 79,Loss: -0.404,Avg.Loss: -0.424,LR: 4.94E-04]Training epoch 7:  71%|███████   | 79/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 80,Loss: -0.660,Avg.Loss: -0.427,LR: 4.94E-04]Training epoch 7:  71%|███████▏  | 80/112 [00:01<00:00, 53.43it/s, Epoch: 7, Batch: 81,Loss: -0.423,Avg.Loss: -0.427,LR: 4.94E-04]Training epoch 7:  72%|███████▏  | 81/112 [00:01<00:00, 53.45it/s, Epoch: 7, Batch: 81,Loss: -0.423,Avg.Loss: -0.427,LR: 4.94E-04]Training epoch 7:  72%|███████▏  | 81/112 [00:01<00:00, 53.45it/s, Epoch: 7, Batch: 82,Loss: -0.474,Avg.Loss: -0.427,LR: 4.94E-04]Training epoch 7:  73%|███████▎  | 82/112 [00:01<00:00, 53.45it/s, Epoch: 7, Batch: 83,Loss: -1.079,Avg.Loss: -0.435,LR: 4.94E-04]Training epoch 7:  74%|███████▍  | 83/112 [00:01<00:00, 53.45it/s, Epoch: 7, Batch: 84,Loss: -0.158,Avg.Loss: -0.432,LR: 4.94E-04]Training epoch 7:  75%|███████▌  | 84/112 [00:01<00:00, 53.45it/s, Epoch: 7, Batch: 85,Loss: -0.551,Avg.Loss: -0.433,LR: 4.94E-04]Training epoch 7:  76%|███████▌  | 85/112 [00:01<00:00, 53.45it/s, Epoch: 7, Batch: 86,Loss: -0.349,Avg.Loss: -0.432,LR: 4.94E-04]Training epoch 7:  77%|███████▋  | 86/112 [00:01<00:00, 53.45it/s, Epoch: 7, Batch: 87,Loss: -0.670,Avg.Loss: -0.435,LR: 4.94E-04]Training epoch 7:  78%|███████▊  | 87/112 [00:01<00:00, 53.54it/s, Epoch: 7, Batch: 87,Loss: -0.670,Avg.Loss: -0.435,LR: 4.94E-04]Training epoch 7:  78%|███████▊  | 87/112 [00:01<00:00, 53.54it/s, Epoch: 7, Batch: 88,Loss: -0.354,Avg.Loss: -0.434,LR: 4.94E-04]Training epoch 7:  79%|███████▊  | 88/112 [00:01<00:00, 53.54it/s, Epoch: 7, Batch: 89,Loss: -0.990,Avg.Loss: -0.440,LR: 4.94E-04]Training epoch 7:  79%|███████▉  | 89/112 [00:01<00:00, 53.54it/s, Epoch: 7, Batch: 90,Loss: -0.678,Avg.Loss: -0.443,LR: 4.94E-04]Training epoch 7:  80%|████████  | 90/112 [00:01<00:00, 53.54it/s, Epoch: 7, Batch: 91,Loss: -0.192,Avg.Loss: -0.440,LR: 4.94E-04]Training epoch 7:  81%|████████▏ | 91/112 [00:01<00:00, 53.54it/s, Epoch: 7, Batch: 92,Loss: -0.742,Avg.Loss: -0.443,LR: 4.94E-04]Training epoch 7:  82%|████████▏ | 92/112 [00:01<00:00, 53.54it/s, Epoch: 7, Batch: 93,Loss: -0.442,Avg.Loss: -0.443,LR: 4.94E-04]Training epoch 7:  83%|████████▎ | 93/112 [00:01<00:00, 53.58it/s, Epoch: 7, Batch: 93,Loss: -0.442,Avg.Loss: -0.443,LR: 4.94E-04]Training epoch 7:  83%|████████▎ | 93/112 [00:01<00:00, 53.58it/s, Epoch: 7, Batch: 94,Loss: -0.101,Avg.Loss: -0.440,LR: 4.94E-04]Training epoch 7:  84%|████████▍ | 94/112 [00:01<00:00, 53.58it/s, Epoch: 7, Batch: 95,Loss: -0.789,Avg.Loss: -0.443,LR: 4.94E-04]Training epoch 7:  85%|████████▍ | 95/112 [00:01<00:00, 53.58it/s, Epoch: 7, Batch: 96,Loss: -0.477,Avg.Loss: -0.444,LR: 4.94E-04]Training epoch 7:  86%|████████▌ | 96/112 [00:01<00:00, 53.58it/s, Epoch: 7, Batch: 97,Loss: -0.414,Avg.Loss: -0.443,LR: 4.94E-04]Training epoch 7:  87%|████████▋ | 97/112 [00:01<00:00, 53.58it/s, Epoch: 7, Batch: 98,Loss: -0.705,Avg.Loss: -0.446,LR: 4.94E-04]Training epoch 7:  88%|████████▊ | 98/112 [00:01<00:00, 53.58it/s, Epoch: 7, Batch: 99,Loss: -0.682,Avg.Loss: -0.448,LR: 4.94E-04]Training epoch 7:  88%|████████▊ | 99/112 [00:01<00:00, 53.63it/s, Epoch: 7, Batch: 99,Loss: -0.682,Avg.Loss: -0.448,LR: 4.94E-04]Training epoch 7:  88%|████████▊ | 99/112 [00:01<00:00, 53.63it/s, Epoch: 7, Batch: 100,Loss: 0.016,Avg.Loss: -0.444,LR: 4.94E-04]Training epoch 7:  89%|████████▉ | 100/112 [00:01<00:00, 53.63it/s, Epoch: 7, Batch: 101,Loss: -0.881,Avg.Loss: -0.448,LR: 4.94E-04]Training epoch 7:  90%|█████████ | 101/112 [00:01<00:00, 53.63it/s, Epoch: 7, Batch: 102,Loss: -0.715,Avg.Loss: -0.451,LR: 4.94E-04]Training epoch 7:  91%|█████████ | 102/112 [00:01<00:00, 53.63it/s, Epoch: 7, Batch: 103,Loss: -0.471,Avg.Loss: -0.451,LR: 4.94E-04]Training epoch 7:  92%|█████████▏| 103/112 [00:01<00:00, 53.63it/s, Epoch: 7, Batch: 104,Loss: -1.047,Avg.Loss: -0.457,LR: 4.94E-04]Training epoch 7:  93%|█████████▎| 104/112 [00:01<00:00, 53.63it/s, Epoch: 7, Batch: 105,Loss: -0.585,Avg.Loss: -0.458,LR: 4.94E-04]Training epoch 7:  94%|█████████▍| 105/112 [00:01<00:00, 53.60it/s, Epoch: 7, Batch: 105,Loss: -0.585,Avg.Loss: -0.458,LR: 4.94E-04]Training epoch 7:  94%|█████████▍| 105/112 [00:01<00:00, 53.60it/s, Epoch: 7, Batch: 106,Loss: -0.140,Avg.Loss: -0.455,LR: 4.94E-04]Training epoch 7:  95%|█████████▍| 106/112 [00:01<00:00, 53.60it/s, Epoch: 7, Batch: 107,Loss: -0.802,Avg.Loss: -0.458,LR: 4.94E-04]Training epoch 7:  96%|█████████▌| 107/112 [00:01<00:00, 53.60it/s, Epoch: 7, Batch: 108,Loss: -0.451,Avg.Loss: -0.458,LR: 4.94E-04]Training epoch 7:  96%|█████████▋| 108/112 [00:02<00:00, 53.60it/s, Epoch: 7, Batch: 109,Loss: -0.015,Avg.Loss: -0.454,LR: 4.94E-04]Training epoch 7:  97%|█████████▋| 109/112 [00:02<00:00, 53.60it/s, Epoch: 7, Batch: 110,Loss: -0.891,Avg.Loss: -0.458,LR: 4.94E-04]Training epoch 7:  98%|█████████▊| 110/112 [00:02<00:00, 53.60it/s, Epoch: 7, Batch: 111,Loss: -0.531,Avg.Loss: -0.459,LR: 4.94E-04]Training epoch 7:  99%|█████████▉| 111/112 [00:02<00:00, 53.45it/s, Epoch: 7, Batch: 111,Loss: -0.531,Avg.Loss: -0.459,LR: 4.94E-04]Training epoch 7:  99%|█████████▉| 111/112 [00:02<00:00, 53.45it/s, Epoch: 7, Batch: 112,Loss: 0.282,Avg.Loss: -0.452,LR: 4.94E-04] Training epoch 7: 100%|██████████| 112/112 [00:02<00:00, 54.07it/s, Epoch: 7, Batch: 112,Loss: 0.282,Avg.Loss: -0.452,LR: 4.94E-04]
Training epoch 8:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 8:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 8, Batch: 1,Loss: -0.933,Avg.Loss: -0.933,LR: 4.94E-04]Training epoch 8:   1%|          | 1/112 [00:00<00:03, 31.89it/s, Epoch: 8, Batch: 2,Loss: -0.475,Avg.Loss: -0.704,LR: 4.94E-04]Training epoch 8:   2%|▏         | 2/112 [00:00<00:02, 43.40it/s, Epoch: 8, Batch: 3,Loss: -0.359,Avg.Loss: -0.589,LR: 4.94E-04]Training epoch 8:   3%|▎         | 3/112 [00:00<00:02, 48.15it/s, Epoch: 8, Batch: 4,Loss: -0.933,Avg.Loss: -0.675,LR: 4.94E-04]Training epoch 8:   4%|▎         | 4/112 [00:00<00:02, 52.81it/s, Epoch: 8, Batch: 5,Loss: -0.442,Avg.Loss: -0.628,LR: 4.94E-04]Training epoch 8:   4%|▍         | 5/112 [00:00<00:01, 54.86it/s, Epoch: 8, Batch: 6,Loss: 0.043,Avg.Loss: -0.516,LR: 4.94E-04] Training epoch 8:   5%|▌         | 6/112 [00:00<00:01, 56.78it/s, Epoch: 8, Batch: 7,Loss: -0.560,Avg.Loss: -0.523,LR: 4.94E-04]Training epoch 8:   6%|▋         | 7/112 [00:00<00:01, 66.14it/s, Epoch: 8, Batch: 7,Loss: -0.560,Avg.Loss: -0.523,LR: 4.94E-04]Training epoch 8:   6%|▋         | 7/112 [00:00<00:01, 66.14it/s, Epoch: 8, Batch: 8,Loss: -0.804,Avg.Loss: -0.558,LR: 4.94E-04]Training epoch 8:   7%|▋         | 8/112 [00:00<00:01, 66.14it/s, Epoch: 8, Batch: 9,Loss: -0.485,Avg.Loss: -0.550,LR: 4.94E-04]Training epoch 8:   8%|▊         | 9/112 [00:00<00:01, 66.14it/s, Epoch: 8, Batch: 10,Loss: -0.664,Avg.Loss: -0.561,LR: 4.94E-04]Training epoch 8:   9%|▉         | 10/112 [00:00<00:01, 66.14it/s, Epoch: 8, Batch: 11,Loss: -0.621,Avg.Loss: -0.567,LR: 4.94E-04]Training epoch 8:  10%|▉         | 11/112 [00:00<00:01, 66.14it/s, Epoch: 8, Batch: 12,Loss: -0.440,Avg.Loss: -0.556,LR: 4.94E-04]Training epoch 8:  11%|█         | 12/112 [00:00<00:01, 66.14it/s, Epoch: 8, Batch: 13,Loss: -0.342,Avg.Loss: -0.540,LR: 4.94E-04]Training epoch 8:  12%|█▏        | 13/112 [00:00<00:01, 66.14it/s, Epoch: 8, Batch: 14,Loss: -0.383,Avg.Loss: -0.528,LR: 4.94E-04]Training epoch 8:  12%|█▎        | 14/112 [00:00<00:01, 64.70it/s, Epoch: 8, Batch: 14,Loss: -0.383,Avg.Loss: -0.528,LR: 4.94E-04]Training epoch 8:  12%|█▎        | 14/112 [00:00<00:01, 64.70it/s, Epoch: 8, Batch: 15,Loss: -0.291,Avg.Loss: -0.513,LR: 4.94E-04]Training epoch 8:  13%|█▎        | 15/112 [00:00<00:01, 64.70it/s, Epoch: 8, Batch: 16,Loss: -0.824,Avg.Loss: -0.532,LR: 4.94E-04]Training epoch 8:  14%|█▍        | 16/112 [00:00<00:01, 64.70it/s, Epoch: 8, Batch: 17,Loss: -0.881,Avg.Loss: -0.553,LR: 4.94E-04]Training epoch 8:  15%|█▌        | 17/112 [00:00<00:01, 64.70it/s, Epoch: 8, Batch: 18,Loss: -0.160,Avg.Loss: -0.531,LR: 4.94E-04]Training epoch 8:  16%|█▌        | 18/112 [00:00<00:01, 64.70it/s, Epoch: 8, Batch: 19,Loss: -0.863,Avg.Loss: -0.548,LR: 4.94E-04]Training epoch 8:  17%|█▋        | 19/112 [00:00<00:01, 64.70it/s, Epoch: 8, Batch: 20,Loss: -0.576,Avg.Loss: -0.550,LR: 4.94E-04]Training epoch 8:  18%|█▊        | 20/112 [00:00<00:01, 64.70it/s, Epoch: 8, Batch: 21,Loss: -0.103,Avg.Loss: -0.528,LR: 4.94E-04]Training epoch 8:  19%|█▉        | 21/112 [00:00<00:01, 58.37it/s, Epoch: 8, Batch: 21,Loss: -0.103,Avg.Loss: -0.528,LR: 4.94E-04]Training epoch 8:  19%|█▉        | 21/112 [00:00<00:01, 58.37it/s, Epoch: 8, Batch: 22,Loss: -0.819,Avg.Loss: -0.542,LR: 4.94E-04]Training epoch 8:  20%|█▉        | 22/112 [00:00<00:01, 58.37it/s, Epoch: 8, Batch: 23,Loss: -0.552,Avg.Loss: -0.542,LR: 4.94E-04]Training epoch 8:  21%|██        | 23/112 [00:00<00:01, 58.37it/s, Epoch: 8, Batch: 24,Loss: -0.797,Avg.Loss: -0.553,LR: 4.94E-04]Training epoch 8:  21%|██▏       | 24/112 [00:00<00:01, 58.37it/s, Epoch: 8, Batch: 25,Loss: -0.654,Avg.Loss: -0.557,LR: 4.94E-04]Training epoch 8:  22%|██▏       | 25/112 [00:00<00:01, 58.37it/s, Epoch: 8, Batch: 26,Loss: -0.587,Avg.Loss: -0.558,LR: 4.94E-04]Training epoch 8:  23%|██▎       | 26/112 [00:00<00:01, 58.37it/s, Epoch: 8, Batch: 27,Loss: 0.093,Avg.Loss: -0.534,LR: 4.94E-04] Training epoch 8:  24%|██▍       | 27/112 [00:00<00:01, 56.29it/s, Epoch: 8, Batch: 27,Loss: 0.093,Avg.Loss: -0.534,LR: 4.94E-04]Training epoch 8:  24%|██▍       | 27/112 [00:00<00:01, 56.29it/s, Epoch: 8, Batch: 28,Loss: -0.789,Avg.Loss: -0.543,LR: 4.94E-04]Training epoch 8:  25%|██▌       | 28/112 [00:00<00:01, 56.29it/s, Epoch: 8, Batch: 29,Loss: -0.727,Avg.Loss: -0.549,LR: 4.94E-04]Training epoch 8:  26%|██▌       | 29/112 [00:00<00:01, 56.29it/s, Epoch: 8, Batch: 30,Loss: -0.421,Avg.Loss: -0.545,LR: 4.94E-04]Training epoch 8:  27%|██▋       | 30/112 [00:00<00:01, 56.29it/s, Epoch: 8, Batch: 31,Loss: -1.039,Avg.Loss: -0.561,LR: 4.93E-04]Training epoch 8:  28%|██▊       | 31/112 [00:00<00:01, 56.29it/s, Epoch: 8, Batch: 32,Loss: -0.668,Avg.Loss: -0.564,LR: 4.93E-04]Training epoch 8:  29%|██▊       | 32/112 [00:00<00:01, 56.29it/s, Epoch: 8, Batch: 33,Loss: -0.691,Avg.Loss: -0.568,LR: 4.93E-04]Training epoch 8:  29%|██▉       | 33/112 [00:00<00:01, 55.18it/s, Epoch: 8, Batch: 33,Loss: -0.691,Avg.Loss: -0.568,LR: 4.93E-04]Training epoch 8:  29%|██▉       | 33/112 [00:00<00:01, 55.18it/s, Epoch: 8, Batch: 34,Loss: -0.744,Avg.Loss: -0.573,LR: 4.93E-04]Training epoch 8:  30%|███       | 34/112 [00:00<00:01, 55.18it/s, Epoch: 8, Batch: 35,Loss: -0.680,Avg.Loss: -0.576,LR: 4.93E-04]Training epoch 8:  31%|███▏      | 35/112 [00:00<00:01, 55.18it/s, Epoch: 8, Batch: 36,Loss: -0.617,Avg.Loss: -0.577,LR: 4.93E-04]Training epoch 8:  32%|███▏      | 36/112 [00:00<00:01, 55.18it/s, Epoch: 8, Batch: 37,Loss: -0.938,Avg.Loss: -0.587,LR: 4.93E-04]Training epoch 8:  33%|███▎      | 37/112 [00:00<00:01, 55.18it/s, Epoch: 8, Batch: 38,Loss: -0.896,Avg.Loss: -0.595,LR: 4.93E-04]Training epoch 8:  34%|███▍      | 38/112 [00:00<00:01, 55.18it/s, Epoch: 8, Batch: 39,Loss: -0.018,Avg.Loss: -0.581,LR: 4.93E-04]Training epoch 8:  35%|███▍      | 39/112 [00:00<00:01, 54.45it/s, Epoch: 8, Batch: 39,Loss: -0.018,Avg.Loss: -0.581,LR: 4.93E-04]Training epoch 8:  35%|███▍      | 39/112 [00:00<00:01, 54.45it/s, Epoch: 8, Batch: 40,Loss: -0.079,Avg.Loss: -0.568,LR: 4.93E-04]Training epoch 8:  36%|███▌      | 40/112 [00:00<00:01, 54.45it/s, Epoch: 8, Batch: 41,Loss: -0.798,Avg.Loss: -0.574,LR: 4.93E-04]Training epoch 8:  37%|███▋      | 41/112 [00:00<00:01, 54.45it/s, Epoch: 8, Batch: 42,Loss: -0.701,Avg.Loss: -0.577,LR: 4.93E-04]Training epoch 8:  38%|███▊      | 42/112 [00:00<00:01, 54.45it/s, Epoch: 8, Batch: 43,Loss: -1.135,Avg.Loss: -0.590,LR: 4.93E-04]Training epoch 8:  38%|███▊      | 43/112 [00:00<00:01, 54.45it/s, Epoch: 8, Batch: 44,Loss: -0.674,Avg.Loss: -0.592,LR: 4.93E-04]Training epoch 8:  39%|███▉      | 44/112 [00:00<00:01, 54.45it/s, Epoch: 8, Batch: 45,Loss: -0.433,Avg.Loss: -0.588,LR: 4.93E-04]Training epoch 8:  40%|████      | 45/112 [00:00<00:01, 53.97it/s, Epoch: 8, Batch: 45,Loss: -0.433,Avg.Loss: -0.588,LR: 4.93E-04]Training epoch 8:  40%|████      | 45/112 [00:00<00:01, 53.97it/s, Epoch: 8, Batch: 46,Loss: -1.051,Avg.Loss: -0.598,LR: 4.93E-04]Training epoch 8:  41%|████      | 46/112 [00:00<00:01, 53.97it/s, Epoch: 8, Batch: 47,Loss: -0.840,Avg.Loss: -0.603,LR: 4.93E-04]Training epoch 8:  42%|████▏     | 47/112 [00:00<00:01, 53.97it/s, Epoch: 8, Batch: 48,Loss: -0.252,Avg.Loss: -0.596,LR: 4.93E-04]Training epoch 8:  43%|████▎     | 48/112 [00:00<00:01, 53.97it/s, Epoch: 8, Batch: 49,Loss: -0.954,Avg.Loss: -0.603,LR: 4.93E-04]Training epoch 8:  44%|████▍     | 49/112 [00:00<00:01, 53.97it/s, Epoch: 8, Batch: 50,Loss: -0.697,Avg.Loss: -0.605,LR: 4.93E-04]Training epoch 8:  45%|████▍     | 50/112 [00:00<00:01, 53.97it/s, Epoch: 8, Batch: 51,Loss: -0.475,Avg.Loss: -0.603,LR: 4.93E-04]Training epoch 8:  46%|████▌     | 51/112 [00:00<00:01, 53.67it/s, Epoch: 8, Batch: 51,Loss: -0.475,Avg.Loss: -0.603,LR: 4.93E-04]Training epoch 8:  46%|████▌     | 51/112 [00:00<00:01, 53.67it/s, Epoch: 8, Batch: 52,Loss: -0.769,Avg.Loss: -0.606,LR: 4.93E-04]Training epoch 8:  46%|████▋     | 52/112 [00:00<00:01, 53.67it/s, Epoch: 8, Batch: 53,Loss: -0.379,Avg.Loss: -0.601,LR: 4.93E-04]Training epoch 8:  47%|████▋     | 53/112 [00:00<00:01, 53.67it/s, Epoch: 8, Batch: 54,Loss: -0.475,Avg.Loss: -0.599,LR: 4.93E-04]Training epoch 8:  48%|████▊     | 54/112 [00:00<00:01, 53.67it/s, Epoch: 8, Batch: 55,Loss: -0.667,Avg.Loss: -0.600,LR: 4.93E-04]Training epoch 8:  49%|████▉     | 55/112 [00:01<00:01, 53.67it/s, Epoch: 8, Batch: 56,Loss: -0.543,Avg.Loss: -0.599,LR: 4.93E-04]Training epoch 8:  50%|█████     | 56/112 [00:01<00:01, 53.67it/s, Epoch: 8, Batch: 57,Loss: -0.148,Avg.Loss: -0.591,LR: 4.93E-04]Training epoch 8:  51%|█████     | 57/112 [00:01<00:01, 53.70it/s, Epoch: 8, Batch: 57,Loss: -0.148,Avg.Loss: -0.591,LR: 4.93E-04]Training epoch 8:  51%|█████     | 57/112 [00:01<00:01, 53.70it/s, Epoch: 8, Batch: 58,Loss: -0.799,Avg.Loss: -0.595,LR: 4.93E-04]Training epoch 8:  52%|█████▏    | 58/112 [00:01<00:01, 53.70it/s, Epoch: 8, Batch: 59,Loss: -0.582,Avg.Loss: -0.595,LR: 4.93E-04]Training epoch 8:  53%|█████▎    | 59/112 [00:01<00:00, 53.70it/s, Epoch: 8, Batch: 60,Loss: 0.326,Avg.Loss: -0.579,LR: 4.93E-04] Training epoch 8:  54%|█████▎    | 60/112 [00:01<00:00, 53.70it/s, Epoch: 8, Batch: 61,Loss: -0.282,Avg.Loss: -0.575,LR: 4.93E-04]Training epoch 8:  54%|█████▍    | 61/112 [00:01<00:00, 53.70it/s, Epoch: 8, Batch: 62,Loss: -0.553,Avg.Loss: -0.574,LR: 4.93E-04]Training epoch 8:  55%|█████▌    | 62/112 [00:01<00:00, 53.70it/s, Epoch: 8, Batch: 63,Loss: -0.386,Avg.Loss: -0.571,LR: 4.93E-04]Training epoch 8:  56%|█████▋    | 63/112 [00:01<00:00, 53.55it/s, Epoch: 8, Batch: 63,Loss: -0.386,Avg.Loss: -0.571,LR: 4.93E-04]Training epoch 8:  56%|█████▋    | 63/112 [00:01<00:00, 53.55it/s, Epoch: 8, Batch: 64,Loss: -1.112,Avg.Loss: -0.580,LR: 4.93E-04]Training epoch 8:  57%|█████▋    | 64/112 [00:01<00:00, 53.55it/s, Epoch: 8, Batch: 65,Loss: -0.377,Avg.Loss: -0.577,LR: 4.93E-04]Training epoch 8:  58%|█████▊    | 65/112 [00:01<00:00, 53.55it/s, Epoch: 8, Batch: 66,Loss: -0.443,Avg.Loss: -0.575,LR: 4.93E-04]Training epoch 8:  59%|█████▉    | 66/112 [00:01<00:00, 53.55it/s, Epoch: 8, Batch: 67,Loss: -0.869,Avg.Loss: -0.579,LR: 4.93E-04]Training epoch 8:  60%|█████▉    | 67/112 [00:01<00:00, 53.55it/s, Epoch: 8, Batch: 68,Loss: 0.170,Avg.Loss: -0.568,LR: 4.93E-04] Training epoch 8:  61%|██████    | 68/112 [00:01<00:00, 53.55it/s, Epoch: 8, Batch: 69,Loss: 0.153,Avg.Loss: -0.557,LR: 4.93E-04]Training epoch 8:  62%|██████▏   | 69/112 [00:01<00:00, 53.38it/s, Epoch: 8, Batch: 69,Loss: 0.153,Avg.Loss: -0.557,LR: 4.93E-04]Training epoch 8:  62%|██████▏   | 69/112 [00:01<00:00, 53.38it/s, Epoch: 8, Batch: 70,Loss: -0.402,Avg.Loss: -0.555,LR: 4.93E-04]Training epoch 8:  62%|██████▎   | 70/112 [00:01<00:00, 53.38it/s, Epoch: 8, Batch: 71,Loss: -0.909,Avg.Loss: -0.560,LR: 4.93E-04]Training epoch 8:  63%|██████▎   | 71/112 [00:01<00:00, 53.38it/s, Epoch: 8, Batch: 72,Loss: -0.598,Avg.Loss: -0.561,LR: 4.93E-04]Training epoch 8:  64%|██████▍   | 72/112 [00:01<00:00, 53.38it/s, Epoch: 8, Batch: 73,Loss: -0.996,Avg.Loss: -0.567,LR: 4.93E-04]Training epoch 8:  65%|██████▌   | 73/112 [00:01<00:00, 53.38it/s, Epoch: 8, Batch: 74,Loss: -0.332,Avg.Loss: -0.564,LR: 4.93E-04]Training epoch 8:  66%|██████▌   | 74/112 [00:01<00:00, 53.38it/s, Epoch: 8, Batch: 75,Loss: -0.167,Avg.Loss: -0.558,LR: 4.93E-04]Training epoch 8:  67%|██████▋   | 75/112 [00:01<00:00, 53.33it/s, Epoch: 8, Batch: 75,Loss: -0.167,Avg.Loss: -0.558,LR: 4.93E-04]Training epoch 8:  67%|██████▋   | 75/112 [00:01<00:00, 53.33it/s, Epoch: 8, Batch: 76,Loss: -0.878,Avg.Loss: -0.562,LR: 4.93E-04]Training epoch 8:  68%|██████▊   | 76/112 [00:01<00:00, 53.33it/s, Epoch: 8, Batch: 77,Loss: -0.519,Avg.Loss: -0.562,LR: 4.93E-04]Training epoch 8:  69%|██████▉   | 77/112 [00:01<00:00, 53.33it/s, Epoch: 8, Batch: 78,Loss: -0.479,Avg.Loss: -0.561,LR: 4.93E-04]Training epoch 8:  70%|██████▉   | 78/112 [00:01<00:00, 53.33it/s, Epoch: 8, Batch: 79,Loss: -0.974,Avg.Loss: -0.566,LR: 4.93E-04]Training epoch 8:  71%|███████   | 79/112 [00:01<00:00, 53.33it/s, Epoch: 8, Batch: 80,Loss: -0.726,Avg.Loss: -0.568,LR: 4.93E-04]Training epoch 8:  71%|███████▏  | 80/112 [00:01<00:00, 53.33it/s, Epoch: 8, Batch: 81,Loss: -0.499,Avg.Loss: -0.567,LR: 4.93E-04]Training epoch 8:  72%|███████▏  | 81/112 [00:01<00:00, 53.23it/s, Epoch: 8, Batch: 81,Loss: -0.499,Avg.Loss: -0.567,LR: 4.93E-04]Training epoch 8:  72%|███████▏  | 81/112 [00:01<00:00, 53.23it/s, Epoch: 8, Batch: 82,Loss: -0.590,Avg.Loss: -0.568,LR: 4.93E-04]Training epoch 8:  73%|███████▎  | 82/112 [00:01<00:00, 53.23it/s, Epoch: 8, Batch: 83,Loss: -1.228,Avg.Loss: -0.575,LR: 4.93E-04]Training epoch 8:  74%|███████▍  | 83/112 [00:01<00:00, 53.23it/s, Epoch: 8, Batch: 84,Loss: -0.515,Avg.Loss: -0.575,LR: 4.93E-04]Training epoch 8:  75%|███████▌  | 84/112 [00:01<00:00, 53.23it/s, Epoch: 8, Batch: 85,Loss: -1.034,Avg.Loss: -0.580,LR: 4.93E-04]Training epoch 8:  76%|███████▌  | 85/112 [00:01<00:00, 53.23it/s, Epoch: 8, Batch: 86,Loss: -0.550,Avg.Loss: -0.580,LR: 4.93E-04]Training epoch 8:  77%|███████▋  | 86/112 [00:01<00:00, 53.23it/s, Epoch: 8, Batch: 87,Loss: -0.500,Avg.Loss: -0.579,LR: 4.93E-04]Training epoch 8:  78%|███████▊  | 87/112 [00:01<00:00, 53.20it/s, Epoch: 8, Batch: 87,Loss: -0.500,Avg.Loss: -0.579,LR: 4.93E-04]Training epoch 8:  78%|███████▊  | 87/112 [00:01<00:00, 53.20it/s, Epoch: 8, Batch: 88,Loss: -0.573,Avg.Loss: -0.579,LR: 4.93E-04]Training epoch 8:  79%|███████▊  | 88/112 [00:01<00:00, 53.20it/s, Epoch: 8, Batch: 89,Loss: -0.784,Avg.Loss: -0.581,LR: 4.93E-04]Training epoch 8:  79%|███████▉  | 89/112 [00:01<00:00, 53.20it/s, Epoch: 8, Batch: 90,Loss: -0.343,Avg.Loss: -0.578,LR: 4.93E-04]Training epoch 8:  80%|████████  | 90/112 [00:01<00:00, 53.20it/s, Epoch: 8, Batch: 91,Loss: -0.855,Avg.Loss: -0.582,LR: 4.93E-04]Training epoch 8:  81%|████████▏ | 91/112 [00:01<00:00, 53.20it/s, Epoch: 8, Batch: 92,Loss: -0.831,Avg.Loss: -0.584,LR: 4.92E-04]Training epoch 8:  82%|████████▏ | 92/112 [00:01<00:00, 53.20it/s, Epoch: 8, Batch: 93,Loss: -0.643,Avg.Loss: -0.585,LR: 4.92E-04]Training epoch 8:  83%|████████▎ | 93/112 [00:01<00:00, 53.25it/s, Epoch: 8, Batch: 93,Loss: -0.643,Avg.Loss: -0.585,LR: 4.92E-04]Training epoch 8:  83%|████████▎ | 93/112 [00:01<00:00, 53.25it/s, Epoch: 8, Batch: 94,Loss: -0.571,Avg.Loss: -0.585,LR: 4.92E-04]Training epoch 8:  84%|████████▍ | 94/112 [00:01<00:00, 53.25it/s, Epoch: 8, Batch: 95,Loss: -0.773,Avg.Loss: -0.587,LR: 4.92E-04]Training epoch 8:  85%|████████▍ | 95/112 [00:01<00:00, 53.25it/s, Epoch: 8, Batch: 96,Loss: -0.619,Avg.Loss: -0.587,LR: 4.92E-04]Training epoch 8:  86%|████████▌ | 96/112 [00:01<00:00, 53.25it/s, Epoch: 8, Batch: 97,Loss: -1.323,Avg.Loss: -0.595,LR: 4.92E-04]Training epoch 8:  87%|████████▋ | 97/112 [00:01<00:00, 53.25it/s, Epoch: 8, Batch: 98,Loss: -0.362,Avg.Loss: -0.592,LR: 4.92E-04]Training epoch 8:  88%|████████▊ | 98/112 [00:01<00:00, 53.25it/s, Epoch: 8, Batch: 99,Loss: -0.225,Avg.Loss: -0.589,LR: 4.92E-04]Training epoch 8:  88%|████████▊ | 99/112 [00:01<00:00, 53.18it/s, Epoch: 8, Batch: 99,Loss: -0.225,Avg.Loss: -0.589,LR: 4.92E-04]Training epoch 8:  88%|████████▊ | 99/112 [00:01<00:00, 53.18it/s, Epoch: 8, Batch: 100,Loss: -0.658,Avg.Loss: -0.589,LR: 4.92E-04]Training epoch 8:  89%|████████▉ | 100/112 [00:01<00:00, 53.18it/s, Epoch: 8, Batch: 101,Loss: -0.754,Avg.Loss: -0.591,LR: 4.92E-04]Training epoch 8:  90%|█████████ | 101/112 [00:01<00:00, 53.18it/s, Epoch: 8, Batch: 102,Loss: -0.187,Avg.Loss: -0.587,LR: 4.92E-04]Training epoch 8:  91%|█████████ | 102/112 [00:01<00:00, 53.18it/s, Epoch: 8, Batch: 103,Loss: -0.499,Avg.Loss: -0.586,LR: 4.92E-04]Training epoch 8:  92%|█████████▏| 103/112 [00:01<00:00, 53.18it/s, Epoch: 8, Batch: 104,Loss: -0.558,Avg.Loss: -0.586,LR: 4.92E-04]Training epoch 8:  93%|█████████▎| 104/112 [00:01<00:00, 53.18it/s, Epoch: 8, Batch: 105,Loss: -0.419,Avg.Loss: -0.584,LR: 4.92E-04]Training epoch 8:  94%|█████████▍| 105/112 [00:01<00:00, 53.22it/s, Epoch: 8, Batch: 105,Loss: -0.419,Avg.Loss: -0.584,LR: 4.92E-04]Training epoch 8:  94%|█████████▍| 105/112 [00:01<00:00, 53.22it/s, Epoch: 8, Batch: 106,Loss: -0.782,Avg.Loss: -0.586,LR: 4.92E-04]Training epoch 8:  95%|█████████▍| 106/112 [00:01<00:00, 53.22it/s, Epoch: 8, Batch: 107,Loss: -1.123,Avg.Loss: -0.591,LR: 4.92E-04]Training epoch 8:  96%|█████████▌| 107/112 [00:01<00:00, 53.22it/s, Epoch: 8, Batch: 108,Loss: -0.708,Avg.Loss: -0.592,LR: 4.92E-04]Training epoch 8:  96%|█████████▋| 108/112 [00:02<00:00, 53.22it/s, Epoch: 8, Batch: 109,Loss: -0.895,Avg.Loss: -0.595,LR: 4.92E-04]Training epoch 8:  97%|█████████▋| 109/112 [00:02<00:00, 53.22it/s, Epoch: 8, Batch: 110,Loss: -0.634,Avg.Loss: -0.595,LR: 4.92E-04]Training epoch 8:  98%|█████████▊| 110/112 [00:02<00:00, 53.22it/s, Epoch: 8, Batch: 111,Loss: 0.233,Avg.Loss: -0.588,LR: 4.92E-04] Training epoch 8:  99%|█████████▉| 111/112 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 111,Loss: 0.233,Avg.Loss: -0.588,LR: 4.92E-04]Training epoch 8:  99%|█████████▉| 111/112 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 112,Loss: 0.938,Avg.Loss: -0.574,LR: 4.92E-04]Training epoch 8: 100%|██████████| 112/112 [00:02<00:00, 54.23it/s, Epoch: 8, Batch: 112,Loss: 0.938,Avg.Loss: -0.574,LR: 4.92E-04]
Training epoch 9:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 9:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 9, Batch: 1,Loss: -0.565,Avg.Loss: -0.565,LR: 4.92E-04]Training epoch 9:   1%|          | 1/112 [00:00<00:03, 30.42it/s, Epoch: 9, Batch: 2,Loss: -0.421,Avg.Loss: -0.493,LR: 4.92E-04]Training epoch 9:   2%|▏         | 2/112 [00:00<00:02, 41.96it/s, Epoch: 9, Batch: 3,Loss: -1.048,Avg.Loss: -0.678,LR: 4.92E-04]Training epoch 9:   3%|▎         | 3/112 [00:00<00:02, 44.62it/s, Epoch: 9, Batch: 4,Loss: -0.883,Avg.Loss: -0.729,LR: 4.92E-04]Training epoch 9:   4%|▎         | 4/112 [00:00<00:02, 47.36it/s, Epoch: 9, Batch: 5,Loss: 0.003,Avg.Loss: -0.583,LR: 4.92E-04] Training epoch 9:   4%|▍         | 5/112 [00:00<00:02, 49.49it/s, Epoch: 9, Batch: 6,Loss: -0.978,Avg.Loss: -0.649,LR: 4.92E-04]Training epoch 9:   5%|▌         | 6/112 [00:00<00:01, 59.29it/s, Epoch: 9, Batch: 6,Loss: -0.978,Avg.Loss: -0.649,LR: 4.92E-04]Training epoch 9:   5%|▌         | 6/112 [00:00<00:01, 59.29it/s, Epoch: 9, Batch: 7,Loss: -0.677,Avg.Loss: -0.653,LR: 4.92E-04]Training epoch 9:   6%|▋         | 7/112 [00:00<00:01, 59.29it/s, Epoch: 9, Batch: 8,Loss: 0.091,Avg.Loss: -0.560,LR: 4.92E-04] Training epoch 9:   7%|▋         | 8/112 [00:00<00:01, 59.29it/s, Epoch: 9, Batch: 9,Loss: -0.763,Avg.Loss: -0.582,LR: 4.92E-04]Training epoch 9:   8%|▊         | 9/112 [00:00<00:01, 59.29it/s, Epoch: 9, Batch: 10,Loss: -0.830,Avg.Loss: -0.607,LR: 4.92E-04]Training epoch 9:   9%|▉         | 10/112 [00:00<00:01, 59.29it/s, Epoch: 9, Batch: 11,Loss: -0.475,Avg.Loss: -0.595,LR: 4.92E-04]Training epoch 9:  10%|▉         | 11/112 [00:00<00:01, 59.29it/s, Epoch: 9, Batch: 12,Loss: -1.129,Avg.Loss: -0.640,LR: 4.92E-04]Training epoch 9:  11%|█         | 12/112 [00:00<00:01, 59.29it/s, Epoch: 9, Batch: 13,Loss: -0.759,Avg.Loss: -0.649,LR: 4.92E-04]Training epoch 9:  12%|█▏        | 13/112 [00:00<00:01, 61.64it/s, Epoch: 9, Batch: 13,Loss: -0.759,Avg.Loss: -0.649,LR: 4.92E-04]Training epoch 9:  12%|█▏        | 13/112 [00:00<00:01, 61.64it/s, Epoch: 9, Batch: 14,Loss: -0.796,Avg.Loss: -0.659,LR: 4.92E-04]Training epoch 9:  12%|█▎        | 14/112 [00:00<00:01, 61.64it/s, Epoch: 9, Batch: 15,Loss: -1.032,Avg.Loss: -0.684,LR: 4.92E-04]Training epoch 9:  13%|█▎        | 15/112 [00:00<00:01, 61.64it/s, Epoch: 9, Batch: 16,Loss: -0.530,Avg.Loss: -0.675,LR: 4.92E-04]Training epoch 9:  14%|█▍        | 16/112 [00:00<00:01, 61.64it/s, Epoch: 9, Batch: 17,Loss: -0.081,Avg.Loss: -0.640,LR: 4.92E-04]Training epoch 9:  15%|█▌        | 17/112 [00:00<00:01, 61.64it/s, Epoch: 9, Batch: 18,Loss: -0.955,Avg.Loss: -0.657,LR: 4.92E-04]Training epoch 9:  16%|█▌        | 18/112 [00:00<00:01, 61.64it/s, Epoch: 9, Batch: 19,Loss: -0.606,Avg.Loss: -0.655,LR: 4.92E-04]Training epoch 9:  17%|█▋        | 19/112 [00:00<00:01, 61.64it/s, Epoch: 9, Batch: 20,Loss: -0.093,Avg.Loss: -0.626,LR: 4.92E-04]Training epoch 9:  18%|█▊        | 20/112 [00:00<00:01, 58.39it/s, Epoch: 9, Batch: 20,Loss: -0.093,Avg.Loss: -0.626,LR: 4.92E-04]Training epoch 9:  18%|█▊        | 20/112 [00:00<00:01, 58.39it/s, Epoch: 9, Batch: 21,Loss: -0.916,Avg.Loss: -0.640,LR: 4.92E-04]Training epoch 9:  19%|█▉        | 21/112 [00:00<00:01, 58.39it/s, Epoch: 9, Batch: 22,Loss: -0.725,Avg.Loss: -0.644,LR: 4.92E-04]Training epoch 9:  20%|█▉        | 22/112 [00:00<00:01, 58.39it/s, Epoch: 9, Batch: 23,Loss: -0.497,Avg.Loss: -0.638,LR: 4.92E-04]Training epoch 9:  21%|██        | 23/112 [00:00<00:01, 58.39it/s, Epoch: 9, Batch: 24,Loss: -1.029,Avg.Loss: -0.654,LR: 4.92E-04]Training epoch 9:  21%|██▏       | 24/112 [00:00<00:01, 58.39it/s, Epoch: 9, Batch: 25,Loss: -0.815,Avg.Loss: -0.660,LR: 4.92E-04]Training epoch 9:  22%|██▏       | 25/112 [00:00<00:01, 58.39it/s, Epoch: 9, Batch: 26,Loss: -0.328,Avg.Loss: -0.648,LR: 4.92E-04]Training epoch 9:  23%|██▎       | 26/112 [00:00<00:01, 55.83it/s, Epoch: 9, Batch: 26,Loss: -0.328,Avg.Loss: -0.648,LR: 4.92E-04]Training epoch 9:  23%|██▎       | 26/112 [00:00<00:01, 55.83it/s, Epoch: 9, Batch: 27,Loss: -0.726,Avg.Loss: -0.651,LR: 4.92E-04]Training epoch 9:  24%|██▍       | 27/112 [00:00<00:01, 55.83it/s, Epoch: 9, Batch: 28,Loss: -0.802,Avg.Loss: -0.656,LR: 4.92E-04]Training epoch 9:  25%|██▌       | 28/112 [00:00<00:01, 55.83it/s, Epoch: 9, Batch: 29,Loss: -0.494,Avg.Loss: -0.650,LR: 4.92E-04]Training epoch 9:  26%|██▌       | 29/112 [00:00<00:01, 55.83it/s, Epoch: 9, Batch: 30,Loss: -0.984,Avg.Loss: -0.661,LR: 4.92E-04]Training epoch 9:  27%|██▋       | 30/112 [00:00<00:01, 55.83it/s, Epoch: 9, Batch: 31,Loss: -0.769,Avg.Loss: -0.665,LR: 4.92E-04]Training epoch 9:  28%|██▊       | 31/112 [00:00<00:01, 55.83it/s, Epoch: 9, Batch: 32,Loss: 0.267,Avg.Loss: -0.636,LR: 4.92E-04] Training epoch 9:  29%|██▊       | 32/112 [00:00<00:01, 55.18it/s, Epoch: 9, Batch: 32,Loss: 0.267,Avg.Loss: -0.636,LR: 4.92E-04]Training epoch 9:  29%|██▊       | 32/112 [00:00<00:01, 55.18it/s, Epoch: 9, Batch: 33,Loss: -1.130,Avg.Loss: -0.651,LR: 4.92E-04]Training epoch 9:  29%|██▉       | 33/112 [00:00<00:01, 55.18it/s, Epoch: 9, Batch: 34,Loss: -0.557,Avg.Loss: -0.648,LR: 4.92E-04]Training epoch 9:  30%|███       | 34/112 [00:00<00:01, 55.18it/s, Epoch: 9, Batch: 35,Loss: -0.837,Avg.Loss: -0.653,LR: 4.92E-04]Training epoch 9:  31%|███▏      | 35/112 [00:00<00:01, 55.18it/s, Epoch: 9, Batch: 36,Loss: -1.020,Avg.Loss: -0.664,LR: 4.92E-04]Training epoch 9:  32%|███▏      | 36/112 [00:00<00:01, 55.18it/s, Epoch: 9, Batch: 37,Loss: -0.915,Avg.Loss: -0.670,LR: 4.91E-04]Training epoch 9:  33%|███▎      | 37/112 [00:00<00:01, 55.18it/s, Epoch: 9, Batch: 38,Loss: -0.139,Avg.Loss: -0.656,LR: 4.91E-04]Training epoch 9:  34%|███▍      | 38/112 [00:00<00:01, 54.93it/s, Epoch: 9, Batch: 38,Loss: -0.139,Avg.Loss: -0.656,LR: 4.91E-04]Training epoch 9:  34%|███▍      | 38/112 [00:00<00:01, 54.93it/s, Epoch: 9, Batch: 39,Loss: -0.846,Avg.Loss: -0.661,LR: 4.91E-04]Training epoch 9:  35%|███▍      | 39/112 [00:00<00:01, 54.93it/s, Epoch: 9, Batch: 40,Loss: -0.923,Avg.Loss: -0.668,LR: 4.91E-04]Training epoch 9:  36%|███▌      | 40/112 [00:00<00:01, 54.93it/s, Epoch: 9, Batch: 41,Loss: -0.666,Avg.Loss: -0.668,LR: 4.91E-04]Training epoch 9:  37%|███▋      | 41/112 [00:00<00:01, 54.93it/s, Epoch: 9, Batch: 42,Loss: -0.440,Avg.Loss: -0.662,LR: 4.91E-04]Training epoch 9:  38%|███▊      | 42/112 [00:00<00:01, 54.93it/s, Epoch: 9, Batch: 43,Loss: -0.718,Avg.Loss: -0.664,LR: 4.91E-04]Training epoch 9:  38%|███▊      | 43/112 [00:00<00:01, 54.93it/s, Epoch: 9, Batch: 44,Loss: -0.481,Avg.Loss: -0.659,LR: 4.91E-04]Training epoch 9:  39%|███▉      | 44/112 [00:00<00:01, 54.41it/s, Epoch: 9, Batch: 44,Loss: -0.481,Avg.Loss: -0.659,LR: 4.91E-04]Training epoch 9:  39%|███▉      | 44/112 [00:00<00:01, 54.41it/s, Epoch: 9, Batch: 45,Loss: -0.801,Avg.Loss: -0.663,LR: 4.91E-04]Training epoch 9:  40%|████      | 45/112 [00:00<00:01, 54.41it/s, Epoch: 9, Batch: 46,Loss: -0.734,Avg.Loss: -0.664,LR: 4.91E-04]Training epoch 9:  41%|████      | 46/112 [00:00<00:01, 54.41it/s, Epoch: 9, Batch: 47,Loss: -0.285,Avg.Loss: -0.656,LR: 4.91E-04]Training epoch 9:  42%|████▏     | 47/112 [00:00<00:01, 54.41it/s, Epoch: 9, Batch: 48,Loss: -1.082,Avg.Loss: -0.665,LR: 4.91E-04]Training epoch 9:  43%|████▎     | 48/112 [00:00<00:01, 54.41it/s, Epoch: 9, Batch: 49,Loss: -0.702,Avg.Loss: -0.666,LR: 4.91E-04]Training epoch 9:  44%|████▍     | 49/112 [00:00<00:01, 54.41it/s, Epoch: 9, Batch: 50,Loss: -0.171,Avg.Loss: -0.656,LR: 4.91E-04]Training epoch 9:  45%|████▍     | 50/112 [00:00<00:01, 54.23it/s, Epoch: 9, Batch: 50,Loss: -0.171,Avg.Loss: -0.656,LR: 4.91E-04]Training epoch 9:  45%|████▍     | 50/112 [00:00<00:01, 54.23it/s, Epoch: 9, Batch: 51,Loss: -0.698,Avg.Loss: -0.657,LR: 4.91E-04]Training epoch 9:  46%|████▌     | 51/112 [00:00<00:01, 54.23it/s, Epoch: 9, Batch: 52,Loss: -0.601,Avg.Loss: -0.656,LR: 4.91E-04]Training epoch 9:  46%|████▋     | 52/112 [00:00<00:01, 54.23it/s, Epoch: 9, Batch: 53,Loss: -0.633,Avg.Loss: -0.655,LR: 4.91E-04]Training epoch 9:  47%|████▋     | 53/112 [00:00<00:01, 54.23it/s, Epoch: 9, Batch: 54,Loss: -0.820,Avg.Loss: -0.658,LR: 4.91E-04]Training epoch 9:  48%|████▊     | 54/112 [00:00<00:01, 54.23it/s, Epoch: 9, Batch: 55,Loss: -0.048,Avg.Loss: -0.647,LR: 4.91E-04]Training epoch 9:  49%|████▉     | 55/112 [00:01<00:01, 54.23it/s, Epoch: 9, Batch: 56,Loss: 0.210,Avg.Loss: -0.632,LR: 4.91E-04] Training epoch 9:  50%|█████     | 56/112 [00:01<00:01, 54.01it/s, Epoch: 9, Batch: 56,Loss: 0.210,Avg.Loss: -0.632,LR: 4.91E-04]Training epoch 9:  50%|█████     | 56/112 [00:01<00:01, 54.01it/s, Epoch: 9, Batch: 57,Loss: -0.610,Avg.Loss: -0.631,LR: 4.91E-04]Training epoch 9:  51%|█████     | 57/112 [00:01<00:01, 54.01it/s, Epoch: 9, Batch: 58,Loss: -1.036,Avg.Loss: -0.638,LR: 4.91E-04]Training epoch 9:  52%|█████▏    | 58/112 [00:01<00:00, 54.01it/s, Epoch: 9, Batch: 59,Loss: -0.594,Avg.Loss: -0.638,LR: 4.91E-04]Training epoch 9:  53%|█████▎    | 59/112 [00:01<00:00, 54.01it/s, Epoch: 9, Batch: 60,Loss: -1.155,Avg.Loss: -0.646,LR: 4.91E-04]Training epoch 9:  54%|█████▎    | 60/112 [00:01<00:00, 54.01it/s, Epoch: 9, Batch: 61,Loss: -0.378,Avg.Loss: -0.642,LR: 4.91E-04]Training epoch 9:  54%|█████▍    | 61/112 [00:01<00:00, 54.01it/s, Epoch: 9, Batch: 62,Loss: -0.298,Avg.Loss: -0.636,LR: 4.91E-04]Training epoch 9:  55%|█████▌    | 62/112 [00:01<00:00, 53.82it/s, Epoch: 9, Batch: 62,Loss: -0.298,Avg.Loss: -0.636,LR: 4.91E-04]Training epoch 9:  55%|█████▌    | 62/112 [00:01<00:00, 53.82it/s, Epoch: 9, Batch: 63,Loss: -0.630,Avg.Loss: -0.636,LR: 4.91E-04]Training epoch 9:  56%|█████▋    | 63/112 [00:01<00:00, 53.82it/s, Epoch: 9, Batch: 64,Loss: -0.907,Avg.Loss: -0.640,LR: 4.91E-04]Training epoch 9:  57%|█████▋    | 64/112 [00:01<00:00, 53.82it/s, Epoch: 9, Batch: 65,Loss: -0.874,Avg.Loss: -0.644,LR: 4.91E-04]Training epoch 9:  58%|█████▊    | 65/112 [00:01<00:00, 53.82it/s, Epoch: 9, Batch: 66,Loss: -0.665,Avg.Loss: -0.644,LR: 4.91E-04]Training epoch 9:  59%|█████▉    | 66/112 [00:01<00:00, 53.82it/s, Epoch: 9, Batch: 67,Loss: -0.555,Avg.Loss: -0.643,LR: 4.91E-04]Training epoch 9:  60%|█████▉    | 67/112 [00:01<00:00, 53.82it/s, Epoch: 9, Batch: 68,Loss: -0.259,Avg.Loss: -0.637,LR: 4.91E-04]Training epoch 9:  61%|██████    | 68/112 [00:01<00:00, 53.80it/s, Epoch: 9, Batch: 68,Loss: -0.259,Avg.Loss: -0.637,LR: 4.91E-04]Training epoch 9:  61%|██████    | 68/112 [00:01<00:00, 53.80it/s, Epoch: 9, Batch: 69,Loss: -0.590,Avg.Loss: -0.637,LR: 4.91E-04]Training epoch 9:  62%|██████▏   | 69/112 [00:01<00:00, 53.80it/s, Epoch: 9, Batch: 70,Loss: -0.784,Avg.Loss: -0.639,LR: 4.91E-04]Training epoch 9:  62%|██████▎   | 70/112 [00:01<00:00, 53.80it/s, Epoch: 9, Batch: 71,Loss: -0.712,Avg.Loss: -0.640,LR: 4.91E-04]Training epoch 9:  63%|██████▎   | 71/112 [00:01<00:00, 53.80it/s, Epoch: 9, Batch: 72,Loss: -0.944,Avg.Loss: -0.644,LR: 4.91E-04]Training epoch 9:  64%|██████▍   | 72/112 [00:01<00:00, 53.80it/s, Epoch: 9, Batch: 73,Loss: -0.612,Avg.Loss: -0.644,LR: 4.91E-04]Training epoch 9:  65%|██████▌   | 73/112 [00:01<00:00, 53.80it/s, Epoch: 9, Batch: 74,Loss: -0.357,Avg.Loss: -0.640,LR: 4.91E-04]Training epoch 9:  66%|██████▌   | 74/112 [00:01<00:00, 53.62it/s, Epoch: 9, Batch: 74,Loss: -0.357,Avg.Loss: -0.640,LR: 4.91E-04]Training epoch 9:  66%|██████▌   | 74/112 [00:01<00:00, 53.62it/s, Epoch: 9, Batch: 75,Loss: -0.792,Avg.Loss: -0.642,LR: 4.91E-04]Training epoch 9:  67%|██████▋   | 75/112 [00:01<00:00, 53.62it/s, Epoch: 9, Batch: 76,Loss: -0.957,Avg.Loss: -0.646,LR: 4.91E-04]Training epoch 9:  68%|██████▊   | 76/112 [00:01<00:00, 53.62it/s, Epoch: 9, Batch: 77,Loss: -0.238,Avg.Loss: -0.641,LR: 4.91E-04]Training epoch 9:  69%|██████▉   | 77/112 [00:01<00:00, 53.62it/s, Epoch: 9, Batch: 78,Loss: -1.127,Avg.Loss: -0.647,LR: 4.91E-04]Training epoch 9:  70%|██████▉   | 78/112 [00:01<00:00, 53.62it/s, Epoch: 9, Batch: 79,Loss: -0.872,Avg.Loss: -0.650,LR: 4.91E-04]Training epoch 9:  71%|███████   | 79/112 [00:01<00:00, 53.62it/s, Epoch: 9, Batch: 80,Loss: -0.388,Avg.Loss: -0.646,LR: 4.91E-04]Training epoch 9:  71%|███████▏  | 80/112 [00:01<00:00, 53.70it/s, Epoch: 9, Batch: 80,Loss: -0.388,Avg.Loss: -0.646,LR: 4.91E-04]Training epoch 9:  71%|███████▏  | 80/112 [00:01<00:00, 53.70it/s, Epoch: 9, Batch: 81,Loss: -0.956,Avg.Loss: -0.650,LR: 4.91E-04]Training epoch 9:  72%|███████▏  | 81/112 [00:01<00:00, 53.70it/s, Epoch: 9, Batch: 82,Loss: -0.926,Avg.Loss: -0.654,LR: 4.91E-04]Training epoch 9:  73%|███████▎  | 82/112 [00:01<00:00, 53.70it/s, Epoch: 9, Batch: 83,Loss: -0.727,Avg.Loss: -0.654,LR: 4.91E-04]Training epoch 9:  74%|███████▍  | 83/112 [00:01<00:00, 53.70it/s, Epoch: 9, Batch: 84,Loss: -1.087,Avg.Loss: -0.660,LR: 4.91E-04]Training epoch 9:  75%|███████▌  | 84/112 [00:01<00:00, 53.70it/s, Epoch: 9, Batch: 85,Loss: -0.620,Avg.Loss: -0.659,LR: 4.91E-04]Training epoch 9:  76%|███████▌  | 85/112 [00:01<00:00, 53.70it/s, Epoch: 9, Batch: 86,Loss: -0.490,Avg.Loss: -0.657,LR: 4.91E-04]Training epoch 9:  77%|███████▋  | 86/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 86,Loss: -0.490,Avg.Loss: -0.657,LR: 4.91E-04]Training epoch 9:  77%|███████▋  | 86/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 87,Loss: -0.297,Avg.Loss: -0.653,LR: 4.91E-04]Training epoch 9:  78%|███████▊  | 87/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 88,Loss: -0.939,Avg.Loss: -0.656,LR: 4.91E-04]Training epoch 9:  79%|███████▊  | 88/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 89,Loss: -0.427,Avg.Loss: -0.654,LR: 4.91E-04]Training epoch 9:  79%|███████▉  | 89/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 90,Loss: -0.867,Avg.Loss: -0.656,LR: 4.90E-04]Training epoch 9:  80%|████████  | 90/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 91,Loss: -0.638,Avg.Loss: -0.656,LR: 4.90E-04]Training epoch 9:  81%|████████▏ | 91/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 92,Loss: -0.311,Avg.Loss: -0.652,LR: 4.90E-04]Training epoch 9:  82%|████████▏ | 92/112 [00:01<00:00, 53.63it/s, Epoch: 9, Batch: 92,Loss: -0.311,Avg.Loss: -0.652,LR: 4.90E-04]Training epoch 9:  82%|████████▏ | 92/112 [00:01<00:00, 53.63it/s, Epoch: 9, Batch: 93,Loss: -1.031,Avg.Loss: -0.656,LR: 4.90E-04]Training epoch 9:  83%|████████▎ | 93/112 [00:01<00:00, 53.63it/s, Epoch: 9, Batch: 94,Loss: -0.348,Avg.Loss: -0.653,LR: 4.90E-04]Training epoch 9:  84%|████████▍ | 94/112 [00:01<00:00, 53.63it/s, Epoch: 9, Batch: 95,Loss: -0.608,Avg.Loss: -0.652,LR: 4.90E-04]Training epoch 9:  85%|████████▍ | 95/112 [00:01<00:00, 53.63it/s, Epoch: 9, Batch: 96,Loss: -0.950,Avg.Loss: -0.656,LR: 4.90E-04]Training epoch 9:  86%|████████▌ | 96/112 [00:01<00:00, 53.63it/s, Epoch: 9, Batch: 97,Loss: -0.136,Avg.Loss: -0.650,LR: 4.90E-04]Training epoch 9:  87%|████████▋ | 97/112 [00:01<00:00, 53.63it/s, Epoch: 9, Batch: 98,Loss: -0.448,Avg.Loss: -0.648,LR: 4.90E-04]Training epoch 9:  88%|████████▊ | 98/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 98,Loss: -0.448,Avg.Loss: -0.648,LR: 4.90E-04]Training epoch 9:  88%|████████▊ | 98/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 99,Loss: -0.617,Avg.Loss: -0.648,LR: 4.90E-04]Training epoch 9:  88%|████████▊ | 99/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 100,Loss: -1.025,Avg.Loss: -0.652,LR: 4.90E-04]Training epoch 9:  89%|████████▉ | 100/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 101,Loss: -0.773,Avg.Loss: -0.653,LR: 4.90E-04]Training epoch 9:  90%|█████████ | 101/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 102,Loss: -1.164,Avg.Loss: -0.658,LR: 4.90E-04]Training epoch 9:  91%|█████████ | 102/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 103,Loss: -0.618,Avg.Loss: -0.657,LR: 4.90E-04]Training epoch 9:  92%|█████████▏| 103/112 [00:01<00:00, 53.67it/s, Epoch: 9, Batch: 104,Loss: -0.719,Avg.Loss: -0.658,LR: 4.90E-04]Training epoch 9:  93%|█████████▎| 104/112 [00:01<00:00, 53.57it/s, Epoch: 9, Batch: 104,Loss: -0.719,Avg.Loss: -0.658,LR: 4.90E-04]Training epoch 9:  93%|█████████▎| 104/112 [00:01<00:00, 53.57it/s, Epoch: 9, Batch: 105,Loss: -0.862,Avg.Loss: -0.660,LR: 4.90E-04]Training epoch 9:  94%|█████████▍| 105/112 [00:01<00:00, 53.57it/s, Epoch: 9, Batch: 106,Loss: -0.927,Avg.Loss: -0.663,LR: 4.90E-04]Training epoch 9:  95%|█████████▍| 106/112 [00:01<00:00, 53.57it/s, Epoch: 9, Batch: 107,Loss: -0.386,Avg.Loss: -0.660,LR: 4.90E-04]Training epoch 9:  96%|█████████▌| 107/112 [00:01<00:00, 53.57it/s, Epoch: 9, Batch: 108,Loss: -0.814,Avg.Loss: -0.661,LR: 4.90E-04]Training epoch 9:  96%|█████████▋| 108/112 [00:02<00:00, 53.57it/s, Epoch: 9, Batch: 109,Loss: -1.070,Avg.Loss: -0.665,LR: 4.90E-04]Training epoch 9:  97%|█████████▋| 109/112 [00:02<00:00, 53.57it/s, Epoch: 9, Batch: 110,Loss: -0.582,Avg.Loss: -0.664,LR: 4.90E-04]Training epoch 9:  98%|█████████▊| 110/112 [00:02<00:00, 52.87it/s, Epoch: 9, Batch: 110,Loss: -0.582,Avg.Loss: -0.664,LR: 4.90E-04]Training epoch 9:  98%|█████████▊| 110/112 [00:02<00:00, 52.87it/s, Epoch: 9, Batch: 111,Loss: -0.915,Avg.Loss: -0.667,LR: 4.90E-04]Training epoch 9:  99%|█████████▉| 111/112 [00:02<00:00, 52.87it/s, Epoch: 9, Batch: 112,Loss: -0.777,Avg.Loss: -0.668,LR: 4.90E-04]Training epoch 9: 100%|██████████| 112/112 [00:02<00:00, 54.14it/s, Epoch: 9, Batch: 112,Loss: -0.777,Avg.Loss: -0.668,LR: 4.90E-04]
Training epoch 10:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 10:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 10, Batch: 1,Loss: 0.204,Avg.Loss: 0.204,LR: 4.90E-04]Training epoch 10:   1%|          | 1/112 [00:00<00:04, 24.67it/s, Epoch: 10, Batch: 2,Loss: -0.215,Avg.Loss: -0.005,LR: 4.90E-04]Training epoch 10:   2%|▏         | 2/112 [00:00<00:03, 35.37it/s, Epoch: 10, Batch: 3,Loss: -0.749,Avg.Loss: -0.253,LR: 4.90E-04]Training epoch 10:   3%|▎         | 3/112 [00:00<00:02, 41.63it/s, Epoch: 10, Batch: 4,Loss: 0.056,Avg.Loss: -0.176,LR: 4.90E-04] Training epoch 10:   4%|▎         | 4/112 [00:00<00:02, 45.84it/s, Epoch: 10, Batch: 5,Loss: -0.544,Avg.Loss: -0.250,LR: 4.90E-04]Training epoch 10:   4%|▍         | 5/112 [00:00<00:02, 49.64it/s, Epoch: 10, Batch: 6,Loss: -0.511,Avg.Loss: -0.293,LR: 4.90E-04]Training epoch 10:   5%|▌         | 6/112 [00:00<00:01, 59.47it/s, Epoch: 10, Batch: 6,Loss: -0.511,Avg.Loss: -0.293,LR: 4.90E-04]Training epoch 10:   5%|▌         | 6/112 [00:00<00:01, 59.47it/s, Epoch: 10, Batch: 7,Loss: -0.021,Avg.Loss: -0.254,LR: 4.90E-04]Training epoch 10:   6%|▋         | 7/112 [00:00<00:01, 59.47it/s, Epoch: 10, Batch: 8,Loss: -0.356,Avg.Loss: -0.267,LR: 4.90E-04]Training epoch 10:   7%|▋         | 8/112 [00:00<00:01, 59.47it/s, Epoch: 10, Batch: 9,Loss: -0.713,Avg.Loss: -0.316,LR: 4.90E-04]Training epoch 10:   8%|▊         | 9/112 [00:00<00:01, 59.47it/s, Epoch: 10, Batch: 10,Loss: -0.322,Avg.Loss: -0.317,LR: 4.90E-04]Training epoch 10:   9%|▉         | 10/112 [00:00<00:01, 59.47it/s, Epoch: 10, Batch: 11,Loss: -0.902,Avg.Loss: -0.370,LR: 4.90E-04]Training epoch 10:  10%|▉         | 11/112 [00:00<00:01, 59.47it/s, Epoch: 10, Batch: 12,Loss: 0.118,Avg.Loss: -0.329,LR: 4.90E-04] Training epoch 10:  11%|█         | 12/112 [00:00<00:01, 59.47it/s, Epoch: 10, Batch: 13,Loss: 0.568,Avg.Loss: -0.260,LR: 4.90E-04]Training epoch 10:  12%|█▏        | 13/112 [00:00<00:01, 62.13it/s, Epoch: 10, Batch: 13,Loss: 0.568,Avg.Loss: -0.260,LR: 4.90E-04]Training epoch 10:  12%|█▏        | 13/112 [00:00<00:01, 62.13it/s, Epoch: 10, Batch: 14,Loss: 0.151,Avg.Loss: -0.231,LR: 4.90E-04]Training epoch 10:  12%|█▎        | 14/112 [00:00<00:01, 62.13it/s, Epoch: 10, Batch: 15,Loss: -0.840,Avg.Loss: -0.272,LR: 4.90E-04]Training epoch 10:  13%|█▎        | 15/112 [00:00<00:01, 62.13it/s, Epoch: 10, Batch: 16,Loss: 0.044,Avg.Loss: -0.252,LR: 4.90E-04] Training epoch 10:  14%|█▍        | 16/112 [00:00<00:01, 62.13it/s, Epoch: 10, Batch: 17,Loss: 2.210,Avg.Loss: -0.107,LR: 4.90E-04]Training epoch 10:  15%|█▌        | 17/112 [00:00<00:01, 62.13it/s, Epoch: 10, Batch: 18,Loss: 0.434,Avg.Loss: -0.077,LR: 4.90E-04]Training epoch 10:  16%|█▌        | 18/112 [00:00<00:01, 62.13it/s, Epoch: 10, Batch: 19,Loss: -0.674,Avg.Loss: -0.108,LR: 4.90E-04]Training epoch 10:  17%|█▋        | 19/112 [00:00<00:01, 62.13it/s, Epoch: 10, Batch: 20,Loss: 0.555,Avg.Loss: -0.075,LR: 4.90E-04] Training epoch 10:  18%|█▊        | 20/112 [00:00<00:01, 58.32it/s, Epoch: 10, Batch: 20,Loss: 0.555,Avg.Loss: -0.075,LR: 4.90E-04]Training epoch 10:  18%|█▊        | 20/112 [00:00<00:01, 58.32it/s, Epoch: 10, Batch: 21,Loss: 1.019,Avg.Loss: -0.023,LR: 4.90E-04]Training epoch 10:  19%|█▉        | 21/112 [00:00<00:01, 58.32it/s, Epoch: 10, Batch: 22,Loss: 0.920,Avg.Loss: 0.020,LR: 4.90E-04] Training epoch 10:  20%|█▉        | 22/112 [00:00<00:01, 58.32it/s, Epoch: 10, Batch: 23,Loss: -0.612,Avg.Loss: -0.008,LR: 4.90E-04]Training epoch 10:  21%|██        | 23/112 [00:00<00:01, 58.32it/s, Epoch: 10, Batch: 24,Loss: -0.975,Avg.Loss: -0.048,LR: 4.90E-04]Training epoch 10:  21%|██▏       | 24/112 [00:00<00:01, 58.32it/s, Epoch: 10, Batch: 25,Loss: -0.207,Avg.Loss: -0.054,LR: 4.90E-04]Training epoch 10:  22%|██▏       | 25/112 [00:00<00:01, 58.32it/s, Epoch: 10, Batch: 26,Loss: -0.730,Avg.Loss: -0.080,LR: 4.90E-04]Training epoch 10:  23%|██▎       | 26/112 [00:00<00:01, 56.28it/s, Epoch: 10, Batch: 26,Loss: -0.730,Avg.Loss: -0.080,LR: 4.90E-04]Training epoch 10:  23%|██▎       | 26/112 [00:00<00:01, 56.28it/s, Epoch: 10, Batch: 27,Loss: -1.091,Avg.Loss: -0.118,LR: 4.90E-04]Training epoch 10:  24%|██▍       | 27/112 [00:00<00:01, 56.28it/s, Epoch: 10, Batch: 28,Loss: -1.008,Avg.Loss: -0.150,LR: 4.90E-04]Training epoch 10:  25%|██▌       | 28/112 [00:00<00:01, 56.28it/s, Epoch: 10, Batch: 29,Loss: -1.072,Avg.Loss: -0.181,LR: 4.89E-04]Training epoch 10:  26%|██▌       | 29/112 [00:00<00:01, 56.28it/s, Epoch: 10, Batch: 30,Loss: -0.872,Avg.Loss: -0.204,LR: 4.89E-04]Training epoch 10:  27%|██▋       | 30/112 [00:00<00:01, 56.28it/s, Epoch: 10, Batch: 31,Loss: -1.048,Avg.Loss: -0.232,LR: 4.89E-04]Training epoch 10:  28%|██▊       | 31/112 [00:00<00:01, 56.28it/s, Epoch: 10, Batch: 32,Loss: -1.042,Avg.Loss: -0.257,LR: 4.89E-04]Training epoch 10:  29%|██▊       | 32/112 [00:00<00:01, 54.53it/s, Epoch: 10, Batch: 32,Loss: -1.042,Avg.Loss: -0.257,LR: 4.89E-04]Training epoch 10:  29%|██▊       | 32/112 [00:00<00:01, 54.53it/s, Epoch: 10, Batch: 33,Loss: -0.882,Avg.Loss: -0.276,LR: 4.89E-04]Training epoch 10:  29%|██▉       | 33/112 [00:00<00:01, 54.53it/s, Epoch: 10, Batch: 34,Loss: -1.043,Avg.Loss: -0.298,LR: 4.89E-04]Training epoch 10:  30%|███       | 34/112 [00:00<00:01, 54.53it/s, Epoch: 10, Batch: 35,Loss: -0.627,Avg.Loss: -0.308,LR: 4.89E-04]Training epoch 10:  31%|███▏      | 35/112 [00:00<00:01, 54.53it/s, Epoch: 10, Batch: 36,Loss: -1.007,Avg.Loss: -0.327,LR: 4.89E-04]Training epoch 10:  32%|███▏      | 36/112 [00:00<00:01, 54.53it/s, Epoch: 10, Batch: 37,Loss: -1.054,Avg.Loss: -0.347,LR: 4.89E-04]Training epoch 10:  33%|███▎      | 37/112 [00:00<00:01, 54.53it/s, Epoch: 10, Batch: 38,Loss: -0.631,Avg.Loss: -0.354,LR: 4.89E-04]Training epoch 10:  34%|███▍      | 38/112 [00:00<00:01, 54.02it/s, Epoch: 10, Batch: 38,Loss: -0.631,Avg.Loss: -0.354,LR: 4.89E-04]Training epoch 10:  34%|███▍      | 38/112 [00:00<00:01, 54.02it/s, Epoch: 10, Batch: 39,Loss: -1.186,Avg.Loss: -0.376,LR: 4.89E-04]Training epoch 10:  35%|███▍      | 39/112 [00:00<00:01, 54.02it/s, Epoch: 10, Batch: 40,Loss: -0.953,Avg.Loss: -0.390,LR: 4.89E-04]Training epoch 10:  36%|███▌      | 40/112 [00:00<00:01, 54.02it/s, Epoch: 10, Batch: 41,Loss: -1.094,Avg.Loss: -0.407,LR: 4.89E-04]Training epoch 10:  37%|███▋      | 41/112 [00:00<00:01, 54.02it/s, Epoch: 10, Batch: 42,Loss: -0.965,Avg.Loss: -0.421,LR: 4.89E-04]Training epoch 10:  38%|███▊      | 42/112 [00:00<00:01, 54.02it/s, Epoch: 10, Batch: 43,Loss: -0.570,Avg.Loss: -0.424,LR: 4.89E-04]Training epoch 10:  38%|███▊      | 43/112 [00:00<00:01, 54.02it/s, Epoch: 10, Batch: 44,Loss: -1.146,Avg.Loss: -0.440,LR: 4.89E-04]Training epoch 10:  39%|███▉      | 44/112 [00:00<00:01, 53.77it/s, Epoch: 10, Batch: 44,Loss: -1.146,Avg.Loss: -0.440,LR: 4.89E-04]Training epoch 10:  39%|███▉      | 44/112 [00:00<00:01, 53.77it/s, Epoch: 10, Batch: 45,Loss: -0.931,Avg.Loss: -0.451,LR: 4.89E-04]Training epoch 10:  40%|████      | 45/112 [00:00<00:01, 53.77it/s, Epoch: 10, Batch: 46,Loss: -1.043,Avg.Loss: -0.464,LR: 4.89E-04]Training epoch 10:  41%|████      | 46/112 [00:00<00:01, 53.77it/s, Epoch: 10, Batch: 47,Loss: -0.982,Avg.Loss: -0.475,LR: 4.89E-04]Training epoch 10:  42%|████▏     | 47/112 [00:00<00:01, 53.77it/s, Epoch: 10, Batch: 48,Loss: -1.182,Avg.Loss: -0.490,LR: 4.89E-04]Training epoch 10:  43%|████▎     | 48/112 [00:00<00:01, 53.77it/s, Epoch: 10, Batch: 49,Loss: -0.673,Avg.Loss: -0.494,LR: 4.89E-04]Training epoch 10:  44%|████▍     | 49/112 [00:00<00:01, 53.77it/s, Epoch: 10, Batch: 50,Loss: -0.153,Avg.Loss: -0.487,LR: 4.89E-04]Training epoch 10:  45%|████▍     | 50/112 [00:00<00:01, 53.58it/s, Epoch: 10, Batch: 50,Loss: -0.153,Avg.Loss: -0.487,LR: 4.89E-04]Training epoch 10:  45%|████▍     | 50/112 [00:00<00:01, 53.58it/s, Epoch: 10, Batch: 51,Loss: -0.992,Avg.Loss: -0.497,LR: 4.89E-04]Training epoch 10:  46%|████▌     | 51/112 [00:00<00:01, 53.58it/s, Epoch: 10, Batch: 52,Loss: -1.142,Avg.Loss: -0.509,LR: 4.89E-04]Training epoch 10:  46%|████▋     | 52/112 [00:00<00:01, 53.58it/s, Epoch: 10, Batch: 53,Loss: -0.948,Avg.Loss: -0.517,LR: 4.89E-04]Training epoch 10:  47%|████▋     | 53/112 [00:00<00:01, 53.58it/s, Epoch: 10, Batch: 54,Loss: -1.066,Avg.Loss: -0.528,LR: 4.89E-04]Training epoch 10:  48%|████▊     | 54/112 [00:01<00:01, 53.58it/s, Epoch: 10, Batch: 55,Loss: -0.895,Avg.Loss: -0.534,LR: 4.89E-04]Training epoch 10:  49%|████▉     | 55/112 [00:01<00:01, 53.58it/s, Epoch: 10, Batch: 56,Loss: -0.983,Avg.Loss: -0.542,LR: 4.89E-04]Training epoch 10:  50%|█████     | 56/112 [00:01<00:01, 53.52it/s, Epoch: 10, Batch: 56,Loss: -0.983,Avg.Loss: -0.542,LR: 4.89E-04]Training epoch 10:  50%|█████     | 56/112 [00:01<00:01, 53.52it/s, Epoch: 10, Batch: 57,Loss: -1.288,Avg.Loss: -0.555,LR: 4.89E-04]Training epoch 10:  51%|█████     | 57/112 [00:01<00:01, 53.52it/s, Epoch: 10, Batch: 58,Loss: -0.648,Avg.Loss: -0.557,LR: 4.89E-04]Training epoch 10:  52%|█████▏    | 58/112 [00:01<00:01, 53.52it/s, Epoch: 10, Batch: 59,Loss: -0.995,Avg.Loss: -0.564,LR: 4.89E-04]Training epoch 10:  53%|█████▎    | 59/112 [00:01<00:00, 53.52it/s, Epoch: 10, Batch: 60,Loss: -1.208,Avg.Loss: -0.575,LR: 4.89E-04]Training epoch 10:  54%|█████▎    | 60/112 [00:01<00:00, 53.52it/s, Epoch: 10, Batch: 61,Loss: -1.311,Avg.Loss: -0.587,LR: 4.89E-04]Training epoch 10:  54%|█████▍    | 61/112 [00:01<00:00, 53.52it/s, Epoch: 10, Batch: 62,Loss: -1.051,Avg.Loss: -0.595,LR: 4.89E-04]Training epoch 10:  55%|█████▌    | 62/112 [00:01<00:00, 52.80it/s, Epoch: 10, Batch: 62,Loss: -1.051,Avg.Loss: -0.595,LR: 4.89E-04]Training epoch 10:  55%|█████▌    | 62/112 [00:01<00:00, 52.80it/s, Epoch: 10, Batch: 63,Loss: -0.901,Avg.Loss: -0.600,LR: 4.89E-04]Training epoch 10:  56%|█████▋    | 63/112 [00:01<00:00, 52.80it/s, Epoch: 10, Batch: 64,Loss: -0.807,Avg.Loss: -0.603,LR: 4.89E-04]Training epoch 10:  57%|█████▋    | 64/112 [00:01<00:00, 52.80it/s, Epoch: 10, Batch: 65,Loss: -1.315,Avg.Loss: -0.614,LR: 4.89E-04]Training epoch 10:  58%|█████▊    | 65/112 [00:01<00:00, 52.80it/s, Epoch: 10, Batch: 66,Loss: -0.907,Avg.Loss: -0.618,LR: 4.89E-04]Training epoch 10:  59%|█████▉    | 66/112 [00:01<00:00, 52.80it/s, Epoch: 10, Batch: 67,Loss: -1.218,Avg.Loss: -0.627,LR: 4.89E-04]Training epoch 10:  60%|█████▉    | 67/112 [00:01<00:00, 52.80it/s, Epoch: 10, Batch: 68,Loss: -0.204,Avg.Loss: -0.621,LR: 4.89E-04]Training epoch 10:  61%|██████    | 68/112 [00:01<00:00, 51.17it/s, Epoch: 10, Batch: 68,Loss: -0.204,Avg.Loss: -0.621,LR: 4.89E-04]Training epoch 10:  61%|██████    | 68/112 [00:01<00:00, 51.17it/s, Epoch: 10, Batch: 69,Loss: -0.073,Avg.Loss: -0.613,LR: 4.89E-04]Training epoch 10:  62%|██████▏   | 69/112 [00:01<00:00, 51.17it/s, Epoch: 10, Batch: 70,Loss: -0.790,Avg.Loss: -0.616,LR: 4.89E-04]Training epoch 10:  62%|██████▎   | 70/112 [00:01<00:00, 51.17it/s, Epoch: 10, Batch: 71,Loss: 0.779,Avg.Loss: -0.596,LR: 4.89E-04] Training epoch 10:  63%|██████▎   | 71/112 [00:01<00:00, 51.17it/s, Epoch: 10, Batch: 72,Loss: 0.914,Avg.Loss: -0.575,LR: 4.89E-04]Training epoch 10:  64%|██████▍   | 72/112 [00:01<00:00, 51.17it/s, Epoch: 10, Batch: 73,Loss: -0.501,Avg.Loss: -0.574,LR: 4.89E-04]Training epoch 10:  65%|██████▌   | 73/112 [00:01<00:00, 51.17it/s, Epoch: 10, Batch: 74,Loss: 0.581,Avg.Loss: -0.558,LR: 4.89E-04] Training epoch 10:  66%|██████▌   | 74/112 [00:01<00:00, 51.75it/s, Epoch: 10, Batch: 74,Loss: 0.581,Avg.Loss: -0.558,LR: 4.89E-04]Training epoch 10:  66%|██████▌   | 74/112 [00:01<00:00, 51.75it/s, Epoch: 10, Batch: 75,Loss: 1.670,Avg.Loss: -0.529,LR: 4.89E-04]Training epoch 10:  67%|██████▋   | 75/112 [00:01<00:00, 51.75it/s, Epoch: 10, Batch: 76,Loss: 0.984,Avg.Loss: -0.509,LR: 4.89E-04]Training epoch 10:  68%|██████▊   | 76/112 [00:01<00:00, 51.75it/s, Epoch: 10, Batch: 77,Loss: -0.734,Avg.Loss: -0.512,LR: 4.89E-04]Training epoch 10:  69%|██████▉   | 77/112 [00:01<00:00, 51.75it/s, Epoch: 10, Batch: 78,Loss: 0.316,Avg.Loss: -0.501,LR: 4.88E-04] Training epoch 10:  70%|██████▉   | 78/112 [00:01<00:00, 51.75it/s, Epoch: 10, Batch: 79,Loss: 1.908,Avg.Loss: -0.470,LR: 4.88E-04]Training epoch 10:  71%|███████   | 79/112 [00:01<00:00, 51.75it/s, Epoch: 10, Batch: 80,Loss: 2.153,Avg.Loss: -0.438,LR: 4.88E-04]Training epoch 10:  71%|███████▏  | 80/112 [00:01<00:00, 52.29it/s, Epoch: 10, Batch: 80,Loss: 2.153,Avg.Loss: -0.438,LR: 4.88E-04]Training epoch 10:  71%|███████▏  | 80/112 [00:01<00:00, 52.29it/s, Epoch: 10, Batch: 81,Loss: 4.433,Avg.Loss: -0.378,LR: 4.88E-04]Training epoch 10:  72%|███████▏  | 81/112 [00:01<00:00, 52.29it/s, Epoch: 10, Batch: 82,Loss: 3.455,Avg.Loss: -0.331,LR: 4.88E-04]Training epoch 10:  73%|███████▎  | 82/112 [00:01<00:00, 52.29it/s, Epoch: 10, Batch: 83,Loss: 4.191,Avg.Loss: -0.276,LR: 4.88E-04]Training epoch 10:  74%|███████▍  | 83/112 [00:01<00:00, 52.29it/s, Epoch: 10, Batch: 84,Loss: 0.886,Avg.Loss: -0.263,LR: 4.88E-04]Training epoch 10:  75%|███████▌  | 84/112 [00:01<00:00, 52.29it/s, Epoch: 10, Batch: 85,Loss: 1.619,Avg.Loss: -0.240,LR: 4.88E-04]Training epoch 10:  76%|███████▌  | 85/112 [00:01<00:00, 52.29it/s, Epoch: 10, Batch: 86,Loss: -0.036,Avg.Loss: -0.238,LR: 4.88E-04]Training epoch 10:  77%|███████▋  | 86/112 [00:01<00:00, 52.60it/s, Epoch: 10, Batch: 86,Loss: -0.036,Avg.Loss: -0.238,LR: 4.88E-04]Training epoch 10:  77%|███████▋  | 86/112 [00:01<00:00, 52.60it/s, Epoch: 10, Batch: 87,Loss: -0.508,Avg.Loss: -0.241,LR: 4.88E-04]Training epoch 10:  78%|███████▊  | 87/112 [00:01<00:00, 52.60it/s, Epoch: 10, Batch: 88,Loss: -0.700,Avg.Loss: -0.246,LR: 4.88E-04]Training epoch 10:  79%|███████▊  | 88/112 [00:01<00:00, 52.60it/s, Epoch: 10, Batch: 89,Loss: -0.737,Avg.Loss: -0.252,LR: 4.88E-04]Training epoch 10:  79%|███████▉  | 89/112 [00:01<00:00, 52.60it/s, Epoch: 10, Batch: 90,Loss: -0.358,Avg.Loss: -0.253,LR: 4.88E-04]Training epoch 10:  80%|████████  | 90/112 [00:01<00:00, 52.60it/s, Epoch: 10, Batch: 91,Loss: -0.938,Avg.Loss: -0.261,LR: 4.88E-04]Training epoch 10:  81%|████████▏ | 91/112 [00:01<00:00, 52.60it/s, Epoch: 10, Batch: 92,Loss: -0.426,Avg.Loss: -0.262,LR: 4.88E-04]Training epoch 10:  82%|████████▏ | 92/112 [00:01<00:00, 52.91it/s, Epoch: 10, Batch: 92,Loss: -0.426,Avg.Loss: -0.262,LR: 4.88E-04]Training epoch 10:  82%|████████▏ | 92/112 [00:01<00:00, 52.91it/s, Epoch: 10, Batch: 93,Loss: -0.138,Avg.Loss: -0.261,LR: 4.88E-04]Training epoch 10:  83%|████████▎ | 93/112 [00:01<00:00, 52.91it/s, Epoch: 10, Batch: 94,Loss: -0.569,Avg.Loss: -0.264,LR: 4.88E-04]Training epoch 10:  84%|████████▍ | 94/112 [00:01<00:00, 52.91it/s, Epoch: 10, Batch: 95,Loss: 0.220,Avg.Loss: -0.259,LR: 4.88E-04] Training epoch 10:  85%|████████▍ | 95/112 [00:01<00:00, 52.91it/s, Epoch: 10, Batch: 96,Loss: 0.742,Avg.Loss: -0.249,LR: 4.88E-04]Training epoch 10:  86%|████████▌ | 96/112 [00:01<00:00, 52.91it/s, Epoch: 10, Batch: 97,Loss: -0.106,Avg.Loss: -0.247,LR: 4.88E-04]Training epoch 10:  87%|████████▋ | 97/112 [00:01<00:00, 52.91it/s, Epoch: 10, Batch: 98,Loss: -0.752,Avg.Loss: -0.252,LR: 4.88E-04]Training epoch 10:  88%|████████▊ | 98/112 [00:01<00:00, 53.05it/s, Epoch: 10, Batch: 98,Loss: -0.752,Avg.Loss: -0.252,LR: 4.88E-04]Training epoch 10:  88%|████████▊ | 98/112 [00:01<00:00, 53.05it/s, Epoch: 10, Batch: 99,Loss: 0.271,Avg.Loss: -0.247,LR: 4.88E-04] Training epoch 10:  88%|████████▊ | 99/112 [00:01<00:00, 53.05it/s, Epoch: 10, Batch: 100,Loss: 1.242,Avg.Loss: -0.232,LR: 4.88E-04]Training epoch 10:  89%|████████▉ | 100/112 [00:01<00:00, 53.05it/s, Epoch: 10, Batch: 101,Loss: 0.522,Avg.Loss: -0.225,LR: 4.88E-04]Training epoch 10:  90%|█████████ | 101/112 [00:01<00:00, 53.05it/s, Epoch: 10, Batch: 102,Loss: -0.503,Avg.Loss: -0.227,LR: 4.88E-04]Training epoch 10:  91%|█████████ | 102/112 [00:01<00:00, 53.05it/s, Epoch: 10, Batch: 103,Loss: -0.498,Avg.Loss: -0.230,LR: 4.88E-04]Training epoch 10:  92%|█████████▏| 103/112 [00:01<00:00, 53.05it/s, Epoch: 10, Batch: 104,Loss: 0.154,Avg.Loss: -0.226,LR: 4.88E-04] Training epoch 10:  93%|█████████▎| 104/112 [00:01<00:00, 53.30it/s, Epoch: 10, Batch: 104,Loss: 0.154,Avg.Loss: -0.226,LR: 4.88E-04]Training epoch 10:  93%|█████████▎| 104/112 [00:01<00:00, 53.30it/s, Epoch: 10, Batch: 105,Loss: -0.162,Avg.Loss: -0.226,LR: 4.88E-04]Training epoch 10:  94%|█████████▍| 105/112 [00:01<00:00, 53.30it/s, Epoch: 10, Batch: 106,Loss: -0.696,Avg.Loss: -0.230,LR: 4.88E-04]Training epoch 10:  95%|█████████▍| 106/112 [00:01<00:00, 53.30it/s, Epoch: 10, Batch: 107,Loss: -0.349,Avg.Loss: -0.231,LR: 4.88E-04]Training epoch 10:  96%|█████████▌| 107/112 [00:02<00:00, 53.30it/s, Epoch: 10, Batch: 108,Loss: 0.066,Avg.Loss: -0.229,LR: 4.88E-04] Training epoch 10:  96%|█████████▋| 108/112 [00:02<00:00, 53.30it/s, Epoch: 10, Batch: 109,Loss: -0.446,Avg.Loss: -0.231,LR: 4.88E-04]Training epoch 10:  97%|█████████▋| 109/112 [00:02<00:00, 53.30it/s, Epoch: 10, Batch: 110,Loss: -0.356,Avg.Loss: -0.232,LR: 4.88E-04]Training epoch 10:  98%|█████████▊| 110/112 [00:02<00:00, 53.46it/s, Epoch: 10, Batch: 110,Loss: -0.356,Avg.Loss: -0.232,LR: 4.88E-04]Training epoch 10:  98%|█████████▊| 110/112 [00:02<00:00, 53.46it/s, Epoch: 10, Batch: 111,Loss: -0.005,Avg.Loss: -0.230,LR: 4.88E-04]Training epoch 10:  99%|█████████▉| 111/112 [00:02<00:00, 53.46it/s, Epoch: 10, Batch: 112,Loss: -0.037,Avg.Loss: -0.228,LR: 4.88E-04]Training epoch 10: 100%|██████████| 112/112 [00:02<00:00, 53.66it/s, Epoch: 10, Batch: 112,Loss: -0.037,Avg.Loss: -0.228,LR: 4.88E-04]
Training epoch 11:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 11:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 11, Batch: 1,Loss: -0.250,Avg.Loss: -0.250,LR: 4.88E-04]Training epoch 11:   1%|          | 1/112 [00:00<00:03, 28.11it/s, Epoch: 11, Batch: 2,Loss: -0.750,Avg.Loss: -0.500,LR: 4.88E-04]Training epoch 11:   2%|▏         | 2/112 [00:00<00:02, 38.04it/s, Epoch: 11, Batch: 3,Loss: -0.723,Avg.Loss: -0.574,LR: 4.88E-04]Training epoch 11:   3%|▎         | 3/112 [00:00<00:02, 43.03it/s, Epoch: 11, Batch: 4,Loss: -0.673,Avg.Loss: -0.599,LR: 4.88E-04]Training epoch 11:   4%|▎         | 4/112 [00:00<00:02, 47.19it/s, Epoch: 11, Batch: 5,Loss: -0.257,Avg.Loss: -0.531,LR: 4.88E-04]Training epoch 11:   4%|▍         | 5/112 [00:00<00:02, 50.94it/s, Epoch: 11, Batch: 6,Loss: -0.801,Avg.Loss: -0.576,LR: 4.88E-04]Training epoch 11:   5%|▌         | 6/112 [00:00<00:01, 53.54it/s, Epoch: 11, Batch: 7,Loss: -0.495,Avg.Loss: -0.564,LR: 4.88E-04]Training epoch 11:   6%|▋         | 7/112 [00:00<00:01, 62.38it/s, Epoch: 11, Batch: 7,Loss: -0.495,Avg.Loss: -0.564,LR: 4.88E-04]Training epoch 11:   6%|▋         | 7/112 [00:00<00:01, 62.38it/s, Epoch: 11, Batch: 8,Loss: -0.464,Avg.Loss: -0.552,LR: 4.88E-04]Training epoch 11:   7%|▋         | 8/112 [00:00<00:01, 62.38it/s, Epoch: 11, Batch: 9,Loss: -0.248,Avg.Loss: -0.518,LR: 4.88E-04]Training epoch 11:   8%|▊         | 9/112 [00:00<00:01, 62.38it/s, Epoch: 11, Batch: 10,Loss: -0.103,Avg.Loss: -0.476,LR: 4.88E-04]Training epoch 11:   9%|▉         | 10/112 [00:00<00:01, 62.38it/s, Epoch: 11, Batch: 11,Loss: -0.567,Avg.Loss: -0.485,LR: 4.88E-04]Training epoch 11:  10%|▉         | 11/112 [00:00<00:01, 62.38it/s, Epoch: 11, Batch: 12,Loss: -0.395,Avg.Loss: -0.477,LR: 4.88E-04]Training epoch 11:  11%|█         | 12/112 [00:00<00:01, 62.38it/s, Epoch: 11, Batch: 13,Loss: -0.463,Avg.Loss: -0.476,LR: 4.87E-04]Training epoch 11:  12%|█▏        | 13/112 [00:00<00:01, 62.38it/s, Epoch: 11, Batch: 14,Loss: -0.411,Avg.Loss: -0.472,LR: 4.87E-04]Training epoch 11:  12%|█▎        | 14/112 [00:00<00:01, 58.85it/s, Epoch: 11, Batch: 14,Loss: -0.411,Avg.Loss: -0.472,LR: 4.87E-04]Training epoch 11:  12%|█▎        | 14/112 [00:00<00:01, 58.85it/s, Epoch: 11, Batch: 15,Loss: -0.825,Avg.Loss: -0.495,LR: 4.87E-04]Training epoch 11:  13%|█▎        | 15/112 [00:00<00:01, 58.85it/s, Epoch: 11, Batch: 16,Loss: -0.613,Avg.Loss: -0.502,LR: 4.87E-04]Training epoch 11:  14%|█▍        | 16/112 [00:00<00:01, 58.85it/s, Epoch: 11, Batch: 17,Loss: 0.192,Avg.Loss: -0.462,LR: 4.87E-04] Training epoch 11:  15%|█▌        | 17/112 [00:00<00:01, 58.85it/s, Epoch: 11, Batch: 18,Loss: -0.710,Avg.Loss: -0.475,LR: 4.87E-04]Training epoch 11:  16%|█▌        | 18/112 [00:00<00:01, 58.85it/s, Epoch: 11, Batch: 19,Loss: -0.776,Avg.Loss: -0.491,LR: 4.87E-04]Training epoch 11:  17%|█▋        | 19/112 [00:00<00:01, 58.85it/s, Epoch: 11, Batch: 20,Loss: -0.375,Avg.Loss: -0.485,LR: 4.87E-04]Training epoch 11:  18%|█▊        | 20/112 [00:00<00:01, 56.25it/s, Epoch: 11, Batch: 20,Loss: -0.375,Avg.Loss: -0.485,LR: 4.87E-04]Training epoch 11:  18%|█▊        | 20/112 [00:00<00:01, 56.25it/s, Epoch: 11, Batch: 21,Loss: -0.790,Avg.Loss: -0.500,LR: 4.87E-04]Training epoch 11:  19%|█▉        | 21/112 [00:00<00:01, 56.25it/s, Epoch: 11, Batch: 22,Loss: -0.701,Avg.Loss: -0.509,LR: 4.87E-04]Training epoch 11:  20%|█▉        | 22/112 [00:00<00:01, 56.25it/s, Epoch: 11, Batch: 23,Loss: -0.967,Avg.Loss: -0.529,LR: 4.87E-04]Training epoch 11:  21%|██        | 23/112 [00:00<00:01, 56.25it/s, Epoch: 11, Batch: 24,Loss: -0.781,Avg.Loss: -0.539,LR: 4.87E-04]Training epoch 11:  21%|██▏       | 24/112 [00:00<00:01, 56.25it/s, Epoch: 11, Batch: 25,Loss: -0.548,Avg.Loss: -0.540,LR: 4.87E-04]Training epoch 11:  22%|██▏       | 25/112 [00:00<00:01, 56.25it/s, Epoch: 11, Batch: 26,Loss: -0.755,Avg.Loss: -0.548,LR: 4.87E-04]Training epoch 11:  23%|██▎       | 26/112 [00:00<00:01, 54.25it/s, Epoch: 11, Batch: 26,Loss: -0.755,Avg.Loss: -0.548,LR: 4.87E-04]Training epoch 11:  23%|██▎       | 26/112 [00:00<00:01, 54.25it/s, Epoch: 11, Batch: 27,Loss: -0.837,Avg.Loss: -0.559,LR: 4.87E-04]Training epoch 11:  24%|██▍       | 27/112 [00:00<00:01, 54.25it/s, Epoch: 11, Batch: 28,Loss: -0.536,Avg.Loss: -0.558,LR: 4.87E-04]Training epoch 11:  25%|██▌       | 28/112 [00:00<00:01, 54.25it/s, Epoch: 11, Batch: 29,Loss: 0.785,Avg.Loss: -0.512,LR: 4.87E-04] Training epoch 11:  26%|██▌       | 29/112 [00:00<00:01, 54.25it/s, Epoch: 11, Batch: 30,Loss: -0.336,Avg.Loss: -0.506,LR: 4.87E-04]Training epoch 11:  27%|██▋       | 30/112 [00:00<00:01, 54.25it/s, Epoch: 11, Batch: 31,Loss: -0.799,Avg.Loss: -0.515,LR: 4.87E-04]Training epoch 11:  28%|██▊       | 31/112 [00:00<00:01, 54.25it/s, Epoch: 11, Batch: 32,Loss: -0.863,Avg.Loss: -0.526,LR: 4.87E-04]Training epoch 11:  29%|██▊       | 32/112 [00:00<00:01, 53.81it/s, Epoch: 11, Batch: 32,Loss: -0.863,Avg.Loss: -0.526,LR: 4.87E-04]Training epoch 11:  29%|██▊       | 32/112 [00:00<00:01, 53.81it/s, Epoch: 11, Batch: 33,Loss: -1.155,Avg.Loss: -0.545,LR: 4.87E-04]Training epoch 11:  29%|██▉       | 33/112 [00:00<00:01, 53.81it/s, Epoch: 11, Batch: 34,Loss: -0.317,Avg.Loss: -0.538,LR: 4.87E-04]Training epoch 11:  30%|███       | 34/112 [00:00<00:01, 53.81it/s, Epoch: 11, Batch: 35,Loss: -0.458,Avg.Loss: -0.536,LR: 4.87E-04]Training epoch 11:  31%|███▏      | 35/112 [00:00<00:01, 53.81it/s, Epoch: 11, Batch: 36,Loss: -0.813,Avg.Loss: -0.544,LR: 4.87E-04]Training epoch 11:  32%|███▏      | 36/112 [00:00<00:01, 53.81it/s, Epoch: 11, Batch: 37,Loss: -0.456,Avg.Loss: -0.541,LR: 4.87E-04]Training epoch 11:  33%|███▎      | 37/112 [00:00<00:01, 53.81it/s, Epoch: 11, Batch: 38,Loss: -0.103,Avg.Loss: -0.530,LR: 4.87E-04]Training epoch 11:  34%|███▍      | 38/112 [00:00<00:01, 53.54it/s, Epoch: 11, Batch: 38,Loss: -0.103,Avg.Loss: -0.530,LR: 4.87E-04]Training epoch 11:  34%|███▍      | 38/112 [00:00<00:01, 53.54it/s, Epoch: 11, Batch: 39,Loss: -0.689,Avg.Loss: -0.534,LR: 4.87E-04]Training epoch 11:  35%|███▍      | 39/112 [00:00<00:01, 53.54it/s, Epoch: 11, Batch: 40,Loss: -0.122,Avg.Loss: -0.524,LR: 4.87E-04]Training epoch 11:  36%|███▌      | 40/112 [00:00<00:01, 53.54it/s, Epoch: 11, Batch: 41,Loss: 0.662,Avg.Loss: -0.495,LR: 4.87E-04] Training epoch 11:  37%|███▋      | 41/112 [00:00<00:01, 53.54it/s, Epoch: 11, Batch: 42,Loss: -0.504,Avg.Loss: -0.495,LR: 4.87E-04]Training epoch 11:  38%|███▊      | 42/112 [00:00<00:01, 53.54it/s, Epoch: 11, Batch: 43,Loss: -0.410,Avg.Loss: -0.493,LR: 4.87E-04]Training epoch 11:  38%|███▊      | 43/112 [00:00<00:01, 53.54it/s, Epoch: 11, Batch: 44,Loss: -0.072,Avg.Loss: -0.483,LR: 4.87E-04]Training epoch 11:  39%|███▉      | 44/112 [00:00<00:01, 53.25it/s, Epoch: 11, Batch: 44,Loss: -0.072,Avg.Loss: -0.483,LR: 4.87E-04]Training epoch 11:  39%|███▉      | 44/112 [00:00<00:01, 53.25it/s, Epoch: 11, Batch: 45,Loss: -0.748,Avg.Loss: -0.489,LR: 4.87E-04]Training epoch 11:  40%|████      | 45/112 [00:00<00:01, 53.25it/s, Epoch: 11, Batch: 46,Loss: -0.351,Avg.Loss: -0.486,LR: 4.87E-04]Training epoch 11:  41%|████      | 46/112 [00:00<00:01, 53.25it/s, Epoch: 11, Batch: 47,Loss: 0.188,Avg.Loss: -0.472,LR: 4.87E-04] Training epoch 11:  42%|████▏     | 47/112 [00:00<00:01, 53.25it/s, Epoch: 11, Batch: 48,Loss: -0.783,Avg.Loss: -0.478,LR: 4.87E-04]Training epoch 11:  43%|████▎     | 48/112 [00:00<00:01, 53.25it/s, Epoch: 11, Batch: 49,Loss: -0.951,Avg.Loss: -0.488,LR: 4.87E-04]Training epoch 11:  44%|████▍     | 49/112 [00:00<00:01, 53.25it/s, Epoch: 11, Batch: 50,Loss: -0.549,Avg.Loss: -0.489,LR: 4.87E-04]Training epoch 11:  45%|████▍     | 50/112 [00:00<00:01, 53.11it/s, Epoch: 11, Batch: 50,Loss: -0.549,Avg.Loss: -0.489,LR: 4.87E-04]Training epoch 11:  45%|████▍     | 50/112 [00:00<00:01, 53.11it/s, Epoch: 11, Batch: 51,Loss: -0.653,Avg.Loss: -0.493,LR: 4.87E-04]Training epoch 11:  46%|████▌     | 51/112 [00:00<00:01, 53.11it/s, Epoch: 11, Batch: 52,Loss: -0.713,Avg.Loss: -0.497,LR: 4.87E-04]Training epoch 11:  46%|████▋     | 52/112 [00:00<00:01, 53.11it/s, Epoch: 11, Batch: 53,Loss: -0.298,Avg.Loss: -0.493,LR: 4.87E-04]Training epoch 11:  47%|████▋     | 53/112 [00:00<00:01, 53.11it/s, Epoch: 11, Batch: 54,Loss: -0.624,Avg.Loss: -0.495,LR: 4.87E-04]Training epoch 11:  48%|████▊     | 54/112 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 55,Loss: -0.500,Avg.Loss: -0.496,LR: 4.87E-04]Training epoch 11:  49%|████▉     | 55/112 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 56,Loss: -0.236,Avg.Loss: -0.491,LR: 4.87E-04]Training epoch 11:  50%|█████     | 56/112 [00:01<00:01, 52.98it/s, Epoch: 11, Batch: 56,Loss: -0.236,Avg.Loss: -0.491,LR: 4.87E-04]Training epoch 11:  50%|█████     | 56/112 [00:01<00:01, 52.98it/s, Epoch: 11, Batch: 57,Loss: -0.194,Avg.Loss: -0.486,LR: 4.86E-04]Training epoch 11:  51%|█████     | 57/112 [00:01<00:01, 52.98it/s, Epoch: 11, Batch: 58,Loss: -0.706,Avg.Loss: -0.489,LR: 4.86E-04]Training epoch 11:  52%|█████▏    | 58/112 [00:01<00:01, 52.98it/s, Epoch: 11, Batch: 59,Loss: -0.632,Avg.Loss: -0.492,LR: 4.86E-04]Training epoch 11:  53%|█████▎    | 59/112 [00:01<00:01, 52.98it/s, Epoch: 11, Batch: 60,Loss: -0.860,Avg.Loss: -0.498,LR: 4.86E-04]Training epoch 11:  54%|█████▎    | 60/112 [00:01<00:00, 52.98it/s, Epoch: 11, Batch: 61,Loss: -0.632,Avg.Loss: -0.500,LR: 4.86E-04]Training epoch 11:  54%|█████▍    | 61/112 [00:01<00:00, 52.98it/s, Epoch: 11, Batch: 62,Loss: -0.299,Avg.Loss: -0.497,LR: 4.86E-04]Training epoch 11:  55%|█████▌    | 62/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 62,Loss: -0.299,Avg.Loss: -0.497,LR: 4.86E-04]Training epoch 11:  55%|█████▌    | 62/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 63,Loss: -0.774,Avg.Loss: -0.501,LR: 4.86E-04]Training epoch 11:  56%|█████▋    | 63/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 64,Loss: -1.003,Avg.Loss: -0.509,LR: 4.86E-04]Training epoch 11:  57%|█████▋    | 64/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 65,Loss: -0.845,Avg.Loss: -0.514,LR: 4.86E-04]Training epoch 11:  58%|█████▊    | 65/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 66,Loss: -1.222,Avg.Loss: -0.525,LR: 4.86E-04]Training epoch 11:  59%|█████▉    | 66/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 67,Loss: -0.321,Avg.Loss: -0.522,LR: 4.86E-04]Training epoch 11:  60%|█████▉    | 67/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 68,Loss: -0.524,Avg.Loss: -0.522,LR: 4.86E-04]Training epoch 11:  61%|██████    | 68/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 68,Loss: -0.524,Avg.Loss: -0.522,LR: 4.86E-04]Training epoch 11:  61%|██████    | 68/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 69,Loss: -0.940,Avg.Loss: -0.528,LR: 4.86E-04]Training epoch 11:  62%|██████▏   | 69/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 70,Loss: -0.498,Avg.Loss: -0.528,LR: 4.86E-04]Training epoch 11:  62%|██████▎   | 70/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 71,Loss: -0.056,Avg.Loss: -0.521,LR: 4.86E-04]Training epoch 11:  63%|██████▎   | 71/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 72,Loss: -0.384,Avg.Loss: -0.519,LR: 4.86E-04]Training epoch 11:  64%|██████▍   | 72/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 73,Loss: -1.119,Avg.Loss: -0.527,LR: 4.86E-04]Training epoch 11:  65%|██████▌   | 73/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 74,Loss: -1.006,Avg.Loss: -0.534,LR: 4.86E-04]Training epoch 11:  66%|██████▌   | 74/112 [00:01<00:00, 52.85it/s, Epoch: 11, Batch: 74,Loss: -1.006,Avg.Loss: -0.534,LR: 4.86E-04]Training epoch 11:  66%|██████▌   | 74/112 [00:01<00:00, 52.85it/s, Epoch: 11, Batch: 75,Loss: -1.242,Avg.Loss: -0.543,LR: 4.86E-04]Training epoch 11:  67%|██████▋   | 75/112 [00:01<00:00, 52.85it/s, Epoch: 11, Batch: 76,Loss: -0.386,Avg.Loss: -0.541,LR: 4.86E-04]Training epoch 11:  68%|██████▊   | 76/112 [00:01<00:00, 52.85it/s, Epoch: 11, Batch: 77,Loss: 0.166,Avg.Loss: -0.532,LR: 4.86E-04] Training epoch 11:  69%|██████▉   | 77/112 [00:01<00:00, 52.85it/s, Epoch: 11, Batch: 78,Loss: -0.752,Avg.Loss: -0.535,LR: 4.86E-04]Training epoch 11:  70%|██████▉   | 78/112 [00:01<00:00, 52.85it/s, Epoch: 11, Batch: 79,Loss: -1.054,Avg.Loss: -0.541,LR: 4.86E-04]Training epoch 11:  71%|███████   | 79/112 [00:01<00:00, 52.85it/s, Epoch: 11, Batch: 80,Loss: -0.872,Avg.Loss: -0.546,LR: 4.86E-04]Training epoch 11:  71%|███████▏  | 80/112 [00:01<00:00, 52.81it/s, Epoch: 11, Batch: 80,Loss: -0.872,Avg.Loss: -0.546,LR: 4.86E-04]Training epoch 11:  71%|███████▏  | 80/112 [00:01<00:00, 52.81it/s, Epoch: 11, Batch: 81,Loss: -1.428,Avg.Loss: -0.556,LR: 4.86E-04]Training epoch 11:  72%|███████▏  | 81/112 [00:01<00:00, 52.81it/s, Epoch: 11, Batch: 82,Loss: -0.185,Avg.Loss: -0.552,LR: 4.86E-04]Training epoch 11:  73%|███████▎  | 82/112 [00:01<00:00, 52.81it/s, Epoch: 11, Batch: 83,Loss: 0.892,Avg.Loss: -0.535,LR: 4.86E-04] Training epoch 11:  74%|███████▍  | 83/112 [00:01<00:00, 52.81it/s, Epoch: 11, Batch: 84,Loss: -0.327,Avg.Loss: -0.532,LR: 4.86E-04]Training epoch 11:  75%|███████▌  | 84/112 [00:01<00:00, 52.81it/s, Epoch: 11, Batch: 85,Loss: -0.728,Avg.Loss: -0.534,LR: 4.86E-04]Training epoch 11:  76%|███████▌  | 85/112 [00:01<00:00, 52.81it/s, Epoch: 11, Batch: 86,Loss: -0.153,Avg.Loss: -0.530,LR: 4.86E-04]Training epoch 11:  77%|███████▋  | 86/112 [00:01<00:00, 52.88it/s, Epoch: 11, Batch: 86,Loss: -0.153,Avg.Loss: -0.530,LR: 4.86E-04]Training epoch 11:  77%|███████▋  | 86/112 [00:01<00:00, 52.88it/s, Epoch: 11, Batch: 87,Loss: -0.784,Avg.Loss: -0.533,LR: 4.86E-04]Training epoch 11:  78%|███████▊  | 87/112 [00:01<00:00, 52.88it/s, Epoch: 11, Batch: 88,Loss: -0.821,Avg.Loss: -0.536,LR: 4.86E-04]Training epoch 11:  79%|███████▊  | 88/112 [00:01<00:00, 52.88it/s, Epoch: 11, Batch: 89,Loss: -0.624,Avg.Loss: -0.537,LR: 4.86E-04]Training epoch 11:  79%|███████▉  | 89/112 [00:01<00:00, 52.88it/s, Epoch: 11, Batch: 90,Loss: -0.622,Avg.Loss: -0.538,LR: 4.86E-04]Training epoch 11:  80%|████████  | 90/112 [00:01<00:00, 52.88it/s, Epoch: 11, Batch: 91,Loss: -0.574,Avg.Loss: -0.538,LR: 4.86E-04]Training epoch 11:  81%|████████▏ | 91/112 [00:01<00:00, 52.88it/s, Epoch: 11, Batch: 92,Loss: -0.400,Avg.Loss: -0.537,LR: 4.86E-04]Training epoch 11:  82%|████████▏ | 92/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 92,Loss: -0.400,Avg.Loss: -0.537,LR: 4.86E-04]Training epoch 11:  82%|████████▏ | 92/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 93,Loss: -1.080,Avg.Loss: -0.543,LR: 4.86E-04]Training epoch 11:  83%|████████▎ | 93/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 94,Loss: -1.282,Avg.Loss: -0.551,LR: 4.86E-04]Training epoch 11:  84%|████████▍ | 94/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 95,Loss: -0.634,Avg.Loss: -0.552,LR: 4.86E-04]Training epoch 11:  85%|████████▍ | 95/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 96,Loss: -0.261,Avg.Loss: -0.548,LR: 4.86E-04]Training epoch 11:  86%|████████▌ | 96/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 97,Loss: -1.425,Avg.Loss: -0.558,LR: 4.86E-04]Training epoch 11:  87%|████████▋ | 97/112 [00:01<00:00, 52.90it/s, Epoch: 11, Batch: 98,Loss: -0.587,Avg.Loss: -0.558,LR: 4.86E-04]Training epoch 11:  88%|████████▊ | 98/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 98,Loss: -0.587,Avg.Loss: -0.558,LR: 4.86E-04]Training epoch 11:  88%|████████▊ | 98/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 99,Loss: -0.503,Avg.Loss: -0.557,LR: 4.86E-04]Training epoch 11:  88%|████████▊ | 99/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 100,Loss: -1.038,Avg.Loss: -0.562,LR: 4.86E-04]Training epoch 11:  89%|████████▉ | 100/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 101,Loss: -0.554,Avg.Loss: -0.562,LR: 4.85E-04]Training epoch 11:  90%|█████████ | 101/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 102,Loss: -0.606,Avg.Loss: -0.562,LR: 4.85E-04]Training epoch 11:  91%|█████████ | 102/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 103,Loss: -0.789,Avg.Loss: -0.565,LR: 4.85E-04]Training epoch 11:  92%|█████████▏| 103/112 [00:01<00:00, 52.86it/s, Epoch: 11, Batch: 104,Loss: -0.377,Avg.Loss: -0.563,LR: 4.85E-04]Training epoch 11:  93%|█████████▎| 104/112 [00:01<00:00, 52.92it/s, Epoch: 11, Batch: 104,Loss: -0.377,Avg.Loss: -0.563,LR: 4.85E-04]Training epoch 11:  93%|█████████▎| 104/112 [00:01<00:00, 52.92it/s, Epoch: 11, Batch: 105,Loss: -0.943,Avg.Loss: -0.566,LR: 4.85E-04]Training epoch 11:  94%|█████████▍| 105/112 [00:01<00:00, 52.92it/s, Epoch: 11, Batch: 106,Loss: -0.911,Avg.Loss: -0.570,LR: 4.85E-04]Training epoch 11:  95%|█████████▍| 106/112 [00:01<00:00, 52.92it/s, Epoch: 11, Batch: 107,Loss: -0.985,Avg.Loss: -0.574,LR: 4.85E-04]Training epoch 11:  96%|█████████▌| 107/112 [00:02<00:00, 52.92it/s, Epoch: 11, Batch: 108,Loss: -1.095,Avg.Loss: -0.578,LR: 4.85E-04]Training epoch 11:  96%|█████████▋| 108/112 [00:02<00:00, 52.92it/s, Epoch: 11, Batch: 109,Loss: -1.280,Avg.Loss: -0.585,LR: 4.85E-04]Training epoch 11:  97%|█████████▋| 109/112 [00:02<00:00, 52.92it/s, Epoch: 11, Batch: 110,Loss: -1.012,Avg.Loss: -0.589,LR: 4.85E-04]Training epoch 11:  98%|█████████▊| 110/112 [00:02<00:00, 52.94it/s, Epoch: 11, Batch: 110,Loss: -1.012,Avg.Loss: -0.589,LR: 4.85E-04]Training epoch 11:  98%|█████████▊| 110/112 [00:02<00:00, 52.94it/s, Epoch: 11, Batch: 111,Loss: -0.882,Avg.Loss: -0.591,LR: 4.85E-04]Training epoch 11:  99%|█████████▉| 111/112 [00:02<00:00, 52.94it/s, Epoch: 11, Batch: 112,Loss: -0.807,Avg.Loss: -0.593,LR: 4.85E-04]Training epoch 11: 100%|██████████| 112/112 [00:02<00:00, 53.42it/s, Epoch: 11, Batch: 112,Loss: -0.807,Avg.Loss: -0.593,LR: 4.85E-04]
Training epoch 12:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 12:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 12, Batch: 1,Loss: -1.161,Avg.Loss: -1.161,LR: 4.85E-04]Training epoch 12:   1%|          | 1/112 [00:00<00:04, 26.02it/s, Epoch: 12, Batch: 2,Loss: -1.377,Avg.Loss: -1.269,LR: 4.85E-04]Training epoch 12:   2%|▏         | 2/112 [00:00<00:02, 36.79it/s, Epoch: 12, Batch: 3,Loss: -0.819,Avg.Loss: -1.119,LR: 4.85E-04]Training epoch 12:   3%|▎         | 3/112 [00:00<00:02, 43.26it/s, Epoch: 12, Batch: 4,Loss: -0.514,Avg.Loss: -0.968,LR: 4.85E-04]Training epoch 12:   4%|▎         | 4/112 [00:00<00:02, 47.49it/s, Epoch: 12, Batch: 5,Loss: -1.123,Avg.Loss: -0.999,LR: 4.85E-04]Training epoch 12:   4%|▍         | 5/112 [00:00<00:02, 50.88it/s, Epoch: 12, Batch: 6,Loss: -0.889,Avg.Loss: -0.981,LR: 4.85E-04]Training epoch 12:   5%|▌         | 6/112 [00:00<00:02, 51.85it/s, Epoch: 12, Batch: 7,Loss: -0.949,Avg.Loss: -0.976,LR: 4.85E-04]Training epoch 12:   6%|▋         | 7/112 [00:00<00:01, 60.42it/s, Epoch: 12, Batch: 7,Loss: -0.949,Avg.Loss: -0.976,LR: 4.85E-04]Training epoch 12:   6%|▋         | 7/112 [00:00<00:01, 60.42it/s, Epoch: 12, Batch: 8,Loss: -1.218,Avg.Loss: -1.006,LR: 4.85E-04]Training epoch 12:   7%|▋         | 8/112 [00:00<00:01, 60.42it/s, Epoch: 12, Batch: 9,Loss: -1.308,Avg.Loss: -1.040,LR: 4.85E-04]Training epoch 12:   8%|▊         | 9/112 [00:00<00:01, 60.42it/s, Epoch: 12, Batch: 10,Loss: -0.936,Avg.Loss: -1.030,LR: 4.85E-04]Training epoch 12:   9%|▉         | 10/112 [00:00<00:01, 60.42it/s, Epoch: 12, Batch: 11,Loss: -0.310,Avg.Loss: -0.964,LR: 4.85E-04]Training epoch 12:  10%|▉         | 11/112 [00:00<00:01, 60.42it/s, Epoch: 12, Batch: 12,Loss: -0.201,Avg.Loss: -0.901,LR: 4.85E-04]Training epoch 12:  11%|█         | 12/112 [00:00<00:01, 60.42it/s, Epoch: 12, Batch: 13,Loss: -0.184,Avg.Loss: -0.845,LR: 4.85E-04]Training epoch 12:  12%|█▏        | 13/112 [00:00<00:01, 60.42it/s, Epoch: 12, Batch: 14,Loss: -0.666,Avg.Loss: -0.833,LR: 4.85E-04]Training epoch 12:  12%|█▎        | 14/112 [00:00<00:01, 57.62it/s, Epoch: 12, Batch: 14,Loss: -0.666,Avg.Loss: -0.833,LR: 4.85E-04]Training epoch 12:  12%|█▎        | 14/112 [00:00<00:01, 57.62it/s, Epoch: 12, Batch: 15,Loss: -0.647,Avg.Loss: -0.820,LR: 4.85E-04]Training epoch 12:  13%|█▎        | 15/112 [00:00<00:01, 57.62it/s, Epoch: 12, Batch: 16,Loss: -0.879,Avg.Loss: -0.824,LR: 4.85E-04]Training epoch 12:  14%|█▍        | 16/112 [00:00<00:01, 57.62it/s, Epoch: 12, Batch: 17,Loss: -1.184,Avg.Loss: -0.845,LR: 4.85E-04]Training epoch 12:  15%|█▌        | 17/112 [00:00<00:01, 57.62it/s, Epoch: 12, Batch: 18,Loss: -0.517,Avg.Loss: -0.827,LR: 4.85E-04]Training epoch 12:  16%|█▌        | 18/112 [00:00<00:01, 57.62it/s, Epoch: 12, Batch: 19,Loss: -0.246,Avg.Loss: -0.796,LR: 4.85E-04]Training epoch 12:  17%|█▋        | 19/112 [00:00<00:01, 57.62it/s, Epoch: 12, Batch: 20,Loss: -0.626,Avg.Loss: -0.788,LR: 4.85E-04]Training epoch 12:  18%|█▊        | 20/112 [00:00<00:01, 55.50it/s, Epoch: 12, Batch: 20,Loss: -0.626,Avg.Loss: -0.788,LR: 4.85E-04]Training epoch 12:  18%|█▊        | 20/112 [00:00<00:01, 55.50it/s, Epoch: 12, Batch: 21,Loss: 0.292,Avg.Loss: -0.736,LR: 4.85E-04] Training epoch 12:  19%|█▉        | 21/112 [00:00<00:01, 55.50it/s, Epoch: 12, Batch: 22,Loss: 0.306,Avg.Loss: -0.689,LR: 4.85E-04]Training epoch 12:  20%|█▉        | 22/112 [00:00<00:01, 55.50it/s, Epoch: 12, Batch: 23,Loss: -0.674,Avg.Loss: -0.688,LR: 4.85E-04]Training epoch 12:  21%|██        | 23/112 [00:00<00:01, 55.50it/s, Epoch: 12, Batch: 24,Loss: -0.585,Avg.Loss: -0.684,LR: 4.85E-04]Training epoch 12:  21%|██▏       | 24/112 [00:00<00:01, 55.50it/s, Epoch: 12, Batch: 25,Loss: 0.069,Avg.Loss: -0.654,LR: 4.85E-04] Training epoch 12:  22%|██▏       | 25/112 [00:00<00:01, 55.50it/s, Epoch: 12, Batch: 26,Loss: 0.062,Avg.Loss: -0.626,LR: 4.85E-04]Training epoch 12:  23%|██▎       | 26/112 [00:00<00:01, 53.71it/s, Epoch: 12, Batch: 26,Loss: 0.062,Avg.Loss: -0.626,LR: 4.85E-04]Training epoch 12:  23%|██▎       | 26/112 [00:00<00:01, 53.71it/s, Epoch: 12, Batch: 27,Loss: -1.280,Avg.Loss: -0.651,LR: 4.85E-04]Training epoch 12:  24%|██▍       | 27/112 [00:00<00:01, 53.71it/s, Epoch: 12, Batch: 28,Loss: -1.195,Avg.Loss: -0.670,LR: 4.85E-04]Training epoch 12:  25%|██▌       | 28/112 [00:00<00:01, 53.71it/s, Epoch: 12, Batch: 29,Loss: -1.067,Avg.Loss: -0.684,LR: 4.85E-04]Training epoch 12:  26%|██▌       | 29/112 [00:00<00:01, 53.71it/s, Epoch: 12, Batch: 30,Loss: -1.217,Avg.Loss: -0.702,LR: 4.84E-04]Training epoch 12:  27%|██▋       | 30/112 [00:00<00:01, 53.71it/s, Epoch: 12, Batch: 31,Loss: -1.003,Avg.Loss: -0.711,LR: 4.84E-04]Training epoch 12:  28%|██▊       | 31/112 [00:00<00:01, 53.71it/s, Epoch: 12, Batch: 32,Loss: -1.225,Avg.Loss: -0.727,LR: 4.84E-04]Training epoch 12:  29%|██▊       | 32/112 [00:00<00:01, 52.95it/s, Epoch: 12, Batch: 32,Loss: -1.225,Avg.Loss: -0.727,LR: 4.84E-04]Training epoch 12:  29%|██▊       | 32/112 [00:00<00:01, 52.95it/s, Epoch: 12, Batch: 33,Loss: -0.486,Avg.Loss: -0.720,LR: 4.84E-04]Training epoch 12:  29%|██▉       | 33/112 [00:00<00:01, 52.95it/s, Epoch: 12, Batch: 34,Loss: 0.576,Avg.Loss: -0.682,LR: 4.84E-04] Training epoch 12:  30%|███       | 34/112 [00:00<00:01, 52.95it/s, Epoch: 12, Batch: 35,Loss: -0.749,Avg.Loss: -0.684,LR: 4.84E-04]Training epoch 12:  31%|███▏      | 35/112 [00:00<00:01, 52.95it/s, Epoch: 12, Batch: 36,Loss: -0.404,Avg.Loss: -0.676,LR: 4.84E-04]Training epoch 12:  32%|███▏      | 36/112 [00:00<00:01, 52.95it/s, Epoch: 12, Batch: 37,Loss: 1.443,Avg.Loss: -0.619,LR: 4.84E-04] Training epoch 12:  33%|███▎      | 37/112 [00:00<00:01, 52.95it/s, Epoch: 12, Batch: 38,Loss: -0.209,Avg.Loss: -0.608,LR: 4.84E-04]Training epoch 12:  34%|███▍      | 38/112 [00:00<00:01, 52.78it/s, Epoch: 12, Batch: 38,Loss: -0.209,Avg.Loss: -0.608,LR: 4.84E-04]Training epoch 12:  34%|███▍      | 38/112 [00:00<00:01, 52.78it/s, Epoch: 12, Batch: 39,Loss: -0.877,Avg.Loss: -0.615,LR: 4.84E-04]Training epoch 12:  35%|███▍      | 39/112 [00:00<00:01, 52.78it/s, Epoch: 12, Batch: 40,Loss: -0.117,Avg.Loss: -0.602,LR: 4.84E-04]Training epoch 12:  36%|███▌      | 40/112 [00:00<00:01, 52.78it/s, Epoch: 12, Batch: 41,Loss: -0.882,Avg.Loss: -0.609,LR: 4.84E-04]Training epoch 12:  37%|███▋      | 41/112 [00:00<00:01, 52.78it/s, Epoch: 12, Batch: 42,Loss: -0.434,Avg.Loss: -0.605,LR: 4.84E-04]Training epoch 12:  38%|███▊      | 42/112 [00:00<00:01, 52.78it/s, Epoch: 12, Batch: 43,Loss: 1.336,Avg.Loss: -0.560,LR: 4.84E-04] Training epoch 12:  38%|███▊      | 43/112 [00:00<00:01, 52.78it/s, Epoch: 12, Batch: 44,Loss: -0.745,Avg.Loss: -0.564,LR: 4.84E-04]Training epoch 12:  39%|███▉      | 44/112 [00:00<00:01, 52.72it/s, Epoch: 12, Batch: 44,Loss: -0.745,Avg.Loss: -0.564,LR: 4.84E-04]Training epoch 12:  39%|███▉      | 44/112 [00:00<00:01, 52.72it/s, Epoch: 12, Batch: 45,Loss: -0.962,Avg.Loss: -0.573,LR: 4.84E-04]Training epoch 12:  40%|████      | 45/112 [00:00<00:01, 52.72it/s, Epoch: 12, Batch: 46,Loss: -0.607,Avg.Loss: -0.574,LR: 4.84E-04]Training epoch 12:  41%|████      | 46/112 [00:00<00:01, 52.72it/s, Epoch: 12, Batch: 47,Loss: -1.405,Avg.Loss: -0.591,LR: 4.84E-04]Training epoch 12:  42%|████▏     | 47/112 [00:00<00:01, 52.72it/s, Epoch: 12, Batch: 48,Loss: -0.531,Avg.Loss: -0.590,LR: 4.84E-04]Training epoch 12:  43%|████▎     | 48/112 [00:00<00:01, 52.72it/s, Epoch: 12, Batch: 49,Loss: -0.187,Avg.Loss: -0.582,LR: 4.84E-04]Training epoch 12:  44%|████▍     | 49/112 [00:00<00:01, 52.72it/s, Epoch: 12, Batch: 50,Loss: -0.658,Avg.Loss: -0.583,LR: 4.84E-04]Training epoch 12:  45%|████▍     | 50/112 [00:00<00:01, 52.73it/s, Epoch: 12, Batch: 50,Loss: -0.658,Avg.Loss: -0.583,LR: 4.84E-04]Training epoch 12:  45%|████▍     | 50/112 [00:00<00:01, 52.73it/s, Epoch: 12, Batch: 51,Loss: -0.408,Avg.Loss: -0.580,LR: 4.84E-04]Training epoch 12:  46%|████▌     | 51/112 [00:00<00:01, 52.73it/s, Epoch: 12, Batch: 52,Loss: -0.042,Avg.Loss: -0.570,LR: 4.84E-04]Training epoch 12:  46%|████▋     | 52/112 [00:00<00:01, 52.73it/s, Epoch: 12, Batch: 53,Loss: -0.833,Avg.Loss: -0.575,LR: 4.84E-04]Training epoch 12:  47%|████▋     | 53/112 [00:01<00:01, 52.73it/s, Epoch: 12, Batch: 54,Loss: -1.084,Avg.Loss: -0.584,LR: 4.84E-04]Training epoch 12:  48%|████▊     | 54/112 [00:01<00:01, 52.73it/s, Epoch: 12, Batch: 55,Loss: -0.896,Avg.Loss: -0.590,LR: 4.84E-04]Training epoch 12:  49%|████▉     | 55/112 [00:01<00:01, 52.73it/s, Epoch: 12, Batch: 56,Loss: -1.375,Avg.Loss: -0.604,LR: 4.84E-04]Training epoch 12:  50%|█████     | 56/112 [00:01<00:01, 52.77it/s, Epoch: 12, Batch: 56,Loss: -1.375,Avg.Loss: -0.604,LR: 4.84E-04]Training epoch 12:  50%|█████     | 56/112 [00:01<00:01, 52.77it/s, Epoch: 12, Batch: 57,Loss: -0.858,Avg.Loss: -0.608,LR: 4.84E-04]Training epoch 12:  51%|█████     | 57/112 [00:01<00:01, 52.77it/s, Epoch: 12, Batch: 58,Loss: 0.141,Avg.Loss: -0.595,LR: 4.84E-04] Training epoch 12:  52%|█████▏    | 58/112 [00:01<00:01, 52.77it/s, Epoch: 12, Batch: 59,Loss: -1.017,Avg.Loss: -0.602,LR: 4.84E-04]Training epoch 12:  53%|█████▎    | 59/112 [00:01<00:01, 52.77it/s, Epoch: 12, Batch: 60,Loss: -0.872,Avg.Loss: -0.607,LR: 4.84E-04]Training epoch 12:  54%|█████▎    | 60/112 [00:01<00:00, 52.77it/s, Epoch: 12, Batch: 61,Loss: -0.661,Avg.Loss: -0.608,LR: 4.84E-04]Training epoch 12:  54%|█████▍    | 61/112 [00:01<00:00, 52.77it/s, Epoch: 12, Batch: 62,Loss: -1.317,Avg.Loss: -0.619,LR: 4.84E-04]Training epoch 12:  55%|█████▌    | 62/112 [00:01<00:00, 52.79it/s, Epoch: 12, Batch: 62,Loss: -1.317,Avg.Loss: -0.619,LR: 4.84E-04]Training epoch 12:  55%|█████▌    | 62/112 [00:01<00:00, 52.79it/s, Epoch: 12, Batch: 63,Loss: -0.682,Avg.Loss: -0.620,LR: 4.84E-04]Training epoch 12:  56%|█████▋    | 63/112 [00:01<00:00, 52.79it/s, Epoch: 12, Batch: 64,Loss: -0.130,Avg.Loss: -0.613,LR: 4.84E-04]Training epoch 12:  57%|█████▋    | 64/112 [00:01<00:00, 52.79it/s, Epoch: 12, Batch: 65,Loss: -1.014,Avg.Loss: -0.619,LR: 4.84E-04]Training epoch 12:  58%|█████▊    | 65/112 [00:01<00:00, 52.79it/s, Epoch: 12, Batch: 66,Loss: -1.236,Avg.Loss: -0.628,LR: 4.84E-04]Training epoch 12:  59%|█████▉    | 66/112 [00:01<00:00, 52.79it/s, Epoch: 12, Batch: 67,Loss: -0.421,Avg.Loss: -0.625,LR: 4.84E-04]Training epoch 12:  60%|█████▉    | 67/112 [00:01<00:00, 52.79it/s, Epoch: 12, Batch: 68,Loss: -1.439,Avg.Loss: -0.637,LR: 4.84E-04]Training epoch 12:  61%|██████    | 68/112 [00:01<00:00, 52.75it/s, Epoch: 12, Batch: 68,Loss: -1.439,Avg.Loss: -0.637,LR: 4.84E-04]Training epoch 12:  61%|██████    | 68/112 [00:01<00:00, 52.75it/s, Epoch: 12, Batch: 69,Loss: -0.595,Avg.Loss: -0.636,LR: 4.84E-04]Training epoch 12:  62%|██████▏   | 69/112 [00:01<00:00, 52.75it/s, Epoch: 12, Batch: 70,Loss: -0.325,Avg.Loss: -0.632,LR: 4.84E-04]Training epoch 12:  62%|██████▎   | 70/112 [00:01<00:00, 52.75it/s, Epoch: 12, Batch: 71,Loss: -1.140,Avg.Loss: -0.639,LR: 4.83E-04]Training epoch 12:  63%|██████▎   | 71/112 [00:01<00:00, 52.75it/s, Epoch: 12, Batch: 72,Loss: -0.495,Avg.Loss: -0.637,LR: 4.83E-04]Training epoch 12:  64%|██████▍   | 72/112 [00:01<00:00, 52.75it/s, Epoch: 12, Batch: 73,Loss: -0.707,Avg.Loss: -0.638,LR: 4.83E-04]Training epoch 12:  65%|██████▌   | 73/112 [00:01<00:00, 52.75it/s, Epoch: 12, Batch: 74,Loss: -1.194,Avg.Loss: -0.646,LR: 4.83E-04]Training epoch 12:  66%|██████▌   | 74/112 [00:01<00:00, 52.73it/s, Epoch: 12, Batch: 74,Loss: -1.194,Avg.Loss: -0.646,LR: 4.83E-04]Training epoch 12:  66%|██████▌   | 74/112 [00:01<00:00, 52.73it/s, Epoch: 12, Batch: 75,Loss: -1.027,Avg.Loss: -0.651,LR: 4.83E-04]Training epoch 12:  67%|██████▋   | 75/112 [00:01<00:00, 52.73it/s, Epoch: 12, Batch: 76,Loss: -0.461,Avg.Loss: -0.648,LR: 4.83E-04]Training epoch 12:  68%|██████▊   | 76/112 [00:01<00:00, 52.73it/s, Epoch: 12, Batch: 77,Loss: -1.280,Avg.Loss: -0.656,LR: 4.83E-04]Training epoch 12:  69%|██████▉   | 77/112 [00:01<00:00, 52.73it/s, Epoch: 12, Batch: 78,Loss: -1.224,Avg.Loss: -0.664,LR: 4.83E-04]Training epoch 12:  70%|██████▉   | 78/112 [00:01<00:00, 52.73it/s, Epoch: 12, Batch: 79,Loss: -0.437,Avg.Loss: -0.661,LR: 4.83E-04]Training epoch 12:  71%|███████   | 79/112 [00:01<00:00, 52.73it/s, Epoch: 12, Batch: 80,Loss: -1.270,Avg.Loss: -0.668,LR: 4.83E-04]Training epoch 12:  71%|███████▏  | 80/112 [00:01<00:00, 52.76it/s, Epoch: 12, Batch: 80,Loss: -1.270,Avg.Loss: -0.668,LR: 4.83E-04]Training epoch 12:  71%|███████▏  | 80/112 [00:01<00:00, 52.76it/s, Epoch: 12, Batch: 81,Loss: -0.808,Avg.Loss: -0.670,LR: 4.83E-04]Training epoch 12:  72%|███████▏  | 81/112 [00:01<00:00, 52.76it/s, Epoch: 12, Batch: 82,Loss: -0.739,Avg.Loss: -0.671,LR: 4.83E-04]Training epoch 12:  73%|███████▎  | 82/112 [00:01<00:00, 52.76it/s, Epoch: 12, Batch: 83,Loss: -1.100,Avg.Loss: -0.676,LR: 4.83E-04]Training epoch 12:  74%|███████▍  | 83/112 [00:01<00:00, 52.76it/s, Epoch: 12, Batch: 84,Loss: -0.783,Avg.Loss: -0.677,LR: 4.83E-04]Training epoch 12:  75%|███████▌  | 84/112 [00:01<00:00, 52.76it/s, Epoch: 12, Batch: 85,Loss: -0.308,Avg.Loss: -0.673,LR: 4.83E-04]Training epoch 12:  76%|███████▌  | 85/112 [00:01<00:00, 52.76it/s, Epoch: 12, Batch: 86,Loss: -1.181,Avg.Loss: -0.679,LR: 4.83E-04]Training epoch 12:  77%|███████▋  | 86/112 [00:01<00:00, 52.87it/s, Epoch: 12, Batch: 86,Loss: -1.181,Avg.Loss: -0.679,LR: 4.83E-04]Training epoch 12:  77%|███████▋  | 86/112 [00:01<00:00, 52.87it/s, Epoch: 12, Batch: 87,Loss: -1.013,Avg.Loss: -0.683,LR: 4.83E-04]Training epoch 12:  78%|███████▊  | 87/112 [00:01<00:00, 52.87it/s, Epoch: 12, Batch: 88,Loss: -0.818,Avg.Loss: -0.684,LR: 4.83E-04]Training epoch 12:  79%|███████▊  | 88/112 [00:01<00:00, 52.87it/s, Epoch: 12, Batch: 89,Loss: -1.007,Avg.Loss: -0.688,LR: 4.83E-04]Training epoch 12:  79%|███████▉  | 89/112 [00:01<00:00, 52.87it/s, Epoch: 12, Batch: 90,Loss: -0.719,Avg.Loss: -0.688,LR: 4.83E-04]Training epoch 12:  80%|████████  | 90/112 [00:01<00:00, 52.87it/s, Epoch: 12, Batch: 91,Loss: -0.103,Avg.Loss: -0.682,LR: 4.83E-04]Training epoch 12:  81%|████████▏ | 91/112 [00:01<00:00, 52.87it/s, Epoch: 12, Batch: 92,Loss: -1.041,Avg.Loss: -0.686,LR: 4.83E-04]Training epoch 12:  82%|████████▏ | 92/112 [00:01<00:00, 52.14it/s, Epoch: 12, Batch: 92,Loss: -1.041,Avg.Loss: -0.686,LR: 4.83E-04]Training epoch 12:  82%|████████▏ | 92/112 [00:01<00:00, 52.14it/s, Epoch: 12, Batch: 93,Loss: -0.943,Avg.Loss: -0.689,LR: 4.83E-04]Training epoch 12:  83%|████████▎ | 93/112 [00:01<00:00, 52.14it/s, Epoch: 12, Batch: 94,Loss: -0.728,Avg.Loss: -0.689,LR: 4.83E-04]Training epoch 12:  84%|████████▍ | 94/112 [00:01<00:00, 52.14it/s, Epoch: 12, Batch: 95,Loss: -1.100,Avg.Loss: -0.693,LR: 4.83E-04]Training epoch 12:  85%|████████▍ | 95/112 [00:01<00:00, 52.14it/s, Epoch: 12, Batch: 96,Loss: -0.761,Avg.Loss: -0.694,LR: 4.83E-04]Training epoch 12:  86%|████████▌ | 96/112 [00:01<00:00, 52.14it/s, Epoch: 12, Batch: 97,Loss: -0.187,Avg.Loss: -0.689,LR: 4.83E-04]Training epoch 12:  87%|████████▋ | 97/112 [00:01<00:00, 52.14it/s, Epoch: 12, Batch: 98,Loss: -1.107,Avg.Loss: -0.693,LR: 4.83E-04]Training epoch 12:  88%|████████▊ | 98/112 [00:01<00:00, 52.41it/s, Epoch: 12, Batch: 98,Loss: -1.107,Avg.Loss: -0.693,LR: 4.83E-04]Training epoch 12:  88%|████████▊ | 98/112 [00:01<00:00, 52.41it/s, Epoch: 12, Batch: 99,Loss: -1.056,Avg.Loss: -0.697,LR: 4.83E-04]Training epoch 12:  88%|████████▊ | 99/112 [00:01<00:00, 52.41it/s, Epoch: 12, Batch: 100,Loss: -0.311,Avg.Loss: -0.693,LR: 4.83E-04]Training epoch 12:  89%|████████▉ | 100/112 [00:01<00:00, 52.41it/s, Epoch: 12, Batch: 101,Loss: -1.200,Avg.Loss: -0.698,LR: 4.83E-04]Training epoch 12:  90%|█████████ | 101/112 [00:01<00:00, 52.41it/s, Epoch: 12, Batch: 102,Loss: -0.314,Avg.Loss: -0.694,LR: 4.83E-04]Training epoch 12:  91%|█████████ | 102/112 [00:01<00:00, 52.41it/s, Epoch: 12, Batch: 103,Loss: -0.491,Avg.Loss: -0.692,LR: 4.83E-04]Training epoch 12:  92%|█████████▏| 103/112 [00:01<00:00, 52.41it/s, Epoch: 12, Batch: 104,Loss: -0.979,Avg.Loss: -0.695,LR: 4.83E-04]Training epoch 12:  93%|█████████▎| 104/112 [00:01<00:00, 52.58it/s, Epoch: 12, Batch: 104,Loss: -0.979,Avg.Loss: -0.695,LR: 4.83E-04]Training epoch 12:  93%|█████████▎| 104/112 [00:01<00:00, 52.58it/s, Epoch: 12, Batch: 105,Loss: -1.052,Avg.Loss: -0.698,LR: 4.83E-04]Training epoch 12:  94%|█████████▍| 105/112 [00:01<00:00, 52.58it/s, Epoch: 12, Batch: 106,Loss: -0.740,Avg.Loss: -0.699,LR: 4.83E-04]Training epoch 12:  95%|█████████▍| 106/112 [00:02<00:00, 52.58it/s, Epoch: 12, Batch: 107,Loss: -0.983,Avg.Loss: -0.701,LR: 4.83E-04]Training epoch 12:  96%|█████████▌| 107/112 [00:02<00:00, 52.58it/s, Epoch: 12, Batch: 108,Loss: -0.880,Avg.Loss: -0.703,LR: 4.83E-04]Training epoch 12:  96%|█████████▋| 108/112 [00:02<00:00, 52.58it/s, Epoch: 12, Batch: 109,Loss: 0.138,Avg.Loss: -0.695,LR: 4.83E-04] Training epoch 12:  97%|█████████▋| 109/112 [00:02<00:00, 52.58it/s, Epoch: 12, Batch: 110,Loss: -0.987,Avg.Loss: -0.698,LR: 4.82E-04]Training epoch 12:  98%|█████████▊| 110/112 [00:02<00:00, 52.87it/s, Epoch: 12, Batch: 110,Loss: -0.987,Avg.Loss: -0.698,LR: 4.82E-04]Training epoch 12:  98%|█████████▊| 110/112 [00:02<00:00, 52.87it/s, Epoch: 12, Batch: 111,Loss: -0.981,Avg.Loss: -0.701,LR: 4.82E-04]Training epoch 12:  99%|█████████▉| 111/112 [00:02<00:00, 52.87it/s, Epoch: 12, Batch: 112,Loss: -1.316,Avg.Loss: -0.706,LR: 4.82E-04]Training epoch 12: 100%|██████████| 112/112 [00:02<00:00, 53.07it/s, Epoch: 12, Batch: 112,Loss: -1.316,Avg.Loss: -0.706,LR: 4.82E-04]
Training epoch 13:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 13:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 13, Batch: 1,Loss: -1.319,Avg.Loss: -1.319,LR: 4.82E-04]Training epoch 13:   1%|          | 1/112 [00:00<00:04, 25.93it/s, Epoch: 13, Batch: 2,Loss: -0.476,Avg.Loss: -0.898,LR: 4.82E-04]Training epoch 13:   2%|▏         | 2/112 [00:00<00:03, 34.51it/s, Epoch: 13, Batch: 3,Loss: -0.213,Avg.Loss: -0.669,LR: 4.82E-04]Training epoch 13:   3%|▎         | 3/112 [00:00<00:02, 41.42it/s, Epoch: 13, Batch: 4,Loss: -0.903,Avg.Loss: -0.728,LR: 4.82E-04]Training epoch 13:   4%|▎         | 4/112 [00:00<00:02, 45.91it/s, Epoch: 13, Batch: 5,Loss: -1.091,Avg.Loss: -0.800,LR: 4.82E-04]Training epoch 13:   4%|▍         | 5/112 [00:00<00:02, 49.37it/s, Epoch: 13, Batch: 6,Loss: -0.771,Avg.Loss: -0.796,LR: 4.82E-04]Training epoch 13:   5%|▌         | 6/112 [00:00<00:01, 59.16it/s, Epoch: 13, Batch: 6,Loss: -0.771,Avg.Loss: -0.796,LR: 4.82E-04]Training epoch 13:   5%|▌         | 6/112 [00:00<00:01, 59.16it/s, Epoch: 13, Batch: 7,Loss: -1.429,Avg.Loss: -0.886,LR: 4.82E-04]Training epoch 13:   6%|▋         | 7/112 [00:00<00:01, 59.16it/s, Epoch: 13, Batch: 8,Loss: -0.810,Avg.Loss: -0.877,LR: 4.82E-04]Training epoch 13:   7%|▋         | 8/112 [00:00<00:01, 59.16it/s, Epoch: 13, Batch: 9,Loss: -0.065,Avg.Loss: -0.786,LR: 4.82E-04]Training epoch 13:   8%|▊         | 9/112 [00:00<00:01, 59.16it/s, Epoch: 13, Batch: 10,Loss: -0.565,Avg.Loss: -0.764,LR: 4.82E-04]Training epoch 13:   9%|▉         | 10/112 [00:00<00:01, 59.16it/s, Epoch: 13, Batch: 11,Loss: -0.742,Avg.Loss: -0.762,LR: 4.82E-04]Training epoch 13:  10%|▉         | 11/112 [00:00<00:01, 59.16it/s, Epoch: 13, Batch: 12,Loss: -0.269,Avg.Loss: -0.721,LR: 4.82E-04]Training epoch 13:  11%|█         | 12/112 [00:00<00:01, 59.16it/s, Epoch: 13, Batch: 13,Loss: -1.019,Avg.Loss: -0.744,LR: 4.82E-04]Training epoch 13:  12%|█▏        | 13/112 [00:00<00:01, 60.47it/s, Epoch: 13, Batch: 13,Loss: -1.019,Avg.Loss: -0.744,LR: 4.82E-04]Training epoch 13:  12%|█▏        | 13/112 [00:00<00:01, 60.47it/s, Epoch: 13, Batch: 14,Loss: -1.056,Avg.Loss: -0.766,LR: 4.82E-04]Training epoch 13:  12%|█▎        | 14/112 [00:00<00:01, 60.47it/s, Epoch: 13, Batch: 15,Loss: -0.662,Avg.Loss: -0.759,LR: 4.82E-04]Training epoch 13:  13%|█▎        | 15/112 [00:00<00:01, 60.47it/s, Epoch: 13, Batch: 16,Loss: -1.386,Avg.Loss: -0.799,LR: 4.82E-04]Training epoch 13:  14%|█▍        | 16/112 [00:00<00:01, 60.47it/s, Epoch: 13, Batch: 17,Loss: -0.269,Avg.Loss: -0.767,LR: 4.82E-04]Training epoch 13:  15%|█▌        | 17/112 [00:00<00:01, 60.47it/s, Epoch: 13, Batch: 18,Loss: -0.223,Avg.Loss: -0.737,LR: 4.82E-04]Training epoch 13:  16%|█▌        | 18/112 [00:00<00:01, 60.47it/s, Epoch: 13, Batch: 19,Loss: -0.842,Avg.Loss: -0.743,LR: 4.82E-04]Training epoch 13:  17%|█▋        | 19/112 [00:00<00:01, 60.47it/s, Epoch: 13, Batch: 20,Loss: -1.124,Avg.Loss: -0.762,LR: 4.82E-04]Training epoch 13:  18%|█▊        | 20/112 [00:00<00:01, 56.30it/s, Epoch: 13, Batch: 20,Loss: -1.124,Avg.Loss: -0.762,LR: 4.82E-04]Training epoch 13:  18%|█▊        | 20/112 [00:00<00:01, 56.30it/s, Epoch: 13, Batch: 21,Loss: -0.896,Avg.Loss: -0.768,LR: 4.82E-04]Training epoch 13:  19%|█▉        | 21/112 [00:00<00:01, 56.30it/s, Epoch: 13, Batch: 22,Loss: -1.264,Avg.Loss: -0.791,LR: 4.82E-04]Training epoch 13:  20%|█▉        | 22/112 [00:00<00:01, 56.30it/s, Epoch: 13, Batch: 23,Loss: -1.011,Avg.Loss: -0.800,LR: 4.82E-04]Training epoch 13:  21%|██        | 23/112 [00:00<00:01, 56.30it/s, Epoch: 13, Batch: 24,Loss: -0.495,Avg.Loss: -0.788,LR: 4.82E-04]Training epoch 13:  21%|██▏       | 24/112 [00:00<00:01, 56.30it/s, Epoch: 13, Batch: 25,Loss: -1.336,Avg.Loss: -0.809,LR: 4.82E-04]Training epoch 13:  22%|██▏       | 25/112 [00:00<00:01, 56.30it/s, Epoch: 13, Batch: 26,Loss: -0.668,Avg.Loss: -0.804,LR: 4.82E-04]Training epoch 13:  23%|██▎       | 26/112 [00:00<00:01, 54.65it/s, Epoch: 13, Batch: 26,Loss: -0.668,Avg.Loss: -0.804,LR: 4.82E-04]Training epoch 13:  23%|██▎       | 26/112 [00:00<00:01, 54.65it/s, Epoch: 13, Batch: 27,Loss: 0.018,Avg.Loss: -0.774,LR: 4.82E-04] Training epoch 13:  24%|██▍       | 27/112 [00:00<00:01, 54.65it/s, Epoch: 13, Batch: 28,Loss: -0.569,Avg.Loss: -0.766,LR: 4.82E-04]Training epoch 13:  25%|██▌       | 28/112 [00:00<00:01, 54.65it/s, Epoch: 13, Batch: 29,Loss: -1.060,Avg.Loss: -0.776,LR: 4.82E-04]Training epoch 13:  26%|██▌       | 29/112 [00:00<00:01, 54.65it/s, Epoch: 13, Batch: 30,Loss: -0.672,Avg.Loss: -0.773,LR: 4.82E-04]Training epoch 13:  27%|██▋       | 30/112 [00:00<00:01, 54.65it/s, Epoch: 13, Batch: 31,Loss: -0.559,Avg.Loss: -0.766,LR: 4.82E-04]Training epoch 13:  28%|██▊       | 31/112 [00:00<00:01, 54.65it/s, Epoch: 13, Batch: 32,Loss: -1.121,Avg.Loss: -0.777,LR: 4.82E-04]Training epoch 13:  29%|██▊       | 32/112 [00:00<00:01, 53.89it/s, Epoch: 13, Batch: 32,Loss: -1.121,Avg.Loss: -0.777,LR: 4.82E-04]Training epoch 13:  29%|██▊       | 32/112 [00:00<00:01, 53.89it/s, Epoch: 13, Batch: 33,Loss: -0.681,Avg.Loss: -0.774,LR: 4.82E-04]Training epoch 13:  29%|██▉       | 33/112 [00:00<00:01, 53.89it/s, Epoch: 13, Batch: 34,Loss: 0.193,Avg.Loss: -0.746,LR: 4.82E-04] Training epoch 13:  30%|███       | 34/112 [00:00<00:01, 53.89it/s, Epoch: 13, Batch: 35,Loss: -0.074,Avg.Loss: -0.727,LR: 4.82E-04]Training epoch 13:  31%|███▏      | 35/112 [00:00<00:01, 53.89it/s, Epoch: 13, Batch: 36,Loss: -0.021,Avg.Loss: -0.707,LR: 4.82E-04]Training epoch 13:  32%|███▏      | 36/112 [00:00<00:01, 53.89it/s, Epoch: 13, Batch: 37,Loss: 0.801,Avg.Loss: -0.666,LR: 4.81E-04] Training epoch 13:  33%|███▎      | 37/112 [00:00<00:01, 53.89it/s, Epoch: 13, Batch: 38,Loss: 0.121,Avg.Loss: -0.645,LR: 4.81E-04]Training epoch 13:  34%|███▍      | 38/112 [00:00<00:01, 53.99it/s, Epoch: 13, Batch: 38,Loss: 0.121,Avg.Loss: -0.645,LR: 4.81E-04]Training epoch 13:  34%|███▍      | 38/112 [00:00<00:01, 53.99it/s, Epoch: 13, Batch: 39,Loss: -1.077,Avg.Loss: -0.657,LR: 4.81E-04]Training epoch 13:  35%|███▍      | 39/112 [00:00<00:01, 53.99it/s, Epoch: 13, Batch: 40,Loss: 0.069,Avg.Loss: -0.638,LR: 4.81E-04] Training epoch 13:  36%|███▌      | 40/112 [00:00<00:01, 53.99it/s, Epoch: 13, Batch: 41,Loss: 1.349,Avg.Loss: -0.590,LR: 4.81E-04]Training epoch 13:  37%|███▋      | 41/112 [00:00<00:01, 53.99it/s, Epoch: 13, Batch: 42,Loss: 1.217,Avg.Loss: -0.547,LR: 4.81E-04]Training epoch 13:  38%|███▊      | 42/112 [00:00<00:01, 53.99it/s, Epoch: 13, Batch: 43,Loss: 0.160,Avg.Loss: -0.531,LR: 4.81E-04]Training epoch 13:  38%|███▊      | 43/112 [00:00<00:01, 53.99it/s, Epoch: 13, Batch: 44,Loss: -0.449,Avg.Loss: -0.529,LR: 4.81E-04]Training epoch 13:  39%|███▉      | 44/112 [00:00<00:01, 53.84it/s, Epoch: 13, Batch: 44,Loss: -0.449,Avg.Loss: -0.529,LR: 4.81E-04]Training epoch 13:  39%|███▉      | 44/112 [00:00<00:01, 53.84it/s, Epoch: 13, Batch: 45,Loss: 0.072,Avg.Loss: -0.515,LR: 4.81E-04] Training epoch 13:  40%|████      | 45/112 [00:00<00:01, 53.84it/s, Epoch: 13, Batch: 46,Loss: -0.536,Avg.Loss: -0.516,LR: 4.81E-04]Training epoch 13:  41%|████      | 46/112 [00:00<00:01, 53.84it/s, Epoch: 13, Batch: 47,Loss: -1.358,Avg.Loss: -0.534,LR: 4.81E-04]Training epoch 13:  42%|████▏     | 47/112 [00:00<00:01, 53.84it/s, Epoch: 13, Batch: 48,Loss: 0.249,Avg.Loss: -0.517,LR: 4.81E-04] Training epoch 13:  43%|████▎     | 48/112 [00:00<00:01, 53.84it/s, Epoch: 13, Batch: 49,Loss: 1.997,Avg.Loss: -0.466,LR: 4.81E-04]Training epoch 13:  44%|████▍     | 49/112 [00:00<00:01, 53.84it/s, Epoch: 13, Batch: 50,Loss: 4.235,Avg.Loss: -0.372,LR: 4.81E-04]Training epoch 13:  45%|████▍     | 50/112 [00:00<00:01, 53.70it/s, Epoch: 13, Batch: 50,Loss: 4.235,Avg.Loss: -0.372,LR: 4.81E-04]Training epoch 13:  45%|████▍     | 50/112 [00:00<00:01, 53.70it/s, Epoch: 13, Batch: 51,Loss: 4.616,Avg.Loss: -0.274,LR: 4.81E-04]Training epoch 13:  46%|████▌     | 51/112 [00:00<00:01, 53.70it/s, Epoch: 13, Batch: 52,Loss: 4.173,Avg.Loss: -0.189,LR: 4.81E-04]Training epoch 13:  46%|████▋     | 52/112 [00:00<00:01, 53.70it/s, Epoch: 13, Batch: 53,Loss: 1.991,Avg.Loss: -0.148,LR: 4.81E-04]Training epoch 13:  47%|████▋     | 53/112 [00:00<00:01, 53.70it/s, Epoch: 13, Batch: 54,Loss: 0.424,Avg.Loss: -0.137,LR: 4.81E-04]Training epoch 13:  48%|████▊     | 54/112 [00:01<00:01, 53.70it/s, Epoch: 13, Batch: 55,Loss: -0.323,Avg.Loss: -0.140,LR: 4.81E-04]Training epoch 13:  49%|████▉     | 55/112 [00:01<00:01, 53.70it/s, Epoch: 13, Batch: 56,Loss: -0.376,Avg.Loss: -0.145,LR: 4.81E-04]Training epoch 13:  50%|█████     | 56/112 [00:01<00:01, 53.62it/s, Epoch: 13, Batch: 56,Loss: -0.376,Avg.Loss: -0.145,LR: 4.81E-04]Training epoch 13:  50%|█████     | 56/112 [00:01<00:01, 53.62it/s, Epoch: 13, Batch: 57,Loss: 0.016,Avg.Loss: -0.142,LR: 4.81E-04] Training epoch 13:  51%|█████     | 57/112 [00:01<00:01, 53.62it/s, Epoch: 13, Batch: 58,Loss: 0.628,Avg.Loss: -0.128,LR: 4.81E-04]Training epoch 13:  52%|█████▏    | 58/112 [00:01<00:01, 53.62it/s, Epoch: 13, Batch: 59,Loss: 0.691,Avg.Loss: -0.115,LR: 4.81E-04]Training epoch 13:  53%|█████▎    | 59/112 [00:01<00:00, 53.62it/s, Epoch: 13, Batch: 60,Loss: -0.520,Avg.Loss: -0.121,LR: 4.81E-04]Training epoch 13:  54%|█████▎    | 60/112 [00:01<00:00, 53.62it/s, Epoch: 13, Batch: 61,Loss: -0.784,Avg.Loss: -0.132,LR: 4.81E-04]Training epoch 13:  54%|█████▍    | 61/112 [00:01<00:00, 53.62it/s, Epoch: 13, Batch: 62,Loss: -0.591,Avg.Loss: -0.140,LR: 4.81E-04]Training epoch 13:  55%|█████▌    | 62/112 [00:01<00:00, 53.50it/s, Epoch: 13, Batch: 62,Loss: -0.591,Avg.Loss: -0.140,LR: 4.81E-04]Training epoch 13:  55%|█████▌    | 62/112 [00:01<00:00, 53.50it/s, Epoch: 13, Batch: 63,Loss: -0.595,Avg.Loss: -0.147,LR: 4.81E-04]Training epoch 13:  56%|█████▋    | 63/112 [00:01<00:00, 53.50it/s, Epoch: 13, Batch: 64,Loss: -0.592,Avg.Loss: -0.154,LR: 4.81E-04]Training epoch 13:  57%|█████▋    | 64/112 [00:01<00:00, 53.50it/s, Epoch: 13, Batch: 65,Loss: -0.475,Avg.Loss: -0.159,LR: 4.81E-04]Training epoch 13:  58%|█████▊    | 65/112 [00:01<00:00, 53.50it/s, Epoch: 13, Batch: 66,Loss: -0.852,Avg.Loss: -0.169,LR: 4.81E-04]Training epoch 13:  59%|█████▉    | 66/112 [00:01<00:00, 53.50it/s, Epoch: 13, Batch: 67,Loss: -0.826,Avg.Loss: -0.179,LR: 4.81E-04]Training epoch 13:  60%|█████▉    | 67/112 [00:01<00:00, 53.50it/s, Epoch: 13, Batch: 68,Loss: -0.848,Avg.Loss: -0.189,LR: 4.81E-04]Training epoch 13:  61%|██████    | 68/112 [00:01<00:00, 53.43it/s, Epoch: 13, Batch: 68,Loss: -0.848,Avg.Loss: -0.189,LR: 4.81E-04]Training epoch 13:  61%|██████    | 68/112 [00:01<00:00, 53.43it/s, Epoch: 13, Batch: 69,Loss: -0.441,Avg.Loss: -0.193,LR: 4.81E-04]Training epoch 13:  62%|██████▏   | 69/112 [00:01<00:00, 53.43it/s, Epoch: 13, Batch: 70,Loss: -0.923,Avg.Loss: -0.203,LR: 4.81E-04]Training epoch 13:  62%|██████▎   | 70/112 [00:01<00:00, 53.43it/s, Epoch: 13, Batch: 71,Loss: -1.063,Avg.Loss: -0.215,LR: 4.81E-04]Training epoch 13:  63%|██████▎   | 71/112 [00:01<00:00, 53.43it/s, Epoch: 13, Batch: 72,Loss: -0.939,Avg.Loss: -0.225,LR: 4.81E-04]Training epoch 13:  64%|██████▍   | 72/112 [00:01<00:00, 53.43it/s, Epoch: 13, Batch: 73,Loss: -0.695,Avg.Loss: -0.232,LR: 4.81E-04]Training epoch 13:  65%|██████▌   | 73/112 [00:01<00:00, 53.43it/s, Epoch: 13, Batch: 74,Loss: -0.876,Avg.Loss: -0.240,LR: 4.80E-04]Training epoch 13:  66%|██████▌   | 74/112 [00:01<00:00, 53.72it/s, Epoch: 13, Batch: 74,Loss: -0.876,Avg.Loss: -0.240,LR: 4.80E-04]Training epoch 13:  66%|██████▌   | 74/112 [00:01<00:00, 53.72it/s, Epoch: 13, Batch: 75,Loss: -0.805,Avg.Loss: -0.248,LR: 4.80E-04]Training epoch 13:  67%|██████▋   | 75/112 [00:01<00:00, 53.72it/s, Epoch: 13, Batch: 76,Loss: -1.025,Avg.Loss: -0.258,LR: 4.80E-04]Training epoch 13:  68%|██████▊   | 76/112 [00:01<00:00, 53.72it/s, Epoch: 13, Batch: 77,Loss: -0.798,Avg.Loss: -0.265,LR: 4.80E-04]Training epoch 13:  69%|██████▉   | 77/112 [00:01<00:00, 53.72it/s, Epoch: 13, Batch: 78,Loss: -0.704,Avg.Loss: -0.271,LR: 4.80E-04]Training epoch 13:  70%|██████▉   | 78/112 [00:01<00:00, 53.72it/s, Epoch: 13, Batch: 79,Loss: -0.935,Avg.Loss: -0.279,LR: 4.80E-04]Training epoch 13:  71%|███████   | 79/112 [00:01<00:00, 53.72it/s, Epoch: 13, Batch: 80,Loss: -0.701,Avg.Loss: -0.284,LR: 4.80E-04]Training epoch 13:  71%|███████▏  | 80/112 [00:01<00:00, 53.79it/s, Epoch: 13, Batch: 80,Loss: -0.701,Avg.Loss: -0.284,LR: 4.80E-04]Training epoch 13:  71%|███████▏  | 80/112 [00:01<00:00, 53.79it/s, Epoch: 13, Batch: 81,Loss: -0.742,Avg.Loss: -0.290,LR: 4.80E-04]Training epoch 13:  72%|███████▏  | 81/112 [00:01<00:00, 53.79it/s, Epoch: 13, Batch: 82,Loss: -1.120,Avg.Loss: -0.300,LR: 4.80E-04]Training epoch 13:  73%|███████▎  | 82/112 [00:01<00:00, 53.79it/s, Epoch: 13, Batch: 83,Loss: -1.064,Avg.Loss: -0.309,LR: 4.80E-04]Training epoch 13:  74%|███████▍  | 83/112 [00:01<00:00, 53.79it/s, Epoch: 13, Batch: 84,Loss: -1.371,Avg.Loss: -0.322,LR: 4.80E-04]Training epoch 13:  75%|███████▌  | 84/112 [00:01<00:00, 53.79it/s, Epoch: 13, Batch: 85,Loss: -0.808,Avg.Loss: -0.328,LR: 4.80E-04]Training epoch 13:  76%|███████▌  | 85/112 [00:01<00:00, 53.79it/s, Epoch: 13, Batch: 86,Loss: -1.295,Avg.Loss: -0.339,LR: 4.80E-04]Training epoch 13:  77%|███████▋  | 86/112 [00:01<00:00, 53.81it/s, Epoch: 13, Batch: 86,Loss: -1.295,Avg.Loss: -0.339,LR: 4.80E-04]Training epoch 13:  77%|███████▋  | 86/112 [00:01<00:00, 53.81it/s, Epoch: 13, Batch: 87,Loss: -1.394,Avg.Loss: -0.351,LR: 4.80E-04]Training epoch 13:  78%|███████▊  | 87/112 [00:01<00:00, 53.81it/s, Epoch: 13, Batch: 88,Loss: -1.445,Avg.Loss: -0.363,LR: 4.80E-04]Training epoch 13:  79%|███████▊  | 88/112 [00:01<00:00, 53.81it/s, Epoch: 13, Batch: 89,Loss: -1.213,Avg.Loss: -0.373,LR: 4.80E-04]Training epoch 13:  79%|███████▉  | 89/112 [00:01<00:00, 53.81it/s, Epoch: 13, Batch: 90,Loss: -0.568,Avg.Loss: -0.375,LR: 4.80E-04]Training epoch 13:  80%|████████  | 90/112 [00:01<00:00, 53.81it/s, Epoch: 13, Batch: 91,Loss: -0.323,Avg.Loss: -0.375,LR: 4.80E-04]Training epoch 13:  81%|████████▏ | 91/112 [00:01<00:00, 53.81it/s, Epoch: 13, Batch: 92,Loss: -1.288,Avg.Loss: -0.385,LR: 4.80E-04]Training epoch 13:  82%|████████▏ | 92/112 [00:01<00:00, 53.78it/s, Epoch: 13, Batch: 92,Loss: -1.288,Avg.Loss: -0.385,LR: 4.80E-04]Training epoch 13:  82%|████████▏ | 92/112 [00:01<00:00, 53.78it/s, Epoch: 13, Batch: 93,Loss: -0.652,Avg.Loss: -0.387,LR: 4.80E-04]Training epoch 13:  83%|████████▎ | 93/112 [00:01<00:00, 53.78it/s, Epoch: 13, Batch: 94,Loss: -0.131,Avg.Loss: -0.385,LR: 4.80E-04]Training epoch 13:  84%|████████▍ | 94/112 [00:01<00:00, 53.78it/s, Epoch: 13, Batch: 95,Loss: 0.068,Avg.Loss: -0.380,LR: 4.80E-04] Training epoch 13:  85%|████████▍ | 95/112 [00:01<00:00, 53.78it/s, Epoch: 13, Batch: 96,Loss: 0.425,Avg.Loss: -0.372,LR: 4.80E-04]Training epoch 13:  86%|████████▌ | 96/112 [00:01<00:00, 53.78it/s, Epoch: 13, Batch: 97,Loss: 1.153,Avg.Loss: -0.356,LR: 4.80E-04]Training epoch 13:  87%|████████▋ | 97/112 [00:01<00:00, 53.78it/s, Epoch: 13, Batch: 98,Loss: 0.202,Avg.Loss: -0.350,LR: 4.80E-04]Training epoch 13:  88%|████████▊ | 98/112 [00:01<00:00, 54.14it/s, Epoch: 13, Batch: 98,Loss: 0.202,Avg.Loss: -0.350,LR: 4.80E-04]Training epoch 13:  88%|████████▊ | 98/112 [00:01<00:00, 54.14it/s, Epoch: 13, Batch: 99,Loss: 0.036,Avg.Loss: -0.346,LR: 4.80E-04]Training epoch 13:  88%|████████▊ | 99/112 [00:01<00:00, 54.14it/s, Epoch: 13, Batch: 100,Loss: -0.638,Avg.Loss: -0.349,LR: 4.80E-04]Training epoch 13:  89%|████████▉ | 100/112 [00:01<00:00, 54.14it/s, Epoch: 13, Batch: 101,Loss: -0.986,Avg.Loss: -0.355,LR: 4.80E-04]Training epoch 13:  90%|█████████ | 101/112 [00:01<00:00, 54.14it/s, Epoch: 13, Batch: 102,Loss: -0.668,Avg.Loss: -0.359,LR: 4.80E-04]Training epoch 13:  91%|█████████ | 102/112 [00:01<00:00, 54.14it/s, Epoch: 13, Batch: 103,Loss: 0.444,Avg.Loss: -0.351,LR: 4.80E-04] Training epoch 13:  92%|█████████▏| 103/112 [00:01<00:00, 54.14it/s, Epoch: 13, Batch: 104,Loss: -0.836,Avg.Loss: -0.355,LR: 4.80E-04]Training epoch 13:  93%|█████████▎| 104/112 [00:01<00:00, 54.16it/s, Epoch: 13, Batch: 104,Loss: -0.836,Avg.Loss: -0.355,LR: 4.80E-04]Training epoch 13:  93%|█████████▎| 104/112 [00:01<00:00, 54.16it/s, Epoch: 13, Batch: 105,Loss: -0.187,Avg.Loss: -0.354,LR: 4.80E-04]Training epoch 13:  94%|█████████▍| 105/112 [00:01<00:00, 54.16it/s, Epoch: 13, Batch: 106,Loss: 0.119,Avg.Loss: -0.349,LR: 4.80E-04] Training epoch 13:  95%|█████████▍| 106/112 [00:01<00:00, 54.16it/s, Epoch: 13, Batch: 107,Loss: -0.834,Avg.Loss: -0.354,LR: 4.80E-04]Training epoch 13:  96%|█████████▌| 107/112 [00:01<00:00, 54.16it/s, Epoch: 13, Batch: 108,Loss: -0.668,Avg.Loss: -0.357,LR: 4.80E-04]Training epoch 13:  96%|█████████▋| 108/112 [00:02<00:00, 54.16it/s, Epoch: 13, Batch: 109,Loss: -0.812,Avg.Loss: -0.361,LR: 4.80E-04]Training epoch 13:  97%|█████████▋| 109/112 [00:02<00:00, 54.16it/s, Epoch: 13, Batch: 110,Loss: -1.283,Avg.Loss: -0.369,LR: 4.79E-04]Training epoch 13:  98%|█████████▊| 110/112 [00:02<00:00, 54.12it/s, Epoch: 13, Batch: 110,Loss: -1.283,Avg.Loss: -0.369,LR: 4.79E-04]Training epoch 13:  98%|█████████▊| 110/112 [00:02<00:00, 54.12it/s, Epoch: 13, Batch: 111,Loss: -0.747,Avg.Loss: -0.373,LR: 4.79E-04]Training epoch 13:  99%|█████████▉| 111/112 [00:02<00:00, 54.12it/s, Epoch: 13, Batch: 112,Loss: 1.489,Avg.Loss: -0.356,LR: 4.79E-04] Training epoch 13: 100%|██████████| 112/112 [00:02<00:00, 54.18it/s, Epoch: 13, Batch: 112,Loss: 1.489,Avg.Loss: -0.356,LR: 4.79E-04]
Training epoch 14:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 14:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 14, Batch: 1,Loss: -1.223,Avg.Loss: -1.223,LR: 4.79E-04]Training epoch 14:   1%|          | 1/112 [00:00<00:04, 25.62it/s, Epoch: 14, Batch: 2,Loss: -1.377,Avg.Loss: -1.300,LR: 4.79E-04]Training epoch 14:   2%|▏         | 2/112 [00:00<00:03, 35.57it/s, Epoch: 14, Batch: 3,Loss: -0.617,Avg.Loss: -1.073,LR: 4.79E-04]Training epoch 14:   3%|▎         | 3/112 [00:00<00:02, 41.67it/s, Epoch: 14, Batch: 4,Loss: -1.039,Avg.Loss: -1.064,LR: 4.79E-04]Training epoch 14:   4%|▎         | 4/112 [00:00<00:02, 45.90it/s, Epoch: 14, Batch: 5,Loss: -0.985,Avg.Loss: -1.048,LR: 4.79E-04]Training epoch 14:   4%|▍         | 5/112 [00:00<00:02, 49.12it/s, Epoch: 14, Batch: 6,Loss: -0.504,Avg.Loss: -0.957,LR: 4.79E-04]Training epoch 14:   5%|▌         | 6/112 [00:00<00:01, 58.85it/s, Epoch: 14, Batch: 6,Loss: -0.504,Avg.Loss: -0.957,LR: 4.79E-04]Training epoch 14:   5%|▌         | 6/112 [00:00<00:01, 58.85it/s, Epoch: 14, Batch: 7,Loss: -1.037,Avg.Loss: -0.969,LR: 4.79E-04]Training epoch 14:   6%|▋         | 7/112 [00:00<00:01, 58.85it/s, Epoch: 14, Batch: 8,Loss: -1.357,Avg.Loss: -1.017,LR: 4.79E-04]Training epoch 14:   7%|▋         | 8/112 [00:00<00:01, 58.85it/s, Epoch: 14, Batch: 9,Loss: -0.834,Avg.Loss: -0.997,LR: 4.79E-04]Training epoch 14:   8%|▊         | 9/112 [00:00<00:01, 58.85it/s, Epoch: 14, Batch: 10,Loss: -1.320,Avg.Loss: -1.029,LR: 4.79E-04]Training epoch 14:   9%|▉         | 10/112 [00:00<00:01, 58.85it/s, Epoch: 14, Batch: 11,Loss: -0.833,Avg.Loss: -1.011,LR: 4.79E-04]Training epoch 14:  10%|▉         | 11/112 [00:00<00:01, 58.85it/s, Epoch: 14, Batch: 12,Loss: -0.599,Avg.Loss: -0.977,LR: 4.79E-04]Training epoch 14:  11%|█         | 12/112 [00:00<00:01, 58.85it/s, Epoch: 14, Batch: 13,Loss: -0.752,Avg.Loss: -0.960,LR: 4.79E-04]Training epoch 14:  12%|█▏        | 13/112 [00:00<00:01, 59.82it/s, Epoch: 14, Batch: 13,Loss: -0.752,Avg.Loss: -0.960,LR: 4.79E-04]Training epoch 14:  12%|█▏        | 13/112 [00:00<00:01, 59.82it/s, Epoch: 14, Batch: 14,Loss: -0.759,Avg.Loss: -0.945,LR: 4.79E-04]Training epoch 14:  12%|█▎        | 14/112 [00:00<00:01, 59.82it/s, Epoch: 14, Batch: 15,Loss: -0.162,Avg.Loss: -0.893,LR: 4.79E-04]Training epoch 14:  13%|█▎        | 15/112 [00:00<00:01, 59.82it/s, Epoch: 14, Batch: 16,Loss: -1.091,Avg.Loss: -0.906,LR: 4.79E-04]Training epoch 14:  14%|█▍        | 16/112 [00:00<00:01, 59.82it/s, Epoch: 14, Batch: 17,Loss: -1.183,Avg.Loss: -0.922,LR: 4.79E-04]Training epoch 14:  15%|█▌        | 17/112 [00:00<00:01, 59.82it/s, Epoch: 14, Batch: 18,Loss: -0.884,Avg.Loss: -0.920,LR: 4.79E-04]Training epoch 14:  16%|█▌        | 18/112 [00:00<00:01, 59.82it/s, Epoch: 14, Batch: 19,Loss: -1.051,Avg.Loss: -0.927,LR: 4.79E-04]Training epoch 14:  17%|█▋        | 19/112 [00:00<00:01, 56.55it/s, Epoch: 14, Batch: 19,Loss: -1.051,Avg.Loss: -0.927,LR: 4.79E-04]Training epoch 14:  17%|█▋        | 19/112 [00:00<00:01, 56.55it/s, Epoch: 14, Batch: 20,Loss: -1.002,Avg.Loss: -0.930,LR: 4.79E-04]Training epoch 14:  18%|█▊        | 20/112 [00:00<00:01, 56.55it/s, Epoch: 14, Batch: 21,Loss: -0.820,Avg.Loss: -0.925,LR: 4.79E-04]Training epoch 14:  19%|█▉        | 21/112 [00:00<00:01, 56.55it/s, Epoch: 14, Batch: 22,Loss: -1.221,Avg.Loss: -0.939,LR: 4.79E-04]Training epoch 14:  20%|█▉        | 22/112 [00:00<00:01, 56.55it/s, Epoch: 14, Batch: 23,Loss: -0.943,Avg.Loss: -0.939,LR: 4.79E-04]Training epoch 14:  21%|██        | 23/112 [00:00<00:01, 56.55it/s, Epoch: 14, Batch: 24,Loss: -0.663,Avg.Loss: -0.927,LR: 4.79E-04]Training epoch 14:  21%|██▏       | 24/112 [00:00<00:01, 56.55it/s, Epoch: 14, Batch: 25,Loss: -0.981,Avg.Loss: -0.929,LR: 4.79E-04]Training epoch 14:  22%|██▏       | 25/112 [00:00<00:01, 54.70it/s, Epoch: 14, Batch: 25,Loss: -0.981,Avg.Loss: -0.929,LR: 4.79E-04]Training epoch 14:  22%|██▏       | 25/112 [00:00<00:01, 54.70it/s, Epoch: 14, Batch: 26,Loss: -1.015,Avg.Loss: -0.933,LR: 4.79E-04]Training epoch 14:  23%|██▎       | 26/112 [00:00<00:01, 54.70it/s, Epoch: 14, Batch: 27,Loss: -0.831,Avg.Loss: -0.929,LR: 4.79E-04]Training epoch 14:  24%|██▍       | 27/112 [00:00<00:01, 54.70it/s, Epoch: 14, Batch: 28,Loss: -1.138,Avg.Loss: -0.936,LR: 4.79E-04]Training epoch 14:  25%|██▌       | 28/112 [00:00<00:01, 54.70it/s, Epoch: 14, Batch: 29,Loss: -0.821,Avg.Loss: -0.932,LR: 4.79E-04]Training epoch 14:  26%|██▌       | 29/112 [00:00<00:01, 54.70it/s, Epoch: 14, Batch: 30,Loss: -0.635,Avg.Loss: -0.923,LR: 4.79E-04]Training epoch 14:  27%|██▋       | 30/112 [00:00<00:01, 54.70it/s, Epoch: 14, Batch: 31,Loss: -1.322,Avg.Loss: -0.935,LR: 4.79E-04]Training epoch 14:  28%|██▊       | 31/112 [00:00<00:01, 54.18it/s, Epoch: 14, Batch: 31,Loss: -1.322,Avg.Loss: -0.935,LR: 4.79E-04]Training epoch 14:  28%|██▊       | 31/112 [00:00<00:01, 54.18it/s, Epoch: 14, Batch: 32,Loss: -0.834,Avg.Loss: -0.932,LR: 4.79E-04]Training epoch 14:  29%|██▊       | 32/112 [00:00<00:01, 54.18it/s, Epoch: 14, Batch: 33,Loss: -0.645,Avg.Loss: -0.924,LR: 4.79E-04]Training epoch 14:  29%|██▉       | 33/112 [00:00<00:01, 54.18it/s, Epoch: 14, Batch: 34,Loss: -1.189,Avg.Loss: -0.931,LR: 4.78E-04]Training epoch 14:  30%|███       | 34/112 [00:00<00:01, 54.18it/s, Epoch: 14, Batch: 35,Loss: -0.989,Avg.Loss: -0.933,LR: 4.78E-04]Training epoch 14:  31%|███▏      | 35/112 [00:00<00:01, 54.18it/s, Epoch: 14, Batch: 36,Loss: -0.691,Avg.Loss: -0.926,LR: 4.78E-04]Training epoch 14:  32%|███▏      | 36/112 [00:00<00:01, 54.18it/s, Epoch: 14, Batch: 37,Loss: -1.052,Avg.Loss: -0.930,LR: 4.78E-04]Training epoch 14:  33%|███▎      | 37/112 [00:00<00:01, 53.93it/s, Epoch: 14, Batch: 37,Loss: -1.052,Avg.Loss: -0.930,LR: 4.78E-04]Training epoch 14:  33%|███▎      | 37/112 [00:00<00:01, 53.93it/s, Epoch: 14, Batch: 38,Loss: -1.081,Avg.Loss: -0.934,LR: 4.78E-04]Training epoch 14:  34%|███▍      | 38/112 [00:00<00:01, 53.93it/s, Epoch: 14, Batch: 39,Loss: -0.677,Avg.Loss: -0.927,LR: 4.78E-04]Training epoch 14:  35%|███▍      | 39/112 [00:00<00:01, 53.93it/s, Epoch: 14, Batch: 40,Loss: -0.921,Avg.Loss: -0.927,LR: 4.78E-04]Training epoch 14:  36%|███▌      | 40/112 [00:00<00:01, 53.93it/s, Epoch: 14, Batch: 41,Loss: -0.843,Avg.Loss: -0.925,LR: 4.78E-04]Training epoch 14:  37%|███▋      | 41/112 [00:00<00:01, 53.93it/s, Epoch: 14, Batch: 42,Loss: -0.502,Avg.Loss: -0.915,LR: 4.78E-04]Training epoch 14:  38%|███▊      | 42/112 [00:00<00:01, 53.93it/s, Epoch: 14, Batch: 43,Loss: -1.360,Avg.Loss: -0.925,LR: 4.78E-04]Training epoch 14:  38%|███▊      | 43/112 [00:00<00:01, 53.69it/s, Epoch: 14, Batch: 43,Loss: -1.360,Avg.Loss: -0.925,LR: 4.78E-04]Training epoch 14:  38%|███▊      | 43/112 [00:00<00:01, 53.69it/s, Epoch: 14, Batch: 44,Loss: -0.569,Avg.Loss: -0.917,LR: 4.78E-04]Training epoch 14:  39%|███▉      | 44/112 [00:00<00:01, 53.69it/s, Epoch: 14, Batch: 45,Loss: -0.525,Avg.Loss: -0.908,LR: 4.78E-04]Training epoch 14:  40%|████      | 45/112 [00:00<00:01, 53.69it/s, Epoch: 14, Batch: 46,Loss: -0.901,Avg.Loss: -0.908,LR: 4.78E-04]Training epoch 14:  41%|████      | 46/112 [00:00<00:01, 53.69it/s, Epoch: 14, Batch: 47,Loss: -1.144,Avg.Loss: -0.913,LR: 4.78E-04]Training epoch 14:  42%|████▏     | 47/112 [00:00<00:01, 53.69it/s, Epoch: 14, Batch: 48,Loss: -0.912,Avg.Loss: -0.913,LR: 4.78E-04]Training epoch 14:  43%|████▎     | 48/112 [00:00<00:01, 53.69it/s, Epoch: 14, Batch: 49,Loss: -1.289,Avg.Loss: -0.921,LR: 4.78E-04]Training epoch 14:  44%|████▍     | 49/112 [00:00<00:01, 53.57it/s, Epoch: 14, Batch: 49,Loss: -1.289,Avg.Loss: -0.921,LR: 4.78E-04]Training epoch 14:  44%|████▍     | 49/112 [00:00<00:01, 53.57it/s, Epoch: 14, Batch: 50,Loss: -0.693,Avg.Loss: -0.916,LR: 4.78E-04]Training epoch 14:  45%|████▍     | 50/112 [00:00<00:01, 53.57it/s, Epoch: 14, Batch: 51,Loss: -0.011,Avg.Loss: -0.899,LR: 4.78E-04]Training epoch 14:  46%|████▌     | 51/112 [00:00<00:01, 53.57it/s, Epoch: 14, Batch: 52,Loss: -0.778,Avg.Loss: -0.896,LR: 4.78E-04]Training epoch 14:  46%|████▋     | 52/112 [00:00<00:01, 53.57it/s, Epoch: 14, Batch: 53,Loss: -0.861,Avg.Loss: -0.896,LR: 4.78E-04]Training epoch 14:  47%|████▋     | 53/112 [00:00<00:01, 53.57it/s, Epoch: 14, Batch: 54,Loss: -0.682,Avg.Loss: -0.892,LR: 4.78E-04]Training epoch 14:  48%|████▊     | 54/112 [00:01<00:01, 53.57it/s, Epoch: 14, Batch: 55,Loss: -0.766,Avg.Loss: -0.889,LR: 4.78E-04]Training epoch 14:  49%|████▉     | 55/112 [00:01<00:01, 53.26it/s, Epoch: 14, Batch: 55,Loss: -0.766,Avg.Loss: -0.889,LR: 4.78E-04]Training epoch 14:  49%|████▉     | 55/112 [00:01<00:01, 53.26it/s, Epoch: 14, Batch: 56,Loss: -1.348,Avg.Loss: -0.898,LR: 4.78E-04]Training epoch 14:  50%|█████     | 56/112 [00:01<00:01, 53.26it/s, Epoch: 14, Batch: 57,Loss: -1.335,Avg.Loss: -0.905,LR: 4.78E-04]Training epoch 14:  51%|█████     | 57/112 [00:01<00:01, 53.26it/s, Epoch: 14, Batch: 58,Loss: -1.063,Avg.Loss: -0.908,LR: 4.78E-04]Training epoch 14:  52%|█████▏    | 58/112 [00:01<00:01, 53.26it/s, Epoch: 14, Batch: 59,Loss: -1.520,Avg.Loss: -0.918,LR: 4.78E-04]Training epoch 14:  53%|█████▎    | 59/112 [00:01<00:00, 53.26it/s, Epoch: 14, Batch: 60,Loss: -0.672,Avg.Loss: -0.914,LR: 4.78E-04]Training epoch 14:  54%|█████▎    | 60/112 [00:01<00:00, 53.26it/s, Epoch: 14, Batch: 61,Loss: -1.052,Avg.Loss: -0.916,LR: 4.78E-04]Training epoch 14:  54%|█████▍    | 61/112 [00:01<00:00, 53.24it/s, Epoch: 14, Batch: 61,Loss: -1.052,Avg.Loss: -0.916,LR: 4.78E-04]Training epoch 14:  54%|█████▍    | 61/112 [00:01<00:00, 53.24it/s, Epoch: 14, Batch: 62,Loss: -0.911,Avg.Loss: -0.916,LR: 4.78E-04]Training epoch 14:  55%|█████▌    | 62/112 [00:01<00:00, 53.24it/s, Epoch: 14, Batch: 63,Loss: -1.296,Avg.Loss: -0.922,LR: 4.78E-04]Training epoch 14:  56%|█████▋    | 63/112 [00:01<00:00, 53.24it/s, Epoch: 14, Batch: 64,Loss: -0.684,Avg.Loss: -0.919,LR: 4.78E-04]Training epoch 14:  57%|█████▋    | 64/112 [00:01<00:00, 53.24it/s, Epoch: 14, Batch: 65,Loss: -0.965,Avg.Loss: -0.919,LR: 4.78E-04]Training epoch 14:  58%|█████▊    | 65/112 [00:01<00:00, 53.24it/s, Epoch: 14, Batch: 66,Loss: -1.109,Avg.Loss: -0.922,LR: 4.78E-04]Training epoch 14:  59%|█████▉    | 66/112 [00:01<00:00, 53.24it/s, Epoch: 14, Batch: 67,Loss: -1.323,Avg.Loss: -0.928,LR: 4.78E-04]Training epoch 14:  60%|█████▉    | 67/112 [00:01<00:00, 53.20it/s, Epoch: 14, Batch: 67,Loss: -1.323,Avg.Loss: -0.928,LR: 4.78E-04]Training epoch 14:  60%|█████▉    | 67/112 [00:01<00:00, 53.20it/s, Epoch: 14, Batch: 68,Loss: -1.155,Avg.Loss: -0.932,LR: 4.78E-04]Training epoch 14:  61%|██████    | 68/112 [00:01<00:00, 53.20it/s, Epoch: 14, Batch: 69,Loss: -1.328,Avg.Loss: -0.937,LR: 4.77E-04]Training epoch 14:  62%|██████▏   | 69/112 [00:01<00:00, 53.20it/s, Epoch: 14, Batch: 70,Loss: -1.248,Avg.Loss: -0.942,LR: 4.77E-04]Training epoch 14:  62%|██████▎   | 70/112 [00:01<00:00, 53.20it/s, Epoch: 14, Batch: 71,Loss: -0.710,Avg.Loss: -0.938,LR: 4.77E-04]Training epoch 14:  63%|██████▎   | 71/112 [00:01<00:00, 53.20it/s, Epoch: 14, Batch: 72,Loss: -1.332,Avg.Loss: -0.944,LR: 4.77E-04]Training epoch 14:  64%|██████▍   | 72/112 [00:01<00:00, 53.20it/s, Epoch: 14, Batch: 73,Loss: -1.168,Avg.Loss: -0.947,LR: 4.77E-04]Training epoch 14:  65%|██████▌   | 73/112 [00:01<00:00, 53.10it/s, Epoch: 14, Batch: 73,Loss: -1.168,Avg.Loss: -0.947,LR: 4.77E-04]Training epoch 14:  65%|██████▌   | 73/112 [00:01<00:00, 53.10it/s, Epoch: 14, Batch: 74,Loss: -1.220,Avg.Loss: -0.951,LR: 4.77E-04]Training epoch 14:  66%|██████▌   | 74/112 [00:01<00:00, 53.10it/s, Epoch: 14, Batch: 75,Loss: -1.156,Avg.Loss: -0.953,LR: 4.77E-04]Training epoch 14:  67%|██████▋   | 75/112 [00:01<00:00, 53.10it/s, Epoch: 14, Batch: 76,Loss: -0.883,Avg.Loss: -0.953,LR: 4.77E-04]Training epoch 14:  68%|██████▊   | 76/112 [00:01<00:00, 53.10it/s, Epoch: 14, Batch: 77,Loss: -0.731,Avg.Loss: -0.950,LR: 4.77E-04]Training epoch 14:  69%|██████▉   | 77/112 [00:01<00:00, 53.10it/s, Epoch: 14, Batch: 78,Loss: -1.161,Avg.Loss: -0.952,LR: 4.77E-04]Training epoch 14:  70%|██████▉   | 78/112 [00:01<00:00, 53.10it/s, Epoch: 14, Batch: 79,Loss: -1.182,Avg.Loss: -0.955,LR: 4.77E-04]Training epoch 14:  71%|███████   | 79/112 [00:01<00:00, 53.22it/s, Epoch: 14, Batch: 79,Loss: -1.182,Avg.Loss: -0.955,LR: 4.77E-04]Training epoch 14:  71%|███████   | 79/112 [00:01<00:00, 53.22it/s, Epoch: 14, Batch: 80,Loss: -1.117,Avg.Loss: -0.957,LR: 4.77E-04]Training epoch 14:  71%|███████▏  | 80/112 [00:01<00:00, 53.22it/s, Epoch: 14, Batch: 81,Loss: -1.303,Avg.Loss: -0.962,LR: 4.77E-04]Training epoch 14:  72%|███████▏  | 81/112 [00:01<00:00, 53.22it/s, Epoch: 14, Batch: 82,Loss: -0.795,Avg.Loss: -0.960,LR: 4.77E-04]Training epoch 14:  73%|███████▎  | 82/112 [00:01<00:00, 53.22it/s, Epoch: 14, Batch: 83,Loss: -1.291,Avg.Loss: -0.964,LR: 4.77E-04]Training epoch 14:  74%|███████▍  | 83/112 [00:01<00:00, 53.22it/s, Epoch: 14, Batch: 84,Loss: -1.286,Avg.Loss: -0.967,LR: 4.77E-04]Training epoch 14:  75%|███████▌  | 84/112 [00:01<00:00, 53.22it/s, Epoch: 14, Batch: 85,Loss: -1.600,Avg.Loss: -0.975,LR: 4.77E-04]Training epoch 14:  76%|███████▌  | 85/112 [00:01<00:00, 53.63it/s, Epoch: 14, Batch: 85,Loss: -1.600,Avg.Loss: -0.975,LR: 4.77E-04]Training epoch 14:  76%|███████▌  | 85/112 [00:01<00:00, 53.63it/s, Epoch: 14, Batch: 86,Loss: -1.149,Avg.Loss: -0.977,LR: 4.77E-04]Training epoch 14:  77%|███████▋  | 86/112 [00:01<00:00, 53.63it/s, Epoch: 14, Batch: 87,Loss: -1.250,Avg.Loss: -0.980,LR: 4.77E-04]Training epoch 14:  78%|███████▊  | 87/112 [00:01<00:00, 53.63it/s, Epoch: 14, Batch: 88,Loss: -1.234,Avg.Loss: -0.983,LR: 4.77E-04]Training epoch 14:  79%|███████▊  | 88/112 [00:01<00:00, 53.63it/s, Epoch: 14, Batch: 89,Loss: -1.427,Avg.Loss: -0.988,LR: 4.77E-04]Training epoch 14:  79%|███████▉  | 89/112 [00:01<00:00, 53.63it/s, Epoch: 14, Batch: 90,Loss: -1.061,Avg.Loss: -0.989,LR: 4.77E-04]Training epoch 14:  80%|████████  | 90/112 [00:01<00:00, 53.63it/s, Epoch: 14, Batch: 91,Loss: -1.619,Avg.Loss: -0.996,LR: 4.77E-04]Training epoch 14:  81%|████████▏ | 91/112 [00:01<00:00, 53.67it/s, Epoch: 14, Batch: 91,Loss: -1.619,Avg.Loss: -0.996,LR: 4.77E-04]Training epoch 14:  81%|████████▏ | 91/112 [00:01<00:00, 53.67it/s, Epoch: 14, Batch: 92,Loss: -1.083,Avg.Loss: -0.997,LR: 4.77E-04]Training epoch 14:  82%|████████▏ | 92/112 [00:01<00:00, 53.67it/s, Epoch: 14, Batch: 93,Loss: -1.132,Avg.Loss: -0.998,LR: 4.77E-04]Training epoch 14:  83%|████████▎ | 93/112 [00:01<00:00, 53.67it/s, Epoch: 14, Batch: 94,Loss: -1.364,Avg.Loss: -1.002,LR: 4.77E-04]Training epoch 14:  84%|████████▍ | 94/112 [00:01<00:00, 53.67it/s, Epoch: 14, Batch: 95,Loss: -1.027,Avg.Loss: -1.002,LR: 4.77E-04]Training epoch 14:  85%|████████▍ | 95/112 [00:01<00:00, 53.67it/s, Epoch: 14, Batch: 96,Loss: -1.393,Avg.Loss: -1.006,LR: 4.77E-04]Training epoch 14:  86%|████████▌ | 96/112 [00:01<00:00, 53.67it/s, Epoch: 14, Batch: 97,Loss: -1.342,Avg.Loss: -1.010,LR: 4.77E-04]Training epoch 14:  87%|████████▋ | 97/112 [00:01<00:00, 53.44it/s, Epoch: 14, Batch: 97,Loss: -1.342,Avg.Loss: -1.010,LR: 4.77E-04]Training epoch 14:  87%|████████▋ | 97/112 [00:01<00:00, 53.44it/s, Epoch: 14, Batch: 98,Loss: -1.234,Avg.Loss: -1.012,LR: 4.77E-04]Training epoch 14:  88%|████████▊ | 98/112 [00:01<00:00, 53.44it/s, Epoch: 14, Batch: 99,Loss: -1.149,Avg.Loss: -1.013,LR: 4.77E-04]Training epoch 14:  88%|████████▊ | 99/112 [00:01<00:00, 53.44it/s, Epoch: 14, Batch: 100,Loss: -1.190,Avg.Loss: -1.015,LR: 4.77E-04]Training epoch 14:  89%|████████▉ | 100/112 [00:01<00:00, 53.44it/s, Epoch: 14, Batch: 101,Loss: -1.465,Avg.Loss: -1.020,LR: 4.77E-04]Training epoch 14:  90%|█████████ | 101/112 [00:01<00:00, 53.44it/s, Epoch: 14, Batch: 102,Loss: -0.986,Avg.Loss: -1.019,LR: 4.77E-04]Training epoch 14:  91%|█████████ | 102/112 [00:01<00:00, 53.44it/s, Epoch: 14, Batch: 103,Loss: -1.405,Avg.Loss: -1.023,LR: 4.76E-04]Training epoch 14:  92%|█████████▏| 103/112 [00:01<00:00, 53.43it/s, Epoch: 14, Batch: 103,Loss: -1.405,Avg.Loss: -1.023,LR: 4.76E-04]Training epoch 14:  92%|█████████▏| 103/112 [00:01<00:00, 53.43it/s, Epoch: 14, Batch: 104,Loss: -1.480,Avg.Loss: -1.027,LR: 4.76E-04]Training epoch 14:  93%|█████████▎| 104/112 [00:01<00:00, 53.43it/s, Epoch: 14, Batch: 105,Loss: -1.465,Avg.Loss: -1.032,LR: 4.76E-04]Training epoch 14:  94%|█████████▍| 105/112 [00:01<00:00, 53.43it/s, Epoch: 14, Batch: 106,Loss: -1.109,Avg.Loss: -1.032,LR: 4.76E-04]Training epoch 14:  95%|█████████▍| 106/112 [00:01<00:00, 53.43it/s, Epoch: 14, Batch: 107,Loss: -1.265,Avg.Loss: -1.034,LR: 4.76E-04]Training epoch 14:  96%|█████████▌| 107/112 [00:02<00:00, 53.43it/s, Epoch: 14, Batch: 108,Loss: -1.561,Avg.Loss: -1.039,LR: 4.76E-04]Training epoch 14:  96%|█████████▋| 108/112 [00:02<00:00, 53.43it/s, Epoch: 14, Batch: 109,Loss: -1.542,Avg.Loss: -1.044,LR: 4.76E-04]Training epoch 14:  97%|█████████▋| 109/112 [00:02<00:00, 53.24it/s, Epoch: 14, Batch: 109,Loss: -1.542,Avg.Loss: -1.044,LR: 4.76E-04]Training epoch 14:  97%|█████████▋| 109/112 [00:02<00:00, 53.24it/s, Epoch: 14, Batch: 110,Loss: -1.092,Avg.Loss: -1.044,LR: 4.76E-04]Training epoch 14:  98%|█████████▊| 110/112 [00:02<00:00, 53.24it/s, Epoch: 14, Batch: 111,Loss: -1.243,Avg.Loss: -1.046,LR: 4.76E-04]Training epoch 14:  99%|█████████▉| 111/112 [00:02<00:00, 53.24it/s, Epoch: 14, Batch: 112,Loss: -1.412,Avg.Loss: -1.049,LR: 4.76E-04]Training epoch 14: 100%|██████████| 112/112 [00:02<00:00, 53.76it/s, Epoch: 14, Batch: 112,Loss: -1.412,Avg.Loss: -1.049,LR: 4.76E-04]
Training epoch 15:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 15:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 15, Batch: 1,Loss: -1.320,Avg.Loss: -1.320,LR: 4.76E-04]Training epoch 15:   1%|          | 1/112 [00:00<00:04, 24.47it/s, Epoch: 15, Batch: 2,Loss: -1.345,Avg.Loss: -1.332,LR: 4.76E-04]Training epoch 15:   2%|▏         | 2/112 [00:00<00:03, 33.46it/s, Epoch: 15, Batch: 3,Loss: -1.422,Avg.Loss: -1.362,LR: 4.76E-04]Training epoch 15:   3%|▎         | 3/112 [00:00<00:02, 39.65it/s, Epoch: 15, Batch: 4,Loss: -1.167,Avg.Loss: -1.314,LR: 4.76E-04]Training epoch 15:   4%|▎         | 4/112 [00:00<00:02, 44.06it/s, Epoch: 15, Batch: 5,Loss: -1.143,Avg.Loss: -1.280,LR: 4.76E-04]Training epoch 15:   4%|▍         | 5/112 [00:00<00:02, 47.80it/s, Epoch: 15, Batch: 6,Loss: -1.549,Avg.Loss: -1.324,LR: 4.76E-04]Training epoch 15:   5%|▌         | 6/112 [00:00<00:01, 57.28it/s, Epoch: 15, Batch: 6,Loss: -1.549,Avg.Loss: -1.324,LR: 4.76E-04]Training epoch 15:   5%|▌         | 6/112 [00:00<00:01, 57.28it/s, Epoch: 15, Batch: 7,Loss: -1.434,Avg.Loss: -1.340,LR: 4.76E-04]Training epoch 15:   6%|▋         | 7/112 [00:00<00:01, 57.28it/s, Epoch: 15, Batch: 8,Loss: -1.263,Avg.Loss: -1.330,LR: 4.76E-04]Training epoch 15:   7%|▋         | 8/112 [00:00<00:01, 57.28it/s, Epoch: 15, Batch: 9,Loss: -1.140,Avg.Loss: -1.309,LR: 4.76E-04]Training epoch 15:   8%|▊         | 9/112 [00:00<00:01, 57.28it/s, Epoch: 15, Batch: 10,Loss: -1.670,Avg.Loss: -1.345,LR: 4.76E-04]Training epoch 15:   9%|▉         | 10/112 [00:00<00:01, 57.28it/s, Epoch: 15, Batch: 11,Loss: -1.695,Avg.Loss: -1.377,LR: 4.76E-04]Training epoch 15:  10%|▉         | 11/112 [00:00<00:01, 57.28it/s, Epoch: 15, Batch: 12,Loss: -1.234,Avg.Loss: -1.365,LR: 4.76E-04]Training epoch 15:  11%|█         | 12/112 [00:00<00:01, 57.28it/s, Epoch: 15, Batch: 13,Loss: -1.273,Avg.Loss: -1.358,LR: 4.76E-04]Training epoch 15:  12%|█▏        | 13/112 [00:00<00:01, 60.75it/s, Epoch: 15, Batch: 13,Loss: -1.273,Avg.Loss: -1.358,LR: 4.76E-04]Training epoch 15:  12%|█▏        | 13/112 [00:00<00:01, 60.75it/s, Epoch: 15, Batch: 14,Loss: -1.603,Avg.Loss: -1.376,LR: 4.76E-04]Training epoch 15:  12%|█▎        | 14/112 [00:00<00:01, 60.75it/s, Epoch: 15, Batch: 15,Loss: -1.547,Avg.Loss: -1.387,LR: 4.76E-04]Training epoch 15:  13%|█▎        | 15/112 [00:00<00:01, 60.75it/s, Epoch: 15, Batch: 16,Loss: -1.007,Avg.Loss: -1.363,LR: 4.76E-04]Training epoch 15:  14%|█▍        | 16/112 [00:00<00:01, 60.75it/s, Epoch: 15, Batch: 17,Loss: -0.678,Avg.Loss: -1.323,LR: 4.76E-04]Training epoch 15:  15%|█▌        | 17/112 [00:00<00:01, 60.75it/s, Epoch: 15, Batch: 18,Loss: -1.614,Avg.Loss: -1.339,LR: 4.76E-04]Training epoch 15:  16%|█▌        | 18/112 [00:00<00:01, 60.75it/s, Epoch: 15, Batch: 19,Loss: -1.141,Avg.Loss: -1.329,LR: 4.76E-04]Training epoch 15:  17%|█▋        | 19/112 [00:00<00:01, 60.75it/s, Epoch: 15, Batch: 20,Loss: -1.313,Avg.Loss: -1.328,LR: 4.76E-04]Training epoch 15:  18%|█▊        | 20/112 [00:00<00:01, 56.44it/s, Epoch: 15, Batch: 20,Loss: -1.313,Avg.Loss: -1.328,LR: 4.76E-04]Training epoch 15:  18%|█▊        | 20/112 [00:00<00:01, 56.44it/s, Epoch: 15, Batch: 21,Loss: -1.360,Avg.Loss: -1.329,LR: 4.76E-04]Training epoch 15:  19%|█▉        | 21/112 [00:00<00:01, 56.44it/s, Epoch: 15, Batch: 22,Loss: -1.398,Avg.Loss: -1.333,LR: 4.76E-04]Training epoch 15:  20%|█▉        | 22/112 [00:00<00:01, 56.44it/s, Epoch: 15, Batch: 23,Loss: -1.914,Avg.Loss: -1.358,LR: 4.76E-04]Training epoch 15:  21%|██        | 23/112 [00:00<00:01, 56.44it/s, Epoch: 15, Batch: 24,Loss: -1.661,Avg.Loss: -1.370,LR: 4.75E-04]Training epoch 15:  21%|██▏       | 24/112 [00:00<00:01, 56.44it/s, Epoch: 15, Batch: 25,Loss: -1.367,Avg.Loss: -1.370,LR: 4.75E-04]Training epoch 15:  22%|██▏       | 25/112 [00:00<00:01, 56.44it/s, Epoch: 15, Batch: 26,Loss: -1.737,Avg.Loss: -1.384,LR: 4.75E-04]Training epoch 15:  23%|██▎       | 26/112 [00:00<00:01, 54.95it/s, Epoch: 15, Batch: 26,Loss: -1.737,Avg.Loss: -1.384,LR: 4.75E-04]Training epoch 15:  23%|██▎       | 26/112 [00:00<00:01, 54.95it/s, Epoch: 15, Batch: 27,Loss: -0.195,Avg.Loss: -1.340,LR: 4.75E-04]Training epoch 15:  24%|██▍       | 27/112 [00:00<00:01, 54.95it/s, Epoch: 15, Batch: 28,Loss: -0.989,Avg.Loss: -1.328,LR: 4.75E-04]Training epoch 15:  25%|██▌       | 28/112 [00:00<00:01, 54.95it/s, Epoch: 15, Batch: 29,Loss: -1.421,Avg.Loss: -1.331,LR: 4.75E-04]Training epoch 15:  26%|██▌       | 29/112 [00:00<00:01, 54.95it/s, Epoch: 15, Batch: 30,Loss: 0.902,Avg.Loss: -1.257,LR: 4.75E-04] Training epoch 15:  27%|██▋       | 30/112 [00:00<00:01, 54.95it/s, Epoch: 15, Batch: 31,Loss: 2.220,Avg.Loss: -1.144,LR: 4.75E-04]Training epoch 15:  28%|██▊       | 31/112 [00:00<00:01, 54.95it/s, Epoch: 15, Batch: 32,Loss: 0.947,Avg.Loss: -1.079,LR: 4.75E-04]Training epoch 15:  29%|██▊       | 32/112 [00:00<00:01, 54.12it/s, Epoch: 15, Batch: 32,Loss: 0.947,Avg.Loss: -1.079,LR: 4.75E-04]Training epoch 15:  29%|██▊       | 32/112 [00:00<00:01, 54.12it/s, Epoch: 15, Batch: 33,Loss: -1.211,Avg.Loss: -1.083,LR: 4.75E-04]Training epoch 15:  29%|██▉       | 33/112 [00:00<00:01, 54.12it/s, Epoch: 15, Batch: 34,Loss: 1.945,Avg.Loss: -0.994,LR: 4.75E-04] Training epoch 15:  30%|███       | 34/112 [00:00<00:01, 54.12it/s, Epoch: 15, Batch: 35,Loss: 6.900,Avg.Loss: -0.768,LR: 4.75E-04]Training epoch 15:  31%|███▏      | 35/112 [00:00<00:01, 54.12it/s, Epoch: 15, Batch: 36,Loss: 5.585,Avg.Loss: -0.592,LR: 4.75E-04]Training epoch 15:  32%|███▏      | 36/112 [00:00<00:01, 54.12it/s, Epoch: 15, Batch: 37,Loss: 1.128,Avg.Loss: -0.546,LR: 4.75E-04]Training epoch 15:  33%|███▎      | 37/112 [00:00<00:01, 54.12it/s, Epoch: 15, Batch: 38,Loss: -1.574,Avg.Loss: -0.573,LR: 4.75E-04]Training epoch 15:  34%|███▍      | 38/112 [00:00<00:01, 53.92it/s, Epoch: 15, Batch: 38,Loss: -1.574,Avg.Loss: -0.573,LR: 4.75E-04]Training epoch 15:  34%|███▍      | 38/112 [00:00<00:01, 53.92it/s, Epoch: 15, Batch: 39,Loss: -0.116,Avg.Loss: -0.561,LR: 4.75E-04]Training epoch 15:  35%|███▍      | 39/112 [00:00<00:01, 53.92it/s, Epoch: 15, Batch: 40,Loss: 0.369,Avg.Loss: -0.538,LR: 4.75E-04] Training epoch 15:  36%|███▌      | 40/112 [00:00<00:01, 53.92it/s, Epoch: 15, Batch: 41,Loss: -0.672,Avg.Loss: -0.541,LR: 4.75E-04]Training epoch 15:  37%|███▋      | 41/112 [00:00<00:01, 53.92it/s, Epoch: 15, Batch: 42,Loss: 1.878,Avg.Loss: -0.483,LR: 4.75E-04] Training epoch 15:  38%|███▊      | 42/112 [00:00<00:01, 53.92it/s, Epoch: 15, Batch: 43,Loss: 3.890,Avg.Loss: -0.382,LR: 4.75E-04]Training epoch 15:  38%|███▊      | 43/112 [00:00<00:01, 53.92it/s, Epoch: 15, Batch: 44,Loss: 3.090,Avg.Loss: -0.303,LR: 4.75E-04]Training epoch 15:  39%|███▉      | 44/112 [00:00<00:01, 53.69it/s, Epoch: 15, Batch: 44,Loss: 3.090,Avg.Loss: -0.303,LR: 4.75E-04]Training epoch 15:  39%|███▉      | 44/112 [00:00<00:01, 53.69it/s, Epoch: 15, Batch: 45,Loss: 0.140,Avg.Loss: -0.293,LR: 4.75E-04]Training epoch 15:  40%|████      | 45/112 [00:00<00:01, 53.69it/s, Epoch: 15, Batch: 46,Loss: -0.032,Avg.Loss: -0.287,LR: 4.75E-04]Training epoch 15:  41%|████      | 46/112 [00:00<00:01, 53.69it/s, Epoch: 15, Batch: 47,Loss: -0.020,Avg.Loss: -0.282,LR: 4.75E-04]Training epoch 15:  42%|████▏     | 47/112 [00:00<00:01, 53.69it/s, Epoch: 15, Batch: 48,Loss: -0.111,Avg.Loss: -0.278,LR: 4.75E-04]Training epoch 15:  43%|████▎     | 48/112 [00:00<00:01, 53.69it/s, Epoch: 15, Batch: 49,Loss: 0.131,Avg.Loss: -0.270,LR: 4.75E-04] Training epoch 15:  44%|████▍     | 49/112 [00:00<00:01, 53.69it/s, Epoch: 15, Batch: 50,Loss: -0.279,Avg.Loss: -0.270,LR: 4.75E-04]Training epoch 15:  45%|████▍     | 50/112 [00:00<00:01, 53.40it/s, Epoch: 15, Batch: 50,Loss: -0.279,Avg.Loss: -0.270,LR: 4.75E-04]Training epoch 15:  45%|████▍     | 50/112 [00:00<00:01, 53.40it/s, Epoch: 15, Batch: 51,Loss: -0.703,Avg.Loss: -0.278,LR: 4.75E-04]Training epoch 15:  46%|████▌     | 51/112 [00:00<00:01, 53.40it/s, Epoch: 15, Batch: 52,Loss: -1.469,Avg.Loss: -0.301,LR: 4.75E-04]Training epoch 15:  46%|████▋     | 52/112 [00:00<00:01, 53.40it/s, Epoch: 15, Batch: 53,Loss: -1.209,Avg.Loss: -0.318,LR: 4.75E-04]Training epoch 15:  47%|████▋     | 53/112 [00:00<00:01, 53.40it/s, Epoch: 15, Batch: 54,Loss: -1.377,Avg.Loss: -0.338,LR: 4.75E-04]Training epoch 15:  48%|████▊     | 54/112 [00:01<00:01, 53.40it/s, Epoch: 15, Batch: 55,Loss: -1.180,Avg.Loss: -0.353,LR: 4.75E-04]Training epoch 15:  49%|████▉     | 55/112 [00:01<00:01, 53.40it/s, Epoch: 15, Batch: 56,Loss: -1.397,Avg.Loss: -0.372,LR: 4.75E-04]Training epoch 15:  50%|█████     | 56/112 [00:01<00:01, 53.44it/s, Epoch: 15, Batch: 56,Loss: -1.397,Avg.Loss: -0.372,LR: 4.75E-04]Training epoch 15:  50%|█████     | 56/112 [00:01<00:01, 53.44it/s, Epoch: 15, Batch: 57,Loss: -0.835,Avg.Loss: -0.380,LR: 4.74E-04]Training epoch 15:  51%|█████     | 57/112 [00:01<00:01, 53.44it/s, Epoch: 15, Batch: 58,Loss: -1.271,Avg.Loss: -0.395,LR: 4.74E-04]Training epoch 15:  52%|█████▏    | 58/112 [00:01<00:01, 53.44it/s, Epoch: 15, Batch: 59,Loss: -1.091,Avg.Loss: -0.407,LR: 4.74E-04]Training epoch 15:  53%|█████▎    | 59/112 [00:01<00:00, 53.44it/s, Epoch: 15, Batch: 60,Loss: -1.044,Avg.Loss: -0.418,LR: 4.74E-04]Training epoch 15:  54%|█████▎    | 60/112 [00:01<00:00, 53.44it/s, Epoch: 15, Batch: 61,Loss: -0.604,Avg.Loss: -0.421,LR: 4.74E-04]Training epoch 15:  54%|█████▍    | 61/112 [00:01<00:00, 53.44it/s, Epoch: 15, Batch: 62,Loss: -0.803,Avg.Loss: -0.427,LR: 4.74E-04]Training epoch 15:  55%|█████▌    | 62/112 [00:01<00:00, 53.46it/s, Epoch: 15, Batch: 62,Loss: -0.803,Avg.Loss: -0.427,LR: 4.74E-04]Training epoch 15:  55%|█████▌    | 62/112 [00:01<00:00, 53.46it/s, Epoch: 15, Batch: 63,Loss: -0.895,Avg.Loss: -0.434,LR: 4.74E-04]Training epoch 15:  56%|█████▋    | 63/112 [00:01<00:00, 53.46it/s, Epoch: 15, Batch: 64,Loss: -1.508,Avg.Loss: -0.451,LR: 4.74E-04]Training epoch 15:  57%|█████▋    | 64/112 [00:01<00:00, 53.46it/s, Epoch: 15, Batch: 65,Loss: -1.149,Avg.Loss: -0.462,LR: 4.74E-04]Training epoch 15:  58%|█████▊    | 65/112 [00:01<00:00, 53.46it/s, Epoch: 15, Batch: 66,Loss: -1.042,Avg.Loss: -0.471,LR: 4.74E-04]Training epoch 15:  59%|█████▉    | 66/112 [00:01<00:00, 53.46it/s, Epoch: 15, Batch: 67,Loss: -1.349,Avg.Loss: -0.484,LR: 4.74E-04]Training epoch 15:  60%|█████▉    | 67/112 [00:01<00:00, 53.46it/s, Epoch: 15, Batch: 68,Loss: -0.792,Avg.Loss: -0.488,LR: 4.74E-04]Training epoch 15:  61%|██████    | 68/112 [00:01<00:00, 53.54it/s, Epoch: 15, Batch: 68,Loss: -0.792,Avg.Loss: -0.488,LR: 4.74E-04]Training epoch 15:  61%|██████    | 68/112 [00:01<00:00, 53.54it/s, Epoch: 15, Batch: 69,Loss: -1.122,Avg.Loss: -0.498,LR: 4.74E-04]Training epoch 15:  62%|██████▏   | 69/112 [00:01<00:00, 53.54it/s, Epoch: 15, Batch: 70,Loss: -1.014,Avg.Loss: -0.505,LR: 4.74E-04]Training epoch 15:  62%|██████▎   | 70/112 [00:01<00:00, 53.54it/s, Epoch: 15, Batch: 71,Loss: -1.426,Avg.Loss: -0.518,LR: 4.74E-04]Training epoch 15:  63%|██████▎   | 71/112 [00:01<00:00, 53.54it/s, Epoch: 15, Batch: 72,Loss: -1.343,Avg.Loss: -0.529,LR: 4.74E-04]Training epoch 15:  64%|██████▍   | 72/112 [00:01<00:00, 53.54it/s, Epoch: 15, Batch: 73,Loss: -1.321,Avg.Loss: -0.540,LR: 4.74E-04]Training epoch 15:  65%|██████▌   | 73/112 [00:01<00:00, 53.54it/s, Epoch: 15, Batch: 74,Loss: -1.231,Avg.Loss: -0.550,LR: 4.74E-04]Training epoch 15:  66%|██████▌   | 74/112 [00:01<00:00, 53.59it/s, Epoch: 15, Batch: 74,Loss: -1.231,Avg.Loss: -0.550,LR: 4.74E-04]Training epoch 15:  66%|██████▌   | 74/112 [00:01<00:00, 53.59it/s, Epoch: 15, Batch: 75,Loss: -1.188,Avg.Loss: -0.558,LR: 4.74E-04]Training epoch 15:  67%|██████▋   | 75/112 [00:01<00:00, 53.59it/s, Epoch: 15, Batch: 76,Loss: -1.277,Avg.Loss: -0.568,LR: 4.74E-04]Training epoch 15:  68%|██████▊   | 76/112 [00:01<00:00, 53.59it/s, Epoch: 15, Batch: 77,Loss: -1.623,Avg.Loss: -0.581,LR: 4.74E-04]Training epoch 15:  69%|██████▉   | 77/112 [00:01<00:00, 53.59it/s, Epoch: 15, Batch: 78,Loss: -1.546,Avg.Loss: -0.594,LR: 4.74E-04]Training epoch 15:  70%|██████▉   | 78/112 [00:01<00:00, 53.59it/s, Epoch: 15, Batch: 79,Loss: -0.766,Avg.Loss: -0.596,LR: 4.74E-04]Training epoch 15:  71%|███████   | 79/112 [00:01<00:00, 53.59it/s, Epoch: 15, Batch: 80,Loss: -1.026,Avg.Loss: -0.601,LR: 4.74E-04]Training epoch 15:  71%|███████▏  | 80/112 [00:01<00:00, 53.61it/s, Epoch: 15, Batch: 80,Loss: -1.026,Avg.Loss: -0.601,LR: 4.74E-04]Training epoch 15:  71%|███████▏  | 80/112 [00:01<00:00, 53.61it/s, Epoch: 15, Batch: 81,Loss: -1.239,Avg.Loss: -0.609,LR: 4.74E-04]Training epoch 15:  72%|███████▏  | 81/112 [00:01<00:00, 53.61it/s, Epoch: 15, Batch: 82,Loss: -1.401,Avg.Loss: -0.619,LR: 4.74E-04]Training epoch 15:  73%|███████▎  | 82/112 [00:01<00:00, 53.61it/s, Epoch: 15, Batch: 83,Loss: -1.112,Avg.Loss: -0.625,LR: 4.74E-04]Training epoch 15:  74%|███████▍  | 83/112 [00:01<00:00, 53.61it/s, Epoch: 15, Batch: 84,Loss: -1.117,Avg.Loss: -0.631,LR: 4.74E-04]Training epoch 15:  75%|███████▌  | 84/112 [00:01<00:00, 53.61it/s, Epoch: 15, Batch: 85,Loss: -1.511,Avg.Loss: -0.641,LR: 4.74E-04]Training epoch 15:  76%|███████▌  | 85/112 [00:01<00:00, 53.61it/s, Epoch: 15, Batch: 86,Loss: -1.372,Avg.Loss: -0.649,LR: 4.74E-04]Training epoch 15:  77%|███████▋  | 86/112 [00:01<00:00, 53.80it/s, Epoch: 15, Batch: 86,Loss: -1.372,Avg.Loss: -0.649,LR: 4.74E-04]Training epoch 15:  77%|███████▋  | 86/112 [00:01<00:00, 53.80it/s, Epoch: 15, Batch: 87,Loss: -1.019,Avg.Loss: -0.654,LR: 4.74E-04]Training epoch 15:  78%|███████▊  | 87/112 [00:01<00:00, 53.80it/s, Epoch: 15, Batch: 88,Loss: -1.195,Avg.Loss: -0.660,LR: 4.74E-04]Training epoch 15:  79%|███████▊  | 88/112 [00:01<00:00, 53.80it/s, Epoch: 15, Batch: 89,Loss: -1.486,Avg.Loss: -0.669,LR: 4.73E-04]Training epoch 15:  79%|███████▉  | 89/112 [00:01<00:00, 53.80it/s, Epoch: 15, Batch: 90,Loss: -1.534,Avg.Loss: -0.679,LR: 4.73E-04]Training epoch 15:  80%|████████  | 90/112 [00:01<00:00, 53.80it/s, Epoch: 15, Batch: 91,Loss: -1.252,Avg.Loss: -0.685,LR: 4.73E-04]Training epoch 15:  81%|████████▏ | 91/112 [00:01<00:00, 53.80it/s, Epoch: 15, Batch: 92,Loss: -1.410,Avg.Loss: -0.693,LR: 4.73E-04]Training epoch 15:  82%|████████▏ | 92/112 [00:01<00:00, 53.73it/s, Epoch: 15, Batch: 92,Loss: -1.410,Avg.Loss: -0.693,LR: 4.73E-04]Training epoch 15:  82%|████████▏ | 92/112 [00:01<00:00, 53.73it/s, Epoch: 15, Batch: 93,Loss: -1.241,Avg.Loss: -0.699,LR: 4.73E-04]Training epoch 15:  83%|████████▎ | 93/112 [00:01<00:00, 53.73it/s, Epoch: 15, Batch: 94,Loss: -0.849,Avg.Loss: -0.700,LR: 4.73E-04]Training epoch 15:  84%|████████▍ | 94/112 [00:01<00:00, 53.73it/s, Epoch: 15, Batch: 95,Loss: -1.653,Avg.Loss: -0.710,LR: 4.73E-04]Training epoch 15:  85%|████████▍ | 95/112 [00:01<00:00, 53.73it/s, Epoch: 15, Batch: 96,Loss: -1.664,Avg.Loss: -0.720,LR: 4.73E-04]Training epoch 15:  86%|████████▌ | 96/112 [00:01<00:00, 53.73it/s, Epoch: 15, Batch: 97,Loss: -1.127,Avg.Loss: -0.724,LR: 4.73E-04]Training epoch 15:  87%|████████▋ | 97/112 [00:01<00:00, 53.73it/s, Epoch: 15, Batch: 98,Loss: -0.951,Avg.Loss: -0.727,LR: 4.73E-04]Training epoch 15:  88%|████████▊ | 98/112 [00:01<00:00, 53.25it/s, Epoch: 15, Batch: 98,Loss: -0.951,Avg.Loss: -0.727,LR: 4.73E-04]Training epoch 15:  88%|████████▊ | 98/112 [00:01<00:00, 53.25it/s, Epoch: 15, Batch: 99,Loss: -1.754,Avg.Loss: -0.737,LR: 4.73E-04]Training epoch 15:  88%|████████▊ | 99/112 [00:01<00:00, 53.25it/s, Epoch: 15, Batch: 100,Loss: -1.658,Avg.Loss: -0.746,LR: 4.73E-04]Training epoch 15:  89%|████████▉ | 100/112 [00:01<00:00, 53.25it/s, Epoch: 15, Batch: 101,Loss: -1.267,Avg.Loss: -0.752,LR: 4.73E-04]Training epoch 15:  90%|█████████ | 101/112 [00:01<00:00, 53.25it/s, Epoch: 15, Batch: 102,Loss: -1.427,Avg.Loss: -0.758,LR: 4.73E-04]Training epoch 15:  91%|█████████ | 102/112 [00:01<00:00, 53.25it/s, Epoch: 15, Batch: 103,Loss: -1.490,Avg.Loss: -0.765,LR: 4.73E-04]Training epoch 15:  92%|█████████▏| 103/112 [00:01<00:00, 53.25it/s, Epoch: 15, Batch: 104,Loss: -1.422,Avg.Loss: -0.772,LR: 4.73E-04]Training epoch 15:  93%|█████████▎| 104/112 [00:01<00:00, 53.16it/s, Epoch: 15, Batch: 104,Loss: -1.422,Avg.Loss: -0.772,LR: 4.73E-04]Training epoch 15:  93%|█████████▎| 104/112 [00:01<00:00, 53.16it/s, Epoch: 15, Batch: 105,Loss: -1.610,Avg.Loss: -0.780,LR: 4.73E-04]Training epoch 15:  94%|█████████▍| 105/112 [00:01<00:00, 53.16it/s, Epoch: 15, Batch: 106,Loss: -1.381,Avg.Loss: -0.785,LR: 4.73E-04]Training epoch 15:  95%|█████████▍| 106/112 [00:01<00:00, 53.16it/s, Epoch: 15, Batch: 107,Loss: -1.288,Avg.Loss: -0.790,LR: 4.73E-04]Training epoch 15:  96%|█████████▌| 107/112 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 108,Loss: -0.988,Avg.Loss: -0.792,LR: 4.73E-04]Training epoch 15:  96%|█████████▋| 108/112 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 109,Loss: -1.440,Avg.Loss: -0.798,LR: 4.73E-04]Training epoch 15:  97%|█████████▋| 109/112 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 110,Loss: -1.699,Avg.Loss: -0.806,LR: 4.73E-04]Training epoch 15:  98%|█████████▊| 110/112 [00:02<00:00, 53.37it/s, Epoch: 15, Batch: 110,Loss: -1.699,Avg.Loss: -0.806,LR: 4.73E-04]Training epoch 15:  98%|█████████▊| 110/112 [00:02<00:00, 53.37it/s, Epoch: 15, Batch: 111,Loss: -1.044,Avg.Loss: -0.808,LR: 4.73E-04]Training epoch 15:  99%|█████████▉| 111/112 [00:02<00:00, 53.37it/s, Epoch: 15, Batch: 112,Loss: -1.395,Avg.Loss: -0.813,LR: 4.73E-04]Training epoch 15: 100%|██████████| 112/112 [00:02<00:00, 53.88it/s, Epoch: 15, Batch: 112,Loss: -1.395,Avg.Loss: -0.813,LR: 4.73E-04]
Training epoch 16:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 16:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 16, Batch: 1,Loss: -1.543,Avg.Loss: -1.543,LR: 4.73E-04]Training epoch 16:   1%|          | 1/112 [00:00<00:04, 27.68it/s, Epoch: 16, Batch: 2,Loss: -1.399,Avg.Loss: -1.471,LR: 4.73E-04]Training epoch 16:   2%|▏         | 2/112 [00:00<00:03, 34.08it/s, Epoch: 16, Batch: 3,Loss: -0.675,Avg.Loss: -1.206,LR: 4.73E-04]Training epoch 16:   3%|▎         | 3/112 [00:00<00:02, 38.83it/s, Epoch: 16, Batch: 4,Loss: -0.745,Avg.Loss: -1.090,LR: 4.73E-04]Training epoch 16:   4%|▎         | 4/112 [00:00<00:02, 42.59it/s, Epoch: 16, Batch: 5,Loss: -1.463,Avg.Loss: -1.165,LR: 4.73E-04]Training epoch 16:   4%|▍         | 5/112 [00:00<00:02, 46.06it/s, Epoch: 16, Batch: 6,Loss: -1.730,Avg.Loss: -1.259,LR: 4.73E-04]Training epoch 16:   5%|▌         | 6/112 [00:00<00:01, 55.20it/s, Epoch: 16, Batch: 6,Loss: -1.730,Avg.Loss: -1.259,LR: 4.73E-04]Training epoch 16:   5%|▌         | 6/112 [00:00<00:01, 55.20it/s, Epoch: 16, Batch: 7,Loss: -1.171,Avg.Loss: -1.247,LR: 4.73E-04]Training epoch 16:   6%|▋         | 7/112 [00:00<00:01, 55.20it/s, Epoch: 16, Batch: 8,Loss: -1.517,Avg.Loss: -1.280,LR: 4.72E-04]Training epoch 16:   7%|▋         | 8/112 [00:00<00:01, 55.20it/s, Epoch: 16, Batch: 9,Loss: -1.065,Avg.Loss: -1.256,LR: 4.72E-04]Training epoch 16:   8%|▊         | 9/112 [00:00<00:01, 55.20it/s, Epoch: 16, Batch: 10,Loss: -1.362,Avg.Loss: -1.267,LR: 4.72E-04]Training epoch 16:   9%|▉         | 10/112 [00:00<00:01, 55.20it/s, Epoch: 16, Batch: 11,Loss: -1.260,Avg.Loss: -1.266,LR: 4.72E-04]Training epoch 16:  10%|▉         | 11/112 [00:00<00:01, 55.20it/s, Epoch: 16, Batch: 12,Loss: -0.913,Avg.Loss: -1.237,LR: 4.72E-04]Training epoch 16:  11%|█         | 12/112 [00:00<00:01, 56.54it/s, Epoch: 16, Batch: 12,Loss: -0.913,Avg.Loss: -1.237,LR: 4.72E-04]Training epoch 16:  11%|█         | 12/112 [00:00<00:01, 56.54it/s, Epoch: 16, Batch: 13,Loss: -1.379,Avg.Loss: -1.248,LR: 4.72E-04]Training epoch 16:  12%|█▏        | 13/112 [00:00<00:01, 56.54it/s, Epoch: 16, Batch: 14,Loss: -1.283,Avg.Loss: -1.250,LR: 4.72E-04]Training epoch 16:  12%|█▎        | 14/112 [00:00<00:01, 56.54it/s, Epoch: 16, Batch: 15,Loss: -1.550,Avg.Loss: -1.270,LR: 4.72E-04]Training epoch 16:  13%|█▎        | 15/112 [00:00<00:01, 56.54it/s, Epoch: 16, Batch: 16,Loss: -1.123,Avg.Loss: -1.261,LR: 4.72E-04]Training epoch 16:  14%|█▍        | 16/112 [00:00<00:01, 56.54it/s, Epoch: 16, Batch: 17,Loss: -1.553,Avg.Loss: -1.278,LR: 4.72E-04]Training epoch 16:  15%|█▌        | 17/112 [00:00<00:01, 56.54it/s, Epoch: 16, Batch: 18,Loss: -1.187,Avg.Loss: -1.273,LR: 4.72E-04]Training epoch 16:  16%|█▌        | 18/112 [00:00<00:01, 54.87it/s, Epoch: 16, Batch: 18,Loss: -1.187,Avg.Loss: -1.273,LR: 4.72E-04]Training epoch 16:  16%|█▌        | 18/112 [00:00<00:01, 54.87it/s, Epoch: 16, Batch: 19,Loss: -1.327,Avg.Loss: -1.276,LR: 4.72E-04]Training epoch 16:  17%|█▋        | 19/112 [00:00<00:01, 54.87it/s, Epoch: 16, Batch: 20,Loss: -1.461,Avg.Loss: -1.285,LR: 4.72E-04]Training epoch 16:  18%|█▊        | 20/112 [00:00<00:01, 54.87it/s, Epoch: 16, Batch: 21,Loss: -1.546,Avg.Loss: -1.298,LR: 4.72E-04]Training epoch 16:  19%|█▉        | 21/112 [00:00<00:01, 54.87it/s, Epoch: 16, Batch: 22,Loss: -1.411,Avg.Loss: -1.303,LR: 4.72E-04]Training epoch 16:  20%|█▉        | 22/112 [00:00<00:01, 54.87it/s, Epoch: 16, Batch: 23,Loss: -1.548,Avg.Loss: -1.313,LR: 4.72E-04]Training epoch 16:  21%|██        | 23/112 [00:00<00:01, 54.87it/s, Epoch: 16, Batch: 24,Loss: -1.603,Avg.Loss: -1.326,LR: 4.72E-04]Training epoch 16:  21%|██▏       | 24/112 [00:00<00:01, 53.95it/s, Epoch: 16, Batch: 24,Loss: -1.603,Avg.Loss: -1.326,LR: 4.72E-04]Training epoch 16:  21%|██▏       | 24/112 [00:00<00:01, 53.95it/s, Epoch: 16, Batch: 25,Loss: -1.265,Avg.Loss: -1.323,LR: 4.72E-04]Training epoch 16:  22%|██▏       | 25/112 [00:00<00:01, 53.95it/s, Epoch: 16, Batch: 26,Loss: -1.507,Avg.Loss: -1.330,LR: 4.72E-04]Training epoch 16:  23%|██▎       | 26/112 [00:00<00:01, 53.95it/s, Epoch: 16, Batch: 27,Loss: -1.184,Avg.Loss: -1.325,LR: 4.72E-04]Training epoch 16:  24%|██▍       | 27/112 [00:00<00:01, 53.95it/s, Epoch: 16, Batch: 28,Loss: -1.479,Avg.Loss: -1.330,LR: 4.72E-04]Training epoch 16:  25%|██▌       | 28/112 [00:00<00:01, 53.95it/s, Epoch: 16, Batch: 29,Loss: -1.787,Avg.Loss: -1.346,LR: 4.72E-04]Training epoch 16:  26%|██▌       | 29/112 [00:00<00:01, 53.95it/s, Epoch: 16, Batch: 30,Loss: -1.504,Avg.Loss: -1.351,LR: 4.72E-04]Training epoch 16:  27%|██▋       | 30/112 [00:00<00:01, 53.12it/s, Epoch: 16, Batch: 30,Loss: -1.504,Avg.Loss: -1.351,LR: 4.72E-04]Training epoch 16:  27%|██▋       | 30/112 [00:00<00:01, 53.12it/s, Epoch: 16, Batch: 31,Loss: -1.287,Avg.Loss: -1.349,LR: 4.72E-04]Training epoch 16:  28%|██▊       | 31/112 [00:00<00:01, 53.12it/s, Epoch: 16, Batch: 32,Loss: -1.201,Avg.Loss: -1.345,LR: 4.72E-04]Training epoch 16:  29%|██▊       | 32/112 [00:00<00:01, 53.12it/s, Epoch: 16, Batch: 33,Loss: -1.819,Avg.Loss: -1.359,LR: 4.72E-04]Training epoch 16:  29%|██▉       | 33/112 [00:00<00:01, 53.12it/s, Epoch: 16, Batch: 34,Loss: -1.714,Avg.Loss: -1.369,LR: 4.72E-04]Training epoch 16:  30%|███       | 34/112 [00:00<00:01, 53.12it/s, Epoch: 16, Batch: 35,Loss: -0.909,Avg.Loss: -1.356,LR: 4.72E-04]Training epoch 16:  31%|███▏      | 35/112 [00:00<00:01, 53.12it/s, Epoch: 16, Batch: 36,Loss: -1.442,Avg.Loss: -1.359,LR: 4.72E-04]Training epoch 16:  32%|███▏      | 36/112 [00:00<00:01, 52.61it/s, Epoch: 16, Batch: 36,Loss: -1.442,Avg.Loss: -1.359,LR: 4.72E-04]Training epoch 16:  32%|███▏      | 36/112 [00:00<00:01, 52.61it/s, Epoch: 16, Batch: 37,Loss: -1.669,Avg.Loss: -1.367,LR: 4.72E-04]Training epoch 16:  33%|███▎      | 37/112 [00:00<00:01, 52.61it/s, Epoch: 16, Batch: 38,Loss: -1.765,Avg.Loss: -1.377,LR: 4.72E-04]Training epoch 16:  34%|███▍      | 38/112 [00:00<00:01, 52.61it/s, Epoch: 16, Batch: 39,Loss: -1.483,Avg.Loss: -1.380,LR: 4.71E-04]Training epoch 16:  35%|███▍      | 39/112 [00:00<00:01, 52.61it/s, Epoch: 16, Batch: 40,Loss: -1.795,Avg.Loss: -1.391,LR: 4.71E-04]Training epoch 16:  36%|███▌      | 40/112 [00:00<00:01, 52.61it/s, Epoch: 16, Batch: 41,Loss: -1.188,Avg.Loss: -1.386,LR: 4.71E-04]Training epoch 16:  37%|███▋      | 41/112 [00:00<00:01, 52.61it/s, Epoch: 16, Batch: 42,Loss: -1.575,Avg.Loss: -1.390,LR: 4.71E-04]Training epoch 16:  38%|███▊      | 42/112 [00:00<00:01, 52.59it/s, Epoch: 16, Batch: 42,Loss: -1.575,Avg.Loss: -1.390,LR: 4.71E-04]Training epoch 16:  38%|███▊      | 42/112 [00:00<00:01, 52.59it/s, Epoch: 16, Batch: 43,Loss: -1.397,Avg.Loss: -1.390,LR: 4.71E-04]Training epoch 16:  38%|███▊      | 43/112 [00:00<00:01, 52.59it/s, Epoch: 16, Batch: 44,Loss: -0.688,Avg.Loss: -1.374,LR: 4.71E-04]Training epoch 16:  39%|███▉      | 44/112 [00:00<00:01, 52.59it/s, Epoch: 16, Batch: 45,Loss: -1.539,Avg.Loss: -1.378,LR: 4.71E-04]Training epoch 16:  40%|████      | 45/112 [00:00<00:01, 52.59it/s, Epoch: 16, Batch: 46,Loss: -1.898,Avg.Loss: -1.389,LR: 4.71E-04]Training epoch 16:  41%|████      | 46/112 [00:00<00:01, 52.59it/s, Epoch: 16, Batch: 47,Loss: -1.767,Avg.Loss: -1.397,LR: 4.71E-04]Training epoch 16:  42%|████▏     | 47/112 [00:00<00:01, 52.59it/s, Epoch: 16, Batch: 48,Loss: -1.463,Avg.Loss: -1.399,LR: 4.71E-04]Training epoch 16:  43%|████▎     | 48/112 [00:00<00:01, 52.87it/s, Epoch: 16, Batch: 48,Loss: -1.463,Avg.Loss: -1.399,LR: 4.71E-04]Training epoch 16:  43%|████▎     | 48/112 [00:00<00:01, 52.87it/s, Epoch: 16, Batch: 49,Loss: -1.560,Avg.Loss: -1.402,LR: 4.71E-04]Training epoch 16:  44%|████▍     | 49/112 [00:00<00:01, 52.87it/s, Epoch: 16, Batch: 50,Loss: -0.882,Avg.Loss: -1.392,LR: 4.71E-04]Training epoch 16:  45%|████▍     | 50/112 [00:00<00:01, 52.87it/s, Epoch: 16, Batch: 51,Loss: -1.692,Avg.Loss: -1.397,LR: 4.71E-04]Training epoch 16:  46%|████▌     | 51/112 [00:00<00:01, 52.87it/s, Epoch: 16, Batch: 52,Loss: -1.426,Avg.Loss: -1.398,LR: 4.71E-04]Training epoch 16:  46%|████▋     | 52/112 [00:00<00:01, 52.87it/s, Epoch: 16, Batch: 53,Loss: -1.832,Avg.Loss: -1.406,LR: 4.71E-04]Training epoch 16:  47%|████▋     | 53/112 [00:01<00:01, 52.87it/s, Epoch: 16, Batch: 54,Loss: -1.444,Avg.Loss: -1.407,LR: 4.71E-04]Training epoch 16:  48%|████▊     | 54/112 [00:01<00:01, 53.16it/s, Epoch: 16, Batch: 54,Loss: -1.444,Avg.Loss: -1.407,LR: 4.71E-04]Training epoch 16:  48%|████▊     | 54/112 [00:01<00:01, 53.16it/s, Epoch: 16, Batch: 55,Loss: -1.463,Avg.Loss: -1.408,LR: 4.71E-04]Training epoch 16:  49%|████▉     | 55/112 [00:01<00:01, 53.16it/s, Epoch: 16, Batch: 56,Loss: -1.496,Avg.Loss: -1.409,LR: 4.71E-04]Training epoch 16:  50%|█████     | 56/112 [00:01<00:01, 53.16it/s, Epoch: 16, Batch: 57,Loss: -1.659,Avg.Loss: -1.414,LR: 4.71E-04]Training epoch 16:  51%|█████     | 57/112 [00:01<00:01, 53.16it/s, Epoch: 16, Batch: 58,Loss: -1.399,Avg.Loss: -1.414,LR: 4.71E-04]Training epoch 16:  52%|█████▏    | 58/112 [00:01<00:01, 53.16it/s, Epoch: 16, Batch: 59,Loss: -1.615,Avg.Loss: -1.417,LR: 4.71E-04]Training epoch 16:  53%|█████▎    | 59/112 [00:01<00:00, 53.16it/s, Epoch: 16, Batch: 60,Loss: -1.627,Avg.Loss: -1.420,LR: 4.71E-04]Training epoch 16:  54%|█████▎    | 60/112 [00:01<00:00, 53.28it/s, Epoch: 16, Batch: 60,Loss: -1.627,Avg.Loss: -1.420,LR: 4.71E-04]Training epoch 16:  54%|█████▎    | 60/112 [00:01<00:00, 53.28it/s, Epoch: 16, Batch: 61,Loss: -1.565,Avg.Loss: -1.423,LR: 4.71E-04]Training epoch 16:  54%|█████▍    | 61/112 [00:01<00:00, 53.28it/s, Epoch: 16, Batch: 62,Loss: -1.453,Avg.Loss: -1.423,LR: 4.71E-04]Training epoch 16:  55%|█████▌    | 62/112 [00:01<00:00, 53.28it/s, Epoch: 16, Batch: 63,Loss: -1.345,Avg.Loss: -1.422,LR: 4.71E-04]Training epoch 16:  56%|█████▋    | 63/112 [00:01<00:00, 53.28it/s, Epoch: 16, Batch: 64,Loss: -1.511,Avg.Loss: -1.424,LR: 4.71E-04]Training epoch 16:  57%|█████▋    | 64/112 [00:01<00:00, 53.28it/s, Epoch: 16, Batch: 65,Loss: -1.603,Avg.Loss: -1.426,LR: 4.71E-04]Training epoch 16:  58%|█████▊    | 65/112 [00:01<00:00, 53.28it/s, Epoch: 16, Batch: 66,Loss: -1.718,Avg.Loss: -1.431,LR: 4.71E-04]Training epoch 16:  59%|█████▉    | 66/112 [00:01<00:00, 53.16it/s, Epoch: 16, Batch: 66,Loss: -1.718,Avg.Loss: -1.431,LR: 4.71E-04]Training epoch 16:  59%|█████▉    | 66/112 [00:01<00:00, 53.16it/s, Epoch: 16, Batch: 67,Loss: -1.722,Avg.Loss: -1.435,LR: 4.71E-04]Training epoch 16:  60%|█████▉    | 67/112 [00:01<00:00, 53.16it/s, Epoch: 16, Batch: 68,Loss: -1.459,Avg.Loss: -1.435,LR: 4.71E-04]Training epoch 16:  61%|██████    | 68/112 [00:01<00:00, 53.16it/s, Epoch: 16, Batch: 69,Loss: -1.340,Avg.Loss: -1.434,LR: 4.71E-04]Training epoch 16:  62%|██████▏   | 69/112 [00:01<00:00, 53.16it/s, Epoch: 16, Batch: 70,Loss: -1.659,Avg.Loss: -1.437,LR: 4.70E-04]Training epoch 16:  62%|██████▎   | 70/112 [00:01<00:00, 53.16it/s, Epoch: 16, Batch: 71,Loss: -1.705,Avg.Loss: -1.441,LR: 4.70E-04]Training epoch 16:  63%|██████▎   | 71/112 [00:01<00:00, 53.16it/s, Epoch: 16, Batch: 72,Loss: -1.522,Avg.Loss: -1.442,LR: 4.70E-04]Training epoch 16:  64%|██████▍   | 72/112 [00:01<00:00, 53.11it/s, Epoch: 16, Batch: 72,Loss: -1.522,Avg.Loss: -1.442,LR: 4.70E-04]Training epoch 16:  64%|██████▍   | 72/112 [00:01<00:00, 53.11it/s, Epoch: 16, Batch: 73,Loss: -1.346,Avg.Loss: -1.441,LR: 4.70E-04]Training epoch 16:  65%|██████▌   | 73/112 [00:01<00:00, 53.11it/s, Epoch: 16, Batch: 74,Loss: -1.765,Avg.Loss: -1.445,LR: 4.70E-04]Training epoch 16:  66%|██████▌   | 74/112 [00:01<00:00, 53.11it/s, Epoch: 16, Batch: 75,Loss: -1.442,Avg.Loss: -1.445,LR: 4.70E-04]Training epoch 16:  67%|██████▋   | 75/112 [00:01<00:00, 53.11it/s, Epoch: 16, Batch: 76,Loss: -1.548,Avg.Loss: -1.446,LR: 4.70E-04]Training epoch 16:  68%|██████▊   | 76/112 [00:01<00:00, 53.11it/s, Epoch: 16, Batch: 77,Loss: -1.596,Avg.Loss: -1.448,LR: 4.70E-04]Training epoch 16:  69%|██████▉   | 77/112 [00:01<00:00, 53.11it/s, Epoch: 16, Batch: 78,Loss: -1.886,Avg.Loss: -1.454,LR: 4.70E-04]Training epoch 16:  70%|██████▉   | 78/112 [00:01<00:00, 53.34it/s, Epoch: 16, Batch: 78,Loss: -1.886,Avg.Loss: -1.454,LR: 4.70E-04]Training epoch 16:  70%|██████▉   | 78/112 [00:01<00:00, 53.34it/s, Epoch: 16, Batch: 79,Loss: -1.630,Avg.Loss: -1.456,LR: 4.70E-04]Training epoch 16:  71%|███████   | 79/112 [00:01<00:00, 53.34it/s, Epoch: 16, Batch: 80,Loss: -1.457,Avg.Loss: -1.456,LR: 4.70E-04]Training epoch 16:  71%|███████▏  | 80/112 [00:01<00:00, 53.34it/s, Epoch: 16, Batch: 81,Loss: -1.445,Avg.Loss: -1.456,LR: 4.70E-04]Training epoch 16:  72%|███████▏  | 81/112 [00:01<00:00, 53.34it/s, Epoch: 16, Batch: 82,Loss: -1.649,Avg.Loss: -1.458,LR: 4.70E-04]Training epoch 16:  73%|███████▎  | 82/112 [00:01<00:00, 53.34it/s, Epoch: 16, Batch: 83,Loss: -1.070,Avg.Loss: -1.454,LR: 4.70E-04]Training epoch 16:  74%|███████▍  | 83/112 [00:01<00:00, 53.34it/s, Epoch: 16, Batch: 84,Loss: -1.760,Avg.Loss: -1.457,LR: 4.70E-04]Training epoch 16:  75%|███████▌  | 84/112 [00:01<00:00, 53.44it/s, Epoch: 16, Batch: 84,Loss: -1.760,Avg.Loss: -1.457,LR: 4.70E-04]Training epoch 16:  75%|███████▌  | 84/112 [00:01<00:00, 53.44it/s, Epoch: 16, Batch: 85,Loss: -0.969,Avg.Loss: -1.452,LR: 4.70E-04]Training epoch 16:  76%|███████▌  | 85/112 [00:01<00:00, 53.44it/s, Epoch: 16, Batch: 86,Loss: -1.061,Avg.Loss: -1.447,LR: 4.70E-04]Training epoch 16:  77%|███████▋  | 86/112 [00:01<00:00, 53.44it/s, Epoch: 16, Batch: 87,Loss: -1.882,Avg.Loss: -1.452,LR: 4.70E-04]Training epoch 16:  78%|███████▊  | 87/112 [00:01<00:00, 53.44it/s, Epoch: 16, Batch: 88,Loss: -1.492,Avg.Loss: -1.453,LR: 4.70E-04]Training epoch 16:  79%|███████▊  | 88/112 [00:01<00:00, 53.44it/s, Epoch: 16, Batch: 89,Loss: -1.321,Avg.Loss: -1.451,LR: 4.70E-04]Training epoch 16:  79%|███████▉  | 89/112 [00:01<00:00, 53.44it/s, Epoch: 16, Batch: 90,Loss: -1.151,Avg.Loss: -1.448,LR: 4.70E-04]Training epoch 16:  80%|████████  | 90/112 [00:01<00:00, 53.35it/s, Epoch: 16, Batch: 90,Loss: -1.151,Avg.Loss: -1.448,LR: 4.70E-04]Training epoch 16:  80%|████████  | 90/112 [00:01<00:00, 53.35it/s, Epoch: 16, Batch: 91,Loss: -1.647,Avg.Loss: -1.450,LR: 4.70E-04]Training epoch 16:  81%|████████▏ | 91/112 [00:01<00:00, 53.35it/s, Epoch: 16, Batch: 92,Loss: -1.272,Avg.Loss: -1.448,LR: 4.70E-04]Training epoch 16:  82%|████████▏ | 92/112 [00:01<00:00, 53.35it/s, Epoch: 16, Batch: 93,Loss: -1.370,Avg.Loss: -1.447,LR: 4.70E-04]Training epoch 16:  83%|████████▎ | 93/112 [00:01<00:00, 53.35it/s, Epoch: 16, Batch: 94,Loss: -1.738,Avg.Loss: -1.450,LR: 4.70E-04]Training epoch 16:  84%|████████▍ | 94/112 [00:01<00:00, 53.35it/s, Epoch: 16, Batch: 95,Loss: -1.561,Avg.Loss: -1.451,LR: 4.70E-04]Training epoch 16:  85%|████████▍ | 95/112 [00:01<00:00, 53.35it/s, Epoch: 16, Batch: 96,Loss: -1.688,Avg.Loss: -1.454,LR: 4.70E-04]Training epoch 16:  86%|████████▌ | 96/112 [00:01<00:00, 53.42it/s, Epoch: 16, Batch: 96,Loss: -1.688,Avg.Loss: -1.454,LR: 4.70E-04]Training epoch 16:  86%|████████▌ | 96/112 [00:01<00:00, 53.42it/s, Epoch: 16, Batch: 97,Loss: -1.649,Avg.Loss: -1.456,LR: 4.70E-04]Training epoch 16:  87%|████████▋ | 97/112 [00:01<00:00, 53.42it/s, Epoch: 16, Batch: 98,Loss: -1.956,Avg.Loss: -1.461,LR: 4.70E-04]Training epoch 16:  88%|████████▊ | 98/112 [00:01<00:00, 53.42it/s, Epoch: 16, Batch: 99,Loss: -1.387,Avg.Loss: -1.460,LR: 4.70E-04]Training epoch 16:  88%|████████▊ | 99/112 [00:01<00:00, 53.42it/s, Epoch: 16, Batch: 100,Loss: -1.690,Avg.Loss: -1.463,LR: 4.69E-04]Training epoch 16:  89%|████████▉ | 100/112 [00:01<00:00, 53.42it/s, Epoch: 16, Batch: 101,Loss: -1.702,Avg.Loss: -1.465,LR: 4.69E-04]Training epoch 16:  90%|█████████ | 101/112 [00:01<00:00, 53.42it/s, Epoch: 16, Batch: 102,Loss: -1.795,Avg.Loss: -1.468,LR: 4.69E-04]Training epoch 16:  91%|█████████ | 102/112 [00:01<00:00, 53.21it/s, Epoch: 16, Batch: 102,Loss: -1.795,Avg.Loss: -1.468,LR: 4.69E-04]Training epoch 16:  91%|█████████ | 102/112 [00:01<00:00, 53.21it/s, Epoch: 16, Batch: 103,Loss: -1.082,Avg.Loss: -1.464,LR: 4.69E-04]Training epoch 16:  92%|█████████▏| 103/112 [00:01<00:00, 53.21it/s, Epoch: 16, Batch: 104,Loss: -1.032,Avg.Loss: -1.460,LR: 4.69E-04]Training epoch 16:  93%|█████████▎| 104/112 [00:01<00:00, 53.21it/s, Epoch: 16, Batch: 105,Loss: -1.433,Avg.Loss: -1.460,LR: 4.69E-04]Training epoch 16:  94%|█████████▍| 105/112 [00:01<00:00, 53.21it/s, Epoch: 16, Batch: 106,Loss: -1.423,Avg.Loss: -1.460,LR: 4.69E-04]Training epoch 16:  95%|█████████▍| 106/112 [00:02<00:00, 53.21it/s, Epoch: 16, Batch: 107,Loss: -1.349,Avg.Loss: -1.459,LR: 4.69E-04]Training epoch 16:  96%|█████████▌| 107/112 [00:02<00:00, 53.21it/s, Epoch: 16, Batch: 108,Loss: -1.787,Avg.Loss: -1.462,LR: 4.69E-04]Training epoch 16:  96%|█████████▋| 108/112 [00:02<00:00, 53.18it/s, Epoch: 16, Batch: 108,Loss: -1.787,Avg.Loss: -1.462,LR: 4.69E-04]Training epoch 16:  96%|█████████▋| 108/112 [00:02<00:00, 53.18it/s, Epoch: 16, Batch: 109,Loss: -1.049,Avg.Loss: -1.458,LR: 4.69E-04]Training epoch 16:  97%|█████████▋| 109/112 [00:02<00:00, 53.18it/s, Epoch: 16, Batch: 110,Loss: -0.863,Avg.Loss: -1.453,LR: 4.69E-04]Training epoch 16:  98%|█████████▊| 110/112 [00:02<00:00, 53.18it/s, Epoch: 16, Batch: 111,Loss: -1.487,Avg.Loss: -1.453,LR: 4.69E-04]Training epoch 16:  99%|█████████▉| 111/112 [00:02<00:00, 53.18it/s, Epoch: 16, Batch: 112,Loss: -1.833,Avg.Loss: -1.456,LR: 4.69E-04]Training epoch 16: 100%|██████████| 112/112 [00:02<00:00, 53.29it/s, Epoch: 16, Batch: 112,Loss: -1.833,Avg.Loss: -1.456,LR: 4.69E-04]
Training epoch 17:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 17:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 17, Batch: 1,Loss: -1.188,Avg.Loss: -1.188,LR: 4.69E-04]Training epoch 17:   1%|          | 1/112 [00:00<00:04, 26.06it/s, Epoch: 17, Batch: 2,Loss: 0.597,Avg.Loss: -0.295,LR: 4.69E-04]Training epoch 17:   2%|▏         | 2/112 [00:00<00:03, 34.73it/s, Epoch: 17, Batch: 3,Loss: 1.349,Avg.Loss: 0.253,LR: 4.69E-04] Training epoch 17:   3%|▎         | 3/112 [00:00<00:02, 38.03it/s, Epoch: 17, Batch: 4,Loss: 0.411,Avg.Loss: 0.292,LR: 4.69E-04]Training epoch 17:   4%|▎         | 4/112 [00:00<00:02, 42.94it/s, Epoch: 17, Batch: 5,Loss: -0.347,Avg.Loss: 0.164,LR: 4.69E-04]Training epoch 17:   4%|▍         | 5/112 [00:00<00:02, 45.54it/s, Epoch: 17, Batch: 6,Loss: -1.549,Avg.Loss: -0.121,LR: 4.69E-04]Training epoch 17:   5%|▌         | 6/112 [00:00<00:01, 54.56it/s, Epoch: 17, Batch: 6,Loss: -1.549,Avg.Loss: -0.121,LR: 4.69E-04]Training epoch 17:   5%|▌         | 6/112 [00:00<00:01, 54.56it/s, Epoch: 17, Batch: 7,Loss: -1.555,Avg.Loss: -0.326,LR: 4.69E-04]Training epoch 17:   6%|▋         | 7/112 [00:00<00:01, 54.56it/s, Epoch: 17, Batch: 8,Loss: -0.057,Avg.Loss: -0.292,LR: 4.69E-04]Training epoch 17:   7%|▋         | 8/112 [00:00<00:01, 54.56it/s, Epoch: 17, Batch: 9,Loss: 0.134,Avg.Loss: -0.245,LR: 4.69E-04] Training epoch 17:   8%|▊         | 9/112 [00:00<00:01, 54.56it/s, Epoch: 17, Batch: 10,Loss: -0.652,Avg.Loss: -0.286,LR: 4.69E-04]Training epoch 17:   9%|▉         | 10/112 [00:00<00:01, 54.56it/s, Epoch: 17, Batch: 11,Loss: 0.060,Avg.Loss: -0.254,LR: 4.69E-04]Training epoch 17:  10%|▉         | 11/112 [00:00<00:01, 54.56it/s, Epoch: 17, Batch: 12,Loss: 3.334,Avg.Loss: 0.045,LR: 4.69E-04] Training epoch 17:  11%|█         | 12/112 [00:00<00:02, 49.70it/s, Epoch: 17, Batch: 12,Loss: 3.334,Avg.Loss: 0.045,LR: 4.69E-04]Training epoch 17:  11%|█         | 12/112 [00:00<00:02, 49.70it/s, Epoch: 17, Batch: 13,Loss: 2.786,Avg.Loss: 0.256,LR: 4.69E-04]Training epoch 17:  12%|█▏        | 13/112 [00:00<00:01, 49.70it/s, Epoch: 17, Batch: 14,Loss: -1.053,Avg.Loss: 0.162,LR: 4.69E-04]Training epoch 17:  12%|█▎        | 14/112 [00:00<00:01, 49.70it/s, Epoch: 17, Batch: 15,Loss: 1.965,Avg.Loss: 0.282,LR: 4.69E-04] Training epoch 17:  13%|█▎        | 15/112 [00:00<00:01, 49.70it/s, Epoch: 17, Batch: 16,Loss: 5.515,Avg.Loss: 0.609,LR: 4.69E-04]Training epoch 17:  14%|█▍        | 16/112 [00:00<00:01, 49.70it/s, Epoch: 17, Batch: 17,Loss: 7.237,Avg.Loss: 0.999,LR: 4.68E-04]Training epoch 17:  15%|█▌        | 17/112 [00:00<00:01, 49.70it/s, Epoch: 17, Batch: 18,Loss: 1.069,Avg.Loss: 1.003,LR: 4.68E-04]Training epoch 17:  16%|█▌        | 18/112 [00:00<00:01, 50.71it/s, Epoch: 17, Batch: 18,Loss: 1.069,Avg.Loss: 1.003,LR: 4.68E-04]Training epoch 17:  16%|█▌        | 18/112 [00:00<00:01, 50.71it/s, Epoch: 17, Batch: 19,Loss: -1.197,Avg.Loss: 0.887,LR: 4.68E-04]Training epoch 17:  17%|█▋        | 19/112 [00:00<00:01, 50.71it/s, Epoch: 17, Batch: 20,Loss: -0.304,Avg.Loss: 0.828,LR: 4.68E-04]Training epoch 17:  18%|█▊        | 20/112 [00:00<00:01, 50.71it/s, Epoch: 17, Batch: 21,Loss: -0.459,Avg.Loss: 0.767,LR: 4.68E-04]Training epoch 17:  19%|█▉        | 21/112 [00:00<00:01, 50.71it/s, Epoch: 17, Batch: 22,Loss: -1.514,Avg.Loss: 0.663,LR: 4.68E-04]Training epoch 17:  20%|█▉        | 22/112 [00:00<00:01, 50.71it/s, Epoch: 17, Batch: 23,Loss: 0.603,Avg.Loss: 0.660,LR: 4.68E-04] Training epoch 17:  21%|██        | 23/112 [00:00<00:01, 50.71it/s, Epoch: 17, Batch: 24,Loss: 3.079,Avg.Loss: 0.761,LR: 4.68E-04]Training epoch 17:  21%|██▏       | 24/112 [00:00<00:01, 50.76it/s, Epoch: 17, Batch: 24,Loss: 3.079,Avg.Loss: 0.761,LR: 4.68E-04]Training epoch 17:  21%|██▏       | 24/112 [00:00<00:01, 50.76it/s, Epoch: 17, Batch: 25,Loss: 0.796,Avg.Loss: 0.762,LR: 4.68E-04]Training epoch 17:  22%|██▏       | 25/112 [00:00<00:01, 50.76it/s, Epoch: 17, Batch: 26,Loss: -1.167,Avg.Loss: 0.688,LR: 4.68E-04]Training epoch 17:  23%|██▎       | 26/112 [00:00<00:01, 50.76it/s, Epoch: 17, Batch: 27,Loss: 0.323,Avg.Loss: 0.675,LR: 4.68E-04] Training epoch 17:  24%|██▍       | 27/112 [00:00<00:01, 50.76it/s, Epoch: 17, Batch: 28,Loss: 3.660,Avg.Loss: 0.781,LR: 4.68E-04]Training epoch 17:  25%|██▌       | 28/112 [00:00<00:01, 50.76it/s, Epoch: 17, Batch: 29,Loss: 2.188,Avg.Loss: 0.830,LR: 4.68E-04]Training epoch 17:  26%|██▌       | 29/112 [00:00<00:01, 50.76it/s, Epoch: 17, Batch: 30,Loss: -0.257,Avg.Loss: 0.794,LR: 4.68E-04]Training epoch 17:  27%|██▋       | 30/112 [00:00<00:01, 51.29it/s, Epoch: 17, Batch: 30,Loss: -0.257,Avg.Loss: 0.794,LR: 4.68E-04]Training epoch 17:  27%|██▋       | 30/112 [00:00<00:01, 51.29it/s, Epoch: 17, Batch: 31,Loss: -1.552,Avg.Loss: 0.718,LR: 4.68E-04]Training epoch 17:  28%|██▊       | 31/112 [00:00<00:01, 51.29it/s, Epoch: 17, Batch: 32,Loss: -0.359,Avg.Loss: 0.684,LR: 4.68E-04]Training epoch 17:  29%|██▊       | 32/112 [00:00<00:01, 51.29it/s, Epoch: 17, Batch: 33,Loss: -0.433,Avg.Loss: 0.650,LR: 4.68E-04]Training epoch 17:  29%|██▉       | 33/112 [00:00<00:01, 51.29it/s, Epoch: 17, Batch: 34,Loss: -1.425,Avg.Loss: 0.589,LR: 4.68E-04]Training epoch 17:  30%|███       | 34/112 [00:00<00:01, 51.29it/s, Epoch: 17, Batch: 35,Loss: -1.493,Avg.Loss: 0.530,LR: 4.68E-04]Training epoch 17:  31%|███▏      | 35/112 [00:00<00:01, 51.29it/s, Epoch: 17, Batch: 36,Loss: -1.401,Avg.Loss: 0.476,LR: 4.68E-04]Training epoch 17:  32%|███▏      | 36/112 [00:00<00:01, 52.05it/s, Epoch: 17, Batch: 36,Loss: -1.401,Avg.Loss: 0.476,LR: 4.68E-04]Training epoch 17:  32%|███▏      | 36/112 [00:00<00:01, 52.05it/s, Epoch: 17, Batch: 37,Loss: -1.216,Avg.Loss: 0.431,LR: 4.68E-04]Training epoch 17:  33%|███▎      | 37/112 [00:00<00:01, 52.05it/s, Epoch: 17, Batch: 38,Loss: -0.740,Avg.Loss: 0.400,LR: 4.68E-04]Training epoch 17:  34%|███▍      | 38/112 [00:00<00:01, 52.05it/s, Epoch: 17, Batch: 39,Loss: -0.530,Avg.Loss: 0.376,LR: 4.68E-04]Training epoch 17:  35%|███▍      | 39/112 [00:00<00:01, 52.05it/s, Epoch: 17, Batch: 40,Loss: -0.997,Avg.Loss: 0.342,LR: 4.68E-04]Training epoch 17:  36%|███▌      | 40/112 [00:00<00:01, 52.05it/s, Epoch: 17, Batch: 41,Loss: -0.636,Avg.Loss: 0.318,LR: 4.68E-04]Training epoch 17:  37%|███▋      | 41/112 [00:00<00:01, 52.05it/s, Epoch: 17, Batch: 42,Loss: 0.364,Avg.Loss: 0.319,LR: 4.68E-04] Training epoch 17:  38%|███▊      | 42/112 [00:00<00:01, 52.39it/s, Epoch: 17, Batch: 42,Loss: 0.364,Avg.Loss: 0.319,LR: 4.68E-04]Training epoch 17:  38%|███▊      | 42/112 [00:00<00:01, 52.39it/s, Epoch: 17, Batch: 43,Loss: -0.364,Avg.Loss: 0.303,LR: 4.68E-04]Training epoch 17:  38%|███▊      | 43/112 [00:00<00:01, 52.39it/s, Epoch: 17, Batch: 44,Loss: -1.815,Avg.Loss: 0.255,LR: 4.68E-04]Training epoch 17:  39%|███▉      | 44/112 [00:00<00:01, 52.39it/s, Epoch: 17, Batch: 45,Loss: -1.811,Avg.Loss: 0.209,LR: 4.68E-04]Training epoch 17:  40%|████      | 45/112 [00:00<00:01, 52.39it/s, Epoch: 17, Batch: 46,Loss: -1.491,Avg.Loss: 0.172,LR: 4.68E-04]Training epoch 17:  41%|████      | 46/112 [00:00<00:01, 52.39it/s, Epoch: 17, Batch: 47,Loss: -1.579,Avg.Loss: 0.135,LR: 4.67E-04]Training epoch 17:  42%|████▏     | 47/112 [00:00<00:01, 52.39it/s, Epoch: 17, Batch: 48,Loss: -1.306,Avg.Loss: 0.105,LR: 4.67E-04]Training epoch 17:  43%|████▎     | 48/112 [00:00<00:01, 52.81it/s, Epoch: 17, Batch: 48,Loss: -1.306,Avg.Loss: 0.105,LR: 4.67E-04]Training epoch 17:  43%|████▎     | 48/112 [00:00<00:01, 52.81it/s, Epoch: 17, Batch: 49,Loss: -1.500,Avg.Loss: 0.072,LR: 4.67E-04]Training epoch 17:  44%|████▍     | 49/112 [00:00<00:01, 52.81it/s, Epoch: 17, Batch: 50,Loss: -1.455,Avg.Loss: 0.041,LR: 4.67E-04]Training epoch 17:  45%|████▍     | 50/112 [00:00<00:01, 52.81it/s, Epoch: 17, Batch: 51,Loss: -1.407,Avg.Loss: 0.013,LR: 4.67E-04]Training epoch 17:  46%|████▌     | 51/112 [00:00<00:01, 52.81it/s, Epoch: 17, Batch: 52,Loss: -0.842,Avg.Loss: -0.003,LR: 4.67E-04]Training epoch 17:  46%|████▋     | 52/112 [00:01<00:01, 52.81it/s, Epoch: 17, Batch: 53,Loss: -0.252,Avg.Loss: -0.008,LR: 4.67E-04]Training epoch 17:  47%|████▋     | 53/112 [00:01<00:01, 52.81it/s, Epoch: 17, Batch: 54,Loss: -1.482,Avg.Loss: -0.035,LR: 4.67E-04]Training epoch 17:  48%|████▊     | 54/112 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 54,Loss: -1.482,Avg.Loss: -0.035,LR: 4.67E-04]Training epoch 17:  48%|████▊     | 54/112 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 55,Loss: 0.394,Avg.Loss: -0.028,LR: 4.67E-04] Training epoch 17:  49%|████▉     | 55/112 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 56,Loss: 1.464,Avg.Loss: -0.001,LR: 4.67E-04]Training epoch 17:  50%|█████     | 56/112 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 57,Loss: 0.815,Avg.Loss: 0.013,LR: 4.67E-04] Training epoch 17:  51%|█████     | 57/112 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 58,Loss: -1.442,Avg.Loss: -0.012,LR: 4.67E-04]Training epoch 17:  52%|█████▏    | 58/112 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 59,Loss: 2.208,Avg.Loss: 0.026,LR: 4.67E-04]  Training epoch 17:  53%|█████▎    | 59/112 [00:01<00:00, 53.01it/s, Epoch: 17, Batch: 60,Loss: 5.434,Avg.Loss: 0.116,LR: 4.67E-04]Training epoch 17:  54%|█████▎    | 60/112 [00:01<00:00, 53.15it/s, Epoch: 17, Batch: 60,Loss: 5.434,Avg.Loss: 0.116,LR: 4.67E-04]Training epoch 17:  54%|█████▎    | 60/112 [00:01<00:00, 53.15it/s, Epoch: 17, Batch: 61,Loss: 7.217,Avg.Loss: 0.232,LR: 4.67E-04]Training epoch 17:  54%|█████▍    | 61/112 [00:01<00:00, 53.15it/s, Epoch: 17, Batch: 62,Loss: 1.952,Avg.Loss: 0.260,LR: 4.67E-04]Training epoch 17:  55%|█████▌    | 62/112 [00:01<00:00, 53.15it/s, Epoch: 17, Batch: 63,Loss: -1.666,Avg.Loss: 0.230,LR: 4.67E-04]Training epoch 17:  56%|█████▋    | 63/112 [00:01<00:00, 53.15it/s, Epoch: 17, Batch: 64,Loss: 0.764,Avg.Loss: 0.238,LR: 4.67E-04] Training epoch 17:  57%|█████▋    | 64/112 [00:01<00:00, 53.15it/s, Epoch: 17, Batch: 65,Loss: 1.485,Avg.Loss: 0.257,LR: 4.67E-04]Training epoch 17:  58%|█████▊    | 65/112 [00:01<00:00, 53.15it/s, Epoch: 17, Batch: 66,Loss: 3.079,Avg.Loss: 0.300,LR: 4.67E-04]Training epoch 17:  59%|█████▉    | 66/112 [00:01<00:00, 53.18it/s, Epoch: 17, Batch: 66,Loss: 3.079,Avg.Loss: 0.300,LR: 4.67E-04]Training epoch 17:  59%|█████▉    | 66/112 [00:01<00:00, 53.18it/s, Epoch: 17, Batch: 67,Loss: 1.604,Avg.Loss: 0.319,LR: 4.67E-04]Training epoch 17:  60%|█████▉    | 67/112 [00:01<00:00, 53.18it/s, Epoch: 17, Batch: 68,Loss: -0.039,Avg.Loss: 0.314,LR: 4.67E-04]Training epoch 17:  61%|██████    | 68/112 [00:01<00:00, 53.18it/s, Epoch: 17, Batch: 69,Loss: 0.690,Avg.Loss: 0.320,LR: 4.67E-04] Training epoch 17:  62%|██████▏   | 69/112 [00:01<00:00, 53.18it/s, Epoch: 17, Batch: 70,Loss: 0.048,Avg.Loss: 0.316,LR: 4.67E-04]Training epoch 17:  62%|██████▎   | 70/112 [00:01<00:00, 53.18it/s, Epoch: 17, Batch: 71,Loss: -1.048,Avg.Loss: 0.296,LR: 4.67E-04]Training epoch 17:  63%|██████▎   | 71/112 [00:01<00:00, 53.18it/s, Epoch: 17, Batch: 72,Loss: -1.386,Avg.Loss: 0.273,LR: 4.67E-04]Training epoch 17:  64%|██████▍   | 72/112 [00:01<00:00, 53.02it/s, Epoch: 17, Batch: 72,Loss: -1.386,Avg.Loss: 0.273,LR: 4.67E-04]Training epoch 17:  64%|██████▍   | 72/112 [00:01<00:00, 53.02it/s, Epoch: 17, Batch: 73,Loss: -1.510,Avg.Loss: 0.249,LR: 4.67E-04]Training epoch 17:  65%|██████▌   | 73/112 [00:01<00:00, 53.02it/s, Epoch: 17, Batch: 74,Loss: -0.873,Avg.Loss: 0.234,LR: 4.67E-04]Training epoch 17:  66%|██████▌   | 74/112 [00:01<00:00, 53.02it/s, Epoch: 17, Batch: 75,Loss: -1.346,Avg.Loss: 0.212,LR: 4.66E-04]Training epoch 17:  67%|██████▋   | 75/112 [00:01<00:00, 53.02it/s, Epoch: 17, Batch: 76,Loss: -1.780,Avg.Loss: 0.186,LR: 4.66E-04]Training epoch 17:  68%|██████▊   | 76/112 [00:01<00:00, 53.02it/s, Epoch: 17, Batch: 77,Loss: -1.278,Avg.Loss: 0.167,LR: 4.66E-04]Training epoch 17:  69%|██████▉   | 77/112 [00:01<00:00, 53.02it/s, Epoch: 17, Batch: 78,Loss: -0.772,Avg.Loss: 0.155,LR: 4.66E-04]Training epoch 17:  70%|██████▉   | 78/112 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 78,Loss: -0.772,Avg.Loss: 0.155,LR: 4.66E-04]Training epoch 17:  70%|██████▉   | 78/112 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 79,Loss: -1.174,Avg.Loss: 0.138,LR: 4.66E-04]Training epoch 17:  71%|███████   | 79/112 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 80,Loss: -1.417,Avg.Loss: 0.119,LR: 4.66E-04]Training epoch 17:  71%|███████▏  | 80/112 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 81,Loss: -1.524,Avg.Loss: 0.099,LR: 4.66E-04]Training epoch 17:  72%|███████▏  | 81/112 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 82,Loss: -1.349,Avg.Loss: 0.081,LR: 4.66E-04]Training epoch 17:  73%|███████▎  | 82/112 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 83,Loss: -1.354,Avg.Loss: 0.064,LR: 4.66E-04]Training epoch 17:  74%|███████▍  | 83/112 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 84,Loss: -0.824,Avg.Loss: 0.053,LR: 4.66E-04]Training epoch 17:  75%|███████▌  | 84/112 [00:01<00:00, 53.16it/s, Epoch: 17, Batch: 84,Loss: -0.824,Avg.Loss: 0.053,LR: 4.66E-04]Training epoch 17:  75%|███████▌  | 84/112 [00:01<00:00, 53.16it/s, Epoch: 17, Batch: 85,Loss: -0.241,Avg.Loss: 0.050,LR: 4.66E-04]Training epoch 17:  76%|███████▌  | 85/112 [00:01<00:00, 53.16it/s, Epoch: 17, Batch: 86,Loss: -0.733,Avg.Loss: 0.041,LR: 4.66E-04]Training epoch 17:  77%|███████▋  | 86/112 [00:01<00:00, 53.16it/s, Epoch: 17, Batch: 87,Loss: -1.144,Avg.Loss: 0.027,LR: 4.66E-04]Training epoch 17:  78%|███████▊  | 87/112 [00:01<00:00, 53.16it/s, Epoch: 17, Batch: 88,Loss: -1.303,Avg.Loss: 0.012,LR: 4.66E-04]Training epoch 17:  79%|███████▊  | 88/112 [00:01<00:00, 53.16it/s, Epoch: 17, Batch: 89,Loss: -0.883,Avg.Loss: 0.002,LR: 4.66E-04]Training epoch 17:  79%|███████▉  | 89/112 [00:01<00:00, 53.16it/s, Epoch: 17, Batch: 90,Loss: -0.486,Avg.Loss: -0.004,LR: 4.66E-04]Training epoch 17:  80%|████████  | 90/112 [00:01<00:00, 53.50it/s, Epoch: 17, Batch: 90,Loss: -0.486,Avg.Loss: -0.004,LR: 4.66E-04]Training epoch 17:  80%|████████  | 90/112 [00:01<00:00, 53.50it/s, Epoch: 17, Batch: 91,Loss: -1.091,Avg.Loss: -0.016,LR: 4.66E-04]Training epoch 17:  81%|████████▏ | 91/112 [00:01<00:00, 53.50it/s, Epoch: 17, Batch: 92,Loss: -1.511,Avg.Loss: -0.032,LR: 4.66E-04]Training epoch 17:  82%|████████▏ | 92/112 [00:01<00:00, 53.50it/s, Epoch: 17, Batch: 93,Loss: -1.299,Avg.Loss: -0.045,LR: 4.66E-04]Training epoch 17:  83%|████████▎ | 93/112 [00:01<00:00, 53.50it/s, Epoch: 17, Batch: 94,Loss: -1.420,Avg.Loss: -0.060,LR: 4.66E-04]Training epoch 17:  84%|████████▍ | 94/112 [00:01<00:00, 53.50it/s, Epoch: 17, Batch: 95,Loss: -1.589,Avg.Loss: -0.076,LR: 4.66E-04]Training epoch 17:  85%|████████▍ | 95/112 [00:01<00:00, 53.50it/s, Epoch: 17, Batch: 96,Loss: -1.752,Avg.Loss: -0.094,LR: 4.66E-04]Training epoch 17:  86%|████████▌ | 96/112 [00:01<00:00, 53.93it/s, Epoch: 17, Batch: 96,Loss: -1.752,Avg.Loss: -0.094,LR: 4.66E-04]Training epoch 17:  86%|████████▌ | 96/112 [00:01<00:00, 53.93it/s, Epoch: 17, Batch: 97,Loss: -1.703,Avg.Loss: -0.110,LR: 4.66E-04]Training epoch 17:  87%|████████▋ | 97/112 [00:01<00:00, 53.93it/s, Epoch: 17, Batch: 98,Loss: -0.913,Avg.Loss: -0.118,LR: 4.66E-04]Training epoch 17:  88%|████████▊ | 98/112 [00:01<00:00, 53.93it/s, Epoch: 17, Batch: 99,Loss: -1.230,Avg.Loss: -0.130,LR: 4.66E-04]Training epoch 17:  88%|████████▊ | 99/112 [00:01<00:00, 53.93it/s, Epoch: 17, Batch: 100,Loss: -1.766,Avg.Loss: -0.146,LR: 4.66E-04]Training epoch 17:  89%|████████▉ | 100/112 [00:01<00:00, 53.93it/s, Epoch: 17, Batch: 101,Loss: -0.878,Avg.Loss: -0.153,LR: 4.66E-04]Training epoch 17:  90%|█████████ | 101/112 [00:01<00:00, 53.93it/s, Epoch: 17, Batch: 102,Loss: 0.068,Avg.Loss: -0.151,LR: 4.66E-04] Training epoch 17:  91%|█████████ | 102/112 [00:01<00:00, 53.90it/s, Epoch: 17, Batch: 102,Loss: 0.068,Avg.Loss: -0.151,LR: 4.66E-04]Training epoch 17:  91%|█████████ | 102/112 [00:01<00:00, 53.90it/s, Epoch: 17, Batch: 103,Loss: 0.256,Avg.Loss: -0.147,LR: 4.66E-04]Training epoch 17:  92%|█████████▏| 103/112 [00:01<00:00, 53.90it/s, Epoch: 17, Batch: 104,Loss: -1.318,Avg.Loss: -0.158,LR: 4.65E-04]Training epoch 17:  93%|█████████▎| 104/112 [00:01<00:00, 53.90it/s, Epoch: 17, Batch: 105,Loss: -0.881,Avg.Loss: -0.165,LR: 4.65E-04]Training epoch 17:  94%|█████████▍| 105/112 [00:02<00:00, 53.90it/s, Epoch: 17, Batch: 106,Loss: 0.079,Avg.Loss: -0.163,LR: 4.65E-04] Training epoch 17:  95%|█████████▍| 106/112 [00:02<00:00, 53.90it/s, Epoch: 17, Batch: 107,Loss: -0.317,Avg.Loss: -0.164,LR: 4.65E-04]Training epoch 17:  96%|█████████▌| 107/112 [00:02<00:00, 53.90it/s, Epoch: 17, Batch: 108,Loss: 0.934,Avg.Loss: -0.154,LR: 4.65E-04] Training epoch 17:  96%|█████████▋| 108/112 [00:02<00:00, 53.74it/s, Epoch: 17, Batch: 108,Loss: 0.934,Avg.Loss: -0.154,LR: 4.65E-04]Training epoch 17:  96%|█████████▋| 108/112 [00:02<00:00, 53.74it/s, Epoch: 17, Batch: 109,Loss: 1.391,Avg.Loss: -0.140,LR: 4.65E-04]Training epoch 17:  97%|█████████▋| 109/112 [00:02<00:00, 53.74it/s, Epoch: 17, Batch: 110,Loss: 0.915,Avg.Loss: -0.130,LR: 4.65E-04]Training epoch 17:  98%|█████████▊| 110/112 [00:02<00:00, 53.74it/s, Epoch: 17, Batch: 111,Loss: -0.827,Avg.Loss: -0.137,LR: 4.65E-04]Training epoch 17:  99%|█████████▉| 111/112 [00:02<00:00, 53.74it/s, Epoch: 17, Batch: 112,Loss: -1.130,Avg.Loss: -0.146,LR: 4.65E-04]Training epoch 17: 100%|██████████| 112/112 [00:02<00:00, 52.82it/s, Epoch: 17, Batch: 112,Loss: -1.130,Avg.Loss: -0.146,LR: 4.65E-04]
Training epoch 18:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 18:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 18, Batch: 1,Loss: 0.087,Avg.Loss: 0.087,LR: 4.65E-04]Training epoch 18:   1%|          | 1/112 [00:00<00:04, 27.26it/s, Epoch: 18, Batch: 2,Loss: -0.121,Avg.Loss: -0.017,LR: 4.65E-04]Training epoch 18:   2%|▏         | 2/112 [00:00<00:02, 37.20it/s, Epoch: 18, Batch: 3,Loss: -1.222,Avg.Loss: -0.419,LR: 4.65E-04]Training epoch 18:   3%|▎         | 3/112 [00:00<00:02, 43.64it/s, Epoch: 18, Batch: 4,Loss: -0.255,Avg.Loss: -0.378,LR: 4.65E-04]Training epoch 18:   4%|▎         | 4/112 [00:00<00:02, 45.71it/s, Epoch: 18, Batch: 5,Loss: 0.588,Avg.Loss: -0.185,LR: 4.65E-04] Training epoch 18:   4%|▍         | 5/112 [00:00<00:02, 48.82it/s, Epoch: 18, Batch: 6,Loss: 0.086,Avg.Loss: -0.140,LR: 4.65E-04]Training epoch 18:   5%|▌         | 6/112 [00:00<00:01, 58.50it/s, Epoch: 18, Batch: 6,Loss: 0.086,Avg.Loss: -0.140,LR: 4.65E-04]Training epoch 18:   5%|▌         | 6/112 [00:00<00:01, 58.50it/s, Epoch: 18, Batch: 7,Loss: -1.130,Avg.Loss: -0.281,LR: 4.65E-04]Training epoch 18:   6%|▋         | 7/112 [00:00<00:01, 58.50it/s, Epoch: 18, Batch: 8,Loss: 0.186,Avg.Loss: -0.223,LR: 4.65E-04] Training epoch 18:   7%|▋         | 8/112 [00:00<00:01, 58.50it/s, Epoch: 18, Batch: 9,Loss: 0.856,Avg.Loss: -0.103,LR: 4.65E-04]Training epoch 18:   8%|▊         | 9/112 [00:00<00:01, 58.50it/s, Epoch: 18, Batch: 10,Loss: 0.508,Avg.Loss: -0.042,LR: 4.65E-04]Training epoch 18:   9%|▉         | 10/112 [00:00<00:01, 58.50it/s, Epoch: 18, Batch: 11,Loss: 0.024,Avg.Loss: -0.036,LR: 4.65E-04]Training epoch 18:  10%|▉         | 11/112 [00:00<00:01, 58.50it/s, Epoch: 18, Batch: 12,Loss: 0.069,Avg.Loss: -0.027,LR: 4.65E-04]Training epoch 18:  11%|█         | 12/112 [00:00<00:01, 57.68it/s, Epoch: 18, Batch: 12,Loss: 0.069,Avg.Loss: -0.027,LR: 4.65E-04]Training epoch 18:  11%|█         | 12/112 [00:00<00:01, 57.68it/s, Epoch: 18, Batch: 13,Loss: -0.568,Avg.Loss: -0.069,LR: 4.65E-04]Training epoch 18:  12%|█▏        | 13/112 [00:00<00:01, 57.68it/s, Epoch: 18, Batch: 14,Loss: -0.909,Avg.Loss: -0.129,LR: 4.65E-04]Training epoch 18:  12%|█▎        | 14/112 [00:00<00:01, 57.68it/s, Epoch: 18, Batch: 15,Loss: 0.050,Avg.Loss: -0.117,LR: 4.65E-04] Training epoch 18:  13%|█▎        | 15/112 [00:00<00:01, 57.68it/s, Epoch: 18, Batch: 16,Loss: 0.882,Avg.Loss: -0.055,LR: 4.65E-04]Training epoch 18:  14%|█▍        | 16/112 [00:00<00:01, 57.68it/s, Epoch: 18, Batch: 17,Loss: 1.109,Avg.Loss: 0.014,LR: 4.65E-04] Training epoch 18:  15%|█▌        | 17/112 [00:00<00:01, 57.68it/s, Epoch: 18, Batch: 18,Loss: 1.836,Avg.Loss: 0.115,LR: 4.65E-04]Training epoch 18:  16%|█▌        | 18/112 [00:00<00:01, 55.33it/s, Epoch: 18, Batch: 18,Loss: 1.836,Avg.Loss: 0.115,LR: 4.65E-04]Training epoch 18:  16%|█▌        | 18/112 [00:00<00:01, 55.33it/s, Epoch: 18, Batch: 19,Loss: 0.998,Avg.Loss: 0.162,LR: 4.65E-04]Training epoch 18:  17%|█▋        | 19/112 [00:00<00:01, 55.33it/s, Epoch: 18, Batch: 20,Loss: 0.102,Avg.Loss: 0.159,LR: 4.64E-04]Training epoch 18:  18%|█▊        | 20/112 [00:00<00:01, 55.33it/s, Epoch: 18, Batch: 21,Loss: -1.156,Avg.Loss: 0.096,LR: 4.64E-04]Training epoch 18:  19%|█▉        | 21/112 [00:00<00:01, 55.33it/s, Epoch: 18, Batch: 22,Loss: -0.768,Avg.Loss: 0.057,LR: 4.64E-04]Training epoch 18:  20%|█▉        | 22/112 [00:00<00:01, 55.33it/s, Epoch: 18, Batch: 23,Loss: -0.411,Avg.Loss: 0.036,LR: 4.64E-04]Training epoch 18:  21%|██        | 23/112 [00:00<00:01, 55.33it/s, Epoch: 18, Batch: 24,Loss: -0.220,Avg.Loss: 0.026,LR: 4.64E-04]Training epoch 18:  21%|██▏       | 24/112 [00:00<00:01, 54.16it/s, Epoch: 18, Batch: 24,Loss: -0.220,Avg.Loss: 0.026,LR: 4.64E-04]Training epoch 18:  21%|██▏       | 24/112 [00:00<00:01, 54.16it/s, Epoch: 18, Batch: 25,Loss: -0.350,Avg.Loss: 0.011,LR: 4.64E-04]Training epoch 18:  22%|██▏       | 25/112 [00:00<00:01, 54.16it/s, Epoch: 18, Batch: 26,Loss: -0.947,Avg.Loss: -0.026,LR: 4.64E-04]Training epoch 18:  23%|██▎       | 26/112 [00:00<00:01, 54.16it/s, Epoch: 18, Batch: 27,Loss: -1.217,Avg.Loss: -0.070,LR: 4.64E-04]Training epoch 18:  24%|██▍       | 27/112 [00:00<00:01, 54.16it/s, Epoch: 18, Batch: 28,Loss: -0.944,Avg.Loss: -0.101,LR: 4.64E-04]Training epoch 18:  25%|██▌       | 28/112 [00:00<00:01, 54.16it/s, Epoch: 18, Batch: 29,Loss: -0.839,Avg.Loss: -0.127,LR: 4.64E-04]Training epoch 18:  26%|██▌       | 29/112 [00:00<00:01, 54.16it/s, Epoch: 18, Batch: 30,Loss: -0.553,Avg.Loss: -0.141,LR: 4.64E-04]Training epoch 18:  27%|██▋       | 30/112 [00:00<00:01, 53.20it/s, Epoch: 18, Batch: 30,Loss: -0.553,Avg.Loss: -0.141,LR: 4.64E-04]Training epoch 18:  27%|██▋       | 30/112 [00:00<00:01, 53.20it/s, Epoch: 18, Batch: 31,Loss: -0.530,Avg.Loss: -0.154,LR: 4.64E-04]Training epoch 18:  28%|██▊       | 31/112 [00:00<00:01, 53.20it/s, Epoch: 18, Batch: 32,Loss: -1.187,Avg.Loss: -0.186,LR: 4.64E-04]Training epoch 18:  29%|██▊       | 32/112 [00:00<00:01, 53.20it/s, Epoch: 18, Batch: 33,Loss: -1.248,Avg.Loss: -0.218,LR: 4.64E-04]Training epoch 18:  29%|██▉       | 33/112 [00:00<00:01, 53.20it/s, Epoch: 18, Batch: 34,Loss: -1.093,Avg.Loss: -0.244,LR: 4.64E-04]Training epoch 18:  30%|███       | 34/112 [00:00<00:01, 53.20it/s, Epoch: 18, Batch: 35,Loss: -1.184,Avg.Loss: -0.271,LR: 4.64E-04]Training epoch 18:  31%|███▏      | 35/112 [00:00<00:01, 53.20it/s, Epoch: 18, Batch: 36,Loss: -1.149,Avg.Loss: -0.295,LR: 4.64E-04]Training epoch 18:  32%|███▏      | 36/112 [00:00<00:01, 53.10it/s, Epoch: 18, Batch: 36,Loss: -1.149,Avg.Loss: -0.295,LR: 4.64E-04]Training epoch 18:  32%|███▏      | 36/112 [00:00<00:01, 53.10it/s, Epoch: 18, Batch: 37,Loss: -0.949,Avg.Loss: -0.313,LR: 4.64E-04]Training epoch 18:  33%|███▎      | 37/112 [00:00<00:01, 53.10it/s, Epoch: 18, Batch: 38,Loss: -1.186,Avg.Loss: -0.336,LR: 4.64E-04]Training epoch 18:  34%|███▍      | 38/112 [00:00<00:01, 53.10it/s, Epoch: 18, Batch: 39,Loss: -1.373,Avg.Loss: -0.362,LR: 4.64E-04]Training epoch 18:  35%|███▍      | 39/112 [00:00<00:01, 53.10it/s, Epoch: 18, Batch: 40,Loss: -0.941,Avg.Loss: -0.377,LR: 4.64E-04]Training epoch 18:  36%|███▌      | 40/112 [00:00<00:01, 53.10it/s, Epoch: 18, Batch: 41,Loss: -1.214,Avg.Loss: -0.397,LR: 4.64E-04]Training epoch 18:  37%|███▋      | 41/112 [00:00<00:01, 53.10it/s, Epoch: 18, Batch: 42,Loss: -1.512,Avg.Loss: -0.424,LR: 4.64E-04]Training epoch 18:  38%|███▊      | 42/112 [00:00<00:01, 53.31it/s, Epoch: 18, Batch: 42,Loss: -1.512,Avg.Loss: -0.424,LR: 4.64E-04]Training epoch 18:  38%|███▊      | 42/112 [00:00<00:01, 53.31it/s, Epoch: 18, Batch: 43,Loss: -1.500,Avg.Loss: -0.449,LR: 4.64E-04]Training epoch 18:  38%|███▊      | 43/112 [00:00<00:01, 53.31it/s, Epoch: 18, Batch: 44,Loss: -0.979,Avg.Loss: -0.461,LR: 4.64E-04]Training epoch 18:  39%|███▉      | 44/112 [00:00<00:01, 53.31it/s, Epoch: 18, Batch: 45,Loss: -1.365,Avg.Loss: -0.481,LR: 4.64E-04]Training epoch 18:  40%|████      | 45/112 [00:00<00:01, 53.31it/s, Epoch: 18, Batch: 46,Loss: -0.632,Avg.Loss: -0.484,LR: 4.64E-04]Training epoch 18:  41%|████      | 46/112 [00:00<00:01, 53.31it/s, Epoch: 18, Batch: 47,Loss: -1.142,Avg.Loss: -0.498,LR: 4.63E-04]Training epoch 18:  42%|████▏     | 47/112 [00:00<00:01, 53.31it/s, Epoch: 18, Batch: 48,Loss: -1.862,Avg.Loss: -0.527,LR: 4.63E-04]Training epoch 18:  43%|████▎     | 48/112 [00:00<00:01, 53.49it/s, Epoch: 18, Batch: 48,Loss: -1.862,Avg.Loss: -0.527,LR: 4.63E-04]Training epoch 18:  43%|████▎     | 48/112 [00:00<00:01, 53.49it/s, Epoch: 18, Batch: 49,Loss: -1.478,Avg.Loss: -0.546,LR: 4.63E-04]Training epoch 18:  44%|████▍     | 49/112 [00:00<00:01, 53.49it/s, Epoch: 18, Batch: 50,Loss: -1.291,Avg.Loss: -0.561,LR: 4.63E-04]Training epoch 18:  45%|████▍     | 50/112 [00:00<00:01, 53.49it/s, Epoch: 18, Batch: 51,Loss: -1.293,Avg.Loss: -0.575,LR: 4.63E-04]Training epoch 18:  46%|████▌     | 51/112 [00:00<00:01, 53.49it/s, Epoch: 18, Batch: 52,Loss: 0.009,Avg.Loss: -0.564,LR: 4.63E-04] Training epoch 18:  46%|████▋     | 52/112 [00:00<00:01, 53.49it/s, Epoch: 18, Batch: 53,Loss: 0.359,Avg.Loss: -0.547,LR: 4.63E-04]Training epoch 18:  47%|████▋     | 53/112 [00:01<00:01, 53.49it/s, Epoch: 18, Batch: 54,Loss: -1.125,Avg.Loss: -0.557,LR: 4.63E-04]Training epoch 18:  48%|████▊     | 54/112 [00:01<00:01, 53.49it/s, Epoch: 18, Batch: 54,Loss: -1.125,Avg.Loss: -0.557,LR: 4.63E-04]Training epoch 18:  48%|████▊     | 54/112 [00:01<00:01, 53.49it/s, Epoch: 18, Batch: 55,Loss: -0.952,Avg.Loss: -0.565,LR: 4.63E-04]Training epoch 18:  49%|████▉     | 55/112 [00:01<00:01, 53.49it/s, Epoch: 18, Batch: 56,Loss: 0.648,Avg.Loss: -0.543,LR: 4.63E-04] Training epoch 18:  50%|█████     | 56/112 [00:01<00:01, 53.49it/s, Epoch: 18, Batch: 57,Loss: -0.735,Avg.Loss: -0.546,LR: 4.63E-04]Training epoch 18:  51%|█████     | 57/112 [00:01<00:01, 53.49it/s, Epoch: 18, Batch: 58,Loss: -1.511,Avg.Loss: -0.563,LR: 4.63E-04]Training epoch 18:  52%|█████▏    | 58/112 [00:01<00:01, 53.49it/s, Epoch: 18, Batch: 59,Loss: -1.169,Avg.Loss: -0.573,LR: 4.63E-04]Training epoch 18:  53%|█████▎    | 59/112 [00:01<00:00, 53.49it/s, Epoch: 18, Batch: 60,Loss: -1.776,Avg.Loss: -0.593,LR: 4.63E-04]Training epoch 18:  54%|█████▎    | 60/112 [00:01<00:00, 53.76it/s, Epoch: 18, Batch: 60,Loss: -1.776,Avg.Loss: -0.593,LR: 4.63E-04]Training epoch 18:  54%|█████▎    | 60/112 [00:01<00:00, 53.76it/s, Epoch: 18, Batch: 61,Loss: -1.925,Avg.Loss: -0.615,LR: 4.63E-04]Training epoch 18:  54%|█████▍    | 61/112 [00:01<00:00, 53.76it/s, Epoch: 18, Batch: 62,Loss: -1.155,Avg.Loss: -0.624,LR: 4.63E-04]Training epoch 18:  55%|█████▌    | 62/112 [00:01<00:00, 53.76it/s, Epoch: 18, Batch: 63,Loss: -1.864,Avg.Loss: -0.643,LR: 4.63E-04]Training epoch 18:  56%|█████▋    | 63/112 [00:01<00:00, 53.76it/s, Epoch: 18, Batch: 64,Loss: -0.883,Avg.Loss: -0.647,LR: 4.63E-04]Training epoch 18:  57%|█████▋    | 64/112 [00:01<00:00, 53.76it/s, Epoch: 18, Batch: 65,Loss: -0.837,Avg.Loss: -0.650,LR: 4.63E-04]Training epoch 18:  58%|█████▊    | 65/112 [00:01<00:00, 53.76it/s, Epoch: 18, Batch: 66,Loss: -1.402,Avg.Loss: -0.662,LR: 4.63E-04]Training epoch 18:  59%|█████▉    | 66/112 [00:01<00:00, 53.62it/s, Epoch: 18, Batch: 66,Loss: -1.402,Avg.Loss: -0.662,LR: 4.63E-04]Training epoch 18:  59%|█████▉    | 66/112 [00:01<00:00, 53.62it/s, Epoch: 18, Batch: 67,Loss: 0.659,Avg.Loss: -0.642,LR: 4.63E-04] Training epoch 18:  60%|█████▉    | 67/112 [00:01<00:00, 53.62it/s, Epoch: 18, Batch: 68,Loss: 4.470,Avg.Loss: -0.567,LR: 4.63E-04]Training epoch 18:  61%|██████    | 68/112 [00:01<00:00, 53.62it/s, Epoch: 18, Batch: 69,Loss: 2.331,Avg.Loss: -0.525,LR: 4.63E-04]Training epoch 18:  62%|██████▏   | 69/112 [00:01<00:00, 53.62it/s, Epoch: 18, Batch: 70,Loss: -0.556,Avg.Loss: -0.525,LR: 4.63E-04]Training epoch 18:  62%|██████▎   | 70/112 [00:01<00:00, 53.62it/s, Epoch: 18, Batch: 71,Loss: 1.479,Avg.Loss: -0.497,LR: 4.63E-04] Training epoch 18:  63%|██████▎   | 71/112 [00:01<00:00, 53.62it/s, Epoch: 18, Batch: 72,Loss: 4.710,Avg.Loss: -0.425,LR: 4.63E-04]Training epoch 18:  64%|██████▍   | 72/112 [00:01<00:00, 53.68it/s, Epoch: 18, Batch: 72,Loss: 4.710,Avg.Loss: -0.425,LR: 4.63E-04]Training epoch 18:  64%|██████▍   | 72/112 [00:01<00:00, 53.68it/s, Epoch: 18, Batch: 73,Loss: 5.263,Avg.Loss: -0.347,LR: 4.63E-04]Training epoch 18:  65%|██████▌   | 73/112 [00:01<00:00, 53.68it/s, Epoch: 18, Batch: 74,Loss: 1.305,Avg.Loss: -0.324,LR: 4.62E-04]Training epoch 18:  66%|██████▌   | 74/112 [00:01<00:00, 53.68it/s, Epoch: 18, Batch: 75,Loss: -1.052,Avg.Loss: -0.334,LR: 4.62E-04]Training epoch 18:  67%|██████▋   | 75/112 [00:01<00:00, 53.68it/s, Epoch: 18, Batch: 76,Loss: 5.621,Avg.Loss: -0.256,LR: 4.62E-04] Training epoch 18:  68%|██████▊   | 76/112 [00:01<00:00, 53.68it/s, Epoch: 18, Batch: 77,Loss: 14.321,Avg.Loss: -0.066,LR: 4.62E-04]Training epoch 18:  69%|██████▉   | 77/112 [00:01<00:00, 53.68it/s, Epoch: 18, Batch: 78,Loss: 14.154,Avg.Loss: 0.116,LR: 4.62E-04] Training epoch 18:  70%|██████▉   | 78/112 [00:01<00:00, 53.64it/s, Epoch: 18, Batch: 78,Loss: 14.154,Avg.Loss: 0.116,LR: 4.62E-04]Training epoch 18:  70%|██████▉   | 78/112 [00:01<00:00, 53.64it/s, Epoch: 18, Batch: 79,Loss: 8.947,Avg.Loss: 0.228,LR: 4.62E-04] Training epoch 18:  71%|███████   | 79/112 [00:01<00:00, 53.64it/s, Epoch: 18, Batch: 80,Loss: 2.587,Avg.Loss: 0.257,LR: 4.62E-04]Training epoch 18:  71%|███████▏  | 80/112 [00:01<00:00, 53.64it/s, Epoch: 18, Batch: 81,Loss: -1.627,Avg.Loss: 0.234,LR: 4.62E-04]Training epoch 18:  72%|███████▏  | 81/112 [00:01<00:00, 53.64it/s, Epoch: 18, Batch: 82,Loss: 0.311,Avg.Loss: 0.235,LR: 4.62E-04] Training epoch 18:  73%|███████▎  | 82/112 [00:01<00:00, 53.64it/s, Epoch: 18, Batch: 83,Loss: 0.243,Avg.Loss: 0.235,LR: 4.62E-04]Training epoch 18:  74%|███████▍  | 83/112 [00:01<00:00, 53.64it/s, Epoch: 18, Batch: 84,Loss: -1.307,Avg.Loss: 0.217,LR: 4.62E-04]Training epoch 18:  75%|███████▌  | 84/112 [00:01<00:00, 53.69it/s, Epoch: 18, Batch: 84,Loss: -1.307,Avg.Loss: 0.217,LR: 4.62E-04]Training epoch 18:  75%|███████▌  | 84/112 [00:01<00:00, 53.69it/s, Epoch: 18, Batch: 85,Loss: -0.843,Avg.Loss: 0.204,LR: 4.62E-04]Training epoch 18:  76%|███████▌  | 85/112 [00:01<00:00, 53.69it/s, Epoch: 18, Batch: 86,Loss: -0.408,Avg.Loss: 0.197,LR: 4.62E-04]Training epoch 18:  77%|███████▋  | 86/112 [00:01<00:00, 53.69it/s, Epoch: 18, Batch: 87,Loss: -1.251,Avg.Loss: 0.180,LR: 4.62E-04]Training epoch 18:  78%|███████▊  | 87/112 [00:01<00:00, 53.69it/s, Epoch: 18, Batch: 88,Loss: -1.500,Avg.Loss: 0.161,LR: 4.62E-04]Training epoch 18:  79%|███████▊  | 88/112 [00:01<00:00, 53.69it/s, Epoch: 18, Batch: 89,Loss: -1.388,Avg.Loss: 0.144,LR: 4.62E-04]Training epoch 18:  79%|███████▉  | 89/112 [00:01<00:00, 53.69it/s, Epoch: 18, Batch: 90,Loss: -1.823,Avg.Loss: 0.122,LR: 4.62E-04]Training epoch 18:  80%|████████  | 90/112 [00:01<00:00, 53.72it/s, Epoch: 18, Batch: 90,Loss: -1.823,Avg.Loss: 0.122,LR: 4.62E-04]Training epoch 18:  80%|████████  | 90/112 [00:01<00:00, 53.72it/s, Epoch: 18, Batch: 91,Loss: -1.210,Avg.Loss: 0.107,LR: 4.62E-04]Training epoch 18:  81%|████████▏ | 91/112 [00:01<00:00, 53.72it/s, Epoch: 18, Batch: 92,Loss: -1.458,Avg.Loss: 0.090,LR: 4.62E-04]Training epoch 18:  82%|████████▏ | 92/112 [00:01<00:00, 53.72it/s, Epoch: 18, Batch: 93,Loss: -1.132,Avg.Loss: 0.077,LR: 4.62E-04]Training epoch 18:  83%|████████▎ | 93/112 [00:01<00:00, 53.72it/s, Epoch: 18, Batch: 94,Loss: -1.286,Avg.Loss: 0.063,LR: 4.62E-04]Training epoch 18:  84%|████████▍ | 94/112 [00:01<00:00, 53.72it/s, Epoch: 18, Batch: 95,Loss: -1.804,Avg.Loss: 0.043,LR: 4.62E-04]Training epoch 18:  85%|████████▍ | 95/112 [00:01<00:00, 53.72it/s, Epoch: 18, Batch: 96,Loss: -1.640,Avg.Loss: 0.026,LR: 4.62E-04]Training epoch 18:  86%|████████▌ | 96/112 [00:01<00:00, 53.75it/s, Epoch: 18, Batch: 96,Loss: -1.640,Avg.Loss: 0.026,LR: 4.62E-04]Training epoch 18:  86%|████████▌ | 96/112 [00:01<00:00, 53.75it/s, Epoch: 18, Batch: 97,Loss: -1.314,Avg.Loss: 0.012,LR: 4.62E-04]Training epoch 18:  87%|████████▋ | 97/112 [00:01<00:00, 53.75it/s, Epoch: 18, Batch: 98,Loss: -1.028,Avg.Loss: 0.001,LR: 4.62E-04]Training epoch 18:  88%|████████▊ | 98/112 [00:01<00:00, 53.75it/s, Epoch: 18, Batch: 99,Loss: -1.669,Avg.Loss: -0.016,LR: 4.62E-04]Training epoch 18:  88%|████████▊ | 99/112 [00:01<00:00, 53.75it/s, Epoch: 18, Batch: 100,Loss: -0.504,Avg.Loss: -0.021,LR: 4.62E-04]Training epoch 18:  89%|████████▉ | 100/112 [00:01<00:00, 53.75it/s, Epoch: 18, Batch: 101,Loss: -0.183,Avg.Loss: -0.022,LR: 4.61E-04]Training epoch 18:  90%|█████████ | 101/112 [00:01<00:00, 53.75it/s, Epoch: 18, Batch: 102,Loss: -0.806,Avg.Loss: -0.030,LR: 4.61E-04]Training epoch 18:  91%|█████████ | 102/112 [00:01<00:00, 53.66it/s, Epoch: 18, Batch: 102,Loss: -0.806,Avg.Loss: -0.030,LR: 4.61E-04]Training epoch 18:  91%|█████████ | 102/112 [00:01<00:00, 53.66it/s, Epoch: 18, Batch: 103,Loss: -0.202,Avg.Loss: -0.032,LR: 4.61E-04]Training epoch 18:  92%|█████████▏| 103/112 [00:01<00:00, 53.66it/s, Epoch: 18, Batch: 104,Loss: 0.589,Avg.Loss: -0.026,LR: 4.61E-04] Training epoch 18:  93%|█████████▎| 104/112 [00:01<00:00, 53.66it/s, Epoch: 18, Batch: 105,Loss: 0.100,Avg.Loss: -0.024,LR: 4.61E-04]Training epoch 18:  94%|█████████▍| 105/112 [00:01<00:00, 53.66it/s, Epoch: 18, Batch: 106,Loss: -0.680,Avg.Loss: -0.031,LR: 4.61E-04]Training epoch 18:  95%|█████████▍| 106/112 [00:01<00:00, 53.66it/s, Epoch: 18, Batch: 107,Loss: -0.977,Avg.Loss: -0.039,LR: 4.61E-04]Training epoch 18:  96%|█████████▌| 107/112 [00:02<00:00, 53.66it/s, Epoch: 18, Batch: 108,Loss: -1.225,Avg.Loss: -0.050,LR: 4.61E-04]Training epoch 18:  96%|█████████▋| 108/112 [00:02<00:00, 53.64it/s, Epoch: 18, Batch: 108,Loss: -1.225,Avg.Loss: -0.050,LR: 4.61E-04]Training epoch 18:  96%|█████████▋| 108/112 [00:02<00:00, 53.64it/s, Epoch: 18, Batch: 109,Loss: -0.908,Avg.Loss: -0.058,LR: 4.61E-04]Training epoch 18:  97%|█████████▋| 109/112 [00:02<00:00, 53.64it/s, Epoch: 18, Batch: 110,Loss: -1.601,Avg.Loss: -0.072,LR: 4.61E-04]Training epoch 18:  98%|█████████▊| 110/112 [00:02<00:00, 53.64it/s, Epoch: 18, Batch: 111,Loss: -1.642,Avg.Loss: -0.086,LR: 4.61E-04]Training epoch 18:  99%|█████████▉| 111/112 [00:02<00:00, 53.64it/s, Epoch: 18, Batch: 112,Loss: -1.479,Avg.Loss: -0.099,LR: 4.61E-04]Training epoch 18: 100%|██████████| 112/112 [00:02<00:00, 53.79it/s, Epoch: 18, Batch: 112,Loss: -1.479,Avg.Loss: -0.099,LR: 4.61E-04]
Training epoch 19:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 19:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 19, Batch: 1,Loss: -0.760,Avg.Loss: -0.760,LR: 4.61E-04]Training epoch 19:   1%|          | 1/112 [00:00<00:04, 27.23it/s, Epoch: 19, Batch: 2,Loss: -0.163,Avg.Loss: -0.462,LR: 4.61E-04]Training epoch 19:   2%|▏         | 2/112 [00:00<00:02, 38.53it/s, Epoch: 19, Batch: 3,Loss: -0.539,Avg.Loss: -0.487,LR: 4.61E-04]Training epoch 19:   3%|▎         | 3/112 [00:00<00:02, 42.80it/s, Epoch: 19, Batch: 4,Loss: 0.499,Avg.Loss: -0.241,LR: 4.61E-04] Training epoch 19:   4%|▎         | 4/112 [00:00<00:02, 46.12it/s, Epoch: 19, Batch: 5,Loss: 1.067,Avg.Loss: 0.021,LR: 4.61E-04] Training epoch 19:   4%|▍         | 5/112 [00:00<00:02, 49.96it/s, Epoch: 19, Batch: 6,Loss: 0.119,Avg.Loss: 0.037,LR: 4.61E-04]Training epoch 19:   5%|▌         | 6/112 [00:00<00:01, 59.87it/s, Epoch: 19, Batch: 6,Loss: 0.119,Avg.Loss: 0.037,LR: 4.61E-04]Training epoch 19:   5%|▌         | 6/112 [00:00<00:01, 59.87it/s, Epoch: 19, Batch: 7,Loss: -1.350,Avg.Loss: -0.161,LR: 4.61E-04]Training epoch 19:   6%|▋         | 7/112 [00:00<00:01, 59.87it/s, Epoch: 19, Batch: 8,Loss: -1.340,Avg.Loss: -0.308,LR: 4.61E-04]Training epoch 19:   7%|▋         | 8/112 [00:00<00:01, 59.87it/s, Epoch: 19, Batch: 9,Loss: -1.706,Avg.Loss: -0.464,LR: 4.61E-04]Training epoch 19:   8%|▊         | 9/112 [00:00<00:01, 59.87it/s, Epoch: 19, Batch: 10,Loss: -1.794,Avg.Loss: -0.597,LR: 4.61E-04]Training epoch 19:   9%|▉         | 10/112 [00:00<00:01, 59.87it/s, Epoch: 19, Batch: 11,Loss: -1.404,Avg.Loss: -0.670,LR: 4.61E-04]Training epoch 19:  10%|▉         | 11/112 [00:00<00:01, 59.87it/s, Epoch: 19, Batch: 12,Loss: -1.446,Avg.Loss: -0.735,LR: 4.61E-04]Training epoch 19:  11%|█         | 12/112 [00:00<00:01, 58.66it/s, Epoch: 19, Batch: 12,Loss: -1.446,Avg.Loss: -0.735,LR: 4.61E-04]Training epoch 19:  11%|█         | 12/112 [00:00<00:01, 58.66it/s, Epoch: 19, Batch: 13,Loss: -1.030,Avg.Loss: -0.757,LR: 4.61E-04]Training epoch 19:  12%|█▏        | 13/112 [00:00<00:01, 58.66it/s, Epoch: 19, Batch: 14,Loss: -0.710,Avg.Loss: -0.754,LR: 4.61E-04]Training epoch 19:  12%|█▎        | 14/112 [00:00<00:01, 58.66it/s, Epoch: 19, Batch: 15,Loss: -0.880,Avg.Loss: -0.762,LR: 4.61E-04]Training epoch 19:  13%|█▎        | 15/112 [00:00<00:01, 58.66it/s, Epoch: 19, Batch: 16,Loss: 0.520,Avg.Loss: -0.682,LR: 4.60E-04] Training epoch 19:  14%|█▍        | 16/112 [00:00<00:01, 58.66it/s, Epoch: 19, Batch: 17,Loss: 1.447,Avg.Loss: -0.557,LR: 4.60E-04]Training epoch 19:  15%|█▌        | 17/112 [00:00<00:01, 58.66it/s, Epoch: 19, Batch: 18,Loss: 0.131,Avg.Loss: -0.519,LR: 4.60E-04]Training epoch 19:  16%|█▌        | 18/112 [00:00<00:01, 55.55it/s, Epoch: 19, Batch: 18,Loss: 0.131,Avg.Loss: -0.519,LR: 4.60E-04]Training epoch 19:  16%|█▌        | 18/112 [00:00<00:01, 55.55it/s, Epoch: 19, Batch: 19,Loss: -1.721,Avg.Loss: -0.582,LR: 4.60E-04]Training epoch 19:  17%|█▋        | 19/112 [00:00<00:01, 55.55it/s, Epoch: 19, Batch: 20,Loss: -1.458,Avg.Loss: -0.626,LR: 4.60E-04]Training epoch 19:  18%|█▊        | 20/112 [00:00<00:01, 55.55it/s, Epoch: 19, Batch: 21,Loss: -1.560,Avg.Loss: -0.670,LR: 4.60E-04]Training epoch 19:  19%|█▉        | 21/112 [00:00<00:01, 55.55it/s, Epoch: 19, Batch: 22,Loss: -1.455,Avg.Loss: -0.706,LR: 4.60E-04]Training epoch 19:  20%|█▉        | 22/112 [00:00<00:01, 55.55it/s, Epoch: 19, Batch: 23,Loss: -1.317,Avg.Loss: -0.733,LR: 4.60E-04]Training epoch 19:  21%|██        | 23/112 [00:00<00:01, 55.55it/s, Epoch: 19, Batch: 24,Loss: -1.218,Avg.Loss: -0.753,LR: 4.60E-04]Training epoch 19:  21%|██▏       | 24/112 [00:00<00:01, 54.08it/s, Epoch: 19, Batch: 24,Loss: -1.218,Avg.Loss: -0.753,LR: 4.60E-04]Training epoch 19:  21%|██▏       | 24/112 [00:00<00:01, 54.08it/s, Epoch: 19, Batch: 25,Loss: -0.851,Avg.Loss: -0.757,LR: 4.60E-04]Training epoch 19:  22%|██▏       | 25/112 [00:00<00:01, 54.08it/s, Epoch: 19, Batch: 26,Loss: -0.610,Avg.Loss: -0.751,LR: 4.60E-04]Training epoch 19:  23%|██▎       | 26/112 [00:00<00:01, 54.08it/s, Epoch: 19, Batch: 27,Loss: -1.188,Avg.Loss: -0.767,LR: 4.60E-04]Training epoch 19:  24%|██▍       | 27/112 [00:00<00:01, 54.08it/s, Epoch: 19, Batch: 28,Loss: -1.094,Avg.Loss: -0.779,LR: 4.60E-04]Training epoch 19:  25%|██▌       | 28/112 [00:00<00:01, 54.08it/s, Epoch: 19, Batch: 29,Loss: -0.930,Avg.Loss: -0.784,LR: 4.60E-04]Training epoch 19:  26%|██▌       | 29/112 [00:00<00:01, 54.08it/s, Epoch: 19, Batch: 30,Loss: -1.307,Avg.Loss: -0.802,LR: 4.60E-04]Training epoch 19:  27%|██▋       | 30/112 [00:00<00:01, 53.36it/s, Epoch: 19, Batch: 30,Loss: -1.307,Avg.Loss: -0.802,LR: 4.60E-04]Training epoch 19:  27%|██▋       | 30/112 [00:00<00:01, 53.36it/s, Epoch: 19, Batch: 31,Loss: -1.622,Avg.Loss: -0.828,LR: 4.60E-04]Training epoch 19:  28%|██▊       | 31/112 [00:00<00:01, 53.36it/s, Epoch: 19, Batch: 32,Loss: -1.792,Avg.Loss: -0.858,LR: 4.60E-04]Training epoch 19:  29%|██▊       | 32/112 [00:00<00:01, 53.36it/s, Epoch: 19, Batch: 33,Loss: -1.352,Avg.Loss: -0.873,LR: 4.60E-04]Training epoch 19:  29%|██▉       | 33/112 [00:00<00:01, 53.36it/s, Epoch: 19, Batch: 34,Loss: -1.342,Avg.Loss: -0.887,LR: 4.60E-04]Training epoch 19:  30%|███       | 34/112 [00:00<00:01, 53.36it/s, Epoch: 19, Batch: 35,Loss: -1.549,Avg.Loss: -0.906,LR: 4.60E-04]Training epoch 19:  31%|███▏      | 35/112 [00:00<00:01, 53.36it/s, Epoch: 19, Batch: 36,Loss: -1.414,Avg.Loss: -0.920,LR: 4.60E-04]Training epoch 19:  32%|███▏      | 36/112 [00:00<00:01, 53.22it/s, Epoch: 19, Batch: 36,Loss: -1.414,Avg.Loss: -0.920,LR: 4.60E-04]Training epoch 19:  32%|███▏      | 36/112 [00:00<00:01, 53.22it/s, Epoch: 19, Batch: 37,Loss: -1.254,Avg.Loss: -0.929,LR: 4.60E-04]Training epoch 19:  33%|███▎      | 37/112 [00:00<00:01, 53.22it/s, Epoch: 19, Batch: 38,Loss: -0.899,Avg.Loss: -0.928,LR: 4.60E-04]Training epoch 19:  34%|███▍      | 38/112 [00:00<00:01, 53.22it/s, Epoch: 19, Batch: 39,Loss: -0.912,Avg.Loss: -0.928,LR: 4.60E-04]Training epoch 19:  35%|███▍      | 39/112 [00:00<00:01, 53.22it/s, Epoch: 19, Batch: 40,Loss: -0.646,Avg.Loss: -0.921,LR: 4.60E-04]Training epoch 19:  36%|███▌      | 40/112 [00:00<00:01, 53.22it/s, Epoch: 19, Batch: 41,Loss: -1.193,Avg.Loss: -0.927,LR: 4.60E-04]Training epoch 19:  37%|███▋      | 41/112 [00:00<00:01, 53.22it/s, Epoch: 19, Batch: 42,Loss: -1.352,Avg.Loss: -0.937,LR: 4.59E-04]Training epoch 19:  38%|███▊      | 42/112 [00:00<00:01, 52.99it/s, Epoch: 19, Batch: 42,Loss: -1.352,Avg.Loss: -0.937,LR: 4.59E-04]Training epoch 19:  38%|███▊      | 42/112 [00:00<00:01, 52.99it/s, Epoch: 19, Batch: 43,Loss: -1.280,Avg.Loss: -0.945,LR: 4.59E-04]Training epoch 19:  38%|███▊      | 43/112 [00:00<00:01, 52.99it/s, Epoch: 19, Batch: 44,Loss: -1.635,Avg.Loss: -0.961,LR: 4.59E-04]Training epoch 19:  39%|███▉      | 44/112 [00:00<00:01, 52.99it/s, Epoch: 19, Batch: 45,Loss: -0.936,Avg.Loss: -0.961,LR: 4.59E-04]Training epoch 19:  40%|████      | 45/112 [00:00<00:01, 52.99it/s, Epoch: 19, Batch: 46,Loss: -1.209,Avg.Loss: -0.966,LR: 4.59E-04]Training epoch 19:  41%|████      | 46/112 [00:00<00:01, 52.99it/s, Epoch: 19, Batch: 47,Loss: -1.483,Avg.Loss: -0.977,LR: 4.59E-04]Training epoch 19:  42%|████▏     | 47/112 [00:00<00:01, 52.99it/s, Epoch: 19, Batch: 48,Loss: -0.759,Avg.Loss: -0.972,LR: 4.59E-04]Training epoch 19:  43%|████▎     | 48/112 [00:00<00:01, 52.98it/s, Epoch: 19, Batch: 48,Loss: -0.759,Avg.Loss: -0.972,LR: 4.59E-04]Training epoch 19:  43%|████▎     | 48/112 [00:00<00:01, 52.98it/s, Epoch: 19, Batch: 49,Loss: -0.964,Avg.Loss: -0.972,LR: 4.59E-04]Training epoch 19:  44%|████▍     | 49/112 [00:00<00:01, 52.98it/s, Epoch: 19, Batch: 50,Loss: -1.695,Avg.Loss: -0.987,LR: 4.59E-04]Training epoch 19:  45%|████▍     | 50/112 [00:00<00:01, 52.98it/s, Epoch: 19, Batch: 51,Loss: -1.362,Avg.Loss: -0.994,LR: 4.59E-04]Training epoch 19:  46%|████▌     | 51/112 [00:00<00:01, 52.98it/s, Epoch: 19, Batch: 52,Loss: -1.433,Avg.Loss: -1.003,LR: 4.59E-04]Training epoch 19:  46%|████▋     | 52/112 [00:00<00:01, 52.98it/s, Epoch: 19, Batch: 53,Loss: -0.990,Avg.Loss: -1.002,LR: 4.59E-04]Training epoch 19:  47%|████▋     | 53/112 [00:01<00:01, 52.98it/s, Epoch: 19, Batch: 54,Loss: -1.270,Avg.Loss: -1.007,LR: 4.59E-04]Training epoch 19:  48%|████▊     | 54/112 [00:01<00:01, 52.82it/s, Epoch: 19, Batch: 54,Loss: -1.270,Avg.Loss: -1.007,LR: 4.59E-04]Training epoch 19:  48%|████▊     | 54/112 [00:01<00:01, 52.82it/s, Epoch: 19, Batch: 55,Loss: -1.626,Avg.Loss: -1.018,LR: 4.59E-04]Training epoch 19:  49%|████▉     | 55/112 [00:01<00:01, 52.82it/s, Epoch: 19, Batch: 56,Loss: -1.480,Avg.Loss: -1.027,LR: 4.59E-04]Training epoch 19:  50%|█████     | 56/112 [00:01<00:01, 52.82it/s, Epoch: 19, Batch: 57,Loss: -1.636,Avg.Loss: -1.037,LR: 4.59E-04]Training epoch 19:  51%|█████     | 57/112 [00:01<00:01, 52.82it/s, Epoch: 19, Batch: 58,Loss: -1.443,Avg.Loss: -1.044,LR: 4.59E-04]Training epoch 19:  52%|█████▏    | 58/112 [00:01<00:01, 52.82it/s, Epoch: 19, Batch: 59,Loss: -1.491,Avg.Loss: -1.052,LR: 4.59E-04]Training epoch 19:  53%|█████▎    | 59/112 [00:01<00:01, 52.82it/s, Epoch: 19, Batch: 60,Loss: -1.446,Avg.Loss: -1.059,LR: 4.59E-04]Training epoch 19:  54%|█████▎    | 60/112 [00:01<00:00, 52.80it/s, Epoch: 19, Batch: 60,Loss: -1.446,Avg.Loss: -1.059,LR: 4.59E-04]Training epoch 19:  54%|█████▎    | 60/112 [00:01<00:00, 52.80it/s, Epoch: 19, Batch: 61,Loss: -1.630,Avg.Loss: -1.068,LR: 4.59E-04]Training epoch 19:  54%|█████▍    | 61/112 [00:01<00:00, 52.80it/s, Epoch: 19, Batch: 62,Loss: -1.542,Avg.Loss: -1.076,LR: 4.59E-04]Training epoch 19:  55%|█████▌    | 62/112 [00:01<00:00, 52.80it/s, Epoch: 19, Batch: 63,Loss: -1.470,Avg.Loss: -1.082,LR: 4.59E-04]Training epoch 19:  56%|█████▋    | 63/112 [00:01<00:00, 52.80it/s, Epoch: 19, Batch: 64,Loss: -1.443,Avg.Loss: -1.087,LR: 4.59E-04]Training epoch 19:  57%|█████▋    | 64/112 [00:01<00:00, 52.80it/s, Epoch: 19, Batch: 65,Loss: -1.899,Avg.Loss: -1.100,LR: 4.59E-04]Training epoch 19:  58%|█████▊    | 65/112 [00:01<00:00, 52.80it/s, Epoch: 19, Batch: 66,Loss: -1.643,Avg.Loss: -1.108,LR: 4.59E-04]Training epoch 19:  59%|█████▉    | 66/112 [00:01<00:00, 52.81it/s, Epoch: 19, Batch: 66,Loss: -1.643,Avg.Loss: -1.108,LR: 4.59E-04]Training epoch 19:  59%|█████▉    | 66/112 [00:01<00:00, 52.81it/s, Epoch: 19, Batch: 67,Loss: -1.413,Avg.Loss: -1.113,LR: 4.59E-04]Training epoch 19:  60%|█████▉    | 67/112 [00:01<00:00, 52.81it/s, Epoch: 19, Batch: 68,Loss: -1.618,Avg.Loss: -1.120,LR: 4.58E-04]Training epoch 19:  61%|██████    | 68/112 [00:01<00:00, 52.81it/s, Epoch: 19, Batch: 69,Loss: -1.831,Avg.Loss: -1.130,LR: 4.58E-04]Training epoch 19:  62%|██████▏   | 69/112 [00:01<00:00, 52.81it/s, Epoch: 19, Batch: 70,Loss: -1.725,Avg.Loss: -1.139,LR: 4.58E-04]Training epoch 19:  62%|██████▎   | 70/112 [00:01<00:00, 52.81it/s, Epoch: 19, Batch: 71,Loss: -1.529,Avg.Loss: -1.144,LR: 4.58E-04]Training epoch 19:  63%|██████▎   | 71/112 [00:01<00:00, 52.81it/s, Epoch: 19, Batch: 72,Loss: -1.516,Avg.Loss: -1.150,LR: 4.58E-04]Training epoch 19:  64%|██████▍   | 72/112 [00:01<00:00, 52.94it/s, Epoch: 19, Batch: 72,Loss: -1.516,Avg.Loss: -1.150,LR: 4.58E-04]Training epoch 19:  64%|██████▍   | 72/112 [00:01<00:00, 52.94it/s, Epoch: 19, Batch: 73,Loss: -1.624,Avg.Loss: -1.156,LR: 4.58E-04]Training epoch 19:  65%|██████▌   | 73/112 [00:01<00:00, 52.94it/s, Epoch: 19, Batch: 74,Loss: -1.486,Avg.Loss: -1.161,LR: 4.58E-04]Training epoch 19:  66%|██████▌   | 74/112 [00:01<00:00, 52.94it/s, Epoch: 19, Batch: 75,Loss: -1.917,Avg.Loss: -1.171,LR: 4.58E-04]Training epoch 19:  67%|██████▋   | 75/112 [00:01<00:00, 52.94it/s, Epoch: 19, Batch: 76,Loss: -1.885,Avg.Loss: -1.180,LR: 4.58E-04]Training epoch 19:  68%|██████▊   | 76/112 [00:01<00:00, 52.94it/s, Epoch: 19, Batch: 77,Loss: -1.218,Avg.Loss: -1.181,LR: 4.58E-04]Training epoch 19:  69%|██████▉   | 77/112 [00:01<00:00, 52.94it/s, Epoch: 19, Batch: 78,Loss: -1.386,Avg.Loss: -1.183,LR: 4.58E-04]Training epoch 19:  70%|██████▉   | 78/112 [00:01<00:00, 52.99it/s, Epoch: 19, Batch: 78,Loss: -1.386,Avg.Loss: -1.183,LR: 4.58E-04]Training epoch 19:  70%|██████▉   | 78/112 [00:01<00:00, 52.99it/s, Epoch: 19, Batch: 79,Loss: -1.173,Avg.Loss: -1.183,LR: 4.58E-04]Training epoch 19:  71%|███████   | 79/112 [00:01<00:00, 52.99it/s, Epoch: 19, Batch: 80,Loss: -0.917,Avg.Loss: -1.180,LR: 4.58E-04]Training epoch 19:  71%|███████▏  | 80/112 [00:01<00:00, 52.99it/s, Epoch: 19, Batch: 81,Loss: -1.438,Avg.Loss: -1.183,LR: 4.58E-04]Training epoch 19:  72%|███████▏  | 81/112 [00:01<00:00, 52.99it/s, Epoch: 19, Batch: 82,Loss: -1.759,Avg.Loss: -1.190,LR: 4.58E-04]Training epoch 19:  73%|███████▎  | 82/112 [00:01<00:00, 52.99it/s, Epoch: 19, Batch: 83,Loss: -1.067,Avg.Loss: -1.188,LR: 4.58E-04]Training epoch 19:  74%|███████▍  | 83/112 [00:01<00:00, 52.99it/s, Epoch: 19, Batch: 84,Loss: -1.285,Avg.Loss: -1.190,LR: 4.58E-04]Training epoch 19:  75%|███████▌  | 84/112 [00:01<00:00, 53.27it/s, Epoch: 19, Batch: 84,Loss: -1.285,Avg.Loss: -1.190,LR: 4.58E-04]Training epoch 19:  75%|███████▌  | 84/112 [00:01<00:00, 53.27it/s, Epoch: 19, Batch: 85,Loss: -1.604,Avg.Loss: -1.194,LR: 4.58E-04]Training epoch 19:  76%|███████▌  | 85/112 [00:01<00:00, 53.27it/s, Epoch: 19, Batch: 86,Loss: -1.482,Avg.Loss: -1.198,LR: 4.58E-04]Training epoch 19:  77%|███████▋  | 86/112 [00:01<00:00, 53.27it/s, Epoch: 19, Batch: 87,Loss: -1.461,Avg.Loss: -1.201,LR: 4.58E-04]Training epoch 19:  78%|███████▊  | 87/112 [00:01<00:00, 53.27it/s, Epoch: 19, Batch: 88,Loss: -1.908,Avg.Loss: -1.209,LR: 4.58E-04]Training epoch 19:  79%|███████▊  | 88/112 [00:01<00:00, 53.27it/s, Epoch: 19, Batch: 89,Loss: -1.097,Avg.Loss: -1.208,LR: 4.58E-04]Training epoch 19:  79%|███████▉  | 89/112 [00:01<00:00, 53.27it/s, Epoch: 19, Batch: 90,Loss: -1.475,Avg.Loss: -1.211,LR: 4.58E-04]Training epoch 19:  80%|████████  | 90/112 [00:01<00:00, 53.53it/s, Epoch: 19, Batch: 90,Loss: -1.475,Avg.Loss: -1.211,LR: 4.58E-04]Training epoch 19:  80%|████████  | 90/112 [00:01<00:00, 53.53it/s, Epoch: 19, Batch: 91,Loss: -1.867,Avg.Loss: -1.218,LR: 4.58E-04]Training epoch 19:  81%|████████▏ | 91/112 [00:01<00:00, 53.53it/s, Epoch: 19, Batch: 92,Loss: -1.929,Avg.Loss: -1.226,LR: 4.58E-04]Training epoch 19:  82%|████████▏ | 92/112 [00:01<00:00, 53.53it/s, Epoch: 19, Batch: 93,Loss: -1.812,Avg.Loss: -1.232,LR: 4.58E-04]Training epoch 19:  83%|████████▎ | 93/112 [00:01<00:00, 53.53it/s, Epoch: 19, Batch: 94,Loss: -1.429,Avg.Loss: -1.234,LR: 4.57E-04]Training epoch 19:  84%|████████▍ | 94/112 [00:01<00:00, 53.53it/s, Epoch: 19, Batch: 95,Loss: -1.451,Avg.Loss: -1.236,LR: 4.57E-04]Training epoch 19:  85%|████████▍ | 95/112 [00:01<00:00, 53.53it/s, Epoch: 19, Batch: 96,Loss: -1.789,Avg.Loss: -1.242,LR: 4.57E-04]Training epoch 19:  86%|████████▌ | 96/112 [00:01<00:00, 53.54it/s, Epoch: 19, Batch: 96,Loss: -1.789,Avg.Loss: -1.242,LR: 4.57E-04]Training epoch 19:  86%|████████▌ | 96/112 [00:01<00:00, 53.54it/s, Epoch: 19, Batch: 97,Loss: -1.848,Avg.Loss: -1.248,LR: 4.57E-04]Training epoch 19:  87%|████████▋ | 97/112 [00:01<00:00, 53.54it/s, Epoch: 19, Batch: 98,Loss: -1.552,Avg.Loss: -1.251,LR: 4.57E-04]Training epoch 19:  88%|████████▊ | 98/112 [00:01<00:00, 53.54it/s, Epoch: 19, Batch: 99,Loss: -1.964,Avg.Loss: -1.259,LR: 4.57E-04]Training epoch 19:  88%|████████▊ | 99/112 [00:01<00:00, 53.54it/s, Epoch: 19, Batch: 100,Loss: -1.548,Avg.Loss: -1.261,LR: 4.57E-04]Training epoch 19:  89%|████████▉ | 100/112 [00:01<00:00, 53.54it/s, Epoch: 19, Batch: 101,Loss: -1.352,Avg.Loss: -1.262,LR: 4.57E-04]Training epoch 19:  90%|█████████ | 101/112 [00:01<00:00, 53.54it/s, Epoch: 19, Batch: 102,Loss: -1.903,Avg.Loss: -1.269,LR: 4.57E-04]Training epoch 19:  91%|█████████ | 102/112 [00:01<00:00, 53.51it/s, Epoch: 19, Batch: 102,Loss: -1.903,Avg.Loss: -1.269,LR: 4.57E-04]Training epoch 19:  91%|█████████ | 102/112 [00:01<00:00, 53.51it/s, Epoch: 19, Batch: 103,Loss: -1.947,Avg.Loss: -1.275,LR: 4.57E-04]Training epoch 19:  92%|█████████▏| 103/112 [00:01<00:00, 53.51it/s, Epoch: 19, Batch: 104,Loss: -1.647,Avg.Loss: -1.279,LR: 4.57E-04]Training epoch 19:  93%|█████████▎| 104/112 [00:01<00:00, 53.51it/s, Epoch: 19, Batch: 105,Loss: -0.967,Avg.Loss: -1.276,LR: 4.57E-04]Training epoch 19:  94%|█████████▍| 105/112 [00:01<00:00, 53.51it/s, Epoch: 19, Batch: 106,Loss: -1.451,Avg.Loss: -1.277,LR: 4.57E-04]Training epoch 19:  95%|█████████▍| 106/112 [00:02<00:00, 53.51it/s, Epoch: 19, Batch: 107,Loss: -1.311,Avg.Loss: -1.278,LR: 4.57E-04]Training epoch 19:  96%|█████████▌| 107/112 [00:02<00:00, 53.51it/s, Epoch: 19, Batch: 108,Loss: -1.991,Avg.Loss: -1.284,LR: 4.57E-04]Training epoch 19:  96%|█████████▋| 108/112 [00:02<00:00, 52.31it/s, Epoch: 19, Batch: 108,Loss: -1.991,Avg.Loss: -1.284,LR: 4.57E-04]Training epoch 19:  96%|█████████▋| 108/112 [00:02<00:00, 52.31it/s, Epoch: 19, Batch: 109,Loss: -1.032,Avg.Loss: -1.282,LR: 4.57E-04]Training epoch 19:  97%|█████████▋| 109/112 [00:02<00:00, 52.31it/s, Epoch: 19, Batch: 110,Loss: -0.048,Avg.Loss: -1.271,LR: 4.57E-04]Training epoch 19:  98%|█████████▊| 110/112 [00:02<00:00, 52.31it/s, Epoch: 19, Batch: 111,Loss: -0.618,Avg.Loss: -1.265,LR: 4.57E-04]Training epoch 19:  99%|█████████▉| 111/112 [00:02<00:00, 52.31it/s, Epoch: 19, Batch: 112,Loss: -1.532,Avg.Loss: -1.267,LR: 4.57E-04]Training epoch 19: 100%|██████████| 112/112 [00:02<00:00, 53.27it/s, Epoch: 19, Batch: 112,Loss: -1.532,Avg.Loss: -1.267,LR: 4.57E-04]
Training epoch 20:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 20:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 20, Batch: 1,Loss: 2.345,Avg.Loss: 2.345,LR: 4.57E-04]Training epoch 20:   1%|          | 1/112 [00:00<00:04, 26.95it/s, Epoch: 20, Batch: 2,Loss: -0.705,Avg.Loss: 0.820,LR: 4.57E-04]Training epoch 20:   2%|▏         | 2/112 [00:00<00:03, 34.51it/s, Epoch: 20, Batch: 3,Loss: -1.062,Avg.Loss: 0.193,LR: 4.57E-04]Training epoch 20:   3%|▎         | 3/112 [00:00<00:02, 41.51it/s, Epoch: 20, Batch: 4,Loss: -1.095,Avg.Loss: -0.129,LR: 4.57E-04]Training epoch 20:   4%|▎         | 4/112 [00:00<00:02, 46.24it/s, Epoch: 20, Batch: 5,Loss: -1.685,Avg.Loss: -0.440,LR: 4.57E-04]Training epoch 20:   4%|▍         | 5/112 [00:00<00:02, 50.12it/s, Epoch: 20, Batch: 6,Loss: -0.017,Avg.Loss: -0.370,LR: 4.57E-04]Training epoch 20:   5%|▌         | 6/112 [00:00<00:02, 51.29it/s, Epoch: 20, Batch: 7,Loss: 2.224,Avg.Loss: 0.001,LR: 4.56E-04]  Training epoch 20:   6%|▋         | 7/112 [00:00<00:01, 59.77it/s, Epoch: 20, Batch: 7,Loss: 2.224,Avg.Loss: 0.001,LR: 4.56E-04]Training epoch 20:   6%|▋         | 7/112 [00:00<00:01, 59.77it/s, Epoch: 20, Batch: 8,Loss: -0.179,Avg.Loss: -0.022,LR: 4.56E-04]Training epoch 20:   7%|▋         | 8/112 [00:00<00:01, 59.77it/s, Epoch: 20, Batch: 9,Loss: -0.208,Avg.Loss: -0.042,LR: 4.56E-04]Training epoch 20:   8%|▊         | 9/112 [00:00<00:01, 59.77it/s, Epoch: 20, Batch: 10,Loss: 1.516,Avg.Loss: 0.113,LR: 4.56E-04] Training epoch 20:   9%|▉         | 10/112 [00:00<00:01, 59.77it/s, Epoch: 20, Batch: 11,Loss: 0.048,Avg.Loss: 0.107,LR: 4.56E-04]Training epoch 20:  10%|▉         | 11/112 [00:00<00:01, 59.77it/s, Epoch: 20, Batch: 12,Loss: -1.138,Avg.Loss: 0.004,LR: 4.56E-04]Training epoch 20:  11%|█         | 12/112 [00:00<00:01, 59.77it/s, Epoch: 20, Batch: 13,Loss: -1.105,Avg.Loss: -0.082,LR: 4.56E-04]Training epoch 20:  12%|█▏        | 13/112 [00:00<00:01, 56.94it/s, Epoch: 20, Batch: 13,Loss: -1.105,Avg.Loss: -0.082,LR: 4.56E-04]Training epoch 20:  12%|█▏        | 13/112 [00:00<00:01, 56.94it/s, Epoch: 20, Batch: 14,Loss: -1.556,Avg.Loss: -0.187,LR: 4.56E-04]Training epoch 20:  12%|█▎        | 14/112 [00:00<00:01, 56.94it/s, Epoch: 20, Batch: 15,Loss: -1.009,Avg.Loss: -0.242,LR: 4.56E-04]Training epoch 20:  13%|█▎        | 15/112 [00:00<00:01, 56.94it/s, Epoch: 20, Batch: 16,Loss: -1.537,Avg.Loss: -0.323,LR: 4.56E-04]Training epoch 20:  14%|█▍        | 16/112 [00:00<00:01, 56.94it/s, Epoch: 20, Batch: 17,Loss: -0.757,Avg.Loss: -0.348,LR: 4.56E-04]Training epoch 20:  15%|█▌        | 17/112 [00:00<00:01, 56.94it/s, Epoch: 20, Batch: 18,Loss: -1.046,Avg.Loss: -0.387,LR: 4.56E-04]Training epoch 20:  16%|█▌        | 18/112 [00:00<00:01, 56.94it/s, Epoch: 20, Batch: 19,Loss: -0.504,Avg.Loss: -0.393,LR: 4.56E-04]Training epoch 20:  17%|█▋        | 19/112 [00:00<00:01, 54.55it/s, Epoch: 20, Batch: 19,Loss: -0.504,Avg.Loss: -0.393,LR: 4.56E-04]Training epoch 20:  17%|█▋        | 19/112 [00:00<00:01, 54.55it/s, Epoch: 20, Batch: 20,Loss: -0.454,Avg.Loss: -0.396,LR: 4.56E-04]Training epoch 20:  18%|█▊        | 20/112 [00:00<00:01, 54.55it/s, Epoch: 20, Batch: 21,Loss: -1.120,Avg.Loss: -0.431,LR: 4.56E-04]Training epoch 20:  19%|█▉        | 21/112 [00:00<00:01, 54.55it/s, Epoch: 20, Batch: 22,Loss: -1.848,Avg.Loss: -0.495,LR: 4.56E-04]Training epoch 20:  20%|█▉        | 22/112 [00:00<00:01, 54.55it/s, Epoch: 20, Batch: 23,Loss: -1.470,Avg.Loss: -0.537,LR: 4.56E-04]Training epoch 20:  21%|██        | 23/112 [00:00<00:01, 54.55it/s, Epoch: 20, Batch: 24,Loss: -1.371,Avg.Loss: -0.572,LR: 4.56E-04]Training epoch 20:  21%|██▏       | 24/112 [00:00<00:01, 54.55it/s, Epoch: 20, Batch: 25,Loss: -1.083,Avg.Loss: -0.593,LR: 4.56E-04]Training epoch 20:  22%|██▏       | 25/112 [00:00<00:01, 53.37it/s, Epoch: 20, Batch: 25,Loss: -1.083,Avg.Loss: -0.593,LR: 4.56E-04]Training epoch 20:  22%|██▏       | 25/112 [00:00<00:01, 53.37it/s, Epoch: 20, Batch: 26,Loss: -1.516,Avg.Loss: -0.628,LR: 4.56E-04]Training epoch 20:  23%|██▎       | 26/112 [00:00<00:01, 53.37it/s, Epoch: 20, Batch: 27,Loss: -1.308,Avg.Loss: -0.653,LR: 4.56E-04]Training epoch 20:  24%|██▍       | 27/112 [00:00<00:01, 53.37it/s, Epoch: 20, Batch: 28,Loss: -0.902,Avg.Loss: -0.662,LR: 4.56E-04]Training epoch 20:  25%|██▌       | 28/112 [00:00<00:01, 53.37it/s, Epoch: 20, Batch: 29,Loss: -1.731,Avg.Loss: -0.699,LR: 4.56E-04]Training epoch 20:  26%|██▌       | 29/112 [00:00<00:01, 53.37it/s, Epoch: 20, Batch: 30,Loss: -1.830,Avg.Loss: -0.737,LR: 4.56E-04]Training epoch 20:  27%|██▋       | 30/112 [00:00<00:01, 53.37it/s, Epoch: 20, Batch: 31,Loss: -1.705,Avg.Loss: -0.768,LR: 4.56E-04]Training epoch 20:  28%|██▊       | 31/112 [00:00<00:01, 52.95it/s, Epoch: 20, Batch: 31,Loss: -1.705,Avg.Loss: -0.768,LR: 4.56E-04]Training epoch 20:  28%|██▊       | 31/112 [00:00<00:01, 52.95it/s, Epoch: 20, Batch: 32,Loss: -2.041,Avg.Loss: -0.808,LR: 4.56E-04]Training epoch 20:  29%|██▊       | 32/112 [00:00<00:01, 52.95it/s, Epoch: 20, Batch: 33,Loss: -0.534,Avg.Loss: -0.799,LR: 4.55E-04]Training epoch 20:  29%|██▉       | 33/112 [00:00<00:01, 52.95it/s, Epoch: 20, Batch: 34,Loss: -0.648,Avg.Loss: -0.795,LR: 4.55E-04]Training epoch 20:  30%|███       | 34/112 [00:00<00:01, 52.95it/s, Epoch: 20, Batch: 35,Loss: -1.985,Avg.Loss: -0.829,LR: 4.55E-04]Training epoch 20:  31%|███▏      | 35/112 [00:00<00:01, 52.95it/s, Epoch: 20, Batch: 36,Loss: 0.527,Avg.Loss: -0.791,LR: 4.55E-04] Training epoch 20:  32%|███▏      | 36/112 [00:00<00:01, 52.95it/s, Epoch: 20, Batch: 37,Loss: 1.588,Avg.Loss: -0.727,LR: 4.55E-04]Training epoch 20:  33%|███▎      | 37/112 [00:00<00:01, 52.79it/s, Epoch: 20, Batch: 37,Loss: 1.588,Avg.Loss: -0.727,LR: 4.55E-04]Training epoch 20:  33%|███▎      | 37/112 [00:00<00:01, 52.79it/s, Epoch: 20, Batch: 38,Loss: 0.629,Avg.Loss: -0.691,LR: 4.55E-04]Training epoch 20:  34%|███▍      | 38/112 [00:00<00:01, 52.79it/s, Epoch: 20, Batch: 39,Loss: -1.703,Avg.Loss: -0.717,LR: 4.55E-04]Training epoch 20:  35%|███▍      | 39/112 [00:00<00:01, 52.79it/s, Epoch: 20, Batch: 40,Loss: 1.989,Avg.Loss: -0.650,LR: 4.55E-04] Training epoch 20:  36%|███▌      | 40/112 [00:00<00:01, 52.79it/s, Epoch: 20, Batch: 41,Loss: 4.435,Avg.Loss: -0.526,LR: 4.55E-04]Training epoch 20:  37%|███▋      | 41/112 [00:00<00:01, 52.79it/s, Epoch: 20, Batch: 42,Loss: 3.097,Avg.Loss: -0.439,LR: 4.55E-04]Training epoch 20:  38%|███▊      | 42/112 [00:00<00:01, 52.79it/s, Epoch: 20, Batch: 43,Loss: -0.361,Avg.Loss: -0.438,LR: 4.55E-04]Training epoch 20:  38%|███▊      | 43/112 [00:00<00:01, 52.68it/s, Epoch: 20, Batch: 43,Loss: -0.361,Avg.Loss: -0.438,LR: 4.55E-04]Training epoch 20:  38%|███▊      | 43/112 [00:00<00:01, 52.68it/s, Epoch: 20, Batch: 44,Loss: -1.394,Avg.Loss: -0.459,LR: 4.55E-04]Training epoch 20:  39%|███▉      | 44/112 [00:00<00:01, 52.68it/s, Epoch: 20, Batch: 45,Loss: 1.019,Avg.Loss: -0.426,LR: 4.55E-04] Training epoch 20:  40%|████      | 45/112 [00:00<00:01, 52.68it/s, Epoch: 20, Batch: 46,Loss: 0.044,Avg.Loss: -0.416,LR: 4.55E-04]Training epoch 20:  41%|████      | 46/112 [00:00<00:01, 52.68it/s, Epoch: 20, Batch: 47,Loss: -1.752,Avg.Loss: -0.445,LR: 4.55E-04]Training epoch 20:  42%|████▏     | 47/112 [00:00<00:01, 52.68it/s, Epoch: 20, Batch: 48,Loss: 0.732,Avg.Loss: -0.420,LR: 4.55E-04] Training epoch 20:  43%|████▎     | 48/112 [00:00<00:01, 52.68it/s, Epoch: 20, Batch: 49,Loss: 2.355,Avg.Loss: -0.363,LR: 4.55E-04]Training epoch 20:  44%|████▍     | 49/112 [00:00<00:01, 52.56it/s, Epoch: 20, Batch: 49,Loss: 2.355,Avg.Loss: -0.363,LR: 4.55E-04]Training epoch 20:  44%|████▍     | 49/112 [00:00<00:01, 52.56it/s, Epoch: 20, Batch: 50,Loss: 2.461,Avg.Loss: -0.307,LR: 4.55E-04]Training epoch 20:  45%|████▍     | 50/112 [00:00<00:01, 52.56it/s, Epoch: 20, Batch: 51,Loss: -0.626,Avg.Loss: -0.313,LR: 4.55E-04]Training epoch 20:  46%|████▌     | 51/112 [00:00<00:01, 52.56it/s, Epoch: 20, Batch: 52,Loss: -0.262,Avg.Loss: -0.312,LR: 4.55E-04]Training epoch 20:  46%|████▋     | 52/112 [00:00<00:01, 52.56it/s, Epoch: 20, Batch: 53,Loss: 0.819,Avg.Loss: -0.291,LR: 4.55E-04] Training epoch 20:  47%|████▋     | 53/112 [00:01<00:01, 52.56it/s, Epoch: 20, Batch: 54,Loss: 0.716,Avg.Loss: -0.272,LR: 4.55E-04]Training epoch 20:  48%|████▊     | 54/112 [00:01<00:01, 52.56it/s, Epoch: 20, Batch: 55,Loss: -1.454,Avg.Loss: -0.294,LR: 4.55E-04]Training epoch 20:  49%|████▉     | 55/112 [00:01<00:01, 52.61it/s, Epoch: 20, Batch: 55,Loss: -1.454,Avg.Loss: -0.294,LR: 4.55E-04]Training epoch 20:  49%|████▉     | 55/112 [00:01<00:01, 52.61it/s, Epoch: 20, Batch: 56,Loss: -0.458,Avg.Loss: -0.297,LR: 4.55E-04]Training epoch 20:  50%|█████     | 56/112 [00:01<00:01, 52.61it/s, Epoch: 20, Batch: 57,Loss: 1.286,Avg.Loss: -0.269,LR: 4.54E-04] Training epoch 20:  51%|█████     | 57/112 [00:01<00:01, 52.61it/s, Epoch: 20, Batch: 58,Loss: 1.069,Avg.Loss: -0.246,LR: 4.54E-04]Training epoch 20:  52%|█████▏    | 58/112 [00:01<00:01, 52.61it/s, Epoch: 20, Batch: 59,Loss: -1.572,Avg.Loss: -0.268,LR: 4.54E-04]Training epoch 20:  53%|█████▎    | 59/112 [00:01<00:01, 52.61it/s, Epoch: 20, Batch: 60,Loss: -0.246,Avg.Loss: -0.268,LR: 4.54E-04]Training epoch 20:  54%|█████▎    | 60/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 61,Loss: 0.924,Avg.Loss: -0.248,LR: 4.54E-04] Training epoch 20:  54%|█████▍    | 61/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 61,Loss: 0.924,Avg.Loss: -0.248,LR: 4.54E-04]Training epoch 20:  54%|█████▍    | 61/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 62,Loss: 0.826,Avg.Loss: -0.231,LR: 4.54E-04]Training epoch 20:  55%|█████▌    | 62/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 63,Loss: -1.097,Avg.Loss: -0.245,LR: 4.54E-04]Training epoch 20:  56%|█████▋    | 63/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 64,Loss: -0.994,Avg.Loss: -0.256,LR: 4.54E-04]Training epoch 20:  57%|█████▋    | 64/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 65,Loss: 0.618,Avg.Loss: -0.243,LR: 4.54E-04] Training epoch 20:  58%|█████▊    | 65/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 66,Loss: -0.264,Avg.Loss: -0.243,LR: 4.54E-04]Training epoch 20:  59%|█████▉    | 66/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 67,Loss: -1.817,Avg.Loss: -0.267,LR: 4.54E-04]Training epoch 20:  60%|█████▉    | 67/112 [00:01<00:00, 52.50it/s, Epoch: 20, Batch: 67,Loss: -1.817,Avg.Loss: -0.267,LR: 4.54E-04]Training epoch 20:  60%|█████▉    | 67/112 [00:01<00:00, 52.50it/s, Epoch: 20, Batch: 68,Loss: -0.503,Avg.Loss: -0.270,LR: 4.54E-04]Training epoch 20:  61%|██████    | 68/112 [00:01<00:00, 52.50it/s, Epoch: 20, Batch: 69,Loss: 0.812,Avg.Loss: -0.255,LR: 4.54E-04] Training epoch 20:  62%|██████▏   | 69/112 [00:01<00:00, 52.50it/s, Epoch: 20, Batch: 70,Loss: 0.603,Avg.Loss: -0.242,LR: 4.54E-04]Training epoch 20:  62%|██████▎   | 70/112 [00:01<00:00, 52.50it/s, Epoch: 20, Batch: 71,Loss: -1.002,Avg.Loss: -0.253,LR: 4.54E-04]Training epoch 20:  63%|██████▎   | 71/112 [00:01<00:00, 52.50it/s, Epoch: 20, Batch: 72,Loss: -1.022,Avg.Loss: -0.264,LR: 4.54E-04]Training epoch 20:  64%|██████▍   | 72/112 [00:01<00:00, 52.50it/s, Epoch: 20, Batch: 73,Loss: 0.442,Avg.Loss: -0.254,LR: 4.54E-04] Training epoch 20:  65%|██████▌   | 73/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 73,Loss: 0.442,Avg.Loss: -0.254,LR: 4.54E-04]Training epoch 20:  65%|██████▌   | 73/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 74,Loss: -0.039,Avg.Loss: -0.251,LR: 4.54E-04]Training epoch 20:  66%|██████▌   | 74/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 75,Loss: -1.437,Avg.Loss: -0.267,LR: 4.54E-04]Training epoch 20:  67%|██████▋   | 75/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 76,Loss: -0.581,Avg.Loss: -0.271,LR: 4.54E-04]Training epoch 20:  68%|██████▊   | 76/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 77,Loss: 0.292,Avg.Loss: -0.264,LR: 4.54E-04] Training epoch 20:  69%|██████▉   | 77/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 78,Loss: -0.302,Avg.Loss: -0.264,LR: 4.54E-04]Training epoch 20:  70%|██████▉   | 78/112 [00:01<00:00, 52.61it/s, Epoch: 20, Batch: 79,Loss: -1.456,Avg.Loss: -0.279,LR: 4.54E-04]Training epoch 20:  71%|███████   | 79/112 [00:01<00:00, 52.83it/s, Epoch: 20, Batch: 79,Loss: -1.456,Avg.Loss: -0.279,LR: 4.54E-04]Training epoch 20:  71%|███████   | 79/112 [00:01<00:00, 52.83it/s, Epoch: 20, Batch: 80,Loss: -1.150,Avg.Loss: -0.290,LR: 4.54E-04]Training epoch 20:  71%|███████▏  | 80/112 [00:01<00:00, 52.83it/s, Epoch: 20, Batch: 81,Loss: -0.269,Avg.Loss: -0.290,LR: 4.54E-04]Training epoch 20:  72%|███████▏  | 81/112 [00:01<00:00, 52.83it/s, Epoch: 20, Batch: 82,Loss: -0.552,Avg.Loss: -0.293,LR: 4.53E-04]Training epoch 20:  73%|███████▎  | 82/112 [00:01<00:00, 52.83it/s, Epoch: 20, Batch: 83,Loss: -1.467,Avg.Loss: -0.307,LR: 4.53E-04]Training epoch 20:  74%|███████▍  | 83/112 [00:01<00:00, 52.83it/s, Epoch: 20, Batch: 84,Loss: -0.929,Avg.Loss: -0.315,LR: 4.53E-04]Training epoch 20:  75%|███████▌  | 84/112 [00:01<00:00, 52.83it/s, Epoch: 20, Batch: 85,Loss: -0.251,Avg.Loss: -0.314,LR: 4.53E-04]Training epoch 20:  76%|███████▌  | 85/112 [00:01<00:00, 53.04it/s, Epoch: 20, Batch: 85,Loss: -0.251,Avg.Loss: -0.314,LR: 4.53E-04]Training epoch 20:  76%|███████▌  | 85/112 [00:01<00:00, 53.04it/s, Epoch: 20, Batch: 86,Loss: -0.260,Avg.Loss: -0.313,LR: 4.53E-04]Training epoch 20:  77%|███████▋  | 86/112 [00:01<00:00, 53.04it/s, Epoch: 20, Batch: 87,Loss: -1.259,Avg.Loss: -0.324,LR: 4.53E-04]Training epoch 20:  78%|███████▊  | 87/112 [00:01<00:00, 53.04it/s, Epoch: 20, Batch: 88,Loss: -1.224,Avg.Loss: -0.334,LR: 4.53E-04]Training epoch 20:  79%|███████▊  | 88/112 [00:01<00:00, 53.04it/s, Epoch: 20, Batch: 89,Loss: 0.761,Avg.Loss: -0.322,LR: 4.53E-04] Training epoch 20:  79%|███████▉  | 89/112 [00:01<00:00, 53.04it/s, Epoch: 20, Batch: 90,Loss: -0.220,Avg.Loss: -0.321,LR: 4.53E-04]Training epoch 20:  80%|████████  | 90/112 [00:01<00:00, 53.04it/s, Epoch: 20, Batch: 91,Loss: -0.891,Avg.Loss: -0.327,LR: 4.53E-04]Training epoch 20:  81%|████████▏ | 91/112 [00:01<00:00, 53.41it/s, Epoch: 20, Batch: 91,Loss: -0.891,Avg.Loss: -0.327,LR: 4.53E-04]Training epoch 20:  81%|████████▏ | 91/112 [00:01<00:00, 53.41it/s, Epoch: 20, Batch: 92,Loss: -1.446,Avg.Loss: -0.339,LR: 4.53E-04]Training epoch 20:  82%|████████▏ | 92/112 [00:01<00:00, 53.41it/s, Epoch: 20, Batch: 93,Loss: -0.258,Avg.Loss: -0.339,LR: 4.53E-04]Training epoch 20:  83%|████████▎ | 93/112 [00:01<00:00, 53.41it/s, Epoch: 20, Batch: 94,Loss: -0.738,Avg.Loss: -0.343,LR: 4.53E-04]Training epoch 20:  84%|████████▍ | 94/112 [00:01<00:00, 53.41it/s, Epoch: 20, Batch: 95,Loss: -1.444,Avg.Loss: -0.354,LR: 4.53E-04]Training epoch 20:  85%|████████▍ | 95/112 [00:01<00:00, 53.41it/s, Epoch: 20, Batch: 96,Loss: -1.138,Avg.Loss: -0.363,LR: 4.53E-04]Training epoch 20:  86%|████████▌ | 96/112 [00:01<00:00, 53.41it/s, Epoch: 20, Batch: 97,Loss: -0.091,Avg.Loss: -0.360,LR: 4.53E-04]Training epoch 20:  87%|████████▋ | 97/112 [00:01<00:00, 53.57it/s, Epoch: 20, Batch: 97,Loss: -0.091,Avg.Loss: -0.360,LR: 4.53E-04]Training epoch 20:  87%|████████▋ | 97/112 [00:01<00:00, 53.57it/s, Epoch: 20, Batch: 98,Loss: -0.260,Avg.Loss: -0.359,LR: 4.53E-04]Training epoch 20:  88%|████████▊ | 98/112 [00:01<00:00, 53.57it/s, Epoch: 20, Batch: 99,Loss: -1.124,Avg.Loss: -0.366,LR: 4.53E-04]Training epoch 20:  88%|████████▊ | 99/112 [00:01<00:00, 53.57it/s, Epoch: 20, Batch: 100,Loss: -0.973,Avg.Loss: -0.373,LR: 4.53E-04]Training epoch 20:  89%|████████▉ | 100/112 [00:01<00:00, 53.57it/s, Epoch: 20, Batch: 101,Loss: -0.465,Avg.Loss: -0.373,LR: 4.53E-04]Training epoch 20:  90%|█████████ | 101/112 [00:01<00:00, 53.57it/s, Epoch: 20, Batch: 102,Loss: -0.560,Avg.Loss: -0.375,LR: 4.53E-04]Training epoch 20:  91%|█████████ | 102/112 [00:01<00:00, 53.57it/s, Epoch: 20, Batch: 103,Loss: -1.316,Avg.Loss: -0.384,LR: 4.53E-04]Training epoch 20:  92%|█████████▏| 103/112 [00:01<00:00, 53.64it/s, Epoch: 20, Batch: 103,Loss: -1.316,Avg.Loss: -0.384,LR: 4.53E-04]Training epoch 20:  92%|█████████▏| 103/112 [00:01<00:00, 53.64it/s, Epoch: 20, Batch: 104,Loss: -1.012,Avg.Loss: -0.390,LR: 4.53E-04]Training epoch 20:  93%|█████████▎| 104/112 [00:01<00:00, 53.64it/s, Epoch: 20, Batch: 105,Loss: 0.367,Avg.Loss: -0.383,LR: 4.53E-04] Training epoch 20:  94%|█████████▍| 105/112 [00:01<00:00, 53.64it/s, Epoch: 20, Batch: 106,Loss: -0.387,Avg.Loss: -0.383,LR: 4.53E-04]Training epoch 20:  95%|█████████▍| 106/112 [00:02<00:00, 53.64it/s, Epoch: 20, Batch: 107,Loss: -1.577,Avg.Loss: -0.394,LR: 4.52E-04]Training epoch 20:  96%|█████████▌| 107/112 [00:02<00:00, 53.64it/s, Epoch: 20, Batch: 108,Loss: -1.035,Avg.Loss: -0.400,LR: 4.52E-04]Training epoch 20:  96%|█████████▋| 108/112 [00:02<00:00, 53.64it/s, Epoch: 20, Batch: 109,Loss: 0.009,Avg.Loss: -0.397,LR: 4.52E-04] Training epoch 20:  97%|█████████▋| 109/112 [00:02<00:00, 53.66it/s, Epoch: 20, Batch: 109,Loss: 0.009,Avg.Loss: -0.397,LR: 4.52E-04]Training epoch 20:  97%|█████████▋| 109/112 [00:02<00:00, 53.66it/s, Epoch: 20, Batch: 110,Loss: -0.440,Avg.Loss: -0.397,LR: 4.52E-04]Training epoch 20:  98%|█████████▊| 110/112 [00:02<00:00, 53.66it/s, Epoch: 20, Batch: 111,Loss: -1.144,Avg.Loss: -0.404,LR: 4.52E-04]Training epoch 20:  99%|█████████▉| 111/112 [00:02<00:00, 53.66it/s, Epoch: 20, Batch: 112,Loss: -1.802,Avg.Loss: -0.416,LR: 4.52E-04]Training epoch 20: 100%|██████████| 112/112 [00:02<00:00, 53.29it/s, Epoch: 20, Batch: 112,Loss: -1.802,Avg.Loss: -0.416,LR: 4.52E-04]
Training epoch 21:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 21:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 21, Batch: 1,Loss: -0.490,Avg.Loss: -0.490,LR: 4.52E-04]Training epoch 21:   1%|          | 1/112 [00:00<00:04, 26.52it/s, Epoch: 21, Batch: 2,Loss: -1.145,Avg.Loss: -0.818,LR: 4.52E-04]Training epoch 21:   2%|▏         | 2/112 [00:00<00:03, 34.90it/s, Epoch: 21, Batch: 3,Loss: -1.617,Avg.Loss: -1.084,LR: 4.52E-04]Training epoch 21:   3%|▎         | 3/112 [00:00<00:02, 40.07it/s, Epoch: 21, Batch: 4,Loss: -0.635,Avg.Loss: -0.972,LR: 4.52E-04]Training epoch 21:   4%|▎         | 4/112 [00:00<00:02, 43.78it/s, Epoch: 21, Batch: 5,Loss: -0.041,Avg.Loss: -0.786,LR: 4.52E-04]Training epoch 21:   4%|▍         | 5/112 [00:00<00:02, 47.71it/s, Epoch: 21, Batch: 6,Loss: -0.604,Avg.Loss: -0.756,LR: 4.52E-04]Training epoch 21:   5%|▌         | 6/112 [00:00<00:01, 57.18it/s, Epoch: 21, Batch: 6,Loss: -0.604,Avg.Loss: -0.756,LR: 4.52E-04]Training epoch 21:   5%|▌         | 6/112 [00:00<00:01, 57.18it/s, Epoch: 21, Batch: 7,Loss: -1.383,Avg.Loss: -0.845,LR: 4.52E-04]Training epoch 21:   6%|▋         | 7/112 [00:00<00:01, 57.18it/s, Epoch: 21, Batch: 8,Loss: -1.239,Avg.Loss: -0.894,LR: 4.52E-04]Training epoch 21:   7%|▋         | 8/112 [00:00<00:01, 57.18it/s, Epoch: 21, Batch: 9,Loss: -0.057,Avg.Loss: -0.801,LR: 4.52E-04]Training epoch 21:   8%|▊         | 9/112 [00:00<00:01, 57.18it/s, Epoch: 21, Batch: 10,Loss: -0.723,Avg.Loss: -0.794,LR: 4.52E-04]Training epoch 21:   9%|▉         | 10/112 [00:00<00:01, 57.18it/s, Epoch: 21, Batch: 11,Loss: -1.041,Avg.Loss: -0.816,LR: 4.52E-04]Training epoch 21:  10%|▉         | 11/112 [00:00<00:01, 57.18it/s, Epoch: 21, Batch: 12,Loss: -1.164,Avg.Loss: -0.845,LR: 4.52E-04]Training epoch 21:  11%|█         | 12/112 [00:00<00:01, 56.70it/s, Epoch: 21, Batch: 12,Loss: -1.164,Avg.Loss: -0.845,LR: 4.52E-04]Training epoch 21:  11%|█         | 12/112 [00:00<00:01, 56.70it/s, Epoch: 21, Batch: 13,Loss: -0.491,Avg.Loss: -0.818,LR: 4.52E-04]Training epoch 21:  12%|█▏        | 13/112 [00:00<00:01, 56.70it/s, Epoch: 21, Batch: 14,Loss: -0.624,Avg.Loss: -0.804,LR: 4.52E-04]Training epoch 21:  12%|█▎        | 14/112 [00:00<00:01, 56.70it/s, Epoch: 21, Batch: 15,Loss: -0.783,Avg.Loss: -0.803,LR: 4.52E-04]Training epoch 21:  13%|█▎        | 15/112 [00:00<00:01, 56.70it/s, Epoch: 21, Batch: 16,Loss: -1.026,Avg.Loss: -0.817,LR: 4.52E-04]Training epoch 21:  14%|█▍        | 16/112 [00:00<00:01, 56.70it/s, Epoch: 21, Batch: 17,Loss: -0.904,Avg.Loss: -0.822,LR: 4.52E-04]Training epoch 21:  15%|█▌        | 17/112 [00:00<00:01, 56.70it/s, Epoch: 21, Batch: 18,Loss: -1.016,Avg.Loss: -0.832,LR: 4.52E-04]Training epoch 21:  16%|█▌        | 18/112 [00:00<00:01, 54.92it/s, Epoch: 21, Batch: 18,Loss: -1.016,Avg.Loss: -0.832,LR: 4.52E-04]Training epoch 21:  16%|█▌        | 18/112 [00:00<00:01, 54.92it/s, Epoch: 21, Batch: 19,Loss: -1.175,Avg.Loss: -0.850,LR: 4.51E-04]Training epoch 21:  17%|█▋        | 19/112 [00:00<00:01, 54.92it/s, Epoch: 21, Batch: 20,Loss: -1.337,Avg.Loss: -0.875,LR: 4.51E-04]Training epoch 21:  18%|█▊        | 20/112 [00:00<00:01, 54.92it/s, Epoch: 21, Batch: 21,Loss: -1.263,Avg.Loss: -0.893,LR: 4.51E-04]Training epoch 21:  19%|█▉        | 21/112 [00:00<00:01, 54.92it/s, Epoch: 21, Batch: 22,Loss: -0.920,Avg.Loss: -0.894,LR: 4.51E-04]Training epoch 21:  20%|█▉        | 22/112 [00:00<00:01, 54.92it/s, Epoch: 21, Batch: 23,Loss: -1.385,Avg.Loss: -0.916,LR: 4.51E-04]Training epoch 21:  21%|██        | 23/112 [00:00<00:01, 54.92it/s, Epoch: 21, Batch: 24,Loss: -1.596,Avg.Loss: -0.944,LR: 4.51E-04]Training epoch 21:  21%|██▏       | 24/112 [00:00<00:01, 53.18it/s, Epoch: 21, Batch: 24,Loss: -1.596,Avg.Loss: -0.944,LR: 4.51E-04]Training epoch 21:  21%|██▏       | 24/112 [00:00<00:01, 53.18it/s, Epoch: 21, Batch: 25,Loss: -1.403,Avg.Loss: -0.962,LR: 4.51E-04]Training epoch 21:  22%|██▏       | 25/112 [00:00<00:01, 53.18it/s, Epoch: 21, Batch: 26,Loss: -1.694,Avg.Loss: -0.991,LR: 4.51E-04]Training epoch 21:  23%|██▎       | 26/112 [00:00<00:01, 53.18it/s, Epoch: 21, Batch: 27,Loss: -1.306,Avg.Loss: -1.002,LR: 4.51E-04]Training epoch 21:  24%|██▍       | 27/112 [00:00<00:01, 53.18it/s, Epoch: 21, Batch: 28,Loss: -1.269,Avg.Loss: -1.012,LR: 4.51E-04]Training epoch 21:  25%|██▌       | 28/112 [00:00<00:01, 53.18it/s, Epoch: 21, Batch: 29,Loss: -1.294,Avg.Loss: -1.022,LR: 4.51E-04]Training epoch 21:  26%|██▌       | 29/112 [00:00<00:01, 53.18it/s, Epoch: 21, Batch: 30,Loss: -1.667,Avg.Loss: -1.043,LR: 4.51E-04]Training epoch 21:  27%|██▋       | 30/112 [00:00<00:01, 52.67it/s, Epoch: 21, Batch: 30,Loss: -1.667,Avg.Loss: -1.043,LR: 4.51E-04]Training epoch 21:  27%|██▋       | 30/112 [00:00<00:01, 52.67it/s, Epoch: 21, Batch: 31,Loss: -1.877,Avg.Loss: -1.070,LR: 4.51E-04]Training epoch 21:  28%|██▊       | 31/112 [00:00<00:01, 52.67it/s, Epoch: 21, Batch: 32,Loss: -1.440,Avg.Loss: -1.082,LR: 4.51E-04]Training epoch 21:  29%|██▊       | 32/112 [00:00<00:01, 52.67it/s, Epoch: 21, Batch: 33,Loss: -1.633,Avg.Loss: -1.098,LR: 4.51E-04]Training epoch 21:  29%|██▉       | 33/112 [00:00<00:01, 52.67it/s, Epoch: 21, Batch: 34,Loss: -1.531,Avg.Loss: -1.111,LR: 4.51E-04]Training epoch 21:  30%|███       | 34/112 [00:00<00:01, 52.67it/s, Epoch: 21, Batch: 35,Loss: -1.700,Avg.Loss: -1.128,LR: 4.51E-04]Training epoch 21:  31%|███▏      | 35/112 [00:00<00:01, 52.67it/s, Epoch: 21, Batch: 36,Loss: -1.589,Avg.Loss: -1.141,LR: 4.51E-04]Training epoch 21:  32%|███▏      | 36/112 [00:00<00:01, 53.04it/s, Epoch: 21, Batch: 36,Loss: -1.589,Avg.Loss: -1.141,LR: 4.51E-04]Training epoch 21:  32%|███▏      | 36/112 [00:00<00:01, 53.04it/s, Epoch: 21, Batch: 37,Loss: -1.762,Avg.Loss: -1.157,LR: 4.51E-04]Training epoch 21:  33%|███▎      | 37/112 [00:00<00:01, 53.04it/s, Epoch: 21, Batch: 38,Loss: -1.496,Avg.Loss: -1.166,LR: 4.51E-04]Training epoch 21:  34%|███▍      | 38/112 [00:00<00:01, 53.04it/s, Epoch: 21, Batch: 39,Loss: -1.609,Avg.Loss: -1.178,LR: 4.51E-04]Training epoch 21:  35%|███▍      | 39/112 [00:00<00:01, 53.04it/s, Epoch: 21, Batch: 40,Loss: -1.896,Avg.Loss: -1.196,LR: 4.51E-04]Training epoch 21:  36%|███▌      | 40/112 [00:00<00:01, 53.04it/s, Epoch: 21, Batch: 41,Loss: -1.802,Avg.Loss: -1.210,LR: 4.51E-04]Training epoch 21:  37%|███▋      | 41/112 [00:00<00:01, 53.04it/s, Epoch: 21, Batch: 42,Loss: -1.591,Avg.Loss: -1.219,LR: 4.51E-04]Training epoch 21:  38%|███▊      | 42/112 [00:00<00:01, 53.24it/s, Epoch: 21, Batch: 42,Loss: -1.591,Avg.Loss: -1.219,LR: 4.51E-04]Training epoch 21:  38%|███▊      | 42/112 [00:00<00:01, 53.24it/s, Epoch: 21, Batch: 43,Loss: -1.528,Avg.Loss: -1.227,LR: 4.50E-04]Training epoch 21:  38%|███▊      | 43/112 [00:00<00:01, 53.24it/s, Epoch: 21, Batch: 44,Loss: -1.539,Avg.Loss: -1.234,LR: 4.50E-04]Training epoch 21:  39%|███▉      | 44/112 [00:00<00:01, 53.24it/s, Epoch: 21, Batch: 45,Loss: -1.724,Avg.Loss: -1.245,LR: 4.50E-04]Training epoch 21:  40%|████      | 45/112 [00:00<00:01, 53.24it/s, Epoch: 21, Batch: 46,Loss: -1.766,Avg.Loss: -1.256,LR: 4.50E-04]Training epoch 21:  41%|████      | 46/112 [00:00<00:01, 53.24it/s, Epoch: 21, Batch: 47,Loss: -1.522,Avg.Loss: -1.262,LR: 4.50E-04]Training epoch 21:  42%|████▏     | 47/112 [00:00<00:01, 53.24it/s, Epoch: 21, Batch: 48,Loss: -2.017,Avg.Loss: -1.277,LR: 4.50E-04]Training epoch 21:  43%|████▎     | 48/112 [00:00<00:01, 53.28it/s, Epoch: 21, Batch: 48,Loss: -2.017,Avg.Loss: -1.277,LR: 4.50E-04]Training epoch 21:  43%|████▎     | 48/112 [00:00<00:01, 53.28it/s, Epoch: 21, Batch: 49,Loss: -1.768,Avg.Loss: -1.287,LR: 4.50E-04]Training epoch 21:  44%|████▍     | 49/112 [00:00<00:01, 53.28it/s, Epoch: 21, Batch: 50,Loss: -1.394,Avg.Loss: -1.290,LR: 4.50E-04]Training epoch 21:  45%|████▍     | 50/112 [00:00<00:01, 53.28it/s, Epoch: 21, Batch: 51,Loss: -1.179,Avg.Loss: -1.287,LR: 4.50E-04]Training epoch 21:  46%|████▌     | 51/112 [00:00<00:01, 53.28it/s, Epoch: 21, Batch: 52,Loss: -2.019,Avg.Loss: -1.301,LR: 4.50E-04]Training epoch 21:  46%|████▋     | 52/112 [00:00<00:01, 53.28it/s, Epoch: 21, Batch: 53,Loss: -1.966,Avg.Loss: -1.314,LR: 4.50E-04]Training epoch 21:  47%|████▋     | 53/112 [00:01<00:01, 53.28it/s, Epoch: 21, Batch: 54,Loss: -1.518,Avg.Loss: -1.318,LR: 4.50E-04]Training epoch 21:  48%|████▊     | 54/112 [00:01<00:01, 53.42it/s, Epoch: 21, Batch: 54,Loss: -1.518,Avg.Loss: -1.318,LR: 4.50E-04]Training epoch 21:  48%|████▊     | 54/112 [00:01<00:01, 53.42it/s, Epoch: 21, Batch: 55,Loss: -1.204,Avg.Loss: -1.316,LR: 4.50E-04]Training epoch 21:  49%|████▉     | 55/112 [00:01<00:01, 53.42it/s, Epoch: 21, Batch: 56,Loss: -1.935,Avg.Loss: -1.327,LR: 4.50E-04]Training epoch 21:  50%|█████     | 56/112 [00:01<00:01, 53.42it/s, Epoch: 21, Batch: 57,Loss: -1.818,Avg.Loss: -1.335,LR: 4.50E-04]Training epoch 21:  51%|█████     | 57/112 [00:01<00:01, 53.42it/s, Epoch: 21, Batch: 58,Loss: -0.926,Avg.Loss: -1.328,LR: 4.50E-04]Training epoch 21:  52%|█████▏    | 58/112 [00:01<00:01, 53.42it/s, Epoch: 21, Batch: 59,Loss: -1.388,Avg.Loss: -1.329,LR: 4.50E-04]Training epoch 21:  53%|█████▎    | 59/112 [00:01<00:00, 53.42it/s, Epoch: 21, Batch: 60,Loss: -1.099,Avg.Loss: -1.325,LR: 4.50E-04]Training epoch 21:  54%|█████▎    | 60/112 [00:01<00:00, 53.47it/s, Epoch: 21, Batch: 60,Loss: -1.099,Avg.Loss: -1.325,LR: 4.50E-04]Training epoch 21:  54%|█████▎    | 60/112 [00:01<00:00, 53.47it/s, Epoch: 21, Batch: 61,Loss: -0.216,Avg.Loss: -1.307,LR: 4.50E-04]Training epoch 21:  54%|█████▍    | 61/112 [00:01<00:00, 53.47it/s, Epoch: 21, Batch: 62,Loss: 0.381,Avg.Loss: -1.280,LR: 4.50E-04] Training epoch 21:  55%|█████▌    | 62/112 [00:01<00:00, 53.47it/s, Epoch: 21, Batch: 63,Loss: 0.439,Avg.Loss: -1.253,LR: 4.50E-04]Training epoch 21:  56%|█████▋    | 63/112 [00:01<00:00, 53.47it/s, Epoch: 21, Batch: 64,Loss: 2.303,Avg.Loss: -1.197,LR: 4.50E-04]Training epoch 21:  57%|█████▋    | 64/112 [00:01<00:00, 53.47it/s, Epoch: 21, Batch: 65,Loss: 1.987,Avg.Loss: -1.148,LR: 4.50E-04]Training epoch 21:  58%|█████▊    | 65/112 [00:01<00:00, 53.47it/s, Epoch: 21, Batch: 66,Loss: 2.898,Avg.Loss: -1.087,LR: 4.49E-04]Training epoch 21:  59%|█████▉    | 66/112 [00:01<00:00, 53.51it/s, Epoch: 21, Batch: 66,Loss: 2.898,Avg.Loss: -1.087,LR: 4.49E-04]Training epoch 21:  59%|█████▉    | 66/112 [00:01<00:00, 53.51it/s, Epoch: 21, Batch: 67,Loss: -0.473,Avg.Loss: -1.078,LR: 4.49E-04]Training epoch 21:  60%|█████▉    | 67/112 [00:01<00:00, 53.51it/s, Epoch: 21, Batch: 68,Loss: 0.041,Avg.Loss: -1.061,LR: 4.49E-04] Training epoch 21:  61%|██████    | 68/112 [00:01<00:00, 53.51it/s, Epoch: 21, Batch: 69,Loss: 0.999,Avg.Loss: -1.031,LR: 4.49E-04]Training epoch 21:  62%|██████▏   | 69/112 [00:01<00:00, 53.51it/s, Epoch: 21, Batch: 70,Loss: -0.208,Avg.Loss: -1.020,LR: 4.49E-04]Training epoch 21:  62%|██████▎   | 70/112 [00:01<00:00, 53.51it/s, Epoch: 21, Batch: 71,Loss: -1.716,Avg.Loss: -1.029,LR: 4.49E-04]Training epoch 21:  63%|██████▎   | 71/112 [00:01<00:00, 53.51it/s, Epoch: 21, Batch: 72,Loss: 0.578,Avg.Loss: -1.007,LR: 4.49E-04] Training epoch 21:  64%|██████▍   | 72/112 [00:01<00:00, 53.40it/s, Epoch: 21, Batch: 72,Loss: 0.578,Avg.Loss: -1.007,LR: 4.49E-04]Training epoch 21:  64%|██████▍   | 72/112 [00:01<00:00, 53.40it/s, Epoch: 21, Batch: 73,Loss: 3.013,Avg.Loss: -0.952,LR: 4.49E-04]Training epoch 21:  65%|██████▌   | 73/112 [00:01<00:00, 53.40it/s, Epoch: 21, Batch: 74,Loss: 3.413,Avg.Loss: -0.893,LR: 4.49E-04]Training epoch 21:  66%|██████▌   | 74/112 [00:01<00:00, 53.40it/s, Epoch: 21, Batch: 75,Loss: -0.459,Avg.Loss: -0.887,LR: 4.49E-04]Training epoch 21:  67%|██████▋   | 75/112 [00:01<00:00, 53.40it/s, Epoch: 21, Batch: 76,Loss: -0.818,Avg.Loss: -0.886,LR: 4.49E-04]Training epoch 21:  68%|██████▊   | 76/112 [00:01<00:00, 53.40it/s, Epoch: 21, Batch: 77,Loss: 0.088,Avg.Loss: -0.874,LR: 4.49E-04] Training epoch 21:  69%|██████▉   | 77/112 [00:01<00:00, 53.40it/s, Epoch: 21, Batch: 78,Loss: -0.193,Avg.Loss: -0.865,LR: 4.49E-04]Training epoch 21:  70%|██████▉   | 78/112 [00:01<00:00, 53.28it/s, Epoch: 21, Batch: 78,Loss: -0.193,Avg.Loss: -0.865,LR: 4.49E-04]Training epoch 21:  70%|██████▉   | 78/112 [00:01<00:00, 53.28it/s, Epoch: 21, Batch: 79,Loss: -1.746,Avg.Loss: -0.876,LR: 4.49E-04]Training epoch 21:  71%|███████   | 79/112 [00:01<00:00, 53.28it/s, Epoch: 21, Batch: 80,Loss: -0.707,Avg.Loss: -0.874,LR: 4.49E-04]Training epoch 21:  71%|███████▏  | 80/112 [00:01<00:00, 53.28it/s, Epoch: 21, Batch: 81,Loss: 1.816,Avg.Loss: -0.841,LR: 4.49E-04] Training epoch 21:  72%|███████▏  | 81/112 [00:01<00:00, 53.28it/s, Epoch: 21, Batch: 82,Loss: 0.637,Avg.Loss: -0.823,LR: 4.49E-04]Training epoch 21:  73%|███████▎  | 82/112 [00:01<00:00, 53.28it/s, Epoch: 21, Batch: 83,Loss: -1.262,Avg.Loss: -0.828,LR: 4.49E-04]Training epoch 21:  74%|███████▍  | 83/112 [00:01<00:00, 53.28it/s, Epoch: 21, Batch: 84,Loss: -0.561,Avg.Loss: -0.825,LR: 4.49E-04]Training epoch 21:  75%|███████▌  | 84/112 [00:01<00:00, 53.24it/s, Epoch: 21, Batch: 84,Loss: -0.561,Avg.Loss: -0.825,LR: 4.49E-04]Training epoch 21:  75%|███████▌  | 84/112 [00:01<00:00, 53.24it/s, Epoch: 21, Batch: 85,Loss: -0.091,Avg.Loss: -0.816,LR: 4.49E-04]Training epoch 21:  76%|███████▌  | 85/112 [00:01<00:00, 53.24it/s, Epoch: 21, Batch: 86,Loss: -0.027,Avg.Loss: -0.807,LR: 4.49E-04]Training epoch 21:  77%|███████▋  | 86/112 [00:01<00:00, 53.24it/s, Epoch: 21, Batch: 87,Loss: -1.429,Avg.Loss: -0.814,LR: 4.49E-04]Training epoch 21:  78%|███████▊  | 87/112 [00:01<00:00, 53.24it/s, Epoch: 21, Batch: 88,Loss: -1.156,Avg.Loss: -0.818,LR: 4.49E-04]Training epoch 21:  79%|███████▊  | 88/112 [00:01<00:00, 53.24it/s, Epoch: 21, Batch: 89,Loss: 0.782,Avg.Loss: -0.800,LR: 4.49E-04] Training epoch 21:  79%|███████▉  | 89/112 [00:01<00:00, 53.24it/s, Epoch: 21, Batch: 90,Loss: 0.221,Avg.Loss: -0.789,LR: 4.48E-04]Training epoch 21:  80%|████████  | 90/112 [00:01<00:00, 53.45it/s, Epoch: 21, Batch: 90,Loss: 0.221,Avg.Loss: -0.789,LR: 4.48E-04]Training epoch 21:  80%|████████  | 90/112 [00:01<00:00, 53.45it/s, Epoch: 21, Batch: 91,Loss: -1.439,Avg.Loss: -0.796,LR: 4.48E-04]Training epoch 21:  81%|████████▏ | 91/112 [00:01<00:00, 53.45it/s, Epoch: 21, Batch: 92,Loss: -0.797,Avg.Loss: -0.796,LR: 4.48E-04]Training epoch 21:  82%|████████▏ | 92/112 [00:01<00:00, 53.45it/s, Epoch: 21, Batch: 93,Loss: 0.351,Avg.Loss: -0.784,LR: 4.48E-04] Training epoch 21:  83%|████████▎ | 93/112 [00:01<00:00, 53.45it/s, Epoch: 21, Batch: 94,Loss: -0.214,Avg.Loss: -0.778,LR: 4.48E-04]Training epoch 21:  84%|████████▍ | 94/112 [00:01<00:00, 53.45it/s, Epoch: 21, Batch: 95,Loss: -1.376,Avg.Loss: -0.784,LR: 4.48E-04]Training epoch 21:  85%|████████▍ | 95/112 [00:01<00:00, 53.45it/s, Epoch: 21, Batch: 96,Loss: -0.741,Avg.Loss: -0.783,LR: 4.48E-04]Training epoch 21:  86%|████████▌ | 96/112 [00:01<00:00, 53.43it/s, Epoch: 21, Batch: 96,Loss: -0.741,Avg.Loss: -0.783,LR: 4.48E-04]Training epoch 21:  86%|████████▌ | 96/112 [00:01<00:00, 53.43it/s, Epoch: 21, Batch: 97,Loss: 0.539,Avg.Loss: -0.770,LR: 4.48E-04] Training epoch 21:  87%|████████▋ | 97/112 [00:01<00:00, 53.43it/s, Epoch: 21, Batch: 98,Loss: -0.075,Avg.Loss: -0.763,LR: 4.48E-04]Training epoch 21:  88%|████████▊ | 98/112 [00:01<00:00, 53.43it/s, Epoch: 21, Batch: 99,Loss: -1.349,Avg.Loss: -0.769,LR: 4.48E-04]Training epoch 21:  88%|████████▊ | 99/112 [00:01<00:00, 53.43it/s, Epoch: 21, Batch: 100,Loss: -1.141,Avg.Loss: -0.772,LR: 4.48E-04]Training epoch 21:  89%|████████▉ | 100/112 [00:01<00:00, 53.43it/s, Epoch: 21, Batch: 101,Loss: -0.529,Avg.Loss: -0.770,LR: 4.48E-04]Training epoch 21:  90%|█████████ | 101/112 [00:01<00:00, 53.43it/s, Epoch: 21, Batch: 102,Loss: -0.028,Avg.Loss: -0.763,LR: 4.48E-04]Training epoch 21:  91%|█████████ | 102/112 [00:01<00:00, 53.44it/s, Epoch: 21, Batch: 102,Loss: -0.028,Avg.Loss: -0.763,LR: 4.48E-04]Training epoch 21:  91%|█████████ | 102/112 [00:01<00:00, 53.44it/s, Epoch: 21, Batch: 103,Loss: -1.238,Avg.Loss: -0.767,LR: 4.48E-04]Training epoch 21:  92%|█████████▏| 103/112 [00:01<00:00, 53.44it/s, Epoch: 21, Batch: 104,Loss: -0.924,Avg.Loss: -0.769,LR: 4.48E-04]Training epoch 21:  93%|█████████▎| 104/112 [00:01<00:00, 53.44it/s, Epoch: 21, Batch: 105,Loss: 0.049,Avg.Loss: -0.761,LR: 4.48E-04] Training epoch 21:  94%|█████████▍| 105/112 [00:01<00:00, 53.44it/s, Epoch: 21, Batch: 106,Loss: -0.313,Avg.Loss: -0.757,LR: 4.48E-04]Training epoch 21:  95%|█████████▍| 106/112 [00:01<00:00, 53.44it/s, Epoch: 21, Batch: 107,Loss: -1.050,Avg.Loss: -0.760,LR: 4.48E-04]Training epoch 21:  96%|█████████▌| 107/112 [00:02<00:00, 53.44it/s, Epoch: 21, Batch: 108,Loss: -1.032,Avg.Loss: -0.762,LR: 4.48E-04]Training epoch 21:  96%|█████████▋| 108/112 [00:02<00:00, 53.66it/s, Epoch: 21, Batch: 108,Loss: -1.032,Avg.Loss: -0.762,LR: 4.48E-04]Training epoch 21:  96%|█████████▋| 108/112 [00:02<00:00, 53.66it/s, Epoch: 21, Batch: 109,Loss: -0.198,Avg.Loss: -0.757,LR: 4.48E-04]Training epoch 21:  97%|█████████▋| 109/112 [00:02<00:00, 53.66it/s, Epoch: 21, Batch: 110,Loss: -0.916,Avg.Loss: -0.758,LR: 4.48E-04]Training epoch 21:  98%|█████████▊| 110/112 [00:02<00:00, 53.66it/s, Epoch: 21, Batch: 111,Loss: -1.388,Avg.Loss: -0.764,LR: 4.48E-04]Training epoch 21:  99%|█████████▉| 111/112 [00:02<00:00, 53.66it/s, Epoch: 21, Batch: 112,Loss: -0.918,Avg.Loss: -0.765,LR: 4.48E-04]Training epoch 21: 100%|██████████| 112/112 [00:02<00:00, 53.50it/s, Epoch: 21, Batch: 112,Loss: -0.918,Avg.Loss: -0.765,LR: 4.48E-04]
Training epoch 22:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 22:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 22, Batch: 1,Loss: 0.104,Avg.Loss: 0.104,LR: 4.47E-04]Training epoch 22:   1%|          | 1/112 [00:00<00:04, 26.48it/s, Epoch: 22, Batch: 2,Loss: -0.700,Avg.Loss: -0.298,LR: 4.47E-04]Training epoch 22:   2%|▏         | 2/112 [00:00<00:03, 34.94it/s, Epoch: 22, Batch: 3,Loss: -1.499,Avg.Loss: -0.698,LR: 4.47E-04]Training epoch 22:   3%|▎         | 3/112 [00:00<00:02, 40.77it/s, Epoch: 22, Batch: 4,Loss: -0.962,Avg.Loss: -0.764,LR: 4.47E-04]Training epoch 22:   4%|▎         | 4/112 [00:00<00:02, 44.69it/s, Epoch: 22, Batch: 5,Loss: -0.319,Avg.Loss: -0.675,LR: 4.47E-04]Training epoch 22:   4%|▍         | 5/112 [00:00<00:02, 48.35it/s, Epoch: 22, Batch: 6,Loss: -0.626,Avg.Loss: -0.667,LR: 4.47E-04]Training epoch 22:   5%|▌         | 6/112 [00:00<00:01, 57.93it/s, Epoch: 22, Batch: 6,Loss: -0.626,Avg.Loss: -0.667,LR: 4.47E-04]Training epoch 22:   5%|▌         | 6/112 [00:00<00:01, 57.93it/s, Epoch: 22, Batch: 7,Loss: -1.570,Avg.Loss: -0.796,LR: 4.47E-04]Training epoch 22:   6%|▋         | 7/112 [00:00<00:01, 57.93it/s, Epoch: 22, Batch: 8,Loss: -1.200,Avg.Loss: -0.847,LR: 4.47E-04]Training epoch 22:   7%|▋         | 8/112 [00:00<00:01, 57.93it/s, Epoch: 22, Batch: 9,Loss: -0.674,Avg.Loss: -0.827,LR: 4.47E-04]Training epoch 22:   8%|▊         | 9/112 [00:00<00:01, 57.93it/s, Epoch: 22, Batch: 10,Loss: -0.356,Avg.Loss: -0.780,LR: 4.47E-04]Training epoch 22:   9%|▉         | 10/112 [00:00<00:01, 57.93it/s, Epoch: 22, Batch: 11,Loss: -1.095,Avg.Loss: -0.809,LR: 4.47E-04]Training epoch 22:  10%|▉         | 11/112 [00:00<00:01, 57.93it/s, Epoch: 22, Batch: 12,Loss: -1.616,Avg.Loss: -0.876,LR: 4.47E-04]Training epoch 22:  11%|█         | 12/112 [00:00<00:01, 58.62it/s, Epoch: 22, Batch: 12,Loss: -1.616,Avg.Loss: -0.876,LR: 4.47E-04]Training epoch 22:  11%|█         | 12/112 [00:00<00:01, 58.62it/s, Epoch: 22, Batch: 13,Loss: -0.870,Avg.Loss: -0.876,LR: 4.47E-04]Training epoch 22:  12%|█▏        | 13/112 [00:00<00:01, 58.62it/s, Epoch: 22, Batch: 14,Loss: -1.053,Avg.Loss: -0.888,LR: 4.47E-04]Training epoch 22:  12%|█▎        | 14/112 [00:00<00:01, 58.62it/s, Epoch: 22, Batch: 15,Loss: -1.164,Avg.Loss: -0.907,LR: 4.47E-04]Training epoch 22:  13%|█▎        | 15/112 [00:00<00:01, 58.62it/s, Epoch: 22, Batch: 16,Loss: -1.080,Avg.Loss: -0.917,LR: 4.47E-04]Training epoch 22:  14%|█▍        | 16/112 [00:00<00:01, 58.62it/s, Epoch: 22, Batch: 17,Loss: -0.299,Avg.Loss: -0.881,LR: 4.47E-04]Training epoch 22:  15%|█▌        | 17/112 [00:00<00:01, 58.62it/s, Epoch: 22, Batch: 18,Loss: -0.474,Avg.Loss: -0.858,LR: 4.47E-04]Training epoch 22:  16%|█▌        | 18/112 [00:00<00:01, 55.82it/s, Epoch: 22, Batch: 18,Loss: -0.474,Avg.Loss: -0.858,LR: 4.47E-04]Training epoch 22:  16%|█▌        | 18/112 [00:00<00:01, 55.82it/s, Epoch: 22, Batch: 19,Loss: -1.225,Avg.Loss: -0.878,LR: 4.47E-04]Training epoch 22:  17%|█▋        | 19/112 [00:00<00:01, 55.82it/s, Epoch: 22, Batch: 20,Loss: -1.233,Avg.Loss: -0.895,LR: 4.47E-04]Training epoch 22:  18%|█▊        | 20/112 [00:00<00:01, 55.82it/s, Epoch: 22, Batch: 21,Loss: -0.758,Avg.Loss: -0.889,LR: 4.47E-04]Training epoch 22:  19%|█▉        | 21/112 [00:00<00:01, 55.82it/s, Epoch: 22, Batch: 22,Loss: -0.821,Avg.Loss: -0.886,LR: 4.47E-04]Training epoch 22:  20%|█▉        | 22/112 [00:00<00:01, 55.82it/s, Epoch: 22, Batch: 23,Loss: -1.319,Avg.Loss: -0.905,LR: 4.47E-04]Training epoch 22:  21%|██        | 23/112 [00:00<00:01, 55.82it/s, Epoch: 22, Batch: 24,Loss: -1.020,Avg.Loss: -0.909,LR: 4.47E-04]Training epoch 22:  21%|██▏       | 24/112 [00:00<00:01, 54.00it/s, Epoch: 22, Batch: 24,Loss: -1.020,Avg.Loss: -0.909,LR: 4.47E-04]Training epoch 22:  21%|██▏       | 24/112 [00:00<00:01, 54.00it/s, Epoch: 22, Batch: 25,Loss: -0.525,Avg.Loss: -0.894,LR: 4.46E-04]Training epoch 22:  22%|██▏       | 25/112 [00:00<00:01, 54.00it/s, Epoch: 22, Batch: 26,Loss: -0.557,Avg.Loss: -0.881,LR: 4.46E-04]Training epoch 22:  23%|██▎       | 26/112 [00:00<00:01, 54.00it/s, Epoch: 22, Batch: 27,Loss: -1.329,Avg.Loss: -0.898,LR: 4.46E-04]Training epoch 22:  24%|██▍       | 27/112 [00:00<00:01, 54.00it/s, Epoch: 22, Batch: 28,Loss: -1.321,Avg.Loss: -0.913,LR: 4.46E-04]Training epoch 22:  25%|██▌       | 28/112 [00:00<00:01, 54.00it/s, Epoch: 22, Batch: 29,Loss: -0.925,Avg.Loss: -0.913,LR: 4.46E-04]Training epoch 22:  26%|██▌       | 29/112 [00:00<00:01, 54.00it/s, Epoch: 22, Batch: 30,Loss: -0.433,Avg.Loss: -0.897,LR: 4.46E-04]Training epoch 22:  27%|██▋       | 30/112 [00:00<00:01, 53.79it/s, Epoch: 22, Batch: 30,Loss: -0.433,Avg.Loss: -0.897,LR: 4.46E-04]Training epoch 22:  27%|██▋       | 30/112 [00:00<00:01, 53.79it/s, Epoch: 22, Batch: 31,Loss: -1.302,Avg.Loss: -0.910,LR: 4.46E-04]Training epoch 22:  28%|██▊       | 31/112 [00:00<00:01, 53.79it/s, Epoch: 22, Batch: 32,Loss: -1.503,Avg.Loss: -0.929,LR: 4.46E-04]Training epoch 22:  29%|██▊       | 32/112 [00:00<00:01, 53.79it/s, Epoch: 22, Batch: 33,Loss: -1.721,Avg.Loss: -0.953,LR: 4.46E-04]Training epoch 22:  29%|██▉       | 33/112 [00:00<00:01, 53.79it/s, Epoch: 22, Batch: 34,Loss: -1.301,Avg.Loss: -0.963,LR: 4.46E-04]Training epoch 22:  30%|███       | 34/112 [00:00<00:01, 53.79it/s, Epoch: 22, Batch: 35,Loss: -1.211,Avg.Loss: -0.970,LR: 4.46E-04]Training epoch 22:  31%|███▏      | 35/112 [00:00<00:01, 53.79it/s, Epoch: 22, Batch: 36,Loss: -1.428,Avg.Loss: -0.983,LR: 4.46E-04]Training epoch 22:  32%|███▏      | 36/112 [00:00<00:01, 53.60it/s, Epoch: 22, Batch: 36,Loss: -1.428,Avg.Loss: -0.983,LR: 4.46E-04]Training epoch 22:  32%|███▏      | 36/112 [00:00<00:01, 53.60it/s, Epoch: 22, Batch: 37,Loss: -1.594,Avg.Loss: -0.999,LR: 4.46E-04]Training epoch 22:  33%|███▎      | 37/112 [00:00<00:01, 53.60it/s, Epoch: 22, Batch: 38,Loss: -1.370,Avg.Loss: -1.009,LR: 4.46E-04]Training epoch 22:  34%|███▍      | 38/112 [00:00<00:01, 53.60it/s, Epoch: 22, Batch: 39,Loss: -1.135,Avg.Loss: -1.012,LR: 4.46E-04]Training epoch 22:  35%|███▍      | 39/112 [00:00<00:01, 53.60it/s, Epoch: 22, Batch: 40,Loss: -1.571,Avg.Loss: -1.026,LR: 4.46E-04]Training epoch 22:  36%|███▌      | 40/112 [00:00<00:01, 53.60it/s, Epoch: 22, Batch: 41,Loss: -1.900,Avg.Loss: -1.048,LR: 4.46E-04]Training epoch 22:  37%|███▋      | 41/112 [00:00<00:01, 53.60it/s, Epoch: 22, Batch: 42,Loss: -1.150,Avg.Loss: -1.050,LR: 4.46E-04]Training epoch 22:  38%|███▊      | 42/112 [00:00<00:01, 53.48it/s, Epoch: 22, Batch: 42,Loss: -1.150,Avg.Loss: -1.050,LR: 4.46E-04]Training epoch 22:  38%|███▊      | 42/112 [00:00<00:01, 53.48it/s, Epoch: 22, Batch: 43,Loss: -0.890,Avg.Loss: -1.046,LR: 4.46E-04]Training epoch 22:  38%|███▊      | 43/112 [00:00<00:01, 53.48it/s, Epoch: 22, Batch: 44,Loss: -1.317,Avg.Loss: -1.052,LR: 4.46E-04]Training epoch 22:  39%|███▉      | 44/112 [00:00<00:01, 53.48it/s, Epoch: 22, Batch: 45,Loss: -1.713,Avg.Loss: -1.067,LR: 4.46E-04]Training epoch 22:  40%|████      | 45/112 [00:00<00:01, 53.48it/s, Epoch: 22, Batch: 46,Loss: -1.379,Avg.Loss: -1.074,LR: 4.46E-04]Training epoch 22:  41%|████      | 46/112 [00:00<00:01, 53.48it/s, Epoch: 22, Batch: 47,Loss: -1.198,Avg.Loss: -1.077,LR: 4.46E-04]Training epoch 22:  42%|████▏     | 47/112 [00:00<00:01, 53.48it/s, Epoch: 22, Batch: 48,Loss: -0.935,Avg.Loss: -1.074,LR: 4.45E-04]Training epoch 22:  43%|████▎     | 48/112 [00:00<00:01, 53.32it/s, Epoch: 22, Batch: 48,Loss: -0.935,Avg.Loss: -1.074,LR: 4.45E-04]Training epoch 22:  43%|████▎     | 48/112 [00:00<00:01, 53.32it/s, Epoch: 22, Batch: 49,Loss: -1.192,Avg.Loss: -1.076,LR: 4.45E-04]Training epoch 22:  44%|████▍     | 49/112 [00:00<00:01, 53.32it/s, Epoch: 22, Batch: 50,Loss: -1.687,Avg.Loss: -1.088,LR: 4.45E-04]Training epoch 22:  45%|████▍     | 50/112 [00:00<00:01, 53.32it/s, Epoch: 22, Batch: 51,Loss: -1.870,Avg.Loss: -1.104,LR: 4.45E-04]Training epoch 22:  46%|████▌     | 51/112 [00:00<00:01, 53.32it/s, Epoch: 22, Batch: 52,Loss: -1.394,Avg.Loss: -1.109,LR: 4.45E-04]Training epoch 22:  46%|████▋     | 52/112 [00:00<00:01, 53.32it/s, Epoch: 22, Batch: 53,Loss: -1.062,Avg.Loss: -1.108,LR: 4.45E-04]Training epoch 22:  47%|████▋     | 53/112 [00:01<00:01, 53.32it/s, Epoch: 22, Batch: 54,Loss: -1.864,Avg.Loss: -1.122,LR: 4.45E-04]Training epoch 22:  48%|████▊     | 54/112 [00:01<00:01, 51.94it/s, Epoch: 22, Batch: 54,Loss: -1.864,Avg.Loss: -1.122,LR: 4.45E-04]Training epoch 22:  48%|████▊     | 54/112 [00:01<00:01, 51.94it/s, Epoch: 22, Batch: 55,Loss: -2.027,Avg.Loss: -1.139,LR: 4.45E-04]Training epoch 22:  49%|████▉     | 55/112 [00:01<00:01, 51.94it/s, Epoch: 22, Batch: 56,Loss: -1.838,Avg.Loss: -1.151,LR: 4.45E-04]Training epoch 22:  50%|█████     | 56/112 [00:01<00:01, 51.94it/s, Epoch: 22, Batch: 57,Loss: -0.972,Avg.Loss: -1.148,LR: 4.45E-04]Training epoch 22:  51%|█████     | 57/112 [00:01<00:01, 51.94it/s, Epoch: 22, Batch: 58,Loss: -1.373,Avg.Loss: -1.152,LR: 4.45E-04]Training epoch 22:  52%|█████▏    | 58/112 [00:01<00:01, 51.94it/s, Epoch: 22, Batch: 59,Loss: -1.154,Avg.Loss: -1.152,LR: 4.45E-04]Training epoch 22:  53%|█████▎    | 59/112 [00:01<00:01, 51.94it/s, Epoch: 22, Batch: 60,Loss: -1.345,Avg.Loss: -1.155,LR: 4.45E-04]Training epoch 22:  54%|█████▎    | 60/112 [00:01<00:00, 52.18it/s, Epoch: 22, Batch: 60,Loss: -1.345,Avg.Loss: -1.155,LR: 4.45E-04]Training epoch 22:  54%|█████▎    | 60/112 [00:01<00:00, 52.18it/s, Epoch: 22, Batch: 61,Loss: -1.560,Avg.Loss: -1.162,LR: 4.45E-04]Training epoch 22:  54%|█████▍    | 61/112 [00:01<00:00, 52.18it/s, Epoch: 22, Batch: 62,Loss: -1.437,Avg.Loss: -1.166,LR: 4.45E-04]Training epoch 22:  55%|█████▌    | 62/112 [00:01<00:00, 52.18it/s, Epoch: 22, Batch: 63,Loss: -1.296,Avg.Loss: -1.168,LR: 4.45E-04]Training epoch 22:  56%|█████▋    | 63/112 [00:01<00:00, 52.18it/s, Epoch: 22, Batch: 64,Loss: -1.611,Avg.Loss: -1.175,LR: 4.45E-04]Training epoch 22:  57%|█████▋    | 64/112 [00:01<00:00, 52.18it/s, Epoch: 22, Batch: 65,Loss: -1.527,Avg.Loss: -1.181,LR: 4.45E-04]Training epoch 22:  58%|█████▊    | 65/112 [00:01<00:00, 52.18it/s, Epoch: 22, Batch: 66,Loss: -1.264,Avg.Loss: -1.182,LR: 4.45E-04]Training epoch 22:  59%|█████▉    | 66/112 [00:01<00:00, 52.57it/s, Epoch: 22, Batch: 66,Loss: -1.264,Avg.Loss: -1.182,LR: 4.45E-04]Training epoch 22:  59%|█████▉    | 66/112 [00:01<00:00, 52.57it/s, Epoch: 22, Batch: 67,Loss: -0.826,Avg.Loss: -1.177,LR: 4.45E-04]Training epoch 22:  60%|█████▉    | 67/112 [00:01<00:00, 52.57it/s, Epoch: 22, Batch: 68,Loss: -1.836,Avg.Loss: -1.186,LR: 4.45E-04]Training epoch 22:  61%|██████    | 68/112 [00:01<00:00, 52.57it/s, Epoch: 22, Batch: 69,Loss: -1.415,Avg.Loss: -1.190,LR: 4.45E-04]Training epoch 22:  62%|██████▏   | 69/112 [00:01<00:00, 52.57it/s, Epoch: 22, Batch: 70,Loss: -1.605,Avg.Loss: -1.196,LR: 4.44E-04]Training epoch 22:  62%|██████▎   | 70/112 [00:01<00:00, 52.57it/s, Epoch: 22, Batch: 71,Loss: -1.581,Avg.Loss: -1.201,LR: 4.44E-04]Training epoch 22:  63%|██████▎   | 71/112 [00:01<00:00, 52.57it/s, Epoch: 22, Batch: 72,Loss: -1.609,Avg.Loss: -1.207,LR: 4.44E-04]Training epoch 22:  64%|██████▍   | 72/112 [00:01<00:00, 52.72it/s, Epoch: 22, Batch: 72,Loss: -1.609,Avg.Loss: -1.207,LR: 4.44E-04]Training epoch 22:  64%|██████▍   | 72/112 [00:01<00:00, 52.72it/s, Epoch: 22, Batch: 73,Loss: -1.504,Avg.Loss: -1.211,LR: 4.44E-04]Training epoch 22:  65%|██████▌   | 73/112 [00:01<00:00, 52.72it/s, Epoch: 22, Batch: 74,Loss: -1.664,Avg.Loss: -1.217,LR: 4.44E-04]Training epoch 22:  66%|██████▌   | 74/112 [00:01<00:00, 52.72it/s, Epoch: 22, Batch: 75,Loss: -0.298,Avg.Loss: -1.205,LR: 4.44E-04]Training epoch 22:  67%|██████▋   | 75/112 [00:01<00:00, 52.72it/s, Epoch: 22, Batch: 76,Loss: -0.655,Avg.Loss: -1.197,LR: 4.44E-04]Training epoch 22:  68%|██████▊   | 76/112 [00:01<00:00, 52.72it/s, Epoch: 22, Batch: 77,Loss: -1.475,Avg.Loss: -1.201,LR: 4.44E-04]Training epoch 22:  69%|██████▉   | 77/112 [00:01<00:00, 52.72it/s, Epoch: 22, Batch: 78,Loss: -1.813,Avg.Loss: -1.209,LR: 4.44E-04]Training epoch 22:  70%|██████▉   | 78/112 [00:01<00:00, 52.87it/s, Epoch: 22, Batch: 78,Loss: -1.813,Avg.Loss: -1.209,LR: 4.44E-04]Training epoch 22:  70%|██████▉   | 78/112 [00:01<00:00, 52.87it/s, Epoch: 22, Batch: 79,Loss: -0.753,Avg.Loss: -1.203,LR: 4.44E-04]Training epoch 22:  71%|███████   | 79/112 [00:01<00:00, 52.87it/s, Epoch: 22, Batch: 80,Loss: -0.582,Avg.Loss: -1.195,LR: 4.44E-04]Training epoch 22:  71%|███████▏  | 80/112 [00:01<00:00, 52.87it/s, Epoch: 22, Batch: 81,Loss: -0.998,Avg.Loss: -1.193,LR: 4.44E-04]Training epoch 22:  72%|███████▏  | 81/112 [00:01<00:00, 52.87it/s, Epoch: 22, Batch: 82,Loss: -1.669,Avg.Loss: -1.199,LR: 4.44E-04]Training epoch 22:  73%|███████▎  | 82/112 [00:01<00:00, 52.87it/s, Epoch: 22, Batch: 83,Loss: -1.161,Avg.Loss: -1.198,LR: 4.44E-04]Training epoch 22:  74%|███████▍  | 83/112 [00:01<00:00, 52.87it/s, Epoch: 22, Batch: 84,Loss: -0.889,Avg.Loss: -1.195,LR: 4.44E-04]Training epoch 22:  75%|███████▌  | 84/112 [00:01<00:00, 53.15it/s, Epoch: 22, Batch: 84,Loss: -0.889,Avg.Loss: -1.195,LR: 4.44E-04]Training epoch 22:  75%|███████▌  | 84/112 [00:01<00:00, 53.15it/s, Epoch: 22, Batch: 85,Loss: -0.368,Avg.Loss: -1.185,LR: 4.44E-04]Training epoch 22:  76%|███████▌  | 85/112 [00:01<00:00, 53.15it/s, Epoch: 22, Batch: 86,Loss: -1.316,Avg.Loss: -1.186,LR: 4.44E-04]Training epoch 22:  77%|███████▋  | 86/112 [00:01<00:00, 53.15it/s, Epoch: 22, Batch: 87,Loss: -1.639,Avg.Loss: -1.192,LR: 4.44E-04]Training epoch 22:  78%|███████▊  | 87/112 [00:01<00:00, 53.15it/s, Epoch: 22, Batch: 88,Loss: -1.425,Avg.Loss: -1.194,LR: 4.44E-04]Training epoch 22:  79%|███████▊  | 88/112 [00:01<00:00, 53.15it/s, Epoch: 22, Batch: 89,Loss: -0.249,Avg.Loss: -1.184,LR: 4.44E-04]Training epoch 22:  79%|███████▉  | 89/112 [00:01<00:00, 53.15it/s, Epoch: 22, Batch: 90,Loss: -0.919,Avg.Loss: -1.181,LR: 4.44E-04]Training epoch 22:  80%|████████  | 90/112 [00:01<00:00, 53.38it/s, Epoch: 22, Batch: 90,Loss: -0.919,Avg.Loss: -1.181,LR: 4.44E-04]Training epoch 22:  80%|████████  | 90/112 [00:01<00:00, 53.38it/s, Epoch: 22, Batch: 91,Loss: -0.167,Avg.Loss: -1.169,LR: 4.44E-04]Training epoch 22:  81%|████████▏ | 91/112 [00:01<00:00, 53.38it/s, Epoch: 22, Batch: 92,Loss: 1.375,Avg.Loss: -1.142,LR: 4.44E-04] Training epoch 22:  82%|████████▏ | 92/112 [00:01<00:00, 53.38it/s, Epoch: 22, Batch: 93,Loss: -0.854,Avg.Loss: -1.139,LR: 4.43E-04]Training epoch 22:  83%|████████▎ | 93/112 [00:01<00:00, 53.38it/s, Epoch: 22, Batch: 94,Loss: -0.969,Avg.Loss: -1.137,LR: 4.43E-04]Training epoch 22:  84%|████████▍ | 94/112 [00:01<00:00, 53.38it/s, Epoch: 22, Batch: 95,Loss: -1.111,Avg.Loss: -1.137,LR: 4.43E-04]Training epoch 22:  85%|████████▍ | 95/112 [00:01<00:00, 53.38it/s, Epoch: 22, Batch: 96,Loss: -1.384,Avg.Loss: -1.139,LR: 4.43E-04]Training epoch 22:  86%|████████▌ | 96/112 [00:01<00:00, 53.62it/s, Epoch: 22, Batch: 96,Loss: -1.384,Avg.Loss: -1.139,LR: 4.43E-04]Training epoch 22:  86%|████████▌ | 96/112 [00:01<00:00, 53.62it/s, Epoch: 22, Batch: 97,Loss: -1.243,Avg.Loss: -1.140,LR: 4.43E-04]Training epoch 22:  87%|████████▋ | 97/112 [00:01<00:00, 53.62it/s, Epoch: 22, Batch: 98,Loss: -0.867,Avg.Loss: -1.137,LR: 4.43E-04]Training epoch 22:  88%|████████▊ | 98/112 [00:01<00:00, 53.62it/s, Epoch: 22, Batch: 99,Loss: -1.262,Avg.Loss: -1.139,LR: 4.43E-04]Training epoch 22:  88%|████████▊ | 99/112 [00:01<00:00, 53.62it/s, Epoch: 22, Batch: 100,Loss: -1.134,Avg.Loss: -1.139,LR: 4.43E-04]Training epoch 22:  89%|████████▉ | 100/112 [00:01<00:00, 53.62it/s, Epoch: 22, Batch: 101,Loss: -1.026,Avg.Loss: -1.138,LR: 4.43E-04]Training epoch 22:  90%|█████████ | 101/112 [00:01<00:00, 53.62it/s, Epoch: 22, Batch: 102,Loss: -1.967,Avg.Loss: -1.146,LR: 4.43E-04]Training epoch 22:  91%|█████████ | 102/112 [00:01<00:00, 53.72it/s, Epoch: 22, Batch: 102,Loss: -1.967,Avg.Loss: -1.146,LR: 4.43E-04]Training epoch 22:  91%|█████████ | 102/112 [00:01<00:00, 53.72it/s, Epoch: 22, Batch: 103,Loss: -0.856,Avg.Loss: -1.143,LR: 4.43E-04]Training epoch 22:  92%|█████████▏| 103/112 [00:01<00:00, 53.72it/s, Epoch: 22, Batch: 104,Loss: 0.105,Avg.Loss: -1.131,LR: 4.43E-04] Training epoch 22:  93%|█████████▎| 104/112 [00:01<00:00, 53.72it/s, Epoch: 22, Batch: 105,Loss: -1.036,Avg.Loss: -1.130,LR: 4.43E-04]Training epoch 22:  94%|█████████▍| 105/112 [00:01<00:00, 53.72it/s, Epoch: 22, Batch: 106,Loss: -1.750,Avg.Loss: -1.136,LR: 4.43E-04]Training epoch 22:  95%|█████████▍| 106/112 [00:01<00:00, 53.72it/s, Epoch: 22, Batch: 107,Loss: -1.642,Avg.Loss: -1.141,LR: 4.43E-04]Training epoch 22:  96%|█████████▌| 107/112 [00:02<00:00, 53.72it/s, Epoch: 22, Batch: 108,Loss: -1.773,Avg.Loss: -1.146,LR: 4.43E-04]Training epoch 22:  96%|█████████▋| 108/112 [00:02<00:00, 53.82it/s, Epoch: 22, Batch: 108,Loss: -1.773,Avg.Loss: -1.146,LR: 4.43E-04]Training epoch 22:  96%|█████████▋| 108/112 [00:02<00:00, 53.82it/s, Epoch: 22, Batch: 109,Loss: -1.393,Avg.Loss: -1.149,LR: 4.43E-04]Training epoch 22:  97%|█████████▋| 109/112 [00:02<00:00, 53.82it/s, Epoch: 22, Batch: 110,Loss: -1.048,Avg.Loss: -1.148,LR: 4.43E-04]Training epoch 22:  98%|█████████▊| 110/112 [00:02<00:00, 53.82it/s, Epoch: 22, Batch: 111,Loss: -1.429,Avg.Loss: -1.150,LR: 4.43E-04]Training epoch 22:  99%|█████████▉| 111/112 [00:02<00:00, 53.82it/s, Epoch: 22, Batch: 112,Loss: -0.045,Avg.Loss: -1.140,LR: 4.43E-04]Training epoch 22: 100%|██████████| 112/112 [00:02<00:00, 53.64it/s, Epoch: 22, Batch: 112,Loss: -0.045,Avg.Loss: -1.140,LR: 4.43E-04]
Training epoch 23:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 23:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 23, Batch: 1,Loss: -0.247,Avg.Loss: -0.247,LR: 4.43E-04]Training epoch 23:   1%|          | 1/112 [00:00<00:04, 26.41it/s, Epoch: 23, Batch: 2,Loss: -0.846,Avg.Loss: -0.547,LR: 4.43E-04]Training epoch 23:   2%|▏         | 2/112 [00:00<00:03, 34.39it/s, Epoch: 23, Batch: 3,Loss: -1.003,Avg.Loss: -0.699,LR: 4.42E-04]Training epoch 23:   3%|▎         | 3/112 [00:00<00:02, 40.35it/s, Epoch: 23, Batch: 4,Loss: -0.707,Avg.Loss: -0.701,LR: 4.42E-04]Training epoch 23:   4%|▎         | 4/112 [00:00<00:02, 44.72it/s, Epoch: 23, Batch: 5,Loss: -1.958,Avg.Loss: -0.952,LR: 4.42E-04]Training epoch 23:   4%|▍         | 5/112 [00:00<00:02, 48.73it/s, Epoch: 23, Batch: 6,Loss: -0.751,Avg.Loss: -0.919,LR: 4.42E-04]Training epoch 23:   5%|▌         | 6/112 [00:00<00:01, 58.40it/s, Epoch: 23, Batch: 6,Loss: -0.751,Avg.Loss: -0.919,LR: 4.42E-04]Training epoch 23:   5%|▌         | 6/112 [00:00<00:01, 58.40it/s, Epoch: 23, Batch: 7,Loss: 0.231,Avg.Loss: -0.754,LR: 4.42E-04] Training epoch 23:   6%|▋         | 7/112 [00:00<00:01, 58.40it/s, Epoch: 23, Batch: 8,Loss: 0.160,Avg.Loss: -0.640,LR: 4.42E-04]Training epoch 23:   7%|▋         | 8/112 [00:00<00:01, 58.40it/s, Epoch: 23, Batch: 9,Loss: -0.984,Avg.Loss: -0.678,LR: 4.42E-04]Training epoch 23:   8%|▊         | 9/112 [00:00<00:01, 58.40it/s, Epoch: 23, Batch: 10,Loss: -1.207,Avg.Loss: -0.731,LR: 4.42E-04]Training epoch 23:   9%|▉         | 10/112 [00:00<00:01, 58.40it/s, Epoch: 23, Batch: 11,Loss: -1.388,Avg.Loss: -0.791,LR: 4.42E-04]Training epoch 23:  10%|▉         | 11/112 [00:00<00:01, 58.40it/s, Epoch: 23, Batch: 12,Loss: -1.634,Avg.Loss: -0.861,LR: 4.42E-04]Training epoch 23:  11%|█         | 12/112 [00:00<00:01, 58.40it/s, Epoch: 23, Batch: 13,Loss: -1.737,Avg.Loss: -0.929,LR: 4.42E-04]Training epoch 23:  12%|█▏        | 13/112 [00:00<00:01, 59.38it/s, Epoch: 23, Batch: 13,Loss: -1.737,Avg.Loss: -0.929,LR: 4.42E-04]Training epoch 23:  12%|█▏        | 13/112 [00:00<00:01, 59.38it/s, Epoch: 23, Batch: 14,Loss: -1.656,Avg.Loss: -0.981,LR: 4.42E-04]Training epoch 23:  12%|█▎        | 14/112 [00:00<00:01, 59.38it/s, Epoch: 23, Batch: 15,Loss: -1.729,Avg.Loss: -1.030,LR: 4.42E-04]Training epoch 23:  13%|█▎        | 15/112 [00:00<00:01, 59.38it/s, Epoch: 23, Batch: 16,Loss: -1.595,Avg.Loss: -1.066,LR: 4.42E-04]Training epoch 23:  14%|█▍        | 16/112 [00:00<00:01, 59.38it/s, Epoch: 23, Batch: 17,Loss: -1.761,Avg.Loss: -1.107,LR: 4.42E-04]Training epoch 23:  15%|█▌        | 17/112 [00:00<00:01, 59.38it/s, Epoch: 23, Batch: 18,Loss: -1.439,Avg.Loss: -1.125,LR: 4.42E-04]Training epoch 23:  16%|█▌        | 18/112 [00:00<00:01, 59.38it/s, Epoch: 23, Batch: 19,Loss: -1.122,Avg.Loss: -1.125,LR: 4.42E-04]Training epoch 23:  17%|█▋        | 19/112 [00:00<00:01, 56.80it/s, Epoch: 23, Batch: 19,Loss: -1.122,Avg.Loss: -1.125,LR: 4.42E-04]Training epoch 23:  17%|█▋        | 19/112 [00:00<00:01, 56.80it/s, Epoch: 23, Batch: 20,Loss: -1.391,Avg.Loss: -1.138,LR: 4.42E-04]Training epoch 23:  18%|█▊        | 20/112 [00:00<00:01, 56.80it/s, Epoch: 23, Batch: 21,Loss: -1.366,Avg.Loss: -1.149,LR: 4.42E-04]Training epoch 23:  19%|█▉        | 21/112 [00:00<00:01, 56.80it/s, Epoch: 23, Batch: 22,Loss: -1.517,Avg.Loss: -1.166,LR: 4.42E-04]Training epoch 23:  20%|█▉        | 22/112 [00:00<00:01, 56.80it/s, Epoch: 23, Batch: 23,Loss: -1.256,Avg.Loss: -1.170,LR: 4.42E-04]Training epoch 23:  21%|██        | 23/112 [00:00<00:01, 56.80it/s, Epoch: 23, Batch: 24,Loss: -1.106,Avg.Loss: -1.167,LR: 4.42E-04]Training epoch 23:  21%|██▏       | 24/112 [00:00<00:01, 56.80it/s, Epoch: 23, Batch: 25,Loss: -1.366,Avg.Loss: -1.175,LR: 4.42E-04]Training epoch 23:  22%|██▏       | 25/112 [00:00<00:01, 54.72it/s, Epoch: 23, Batch: 25,Loss: -1.366,Avg.Loss: -1.175,LR: 4.42E-04]Training epoch 23:  22%|██▏       | 25/112 [00:00<00:01, 54.72it/s, Epoch: 23, Batch: 26,Loss: -0.759,Avg.Loss: -1.159,LR: 4.41E-04]Training epoch 23:  23%|██▎       | 26/112 [00:00<00:01, 54.72it/s, Epoch: 23, Batch: 27,Loss: -0.699,Avg.Loss: -1.142,LR: 4.41E-04]Training epoch 23:  24%|██▍       | 27/112 [00:00<00:01, 54.72it/s, Epoch: 23, Batch: 28,Loss: -1.427,Avg.Loss: -1.152,LR: 4.41E-04]Training epoch 23:  25%|██▌       | 28/112 [00:00<00:01, 54.72it/s, Epoch: 23, Batch: 29,Loss: -1.622,Avg.Loss: -1.168,LR: 4.41E-04]Training epoch 23:  26%|██▌       | 29/112 [00:00<00:01, 54.72it/s, Epoch: 23, Batch: 30,Loss: -0.945,Avg.Loss: -1.161,LR: 4.41E-04]Training epoch 23:  27%|██▋       | 30/112 [00:00<00:01, 54.72it/s, Epoch: 23, Batch: 31,Loss: -1.179,Avg.Loss: -1.161,LR: 4.41E-04]Training epoch 23:  28%|██▊       | 31/112 [00:00<00:01, 54.49it/s, Epoch: 23, Batch: 31,Loss: -1.179,Avg.Loss: -1.161,LR: 4.41E-04]Training epoch 23:  28%|██▊       | 31/112 [00:00<00:01, 54.49it/s, Epoch: 23, Batch: 32,Loss: -1.254,Avg.Loss: -1.164,LR: 4.41E-04]Training epoch 23:  29%|██▊       | 32/112 [00:00<00:01, 54.49it/s, Epoch: 23, Batch: 33,Loss: -1.123,Avg.Loss: -1.163,LR: 4.41E-04]Training epoch 23:  29%|██▉       | 33/112 [00:00<00:01, 54.49it/s, Epoch: 23, Batch: 34,Loss: -1.508,Avg.Loss: -1.173,LR: 4.41E-04]Training epoch 23:  30%|███       | 34/112 [00:00<00:01, 54.49it/s, Epoch: 23, Batch: 35,Loss: -1.080,Avg.Loss: -1.171,LR: 4.41E-04]Training epoch 23:  31%|███▏      | 35/112 [00:00<00:01, 54.49it/s, Epoch: 23, Batch: 36,Loss: -0.944,Avg.Loss: -1.164,LR: 4.41E-04]Training epoch 23:  32%|███▏      | 36/112 [00:00<00:01, 54.49it/s, Epoch: 23, Batch: 37,Loss: -1.182,Avg.Loss: -1.165,LR: 4.41E-04]Training epoch 23:  33%|███▎      | 37/112 [00:00<00:01, 54.34it/s, Epoch: 23, Batch: 37,Loss: -1.182,Avg.Loss: -1.165,LR: 4.41E-04]Training epoch 23:  33%|███▎      | 37/112 [00:00<00:01, 54.34it/s, Epoch: 23, Batch: 38,Loss: -1.957,Avg.Loss: -1.186,LR: 4.41E-04]Training epoch 23:  34%|███▍      | 38/112 [00:00<00:01, 54.34it/s, Epoch: 23, Batch: 39,Loss: -1.679,Avg.Loss: -1.198,LR: 4.41E-04]Training epoch 23:  35%|███▍      | 39/112 [00:00<00:01, 54.34it/s, Epoch: 23, Batch: 40,Loss: -1.777,Avg.Loss: -1.213,LR: 4.41E-04]Training epoch 23:  36%|███▌      | 40/112 [00:00<00:01, 54.34it/s, Epoch: 23, Batch: 41,Loss: -1.148,Avg.Loss: -1.211,LR: 4.41E-04]Training epoch 23:  37%|███▋      | 41/112 [00:00<00:01, 54.34it/s, Epoch: 23, Batch: 42,Loss: -0.599,Avg.Loss: -1.197,LR: 4.41E-04]Training epoch 23:  38%|███▊      | 42/112 [00:00<00:01, 54.34it/s, Epoch: 23, Batch: 43,Loss: -1.502,Avg.Loss: -1.204,LR: 4.41E-04]Training epoch 23:  38%|███▊      | 43/112 [00:00<00:01, 54.51it/s, Epoch: 23, Batch: 43,Loss: -1.502,Avg.Loss: -1.204,LR: 4.41E-04]Training epoch 23:  38%|███▊      | 43/112 [00:00<00:01, 54.51it/s, Epoch: 23, Batch: 44,Loss: -1.320,Avg.Loss: -1.206,LR: 4.41E-04]Training epoch 23:  39%|███▉      | 44/112 [00:00<00:01, 54.51it/s, Epoch: 23, Batch: 45,Loss: -1.090,Avg.Loss: -1.204,LR: 4.41E-04]Training epoch 23:  40%|████      | 45/112 [00:00<00:01, 54.51it/s, Epoch: 23, Batch: 46,Loss: -1.864,Avg.Loss: -1.218,LR: 4.41E-04]Training epoch 23:  41%|████      | 46/112 [00:00<00:01, 54.51it/s, Epoch: 23, Batch: 47,Loss: -1.187,Avg.Loss: -1.217,LR: 4.41E-04]Training epoch 23:  42%|████▏     | 47/112 [00:00<00:01, 54.51it/s, Epoch: 23, Batch: 48,Loss: -0.847,Avg.Loss: -1.210,LR: 4.40E-04]Training epoch 23:  43%|████▎     | 48/112 [00:00<00:01, 54.51it/s, Epoch: 23, Batch: 49,Loss: -1.251,Avg.Loss: -1.211,LR: 4.40E-04]Training epoch 23:  44%|████▍     | 49/112 [00:00<00:01, 54.16it/s, Epoch: 23, Batch: 49,Loss: -1.251,Avg.Loss: -1.211,LR: 4.40E-04]Training epoch 23:  44%|████▍     | 49/112 [00:00<00:01, 54.16it/s, Epoch: 23, Batch: 50,Loss: -1.335,Avg.Loss: -1.213,LR: 4.40E-04]Training epoch 23:  45%|████▍     | 50/112 [00:00<00:01, 54.16it/s, Epoch: 23, Batch: 51,Loss: -1.324,Avg.Loss: -1.215,LR: 4.40E-04]Training epoch 23:  46%|████▌     | 51/112 [00:00<00:01, 54.16it/s, Epoch: 23, Batch: 52,Loss: -1.476,Avg.Loss: -1.220,LR: 4.40E-04]Training epoch 23:  46%|████▋     | 52/112 [00:00<00:01, 54.16it/s, Epoch: 23, Batch: 53,Loss: -1.695,Avg.Loss: -1.229,LR: 4.40E-04]Training epoch 23:  47%|████▋     | 53/112 [00:00<00:01, 54.16it/s, Epoch: 23, Batch: 54,Loss: -1.110,Avg.Loss: -1.227,LR: 4.40E-04]Training epoch 23:  48%|████▊     | 54/112 [00:01<00:01, 54.16it/s, Epoch: 23, Batch: 55,Loss: -1.890,Avg.Loss: -1.239,LR: 4.40E-04]Training epoch 23:  49%|████▉     | 55/112 [00:01<00:01, 53.50it/s, Epoch: 23, Batch: 55,Loss: -1.890,Avg.Loss: -1.239,LR: 4.40E-04]Training epoch 23:  49%|████▉     | 55/112 [00:01<00:01, 53.50it/s, Epoch: 23, Batch: 56,Loss: -1.169,Avg.Loss: -1.238,LR: 4.40E-04]Training epoch 23:  50%|█████     | 56/112 [00:01<00:01, 53.50it/s, Epoch: 23, Batch: 57,Loss: -0.804,Avg.Loss: -1.230,LR: 4.40E-04]Training epoch 23:  51%|█████     | 57/112 [00:01<00:01, 53.50it/s, Epoch: 23, Batch: 58,Loss: -1.441,Avg.Loss: -1.234,LR: 4.40E-04]Training epoch 23:  52%|█████▏    | 58/112 [00:01<00:01, 53.50it/s, Epoch: 23, Batch: 59,Loss: -2.007,Avg.Loss: -1.247,LR: 4.40E-04]Training epoch 23:  53%|█████▎    | 59/112 [00:01<00:00, 53.50it/s, Epoch: 23, Batch: 60,Loss: -1.292,Avg.Loss: -1.248,LR: 4.40E-04]Training epoch 23:  54%|█████▎    | 60/112 [00:01<00:00, 53.50it/s, Epoch: 23, Batch: 61,Loss: -1.917,Avg.Loss: -1.259,LR: 4.40E-04]Training epoch 23:  54%|█████▍    | 61/112 [00:01<00:00, 53.69it/s, Epoch: 23, Batch: 61,Loss: -1.917,Avg.Loss: -1.259,LR: 4.40E-04]Training epoch 23:  54%|█████▍    | 61/112 [00:01<00:00, 53.69it/s, Epoch: 23, Batch: 62,Loss: -1.131,Avg.Loss: -1.257,LR: 4.40E-04]Training epoch 23:  55%|█████▌    | 62/112 [00:01<00:00, 53.69it/s, Epoch: 23, Batch: 63,Loss: -0.502,Avg.Loss: -1.245,LR: 4.40E-04]Training epoch 23:  56%|█████▋    | 63/112 [00:01<00:00, 53.69it/s, Epoch: 23, Batch: 64,Loss: -1.423,Avg.Loss: -1.247,LR: 4.40E-04]Training epoch 23:  57%|█████▋    | 64/112 [00:01<00:00, 53.69it/s, Epoch: 23, Batch: 65,Loss: -1.879,Avg.Loss: -1.257,LR: 4.40E-04]Training epoch 23:  58%|█████▊    | 65/112 [00:01<00:00, 53.69it/s, Epoch: 23, Batch: 66,Loss: -1.465,Avg.Loss: -1.260,LR: 4.40E-04]Training epoch 23:  59%|█████▉    | 66/112 [00:01<00:00, 53.69it/s, Epoch: 23, Batch: 67,Loss: -1.985,Avg.Loss: -1.271,LR: 4.40E-04]Training epoch 23:  60%|█████▉    | 67/112 [00:01<00:00, 53.65it/s, Epoch: 23, Batch: 67,Loss: -1.985,Avg.Loss: -1.271,LR: 4.40E-04]Training epoch 23:  60%|█████▉    | 67/112 [00:01<00:00, 53.65it/s, Epoch: 23, Batch: 68,Loss: -1.371,Avg.Loss: -1.273,LR: 4.40E-04]Training epoch 23:  61%|██████    | 68/112 [00:01<00:00, 53.65it/s, Epoch: 23, Batch: 69,Loss: -0.501,Avg.Loss: -1.261,LR: 4.40E-04]Training epoch 23:  62%|██████▏   | 69/112 [00:01<00:00, 53.65it/s, Epoch: 23, Batch: 70,Loss: -1.704,Avg.Loss: -1.268,LR: 4.39E-04]Training epoch 23:  62%|██████▎   | 70/112 [00:01<00:00, 53.65it/s, Epoch: 23, Batch: 71,Loss: -1.526,Avg.Loss: -1.271,LR: 4.39E-04]Training epoch 23:  63%|██████▎   | 71/112 [00:01<00:00, 53.65it/s, Epoch: 23, Batch: 72,Loss: -1.240,Avg.Loss: -1.271,LR: 4.39E-04]Training epoch 23:  64%|██████▍   | 72/112 [00:01<00:00, 53.65it/s, Epoch: 23, Batch: 73,Loss: -1.855,Avg.Loss: -1.279,LR: 4.39E-04]Training epoch 23:  65%|██████▌   | 73/112 [00:01<00:00, 53.94it/s, Epoch: 23, Batch: 73,Loss: -1.855,Avg.Loss: -1.279,LR: 4.39E-04]Training epoch 23:  65%|██████▌   | 73/112 [00:01<00:00, 53.94it/s, Epoch: 23, Batch: 74,Loss: -1.163,Avg.Loss: -1.277,LR: 4.39E-04]Training epoch 23:  66%|██████▌   | 74/112 [00:01<00:00, 53.94it/s, Epoch: 23, Batch: 75,Loss: -0.396,Avg.Loss: -1.266,LR: 4.39E-04]Training epoch 23:  67%|██████▋   | 75/112 [00:01<00:00, 53.94it/s, Epoch: 23, Batch: 76,Loss: -1.600,Avg.Loss: -1.270,LR: 4.39E-04]Training epoch 23:  68%|██████▊   | 76/112 [00:01<00:00, 53.94it/s, Epoch: 23, Batch: 77,Loss: -1.968,Avg.Loss: -1.279,LR: 4.39E-04]Training epoch 23:  69%|██████▉   | 77/112 [00:01<00:00, 53.94it/s, Epoch: 23, Batch: 78,Loss: -1.353,Avg.Loss: -1.280,LR: 4.39E-04]Training epoch 23:  70%|██████▉   | 78/112 [00:01<00:00, 53.94it/s, Epoch: 23, Batch: 79,Loss: -1.835,Avg.Loss: -1.287,LR: 4.39E-04]Training epoch 23:  71%|███████   | 79/112 [00:01<00:00, 54.04it/s, Epoch: 23, Batch: 79,Loss: -1.835,Avg.Loss: -1.287,LR: 4.39E-04]Training epoch 23:  71%|███████   | 79/112 [00:01<00:00, 54.04it/s, Epoch: 23, Batch: 80,Loss: -1.150,Avg.Loss: -1.285,LR: 4.39E-04]Training epoch 23:  71%|███████▏  | 80/112 [00:01<00:00, 54.04it/s, Epoch: 23, Batch: 81,Loss: -0.264,Avg.Loss: -1.273,LR: 4.39E-04]Training epoch 23:  72%|███████▏  | 81/112 [00:01<00:00, 54.04it/s, Epoch: 23, Batch: 82,Loss: -1.160,Avg.Loss: -1.271,LR: 4.39E-04]Training epoch 23:  73%|███████▎  | 82/112 [00:01<00:00, 54.04it/s, Epoch: 23, Batch: 83,Loss: -1.942,Avg.Loss: -1.279,LR: 4.39E-04]Training epoch 23:  74%|███████▍  | 83/112 [00:01<00:00, 54.04it/s, Epoch: 23, Batch: 84,Loss: -1.707,Avg.Loss: -1.284,LR: 4.39E-04]Training epoch 23:  75%|███████▌  | 84/112 [00:01<00:00, 54.04it/s, Epoch: 23, Batch: 85,Loss: -2.083,Avg.Loss: -1.294,LR: 4.39E-04]Training epoch 23:  76%|███████▌  | 85/112 [00:01<00:00, 54.20it/s, Epoch: 23, Batch: 85,Loss: -2.083,Avg.Loss: -1.294,LR: 4.39E-04]Training epoch 23:  76%|███████▌  | 85/112 [00:01<00:00, 54.20it/s, Epoch: 23, Batch: 86,Loss: -1.523,Avg.Loss: -1.297,LR: 4.39E-04]Training epoch 23:  77%|███████▋  | 86/112 [00:01<00:00, 54.20it/s, Epoch: 23, Batch: 87,Loss: -0.428,Avg.Loss: -1.287,LR: 4.39E-04]Training epoch 23:  78%|███████▊  | 87/112 [00:01<00:00, 54.20it/s, Epoch: 23, Batch: 88,Loss: -1.718,Avg.Loss: -1.291,LR: 4.39E-04]Training epoch 23:  79%|███████▊  | 88/112 [00:01<00:00, 54.20it/s, Epoch: 23, Batch: 89,Loss: -1.868,Avg.Loss: -1.298,LR: 4.39E-04]Training epoch 23:  79%|███████▉  | 89/112 [00:01<00:00, 54.20it/s, Epoch: 23, Batch: 90,Loss: -1.194,Avg.Loss: -1.297,LR: 4.39E-04]Training epoch 23:  80%|████████  | 90/112 [00:01<00:00, 54.20it/s, Epoch: 23, Batch: 91,Loss: -1.772,Avg.Loss: -1.302,LR: 4.38E-04]Training epoch 23:  81%|████████▏ | 91/112 [00:01<00:00, 54.08it/s, Epoch: 23, Batch: 91,Loss: -1.772,Avg.Loss: -1.302,LR: 4.38E-04]Training epoch 23:  81%|████████▏ | 91/112 [00:01<00:00, 54.08it/s, Epoch: 23, Batch: 92,Loss: -1.537,Avg.Loss: -1.305,LR: 4.38E-04]Training epoch 23:  82%|████████▏ | 92/112 [00:01<00:00, 54.08it/s, Epoch: 23, Batch: 93,Loss: -1.118,Avg.Loss: -1.303,LR: 4.38E-04]Training epoch 23:  83%|████████▎ | 93/112 [00:01<00:00, 54.08it/s, Epoch: 23, Batch: 94,Loss: -1.628,Avg.Loss: -1.306,LR: 4.38E-04]Training epoch 23:  84%|████████▍ | 94/112 [00:01<00:00, 54.08it/s, Epoch: 23, Batch: 95,Loss: -1.629,Avg.Loss: -1.309,LR: 4.38E-04]Training epoch 23:  85%|████████▍ | 95/112 [00:01<00:00, 54.08it/s, Epoch: 23, Batch: 96,Loss: -1.165,Avg.Loss: -1.308,LR: 4.38E-04]Training epoch 23:  86%|████████▌ | 96/112 [00:01<00:00, 54.08it/s, Epoch: 23, Batch: 97,Loss: -1.339,Avg.Loss: -1.308,LR: 4.38E-04]Training epoch 23:  87%|████████▋ | 97/112 [00:01<00:00, 53.88it/s, Epoch: 23, Batch: 97,Loss: -1.339,Avg.Loss: -1.308,LR: 4.38E-04]Training epoch 23:  87%|████████▋ | 97/112 [00:01<00:00, 53.88it/s, Epoch: 23, Batch: 98,Loss: -1.054,Avg.Loss: -1.306,LR: 4.38E-04]Training epoch 23:  88%|████████▊ | 98/112 [00:01<00:00, 53.88it/s, Epoch: 23, Batch: 99,Loss: -0.825,Avg.Loss: -1.301,LR: 4.38E-04]Training epoch 23:  88%|████████▊ | 99/112 [00:01<00:00, 53.88it/s, Epoch: 23, Batch: 100,Loss: -1.759,Avg.Loss: -1.305,LR: 4.38E-04]Training epoch 23:  89%|████████▉ | 100/112 [00:01<00:00, 53.88it/s, Epoch: 23, Batch: 101,Loss: -1.339,Avg.Loss: -1.306,LR: 4.38E-04]Training epoch 23:  90%|█████████ | 101/112 [00:01<00:00, 53.88it/s, Epoch: 23, Batch: 102,Loss: -0.876,Avg.Loss: -1.302,LR: 4.38E-04]Training epoch 23:  91%|█████████ | 102/112 [00:01<00:00, 53.88it/s, Epoch: 23, Batch: 103,Loss: -1.590,Avg.Loss: -1.304,LR: 4.38E-04]Training epoch 23:  92%|█████████▏| 103/112 [00:01<00:00, 53.79it/s, Epoch: 23, Batch: 103,Loss: -1.590,Avg.Loss: -1.304,LR: 4.38E-04]Training epoch 23:  92%|█████████▏| 103/112 [00:01<00:00, 53.79it/s, Epoch: 23, Batch: 104,Loss: -1.961,Avg.Loss: -1.311,LR: 4.38E-04]Training epoch 23:  93%|█████████▎| 104/112 [00:01<00:00, 53.79it/s, Epoch: 23, Batch: 105,Loss: -1.223,Avg.Loss: -1.310,LR: 4.38E-04]Training epoch 23:  94%|█████████▍| 105/112 [00:01<00:00, 53.79it/s, Epoch: 23, Batch: 106,Loss: -1.531,Avg.Loss: -1.312,LR: 4.38E-04]Training epoch 23:  95%|█████████▍| 106/112 [00:01<00:00, 53.79it/s, Epoch: 23, Batch: 107,Loss: -1.419,Avg.Loss: -1.313,LR: 4.38E-04]Training epoch 23:  96%|█████████▌| 107/112 [00:01<00:00, 53.79it/s, Epoch: 23, Batch: 108,Loss: -1.108,Avg.Loss: -1.311,LR: 4.38E-04]Training epoch 23:  96%|█████████▋| 108/112 [00:02<00:00, 53.79it/s, Epoch: 23, Batch: 109,Loss: -1.811,Avg.Loss: -1.316,LR: 4.38E-04]Training epoch 23:  97%|█████████▋| 109/112 [00:02<00:00, 53.77it/s, Epoch: 23, Batch: 109,Loss: -1.811,Avg.Loss: -1.316,LR: 4.38E-04]Training epoch 23:  97%|█████████▋| 109/112 [00:02<00:00, 53.77it/s, Epoch: 23, Batch: 110,Loss: -1.597,Avg.Loss: -1.318,LR: 4.38E-04]Training epoch 23:  98%|█████████▊| 110/112 [00:02<00:00, 53.77it/s, Epoch: 23, Batch: 111,Loss: -1.301,Avg.Loss: -1.318,LR: 4.38E-04]Training epoch 23:  99%|█████████▉| 111/112 [00:02<00:00, 53.77it/s, Epoch: 23, Batch: 112,Loss: -2.471,Avg.Loss: -1.328,LR: 4.38E-04]Training epoch 23: 100%|██████████| 112/112 [00:02<00:00, 54.23it/s, Epoch: 23, Batch: 112,Loss: -2.471,Avg.Loss: -1.328,LR: 4.38E-04]
Training epoch 24:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 24:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 24, Batch: 1,Loss: -1.484,Avg.Loss: -1.484,LR: 4.37E-04]Training epoch 24:   1%|          | 1/112 [00:00<00:04, 22.20it/s, Epoch: 24, Batch: 2,Loss: -0.999,Avg.Loss: -1.241,LR: 4.37E-04]Training epoch 24:   2%|▏         | 2/112 [00:00<00:03, 32.47it/s, Epoch: 24, Batch: 3,Loss: -1.588,Avg.Loss: -1.357,LR: 4.37E-04]Training epoch 24:   3%|▎         | 3/112 [00:00<00:02, 38.48it/s, Epoch: 24, Batch: 4,Loss: -1.578,Avg.Loss: -1.412,LR: 4.37E-04]Training epoch 24:   4%|▎         | 4/112 [00:00<00:02, 42.93it/s, Epoch: 24, Batch: 5,Loss: -0.518,Avg.Loss: -1.233,LR: 4.37E-04]Training epoch 24:   4%|▍         | 5/112 [00:00<00:02, 44.80it/s, Epoch: 24, Batch: 6,Loss: -1.627,Avg.Loss: -1.299,LR: 4.37E-04]Training epoch 24:   5%|▌         | 6/112 [00:00<00:01, 53.67it/s, Epoch: 24, Batch: 6,Loss: -1.627,Avg.Loss: -1.299,LR: 4.37E-04]Training epoch 24:   5%|▌         | 6/112 [00:00<00:01, 53.67it/s, Epoch: 24, Batch: 7,Loss: -1.631,Avg.Loss: -1.347,LR: 4.37E-04]Training epoch 24:   6%|▋         | 7/112 [00:00<00:01, 53.67it/s, Epoch: 24, Batch: 8,Loss: -1.644,Avg.Loss: -1.384,LR: 4.37E-04]Training epoch 24:   7%|▋         | 8/112 [00:00<00:01, 53.67it/s, Epoch: 24, Batch: 9,Loss: -1.664,Avg.Loss: -1.415,LR: 4.37E-04]Training epoch 24:   8%|▊         | 9/112 [00:00<00:01, 53.67it/s, Epoch: 24, Batch: 10,Loss: -1.312,Avg.Loss: -1.405,LR: 4.37E-04]Training epoch 24:   9%|▉         | 10/112 [00:00<00:01, 53.67it/s, Epoch: 24, Batch: 11,Loss: -1.235,Avg.Loss: -1.389,LR: 4.37E-04]Training epoch 24:  10%|▉         | 11/112 [00:00<00:01, 53.67it/s, Epoch: 24, Batch: 12,Loss: -2.002,Avg.Loss: -1.440,LR: 4.37E-04]Training epoch 24:  11%|█         | 12/112 [00:00<00:01, 53.67it/s, Epoch: 24, Batch: 13,Loss: -1.424,Avg.Loss: -1.439,LR: 4.37E-04]Training epoch 24:  12%|█▏        | 13/112 [00:00<00:01, 59.83it/s, Epoch: 24, Batch: 13,Loss: -1.424,Avg.Loss: -1.439,LR: 4.37E-04]Training epoch 24:  12%|█▏        | 13/112 [00:00<00:01, 59.83it/s, Epoch: 24, Batch: 14,Loss: -0.657,Avg.Loss: -1.383,LR: 4.37E-04]Training epoch 24:  12%|█▎        | 14/112 [00:00<00:01, 59.83it/s, Epoch: 24, Batch: 15,Loss: -1.600,Avg.Loss: -1.398,LR: 4.37E-04]Training epoch 24:  13%|█▎        | 15/112 [00:00<00:01, 59.83it/s, Epoch: 24, Batch: 16,Loss: -1.816,Avg.Loss: -1.424,LR: 4.37E-04]Training epoch 24:  14%|█▍        | 16/112 [00:00<00:01, 59.83it/s, Epoch: 24, Batch: 17,Loss: -1.551,Avg.Loss: -1.431,LR: 4.37E-04]Training epoch 24:  15%|█▌        | 17/112 [00:00<00:01, 59.83it/s, Epoch: 24, Batch: 18,Loss: -1.847,Avg.Loss: -1.454,LR: 4.37E-04]Training epoch 24:  16%|█▌        | 18/112 [00:00<00:01, 59.83it/s, Epoch: 24, Batch: 19,Loss: -1.129,Avg.Loss: -1.437,LR: 4.37E-04]Training epoch 24:  17%|█▋        | 19/112 [00:00<00:01, 56.71it/s, Epoch: 24, Batch: 19,Loss: -1.129,Avg.Loss: -1.437,LR: 4.37E-04]Training epoch 24:  17%|█▋        | 19/112 [00:00<00:01, 56.71it/s, Epoch: 24, Batch: 20,Loss: -1.330,Avg.Loss: -1.432,LR: 4.37E-04]Training epoch 24:  18%|█▊        | 20/112 [00:00<00:01, 56.71it/s, Epoch: 24, Batch: 21,Loss: -1.719,Avg.Loss: -1.446,LR: 4.37E-04]Training epoch 24:  19%|█▉        | 21/112 [00:00<00:01, 56.71it/s, Epoch: 24, Batch: 22,Loss: -0.844,Avg.Loss: -1.418,LR: 4.37E-04]Training epoch 24:  20%|█▉        | 22/112 [00:00<00:01, 56.71it/s, Epoch: 24, Batch: 23,Loss: -1.005,Avg.Loss: -1.400,LR: 4.36E-04]Training epoch 24:  21%|██        | 23/112 [00:00<00:01, 56.71it/s, Epoch: 24, Batch: 24,Loss: -1.740,Avg.Loss: -1.414,LR: 4.36E-04]Training epoch 24:  21%|██▏       | 24/112 [00:00<00:01, 56.71it/s, Epoch: 24, Batch: 25,Loss: -1.227,Avg.Loss: -1.407,LR: 4.36E-04]Training epoch 24:  22%|██▏       | 25/112 [00:00<00:01, 54.87it/s, Epoch: 24, Batch: 25,Loss: -1.227,Avg.Loss: -1.407,LR: 4.36E-04]Training epoch 24:  22%|██▏       | 25/112 [00:00<00:01, 54.87it/s, Epoch: 24, Batch: 26,Loss: -0.849,Avg.Loss: -1.385,LR: 4.36E-04]Training epoch 24:  23%|██▎       | 26/112 [00:00<00:01, 54.87it/s, Epoch: 24, Batch: 27,Loss: -1.361,Avg.Loss: -1.385,LR: 4.36E-04]Training epoch 24:  24%|██▍       | 27/112 [00:00<00:01, 54.87it/s, Epoch: 24, Batch: 28,Loss: -1.725,Avg.Loss: -1.397,LR: 4.36E-04]Training epoch 24:  25%|██▌       | 28/112 [00:00<00:01, 54.87it/s, Epoch: 24, Batch: 29,Loss: -1.319,Avg.Loss: -1.394,LR: 4.36E-04]Training epoch 24:  26%|██▌       | 29/112 [00:00<00:01, 54.87it/s, Epoch: 24, Batch: 30,Loss: -1.974,Avg.Loss: -1.413,LR: 4.36E-04]Training epoch 24:  27%|██▋       | 30/112 [00:00<00:01, 54.87it/s, Epoch: 24, Batch: 31,Loss: -0.997,Avg.Loss: -1.400,LR: 4.36E-04]Training epoch 24:  28%|██▊       | 31/112 [00:00<00:01, 54.07it/s, Epoch: 24, Batch: 31,Loss: -0.997,Avg.Loss: -1.400,LR: 4.36E-04]Training epoch 24:  28%|██▊       | 31/112 [00:00<00:01, 54.07it/s, Epoch: 24, Batch: 32,Loss: -0.662,Avg.Loss: -1.377,LR: 4.36E-04]Training epoch 24:  29%|██▊       | 32/112 [00:00<00:01, 54.07it/s, Epoch: 24, Batch: 33,Loss: -1.064,Avg.Loss: -1.367,LR: 4.36E-04]Training epoch 24:  29%|██▉       | 33/112 [00:00<00:01, 54.07it/s, Epoch: 24, Batch: 34,Loss: -1.662,Avg.Loss: -1.376,LR: 4.36E-04]Training epoch 24:  30%|███       | 34/112 [00:00<00:01, 54.07it/s, Epoch: 24, Batch: 35,Loss: -1.287,Avg.Loss: -1.374,LR: 4.36E-04]Training epoch 24:  31%|███▏      | 35/112 [00:00<00:01, 54.07it/s, Epoch: 24, Batch: 36,Loss: -1.726,Avg.Loss: -1.383,LR: 4.36E-04]Training epoch 24:  32%|███▏      | 36/112 [00:00<00:01, 54.07it/s, Epoch: 24, Batch: 37,Loss: -1.295,Avg.Loss: -1.381,LR: 4.36E-04]Training epoch 24:  33%|███▎      | 37/112 [00:00<00:01, 54.15it/s, Epoch: 24, Batch: 37,Loss: -1.295,Avg.Loss: -1.381,LR: 4.36E-04]Training epoch 24:  33%|███▎      | 37/112 [00:00<00:01, 54.15it/s, Epoch: 24, Batch: 38,Loss: -1.252,Avg.Loss: -1.378,LR: 4.36E-04]Training epoch 24:  34%|███▍      | 38/112 [00:00<00:01, 54.15it/s, Epoch: 24, Batch: 39,Loss: -1.622,Avg.Loss: -1.384,LR: 4.36E-04]Training epoch 24:  35%|███▍      | 39/112 [00:00<00:01, 54.15it/s, Epoch: 24, Batch: 40,Loss: -1.420,Avg.Loss: -1.385,LR: 4.36E-04]Training epoch 24:  36%|███▌      | 40/112 [00:00<00:01, 54.15it/s, Epoch: 24, Batch: 41,Loss: -1.088,Avg.Loss: -1.377,LR: 4.36E-04]Training epoch 24:  37%|███▋      | 41/112 [00:00<00:01, 54.15it/s, Epoch: 24, Batch: 42,Loss: -0.292,Avg.Loss: -1.352,LR: 4.36E-04]Training epoch 24:  38%|███▊      | 42/112 [00:00<00:01, 54.15it/s, Epoch: 24, Batch: 43,Loss: -0.680,Avg.Loss: -1.336,LR: 4.36E-04]Training epoch 24:  38%|███▊      | 43/112 [00:00<00:01, 53.96it/s, Epoch: 24, Batch: 43,Loss: -0.680,Avg.Loss: -1.336,LR: 4.36E-04]Training epoch 24:  38%|███▊      | 43/112 [00:00<00:01, 53.96it/s, Epoch: 24, Batch: 44,Loss: -1.644,Avg.Loss: -1.343,LR: 4.35E-04]Training epoch 24:  39%|███▉      | 44/112 [00:00<00:01, 53.96it/s, Epoch: 24, Batch: 45,Loss: -1.356,Avg.Loss: -1.343,LR: 4.35E-04]Training epoch 24:  40%|████      | 45/112 [00:00<00:01, 53.96it/s, Epoch: 24, Batch: 46,Loss: -1.833,Avg.Loss: -1.354,LR: 4.35E-04]Training epoch 24:  41%|████      | 46/112 [00:00<00:01, 53.96it/s, Epoch: 24, Batch: 47,Loss: -1.704,Avg.Loss: -1.361,LR: 4.35E-04]Training epoch 24:  42%|████▏     | 47/112 [00:00<00:01, 53.96it/s, Epoch: 24, Batch: 48,Loss: -1.519,Avg.Loss: -1.365,LR: 4.35E-04]Training epoch 24:  43%|████▎     | 48/112 [00:00<00:01, 53.96it/s, Epoch: 24, Batch: 49,Loss: -2.087,Avg.Loss: -1.379,LR: 4.35E-04]Training epoch 24:  44%|████▍     | 49/112 [00:00<00:01, 53.68it/s, Epoch: 24, Batch: 49,Loss: -2.087,Avg.Loss: -1.379,LR: 4.35E-04]Training epoch 24:  44%|████▍     | 49/112 [00:00<00:01, 53.68it/s, Epoch: 24, Batch: 50,Loss: -1.529,Avg.Loss: -1.382,LR: 4.35E-04]Training epoch 24:  45%|████▍     | 50/112 [00:00<00:01, 53.68it/s, Epoch: 24, Batch: 51,Loss: -1.687,Avg.Loss: -1.388,LR: 4.35E-04]Training epoch 24:  46%|████▌     | 51/112 [00:00<00:01, 53.68it/s, Epoch: 24, Batch: 52,Loss: -1.887,Avg.Loss: -1.398,LR: 4.35E-04]Training epoch 24:  46%|████▋     | 52/112 [00:00<00:01, 53.68it/s, Epoch: 24, Batch: 53,Loss: -1.686,Avg.Loss: -1.403,LR: 4.35E-04]Training epoch 24:  47%|████▋     | 53/112 [00:00<00:01, 53.68it/s, Epoch: 24, Batch: 54,Loss: -1.514,Avg.Loss: -1.405,LR: 4.35E-04]Training epoch 24:  48%|████▊     | 54/112 [00:01<00:01, 53.68it/s, Epoch: 24, Batch: 55,Loss: -1.598,Avg.Loss: -1.409,LR: 4.35E-04]Training epoch 24:  49%|████▉     | 55/112 [00:01<00:01, 53.70it/s, Epoch: 24, Batch: 55,Loss: -1.598,Avg.Loss: -1.409,LR: 4.35E-04]Training epoch 24:  49%|████▉     | 55/112 [00:01<00:01, 53.70it/s, Epoch: 24, Batch: 56,Loss: -1.030,Avg.Loss: -1.402,LR: 4.35E-04]Training epoch 24:  50%|█████     | 56/112 [00:01<00:01, 53.70it/s, Epoch: 24, Batch: 57,Loss: -2.161,Avg.Loss: -1.416,LR: 4.35E-04]Training epoch 24:  51%|█████     | 57/112 [00:01<00:01, 53.70it/s, Epoch: 24, Batch: 58,Loss: -1.612,Avg.Loss: -1.419,LR: 4.35E-04]Training epoch 24:  52%|█████▏    | 58/112 [00:01<00:01, 53.70it/s, Epoch: 24, Batch: 59,Loss: -1.696,Avg.Loss: -1.424,LR: 4.35E-04]Training epoch 24:  53%|█████▎    | 59/112 [00:01<00:00, 53.70it/s, Epoch: 24, Batch: 60,Loss: -1.567,Avg.Loss: -1.426,LR: 4.35E-04]Training epoch 24:  54%|█████▎    | 60/112 [00:01<00:00, 53.70it/s, Epoch: 24, Batch: 61,Loss: -1.983,Avg.Loss: -1.435,LR: 4.35E-04]Training epoch 24:  54%|█████▍    | 61/112 [00:01<00:00, 53.73it/s, Epoch: 24, Batch: 61,Loss: -1.983,Avg.Loss: -1.435,LR: 4.35E-04]Training epoch 24:  54%|█████▍    | 61/112 [00:01<00:00, 53.73it/s, Epoch: 24, Batch: 62,Loss: -1.414,Avg.Loss: -1.435,LR: 4.35E-04]Training epoch 24:  55%|█████▌    | 62/112 [00:01<00:00, 53.73it/s, Epoch: 24, Batch: 63,Loss: -1.683,Avg.Loss: -1.439,LR: 4.35E-04]Training epoch 24:  56%|█████▋    | 63/112 [00:01<00:00, 53.73it/s, Epoch: 24, Batch: 64,Loss: -1.290,Avg.Loss: -1.436,LR: 4.35E-04]Training epoch 24:  57%|█████▋    | 64/112 [00:01<00:00, 53.73it/s, Epoch: 24, Batch: 65,Loss: -1.784,Avg.Loss: -1.442,LR: 4.34E-04]Training epoch 24:  58%|█████▊    | 65/112 [00:01<00:00, 53.73it/s, Epoch: 24, Batch: 66,Loss: -1.419,Avg.Loss: -1.441,LR: 4.34E-04]Training epoch 24:  59%|█████▉    | 66/112 [00:01<00:00, 53.73it/s, Epoch: 24, Batch: 67,Loss: -1.680,Avg.Loss: -1.445,LR: 4.34E-04]Training epoch 24:  60%|█████▉    | 67/112 [00:01<00:00, 53.57it/s, Epoch: 24, Batch: 67,Loss: -1.680,Avg.Loss: -1.445,LR: 4.34E-04]Training epoch 24:  60%|█████▉    | 67/112 [00:01<00:00, 53.57it/s, Epoch: 24, Batch: 68,Loss: -1.727,Avg.Loss: -1.449,LR: 4.34E-04]Training epoch 24:  61%|██████    | 68/112 [00:01<00:00, 53.57it/s, Epoch: 24, Batch: 69,Loss: -1.390,Avg.Loss: -1.448,LR: 4.34E-04]Training epoch 24:  62%|██████▏   | 69/112 [00:01<00:00, 53.57it/s, Epoch: 24, Batch: 70,Loss: -1.898,Avg.Loss: -1.455,LR: 4.34E-04]Training epoch 24:  62%|██████▎   | 70/112 [00:01<00:00, 53.57it/s, Epoch: 24, Batch: 71,Loss: -1.863,Avg.Loss: -1.460,LR: 4.34E-04]Training epoch 24:  63%|██████▎   | 71/112 [00:01<00:00, 53.57it/s, Epoch: 24, Batch: 72,Loss: -1.916,Avg.Loss: -1.467,LR: 4.34E-04]Training epoch 24:  64%|██████▍   | 72/112 [00:01<00:00, 53.57it/s, Epoch: 24, Batch: 73,Loss: -1.932,Avg.Loss: -1.473,LR: 4.34E-04]Training epoch 24:  65%|██████▌   | 73/112 [00:01<00:00, 53.65it/s, Epoch: 24, Batch: 73,Loss: -1.932,Avg.Loss: -1.473,LR: 4.34E-04]Training epoch 24:  65%|██████▌   | 73/112 [00:01<00:00, 53.65it/s, Epoch: 24, Batch: 74,Loss: -1.316,Avg.Loss: -1.471,LR: 4.34E-04]Training epoch 24:  66%|██████▌   | 74/112 [00:01<00:00, 53.65it/s, Epoch: 24, Batch: 75,Loss: -1.421,Avg.Loss: -1.470,LR: 4.34E-04]Training epoch 24:  67%|██████▋   | 75/112 [00:01<00:00, 53.65it/s, Epoch: 24, Batch: 76,Loss: -1.626,Avg.Loss: -1.472,LR: 4.34E-04]Training epoch 24:  68%|██████▊   | 76/112 [00:01<00:00, 53.65it/s, Epoch: 24, Batch: 77,Loss: -1.916,Avg.Loss: -1.478,LR: 4.34E-04]Training epoch 24:  69%|██████▉   | 77/112 [00:01<00:00, 53.65it/s, Epoch: 24, Batch: 78,Loss: -1.918,Avg.Loss: -1.484,LR: 4.34E-04]Training epoch 24:  70%|██████▉   | 78/112 [00:01<00:00, 53.65it/s, Epoch: 24, Batch: 79,Loss: -1.949,Avg.Loss: -1.490,LR: 4.34E-04]Training epoch 24:  71%|███████   | 79/112 [00:01<00:00, 53.34it/s, Epoch: 24, Batch: 79,Loss: -1.949,Avg.Loss: -1.490,LR: 4.34E-04]Training epoch 24:  71%|███████   | 79/112 [00:01<00:00, 53.34it/s, Epoch: 24, Batch: 80,Loss: -1.954,Avg.Loss: -1.495,LR: 4.34E-04]Training epoch 24:  71%|███████▏  | 80/112 [00:01<00:00, 53.34it/s, Epoch: 24, Batch: 81,Loss: -1.976,Avg.Loss: -1.501,LR: 4.34E-04]Training epoch 24:  72%|███████▏  | 81/112 [00:01<00:00, 53.34it/s, Epoch: 24, Batch: 82,Loss: -1.572,Avg.Loss: -1.502,LR: 4.34E-04]Training epoch 24:  73%|███████▎  | 82/112 [00:01<00:00, 53.34it/s, Epoch: 24, Batch: 83,Loss: -1.480,Avg.Loss: -1.502,LR: 4.34E-04]Training epoch 24:  74%|███████▍  | 83/112 [00:01<00:00, 53.34it/s, Epoch: 24, Batch: 84,Loss: -1.912,Avg.Loss: -1.507,LR: 4.34E-04]Training epoch 24:  75%|███████▌  | 84/112 [00:01<00:00, 53.34it/s, Epoch: 24, Batch: 85,Loss: -2.017,Avg.Loss: -1.513,LR: 4.34E-04]Training epoch 24:  76%|███████▌  | 85/112 [00:01<00:00, 53.40it/s, Epoch: 24, Batch: 85,Loss: -2.017,Avg.Loss: -1.513,LR: 4.34E-04]Training epoch 24:  76%|███████▌  | 85/112 [00:01<00:00, 53.40it/s, Epoch: 24, Batch: 86,Loss: -1.723,Avg.Loss: -1.515,LR: 4.33E-04]Training epoch 24:  77%|███████▋  | 86/112 [00:01<00:00, 53.40it/s, Epoch: 24, Batch: 87,Loss: -1.949,Avg.Loss: -1.520,LR: 4.33E-04]Training epoch 24:  78%|███████▊  | 87/112 [00:01<00:00, 53.40it/s, Epoch: 24, Batch: 88,Loss: -1.969,Avg.Loss: -1.525,LR: 4.33E-04]Training epoch 24:  79%|███████▊  | 88/112 [00:01<00:00, 53.40it/s, Epoch: 24, Batch: 89,Loss: -1.944,Avg.Loss: -1.530,LR: 4.33E-04]Training epoch 24:  79%|███████▉  | 89/112 [00:01<00:00, 53.40it/s, Epoch: 24, Batch: 90,Loss: -1.801,Avg.Loss: -1.533,LR: 4.33E-04]Training epoch 24:  80%|████████  | 90/112 [00:01<00:00, 53.40it/s, Epoch: 24, Batch: 91,Loss: -1.571,Avg.Loss: -1.534,LR: 4.33E-04]Training epoch 24:  81%|████████▏ | 91/112 [00:01<00:00, 53.55it/s, Epoch: 24, Batch: 91,Loss: -1.571,Avg.Loss: -1.534,LR: 4.33E-04]Training epoch 24:  81%|████████▏ | 91/112 [00:01<00:00, 53.55it/s, Epoch: 24, Batch: 92,Loss: -2.058,Avg.Loss: -1.539,LR: 4.33E-04]Training epoch 24:  82%|████████▏ | 92/112 [00:01<00:00, 53.55it/s, Epoch: 24, Batch: 93,Loss: -2.246,Avg.Loss: -1.547,LR: 4.33E-04]Training epoch 24:  83%|████████▎ | 93/112 [00:01<00:00, 53.55it/s, Epoch: 24, Batch: 94,Loss: -1.816,Avg.Loss: -1.550,LR: 4.33E-04]Training epoch 24:  84%|████████▍ | 94/112 [00:01<00:00, 53.55it/s, Epoch: 24, Batch: 95,Loss: -1.959,Avg.Loss: -1.554,LR: 4.33E-04]Training epoch 24:  85%|████████▍ | 95/112 [00:01<00:00, 53.55it/s, Epoch: 24, Batch: 96,Loss: -1.706,Avg.Loss: -1.556,LR: 4.33E-04]Training epoch 24:  86%|████████▌ | 96/112 [00:01<00:00, 53.55it/s, Epoch: 24, Batch: 97,Loss: -2.027,Avg.Loss: -1.560,LR: 4.33E-04]Training epoch 24:  87%|████████▋ | 97/112 [00:01<00:00, 53.63it/s, Epoch: 24, Batch: 97,Loss: -2.027,Avg.Loss: -1.560,LR: 4.33E-04]Training epoch 24:  87%|████████▋ | 97/112 [00:01<00:00, 53.63it/s, Epoch: 24, Batch: 98,Loss: -2.229,Avg.Loss: -1.567,LR: 4.33E-04]Training epoch 24:  88%|████████▊ | 98/112 [00:01<00:00, 53.63it/s, Epoch: 24, Batch: 99,Loss: -2.282,Avg.Loss: -1.574,LR: 4.33E-04]Training epoch 24:  88%|████████▊ | 99/112 [00:01<00:00, 53.63it/s, Epoch: 24, Batch: 100,Loss: -1.093,Avg.Loss: -1.570,LR: 4.33E-04]Training epoch 24:  89%|████████▉ | 100/112 [00:01<00:00, 53.63it/s, Epoch: 24, Batch: 101,Loss: -1.242,Avg.Loss: -1.566,LR: 4.33E-04]Training epoch 24:  90%|█████████ | 101/112 [00:01<00:00, 53.63it/s, Epoch: 24, Batch: 102,Loss: -2.192,Avg.Loss: -1.573,LR: 4.33E-04]Training epoch 24:  91%|█████████ | 102/112 [00:01<00:00, 53.63it/s, Epoch: 24, Batch: 103,Loss: -2.025,Avg.Loss: -1.577,LR: 4.33E-04]Training epoch 24:  92%|█████████▏| 103/112 [00:01<00:00, 53.59it/s, Epoch: 24, Batch: 103,Loss: -2.025,Avg.Loss: -1.577,LR: 4.33E-04]Training epoch 24:  92%|█████████▏| 103/112 [00:01<00:00, 53.59it/s, Epoch: 24, Batch: 104,Loss: -1.862,Avg.Loss: -1.580,LR: 4.33E-04]Training epoch 24:  93%|█████████▎| 104/112 [00:01<00:00, 53.59it/s, Epoch: 24, Batch: 105,Loss: -2.399,Avg.Loss: -1.587,LR: 4.33E-04]Training epoch 24:  94%|█████████▍| 105/112 [00:01<00:00, 53.59it/s, Epoch: 24, Batch: 106,Loss: -0.705,Avg.Loss: -1.579,LR: 4.33E-04]Training epoch 24:  95%|█████████▍| 106/112 [00:01<00:00, 53.59it/s, Epoch: 24, Batch: 107,Loss: -0.052,Avg.Loss: -1.565,LR: 4.32E-04]Training epoch 24:  96%|█████████▌| 107/112 [00:01<00:00, 53.59it/s, Epoch: 24, Batch: 108,Loss: -1.878,Avg.Loss: -1.568,LR: 4.32E-04]Training epoch 24:  96%|█████████▋| 108/112 [00:02<00:00, 53.59it/s, Epoch: 24, Batch: 109,Loss: -1.180,Avg.Loss: -1.564,LR: 4.32E-04]Training epoch 24:  97%|█████████▋| 109/112 [00:02<00:00, 53.85it/s, Epoch: 24, Batch: 109,Loss: -1.180,Avg.Loss: -1.564,LR: 4.32E-04]Training epoch 24:  97%|█████████▋| 109/112 [00:02<00:00, 53.85it/s, Epoch: 24, Batch: 110,Loss: -0.328,Avg.Loss: -1.553,LR: 4.32E-04]Training epoch 24:  98%|█████████▊| 110/112 [00:02<00:00, 53.85it/s, Epoch: 24, Batch: 111,Loss: -1.306,Avg.Loss: -1.551,LR: 4.32E-04]Training epoch 24:  99%|█████████▉| 111/112 [00:02<00:00, 53.85it/s, Epoch: 24, Batch: 112,Loss: 0.117,Avg.Loss: -1.536,LR: 4.32E-04] Training epoch 24: 100%|██████████| 112/112 [00:02<00:00, 53.92it/s, Epoch: 24, Batch: 112,Loss: 0.117,Avg.Loss: -1.536,LR: 4.32E-04]
Training epoch 25:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 25:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 25, Batch: 1,Loss: 1.040,Avg.Loss: 1.040,LR: 4.32E-04]Training epoch 25:   1%|          | 1/112 [00:00<00:03, 29.33it/s, Epoch: 25, Batch: 2,Loss: 2.192,Avg.Loss: 1.616,LR: 4.32E-04]Training epoch 25:   2%|▏         | 2/112 [00:00<00:02, 39.30it/s, Epoch: 25, Batch: 3,Loss: 0.491,Avg.Loss: 1.241,LR: 4.32E-04]Training epoch 25:   3%|▎         | 3/112 [00:00<00:02, 43.59it/s, Epoch: 25, Batch: 4,Loss: 0.765,Avg.Loss: 1.122,LR: 4.32E-04]Training epoch 25:   4%|▎         | 4/112 [00:00<00:02, 46.43it/s, Epoch: 25, Batch: 5,Loss: 1.430,Avg.Loss: 1.184,LR: 4.32E-04]Training epoch 25:   4%|▍         | 5/112 [00:00<00:02, 48.12it/s, Epoch: 25, Batch: 6,Loss: 0.291,Avg.Loss: 1.035,LR: 4.32E-04]Training epoch 25:   5%|▌         | 6/112 [00:00<00:01, 57.64it/s, Epoch: 25, Batch: 6,Loss: 0.291,Avg.Loss: 1.035,LR: 4.32E-04]Training epoch 25:   5%|▌         | 6/112 [00:00<00:01, 57.64it/s, Epoch: 25, Batch: 7,Loss: -1.048,Avg.Loss: 0.737,LR: 4.32E-04]Training epoch 25:   6%|▋         | 7/112 [00:00<00:01, 57.64it/s, Epoch: 25, Batch: 8,Loss: -0.535,Avg.Loss: 0.578,LR: 4.32E-04]Training epoch 25:   7%|▋         | 8/112 [00:00<00:01, 57.64it/s, Epoch: 25, Batch: 9,Loss: -0.981,Avg.Loss: 0.405,LR: 4.32E-04]Training epoch 25:   8%|▊         | 9/112 [00:00<00:01, 57.64it/s, Epoch: 25, Batch: 10,Loss: -1.074,Avg.Loss: 0.257,LR: 4.32E-04]Training epoch 25:   9%|▉         | 10/112 [00:00<00:01, 57.64it/s, Epoch: 25, Batch: 11,Loss: -1.051,Avg.Loss: 0.138,LR: 4.32E-04]Training epoch 25:  10%|▉         | 11/112 [00:00<00:01, 57.64it/s, Epoch: 25, Batch: 12,Loss: -1.300,Avg.Loss: 0.018,LR: 4.32E-04]Training epoch 25:  11%|█         | 12/112 [00:00<00:01, 57.64it/s, Epoch: 25, Batch: 13,Loss: -1.876,Avg.Loss: -0.127,LR: 4.32E-04]Training epoch 25:  12%|█▏        | 13/112 [00:00<00:01, 58.32it/s, Epoch: 25, Batch: 13,Loss: -1.876,Avg.Loss: -0.127,LR: 4.32E-04]Training epoch 25:  12%|█▏        | 13/112 [00:00<00:01, 58.32it/s, Epoch: 25, Batch: 14,Loss: -2.104,Avg.Loss: -0.269,LR: 4.32E-04]Training epoch 25:  12%|█▎        | 14/112 [00:00<00:01, 58.32it/s, Epoch: 25, Batch: 15,Loss: -1.832,Avg.Loss: -0.373,LR: 4.32E-04]Training epoch 25:  13%|█▎        | 15/112 [00:00<00:01, 58.32it/s, Epoch: 25, Batch: 16,Loss: -1.127,Avg.Loss: -0.420,LR: 4.31E-04]Training epoch 25:  14%|█▍        | 16/112 [00:00<00:01, 58.32it/s, Epoch: 25, Batch: 17,Loss: -1.207,Avg.Loss: -0.466,LR: 4.31E-04]Training epoch 25:  15%|█▌        | 17/112 [00:00<00:01, 58.32it/s, Epoch: 25, Batch: 18,Loss: -0.554,Avg.Loss: -0.471,LR: 4.31E-04]Training epoch 25:  16%|█▌        | 18/112 [00:00<00:01, 58.32it/s, Epoch: 25, Batch: 19,Loss: -1.128,Avg.Loss: -0.506,LR: 4.31E-04]Training epoch 25:  17%|█▋        | 19/112 [00:00<00:01, 55.68it/s, Epoch: 25, Batch: 19,Loss: -1.128,Avg.Loss: -0.506,LR: 4.31E-04]Training epoch 25:  17%|█▋        | 19/112 [00:00<00:01, 55.68it/s, Epoch: 25, Batch: 20,Loss: -1.757,Avg.Loss: -0.568,LR: 4.31E-04]Training epoch 25:  18%|█▊        | 20/112 [00:00<00:01, 55.68it/s, Epoch: 25, Batch: 21,Loss: -1.946,Avg.Loss: -0.634,LR: 4.31E-04]Training epoch 25:  19%|█▉        | 21/112 [00:00<00:01, 55.68it/s, Epoch: 25, Batch: 22,Loss: -1.521,Avg.Loss: -0.674,LR: 4.31E-04]Training epoch 25:  20%|█▉        | 22/112 [00:00<00:01, 55.68it/s, Epoch: 25, Batch: 23,Loss: -1.617,Avg.Loss: -0.715,LR: 4.31E-04]Training epoch 25:  21%|██        | 23/112 [00:00<00:01, 55.68it/s, Epoch: 25, Batch: 24,Loss: -1.376,Avg.Loss: -0.743,LR: 4.31E-04]Training epoch 25:  21%|██▏       | 24/112 [00:00<00:01, 55.68it/s, Epoch: 25, Batch: 25,Loss: -1.305,Avg.Loss: -0.765,LR: 4.31E-04]Training epoch 25:  22%|██▏       | 25/112 [00:00<00:01, 53.77it/s, Epoch: 25, Batch: 25,Loss: -1.305,Avg.Loss: -0.765,LR: 4.31E-04]Training epoch 25:  22%|██▏       | 25/112 [00:00<00:01, 53.77it/s, Epoch: 25, Batch: 26,Loss: -1.378,Avg.Loss: -0.789,LR: 4.31E-04]Training epoch 25:  23%|██▎       | 26/112 [00:00<00:01, 53.77it/s, Epoch: 25, Batch: 27,Loss: -1.338,Avg.Loss: -0.809,LR: 4.31E-04]Training epoch 25:  24%|██▍       | 27/112 [00:00<00:01, 53.77it/s, Epoch: 25, Batch: 28,Loss: -0.222,Avg.Loss: -0.788,LR: 4.31E-04]Training epoch 25:  25%|██▌       | 28/112 [00:00<00:01, 53.77it/s, Epoch: 25, Batch: 29,Loss: 0.605,Avg.Loss: -0.740,LR: 4.31E-04] Training epoch 25:  26%|██▌       | 29/112 [00:00<00:01, 53.77it/s, Epoch: 25, Batch: 30,Loss: -1.038,Avg.Loss: -0.750,LR: 4.31E-04]Training epoch 25:  27%|██▋       | 30/112 [00:00<00:01, 53.77it/s, Epoch: 25, Batch: 31,Loss: -1.574,Avg.Loss: -0.777,LR: 4.31E-04]Training epoch 25:  28%|██▊       | 31/112 [00:00<00:01, 51.61it/s, Epoch: 25, Batch: 31,Loss: -1.574,Avg.Loss: -0.777,LR: 4.31E-04]Training epoch 25:  28%|██▊       | 31/112 [00:00<00:01, 51.61it/s, Epoch: 25, Batch: 32,Loss: -1.337,Avg.Loss: -0.794,LR: 4.31E-04]Training epoch 25:  29%|██▊       | 32/112 [00:00<00:01, 51.61it/s, Epoch: 25, Batch: 33,Loss: -1.636,Avg.Loss: -0.820,LR: 4.31E-04]Training epoch 25:  29%|██▉       | 33/112 [00:00<00:01, 51.61it/s, Epoch: 25, Batch: 34,Loss: -0.997,Avg.Loss: -0.825,LR: 4.31E-04]Training epoch 25:  30%|███       | 34/112 [00:00<00:01, 51.61it/s, Epoch: 25, Batch: 35,Loss: -0.870,Avg.Loss: -0.826,LR: 4.31E-04]Training epoch 25:  31%|███▏      | 35/112 [00:00<00:01, 51.61it/s, Epoch: 25, Batch: 36,Loss: -1.631,Avg.Loss: -0.848,LR: 4.31E-04]Training epoch 25:  32%|███▏      | 36/112 [00:00<00:01, 51.61it/s, Epoch: 25, Batch: 37,Loss: -0.864,Avg.Loss: -0.849,LR: 4.30E-04]Training epoch 25:  33%|███▎      | 37/112 [00:00<00:01, 52.38it/s, Epoch: 25, Batch: 37,Loss: -0.864,Avg.Loss: -0.849,LR: 4.30E-04]Training epoch 25:  33%|███▎      | 37/112 [00:00<00:01, 52.38it/s, Epoch: 25, Batch: 38,Loss: -0.833,Avg.Loss: -0.848,LR: 4.30E-04]Training epoch 25:  34%|███▍      | 38/112 [00:00<00:01, 52.38it/s, Epoch: 25, Batch: 39,Loss: -1.621,Avg.Loss: -0.868,LR: 4.30E-04]Training epoch 25:  35%|███▍      | 39/112 [00:00<00:01, 52.38it/s, Epoch: 25, Batch: 40,Loss: 0.119,Avg.Loss: -0.844,LR: 4.30E-04] Training epoch 25:  36%|███▌      | 40/112 [00:00<00:01, 52.38it/s, Epoch: 25, Batch: 41,Loss: 2.017,Avg.Loss: -0.774,LR: 4.30E-04]Training epoch 25:  37%|███▋      | 41/112 [00:00<00:01, 52.38it/s, Epoch: 25, Batch: 42,Loss: 2.608,Avg.Loss: -0.693,LR: 4.30E-04]Training epoch 25:  38%|███▊      | 42/112 [00:00<00:01, 52.38it/s, Epoch: 25, Batch: 43,Loss: 1.787,Avg.Loss: -0.636,LR: 4.30E-04]Training epoch 25:  38%|███▊      | 43/112 [00:00<00:01, 52.67it/s, Epoch: 25, Batch: 43,Loss: 1.787,Avg.Loss: -0.636,LR: 4.30E-04]Training epoch 25:  38%|███▊      | 43/112 [00:00<00:01, 52.67it/s, Epoch: 25, Batch: 44,Loss: 2.018,Avg.Loss: -0.575,LR: 4.30E-04]Training epoch 25:  39%|███▉      | 44/112 [00:00<00:01, 52.67it/s, Epoch: 25, Batch: 45,Loss: 1.870,Avg.Loss: -0.521,LR: 4.30E-04]Training epoch 25:  40%|████      | 45/112 [00:00<00:01, 52.67it/s, Epoch: 25, Batch: 46,Loss: -0.604,Avg.Loss: -0.523,LR: 4.30E-04]Training epoch 25:  41%|████      | 46/112 [00:00<00:01, 52.67it/s, Epoch: 25, Batch: 47,Loss: 0.335,Avg.Loss: -0.505,LR: 4.30E-04] Training epoch 25:  42%|████▏     | 47/112 [00:00<00:01, 52.67it/s, Epoch: 25, Batch: 48,Loss: 2.601,Avg.Loss: -0.440,LR: 4.30E-04]Training epoch 25:  43%|████▎     | 48/112 [00:00<00:01, 52.67it/s, Epoch: 25, Batch: 49,Loss: 2.118,Avg.Loss: -0.388,LR: 4.30E-04]Training epoch 25:  44%|████▍     | 49/112 [00:00<00:01, 53.08it/s, Epoch: 25, Batch: 49,Loss: 2.118,Avg.Loss: -0.388,LR: 4.30E-04]Training epoch 25:  44%|████▍     | 49/112 [00:00<00:01, 53.08it/s, Epoch: 25, Batch: 50,Loss: 0.912,Avg.Loss: -0.362,LR: 4.30E-04]Training epoch 25:  45%|████▍     | 50/112 [00:00<00:01, 53.08it/s, Epoch: 25, Batch: 51,Loss: 0.558,Avg.Loss: -0.344,LR: 4.30E-04]Training epoch 25:  46%|████▌     | 51/112 [00:00<00:01, 53.08it/s, Epoch: 25, Batch: 52,Loss: 0.054,Avg.Loss: -0.336,LR: 4.30E-04]Training epoch 25:  46%|████▋     | 52/112 [00:00<00:01, 53.08it/s, Epoch: 25, Batch: 53,Loss: -1.141,Avg.Loss: -0.351,LR: 4.30E-04]Training epoch 25:  47%|████▋     | 53/112 [00:01<00:01, 53.08it/s, Epoch: 25, Batch: 54,Loss: -1.243,Avg.Loss: -0.368,LR: 4.30E-04]Training epoch 25:  48%|████▊     | 54/112 [00:01<00:01, 53.08it/s, Epoch: 25, Batch: 55,Loss: 0.190,Avg.Loss: -0.358,LR: 4.30E-04] Training epoch 25:  49%|████▉     | 55/112 [00:01<00:01, 53.25it/s, Epoch: 25, Batch: 55,Loss: 0.190,Avg.Loss: -0.358,LR: 4.30E-04]Training epoch 25:  49%|████▉     | 55/112 [00:01<00:01, 53.25it/s, Epoch: 25, Batch: 56,Loss: -0.665,Avg.Loss: -0.363,LR: 4.30E-04]Training epoch 25:  50%|█████     | 56/112 [00:01<00:01, 53.25it/s, Epoch: 25, Batch: 57,Loss: -0.501,Avg.Loss: -0.365,LR: 4.29E-04]Training epoch 25:  51%|█████     | 57/112 [00:01<00:01, 53.25it/s, Epoch: 25, Batch: 58,Loss: -0.938,Avg.Loss: -0.375,LR: 4.29E-04]Training epoch 25:  52%|█████▏    | 58/112 [00:01<00:01, 53.25it/s, Epoch: 25, Batch: 59,Loss: -1.295,Avg.Loss: -0.391,LR: 4.29E-04]Training epoch 25:  53%|█████▎    | 59/112 [00:01<00:00, 53.25it/s, Epoch: 25, Batch: 60,Loss: -1.393,Avg.Loss: -0.408,LR: 4.29E-04]Training epoch 25:  54%|█████▎    | 60/112 [00:01<00:00, 53.25it/s, Epoch: 25, Batch: 61,Loss: -1.602,Avg.Loss: -0.427,LR: 4.29E-04]Training epoch 25:  54%|█████▍    | 61/112 [00:01<00:00, 53.40it/s, Epoch: 25, Batch: 61,Loss: -1.602,Avg.Loss: -0.427,LR: 4.29E-04]Training epoch 25:  54%|█████▍    | 61/112 [00:01<00:00, 53.40it/s, Epoch: 25, Batch: 62,Loss: -1.692,Avg.Loss: -0.448,LR: 4.29E-04]Training epoch 25:  55%|█████▌    | 62/112 [00:01<00:00, 53.40it/s, Epoch: 25, Batch: 63,Loss: -0.807,Avg.Loss: -0.453,LR: 4.29E-04]Training epoch 25:  56%|█████▋    | 63/112 [00:01<00:00, 53.40it/s, Epoch: 25, Batch: 64,Loss: -0.401,Avg.Loss: -0.452,LR: 4.29E-04]Training epoch 25:  57%|█████▋    | 64/112 [00:01<00:00, 53.40it/s, Epoch: 25, Batch: 65,Loss: -0.926,Avg.Loss: -0.460,LR: 4.29E-04]Training epoch 25:  58%|█████▊    | 65/112 [00:01<00:00, 53.40it/s, Epoch: 25, Batch: 66,Loss: -1.289,Avg.Loss: -0.472,LR: 4.29E-04]Training epoch 25:  59%|█████▉    | 66/112 [00:01<00:00, 53.40it/s, Epoch: 25, Batch: 67,Loss: -1.415,Avg.Loss: -0.486,LR: 4.29E-04]Training epoch 25:  60%|█████▉    | 67/112 [00:01<00:00, 53.34it/s, Epoch: 25, Batch: 67,Loss: -1.415,Avg.Loss: -0.486,LR: 4.29E-04]Training epoch 25:  60%|█████▉    | 67/112 [00:01<00:00, 53.34it/s, Epoch: 25, Batch: 68,Loss: -1.409,Avg.Loss: -0.500,LR: 4.29E-04]Training epoch 25:  61%|██████    | 68/112 [00:01<00:00, 53.34it/s, Epoch: 25, Batch: 69,Loss: -1.588,Avg.Loss: -0.516,LR: 4.29E-04]Training epoch 25:  62%|██████▏   | 69/112 [00:01<00:00, 53.34it/s, Epoch: 25, Batch: 70,Loss: -1.092,Avg.Loss: -0.524,LR: 4.29E-04]Training epoch 25:  62%|██████▎   | 70/112 [00:01<00:00, 53.34it/s, Epoch: 25, Batch: 71,Loss: -1.507,Avg.Loss: -0.538,LR: 4.29E-04]Training epoch 25:  63%|██████▎   | 71/112 [00:01<00:00, 53.34it/s, Epoch: 25, Batch: 72,Loss: -1.309,Avg.Loss: -0.549,LR: 4.29E-04]Training epoch 25:  64%|██████▍   | 72/112 [00:01<00:00, 53.34it/s, Epoch: 25, Batch: 73,Loss: -0.551,Avg.Loss: -0.549,LR: 4.29E-04]Training epoch 25:  65%|██████▌   | 73/112 [00:01<00:00, 53.37it/s, Epoch: 25, Batch: 73,Loss: -0.551,Avg.Loss: -0.549,LR: 4.29E-04]Training epoch 25:  65%|██████▌   | 73/112 [00:01<00:00, 53.37it/s, Epoch: 25, Batch: 74,Loss: -1.202,Avg.Loss: -0.557,LR: 4.29E-04]Training epoch 25:  66%|██████▌   | 74/112 [00:01<00:00, 53.37it/s, Epoch: 25, Batch: 75,Loss: -1.035,Avg.Loss: -0.564,LR: 4.29E-04]Training epoch 25:  67%|██████▋   | 75/112 [00:01<00:00, 53.37it/s, Epoch: 25, Batch: 76,Loss: -0.860,Avg.Loss: -0.568,LR: 4.29E-04]Training epoch 25:  68%|██████▊   | 76/112 [00:01<00:00, 53.37it/s, Epoch: 25, Batch: 77,Loss: -1.504,Avg.Loss: -0.580,LR: 4.29E-04]Training epoch 25:  69%|██████▉   | 77/112 [00:01<00:00, 53.37it/s, Epoch: 25, Batch: 78,Loss: -1.707,Avg.Loss: -0.594,LR: 4.28E-04]Training epoch 25:  70%|██████▉   | 78/112 [00:01<00:00, 53.37it/s, Epoch: 25, Batch: 79,Loss: -1.235,Avg.Loss: -0.602,LR: 4.28E-04]Training epoch 25:  71%|███████   | 79/112 [00:01<00:00, 53.30it/s, Epoch: 25, Batch: 79,Loss: -1.235,Avg.Loss: -0.602,LR: 4.28E-04]Training epoch 25:  71%|███████   | 79/112 [00:01<00:00, 53.30it/s, Epoch: 25, Batch: 80,Loss: -1.916,Avg.Loss: -0.619,LR: 4.28E-04]Training epoch 25:  71%|███████▏  | 80/112 [00:01<00:00, 53.30it/s, Epoch: 25, Batch: 81,Loss: -1.176,Avg.Loss: -0.626,LR: 4.28E-04]Training epoch 25:  72%|███████▏  | 81/112 [00:01<00:00, 53.30it/s, Epoch: 25, Batch: 82,Loss: -1.238,Avg.Loss: -0.633,LR: 4.28E-04]Training epoch 25:  73%|███████▎  | 82/112 [00:01<00:00, 53.30it/s, Epoch: 25, Batch: 83,Loss: -1.557,Avg.Loss: -0.644,LR: 4.28E-04]Training epoch 25:  74%|███████▍  | 83/112 [00:01<00:00, 53.30it/s, Epoch: 25, Batch: 84,Loss: -1.284,Avg.Loss: -0.652,LR: 4.28E-04]Training epoch 25:  75%|███████▌  | 84/112 [00:01<00:00, 53.30it/s, Epoch: 25, Batch: 85,Loss: -1.250,Avg.Loss: -0.659,LR: 4.28E-04]Training epoch 25:  76%|███████▌  | 85/112 [00:01<00:00, 53.43it/s, Epoch: 25, Batch: 85,Loss: -1.250,Avg.Loss: -0.659,LR: 4.28E-04]Training epoch 25:  76%|███████▌  | 85/112 [00:01<00:00, 53.43it/s, Epoch: 25, Batch: 86,Loss: -1.708,Avg.Loss: -0.671,LR: 4.28E-04]Training epoch 25:  77%|███████▋  | 86/112 [00:01<00:00, 53.43it/s, Epoch: 25, Batch: 87,Loss: -1.621,Avg.Loss: -0.682,LR: 4.28E-04]Training epoch 25:  78%|███████▊  | 87/112 [00:01<00:00, 53.43it/s, Epoch: 25, Batch: 88,Loss: -1.334,Avg.Loss: -0.689,LR: 4.28E-04]Training epoch 25:  79%|███████▊  | 88/112 [00:01<00:00, 53.43it/s, Epoch: 25, Batch: 89,Loss: -1.830,Avg.Loss: -0.702,LR: 4.28E-04]Training epoch 25:  79%|███████▉  | 89/112 [00:01<00:00, 53.43it/s, Epoch: 25, Batch: 90,Loss: -1.114,Avg.Loss: -0.707,LR: 4.28E-04]Training epoch 25:  80%|████████  | 90/112 [00:01<00:00, 53.43it/s, Epoch: 25, Batch: 91,Loss: -1.300,Avg.Loss: -0.713,LR: 4.28E-04]Training epoch 25:  81%|████████▏ | 91/112 [00:01<00:00, 53.51it/s, Epoch: 25, Batch: 91,Loss: -1.300,Avg.Loss: -0.713,LR: 4.28E-04]Training epoch 25:  81%|████████▏ | 91/112 [00:01<00:00, 53.51it/s, Epoch: 25, Batch: 92,Loss: -1.509,Avg.Loss: -0.722,LR: 4.28E-04]Training epoch 25:  82%|████████▏ | 92/112 [00:01<00:00, 53.51it/s, Epoch: 25, Batch: 93,Loss: -1.455,Avg.Loss: -0.730,LR: 4.28E-04]Training epoch 25:  83%|████████▎ | 93/112 [00:01<00:00, 53.51it/s, Epoch: 25, Batch: 94,Loss: -1.120,Avg.Loss: -0.734,LR: 4.28E-04]Training epoch 25:  84%|████████▍ | 94/112 [00:01<00:00, 53.51it/s, Epoch: 25, Batch: 95,Loss: -1.648,Avg.Loss: -0.744,LR: 4.28E-04]Training epoch 25:  85%|████████▍ | 95/112 [00:01<00:00, 53.51it/s, Epoch: 25, Batch: 96,Loss: -1.764,Avg.Loss: -0.754,LR: 4.28E-04]Training epoch 25:  86%|████████▌ | 96/112 [00:01<00:00, 53.51it/s, Epoch: 25, Batch: 97,Loss: -1.689,Avg.Loss: -0.764,LR: 4.28E-04]Training epoch 25:  87%|████████▋ | 97/112 [00:01<00:00, 53.56it/s, Epoch: 25, Batch: 97,Loss: -1.689,Avg.Loss: -0.764,LR: 4.28E-04]Training epoch 25:  87%|████████▋ | 97/112 [00:01<00:00, 53.56it/s, Epoch: 25, Batch: 98,Loss: -1.795,Avg.Loss: -0.774,LR: 4.27E-04]Training epoch 25:  88%|████████▊ | 98/112 [00:01<00:00, 53.56it/s, Epoch: 25, Batch: 99,Loss: -1.874,Avg.Loss: -0.786,LR: 4.27E-04]Training epoch 25:  88%|████████▊ | 99/112 [00:01<00:00, 53.56it/s, Epoch: 25, Batch: 100,Loss: -1.592,Avg.Loss: -0.794,LR: 4.27E-04]Training epoch 25:  89%|████████▉ | 100/112 [00:01<00:00, 53.56it/s, Epoch: 25, Batch: 101,Loss: -1.319,Avg.Loss: -0.799,LR: 4.27E-04]Training epoch 25:  90%|█████████ | 101/112 [00:01<00:00, 53.56it/s, Epoch: 25, Batch: 102,Loss: -1.357,Avg.Loss: -0.804,LR: 4.27E-04]Training epoch 25:  91%|█████████ | 102/112 [00:01<00:00, 53.56it/s, Epoch: 25, Batch: 103,Loss: -2.031,Avg.Loss: -0.816,LR: 4.27E-04]Training epoch 25:  92%|█████████▏| 103/112 [00:01<00:00, 53.60it/s, Epoch: 25, Batch: 103,Loss: -2.031,Avg.Loss: -0.816,LR: 4.27E-04]Training epoch 25:  92%|█████████▏| 103/112 [00:01<00:00, 53.60it/s, Epoch: 25, Batch: 104,Loss: -1.946,Avg.Loss: -0.827,LR: 4.27E-04]Training epoch 25:  93%|█████████▎| 104/112 [00:01<00:00, 53.60it/s, Epoch: 25, Batch: 105,Loss: -1.818,Avg.Loss: -0.837,LR: 4.27E-04]Training epoch 25:  94%|█████████▍| 105/112 [00:01<00:00, 53.60it/s, Epoch: 25, Batch: 106,Loss: -2.087,Avg.Loss: -0.848,LR: 4.27E-04]Training epoch 25:  95%|█████████▍| 106/112 [00:01<00:00, 53.60it/s, Epoch: 25, Batch: 107,Loss: -1.642,Avg.Loss: -0.856,LR: 4.27E-04]Training epoch 25:  96%|█████████▌| 107/112 [00:02<00:00, 53.60it/s, Epoch: 25, Batch: 108,Loss: -1.125,Avg.Loss: -0.858,LR: 4.27E-04]Training epoch 25:  96%|█████████▋| 108/112 [00:02<00:00, 53.60it/s, Epoch: 25, Batch: 109,Loss: -1.684,Avg.Loss: -0.866,LR: 4.27E-04]Training epoch 25:  97%|█████████▋| 109/112 [00:02<00:00, 53.66it/s, Epoch: 25, Batch: 109,Loss: -1.684,Avg.Loss: -0.866,LR: 4.27E-04]Training epoch 25:  97%|█████████▋| 109/112 [00:02<00:00, 53.66it/s, Epoch: 25, Batch: 110,Loss: -1.153,Avg.Loss: -0.868,LR: 4.27E-04]Training epoch 25:  98%|█████████▊| 110/112 [00:02<00:00, 53.66it/s, Epoch: 25, Batch: 111,Loss: -0.374,Avg.Loss: -0.864,LR: 4.27E-04]Training epoch 25:  99%|█████████▉| 111/112 [00:02<00:00, 53.66it/s, Epoch: 25, Batch: 112,Loss: -1.711,Avg.Loss: -0.872,LR: 4.27E-04]Training epoch 25: 100%|██████████| 112/112 [00:02<00:00, 53.50it/s, Epoch: 25, Batch: 112,Loss: -1.711,Avg.Loss: -0.872,LR: 4.27E-04]
Training epoch 26:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 26:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 26, Batch: 1,Loss: -1.705,Avg.Loss: -1.705,LR: 4.27E-04]Training epoch 26:   1%|          | 1/112 [00:00<00:04, 23.76it/s, Epoch: 26, Batch: 2,Loss: -1.658,Avg.Loss: -1.682,LR: 4.27E-04]Training epoch 26:   2%|▏         | 2/112 [00:00<00:03, 34.68it/s, Epoch: 26, Batch: 3,Loss: -1.665,Avg.Loss: -1.676,LR: 4.27E-04]Training epoch 26:   3%|▎         | 3/112 [00:00<00:02, 41.09it/s, Epoch: 26, Batch: 4,Loss: -1.602,Avg.Loss: -1.658,LR: 4.27E-04]Training epoch 26:   4%|▎         | 4/112 [00:00<00:02, 46.27it/s, Epoch: 26, Batch: 5,Loss: -1.393,Avg.Loss: -1.605,LR: 4.27E-04]Training epoch 26:   4%|▍         | 5/112 [00:00<00:02, 49.87it/s, Epoch: 26, Batch: 6,Loss: -1.568,Avg.Loss: -1.599,LR: 4.26E-04]Training epoch 26:   5%|▌         | 6/112 [00:00<00:01, 59.76it/s, Epoch: 26, Batch: 6,Loss: -1.568,Avg.Loss: -1.599,LR: 4.26E-04]Training epoch 26:   5%|▌         | 6/112 [00:00<00:01, 59.76it/s, Epoch: 26, Batch: 7,Loss: -1.414,Avg.Loss: -1.572,LR: 4.26E-04]Training epoch 26:   6%|▋         | 7/112 [00:00<00:01, 59.76it/s, Epoch: 26, Batch: 8,Loss: -2.062,Avg.Loss: -1.633,LR: 4.26E-04]Training epoch 26:   7%|▋         | 8/112 [00:00<00:01, 59.76it/s, Epoch: 26, Batch: 9,Loss: -1.983,Avg.Loss: -1.672,LR: 4.26E-04]Training epoch 26:   8%|▊         | 9/112 [00:00<00:01, 59.76it/s, Epoch: 26, Batch: 10,Loss: -1.646,Avg.Loss: -1.670,LR: 4.26E-04]Training epoch 26:   9%|▉         | 10/112 [00:00<00:01, 59.76it/s, Epoch: 26, Batch: 11,Loss: -1.070,Avg.Loss: -1.615,LR: 4.26E-04]Training epoch 26:  10%|▉         | 11/112 [00:00<00:01, 59.76it/s, Epoch: 26, Batch: 12,Loss: -0.489,Avg.Loss: -1.521,LR: 4.26E-04]Training epoch 26:  11%|█         | 12/112 [00:00<00:01, 55.97it/s, Epoch: 26, Batch: 12,Loss: -0.489,Avg.Loss: -1.521,LR: 4.26E-04]Training epoch 26:  11%|█         | 12/112 [00:00<00:01, 55.97it/s, Epoch: 26, Batch: 13,Loss: -1.767,Avg.Loss: -1.540,LR: 4.26E-04]Training epoch 26:  12%|█▏        | 13/112 [00:00<00:01, 55.97it/s, Epoch: 26, Batch: 14,Loss: -1.219,Avg.Loss: -1.517,LR: 4.26E-04]Training epoch 26:  12%|█▎        | 14/112 [00:00<00:01, 55.97it/s, Epoch: 26, Batch: 15,Loss: -1.126,Avg.Loss: -1.491,LR: 4.26E-04]Training epoch 26:  13%|█▎        | 15/112 [00:00<00:01, 55.97it/s, Epoch: 26, Batch: 16,Loss: -0.116,Avg.Loss: -1.405,LR: 4.26E-04]Training epoch 26:  14%|█▍        | 16/112 [00:00<00:01, 55.97it/s, Epoch: 26, Batch: 17,Loss: -0.222,Avg.Loss: -1.336,LR: 4.26E-04]Training epoch 26:  15%|█▌        | 17/112 [00:00<00:01, 55.97it/s, Epoch: 26, Batch: 18,Loss: -1.392,Avg.Loss: -1.339,LR: 4.26E-04]Training epoch 26:  16%|█▌        | 18/112 [00:00<00:01, 54.48it/s, Epoch: 26, Batch: 18,Loss: -1.392,Avg.Loss: -1.339,LR: 4.26E-04]Training epoch 26:  16%|█▌        | 18/112 [00:00<00:01, 54.48it/s, Epoch: 26, Batch: 19,Loss: -1.417,Avg.Loss: -1.343,LR: 4.26E-04]Training epoch 26:  17%|█▋        | 19/112 [00:00<00:01, 54.48it/s, Epoch: 26, Batch: 20,Loss: -1.179,Avg.Loss: -1.335,LR: 4.26E-04]Training epoch 26:  18%|█▊        | 20/112 [00:00<00:01, 54.48it/s, Epoch: 26, Batch: 21,Loss: -0.702,Avg.Loss: -1.305,LR: 4.26E-04]Training epoch 26:  19%|█▉        | 21/112 [00:00<00:01, 54.48it/s, Epoch: 26, Batch: 22,Loss: -0.862,Avg.Loss: -1.285,LR: 4.26E-04]Training epoch 26:  20%|█▉        | 22/112 [00:00<00:01, 54.48it/s, Epoch: 26, Batch: 23,Loss: -1.846,Avg.Loss: -1.309,LR: 4.26E-04]Training epoch 26:  21%|██        | 23/112 [00:00<00:01, 54.48it/s, Epoch: 26, Batch: 24,Loss: -1.659,Avg.Loss: -1.324,LR: 4.26E-04]Training epoch 26:  21%|██▏       | 24/112 [00:00<00:01, 53.53it/s, Epoch: 26, Batch: 24,Loss: -1.659,Avg.Loss: -1.324,LR: 4.26E-04]Training epoch 26:  21%|██▏       | 24/112 [00:00<00:01, 53.53it/s, Epoch: 26, Batch: 25,Loss: -1.078,Avg.Loss: -1.314,LR: 4.26E-04]Training epoch 26:  22%|██▏       | 25/112 [00:00<00:01, 53.53it/s, Epoch: 26, Batch: 26,Loss: -0.839,Avg.Loss: -1.295,LR: 4.25E-04]Training epoch 26:  23%|██▎       | 26/112 [00:00<00:01, 53.53it/s, Epoch: 26, Batch: 27,Loss: -1.976,Avg.Loss: -1.321,LR: 4.25E-04]Training epoch 26:  24%|██▍       | 27/112 [00:00<00:01, 53.53it/s, Epoch: 26, Batch: 28,Loss: -1.879,Avg.Loss: -1.341,LR: 4.25E-04]Training epoch 26:  25%|██▌       | 28/112 [00:00<00:01, 53.53it/s, Epoch: 26, Batch: 29,Loss: -1.250,Avg.Loss: -1.337,LR: 4.25E-04]Training epoch 26:  26%|██▌       | 29/112 [00:00<00:01, 53.53it/s, Epoch: 26, Batch: 30,Loss: -1.201,Avg.Loss: -1.333,LR: 4.25E-04]Training epoch 26:  27%|██▋       | 30/112 [00:00<00:01, 52.94it/s, Epoch: 26, Batch: 30,Loss: -1.201,Avg.Loss: -1.333,LR: 4.25E-04]Training epoch 26:  27%|██▋       | 30/112 [00:00<00:01, 52.94it/s, Epoch: 26, Batch: 31,Loss: -1.239,Avg.Loss: -1.330,LR: 4.25E-04]Training epoch 26:  28%|██▊       | 31/112 [00:00<00:01, 52.94it/s, Epoch: 26, Batch: 32,Loss: -1.591,Avg.Loss: -1.338,LR: 4.25E-04]Training epoch 26:  29%|██▊       | 32/112 [00:00<00:01, 52.94it/s, Epoch: 26, Batch: 33,Loss: -1.405,Avg.Loss: -1.340,LR: 4.25E-04]Training epoch 26:  29%|██▉       | 33/112 [00:00<00:01, 52.94it/s, Epoch: 26, Batch: 34,Loss: -1.776,Avg.Loss: -1.353,LR: 4.25E-04]Training epoch 26:  30%|███       | 34/112 [00:00<00:01, 52.94it/s, Epoch: 26, Batch: 35,Loss: -1.744,Avg.Loss: -1.364,LR: 4.25E-04]Training epoch 26:  31%|███▏      | 35/112 [00:00<00:01, 52.94it/s, Epoch: 26, Batch: 36,Loss: -1.898,Avg.Loss: -1.379,LR: 4.25E-04]Training epoch 26:  32%|███▏      | 36/112 [00:00<00:01, 52.98it/s, Epoch: 26, Batch: 36,Loss: -1.898,Avg.Loss: -1.379,LR: 4.25E-04]Training epoch 26:  32%|███▏      | 36/112 [00:00<00:01, 52.98it/s, Epoch: 26, Batch: 37,Loss: -1.734,Avg.Loss: -1.389,LR: 4.25E-04]Training epoch 26:  33%|███▎      | 37/112 [00:00<00:01, 52.98it/s, Epoch: 26, Batch: 38,Loss: -1.421,Avg.Loss: -1.389,LR: 4.25E-04]Training epoch 26:  34%|███▍      | 38/112 [00:00<00:01, 52.98it/s, Epoch: 26, Batch: 39,Loss: -1.522,Avg.Loss: -1.393,LR: 4.25E-04]Training epoch 26:  35%|███▍      | 39/112 [00:00<00:01, 52.98it/s, Epoch: 26, Batch: 40,Loss: -2.055,Avg.Loss: -1.409,LR: 4.25E-04]Training epoch 26:  36%|███▌      | 40/112 [00:00<00:01, 52.98it/s, Epoch: 26, Batch: 41,Loss: -2.037,Avg.Loss: -1.425,LR: 4.25E-04]Training epoch 26:  37%|███▋      | 41/112 [00:00<00:01, 52.98it/s, Epoch: 26, Batch: 42,Loss: -2.015,Avg.Loss: -1.439,LR: 4.25E-04]Training epoch 26:  38%|███▊      | 42/112 [00:00<00:01, 52.95it/s, Epoch: 26, Batch: 42,Loss: -2.015,Avg.Loss: -1.439,LR: 4.25E-04]Training epoch 26:  38%|███▊      | 42/112 [00:00<00:01, 52.95it/s, Epoch: 26, Batch: 43,Loss: -1.938,Avg.Loss: -1.450,LR: 4.25E-04]Training epoch 26:  38%|███▊      | 43/112 [00:00<00:01, 52.95it/s, Epoch: 26, Batch: 44,Loss: -1.701,Avg.Loss: -1.456,LR: 4.25E-04]Training epoch 26:  39%|███▉      | 44/112 [00:00<00:01, 52.95it/s, Epoch: 26, Batch: 45,Loss: -1.659,Avg.Loss: -1.461,LR: 4.25E-04]Training epoch 26:  40%|████      | 45/112 [00:00<00:01, 52.95it/s, Epoch: 26, Batch: 46,Loss: -1.786,Avg.Loss: -1.468,LR: 4.24E-04]Training epoch 26:  41%|████      | 46/112 [00:00<00:01, 52.95it/s, Epoch: 26, Batch: 47,Loss: -2.029,Avg.Loss: -1.480,LR: 4.24E-04]Training epoch 26:  42%|████▏     | 47/112 [00:00<00:01, 52.95it/s, Epoch: 26, Batch: 48,Loss: -1.842,Avg.Loss: -1.487,LR: 4.24E-04]Training epoch 26:  43%|████▎     | 48/112 [00:00<00:01, 53.21it/s, Epoch: 26, Batch: 48,Loss: -1.842,Avg.Loss: -1.487,LR: 4.24E-04]Training epoch 26:  43%|████▎     | 48/112 [00:00<00:01, 53.21it/s, Epoch: 26, Batch: 49,Loss: -2.009,Avg.Loss: -1.498,LR: 4.24E-04]Training epoch 26:  44%|████▍     | 49/112 [00:00<00:01, 53.21it/s, Epoch: 26, Batch: 50,Loss: -1.633,Avg.Loss: -1.500,LR: 4.24E-04]Training epoch 26:  45%|████▍     | 50/112 [00:00<00:01, 53.21it/s, Epoch: 26, Batch: 51,Loss: -2.129,Avg.Loss: -1.513,LR: 4.24E-04]Training epoch 26:  46%|████▌     | 51/112 [00:00<00:01, 53.21it/s, Epoch: 26, Batch: 52,Loss: -2.049,Avg.Loss: -1.523,LR: 4.24E-04]Training epoch 26:  46%|████▋     | 52/112 [00:00<00:01, 53.21it/s, Epoch: 26, Batch: 53,Loss: -1.490,Avg.Loss: -1.522,LR: 4.24E-04]Training epoch 26:  47%|████▋     | 53/112 [00:01<00:01, 53.21it/s, Epoch: 26, Batch: 54,Loss: -2.170,Avg.Loss: -1.534,LR: 4.24E-04]Training epoch 26:  48%|████▊     | 54/112 [00:01<00:01, 52.86it/s, Epoch: 26, Batch: 54,Loss: -2.170,Avg.Loss: -1.534,LR: 4.24E-04]Training epoch 26:  48%|████▊     | 54/112 [00:01<00:01, 52.86it/s, Epoch: 26, Batch: 55,Loss: -1.783,Avg.Loss: -1.539,LR: 4.24E-04]Training epoch 26:  49%|████▉     | 55/112 [00:01<00:01, 52.86it/s, Epoch: 26, Batch: 56,Loss: -1.917,Avg.Loss: -1.546,LR: 4.24E-04]Training epoch 26:  50%|█████     | 56/112 [00:01<00:01, 52.86it/s, Epoch: 26, Batch: 57,Loss: -1.850,Avg.Loss: -1.551,LR: 4.24E-04]Training epoch 26:  51%|█████     | 57/112 [00:01<00:01, 52.86it/s, Epoch: 26, Batch: 58,Loss: -1.460,Avg.Loss: -1.549,LR: 4.24E-04]Training epoch 26:  52%|█████▏    | 58/112 [00:01<00:01, 52.86it/s, Epoch: 26, Batch: 59,Loss: -1.635,Avg.Loss: -1.551,LR: 4.24E-04]Training epoch 26:  53%|█████▎    | 59/112 [00:01<00:01, 52.86it/s, Epoch: 26, Batch: 60,Loss: -1.789,Avg.Loss: -1.555,LR: 4.24E-04]Training epoch 26:  54%|█████▎    | 60/112 [00:01<00:00, 52.98it/s, Epoch: 26, Batch: 60,Loss: -1.789,Avg.Loss: -1.555,LR: 4.24E-04]Training epoch 26:  54%|█████▎    | 60/112 [00:01<00:00, 52.98it/s, Epoch: 26, Batch: 61,Loss: -2.010,Avg.Loss: -1.562,LR: 4.24E-04]Training epoch 26:  54%|█████▍    | 61/112 [00:01<00:00, 52.98it/s, Epoch: 26, Batch: 62,Loss: -2.023,Avg.Loss: -1.570,LR: 4.24E-04]Training epoch 26:  55%|█████▌    | 62/112 [00:01<00:00, 52.98it/s, Epoch: 26, Batch: 63,Loss: -1.541,Avg.Loss: -1.569,LR: 4.24E-04]Training epoch 26:  56%|█████▋    | 63/112 [00:01<00:00, 52.98it/s, Epoch: 26, Batch: 64,Loss: -1.656,Avg.Loss: -1.571,LR: 4.24E-04]Training epoch 26:  57%|█████▋    | 64/112 [00:01<00:00, 52.98it/s, Epoch: 26, Batch: 65,Loss: -1.951,Avg.Loss: -1.577,LR: 4.24E-04]Training epoch 26:  58%|█████▊    | 65/112 [00:01<00:00, 52.98it/s, Epoch: 26, Batch: 66,Loss: -1.955,Avg.Loss: -1.582,LR: 4.23E-04]Training epoch 26:  59%|█████▉    | 66/112 [00:01<00:00, 53.00it/s, Epoch: 26, Batch: 66,Loss: -1.955,Avg.Loss: -1.582,LR: 4.23E-04]Training epoch 26:  59%|█████▉    | 66/112 [00:01<00:00, 53.00it/s, Epoch: 26, Batch: 67,Loss: -1.809,Avg.Loss: -1.586,LR: 4.23E-04]Training epoch 26:  60%|█████▉    | 67/112 [00:01<00:00, 53.00it/s, Epoch: 26, Batch: 68,Loss: -1.673,Avg.Loss: -1.587,LR: 4.23E-04]Training epoch 26:  61%|██████    | 68/112 [00:01<00:00, 53.00it/s, Epoch: 26, Batch: 69,Loss: -2.059,Avg.Loss: -1.594,LR: 4.23E-04]Training epoch 26:  62%|██████▏   | 69/112 [00:01<00:00, 53.00it/s, Epoch: 26, Batch: 70,Loss: -1.920,Avg.Loss: -1.598,LR: 4.23E-04]Training epoch 26:  62%|██████▎   | 70/112 [00:01<00:00, 53.00it/s, Epoch: 26, Batch: 71,Loss: -2.008,Avg.Loss: -1.604,LR: 4.23E-04]Training epoch 26:  63%|██████▎   | 71/112 [00:01<00:00, 53.00it/s, Epoch: 26, Batch: 72,Loss: -1.794,Avg.Loss: -1.607,LR: 4.23E-04]Training epoch 26:  64%|██████▍   | 72/112 [00:01<00:00, 53.07it/s, Epoch: 26, Batch: 72,Loss: -1.794,Avg.Loss: -1.607,LR: 4.23E-04]Training epoch 26:  64%|██████▍   | 72/112 [00:01<00:00, 53.07it/s, Epoch: 26, Batch: 73,Loss: -1.636,Avg.Loss: -1.607,LR: 4.23E-04]Training epoch 26:  65%|██████▌   | 73/112 [00:01<00:00, 53.07it/s, Epoch: 26, Batch: 74,Loss: -1.914,Avg.Loss: -1.611,LR: 4.23E-04]Training epoch 26:  66%|██████▌   | 74/112 [00:01<00:00, 53.07it/s, Epoch: 26, Batch: 75,Loss: -2.344,Avg.Loss: -1.621,LR: 4.23E-04]Training epoch 26:  67%|██████▋   | 75/112 [00:01<00:00, 53.07it/s, Epoch: 26, Batch: 76,Loss: -1.380,Avg.Loss: -1.618,LR: 4.23E-04]Training epoch 26:  68%|██████▊   | 76/112 [00:01<00:00, 53.07it/s, Epoch: 26, Batch: 77,Loss: -1.307,Avg.Loss: -1.614,LR: 4.23E-04]Training epoch 26:  69%|██████▉   | 77/112 [00:01<00:00, 53.07it/s, Epoch: 26, Batch: 78,Loss: -1.990,Avg.Loss: -1.619,LR: 4.23E-04]Training epoch 26:  70%|██████▉   | 78/112 [00:01<00:00, 53.27it/s, Epoch: 26, Batch: 78,Loss: -1.990,Avg.Loss: -1.619,LR: 4.23E-04]Training epoch 26:  70%|██████▉   | 78/112 [00:01<00:00, 53.27it/s, Epoch: 26, Batch: 79,Loss: -2.019,Avg.Loss: -1.624,LR: 4.23E-04]Training epoch 26:  71%|███████   | 79/112 [00:01<00:00, 53.27it/s, Epoch: 26, Batch: 80,Loss: -2.075,Avg.Loss: -1.629,LR: 4.23E-04]Training epoch 26:  71%|███████▏  | 80/112 [00:01<00:00, 53.27it/s, Epoch: 26, Batch: 81,Loss: -2.171,Avg.Loss: -1.636,LR: 4.23E-04]Training epoch 26:  72%|███████▏  | 81/112 [00:01<00:00, 53.27it/s, Epoch: 26, Batch: 82,Loss: -1.886,Avg.Loss: -1.639,LR: 4.23E-04]Training epoch 26:  73%|███████▎  | 82/112 [00:01<00:00, 53.27it/s, Epoch: 26, Batch: 83,Loss: -1.910,Avg.Loss: -1.642,LR: 4.23E-04]Training epoch 26:  74%|███████▍  | 83/112 [00:01<00:00, 53.27it/s, Epoch: 26, Batch: 84,Loss: -2.063,Avg.Loss: -1.647,LR: 4.23E-04]Training epoch 26:  75%|███████▌  | 84/112 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 84,Loss: -2.063,Avg.Loss: -1.647,LR: 4.23E-04]Training epoch 26:  75%|███████▌  | 84/112 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 85,Loss: -1.961,Avg.Loss: -1.651,LR: 4.23E-04]Training epoch 26:  76%|███████▌  | 85/112 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 86,Loss: -1.767,Avg.Loss: -1.653,LR: 4.22E-04]Training epoch 26:  77%|███████▋  | 86/112 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 87,Loss: -1.768,Avg.Loss: -1.654,LR: 4.22E-04]Training epoch 26:  78%|███████▊  | 87/112 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 88,Loss: -2.002,Avg.Loss: -1.658,LR: 4.22E-04]Training epoch 26:  79%|███████▊  | 88/112 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 89,Loss: -2.093,Avg.Loss: -1.663,LR: 4.22E-04]Training epoch 26:  79%|███████▉  | 89/112 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 90,Loss: -1.848,Avg.Loss: -1.665,LR: 4.22E-04]Training epoch 26:  80%|████████  | 90/112 [00:01<00:00, 53.22it/s, Epoch: 26, Batch: 90,Loss: -1.848,Avg.Loss: -1.665,LR: 4.22E-04]Training epoch 26:  80%|████████  | 90/112 [00:01<00:00, 53.22it/s, Epoch: 26, Batch: 91,Loss: -1.791,Avg.Loss: -1.666,LR: 4.22E-04]Training epoch 26:  81%|████████▏ | 91/112 [00:01<00:00, 53.22it/s, Epoch: 26, Batch: 92,Loss: -1.873,Avg.Loss: -1.668,LR: 4.22E-04]Training epoch 26:  82%|████████▏ | 92/112 [00:01<00:00, 53.22it/s, Epoch: 26, Batch: 93,Loss: -2.063,Avg.Loss: -1.673,LR: 4.22E-04]Training epoch 26:  83%|████████▎ | 93/112 [00:01<00:00, 53.22it/s, Epoch: 26, Batch: 94,Loss: -1.749,Avg.Loss: -1.673,LR: 4.22E-04]Training epoch 26:  84%|████████▍ | 94/112 [00:01<00:00, 53.22it/s, Epoch: 26, Batch: 95,Loss: -1.979,Avg.Loss: -1.677,LR: 4.22E-04]Training epoch 26:  85%|████████▍ | 95/112 [00:01<00:00, 53.22it/s, Epoch: 26, Batch: 96,Loss: -1.659,Avg.Loss: -1.676,LR: 4.22E-04]Training epoch 26:  86%|████████▌ | 96/112 [00:01<00:00, 53.42it/s, Epoch: 26, Batch: 96,Loss: -1.659,Avg.Loss: -1.676,LR: 4.22E-04]Training epoch 26:  86%|████████▌ | 96/112 [00:01<00:00, 53.42it/s, Epoch: 26, Batch: 97,Loss: -1.916,Avg.Loss: -1.679,LR: 4.22E-04]Training epoch 26:  87%|████████▋ | 97/112 [00:01<00:00, 53.42it/s, Epoch: 26, Batch: 98,Loss: -1.556,Avg.Loss: -1.678,LR: 4.22E-04]Training epoch 26:  88%|████████▊ | 98/112 [00:01<00:00, 53.42it/s, Epoch: 26, Batch: 99,Loss: -1.739,Avg.Loss: -1.678,LR: 4.22E-04]Training epoch 26:  88%|████████▊ | 99/112 [00:01<00:00, 53.42it/s, Epoch: 26, Batch: 100,Loss: -2.150,Avg.Loss: -1.683,LR: 4.22E-04]Training epoch 26:  89%|████████▉ | 100/112 [00:01<00:00, 53.42it/s, Epoch: 26, Batch: 101,Loss: -2.146,Avg.Loss: -1.688,LR: 4.22E-04]Training epoch 26:  90%|█████████ | 101/112 [00:01<00:00, 53.42it/s, Epoch: 26, Batch: 102,Loss: -1.910,Avg.Loss: -1.690,LR: 4.22E-04]Training epoch 26:  91%|█████████ | 102/112 [00:01<00:00, 53.34it/s, Epoch: 26, Batch: 102,Loss: -1.910,Avg.Loss: -1.690,LR: 4.22E-04]Training epoch 26:  91%|█████████ | 102/112 [00:01<00:00, 53.34it/s, Epoch: 26, Batch: 103,Loss: -2.014,Avg.Loss: -1.693,LR: 4.22E-04]Training epoch 26:  92%|█████████▏| 103/112 [00:01<00:00, 53.34it/s, Epoch: 26, Batch: 104,Loss: -1.960,Avg.Loss: -1.695,LR: 4.22E-04]Training epoch 26:  93%|█████████▎| 104/112 [00:01<00:00, 53.34it/s, Epoch: 26, Batch: 105,Loss: -1.895,Avg.Loss: -1.697,LR: 4.21E-04]Training epoch 26:  94%|█████████▍| 105/112 [00:01<00:00, 53.34it/s, Epoch: 26, Batch: 106,Loss: -1.961,Avg.Loss: -1.700,LR: 4.21E-04]Training epoch 26:  95%|█████████▍| 106/112 [00:02<00:00, 53.34it/s, Epoch: 26, Batch: 107,Loss: -1.886,Avg.Loss: -1.702,LR: 4.21E-04]Training epoch 26:  96%|█████████▌| 107/112 [00:02<00:00, 53.34it/s, Epoch: 26, Batch: 108,Loss: -2.134,Avg.Loss: -1.706,LR: 4.21E-04]Training epoch 26:  96%|█████████▋| 108/112 [00:02<00:00, 53.13it/s, Epoch: 26, Batch: 108,Loss: -2.134,Avg.Loss: -1.706,LR: 4.21E-04]Training epoch 26:  96%|█████████▋| 108/112 [00:02<00:00, 53.13it/s, Epoch: 26, Batch: 109,Loss: -1.784,Avg.Loss: -1.706,LR: 4.21E-04]Training epoch 26:  97%|█████████▋| 109/112 [00:02<00:00, 53.13it/s, Epoch: 26, Batch: 110,Loss: -1.929,Avg.Loss: -1.708,LR: 4.21E-04]Training epoch 26:  98%|█████████▊| 110/112 [00:02<00:00, 53.13it/s, Epoch: 26, Batch: 111,Loss: -2.280,Avg.Loss: -1.714,LR: 4.21E-04]Training epoch 26:  99%|█████████▉| 111/112 [00:02<00:00, 53.13it/s, Epoch: 26, Batch: 112,Loss: -2.291,Avg.Loss: -1.719,LR: 4.21E-04]Training epoch 26: 100%|██████████| 112/112 [00:02<00:00, 53.27it/s, Epoch: 26, Batch: 112,Loss: -2.291,Avg.Loss: -1.719,LR: 4.21E-04]
Training epoch 27:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 27:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 27, Batch: 1,Loss: -1.911,Avg.Loss: -1.911,LR: 4.21E-04]Training epoch 27:   1%|          | 1/112 [00:00<00:04, 22.52it/s, Epoch: 27, Batch: 2,Loss: -2.182,Avg.Loss: -2.047,LR: 4.21E-04]Training epoch 27:   2%|▏         | 2/112 [00:00<00:03, 32.19it/s, Epoch: 27, Batch: 3,Loss: -2.399,Avg.Loss: -2.164,LR: 4.21E-04]Training epoch 27:   3%|▎         | 3/112 [00:00<00:02, 37.30it/s, Epoch: 27, Batch: 4,Loss: -1.642,Avg.Loss: -2.033,LR: 4.21E-04]Training epoch 27:   4%|▎         | 4/112 [00:00<00:02, 41.84it/s, Epoch: 27, Batch: 5,Loss: -1.741,Avg.Loss: -1.975,LR: 4.21E-04]Training epoch 27:   4%|▍         | 5/112 [00:00<00:02, 45.86it/s, Epoch: 27, Batch: 6,Loss: -2.080,Avg.Loss: -1.993,LR: 4.21E-04]Training epoch 27:   5%|▌         | 6/112 [00:00<00:01, 54.96it/s, Epoch: 27, Batch: 6,Loss: -2.080,Avg.Loss: -1.993,LR: 4.21E-04]Training epoch 27:   5%|▌         | 6/112 [00:00<00:01, 54.96it/s, Epoch: 27, Batch: 7,Loss: -1.937,Avg.Loss: -1.985,LR: 4.21E-04]Training epoch 27:   6%|▋         | 7/112 [00:00<00:01, 54.96it/s, Epoch: 27, Batch: 8,Loss: -2.322,Avg.Loss: -2.027,LR: 4.21E-04]Training epoch 27:   7%|▋         | 8/112 [00:00<00:01, 54.96it/s, Epoch: 27, Batch: 9,Loss: -0.473,Avg.Loss: -1.854,LR: 4.21E-04]Training epoch 27:   8%|▊         | 9/112 [00:00<00:01, 54.96it/s, Epoch: 27, Batch: 10,Loss: 0.098,Avg.Loss: -1.659,LR: 4.21E-04]Training epoch 27:   9%|▉         | 10/112 [00:00<00:01, 54.96it/s, Epoch: 27, Batch: 11,Loss: -0.506,Avg.Loss: -1.554,LR: 4.21E-04]Training epoch 27:  10%|▉         | 11/112 [00:00<00:01, 54.96it/s, Epoch: 27, Batch: 12,Loss: -1.491,Avg.Loss: -1.549,LR: 4.21E-04]Training epoch 27:  11%|█         | 12/112 [00:00<00:01, 55.42it/s, Epoch: 27, Batch: 12,Loss: -1.491,Avg.Loss: -1.549,LR: 4.21E-04]Training epoch 27:  11%|█         | 12/112 [00:00<00:01, 55.42it/s, Epoch: 27, Batch: 13,Loss: -1.514,Avg.Loss: -1.546,LR: 4.20E-04]Training epoch 27:  12%|█▏        | 13/112 [00:00<00:01, 55.42it/s, Epoch: 27, Batch: 14,Loss: -2.263,Avg.Loss: -1.597,LR: 4.20E-04]Training epoch 27:  12%|█▎        | 14/112 [00:00<00:01, 55.42it/s, Epoch: 27, Batch: 15,Loss: -0.193,Avg.Loss: -1.504,LR: 4.20E-04]Training epoch 27:  13%|█▎        | 15/112 [00:00<00:01, 55.42it/s, Epoch: 27, Batch: 16,Loss: 1.700,Avg.Loss: -1.304,LR: 4.20E-04] Training epoch 27:  14%|█▍        | 16/112 [00:00<00:01, 55.42it/s, Epoch: 27, Batch: 17,Loss: -0.414,Avg.Loss: -1.251,LR: 4.20E-04]Training epoch 27:  15%|█▌        | 17/112 [00:00<00:01, 55.42it/s, Epoch: 27, Batch: 18,Loss: -1.468,Avg.Loss: -1.263,LR: 4.20E-04]Training epoch 27:  16%|█▌        | 18/112 [00:00<00:01, 54.81it/s, Epoch: 27, Batch: 18,Loss: -1.468,Avg.Loss: -1.263,LR: 4.20E-04]Training epoch 27:  16%|█▌        | 18/112 [00:00<00:01, 54.81it/s, Epoch: 27, Batch: 19,Loss: -1.451,Avg.Loss: -1.273,LR: 4.20E-04]Training epoch 27:  17%|█▋        | 19/112 [00:00<00:01, 54.81it/s, Epoch: 27, Batch: 20,Loss: -2.390,Avg.Loss: -1.329,LR: 4.20E-04]Training epoch 27:  18%|█▊        | 20/112 [00:00<00:01, 54.81it/s, Epoch: 27, Batch: 21,Loss: -1.738,Avg.Loss: -1.348,LR: 4.20E-04]Training epoch 27:  19%|█▉        | 21/112 [00:00<00:01, 54.81it/s, Epoch: 27, Batch: 22,Loss: -0.852,Avg.Loss: -1.326,LR: 4.20E-04]Training epoch 27:  20%|█▉        | 22/112 [00:00<00:01, 54.81it/s, Epoch: 27, Batch: 23,Loss: -1.314,Avg.Loss: -1.325,LR: 4.20E-04]Training epoch 27:  21%|██        | 23/112 [00:00<00:01, 54.81it/s, Epoch: 27, Batch: 24,Loss: -0.096,Avg.Loss: -1.274,LR: 4.20E-04]Training epoch 27:  21%|██▏       | 24/112 [00:00<00:01, 52.35it/s, Epoch: 27, Batch: 24,Loss: -0.096,Avg.Loss: -1.274,LR: 4.20E-04]Training epoch 27:  21%|██▏       | 24/112 [00:00<00:01, 52.35it/s, Epoch: 27, Batch: 25,Loss: 0.165,Avg.Loss: -1.217,LR: 4.20E-04] Training epoch 27:  22%|██▏       | 25/112 [00:00<00:01, 52.35it/s, Epoch: 27, Batch: 26,Loss: -1.623,Avg.Loss: -1.232,LR: 4.20E-04]Training epoch 27:  23%|██▎       | 26/112 [00:00<00:01, 52.35it/s, Epoch: 27, Batch: 27,Loss: -2.093,Avg.Loss: -1.264,LR: 4.20E-04]Training epoch 27:  24%|██▍       | 27/112 [00:00<00:01, 52.35it/s, Epoch: 27, Batch: 28,Loss: -1.002,Avg.Loss: -1.255,LR: 4.20E-04]Training epoch 27:  25%|██▌       | 28/112 [00:00<00:01, 52.35it/s, Epoch: 27, Batch: 29,Loss: -1.903,Avg.Loss: -1.277,LR: 4.20E-04]Training epoch 27:  26%|██▌       | 29/112 [00:00<00:01, 52.35it/s, Epoch: 27, Batch: 30,Loss: -1.585,Avg.Loss: -1.287,LR: 4.20E-04]Training epoch 27:  27%|██▋       | 30/112 [00:00<00:01, 51.63it/s, Epoch: 27, Batch: 30,Loss: -1.585,Avg.Loss: -1.287,LR: 4.20E-04]Training epoch 27:  27%|██▋       | 30/112 [00:00<00:01, 51.63it/s, Epoch: 27, Batch: 31,Loss: -1.033,Avg.Loss: -1.279,LR: 4.20E-04]Training epoch 27:  28%|██▊       | 31/112 [00:00<00:01, 51.63it/s, Epoch: 27, Batch: 32,Loss: -1.753,Avg.Loss: -1.294,LR: 4.19E-04]Training epoch 27:  29%|██▊       | 32/112 [00:00<00:01, 51.63it/s, Epoch: 27, Batch: 33,Loss: -1.983,Avg.Loss: -1.315,LR: 4.19E-04]Training epoch 27:  29%|██▉       | 33/112 [00:00<00:01, 51.63it/s, Epoch: 27, Batch: 34,Loss: -1.567,Avg.Loss: -1.322,LR: 4.19E-04]Training epoch 27:  30%|███       | 34/112 [00:00<00:01, 51.63it/s, Epoch: 27, Batch: 35,Loss: -1.728,Avg.Loss: -1.334,LR: 4.19E-04]Training epoch 27:  31%|███▏      | 35/112 [00:00<00:01, 51.63it/s, Epoch: 27, Batch: 36,Loss: -0.006,Avg.Loss: -1.297,LR: 4.19E-04]Training epoch 27:  32%|███▏      | 36/112 [00:00<00:01, 52.34it/s, Epoch: 27, Batch: 36,Loss: -0.006,Avg.Loss: -1.297,LR: 4.19E-04]Training epoch 27:  32%|███▏      | 36/112 [00:00<00:01, 52.34it/s, Epoch: 27, Batch: 37,Loss: 0.303,Avg.Loss: -1.254,LR: 4.19E-04] Training epoch 27:  33%|███▎      | 37/112 [00:00<00:01, 52.34it/s, Epoch: 27, Batch: 38,Loss: -0.404,Avg.Loss: -1.231,LR: 4.19E-04]Training epoch 27:  34%|███▍      | 38/112 [00:00<00:01, 52.34it/s, Epoch: 27, Batch: 39,Loss: -1.848,Avg.Loss: -1.247,LR: 4.19E-04]Training epoch 27:  35%|███▍      | 39/112 [00:00<00:01, 52.34it/s, Epoch: 27, Batch: 40,Loss: -1.333,Avg.Loss: -1.249,LR: 4.19E-04]Training epoch 27:  36%|███▌      | 40/112 [00:00<00:01, 52.34it/s, Epoch: 27, Batch: 41,Loss: -1.811,Avg.Loss: -1.263,LR: 4.19E-04]Training epoch 27:  37%|███▋      | 41/112 [00:00<00:01, 52.34it/s, Epoch: 27, Batch: 42,Loss: -1.480,Avg.Loss: -1.268,LR: 4.19E-04]Training epoch 27:  38%|███▊      | 42/112 [00:00<00:01, 52.58it/s, Epoch: 27, Batch: 42,Loss: -1.480,Avg.Loss: -1.268,LR: 4.19E-04]Training epoch 27:  38%|███▊      | 42/112 [00:00<00:01, 52.58it/s, Epoch: 27, Batch: 43,Loss: -1.425,Avg.Loss: -1.272,LR: 4.19E-04]Training epoch 27:  38%|███▊      | 43/112 [00:00<00:01, 52.58it/s, Epoch: 27, Batch: 44,Loss: -1.774,Avg.Loss: -1.283,LR: 4.19E-04]Training epoch 27:  39%|███▉      | 44/112 [00:00<00:01, 52.58it/s, Epoch: 27, Batch: 45,Loss: -1.401,Avg.Loss: -1.286,LR: 4.19E-04]Training epoch 27:  40%|████      | 45/112 [00:00<00:01, 52.58it/s, Epoch: 27, Batch: 46,Loss: -1.402,Avg.Loss: -1.288,LR: 4.19E-04]Training epoch 27:  41%|████      | 46/112 [00:00<00:01, 52.58it/s, Epoch: 27, Batch: 47,Loss: -1.881,Avg.Loss: -1.301,LR: 4.19E-04]Training epoch 27:  42%|████▏     | 47/112 [00:00<00:01, 52.58it/s, Epoch: 27, Batch: 48,Loss: -1.416,Avg.Loss: -1.303,LR: 4.19E-04]Training epoch 27:  43%|████▎     | 48/112 [00:00<00:01, 52.71it/s, Epoch: 27, Batch: 48,Loss: -1.416,Avg.Loss: -1.303,LR: 4.19E-04]Training epoch 27:  43%|████▎     | 48/112 [00:00<00:01, 52.71it/s, Epoch: 27, Batch: 49,Loss: -0.971,Avg.Loss: -1.297,LR: 4.19E-04]Training epoch 27:  44%|████▍     | 49/112 [00:00<00:01, 52.71it/s, Epoch: 27, Batch: 50,Loss: -1.725,Avg.Loss: -1.305,LR: 4.19E-04]Training epoch 27:  45%|████▍     | 50/112 [00:00<00:01, 52.71it/s, Epoch: 27, Batch: 51,Loss: -1.582,Avg.Loss: -1.311,LR: 4.19E-04]Training epoch 27:  46%|████▌     | 51/112 [00:00<00:01, 52.71it/s, Epoch: 27, Batch: 52,Loss: -2.091,Avg.Loss: -1.326,LR: 4.18E-04]Training epoch 27:  46%|████▋     | 52/112 [00:01<00:01, 52.71it/s, Epoch: 27, Batch: 53,Loss: -1.012,Avg.Loss: -1.320,LR: 4.18E-04]Training epoch 27:  47%|████▋     | 53/112 [00:01<00:01, 52.71it/s, Epoch: 27, Batch: 54,Loss: -0.292,Avg.Loss: -1.301,LR: 4.18E-04]Training epoch 27:  48%|████▊     | 54/112 [00:01<00:01, 52.90it/s, Epoch: 27, Batch: 54,Loss: -0.292,Avg.Loss: -1.301,LR: 4.18E-04]Training epoch 27:  48%|████▊     | 54/112 [00:01<00:01, 52.90it/s, Epoch: 27, Batch: 55,Loss: -1.155,Avg.Loss: -1.298,LR: 4.18E-04]Training epoch 27:  49%|████▉     | 55/112 [00:01<00:01, 52.90it/s, Epoch: 27, Batch: 56,Loss: -1.497,Avg.Loss: -1.302,LR: 4.18E-04]Training epoch 27:  50%|█████     | 56/112 [00:01<00:01, 52.90it/s, Epoch: 27, Batch: 57,Loss: -0.852,Avg.Loss: -1.294,LR: 4.18E-04]Training epoch 27:  51%|█████     | 57/112 [00:01<00:01, 52.90it/s, Epoch: 27, Batch: 58,Loss: -1.387,Avg.Loss: -1.295,LR: 4.18E-04]Training epoch 27:  52%|█████▏    | 58/112 [00:01<00:01, 52.90it/s, Epoch: 27, Batch: 59,Loss: -1.647,Avg.Loss: -1.301,LR: 4.18E-04]Training epoch 27:  53%|█████▎    | 59/112 [00:01<00:01, 52.90it/s, Epoch: 27, Batch: 60,Loss: -1.492,Avg.Loss: -1.304,LR: 4.18E-04]Training epoch 27:  54%|█████▎    | 60/112 [00:01<00:00, 53.09it/s, Epoch: 27, Batch: 60,Loss: -1.492,Avg.Loss: -1.304,LR: 4.18E-04]Training epoch 27:  54%|█████▎    | 60/112 [00:01<00:00, 53.09it/s, Epoch: 27, Batch: 61,Loss: -1.948,Avg.Loss: -1.315,LR: 4.18E-04]Training epoch 27:  54%|█████▍    | 61/112 [00:01<00:00, 53.09it/s, Epoch: 27, Batch: 62,Loss: -1.957,Avg.Loss: -1.325,LR: 4.18E-04]Training epoch 27:  55%|█████▌    | 62/112 [00:01<00:00, 53.09it/s, Epoch: 27, Batch: 63,Loss: -1.906,Avg.Loss: -1.335,LR: 4.18E-04]Training epoch 27:  56%|█████▋    | 63/112 [00:01<00:00, 53.09it/s, Epoch: 27, Batch: 64,Loss: -0.840,Avg.Loss: -1.327,LR: 4.18E-04]Training epoch 27:  57%|█████▋    | 64/112 [00:01<00:00, 53.09it/s, Epoch: 27, Batch: 65,Loss: -0.587,Avg.Loss: -1.315,LR: 4.18E-04]Training epoch 27:  58%|█████▊    | 65/112 [00:01<00:00, 53.09it/s, Epoch: 27, Batch: 66,Loss: -1.774,Avg.Loss: -1.322,LR: 4.18E-04]Training epoch 27:  59%|█████▉    | 66/112 [00:01<00:00, 53.38it/s, Epoch: 27, Batch: 66,Loss: -1.774,Avg.Loss: -1.322,LR: 4.18E-04]Training epoch 27:  59%|█████▉    | 66/112 [00:01<00:00, 53.38it/s, Epoch: 27, Batch: 67,Loss: -0.524,Avg.Loss: -1.310,LR: 4.18E-04]Training epoch 27:  60%|█████▉    | 67/112 [00:01<00:00, 53.38it/s, Epoch: 27, Batch: 68,Loss: 0.903,Avg.Loss: -1.278,LR: 4.18E-04] Training epoch 27:  61%|██████    | 68/112 [00:01<00:00, 53.38it/s, Epoch: 27, Batch: 69,Loss: -0.578,Avg.Loss: -1.268,LR: 4.18E-04]Training epoch 27:  62%|██████▏   | 69/112 [00:01<00:00, 53.38it/s, Epoch: 27, Batch: 70,Loss: -1.749,Avg.Loss: -1.275,LR: 4.18E-04]Training epoch 27:  62%|██████▎   | 70/112 [00:01<00:00, 53.38it/s, Epoch: 27, Batch: 71,Loss: -0.908,Avg.Loss: -1.269,LR: 4.17E-04]Training epoch 27:  63%|██████▎   | 71/112 [00:01<00:00, 53.38it/s, Epoch: 27, Batch: 72,Loss: -0.594,Avg.Loss: -1.260,LR: 4.17E-04]Training epoch 27:  64%|██████▍   | 72/112 [00:01<00:00, 53.37it/s, Epoch: 27, Batch: 72,Loss: -0.594,Avg.Loss: -1.260,LR: 4.17E-04]Training epoch 27:  64%|██████▍   | 72/112 [00:01<00:00, 53.37it/s, Epoch: 27, Batch: 73,Loss: -1.184,Avg.Loss: -1.259,LR: 4.17E-04]Training epoch 27:  65%|██████▌   | 73/112 [00:01<00:00, 53.37it/s, Epoch: 27, Batch: 74,Loss: -0.877,Avg.Loss: -1.254,LR: 4.17E-04]Training epoch 27:  66%|██████▌   | 74/112 [00:01<00:00, 53.37it/s, Epoch: 27, Batch: 75,Loss: 0.195,Avg.Loss: -1.235,LR: 4.17E-04] Training epoch 27:  67%|██████▋   | 75/112 [00:01<00:00, 53.37it/s, Epoch: 27, Batch: 76,Loss: -1.171,Avg.Loss: -1.234,LR: 4.17E-04]Training epoch 27:  68%|██████▊   | 76/112 [00:01<00:00, 53.37it/s, Epoch: 27, Batch: 77,Loss: -1.757,Avg.Loss: -1.241,LR: 4.17E-04]Training epoch 27:  69%|██████▉   | 77/112 [00:01<00:00, 53.37it/s, Epoch: 27, Batch: 78,Loss: -1.081,Avg.Loss: -1.238,LR: 4.17E-04]Training epoch 27:  70%|██████▉   | 78/112 [00:01<00:00, 53.23it/s, Epoch: 27, Batch: 78,Loss: -1.081,Avg.Loss: -1.238,LR: 4.17E-04]Training epoch 27:  70%|██████▉   | 78/112 [00:01<00:00, 53.23it/s, Epoch: 27, Batch: 79,Loss: -1.785,Avg.Loss: -1.245,LR: 4.17E-04]Training epoch 27:  71%|███████   | 79/112 [00:01<00:00, 53.23it/s, Epoch: 27, Batch: 80,Loss: -0.795,Avg.Loss: -1.240,LR: 4.17E-04]Training epoch 27:  71%|███████▏  | 80/112 [00:01<00:00, 53.23it/s, Epoch: 27, Batch: 81,Loss: -0.340,Avg.Loss: -1.229,LR: 4.17E-04]Training epoch 27:  72%|███████▏  | 81/112 [00:01<00:00, 53.23it/s, Epoch: 27, Batch: 82,Loss: -1.080,Avg.Loss: -1.227,LR: 4.17E-04]Training epoch 27:  73%|███████▎  | 82/112 [00:01<00:00, 53.23it/s, Epoch: 27, Batch: 83,Loss: -1.920,Avg.Loss: -1.235,LR: 4.17E-04]Training epoch 27:  74%|███████▍  | 83/112 [00:01<00:00, 53.23it/s, Epoch: 27, Batch: 84,Loss: -1.684,Avg.Loss: -1.241,LR: 4.17E-04]Training epoch 27:  75%|███████▌  | 84/112 [00:01<00:00, 53.30it/s, Epoch: 27, Batch: 84,Loss: -1.684,Avg.Loss: -1.241,LR: 4.17E-04]Training epoch 27:  75%|███████▌  | 84/112 [00:01<00:00, 53.30it/s, Epoch: 27, Batch: 85,Loss: -1.479,Avg.Loss: -1.243,LR: 4.17E-04]Training epoch 27:  76%|███████▌  | 85/112 [00:01<00:00, 53.30it/s, Epoch: 27, Batch: 86,Loss: -1.246,Avg.Loss: -1.243,LR: 4.17E-04]Training epoch 27:  77%|███████▋  | 86/112 [00:01<00:00, 53.30it/s, Epoch: 27, Batch: 87,Loss: -0.621,Avg.Loss: -1.236,LR: 4.17E-04]Training epoch 27:  78%|███████▊  | 87/112 [00:01<00:00, 53.30it/s, Epoch: 27, Batch: 88,Loss: -1.395,Avg.Loss: -1.238,LR: 4.17E-04]Training epoch 27:  79%|███████▊  | 88/112 [00:01<00:00, 53.30it/s, Epoch: 27, Batch: 89,Loss: -0.751,Avg.Loss: -1.233,LR: 4.17E-04]Training epoch 27:  79%|███████▉  | 89/112 [00:01<00:00, 53.30it/s, Epoch: 27, Batch: 90,Loss: -0.635,Avg.Loss: -1.226,LR: 4.16E-04]Training epoch 27:  80%|████████  | 90/112 [00:01<00:00, 53.27it/s, Epoch: 27, Batch: 90,Loss: -0.635,Avg.Loss: -1.226,LR: 4.16E-04]Training epoch 27:  80%|████████  | 90/112 [00:01<00:00, 53.27it/s, Epoch: 27, Batch: 91,Loss: -1.526,Avg.Loss: -1.229,LR: 4.16E-04]Training epoch 27:  81%|████████▏ | 91/112 [00:01<00:00, 53.27it/s, Epoch: 27, Batch: 92,Loss: -1.827,Avg.Loss: -1.236,LR: 4.16E-04]Training epoch 27:  82%|████████▏ | 92/112 [00:01<00:00, 53.27it/s, Epoch: 27, Batch: 93,Loss: -1.693,Avg.Loss: -1.241,LR: 4.16E-04]Training epoch 27:  83%|████████▎ | 93/112 [00:01<00:00, 53.27it/s, Epoch: 27, Batch: 94,Loss: -1.881,Avg.Loss: -1.247,LR: 4.16E-04]Training epoch 27:  84%|████████▍ | 94/112 [00:01<00:00, 53.27it/s, Epoch: 27, Batch: 95,Loss: -1.339,Avg.Loss: -1.248,LR: 4.16E-04]Training epoch 27:  85%|████████▍ | 95/112 [00:01<00:00, 53.27it/s, Epoch: 27, Batch: 96,Loss: -0.968,Avg.Loss: -1.245,LR: 4.16E-04]Training epoch 27:  86%|████████▌ | 96/112 [00:01<00:00, 53.21it/s, Epoch: 27, Batch: 96,Loss: -0.968,Avg.Loss: -1.245,LR: 4.16E-04]Training epoch 27:  86%|████████▌ | 96/112 [00:01<00:00, 53.21it/s, Epoch: 27, Batch: 97,Loss: -1.630,Avg.Loss: -1.249,LR: 4.16E-04]Training epoch 27:  87%|████████▋ | 97/112 [00:01<00:00, 53.21it/s, Epoch: 27, Batch: 98,Loss: -0.931,Avg.Loss: -1.246,LR: 4.16E-04]Training epoch 27:  88%|████████▊ | 98/112 [00:01<00:00, 53.21it/s, Epoch: 27, Batch: 99,Loss: -0.654,Avg.Loss: -1.240,LR: 4.16E-04]Training epoch 27:  88%|████████▊ | 99/112 [00:01<00:00, 53.21it/s, Epoch: 27, Batch: 100,Loss: -1.626,Avg.Loss: -1.244,LR: 4.16E-04]Training epoch 27:  89%|████████▉ | 100/112 [00:01<00:00, 53.21it/s, Epoch: 27, Batch: 101,Loss: -1.713,Avg.Loss: -1.249,LR: 4.16E-04]Training epoch 27:  90%|█████████ | 101/112 [00:01<00:00, 53.21it/s, Epoch: 27, Batch: 102,Loss: -1.520,Avg.Loss: -1.251,LR: 4.16E-04]Training epoch 27:  91%|█████████ | 102/112 [00:01<00:00, 53.50it/s, Epoch: 27, Batch: 102,Loss: -1.520,Avg.Loss: -1.251,LR: 4.16E-04]Training epoch 27:  91%|█████████ | 102/112 [00:01<00:00, 53.50it/s, Epoch: 27, Batch: 103,Loss: -1.932,Avg.Loss: -1.258,LR: 4.16E-04]Training epoch 27:  92%|█████████▏| 103/112 [00:01<00:00, 53.50it/s, Epoch: 27, Batch: 104,Loss: -0.984,Avg.Loss: -1.255,LR: 4.16E-04]Training epoch 27:  93%|█████████▎| 104/112 [00:01<00:00, 53.50it/s, Epoch: 27, Batch: 105,Loss: -0.991,Avg.Loss: -1.253,LR: 4.16E-04]Training epoch 27:  94%|█████████▍| 105/112 [00:01<00:00, 53.50it/s, Epoch: 27, Batch: 106,Loss: -1.546,Avg.Loss: -1.256,LR: 4.16E-04]Training epoch 27:  95%|█████████▍| 106/112 [00:02<00:00, 53.50it/s, Epoch: 27, Batch: 107,Loss: -1.638,Avg.Loss: -1.259,LR: 4.16E-04]Training epoch 27:  96%|█████████▌| 107/112 [00:02<00:00, 53.50it/s, Epoch: 27, Batch: 108,Loss: -1.282,Avg.Loss: -1.259,LR: 4.16E-04]Training epoch 27:  96%|█████████▋| 108/112 [00:02<00:00, 53.76it/s, Epoch: 27, Batch: 108,Loss: -1.282,Avg.Loss: -1.259,LR: 4.16E-04]Training epoch 27:  96%|█████████▋| 108/112 [00:02<00:00, 53.76it/s, Epoch: 27, Batch: 109,Loss: -1.876,Avg.Loss: -1.265,LR: 4.15E-04]Training epoch 27:  97%|█████████▋| 109/112 [00:02<00:00, 53.76it/s, Epoch: 27, Batch: 110,Loss: -1.500,Avg.Loss: -1.267,LR: 4.15E-04]Training epoch 27:  98%|█████████▊| 110/112 [00:02<00:00, 53.76it/s, Epoch: 27, Batch: 111,Loss: -0.718,Avg.Loss: -1.262,LR: 4.15E-04]Training epoch 27:  99%|█████████▉| 111/112 [00:02<00:00, 53.76it/s, Epoch: 27, Batch: 112,Loss: -1.583,Avg.Loss: -1.265,LR: 4.15E-04]Training epoch 27: 100%|██████████| 112/112 [00:02<00:00, 53.21it/s, Epoch: 27, Batch: 112,Loss: -1.583,Avg.Loss: -1.265,LR: 4.15E-04]
Training epoch 28:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 28:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 28, Batch: 1,Loss: -1.993,Avg.Loss: -1.993,LR: 4.15E-04]Training epoch 28:   1%|          | 1/112 [00:00<00:04, 24.74it/s, Epoch: 28, Batch: 2,Loss: -1.148,Avg.Loss: -1.571,LR: 4.15E-04]Training epoch 28:   2%|▏         | 2/112 [00:00<00:03, 34.12it/s, Epoch: 28, Batch: 3,Loss: -2.096,Avg.Loss: -1.746,LR: 4.15E-04]Training epoch 28:   3%|▎         | 3/112 [00:00<00:02, 40.79it/s, Epoch: 28, Batch: 4,Loss: -1.628,Avg.Loss: -1.716,LR: 4.15E-04]Training epoch 28:   4%|▎         | 4/112 [00:00<00:02, 46.01it/s, Epoch: 28, Batch: 5,Loss: -0.460,Avg.Loss: -1.465,LR: 4.15E-04]Training epoch 28:   4%|▍         | 5/112 [00:00<00:02, 49.59it/s, Epoch: 28, Batch: 6,Loss: -1.839,Avg.Loss: -1.527,LR: 4.15E-04]Training epoch 28:   5%|▌         | 6/112 [00:00<00:01, 59.42it/s, Epoch: 28, Batch: 6,Loss: -1.839,Avg.Loss: -1.527,LR: 4.15E-04]Training epoch 28:   5%|▌         | 6/112 [00:00<00:01, 59.42it/s, Epoch: 28, Batch: 7,Loss: -1.662,Avg.Loss: -1.546,LR: 4.15E-04]Training epoch 28:   6%|▋         | 7/112 [00:00<00:01, 59.42it/s, Epoch: 28, Batch: 8,Loss: -1.743,Avg.Loss: -1.571,LR: 4.15E-04]Training epoch 28:   7%|▋         | 8/112 [00:00<00:01, 59.42it/s, Epoch: 28, Batch: 9,Loss: -2.043,Avg.Loss: -1.623,LR: 4.15E-04]Training epoch 28:   8%|▊         | 9/112 [00:00<00:01, 59.42it/s, Epoch: 28, Batch: 10,Loss: -1.419,Avg.Loss: -1.603,LR: 4.15E-04]Training epoch 28:   9%|▉         | 10/112 [00:00<00:01, 59.42it/s, Epoch: 28, Batch: 11,Loss: -0.629,Avg.Loss: -1.514,LR: 4.15E-04]Training epoch 28:  10%|▉         | 11/112 [00:00<00:01, 59.42it/s, Epoch: 28, Batch: 12,Loss: -1.605,Avg.Loss: -1.522,LR: 4.15E-04]Training epoch 28:  11%|█         | 12/112 [00:00<00:01, 58.43it/s, Epoch: 28, Batch: 12,Loss: -1.605,Avg.Loss: -1.522,LR: 4.15E-04]Training epoch 28:  11%|█         | 12/112 [00:00<00:01, 58.43it/s, Epoch: 28, Batch: 13,Loss: -1.925,Avg.Loss: -1.553,LR: 4.15E-04]Training epoch 28:  12%|█▏        | 13/112 [00:00<00:01, 58.43it/s, Epoch: 28, Batch: 14,Loss: -1.407,Avg.Loss: -1.543,LR: 4.15E-04]Training epoch 28:  12%|█▎        | 14/112 [00:00<00:01, 58.43it/s, Epoch: 28, Batch: 15,Loss: -2.074,Avg.Loss: -1.578,LR: 4.15E-04]Training epoch 28:  13%|█▎        | 15/112 [00:00<00:01, 58.43it/s, Epoch: 28, Batch: 16,Loss: -1.462,Avg.Loss: -1.571,LR: 4.14E-04]Training epoch 28:  14%|█▍        | 16/112 [00:00<00:01, 58.43it/s, Epoch: 28, Batch: 17,Loss: -0.808,Avg.Loss: -1.526,LR: 4.14E-04]Training epoch 28:  15%|█▌        | 17/112 [00:00<00:01, 58.43it/s, Epoch: 28, Batch: 18,Loss: -1.880,Avg.Loss: -1.546,LR: 4.14E-04]Training epoch 28:  16%|█▌        | 18/112 [00:00<00:01, 55.70it/s, Epoch: 28, Batch: 18,Loss: -1.880,Avg.Loss: -1.546,LR: 4.14E-04]Training epoch 28:  16%|█▌        | 18/112 [00:00<00:01, 55.70it/s, Epoch: 28, Batch: 19,Loss: -1.461,Avg.Loss: -1.541,LR: 4.14E-04]Training epoch 28:  17%|█▋        | 19/112 [00:00<00:01, 55.70it/s, Epoch: 28, Batch: 20,Loss: -1.422,Avg.Loss: -1.535,LR: 4.14E-04]Training epoch 28:  18%|█▊        | 20/112 [00:00<00:01, 55.70it/s, Epoch: 28, Batch: 21,Loss: -2.087,Avg.Loss: -1.561,LR: 4.14E-04]Training epoch 28:  19%|█▉        | 21/112 [00:00<00:01, 55.70it/s, Epoch: 28, Batch: 22,Loss: -1.507,Avg.Loss: -1.559,LR: 4.14E-04]Training epoch 28:  20%|█▉        | 22/112 [00:00<00:01, 55.70it/s, Epoch: 28, Batch: 23,Loss: -1.455,Avg.Loss: -1.554,LR: 4.14E-04]Training epoch 28:  21%|██        | 23/112 [00:00<00:01, 55.70it/s, Epoch: 28, Batch: 24,Loss: -1.548,Avg.Loss: -1.554,LR: 4.14E-04]Training epoch 28:  21%|██▏       | 24/112 [00:00<00:01, 54.37it/s, Epoch: 28, Batch: 24,Loss: -1.548,Avg.Loss: -1.554,LR: 4.14E-04]Training epoch 28:  21%|██▏       | 24/112 [00:00<00:01, 54.37it/s, Epoch: 28, Batch: 25,Loss: -1.750,Avg.Loss: -1.562,LR: 4.14E-04]Training epoch 28:  22%|██▏       | 25/112 [00:00<00:01, 54.37it/s, Epoch: 28, Batch: 26,Loss: -1.663,Avg.Loss: -1.566,LR: 4.14E-04]Training epoch 28:  23%|██▎       | 26/112 [00:00<00:01, 54.37it/s, Epoch: 28, Batch: 27,Loss: -2.035,Avg.Loss: -1.583,LR: 4.14E-04]Training epoch 28:  24%|██▍       | 27/112 [00:00<00:01, 54.37it/s, Epoch: 28, Batch: 28,Loss: -1.673,Avg.Loss: -1.586,LR: 4.14E-04]Training epoch 28:  25%|██▌       | 28/112 [00:00<00:01, 54.37it/s, Epoch: 28, Batch: 29,Loss: -1.075,Avg.Loss: -1.569,LR: 4.14E-04]Training epoch 28:  26%|██▌       | 29/112 [00:00<00:01, 54.37it/s, Epoch: 28, Batch: 30,Loss: -1.589,Avg.Loss: -1.569,LR: 4.14E-04]Training epoch 28:  27%|██▋       | 30/112 [00:00<00:01, 53.74it/s, Epoch: 28, Batch: 30,Loss: -1.589,Avg.Loss: -1.569,LR: 4.14E-04]Training epoch 28:  27%|██▋       | 30/112 [00:00<00:01, 53.74it/s, Epoch: 28, Batch: 31,Loss: -1.738,Avg.Loss: -1.575,LR: 4.14E-04]Training epoch 28:  28%|██▊       | 31/112 [00:00<00:01, 53.74it/s, Epoch: 28, Batch: 32,Loss: -1.098,Avg.Loss: -1.560,LR: 4.14E-04]Training epoch 28:  29%|██▊       | 32/112 [00:00<00:01, 53.74it/s, Epoch: 28, Batch: 33,Loss: -1.902,Avg.Loss: -1.570,LR: 4.14E-04]Training epoch 28:  29%|██▉       | 33/112 [00:00<00:01, 53.74it/s, Epoch: 28, Batch: 34,Loss: -1.754,Avg.Loss: -1.576,LR: 4.14E-04]Training epoch 28:  30%|███       | 34/112 [00:00<00:01, 53.74it/s, Epoch: 28, Batch: 35,Loss: -1.318,Avg.Loss: -1.568,LR: 4.13E-04]Training epoch 28:  31%|███▏      | 35/112 [00:00<00:01, 53.74it/s, Epoch: 28, Batch: 36,Loss: -2.113,Avg.Loss: -1.584,LR: 4.13E-04]Training epoch 28:  32%|███▏      | 36/112 [00:00<00:01, 53.41it/s, Epoch: 28, Batch: 36,Loss: -2.113,Avg.Loss: -1.584,LR: 4.13E-04]Training epoch 28:  32%|███▏      | 36/112 [00:00<00:01, 53.41it/s, Epoch: 28, Batch: 37,Loss: -1.558,Avg.Loss: -1.583,LR: 4.13E-04]Training epoch 28:  33%|███▎      | 37/112 [00:00<00:01, 53.41it/s, Epoch: 28, Batch: 38,Loss: -1.322,Avg.Loss: -1.576,LR: 4.13E-04]Training epoch 28:  34%|███▍      | 38/112 [00:00<00:01, 53.41it/s, Epoch: 28, Batch: 39,Loss: -2.111,Avg.Loss: -1.590,LR: 4.13E-04]Training epoch 28:  35%|███▍      | 39/112 [00:00<00:01, 53.41it/s, Epoch: 28, Batch: 40,Loss: -1.581,Avg.Loss: -1.589,LR: 4.13E-04]Training epoch 28:  36%|███▌      | 40/112 [00:00<00:01, 53.41it/s, Epoch: 28, Batch: 41,Loss: -1.341,Avg.Loss: -1.583,LR: 4.13E-04]Training epoch 28:  37%|███▋      | 41/112 [00:00<00:01, 53.41it/s, Epoch: 28, Batch: 42,Loss: -1.530,Avg.Loss: -1.582,LR: 4.13E-04]Training epoch 28:  38%|███▊      | 42/112 [00:00<00:01, 53.27it/s, Epoch: 28, Batch: 42,Loss: -1.530,Avg.Loss: -1.582,LR: 4.13E-04]Training epoch 28:  38%|███▊      | 42/112 [00:00<00:01, 53.27it/s, Epoch: 28, Batch: 43,Loss: -1.435,Avg.Loss: -1.579,LR: 4.13E-04]Training epoch 28:  38%|███▊      | 43/112 [00:00<00:01, 53.27it/s, Epoch: 28, Batch: 44,Loss: -1.431,Avg.Loss: -1.575,LR: 4.13E-04]Training epoch 28:  39%|███▉      | 44/112 [00:00<00:01, 53.27it/s, Epoch: 28, Batch: 45,Loss: -2.049,Avg.Loss: -1.586,LR: 4.13E-04]Training epoch 28:  40%|████      | 45/112 [00:00<00:01, 53.27it/s, Epoch: 28, Batch: 46,Loss: -2.222,Avg.Loss: -1.600,LR: 4.13E-04]Training epoch 28:  41%|████      | 46/112 [00:00<00:01, 53.27it/s, Epoch: 28, Batch: 47,Loss: -1.386,Avg.Loss: -1.595,LR: 4.13E-04]Training epoch 28:  42%|████▏     | 47/112 [00:00<00:01, 53.27it/s, Epoch: 28, Batch: 48,Loss: -1.844,Avg.Loss: -1.600,LR: 4.13E-04]Training epoch 28:  43%|████▎     | 48/112 [00:00<00:01, 53.17it/s, Epoch: 28, Batch: 48,Loss: -1.844,Avg.Loss: -1.600,LR: 4.13E-04]Training epoch 28:  43%|████▎     | 48/112 [00:00<00:01, 53.17it/s, Epoch: 28, Batch: 49,Loss: -1.628,Avg.Loss: -1.601,LR: 4.13E-04]Training epoch 28:  44%|████▍     | 49/112 [00:00<00:01, 53.17it/s, Epoch: 28, Batch: 50,Loss: -1.430,Avg.Loss: -1.597,LR: 4.13E-04]Training epoch 28:  45%|████▍     | 50/112 [00:00<00:01, 53.17it/s, Epoch: 28, Batch: 51,Loss: -2.002,Avg.Loss: -1.605,LR: 4.13E-04]Training epoch 28:  46%|████▌     | 51/112 [00:00<00:01, 53.17it/s, Epoch: 28, Batch: 52,Loss: -1.937,Avg.Loss: -1.612,LR: 4.13E-04]Training epoch 28:  46%|████▋     | 52/112 [00:00<00:01, 53.17it/s, Epoch: 28, Batch: 53,Loss: -1.087,Avg.Loss: -1.602,LR: 4.13E-04]Training epoch 28:  47%|████▋     | 53/112 [00:01<00:01, 53.17it/s, Epoch: 28, Batch: 54,Loss: -2.217,Avg.Loss: -1.613,LR: 4.12E-04]Training epoch 28:  48%|████▊     | 54/112 [00:01<00:01, 53.08it/s, Epoch: 28, Batch: 54,Loss: -2.217,Avg.Loss: -1.613,LR: 4.12E-04]Training epoch 28:  48%|████▊     | 54/112 [00:01<00:01, 53.08it/s, Epoch: 28, Batch: 55,Loss: -1.735,Avg.Loss: -1.615,LR: 4.12E-04]Training epoch 28:  49%|████▉     | 55/112 [00:01<00:01, 53.08it/s, Epoch: 28, Batch: 56,Loss: -1.351,Avg.Loss: -1.611,LR: 4.12E-04]Training epoch 28:  50%|█████     | 56/112 [00:01<00:01, 53.08it/s, Epoch: 28, Batch: 57,Loss: -1.623,Avg.Loss: -1.611,LR: 4.12E-04]Training epoch 28:  51%|█████     | 57/112 [00:01<00:01, 53.08it/s, Epoch: 28, Batch: 58,Loss: -1.440,Avg.Loss: -1.608,LR: 4.12E-04]Training epoch 28:  52%|█████▏    | 58/112 [00:01<00:01, 53.08it/s, Epoch: 28, Batch: 59,Loss: -1.519,Avg.Loss: -1.607,LR: 4.12E-04]Training epoch 28:  53%|█████▎    | 59/112 [00:01<00:00, 53.08it/s, Epoch: 28, Batch: 60,Loss: -1.802,Avg.Loss: -1.610,LR: 4.12E-04]Training epoch 28:  54%|█████▎    | 60/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 60,Loss: -1.802,Avg.Loss: -1.610,LR: 4.12E-04]Training epoch 28:  54%|█████▎    | 60/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 61,Loss: -1.902,Avg.Loss: -1.615,LR: 4.12E-04]Training epoch 28:  54%|█████▍    | 61/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 62,Loss: -1.295,Avg.Loss: -1.609,LR: 4.12E-04]Training epoch 28:  55%|█████▌    | 62/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 63,Loss: -1.845,Avg.Loss: -1.613,LR: 4.12E-04]Training epoch 28:  56%|█████▋    | 63/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 64,Loss: -1.739,Avg.Loss: -1.615,LR: 4.12E-04]Training epoch 28:  57%|█████▋    | 64/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 65,Loss: -1.280,Avg.Loss: -1.610,LR: 4.12E-04]Training epoch 28:  58%|█████▊    | 65/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 66,Loss: -1.902,Avg.Loss: -1.614,LR: 4.12E-04]Training epoch 28:  59%|█████▉    | 66/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 66,Loss: -1.902,Avg.Loss: -1.614,LR: 4.12E-04]Training epoch 28:  59%|█████▉    | 66/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 67,Loss: -1.928,Avg.Loss: -1.619,LR: 4.12E-04]Training epoch 28:  60%|█████▉    | 67/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 68,Loss: -1.811,Avg.Loss: -1.622,LR: 4.12E-04]Training epoch 28:  61%|██████    | 68/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 69,Loss: -1.727,Avg.Loss: -1.623,LR: 4.12E-04]Training epoch 28:  62%|██████▏   | 69/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 70,Loss: -1.947,Avg.Loss: -1.628,LR: 4.12E-04]Training epoch 28:  62%|██████▎   | 70/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 71,Loss: -1.076,Avg.Loss: -1.620,LR: 4.12E-04]Training epoch 28:  63%|██████▎   | 71/112 [00:01<00:00, 53.00it/s, Epoch: 28, Batch: 72,Loss: -1.605,Avg.Loss: -1.620,LR: 4.12E-04]Training epoch 28:  64%|██████▍   | 72/112 [00:01<00:00, 52.92it/s, Epoch: 28, Batch: 72,Loss: -1.605,Avg.Loss: -1.620,LR: 4.12E-04]Training epoch 28:  64%|██████▍   | 72/112 [00:01<00:00, 52.92it/s, Epoch: 28, Batch: 73,Loss: -1.827,Avg.Loss: -1.623,LR: 4.11E-04]Training epoch 28:  65%|██████▌   | 73/112 [00:01<00:00, 52.92it/s, Epoch: 28, Batch: 74,Loss: -1.302,Avg.Loss: -1.619,LR: 4.11E-04]Training epoch 28:  66%|██████▌   | 74/112 [00:01<00:00, 52.92it/s, Epoch: 28, Batch: 75,Loss: -1.930,Avg.Loss: -1.623,LR: 4.11E-04]Training epoch 28:  67%|██████▋   | 75/112 [00:01<00:00, 52.92it/s, Epoch: 28, Batch: 76,Loss: -1.664,Avg.Loss: -1.623,LR: 4.11E-04]Training epoch 28:  68%|██████▊   | 76/112 [00:01<00:00, 52.92it/s, Epoch: 28, Batch: 77,Loss: -1.365,Avg.Loss: -1.620,LR: 4.11E-04]Training epoch 28:  69%|██████▉   | 77/112 [00:01<00:00, 52.92it/s, Epoch: 28, Batch: 78,Loss: -1.920,Avg.Loss: -1.624,LR: 4.11E-04]Training epoch 28:  70%|██████▉   | 78/112 [00:01<00:00, 52.84it/s, Epoch: 28, Batch: 78,Loss: -1.920,Avg.Loss: -1.624,LR: 4.11E-04]Training epoch 28:  70%|██████▉   | 78/112 [00:01<00:00, 52.84it/s, Epoch: 28, Batch: 79,Loss: -1.800,Avg.Loss: -1.626,LR: 4.11E-04]Training epoch 28:  71%|███████   | 79/112 [00:01<00:00, 52.84it/s, Epoch: 28, Batch: 80,Loss: -1.301,Avg.Loss: -1.622,LR: 4.11E-04]Training epoch 28:  71%|███████▏  | 80/112 [00:01<00:00, 52.84it/s, Epoch: 28, Batch: 81,Loss: -2.091,Avg.Loss: -1.628,LR: 4.11E-04]Training epoch 28:  72%|███████▏  | 81/112 [00:01<00:00, 52.84it/s, Epoch: 28, Batch: 82,Loss: -1.770,Avg.Loss: -1.629,LR: 4.11E-04]Training epoch 28:  73%|███████▎  | 82/112 [00:01<00:00, 52.84it/s, Epoch: 28, Batch: 83,Loss: -1.298,Avg.Loss: -1.625,LR: 4.11E-04]Training epoch 28:  74%|███████▍  | 83/112 [00:01<00:00, 52.84it/s, Epoch: 28, Batch: 84,Loss: -1.987,Avg.Loss: -1.630,LR: 4.11E-04]Training epoch 28:  75%|███████▌  | 84/112 [00:01<00:00, 52.97it/s, Epoch: 28, Batch: 84,Loss: -1.987,Avg.Loss: -1.630,LR: 4.11E-04]Training epoch 28:  75%|███████▌  | 84/112 [00:01<00:00, 52.97it/s, Epoch: 28, Batch: 85,Loss: -1.666,Avg.Loss: -1.630,LR: 4.11E-04]Training epoch 28:  76%|███████▌  | 85/112 [00:01<00:00, 52.97it/s, Epoch: 28, Batch: 86,Loss: -1.248,Avg.Loss: -1.626,LR: 4.11E-04]Training epoch 28:  77%|███████▋  | 86/112 [00:01<00:00, 52.97it/s, Epoch: 28, Batch: 87,Loss: -1.751,Avg.Loss: -1.627,LR: 4.11E-04]Training epoch 28:  78%|███████▊  | 87/112 [00:01<00:00, 52.97it/s, Epoch: 28, Batch: 88,Loss: -1.852,Avg.Loss: -1.630,LR: 4.11E-04]Training epoch 28:  79%|███████▊  | 88/112 [00:01<00:00, 52.97it/s, Epoch: 28, Batch: 89,Loss: -1.081,Avg.Loss: -1.624,LR: 4.11E-04]Training epoch 28:  79%|███████▉  | 89/112 [00:01<00:00, 52.97it/s, Epoch: 28, Batch: 90,Loss: -1.567,Avg.Loss: -1.623,LR: 4.11E-04]Training epoch 28:  80%|████████  | 90/112 [00:01<00:00, 52.93it/s, Epoch: 28, Batch: 90,Loss: -1.567,Avg.Loss: -1.623,LR: 4.11E-04]Training epoch 28:  80%|████████  | 90/112 [00:01<00:00, 52.93it/s, Epoch: 28, Batch: 91,Loss: -1.726,Avg.Loss: -1.624,LR: 4.10E-04]Training epoch 28:  81%|████████▏ | 91/112 [00:01<00:00, 52.93it/s, Epoch: 28, Batch: 92,Loss: -1.599,Avg.Loss: -1.624,LR: 4.10E-04]Training epoch 28:  82%|████████▏ | 92/112 [00:01<00:00, 52.93it/s, Epoch: 28, Batch: 93,Loss: -2.045,Avg.Loss: -1.628,LR: 4.10E-04]Training epoch 28:  83%|████████▎ | 93/112 [00:01<00:00, 52.93it/s, Epoch: 28, Batch: 94,Loss: -1.744,Avg.Loss: -1.630,LR: 4.10E-04]Training epoch 28:  84%|████████▍ | 94/112 [00:01<00:00, 52.93it/s, Epoch: 28, Batch: 95,Loss: -1.333,Avg.Loss: -1.626,LR: 4.10E-04]Training epoch 28:  85%|████████▍ | 95/112 [00:01<00:00, 52.93it/s, Epoch: 28, Batch: 96,Loss: -1.888,Avg.Loss: -1.629,LR: 4.10E-04]Training epoch 28:  86%|████████▌ | 96/112 [00:01<00:00, 52.75it/s, Epoch: 28, Batch: 96,Loss: -1.888,Avg.Loss: -1.629,LR: 4.10E-04]Training epoch 28:  86%|████████▌ | 96/112 [00:01<00:00, 52.75it/s, Epoch: 28, Batch: 97,Loss: -2.039,Avg.Loss: -1.633,LR: 4.10E-04]Training epoch 28:  87%|████████▋ | 97/112 [00:01<00:00, 52.75it/s, Epoch: 28, Batch: 98,Loss: -1.264,Avg.Loss: -1.630,LR: 4.10E-04]Training epoch 28:  88%|████████▊ | 98/112 [00:01<00:00, 52.75it/s, Epoch: 28, Batch: 99,Loss: -1.877,Avg.Loss: -1.632,LR: 4.10E-04]Training epoch 28:  88%|████████▊ | 99/112 [00:01<00:00, 52.75it/s, Epoch: 28, Batch: 100,Loss: -2.025,Avg.Loss: -1.636,LR: 4.10E-04]Training epoch 28:  89%|████████▉ | 100/112 [00:01<00:00, 52.75it/s, Epoch: 28, Batch: 101,Loss: -1.426,Avg.Loss: -1.634,LR: 4.10E-04]Training epoch 28:  90%|█████████ | 101/112 [00:01<00:00, 52.75it/s, Epoch: 28, Batch: 102,Loss: -1.849,Avg.Loss: -1.636,LR: 4.10E-04]Training epoch 28:  91%|█████████ | 102/112 [00:01<00:00, 52.72it/s, Epoch: 28, Batch: 102,Loss: -1.849,Avg.Loss: -1.636,LR: 4.10E-04]Training epoch 28:  91%|█████████ | 102/112 [00:01<00:00, 52.72it/s, Epoch: 28, Batch: 103,Loss: -1.628,Avg.Loss: -1.636,LR: 4.10E-04]Training epoch 28:  92%|█████████▏| 103/112 [00:01<00:00, 52.72it/s, Epoch: 28, Batch: 104,Loss: -1.405,Avg.Loss: -1.634,LR: 4.10E-04]Training epoch 28:  93%|█████████▎| 104/112 [00:01<00:00, 52.72it/s, Epoch: 28, Batch: 105,Loss: -1.707,Avg.Loss: -1.634,LR: 4.10E-04]Training epoch 28:  94%|█████████▍| 105/112 [00:01<00:00, 52.72it/s, Epoch: 28, Batch: 106,Loss: -1.997,Avg.Loss: -1.638,LR: 4.10E-04]Training epoch 28:  95%|█████████▍| 106/112 [00:02<00:00, 52.72it/s, Epoch: 28, Batch: 107,Loss: -1.468,Avg.Loss: -1.636,LR: 4.10E-04]Training epoch 28:  96%|█████████▌| 107/112 [00:02<00:00, 52.72it/s, Epoch: 28, Batch: 108,Loss: -2.232,Avg.Loss: -1.642,LR: 4.10E-04]Training epoch 28:  96%|█████████▋| 108/112 [00:02<00:00, 52.93it/s, Epoch: 28, Batch: 108,Loss: -2.232,Avg.Loss: -1.642,LR: 4.10E-04]Training epoch 28:  96%|█████████▋| 108/112 [00:02<00:00, 52.93it/s, Epoch: 28, Batch: 109,Loss: -1.641,Avg.Loss: -1.642,LR: 4.10E-04]Training epoch 28:  97%|█████████▋| 109/112 [00:02<00:00, 52.93it/s, Epoch: 28, Batch: 110,Loss: -1.126,Avg.Loss: -1.637,LR: 4.09E-04]Training epoch 28:  98%|█████████▊| 110/112 [00:02<00:00, 52.93it/s, Epoch: 28, Batch: 111,Loss: -1.691,Avg.Loss: -1.638,LR: 4.09E-04]Training epoch 28:  99%|█████████▉| 111/112 [00:02<00:00, 52.93it/s, Epoch: 28, Batch: 112,Loss: -1.556,Avg.Loss: -1.637,LR: 4.09E-04]Training epoch 28: 100%|██████████| 112/112 [00:02<00:00, 53.32it/s, Epoch: 28, Batch: 112,Loss: -1.556,Avg.Loss: -1.637,LR: 4.09E-04]
Training epoch 29:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 29:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 29, Batch: 1,Loss: -0.055,Avg.Loss: -0.055,LR: 4.09E-04]Training epoch 29:   1%|          | 1/112 [00:00<00:04, 26.49it/s, Epoch: 29, Batch: 2,Loss: 3.975,Avg.Loss: 1.960,LR: 4.09E-04]Training epoch 29:   2%|▏         | 2/112 [00:00<00:03, 33.05it/s, Epoch: 29, Batch: 3,Loss: 3.318,Avg.Loss: 2.413,LR: 4.09E-04]Training epoch 29:   3%|▎         | 3/112 [00:00<00:02, 38.66it/s, Epoch: 29, Batch: 4,Loss: 3.280,Avg.Loss: 2.629,LR: 4.09E-04]Training epoch 29:   4%|▎         | 4/112 [00:00<00:02, 42.67it/s, Epoch: 29, Batch: 5,Loss: 1.910,Avg.Loss: 2.486,LR: 4.09E-04]Training epoch 29:   4%|▍         | 5/112 [00:00<00:02, 46.95it/s, Epoch: 29, Batch: 6,Loss: 2.662,Avg.Loss: 2.515,LR: 4.09E-04]Training epoch 29:   5%|▌         | 6/112 [00:00<00:01, 56.27it/s, Epoch: 29, Batch: 6,Loss: 2.662,Avg.Loss: 2.515,LR: 4.09E-04]Training epoch 29:   5%|▌         | 6/112 [00:00<00:01, 56.27it/s, Epoch: 29, Batch: 7,Loss: -0.170,Avg.Loss: 2.131,LR: 4.09E-04]Training epoch 29:   6%|▋         | 7/112 [00:00<00:01, 56.27it/s, Epoch: 29, Batch: 8,Loss: -0.498,Avg.Loss: 1.803,LR: 4.09E-04]Training epoch 29:   7%|▋         | 8/112 [00:00<00:01, 56.27it/s, Epoch: 29, Batch: 9,Loss: -1.035,Avg.Loss: 1.487,LR: 4.09E-04]Training epoch 29:   8%|▊         | 9/112 [00:00<00:01, 56.27it/s, Epoch: 29, Batch: 10,Loss: 0.324,Avg.Loss: 1.371,LR: 4.09E-04]Training epoch 29:   9%|▉         | 10/112 [00:00<00:01, 56.27it/s, Epoch: 29, Batch: 11,Loss: -0.734,Avg.Loss: 1.180,LR: 4.09E-04]Training epoch 29:  10%|▉         | 11/112 [00:00<00:01, 56.27it/s, Epoch: 29, Batch: 12,Loss: -0.355,Avg.Loss: 1.052,LR: 4.09E-04]Training epoch 29:  11%|█         | 12/112 [00:00<00:01, 55.83it/s, Epoch: 29, Batch: 12,Loss: -0.355,Avg.Loss: 1.052,LR: 4.09E-04]Training epoch 29:  11%|█         | 12/112 [00:00<00:01, 55.83it/s, Epoch: 29, Batch: 13,Loss: -0.460,Avg.Loss: 0.936,LR: 4.09E-04]Training epoch 29:  12%|█▏        | 13/112 [00:00<00:01, 55.83it/s, Epoch: 29, Batch: 14,Loss: -0.768,Avg.Loss: 0.814,LR: 4.09E-04]Training epoch 29:  12%|█▎        | 14/112 [00:00<00:01, 55.83it/s, Epoch: 29, Batch: 15,Loss: -1.435,Avg.Loss: 0.664,LR: 4.09E-04]Training epoch 29:  13%|█▎        | 15/112 [00:00<00:01, 55.83it/s, Epoch: 29, Batch: 16,Loss: -0.007,Avg.Loss: 0.622,LR: 4.08E-04]Training epoch 29:  14%|█▍        | 16/112 [00:00<00:01, 55.83it/s, Epoch: 29, Batch: 17,Loss: 0.481,Avg.Loss: 0.614,LR: 4.08E-04] Training epoch 29:  15%|█▌        | 17/112 [00:00<00:01, 55.83it/s, Epoch: 29, Batch: 18,Loss: 1.416,Avg.Loss: 0.658,LR: 4.08E-04]Training epoch 29:  16%|█▌        | 18/112 [00:00<00:01, 54.47it/s, Epoch: 29, Batch: 18,Loss: 1.416,Avg.Loss: 0.658,LR: 4.08E-04]Training epoch 29:  16%|█▌        | 18/112 [00:00<00:01, 54.47it/s, Epoch: 29, Batch: 19,Loss: -0.749,Avg.Loss: 0.584,LR: 4.08E-04]Training epoch 29:  17%|█▋        | 19/112 [00:00<00:01, 54.47it/s, Epoch: 29, Batch: 20,Loss: -1.061,Avg.Loss: 0.502,LR: 4.08E-04]Training epoch 29:  18%|█▊        | 20/112 [00:00<00:01, 54.47it/s, Epoch: 29, Batch: 21,Loss: -0.236,Avg.Loss: 0.467,LR: 4.08E-04]Training epoch 29:  19%|█▉        | 21/112 [00:00<00:01, 54.47it/s, Epoch: 29, Batch: 22,Loss: -0.976,Avg.Loss: 0.401,LR: 4.08E-04]Training epoch 29:  20%|█▉        | 22/112 [00:00<00:01, 54.47it/s, Epoch: 29, Batch: 23,Loss: -1.472,Avg.Loss: 0.320,LR: 4.08E-04]Training epoch 29:  21%|██        | 23/112 [00:00<00:01, 54.47it/s, Epoch: 29, Batch: 24,Loss: -0.759,Avg.Loss: 0.275,LR: 4.08E-04]Training epoch 29:  21%|██▏       | 24/112 [00:00<00:01, 53.32it/s, Epoch: 29, Batch: 24,Loss: -0.759,Avg.Loss: 0.275,LR: 4.08E-04]Training epoch 29:  21%|██▏       | 24/112 [00:00<00:01, 53.32it/s, Epoch: 29, Batch: 25,Loss: -0.154,Avg.Loss: 0.258,LR: 4.08E-04]Training epoch 29:  22%|██▏       | 25/112 [00:00<00:01, 53.32it/s, Epoch: 29, Batch: 26,Loss: 0.259,Avg.Loss: 0.258,LR: 4.08E-04] Training epoch 29:  23%|██▎       | 26/112 [00:00<00:01, 53.32it/s, Epoch: 29, Batch: 27,Loss: -1.243,Avg.Loss: 0.202,LR: 4.08E-04]Training epoch 29:  24%|██▍       | 27/112 [00:00<00:01, 53.32it/s, Epoch: 29, Batch: 28,Loss: -0.610,Avg.Loss: 0.173,LR: 4.08E-04]Training epoch 29:  25%|██▌       | 28/112 [00:00<00:01, 53.32it/s, Epoch: 29, Batch: 29,Loss: 0.255,Avg.Loss: 0.176,LR: 4.08E-04] Training epoch 29:  26%|██▌       | 29/112 [00:00<00:01, 53.32it/s, Epoch: 29, Batch: 30,Loss: -0.424,Avg.Loss: 0.156,LR: 4.08E-04]Training epoch 29:  27%|██▋       | 30/112 [00:00<00:01, 52.94it/s, Epoch: 29, Batch: 30,Loss: -0.424,Avg.Loss: 0.156,LR: 4.08E-04]Training epoch 29:  27%|██▋       | 30/112 [00:00<00:01, 52.94it/s, Epoch: 29, Batch: 31,Loss: -1.170,Avg.Loss: 0.113,LR: 4.08E-04]Training epoch 29:  28%|██▊       | 31/112 [00:00<00:01, 52.94it/s, Epoch: 29, Batch: 32,Loss: -1.207,Avg.Loss: 0.072,LR: 4.08E-04]Training epoch 29:  29%|██▊       | 32/112 [00:00<00:01, 52.94it/s, Epoch: 29, Batch: 33,Loss: -0.764,Avg.Loss: 0.047,LR: 4.08E-04]Training epoch 29:  29%|██▉       | 33/112 [00:00<00:01, 52.94it/s, Epoch: 29, Batch: 34,Loss: -0.562,Avg.Loss: 0.029,LR: 4.08E-04]Training epoch 29:  30%|███       | 34/112 [00:00<00:01, 52.94it/s, Epoch: 29, Batch: 35,Loss: -1.564,Avg.Loss: -0.017,LR: 4.07E-04]Training epoch 29:  31%|███▏      | 35/112 [00:00<00:01, 52.94it/s, Epoch: 29, Batch: 36,Loss: -1.161,Avg.Loss: -0.049,LR: 4.07E-04]Training epoch 29:  32%|███▏      | 36/112 [00:00<00:01, 53.07it/s, Epoch: 29, Batch: 36,Loss: -1.161,Avg.Loss: -0.049,LR: 4.07E-04]Training epoch 29:  32%|███▏      | 36/112 [00:00<00:01, 53.07it/s, Epoch: 29, Batch: 37,Loss: -0.218,Avg.Loss: -0.053,LR: 4.07E-04]Training epoch 29:  33%|███▎      | 37/112 [00:00<00:01, 53.07it/s, Epoch: 29, Batch: 38,Loss: -1.112,Avg.Loss: -0.081,LR: 4.07E-04]Training epoch 29:  34%|███▍      | 38/112 [00:00<00:01, 53.07it/s, Epoch: 29, Batch: 39,Loss: -1.737,Avg.Loss: -0.123,LR: 4.07E-04]Training epoch 29:  35%|███▍      | 39/112 [00:00<00:01, 53.07it/s, Epoch: 29, Batch: 40,Loss: -1.291,Avg.Loss: -0.153,LR: 4.07E-04]Training epoch 29:  36%|███▌      | 40/112 [00:00<00:01, 53.07it/s, Epoch: 29, Batch: 41,Loss: -0.574,Avg.Loss: -0.163,LR: 4.07E-04]Training epoch 29:  37%|███▋      | 41/112 [00:00<00:01, 53.07it/s, Epoch: 29, Batch: 42,Loss: -1.022,Avg.Loss: -0.183,LR: 4.07E-04]Training epoch 29:  38%|███▊      | 42/112 [00:00<00:01, 53.41it/s, Epoch: 29, Batch: 42,Loss: -1.022,Avg.Loss: -0.183,LR: 4.07E-04]Training epoch 29:  38%|███▊      | 42/112 [00:00<00:01, 53.41it/s, Epoch: 29, Batch: 43,Loss: -1.575,Avg.Loss: -0.216,LR: 4.07E-04]Training epoch 29:  38%|███▊      | 43/112 [00:00<00:01, 53.41it/s, Epoch: 29, Batch: 44,Loss: -0.759,Avg.Loss: -0.228,LR: 4.07E-04]Training epoch 29:  39%|███▉      | 44/112 [00:00<00:01, 53.41it/s, Epoch: 29, Batch: 45,Loss: -0.142,Avg.Loss: -0.226,LR: 4.07E-04]Training epoch 29:  40%|████      | 45/112 [00:00<00:01, 53.41it/s, Epoch: 29, Batch: 46,Loss: -0.346,Avg.Loss: -0.229,LR: 4.07E-04]Training epoch 29:  41%|████      | 46/112 [00:00<00:01, 53.41it/s, Epoch: 29, Batch: 47,Loss: -1.096,Avg.Loss: -0.247,LR: 4.07E-04]Training epoch 29:  42%|████▏     | 47/112 [00:00<00:01, 53.41it/s, Epoch: 29, Batch: 48,Loss: -1.507,Avg.Loss: -0.273,LR: 4.07E-04]Training epoch 29:  43%|████▎     | 48/112 [00:00<00:01, 53.48it/s, Epoch: 29, Batch: 48,Loss: -1.507,Avg.Loss: -0.273,LR: 4.07E-04]Training epoch 29:  43%|████▎     | 48/112 [00:00<00:01, 53.48it/s, Epoch: 29, Batch: 49,Loss: -0.198,Avg.Loss: -0.272,LR: 4.07E-04]Training epoch 29:  44%|████▍     | 49/112 [00:00<00:01, 53.48it/s, Epoch: 29, Batch: 50,Loss: -0.779,Avg.Loss: -0.282,LR: 4.07E-04]Training epoch 29:  45%|████▍     | 50/112 [00:00<00:01, 53.48it/s, Epoch: 29, Batch: 51,Loss: -1.309,Avg.Loss: -0.302,LR: 4.07E-04]Training epoch 29:  46%|████▌     | 51/112 [00:00<00:01, 53.48it/s, Epoch: 29, Batch: 52,Loss: -1.074,Avg.Loss: -0.317,LR: 4.07E-04]Training epoch 29:  46%|████▋     | 52/112 [00:00<00:01, 53.48it/s, Epoch: 29, Batch: 53,Loss: -0.723,Avg.Loss: -0.325,LR: 4.06E-04]Training epoch 29:  47%|████▋     | 53/112 [00:01<00:01, 53.48it/s, Epoch: 29, Batch: 54,Loss: -0.678,Avg.Loss: -0.331,LR: 4.06E-04]Training epoch 29:  48%|████▊     | 54/112 [00:01<00:01, 53.61it/s, Epoch: 29, Batch: 54,Loss: -0.678,Avg.Loss: -0.331,LR: 4.06E-04]Training epoch 29:  48%|████▊     | 54/112 [00:01<00:01, 53.61it/s, Epoch: 29, Batch: 55,Loss: -1.819,Avg.Loss: -0.358,LR: 4.06E-04]Training epoch 29:  49%|████▉     | 55/112 [00:01<00:01, 53.61it/s, Epoch: 29, Batch: 56,Loss: -1.172,Avg.Loss: -0.373,LR: 4.06E-04]Training epoch 29:  50%|█████     | 56/112 [00:01<00:01, 53.61it/s, Epoch: 29, Batch: 57,Loss: -0.436,Avg.Loss: -0.374,LR: 4.06E-04]Training epoch 29:  51%|█████     | 57/112 [00:01<00:01, 53.61it/s, Epoch: 29, Batch: 58,Loss: -0.531,Avg.Loss: -0.377,LR: 4.06E-04]Training epoch 29:  52%|█████▏    | 58/112 [00:01<00:01, 53.61it/s, Epoch: 29, Batch: 59,Loss: -1.501,Avg.Loss: -0.396,LR: 4.06E-04]Training epoch 29:  53%|█████▎    | 59/112 [00:01<00:00, 53.61it/s, Epoch: 29, Batch: 60,Loss: -1.382,Avg.Loss: -0.412,LR: 4.06E-04]Training epoch 29:  54%|█████▎    | 60/112 [00:01<00:00, 53.70it/s, Epoch: 29, Batch: 60,Loss: -1.382,Avg.Loss: -0.412,LR: 4.06E-04]Training epoch 29:  54%|█████▎    | 60/112 [00:01<00:00, 53.70it/s, Epoch: 29, Batch: 61,Loss: -0.824,Avg.Loss: -0.419,LR: 4.06E-04]Training epoch 29:  54%|█████▍    | 61/112 [00:01<00:00, 53.70it/s, Epoch: 29, Batch: 62,Loss: -0.918,Avg.Loss: -0.427,LR: 4.06E-04]Training epoch 29:  55%|█████▌    | 62/112 [00:01<00:00, 53.70it/s, Epoch: 29, Batch: 63,Loss: -1.769,Avg.Loss: -0.448,LR: 4.06E-04]Training epoch 29:  56%|█████▋    | 63/112 [00:01<00:00, 53.70it/s, Epoch: 29, Batch: 64,Loss: -1.644,Avg.Loss: -0.467,LR: 4.06E-04]Training epoch 29:  57%|█████▋    | 64/112 [00:01<00:00, 53.70it/s, Epoch: 29, Batch: 65,Loss: -0.341,Avg.Loss: -0.465,LR: 4.06E-04]Training epoch 29:  58%|█████▊    | 65/112 [00:01<00:00, 53.70it/s, Epoch: 29, Batch: 66,Loss: -1.020,Avg.Loss: -0.473,LR: 4.06E-04]Training epoch 29:  59%|█████▉    | 66/112 [00:01<00:00, 53.78it/s, Epoch: 29, Batch: 66,Loss: -1.020,Avg.Loss: -0.473,LR: 4.06E-04]Training epoch 29:  59%|█████▉    | 66/112 [00:01<00:00, 53.78it/s, Epoch: 29, Batch: 67,Loss: -1.762,Avg.Loss: -0.493,LR: 4.06E-04]Training epoch 29:  60%|█████▉    | 67/112 [00:01<00:00, 53.78it/s, Epoch: 29, Batch: 68,Loss: -1.433,Avg.Loss: -0.506,LR: 4.06E-04]Training epoch 29:  61%|██████    | 68/112 [00:01<00:00, 53.78it/s, Epoch: 29, Batch: 69,Loss: -0.886,Avg.Loss: -0.512,LR: 4.06E-04]Training epoch 29:  62%|██████▏   | 69/112 [00:01<00:00, 53.78it/s, Epoch: 29, Batch: 70,Loss: -0.922,Avg.Loss: -0.518,LR: 4.06E-04]Training epoch 29:  62%|██████▎   | 70/112 [00:01<00:00, 53.78it/s, Epoch: 29, Batch: 71,Loss: -1.429,Avg.Loss: -0.531,LR: 4.05E-04]Training epoch 29:  63%|██████▎   | 71/112 [00:01<00:00, 53.78it/s, Epoch: 29, Batch: 72,Loss: -1.468,Avg.Loss: -0.544,LR: 4.05E-04]Training epoch 29:  64%|██████▍   | 72/112 [00:01<00:00, 53.63it/s, Epoch: 29, Batch: 72,Loss: -1.468,Avg.Loss: -0.544,LR: 4.05E-04]Training epoch 29:  64%|██████▍   | 72/112 [00:01<00:00, 53.63it/s, Epoch: 29, Batch: 73,Loss: -0.861,Avg.Loss: -0.548,LR: 4.05E-04]Training epoch 29:  65%|██████▌   | 73/112 [00:01<00:00, 53.63it/s, Epoch: 29, Batch: 74,Loss: -1.363,Avg.Loss: -0.559,LR: 4.05E-04]Training epoch 29:  66%|██████▌   | 74/112 [00:01<00:00, 53.63it/s, Epoch: 29, Batch: 75,Loss: -1.465,Avg.Loss: -0.571,LR: 4.05E-04]Training epoch 29:  67%|██████▋   | 75/112 [00:01<00:00, 53.63it/s, Epoch: 29, Batch: 76,Loss: -1.338,Avg.Loss: -0.581,LR: 4.05E-04]Training epoch 29:  68%|██████▊   | 76/112 [00:01<00:00, 53.63it/s, Epoch: 29, Batch: 77,Loss: -0.286,Avg.Loss: -0.577,LR: 4.05E-04]Training epoch 29:  69%|██████▉   | 77/112 [00:01<00:00, 53.63it/s, Epoch: 29, Batch: 78,Loss: -1.139,Avg.Loss: -0.585,LR: 4.05E-04]Training epoch 29:  70%|██████▉   | 78/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 78,Loss: -1.139,Avg.Loss: -0.585,LR: 4.05E-04]Training epoch 29:  70%|██████▉   | 78/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 79,Loss: -1.637,Avg.Loss: -0.598,LR: 4.05E-04]Training epoch 29:  71%|███████   | 79/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 80,Loss: -1.388,Avg.Loss: -0.608,LR: 4.05E-04]Training epoch 29:  71%|███████▏  | 80/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 81,Loss: -0.511,Avg.Loss: -0.607,LR: 4.05E-04]Training epoch 29:  72%|███████▏  | 81/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 82,Loss: -0.734,Avg.Loss: -0.608,LR: 4.05E-04]Training epoch 29:  73%|███████▎  | 82/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 83,Loss: -0.997,Avg.Loss: -0.613,LR: 4.05E-04]Training epoch 29:  74%|███████▍  | 83/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 84,Loss: -1.399,Avg.Loss: -0.622,LR: 4.05E-04]Training epoch 29:  75%|███████▌  | 84/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 84,Loss: -1.399,Avg.Loss: -0.622,LR: 4.05E-04]Training epoch 29:  75%|███████▌  | 84/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 85,Loss: -1.201,Avg.Loss: -0.629,LR: 4.05E-04]Training epoch 29:  76%|███████▌  | 85/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 86,Loss: -1.530,Avg.Loss: -0.639,LR: 4.05E-04]Training epoch 29:  77%|███████▋  | 86/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 87,Loss: -1.348,Avg.Loss: -0.648,LR: 4.05E-04]Training epoch 29:  78%|███████▊  | 87/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 88,Loss: -0.921,Avg.Loss: -0.651,LR: 4.05E-04]Training epoch 29:  79%|███████▊  | 88/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 89,Loss: -1.628,Avg.Loss: -0.662,LR: 4.04E-04]Training epoch 29:  79%|███████▉  | 89/112 [00:01<00:00, 53.45it/s, Epoch: 29, Batch: 90,Loss: -1.922,Avg.Loss: -0.676,LR: 4.04E-04]Training epoch 29:  80%|████████  | 90/112 [00:01<00:00, 53.66it/s, Epoch: 29, Batch: 90,Loss: -1.922,Avg.Loss: -0.676,LR: 4.04E-04]Training epoch 29:  80%|████████  | 90/112 [00:01<00:00, 53.66it/s, Epoch: 29, Batch: 91,Loss: -1.969,Avg.Loss: -0.690,LR: 4.04E-04]Training epoch 29:  81%|████████▏ | 91/112 [00:01<00:00, 53.66it/s, Epoch: 29, Batch: 92,Loss: -1.841,Avg.Loss: -0.702,LR: 4.04E-04]Training epoch 29:  82%|████████▏ | 92/112 [00:01<00:00, 53.66it/s, Epoch: 29, Batch: 93,Loss: -1.337,Avg.Loss: -0.709,LR: 4.04E-04]Training epoch 29:  83%|████████▎ | 93/112 [00:01<00:00, 53.66it/s, Epoch: 29, Batch: 94,Loss: -1.040,Avg.Loss: -0.713,LR: 4.04E-04]Training epoch 29:  84%|████████▍ | 94/112 [00:01<00:00, 53.66it/s, Epoch: 29, Batch: 95,Loss: -1.930,Avg.Loss: -0.726,LR: 4.04E-04]Training epoch 29:  85%|████████▍ | 95/112 [00:01<00:00, 53.66it/s, Epoch: 29, Batch: 96,Loss: -1.550,Avg.Loss: -0.734,LR: 4.04E-04]Training epoch 29:  86%|████████▌ | 96/112 [00:01<00:00, 53.72it/s, Epoch: 29, Batch: 96,Loss: -1.550,Avg.Loss: -0.734,LR: 4.04E-04]Training epoch 29:  86%|████████▌ | 96/112 [00:01<00:00, 53.72it/s, Epoch: 29, Batch: 97,Loss: -1.013,Avg.Loss: -0.737,LR: 4.04E-04]Training epoch 29:  87%|████████▋ | 97/112 [00:01<00:00, 53.72it/s, Epoch: 29, Batch: 98,Loss: -1.520,Avg.Loss: -0.745,LR: 4.04E-04]Training epoch 29:  88%|████████▊ | 98/112 [00:01<00:00, 53.72it/s, Epoch: 29, Batch: 99,Loss: -1.819,Avg.Loss: -0.756,LR: 4.04E-04]Training epoch 29:  88%|████████▊ | 99/112 [00:01<00:00, 53.72it/s, Epoch: 29, Batch: 100,Loss: -1.872,Avg.Loss: -0.767,LR: 4.04E-04]Training epoch 29:  89%|████████▉ | 100/112 [00:01<00:00, 53.72it/s, Epoch: 29, Batch: 101,Loss: -1.731,Avg.Loss: -0.777,LR: 4.04E-04]Training epoch 29:  90%|█████████ | 101/112 [00:01<00:00, 53.72it/s, Epoch: 29, Batch: 102,Loss: -2.016,Avg.Loss: -0.789,LR: 4.04E-04]Training epoch 29:  91%|█████████ | 102/112 [00:01<00:00, 53.87it/s, Epoch: 29, Batch: 102,Loss: -2.016,Avg.Loss: -0.789,LR: 4.04E-04]Training epoch 29:  91%|█████████ | 102/112 [00:01<00:00, 53.87it/s, Epoch: 29, Batch: 103,Loss: -1.988,Avg.Loss: -0.800,LR: 4.04E-04]Training epoch 29:  92%|█████████▏| 103/112 [00:01<00:00, 53.87it/s, Epoch: 29, Batch: 104,Loss: -1.885,Avg.Loss: -0.811,LR: 4.04E-04]Training epoch 29:  93%|█████████▎| 104/112 [00:01<00:00, 53.87it/s, Epoch: 29, Batch: 105,Loss: -1.555,Avg.Loss: -0.818,LR: 4.04E-04]Training epoch 29:  94%|█████████▍| 105/112 [00:01<00:00, 53.87it/s, Epoch: 29, Batch: 106,Loss: -1.985,Avg.Loss: -0.829,LR: 4.04E-04]Training epoch 29:  95%|█████████▍| 106/112 [00:01<00:00, 53.87it/s, Epoch: 29, Batch: 107,Loss: -1.867,Avg.Loss: -0.839,LR: 4.04E-04]Training epoch 29:  96%|█████████▌| 107/112 [00:02<00:00, 53.87it/s, Epoch: 29, Batch: 108,Loss: -1.663,Avg.Loss: -0.846,LR: 4.03E-04]Training epoch 29:  96%|█████████▋| 108/112 [00:02<00:00, 53.76it/s, Epoch: 29, Batch: 108,Loss: -1.663,Avg.Loss: -0.846,LR: 4.03E-04]Training epoch 29:  96%|█████████▋| 108/112 [00:02<00:00, 53.76it/s, Epoch: 29, Batch: 109,Loss: -1.971,Avg.Loss: -0.857,LR: 4.03E-04]Training epoch 29:  97%|█████████▋| 109/112 [00:02<00:00, 53.76it/s, Epoch: 29, Batch: 110,Loss: -1.731,Avg.Loss: -0.865,LR: 4.03E-04]Training epoch 29:  98%|█████████▊| 110/112 [00:02<00:00, 53.76it/s, Epoch: 29, Batch: 111,Loss: -2.134,Avg.Loss: -0.876,LR: 4.03E-04]Training epoch 29:  99%|█████████▉| 111/112 [00:02<00:00, 53.76it/s, Epoch: 29, Batch: 112,Loss: -1.705,Avg.Loss: -0.883,LR: 4.03E-04]Training epoch 29: 100%|██████████| 112/112 [00:02<00:00, 53.64it/s, Epoch: 29, Batch: 112,Loss: -1.705,Avg.Loss: -0.883,LR: 4.03E-04]
Training epoch 30:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 30:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 30, Batch: 1,Loss: -0.359,Avg.Loss: -0.359,LR: 4.03E-04]Training epoch 30:   1%|          | 1/112 [00:00<00:04, 25.07it/s, Epoch: 30, Batch: 2,Loss: -1.430,Avg.Loss: -0.894,LR: 4.03E-04]Training epoch 30:   2%|▏         | 2/112 [00:00<00:03, 36.00it/s, Epoch: 30, Batch: 3,Loss: -0.851,Avg.Loss: -0.880,LR: 4.03E-04]Training epoch 30:   3%|▎         | 3/112 [00:00<00:02, 41.99it/s, Epoch: 30, Batch: 4,Loss: -1.100,Avg.Loss: -0.935,LR: 4.03E-04]Training epoch 30:   4%|▎         | 4/112 [00:00<00:02, 46.18it/s, Epoch: 30, Batch: 5,Loss: -1.863,Avg.Loss: -1.120,LR: 4.03E-04]Training epoch 30:   4%|▍         | 5/112 [00:00<00:02, 49.95it/s, Epoch: 30, Batch: 6,Loss: -1.829,Avg.Loss: -1.239,LR: 4.03E-04]Training epoch 30:   5%|▌         | 6/112 [00:00<00:01, 59.86it/s, Epoch: 30, Batch: 6,Loss: -1.829,Avg.Loss: -1.239,LR: 4.03E-04]Training epoch 30:   5%|▌         | 6/112 [00:00<00:01, 59.86it/s, Epoch: 30, Batch: 7,Loss: -0.780,Avg.Loss: -1.173,LR: 4.03E-04]Training epoch 30:   6%|▋         | 7/112 [00:00<00:01, 59.86it/s, Epoch: 30, Batch: 8,Loss: -1.636,Avg.Loss: -1.231,LR: 4.03E-04]Training epoch 30:   7%|▋         | 8/112 [00:00<00:01, 59.86it/s, Epoch: 30, Batch: 9,Loss: -2.042,Avg.Loss: -1.321,LR: 4.03E-04]Training epoch 30:   8%|▊         | 9/112 [00:00<00:01, 59.86it/s, Epoch: 30, Batch: 10,Loss: -1.764,Avg.Loss: -1.365,LR: 4.03E-04]Training epoch 30:   9%|▉         | 10/112 [00:00<00:01, 59.86it/s, Epoch: 30, Batch: 11,Loss: -1.715,Avg.Loss: -1.397,LR: 4.03E-04]Training epoch 30:  10%|▉         | 11/112 [00:00<00:01, 59.86it/s, Epoch: 30, Batch: 12,Loss: -1.101,Avg.Loss: -1.373,LR: 4.03E-04]Training epoch 30:  11%|█         | 12/112 [00:00<00:01, 59.86it/s, Epoch: 30, Batch: 13,Loss: -1.313,Avg.Loss: -1.368,LR: 4.03E-04]Training epoch 30:  12%|█▏        | 13/112 [00:00<00:01, 63.06it/s, Epoch: 30, Batch: 13,Loss: -1.313,Avg.Loss: -1.368,LR: 4.03E-04]Training epoch 30:  12%|█▏        | 13/112 [00:00<00:01, 63.06it/s, Epoch: 30, Batch: 14,Loss: -2.016,Avg.Loss: -1.414,LR: 4.02E-04]Training epoch 30:  12%|█▎        | 14/112 [00:00<00:01, 63.06it/s, Epoch: 30, Batch: 15,Loss: -2.202,Avg.Loss: -1.467,LR: 4.02E-04]Training epoch 30:  13%|█▎        | 15/112 [00:00<00:01, 63.06it/s, Epoch: 30, Batch: 16,Loss: -1.936,Avg.Loss: -1.496,LR: 4.02E-04]Training epoch 30:  14%|█▍        | 16/112 [00:00<00:01, 63.06it/s, Epoch: 30, Batch: 17,Loss: -1.954,Avg.Loss: -1.523,LR: 4.02E-04]Training epoch 30:  15%|█▌        | 17/112 [00:00<00:01, 63.06it/s, Epoch: 30, Batch: 18,Loss: -2.132,Avg.Loss: -1.557,LR: 4.02E-04]Training epoch 30:  16%|█▌        | 18/112 [00:00<00:01, 63.06it/s, Epoch: 30, Batch: 19,Loss: -2.104,Avg.Loss: -1.586,LR: 4.02E-04]Training epoch 30:  17%|█▋        | 19/112 [00:00<00:01, 63.06it/s, Epoch: 30, Batch: 20,Loss: -0.901,Avg.Loss: -1.551,LR: 4.02E-04]Training epoch 30:  18%|█▊        | 20/112 [00:00<00:01, 58.14it/s, Epoch: 30, Batch: 20,Loss: -0.901,Avg.Loss: -1.551,LR: 4.02E-04]Training epoch 30:  18%|█▊        | 20/112 [00:00<00:01, 58.14it/s, Epoch: 30, Batch: 21,Loss: -0.763,Avg.Loss: -1.514,LR: 4.02E-04]Training epoch 30:  19%|█▉        | 21/112 [00:00<00:01, 58.14it/s, Epoch: 30, Batch: 22,Loss: -1.471,Avg.Loss: -1.512,LR: 4.02E-04]Training epoch 30:  20%|█▉        | 22/112 [00:00<00:01, 58.14it/s, Epoch: 30, Batch: 23,Loss: -1.084,Avg.Loss: -1.493,LR: 4.02E-04]Training epoch 30:  21%|██        | 23/112 [00:00<00:01, 58.14it/s, Epoch: 30, Batch: 24,Loss: 0.560,Avg.Loss: -1.408,LR: 4.02E-04] Training epoch 30:  21%|██▏       | 24/112 [00:00<00:01, 58.14it/s, Epoch: 30, Batch: 25,Loss: -0.231,Avg.Loss: -1.361,LR: 4.02E-04]Training epoch 30:  22%|██▏       | 25/112 [00:00<00:01, 58.14it/s, Epoch: 30, Batch: 26,Loss: -1.553,Avg.Loss: -1.368,LR: 4.02E-04]Training epoch 30:  23%|██▎       | 26/112 [00:00<00:01, 56.12it/s, Epoch: 30, Batch: 26,Loss: -1.553,Avg.Loss: -1.368,LR: 4.02E-04]Training epoch 30:  23%|██▎       | 26/112 [00:00<00:01, 56.12it/s, Epoch: 30, Batch: 27,Loss: -1.562,Avg.Loss: -1.375,LR: 4.02E-04]Training epoch 30:  24%|██▍       | 27/112 [00:00<00:01, 56.12it/s, Epoch: 30, Batch: 28,Loss: -1.770,Avg.Loss: -1.389,LR: 4.02E-04]Training epoch 30:  25%|██▌       | 28/112 [00:00<00:01, 56.12it/s, Epoch: 30, Batch: 29,Loss: -1.136,Avg.Loss: -1.381,LR: 4.02E-04]Training epoch 30:  26%|██▌       | 29/112 [00:00<00:01, 56.12it/s, Epoch: 30, Batch: 30,Loss: -0.439,Avg.Loss: -1.349,LR: 4.02E-04]Training epoch 30:  27%|██▋       | 30/112 [00:00<00:01, 56.12it/s, Epoch: 30, Batch: 31,Loss: -1.585,Avg.Loss: -1.357,LR: 4.02E-04]Training epoch 30:  28%|██▊       | 31/112 [00:00<00:01, 56.12it/s, Epoch: 30, Batch: 32,Loss: -0.708,Avg.Loss: -1.336,LR: 4.01E-04]Training epoch 30:  29%|██▊       | 32/112 [00:00<00:01, 55.08it/s, Epoch: 30, Batch: 32,Loss: -0.708,Avg.Loss: -1.336,LR: 4.01E-04]Training epoch 30:  29%|██▊       | 32/112 [00:00<00:01, 55.08it/s, Epoch: 30, Batch: 33,Loss: 0.506,Avg.Loss: -1.281,LR: 4.01E-04] Training epoch 30:  29%|██▉       | 33/112 [00:00<00:01, 55.08it/s, Epoch: 30, Batch: 34,Loss: -1.142,Avg.Loss: -1.277,LR: 4.01E-04]Training epoch 30:  30%|███       | 34/112 [00:00<00:01, 55.08it/s, Epoch: 30, Batch: 35,Loss: -1.779,Avg.Loss: -1.291,LR: 4.01E-04]Training epoch 30:  31%|███▏      | 35/112 [00:00<00:01, 55.08it/s, Epoch: 30, Batch: 36,Loss: -1.266,Avg.Loss: -1.290,LR: 4.01E-04]Training epoch 30:  32%|███▏      | 36/112 [00:00<00:01, 55.08it/s, Epoch: 30, Batch: 37,Loss: -2.217,Avg.Loss: -1.315,LR: 4.01E-04]Training epoch 30:  33%|███▎      | 37/112 [00:00<00:01, 55.08it/s, Epoch: 30, Batch: 38,Loss: -1.166,Avg.Loss: -1.311,LR: 4.01E-04]Training epoch 30:  34%|███▍      | 38/112 [00:00<00:01, 54.62it/s, Epoch: 30, Batch: 38,Loss: -1.166,Avg.Loss: -1.311,LR: 4.01E-04]Training epoch 30:  34%|███▍      | 38/112 [00:00<00:01, 54.62it/s, Epoch: 30, Batch: 39,Loss: -0.487,Avg.Loss: -1.290,LR: 4.01E-04]Training epoch 30:  35%|███▍      | 39/112 [00:00<00:01, 54.62it/s, Epoch: 30, Batch: 40,Loss: -1.330,Avg.Loss: -1.291,LR: 4.01E-04]Training epoch 30:  36%|███▌      | 40/112 [00:00<00:01, 54.62it/s, Epoch: 30, Batch: 41,Loss: -1.879,Avg.Loss: -1.306,LR: 4.01E-04]Training epoch 30:  37%|███▋      | 41/112 [00:00<00:01, 54.62it/s, Epoch: 30, Batch: 42,Loss: -1.267,Avg.Loss: -1.305,LR: 4.01E-04]Training epoch 30:  38%|███▊      | 42/112 [00:00<00:01, 54.62it/s, Epoch: 30, Batch: 43,Loss: -1.610,Avg.Loss: -1.312,LR: 4.01E-04]Training epoch 30:  38%|███▊      | 43/112 [00:00<00:01, 54.62it/s, Epoch: 30, Batch: 44,Loss: -1.324,Avg.Loss: -1.312,LR: 4.01E-04]Training epoch 30:  39%|███▉      | 44/112 [00:00<00:01, 54.36it/s, Epoch: 30, Batch: 44,Loss: -1.324,Avg.Loss: -1.312,LR: 4.01E-04]Training epoch 30:  39%|███▉      | 44/112 [00:00<00:01, 54.36it/s, Epoch: 30, Batch: 45,Loss: -0.973,Avg.Loss: -1.304,LR: 4.01E-04]Training epoch 30:  40%|████      | 45/112 [00:00<00:01, 54.36it/s, Epoch: 30, Batch: 46,Loss: -1.665,Avg.Loss: -1.312,LR: 4.01E-04]Training epoch 30:  41%|████      | 46/112 [00:00<00:01, 54.36it/s, Epoch: 30, Batch: 47,Loss: -1.510,Avg.Loss: -1.317,LR: 4.01E-04]Training epoch 30:  42%|████▏     | 47/112 [00:00<00:01, 54.36it/s, Epoch: 30, Batch: 48,Loss: -1.391,Avg.Loss: -1.318,LR: 4.01E-04]Training epoch 30:  43%|████▎     | 48/112 [00:00<00:01, 54.36it/s, Epoch: 30, Batch: 49,Loss: -2.256,Avg.Loss: -1.337,LR: 4.00E-04]Training epoch 30:  44%|████▍     | 49/112 [00:00<00:01, 54.36it/s, Epoch: 30, Batch: 50,Loss: -1.721,Avg.Loss: -1.345,LR: 4.00E-04]Training epoch 30:  45%|████▍     | 50/112 [00:00<00:01, 54.40it/s, Epoch: 30, Batch: 50,Loss: -1.721,Avg.Loss: -1.345,LR: 4.00E-04]Training epoch 30:  45%|████▍     | 50/112 [00:00<00:01, 54.40it/s, Epoch: 30, Batch: 51,Loss: -0.950,Avg.Loss: -1.337,LR: 4.00E-04]Training epoch 30:  46%|████▌     | 51/112 [00:00<00:01, 54.40it/s, Epoch: 30, Batch: 52,Loss: -1.862,Avg.Loss: -1.347,LR: 4.00E-04]Training epoch 30:  46%|████▋     | 52/112 [00:00<00:01, 54.40it/s, Epoch: 30, Batch: 53,Loss: -1.636,Avg.Loss: -1.353,LR: 4.00E-04]Training epoch 30:  47%|████▋     | 53/112 [00:00<00:01, 54.40it/s, Epoch: 30, Batch: 54,Loss: -1.310,Avg.Loss: -1.352,LR: 4.00E-04]Training epoch 30:  48%|████▊     | 54/112 [00:00<00:01, 54.40it/s, Epoch: 30, Batch: 55,Loss: -1.940,Avg.Loss: -1.363,LR: 4.00E-04]Training epoch 30:  49%|████▉     | 55/112 [00:01<00:01, 54.40it/s, Epoch: 30, Batch: 56,Loss: -1.249,Avg.Loss: -1.361,LR: 4.00E-04]Training epoch 30:  50%|█████     | 56/112 [00:01<00:01, 54.25it/s, Epoch: 30, Batch: 56,Loss: -1.249,Avg.Loss: -1.361,LR: 4.00E-04]Training epoch 30:  50%|█████     | 56/112 [00:01<00:01, 54.25it/s, Epoch: 30, Batch: 57,Loss: -0.965,Avg.Loss: -1.354,LR: 4.00E-04]Training epoch 30:  51%|█████     | 57/112 [00:01<00:01, 54.25it/s, Epoch: 30, Batch: 58,Loss: -1.678,Avg.Loss: -1.359,LR: 4.00E-04]Training epoch 30:  52%|█████▏    | 58/112 [00:01<00:00, 54.25it/s, Epoch: 30, Batch: 59,Loss: -1.939,Avg.Loss: -1.369,LR: 4.00E-04]Training epoch 30:  53%|█████▎    | 59/112 [00:01<00:00, 54.25it/s, Epoch: 30, Batch: 60,Loss: -1.356,Avg.Loss: -1.369,LR: 4.00E-04]Training epoch 30:  54%|█████▎    | 60/112 [00:01<00:00, 54.25it/s, Epoch: 30, Batch: 61,Loss: -2.154,Avg.Loss: -1.382,LR: 4.00E-04]Training epoch 30:  54%|█████▍    | 61/112 [00:01<00:00, 54.25it/s, Epoch: 30, Batch: 62,Loss: -1.681,Avg.Loss: -1.387,LR: 4.00E-04]Training epoch 30:  55%|█████▌    | 62/112 [00:01<00:00, 53.90it/s, Epoch: 30, Batch: 62,Loss: -1.681,Avg.Loss: -1.387,LR: 4.00E-04]Training epoch 30:  55%|█████▌    | 62/112 [00:01<00:00, 53.90it/s, Epoch: 30, Batch: 63,Loss: -1.513,Avg.Loss: -1.389,LR: 4.00E-04]Training epoch 30:  56%|█████▋    | 63/112 [00:01<00:00, 53.90it/s, Epoch: 30, Batch: 64,Loss: -1.831,Avg.Loss: -1.395,LR: 4.00E-04]Training epoch 30:  57%|█████▋    | 64/112 [00:01<00:00, 53.90it/s, Epoch: 30, Batch: 65,Loss: -1.656,Avg.Loss: -1.400,LR: 4.00E-04]Training epoch 30:  58%|█████▊    | 65/112 [00:01<00:00, 53.90it/s, Epoch: 30, Batch: 66,Loss: -1.456,Avg.Loss: -1.400,LR: 4.00E-04]Training epoch 30:  59%|█████▉    | 66/112 [00:01<00:00, 53.90it/s, Epoch: 30, Batch: 67,Loss: -1.971,Avg.Loss: -1.409,LR: 3.99E-04]Training epoch 30:  60%|█████▉    | 67/112 [00:01<00:00, 53.90it/s, Epoch: 30, Batch: 68,Loss: -1.700,Avg.Loss: -1.413,LR: 3.99E-04]Training epoch 30:  61%|██████    | 68/112 [00:01<00:00, 53.78it/s, Epoch: 30, Batch: 68,Loss: -1.700,Avg.Loss: -1.413,LR: 3.99E-04]Training epoch 30:  61%|██████    | 68/112 [00:01<00:00, 53.78it/s, Epoch: 30, Batch: 69,Loss: -1.249,Avg.Loss: -1.411,LR: 3.99E-04]Training epoch 30:  62%|██████▏   | 69/112 [00:01<00:00, 53.78it/s, Epoch: 30, Batch: 70,Loss: -1.883,Avg.Loss: -1.418,LR: 3.99E-04]Training epoch 30:  62%|██████▎   | 70/112 [00:01<00:00, 53.78it/s, Epoch: 30, Batch: 71,Loss: -1.701,Avg.Loss: -1.422,LR: 3.99E-04]Training epoch 30:  63%|██████▎   | 71/112 [00:01<00:00, 53.78it/s, Epoch: 30, Batch: 72,Loss: -1.085,Avg.Loss: -1.417,LR: 3.99E-04]Training epoch 30:  64%|██████▍   | 72/112 [00:01<00:00, 53.78it/s, Epoch: 30, Batch: 73,Loss: -1.872,Avg.Loss: -1.423,LR: 3.99E-04]Training epoch 30:  65%|██████▌   | 73/112 [00:01<00:00, 53.78it/s, Epoch: 30, Batch: 74,Loss: -1.935,Avg.Loss: -1.430,LR: 3.99E-04]Training epoch 30:  66%|██████▌   | 74/112 [00:01<00:00, 53.82it/s, Epoch: 30, Batch: 74,Loss: -1.935,Avg.Loss: -1.430,LR: 3.99E-04]Training epoch 30:  66%|██████▌   | 74/112 [00:01<00:00, 53.82it/s, Epoch: 30, Batch: 75,Loss: -1.473,Avg.Loss: -1.431,LR: 3.99E-04]Training epoch 30:  67%|██████▋   | 75/112 [00:01<00:00, 53.82it/s, Epoch: 30, Batch: 76,Loss: -1.902,Avg.Loss: -1.437,LR: 3.99E-04]Training epoch 30:  68%|██████▊   | 76/112 [00:01<00:00, 53.82it/s, Epoch: 30, Batch: 77,Loss: -1.604,Avg.Loss: -1.439,LR: 3.99E-04]Training epoch 30:  69%|██████▉   | 77/112 [00:01<00:00, 53.82it/s, Epoch: 30, Batch: 78,Loss: -0.806,Avg.Loss: -1.431,LR: 3.99E-04]Training epoch 30:  70%|██████▉   | 78/112 [00:01<00:00, 53.82it/s, Epoch: 30, Batch: 79,Loss: -1.957,Avg.Loss: -1.437,LR: 3.99E-04]Training epoch 30:  71%|███████   | 79/112 [00:01<00:00, 53.82it/s, Epoch: 30, Batch: 80,Loss: -1.785,Avg.Loss: -1.442,LR: 3.99E-04]Training epoch 30:  71%|███████▏  | 80/112 [00:01<00:00, 54.04it/s, Epoch: 30, Batch: 80,Loss: -1.785,Avg.Loss: -1.442,LR: 3.99E-04]Training epoch 30:  71%|███████▏  | 80/112 [00:01<00:00, 54.04it/s, Epoch: 30, Batch: 81,Loss: -1.351,Avg.Loss: -1.441,LR: 3.99E-04]Training epoch 30:  72%|███████▏  | 81/112 [00:01<00:00, 54.04it/s, Epoch: 30, Batch: 82,Loss: -2.222,Avg.Loss: -1.450,LR: 3.99E-04]Training epoch 30:  73%|███████▎  | 82/112 [00:01<00:00, 54.04it/s, Epoch: 30, Batch: 83,Loss: -1.812,Avg.Loss: -1.455,LR: 3.99E-04]Training epoch 30:  74%|███████▍  | 83/112 [00:01<00:00, 54.04it/s, Epoch: 30, Batch: 84,Loss: -1.325,Avg.Loss: -1.453,LR: 3.99E-04]Training epoch 30:  75%|███████▌  | 84/112 [00:01<00:00, 54.04it/s, Epoch: 30, Batch: 85,Loss: -2.134,Avg.Loss: -1.461,LR: 3.98E-04]Training epoch 30:  76%|███████▌  | 85/112 [00:01<00:00, 54.04it/s, Epoch: 30, Batch: 86,Loss: -1.738,Avg.Loss: -1.464,LR: 3.98E-04]Training epoch 30:  77%|███████▋  | 86/112 [00:01<00:00, 54.37it/s, Epoch: 30, Batch: 86,Loss: -1.738,Avg.Loss: -1.464,LR: 3.98E-04]Training epoch 30:  77%|███████▋  | 86/112 [00:01<00:00, 54.37it/s, Epoch: 30, Batch: 87,Loss: -1.642,Avg.Loss: -1.466,LR: 3.98E-04]Training epoch 30:  78%|███████▊  | 87/112 [00:01<00:00, 54.37it/s, Epoch: 30, Batch: 88,Loss: -1.933,Avg.Loss: -1.472,LR: 3.98E-04]Training epoch 30:  79%|███████▊  | 88/112 [00:01<00:00, 54.37it/s, Epoch: 30, Batch: 89,Loss: -1.816,Avg.Loss: -1.476,LR: 3.98E-04]Training epoch 30:  79%|███████▉  | 89/112 [00:01<00:00, 54.37it/s, Epoch: 30, Batch: 90,Loss: -0.855,Avg.Loss: -1.469,LR: 3.98E-04]Training epoch 30:  80%|████████  | 90/112 [00:01<00:00, 54.37it/s, Epoch: 30, Batch: 91,Loss: -2.098,Avg.Loss: -1.476,LR: 3.98E-04]Training epoch 30:  81%|████████▏ | 91/112 [00:01<00:00, 54.37it/s, Epoch: 30, Batch: 92,Loss: -2.031,Avg.Loss: -1.482,LR: 3.98E-04]Training epoch 30:  82%|████████▏ | 92/112 [00:01<00:00, 54.39it/s, Epoch: 30, Batch: 92,Loss: -2.031,Avg.Loss: -1.482,LR: 3.98E-04]Training epoch 30:  82%|████████▏ | 92/112 [00:01<00:00, 54.39it/s, Epoch: 30, Batch: 93,Loss: -1.632,Avg.Loss: -1.483,LR: 3.98E-04]Training epoch 30:  83%|████████▎ | 93/112 [00:01<00:00, 54.39it/s, Epoch: 30, Batch: 94,Loss: -2.003,Avg.Loss: -1.489,LR: 3.98E-04]Training epoch 30:  84%|████████▍ | 94/112 [00:01<00:00, 54.39it/s, Epoch: 30, Batch: 95,Loss: -1.778,Avg.Loss: -1.492,LR: 3.98E-04]Training epoch 30:  85%|████████▍ | 95/112 [00:01<00:00, 54.39it/s, Epoch: 30, Batch: 96,Loss: -1.294,Avg.Loss: -1.490,LR: 3.98E-04]Training epoch 30:  86%|████████▌ | 96/112 [00:01<00:00, 54.39it/s, Epoch: 30, Batch: 97,Loss: -2.023,Avg.Loss: -1.495,LR: 3.98E-04]Training epoch 30:  87%|████████▋ | 97/112 [00:01<00:00, 54.39it/s, Epoch: 30, Batch: 98,Loss: -1.952,Avg.Loss: -1.500,LR: 3.98E-04]Training epoch 30:  88%|████████▊ | 98/112 [00:01<00:00, 53.58it/s, Epoch: 30, Batch: 98,Loss: -1.952,Avg.Loss: -1.500,LR: 3.98E-04]Training epoch 30:  88%|████████▊ | 98/112 [00:01<00:00, 53.58it/s, Epoch: 30, Batch: 99,Loss: -1.473,Avg.Loss: -1.500,LR: 3.98E-04]Training epoch 30:  88%|████████▊ | 99/112 [00:01<00:00, 53.58it/s, Epoch: 30, Batch: 100,Loss: -1.935,Avg.Loss: -1.504,LR: 3.98E-04]Training epoch 30:  89%|████████▉ | 100/112 [00:01<00:00, 53.58it/s, Epoch: 30, Batch: 101,Loss: -1.891,Avg.Loss: -1.508,LR: 3.98E-04]Training epoch 30:  90%|█████████ | 101/112 [00:01<00:00, 53.58it/s, Epoch: 30, Batch: 102,Loss: -1.505,Avg.Loss: -1.508,LR: 3.98E-04]Training epoch 30:  91%|█████████ | 102/112 [00:01<00:00, 53.58it/s, Epoch: 30, Batch: 103,Loss: -2.143,Avg.Loss: -1.514,LR: 3.97E-04]Training epoch 30:  92%|█████████▏| 103/112 [00:01<00:00, 53.58it/s, Epoch: 30, Batch: 104,Loss: -1.518,Avg.Loss: -1.514,LR: 3.97E-04]Training epoch 30:  93%|█████████▎| 104/112 [00:01<00:00, 53.33it/s, Epoch: 30, Batch: 104,Loss: -1.518,Avg.Loss: -1.514,LR: 3.97E-04]Training epoch 30:  93%|█████████▎| 104/112 [00:01<00:00, 53.33it/s, Epoch: 30, Batch: 105,Loss: -1.539,Avg.Loss: -1.514,LR: 3.97E-04]Training epoch 30:  94%|█████████▍| 105/112 [00:01<00:00, 53.33it/s, Epoch: 30, Batch: 106,Loss: -1.892,Avg.Loss: -1.518,LR: 3.97E-04]Training epoch 30:  95%|█████████▍| 106/112 [00:01<00:00, 53.33it/s, Epoch: 30, Batch: 107,Loss: -1.996,Avg.Loss: -1.522,LR: 3.97E-04]Training epoch 30:  96%|█████████▌| 107/112 [00:01<00:00, 53.33it/s, Epoch: 30, Batch: 108,Loss: -1.672,Avg.Loss: -1.524,LR: 3.97E-04]Training epoch 30:  96%|█████████▋| 108/112 [00:01<00:00, 53.33it/s, Epoch: 30, Batch: 109,Loss: -2.280,Avg.Loss: -1.531,LR: 3.97E-04]Training epoch 30:  97%|█████████▋| 109/112 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 110,Loss: -1.426,Avg.Loss: -1.530,LR: 3.97E-04]Training epoch 30:  98%|█████████▊| 110/112 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 110,Loss: -1.426,Avg.Loss: -1.530,LR: 3.97E-04]Training epoch 30:  98%|█████████▊| 110/112 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 111,Loss: -0.637,Avg.Loss: -1.522,LR: 3.97E-04]Training epoch 30:  99%|█████████▉| 111/112 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 112,Loss: -2.421,Avg.Loss: -1.530,LR: 3.97E-04]Training epoch 30: 100%|██████████| 112/112 [00:02<00:00, 54.45it/s, Epoch: 30, Batch: 112,Loss: -2.421,Avg.Loss: -1.530,LR: 3.97E-04]
Training epoch 31:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 31:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 31, Batch: 1,Loss: -1.043,Avg.Loss: -1.043,LR: 3.97E-04]Training epoch 31:   1%|          | 1/112 [00:00<00:03, 29.67it/s, Epoch: 31, Batch: 2,Loss: -1.038,Avg.Loss: -1.040,LR: 3.97E-04]Training epoch 31:   2%|▏         | 2/112 [00:00<00:02, 37.04it/s, Epoch: 31, Batch: 3,Loss: -1.959,Avg.Loss: -1.347,LR: 3.97E-04]Training epoch 31:   3%|▎         | 3/112 [00:00<00:02, 43.47it/s, Epoch: 31, Batch: 4,Loss: -1.517,Avg.Loss: -1.389,LR: 3.97E-04]Training epoch 31:   4%|▎         | 4/112 [00:00<00:02, 48.23it/s, Epoch: 31, Batch: 5,Loss: -0.868,Avg.Loss: -1.285,LR: 3.97E-04]Training epoch 31:   4%|▍         | 5/112 [00:00<00:02, 51.37it/s, Epoch: 31, Batch: 6,Loss: -0.547,Avg.Loss: -1.162,LR: 3.97E-04]Training epoch 31:   5%|▌         | 6/112 [00:00<00:01, 54.01it/s, Epoch: 31, Batch: 7,Loss: -0.271,Avg.Loss: -1.035,LR: 3.97E-04]Training epoch 31:   6%|▋         | 7/112 [00:00<00:01, 62.90it/s, Epoch: 31, Batch: 7,Loss: -0.271,Avg.Loss: -1.035,LR: 3.97E-04]Training epoch 31:   6%|▋         | 7/112 [00:00<00:01, 62.90it/s, Epoch: 31, Batch: 8,Loss: -0.906,Avg.Loss: -1.019,LR: 3.96E-04]Training epoch 31:   7%|▋         | 8/112 [00:00<00:01, 62.90it/s, Epoch: 31, Batch: 9,Loss: -1.614,Avg.Loss: -1.085,LR: 3.96E-04]Training epoch 31:   8%|▊         | 9/112 [00:00<00:01, 62.90it/s, Epoch: 31, Batch: 10,Loss: -2.164,Avg.Loss: -1.193,LR: 3.96E-04]Training epoch 31:   9%|▉         | 10/112 [00:00<00:01, 62.90it/s, Epoch: 31, Batch: 11,Loss: -1.774,Avg.Loss: -1.245,LR: 3.96E-04]Training epoch 31:  10%|▉         | 11/112 [00:00<00:01, 62.90it/s, Epoch: 31, Batch: 12,Loss: -1.912,Avg.Loss: -1.301,LR: 3.96E-04]Training epoch 31:  11%|█         | 12/112 [00:00<00:01, 62.90it/s, Epoch: 31, Batch: 13,Loss: -0.573,Avg.Loss: -1.245,LR: 3.96E-04]Training epoch 31:  12%|█▏        | 13/112 [00:00<00:01, 62.90it/s, Epoch: 31, Batch: 14,Loss: -0.424,Avg.Loss: -1.186,LR: 3.96E-04]Training epoch 31:  12%|█▎        | 14/112 [00:00<00:01, 57.35it/s, Epoch: 31, Batch: 14,Loss: -0.424,Avg.Loss: -1.186,LR: 3.96E-04]Training epoch 31:  12%|█▎        | 14/112 [00:00<00:01, 57.35it/s, Epoch: 31, Batch: 15,Loss: -1.668,Avg.Loss: -1.218,LR: 3.96E-04]Training epoch 31:  13%|█▎        | 15/112 [00:00<00:01, 57.35it/s, Epoch: 31, Batch: 16,Loss: -1.270,Avg.Loss: -1.222,LR: 3.96E-04]Training epoch 31:  14%|█▍        | 16/112 [00:00<00:01, 57.35it/s, Epoch: 31, Batch: 17,Loss: -0.396,Avg.Loss: -1.173,LR: 3.96E-04]Training epoch 31:  15%|█▌        | 17/112 [00:00<00:01, 57.35it/s, Epoch: 31, Batch: 18,Loss: -0.740,Avg.Loss: -1.149,LR: 3.96E-04]Training epoch 31:  16%|█▌        | 18/112 [00:00<00:01, 57.35it/s, Epoch: 31, Batch: 19,Loss: -1.461,Avg.Loss: -1.166,LR: 3.96E-04]Training epoch 31:  17%|█▋        | 19/112 [00:00<00:01, 57.35it/s, Epoch: 31, Batch: 20,Loss: -0.511,Avg.Loss: -1.133,LR: 3.96E-04]Training epoch 31:  18%|█▊        | 20/112 [00:00<00:01, 55.60it/s, Epoch: 31, Batch: 20,Loss: -0.511,Avg.Loss: -1.133,LR: 3.96E-04]Training epoch 31:  18%|█▊        | 20/112 [00:00<00:01, 55.60it/s, Epoch: 31, Batch: 21,Loss: -0.351,Avg.Loss: -1.096,LR: 3.96E-04]Training epoch 31:  19%|█▉        | 21/112 [00:00<00:01, 55.60it/s, Epoch: 31, Batch: 22,Loss: -1.520,Avg.Loss: -1.115,LR: 3.96E-04]Training epoch 31:  20%|█▉        | 22/112 [00:00<00:01, 55.60it/s, Epoch: 31, Batch: 23,Loss: -0.892,Avg.Loss: -1.105,LR: 3.96E-04]Training epoch 31:  21%|██        | 23/112 [00:00<00:01, 55.60it/s, Epoch: 31, Batch: 24,Loss: -0.542,Avg.Loss: -1.082,LR: 3.96E-04]Training epoch 31:  21%|██▏       | 24/112 [00:00<00:01, 55.60it/s, Epoch: 31, Batch: 25,Loss: -0.270,Avg.Loss: -1.049,LR: 3.96E-04]Training epoch 31:  22%|██▏       | 25/112 [00:00<00:01, 55.60it/s, Epoch: 31, Batch: 26,Loss: -1.185,Avg.Loss: -1.054,LR: 3.95E-04]Training epoch 31:  23%|██▎       | 26/112 [00:00<00:01, 54.09it/s, Epoch: 31, Batch: 26,Loss: -1.185,Avg.Loss: -1.054,LR: 3.95E-04]Training epoch 31:  23%|██▎       | 26/112 [00:00<00:01, 54.09it/s, Epoch: 31, Batch: 27,Loss: -1.366,Avg.Loss: -1.066,LR: 3.95E-04]Training epoch 31:  24%|██▍       | 27/112 [00:00<00:01, 54.09it/s, Epoch: 31, Batch: 28,Loss: -0.954,Avg.Loss: -1.062,LR: 3.95E-04]Training epoch 31:  25%|██▌       | 28/112 [00:00<00:01, 54.09it/s, Epoch: 31, Batch: 29,Loss: -1.754,Avg.Loss: -1.086,LR: 3.95E-04]Training epoch 31:  26%|██▌       | 29/112 [00:00<00:01, 54.09it/s, Epoch: 31, Batch: 30,Loss: -1.559,Avg.Loss: -1.102,LR: 3.95E-04]Training epoch 31:  27%|██▋       | 30/112 [00:00<00:01, 54.09it/s, Epoch: 31, Batch: 31,Loss: -1.800,Avg.Loss: -1.124,LR: 3.95E-04]Training epoch 31:  28%|██▊       | 31/112 [00:00<00:01, 54.09it/s, Epoch: 31, Batch: 32,Loss: -2.042,Avg.Loss: -1.153,LR: 3.95E-04]Training epoch 31:  29%|██▊       | 32/112 [00:00<00:01, 53.45it/s, Epoch: 31, Batch: 32,Loss: -2.042,Avg.Loss: -1.153,LR: 3.95E-04]Training epoch 31:  29%|██▊       | 32/112 [00:00<00:01, 53.45it/s, Epoch: 31, Batch: 33,Loss: -2.144,Avg.Loss: -1.183,LR: 3.95E-04]Training epoch 31:  29%|██▉       | 33/112 [00:00<00:01, 53.45it/s, Epoch: 31, Batch: 34,Loss: -1.936,Avg.Loss: -1.205,LR: 3.95E-04]Training epoch 31:  30%|███       | 34/112 [00:00<00:01, 53.45it/s, Epoch: 31, Batch: 35,Loss: -1.644,Avg.Loss: -1.218,LR: 3.95E-04]Training epoch 31:  31%|███▏      | 35/112 [00:00<00:01, 53.45it/s, Epoch: 31, Batch: 36,Loss: -1.639,Avg.Loss: -1.229,LR: 3.95E-04]Training epoch 31:  32%|███▏      | 36/112 [00:00<00:01, 53.45it/s, Epoch: 31, Batch: 37,Loss: -0.339,Avg.Loss: -1.205,LR: 3.95E-04]Training epoch 31:  33%|███▎      | 37/112 [00:00<00:01, 53.45it/s, Epoch: 31, Batch: 38,Loss: 0.481,Avg.Loss: -1.161,LR: 3.95E-04] Training epoch 31:  34%|███▍      | 38/112 [00:00<00:01, 53.34it/s, Epoch: 31, Batch: 38,Loss: 0.481,Avg.Loss: -1.161,LR: 3.95E-04]Training epoch 31:  34%|███▍      | 38/112 [00:00<00:01, 53.34it/s, Epoch: 31, Batch: 39,Loss: -0.144,Avg.Loss: -1.135,LR: 3.95E-04]Training epoch 31:  35%|███▍      | 39/112 [00:00<00:01, 53.34it/s, Epoch: 31, Batch: 40,Loss: -1.847,Avg.Loss: -1.153,LR: 3.95E-04]Training epoch 31:  36%|███▌      | 40/112 [00:00<00:01, 53.34it/s, Epoch: 31, Batch: 41,Loss: -1.200,Avg.Loss: -1.154,LR: 3.95E-04]Training epoch 31:  37%|███▋      | 41/112 [00:00<00:01, 53.34it/s, Epoch: 31, Batch: 42,Loss: -0.345,Avg.Loss: -1.134,LR: 3.95E-04]Training epoch 31:  38%|███▊      | 42/112 [00:00<00:01, 53.34it/s, Epoch: 31, Batch: 43,Loss: -0.706,Avg.Loss: -1.124,LR: 3.94E-04]Training epoch 31:  38%|███▊      | 43/112 [00:00<00:01, 53.34it/s, Epoch: 31, Batch: 44,Loss: -1.599,Avg.Loss: -1.135,LR: 3.94E-04]Training epoch 31:  39%|███▉      | 44/112 [00:00<00:01, 53.35it/s, Epoch: 31, Batch: 44,Loss: -1.599,Avg.Loss: -1.135,LR: 3.94E-04]Training epoch 31:  39%|███▉      | 44/112 [00:00<00:01, 53.35it/s, Epoch: 31, Batch: 45,Loss: -1.948,Avg.Loss: -1.153,LR: 3.94E-04]Training epoch 31:  40%|████      | 45/112 [00:00<00:01, 53.35it/s, Epoch: 31, Batch: 46,Loss: -1.132,Avg.Loss: -1.153,LR: 3.94E-04]Training epoch 31:  41%|████      | 46/112 [00:00<00:01, 53.35it/s, Epoch: 31, Batch: 47,Loss: -1.831,Avg.Loss: -1.167,LR: 3.94E-04]Training epoch 31:  42%|████▏     | 47/112 [00:00<00:01, 53.35it/s, Epoch: 31, Batch: 48,Loss: -2.017,Avg.Loss: -1.185,LR: 3.94E-04]Training epoch 31:  43%|████▎     | 48/112 [00:00<00:01, 53.35it/s, Epoch: 31, Batch: 49,Loss: -1.964,Avg.Loss: -1.201,LR: 3.94E-04]Training epoch 31:  44%|████▍     | 49/112 [00:00<00:01, 53.35it/s, Epoch: 31, Batch: 50,Loss: -1.982,Avg.Loss: -1.216,LR: 3.94E-04]Training epoch 31:  45%|████▍     | 50/112 [00:00<00:01, 53.43it/s, Epoch: 31, Batch: 50,Loss: -1.982,Avg.Loss: -1.216,LR: 3.94E-04]Training epoch 31:  45%|████▍     | 50/112 [00:00<00:01, 53.43it/s, Epoch: 31, Batch: 51,Loss: -1.866,Avg.Loss: -1.229,LR: 3.94E-04]Training epoch 31:  46%|████▌     | 51/112 [00:00<00:01, 53.43it/s, Epoch: 31, Batch: 52,Loss: -1.711,Avg.Loss: -1.238,LR: 3.94E-04]Training epoch 31:  46%|████▋     | 52/112 [00:00<00:01, 53.43it/s, Epoch: 31, Batch: 53,Loss: -1.314,Avg.Loss: -1.240,LR: 3.94E-04]Training epoch 31:  47%|████▋     | 53/112 [00:00<00:01, 53.43it/s, Epoch: 31, Batch: 54,Loss: -0.922,Avg.Loss: -1.234,LR: 3.94E-04]Training epoch 31:  48%|████▊     | 54/112 [00:01<00:01, 53.43it/s, Epoch: 31, Batch: 55,Loss: -1.394,Avg.Loss: -1.237,LR: 3.94E-04]Training epoch 31:  49%|████▉     | 55/112 [00:01<00:01, 53.43it/s, Epoch: 31, Batch: 56,Loss: -2.030,Avg.Loss: -1.251,LR: 3.94E-04]Training epoch 31:  50%|█████     | 56/112 [00:01<00:01, 53.40it/s, Epoch: 31, Batch: 56,Loss: -2.030,Avg.Loss: -1.251,LR: 3.94E-04]Training epoch 31:  50%|█████     | 56/112 [00:01<00:01, 53.40it/s, Epoch: 31, Batch: 57,Loss: -1.885,Avg.Loss: -1.262,LR: 3.94E-04]Training epoch 31:  51%|█████     | 57/112 [00:01<00:01, 53.40it/s, Epoch: 31, Batch: 58,Loss: -1.107,Avg.Loss: -1.260,LR: 3.94E-04]Training epoch 31:  52%|█████▏    | 58/112 [00:01<00:01, 53.40it/s, Epoch: 31, Batch: 59,Loss: -0.187,Avg.Loss: -1.241,LR: 3.94E-04]Training epoch 31:  53%|█████▎    | 59/112 [00:01<00:00, 53.40it/s, Epoch: 31, Batch: 60,Loss: -0.771,Avg.Loss: -1.234,LR: 3.94E-04]Training epoch 31:  54%|█████▎    | 60/112 [00:01<00:00, 53.40it/s, Epoch: 31, Batch: 61,Loss: -1.332,Avg.Loss: -1.235,LR: 3.93E-04]Training epoch 31:  54%|█████▍    | 61/112 [00:01<00:00, 53.40it/s, Epoch: 31, Batch: 62,Loss: -1.113,Avg.Loss: -1.233,LR: 3.93E-04]Training epoch 31:  55%|█████▌    | 62/112 [00:01<00:00, 53.41it/s, Epoch: 31, Batch: 62,Loss: -1.113,Avg.Loss: -1.233,LR: 3.93E-04]Training epoch 31:  55%|█████▌    | 62/112 [00:01<00:00, 53.41it/s, Epoch: 31, Batch: 63,Loss: -1.960,Avg.Loss: -1.245,LR: 3.93E-04]Training epoch 31:  56%|█████▋    | 63/112 [00:01<00:00, 53.41it/s, Epoch: 31, Batch: 64,Loss: -0.870,Avg.Loss: -1.239,LR: 3.93E-04]Training epoch 31:  57%|█████▋    | 64/112 [00:01<00:00, 53.41it/s, Epoch: 31, Batch: 65,Loss: 0.295,Avg.Loss: -1.215,LR: 3.93E-04] Training epoch 31:  58%|█████▊    | 65/112 [00:01<00:00, 53.41it/s, Epoch: 31, Batch: 66,Loss: -0.157,Avg.Loss: -1.199,LR: 3.93E-04]Training epoch 31:  59%|█████▉    | 66/112 [00:01<00:00, 53.41it/s, Epoch: 31, Batch: 67,Loss: -0.953,Avg.Loss: -1.196,LR: 3.93E-04]Training epoch 31:  60%|█████▉    | 67/112 [00:01<00:00, 53.41it/s, Epoch: 31, Batch: 68,Loss: -1.343,Avg.Loss: -1.198,LR: 3.93E-04]Training epoch 31:  61%|██████    | 68/112 [00:01<00:00, 53.45it/s, Epoch: 31, Batch: 68,Loss: -1.343,Avg.Loss: -1.198,LR: 3.93E-04]Training epoch 31:  61%|██████    | 68/112 [00:01<00:00, 53.45it/s, Epoch: 31, Batch: 69,Loss: -1.441,Avg.Loss: -1.201,LR: 3.93E-04]Training epoch 31:  62%|██████▏   | 69/112 [00:01<00:00, 53.45it/s, Epoch: 31, Batch: 70,Loss: -2.173,Avg.Loss: -1.215,LR: 3.93E-04]Training epoch 31:  62%|██████▎   | 70/112 [00:01<00:00, 53.45it/s, Epoch: 31, Batch: 71,Loss: -1.551,Avg.Loss: -1.220,LR: 3.93E-04]Training epoch 31:  63%|██████▎   | 71/112 [00:01<00:00, 53.45it/s, Epoch: 31, Batch: 72,Loss: -1.568,Avg.Loss: -1.225,LR: 3.93E-04]Training epoch 31:  64%|██████▍   | 72/112 [00:01<00:00, 53.45it/s, Epoch: 31, Batch: 73,Loss: -1.869,Avg.Loss: -1.234,LR: 3.93E-04]Training epoch 31:  65%|██████▌   | 73/112 [00:01<00:00, 53.45it/s, Epoch: 31, Batch: 74,Loss: -1.140,Avg.Loss: -1.232,LR: 3.93E-04]Training epoch 31:  66%|██████▌   | 74/112 [00:01<00:00, 50.36it/s, Epoch: 31, Batch: 74,Loss: -1.140,Avg.Loss: -1.232,LR: 3.93E-04]Training epoch 31:  66%|██████▌   | 74/112 [00:01<00:00, 50.36it/s, Epoch: 31, Batch: 75,Loss: -1.103,Avg.Loss: -1.231,LR: 3.93E-04]Training epoch 31:  67%|██████▋   | 75/112 [00:01<00:00, 50.36it/s, Epoch: 31, Batch: 76,Loss: -1.882,Avg.Loss: -1.239,LR: 3.93E-04]Training epoch 31:  68%|██████▊   | 76/112 [00:01<00:00, 50.36it/s, Epoch: 31, Batch: 77,Loss: -0.158,Avg.Loss: -1.225,LR: 3.93E-04]Training epoch 31:  69%|██████▉   | 77/112 [00:01<00:00, 50.36it/s, Epoch: 31, Batch: 78,Loss: 1.854,Avg.Loss: -1.186,LR: 3.92E-04] Training epoch 31:  70%|██████▉   | 78/112 [00:01<00:00, 50.36it/s, Epoch: 31, Batch: 79,Loss: 0.787,Avg.Loss: -1.161,LR: 3.92E-04]Training epoch 31:  71%|███████   | 79/112 [00:01<00:00, 50.36it/s, Epoch: 31, Batch: 80,Loss: -1.908,Avg.Loss: -1.170,LR: 3.92E-04]Training epoch 31:  71%|███████▏  | 80/112 [00:01<00:00, 51.64it/s, Epoch: 31, Batch: 80,Loss: -1.908,Avg.Loss: -1.170,LR: 3.92E-04]Training epoch 31:  71%|███████▏  | 80/112 [00:01<00:00, 51.64it/s, Epoch: 31, Batch: 81,Loss: 0.356,Avg.Loss: -1.151,LR: 3.92E-04] Training epoch 31:  72%|███████▏  | 81/112 [00:01<00:00, 51.64it/s, Epoch: 31, Batch: 82,Loss: 1.289,Avg.Loss: -1.121,LR: 3.92E-04]Training epoch 31:  73%|███████▎  | 82/112 [00:01<00:00, 51.64it/s, Epoch: 31, Batch: 83,Loss: 3.139,Avg.Loss: -1.070,LR: 3.92E-04]Training epoch 31:  74%|███████▍  | 83/112 [00:01<00:00, 51.64it/s, Epoch: 31, Batch: 84,Loss: -0.236,Avg.Loss: -1.060,LR: 3.92E-04]Training epoch 31:  75%|███████▌  | 84/112 [00:01<00:00, 51.64it/s, Epoch: 31, Batch: 85,Loss: -1.808,Avg.Loss: -1.069,LR: 3.92E-04]Training epoch 31:  76%|███████▌  | 85/112 [00:01<00:00, 51.64it/s, Epoch: 31, Batch: 86,Loss: -1.030,Avg.Loss: -1.068,LR: 3.92E-04]Training epoch 31:  77%|███████▋  | 86/112 [00:01<00:00, 52.68it/s, Epoch: 31, Batch: 86,Loss: -1.030,Avg.Loss: -1.068,LR: 3.92E-04]Training epoch 31:  77%|███████▋  | 86/112 [00:01<00:00, 52.68it/s, Epoch: 31, Batch: 87,Loss: -1.158,Avg.Loss: -1.069,LR: 3.92E-04]Training epoch 31:  78%|███████▊  | 87/112 [00:01<00:00, 52.68it/s, Epoch: 31, Batch: 88,Loss: -1.861,Avg.Loss: -1.078,LR: 3.92E-04]Training epoch 31:  79%|███████▊  | 88/112 [00:01<00:00, 52.68it/s, Epoch: 31, Batch: 89,Loss: -2.258,Avg.Loss: -1.092,LR: 3.92E-04]Training epoch 31:  79%|███████▉  | 89/112 [00:01<00:00, 52.68it/s, Epoch: 31, Batch: 90,Loss: -1.803,Avg.Loss: -1.100,LR: 3.92E-04]Training epoch 31:  80%|████████  | 90/112 [00:01<00:00, 52.68it/s, Epoch: 31, Batch: 91,Loss: -2.172,Avg.Loss: -1.111,LR: 3.92E-04]Training epoch 31:  81%|████████▏ | 91/112 [00:01<00:00, 52.68it/s, Epoch: 31, Batch: 92,Loss: -1.517,Avg.Loss: -1.116,LR: 3.92E-04]Training epoch 31:  82%|████████▏ | 92/112 [00:01<00:00, 53.18it/s, Epoch: 31, Batch: 92,Loss: -1.517,Avg.Loss: -1.116,LR: 3.92E-04]Training epoch 31:  82%|████████▏ | 92/112 [00:01<00:00, 53.18it/s, Epoch: 31, Batch: 93,Loss: -1.585,Avg.Loss: -1.121,LR: 3.92E-04]Training epoch 31:  83%|████████▎ | 93/112 [00:01<00:00, 53.18it/s, Epoch: 31, Batch: 94,Loss: -1.770,Avg.Loss: -1.128,LR: 3.92E-04]Training epoch 31:  84%|████████▍ | 94/112 [00:01<00:00, 53.18it/s, Epoch: 31, Batch: 95,Loss: -1.781,Avg.Loss: -1.135,LR: 3.92E-04]Training epoch 31:  85%|████████▍ | 95/112 [00:01<00:00, 53.18it/s, Epoch: 31, Batch: 96,Loss: -1.983,Avg.Loss: -1.143,LR: 3.91E-04]Training epoch 31:  86%|████████▌ | 96/112 [00:01<00:00, 53.18it/s, Epoch: 31, Batch: 97,Loss: -2.032,Avg.Loss: -1.153,LR: 3.91E-04]Training epoch 31:  87%|████████▋ | 97/112 [00:01<00:00, 53.18it/s, Epoch: 31, Batch: 98,Loss: -1.854,Avg.Loss: -1.160,LR: 3.91E-04]Training epoch 31:  88%|████████▊ | 98/112 [00:01<00:00, 53.70it/s, Epoch: 31, Batch: 98,Loss: -1.854,Avg.Loss: -1.160,LR: 3.91E-04]Training epoch 31:  88%|████████▊ | 98/112 [00:01<00:00, 53.70it/s, Epoch: 31, Batch: 99,Loss: -2.281,Avg.Loss: -1.171,LR: 3.91E-04]Training epoch 31:  88%|████████▊ | 99/112 [00:01<00:00, 53.70it/s, Epoch: 31, Batch: 100,Loss: -2.072,Avg.Loss: -1.180,LR: 3.91E-04]Training epoch 31:  89%|████████▉ | 100/112 [00:01<00:00, 53.70it/s, Epoch: 31, Batch: 101,Loss: -2.086,Avg.Loss: -1.189,LR: 3.91E-04]Training epoch 31:  90%|█████████ | 101/112 [00:01<00:00, 53.70it/s, Epoch: 31, Batch: 102,Loss: -2.224,Avg.Loss: -1.199,LR: 3.91E-04]Training epoch 31:  91%|█████████ | 102/112 [00:01<00:00, 53.70it/s, Epoch: 31, Batch: 103,Loss: -1.998,Avg.Loss: -1.207,LR: 3.91E-04]Training epoch 31:  92%|█████████▏| 103/112 [00:01<00:00, 53.70it/s, Epoch: 31, Batch: 104,Loss: -1.295,Avg.Loss: -1.208,LR: 3.91E-04]Training epoch 31:  93%|█████████▎| 104/112 [00:01<00:00, 53.89it/s, Epoch: 31, Batch: 104,Loss: -1.295,Avg.Loss: -1.208,LR: 3.91E-04]Training epoch 31:  93%|█████████▎| 104/112 [00:01<00:00, 53.89it/s, Epoch: 31, Batch: 105,Loss: -1.529,Avg.Loss: -1.211,LR: 3.91E-04]Training epoch 31:  94%|█████████▍| 105/112 [00:01<00:00, 53.89it/s, Epoch: 31, Batch: 106,Loss: -1.601,Avg.Loss: -1.215,LR: 3.91E-04]Training epoch 31:  95%|█████████▍| 106/112 [00:01<00:00, 53.89it/s, Epoch: 31, Batch: 107,Loss: -1.577,Avg.Loss: -1.218,LR: 3.91E-04]Training epoch 31:  96%|█████████▌| 107/112 [00:02<00:00, 53.89it/s, Epoch: 31, Batch: 108,Loss: -2.293,Avg.Loss: -1.228,LR: 3.91E-04]Training epoch 31:  96%|█████████▋| 108/112 [00:02<00:00, 53.89it/s, Epoch: 31, Batch: 109,Loss: -1.910,Avg.Loss: -1.234,LR: 3.91E-04]Training epoch 31:  97%|█████████▋| 109/112 [00:02<00:00, 53.89it/s, Epoch: 31, Batch: 110,Loss: -2.283,Avg.Loss: -1.244,LR: 3.91E-04]Training epoch 31:  98%|█████████▊| 110/112 [00:02<00:00, 54.12it/s, Epoch: 31, Batch: 110,Loss: -2.283,Avg.Loss: -1.244,LR: 3.91E-04]Training epoch 31:  98%|█████████▊| 110/112 [00:02<00:00, 54.12it/s, Epoch: 31, Batch: 111,Loss: -1.853,Avg.Loss: -1.249,LR: 3.91E-04]Training epoch 31:  99%|█████████▉| 111/112 [00:02<00:00, 54.12it/s, Epoch: 31, Batch: 112,Loss: -2.128,Avg.Loss: -1.257,LR: 3.91E-04]Training epoch 31: 100%|██████████| 112/112 [00:02<00:00, 53.57it/s, Epoch: 31, Batch: 112,Loss: -2.128,Avg.Loss: -1.257,LR: 3.91E-04]
Training epoch 32:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 32:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 32, Batch: 1,Loss: -1.905,Avg.Loss: -1.905,LR: 3.90E-04]Training epoch 32:   1%|          | 1/112 [00:00<00:04, 26.33it/s, Epoch: 32, Batch: 2,Loss: -1.913,Avg.Loss: -1.909,LR: 3.90E-04]Training epoch 32:   2%|▏         | 2/112 [00:00<00:02, 37.68it/s, Epoch: 32, Batch: 3,Loss: -1.747,Avg.Loss: -1.855,LR: 3.90E-04]Training epoch 32:   3%|▎         | 3/112 [00:00<00:02, 44.63it/s, Epoch: 32, Batch: 4,Loss: -1.982,Avg.Loss: -1.887,LR: 3.90E-04]Training epoch 32:   4%|▎         | 4/112 [00:00<00:02, 48.97it/s, Epoch: 32, Batch: 5,Loss: -1.719,Avg.Loss: -1.853,LR: 3.90E-04]Training epoch 32:   4%|▍         | 5/112 [00:00<00:02, 51.80it/s, Epoch: 32, Batch: 6,Loss: -1.666,Avg.Loss: -1.822,LR: 3.90E-04]Training epoch 32:   5%|▌         | 6/112 [00:00<00:01, 54.12it/s, Epoch: 32, Batch: 7,Loss: -1.910,Avg.Loss: -1.835,LR: 3.90E-04]Training epoch 32:   6%|▋         | 7/112 [00:00<00:01, 63.05it/s, Epoch: 32, Batch: 7,Loss: -1.910,Avg.Loss: -1.835,LR: 3.90E-04]Training epoch 32:   6%|▋         | 7/112 [00:00<00:01, 63.05it/s, Epoch: 32, Batch: 8,Loss: -0.903,Avg.Loss: -1.718,LR: 3.90E-04]Training epoch 32:   7%|▋         | 8/112 [00:00<00:01, 63.05it/s, Epoch: 32, Batch: 9,Loss: 0.830,Avg.Loss: -1.435,LR: 3.90E-04] Training epoch 32:   8%|▊         | 9/112 [00:00<00:01, 63.05it/s, Epoch: 32, Batch: 10,Loss: -0.602,Avg.Loss: -1.352,LR: 3.90E-04]Training epoch 32:   9%|▉         | 10/112 [00:00<00:01, 63.05it/s, Epoch: 32, Batch: 11,Loss: -0.813,Avg.Loss: -1.303,LR: 3.90E-04]Training epoch 32:  10%|▉         | 11/112 [00:00<00:01, 63.05it/s, Epoch: 32, Batch: 12,Loss: -1.316,Avg.Loss: -1.304,LR: 3.90E-04]Training epoch 32:  11%|█         | 12/112 [00:00<00:01, 63.05it/s, Epoch: 32, Batch: 13,Loss: -1.632,Avg.Loss: -1.329,LR: 3.90E-04]Training epoch 32:  12%|█▏        | 13/112 [00:00<00:01, 63.05it/s, Epoch: 32, Batch: 14,Loss: -1.378,Avg.Loss: -1.333,LR: 3.90E-04]Training epoch 32:  12%|█▎        | 14/112 [00:00<00:01, 56.97it/s, Epoch: 32, Batch: 14,Loss: -1.378,Avg.Loss: -1.333,LR: 3.90E-04]Training epoch 32:  12%|█▎        | 14/112 [00:00<00:01, 56.97it/s, Epoch: 32, Batch: 15,Loss: -0.660,Avg.Loss: -1.288,LR: 3.90E-04]Training epoch 32:  13%|█▎        | 15/112 [00:00<00:01, 56.97it/s, Epoch: 32, Batch: 16,Loss: -1.331,Avg.Loss: -1.290,LR: 3.90E-04]Training epoch 32:  14%|█▍        | 16/112 [00:00<00:01, 56.97it/s, Epoch: 32, Batch: 17,Loss: -0.938,Avg.Loss: -1.270,LR: 3.90E-04]Training epoch 32:  15%|█▌        | 17/112 [00:00<00:01, 56.97it/s, Epoch: 32, Batch: 18,Loss: -1.211,Avg.Loss: -1.266,LR: 3.89E-04]Training epoch 32:  16%|█▌        | 18/112 [00:00<00:01, 56.97it/s, Epoch: 32, Batch: 19,Loss: -2.221,Avg.Loss: -1.317,LR: 3.89E-04]Training epoch 32:  17%|█▋        | 19/112 [00:00<00:01, 56.97it/s, Epoch: 32, Batch: 20,Loss: -0.627,Avg.Loss: -1.282,LR: 3.89E-04]Training epoch 32:  18%|█▊        | 20/112 [00:00<00:01, 55.63it/s, Epoch: 32, Batch: 20,Loss: -0.627,Avg.Loss: -1.282,LR: 3.89E-04]Training epoch 32:  18%|█▊        | 20/112 [00:00<00:01, 55.63it/s, Epoch: 32, Batch: 21,Loss: 0.772,Avg.Loss: -1.184,LR: 3.89E-04] Training epoch 32:  19%|█▉        | 21/112 [00:00<00:01, 55.63it/s, Epoch: 32, Batch: 22,Loss: 0.058,Avg.Loss: -1.128,LR: 3.89E-04]Training epoch 32:  20%|█▉        | 22/112 [00:00<00:01, 55.63it/s, Epoch: 32, Batch: 23,Loss: -1.458,Avg.Loss: -1.142,LR: 3.89E-04]Training epoch 32:  21%|██        | 23/112 [00:00<00:01, 55.63it/s, Epoch: 32, Batch: 24,Loss: -0.334,Avg.Loss: -1.109,LR: 3.89E-04]Training epoch 32:  21%|██▏       | 24/112 [00:00<00:01, 55.63it/s, Epoch: 32, Batch: 25,Loss: 0.638,Avg.Loss: -1.039,LR: 3.89E-04] Training epoch 32:  22%|██▏       | 25/112 [00:00<00:01, 55.63it/s, Epoch: 32, Batch: 26,Loss: -0.714,Avg.Loss: -1.026,LR: 3.89E-04]Training epoch 32:  23%|██▎       | 26/112 [00:00<00:01, 53.79it/s, Epoch: 32, Batch: 26,Loss: -0.714,Avg.Loss: -1.026,LR: 3.89E-04]Training epoch 32:  23%|██▎       | 26/112 [00:00<00:01, 53.79it/s, Epoch: 32, Batch: 27,Loss: -1.660,Avg.Loss: -1.050,LR: 3.89E-04]Training epoch 32:  24%|██▍       | 27/112 [00:00<00:01, 53.79it/s, Epoch: 32, Batch: 28,Loss: 1.310,Avg.Loss: -0.965,LR: 3.89E-04] Training epoch 32:  25%|██▌       | 28/112 [00:00<00:01, 53.79it/s, Epoch: 32, Batch: 29,Loss: 5.887,Avg.Loss: -0.729,LR: 3.89E-04]Training epoch 32:  26%|██▌       | 29/112 [00:00<00:01, 53.79it/s, Epoch: 32, Batch: 30,Loss: 4.214,Avg.Loss: -0.564,LR: 3.89E-04]Training epoch 32:  27%|██▋       | 30/112 [00:00<00:01, 53.79it/s, Epoch: 32, Batch: 31,Loss: 0.904,Avg.Loss: -0.517,LR: 3.89E-04]Training epoch 32:  28%|██▊       | 31/112 [00:00<00:01, 53.79it/s, Epoch: 32, Batch: 32,Loss: -1.724,Avg.Loss: -0.555,LR: 3.89E-04]Training epoch 32:  29%|██▊       | 32/112 [00:00<00:01, 52.87it/s, Epoch: 32, Batch: 32,Loss: -1.724,Avg.Loss: -0.555,LR: 3.89E-04]Training epoch 32:  29%|██▊       | 32/112 [00:00<00:01, 52.87it/s, Epoch: 32, Batch: 33,Loss: 0.154,Avg.Loss: -0.533,LR: 3.89E-04] Training epoch 32:  29%|██▉       | 33/112 [00:00<00:01, 52.87it/s, Epoch: 32, Batch: 34,Loss: 2.044,Avg.Loss: -0.457,LR: 3.89E-04]Training epoch 32:  30%|███       | 34/112 [00:00<00:01, 52.87it/s, Epoch: 32, Batch: 35,Loss: 2.560,Avg.Loss: -0.371,LR: 3.88E-04]Training epoch 32:  31%|███▏      | 35/112 [00:00<00:01, 52.87it/s, Epoch: 32, Batch: 36,Loss: -0.290,Avg.Loss: -0.369,LR: 3.88E-04]Training epoch 32:  32%|███▏      | 36/112 [00:00<00:01, 52.87it/s, Epoch: 32, Batch: 37,Loss: -1.407,Avg.Loss: -0.397,LR: 3.88E-04]Training epoch 32:  33%|███▎      | 37/112 [00:00<00:01, 52.87it/s, Epoch: 32, Batch: 38,Loss: -1.072,Avg.Loss: -0.415,LR: 3.88E-04]Training epoch 32:  34%|███▍      | 38/112 [00:00<00:01, 52.98it/s, Epoch: 32, Batch: 38,Loss: -1.072,Avg.Loss: -0.415,LR: 3.88E-04]Training epoch 32:  34%|███▍      | 38/112 [00:00<00:01, 52.98it/s, Epoch: 32, Batch: 39,Loss: -1.318,Avg.Loss: -0.438,LR: 3.88E-04]Training epoch 32:  35%|███▍      | 39/112 [00:00<00:01, 52.98it/s, Epoch: 32, Batch: 40,Loss: -2.191,Avg.Loss: -0.482,LR: 3.88E-04]Training epoch 32:  36%|███▌      | 40/112 [00:00<00:01, 52.98it/s, Epoch: 32, Batch: 41,Loss: -2.042,Avg.Loss: -0.520,LR: 3.88E-04]Training epoch 32:  37%|███▋      | 41/112 [00:00<00:01, 52.98it/s, Epoch: 32, Batch: 42,Loss: -1.573,Avg.Loss: -0.545,LR: 3.88E-04]Training epoch 32:  38%|███▊      | 42/112 [00:00<00:01, 52.98it/s, Epoch: 32, Batch: 43,Loss: -1.887,Avg.Loss: -0.576,LR: 3.88E-04]Training epoch 32:  38%|███▊      | 43/112 [00:00<00:01, 52.98it/s, Epoch: 32, Batch: 44,Loss: -1.969,Avg.Loss: -0.608,LR: 3.88E-04]Training epoch 32:  39%|███▉      | 44/112 [00:00<00:01, 51.35it/s, Epoch: 32, Batch: 44,Loss: -1.969,Avg.Loss: -0.608,LR: 3.88E-04]Training epoch 32:  39%|███▉      | 44/112 [00:00<00:01, 51.35it/s, Epoch: 32, Batch: 45,Loss: -1.953,Avg.Loss: -0.638,LR: 3.88E-04]Training epoch 32:  40%|████      | 45/112 [00:00<00:01, 51.35it/s, Epoch: 32, Batch: 46,Loss: -1.508,Avg.Loss: -0.657,LR: 3.88E-04]Training epoch 32:  41%|████      | 46/112 [00:00<00:01, 51.35it/s, Epoch: 32, Batch: 47,Loss: -1.752,Avg.Loss: -0.680,LR: 3.88E-04]Training epoch 32:  42%|████▏     | 47/112 [00:00<00:01, 51.35it/s, Epoch: 32, Batch: 48,Loss: -1.685,Avg.Loss: -0.701,LR: 3.88E-04]Training epoch 32:  43%|████▎     | 48/112 [00:00<00:01, 51.35it/s, Epoch: 32, Batch: 49,Loss: -1.760,Avg.Loss: -0.722,LR: 3.88E-04]Training epoch 32:  44%|████▍     | 49/112 [00:00<00:01, 51.35it/s, Epoch: 32, Batch: 50,Loss: -2.311,Avg.Loss: -0.754,LR: 3.88E-04]Training epoch 32:  45%|████▍     | 50/112 [00:00<00:01, 52.06it/s, Epoch: 32, Batch: 50,Loss: -2.311,Avg.Loss: -0.754,LR: 3.88E-04]Training epoch 32:  45%|████▍     | 50/112 [00:00<00:01, 52.06it/s, Epoch: 32, Batch: 51,Loss: -1.763,Avg.Loss: -0.774,LR: 3.88E-04]Training epoch 32:  46%|████▌     | 51/112 [00:00<00:01, 52.06it/s, Epoch: 32, Batch: 52,Loss: -1.606,Avg.Loss: -0.790,LR: 3.87E-04]Training epoch 32:  46%|████▋     | 52/112 [00:00<00:01, 52.06it/s, Epoch: 32, Batch: 53,Loss: -2.070,Avg.Loss: -0.814,LR: 3.87E-04]Training epoch 32:  47%|████▋     | 53/112 [00:01<00:01, 52.06it/s, Epoch: 32, Batch: 54,Loss: -1.757,Avg.Loss: -0.832,LR: 3.87E-04]Training epoch 32:  48%|████▊     | 54/112 [00:01<00:01, 52.06it/s, Epoch: 32, Batch: 55,Loss: -1.747,Avg.Loss: -0.848,LR: 3.87E-04]Training epoch 32:  49%|████▉     | 55/112 [00:01<00:01, 52.06it/s, Epoch: 32, Batch: 56,Loss: -2.054,Avg.Loss: -0.870,LR: 3.87E-04]Training epoch 32:  50%|█████     | 56/112 [00:01<00:01, 52.27it/s, Epoch: 32, Batch: 56,Loss: -2.054,Avg.Loss: -0.870,LR: 3.87E-04]Training epoch 32:  50%|█████     | 56/112 [00:01<00:01, 52.27it/s, Epoch: 32, Batch: 57,Loss: -1.057,Avg.Loss: -0.873,LR: 3.87E-04]Training epoch 32:  51%|█████     | 57/112 [00:01<00:01, 52.27it/s, Epoch: 32, Batch: 58,Loss: -0.425,Avg.Loss: -0.865,LR: 3.87E-04]Training epoch 32:  52%|█████▏    | 58/112 [00:01<00:01, 52.27it/s, Epoch: 32, Batch: 59,Loss: -1.217,Avg.Loss: -0.871,LR: 3.87E-04]Training epoch 32:  53%|█████▎    | 59/112 [00:01<00:01, 52.27it/s, Epoch: 32, Batch: 60,Loss: -1.951,Avg.Loss: -0.889,LR: 3.87E-04]Training epoch 32:  54%|█████▎    | 60/112 [00:01<00:00, 52.27it/s, Epoch: 32, Batch: 61,Loss: -1.479,Avg.Loss: -0.899,LR: 3.87E-04]Training epoch 32:  54%|█████▍    | 61/112 [00:01<00:00, 52.27it/s, Epoch: 32, Batch: 62,Loss: -1.952,Avg.Loss: -0.916,LR: 3.87E-04]Training epoch 32:  55%|█████▌    | 62/112 [00:01<00:00, 52.65it/s, Epoch: 32, Batch: 62,Loss: -1.952,Avg.Loss: -0.916,LR: 3.87E-04]Training epoch 32:  55%|█████▌    | 62/112 [00:01<00:00, 52.65it/s, Epoch: 32, Batch: 63,Loss: -1.746,Avg.Loss: -0.929,LR: 3.87E-04]Training epoch 32:  56%|█████▋    | 63/112 [00:01<00:00, 52.65it/s, Epoch: 32, Batch: 64,Loss: -1.836,Avg.Loss: -0.943,LR: 3.87E-04]Training epoch 32:  57%|█████▋    | 64/112 [00:01<00:00, 52.65it/s, Epoch: 32, Batch: 65,Loss: -1.578,Avg.Loss: -0.953,LR: 3.87E-04]Training epoch 32:  58%|█████▊    | 65/112 [00:01<00:00, 52.65it/s, Epoch: 32, Batch: 66,Loss: -1.293,Avg.Loss: -0.958,LR: 3.87E-04]Training epoch 32:  59%|█████▉    | 66/112 [00:01<00:00, 52.65it/s, Epoch: 32, Batch: 67,Loss: -1.900,Avg.Loss: -0.972,LR: 3.87E-04]Training epoch 32:  60%|█████▉    | 67/112 [00:01<00:00, 52.65it/s, Epoch: 32, Batch: 68,Loss: -2.166,Avg.Loss: -0.990,LR: 3.87E-04]Training epoch 32:  61%|██████    | 68/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 68,Loss: -2.166,Avg.Loss: -0.990,LR: 3.87E-04]Training epoch 32:  61%|██████    | 68/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 69,Loss: -2.332,Avg.Loss: -1.009,LR: 3.86E-04]Training epoch 32:  62%|██████▏   | 69/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 70,Loss: -2.046,Avg.Loss: -1.024,LR: 3.86E-04]Training epoch 32:  62%|██████▎   | 70/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 71,Loss: -2.084,Avg.Loss: -1.039,LR: 3.86E-04]Training epoch 32:  63%|██████▎   | 71/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 72,Loss: -1.981,Avg.Loss: -1.052,LR: 3.86E-04]Training epoch 32:  64%|██████▍   | 72/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 73,Loss: -2.105,Avg.Loss: -1.067,LR: 3.86E-04]Training epoch 32:  65%|██████▌   | 73/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 74,Loss: -1.692,Avg.Loss: -1.075,LR: 3.86E-04]Training epoch 32:  66%|██████▌   | 74/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 74,Loss: -1.692,Avg.Loss: -1.075,LR: 3.86E-04]Training epoch 32:  66%|██████▌   | 74/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 75,Loss: -2.256,Avg.Loss: -1.091,LR: 3.86E-04]Training epoch 32:  67%|██████▋   | 75/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 76,Loss: -2.314,Avg.Loss: -1.107,LR: 3.86E-04]Training epoch 32:  68%|██████▊   | 76/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 77,Loss: -2.128,Avg.Loss: -1.120,LR: 3.86E-04]Training epoch 32:  69%|██████▉   | 77/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 78,Loss: -1.683,Avg.Loss: -1.127,LR: 3.86E-04]Training epoch 32:  70%|██████▉   | 78/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 79,Loss: -1.821,Avg.Loss: -1.136,LR: 3.86E-04]Training epoch 32:  71%|███████   | 79/112 [00:01<00:00, 52.87it/s, Epoch: 32, Batch: 80,Loss: -1.876,Avg.Loss: -1.145,LR: 3.86E-04]Training epoch 32:  71%|███████▏  | 80/112 [00:01<00:00, 52.91it/s, Epoch: 32, Batch: 80,Loss: -1.876,Avg.Loss: -1.145,LR: 3.86E-04]Training epoch 32:  71%|███████▏  | 80/112 [00:01<00:00, 52.91it/s, Epoch: 32, Batch: 81,Loss: -2.135,Avg.Loss: -1.158,LR: 3.86E-04]Training epoch 32:  72%|███████▏  | 81/112 [00:01<00:00, 52.91it/s, Epoch: 32, Batch: 82,Loss: -1.675,Avg.Loss: -1.164,LR: 3.86E-04]Training epoch 32:  73%|███████▎  | 82/112 [00:01<00:00, 52.91it/s, Epoch: 32, Batch: 83,Loss: -1.850,Avg.Loss: -1.172,LR: 3.86E-04]Training epoch 32:  74%|███████▍  | 83/112 [00:01<00:00, 52.91it/s, Epoch: 32, Batch: 84,Loss: -1.994,Avg.Loss: -1.182,LR: 3.86E-04]Training epoch 32:  75%|███████▌  | 84/112 [00:01<00:00, 52.91it/s, Epoch: 32, Batch: 85,Loss: -2.401,Avg.Loss: -1.196,LR: 3.86E-04]Training epoch 32:  76%|███████▌  | 85/112 [00:01<00:00, 52.91it/s, Epoch: 32, Batch: 86,Loss: -2.418,Avg.Loss: -1.210,LR: 3.85E-04]Training epoch 32:  77%|███████▋  | 86/112 [00:01<00:00, 53.02it/s, Epoch: 32, Batch: 86,Loss: -2.418,Avg.Loss: -1.210,LR: 3.85E-04]Training epoch 32:  77%|███████▋  | 86/112 [00:01<00:00, 53.02it/s, Epoch: 32, Batch: 87,Loss: -1.961,Avg.Loss: -1.219,LR: 3.85E-04]Training epoch 32:  78%|███████▊  | 87/112 [00:01<00:00, 53.02it/s, Epoch: 32, Batch: 88,Loss: -1.530,Avg.Loss: -1.223,LR: 3.85E-04]Training epoch 32:  79%|███████▊  | 88/112 [00:01<00:00, 53.02it/s, Epoch: 32, Batch: 89,Loss: -2.058,Avg.Loss: -1.232,LR: 3.85E-04]Training epoch 32:  79%|███████▉  | 89/112 [00:01<00:00, 53.02it/s, Epoch: 32, Batch: 90,Loss: -1.424,Avg.Loss: -1.234,LR: 3.85E-04]Training epoch 32:  80%|████████  | 90/112 [00:01<00:00, 53.02it/s, Epoch: 32, Batch: 91,Loss: -2.397,Avg.Loss: -1.247,LR: 3.85E-04]Training epoch 32:  81%|████████▏ | 91/112 [00:01<00:00, 53.02it/s, Epoch: 32, Batch: 92,Loss: -2.223,Avg.Loss: -1.258,LR: 3.85E-04]Training epoch 32:  82%|████████▏ | 92/112 [00:01<00:00, 53.00it/s, Epoch: 32, Batch: 92,Loss: -2.223,Avg.Loss: -1.258,LR: 3.85E-04]Training epoch 32:  82%|████████▏ | 92/112 [00:01<00:00, 53.00it/s, Epoch: 32, Batch: 93,Loss: -1.922,Avg.Loss: -1.265,LR: 3.85E-04]Training epoch 32:  83%|████████▎ | 93/112 [00:01<00:00, 53.00it/s, Epoch: 32, Batch: 94,Loss: -1.825,Avg.Loss: -1.271,LR: 3.85E-04]Training epoch 32:  84%|████████▍ | 94/112 [00:01<00:00, 53.00it/s, Epoch: 32, Batch: 95,Loss: -2.067,Avg.Loss: -1.279,LR: 3.85E-04]Training epoch 32:  85%|████████▍ | 95/112 [00:01<00:00, 53.00it/s, Epoch: 32, Batch: 96,Loss: -1.856,Avg.Loss: -1.285,LR: 3.85E-04]Training epoch 32:  86%|████████▌ | 96/112 [00:01<00:00, 53.00it/s, Epoch: 32, Batch: 97,Loss: -2.249,Avg.Loss: -1.295,LR: 3.85E-04]Training epoch 32:  87%|████████▋ | 97/112 [00:01<00:00, 53.00it/s, Epoch: 32, Batch: 98,Loss: -2.527,Avg.Loss: -1.308,LR: 3.85E-04]Training epoch 32:  88%|████████▊ | 98/112 [00:01<00:00, 53.12it/s, Epoch: 32, Batch: 98,Loss: -2.527,Avg.Loss: -1.308,LR: 3.85E-04]Training epoch 32:  88%|████████▊ | 98/112 [00:01<00:00, 53.12it/s, Epoch: 32, Batch: 99,Loss: -1.605,Avg.Loss: -1.311,LR: 3.85E-04]Training epoch 32:  88%|████████▊ | 99/112 [00:01<00:00, 53.12it/s, Epoch: 32, Batch: 100,Loss: -1.594,Avg.Loss: -1.313,LR: 3.85E-04]Training epoch 32:  89%|████████▉ | 100/112 [00:01<00:00, 53.12it/s, Epoch: 32, Batch: 101,Loss: -1.937,Avg.Loss: -1.320,LR: 3.85E-04]Training epoch 32:  90%|█████████ | 101/112 [00:01<00:00, 53.12it/s, Epoch: 32, Batch: 102,Loss: -2.346,Avg.Loss: -1.330,LR: 3.85E-04]Training epoch 32:  91%|█████████ | 102/112 [00:01<00:00, 53.12it/s, Epoch: 32, Batch: 103,Loss: -2.307,Avg.Loss: -1.339,LR: 3.84E-04]Training epoch 32:  92%|█████████▏| 103/112 [00:01<00:00, 53.12it/s, Epoch: 32, Batch: 104,Loss: -2.181,Avg.Loss: -1.347,LR: 3.84E-04]Training epoch 32:  93%|█████████▎| 104/112 [00:01<00:00, 52.98it/s, Epoch: 32, Batch: 104,Loss: -2.181,Avg.Loss: -1.347,LR: 3.84E-04]Training epoch 32:  93%|█████████▎| 104/112 [00:01<00:00, 52.98it/s, Epoch: 32, Batch: 105,Loss: -2.410,Avg.Loss: -1.357,LR: 3.84E-04]Training epoch 32:  94%|█████████▍| 105/112 [00:01<00:00, 52.98it/s, Epoch: 32, Batch: 106,Loss: -2.450,Avg.Loss: -1.368,LR: 3.84E-04]Training epoch 32:  95%|█████████▍| 106/112 [00:02<00:00, 52.98it/s, Epoch: 32, Batch: 107,Loss: -2.139,Avg.Loss: -1.375,LR: 3.84E-04]Training epoch 32:  96%|█████████▌| 107/112 [00:02<00:00, 52.98it/s, Epoch: 32, Batch: 108,Loss: -2.529,Avg.Loss: -1.386,LR: 3.84E-04]Training epoch 32:  96%|█████████▋| 108/112 [00:02<00:00, 52.98it/s, Epoch: 32, Batch: 109,Loss: -0.805,Avg.Loss: -1.380,LR: 3.84E-04]Training epoch 32:  97%|█████████▋| 109/112 [00:02<00:00, 52.98it/s, Epoch: 32, Batch: 110,Loss: -0.855,Avg.Loss: -1.375,LR: 3.84E-04]Training epoch 32:  98%|█████████▊| 110/112 [00:02<00:00, 53.15it/s, Epoch: 32, Batch: 110,Loss: -0.855,Avg.Loss: -1.375,LR: 3.84E-04]Training epoch 32:  98%|█████████▊| 110/112 [00:02<00:00, 53.15it/s, Epoch: 32, Batch: 111,Loss: -1.533,Avg.Loss: -1.377,LR: 3.84E-04]Training epoch 32:  99%|█████████▉| 111/112 [00:02<00:00, 53.15it/s, Epoch: 32, Batch: 112,Loss: -0.511,Avg.Loss: -1.369,LR: 3.84E-04]Training epoch 32: 100%|██████████| 112/112 [00:02<00:00, 53.16it/s, Epoch: 32, Batch: 112,Loss: -0.511,Avg.Loss: -1.369,LR: 3.84E-04]
Training epoch 33:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 33:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 33, Batch: 1,Loss: 0.502,Avg.Loss: 0.502,LR: 3.84E-04]Training epoch 33:   1%|          | 1/112 [00:00<00:04, 25.57it/s, Epoch: 33, Batch: 2,Loss: -0.590,Avg.Loss: -0.044,LR: 3.84E-04]Training epoch 33:   2%|▏         | 2/112 [00:00<00:03, 31.83it/s, Epoch: 33, Batch: 3,Loss: -2.241,Avg.Loss: -0.776,LR: 3.84E-04]Training epoch 33:   3%|▎         | 3/112 [00:00<00:03, 36.05it/s, Epoch: 33, Batch: 4,Loss: -1.857,Avg.Loss: -1.047,LR: 3.84E-04]Training epoch 33:   4%|▎         | 4/112 [00:00<00:02, 40.27it/s, Epoch: 33, Batch: 5,Loss: -0.860,Avg.Loss: -1.009,LR: 3.84E-04]Training epoch 33:   4%|▍         | 5/112 [00:00<00:02, 43.10it/s, Epoch: 33, Batch: 6,Loss: -0.215,Avg.Loss: -0.877,LR: 3.84E-04]Training epoch 33:   5%|▌         | 6/112 [00:00<00:02, 51.64it/s, Epoch: 33, Batch: 6,Loss: -0.215,Avg.Loss: -0.877,LR: 3.84E-04]Training epoch 33:   5%|▌         | 6/112 [00:00<00:02, 51.64it/s, Epoch: 33, Batch: 7,Loss: 0.861,Avg.Loss: -0.629,LR: 3.84E-04] Training epoch 33:   6%|▋         | 7/112 [00:00<00:02, 51.64it/s, Epoch: 33, Batch: 8,Loss: 0.378,Avg.Loss: -0.503,LR: 3.83E-04]Training epoch 33:   7%|▋         | 8/112 [00:00<00:02, 51.64it/s, Epoch: 33, Batch: 9,Loss: -0.260,Avg.Loss: -0.476,LR: 3.83E-04]Training epoch 33:   8%|▊         | 9/112 [00:00<00:01, 51.64it/s, Epoch: 33, Batch: 10,Loss: -0.786,Avg.Loss: -0.507,LR: 3.83E-04]Training epoch 33:   9%|▉         | 10/112 [00:00<00:01, 51.64it/s, Epoch: 33, Batch: 11,Loss: 0.079,Avg.Loss: -0.454,LR: 3.83E-04]Training epoch 33:  10%|▉         | 11/112 [00:00<00:01, 51.64it/s, Epoch: 33, Batch: 12,Loss: -0.099,Avg.Loss: -0.424,LR: 3.83E-04]Training epoch 33:  11%|█         | 12/112 [00:00<00:01, 55.33it/s, Epoch: 33, Batch: 12,Loss: -0.099,Avg.Loss: -0.424,LR: 3.83E-04]Training epoch 33:  11%|█         | 12/112 [00:00<00:01, 55.33it/s, Epoch: 33, Batch: 13,Loss: -1.629,Avg.Loss: -0.517,LR: 3.83E-04]Training epoch 33:  12%|█▏        | 13/112 [00:00<00:01, 55.33it/s, Epoch: 33, Batch: 14,Loss: -1.156,Avg.Loss: -0.562,LR: 3.83E-04]Training epoch 33:  12%|█▎        | 14/112 [00:00<00:01, 55.33it/s, Epoch: 33, Batch: 15,Loss: -1.950,Avg.Loss: -0.655,LR: 3.83E-04]Training epoch 33:  13%|█▎        | 15/112 [00:00<00:01, 55.33it/s, Epoch: 33, Batch: 16,Loss: -1.695,Avg.Loss: -0.720,LR: 3.83E-04]Training epoch 33:  14%|█▍        | 16/112 [00:00<00:01, 55.33it/s, Epoch: 33, Batch: 17,Loss: -0.959,Avg.Loss: -0.734,LR: 3.83E-04]Training epoch 33:  15%|█▌        | 17/112 [00:00<00:01, 55.33it/s, Epoch: 33, Batch: 18,Loss: -1.647,Avg.Loss: -0.785,LR: 3.83E-04]Training epoch 33:  16%|█▌        | 18/112 [00:00<00:01, 54.69it/s, Epoch: 33, Batch: 18,Loss: -1.647,Avg.Loss: -0.785,LR: 3.83E-04]Training epoch 33:  16%|█▌        | 18/112 [00:00<00:01, 54.69it/s, Epoch: 33, Batch: 19,Loss: -1.372,Avg.Loss: -0.816,LR: 3.83E-04]Training epoch 33:  17%|█▋        | 19/112 [00:00<00:01, 54.69it/s, Epoch: 33, Batch: 20,Loss: -0.307,Avg.Loss: -0.790,LR: 3.83E-04]Training epoch 33:  18%|█▊        | 20/112 [00:00<00:01, 54.69it/s, Epoch: 33, Batch: 21,Loss: -1.859,Avg.Loss: -0.841,LR: 3.83E-04]Training epoch 33:  19%|█▉        | 21/112 [00:00<00:01, 54.69it/s, Epoch: 33, Batch: 22,Loss: -1.855,Avg.Loss: -0.887,LR: 3.83E-04]Training epoch 33:  20%|█▉        | 22/112 [00:00<00:01, 54.69it/s, Epoch: 33, Batch: 23,Loss: -0.719,Avg.Loss: -0.880,LR: 3.83E-04]Training epoch 33:  21%|██        | 23/112 [00:00<00:01, 54.69it/s, Epoch: 33, Batch: 24,Loss: -2.017,Avg.Loss: -0.927,LR: 3.83E-04]Training epoch 33:  21%|██▏       | 24/112 [00:00<00:01, 53.88it/s, Epoch: 33, Batch: 24,Loss: -2.017,Avg.Loss: -0.927,LR: 3.83E-04]Training epoch 33:  21%|██▏       | 24/112 [00:00<00:01, 53.88it/s, Epoch: 33, Batch: 25,Loss: -2.006,Avg.Loss: -0.970,LR: 3.82E-04]Training epoch 33:  22%|██▏       | 25/112 [00:00<00:01, 53.88it/s, Epoch: 33, Batch: 26,Loss: -0.867,Avg.Loss: -0.966,LR: 3.82E-04]Training epoch 33:  23%|██▎       | 26/112 [00:00<00:01, 53.88it/s, Epoch: 33, Batch: 27,Loss: -1.779,Avg.Loss: -0.996,LR: 3.82E-04]Training epoch 33:  24%|██▍       | 27/112 [00:00<00:01, 53.88it/s, Epoch: 33, Batch: 28,Loss: -1.300,Avg.Loss: -1.007,LR: 3.82E-04]Training epoch 33:  25%|██▌       | 28/112 [00:00<00:01, 53.88it/s, Epoch: 33, Batch: 29,Loss: -1.322,Avg.Loss: -1.018,LR: 3.82E-04]Training epoch 33:  26%|██▌       | 29/112 [00:00<00:01, 53.88it/s, Epoch: 33, Batch: 30,Loss: -1.830,Avg.Loss: -1.045,LR: 3.82E-04]Training epoch 33:  27%|██▋       | 30/112 [00:00<00:01, 53.68it/s, Epoch: 33, Batch: 30,Loss: -1.830,Avg.Loss: -1.045,LR: 3.82E-04]Training epoch 33:  27%|██▋       | 30/112 [00:00<00:01, 53.68it/s, Epoch: 33, Batch: 31,Loss: -1.867,Avg.Loss: -1.072,LR: 3.82E-04]Training epoch 33:  28%|██▊       | 31/112 [00:00<00:01, 53.68it/s, Epoch: 33, Batch: 32,Loss: -1.436,Avg.Loss: -1.083,LR: 3.82E-04]Training epoch 33:  29%|██▊       | 32/112 [00:00<00:01, 53.68it/s, Epoch: 33, Batch: 33,Loss: -2.239,Avg.Loss: -1.118,LR: 3.82E-04]Training epoch 33:  29%|██▉       | 33/112 [00:00<00:01, 53.68it/s, Epoch: 33, Batch: 34,Loss: -1.809,Avg.Loss: -1.138,LR: 3.82E-04]Training epoch 33:  30%|███       | 34/112 [00:00<00:01, 53.68it/s, Epoch: 33, Batch: 35,Loss: -1.310,Avg.Loss: -1.143,LR: 3.82E-04]Training epoch 33:  31%|███▏      | 35/112 [00:00<00:01, 53.68it/s, Epoch: 33, Batch: 36,Loss: -2.072,Avg.Loss: -1.169,LR: 3.82E-04]Training epoch 33:  32%|███▏      | 36/112 [00:00<00:01, 53.60it/s, Epoch: 33, Batch: 36,Loss: -2.072,Avg.Loss: -1.169,LR: 3.82E-04]Training epoch 33:  32%|███▏      | 36/112 [00:00<00:01, 53.60it/s, Epoch: 33, Batch: 37,Loss: -2.317,Avg.Loss: -1.200,LR: 3.82E-04]Training epoch 33:  33%|███▎      | 37/112 [00:00<00:01, 53.60it/s, Epoch: 33, Batch: 38,Loss: -1.199,Avg.Loss: -1.200,LR: 3.82E-04]Training epoch 33:  34%|███▍      | 38/112 [00:00<00:01, 53.60it/s, Epoch: 33, Batch: 39,Loss: -2.128,Avg.Loss: -1.224,LR: 3.82E-04]Training epoch 33:  35%|███▍      | 39/112 [00:00<00:01, 53.60it/s, Epoch: 33, Batch: 40,Loss: -1.953,Avg.Loss: -1.242,LR: 3.82E-04]Training epoch 33:  36%|███▌      | 40/112 [00:00<00:01, 53.60it/s, Epoch: 33, Batch: 41,Loss: -1.523,Avg.Loss: -1.249,LR: 3.82E-04]Training epoch 33:  37%|███▋      | 41/112 [00:00<00:01, 53.60it/s, Epoch: 33, Batch: 42,Loss: -2.242,Avg.Loss: -1.273,LR: 3.81E-04]Training epoch 33:  38%|███▊      | 42/112 [00:00<00:01, 53.79it/s, Epoch: 33, Batch: 42,Loss: -2.242,Avg.Loss: -1.273,LR: 3.81E-04]Training epoch 33:  38%|███▊      | 42/112 [00:00<00:01, 53.79it/s, Epoch: 33, Batch: 43,Loss: -1.924,Avg.Loss: -1.288,LR: 3.81E-04]Training epoch 33:  38%|███▊      | 43/112 [00:00<00:01, 53.79it/s, Epoch: 33, Batch: 44,Loss: -1.173,Avg.Loss: -1.285,LR: 3.81E-04]Training epoch 33:  39%|███▉      | 44/112 [00:00<00:01, 53.79it/s, Epoch: 33, Batch: 45,Loss: -2.149,Avg.Loss: -1.304,LR: 3.81E-04]Training epoch 33:  40%|████      | 45/112 [00:00<00:01, 53.79it/s, Epoch: 33, Batch: 46,Loss: -1.894,Avg.Loss: -1.317,LR: 3.81E-04]Training epoch 33:  41%|████      | 46/112 [00:00<00:01, 53.79it/s, Epoch: 33, Batch: 47,Loss: -1.747,Avg.Loss: -1.326,LR: 3.81E-04]Training epoch 33:  42%|████▏     | 47/112 [00:00<00:01, 53.79it/s, Epoch: 33, Batch: 48,Loss: -2.490,Avg.Loss: -1.351,LR: 3.81E-04]Training epoch 33:  43%|████▎     | 48/112 [00:00<00:01, 53.41it/s, Epoch: 33, Batch: 48,Loss: -2.490,Avg.Loss: -1.351,LR: 3.81E-04]Training epoch 33:  43%|████▎     | 48/112 [00:00<00:01, 53.41it/s, Epoch: 33, Batch: 49,Loss: -1.662,Avg.Loss: -1.357,LR: 3.81E-04]Training epoch 33:  44%|████▍     | 49/112 [00:00<00:01, 53.41it/s, Epoch: 33, Batch: 50,Loss: -0.677,Avg.Loss: -1.343,LR: 3.81E-04]Training epoch 33:  45%|████▍     | 50/112 [00:00<00:01, 53.41it/s, Epoch: 33, Batch: 51,Loss: -1.649,Avg.Loss: -1.349,LR: 3.81E-04]Training epoch 33:  46%|████▌     | 51/112 [00:00<00:01, 53.41it/s, Epoch: 33, Batch: 52,Loss: -2.173,Avg.Loss: -1.365,LR: 3.81E-04]Training epoch 33:  46%|████▋     | 52/112 [00:00<00:01, 53.41it/s, Epoch: 33, Batch: 53,Loss: -1.883,Avg.Loss: -1.375,LR: 3.81E-04]Training epoch 33:  47%|████▋     | 53/112 [00:01<00:01, 53.41it/s, Epoch: 33, Batch: 54,Loss: -1.992,Avg.Loss: -1.386,LR: 3.81E-04]Training epoch 33:  48%|████▊     | 54/112 [00:01<00:01, 53.36it/s, Epoch: 33, Batch: 54,Loss: -1.992,Avg.Loss: -1.386,LR: 3.81E-04]Training epoch 33:  48%|████▊     | 54/112 [00:01<00:01, 53.36it/s, Epoch: 33, Batch: 55,Loss: -2.059,Avg.Loss: -1.399,LR: 3.81E-04]Training epoch 33:  49%|████▉     | 55/112 [00:01<00:01, 53.36it/s, Epoch: 33, Batch: 56,Loss: -1.341,Avg.Loss: -1.398,LR: 3.81E-04]Training epoch 33:  50%|█████     | 56/112 [00:01<00:01, 53.36it/s, Epoch: 33, Batch: 57,Loss: -2.335,Avg.Loss: -1.414,LR: 3.81E-04]Training epoch 33:  51%|█████     | 57/112 [00:01<00:01, 53.36it/s, Epoch: 33, Batch: 58,Loss: -1.983,Avg.Loss: -1.424,LR: 3.81E-04]Training epoch 33:  52%|█████▏    | 58/112 [00:01<00:01, 53.36it/s, Epoch: 33, Batch: 59,Loss: -1.695,Avg.Loss: -1.428,LR: 3.80E-04]Training epoch 33:  53%|█████▎    | 59/112 [00:01<00:00, 53.36it/s, Epoch: 33, Batch: 60,Loss: -2.101,Avg.Loss: -1.440,LR: 3.80E-04]Training epoch 33:  54%|█████▎    | 60/112 [00:01<00:00, 53.31it/s, Epoch: 33, Batch: 60,Loss: -2.101,Avg.Loss: -1.440,LR: 3.80E-04]Training epoch 33:  54%|█████▎    | 60/112 [00:01<00:00, 53.31it/s, Epoch: 33, Batch: 61,Loss: -1.962,Avg.Loss: -1.448,LR: 3.80E-04]Training epoch 33:  54%|█████▍    | 61/112 [00:01<00:00, 53.31it/s, Epoch: 33, Batch: 62,Loss: -0.688,Avg.Loss: -1.436,LR: 3.80E-04]Training epoch 33:  55%|█████▌    | 62/112 [00:01<00:00, 53.31it/s, Epoch: 33, Batch: 63,Loss: -1.707,Avg.Loss: -1.440,LR: 3.80E-04]Training epoch 33:  56%|█████▋    | 63/112 [00:01<00:00, 53.31it/s, Epoch: 33, Batch: 64,Loss: -2.055,Avg.Loss: -1.450,LR: 3.80E-04]Training epoch 33:  57%|█████▋    | 64/112 [00:01<00:00, 53.31it/s, Epoch: 33, Batch: 65,Loss: -1.772,Avg.Loss: -1.455,LR: 3.80E-04]Training epoch 33:  58%|█████▊    | 65/112 [00:01<00:00, 53.31it/s, Epoch: 33, Batch: 66,Loss: -2.151,Avg.Loss: -1.465,LR: 3.80E-04]Training epoch 33:  59%|█████▉    | 66/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 66,Loss: -2.151,Avg.Loss: -1.465,LR: 3.80E-04]Training epoch 33:  59%|█████▉    | 66/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 67,Loss: -2.263,Avg.Loss: -1.477,LR: 3.80E-04]Training epoch 33:  60%|█████▉    | 67/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 68,Loss: -1.513,Avg.Loss: -1.478,LR: 3.80E-04]Training epoch 33:  61%|██████    | 68/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 69,Loss: -2.054,Avg.Loss: -1.486,LR: 3.80E-04]Training epoch 33:  62%|██████▏   | 69/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 70,Loss: -2.063,Avg.Loss: -1.494,LR: 3.80E-04]Training epoch 33:  62%|██████▎   | 70/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 71,Loss: -1.238,Avg.Loss: -1.491,LR: 3.80E-04]Training epoch 33:  63%|██████▎   | 71/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 72,Loss: -2.170,Avg.Loss: -1.500,LR: 3.80E-04]Training epoch 33:  64%|██████▍   | 72/112 [00:01<00:00, 53.40it/s, Epoch: 33, Batch: 72,Loss: -2.170,Avg.Loss: -1.500,LR: 3.80E-04]Training epoch 33:  64%|██████▍   | 72/112 [00:01<00:00, 53.40it/s, Epoch: 33, Batch: 73,Loss: -2.174,Avg.Loss: -1.509,LR: 3.80E-04]Training epoch 33:  65%|██████▌   | 73/112 [00:01<00:00, 53.40it/s, Epoch: 33, Batch: 74,Loss: -1.581,Avg.Loss: -1.510,LR: 3.80E-04]Training epoch 33:  66%|██████▌   | 74/112 [00:01<00:00, 53.40it/s, Epoch: 33, Batch: 75,Loss: -2.443,Avg.Loss: -1.523,LR: 3.79E-04]Training epoch 33:  67%|██████▋   | 75/112 [00:01<00:00, 53.40it/s, Epoch: 33, Batch: 76,Loss: -1.714,Avg.Loss: -1.525,LR: 3.79E-04]Training epoch 33:  68%|██████▊   | 76/112 [00:01<00:00, 53.40it/s, Epoch: 33, Batch: 77,Loss: -1.257,Avg.Loss: -1.522,LR: 3.79E-04]Training epoch 33:  69%|██████▉   | 77/112 [00:01<00:00, 53.40it/s, Epoch: 33, Batch: 78,Loss: -1.703,Avg.Loss: -1.524,LR: 3.79E-04]Training epoch 33:  70%|██████▉   | 78/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 78,Loss: -1.703,Avg.Loss: -1.524,LR: 3.79E-04]Training epoch 33:  70%|██████▉   | 78/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 79,Loss: -1.948,Avg.Loss: -1.530,LR: 3.79E-04]Training epoch 33:  71%|███████   | 79/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 80,Loss: -1.654,Avg.Loss: -1.531,LR: 3.79E-04]Training epoch 33:  71%|███████▏  | 80/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 81,Loss: -2.268,Avg.Loss: -1.540,LR: 3.79E-04]Training epoch 33:  72%|███████▏  | 81/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 82,Loss: -1.472,Avg.Loss: -1.539,LR: 3.79E-04]Training epoch 33:  73%|███████▎  | 82/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 83,Loss: -1.319,Avg.Loss: -1.537,LR: 3.79E-04]Training epoch 33:  74%|███████▍  | 83/112 [00:01<00:00, 53.37it/s, Epoch: 33, Batch: 84,Loss: -1.665,Avg.Loss: -1.538,LR: 3.79E-04]Training epoch 33:  75%|███████▌  | 84/112 [00:01<00:00, 53.41it/s, Epoch: 33, Batch: 84,Loss: -1.665,Avg.Loss: -1.538,LR: 3.79E-04]Training epoch 33:  75%|███████▌  | 84/112 [00:01<00:00, 53.41it/s, Epoch: 33, Batch: 85,Loss: -1.896,Avg.Loss: -1.542,LR: 3.79E-04]Training epoch 33:  76%|███████▌  | 85/112 [00:01<00:00, 53.41it/s, Epoch: 33, Batch: 86,Loss: -1.714,Avg.Loss: -1.544,LR: 3.79E-04]Training epoch 33:  77%|███████▋  | 86/112 [00:01<00:00, 53.41it/s, Epoch: 33, Batch: 87,Loss: -2.210,Avg.Loss: -1.552,LR: 3.79E-04]Training epoch 33:  78%|███████▊  | 87/112 [00:01<00:00, 53.41it/s, Epoch: 33, Batch: 88,Loss: -1.792,Avg.Loss: -1.555,LR: 3.79E-04]Training epoch 33:  79%|███████▊  | 88/112 [00:01<00:00, 53.41it/s, Epoch: 33, Batch: 89,Loss: -1.172,Avg.Loss: -1.551,LR: 3.79E-04]Training epoch 33:  79%|███████▉  | 89/112 [00:01<00:00, 53.41it/s, Epoch: 33, Batch: 90,Loss: -2.110,Avg.Loss: -1.557,LR: 3.79E-04]Training epoch 33:  80%|████████  | 90/112 [00:01<00:00, 53.73it/s, Epoch: 33, Batch: 90,Loss: -2.110,Avg.Loss: -1.557,LR: 3.79E-04]Training epoch 33:  80%|████████  | 90/112 [00:01<00:00, 53.73it/s, Epoch: 33, Batch: 91,Loss: -1.176,Avg.Loss: -1.553,LR: 3.79E-04]Training epoch 33:  81%|████████▏ | 91/112 [00:01<00:00, 53.73it/s, Epoch: 33, Batch: 92,Loss: -1.885,Avg.Loss: -1.556,LR: 3.78E-04]Training epoch 33:  82%|████████▏ | 92/112 [00:01<00:00, 53.73it/s, Epoch: 33, Batch: 93,Loss: -2.481,Avg.Loss: -1.566,LR: 3.78E-04]Training epoch 33:  83%|████████▎ | 93/112 [00:01<00:00, 53.73it/s, Epoch: 33, Batch: 94,Loss: -1.226,Avg.Loss: -1.562,LR: 3.78E-04]Training epoch 33:  84%|████████▍ | 94/112 [00:01<00:00, 53.73it/s, Epoch: 33, Batch: 95,Loss: -0.077,Avg.Loss: -1.547,LR: 3.78E-04]Training epoch 33:  85%|████████▍ | 95/112 [00:01<00:00, 53.73it/s, Epoch: 33, Batch: 96,Loss: -0.607,Avg.Loss: -1.537,LR: 3.78E-04]Training epoch 33:  86%|████████▌ | 96/112 [00:01<00:00, 53.92it/s, Epoch: 33, Batch: 96,Loss: -0.607,Avg.Loss: -1.537,LR: 3.78E-04]Training epoch 33:  86%|████████▌ | 96/112 [00:01<00:00, 53.92it/s, Epoch: 33, Batch: 97,Loss: -1.934,Avg.Loss: -1.541,LR: 3.78E-04]Training epoch 33:  87%|████████▋ | 97/112 [00:01<00:00, 53.92it/s, Epoch: 33, Batch: 98,Loss: -1.284,Avg.Loss: -1.539,LR: 3.78E-04]Training epoch 33:  88%|████████▊ | 98/112 [00:01<00:00, 53.92it/s, Epoch: 33, Batch: 99,Loss: 1.260,Avg.Loss: -1.510,LR: 3.78E-04] Training epoch 33:  88%|████████▊ | 99/112 [00:01<00:00, 53.92it/s, Epoch: 33, Batch: 100,Loss: 0.401,Avg.Loss: -1.491,LR: 3.78E-04]Training epoch 33:  89%|████████▉ | 100/112 [00:01<00:00, 53.92it/s, Epoch: 33, Batch: 101,Loss: -1.549,Avg.Loss: -1.492,LR: 3.78E-04]Training epoch 33:  90%|█████████ | 101/112 [00:01<00:00, 53.92it/s, Epoch: 33, Batch: 102,Loss: -0.031,Avg.Loss: -1.477,LR: 3.78E-04]Training epoch 33:  91%|█████████ | 102/112 [00:01<00:00, 53.82it/s, Epoch: 33, Batch: 102,Loss: -0.031,Avg.Loss: -1.477,LR: 3.78E-04]Training epoch 33:  91%|█████████ | 102/112 [00:01<00:00, 53.82it/s, Epoch: 33, Batch: 103,Loss: 1.170,Avg.Loss: -1.452,LR: 3.78E-04] Training epoch 33:  92%|█████████▏| 103/112 [00:01<00:00, 53.82it/s, Epoch: 33, Batch: 104,Loss: 1.376,Avg.Loss: -1.425,LR: 3.78E-04]Training epoch 33:  93%|█████████▎| 104/112 [00:01<00:00, 53.82it/s, Epoch: 33, Batch: 105,Loss: -0.288,Avg.Loss: -1.414,LR: 3.78E-04]Training epoch 33:  94%|█████████▍| 105/112 [00:01<00:00, 53.82it/s, Epoch: 33, Batch: 106,Loss: -1.532,Avg.Loss: -1.415,LR: 3.78E-04]Training epoch 33:  95%|█████████▍| 106/112 [00:01<00:00, 53.82it/s, Epoch: 33, Batch: 107,Loss: -1.345,Avg.Loss: -1.414,LR: 3.78E-04]Training epoch 33:  96%|█████████▌| 107/112 [00:02<00:00, 53.82it/s, Epoch: 33, Batch: 108,Loss: -1.793,Avg.Loss: -1.418,LR: 3.78E-04]Training epoch 33:  96%|█████████▋| 108/112 [00:02<00:00, 53.75it/s, Epoch: 33, Batch: 108,Loss: -1.793,Avg.Loss: -1.418,LR: 3.78E-04]Training epoch 33:  96%|█████████▋| 108/112 [00:02<00:00, 53.75it/s, Epoch: 33, Batch: 109,Loss: -1.481,Avg.Loss: -1.418,LR: 3.77E-04]Training epoch 33:  97%|█████████▋| 109/112 [00:02<00:00, 53.75it/s, Epoch: 33, Batch: 110,Loss: -2.051,Avg.Loss: -1.424,LR: 3.77E-04]Training epoch 33:  98%|█████████▊| 110/112 [00:02<00:00, 53.75it/s, Epoch: 33, Batch: 111,Loss: -1.996,Avg.Loss: -1.429,LR: 3.77E-04]Training epoch 33:  99%|█████████▉| 111/112 [00:02<00:00, 53.75it/s, Epoch: 33, Batch: 112,Loss: -2.320,Avg.Loss: -1.437,LR: 3.77E-04]Training epoch 33: 100%|██████████| 112/112 [00:02<00:00, 53.58it/s, Epoch: 33, Batch: 112,Loss: -2.320,Avg.Loss: -1.437,LR: 3.77E-04]
Training epoch 34:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 34:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 34, Batch: 1,Loss: -2.021,Avg.Loss: -2.021,LR: 3.77E-04]Training epoch 34:   1%|          | 1/112 [00:00<00:04, 23.91it/s, Epoch: 34, Batch: 2,Loss: -2.104,Avg.Loss: -2.063,LR: 3.77E-04]Training epoch 34:   2%|▏         | 2/112 [00:00<00:03, 33.68it/s, Epoch: 34, Batch: 3,Loss: -2.239,Avg.Loss: -2.121,LR: 3.77E-04]Training epoch 34:   3%|▎         | 3/112 [00:00<00:02, 38.06it/s, Epoch: 34, Batch: 4,Loss: -2.091,Avg.Loss: -2.114,LR: 3.77E-04]Training epoch 34:   4%|▎         | 4/112 [00:00<00:02, 41.23it/s, Epoch: 34, Batch: 5,Loss: -2.085,Avg.Loss: -2.108,LR: 3.77E-04]Training epoch 34:   4%|▍         | 5/112 [00:00<00:02, 44.65it/s, Epoch: 34, Batch: 6,Loss: -2.056,Avg.Loss: -2.099,LR: 3.77E-04]Training epoch 34:   5%|▌         | 6/112 [00:00<00:01, 53.49it/s, Epoch: 34, Batch: 6,Loss: -2.056,Avg.Loss: -2.099,LR: 3.77E-04]Training epoch 34:   5%|▌         | 6/112 [00:00<00:01, 53.49it/s, Epoch: 34, Batch: 7,Loss: -1.478,Avg.Loss: -2.011,LR: 3.77E-04]Training epoch 34:   6%|▋         | 7/112 [00:00<00:01, 53.49it/s, Epoch: 34, Batch: 8,Loss: -1.726,Avg.Loss: -1.975,LR: 3.77E-04]Training epoch 34:   7%|▋         | 8/112 [00:00<00:01, 53.49it/s, Epoch: 34, Batch: 9,Loss: -1.588,Avg.Loss: -1.932,LR: 3.77E-04]Training epoch 34:   8%|▊         | 9/112 [00:00<00:01, 53.49it/s, Epoch: 34, Batch: 10,Loss: -1.830,Avg.Loss: -1.922,LR: 3.77E-04]Training epoch 34:   9%|▉         | 10/112 [00:00<00:01, 53.49it/s, Epoch: 34, Batch: 11,Loss: -2.459,Avg.Loss: -1.971,LR: 3.77E-04]Training epoch 34:  10%|▉         | 11/112 [00:00<00:01, 53.49it/s, Epoch: 34, Batch: 12,Loss: -1.150,Avg.Loss: -1.902,LR: 3.77E-04]Training epoch 34:  11%|█         | 12/112 [00:00<00:01, 55.62it/s, Epoch: 34, Batch: 12,Loss: -1.150,Avg.Loss: -1.902,LR: 3.77E-04]Training epoch 34:  11%|█         | 12/112 [00:00<00:01, 55.62it/s, Epoch: 34, Batch: 13,Loss: -0.704,Avg.Loss: -1.810,LR: 3.76E-04]Training epoch 34:  12%|█▏        | 13/112 [00:00<00:01, 55.62it/s, Epoch: 34, Batch: 14,Loss: -1.060,Avg.Loss: -1.757,LR: 3.76E-04]Training epoch 34:  12%|█▎        | 14/112 [00:00<00:01, 55.62it/s, Epoch: 34, Batch: 15,Loss: -1.596,Avg.Loss: -1.746,LR: 3.76E-04]Training epoch 34:  13%|█▎        | 15/112 [00:00<00:01, 55.62it/s, Epoch: 34, Batch: 16,Loss: -1.339,Avg.Loss: -1.720,LR: 3.76E-04]Training epoch 34:  14%|█▍        | 16/112 [00:00<00:01, 55.62it/s, Epoch: 34, Batch: 17,Loss: -2.093,Avg.Loss: -1.742,LR: 3.76E-04]Training epoch 34:  15%|█▌        | 17/112 [00:00<00:01, 55.62it/s, Epoch: 34, Batch: 18,Loss: -1.535,Avg.Loss: -1.731,LR: 3.76E-04]Training epoch 34:  16%|█▌        | 18/112 [00:00<00:01, 55.39it/s, Epoch: 34, Batch: 18,Loss: -1.535,Avg.Loss: -1.731,LR: 3.76E-04]Training epoch 34:  16%|█▌        | 18/112 [00:00<00:01, 55.39it/s, Epoch: 34, Batch: 19,Loss: -1.586,Avg.Loss: -1.723,LR: 3.76E-04]Training epoch 34:  17%|█▋        | 19/112 [00:00<00:01, 55.39it/s, Epoch: 34, Batch: 20,Loss: -2.380,Avg.Loss: -1.756,LR: 3.76E-04]Training epoch 34:  18%|█▊        | 20/112 [00:00<00:01, 55.39it/s, Epoch: 34, Batch: 21,Loss: -1.405,Avg.Loss: -1.739,LR: 3.76E-04]Training epoch 34:  19%|█▉        | 21/112 [00:00<00:01, 55.39it/s, Epoch: 34, Batch: 22,Loss: -0.772,Avg.Loss: -1.695,LR: 3.76E-04]Training epoch 34:  20%|█▉        | 22/112 [00:00<00:01, 55.39it/s, Epoch: 34, Batch: 23,Loss: -1.513,Avg.Loss: -1.687,LR: 3.76E-04]Training epoch 34:  21%|██        | 23/112 [00:00<00:01, 55.39it/s, Epoch: 34, Batch: 24,Loss: -2.156,Avg.Loss: -1.707,LR: 3.76E-04]Training epoch 34:  21%|██▏       | 24/112 [00:00<00:01, 53.86it/s, Epoch: 34, Batch: 24,Loss: -2.156,Avg.Loss: -1.707,LR: 3.76E-04]Training epoch 34:  21%|██▏       | 24/112 [00:00<00:01, 53.86it/s, Epoch: 34, Batch: 25,Loss: -1.867,Avg.Loss: -1.713,LR: 3.76E-04]Training epoch 34:  22%|██▏       | 25/112 [00:00<00:01, 53.86it/s, Epoch: 34, Batch: 26,Loss: -2.272,Avg.Loss: -1.735,LR: 3.76E-04]Training epoch 34:  23%|██▎       | 26/112 [00:00<00:01, 53.86it/s, Epoch: 34, Batch: 27,Loss: -2.486,Avg.Loss: -1.763,LR: 3.76E-04]Training epoch 34:  24%|██▍       | 27/112 [00:00<00:01, 53.86it/s, Epoch: 34, Batch: 28,Loss: -2.281,Avg.Loss: -1.781,LR: 3.76E-04]Training epoch 34:  25%|██▌       | 28/112 [00:00<00:01, 53.86it/s, Epoch: 34, Batch: 29,Loss: -1.877,Avg.Loss: -1.785,LR: 3.76E-04]Training epoch 34:  26%|██▌       | 29/112 [00:00<00:01, 53.86it/s, Epoch: 34, Batch: 30,Loss: -1.878,Avg.Loss: -1.788,LR: 3.75E-04]Training epoch 34:  27%|██▋       | 30/112 [00:00<00:01, 53.47it/s, Epoch: 34, Batch: 30,Loss: -1.878,Avg.Loss: -1.788,LR: 3.75E-04]Training epoch 34:  27%|██▋       | 30/112 [00:00<00:01, 53.47it/s, Epoch: 34, Batch: 31,Loss: -1.215,Avg.Loss: -1.769,LR: 3.75E-04]Training epoch 34:  28%|██▊       | 31/112 [00:00<00:01, 53.47it/s, Epoch: 34, Batch: 32,Loss: -2.103,Avg.Loss: -1.780,LR: 3.75E-04]Training epoch 34:  29%|██▊       | 32/112 [00:00<00:01, 53.47it/s, Epoch: 34, Batch: 33,Loss: -1.655,Avg.Loss: -1.776,LR: 3.75E-04]Training epoch 34:  29%|██▉       | 33/112 [00:00<00:01, 53.47it/s, Epoch: 34, Batch: 34,Loss: -0.666,Avg.Loss: -1.743,LR: 3.75E-04]Training epoch 34:  30%|███       | 34/112 [00:00<00:01, 53.47it/s, Epoch: 34, Batch: 35,Loss: -1.541,Avg.Loss: -1.737,LR: 3.75E-04]Training epoch 34:  31%|███▏      | 35/112 [00:00<00:01, 53.47it/s, Epoch: 34, Batch: 36,Loss: -2.184,Avg.Loss: -1.750,LR: 3.75E-04]Training epoch 34:  32%|███▏      | 36/112 [00:00<00:01, 53.14it/s, Epoch: 34, Batch: 36,Loss: -2.184,Avg.Loss: -1.750,LR: 3.75E-04]Training epoch 34:  32%|███▏      | 36/112 [00:00<00:01, 53.14it/s, Epoch: 34, Batch: 37,Loss: -2.014,Avg.Loss: -1.757,LR: 3.75E-04]Training epoch 34:  33%|███▎      | 37/112 [00:00<00:01, 53.14it/s, Epoch: 34, Batch: 38,Loss: -2.226,Avg.Loss: -1.769,LR: 3.75E-04]Training epoch 34:  34%|███▍      | 38/112 [00:00<00:01, 53.14it/s, Epoch: 34, Batch: 39,Loss: -1.452,Avg.Loss: -1.761,LR: 3.75E-04]Training epoch 34:  35%|███▍      | 39/112 [00:00<00:01, 53.14it/s, Epoch: 34, Batch: 40,Loss: -0.871,Avg.Loss: -1.739,LR: 3.75E-04]Training epoch 34:  36%|███▌      | 40/112 [00:00<00:01, 53.14it/s, Epoch: 34, Batch: 41,Loss: -1.617,Avg.Loss: -1.736,LR: 3.75E-04]Training epoch 34:  37%|███▋      | 41/112 [00:00<00:01, 53.14it/s, Epoch: 34, Batch: 42,Loss: -1.442,Avg.Loss: -1.729,LR: 3.75E-04]Training epoch 34:  38%|███▊      | 42/112 [00:00<00:01, 53.12it/s, Epoch: 34, Batch: 42,Loss: -1.442,Avg.Loss: -1.729,LR: 3.75E-04]Training epoch 34:  38%|███▊      | 42/112 [00:00<00:01, 53.12it/s, Epoch: 34, Batch: 43,Loss: -1.147,Avg.Loss: -1.715,LR: 3.75E-04]Training epoch 34:  38%|███▊      | 43/112 [00:00<00:01, 53.12it/s, Epoch: 34, Batch: 44,Loss: -1.757,Avg.Loss: -1.716,LR: 3.75E-04]Training epoch 34:  39%|███▉      | 44/112 [00:00<00:01, 53.12it/s, Epoch: 34, Batch: 45,Loss: -2.233,Avg.Loss: -1.728,LR: 3.75E-04]Training epoch 34:  40%|████      | 45/112 [00:00<00:01, 53.12it/s, Epoch: 34, Batch: 46,Loss: -1.585,Avg.Loss: -1.725,LR: 3.74E-04]Training epoch 34:  41%|████      | 46/112 [00:00<00:01, 53.12it/s, Epoch: 34, Batch: 47,Loss: -2.259,Avg.Loss: -1.736,LR: 3.74E-04]Training epoch 34:  42%|████▏     | 47/112 [00:00<00:01, 53.12it/s, Epoch: 34, Batch: 48,Loss: -1.277,Avg.Loss: -1.727,LR: 3.74E-04]Training epoch 34:  43%|████▎     | 48/112 [00:00<00:01, 52.93it/s, Epoch: 34, Batch: 48,Loss: -1.277,Avg.Loss: -1.727,LR: 3.74E-04]Training epoch 34:  43%|████▎     | 48/112 [00:00<00:01, 52.93it/s, Epoch: 34, Batch: 49,Loss: -0.972,Avg.Loss: -1.711,LR: 3.74E-04]Training epoch 34:  44%|████▍     | 49/112 [00:00<00:01, 52.93it/s, Epoch: 34, Batch: 50,Loss: -1.481,Avg.Loss: -1.707,LR: 3.74E-04]Training epoch 34:  45%|████▍     | 50/112 [00:00<00:01, 52.93it/s, Epoch: 34, Batch: 51,Loss: -2.048,Avg.Loss: -1.713,LR: 3.74E-04]Training epoch 34:  46%|████▌     | 51/112 [00:00<00:01, 52.93it/s, Epoch: 34, Batch: 52,Loss: -1.544,Avg.Loss: -1.710,LR: 3.74E-04]Training epoch 34:  46%|████▋     | 52/112 [00:00<00:01, 52.93it/s, Epoch: 34, Batch: 53,Loss: -2.276,Avg.Loss: -1.721,LR: 3.74E-04]Training epoch 34:  47%|████▋     | 53/112 [00:01<00:01, 52.93it/s, Epoch: 34, Batch: 54,Loss: -2.548,Avg.Loss: -1.736,LR: 3.74E-04]Training epoch 34:  48%|████▊     | 54/112 [00:01<00:01, 52.93it/s, Epoch: 34, Batch: 54,Loss: -2.548,Avg.Loss: -1.736,LR: 3.74E-04]Training epoch 34:  48%|████▊     | 54/112 [00:01<00:01, 52.93it/s, Epoch: 34, Batch: 55,Loss: -2.362,Avg.Loss: -1.747,LR: 3.74E-04]Training epoch 34:  49%|████▉     | 55/112 [00:01<00:01, 52.93it/s, Epoch: 34, Batch: 56,Loss: -1.851,Avg.Loss: -1.749,LR: 3.74E-04]Training epoch 34:  50%|█████     | 56/112 [00:01<00:01, 52.93it/s, Epoch: 34, Batch: 57,Loss: -1.626,Avg.Loss: -1.747,LR: 3.74E-04]Training epoch 34:  51%|█████     | 57/112 [00:01<00:01, 52.93it/s, Epoch: 34, Batch: 58,Loss: -1.710,Avg.Loss: -1.746,LR: 3.74E-04]Training epoch 34:  52%|█████▏    | 58/112 [00:01<00:01, 52.93it/s, Epoch: 34, Batch: 59,Loss: -1.749,Avg.Loss: -1.746,LR: 3.74E-04]Training epoch 34:  53%|█████▎    | 59/112 [00:01<00:01, 52.93it/s, Epoch: 34, Batch: 60,Loss: -2.276,Avg.Loss: -1.755,LR: 3.74E-04]Training epoch 34:  54%|█████▎    | 60/112 [00:01<00:00, 52.85it/s, Epoch: 34, Batch: 60,Loss: -2.276,Avg.Loss: -1.755,LR: 3.74E-04]Training epoch 34:  54%|█████▎    | 60/112 [00:01<00:00, 52.85it/s, Epoch: 34, Batch: 61,Loss: -2.305,Avg.Loss: -1.764,LR: 3.74E-04]Training epoch 34:  54%|█████▍    | 61/112 [00:01<00:00, 52.85it/s, Epoch: 34, Batch: 62,Loss: -2.241,Avg.Loss: -1.772,LR: 3.73E-04]Training epoch 34:  55%|█████▌    | 62/112 [00:01<00:00, 52.85it/s, Epoch: 34, Batch: 63,Loss: -2.112,Avg.Loss: -1.777,LR: 3.73E-04]Training epoch 34:  56%|█████▋    | 63/112 [00:01<00:00, 52.85it/s, Epoch: 34, Batch: 64,Loss: -2.156,Avg.Loss: -1.783,LR: 3.73E-04]Training epoch 34:  57%|█████▋    | 64/112 [00:01<00:00, 52.85it/s, Epoch: 34, Batch: 65,Loss: -2.298,Avg.Loss: -1.791,LR: 3.73E-04]Training epoch 34:  58%|█████▊    | 65/112 [00:01<00:00, 52.85it/s, Epoch: 34, Batch: 66,Loss: -1.887,Avg.Loss: -1.793,LR: 3.73E-04]Training epoch 34:  59%|█████▉    | 66/112 [00:01<00:00, 52.82it/s, Epoch: 34, Batch: 66,Loss: -1.887,Avg.Loss: -1.793,LR: 3.73E-04]Training epoch 34:  59%|█████▉    | 66/112 [00:01<00:00, 52.82it/s, Epoch: 34, Batch: 67,Loss: -1.885,Avg.Loss: -1.794,LR: 3.73E-04]Training epoch 34:  60%|█████▉    | 67/112 [00:01<00:00, 52.82it/s, Epoch: 34, Batch: 68,Loss: -1.607,Avg.Loss: -1.791,LR: 3.73E-04]Training epoch 34:  61%|██████    | 68/112 [00:01<00:00, 52.82it/s, Epoch: 34, Batch: 69,Loss: -2.195,Avg.Loss: -1.797,LR: 3.73E-04]Training epoch 34:  62%|██████▏   | 69/112 [00:01<00:00, 52.82it/s, Epoch: 34, Batch: 70,Loss: -1.995,Avg.Loss: -1.800,LR: 3.73E-04]Training epoch 34:  62%|██████▎   | 70/112 [00:01<00:00, 52.82it/s, Epoch: 34, Batch: 71,Loss: -2.336,Avg.Loss: -1.807,LR: 3.73E-04]Training epoch 34:  63%|██████▎   | 71/112 [00:01<00:00, 52.82it/s, Epoch: 34, Batch: 72,Loss: -1.992,Avg.Loss: -1.810,LR: 3.73E-04]Training epoch 34:  64%|██████▍   | 72/112 [00:01<00:00, 52.84it/s, Epoch: 34, Batch: 72,Loss: -1.992,Avg.Loss: -1.810,LR: 3.73E-04]Training epoch 34:  64%|██████▍   | 72/112 [00:01<00:00, 52.84it/s, Epoch: 34, Batch: 73,Loss: -2.148,Avg.Loss: -1.815,LR: 3.73E-04]Training epoch 34:  65%|██████▌   | 73/112 [00:01<00:00, 52.84it/s, Epoch: 34, Batch: 74,Loss: -1.946,Avg.Loss: -1.816,LR: 3.73E-04]Training epoch 34:  66%|██████▌   | 74/112 [00:01<00:00, 52.84it/s, Epoch: 34, Batch: 75,Loss: -2.087,Avg.Loss: -1.820,LR: 3.73E-04]Training epoch 34:  67%|██████▋   | 75/112 [00:01<00:00, 52.84it/s, Epoch: 34, Batch: 76,Loss: -1.985,Avg.Loss: -1.822,LR: 3.73E-04]Training epoch 34:  68%|██████▊   | 76/112 [00:01<00:00, 52.84it/s, Epoch: 34, Batch: 77,Loss: -1.906,Avg.Loss: -1.823,LR: 3.73E-04]Training epoch 34:  69%|██████▉   | 77/112 [00:01<00:00, 52.84it/s, Epoch: 34, Batch: 78,Loss: -2.280,Avg.Loss: -1.829,LR: 3.73E-04]Training epoch 34:  70%|██████▉   | 78/112 [00:01<00:00, 52.83it/s, Epoch: 34, Batch: 78,Loss: -2.280,Avg.Loss: -1.829,LR: 3.73E-04]Training epoch 34:  70%|██████▉   | 78/112 [00:01<00:00, 52.83it/s, Epoch: 34, Batch: 79,Loss: -2.423,Avg.Loss: -1.837,LR: 3.72E-04]Training epoch 34:  71%|███████   | 79/112 [00:01<00:00, 52.83it/s, Epoch: 34, Batch: 80,Loss: -2.295,Avg.Loss: -1.842,LR: 3.72E-04]Training epoch 34:  71%|███████▏  | 80/112 [00:01<00:00, 52.83it/s, Epoch: 34, Batch: 81,Loss: -2.085,Avg.Loss: -1.845,LR: 3.72E-04]Training epoch 34:  72%|███████▏  | 81/112 [00:01<00:00, 52.83it/s, Epoch: 34, Batch: 82,Loss: -2.238,Avg.Loss: -1.850,LR: 3.72E-04]Training epoch 34:  73%|███████▎  | 82/112 [00:01<00:00, 52.83it/s, Epoch: 34, Batch: 83,Loss: -1.798,Avg.Loss: -1.850,LR: 3.72E-04]Training epoch 34:  74%|███████▍  | 83/112 [00:01<00:00, 52.83it/s, Epoch: 34, Batch: 84,Loss: -1.674,Avg.Loss: -1.847,LR: 3.72E-04]Training epoch 34:  75%|███████▌  | 84/112 [00:01<00:00, 52.89it/s, Epoch: 34, Batch: 84,Loss: -1.674,Avg.Loss: -1.847,LR: 3.72E-04]Training epoch 34:  75%|███████▌  | 84/112 [00:01<00:00, 52.89it/s, Epoch: 34, Batch: 85,Loss: -2.794,Avg.Loss: -1.859,LR: 3.72E-04]Training epoch 34:  76%|███████▌  | 85/112 [00:01<00:00, 52.89it/s, Epoch: 34, Batch: 86,Loss: -1.165,Avg.Loss: -1.851,LR: 3.72E-04]Training epoch 34:  77%|███████▋  | 86/112 [00:01<00:00, 52.89it/s, Epoch: 34, Batch: 87,Loss: -0.692,Avg.Loss: -1.837,LR: 3.72E-04]Training epoch 34:  78%|███████▊  | 87/112 [00:01<00:00, 52.89it/s, Epoch: 34, Batch: 88,Loss: 0.733,Avg.Loss: -1.808,LR: 3.72E-04] Training epoch 34:  79%|███████▊  | 88/112 [00:01<00:00, 52.89it/s, Epoch: 34, Batch: 89,Loss: 2.004,Avg.Loss: -1.765,LR: 3.72E-04]Training epoch 34:  79%|███████▉  | 89/112 [00:01<00:00, 52.89it/s, Epoch: 34, Batch: 90,Loss: -0.595,Avg.Loss: -1.752,LR: 3.72E-04]Training epoch 34:  80%|████████  | 90/112 [00:01<00:00, 52.98it/s, Epoch: 34, Batch: 90,Loss: -0.595,Avg.Loss: -1.752,LR: 3.72E-04]Training epoch 34:  80%|████████  | 90/112 [00:01<00:00, 52.98it/s, Epoch: 34, Batch: 91,Loss: -1.968,Avg.Loss: -1.755,LR: 3.72E-04]Training epoch 34:  81%|████████▏ | 91/112 [00:01<00:00, 52.98it/s, Epoch: 34, Batch: 92,Loss: -1.329,Avg.Loss: -1.750,LR: 3.72E-04]Training epoch 34:  82%|████████▏ | 92/112 [00:01<00:00, 52.98it/s, Epoch: 34, Batch: 93,Loss: -1.136,Avg.Loss: -1.743,LR: 3.72E-04]Training epoch 34:  83%|████████▎ | 93/112 [00:01<00:00, 52.98it/s, Epoch: 34, Batch: 94,Loss: 0.120,Avg.Loss: -1.724,LR: 3.72E-04] Training epoch 34:  84%|████████▍ | 94/112 [00:01<00:00, 52.98it/s, Epoch: 34, Batch: 95,Loss: 0.373,Avg.Loss: -1.701,LR: 3.71E-04]Training epoch 34:  85%|████████▍ | 95/112 [00:01<00:00, 52.98it/s, Epoch: 34, Batch: 96,Loss: 0.517,Avg.Loss: -1.678,LR: 3.71E-04]Training epoch 34:  86%|████████▌ | 96/112 [00:01<00:00, 53.03it/s, Epoch: 34, Batch: 96,Loss: 0.517,Avg.Loss: -1.678,LR: 3.71E-04]Training epoch 34:  86%|████████▌ | 96/112 [00:01<00:00, 53.03it/s, Epoch: 34, Batch: 97,Loss: -0.316,Avg.Loss: -1.664,LR: 3.71E-04]Training epoch 34:  87%|████████▋ | 97/112 [00:01<00:00, 53.03it/s, Epoch: 34, Batch: 98,Loss: -1.501,Avg.Loss: -1.663,LR: 3.71E-04]Training epoch 34:  88%|████████▊ | 98/112 [00:01<00:00, 53.03it/s, Epoch: 34, Batch: 99,Loss: -0.185,Avg.Loss: -1.648,LR: 3.71E-04]Training epoch 34:  88%|████████▊ | 99/112 [00:01<00:00, 53.03it/s, Epoch: 34, Batch: 100,Loss: 2.506,Avg.Loss: -1.606,LR: 3.71E-04]Training epoch 34:  89%|████████▉ | 100/112 [00:01<00:00, 53.03it/s, Epoch: 34, Batch: 101,Loss: 1.100,Avg.Loss: -1.579,LR: 3.71E-04]Training epoch 34:  90%|█████████ | 101/112 [00:01<00:00, 53.03it/s, Epoch: 34, Batch: 102,Loss: -1.310,Avg.Loss: -1.577,LR: 3.71E-04]Training epoch 34:  91%|█████████ | 102/112 [00:01<00:00, 52.99it/s, Epoch: 34, Batch: 102,Loss: -1.310,Avg.Loss: -1.577,LR: 3.71E-04]Training epoch 34:  91%|█████████ | 102/112 [00:01<00:00, 52.99it/s, Epoch: 34, Batch: 103,Loss: 0.455,Avg.Loss: -1.557,LR: 3.71E-04] Training epoch 34:  92%|█████████▏| 103/112 [00:01<00:00, 52.99it/s, Epoch: 34, Batch: 104,Loss: 0.838,Avg.Loss: -1.534,LR: 3.71E-04]Training epoch 34:  93%|█████████▎| 104/112 [00:01<00:00, 52.99it/s, Epoch: 34, Batch: 105,Loss: 1.910,Avg.Loss: -1.501,LR: 3.71E-04]Training epoch 34:  94%|█████████▍| 105/112 [00:01<00:00, 52.99it/s, Epoch: 34, Batch: 106,Loss: -0.161,Avg.Loss: -1.489,LR: 3.71E-04]Training epoch 34:  95%|█████████▍| 106/112 [00:02<00:00, 52.99it/s, Epoch: 34, Batch: 107,Loss: -1.153,Avg.Loss: -1.485,LR: 3.71E-04]Training epoch 34:  96%|█████████▌| 107/112 [00:02<00:00, 52.99it/s, Epoch: 34, Batch: 108,Loss: -0.324,Avg.Loss: -1.475,LR: 3.71E-04]Training epoch 34:  96%|█████████▋| 108/112 [00:02<00:00, 52.88it/s, Epoch: 34, Batch: 108,Loss: -0.324,Avg.Loss: -1.475,LR: 3.71E-04]Training epoch 34:  96%|█████████▋| 108/112 [00:02<00:00, 52.88it/s, Epoch: 34, Batch: 109,Loss: -0.913,Avg.Loss: -1.470,LR: 3.71E-04]Training epoch 34:  97%|█████████▋| 109/112 [00:02<00:00, 52.88it/s, Epoch: 34, Batch: 110,Loss: -1.187,Avg.Loss: -1.467,LR: 3.71E-04]Training epoch 34:  98%|█████████▊| 110/112 [00:02<00:00, 52.88it/s, Epoch: 34, Batch: 111,Loss: -1.371,Avg.Loss: -1.466,LR: 3.70E-04]Training epoch 34:  99%|█████████▉| 111/112 [00:02<00:00, 52.88it/s, Epoch: 34, Batch: 112,Loss: -0.926,Avg.Loss: -1.461,LR: 3.70E-04]Training epoch 34: 100%|██████████| 112/112 [00:02<00:00, 53.10it/s, Epoch: 34, Batch: 112,Loss: -0.926,Avg.Loss: -1.461,LR: 3.70E-04]
Training epoch 35:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 35:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 35, Batch: 1,Loss: -1.536,Avg.Loss: -1.536,LR: 3.70E-04]Training epoch 35:   1%|          | 1/112 [00:00<00:04, 24.63it/s, Epoch: 35, Batch: 2,Loss: -1.592,Avg.Loss: -1.564,LR: 3.70E-04]Training epoch 35:   2%|▏         | 2/112 [00:00<00:03, 34.82it/s, Epoch: 35, Batch: 3,Loss: -1.376,Avg.Loss: -1.501,LR: 3.70E-04]Training epoch 35:   3%|▎         | 3/112 [00:00<00:02, 40.10it/s, Epoch: 35, Batch: 4,Loss: -1.925,Avg.Loss: -1.607,LR: 3.70E-04]Training epoch 35:   4%|▎         | 4/112 [00:00<00:02, 42.49it/s, Epoch: 35, Batch: 5,Loss: -1.807,Avg.Loss: -1.647,LR: 3.70E-04]Training epoch 35:   4%|▍         | 5/112 [00:00<00:02, 44.27it/s, Epoch: 35, Batch: 6,Loss: -2.292,Avg.Loss: -1.755,LR: 3.70E-04]Training epoch 35:   5%|▌         | 6/112 [00:00<00:01, 53.04it/s, Epoch: 35, Batch: 6,Loss: -2.292,Avg.Loss: -1.755,LR: 3.70E-04]Training epoch 35:   5%|▌         | 6/112 [00:00<00:01, 53.04it/s, Epoch: 35, Batch: 7,Loss: -2.135,Avg.Loss: -1.809,LR: 3.70E-04]Training epoch 35:   6%|▋         | 7/112 [00:00<00:01, 53.04it/s, Epoch: 35, Batch: 8,Loss: -1.939,Avg.Loss: -1.825,LR: 3.70E-04]Training epoch 35:   7%|▋         | 8/112 [00:00<00:01, 53.04it/s, Epoch: 35, Batch: 9,Loss: -2.065,Avg.Loss: -1.852,LR: 3.70E-04]Training epoch 35:   8%|▊         | 9/112 [00:00<00:01, 53.04it/s, Epoch: 35, Batch: 10,Loss: -1.948,Avg.Loss: -1.862,LR: 3.70E-04]Training epoch 35:   9%|▉         | 10/112 [00:00<00:01, 53.04it/s, Epoch: 35, Batch: 11,Loss: -2.101,Avg.Loss: -1.883,LR: 3.70E-04]Training epoch 35:  10%|▉         | 11/112 [00:00<00:01, 53.04it/s, Epoch: 35, Batch: 12,Loss: -1.904,Avg.Loss: -1.885,LR: 3.70E-04]Training epoch 35:  11%|█         | 12/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 12,Loss: -1.904,Avg.Loss: -1.885,LR: 3.70E-04]Training epoch 35:  11%|█         | 12/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 13,Loss: -2.007,Avg.Loss: -1.894,LR: 3.70E-04]Training epoch 35:  12%|█▏        | 13/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 14,Loss: -2.063,Avg.Loss: -1.906,LR: 3.70E-04]Training epoch 35:  12%|█▎        | 14/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 15,Loss: -2.148,Avg.Loss: -1.923,LR: 3.70E-04]Training epoch 35:  13%|█▎        | 15/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 16,Loss: -1.550,Avg.Loss: -1.899,LR: 3.69E-04]Training epoch 35:  14%|█▍        | 16/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 17,Loss: -1.876,Avg.Loss: -1.898,LR: 3.69E-04]Training epoch 35:  15%|█▌        | 17/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 18,Loss: -2.244,Avg.Loss: -1.917,LR: 3.69E-04]Training epoch 35:  16%|█▌        | 18/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 18,Loss: -2.244,Avg.Loss: -1.917,LR: 3.69E-04]Training epoch 35:  16%|█▌        | 18/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 19,Loss: -2.267,Avg.Loss: -1.936,LR: 3.69E-04]Training epoch 35:  17%|█▋        | 19/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 20,Loss: -1.841,Avg.Loss: -1.931,LR: 3.69E-04]Training epoch 35:  18%|█▊        | 20/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 21,Loss: -1.592,Avg.Loss: -1.915,LR: 3.69E-04]Training epoch 35:  19%|█▉        | 21/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 22,Loss: -1.368,Avg.Loss: -1.890,LR: 3.69E-04]Training epoch 35:  20%|█▉        | 22/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 23,Loss: -1.059,Avg.Loss: -1.854,LR: 3.69E-04]Training epoch 35:  21%|██        | 23/112 [00:00<00:01, 52.80it/s, Epoch: 35, Batch: 24,Loss: -2.065,Avg.Loss: -1.863,LR: 3.69E-04]Training epoch 35:  21%|██▏       | 24/112 [00:00<00:01, 52.63it/s, Epoch: 35, Batch: 24,Loss: -2.065,Avg.Loss: -1.863,LR: 3.69E-04]Training epoch 35:  21%|██▏       | 24/112 [00:00<00:01, 52.63it/s, Epoch: 35, Batch: 25,Loss: -2.284,Avg.Loss: -1.879,LR: 3.69E-04]Training epoch 35:  22%|██▏       | 25/112 [00:00<00:01, 52.63it/s, Epoch: 35, Batch: 26,Loss: -1.052,Avg.Loss: -1.848,LR: 3.69E-04]Training epoch 35:  23%|██▎       | 26/112 [00:00<00:01, 52.63it/s, Epoch: 35, Batch: 27,Loss: -1.172,Avg.Loss: -1.823,LR: 3.69E-04]Training epoch 35:  24%|██▍       | 27/112 [00:00<00:01, 52.63it/s, Epoch: 35, Batch: 28,Loss: -2.078,Avg.Loss: -1.832,LR: 3.69E-04]Training epoch 35:  25%|██▌       | 28/112 [00:00<00:01, 52.63it/s, Epoch: 35, Batch: 29,Loss: -2.574,Avg.Loss: -1.857,LR: 3.69E-04]Training epoch 35:  26%|██▌       | 29/112 [00:00<00:01, 52.63it/s, Epoch: 35, Batch: 30,Loss: -1.861,Avg.Loss: -1.857,LR: 3.69E-04]Training epoch 35:  27%|██▋       | 30/112 [00:00<00:01, 52.54it/s, Epoch: 35, Batch: 30,Loss: -1.861,Avg.Loss: -1.857,LR: 3.69E-04]Training epoch 35:  27%|██▋       | 30/112 [00:00<00:01, 52.54it/s, Epoch: 35, Batch: 31,Loss: -2.243,Avg.Loss: -1.870,LR: 3.69E-04]Training epoch 35:  28%|██▊       | 31/112 [00:00<00:01, 52.54it/s, Epoch: 35, Batch: 32,Loss: -2.283,Avg.Loss: -1.883,LR: 3.68E-04]Training epoch 35:  29%|██▊       | 32/112 [00:00<00:01, 52.54it/s, Epoch: 35, Batch: 33,Loss: -2.393,Avg.Loss: -1.898,LR: 3.68E-04]Training epoch 35:  29%|██▉       | 33/112 [00:00<00:01, 52.54it/s, Epoch: 35, Batch: 34,Loss: -1.663,Avg.Loss: -1.891,LR: 3.68E-04]Training epoch 35:  30%|███       | 34/112 [00:00<00:01, 52.54it/s, Epoch: 35, Batch: 35,Loss: -1.548,Avg.Loss: -1.882,LR: 3.68E-04]Training epoch 35:  31%|███▏      | 35/112 [00:00<00:01, 52.54it/s, Epoch: 35, Batch: 36,Loss: -2.552,Avg.Loss: -1.900,LR: 3.68E-04]Training epoch 35:  32%|███▏      | 36/112 [00:00<00:01, 52.75it/s, Epoch: 35, Batch: 36,Loss: -2.552,Avg.Loss: -1.900,LR: 3.68E-04]Training epoch 35:  32%|███▏      | 36/112 [00:00<00:01, 52.75it/s, Epoch: 35, Batch: 37,Loss: -0.899,Avg.Loss: -1.873,LR: 3.68E-04]Training epoch 35:  33%|███▎      | 37/112 [00:00<00:01, 52.75it/s, Epoch: 35, Batch: 38,Loss: 0.858,Avg.Loss: -1.801,LR: 3.68E-04] Training epoch 35:  34%|███▍      | 38/112 [00:00<00:01, 52.75it/s, Epoch: 35, Batch: 39,Loss: -0.627,Avg.Loss: -1.771,LR: 3.68E-04]Training epoch 35:  35%|███▍      | 39/112 [00:00<00:01, 52.75it/s, Epoch: 35, Batch: 40,Loss: -2.027,Avg.Loss: -1.777,LR: 3.68E-04]Training epoch 35:  36%|███▌      | 40/112 [00:00<00:01, 52.75it/s, Epoch: 35, Batch: 41,Loss: -0.254,Avg.Loss: -1.740,LR: 3.68E-04]Training epoch 35:  37%|███▋      | 41/112 [00:00<00:01, 52.75it/s, Epoch: 35, Batch: 42,Loss: 1.777,Avg.Loss: -1.657,LR: 3.68E-04] Training epoch 35:  38%|███▊      | 42/112 [00:00<00:01, 52.93it/s, Epoch: 35, Batch: 42,Loss: 1.777,Avg.Loss: -1.657,LR: 3.68E-04]Training epoch 35:  38%|███▊      | 42/112 [00:00<00:01, 52.93it/s, Epoch: 35, Batch: 43,Loss: 1.729,Avg.Loss: -1.578,LR: 3.68E-04]Training epoch 35:  38%|███▊      | 43/112 [00:00<00:01, 52.93it/s, Epoch: 35, Batch: 44,Loss: -0.748,Avg.Loss: -1.559,LR: 3.68E-04]Training epoch 35:  39%|███▉      | 44/112 [00:00<00:01, 52.93it/s, Epoch: 35, Batch: 45,Loss: -2.222,Avg.Loss: -1.574,LR: 3.68E-04]Training epoch 35:  40%|████      | 45/112 [00:00<00:01, 52.93it/s, Epoch: 35, Batch: 46,Loss: -1.274,Avg.Loss: -1.567,LR: 3.68E-04]Training epoch 35:  41%|████      | 46/112 [00:00<00:01, 52.93it/s, Epoch: 35, Batch: 47,Loss: -1.889,Avg.Loss: -1.574,LR: 3.68E-04]Training epoch 35:  42%|████▏     | 47/112 [00:00<00:01, 52.93it/s, Epoch: 35, Batch: 48,Loss: -2.427,Avg.Loss: -1.592,LR: 3.67E-04]Training epoch 35:  43%|████▎     | 48/112 [00:00<00:01, 52.99it/s, Epoch: 35, Batch: 48,Loss: -2.427,Avg.Loss: -1.592,LR: 3.67E-04]Training epoch 35:  43%|████▎     | 48/112 [00:00<00:01, 52.99it/s, Epoch: 35, Batch: 49,Loss: -2.441,Avg.Loss: -1.609,LR: 3.67E-04]Training epoch 35:  44%|████▍     | 49/112 [00:00<00:01, 52.99it/s, Epoch: 35, Batch: 50,Loss: -2.276,Avg.Loss: -1.622,LR: 3.67E-04]Training epoch 35:  45%|████▍     | 50/112 [00:00<00:01, 52.99it/s, Epoch: 35, Batch: 51,Loss: -2.099,Avg.Loss: -1.632,LR: 3.67E-04]Training epoch 35:  46%|████▌     | 51/112 [00:00<00:01, 52.99it/s, Epoch: 35, Batch: 52,Loss: -1.857,Avg.Loss: -1.636,LR: 3.67E-04]Training epoch 35:  46%|████▋     | 52/112 [00:01<00:01, 52.99it/s, Epoch: 35, Batch: 53,Loss: -1.852,Avg.Loss: -1.640,LR: 3.67E-04]Training epoch 35:  47%|████▋     | 53/112 [00:01<00:01, 52.99it/s, Epoch: 35, Batch: 54,Loss: -2.390,Avg.Loss: -1.654,LR: 3.67E-04]Training epoch 35:  48%|████▊     | 54/112 [00:01<00:01, 53.01it/s, Epoch: 35, Batch: 54,Loss: -2.390,Avg.Loss: -1.654,LR: 3.67E-04]Training epoch 35:  48%|████▊     | 54/112 [00:01<00:01, 53.01it/s, Epoch: 35, Batch: 55,Loss: -2.342,Avg.Loss: -1.667,LR: 3.67E-04]Training epoch 35:  49%|████▉     | 55/112 [00:01<00:01, 53.01it/s, Epoch: 35, Batch: 56,Loss: -2.146,Avg.Loss: -1.675,LR: 3.67E-04]Training epoch 35:  50%|█████     | 56/112 [00:01<00:01, 53.01it/s, Epoch: 35, Batch: 57,Loss: -1.893,Avg.Loss: -1.679,LR: 3.67E-04]Training epoch 35:  51%|█████     | 57/112 [00:01<00:01, 53.01it/s, Epoch: 35, Batch: 58,Loss: -1.155,Avg.Loss: -1.670,LR: 3.67E-04]Training epoch 35:  52%|█████▏    | 58/112 [00:01<00:01, 53.01it/s, Epoch: 35, Batch: 59,Loss: -1.750,Avg.Loss: -1.671,LR: 3.67E-04]Training epoch 35:  53%|█████▎    | 59/112 [00:01<00:00, 53.01it/s, Epoch: 35, Batch: 60,Loss: -2.281,Avg.Loss: -1.681,LR: 3.67E-04]Training epoch 35:  54%|█████▎    | 60/112 [00:01<00:00, 53.11it/s, Epoch: 35, Batch: 60,Loss: -2.281,Avg.Loss: -1.681,LR: 3.67E-04]Training epoch 35:  54%|█████▎    | 60/112 [00:01<00:00, 53.11it/s, Epoch: 35, Batch: 61,Loss: -2.102,Avg.Loss: -1.688,LR: 3.67E-04]Training epoch 35:  54%|█████▍    | 61/112 [00:01<00:00, 53.11it/s, Epoch: 35, Batch: 62,Loss: -1.958,Avg.Loss: -1.693,LR: 3.67E-04]Training epoch 35:  55%|█████▌    | 62/112 [00:01<00:00, 53.11it/s, Epoch: 35, Batch: 63,Loss: -2.436,Avg.Loss: -1.705,LR: 3.67E-04]Training epoch 35:  56%|█████▋    | 63/112 [00:01<00:00, 53.11it/s, Epoch: 35, Batch: 64,Loss: -2.258,Avg.Loss: -1.713,LR: 3.66E-04]Training epoch 35:  57%|█████▋    | 64/112 [00:01<00:00, 53.11it/s, Epoch: 35, Batch: 65,Loss: -1.889,Avg.Loss: -1.716,LR: 3.66E-04]Training epoch 35:  58%|█████▊    | 65/112 [00:01<00:00, 53.11it/s, Epoch: 35, Batch: 66,Loss: -2.223,Avg.Loss: -1.724,LR: 3.66E-04]Training epoch 35:  59%|█████▉    | 66/112 [00:01<00:00, 53.08it/s, Epoch: 35, Batch: 66,Loss: -2.223,Avg.Loss: -1.724,LR: 3.66E-04]Training epoch 35:  59%|█████▉    | 66/112 [00:01<00:00, 53.08it/s, Epoch: 35, Batch: 67,Loss: -1.983,Avg.Loss: -1.727,LR: 3.66E-04]Training epoch 35:  60%|█████▉    | 67/112 [00:01<00:00, 53.08it/s, Epoch: 35, Batch: 68,Loss: -1.950,Avg.Loss: -1.731,LR: 3.66E-04]Training epoch 35:  61%|██████    | 68/112 [00:01<00:00, 53.08it/s, Epoch: 35, Batch: 69,Loss: -1.622,Avg.Loss: -1.729,LR: 3.66E-04]Training epoch 35:  62%|██████▏   | 69/112 [00:01<00:00, 53.08it/s, Epoch: 35, Batch: 70,Loss: -1.796,Avg.Loss: -1.730,LR: 3.66E-04]Training epoch 35:  62%|██████▎   | 70/112 [00:01<00:00, 53.08it/s, Epoch: 35, Batch: 71,Loss: -2.233,Avg.Loss: -1.737,LR: 3.66E-04]Training epoch 35:  63%|██████▎   | 71/112 [00:01<00:00, 53.08it/s, Epoch: 35, Batch: 72,Loss: -2.171,Avg.Loss: -1.743,LR: 3.66E-04]Training epoch 35:  64%|██████▍   | 72/112 [00:01<00:00, 53.17it/s, Epoch: 35, Batch: 72,Loss: -2.171,Avg.Loss: -1.743,LR: 3.66E-04]Training epoch 35:  64%|██████▍   | 72/112 [00:01<00:00, 53.17it/s, Epoch: 35, Batch: 73,Loss: -2.129,Avg.Loss: -1.748,LR: 3.66E-04]Training epoch 35:  65%|██████▌   | 73/112 [00:01<00:00, 53.17it/s, Epoch: 35, Batch: 74,Loss: -2.387,Avg.Loss: -1.757,LR: 3.66E-04]Training epoch 35:  66%|██████▌   | 74/112 [00:01<00:00, 53.17it/s, Epoch: 35, Batch: 75,Loss: -2.217,Avg.Loss: -1.763,LR: 3.66E-04]Training epoch 35:  67%|██████▋   | 75/112 [00:01<00:00, 53.17it/s, Epoch: 35, Batch: 76,Loss: -2.090,Avg.Loss: -1.768,LR: 3.66E-04]Training epoch 35:  68%|██████▊   | 76/112 [00:01<00:00, 53.17it/s, Epoch: 35, Batch: 77,Loss: -1.845,Avg.Loss: -1.769,LR: 3.66E-04]Training epoch 35:  69%|██████▉   | 77/112 [00:01<00:00, 53.17it/s, Epoch: 35, Batch: 78,Loss: -2.327,Avg.Loss: -1.776,LR: 3.66E-04]Training epoch 35:  70%|██████▉   | 78/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 78,Loss: -2.327,Avg.Loss: -1.776,LR: 3.66E-04]Training epoch 35:  70%|██████▉   | 78/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 79,Loss: -1.401,Avg.Loss: -1.771,LR: 3.66E-04]Training epoch 35:  71%|███████   | 79/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 80,Loss: -1.944,Avg.Loss: -1.773,LR: 3.65E-04]Training epoch 35:  71%|███████▏  | 80/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 81,Loss: -2.126,Avg.Loss: -1.777,LR: 3.65E-04]Training epoch 35:  72%|███████▏  | 81/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 82,Loss: -2.405,Avg.Loss: -1.785,LR: 3.65E-04]Training epoch 35:  73%|███████▎  | 82/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 83,Loss: -2.155,Avg.Loss: -1.790,LR: 3.65E-04]Training epoch 35:  74%|███████▍  | 83/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 84,Loss: -2.188,Avg.Loss: -1.794,LR: 3.65E-04]Training epoch 35:  75%|███████▌  | 84/112 [00:01<00:00, 52.70it/s, Epoch: 35, Batch: 84,Loss: -2.188,Avg.Loss: -1.794,LR: 3.65E-04]Training epoch 35:  75%|███████▌  | 84/112 [00:01<00:00, 52.70it/s, Epoch: 35, Batch: 85,Loss: -1.908,Avg.Loss: -1.796,LR: 3.65E-04]Training epoch 35:  76%|███████▌  | 85/112 [00:01<00:00, 52.70it/s, Epoch: 35, Batch: 86,Loss: -1.155,Avg.Loss: -1.788,LR: 3.65E-04]Training epoch 35:  77%|███████▋  | 86/112 [00:01<00:00, 52.70it/s, Epoch: 35, Batch: 87,Loss: -2.360,Avg.Loss: -1.795,LR: 3.65E-04]Training epoch 35:  78%|███████▊  | 87/112 [00:01<00:00, 52.70it/s, Epoch: 35, Batch: 88,Loss: -0.682,Avg.Loss: -1.782,LR: 3.65E-04]Training epoch 35:  79%|███████▊  | 88/112 [00:01<00:00, 52.70it/s, Epoch: 35, Batch: 89,Loss: -0.646,Avg.Loss: -1.769,LR: 3.65E-04]Training epoch 35:  79%|███████▉  | 89/112 [00:01<00:00, 52.70it/s, Epoch: 35, Batch: 90,Loss: -1.406,Avg.Loss: -1.765,LR: 3.65E-04]Training epoch 35:  80%|████████  | 90/112 [00:01<00:00, 52.78it/s, Epoch: 35, Batch: 90,Loss: -1.406,Avg.Loss: -1.765,LR: 3.65E-04]Training epoch 35:  80%|████████  | 90/112 [00:01<00:00, 52.78it/s, Epoch: 35, Batch: 91,Loss: -1.270,Avg.Loss: -1.760,LR: 3.65E-04]Training epoch 35:  81%|████████▏ | 91/112 [00:01<00:00, 52.78it/s, Epoch: 35, Batch: 92,Loss: 0.170,Avg.Loss: -1.739,LR: 3.65E-04] Training epoch 35:  82%|████████▏ | 92/112 [00:01<00:00, 52.78it/s, Epoch: 35, Batch: 93,Loss: -1.083,Avg.Loss: -1.732,LR: 3.65E-04]Training epoch 35:  83%|████████▎ | 93/112 [00:01<00:00, 52.78it/s, Epoch: 35, Batch: 94,Loss: -1.723,Avg.Loss: -1.732,LR: 3.65E-04]Training epoch 35:  84%|████████▍ | 94/112 [00:01<00:00, 52.78it/s, Epoch: 35, Batch: 95,Loss: -1.358,Avg.Loss: -1.728,LR: 3.65E-04]Training epoch 35:  85%|████████▍ | 95/112 [00:01<00:00, 52.78it/s, Epoch: 35, Batch: 96,Loss: -2.381,Avg.Loss: -1.735,LR: 3.64E-04]Training epoch 35:  86%|████████▌ | 96/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 96,Loss: -2.381,Avg.Loss: -1.735,LR: 3.64E-04]Training epoch 35:  86%|████████▌ | 96/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 97,Loss: -1.011,Avg.Loss: -1.727,LR: 3.64E-04]Training epoch 35:  87%|████████▋ | 97/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 98,Loss: 0.021,Avg.Loss: -1.709,LR: 3.64E-04] Training epoch 35:  88%|████████▊ | 98/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 99,Loss: -1.349,Avg.Loss: -1.706,LR: 3.64E-04]Training epoch 35:  88%|████████▊ | 99/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 100,Loss: -1.769,Avg.Loss: -1.706,LR: 3.64E-04]Training epoch 35:  89%|████████▉ | 100/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 101,Loss: -1.936,Avg.Loss: -1.709,LR: 3.64E-04]Training epoch 35:  90%|█████████ | 101/112 [00:01<00:00, 53.03it/s, Epoch: 35, Batch: 102,Loss: -2.247,Avg.Loss: -1.714,LR: 3.64E-04]Training epoch 35:  91%|█████████ | 102/112 [00:01<00:00, 53.24it/s, Epoch: 35, Batch: 102,Loss: -2.247,Avg.Loss: -1.714,LR: 3.64E-04]Training epoch 35:  91%|█████████ | 102/112 [00:01<00:00, 53.24it/s, Epoch: 35, Batch: 103,Loss: -1.522,Avg.Loss: -1.712,LR: 3.64E-04]Training epoch 35:  92%|█████████▏| 103/112 [00:01<00:00, 53.24it/s, Epoch: 35, Batch: 104,Loss: -0.299,Avg.Loss: -1.698,LR: 3.64E-04]Training epoch 35:  93%|█████████▎| 104/112 [00:01<00:00, 53.24it/s, Epoch: 35, Batch: 105,Loss: -1.212,Avg.Loss: -1.694,LR: 3.64E-04]Training epoch 35:  94%|█████████▍| 105/112 [00:02<00:00, 53.24it/s, Epoch: 35, Batch: 106,Loss: -1.719,Avg.Loss: -1.694,LR: 3.64E-04]Training epoch 35:  95%|█████████▍| 106/112 [00:02<00:00, 53.24it/s, Epoch: 35, Batch: 107,Loss: -1.302,Avg.Loss: -1.690,LR: 3.64E-04]Training epoch 35:  96%|█████████▌| 107/112 [00:02<00:00, 53.24it/s, Epoch: 35, Batch: 108,Loss: -2.313,Avg.Loss: -1.696,LR: 3.64E-04]Training epoch 35:  96%|█████████▋| 108/112 [00:02<00:00, 53.08it/s, Epoch: 35, Batch: 108,Loss: -2.313,Avg.Loss: -1.696,LR: 3.64E-04]Training epoch 35:  96%|█████████▋| 108/112 [00:02<00:00, 53.08it/s, Epoch: 35, Batch: 109,Loss: -2.033,Avg.Loss: -1.699,LR: 3.64E-04]Training epoch 35:  97%|█████████▋| 109/112 [00:02<00:00, 53.08it/s, Epoch: 35, Batch: 110,Loss: -1.538,Avg.Loss: -1.698,LR: 3.64E-04]Training epoch 35:  98%|█████████▊| 110/112 [00:02<00:00, 53.08it/s, Epoch: 35, Batch: 111,Loss: -2.085,Avg.Loss: -1.701,LR: 3.64E-04]Training epoch 35:  99%|█████████▉| 111/112 [00:02<00:00, 53.08it/s, Epoch: 35, Batch: 112,Loss: -0.809,Avg.Loss: -1.693,LR: 3.63E-04]Training epoch 35: 100%|██████████| 112/112 [00:02<00:00, 52.90it/s, Epoch: 35, Batch: 112,Loss: -0.809,Avg.Loss: -1.693,LR: 3.63E-04]
Training epoch 36:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 36:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 36, Batch: 1,Loss: -1.164,Avg.Loss: -1.164,LR: 3.63E-04]Training epoch 36:   1%|          | 1/112 [00:00<00:04, 25.44it/s, Epoch: 36, Batch: 2,Loss: -2.384,Avg.Loss: -1.774,LR: 3.63E-04]Training epoch 36:   2%|▏         | 2/112 [00:00<00:02, 38.11it/s, Epoch: 36, Batch: 3,Loss: -1.998,Avg.Loss: -1.849,LR: 3.63E-04]Training epoch 36:   3%|▎         | 3/112 [00:00<00:02, 42.94it/s, Epoch: 36, Batch: 4,Loss: -0.648,Avg.Loss: -1.549,LR: 3.63E-04]Training epoch 36:   4%|▎         | 4/112 [00:00<00:02, 48.12it/s, Epoch: 36, Batch: 5,Loss: -1.528,Avg.Loss: -1.544,LR: 3.63E-04]Training epoch 36:   4%|▍         | 5/112 [00:00<00:02, 49.46it/s, Epoch: 36, Batch: 6,Loss: -1.526,Avg.Loss: -1.541,LR: 3.63E-04]Training epoch 36:   5%|▌         | 6/112 [00:00<00:01, 59.26it/s, Epoch: 36, Batch: 6,Loss: -1.526,Avg.Loss: -1.541,LR: 3.63E-04]Training epoch 36:   5%|▌         | 6/112 [00:00<00:01, 59.26it/s, Epoch: 36, Batch: 7,Loss: -1.837,Avg.Loss: -1.584,LR: 3.63E-04]Training epoch 36:   6%|▋         | 7/112 [00:00<00:01, 59.26it/s, Epoch: 36, Batch: 8,Loss: -2.162,Avg.Loss: -1.656,LR: 3.63E-04]Training epoch 36:   7%|▋         | 8/112 [00:00<00:01, 59.26it/s, Epoch: 36, Batch: 9,Loss: -1.588,Avg.Loss: -1.648,LR: 3.63E-04]Training epoch 36:   8%|▊         | 9/112 [00:00<00:01, 59.26it/s, Epoch: 36, Batch: 10,Loss: -0.743,Avg.Loss: -1.558,LR: 3.63E-04]Training epoch 36:   9%|▉         | 10/112 [00:00<00:01, 59.26it/s, Epoch: 36, Batch: 11,Loss: -1.311,Avg.Loss: -1.535,LR: 3.63E-04]Training epoch 36:  10%|▉         | 11/112 [00:00<00:01, 59.26it/s, Epoch: 36, Batch: 12,Loss: -1.639,Avg.Loss: -1.544,LR: 3.63E-04]Training epoch 36:  11%|█         | 12/112 [00:00<00:01, 55.82it/s, Epoch: 36, Batch: 12,Loss: -1.639,Avg.Loss: -1.544,LR: 3.63E-04]Training epoch 36:  11%|█         | 12/112 [00:00<00:01, 55.82it/s, Epoch: 36, Batch: 13,Loss: -1.507,Avg.Loss: -1.541,LR: 3.63E-04]Training epoch 36:  12%|█▏        | 13/112 [00:00<00:01, 55.82it/s, Epoch: 36, Batch: 14,Loss: -2.311,Avg.Loss: -1.596,LR: 3.63E-04]Training epoch 36:  12%|█▎        | 14/112 [00:00<00:01, 55.82it/s, Epoch: 36, Batch: 15,Loss: -1.574,Avg.Loss: -1.595,LR: 3.63E-04]Training epoch 36:  13%|█▎        | 15/112 [00:00<00:01, 55.82it/s, Epoch: 36, Batch: 16,Loss: -0.863,Avg.Loss: -1.549,LR: 3.62E-04]Training epoch 36:  14%|█▍        | 16/112 [00:00<00:01, 55.82it/s, Epoch: 36, Batch: 17,Loss: -1.828,Avg.Loss: -1.565,LR: 3.62E-04]Training epoch 36:  15%|█▌        | 17/112 [00:00<00:01, 55.82it/s, Epoch: 36, Batch: 18,Loss: -2.111,Avg.Loss: -1.596,LR: 3.62E-04]Training epoch 36:  16%|█▌        | 18/112 [00:00<00:01, 54.32it/s, Epoch: 36, Batch: 18,Loss: -2.111,Avg.Loss: -1.596,LR: 3.62E-04]Training epoch 36:  16%|█▌        | 18/112 [00:00<00:01, 54.32it/s, Epoch: 36, Batch: 19,Loss: -1.744,Avg.Loss: -1.603,LR: 3.62E-04]Training epoch 36:  17%|█▋        | 19/112 [00:00<00:01, 54.32it/s, Epoch: 36, Batch: 20,Loss: -2.359,Avg.Loss: -1.641,LR: 3.62E-04]Training epoch 36:  18%|█▊        | 20/112 [00:00<00:01, 54.32it/s, Epoch: 36, Batch: 21,Loss: -2.226,Avg.Loss: -1.669,LR: 3.62E-04]Training epoch 36:  19%|█▉        | 21/112 [00:00<00:01, 54.32it/s, Epoch: 36, Batch: 22,Loss: -1.624,Avg.Loss: -1.667,LR: 3.62E-04]Training epoch 36:  20%|█▉        | 22/112 [00:00<00:01, 54.32it/s, Epoch: 36, Batch: 23,Loss: -2.424,Avg.Loss: -1.700,LR: 3.62E-04]Training epoch 36:  21%|██        | 23/112 [00:00<00:01, 54.32it/s, Epoch: 36, Batch: 24,Loss: -1.552,Avg.Loss: -1.694,LR: 3.62E-04]Training epoch 36:  21%|██▏       | 24/112 [00:00<00:01, 53.36it/s, Epoch: 36, Batch: 24,Loss: -1.552,Avg.Loss: -1.694,LR: 3.62E-04]Training epoch 36:  21%|██▏       | 24/112 [00:00<00:01, 53.36it/s, Epoch: 36, Batch: 25,Loss: -0.981,Avg.Loss: -1.665,LR: 3.62E-04]Training epoch 36:  22%|██▏       | 25/112 [00:00<00:01, 53.36it/s, Epoch: 36, Batch: 26,Loss: -1.697,Avg.Loss: -1.666,LR: 3.62E-04]Training epoch 36:  23%|██▎       | 26/112 [00:00<00:01, 53.36it/s, Epoch: 36, Batch: 27,Loss: -2.477,Avg.Loss: -1.696,LR: 3.62E-04]Training epoch 36:  24%|██▍       | 27/112 [00:00<00:01, 53.36it/s, Epoch: 36, Batch: 28,Loss: -2.128,Avg.Loss: -1.712,LR: 3.62E-04]Training epoch 36:  25%|██▌       | 28/112 [00:00<00:01, 53.36it/s, Epoch: 36, Batch: 29,Loss: -2.739,Avg.Loss: -1.747,LR: 3.62E-04]Training epoch 36:  26%|██▌       | 29/112 [00:00<00:01, 53.36it/s, Epoch: 36, Batch: 30,Loss: -1.409,Avg.Loss: -1.736,LR: 3.62E-04]Training epoch 36:  27%|██▋       | 30/112 [00:00<00:01, 53.41it/s, Epoch: 36, Batch: 30,Loss: -1.409,Avg.Loss: -1.736,LR: 3.62E-04]Training epoch 36:  27%|██▋       | 30/112 [00:00<00:01, 53.41it/s, Epoch: 36, Batch: 31,Loss: -1.260,Avg.Loss: -1.721,LR: 3.62E-04]Training epoch 36:  28%|██▊       | 31/112 [00:00<00:01, 53.41it/s, Epoch: 36, Batch: 32,Loss: -1.833,Avg.Loss: -1.724,LR: 3.61E-04]Training epoch 36:  29%|██▊       | 32/112 [00:00<00:01, 53.41it/s, Epoch: 36, Batch: 33,Loss: -2.003,Avg.Loss: -1.733,LR: 3.61E-04]Training epoch 36:  29%|██▉       | 33/112 [00:00<00:01, 53.41it/s, Epoch: 36, Batch: 34,Loss: -1.888,Avg.Loss: -1.737,LR: 3.61E-04]Training epoch 36:  30%|███       | 34/112 [00:00<00:01, 53.41it/s, Epoch: 36, Batch: 35,Loss: -2.126,Avg.Loss: -1.748,LR: 3.61E-04]Training epoch 36:  31%|███▏      | 35/112 [00:00<00:01, 53.41it/s, Epoch: 36, Batch: 36,Loss: -2.124,Avg.Loss: -1.759,LR: 3.61E-04]Training epoch 36:  32%|███▏      | 36/112 [00:00<00:01, 53.43it/s, Epoch: 36, Batch: 36,Loss: -2.124,Avg.Loss: -1.759,LR: 3.61E-04]Training epoch 36:  32%|███▏      | 36/112 [00:00<00:01, 53.43it/s, Epoch: 36, Batch: 37,Loss: -1.616,Avg.Loss: -1.755,LR: 3.61E-04]Training epoch 36:  33%|███▎      | 37/112 [00:00<00:01, 53.43it/s, Epoch: 36, Batch: 38,Loss: -2.335,Avg.Loss: -1.770,LR: 3.61E-04]Training epoch 36:  34%|███▍      | 38/112 [00:00<00:01, 53.43it/s, Epoch: 36, Batch: 39,Loss: -1.882,Avg.Loss: -1.773,LR: 3.61E-04]Training epoch 36:  35%|███▍      | 39/112 [00:00<00:01, 53.43it/s, Epoch: 36, Batch: 40,Loss: -1.417,Avg.Loss: -1.764,LR: 3.61E-04]Training epoch 36:  36%|███▌      | 40/112 [00:00<00:01, 53.43it/s, Epoch: 36, Batch: 41,Loss: -1.659,Avg.Loss: -1.761,LR: 3.61E-04]Training epoch 36:  37%|███▋      | 41/112 [00:00<00:01, 53.43it/s, Epoch: 36, Batch: 42,Loss: -2.188,Avg.Loss: -1.772,LR: 3.61E-04]Training epoch 36:  38%|███▊      | 42/112 [00:00<00:01, 53.54it/s, Epoch: 36, Batch: 42,Loss: -2.188,Avg.Loss: -1.772,LR: 3.61E-04]Training epoch 36:  38%|███▊      | 42/112 [00:00<00:01, 53.54it/s, Epoch: 36, Batch: 43,Loss: -1.762,Avg.Loss: -1.771,LR: 3.61E-04]Training epoch 36:  38%|███▊      | 43/112 [00:00<00:01, 53.54it/s, Epoch: 36, Batch: 44,Loss: -2.249,Avg.Loss: -1.782,LR: 3.61E-04]Training epoch 36:  39%|███▉      | 44/112 [00:00<00:01, 53.54it/s, Epoch: 36, Batch: 45,Loss: -2.151,Avg.Loss: -1.790,LR: 3.61E-04]Training epoch 36:  40%|████      | 45/112 [00:00<00:01, 53.54it/s, Epoch: 36, Batch: 46,Loss: -1.387,Avg.Loss: -1.782,LR: 3.61E-04]Training epoch 36:  41%|████      | 46/112 [00:00<00:01, 53.54it/s, Epoch: 36, Batch: 47,Loss: -2.145,Avg.Loss: -1.789,LR: 3.61E-04]Training epoch 36:  42%|████▏     | 47/112 [00:00<00:01, 53.54it/s, Epoch: 36, Batch: 48,Loss: -2.250,Avg.Loss: -1.799,LR: 3.60E-04]Training epoch 36:  43%|████▎     | 48/112 [00:00<00:01, 53.58it/s, Epoch: 36, Batch: 48,Loss: -2.250,Avg.Loss: -1.799,LR: 3.60E-04]Training epoch 36:  43%|████▎     | 48/112 [00:00<00:01, 53.58it/s, Epoch: 36, Batch: 49,Loss: -2.093,Avg.Loss: -1.805,LR: 3.60E-04]Training epoch 36:  44%|████▍     | 49/112 [00:00<00:01, 53.58it/s, Epoch: 36, Batch: 50,Loss: -2.277,Avg.Loss: -1.814,LR: 3.60E-04]Training epoch 36:  45%|████▍     | 50/112 [00:00<00:01, 53.58it/s, Epoch: 36, Batch: 51,Loss: -2.105,Avg.Loss: -1.820,LR: 3.60E-04]Training epoch 36:  46%|████▌     | 51/112 [00:00<00:01, 53.58it/s, Epoch: 36, Batch: 52,Loss: -1.779,Avg.Loss: -1.819,LR: 3.60E-04]Training epoch 36:  46%|████▋     | 52/112 [00:00<00:01, 53.58it/s, Epoch: 36, Batch: 53,Loss: -2.180,Avg.Loss: -1.826,LR: 3.60E-04]Training epoch 36:  47%|████▋     | 53/112 [00:01<00:01, 53.58it/s, Epoch: 36, Batch: 54,Loss: -1.849,Avg.Loss: -1.827,LR: 3.60E-04]Training epoch 36:  48%|████▊     | 54/112 [00:01<00:01, 53.61it/s, Epoch: 36, Batch: 54,Loss: -1.849,Avg.Loss: -1.827,LR: 3.60E-04]Training epoch 36:  48%|████▊     | 54/112 [00:01<00:01, 53.61it/s, Epoch: 36, Batch: 55,Loss: -1.779,Avg.Loss: -1.826,LR: 3.60E-04]Training epoch 36:  49%|████▉     | 55/112 [00:01<00:01, 53.61it/s, Epoch: 36, Batch: 56,Loss: -2.304,Avg.Loss: -1.834,LR: 3.60E-04]Training epoch 36:  50%|█████     | 56/112 [00:01<00:01, 53.61it/s, Epoch: 36, Batch: 57,Loss: -2.226,Avg.Loss: -1.841,LR: 3.60E-04]Training epoch 36:  51%|█████     | 57/112 [00:01<00:01, 53.61it/s, Epoch: 36, Batch: 58,Loss: -1.170,Avg.Loss: -1.830,LR: 3.60E-04]Training epoch 36:  52%|█████▏    | 58/112 [00:01<00:01, 53.61it/s, Epoch: 36, Batch: 59,Loss: -1.727,Avg.Loss: -1.828,LR: 3.60E-04]Training epoch 36:  53%|█████▎    | 59/112 [00:01<00:00, 53.61it/s, Epoch: 36, Batch: 60,Loss: -2.036,Avg.Loss: -1.831,LR: 3.60E-04]Training epoch 36:  54%|█████▎    | 60/112 [00:01<00:00, 53.46it/s, Epoch: 36, Batch: 60,Loss: -2.036,Avg.Loss: -1.831,LR: 3.60E-04]Training epoch 36:  54%|█████▎    | 60/112 [00:01<00:00, 53.46it/s, Epoch: 36, Batch: 61,Loss: -1.939,Avg.Loss: -1.833,LR: 3.60E-04]Training epoch 36:  54%|█████▍    | 61/112 [00:01<00:00, 53.46it/s, Epoch: 36, Batch: 62,Loss: -2.112,Avg.Loss: -1.838,LR: 3.60E-04]Training epoch 36:  55%|█████▌    | 62/112 [00:01<00:00, 53.46it/s, Epoch: 36, Batch: 63,Loss: -1.979,Avg.Loss: -1.840,LR: 3.60E-04]Training epoch 36:  56%|█████▋    | 63/112 [00:01<00:00, 53.46it/s, Epoch: 36, Batch: 64,Loss: -1.308,Avg.Loss: -1.832,LR: 3.59E-04]Training epoch 36:  57%|█████▋    | 64/112 [00:01<00:00, 53.46it/s, Epoch: 36, Batch: 65,Loss: -1.774,Avg.Loss: -1.831,LR: 3.59E-04]Training epoch 36:  58%|█████▊    | 65/112 [00:01<00:00, 53.46it/s, Epoch: 36, Batch: 66,Loss: -2.367,Avg.Loss: -1.839,LR: 3.59E-04]Training epoch 36:  59%|█████▉    | 66/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 66,Loss: -2.367,Avg.Loss: -1.839,LR: 3.59E-04]Training epoch 36:  59%|█████▉    | 66/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 67,Loss: -1.686,Avg.Loss: -1.837,LR: 3.59E-04]Training epoch 36:  60%|█████▉    | 67/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 68,Loss: -2.462,Avg.Loss: -1.846,LR: 3.59E-04]Training epoch 36:  61%|██████    | 68/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 69,Loss: -1.631,Avg.Loss: -1.843,LR: 3.59E-04]Training epoch 36:  62%|██████▏   | 69/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 70,Loss: -1.170,Avg.Loss: -1.833,LR: 3.59E-04]Training epoch 36:  62%|██████▎   | 70/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 71,Loss: -2.464,Avg.Loss: -1.842,LR: 3.59E-04]Training epoch 36:  63%|██████▎   | 71/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 72,Loss: -2.072,Avg.Loss: -1.845,LR: 3.59E-04]Training epoch 36:  64%|██████▍   | 72/112 [00:01<00:00, 53.47it/s, Epoch: 36, Batch: 72,Loss: -2.072,Avg.Loss: -1.845,LR: 3.59E-04]Training epoch 36:  64%|██████▍   | 72/112 [00:01<00:00, 53.47it/s, Epoch: 36, Batch: 73,Loss: -1.690,Avg.Loss: -1.843,LR: 3.59E-04]Training epoch 36:  65%|██████▌   | 73/112 [00:01<00:00, 53.47it/s, Epoch: 36, Batch: 74,Loss: -2.367,Avg.Loss: -1.850,LR: 3.59E-04]Training epoch 36:  66%|██████▌   | 74/112 [00:01<00:00, 53.47it/s, Epoch: 36, Batch: 75,Loss: -2.160,Avg.Loss: -1.854,LR: 3.59E-04]Training epoch 36:  67%|██████▋   | 75/112 [00:01<00:00, 53.47it/s, Epoch: 36, Batch: 76,Loss: -1.419,Avg.Loss: -1.848,LR: 3.59E-04]Training epoch 36:  68%|██████▊   | 76/112 [00:01<00:00, 53.47it/s, Epoch: 36, Batch: 77,Loss: -2.046,Avg.Loss: -1.851,LR: 3.59E-04]Training epoch 36:  69%|██████▉   | 77/112 [00:01<00:00, 53.47it/s, Epoch: 36, Batch: 78,Loss: -2.336,Avg.Loss: -1.857,LR: 3.59E-04]Training epoch 36:  70%|██████▉   | 78/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 78,Loss: -2.336,Avg.Loss: -1.857,LR: 3.59E-04]Training epoch 36:  70%|██████▉   | 78/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 79,Loss: -1.961,Avg.Loss: -1.859,LR: 3.59E-04]Training epoch 36:  71%|███████   | 79/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 80,Loss: -2.421,Avg.Loss: -1.866,LR: 3.58E-04]Training epoch 36:  71%|███████▏  | 80/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 81,Loss: -1.680,Avg.Loss: -1.863,LR: 3.58E-04]Training epoch 36:  72%|███████▏  | 81/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 82,Loss: -1.331,Avg.Loss: -1.857,LR: 3.58E-04]Training epoch 36:  73%|███████▎  | 82/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 83,Loss: -2.364,Avg.Loss: -1.863,LR: 3.58E-04]Training epoch 36:  74%|███████▍  | 83/112 [00:01<00:00, 53.39it/s, Epoch: 36, Batch: 84,Loss: -2.289,Avg.Loss: -1.868,LR: 3.58E-04]Training epoch 36:  75%|███████▌  | 84/112 [00:01<00:00, 53.56it/s, Epoch: 36, Batch: 84,Loss: -2.289,Avg.Loss: -1.868,LR: 3.58E-04]Training epoch 36:  75%|███████▌  | 84/112 [00:01<00:00, 53.56it/s, Epoch: 36, Batch: 85,Loss: -2.297,Avg.Loss: -1.873,LR: 3.58E-04]Training epoch 36:  76%|███████▌  | 85/112 [00:01<00:00, 53.56it/s, Epoch: 36, Batch: 86,Loss: -2.388,Avg.Loss: -1.879,LR: 3.58E-04]Training epoch 36:  77%|███████▋  | 86/112 [00:01<00:00, 53.56it/s, Epoch: 36, Batch: 87,Loss: -1.594,Avg.Loss: -1.876,LR: 3.58E-04]Training epoch 36:  78%|███████▊  | 87/112 [00:01<00:00, 53.56it/s, Epoch: 36, Batch: 88,Loss: -1.029,Avg.Loss: -1.866,LR: 3.58E-04]Training epoch 36:  79%|███████▊  | 88/112 [00:01<00:00, 53.56it/s, Epoch: 36, Batch: 89,Loss: -1.854,Avg.Loss: -1.866,LR: 3.58E-04]Training epoch 36:  79%|███████▉  | 89/112 [00:01<00:00, 53.56it/s, Epoch: 36, Batch: 90,Loss: -1.928,Avg.Loss: -1.867,LR: 3.58E-04]Training epoch 36:  80%|████████  | 90/112 [00:01<00:00, 53.53it/s, Epoch: 36, Batch: 90,Loss: -1.928,Avg.Loss: -1.867,LR: 3.58E-04]Training epoch 36:  80%|████████  | 90/112 [00:01<00:00, 53.53it/s, Epoch: 36, Batch: 91,Loss: -1.811,Avg.Loss: -1.866,LR: 3.58E-04]Training epoch 36:  81%|████████▏ | 91/112 [00:01<00:00, 53.53it/s, Epoch: 36, Batch: 92,Loss: -2.565,Avg.Loss: -1.874,LR: 3.58E-04]Training epoch 36:  82%|████████▏ | 92/112 [00:01<00:00, 53.53it/s, Epoch: 36, Batch: 93,Loss: -1.573,Avg.Loss: -1.870,LR: 3.58E-04]Training epoch 36:  83%|████████▎ | 93/112 [00:01<00:00, 53.53it/s, Epoch: 36, Batch: 94,Loss: -1.431,Avg.Loss: -1.866,LR: 3.58E-04]Training epoch 36:  84%|████████▍ | 94/112 [00:01<00:00, 53.53it/s, Epoch: 36, Batch: 95,Loss: -2.351,Avg.Loss: -1.871,LR: 3.58E-04]Training epoch 36:  85%|████████▍ | 95/112 [00:01<00:00, 53.53it/s, Epoch: 36, Batch: 96,Loss: -2.084,Avg.Loss: -1.873,LR: 3.57E-04]Training epoch 36:  86%|████████▌ | 96/112 [00:01<00:00, 53.85it/s, Epoch: 36, Batch: 96,Loss: -2.084,Avg.Loss: -1.873,LR: 3.57E-04]Training epoch 36:  86%|████████▌ | 96/112 [00:01<00:00, 53.85it/s, Epoch: 36, Batch: 97,Loss: -1.468,Avg.Loss: -1.869,LR: 3.57E-04]Training epoch 36:  87%|████████▋ | 97/112 [00:01<00:00, 53.85it/s, Epoch: 36, Batch: 98,Loss: -2.155,Avg.Loss: -1.872,LR: 3.57E-04]Training epoch 36:  88%|████████▊ | 98/112 [00:01<00:00, 53.85it/s, Epoch: 36, Batch: 99,Loss: -2.055,Avg.Loss: -1.874,LR: 3.57E-04]Training epoch 36:  88%|████████▊ | 99/112 [00:01<00:00, 53.85it/s, Epoch: 36, Batch: 100,Loss: -1.761,Avg.Loss: -1.873,LR: 3.57E-04]Training epoch 36:  89%|████████▉ | 100/112 [00:01<00:00, 53.85it/s, Epoch: 36, Batch: 101,Loss: -1.718,Avg.Loss: -1.871,LR: 3.57E-04]Training epoch 36:  90%|█████████ | 101/112 [00:01<00:00, 53.85it/s, Epoch: 36, Batch: 102,Loss: -2.305,Avg.Loss: -1.875,LR: 3.57E-04]Training epoch 36:  91%|█████████ | 102/112 [00:01<00:00, 53.97it/s, Epoch: 36, Batch: 102,Loss: -2.305,Avg.Loss: -1.875,LR: 3.57E-04]Training epoch 36:  91%|█████████ | 102/112 [00:01<00:00, 53.97it/s, Epoch: 36, Batch: 103,Loss: -1.883,Avg.Loss: -1.875,LR: 3.57E-04]Training epoch 36:  92%|█████████▏| 103/112 [00:01<00:00, 53.97it/s, Epoch: 36, Batch: 104,Loss: -2.237,Avg.Loss: -1.879,LR: 3.57E-04]Training epoch 36:  93%|█████████▎| 104/112 [00:01<00:00, 53.97it/s, Epoch: 36, Batch: 105,Loss: -1.953,Avg.Loss: -1.880,LR: 3.57E-04]Training epoch 36:  94%|█████████▍| 105/112 [00:01<00:00, 53.97it/s, Epoch: 36, Batch: 106,Loss: -1.179,Avg.Loss: -1.873,LR: 3.57E-04]Training epoch 36:  95%|█████████▍| 106/112 [00:01<00:00, 53.97it/s, Epoch: 36, Batch: 107,Loss: -1.993,Avg.Loss: -1.874,LR: 3.57E-04]Training epoch 36:  96%|█████████▌| 107/112 [00:02<00:00, 53.97it/s, Epoch: 36, Batch: 108,Loss: -2.096,Avg.Loss: -1.876,LR: 3.57E-04]Training epoch 36:  96%|█████████▋| 108/112 [00:02<00:00, 54.06it/s, Epoch: 36, Batch: 108,Loss: -2.096,Avg.Loss: -1.876,LR: 3.57E-04]Training epoch 36:  96%|█████████▋| 108/112 [00:02<00:00, 54.06it/s, Epoch: 36, Batch: 109,Loss: -1.525,Avg.Loss: -1.873,LR: 3.57E-04]Training epoch 36:  97%|█████████▋| 109/112 [00:02<00:00, 54.06it/s, Epoch: 36, Batch: 110,Loss: -2.270,Avg.Loss: -1.876,LR: 3.57E-04]Training epoch 36:  98%|█████████▊| 110/112 [00:02<00:00, 54.06it/s, Epoch: 36, Batch: 111,Loss: -2.250,Avg.Loss: -1.880,LR: 3.57E-04]Training epoch 36:  99%|█████████▉| 111/112 [00:02<00:00, 54.06it/s, Epoch: 36, Batch: 112,Loss: -0.367,Avg.Loss: -1.866,LR: 3.56E-04]Training epoch 36: 100%|██████████| 112/112 [00:02<00:00, 53.74it/s, Epoch: 36, Batch: 112,Loss: -0.367,Avg.Loss: -1.866,LR: 3.56E-04]
Training epoch 37:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 37:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 37, Batch: 1,Loss: -1.991,Avg.Loss: -1.991,LR: 3.56E-04]Training epoch 37:   1%|          | 1/112 [00:00<00:03, 30.61it/s, Epoch: 37, Batch: 2,Loss: -1.769,Avg.Loss: -1.880,LR: 3.56E-04]Training epoch 37:   2%|▏         | 2/112 [00:00<00:02, 43.36it/s, Epoch: 37, Batch: 3,Loss: -1.882,Avg.Loss: -1.881,LR: 3.56E-04]Training epoch 37:   3%|▎         | 3/112 [00:00<00:02, 49.24it/s, Epoch: 37, Batch: 4,Loss: -2.359,Avg.Loss: -2.000,LR: 3.56E-04]Training epoch 37:   4%|▎         | 4/112 [00:00<00:01, 54.33it/s, Epoch: 37, Batch: 5,Loss: -1.515,Avg.Loss: -1.903,LR: 3.56E-04]Training epoch 37:   4%|▍         | 5/112 [00:00<00:01, 54.78it/s, Epoch: 37, Batch: 6,Loss: -0.508,Avg.Loss: -1.670,LR: 3.56E-04]Training epoch 37:   5%|▌         | 6/112 [00:00<00:01, 55.33it/s, Epoch: 37, Batch: 7,Loss: -1.594,Avg.Loss: -1.660,LR: 3.56E-04]Training epoch 37:   6%|▋         | 7/112 [00:00<00:01, 64.47it/s, Epoch: 37, Batch: 7,Loss: -1.594,Avg.Loss: -1.660,LR: 3.56E-04]Training epoch 37:   6%|▋         | 7/112 [00:00<00:01, 64.47it/s, Epoch: 37, Batch: 8,Loss: -1.836,Avg.Loss: -1.682,LR: 3.56E-04]Training epoch 37:   7%|▋         | 8/112 [00:00<00:01, 64.47it/s, Epoch: 37, Batch: 9,Loss: -1.906,Avg.Loss: -1.707,LR: 3.56E-04]Training epoch 37:   8%|▊         | 9/112 [00:00<00:01, 64.47it/s, Epoch: 37, Batch: 10,Loss: -2.311,Avg.Loss: -1.767,LR: 3.56E-04]Training epoch 37:   9%|▉         | 10/112 [00:00<00:01, 64.47it/s, Epoch: 37, Batch: 11,Loss: -2.136,Avg.Loss: -1.801,LR: 3.56E-04]Training epoch 37:  10%|▉         | 11/112 [00:00<00:01, 64.47it/s, Epoch: 37, Batch: 12,Loss: -1.170,Avg.Loss: -1.748,LR: 3.56E-04]Training epoch 37:  11%|█         | 12/112 [00:00<00:01, 64.47it/s, Epoch: 37, Batch: 13,Loss: -1.718,Avg.Loss: -1.746,LR: 3.56E-04]Training epoch 37:  12%|█▏        | 13/112 [00:00<00:01, 64.47it/s, Epoch: 37, Batch: 14,Loss: -1.116,Avg.Loss: -1.701,LR: 3.56E-04]Training epoch 37:  12%|█▎        | 14/112 [00:00<00:01, 61.05it/s, Epoch: 37, Batch: 14,Loss: -1.116,Avg.Loss: -1.701,LR: 3.56E-04]Training epoch 37:  12%|█▎        | 14/112 [00:00<00:01, 61.05it/s, Epoch: 37, Batch: 15,Loss: -1.849,Avg.Loss: -1.711,LR: 3.55E-04]Training epoch 37:  13%|█▎        | 15/112 [00:00<00:01, 61.05it/s, Epoch: 37, Batch: 16,Loss: -2.452,Avg.Loss: -1.757,LR: 3.55E-04]Training epoch 37:  14%|█▍        | 16/112 [00:00<00:01, 61.05it/s, Epoch: 37, Batch: 17,Loss: -1.989,Avg.Loss: -1.771,LR: 3.55E-04]Training epoch 37:  15%|█▌        | 17/112 [00:00<00:01, 61.05it/s, Epoch: 37, Batch: 18,Loss: -1.560,Avg.Loss: -1.759,LR: 3.55E-04]Training epoch 37:  16%|█▌        | 18/112 [00:00<00:01, 61.05it/s, Epoch: 37, Batch: 19,Loss: -1.842,Avg.Loss: -1.763,LR: 3.55E-04]Training epoch 37:  17%|█▋        | 19/112 [00:00<00:01, 61.05it/s, Epoch: 37, Batch: 20,Loss: -1.653,Avg.Loss: -1.758,LR: 3.55E-04]Training epoch 37:  18%|█▊        | 20/112 [00:00<00:01, 61.05it/s, Epoch: 37, Batch: 21,Loss: -1.739,Avg.Loss: -1.757,LR: 3.55E-04]Training epoch 37:  19%|█▉        | 21/112 [00:00<00:01, 56.99it/s, Epoch: 37, Batch: 21,Loss: -1.739,Avg.Loss: -1.757,LR: 3.55E-04]Training epoch 37:  19%|█▉        | 21/112 [00:00<00:01, 56.99it/s, Epoch: 37, Batch: 22,Loss: -2.360,Avg.Loss: -1.784,LR: 3.55E-04]Training epoch 37:  20%|█▉        | 22/112 [00:00<00:01, 56.99it/s, Epoch: 37, Batch: 23,Loss: -2.296,Avg.Loss: -1.807,LR: 3.55E-04]Training epoch 37:  21%|██        | 23/112 [00:00<00:01, 56.99it/s, Epoch: 37, Batch: 24,Loss: -1.289,Avg.Loss: -1.785,LR: 3.55E-04]Training epoch 37:  21%|██▏       | 24/112 [00:00<00:01, 56.99it/s, Epoch: 37, Batch: 25,Loss: -2.049,Avg.Loss: -1.796,LR: 3.55E-04]Training epoch 37:  22%|██▏       | 25/112 [00:00<00:01, 56.99it/s, Epoch: 37, Batch: 26,Loss: -2.087,Avg.Loss: -1.807,LR: 3.55E-04]Training epoch 37:  23%|██▎       | 26/112 [00:00<00:01, 56.99it/s, Epoch: 37, Batch: 27,Loss: -2.061,Avg.Loss: -1.816,LR: 3.55E-04]Training epoch 37:  24%|██▍       | 27/112 [00:00<00:01, 54.91it/s, Epoch: 37, Batch: 27,Loss: -2.061,Avg.Loss: -1.816,LR: 3.55E-04]Training epoch 37:  24%|██▍       | 27/112 [00:00<00:01, 54.91it/s, Epoch: 37, Batch: 28,Loss: -2.355,Avg.Loss: -1.835,LR: 3.55E-04]Training epoch 37:  25%|██▌       | 28/112 [00:00<00:01, 54.91it/s, Epoch: 37, Batch: 29,Loss: -1.669,Avg.Loss: -1.830,LR: 3.55E-04]Training epoch 37:  26%|██▌       | 29/112 [00:00<00:01, 54.91it/s, Epoch: 37, Batch: 30,Loss: -0.897,Avg.Loss: -1.799,LR: 3.55E-04]Training epoch 37:  27%|██▋       | 30/112 [00:00<00:01, 54.91it/s, Epoch: 37, Batch: 31,Loss: -1.876,Avg.Loss: -1.801,LR: 3.54E-04]Training epoch 37:  28%|██▊       | 31/112 [00:00<00:01, 54.91it/s, Epoch: 37, Batch: 32,Loss: -2.105,Avg.Loss: -1.811,LR: 3.54E-04]Training epoch 37:  29%|██▊       | 32/112 [00:00<00:01, 54.91it/s, Epoch: 37, Batch: 33,Loss: -1.852,Avg.Loss: -1.812,LR: 3.54E-04]Training epoch 37:  29%|██▉       | 33/112 [00:00<00:01, 54.06it/s, Epoch: 37, Batch: 33,Loss: -1.852,Avg.Loss: -1.812,LR: 3.54E-04]Training epoch 37:  29%|██▉       | 33/112 [00:00<00:01, 54.06it/s, Epoch: 37, Batch: 34,Loss: -2.466,Avg.Loss: -1.831,LR: 3.54E-04]Training epoch 37:  30%|███       | 34/112 [00:00<00:01, 54.06it/s, Epoch: 37, Batch: 35,Loss: -1.654,Avg.Loss: -1.826,LR: 3.54E-04]Training epoch 37:  31%|███▏      | 35/112 [00:00<00:01, 54.06it/s, Epoch: 37, Batch: 36,Loss: -1.285,Avg.Loss: -1.811,LR: 3.54E-04]Training epoch 37:  32%|███▏      | 36/112 [00:00<00:01, 54.06it/s, Epoch: 37, Batch: 37,Loss: -1.607,Avg.Loss: -1.805,LR: 3.54E-04]Training epoch 37:  33%|███▎      | 37/112 [00:00<00:01, 54.06it/s, Epoch: 37, Batch: 38,Loss: -1.728,Avg.Loss: -1.803,LR: 3.54E-04]Training epoch 37:  34%|███▍      | 38/112 [00:00<00:01, 54.06it/s, Epoch: 37, Batch: 39,Loss: -1.554,Avg.Loss: -1.797,LR: 3.54E-04]Training epoch 37:  35%|███▍      | 39/112 [00:00<00:01, 53.78it/s, Epoch: 37, Batch: 39,Loss: -1.554,Avg.Loss: -1.797,LR: 3.54E-04]Training epoch 37:  35%|███▍      | 39/112 [00:00<00:01, 53.78it/s, Epoch: 37, Batch: 40,Loss: -1.887,Avg.Loss: -1.799,LR: 3.54E-04]Training epoch 37:  36%|███▌      | 40/112 [00:00<00:01, 53.78it/s, Epoch: 37, Batch: 41,Loss: -2.151,Avg.Loss: -1.808,LR: 3.54E-04]Training epoch 37:  37%|███▋      | 41/112 [00:00<00:01, 53.78it/s, Epoch: 37, Batch: 42,Loss: -1.622,Avg.Loss: -1.803,LR: 3.54E-04]Training epoch 37:  38%|███▊      | 42/112 [00:00<00:01, 53.78it/s, Epoch: 37, Batch: 43,Loss: -2.248,Avg.Loss: -1.814,LR: 3.54E-04]Training epoch 37:  38%|███▊      | 43/112 [00:00<00:01, 53.78it/s, Epoch: 37, Batch: 44,Loss: -1.504,Avg.Loss: -1.807,LR: 3.54E-04]Training epoch 37:  39%|███▉      | 44/112 [00:00<00:01, 53.78it/s, Epoch: 37, Batch: 45,Loss: -1.384,Avg.Loss: -1.797,LR: 3.54E-04]Training epoch 37:  40%|████      | 45/112 [00:00<00:01, 53.58it/s, Epoch: 37, Batch: 45,Loss: -1.384,Avg.Loss: -1.797,LR: 3.54E-04]Training epoch 37:  40%|████      | 45/112 [00:00<00:01, 53.58it/s, Epoch: 37, Batch: 46,Loss: -1.695,Avg.Loss: -1.795,LR: 3.54E-04]Training epoch 37:  41%|████      | 46/112 [00:00<00:01, 53.58it/s, Epoch: 37, Batch: 47,Loss: -2.068,Avg.Loss: -1.801,LR: 3.53E-04]Training epoch 37:  42%|████▏     | 47/112 [00:00<00:01, 53.58it/s, Epoch: 37, Batch: 48,Loss: -2.050,Avg.Loss: -1.806,LR: 3.53E-04]Training epoch 37:  43%|████▎     | 48/112 [00:00<00:01, 53.58it/s, Epoch: 37, Batch: 49,Loss: -2.344,Avg.Loss: -1.817,LR: 3.53E-04]Training epoch 37:  44%|████▍     | 49/112 [00:00<00:01, 53.58it/s, Epoch: 37, Batch: 50,Loss: -1.504,Avg.Loss: -1.811,LR: 3.53E-04]Training epoch 37:  45%|████▍     | 50/112 [00:00<00:01, 53.58it/s, Epoch: 37, Batch: 51,Loss: -1.499,Avg.Loss: -1.805,LR: 3.53E-04]Training epoch 37:  46%|████▌     | 51/112 [00:00<00:01, 53.39it/s, Epoch: 37, Batch: 51,Loss: -1.499,Avg.Loss: -1.805,LR: 3.53E-04]Training epoch 37:  46%|████▌     | 51/112 [00:00<00:01, 53.39it/s, Epoch: 37, Batch: 52,Loss: -2.194,Avg.Loss: -1.812,LR: 3.53E-04]Training epoch 37:  46%|████▋     | 52/112 [00:00<00:01, 53.39it/s, Epoch: 37, Batch: 53,Loss: -1.846,Avg.Loss: -1.813,LR: 3.53E-04]Training epoch 37:  47%|████▋     | 53/112 [00:00<00:01, 53.39it/s, Epoch: 37, Batch: 54,Loss: -1.313,Avg.Loss: -1.804,LR: 3.53E-04]Training epoch 37:  48%|████▊     | 54/112 [00:01<00:01, 53.39it/s, Epoch: 37, Batch: 55,Loss: -2.003,Avg.Loss: -1.807,LR: 3.53E-04]Training epoch 37:  49%|████▉     | 55/112 [00:01<00:01, 53.39it/s, Epoch: 37, Batch: 56,Loss: -2.178,Avg.Loss: -1.814,LR: 3.53E-04]Training epoch 37:  50%|█████     | 56/112 [00:01<00:01, 53.39it/s, Epoch: 37, Batch: 57,Loss: -1.701,Avg.Loss: -1.812,LR: 3.53E-04]Training epoch 37:  51%|█████     | 57/112 [00:01<00:01, 53.24it/s, Epoch: 37, Batch: 57,Loss: -1.701,Avg.Loss: -1.812,LR: 3.53E-04]Training epoch 37:  51%|█████     | 57/112 [00:01<00:01, 53.24it/s, Epoch: 37, Batch: 58,Loss: -2.322,Avg.Loss: -1.821,LR: 3.53E-04]Training epoch 37:  52%|█████▏    | 58/112 [00:01<00:01, 53.24it/s, Epoch: 37, Batch: 59,Loss: -1.581,Avg.Loss: -1.817,LR: 3.53E-04]Training epoch 37:  53%|█████▎    | 59/112 [00:01<00:00, 53.24it/s, Epoch: 37, Batch: 60,Loss: -0.665,Avg.Loss: -1.797,LR: 3.53E-04]Training epoch 37:  54%|█████▎    | 60/112 [00:01<00:00, 53.24it/s, Epoch: 37, Batch: 61,Loss: -2.189,Avg.Loss: -1.804,LR: 3.53E-04]Training epoch 37:  54%|█████▍    | 61/112 [00:01<00:00, 53.24it/s, Epoch: 37, Batch: 62,Loss: -2.020,Avg.Loss: -1.807,LR: 3.52E-04]Training epoch 37:  55%|█████▌    | 62/112 [00:01<00:00, 53.24it/s, Epoch: 37, Batch: 63,Loss: -1.845,Avg.Loss: -1.808,LR: 3.52E-04]Training epoch 37:  56%|█████▋    | 63/112 [00:01<00:00, 53.35it/s, Epoch: 37, Batch: 63,Loss: -1.845,Avg.Loss: -1.808,LR: 3.52E-04]Training epoch 37:  56%|█████▋    | 63/112 [00:01<00:00, 53.35it/s, Epoch: 37, Batch: 64,Loss: -2.277,Avg.Loss: -1.815,LR: 3.52E-04]Training epoch 37:  57%|█████▋    | 64/112 [00:01<00:00, 53.35it/s, Epoch: 37, Batch: 65,Loss: -2.071,Avg.Loss: -1.819,LR: 3.52E-04]Training epoch 37:  58%|█████▊    | 65/112 [00:01<00:00, 53.35it/s, Epoch: 37, Batch: 66,Loss: -1.371,Avg.Loss: -1.812,LR: 3.52E-04]Training epoch 37:  59%|█████▉    | 66/112 [00:01<00:00, 53.35it/s, Epoch: 37, Batch: 67,Loss: -1.596,Avg.Loss: -1.809,LR: 3.52E-04]Training epoch 37:  60%|█████▉    | 67/112 [00:01<00:00, 53.35it/s, Epoch: 37, Batch: 68,Loss: -1.472,Avg.Loss: -1.804,LR: 3.52E-04]Training epoch 37:  61%|██████    | 68/112 [00:01<00:00, 53.35it/s, Epoch: 37, Batch: 69,Loss: -1.345,Avg.Loss: -1.798,LR: 3.52E-04]Training epoch 37:  62%|██████▏   | 69/112 [00:01<00:00, 53.58it/s, Epoch: 37, Batch: 69,Loss: -1.345,Avg.Loss: -1.798,LR: 3.52E-04]Training epoch 37:  62%|██████▏   | 69/112 [00:01<00:00, 53.58it/s, Epoch: 37, Batch: 70,Loss: -1.411,Avg.Loss: -1.792,LR: 3.52E-04]Training epoch 37:  62%|██████▎   | 70/112 [00:01<00:00, 53.58it/s, Epoch: 37, Batch: 71,Loss: -2.409,Avg.Loss: -1.801,LR: 3.52E-04]Training epoch 37:  63%|██████▎   | 71/112 [00:01<00:00, 53.58it/s, Epoch: 37, Batch: 72,Loss: -1.979,Avg.Loss: -1.803,LR: 3.52E-04]Training epoch 37:  64%|██████▍   | 72/112 [00:01<00:00, 53.58it/s, Epoch: 37, Batch: 73,Loss: -2.236,Avg.Loss: -1.809,LR: 3.52E-04]Training epoch 37:  65%|██████▌   | 73/112 [00:01<00:00, 53.58it/s, Epoch: 37, Batch: 74,Loss: -1.668,Avg.Loss: -1.807,LR: 3.52E-04]Training epoch 37:  66%|██████▌   | 74/112 [00:01<00:00, 53.58it/s, Epoch: 37, Batch: 75,Loss: -1.664,Avg.Loss: -1.805,LR: 3.52E-04]Training epoch 37:  67%|██████▋   | 75/112 [00:01<00:00, 53.34it/s, Epoch: 37, Batch: 75,Loss: -1.664,Avg.Loss: -1.805,LR: 3.52E-04]Training epoch 37:  67%|██████▋   | 75/112 [00:01<00:00, 53.34it/s, Epoch: 37, Batch: 76,Loss: -2.081,Avg.Loss: -1.809,LR: 3.52E-04]Training epoch 37:  68%|██████▊   | 76/112 [00:01<00:00, 53.34it/s, Epoch: 37, Batch: 77,Loss: -1.850,Avg.Loss: -1.809,LR: 3.52E-04]Training epoch 37:  69%|██████▉   | 77/112 [00:01<00:00, 53.34it/s, Epoch: 37, Batch: 78,Loss: -1.402,Avg.Loss: -1.804,LR: 3.51E-04]Training epoch 37:  70%|██████▉   | 78/112 [00:01<00:00, 53.34it/s, Epoch: 37, Batch: 79,Loss: -2.010,Avg.Loss: -1.807,LR: 3.51E-04]Training epoch 37:  71%|███████   | 79/112 [00:01<00:00, 53.34it/s, Epoch: 37, Batch: 80,Loss: -1.785,Avg.Loss: -1.807,LR: 3.51E-04]Training epoch 37:  71%|███████▏  | 80/112 [00:01<00:00, 53.34it/s, Epoch: 37, Batch: 81,Loss: -1.493,Avg.Loss: -1.803,LR: 3.51E-04]Training epoch 37:  72%|███████▏  | 81/112 [00:01<00:00, 52.13it/s, Epoch: 37, Batch: 81,Loss: -1.493,Avg.Loss: -1.803,LR: 3.51E-04]Training epoch 37:  72%|███████▏  | 81/112 [00:01<00:00, 52.13it/s, Epoch: 37, Batch: 82,Loss: -2.489,Avg.Loss: -1.811,LR: 3.51E-04]Training epoch 37:  73%|███████▎  | 82/112 [00:01<00:00, 52.13it/s, Epoch: 37, Batch: 83,Loss: -2.000,Avg.Loss: -1.813,LR: 3.51E-04]Training epoch 37:  74%|███████▍  | 83/112 [00:01<00:00, 52.13it/s, Epoch: 37, Batch: 84,Loss: -1.538,Avg.Loss: -1.810,LR: 3.51E-04]Training epoch 37:  75%|███████▌  | 84/112 [00:01<00:00, 52.13it/s, Epoch: 37, Batch: 85,Loss: -2.243,Avg.Loss: -1.815,LR: 3.51E-04]Training epoch 37:  76%|███████▌  | 85/112 [00:01<00:00, 52.13it/s, Epoch: 37, Batch: 86,Loss: -1.823,Avg.Loss: -1.815,LR: 3.51E-04]Training epoch 37:  77%|███████▋  | 86/112 [00:01<00:00, 52.13it/s, Epoch: 37, Batch: 87,Loss: -1.965,Avg.Loss: -1.817,LR: 3.51E-04]Training epoch 37:  78%|███████▊  | 87/112 [00:01<00:00, 52.53it/s, Epoch: 37, Batch: 87,Loss: -1.965,Avg.Loss: -1.817,LR: 3.51E-04]Training epoch 37:  78%|███████▊  | 87/112 [00:01<00:00, 52.53it/s, Epoch: 37, Batch: 88,Loss: -2.215,Avg.Loss: -1.821,LR: 3.51E-04]Training epoch 37:  79%|███████▊  | 88/112 [00:01<00:00, 52.53it/s, Epoch: 37, Batch: 89,Loss: -1.868,Avg.Loss: -1.822,LR: 3.51E-04]Training epoch 37:  79%|███████▉  | 89/112 [00:01<00:00, 52.53it/s, Epoch: 37, Batch: 90,Loss: -1.349,Avg.Loss: -1.817,LR: 3.51E-04]Training epoch 37:  80%|████████  | 90/112 [00:01<00:00, 52.53it/s, Epoch: 37, Batch: 91,Loss: -2.410,Avg.Loss: -1.823,LR: 3.51E-04]Training epoch 37:  81%|████████▏ | 91/112 [00:01<00:00, 52.53it/s, Epoch: 37, Batch: 92,Loss: -2.134,Avg.Loss: -1.827,LR: 3.51E-04]Training epoch 37:  82%|████████▏ | 92/112 [00:01<00:00, 52.53it/s, Epoch: 37, Batch: 93,Loss: -1.585,Avg.Loss: -1.824,LR: 3.51E-04]Training epoch 37:  83%|████████▎ | 93/112 [00:01<00:00, 52.94it/s, Epoch: 37, Batch: 93,Loss: -1.585,Avg.Loss: -1.824,LR: 3.51E-04]Training epoch 37:  83%|████████▎ | 93/112 [00:01<00:00, 52.94it/s, Epoch: 37, Batch: 94,Loss: -2.289,Avg.Loss: -1.829,LR: 3.50E-04]Training epoch 37:  84%|████████▍ | 94/112 [00:01<00:00, 52.94it/s, Epoch: 37, Batch: 95,Loss: -2.089,Avg.Loss: -1.832,LR: 3.50E-04]Training epoch 37:  85%|████████▍ | 95/112 [00:01<00:00, 52.94it/s, Epoch: 37, Batch: 96,Loss: -1.782,Avg.Loss: -1.831,LR: 3.50E-04]Training epoch 37:  86%|████████▌ | 96/112 [00:01<00:00, 52.94it/s, Epoch: 37, Batch: 97,Loss: -2.468,Avg.Loss: -1.838,LR: 3.50E-04]Training epoch 37:  87%|████████▋ | 97/112 [00:01<00:00, 52.94it/s, Epoch: 37, Batch: 98,Loss: -2.010,Avg.Loss: -1.840,LR: 3.50E-04]Training epoch 37:  88%|████████▊ | 98/112 [00:01<00:00, 52.94it/s, Epoch: 37, Batch: 99,Loss: -1.334,Avg.Loss: -1.834,LR: 3.50E-04]Training epoch 37:  88%|████████▊ | 99/112 [00:01<00:00, 53.08it/s, Epoch: 37, Batch: 99,Loss: -1.334,Avg.Loss: -1.834,LR: 3.50E-04]Training epoch 37:  88%|████████▊ | 99/112 [00:01<00:00, 53.08it/s, Epoch: 37, Batch: 100,Loss: -2.237,Avg.Loss: -1.838,LR: 3.50E-04]Training epoch 37:  89%|████████▉ | 100/112 [00:01<00:00, 53.08it/s, Epoch: 37, Batch: 101,Loss: -2.214,Avg.Loss: -1.842,LR: 3.50E-04]Training epoch 37:  90%|█████████ | 101/112 [00:01<00:00, 53.08it/s, Epoch: 37, Batch: 102,Loss: -1.795,Avg.Loss: -1.842,LR: 3.50E-04]Training epoch 37:  91%|█████████ | 102/112 [00:01<00:00, 53.08it/s, Epoch: 37, Batch: 103,Loss: -2.337,Avg.Loss: -1.847,LR: 3.50E-04]Training epoch 37:  92%|█████████▏| 103/112 [00:01<00:00, 53.08it/s, Epoch: 37, Batch: 104,Loss: -1.955,Avg.Loss: -1.848,LR: 3.50E-04]Training epoch 37:  93%|█████████▎| 104/112 [00:01<00:00, 53.08it/s, Epoch: 37, Batch: 105,Loss: -1.473,Avg.Loss: -1.844,LR: 3.50E-04]Training epoch 37:  94%|█████████▍| 105/112 [00:01<00:00, 53.26it/s, Epoch: 37, Batch: 105,Loss: -1.473,Avg.Loss: -1.844,LR: 3.50E-04]Training epoch 37:  94%|█████████▍| 105/112 [00:01<00:00, 53.26it/s, Epoch: 37, Batch: 106,Loss: -1.727,Avg.Loss: -1.843,LR: 3.50E-04]Training epoch 37:  95%|█████████▍| 106/112 [00:01<00:00, 53.26it/s, Epoch: 37, Batch: 107,Loss: -2.247,Avg.Loss: -1.847,LR: 3.50E-04]Training epoch 37:  96%|█████████▌| 107/112 [00:02<00:00, 53.26it/s, Epoch: 37, Batch: 108,Loss: -1.686,Avg.Loss: -1.845,LR: 3.50E-04]Training epoch 37:  96%|█████████▋| 108/112 [00:02<00:00, 53.26it/s, Epoch: 37, Batch: 109,Loss: -2.301,Avg.Loss: -1.849,LR: 3.49E-04]Training epoch 37:  97%|█████████▋| 109/112 [00:02<00:00, 53.26it/s, Epoch: 37, Batch: 110,Loss: -1.792,Avg.Loss: -1.849,LR: 3.49E-04]Training epoch 37:  98%|█████████▊| 110/112 [00:02<00:00, 53.26it/s, Epoch: 37, Batch: 111,Loss: -1.533,Avg.Loss: -1.846,LR: 3.49E-04]Training epoch 37:  99%|█████████▉| 111/112 [00:02<00:00, 53.12it/s, Epoch: 37, Batch: 111,Loss: -1.533,Avg.Loss: -1.846,LR: 3.49E-04]Training epoch 37:  99%|█████████▉| 111/112 [00:02<00:00, 53.12it/s, Epoch: 37, Batch: 112,Loss: -1.845,Avg.Loss: -1.846,LR: 3.49E-04]Training epoch 37: 100%|██████████| 112/112 [00:02<00:00, 53.74it/s, Epoch: 37, Batch: 112,Loss: -1.845,Avg.Loss: -1.846,LR: 3.49E-04]
Training epoch 38:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 38:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 38, Batch: 1,Loss: -2.346,Avg.Loss: -2.346,LR: 3.49E-04]Training epoch 38:   1%|          | 1/112 [00:00<00:04, 26.75it/s, Epoch: 38, Batch: 2,Loss: -1.464,Avg.Loss: -1.905,LR: 3.49E-04]Training epoch 38:   2%|▏         | 2/112 [00:00<00:03, 35.65it/s, Epoch: 38, Batch: 3,Loss: -2.232,Avg.Loss: -2.014,LR: 3.49E-04]Training epoch 38:   3%|▎         | 3/112 [00:00<00:02, 42.87it/s, Epoch: 38, Batch: 4,Loss: -2.253,Avg.Loss: -2.074,LR: 3.49E-04]Training epoch 38:   4%|▎         | 4/112 [00:00<00:02, 47.96it/s, Epoch: 38, Batch: 5,Loss: -1.880,Avg.Loss: -2.035,LR: 3.49E-04]Training epoch 38:   4%|▍         | 5/112 [00:00<00:02, 51.27it/s, Epoch: 38, Batch: 6,Loss: -2.323,Avg.Loss: -2.083,LR: 3.49E-04]Training epoch 38:   5%|▌         | 6/112 [00:00<00:01, 53.78it/s, Epoch: 38, Batch: 7,Loss: -1.789,Avg.Loss: -2.041,LR: 3.49E-04]Training epoch 38:   6%|▋         | 7/112 [00:00<00:01, 62.62it/s, Epoch: 38, Batch: 7,Loss: -1.789,Avg.Loss: -2.041,LR: 3.49E-04]Training epoch 38:   6%|▋         | 7/112 [00:00<00:01, 62.62it/s, Epoch: 38, Batch: 8,Loss: -1.315,Avg.Loss: -1.950,LR: 3.49E-04]Training epoch 38:   7%|▋         | 8/112 [00:00<00:01, 62.62it/s, Epoch: 38, Batch: 9,Loss: -2.027,Avg.Loss: -1.959,LR: 3.49E-04]Training epoch 38:   8%|▊         | 9/112 [00:00<00:01, 62.62it/s, Epoch: 38, Batch: 10,Loss: -1.995,Avg.Loss: -1.962,LR: 3.49E-04]Training epoch 38:   9%|▉         | 10/112 [00:00<00:01, 62.62it/s, Epoch: 38, Batch: 11,Loss: -1.278,Avg.Loss: -1.900,LR: 3.49E-04]Training epoch 38:  10%|▉         | 11/112 [00:00<00:01, 62.62it/s, Epoch: 38, Batch: 12,Loss: -1.735,Avg.Loss: -1.886,LR: 3.49E-04]Training epoch 38:  11%|█         | 12/112 [00:00<00:01, 62.62it/s, Epoch: 38, Batch: 13,Loss: -1.628,Avg.Loss: -1.867,LR: 3.48E-04]Training epoch 38:  12%|█▏        | 13/112 [00:00<00:01, 62.62it/s, Epoch: 38, Batch: 14,Loss: -1.478,Avg.Loss: -1.839,LR: 3.48E-04]Training epoch 38:  12%|█▎        | 14/112 [00:00<00:01, 58.18it/s, Epoch: 38, Batch: 14,Loss: -1.478,Avg.Loss: -1.839,LR: 3.48E-04]Training epoch 38:  12%|█▎        | 14/112 [00:00<00:01, 58.18it/s, Epoch: 38, Batch: 15,Loss: -2.396,Avg.Loss: -1.876,LR: 3.48E-04]Training epoch 38:  13%|█▎        | 15/112 [00:00<00:01, 58.18it/s, Epoch: 38, Batch: 16,Loss: -2.011,Avg.Loss: -1.884,LR: 3.48E-04]Training epoch 38:  14%|█▍        | 16/112 [00:00<00:01, 58.18it/s, Epoch: 38, Batch: 17,Loss: -1.891,Avg.Loss: -1.885,LR: 3.48E-04]Training epoch 38:  15%|█▌        | 17/112 [00:00<00:01, 58.18it/s, Epoch: 38, Batch: 18,Loss: -2.389,Avg.Loss: -1.913,LR: 3.48E-04]Training epoch 38:  16%|█▌        | 18/112 [00:00<00:01, 58.18it/s, Epoch: 38, Batch: 19,Loss: -1.753,Avg.Loss: -1.904,LR: 3.48E-04]Training epoch 38:  17%|█▋        | 19/112 [00:00<00:01, 58.18it/s, Epoch: 38, Batch: 20,Loss: -0.616,Avg.Loss: -1.840,LR: 3.48E-04]Training epoch 38:  18%|█▊        | 20/112 [00:00<00:01, 55.96it/s, Epoch: 38, Batch: 20,Loss: -0.616,Avg.Loss: -1.840,LR: 3.48E-04]Training epoch 38:  18%|█▊        | 20/112 [00:00<00:01, 55.96it/s, Epoch: 38, Batch: 21,Loss: -1.250,Avg.Loss: -1.812,LR: 3.48E-04]Training epoch 38:  19%|█▉        | 21/112 [00:00<00:01, 55.96it/s, Epoch: 38, Batch: 22,Loss: -2.117,Avg.Loss: -1.826,LR: 3.48E-04]Training epoch 38:  20%|█▉        | 22/112 [00:00<00:01, 55.96it/s, Epoch: 38, Batch: 23,Loss: -2.181,Avg.Loss: -1.841,LR: 3.48E-04]Training epoch 38:  21%|██        | 23/112 [00:00<00:01, 55.96it/s, Epoch: 38, Batch: 24,Loss: -2.357,Avg.Loss: -1.863,LR: 3.48E-04]Training epoch 38:  21%|██▏       | 24/112 [00:00<00:01, 55.96it/s, Epoch: 38, Batch: 25,Loss: -1.787,Avg.Loss: -1.860,LR: 3.48E-04]Training epoch 38:  22%|██▏       | 25/112 [00:00<00:01, 55.96it/s, Epoch: 38, Batch: 26,Loss: -1.568,Avg.Loss: -1.848,LR: 3.48E-04]Training epoch 38:  23%|██▎       | 26/112 [00:00<00:01, 54.47it/s, Epoch: 38, Batch: 26,Loss: -1.568,Avg.Loss: -1.848,LR: 3.48E-04]Training epoch 38:  23%|██▎       | 26/112 [00:00<00:01, 54.47it/s, Epoch: 38, Batch: 27,Loss: -1.775,Avg.Loss: -1.846,LR: 3.48E-04]Training epoch 38:  24%|██▍       | 27/112 [00:00<00:01, 54.47it/s, Epoch: 38, Batch: 28,Loss: -2.415,Avg.Loss: -1.866,LR: 3.47E-04]Training epoch 38:  25%|██▌       | 28/112 [00:00<00:01, 54.47it/s, Epoch: 38, Batch: 29,Loss: -1.675,Avg.Loss: -1.859,LR: 3.47E-04]Training epoch 38:  26%|██▌       | 29/112 [00:00<00:01, 54.47it/s, Epoch: 38, Batch: 30,Loss: -2.032,Avg.Loss: -1.865,LR: 3.47E-04]Training epoch 38:  27%|██▋       | 30/112 [00:00<00:01, 54.47it/s, Epoch: 38, Batch: 31,Loss: -2.108,Avg.Loss: -1.873,LR: 3.47E-04]Training epoch 38:  28%|██▊       | 31/112 [00:00<00:01, 54.47it/s, Epoch: 38, Batch: 32,Loss: -1.493,Avg.Loss: -1.861,LR: 3.47E-04]Training epoch 38:  29%|██▊       | 32/112 [00:00<00:01, 53.77it/s, Epoch: 38, Batch: 32,Loss: -1.493,Avg.Loss: -1.861,LR: 3.47E-04]Training epoch 38:  29%|██▊       | 32/112 [00:00<00:01, 53.77it/s, Epoch: 38, Batch: 33,Loss: -1.753,Avg.Loss: -1.858,LR: 3.47E-04]Training epoch 38:  29%|██▉       | 33/112 [00:00<00:01, 53.77it/s, Epoch: 38, Batch: 34,Loss: -2.348,Avg.Loss: -1.872,LR: 3.47E-04]Training epoch 38:  30%|███       | 34/112 [00:00<00:01, 53.77it/s, Epoch: 38, Batch: 35,Loss: -2.080,Avg.Loss: -1.878,LR: 3.47E-04]Training epoch 38:  31%|███▏      | 35/112 [00:00<00:01, 53.77it/s, Epoch: 38, Batch: 36,Loss: -2.618,Avg.Loss: -1.899,LR: 3.47E-04]Training epoch 38:  32%|███▏      | 36/112 [00:00<00:01, 53.77it/s, Epoch: 38, Batch: 37,Loss: -1.549,Avg.Loss: -1.889,LR: 3.47E-04]Training epoch 38:  33%|███▎      | 37/112 [00:00<00:01, 53.77it/s, Epoch: 38, Batch: 38,Loss: -1.337,Avg.Loss: -1.875,LR: 3.47E-04]Training epoch 38:  34%|███▍      | 38/112 [00:00<00:01, 53.50it/s, Epoch: 38, Batch: 38,Loss: -1.337,Avg.Loss: -1.875,LR: 3.47E-04]Training epoch 38:  34%|███▍      | 38/112 [00:00<00:01, 53.50it/s, Epoch: 38, Batch: 39,Loss: -2.593,Avg.Loss: -1.893,LR: 3.47E-04]Training epoch 38:  35%|███▍      | 39/112 [00:00<00:01, 53.50it/s, Epoch: 38, Batch: 40,Loss: -2.056,Avg.Loss: -1.897,LR: 3.47E-04]Training epoch 38:  36%|███▌      | 40/112 [00:00<00:01, 53.50it/s, Epoch: 38, Batch: 41,Loss: -1.760,Avg.Loss: -1.894,LR: 3.47E-04]Training epoch 38:  37%|███▋      | 41/112 [00:00<00:01, 53.50it/s, Epoch: 38, Batch: 42,Loss: -2.501,Avg.Loss: -1.908,LR: 3.47E-04]Training epoch 38:  38%|███▊      | 42/112 [00:00<00:01, 53.50it/s, Epoch: 38, Batch: 43,Loss: -1.683,Avg.Loss: -1.903,LR: 3.47E-04]Training epoch 38:  38%|███▊      | 43/112 [00:00<00:01, 53.50it/s, Epoch: 38, Batch: 44,Loss: -1.787,Avg.Loss: -1.901,LR: 3.46E-04]Training epoch 38:  39%|███▉      | 44/112 [00:00<00:01, 53.32it/s, Epoch: 38, Batch: 44,Loss: -1.787,Avg.Loss: -1.901,LR: 3.46E-04]Training epoch 38:  39%|███▉      | 44/112 [00:00<00:01, 53.32it/s, Epoch: 38, Batch: 45,Loss: -2.358,Avg.Loss: -1.911,LR: 3.46E-04]Training epoch 38:  40%|████      | 45/112 [00:00<00:01, 53.32it/s, Epoch: 38, Batch: 46,Loss: -2.053,Avg.Loss: -1.914,LR: 3.46E-04]Training epoch 38:  41%|████      | 46/112 [00:00<00:01, 53.32it/s, Epoch: 38, Batch: 47,Loss: -1.768,Avg.Loss: -1.911,LR: 3.46E-04]Training epoch 38:  42%|████▏     | 47/112 [00:00<00:01, 53.32it/s, Epoch: 38, Batch: 48,Loss: -2.275,Avg.Loss: -1.918,LR: 3.46E-04]Training epoch 38:  43%|████▎     | 48/112 [00:00<00:01, 53.32it/s, Epoch: 38, Batch: 49,Loss: -1.846,Avg.Loss: -1.917,LR: 3.46E-04]Training epoch 38:  44%|████▍     | 49/112 [00:00<00:01, 53.32it/s, Epoch: 38, Batch: 50,Loss: -1.959,Avg.Loss: -1.918,LR: 3.46E-04]Training epoch 38:  45%|████▍     | 50/112 [00:00<00:01, 53.43it/s, Epoch: 38, Batch: 50,Loss: -1.959,Avg.Loss: -1.918,LR: 3.46E-04]Training epoch 38:  45%|████▍     | 50/112 [00:00<00:01, 53.43it/s, Epoch: 38, Batch: 51,Loss: -2.287,Avg.Loss: -1.925,LR: 3.46E-04]Training epoch 38:  46%|████▌     | 51/112 [00:00<00:01, 53.43it/s, Epoch: 38, Batch: 52,Loss: -2.078,Avg.Loss: -1.928,LR: 3.46E-04]Training epoch 38:  46%|████▋     | 52/112 [00:00<00:01, 53.43it/s, Epoch: 38, Batch: 53,Loss: -1.806,Avg.Loss: -1.926,LR: 3.46E-04]Training epoch 38:  47%|████▋     | 53/112 [00:00<00:01, 53.43it/s, Epoch: 38, Batch: 54,Loss: -2.461,Avg.Loss: -1.935,LR: 3.46E-04]Training epoch 38:  48%|████▊     | 54/112 [00:01<00:01, 53.43it/s, Epoch: 38, Batch: 55,Loss: -2.042,Avg.Loss: -1.937,LR: 3.46E-04]Training epoch 38:  49%|████▉     | 55/112 [00:01<00:01, 53.43it/s, Epoch: 38, Batch: 56,Loss: -1.746,Avg.Loss: -1.934,LR: 3.46E-04]Training epoch 38:  50%|█████     | 56/112 [00:01<00:01, 53.45it/s, Epoch: 38, Batch: 56,Loss: -1.746,Avg.Loss: -1.934,LR: 3.46E-04]Training epoch 38:  50%|█████     | 56/112 [00:01<00:01, 53.45it/s, Epoch: 38, Batch: 57,Loss: -2.017,Avg.Loss: -1.935,LR: 3.46E-04]Training epoch 38:  51%|█████     | 57/112 [00:01<00:01, 53.45it/s, Epoch: 38, Batch: 58,Loss: -2.225,Avg.Loss: -1.940,LR: 3.46E-04]Training epoch 38:  52%|█████▏    | 58/112 [00:01<00:01, 53.45it/s, Epoch: 38, Batch: 59,Loss: -1.591,Avg.Loss: -1.934,LR: 3.45E-04]Training epoch 38:  53%|█████▎    | 59/112 [00:01<00:00, 53.45it/s, Epoch: 38, Batch: 60,Loss: -2.241,Avg.Loss: -1.940,LR: 3.45E-04]Training epoch 38:  54%|█████▎    | 60/112 [00:01<00:00, 53.45it/s, Epoch: 38, Batch: 61,Loss: -1.855,Avg.Loss: -1.938,LR: 3.45E-04]Training epoch 38:  54%|█████▍    | 61/112 [00:01<00:00, 53.45it/s, Epoch: 38, Batch: 62,Loss: -1.451,Avg.Loss: -1.930,LR: 3.45E-04]Training epoch 38:  55%|█████▌    | 62/112 [00:01<00:00, 53.36it/s, Epoch: 38, Batch: 62,Loss: -1.451,Avg.Loss: -1.930,LR: 3.45E-04]Training epoch 38:  55%|█████▌    | 62/112 [00:01<00:00, 53.36it/s, Epoch: 38, Batch: 63,Loss: -1.988,Avg.Loss: -1.931,LR: 3.45E-04]Training epoch 38:  56%|█████▋    | 63/112 [00:01<00:00, 53.36it/s, Epoch: 38, Batch: 64,Loss: -2.094,Avg.Loss: -1.934,LR: 3.45E-04]Training epoch 38:  57%|█████▋    | 64/112 [00:01<00:00, 53.36it/s, Epoch: 38, Batch: 65,Loss: -1.580,Avg.Loss: -1.928,LR: 3.45E-04]Training epoch 38:  58%|█████▊    | 65/112 [00:01<00:00, 53.36it/s, Epoch: 38, Batch: 66,Loss: -2.264,Avg.Loss: -1.933,LR: 3.45E-04]Training epoch 38:  59%|█████▉    | 66/112 [00:01<00:00, 53.36it/s, Epoch: 38, Batch: 67,Loss: -2.533,Avg.Loss: -1.942,LR: 3.45E-04]Training epoch 38:  60%|█████▉    | 67/112 [00:01<00:00, 53.36it/s, Epoch: 38, Batch: 68,Loss: -1.480,Avg.Loss: -1.936,LR: 3.45E-04]Training epoch 38:  61%|██████    | 68/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 68,Loss: -1.480,Avg.Loss: -1.936,LR: 3.45E-04]Training epoch 38:  61%|██████    | 68/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 69,Loss: -2.168,Avg.Loss: -1.939,LR: 3.45E-04]Training epoch 38:  62%|██████▏   | 69/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 70,Loss: -2.006,Avg.Loss: -1.940,LR: 3.45E-04]Training epoch 38:  62%|██████▎   | 70/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 71,Loss: -1.472,Avg.Loss: -1.933,LR: 3.45E-04]Training epoch 38:  63%|██████▎   | 71/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 72,Loss: -2.162,Avg.Loss: -1.936,LR: 3.45E-04]Training epoch 38:  64%|██████▍   | 72/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 73,Loss: -1.972,Avg.Loss: -1.937,LR: 3.45E-04]Training epoch 38:  65%|██████▌   | 73/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 74,Loss: -1.342,Avg.Loss: -1.929,LR: 3.45E-04]Training epoch 38:  66%|██████▌   | 74/112 [00:01<00:00, 53.40it/s, Epoch: 38, Batch: 74,Loss: -1.342,Avg.Loss: -1.929,LR: 3.45E-04]Training epoch 38:  66%|██████▌   | 74/112 [00:01<00:00, 53.40it/s, Epoch: 38, Batch: 75,Loss: -2.246,Avg.Loss: -1.933,LR: 3.44E-04]Training epoch 38:  67%|██████▋   | 75/112 [00:01<00:00, 53.40it/s, Epoch: 38, Batch: 76,Loss: -2.108,Avg.Loss: -1.935,LR: 3.44E-04]Training epoch 38:  68%|██████▊   | 76/112 [00:01<00:00, 53.40it/s, Epoch: 38, Batch: 77,Loss: -2.003,Avg.Loss: -1.936,LR: 3.44E-04]Training epoch 38:  69%|██████▉   | 77/112 [00:01<00:00, 53.40it/s, Epoch: 38, Batch: 78,Loss: -2.420,Avg.Loss: -1.943,LR: 3.44E-04]Training epoch 38:  70%|██████▉   | 78/112 [00:01<00:00, 53.40it/s, Epoch: 38, Batch: 79,Loss: -2.079,Avg.Loss: -1.944,LR: 3.44E-04]Training epoch 38:  71%|███████   | 79/112 [00:01<00:00, 53.40it/s, Epoch: 38, Batch: 80,Loss: -1.202,Avg.Loss: -1.935,LR: 3.44E-04]Training epoch 38:  71%|███████▏  | 80/112 [00:01<00:00, 53.53it/s, Epoch: 38, Batch: 80,Loss: -1.202,Avg.Loss: -1.935,LR: 3.44E-04]Training epoch 38:  71%|███████▏  | 80/112 [00:01<00:00, 53.53it/s, Epoch: 38, Batch: 81,Loss: -2.148,Avg.Loss: -1.938,LR: 3.44E-04]Training epoch 38:  72%|███████▏  | 81/112 [00:01<00:00, 53.53it/s, Epoch: 38, Batch: 82,Loss: -2.085,Avg.Loss: -1.939,LR: 3.44E-04]Training epoch 38:  73%|███████▎  | 82/112 [00:01<00:00, 53.53it/s, Epoch: 38, Batch: 83,Loss: -2.051,Avg.Loss: -1.941,LR: 3.44E-04]Training epoch 38:  74%|███████▍  | 83/112 [00:01<00:00, 53.53it/s, Epoch: 38, Batch: 84,Loss: -2.377,Avg.Loss: -1.946,LR: 3.44E-04]Training epoch 38:  75%|███████▌  | 84/112 [00:01<00:00, 53.53it/s, Epoch: 38, Batch: 85,Loss: -2.118,Avg.Loss: -1.948,LR: 3.44E-04]Training epoch 38:  76%|███████▌  | 85/112 [00:01<00:00, 53.53it/s, Epoch: 38, Batch: 86,Loss: -1.491,Avg.Loss: -1.943,LR: 3.44E-04]Training epoch 38:  77%|███████▋  | 86/112 [00:01<00:00, 53.39it/s, Epoch: 38, Batch: 86,Loss: -1.491,Avg.Loss: -1.943,LR: 3.44E-04]Training epoch 38:  77%|███████▋  | 86/112 [00:01<00:00, 53.39it/s, Epoch: 38, Batch: 87,Loss: -2.217,Avg.Loss: -1.946,LR: 3.44E-04]Training epoch 38:  78%|███████▊  | 87/112 [00:01<00:00, 53.39it/s, Epoch: 38, Batch: 88,Loss: -2.197,Avg.Loss: -1.949,LR: 3.44E-04]Training epoch 38:  79%|███████▊  | 88/112 [00:01<00:00, 53.39it/s, Epoch: 38, Batch: 89,Loss: -1.733,Avg.Loss: -1.946,LR: 3.44E-04]Training epoch 38:  79%|███████▉  | 89/112 [00:01<00:00, 53.39it/s, Epoch: 38, Batch: 90,Loss: -2.222,Avg.Loss: -1.949,LR: 3.43E-04]Training epoch 38:  80%|████████  | 90/112 [00:01<00:00, 53.39it/s, Epoch: 38, Batch: 91,Loss: -1.917,Avg.Loss: -1.949,LR: 3.43E-04]Training epoch 38:  81%|████████▏ | 91/112 [00:01<00:00, 53.39it/s, Epoch: 38, Batch: 92,Loss: -1.133,Avg.Loss: -1.940,LR: 3.43E-04]Training epoch 38:  82%|████████▏ | 92/112 [00:01<00:00, 53.49it/s, Epoch: 38, Batch: 92,Loss: -1.133,Avg.Loss: -1.940,LR: 3.43E-04]Training epoch 38:  82%|████████▏ | 92/112 [00:01<00:00, 53.49it/s, Epoch: 38, Batch: 93,Loss: -2.055,Avg.Loss: -1.941,LR: 3.43E-04]Training epoch 38:  83%|████████▎ | 93/112 [00:01<00:00, 53.49it/s, Epoch: 38, Batch: 94,Loss: -2.340,Avg.Loss: -1.946,LR: 3.43E-04]Training epoch 38:  84%|████████▍ | 94/112 [00:01<00:00, 53.49it/s, Epoch: 38, Batch: 95,Loss: -1.913,Avg.Loss: -1.945,LR: 3.43E-04]Training epoch 38:  85%|████████▍ | 95/112 [00:01<00:00, 53.49it/s, Epoch: 38, Batch: 96,Loss: -2.390,Avg.Loss: -1.950,LR: 3.43E-04]Training epoch 38:  86%|████████▌ | 96/112 [00:01<00:00, 53.49it/s, Epoch: 38, Batch: 97,Loss: -1.368,Avg.Loss: -1.944,LR: 3.43E-04]Training epoch 38:  87%|████████▋ | 97/112 [00:01<00:00, 53.49it/s, Epoch: 38, Batch: 98,Loss: -0.903,Avg.Loss: -1.933,LR: 3.43E-04]Training epoch 38:  88%|████████▊ | 98/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 98,Loss: -0.903,Avg.Loss: -1.933,LR: 3.43E-04]Training epoch 38:  88%|████████▊ | 98/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 99,Loss: -1.818,Avg.Loss: -1.932,LR: 3.43E-04]Training epoch 38:  88%|████████▊ | 99/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 100,Loss: -2.301,Avg.Loss: -1.936,LR: 3.43E-04]Training epoch 38:  89%|████████▉ | 100/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 101,Loss: -2.170,Avg.Loss: -1.938,LR: 3.43E-04]Training epoch 38:  90%|█████████ | 101/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 102,Loss: -2.067,Avg.Loss: -1.939,LR: 3.43E-04]Training epoch 38:  91%|█████████ | 102/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 103,Loss: -2.187,Avg.Loss: -1.942,LR: 3.43E-04]Training epoch 38:  92%|█████████▏| 103/112 [00:01<00:00, 53.50it/s, Epoch: 38, Batch: 104,Loss: -1.633,Avg.Loss: -1.939,LR: 3.43E-04]Training epoch 38:  93%|█████████▎| 104/112 [00:01<00:00, 53.47it/s, Epoch: 38, Batch: 104,Loss: -1.633,Avg.Loss: -1.939,LR: 3.43E-04]Training epoch 38:  93%|█████████▎| 104/112 [00:01<00:00, 53.47it/s, Epoch: 38, Batch: 105,Loss: -2.154,Avg.Loss: -1.941,LR: 3.42E-04]Training epoch 38:  94%|█████████▍| 105/112 [00:01<00:00, 53.47it/s, Epoch: 38, Batch: 106,Loss: -2.269,Avg.Loss: -1.944,LR: 3.42E-04]Training epoch 38:  95%|█████████▍| 106/112 [00:01<00:00, 53.47it/s, Epoch: 38, Batch: 107,Loss: -1.650,Avg.Loss: -1.941,LR: 3.42E-04]Training epoch 38:  96%|█████████▌| 107/112 [00:02<00:00, 53.47it/s, Epoch: 38, Batch: 108,Loss: -1.823,Avg.Loss: -1.940,LR: 3.42E-04]Training epoch 38:  96%|█████████▋| 108/112 [00:02<00:00, 53.47it/s, Epoch: 38, Batch: 109,Loss: -2.072,Avg.Loss: -1.941,LR: 3.42E-04]Training epoch 38:  97%|█████████▋| 109/112 [00:02<00:00, 53.47it/s, Epoch: 38, Batch: 110,Loss: -1.383,Avg.Loss: -1.936,LR: 3.42E-04]Training epoch 38:  98%|█████████▊| 110/112 [00:02<00:00, 53.37it/s, Epoch: 38, Batch: 110,Loss: -1.383,Avg.Loss: -1.936,LR: 3.42E-04]Training epoch 38:  98%|█████████▊| 110/112 [00:02<00:00, 53.37it/s, Epoch: 38, Batch: 111,Loss: -1.838,Avg.Loss: -1.935,LR: 3.42E-04]Training epoch 38:  99%|█████████▉| 111/112 [00:02<00:00, 53.37it/s, Epoch: 38, Batch: 112,Loss: -1.520,Avg.Loss: -1.932,LR: 3.42E-04]Training epoch 38: 100%|██████████| 112/112 [00:02<00:00, 53.79it/s, Epoch: 38, Batch: 112,Loss: -1.520,Avg.Loss: -1.932,LR: 3.42E-04]
Training epoch 39:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 39:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 39, Batch: 1,Loss: 0.387,Avg.Loss: 0.387,LR: 3.42E-04]Training epoch 39:   1%|          | 1/112 [00:00<00:04, 27.72it/s, Epoch: 39, Batch: 2,Loss: 2.117,Avg.Loss: 1.252,LR: 3.42E-04]Training epoch 39:   2%|▏         | 2/112 [00:00<00:03, 36.26it/s, Epoch: 39, Batch: 3,Loss: 3.340,Avg.Loss: 1.948,LR: 3.42E-04]Training epoch 39:   3%|▎         | 3/112 [00:00<00:02, 41.09it/s, Epoch: 39, Batch: 4,Loss: 1.646,Avg.Loss: 1.873,LR: 3.42E-04]Training epoch 39:   4%|▎         | 4/112 [00:00<00:02, 43.40it/s, Epoch: 39, Batch: 5,Loss: -1.372,Avg.Loss: 1.224,LR: 3.42E-04]Training epoch 39:   4%|▍         | 5/112 [00:00<00:02, 45.13it/s, Epoch: 39, Batch: 6,Loss: -1.073,Avg.Loss: 0.841,LR: 3.42E-04]Training epoch 39:   5%|▌         | 6/112 [00:00<00:01, 54.07it/s, Epoch: 39, Batch: 6,Loss: -1.073,Avg.Loss: 0.841,LR: 3.42E-04]Training epoch 39:   5%|▌         | 6/112 [00:00<00:01, 54.07it/s, Epoch: 39, Batch: 7,Loss: -0.547,Avg.Loss: 0.643,LR: 3.42E-04]Training epoch 39:   6%|▋         | 7/112 [00:00<00:01, 54.07it/s, Epoch: 39, Batch: 8,Loss: -1.219,Avg.Loss: 0.410,LR: 3.42E-04]Training epoch 39:   7%|▋         | 8/112 [00:00<00:01, 54.07it/s, Epoch: 39, Batch: 9,Loss: -0.077,Avg.Loss: 0.356,LR: 3.41E-04]Training epoch 39:   8%|▊         | 9/112 [00:00<00:01, 54.07it/s, Epoch: 39, Batch: 10,Loss: 0.254,Avg.Loss: 0.346,LR: 3.41E-04]Training epoch 39:   9%|▉         | 10/112 [00:00<00:01, 54.07it/s, Epoch: 39, Batch: 11,Loss: -1.044,Avg.Loss: 0.219,LR: 3.41E-04]Training epoch 39:  10%|▉         | 11/112 [00:00<00:01, 54.07it/s, Epoch: 39, Batch: 12,Loss: -1.379,Avg.Loss: 0.086,LR: 3.41E-04]Training epoch 39:  11%|█         | 12/112 [00:00<00:01, 53.38it/s, Epoch: 39, Batch: 12,Loss: -1.379,Avg.Loss: 0.086,LR: 3.41E-04]Training epoch 39:  11%|█         | 12/112 [00:00<00:01, 53.38it/s, Epoch: 39, Batch: 13,Loss: -1.855,Avg.Loss: -0.063,LR: 3.41E-04]Training epoch 39:  12%|█▏        | 13/112 [00:00<00:01, 53.38it/s, Epoch: 39, Batch: 14,Loss: -1.138,Avg.Loss: -0.140,LR: 3.41E-04]Training epoch 39:  12%|█▎        | 14/112 [00:00<00:01, 53.38it/s, Epoch: 39, Batch: 15,Loss: -1.476,Avg.Loss: -0.229,LR: 3.41E-04]Training epoch 39:  13%|█▎        | 15/112 [00:00<00:01, 53.38it/s, Epoch: 39, Batch: 16,Loss: -1.402,Avg.Loss: -0.302,LR: 3.41E-04]Training epoch 39:  14%|█▍        | 16/112 [00:00<00:01, 53.38it/s, Epoch: 39, Batch: 17,Loss: -1.263,Avg.Loss: -0.359,LR: 3.41E-04]Training epoch 39:  15%|█▌        | 17/112 [00:00<00:01, 53.38it/s, Epoch: 39, Batch: 18,Loss: -1.638,Avg.Loss: -0.430,LR: 3.41E-04]Training epoch 39:  16%|█▌        | 18/112 [00:00<00:01, 52.93it/s, Epoch: 39, Batch: 18,Loss: -1.638,Avg.Loss: -0.430,LR: 3.41E-04]Training epoch 39:  16%|█▌        | 18/112 [00:00<00:01, 52.93it/s, Epoch: 39, Batch: 19,Loss: -1.744,Avg.Loss: -0.499,LR: 3.41E-04]Training epoch 39:  17%|█▋        | 19/112 [00:00<00:01, 52.93it/s, Epoch: 39, Batch: 20,Loss: -1.027,Avg.Loss: -0.526,LR: 3.41E-04]Training epoch 39:  18%|█▊        | 20/112 [00:00<00:01, 52.93it/s, Epoch: 39, Batch: 21,Loss: -0.736,Avg.Loss: -0.536,LR: 3.41E-04]Training epoch 39:  19%|█▉        | 21/112 [00:00<00:01, 52.93it/s, Epoch: 39, Batch: 22,Loss: -0.800,Avg.Loss: -0.548,LR: 3.41E-04]Training epoch 39:  20%|█▉        | 22/112 [00:00<00:01, 52.93it/s, Epoch: 39, Batch: 23,Loss: -1.667,Avg.Loss: -0.596,LR: 3.41E-04]Training epoch 39:  21%|██        | 23/112 [00:00<00:01, 52.93it/s, Epoch: 39, Batch: 24,Loss: -1.941,Avg.Loss: -0.652,LR: 3.40E-04]Training epoch 39:  21%|██▏       | 24/112 [00:00<00:01, 53.02it/s, Epoch: 39, Batch: 24,Loss: -1.941,Avg.Loss: -0.652,LR: 3.40E-04]Training epoch 39:  21%|██▏       | 24/112 [00:00<00:01, 53.02it/s, Epoch: 39, Batch: 25,Loss: -1.241,Avg.Loss: -0.676,LR: 3.40E-04]Training epoch 39:  22%|██▏       | 25/112 [00:00<00:01, 53.02it/s, Epoch: 39, Batch: 26,Loss: -1.286,Avg.Loss: -0.699,LR: 3.40E-04]Training epoch 39:  23%|██▎       | 26/112 [00:00<00:01, 53.02it/s, Epoch: 39, Batch: 27,Loss: -0.985,Avg.Loss: -0.710,LR: 3.40E-04]Training epoch 39:  24%|██▍       | 27/112 [00:00<00:01, 53.02it/s, Epoch: 39, Batch: 28,Loss: -1.422,Avg.Loss: -0.735,LR: 3.40E-04]Training epoch 39:  25%|██▌       | 28/112 [00:00<00:01, 53.02it/s, Epoch: 39, Batch: 29,Loss: -1.231,Avg.Loss: -0.752,LR: 3.40E-04]Training epoch 39:  26%|██▌       | 29/112 [00:00<00:01, 53.02it/s, Epoch: 39, Batch: 30,Loss: -1.456,Avg.Loss: -0.776,LR: 3.40E-04]Training epoch 39:  27%|██▋       | 30/112 [00:00<00:01, 52.68it/s, Epoch: 39, Batch: 30,Loss: -1.456,Avg.Loss: -0.776,LR: 3.40E-04]Training epoch 39:  27%|██▋       | 30/112 [00:00<00:01, 52.68it/s, Epoch: 39, Batch: 31,Loss: -1.044,Avg.Loss: -0.784,LR: 3.40E-04]Training epoch 39:  28%|██▊       | 31/112 [00:00<00:01, 52.68it/s, Epoch: 39, Batch: 32,Loss: -1.537,Avg.Loss: -0.808,LR: 3.40E-04]Training epoch 39:  29%|██▊       | 32/112 [00:00<00:01, 52.68it/s, Epoch: 39, Batch: 33,Loss: -1.720,Avg.Loss: -0.836,LR: 3.40E-04]Training epoch 39:  29%|██▉       | 33/112 [00:00<00:01, 52.68it/s, Epoch: 39, Batch: 34,Loss: -1.579,Avg.Loss: -0.858,LR: 3.40E-04]Training epoch 39:  30%|███       | 34/112 [00:00<00:01, 52.68it/s, Epoch: 39, Batch: 35,Loss: -0.419,Avg.Loss: -0.845,LR: 3.40E-04]Training epoch 39:  31%|███▏      | 35/112 [00:00<00:01, 52.68it/s, Epoch: 39, Batch: 36,Loss: -1.453,Avg.Loss: -0.862,LR: 3.40E-04]Training epoch 39:  32%|███▏      | 36/112 [00:00<00:01, 52.72it/s, Epoch: 39, Batch: 36,Loss: -1.453,Avg.Loss: -0.862,LR: 3.40E-04]Training epoch 39:  32%|███▏      | 36/112 [00:00<00:01, 52.72it/s, Epoch: 39, Batch: 37,Loss: -0.926,Avg.Loss: -0.864,LR: 3.40E-04]Training epoch 39:  33%|███▎      | 37/112 [00:00<00:01, 52.72it/s, Epoch: 39, Batch: 38,Loss: -1.574,Avg.Loss: -0.882,LR: 3.40E-04]Training epoch 39:  34%|███▍      | 38/112 [00:00<00:01, 52.72it/s, Epoch: 39, Batch: 39,Loss: -2.016,Avg.Loss: -0.911,LR: 3.39E-04]Training epoch 39:  35%|███▍      | 39/112 [00:00<00:01, 52.72it/s, Epoch: 39, Batch: 40,Loss: -1.684,Avg.Loss: -0.931,LR: 3.39E-04]Training epoch 39:  36%|███▌      | 40/112 [00:00<00:01, 52.72it/s, Epoch: 39, Batch: 41,Loss: -1.876,Avg.Loss: -0.954,LR: 3.39E-04]Training epoch 39:  37%|███▋      | 41/112 [00:00<00:01, 52.72it/s, Epoch: 39, Batch: 42,Loss: -1.801,Avg.Loss: -0.974,LR: 3.39E-04]Training epoch 39:  38%|███▊      | 42/112 [00:00<00:01, 52.91it/s, Epoch: 39, Batch: 42,Loss: -1.801,Avg.Loss: -0.974,LR: 3.39E-04]Training epoch 39:  38%|███▊      | 42/112 [00:00<00:01, 52.91it/s, Epoch: 39, Batch: 43,Loss: -1.660,Avg.Loss: -0.990,LR: 3.39E-04]Training epoch 39:  38%|███▊      | 43/112 [00:00<00:01, 52.91it/s, Epoch: 39, Batch: 44,Loss: -1.827,Avg.Loss: -1.009,LR: 3.39E-04]Training epoch 39:  39%|███▉      | 44/112 [00:00<00:01, 52.91it/s, Epoch: 39, Batch: 45,Loss: -1.621,Avg.Loss: -1.022,LR: 3.39E-04]Training epoch 39:  40%|████      | 45/112 [00:00<00:01, 52.91it/s, Epoch: 39, Batch: 46,Loss: -1.831,Avg.Loss: -1.040,LR: 3.39E-04]Training epoch 39:  41%|████      | 46/112 [00:00<00:01, 52.91it/s, Epoch: 39, Batch: 47,Loss: -2.119,Avg.Loss: -1.063,LR: 3.39E-04]Training epoch 39:  42%|████▏     | 47/112 [00:00<00:01, 52.91it/s, Epoch: 39, Batch: 48,Loss: -1.667,Avg.Loss: -1.076,LR: 3.39E-04]Training epoch 39:  43%|████▎     | 48/112 [00:00<00:01, 52.85it/s, Epoch: 39, Batch: 48,Loss: -1.667,Avg.Loss: -1.076,LR: 3.39E-04]Training epoch 39:  43%|████▎     | 48/112 [00:00<00:01, 52.85it/s, Epoch: 39, Batch: 49,Loss: -1.983,Avg.Loss: -1.094,LR: 3.39E-04]Training epoch 39:  44%|████▍     | 49/112 [00:00<00:01, 52.85it/s, Epoch: 39, Batch: 50,Loss: -2.095,Avg.Loss: -1.114,LR: 3.39E-04]Training epoch 39:  45%|████▍     | 50/112 [00:00<00:01, 52.85it/s, Epoch: 39, Batch: 51,Loss: -1.852,Avg.Loss: -1.129,LR: 3.39E-04]Training epoch 39:  46%|████▌     | 51/112 [00:00<00:01, 52.85it/s, Epoch: 39, Batch: 52,Loss: -1.569,Avg.Loss: -1.137,LR: 3.39E-04]Training epoch 39:  46%|████▋     | 52/112 [00:01<00:01, 52.85it/s, Epoch: 39, Batch: 53,Loss: -1.947,Avg.Loss: -1.152,LR: 3.39E-04]Training epoch 39:  47%|████▋     | 53/112 [00:01<00:01, 52.85it/s, Epoch: 39, Batch: 54,Loss: -0.850,Avg.Loss: -1.147,LR: 3.38E-04]Training epoch 39:  48%|████▊     | 54/112 [00:01<00:01, 52.87it/s, Epoch: 39, Batch: 54,Loss: -0.850,Avg.Loss: -1.147,LR: 3.38E-04]Training epoch 39:  48%|████▊     | 54/112 [00:01<00:01, 52.87it/s, Epoch: 39, Batch: 55,Loss: -0.335,Avg.Loss: -1.132,LR: 3.38E-04]Training epoch 39:  49%|████▉     | 55/112 [00:01<00:01, 52.87it/s, Epoch: 39, Batch: 56,Loss: -0.558,Avg.Loss: -1.122,LR: 3.38E-04]Training epoch 39:  50%|█████     | 56/112 [00:01<00:01, 52.87it/s, Epoch: 39, Batch: 57,Loss: -0.706,Avg.Loss: -1.114,LR: 3.38E-04]Training epoch 39:  51%|█████     | 57/112 [00:01<00:01, 52.87it/s, Epoch: 39, Batch: 58,Loss: 0.079,Avg.Loss: -1.094,LR: 3.38E-04] Training epoch 39:  52%|█████▏    | 58/112 [00:01<00:01, 52.87it/s, Epoch: 39, Batch: 59,Loss: -1.142,Avg.Loss: -1.095,LR: 3.38E-04]Training epoch 39:  53%|█████▎    | 59/112 [00:01<00:01, 52.87it/s, Epoch: 39, Batch: 60,Loss: -1.776,Avg.Loss: -1.106,LR: 3.38E-04]Training epoch 39:  54%|█████▎    | 60/112 [00:01<00:00, 53.05it/s, Epoch: 39, Batch: 60,Loss: -1.776,Avg.Loss: -1.106,LR: 3.38E-04]Training epoch 39:  54%|█████▎    | 60/112 [00:01<00:00, 53.05it/s, Epoch: 39, Batch: 61,Loss: -1.970,Avg.Loss: -1.120,LR: 3.38E-04]Training epoch 39:  54%|█████▍    | 61/112 [00:01<00:00, 53.05it/s, Epoch: 39, Batch: 62,Loss: -2.075,Avg.Loss: -1.136,LR: 3.38E-04]Training epoch 39:  55%|█████▌    | 62/112 [00:01<00:00, 53.05it/s, Epoch: 39, Batch: 63,Loss: -1.541,Avg.Loss: -1.142,LR: 3.38E-04]Training epoch 39:  56%|█████▋    | 63/112 [00:01<00:00, 53.05it/s, Epoch: 39, Batch: 64,Loss: -1.957,Avg.Loss: -1.155,LR: 3.38E-04]Training epoch 39:  57%|█████▋    | 64/112 [00:01<00:00, 53.05it/s, Epoch: 39, Batch: 65,Loss: -2.242,Avg.Loss: -1.172,LR: 3.38E-04]Training epoch 39:  58%|█████▊    | 65/112 [00:01<00:00, 53.05it/s, Epoch: 39, Batch: 66,Loss: -1.808,Avg.Loss: -1.181,LR: 3.38E-04]Training epoch 39:  59%|█████▉    | 66/112 [00:01<00:00, 53.19it/s, Epoch: 39, Batch: 66,Loss: -1.808,Avg.Loss: -1.181,LR: 3.38E-04]Training epoch 39:  59%|█████▉    | 66/112 [00:01<00:00, 53.19it/s, Epoch: 39, Batch: 67,Loss: -1.233,Avg.Loss: -1.182,LR: 3.38E-04]Training epoch 39:  60%|█████▉    | 67/112 [00:01<00:00, 53.19it/s, Epoch: 39, Batch: 68,Loss: -2.125,Avg.Loss: -1.196,LR: 3.38E-04]Training epoch 39:  61%|██████    | 68/112 [00:01<00:00, 53.19it/s, Epoch: 39, Batch: 69,Loss: -1.878,Avg.Loss: -1.206,LR: 3.38E-04]Training epoch 39:  62%|██████▏   | 69/112 [00:01<00:00, 53.19it/s, Epoch: 39, Batch: 70,Loss: -2.188,Avg.Loss: -1.220,LR: 3.37E-04]Training epoch 39:  62%|██████▎   | 70/112 [00:01<00:00, 53.19it/s, Epoch: 39, Batch: 71,Loss: -2.224,Avg.Loss: -1.234,LR: 3.37E-04]Training epoch 39:  63%|██████▎   | 71/112 [00:01<00:00, 53.19it/s, Epoch: 39, Batch: 72,Loss: -2.055,Avg.Loss: -1.245,LR: 3.37E-04]Training epoch 39:  64%|██████▍   | 72/112 [00:01<00:00, 53.18it/s, Epoch: 39, Batch: 72,Loss: -2.055,Avg.Loss: -1.245,LR: 3.37E-04]Training epoch 39:  64%|██████▍   | 72/112 [00:01<00:00, 53.18it/s, Epoch: 39, Batch: 73,Loss: -1.934,Avg.Loss: -1.255,LR: 3.37E-04]Training epoch 39:  65%|██████▌   | 73/112 [00:01<00:00, 53.18it/s, Epoch: 39, Batch: 74,Loss: -2.298,Avg.Loss: -1.269,LR: 3.37E-04]Training epoch 39:  66%|██████▌   | 74/112 [00:01<00:00, 53.18it/s, Epoch: 39, Batch: 75,Loss: -2.563,Avg.Loss: -1.286,LR: 3.37E-04]Training epoch 39:  67%|██████▋   | 75/112 [00:01<00:00, 53.18it/s, Epoch: 39, Batch: 76,Loss: -2.575,Avg.Loss: -1.303,LR: 3.37E-04]Training epoch 39:  68%|██████▊   | 76/112 [00:01<00:00, 53.18it/s, Epoch: 39, Batch: 77,Loss: -1.711,Avg.Loss: -1.308,LR: 3.37E-04]Training epoch 39:  69%|██████▉   | 77/112 [00:01<00:00, 53.18it/s, Epoch: 39, Batch: 78,Loss: -1.249,Avg.Loss: -1.308,LR: 3.37E-04]Training epoch 39:  70%|██████▉   | 78/112 [00:01<00:00, 53.39it/s, Epoch: 39, Batch: 78,Loss: -1.249,Avg.Loss: -1.308,LR: 3.37E-04]Training epoch 39:  70%|██████▉   | 78/112 [00:01<00:00, 53.39it/s, Epoch: 39, Batch: 79,Loss: -2.146,Avg.Loss: -1.318,LR: 3.37E-04]Training epoch 39:  71%|███████   | 79/112 [00:01<00:00, 53.39it/s, Epoch: 39, Batch: 80,Loss: -0.591,Avg.Loss: -1.309,LR: 3.37E-04]Training epoch 39:  71%|███████▏  | 80/112 [00:01<00:00, 53.39it/s, Epoch: 39, Batch: 81,Loss: 0.565,Avg.Loss: -1.286,LR: 3.37E-04] Training epoch 39:  72%|███████▏  | 81/112 [00:01<00:00, 53.39it/s, Epoch: 39, Batch: 82,Loss: -0.593,Avg.Loss: -1.277,LR: 3.37E-04]Training epoch 39:  73%|███████▎  | 82/112 [00:01<00:00, 53.39it/s, Epoch: 39, Batch: 83,Loss: -2.122,Avg.Loss: -1.288,LR: 3.37E-04]Training epoch 39:  74%|███████▍  | 83/112 [00:01<00:00, 53.39it/s, Epoch: 39, Batch: 84,Loss: 0.077,Avg.Loss: -1.271,LR: 3.37E-04] Training epoch 39:  75%|███████▌  | 84/112 [00:01<00:00, 53.41it/s, Epoch: 39, Batch: 84,Loss: 0.077,Avg.Loss: -1.271,LR: 3.37E-04]Training epoch 39:  75%|███████▌  | 84/112 [00:01<00:00, 53.41it/s, Epoch: 39, Batch: 85,Loss: 3.480,Avg.Loss: -1.216,LR: 3.36E-04]Training epoch 39:  76%|███████▌  | 85/112 [00:01<00:00, 53.41it/s, Epoch: 39, Batch: 86,Loss: 2.070,Avg.Loss: -1.177,LR: 3.36E-04]Training epoch 39:  77%|███████▋  | 86/112 [00:01<00:00, 53.41it/s, Epoch: 39, Batch: 87,Loss: 0.006,Avg.Loss: -1.164,LR: 3.36E-04]Training epoch 39:  78%|███████▊  | 87/112 [00:01<00:00, 53.41it/s, Epoch: 39, Batch: 88,Loss: -2.076,Avg.Loss: -1.174,LR: 3.36E-04]Training epoch 39:  79%|███████▊  | 88/112 [00:01<00:00, 53.41it/s, Epoch: 39, Batch: 89,Loss: -1.756,Avg.Loss: -1.181,LR: 3.36E-04]Training epoch 39:  79%|███████▉  | 89/112 [00:01<00:00, 53.41it/s, Epoch: 39, Batch: 90,Loss: -2.339,Avg.Loss: -1.193,LR: 3.36E-04]Training epoch 39:  80%|████████  | 90/112 [00:01<00:00, 53.70it/s, Epoch: 39, Batch: 90,Loss: -2.339,Avg.Loss: -1.193,LR: 3.36E-04]Training epoch 39:  80%|████████  | 90/112 [00:01<00:00, 53.70it/s, Epoch: 39, Batch: 91,Loss: -1.889,Avg.Loss: -1.201,LR: 3.36E-04]Training epoch 39:  81%|████████▏ | 91/112 [00:01<00:00, 53.70it/s, Epoch: 39, Batch: 92,Loss: -1.919,Avg.Loss: -1.209,LR: 3.36E-04]Training epoch 39:  82%|████████▏ | 92/112 [00:01<00:00, 53.70it/s, Epoch: 39, Batch: 93,Loss: -2.267,Avg.Loss: -1.220,LR: 3.36E-04]Training epoch 39:  83%|████████▎ | 93/112 [00:01<00:00, 53.70it/s, Epoch: 39, Batch: 94,Loss: -1.276,Avg.Loss: -1.221,LR: 3.36E-04]Training epoch 39:  84%|████████▍ | 94/112 [00:01<00:00, 53.70it/s, Epoch: 39, Batch: 95,Loss: -0.134,Avg.Loss: -1.209,LR: 3.36E-04]Training epoch 39:  85%|████████▍ | 95/112 [00:01<00:00, 53.70it/s, Epoch: 39, Batch: 96,Loss: -1.447,Avg.Loss: -1.212,LR: 3.36E-04]Training epoch 39:  86%|████████▌ | 96/112 [00:01<00:00, 53.64it/s, Epoch: 39, Batch: 96,Loss: -1.447,Avg.Loss: -1.212,LR: 3.36E-04]Training epoch 39:  86%|████████▌ | 96/112 [00:01<00:00, 53.64it/s, Epoch: 39, Batch: 97,Loss: -2.401,Avg.Loss: -1.224,LR: 3.36E-04]Training epoch 39:  87%|████████▋ | 97/112 [00:01<00:00, 53.64it/s, Epoch: 39, Batch: 98,Loss: -2.176,Avg.Loss: -1.234,LR: 3.36E-04]Training epoch 39:  88%|████████▊ | 98/112 [00:01<00:00, 53.64it/s, Epoch: 39, Batch: 99,Loss: -2.302,Avg.Loss: -1.245,LR: 3.36E-04]Training epoch 39:  88%|████████▊ | 99/112 [00:01<00:00, 53.64it/s, Epoch: 39, Batch: 100,Loss: -2.494,Avg.Loss: -1.257,LR: 3.35E-04]Training epoch 39:  89%|████████▉ | 100/112 [00:01<00:00, 53.64it/s, Epoch: 39, Batch: 101,Loss: -1.761,Avg.Loss: -1.262,LR: 3.35E-04]Training epoch 39:  90%|█████████ | 101/112 [00:01<00:00, 53.64it/s, Epoch: 39, Batch: 102,Loss: -1.888,Avg.Loss: -1.268,LR: 3.35E-04]Training epoch 39:  91%|█████████ | 102/112 [00:01<00:00, 53.81it/s, Epoch: 39, Batch: 102,Loss: -1.888,Avg.Loss: -1.268,LR: 3.35E-04]Training epoch 39:  91%|█████████ | 102/112 [00:01<00:00, 53.81it/s, Epoch: 39, Batch: 103,Loss: -2.295,Avg.Loss: -1.278,LR: 3.35E-04]Training epoch 39:  92%|█████████▏| 103/112 [00:01<00:00, 53.81it/s, Epoch: 39, Batch: 104,Loss: -2.263,Avg.Loss: -1.288,LR: 3.35E-04]Training epoch 39:  93%|█████████▎| 104/112 [00:01<00:00, 53.81it/s, Epoch: 39, Batch: 105,Loss: -1.489,Avg.Loss: -1.290,LR: 3.35E-04]Training epoch 39:  94%|█████████▍| 105/112 [00:01<00:00, 53.81it/s, Epoch: 39, Batch: 106,Loss: -1.360,Avg.Loss: -1.290,LR: 3.35E-04]Training epoch 39:  95%|█████████▍| 106/112 [00:02<00:00, 53.81it/s, Epoch: 39, Batch: 107,Loss: -1.708,Avg.Loss: -1.294,LR: 3.35E-04]Training epoch 39:  96%|█████████▌| 107/112 [00:02<00:00, 53.81it/s, Epoch: 39, Batch: 108,Loss: -2.206,Avg.Loss: -1.303,LR: 3.35E-04]Training epoch 39:  96%|█████████▋| 108/112 [00:02<00:00, 53.94it/s, Epoch: 39, Batch: 108,Loss: -2.206,Avg.Loss: -1.303,LR: 3.35E-04]Training epoch 39:  96%|█████████▋| 108/112 [00:02<00:00, 53.94it/s, Epoch: 39, Batch: 109,Loss: -1.926,Avg.Loss: -1.308,LR: 3.35E-04]Training epoch 39:  97%|█████████▋| 109/112 [00:02<00:00, 53.94it/s, Epoch: 39, Batch: 110,Loss: -2.507,Avg.Loss: -1.319,LR: 3.35E-04]Training epoch 39:  98%|█████████▊| 110/112 [00:02<00:00, 53.94it/s, Epoch: 39, Batch: 111,Loss: -2.313,Avg.Loss: -1.328,LR: 3.35E-04]Training epoch 39:  99%|█████████▉| 111/112 [00:02<00:00, 53.94it/s, Epoch: 39, Batch: 112,Loss: -2.268,Avg.Loss: -1.337,LR: 3.35E-04]Training epoch 39: 100%|██████████| 112/112 [00:02<00:00, 53.19it/s, Epoch: 39, Batch: 112,Loss: -2.268,Avg.Loss: -1.337,LR: 3.35E-04]
Training epoch 40:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 40:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 40, Batch: 1,Loss: -2.561,Avg.Loss: -2.561,LR: 3.35E-04]Training epoch 40:   1%|          | 1/112 [00:00<00:04, 25.57it/s, Epoch: 40, Batch: 2,Loss: -2.622,Avg.Loss: -2.591,LR: 3.35E-04]Training epoch 40:   2%|▏         | 2/112 [00:00<00:03, 35.77it/s, Epoch: 40, Batch: 3,Loss: -1.761,Avg.Loss: -2.315,LR: 3.34E-04]Training epoch 40:   3%|▎         | 3/112 [00:00<00:02, 41.26it/s, Epoch: 40, Batch: 4,Loss: -1.603,Avg.Loss: -2.137,LR: 3.34E-04]Training epoch 40:   4%|▎         | 4/112 [00:00<00:02, 45.96it/s, Epoch: 40, Batch: 5,Loss: -2.018,Avg.Loss: -2.113,LR: 3.34E-04]Training epoch 40:   4%|▍         | 5/112 [00:00<00:02, 47.51it/s, Epoch: 40, Batch: 6,Loss: -1.161,Avg.Loss: -1.954,LR: 3.34E-04]Training epoch 40:   5%|▌         | 6/112 [00:00<00:01, 56.92it/s, Epoch: 40, Batch: 6,Loss: -1.161,Avg.Loss: -1.954,LR: 3.34E-04]Training epoch 40:   5%|▌         | 6/112 [00:00<00:01, 56.92it/s, Epoch: 40, Batch: 7,Loss: -1.274,Avg.Loss: -1.857,LR: 3.34E-04]Training epoch 40:   6%|▋         | 7/112 [00:00<00:01, 56.92it/s, Epoch: 40, Batch: 8,Loss: -1.976,Avg.Loss: -1.872,LR: 3.34E-04]Training epoch 40:   7%|▋         | 8/112 [00:00<00:01, 56.92it/s, Epoch: 40, Batch: 9,Loss: -1.604,Avg.Loss: -1.842,LR: 3.34E-04]Training epoch 40:   8%|▊         | 9/112 [00:00<00:01, 56.92it/s, Epoch: 40, Batch: 10,Loss: -0.295,Avg.Loss: -1.687,LR: 3.34E-04]Training epoch 40:   9%|▉         | 10/112 [00:00<00:01, 56.92it/s, Epoch: 40, Batch: 11,Loss: -0.943,Avg.Loss: -1.620,LR: 3.34E-04]Training epoch 40:  10%|▉         | 11/112 [00:00<00:01, 56.92it/s, Epoch: 40, Batch: 12,Loss: -1.943,Avg.Loss: -1.647,LR: 3.34E-04]Training epoch 40:  11%|█         | 12/112 [00:00<00:01, 54.70it/s, Epoch: 40, Batch: 12,Loss: -1.943,Avg.Loss: -1.647,LR: 3.34E-04]Training epoch 40:  11%|█         | 12/112 [00:00<00:01, 54.70it/s, Epoch: 40, Batch: 13,Loss: -0.191,Avg.Loss: -1.535,LR: 3.34E-04]Training epoch 40:  12%|█▏        | 13/112 [00:00<00:01, 54.70it/s, Epoch: 40, Batch: 14,Loss: 1.387,Avg.Loss: -1.326,LR: 3.34E-04] Training epoch 40:  12%|█▎        | 14/112 [00:00<00:01, 54.70it/s, Epoch: 40, Batch: 15,Loss: -0.250,Avg.Loss: -1.254,LR: 3.34E-04]Training epoch 40:  13%|█▎        | 15/112 [00:00<00:01, 54.70it/s, Epoch: 40, Batch: 16,Loss: -2.071,Avg.Loss: -1.305,LR: 3.34E-04]Training epoch 40:  14%|█▍        | 16/112 [00:00<00:01, 54.70it/s, Epoch: 40, Batch: 17,Loss: -0.263,Avg.Loss: -1.244,LR: 3.34E-04]Training epoch 40:  15%|█▌        | 17/112 [00:00<00:01, 54.70it/s, Epoch: 40, Batch: 18,Loss: 3.160,Avg.Loss: -0.999,LR: 3.33E-04] Training epoch 40:  16%|█▌        | 18/112 [00:00<00:01, 53.37it/s, Epoch: 40, Batch: 18,Loss: 3.160,Avg.Loss: -0.999,LR: 3.33E-04]Training epoch 40:  16%|█▌        | 18/112 [00:00<00:01, 53.37it/s, Epoch: 40, Batch: 19,Loss: 3.692,Avg.Loss: -0.752,LR: 3.33E-04]Training epoch 40:  17%|█▋        | 19/112 [00:00<00:01, 53.37it/s, Epoch: 40, Batch: 20,Loss: 0.205,Avg.Loss: -0.705,LR: 3.33E-04]Training epoch 40:  18%|█▊        | 20/112 [00:00<00:01, 53.37it/s, Epoch: 40, Batch: 21,Loss: -1.674,Avg.Loss: -0.751,LR: 3.33E-04]Training epoch 40:  19%|█▉        | 21/112 [00:00<00:01, 53.37it/s, Epoch: 40, Batch: 22,Loss: 0.038,Avg.Loss: -0.715,LR: 3.33E-04] Training epoch 40:  20%|█▉        | 22/112 [00:00<00:01, 53.37it/s, Epoch: 40, Batch: 23,Loss: 1.463,Avg.Loss: -0.620,LR: 3.33E-04]Training epoch 40:  21%|██        | 23/112 [00:00<00:01, 53.37it/s, Epoch: 40, Batch: 24,Loss: 1.514,Avg.Loss: -0.531,LR: 3.33E-04]Training epoch 40:  21%|██▏       | 24/112 [00:00<00:01, 53.02it/s, Epoch: 40, Batch: 24,Loss: 1.514,Avg.Loss: -0.531,LR: 3.33E-04]Training epoch 40:  21%|██▏       | 24/112 [00:00<00:01, 53.02it/s, Epoch: 40, Batch: 25,Loss: -0.484,Avg.Loss: -0.529,LR: 3.33E-04]Training epoch 40:  22%|██▏       | 25/112 [00:00<00:01, 53.02it/s, Epoch: 40, Batch: 26,Loss: -0.726,Avg.Loss: -0.537,LR: 3.33E-04]Training epoch 40:  23%|██▎       | 26/112 [00:00<00:01, 53.02it/s, Epoch: 40, Batch: 27,Loss: 0.507,Avg.Loss: -0.498,LR: 3.33E-04] Training epoch 40:  24%|██▍       | 27/112 [00:00<00:01, 53.02it/s, Epoch: 40, Batch: 28,Loss: 0.508,Avg.Loss: -0.462,LR: 3.33E-04]Training epoch 40:  25%|██▌       | 28/112 [00:00<00:01, 53.02it/s, Epoch: 40, Batch: 29,Loss: -1.256,Avg.Loss: -0.490,LR: 3.33E-04]Training epoch 40:  26%|██▌       | 29/112 [00:00<00:01, 53.02it/s, Epoch: 40, Batch: 30,Loss: -0.705,Avg.Loss: -0.497,LR: 3.33E-04]Training epoch 40:  27%|██▋       | 30/112 [00:00<00:01, 52.45it/s, Epoch: 40, Batch: 30,Loss: -0.705,Avg.Loss: -0.497,LR: 3.33E-04]Training epoch 40:  27%|██▋       | 30/112 [00:00<00:01, 52.45it/s, Epoch: 40, Batch: 31,Loss: -0.567,Avg.Loss: -0.499,LR: 3.33E-04]Training epoch 40:  28%|██▊       | 31/112 [00:00<00:01, 52.45it/s, Epoch: 40, Batch: 32,Loss: -1.087,Avg.Loss: -0.517,LR: 3.33E-04]Training epoch 40:  29%|██▊       | 32/112 [00:00<00:01, 52.45it/s, Epoch: 40, Batch: 33,Loss: -2.238,Avg.Loss: -0.570,LR: 3.33E-04]Training epoch 40:  29%|██▉       | 33/112 [00:00<00:01, 52.45it/s, Epoch: 40, Batch: 34,Loss: -0.724,Avg.Loss: -0.574,LR: 3.32E-04]Training epoch 40:  30%|███       | 34/112 [00:00<00:01, 52.45it/s, Epoch: 40, Batch: 35,Loss: 1.224,Avg.Loss: -0.523,LR: 3.32E-04] Training epoch 40:  31%|███▏      | 35/112 [00:00<00:01, 52.45it/s, Epoch: 40, Batch: 36,Loss: 1.314,Avg.Loss: -0.472,LR: 3.32E-04]Training epoch 40:  32%|███▏      | 36/112 [00:00<00:01, 52.65it/s, Epoch: 40, Batch: 36,Loss: 1.314,Avg.Loss: -0.472,LR: 3.32E-04]Training epoch 40:  32%|███▏      | 36/112 [00:00<00:01, 52.65it/s, Epoch: 40, Batch: 37,Loss: -0.573,Avg.Loss: -0.474,LR: 3.32E-04]Training epoch 40:  33%|███▎      | 37/112 [00:00<00:01, 52.65it/s, Epoch: 40, Batch: 38,Loss: -1.288,Avg.Loss: -0.496,LR: 3.32E-04]Training epoch 40:  34%|███▍      | 38/112 [00:00<00:01, 52.65it/s, Epoch: 40, Batch: 39,Loss: -0.650,Avg.Loss: -0.500,LR: 3.32E-04]Training epoch 40:  35%|███▍      | 39/112 [00:00<00:01, 52.65it/s, Epoch: 40, Batch: 40,Loss: -1.341,Avg.Loss: -0.521,LR: 3.32E-04]Training epoch 40:  36%|███▌      | 40/112 [00:00<00:01, 52.65it/s, Epoch: 40, Batch: 41,Loss: -2.069,Avg.Loss: -0.559,LR: 3.32E-04]Training epoch 40:  37%|███▋      | 41/112 [00:00<00:01, 52.65it/s, Epoch: 40, Batch: 42,Loss: -0.568,Avg.Loss: -0.559,LR: 3.32E-04]Training epoch 40:  38%|███▊      | 42/112 [00:00<00:01, 52.85it/s, Epoch: 40, Batch: 42,Loss: -0.568,Avg.Loss: -0.559,LR: 3.32E-04]Training epoch 40:  38%|███▊      | 42/112 [00:00<00:01, 52.85it/s, Epoch: 40, Batch: 43,Loss: 0.520,Avg.Loss: -0.534,LR: 3.32E-04] Training epoch 40:  38%|███▊      | 43/112 [00:00<00:01, 52.85it/s, Epoch: 40, Batch: 44,Loss: 0.173,Avg.Loss: -0.518,LR: 3.32E-04]Training epoch 40:  39%|███▉      | 44/112 [00:00<00:01, 52.85it/s, Epoch: 40, Batch: 45,Loss: -1.586,Avg.Loss: -0.541,LR: 3.32E-04]Training epoch 40:  40%|████      | 45/112 [00:00<00:01, 52.85it/s, Epoch: 40, Batch: 46,Loss: -1.298,Avg.Loss: -0.558,LR: 3.32E-04]Training epoch 40:  41%|████      | 46/112 [00:00<00:01, 52.85it/s, Epoch: 40, Batch: 47,Loss: 0.293,Avg.Loss: -0.540,LR: 3.32E-04] Training epoch 40:  42%|████▏     | 47/112 [00:00<00:01, 52.85it/s, Epoch: 40, Batch: 48,Loss: -0.468,Avg.Loss: -0.538,LR: 3.32E-04]Training epoch 40:  43%|████▎     | 48/112 [00:00<00:01, 52.61it/s, Epoch: 40, Batch: 48,Loss: -0.468,Avg.Loss: -0.538,LR: 3.32E-04]Training epoch 40:  43%|████▎     | 48/112 [00:00<00:01, 52.61it/s, Epoch: 40, Batch: 49,Loss: -1.612,Avg.Loss: -0.560,LR: 3.31E-04]Training epoch 40:  44%|████▍     | 49/112 [00:00<00:01, 52.61it/s, Epoch: 40, Batch: 50,Loss: -1.470,Avg.Loss: -0.578,LR: 3.31E-04]Training epoch 40:  45%|████▍     | 50/112 [00:00<00:01, 52.61it/s, Epoch: 40, Batch: 51,Loss: 0.264,Avg.Loss: -0.562,LR: 3.31E-04] Training epoch 40:  46%|████▌     | 51/112 [00:00<00:01, 52.61it/s, Epoch: 40, Batch: 52,Loss: -0.729,Avg.Loss: -0.565,LR: 3.31E-04]Training epoch 40:  46%|████▋     | 52/112 [00:00<00:01, 52.61it/s, Epoch: 40, Batch: 53,Loss: -2.001,Avg.Loss: -0.592,LR: 3.31E-04]Training epoch 40:  47%|████▋     | 53/112 [00:01<00:01, 52.61it/s, Epoch: 40, Batch: 54,Loss: -1.196,Avg.Loss: -0.603,LR: 3.31E-04]Training epoch 40:  48%|████▊     | 54/112 [00:01<00:01, 52.78it/s, Epoch: 40, Batch: 54,Loss: -1.196,Avg.Loss: -0.603,LR: 3.31E-04]Training epoch 40:  48%|████▊     | 54/112 [00:01<00:01, 52.78it/s, Epoch: 40, Batch: 55,Loss: -0.357,Avg.Loss: -0.599,LR: 3.31E-04]Training epoch 40:  49%|████▉     | 55/112 [00:01<00:01, 52.78it/s, Epoch: 40, Batch: 56,Loss: -0.618,Avg.Loss: -0.599,LR: 3.31E-04]Training epoch 40:  50%|█████     | 56/112 [00:01<00:01, 52.78it/s, Epoch: 40, Batch: 57,Loss: -2.148,Avg.Loss: -0.626,LR: 3.31E-04]Training epoch 40:  51%|█████     | 57/112 [00:01<00:01, 52.78it/s, Epoch: 40, Batch: 58,Loss: -1.723,Avg.Loss: -0.645,LR: 3.31E-04]Training epoch 40:  52%|█████▏    | 58/112 [00:01<00:01, 52.78it/s, Epoch: 40, Batch: 59,Loss: -0.858,Avg.Loss: -0.649,LR: 3.31E-04]Training epoch 40:  53%|█████▎    | 59/112 [00:01<00:01, 52.78it/s, Epoch: 40, Batch: 60,Loss: -0.944,Avg.Loss: -0.654,LR: 3.31E-04]Training epoch 40:  54%|█████▎    | 60/112 [00:01<00:00, 52.86it/s, Epoch: 40, Batch: 60,Loss: -0.944,Avg.Loss: -0.654,LR: 3.31E-04]Training epoch 40:  54%|█████▎    | 60/112 [00:01<00:00, 52.86it/s, Epoch: 40, Batch: 61,Loss: -2.252,Avg.Loss: -0.680,LR: 3.31E-04]Training epoch 40:  54%|█████▍    | 61/112 [00:01<00:00, 52.86it/s, Epoch: 40, Batch: 62,Loss: -1.387,Avg.Loss: -0.691,LR: 3.31E-04]Training epoch 40:  55%|█████▌    | 62/112 [00:01<00:00, 52.86it/s, Epoch: 40, Batch: 63,Loss: 0.152,Avg.Loss: -0.678,LR: 3.31E-04] Training epoch 40:  56%|█████▋    | 63/112 [00:01<00:00, 52.86it/s, Epoch: 40, Batch: 64,Loss: -0.805,Avg.Loss: -0.680,LR: 3.30E-04]Training epoch 40:  57%|█████▋    | 64/112 [00:01<00:00, 52.86it/s, Epoch: 40, Batch: 65,Loss: -1.875,Avg.Loss: -0.698,LR: 3.30E-04]Training epoch 40:  58%|█████▊    | 65/112 [00:01<00:00, 52.86it/s, Epoch: 40, Batch: 66,Loss: -1.976,Avg.Loss: -0.718,LR: 3.30E-04]Training epoch 40:  59%|█████▉    | 66/112 [00:01<00:00, 52.95it/s, Epoch: 40, Batch: 66,Loss: -1.976,Avg.Loss: -0.718,LR: 3.30E-04]Training epoch 40:  59%|█████▉    | 66/112 [00:01<00:00, 52.95it/s, Epoch: 40, Batch: 67,Loss: -0.963,Avg.Loss: -0.721,LR: 3.30E-04]Training epoch 40:  60%|█████▉    | 67/112 [00:01<00:00, 52.95it/s, Epoch: 40, Batch: 68,Loss: -0.936,Avg.Loss: -0.725,LR: 3.30E-04]Training epoch 40:  61%|██████    | 68/112 [00:01<00:00, 52.95it/s, Epoch: 40, Batch: 69,Loss: -1.919,Avg.Loss: -0.742,LR: 3.30E-04]Training epoch 40:  62%|██████▏   | 69/112 [00:01<00:00, 52.95it/s, Epoch: 40, Batch: 70,Loss: -1.463,Avg.Loss: -0.752,LR: 3.30E-04]Training epoch 40:  62%|██████▎   | 70/112 [00:01<00:00, 52.95it/s, Epoch: 40, Batch: 71,Loss: -0.746,Avg.Loss: -0.752,LR: 3.30E-04]Training epoch 40:  63%|██████▎   | 71/112 [00:01<00:00, 52.95it/s, Epoch: 40, Batch: 72,Loss: -0.723,Avg.Loss: -0.752,LR: 3.30E-04]Training epoch 40:  64%|██████▍   | 72/112 [00:01<00:00, 53.13it/s, Epoch: 40, Batch: 72,Loss: -0.723,Avg.Loss: -0.752,LR: 3.30E-04]Training epoch 40:  64%|██████▍   | 72/112 [00:01<00:00, 53.13it/s, Epoch: 40, Batch: 73,Loss: -1.930,Avg.Loss: -0.768,LR: 3.30E-04]Training epoch 40:  65%|██████▌   | 73/112 [00:01<00:00, 53.13it/s, Epoch: 40, Batch: 74,Loss: -1.985,Avg.Loss: -0.784,LR: 3.30E-04]Training epoch 40:  66%|██████▌   | 74/112 [00:01<00:00, 53.13it/s, Epoch: 40, Batch: 75,Loss: -0.603,Avg.Loss: -0.782,LR: 3.30E-04]Training epoch 40:  67%|██████▋   | 75/112 [00:01<00:00, 53.13it/s, Epoch: 40, Batch: 76,Loss: -0.774,Avg.Loss: -0.782,LR: 3.30E-04]Training epoch 40:  68%|██████▊   | 76/112 [00:01<00:00, 53.13it/s, Epoch: 40, Batch: 77,Loss: -1.910,Avg.Loss: -0.796,LR: 3.30E-04]Training epoch 40:  69%|██████▉   | 77/112 [00:01<00:00, 53.13it/s, Epoch: 40, Batch: 78,Loss: -1.917,Avg.Loss: -0.811,LR: 3.30E-04]Training epoch 40:  70%|██████▉   | 78/112 [00:01<00:00, 53.41it/s, Epoch: 40, Batch: 78,Loss: -1.917,Avg.Loss: -0.811,LR: 3.30E-04]Training epoch 40:  70%|██████▉   | 78/112 [00:01<00:00, 53.41it/s, Epoch: 40, Batch: 79,Loss: -1.313,Avg.Loss: -0.817,LR: 3.29E-04]Training epoch 40:  71%|███████   | 79/112 [00:01<00:00, 53.41it/s, Epoch: 40, Batch: 80,Loss: -1.145,Avg.Loss: -0.821,LR: 3.29E-04]Training epoch 40:  71%|███████▏  | 80/112 [00:01<00:00, 53.41it/s, Epoch: 40, Batch: 81,Loss: -2.492,Avg.Loss: -0.842,LR: 3.29E-04]Training epoch 40:  72%|███████▏  | 81/112 [00:01<00:00, 53.41it/s, Epoch: 40, Batch: 82,Loss: -1.277,Avg.Loss: -0.847,LR: 3.29E-04]Training epoch 40:  73%|███████▎  | 82/112 [00:01<00:00, 53.41it/s, Epoch: 40, Batch: 83,Loss: -0.287,Avg.Loss: -0.840,LR: 3.29E-04]Training epoch 40:  74%|███████▍  | 83/112 [00:01<00:00, 53.41it/s, Epoch: 40, Batch: 84,Loss: -0.538,Avg.Loss: -0.837,LR: 3.29E-04]Training epoch 40:  75%|███████▌  | 84/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 84,Loss: -0.538,Avg.Loss: -0.837,LR: 3.29E-04]Training epoch 40:  75%|███████▌  | 84/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 85,Loss: -1.663,Avg.Loss: -0.847,LR: 3.29E-04]Training epoch 40:  76%|███████▌  | 85/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 86,Loss: -2.007,Avg.Loss: -0.860,LR: 3.29E-04]Training epoch 40:  77%|███████▋  | 86/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 87,Loss: -1.647,Avg.Loss: -0.869,LR: 3.29E-04]Training epoch 40:  78%|███████▊  | 87/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 88,Loss: -1.456,Avg.Loss: -0.876,LR: 3.29E-04]Training epoch 40:  79%|███████▊  | 88/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 89,Loss: -2.514,Avg.Loss: -0.894,LR: 3.29E-04]Training epoch 40:  79%|███████▉  | 89/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 90,Loss: -1.674,Avg.Loss: -0.903,LR: 3.29E-04]Training epoch 40:  80%|████████  | 90/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 90,Loss: -1.674,Avg.Loss: -0.903,LR: 3.29E-04]Training epoch 40:  80%|████████  | 90/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 91,Loss: -0.398,Avg.Loss: -0.897,LR: 3.29E-04]Training epoch 40:  81%|████████▏ | 91/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 92,Loss: -0.396,Avg.Loss: -0.892,LR: 3.29E-04]Training epoch 40:  82%|████████▏ | 92/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 93,Loss: -1.804,Avg.Loss: -0.902,LR: 3.29E-04]Training epoch 40:  83%|████████▎ | 93/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 94,Loss: -1.678,Avg.Loss: -0.910,LR: 3.28E-04]Training epoch 40:  84%|████████▍ | 94/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 95,Loss: -1.539,Avg.Loss: -0.917,LR: 3.28E-04]Training epoch 40:  85%|████████▍ | 95/112 [00:01<00:00, 53.54it/s, Epoch: 40, Batch: 96,Loss: -1.818,Avg.Loss: -0.926,LR: 3.28E-04]Training epoch 40:  86%|████████▌ | 96/112 [00:01<00:00, 53.43it/s, Epoch: 40, Batch: 96,Loss: -1.818,Avg.Loss: -0.926,LR: 3.28E-04]Training epoch 40:  86%|████████▌ | 96/112 [00:01<00:00, 53.43it/s, Epoch: 40, Batch: 97,Loss: -2.027,Avg.Loss: -0.937,LR: 3.28E-04]Training epoch 40:  87%|████████▋ | 97/112 [00:01<00:00, 53.43it/s, Epoch: 40, Batch: 98,Loss: -1.548,Avg.Loss: -0.943,LR: 3.28E-04]Training epoch 40:  88%|████████▊ | 98/112 [00:01<00:00, 53.43it/s, Epoch: 40, Batch: 99,Loss: -0.947,Avg.Loss: -0.944,LR: 3.28E-04]Training epoch 40:  88%|████████▊ | 99/112 [00:01<00:00, 53.43it/s, Epoch: 40, Batch: 100,Loss: -1.239,Avg.Loss: -0.946,LR: 3.28E-04]Training epoch 40:  89%|████████▉ | 100/112 [00:01<00:00, 53.43it/s, Epoch: 40, Batch: 101,Loss: -1.862,Avg.Loss: -0.956,LR: 3.28E-04]Training epoch 40:  90%|█████████ | 101/112 [00:01<00:00, 53.43it/s, Epoch: 40, Batch: 102,Loss: -1.997,Avg.Loss: -0.966,LR: 3.28E-04]Training epoch 40:  91%|█████████ | 102/112 [00:01<00:00, 53.47it/s, Epoch: 40, Batch: 102,Loss: -1.997,Avg.Loss: -0.966,LR: 3.28E-04]Training epoch 40:  91%|█████████ | 102/112 [00:01<00:00, 53.47it/s, Epoch: 40, Batch: 103,Loss: -1.040,Avg.Loss: -0.966,LR: 3.28E-04]Training epoch 40:  92%|█████████▏| 103/112 [00:01<00:00, 53.47it/s, Epoch: 40, Batch: 104,Loss: -1.257,Avg.Loss: -0.969,LR: 3.28E-04]Training epoch 40:  93%|█████████▎| 104/112 [00:01<00:00, 53.47it/s, Epoch: 40, Batch: 105,Loss: -1.860,Avg.Loss: -0.978,LR: 3.28E-04]Training epoch 40:  94%|█████████▍| 105/112 [00:01<00:00, 53.47it/s, Epoch: 40, Batch: 106,Loss: -1.412,Avg.Loss: -0.982,LR: 3.28E-04]Training epoch 40:  95%|█████████▍| 106/112 [00:02<00:00, 53.47it/s, Epoch: 40, Batch: 107,Loss: -0.972,Avg.Loss: -0.982,LR: 3.28E-04]Training epoch 40:  96%|█████████▌| 107/112 [00:02<00:00, 53.47it/s, Epoch: 40, Batch: 108,Loss: -0.579,Avg.Loss: -0.978,LR: 3.28E-04]Training epoch 40:  96%|█████████▋| 108/112 [00:02<00:00, 53.65it/s, Epoch: 40, Batch: 108,Loss: -0.579,Avg.Loss: -0.978,LR: 3.28E-04]Training epoch 40:  96%|█████████▋| 108/112 [00:02<00:00, 53.65it/s, Epoch: 40, Batch: 109,Loss: -2.173,Avg.Loss: -0.989,LR: 3.27E-04]Training epoch 40:  97%|█████████▋| 109/112 [00:02<00:00, 53.65it/s, Epoch: 40, Batch: 110,Loss: -1.534,Avg.Loss: -0.994,LR: 3.27E-04]Training epoch 40:  98%|█████████▊| 110/112 [00:02<00:00, 53.65it/s, Epoch: 40, Batch: 111,Loss: -1.044,Avg.Loss: -0.994,LR: 3.27E-04]Training epoch 40:  99%|█████████▉| 111/112 [00:02<00:00, 53.65it/s, Epoch: 40, Batch: 112,Loss: -0.986,Avg.Loss: -0.994,LR: 3.27E-04]Training epoch 40: 100%|██████████| 112/112 [00:02<00:00, 53.20it/s, Epoch: 40, Batch: 112,Loss: -0.986,Avg.Loss: -0.994,LR: 3.27E-04]
Training epoch 41:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 41:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 41, Batch: 1,Loss: -0.559,Avg.Loss: -0.559,LR: 3.27E-04]Training epoch 41:   1%|          | 1/112 [00:00<00:03, 27.76it/s, Epoch: 41, Batch: 2,Loss: -0.878,Avg.Loss: -0.719,LR: 3.27E-04]Training epoch 41:   2%|▏         | 2/112 [00:00<00:02, 37.83it/s, Epoch: 41, Batch: 3,Loss: -1.255,Avg.Loss: -0.897,LR: 3.27E-04]Training epoch 41:   3%|▎         | 3/112 [00:00<00:02, 45.06it/s, Epoch: 41, Batch: 4,Loss: -1.006,Avg.Loss: -0.925,LR: 3.27E-04]Training epoch 41:   4%|▎         | 4/112 [00:00<00:02, 47.74it/s, Epoch: 41, Batch: 5,Loss: 0.393,Avg.Loss: -0.661,LR: 3.27E-04] Training epoch 41:   4%|▍         | 5/112 [00:00<00:02, 49.65it/s, Epoch: 41, Batch: 6,Loss: -0.104,Avg.Loss: -0.568,LR: 3.27E-04]Training epoch 41:   5%|▌         | 6/112 [00:00<00:01, 59.50it/s, Epoch: 41, Batch: 6,Loss: -0.104,Avg.Loss: -0.568,LR: 3.27E-04]Training epoch 41:   5%|▌         | 6/112 [00:00<00:01, 59.50it/s, Epoch: 41, Batch: 7,Loss: -0.825,Avg.Loss: -0.605,LR: 3.27E-04]Training epoch 41:   6%|▋         | 7/112 [00:00<00:01, 59.50it/s, Epoch: 41, Batch: 8,Loss: -1.075,Avg.Loss: -0.664,LR: 3.27E-04]Training epoch 41:   7%|▋         | 8/112 [00:00<00:01, 59.50it/s, Epoch: 41, Batch: 9,Loss: -1.429,Avg.Loss: -0.749,LR: 3.27E-04]Training epoch 41:   8%|▊         | 9/112 [00:00<00:01, 59.50it/s, Epoch: 41, Batch: 10,Loss: -1.300,Avg.Loss: -0.804,LR: 3.27E-04]Training epoch 41:   9%|▉         | 10/112 [00:00<00:01, 59.50it/s, Epoch: 41, Batch: 11,Loss: -1.972,Avg.Loss: -0.910,LR: 3.27E-04]Training epoch 41:  10%|▉         | 11/112 [00:00<00:01, 59.50it/s, Epoch: 41, Batch: 12,Loss: -2.039,Avg.Loss: -1.004,LR: 3.26E-04]Training epoch 41:  11%|█         | 12/112 [00:00<00:01, 55.74it/s, Epoch: 41, Batch: 12,Loss: -2.039,Avg.Loss: -1.004,LR: 3.26E-04]Training epoch 41:  11%|█         | 12/112 [00:00<00:01, 55.74it/s, Epoch: 41, Batch: 13,Loss: -1.475,Avg.Loss: -1.040,LR: 3.26E-04]Training epoch 41:  12%|█▏        | 13/112 [00:00<00:01, 55.74it/s, Epoch: 41, Batch: 14,Loss: -2.222,Avg.Loss: -1.125,LR: 3.26E-04]Training epoch 41:  12%|█▎        | 14/112 [00:00<00:01, 55.74it/s, Epoch: 41, Batch: 15,Loss: -2.084,Avg.Loss: -1.189,LR: 3.26E-04]Training epoch 41:  13%|█▎        | 15/112 [00:00<00:01, 55.74it/s, Epoch: 41, Batch: 16,Loss: -1.612,Avg.Loss: -1.215,LR: 3.26E-04]Training epoch 41:  14%|█▍        | 16/112 [00:00<00:01, 55.74it/s, Epoch: 41, Batch: 17,Loss: -2.093,Avg.Loss: -1.267,LR: 3.26E-04]Training epoch 41:  15%|█▌        | 17/112 [00:00<00:01, 55.74it/s, Epoch: 41, Batch: 18,Loss: -2.006,Avg.Loss: -1.308,LR: 3.26E-04]Training epoch 41:  16%|█▌        | 18/112 [00:00<00:01, 54.26it/s, Epoch: 41, Batch: 18,Loss: -2.006,Avg.Loss: -1.308,LR: 3.26E-04]Training epoch 41:  16%|█▌        | 18/112 [00:00<00:01, 54.26it/s, Epoch: 41, Batch: 19,Loss: -2.108,Avg.Loss: -1.350,LR: 3.26E-04]Training epoch 41:  17%|█▋        | 19/112 [00:00<00:01, 54.26it/s, Epoch: 41, Batch: 20,Loss: -2.061,Avg.Loss: -1.386,LR: 3.26E-04]Training epoch 41:  18%|█▊        | 20/112 [00:00<00:01, 54.26it/s, Epoch: 41, Batch: 21,Loss: -2.306,Avg.Loss: -1.429,LR: 3.26E-04]Training epoch 41:  19%|█▉        | 21/112 [00:00<00:01, 54.26it/s, Epoch: 41, Batch: 22,Loss: -2.239,Avg.Loss: -1.466,LR: 3.26E-04]Training epoch 41:  20%|█▉        | 22/112 [00:00<00:01, 54.26it/s, Epoch: 41, Batch: 23,Loss: -2.014,Avg.Loss: -1.490,LR: 3.26E-04]Training epoch 41:  21%|██        | 23/112 [00:00<00:01, 54.26it/s, Epoch: 41, Batch: 24,Loss: -1.838,Avg.Loss: -1.505,LR: 3.26E-04]Training epoch 41:  21%|██▏       | 24/112 [00:00<00:01, 52.74it/s, Epoch: 41, Batch: 24,Loss: -1.838,Avg.Loss: -1.505,LR: 3.26E-04]Training epoch 41:  21%|██▏       | 24/112 [00:00<00:01, 52.74it/s, Epoch: 41, Batch: 25,Loss: -2.104,Avg.Loss: -1.528,LR: 3.26E-04]Training epoch 41:  22%|██▏       | 25/112 [00:00<00:01, 52.74it/s, Epoch: 41, Batch: 26,Loss: -1.937,Avg.Loss: -1.544,LR: 3.26E-04]Training epoch 41:  23%|██▎       | 26/112 [00:00<00:01, 52.74it/s, Epoch: 41, Batch: 27,Loss: -1.438,Avg.Loss: -1.540,LR: 3.25E-04]Training epoch 41:  24%|██▍       | 27/112 [00:00<00:01, 52.74it/s, Epoch: 41, Batch: 28,Loss: -1.792,Avg.Loss: -1.549,LR: 3.25E-04]Training epoch 41:  25%|██▌       | 28/112 [00:00<00:01, 52.74it/s, Epoch: 41, Batch: 29,Loss: -1.636,Avg.Loss: -1.552,LR: 3.25E-04]Training epoch 41:  26%|██▌       | 29/112 [00:00<00:01, 52.74it/s, Epoch: 41, Batch: 30,Loss: -1.776,Avg.Loss: -1.560,LR: 3.25E-04]Training epoch 41:  27%|██▋       | 30/112 [00:00<00:01, 53.00it/s, Epoch: 41, Batch: 30,Loss: -1.776,Avg.Loss: -1.560,LR: 3.25E-04]Training epoch 41:  27%|██▋       | 30/112 [00:00<00:01, 53.00it/s, Epoch: 41, Batch: 31,Loss: -2.214,Avg.Loss: -1.581,LR: 3.25E-04]Training epoch 41:  28%|██▊       | 31/112 [00:00<00:01, 53.00it/s, Epoch: 41, Batch: 32,Loss: -1.905,Avg.Loss: -1.591,LR: 3.25E-04]Training epoch 41:  29%|██▊       | 32/112 [00:00<00:01, 53.00it/s, Epoch: 41, Batch: 33,Loss: -0.852,Avg.Loss: -1.569,LR: 3.25E-04]Training epoch 41:  29%|██▉       | 33/112 [00:00<00:01, 53.00it/s, Epoch: 41, Batch: 34,Loss: -0.027,Avg.Loss: -1.523,LR: 3.25E-04]Training epoch 41:  30%|███       | 34/112 [00:00<00:01, 53.00it/s, Epoch: 41, Batch: 35,Loss: -0.628,Avg.Loss: -1.498,LR: 3.25E-04]Training epoch 41:  31%|███▏      | 35/112 [00:00<00:01, 53.00it/s, Epoch: 41, Batch: 36,Loss: -1.644,Avg.Loss: -1.502,LR: 3.25E-04]Training epoch 41:  32%|███▏      | 36/112 [00:00<00:01, 53.12it/s, Epoch: 41, Batch: 36,Loss: -1.644,Avg.Loss: -1.502,LR: 3.25E-04]Training epoch 41:  32%|███▏      | 36/112 [00:00<00:01, 53.12it/s, Epoch: 41, Batch: 37,Loss: -2.180,Avg.Loss: -1.520,LR: 3.25E-04]Training epoch 41:  33%|███▎      | 37/112 [00:00<00:01, 53.12it/s, Epoch: 41, Batch: 38,Loss: -1.641,Avg.Loss: -1.523,LR: 3.25E-04]Training epoch 41:  34%|███▍      | 38/112 [00:00<00:01, 53.12it/s, Epoch: 41, Batch: 39,Loss: -1.367,Avg.Loss: -1.519,LR: 3.25E-04]Training epoch 41:  35%|███▍      | 39/112 [00:00<00:01, 53.12it/s, Epoch: 41, Batch: 40,Loss: -1.224,Avg.Loss: -1.512,LR: 3.25E-04]Training epoch 41:  36%|███▌      | 40/112 [00:00<00:01, 53.12it/s, Epoch: 41, Batch: 41,Loss: -1.584,Avg.Loss: -1.514,LR: 3.25E-04]Training epoch 41:  37%|███▋      | 41/112 [00:00<00:01, 53.12it/s, Epoch: 41, Batch: 42,Loss: -2.062,Avg.Loss: -1.527,LR: 3.24E-04]Training epoch 41:  38%|███▊      | 42/112 [00:00<00:01, 53.23it/s, Epoch: 41, Batch: 42,Loss: -2.062,Avg.Loss: -1.527,LR: 3.24E-04]Training epoch 41:  38%|███▊      | 42/112 [00:00<00:01, 53.23it/s, Epoch: 41, Batch: 43,Loss: -2.013,Avg.Loss: -1.538,LR: 3.24E-04]Training epoch 41:  38%|███▊      | 43/112 [00:00<00:01, 53.23it/s, Epoch: 41, Batch: 44,Loss: -2.379,Avg.Loss: -1.557,LR: 3.24E-04]Training epoch 41:  39%|███▉      | 44/112 [00:00<00:01, 53.23it/s, Epoch: 41, Batch: 45,Loss: -2.040,Avg.Loss: -1.568,LR: 3.24E-04]Training epoch 41:  40%|████      | 45/112 [00:00<00:01, 53.23it/s, Epoch: 41, Batch: 46,Loss: -1.931,Avg.Loss: -1.576,LR: 3.24E-04]Training epoch 41:  41%|████      | 46/112 [00:00<00:01, 53.23it/s, Epoch: 41, Batch: 47,Loss: -2.053,Avg.Loss: -1.586,LR: 3.24E-04]Training epoch 41:  42%|████▏     | 47/112 [00:00<00:01, 53.23it/s, Epoch: 41, Batch: 48,Loss: -1.776,Avg.Loss: -1.590,LR: 3.24E-04]Training epoch 41:  43%|████▎     | 48/112 [00:00<00:01, 53.19it/s, Epoch: 41, Batch: 48,Loss: -1.776,Avg.Loss: -1.590,LR: 3.24E-04]Training epoch 41:  43%|████▎     | 48/112 [00:00<00:01, 53.19it/s, Epoch: 41, Batch: 49,Loss: -2.069,Avg.Loss: -1.600,LR: 3.24E-04]Training epoch 41:  44%|████▍     | 49/112 [00:00<00:01, 53.19it/s, Epoch: 41, Batch: 50,Loss: -2.314,Avg.Loss: -1.614,LR: 3.24E-04]Training epoch 41:  45%|████▍     | 50/112 [00:00<00:01, 53.19it/s, Epoch: 41, Batch: 51,Loss: -2.027,Avg.Loss: -1.622,LR: 3.24E-04]Training epoch 41:  46%|████▌     | 51/112 [00:00<00:01, 53.19it/s, Epoch: 41, Batch: 52,Loss: -2.064,Avg.Loss: -1.630,LR: 3.24E-04]Training epoch 41:  46%|████▋     | 52/112 [00:00<00:01, 53.19it/s, Epoch: 41, Batch: 53,Loss: -2.116,Avg.Loss: -1.640,LR: 3.24E-04]Training epoch 41:  47%|████▋     | 53/112 [00:01<00:01, 53.19it/s, Epoch: 41, Batch: 54,Loss: -2.080,Avg.Loss: -1.648,LR: 3.24E-04]Training epoch 41:  48%|████▊     | 54/112 [00:01<00:01, 53.24it/s, Epoch: 41, Batch: 54,Loss: -2.080,Avg.Loss: -1.648,LR: 3.24E-04]Training epoch 41:  48%|████▊     | 54/112 [00:01<00:01, 53.24it/s, Epoch: 41, Batch: 55,Loss: -2.274,Avg.Loss: -1.659,LR: 3.24E-04]Training epoch 41:  49%|████▉     | 55/112 [00:01<00:01, 53.24it/s, Epoch: 41, Batch: 56,Loss: -2.153,Avg.Loss: -1.668,LR: 3.24E-04]Training epoch 41:  50%|█████     | 56/112 [00:01<00:01, 53.24it/s, Epoch: 41, Batch: 57,Loss: -2.321,Avg.Loss: -1.679,LR: 3.23E-04]Training epoch 41:  51%|█████     | 57/112 [00:01<00:01, 53.24it/s, Epoch: 41, Batch: 58,Loss: -2.058,Avg.Loss: -1.686,LR: 3.23E-04]Training epoch 41:  52%|█████▏    | 58/112 [00:01<00:01, 53.24it/s, Epoch: 41, Batch: 59,Loss: -2.004,Avg.Loss: -1.691,LR: 3.23E-04]Training epoch 41:  53%|█████▎    | 59/112 [00:01<00:00, 53.24it/s, Epoch: 41, Batch: 60,Loss: -2.406,Avg.Loss: -1.703,LR: 3.23E-04]Training epoch 41:  54%|█████▎    | 60/112 [00:01<00:00, 53.43it/s, Epoch: 41, Batch: 60,Loss: -2.406,Avg.Loss: -1.703,LR: 3.23E-04]Training epoch 41:  54%|█████▎    | 60/112 [00:01<00:00, 53.43it/s, Epoch: 41, Batch: 61,Loss: -2.294,Avg.Loss: -1.713,LR: 3.23E-04]Training epoch 41:  54%|█████▍    | 61/112 [00:01<00:00, 53.43it/s, Epoch: 41, Batch: 62,Loss: -2.126,Avg.Loss: -1.720,LR: 3.23E-04]Training epoch 41:  55%|█████▌    | 62/112 [00:01<00:00, 53.43it/s, Epoch: 41, Batch: 63,Loss: -2.303,Avg.Loss: -1.729,LR: 3.23E-04]Training epoch 41:  56%|█████▋    | 63/112 [00:01<00:00, 53.43it/s, Epoch: 41, Batch: 64,Loss: -2.133,Avg.Loss: -1.735,LR: 3.23E-04]Training epoch 41:  57%|█████▋    | 64/112 [00:01<00:00, 53.43it/s, Epoch: 41, Batch: 65,Loss: -2.037,Avg.Loss: -1.740,LR: 3.23E-04]Training epoch 41:  58%|█████▊    | 65/112 [00:01<00:00, 53.43it/s, Epoch: 41, Batch: 66,Loss: -2.480,Avg.Loss: -1.751,LR: 3.23E-04]Training epoch 41:  59%|█████▉    | 66/112 [00:01<00:00, 53.37it/s, Epoch: 41, Batch: 66,Loss: -2.480,Avg.Loss: -1.751,LR: 3.23E-04]Training epoch 41:  59%|█████▉    | 66/112 [00:01<00:00, 53.37it/s, Epoch: 41, Batch: 67,Loss: -1.908,Avg.Loss: -1.753,LR: 3.23E-04]Training epoch 41:  60%|█████▉    | 67/112 [00:01<00:00, 53.37it/s, Epoch: 41, Batch: 68,Loss: -2.180,Avg.Loss: -1.760,LR: 3.23E-04]Training epoch 41:  61%|██████    | 68/112 [00:01<00:00, 53.37it/s, Epoch: 41, Batch: 69,Loss: -2.226,Avg.Loss: -1.766,LR: 3.23E-04]Training epoch 41:  62%|██████▏   | 69/112 [00:01<00:00, 53.37it/s, Epoch: 41, Batch: 70,Loss: -2.587,Avg.Loss: -1.778,LR: 3.23E-04]Training epoch 41:  62%|██████▎   | 70/112 [00:01<00:00, 53.37it/s, Epoch: 41, Batch: 71,Loss: -2.246,Avg.Loss: -1.785,LR: 3.23E-04]Training epoch 41:  63%|██████▎   | 71/112 [00:01<00:00, 53.37it/s, Epoch: 41, Batch: 72,Loss: -2.267,Avg.Loss: -1.791,LR: 3.22E-04]Training epoch 41:  64%|██████▍   | 72/112 [00:01<00:00, 53.42it/s, Epoch: 41, Batch: 72,Loss: -2.267,Avg.Loss: -1.791,LR: 3.22E-04]Training epoch 41:  64%|██████▍   | 72/112 [00:01<00:00, 53.42it/s, Epoch: 41, Batch: 73,Loss: -2.314,Avg.Loss: -1.799,LR: 3.22E-04]Training epoch 41:  65%|██████▌   | 73/112 [00:01<00:00, 53.42it/s, Epoch: 41, Batch: 74,Loss: -2.433,Avg.Loss: -1.807,LR: 3.22E-04]Training epoch 41:  66%|██████▌   | 74/112 [00:01<00:00, 53.42it/s, Epoch: 41, Batch: 75,Loss: -2.278,Avg.Loss: -1.813,LR: 3.22E-04]Training epoch 41:  67%|██████▋   | 75/112 [00:01<00:00, 53.42it/s, Epoch: 41, Batch: 76,Loss: -2.186,Avg.Loss: -1.818,LR: 3.22E-04]Training epoch 41:  68%|██████▊   | 76/112 [00:01<00:00, 53.42it/s, Epoch: 41, Batch: 77,Loss: -2.521,Avg.Loss: -1.827,LR: 3.22E-04]Training epoch 41:  69%|██████▉   | 77/112 [00:01<00:00, 53.42it/s, Epoch: 41, Batch: 78,Loss: -2.388,Avg.Loss: -1.835,LR: 3.22E-04]Training epoch 41:  70%|██████▉   | 78/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 78,Loss: -2.388,Avg.Loss: -1.835,LR: 3.22E-04]Training epoch 41:  70%|██████▉   | 78/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 79,Loss: -2.508,Avg.Loss: -1.843,LR: 3.22E-04]Training epoch 41:  71%|███████   | 79/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 80,Loss: -2.358,Avg.Loss: -1.850,LR: 3.22E-04]Training epoch 41:  71%|███████▏  | 80/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 81,Loss: -2.265,Avg.Loss: -1.855,LR: 3.22E-04]Training epoch 41:  72%|███████▏  | 81/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 82,Loss: -1.972,Avg.Loss: -1.856,LR: 3.22E-04]Training epoch 41:  73%|███████▎  | 82/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 83,Loss: -2.582,Avg.Loss: -1.865,LR: 3.22E-04]Training epoch 41:  74%|███████▍  | 83/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 84,Loss: -2.727,Avg.Loss: -1.875,LR: 3.22E-04]Training epoch 41:  75%|███████▌  | 84/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 84,Loss: -2.727,Avg.Loss: -1.875,LR: 3.22E-04]Training epoch 41:  75%|███████▌  | 84/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 85,Loss: -2.646,Avg.Loss: -1.884,LR: 3.22E-04]Training epoch 41:  76%|███████▌  | 85/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 86,Loss: -2.492,Avg.Loss: -1.891,LR: 3.21E-04]Training epoch 41:  77%|███████▋  | 86/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 87,Loss: -1.698,Avg.Loss: -1.889,LR: 3.21E-04]Training epoch 41:  78%|███████▊  | 87/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 88,Loss: -1.929,Avg.Loss: -1.890,LR: 3.21E-04]Training epoch 41:  79%|███████▊  | 88/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 89,Loss: -2.308,Avg.Loss: -1.894,LR: 3.21E-04]Training epoch 41:  79%|███████▉  | 89/112 [00:01<00:00, 53.41it/s, Epoch: 41, Batch: 90,Loss: -0.232,Avg.Loss: -1.876,LR: 3.21E-04]Training epoch 41:  80%|████████  | 90/112 [00:01<00:00, 53.55it/s, Epoch: 41, Batch: 90,Loss: -0.232,Avg.Loss: -1.876,LR: 3.21E-04]Training epoch 41:  80%|████████  | 90/112 [00:01<00:00, 53.55it/s, Epoch: 41, Batch: 91,Loss: 2.498,Avg.Loss: -1.828,LR: 3.21E-04] Training epoch 41:  81%|████████▏ | 91/112 [00:01<00:00, 53.55it/s, Epoch: 41, Batch: 92,Loss: 0.566,Avg.Loss: -1.802,LR: 3.21E-04]Training epoch 41:  82%|████████▏ | 92/112 [00:01<00:00, 53.55it/s, Epoch: 41, Batch: 93,Loss: -2.295,Avg.Loss: -1.807,LR: 3.21E-04]Training epoch 41:  83%|████████▎ | 93/112 [00:01<00:00, 53.55it/s, Epoch: 41, Batch: 94,Loss: -1.251,Avg.Loss: -1.801,LR: 3.21E-04]Training epoch 41:  84%|████████▍ | 94/112 [00:01<00:00, 53.55it/s, Epoch: 41, Batch: 95,Loss: 1.369,Avg.Loss: -1.768,LR: 3.21E-04] Training epoch 41:  85%|████████▍ | 95/112 [00:01<00:00, 53.55it/s, Epoch: 41, Batch: 96,Loss: 1.208,Avg.Loss: -1.737,LR: 3.21E-04]Training epoch 41:  86%|████████▌ | 96/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 96,Loss: 1.208,Avg.Loss: -1.737,LR: 3.21E-04]Training epoch 41:  86%|████████▌ | 96/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 97,Loss: -1.438,Avg.Loss: -1.734,LR: 3.21E-04]Training epoch 41:  87%|████████▋ | 97/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 98,Loss: -2.063,Avg.Loss: -1.737,LR: 3.21E-04]Training epoch 41:  88%|████████▊ | 98/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 99,Loss: -1.022,Avg.Loss: -1.730,LR: 3.21E-04]Training epoch 41:  88%|████████▊ | 99/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 100,Loss: -1.822,Avg.Loss: -1.731,LR: 3.21E-04]Training epoch 41:  89%|████████▉ | 100/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 101,Loss: -2.473,Avg.Loss: -1.738,LR: 3.20E-04]Training epoch 41:  90%|█████████ | 101/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 102,Loss: -2.323,Avg.Loss: -1.744,LR: 3.20E-04]Training epoch 41:  91%|█████████ | 102/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 102,Loss: -2.323,Avg.Loss: -1.744,LR: 3.20E-04]Training epoch 41:  91%|█████████ | 102/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 103,Loss: -2.449,Avg.Loss: -1.751,LR: 3.20E-04]Training epoch 41:  92%|█████████▏| 103/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 104,Loss: -2.521,Avg.Loss: -1.758,LR: 3.20E-04]Training epoch 41:  93%|█████████▎| 104/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 105,Loss: -2.560,Avg.Loss: -1.766,LR: 3.20E-04]Training epoch 41:  94%|█████████▍| 105/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 106,Loss: -2.576,Avg.Loss: -1.773,LR: 3.20E-04]Training epoch 41:  95%|█████████▍| 106/112 [00:01<00:00, 53.49it/s, Epoch: 41, Batch: 107,Loss: -2.197,Avg.Loss: -1.777,LR: 3.20E-04]Training epoch 41:  96%|█████████▌| 107/112 [00:02<00:00, 53.49it/s, Epoch: 41, Batch: 108,Loss: -1.417,Avg.Loss: -1.774,LR: 3.20E-04]Training epoch 41:  96%|█████████▋| 108/112 [00:02<00:00, 53.43it/s, Epoch: 41, Batch: 108,Loss: -1.417,Avg.Loss: -1.774,LR: 3.20E-04]Training epoch 41:  96%|█████████▋| 108/112 [00:02<00:00, 53.43it/s, Epoch: 41, Batch: 109,Loss: -1.806,Avg.Loss: -1.774,LR: 3.20E-04]Training epoch 41:  97%|█████████▋| 109/112 [00:02<00:00, 53.43it/s, Epoch: 41, Batch: 110,Loss: -2.670,Avg.Loss: -1.782,LR: 3.20E-04]Training epoch 41:  98%|█████████▊| 110/112 [00:02<00:00, 53.43it/s, Epoch: 41, Batch: 111,Loss: -0.463,Avg.Loss: -1.770,LR: 3.20E-04]Training epoch 41:  99%|█████████▉| 111/112 [00:02<00:00, 53.43it/s, Epoch: 41, Batch: 112,Loss: 3.938,Avg.Loss: -1.720,LR: 3.20E-04] Training epoch 41: 100%|██████████| 112/112 [00:02<00:00, 53.43it/s, Epoch: 41, Batch: 112,Loss: 3.938,Avg.Loss: -1.720,LR: 3.20E-04]
Training epoch 42:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 42:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 42, Batch: 1,Loss: 1.113,Avg.Loss: 1.113,LR: 3.20E-04]Training epoch 42:   1%|          | 1/112 [00:00<00:03, 28.77it/s, Epoch: 42, Batch: 2,Loss: -1.224,Avg.Loss: -0.056,LR: 3.20E-04]Training epoch 42:   2%|▏         | 2/112 [00:00<00:02, 40.48it/s, Epoch: 42, Batch: 3,Loss: 1.052,Avg.Loss: 0.314,LR: 3.20E-04]  Training epoch 42:   3%|▎         | 3/112 [00:00<00:02, 44.83it/s, Epoch: 42, Batch: 4,Loss: 2.172,Avg.Loss: 0.778,LR: 3.19E-04]Training epoch 42:   4%|▎         | 4/112 [00:00<00:02, 48.89it/s, Epoch: 42, Batch: 5,Loss: 3.815,Avg.Loss: 1.386,LR: 3.19E-04]Training epoch 42:   4%|▍         | 5/112 [00:00<00:02, 50.15it/s, Epoch: 42, Batch: 6,Loss: 0.117,Avg.Loss: 1.174,LR: 3.19E-04]Training epoch 42:   5%|▌         | 6/112 [00:00<00:02, 50.71it/s, Epoch: 42, Batch: 7,Loss: -1.978,Avg.Loss: 0.724,LR: 3.19E-04]Training epoch 42:   6%|▋         | 7/112 [00:00<00:01, 59.08it/s, Epoch: 42, Batch: 7,Loss: -1.978,Avg.Loss: 0.724,LR: 3.19E-04]Training epoch 42:   6%|▋         | 7/112 [00:00<00:01, 59.08it/s, Epoch: 42, Batch: 8,Loss: 1.119,Avg.Loss: 0.773,LR: 3.19E-04] Training epoch 42:   7%|▋         | 8/112 [00:00<00:01, 59.08it/s, Epoch: 42, Batch: 9,Loss: 5.053,Avg.Loss: 1.249,LR: 3.19E-04]Training epoch 42:   8%|▊         | 9/112 [00:00<00:01, 59.08it/s, Epoch: 42, Batch: 10,Loss: 6.660,Avg.Loss: 1.790,LR: 3.19E-04]Training epoch 42:   9%|▉         | 10/112 [00:00<00:01, 59.08it/s, Epoch: 42, Batch: 11,Loss: 2.975,Avg.Loss: 1.898,LR: 3.19E-04]Training epoch 42:  10%|▉         | 11/112 [00:00<00:01, 59.08it/s, Epoch: 42, Batch: 12,Loss: -0.072,Avg.Loss: 1.733,LR: 3.19E-04]Training epoch 42:  11%|█         | 12/112 [00:00<00:01, 59.08it/s, Epoch: 42, Batch: 13,Loss: -1.414,Avg.Loss: 1.491,LR: 3.19E-04]Training epoch 42:  12%|█▏        | 13/112 [00:00<00:01, 56.09it/s, Epoch: 42, Batch: 13,Loss: -1.414,Avg.Loss: 1.491,LR: 3.19E-04]Training epoch 42:  12%|█▏        | 13/112 [00:00<00:01, 56.09it/s, Epoch: 42, Batch: 14,Loss: -0.200,Avg.Loss: 1.371,LR: 3.19E-04]Training epoch 42:  12%|█▎        | 14/112 [00:00<00:01, 56.09it/s, Epoch: 42, Batch: 15,Loss: -0.833,Avg.Loss: 1.224,LR: 3.19E-04]Training epoch 42:  13%|█▎        | 15/112 [00:00<00:01, 56.09it/s, Epoch: 42, Batch: 16,Loss: -1.886,Avg.Loss: 1.029,LR: 3.19E-04]Training epoch 42:  14%|█▍        | 16/112 [00:00<00:01, 56.09it/s, Epoch: 42, Batch: 17,Loss: -1.322,Avg.Loss: 0.891,LR: 3.19E-04]Training epoch 42:  15%|█▌        | 17/112 [00:00<00:01, 56.09it/s, Epoch: 42, Batch: 18,Loss: -0.775,Avg.Loss: 0.798,LR: 3.19E-04]Training epoch 42:  16%|█▌        | 18/112 [00:00<00:01, 56.09it/s, Epoch: 42, Batch: 19,Loss: -1.646,Avg.Loss: 0.670,LR: 3.18E-04]Training epoch 42:  17%|█▋        | 19/112 [00:00<00:01, 54.87it/s, Epoch: 42, Batch: 19,Loss: -1.646,Avg.Loss: 0.670,LR: 3.18E-04]Training epoch 42:  17%|█▋        | 19/112 [00:00<00:01, 54.87it/s, Epoch: 42, Batch: 20,Loss: -2.145,Avg.Loss: 0.529,LR: 3.18E-04]Training epoch 42:  18%|█▊        | 20/112 [00:00<00:01, 54.87it/s, Epoch: 42, Batch: 21,Loss: -1.894,Avg.Loss: 0.414,LR: 3.18E-04]Training epoch 42:  19%|█▉        | 21/112 [00:00<00:01, 54.87it/s, Epoch: 42, Batch: 22,Loss: -2.238,Avg.Loss: 0.293,LR: 3.18E-04]Training epoch 42:  20%|█▉        | 22/112 [00:00<00:01, 54.87it/s, Epoch: 42, Batch: 23,Loss: -2.438,Avg.Loss: 0.174,LR: 3.18E-04]Training epoch 42:  21%|██        | 23/112 [00:00<00:01, 54.87it/s, Epoch: 42, Batch: 24,Loss: -1.592,Avg.Loss: 0.101,LR: 3.18E-04]Training epoch 42:  21%|██▏       | 24/112 [00:00<00:01, 54.87it/s, Epoch: 42, Batch: 25,Loss: -2.204,Avg.Loss: 0.009,LR: 3.18E-04]Training epoch 42:  22%|██▏       | 25/112 [00:00<00:01, 52.90it/s, Epoch: 42, Batch: 25,Loss: -2.204,Avg.Loss: 0.009,LR: 3.18E-04]Training epoch 42:  22%|██▏       | 25/112 [00:00<00:01, 52.90it/s, Epoch: 42, Batch: 26,Loss: -2.222,Avg.Loss: -0.077,LR: 3.18E-04]Training epoch 42:  23%|██▎       | 26/112 [00:00<00:01, 52.90it/s, Epoch: 42, Batch: 27,Loss: -1.683,Avg.Loss: -0.137,LR: 3.18E-04]Training epoch 42:  24%|██▍       | 27/112 [00:00<00:01, 52.90it/s, Epoch: 42, Batch: 28,Loss: -2.074,Avg.Loss: -0.206,LR: 3.18E-04]Training epoch 42:  25%|██▌       | 28/112 [00:00<00:01, 52.90it/s, Epoch: 42, Batch: 29,Loss: -2.055,Avg.Loss: -0.270,LR: 3.18E-04]Training epoch 42:  26%|██▌       | 29/112 [00:00<00:01, 52.90it/s, Epoch: 42, Batch: 30,Loss: -2.335,Avg.Loss: -0.338,LR: 3.18E-04]Training epoch 42:  27%|██▋       | 30/112 [00:00<00:01, 52.90it/s, Epoch: 42, Batch: 31,Loss: -1.720,Avg.Loss: -0.383,LR: 3.18E-04]Training epoch 42:  28%|██▊       | 31/112 [00:00<00:01, 52.74it/s, Epoch: 42, Batch: 31,Loss: -1.720,Avg.Loss: -0.383,LR: 3.18E-04]Training epoch 42:  28%|██▊       | 31/112 [00:00<00:01, 52.74it/s, Epoch: 42, Batch: 32,Loss: -1.062,Avg.Loss: -0.404,LR: 3.18E-04]Training epoch 42:  29%|██▊       | 32/112 [00:00<00:01, 52.74it/s, Epoch: 42, Batch: 33,Loss: -1.837,Avg.Loss: -0.448,LR: 3.18E-04]Training epoch 42:  29%|██▉       | 33/112 [00:00<00:01, 52.74it/s, Epoch: 42, Batch: 34,Loss: -1.939,Avg.Loss: -0.491,LR: 3.17E-04]Training epoch 42:  30%|███       | 34/112 [00:00<00:01, 52.74it/s, Epoch: 42, Batch: 35,Loss: -1.863,Avg.Loss: -0.531,LR: 3.17E-04]Training epoch 42:  31%|███▏      | 35/112 [00:00<00:01, 52.74it/s, Epoch: 42, Batch: 36,Loss: -1.582,Avg.Loss: -0.560,LR: 3.17E-04]Training epoch 42:  32%|███▏      | 36/112 [00:00<00:01, 52.74it/s, Epoch: 42, Batch: 37,Loss: -1.293,Avg.Loss: -0.580,LR: 3.17E-04]Training epoch 42:  33%|███▎      | 37/112 [00:00<00:01, 52.78it/s, Epoch: 42, Batch: 37,Loss: -1.293,Avg.Loss: -0.580,LR: 3.17E-04]Training epoch 42:  33%|███▎      | 37/112 [00:00<00:01, 52.78it/s, Epoch: 42, Batch: 38,Loss: -1.140,Avg.Loss: -0.594,LR: 3.17E-04]Training epoch 42:  34%|███▍      | 38/112 [00:00<00:01, 52.78it/s, Epoch: 42, Batch: 39,Loss: -1.738,Avg.Loss: -0.624,LR: 3.17E-04]Training epoch 42:  35%|███▍      | 39/112 [00:00<00:01, 52.78it/s, Epoch: 42, Batch: 40,Loss: -2.022,Avg.Loss: -0.659,LR: 3.17E-04]Training epoch 42:  36%|███▌      | 40/112 [00:00<00:01, 52.78it/s, Epoch: 42, Batch: 41,Loss: -1.817,Avg.Loss: -0.687,LR: 3.17E-04]Training epoch 42:  37%|███▋      | 41/112 [00:00<00:01, 52.78it/s, Epoch: 42, Batch: 42,Loss: -2.011,Avg.Loss: -0.718,LR: 3.17E-04]Training epoch 42:  38%|███▊      | 42/112 [00:00<00:01, 52.78it/s, Epoch: 42, Batch: 43,Loss: -1.972,Avg.Loss: -0.748,LR: 3.17E-04]Training epoch 42:  38%|███▊      | 43/112 [00:00<00:01, 52.73it/s, Epoch: 42, Batch: 43,Loss: -1.972,Avg.Loss: -0.748,LR: 3.17E-04]Training epoch 42:  38%|███▊      | 43/112 [00:00<00:01, 52.73it/s, Epoch: 42, Batch: 44,Loss: -1.733,Avg.Loss: -0.770,LR: 3.17E-04]Training epoch 42:  39%|███▉      | 44/112 [00:00<00:01, 52.73it/s, Epoch: 42, Batch: 45,Loss: -2.134,Avg.Loss: -0.800,LR: 3.17E-04]Training epoch 42:  40%|████      | 45/112 [00:00<00:01, 52.73it/s, Epoch: 42, Batch: 46,Loss: -1.271,Avg.Loss: -0.811,LR: 3.17E-04]Training epoch 42:  41%|████      | 46/112 [00:00<00:01, 52.73it/s, Epoch: 42, Batch: 47,Loss: -0.772,Avg.Loss: -0.810,LR: 3.17E-04]Training epoch 42:  42%|████▏     | 47/112 [00:00<00:01, 52.73it/s, Epoch: 42, Batch: 48,Loss: -1.440,Avg.Loss: -0.823,LR: 3.17E-04]Training epoch 42:  43%|████▎     | 48/112 [00:00<00:01, 52.73it/s, Epoch: 42, Batch: 49,Loss: -1.260,Avg.Loss: -0.832,LR: 3.16E-04]Training epoch 42:  44%|████▍     | 49/112 [00:00<00:01, 52.81it/s, Epoch: 42, Batch: 49,Loss: -1.260,Avg.Loss: -0.832,LR: 3.16E-04]Training epoch 42:  44%|████▍     | 49/112 [00:00<00:01, 52.81it/s, Epoch: 42, Batch: 50,Loss: -1.428,Avg.Loss: -0.844,LR: 3.16E-04]Training epoch 42:  45%|████▍     | 50/112 [00:00<00:01, 52.81it/s, Epoch: 42, Batch: 51,Loss: -1.970,Avg.Loss: -0.866,LR: 3.16E-04]Training epoch 42:  46%|████▌     | 51/112 [00:00<00:01, 52.81it/s, Epoch: 42, Batch: 52,Loss: -2.020,Avg.Loss: -0.888,LR: 3.16E-04]Training epoch 42:  46%|████▋     | 52/112 [00:00<00:01, 52.81it/s, Epoch: 42, Batch: 53,Loss: -2.223,Avg.Loss: -0.913,LR: 3.16E-04]Training epoch 42:  47%|████▋     | 53/112 [00:01<00:01, 52.81it/s, Epoch: 42, Batch: 54,Loss: -2.223,Avg.Loss: -0.937,LR: 3.16E-04]Training epoch 42:  48%|████▊     | 54/112 [00:01<00:01, 52.81it/s, Epoch: 42, Batch: 55,Loss: -2.001,Avg.Loss: -0.957,LR: 3.16E-04]Training epoch 42:  49%|████▉     | 55/112 [00:01<00:01, 53.06it/s, Epoch: 42, Batch: 55,Loss: -2.001,Avg.Loss: -0.957,LR: 3.16E-04]Training epoch 42:  49%|████▉     | 55/112 [00:01<00:01, 53.06it/s, Epoch: 42, Batch: 56,Loss: -1.914,Avg.Loss: -0.974,LR: 3.16E-04]Training epoch 42:  50%|█████     | 56/112 [00:01<00:01, 53.06it/s, Epoch: 42, Batch: 57,Loss: -2.077,Avg.Loss: -0.993,LR: 3.16E-04]Training epoch 42:  51%|█████     | 57/112 [00:01<00:01, 53.06it/s, Epoch: 42, Batch: 58,Loss: -2.562,Avg.Loss: -1.020,LR: 3.16E-04]Training epoch 42:  52%|█████▏    | 58/112 [00:01<00:01, 53.06it/s, Epoch: 42, Batch: 59,Loss: -2.304,Avg.Loss: -1.042,LR: 3.16E-04]Training epoch 42:  53%|█████▎    | 59/112 [00:01<00:00, 53.06it/s, Epoch: 42, Batch: 60,Loss: -2.174,Avg.Loss: -1.061,LR: 3.16E-04]Training epoch 42:  54%|█████▎    | 60/112 [00:01<00:00, 53.06it/s, Epoch: 42, Batch: 61,Loss: -2.515,Avg.Loss: -1.085,LR: 3.16E-04]Training epoch 42:  54%|█████▍    | 61/112 [00:01<00:00, 53.01it/s, Epoch: 42, Batch: 61,Loss: -2.515,Avg.Loss: -1.085,LR: 3.16E-04]Training epoch 42:  54%|█████▍    | 61/112 [00:01<00:00, 53.01it/s, Epoch: 42, Batch: 62,Loss: -2.358,Avg.Loss: -1.105,LR: 3.16E-04]Training epoch 42:  55%|█████▌    | 62/112 [00:01<00:00, 53.01it/s, Epoch: 42, Batch: 63,Loss: -1.794,Avg.Loss: -1.116,LR: 3.15E-04]Training epoch 42:  56%|█████▋    | 63/112 [00:01<00:00, 53.01it/s, Epoch: 42, Batch: 64,Loss: -1.979,Avg.Loss: -1.130,LR: 3.15E-04]Training epoch 42:  57%|█████▋    | 64/112 [00:01<00:00, 53.01it/s, Epoch: 42, Batch: 65,Loss: -2.055,Avg.Loss: -1.144,LR: 3.15E-04]Training epoch 42:  58%|█████▊    | 65/112 [00:01<00:00, 53.01it/s, Epoch: 42, Batch: 66,Loss: -2.380,Avg.Loss: -1.163,LR: 3.15E-04]Training epoch 42:  59%|█████▉    | 66/112 [00:01<00:00, 53.01it/s, Epoch: 42, Batch: 67,Loss: -1.736,Avg.Loss: -1.171,LR: 3.15E-04]Training epoch 42:  60%|█████▉    | 67/112 [00:01<00:00, 52.94it/s, Epoch: 42, Batch: 67,Loss: -1.736,Avg.Loss: -1.171,LR: 3.15E-04]Training epoch 42:  60%|█████▉    | 67/112 [00:01<00:00, 52.94it/s, Epoch: 42, Batch: 68,Loss: -2.014,Avg.Loss: -1.184,LR: 3.15E-04]Training epoch 42:  61%|██████    | 68/112 [00:01<00:00, 52.94it/s, Epoch: 42, Batch: 69,Loss: -2.032,Avg.Loss: -1.196,LR: 3.15E-04]Training epoch 42:  62%|██████▏   | 69/112 [00:01<00:00, 52.94it/s, Epoch: 42, Batch: 70,Loss: -1.994,Avg.Loss: -1.207,LR: 3.15E-04]Training epoch 42:  62%|██████▎   | 70/112 [00:01<00:00, 52.94it/s, Epoch: 42, Batch: 71,Loss: -2.054,Avg.Loss: -1.219,LR: 3.15E-04]Training epoch 42:  63%|██████▎   | 71/112 [00:01<00:00, 52.94it/s, Epoch: 42, Batch: 72,Loss: -0.850,Avg.Loss: -1.214,LR: 3.15E-04]Training epoch 42:  64%|██████▍   | 72/112 [00:01<00:00, 52.94it/s, Epoch: 42, Batch: 73,Loss: 0.585,Avg.Loss: -1.189,LR: 3.15E-04] Training epoch 42:  65%|██████▌   | 73/112 [00:01<00:00, 52.84it/s, Epoch: 42, Batch: 73,Loss: 0.585,Avg.Loss: -1.189,LR: 3.15E-04]Training epoch 42:  65%|██████▌   | 73/112 [00:01<00:00, 52.84it/s, Epoch: 42, Batch: 74,Loss: -0.566,Avg.Loss: -1.181,LR: 3.15E-04]Training epoch 42:  66%|██████▌   | 74/112 [00:01<00:00, 52.84it/s, Epoch: 42, Batch: 75,Loss: -2.014,Avg.Loss: -1.192,LR: 3.15E-04]Training epoch 42:  67%|██████▋   | 75/112 [00:01<00:00, 52.84it/s, Epoch: 42, Batch: 76,Loss: -0.775,Avg.Loss: -1.187,LR: 3.15E-04]Training epoch 42:  68%|██████▊   | 76/112 [00:01<00:00, 52.84it/s, Epoch: 42, Batch: 77,Loss: 0.337,Avg.Loss: -1.167,LR: 3.15E-04] Training epoch 42:  69%|██████▉   | 77/112 [00:01<00:00, 52.84it/s, Epoch: 42, Batch: 78,Loss: 0.486,Avg.Loss: -1.146,LR: 3.14E-04]Training epoch 42:  70%|██████▉   | 78/112 [00:01<00:00, 52.84it/s, Epoch: 42, Batch: 79,Loss: -1.499,Avg.Loss: -1.150,LR: 3.14E-04]Training epoch 42:  71%|███████   | 79/112 [00:01<00:00, 54.44it/s, Epoch: 42, Batch: 79,Loss: -1.499,Avg.Loss: -1.150,LR: 3.14E-04]Training epoch 42:  71%|███████   | 79/112 [00:01<00:00, 54.44it/s, Epoch: 42, Batch: 80,Loss: -2.191,Avg.Loss: -1.163,LR: 3.14E-04]Training epoch 42:  71%|███████▏  | 80/112 [00:01<00:00, 54.44it/s, Epoch: 42, Batch: 81,Loss: -1.602,Avg.Loss: -1.169,LR: 3.14E-04]Training epoch 42:  72%|███████▏  | 81/112 [00:01<00:00, 54.44it/s, Epoch: 42, Batch: 82,Loss: -1.945,Avg.Loss: -1.178,LR: 3.14E-04]Training epoch 42:  73%|███████▎  | 82/112 [00:01<00:00, 54.44it/s, Epoch: 42, Batch: 83,Loss: -2.517,Avg.Loss: -1.194,LR: 3.14E-04]Training epoch 42:  74%|███████▍  | 83/112 [00:01<00:00, 54.44it/s, Epoch: 42, Batch: 84,Loss: -2.243,Avg.Loss: -1.207,LR: 3.14E-04]Training epoch 42:  75%|███████▌  | 84/112 [00:01<00:00, 54.44it/s, Epoch: 42, Batch: 85,Loss: -2.566,Avg.Loss: -1.223,LR: 3.14E-04]Training epoch 42:  76%|███████▌  | 85/112 [00:01<00:00, 54.25it/s, Epoch: 42, Batch: 85,Loss: -2.566,Avg.Loss: -1.223,LR: 3.14E-04]Training epoch 42:  76%|███████▌  | 85/112 [00:01<00:00, 54.25it/s, Epoch: 42, Batch: 86,Loss: -1.795,Avg.Loss: -1.229,LR: 3.14E-04]Training epoch 42:  77%|███████▋  | 86/112 [00:01<00:00, 54.25it/s, Epoch: 42, Batch: 87,Loss: -1.286,Avg.Loss: -1.230,LR: 3.14E-04]Training epoch 42:  78%|███████▊  | 87/112 [00:01<00:00, 54.25it/s, Epoch: 42, Batch: 88,Loss: -1.958,Avg.Loss: -1.238,LR: 3.14E-04]Training epoch 42:  79%|███████▊  | 88/112 [00:01<00:00, 54.25it/s, Epoch: 42, Batch: 89,Loss: -1.190,Avg.Loss: -1.238,LR: 3.14E-04]Training epoch 42:  79%|███████▉  | 89/112 [00:01<00:00, 54.25it/s, Epoch: 42, Batch: 90,Loss: -1.012,Avg.Loss: -1.235,LR: 3.14E-04]Training epoch 42:  80%|████████  | 90/112 [00:01<00:00, 54.25it/s, Epoch: 42, Batch: 91,Loss: -1.658,Avg.Loss: -1.240,LR: 3.14E-04]Training epoch 42:  81%|████████▏ | 91/112 [00:01<00:00, 54.08it/s, Epoch: 42, Batch: 91,Loss: -1.658,Avg.Loss: -1.240,LR: 3.14E-04]Training epoch 42:  81%|████████▏ | 91/112 [00:01<00:00, 54.08it/s, Epoch: 42, Batch: 92,Loss: -2.332,Avg.Loss: -1.252,LR: 3.14E-04]Training epoch 42:  82%|████████▏ | 92/112 [00:01<00:00, 54.08it/s, Epoch: 42, Batch: 93,Loss: -2.314,Avg.Loss: -1.263,LR: 3.13E-04]Training epoch 42:  83%|████████▎ | 93/112 [00:01<00:00, 54.08it/s, Epoch: 42, Batch: 94,Loss: -2.529,Avg.Loss: -1.277,LR: 3.13E-04]Training epoch 42:  84%|████████▍ | 94/112 [00:01<00:00, 54.08it/s, Epoch: 42, Batch: 95,Loss: -2.028,Avg.Loss: -1.284,LR: 3.13E-04]Training epoch 42:  85%|████████▍ | 95/112 [00:01<00:00, 54.08it/s, Epoch: 42, Batch: 96,Loss: -2.629,Avg.Loss: -1.298,LR: 3.13E-04]Training epoch 42:  86%|████████▌ | 96/112 [00:01<00:00, 54.08it/s, Epoch: 42, Batch: 97,Loss: -1.814,Avg.Loss: -1.304,LR: 3.13E-04]Training epoch 42:  87%|████████▋ | 97/112 [00:01<00:00, 53.78it/s, Epoch: 42, Batch: 97,Loss: -1.814,Avg.Loss: -1.304,LR: 3.13E-04]Training epoch 42:  87%|████████▋ | 97/112 [00:01<00:00, 53.78it/s, Epoch: 42, Batch: 98,Loss: -1.168,Avg.Loss: -1.302,LR: 3.13E-04]Training epoch 42:  88%|████████▊ | 98/112 [00:01<00:00, 53.78it/s, Epoch: 42, Batch: 99,Loss: -1.066,Avg.Loss: -1.300,LR: 3.13E-04]Training epoch 42:  88%|████████▊ | 99/112 [00:01<00:00, 53.78it/s, Epoch: 42, Batch: 100,Loss: -1.578,Avg.Loss: -1.303,LR: 3.13E-04]Training epoch 42:  89%|████████▉ | 100/112 [00:01<00:00, 53.78it/s, Epoch: 42, Batch: 101,Loss: 0.095,Avg.Loss: -1.289,LR: 3.13E-04]Training epoch 42:  90%|█████████ | 101/112 [00:01<00:00, 53.78it/s, Epoch: 42, Batch: 102,Loss: -0.879,Avg.Loss: -1.285,LR: 3.13E-04]Training epoch 42:  91%|█████████ | 102/112 [00:01<00:00, 53.78it/s, Epoch: 42, Batch: 103,Loss: -2.450,Avg.Loss: -1.296,LR: 3.13E-04]Training epoch 42:  92%|█████████▏| 103/112 [00:01<00:00, 53.68it/s, Epoch: 42, Batch: 103,Loss: -2.450,Avg.Loss: -1.296,LR: 3.13E-04]Training epoch 42:  92%|█████████▏| 103/112 [00:01<00:00, 53.68it/s, Epoch: 42, Batch: 104,Loss: -1.294,Avg.Loss: -1.296,LR: 3.13E-04]Training epoch 42:  93%|█████████▎| 104/112 [00:01<00:00, 53.68it/s, Epoch: 42, Batch: 105,Loss: 0.947,Avg.Loss: -1.275,LR: 3.13E-04] Training epoch 42:  94%|█████████▍| 105/112 [00:01<00:00, 53.68it/s, Epoch: 42, Batch: 106,Loss: 0.247,Avg.Loss: -1.261,LR: 3.13E-04]Training epoch 42:  95%|█████████▍| 106/112 [00:01<00:00, 53.68it/s, Epoch: 42, Batch: 107,Loss: -0.865,Avg.Loss: -1.257,LR: 3.13E-04]Training epoch 42:  96%|█████████▌| 107/112 [00:02<00:00, 53.68it/s, Epoch: 42, Batch: 108,Loss: -1.040,Avg.Loss: -1.255,LR: 3.12E-04]Training epoch 42:  96%|█████████▋| 108/112 [00:02<00:00, 53.68it/s, Epoch: 42, Batch: 109,Loss: -1.007,Avg.Loss: -1.253,LR: 3.12E-04]Training epoch 42:  97%|█████████▋| 109/112 [00:02<00:00, 53.61it/s, Epoch: 42, Batch: 109,Loss: -1.007,Avg.Loss: -1.253,LR: 3.12E-04]Training epoch 42:  97%|█████████▋| 109/112 [00:02<00:00, 53.61it/s, Epoch: 42, Batch: 110,Loss: -1.422,Avg.Loss: -1.254,LR: 3.12E-04]Training epoch 42:  98%|█████████▊| 110/112 [00:02<00:00, 53.61it/s, Epoch: 42, Batch: 111,Loss: -2.570,Avg.Loss: -1.266,LR: 3.12E-04]Training epoch 42:  99%|█████████▉| 111/112 [00:02<00:00, 53.61it/s, Epoch: 42, Batch: 112,Loss: -0.292,Avg.Loss: -1.257,LR: 3.12E-04]Training epoch 42: 100%|██████████| 112/112 [00:02<00:00, 53.49it/s, Epoch: 42, Batch: 112,Loss: -0.292,Avg.Loss: -1.257,LR: 3.12E-04]
Training epoch 43:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 43:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 43, Batch: 1,Loss: 1.400,Avg.Loss: 1.400,LR: 3.12E-04]Training epoch 43:   1%|          | 1/112 [00:00<00:03, 30.40it/s, Epoch: 43, Batch: 2,Loss: 0.804,Avg.Loss: 1.102,LR: 3.12E-04]Training epoch 43:   2%|▏         | 2/112 [00:00<00:02, 42.21it/s, Epoch: 43, Batch: 3,Loss: -0.950,Avg.Loss: 0.418,LR: 3.12E-04]Training epoch 43:   3%|▎         | 3/112 [00:00<00:02, 48.42it/s, Epoch: 43, Batch: 4,Loss: -0.875,Avg.Loss: 0.095,LR: 3.12E-04]Training epoch 43:   4%|▎         | 4/112 [00:00<00:02, 52.36it/s, Epoch: 43, Batch: 5,Loss: -0.650,Avg.Loss: -0.054,LR: 3.12E-04]Training epoch 43:   4%|▍         | 5/112 [00:00<00:02, 52.35it/s, Epoch: 43, Batch: 6,Loss: -0.470,Avg.Loss: -0.123,LR: 3.12E-04]Training epoch 43:   5%|▌         | 6/112 [00:00<00:02, 52.26it/s, Epoch: 43, Batch: 7,Loss: -2.451,Avg.Loss: -0.456,LR: 3.12E-04]Training epoch 43:   6%|▋         | 7/112 [00:00<00:01, 60.87it/s, Epoch: 43, Batch: 7,Loss: -2.451,Avg.Loss: -0.456,LR: 3.12E-04]Training epoch 43:   6%|▋         | 7/112 [00:00<00:01, 60.87it/s, Epoch: 43, Batch: 8,Loss: -2.248,Avg.Loss: -0.680,LR: 3.12E-04]Training epoch 43:   7%|▋         | 8/112 [00:00<00:01, 60.87it/s, Epoch: 43, Batch: 9,Loss: -1.580,Avg.Loss: -0.780,LR: 3.12E-04]Training epoch 43:   8%|▊         | 9/112 [00:00<00:01, 60.87it/s, Epoch: 43, Batch: 10,Loss: -1.699,Avg.Loss: -0.872,LR: 3.11E-04]Training epoch 43:   9%|▉         | 10/112 [00:00<00:01, 60.87it/s, Epoch: 43, Batch: 11,Loss: -2.062,Avg.Loss: -0.980,LR: 3.11E-04]Training epoch 43:  10%|▉         | 11/112 [00:00<00:01, 60.87it/s, Epoch: 43, Batch: 12,Loss: -1.216,Avg.Loss: -1.000,LR: 3.11E-04]Training epoch 43:  11%|█         | 12/112 [00:00<00:01, 60.87it/s, Epoch: 43, Batch: 13,Loss: -0.211,Avg.Loss: -0.939,LR: 3.11E-04]Training epoch 43:  12%|█▏        | 13/112 [00:00<00:01, 60.87it/s, Epoch: 43, Batch: 14,Loss: -1.157,Avg.Loss: -0.955,LR: 3.11E-04]Training epoch 43:  12%|█▎        | 14/112 [00:00<00:01, 56.19it/s, Epoch: 43, Batch: 14,Loss: -1.157,Avg.Loss: -0.955,LR: 3.11E-04]Training epoch 43:  12%|█▎        | 14/112 [00:00<00:01, 56.19it/s, Epoch: 43, Batch: 15,Loss: -2.426,Avg.Loss: -1.053,LR: 3.11E-04]Training epoch 43:  13%|█▎        | 15/112 [00:00<00:01, 56.19it/s, Epoch: 43, Batch: 16,Loss: -1.460,Avg.Loss: -1.078,LR: 3.11E-04]Training epoch 43:  14%|█▍        | 16/112 [00:00<00:01, 56.19it/s, Epoch: 43, Batch: 17,Loss: -0.113,Avg.Loss: -1.021,LR: 3.11E-04]Training epoch 43:  15%|█▌        | 17/112 [00:00<00:01, 56.19it/s, Epoch: 43, Batch: 18,Loss: 0.037,Avg.Loss: -0.963,LR: 3.11E-04] Training epoch 43:  16%|█▌        | 18/112 [00:00<00:01, 56.19it/s, Epoch: 43, Batch: 19,Loss: -2.174,Avg.Loss: -1.026,LR: 3.11E-04]Training epoch 43:  17%|█▋        | 19/112 [00:00<00:01, 56.19it/s, Epoch: 43, Batch: 20,Loss: -2.147,Avg.Loss: -1.082,LR: 3.11E-04]Training epoch 43:  18%|█▊        | 20/112 [00:00<00:01, 54.90it/s, Epoch: 43, Batch: 20,Loss: -2.147,Avg.Loss: -1.082,LR: 3.11E-04]Training epoch 43:  18%|█▊        | 20/112 [00:00<00:01, 54.90it/s, Epoch: 43, Batch: 21,Loss: -1.814,Avg.Loss: -1.117,LR: 3.11E-04]Training epoch 43:  19%|█▉        | 21/112 [00:00<00:01, 54.90it/s, Epoch: 43, Batch: 22,Loss: -1.715,Avg.Loss: -1.144,LR: 3.11E-04]Training epoch 43:  20%|█▉        | 22/112 [00:00<00:01, 54.90it/s, Epoch: 43, Batch: 23,Loss: -2.499,Avg.Loss: -1.203,LR: 3.11E-04]Training epoch 43:  21%|██        | 23/112 [00:00<00:01, 54.90it/s, Epoch: 43, Batch: 24,Loss: -1.389,Avg.Loss: -1.211,LR: 3.11E-04]Training epoch 43:  21%|██▏       | 24/112 [00:00<00:01, 54.90it/s, Epoch: 43, Batch: 25,Loss: -0.113,Avg.Loss: -1.167,LR: 3.10E-04]Training epoch 43:  22%|██▏       | 25/112 [00:00<00:01, 54.90it/s, Epoch: 43, Batch: 26,Loss: -0.105,Avg.Loss: -1.126,LR: 3.10E-04]Training epoch 43:  23%|██▎       | 26/112 [00:00<00:01, 53.12it/s, Epoch: 43, Batch: 26,Loss: -0.105,Avg.Loss: -1.126,LR: 3.10E-04]Training epoch 43:  23%|██▎       | 26/112 [00:00<00:01, 53.12it/s, Epoch: 43, Batch: 27,Loss: -1.070,Avg.Loss: -1.124,LR: 3.10E-04]Training epoch 43:  24%|██▍       | 27/112 [00:00<00:01, 53.12it/s, Epoch: 43, Batch: 28,Loss: -1.733,Avg.Loss: -1.146,LR: 3.10E-04]Training epoch 43:  25%|██▌       | 28/112 [00:00<00:01, 53.12it/s, Epoch: 43, Batch: 29,Loss: -1.623,Avg.Loss: -1.162,LR: 3.10E-04]Training epoch 43:  26%|██▌       | 29/112 [00:00<00:01, 53.12it/s, Epoch: 43, Batch: 30,Loss: -1.842,Avg.Loss: -1.185,LR: 3.10E-04]Training epoch 43:  27%|██▋       | 30/112 [00:00<00:01, 53.12it/s, Epoch: 43, Batch: 31,Loss: -2.510,Avg.Loss: -1.228,LR: 3.10E-04]Training epoch 43:  28%|██▊       | 31/112 [00:00<00:01, 53.12it/s, Epoch: 43, Batch: 32,Loss: -1.519,Avg.Loss: -1.237,LR: 3.10E-04]Training epoch 43:  29%|██▊       | 32/112 [00:00<00:01, 52.81it/s, Epoch: 43, Batch: 32,Loss: -1.519,Avg.Loss: -1.237,LR: 3.10E-04]Training epoch 43:  29%|██▊       | 32/112 [00:00<00:01, 52.81it/s, Epoch: 43, Batch: 33,Loss: -0.431,Avg.Loss: -1.212,LR: 3.10E-04]Training epoch 43:  29%|██▉       | 33/112 [00:00<00:01, 52.81it/s, Epoch: 43, Batch: 34,Loss: -0.725,Avg.Loss: -1.198,LR: 3.10E-04]Training epoch 43:  30%|███       | 34/112 [00:00<00:01, 52.81it/s, Epoch: 43, Batch: 35,Loss: -1.787,Avg.Loss: -1.215,LR: 3.10E-04]Training epoch 43:  31%|███▏      | 35/112 [00:00<00:01, 52.81it/s, Epoch: 43, Batch: 36,Loss: -2.130,Avg.Loss: -1.240,LR: 3.10E-04]Training epoch 43:  32%|███▏      | 36/112 [00:00<00:01, 52.81it/s, Epoch: 43, Batch: 37,Loss: -0.655,Avg.Loss: -1.225,LR: 3.10E-04]Training epoch 43:  33%|███▎      | 37/112 [00:00<00:01, 52.81it/s, Epoch: 43, Batch: 38,Loss: -1.155,Avg.Loss: -1.223,LR: 3.10E-04]Training epoch 43:  34%|███▍      | 38/112 [00:00<00:01, 52.86it/s, Epoch: 43, Batch: 38,Loss: -1.155,Avg.Loss: -1.223,LR: 3.10E-04]Training epoch 43:  34%|███▍      | 38/112 [00:00<00:01, 52.86it/s, Epoch: 43, Batch: 39,Loss: -2.278,Avg.Loss: -1.250,LR: 3.10E-04]Training epoch 43:  35%|███▍      | 39/112 [00:00<00:01, 52.86it/s, Epoch: 43, Batch: 40,Loss: -2.184,Avg.Loss: -1.273,LR: 3.09E-04]Training epoch 43:  36%|███▌      | 40/112 [00:00<00:01, 52.86it/s, Epoch: 43, Batch: 41,Loss: -1.671,Avg.Loss: -1.283,LR: 3.09E-04]Training epoch 43:  37%|███▋      | 41/112 [00:00<00:01, 52.86it/s, Epoch: 43, Batch: 42,Loss: -1.693,Avg.Loss: -1.293,LR: 3.09E-04]Training epoch 43:  38%|███▊      | 42/112 [00:00<00:01, 52.86it/s, Epoch: 43, Batch: 43,Loss: -2.458,Avg.Loss: -1.320,LR: 3.09E-04]Training epoch 43:  38%|███▊      | 43/112 [00:00<00:01, 52.86it/s, Epoch: 43, Batch: 44,Loss: -1.835,Avg.Loss: -1.331,LR: 3.09E-04]Training epoch 43:  39%|███▉      | 44/112 [00:00<00:01, 52.90it/s, Epoch: 43, Batch: 44,Loss: -1.835,Avg.Loss: -1.331,LR: 3.09E-04]Training epoch 43:  39%|███▉      | 44/112 [00:00<00:01, 52.90it/s, Epoch: 43, Batch: 45,Loss: -1.085,Avg.Loss: -1.326,LR: 3.09E-04]Training epoch 43:  40%|████      | 45/112 [00:00<00:01, 52.90it/s, Epoch: 43, Batch: 46,Loss: -1.099,Avg.Loss: -1.321,LR: 3.09E-04]Training epoch 43:  41%|████      | 46/112 [00:00<00:01, 52.90it/s, Epoch: 43, Batch: 47,Loss: -1.746,Avg.Loss: -1.330,LR: 3.09E-04]Training epoch 43:  42%|████▏     | 47/112 [00:00<00:01, 52.90it/s, Epoch: 43, Batch: 48,Loss: -2.096,Avg.Loss: -1.346,LR: 3.09E-04]Training epoch 43:  43%|████▎     | 48/112 [00:00<00:01, 52.90it/s, Epoch: 43, Batch: 49,Loss: -1.709,Avg.Loss: -1.353,LR: 3.09E-04]Training epoch 43:  44%|████▍     | 49/112 [00:00<00:01, 52.90it/s, Epoch: 43, Batch: 50,Loss: -1.690,Avg.Loss: -1.360,LR: 3.09E-04]Training epoch 43:  45%|████▍     | 50/112 [00:00<00:01, 53.24it/s, Epoch: 43, Batch: 50,Loss: -1.690,Avg.Loss: -1.360,LR: 3.09E-04]Training epoch 43:  45%|████▍     | 50/112 [00:00<00:01, 53.24it/s, Epoch: 43, Batch: 51,Loss: -2.339,Avg.Loss: -1.379,LR: 3.09E-04]Training epoch 43:  46%|████▌     | 51/112 [00:00<00:01, 53.24it/s, Epoch: 43, Batch: 52,Loss: -1.735,Avg.Loss: -1.386,LR: 3.09E-04]Training epoch 43:  46%|████▋     | 52/112 [00:00<00:01, 53.24it/s, Epoch: 43, Batch: 53,Loss: -0.916,Avg.Loss: -1.377,LR: 3.09E-04]Training epoch 43:  47%|████▋     | 53/112 [00:01<00:01, 53.24it/s, Epoch: 43, Batch: 54,Loss: -1.352,Avg.Loss: -1.377,LR: 3.08E-04]Training epoch 43:  48%|████▊     | 54/112 [00:01<00:01, 53.24it/s, Epoch: 43, Batch: 55,Loss: -2.159,Avg.Loss: -1.391,LR: 3.08E-04]Training epoch 43:  49%|████▉     | 55/112 [00:01<00:01, 53.24it/s, Epoch: 43, Batch: 56,Loss: -1.760,Avg.Loss: -1.398,LR: 3.08E-04]Training epoch 43:  50%|█████     | 56/112 [00:01<00:01, 53.13it/s, Epoch: 43, Batch: 56,Loss: -1.760,Avg.Loss: -1.398,LR: 3.08E-04]Training epoch 43:  50%|█████     | 56/112 [00:01<00:01, 53.13it/s, Epoch: 43, Batch: 57,Loss: -0.984,Avg.Loss: -1.390,LR: 3.08E-04]Training epoch 43:  51%|█████     | 57/112 [00:01<00:01, 53.13it/s, Epoch: 43, Batch: 58,Loss: -1.070,Avg.Loss: -1.385,LR: 3.08E-04]Training epoch 43:  52%|█████▏    | 58/112 [00:01<00:01, 53.13it/s, Epoch: 43, Batch: 59,Loss: -2.299,Avg.Loss: -1.400,LR: 3.08E-04]Training epoch 43:  53%|█████▎    | 59/112 [00:01<00:00, 53.13it/s, Epoch: 43, Batch: 60,Loss: -2.304,Avg.Loss: -1.415,LR: 3.08E-04]Training epoch 43:  54%|█████▎    | 60/112 [00:01<00:00, 53.13it/s, Epoch: 43, Batch: 61,Loss: -1.673,Avg.Loss: -1.420,LR: 3.08E-04]Training epoch 43:  54%|█████▍    | 61/112 [00:01<00:00, 53.13it/s, Epoch: 43, Batch: 62,Loss: -1.662,Avg.Loss: -1.424,LR: 3.08E-04]Training epoch 43:  55%|█████▌    | 62/112 [00:01<00:00, 53.19it/s, Epoch: 43, Batch: 62,Loss: -1.662,Avg.Loss: -1.424,LR: 3.08E-04]Training epoch 43:  55%|█████▌    | 62/112 [00:01<00:00, 53.19it/s, Epoch: 43, Batch: 63,Loss: -2.428,Avg.Loss: -1.440,LR: 3.08E-04]Training epoch 43:  56%|█████▋    | 63/112 [00:01<00:00, 53.19it/s, Epoch: 43, Batch: 64,Loss: -1.480,Avg.Loss: -1.440,LR: 3.08E-04]Training epoch 43:  57%|█████▋    | 64/112 [00:01<00:00, 53.19it/s, Epoch: 43, Batch: 65,Loss: -0.995,Avg.Loss: -1.433,LR: 3.08E-04]Training epoch 43:  58%|█████▊    | 65/112 [00:01<00:00, 53.19it/s, Epoch: 43, Batch: 66,Loss: -0.839,Avg.Loss: -1.424,LR: 3.08E-04]Training epoch 43:  59%|█████▉    | 66/112 [00:01<00:00, 53.19it/s, Epoch: 43, Batch: 67,Loss: -1.588,Avg.Loss: -1.427,LR: 3.08E-04]Training epoch 43:  60%|█████▉    | 67/112 [00:01<00:00, 53.19it/s, Epoch: 43, Batch: 68,Loss: -1.803,Avg.Loss: -1.432,LR: 3.08E-04]Training epoch 43:  61%|██████    | 68/112 [00:01<00:00, 53.04it/s, Epoch: 43, Batch: 68,Loss: -1.803,Avg.Loss: -1.432,LR: 3.08E-04]Training epoch 43:  61%|██████    | 68/112 [00:01<00:00, 53.04it/s, Epoch: 43, Batch: 69,Loss: -1.312,Avg.Loss: -1.431,LR: 3.07E-04]Training epoch 43:  62%|██████▏   | 69/112 [00:01<00:00, 53.04it/s, Epoch: 43, Batch: 70,Loss: -1.530,Avg.Loss: -1.432,LR: 3.07E-04]Training epoch 43:  62%|██████▎   | 70/112 [00:01<00:00, 53.04it/s, Epoch: 43, Batch: 71,Loss: -1.848,Avg.Loss: -1.438,LR: 3.07E-04]Training epoch 43:  63%|██████▎   | 71/112 [00:01<00:00, 53.04it/s, Epoch: 43, Batch: 72,Loss: -1.997,Avg.Loss: -1.446,LR: 3.07E-04]Training epoch 43:  64%|██████▍   | 72/112 [00:01<00:00, 53.04it/s, Epoch: 43, Batch: 73,Loss: -0.877,Avg.Loss: -1.438,LR: 3.07E-04]Training epoch 43:  65%|██████▌   | 73/112 [00:01<00:00, 53.04it/s, Epoch: 43, Batch: 74,Loss: -1.576,Avg.Loss: -1.440,LR: 3.07E-04]Training epoch 43:  66%|██████▌   | 74/112 [00:01<00:00, 53.12it/s, Epoch: 43, Batch: 74,Loss: -1.576,Avg.Loss: -1.440,LR: 3.07E-04]Training epoch 43:  66%|██████▌   | 74/112 [00:01<00:00, 53.12it/s, Epoch: 43, Batch: 75,Loss: -2.287,Avg.Loss: -1.451,LR: 3.07E-04]Training epoch 43:  67%|██████▋   | 75/112 [00:01<00:00, 53.12it/s, Epoch: 43, Batch: 76,Loss: -1.789,Avg.Loss: -1.455,LR: 3.07E-04]Training epoch 43:  68%|██████▊   | 76/112 [00:01<00:00, 53.12it/s, Epoch: 43, Batch: 77,Loss: -0.734,Avg.Loss: -1.446,LR: 3.07E-04]Training epoch 43:  69%|██████▉   | 77/112 [00:01<00:00, 53.12it/s, Epoch: 43, Batch: 78,Loss: -0.537,Avg.Loss: -1.434,LR: 3.07E-04]Training epoch 43:  70%|██████▉   | 78/112 [00:01<00:00, 53.12it/s, Epoch: 43, Batch: 79,Loss: -1.512,Avg.Loss: -1.435,LR: 3.07E-04]Training epoch 43:  71%|███████   | 79/112 [00:01<00:00, 53.12it/s, Epoch: 43, Batch: 80,Loss: -2.233,Avg.Loss: -1.445,LR: 3.07E-04]Training epoch 43:  71%|███████▏  | 80/112 [00:01<00:00, 53.16it/s, Epoch: 43, Batch: 80,Loss: -2.233,Avg.Loss: -1.445,LR: 3.07E-04]Training epoch 43:  71%|███████▏  | 80/112 [00:01<00:00, 53.16it/s, Epoch: 43, Batch: 81,Loss: -1.840,Avg.Loss: -1.450,LR: 3.07E-04]Training epoch 43:  72%|███████▏  | 81/112 [00:01<00:00, 53.16it/s, Epoch: 43, Batch: 82,Loss: -2.044,Avg.Loss: -1.457,LR: 3.07E-04]Training epoch 43:  73%|███████▎  | 82/112 [00:01<00:00, 53.16it/s, Epoch: 43, Batch: 83,Loss: -2.394,Avg.Loss: -1.469,LR: 3.07E-04]Training epoch 43:  74%|███████▍  | 83/112 [00:01<00:00, 53.16it/s, Epoch: 43, Batch: 84,Loss: -2.089,Avg.Loss: -1.476,LR: 3.06E-04]Training epoch 43:  75%|███████▌  | 84/112 [00:01<00:00, 53.16it/s, Epoch: 43, Batch: 85,Loss: -2.254,Avg.Loss: -1.485,LR: 3.06E-04]Training epoch 43:  76%|███████▌  | 85/112 [00:01<00:00, 53.16it/s, Epoch: 43, Batch: 86,Loss: -1.855,Avg.Loss: -1.490,LR: 3.06E-04]Training epoch 43:  77%|███████▋  | 86/112 [00:01<00:00, 53.27it/s, Epoch: 43, Batch: 86,Loss: -1.855,Avg.Loss: -1.490,LR: 3.06E-04]Training epoch 43:  77%|███████▋  | 86/112 [00:01<00:00, 53.27it/s, Epoch: 43, Batch: 87,Loss: -2.320,Avg.Loss: -1.499,LR: 3.06E-04]Training epoch 43:  78%|███████▊  | 87/112 [00:01<00:00, 53.27it/s, Epoch: 43, Batch: 88,Loss: -2.055,Avg.Loss: -1.505,LR: 3.06E-04]Training epoch 43:  79%|███████▊  | 88/112 [00:01<00:00, 53.27it/s, Epoch: 43, Batch: 89,Loss: -2.237,Avg.Loss: -1.514,LR: 3.06E-04]Training epoch 43:  79%|███████▉  | 89/112 [00:01<00:00, 53.27it/s, Epoch: 43, Batch: 90,Loss: -1.799,Avg.Loss: -1.517,LR: 3.06E-04]Training epoch 43:  80%|████████  | 90/112 [00:01<00:00, 53.27it/s, Epoch: 43, Batch: 91,Loss: -1.916,Avg.Loss: -1.521,LR: 3.06E-04]Training epoch 43:  81%|████████▏ | 91/112 [00:01<00:00, 53.27it/s, Epoch: 43, Batch: 92,Loss: -2.270,Avg.Loss: -1.529,LR: 3.06E-04]Training epoch 43:  82%|████████▏ | 92/112 [00:01<00:00, 53.34it/s, Epoch: 43, Batch: 92,Loss: -2.270,Avg.Loss: -1.529,LR: 3.06E-04]Training epoch 43:  82%|████████▏ | 92/112 [00:01<00:00, 53.34it/s, Epoch: 43, Batch: 93,Loss: -1.454,Avg.Loss: -1.529,LR: 3.06E-04]Training epoch 43:  83%|████████▎ | 93/112 [00:01<00:00, 53.34it/s, Epoch: 43, Batch: 94,Loss: -1.974,Avg.Loss: -1.533,LR: 3.06E-04]Training epoch 43:  84%|████████▍ | 94/112 [00:01<00:00, 53.34it/s, Epoch: 43, Batch: 95,Loss: -2.282,Avg.Loss: -1.541,LR: 3.06E-04]Training epoch 43:  85%|████████▍ | 95/112 [00:01<00:00, 53.34it/s, Epoch: 43, Batch: 96,Loss: -2.577,Avg.Loss: -1.552,LR: 3.06E-04]Training epoch 43:  86%|████████▌ | 96/112 [00:01<00:00, 53.34it/s, Epoch: 43, Batch: 97,Loss: -1.624,Avg.Loss: -1.553,LR: 3.06E-04]Training epoch 43:  87%|████████▋ | 97/112 [00:01<00:00, 53.34it/s, Epoch: 43, Batch: 98,Loss: -1.576,Avg.Loss: -1.553,LR: 3.05E-04]Training epoch 43:  88%|████████▊ | 98/112 [00:01<00:00, 53.38it/s, Epoch: 43, Batch: 98,Loss: -1.576,Avg.Loss: -1.553,LR: 3.05E-04]Training epoch 43:  88%|████████▊ | 98/112 [00:01<00:00, 53.38it/s, Epoch: 43, Batch: 99,Loss: -0.773,Avg.Loss: -1.545,LR: 3.05E-04]Training epoch 43:  88%|████████▊ | 99/112 [00:01<00:00, 53.38it/s, Epoch: 43, Batch: 100,Loss: -0.713,Avg.Loss: -1.537,LR: 3.05E-04]Training epoch 43:  89%|████████▉ | 100/112 [00:01<00:00, 53.38it/s, Epoch: 43, Batch: 101,Loss: -1.438,Avg.Loss: -1.536,LR: 3.05E-04]Training epoch 43:  90%|█████████ | 101/112 [00:01<00:00, 53.38it/s, Epoch: 43, Batch: 102,Loss: -1.986,Avg.Loss: -1.540,LR: 3.05E-04]Training epoch 43:  91%|█████████ | 102/112 [00:01<00:00, 53.38it/s, Epoch: 43, Batch: 103,Loss: -1.795,Avg.Loss: -1.543,LR: 3.05E-04]Training epoch 43:  92%|█████████▏| 103/112 [00:01<00:00, 53.38it/s, Epoch: 43, Batch: 104,Loss: -1.365,Avg.Loss: -1.541,LR: 3.05E-04]Training epoch 43:  93%|█████████▎| 104/112 [00:01<00:00, 53.60it/s, Epoch: 43, Batch: 104,Loss: -1.365,Avg.Loss: -1.541,LR: 3.05E-04]Training epoch 43:  93%|█████████▎| 104/112 [00:01<00:00, 53.60it/s, Epoch: 43, Batch: 105,Loss: -1.740,Avg.Loss: -1.543,LR: 3.05E-04]Training epoch 43:  94%|█████████▍| 105/112 [00:01<00:00, 53.60it/s, Epoch: 43, Batch: 106,Loss: -2.016,Avg.Loss: -1.547,LR: 3.05E-04]Training epoch 43:  95%|█████████▍| 106/112 [00:01<00:00, 53.60it/s, Epoch: 43, Batch: 107,Loss: -1.795,Avg.Loss: -1.550,LR: 3.05E-04]Training epoch 43:  96%|█████████▌| 107/112 [00:02<00:00, 53.60it/s, Epoch: 43, Batch: 108,Loss: -2.320,Avg.Loss: -1.557,LR: 3.05E-04]Training epoch 43:  96%|█████████▋| 108/112 [00:02<00:00, 53.60it/s, Epoch: 43, Batch: 109,Loss: -2.153,Avg.Loss: -1.562,LR: 3.05E-04]Training epoch 43:  97%|█████████▋| 109/112 [00:02<00:00, 53.60it/s, Epoch: 43, Batch: 110,Loss: -1.764,Avg.Loss: -1.564,LR: 3.05E-04]Training epoch 43:  98%|█████████▊| 110/112 [00:02<00:00, 53.59it/s, Epoch: 43, Batch: 110,Loss: -1.764,Avg.Loss: -1.564,LR: 3.05E-04]Training epoch 43:  98%|█████████▊| 110/112 [00:02<00:00, 53.59it/s, Epoch: 43, Batch: 111,Loss: -1.902,Avg.Loss: -1.567,LR: 3.05E-04]Training epoch 43:  99%|█████████▉| 111/112 [00:02<00:00, 53.59it/s, Epoch: 43, Batch: 112,Loss: -1.725,Avg.Loss: -1.568,LR: 3.05E-04]Training epoch 43: 100%|██████████| 112/112 [00:02<00:00, 53.44it/s, Epoch: 43, Batch: 112,Loss: -1.725,Avg.Loss: -1.568,LR: 3.05E-04]
Training epoch 44:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 44:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 44, Batch: 1,Loss: -0.967,Avg.Loss: -0.967,LR: 3.04E-04]Training epoch 44:   1%|          | 1/112 [00:00<00:04, 24.45it/s, Epoch: 44, Batch: 2,Loss: -1.924,Avg.Loss: -1.445,LR: 3.04E-04]Training epoch 44:   2%|▏         | 2/112 [00:00<00:03, 34.02it/s, Epoch: 44, Batch: 3,Loss: -2.295,Avg.Loss: -1.728,LR: 3.04E-04]Training epoch 44:   3%|▎         | 3/112 [00:00<00:02, 39.72it/s, Epoch: 44, Batch: 4,Loss: -2.225,Avg.Loss: -1.853,LR: 3.04E-04]Training epoch 44:   4%|▎         | 4/112 [00:00<00:02, 42.84it/s, Epoch: 44, Batch: 5,Loss: -2.334,Avg.Loss: -1.949,LR: 3.04E-04]Training epoch 44:   4%|▍         | 5/112 [00:00<00:02, 45.68it/s, Epoch: 44, Batch: 6,Loss: -1.725,Avg.Loss: -1.912,LR: 3.04E-04]Training epoch 44:   5%|▌         | 6/112 [00:00<00:01, 54.70it/s, Epoch: 44, Batch: 6,Loss: -1.725,Avg.Loss: -1.912,LR: 3.04E-04]Training epoch 44:   5%|▌         | 6/112 [00:00<00:01, 54.70it/s, Epoch: 44, Batch: 7,Loss: -0.719,Avg.Loss: -1.741,LR: 3.04E-04]Training epoch 44:   6%|▋         | 7/112 [00:00<00:01, 54.70it/s, Epoch: 44, Batch: 8,Loss: -0.144,Avg.Loss: -1.542,LR: 3.04E-04]Training epoch 44:   7%|▋         | 8/112 [00:00<00:01, 54.70it/s, Epoch: 44, Batch: 9,Loss: -1.721,Avg.Loss: -1.562,LR: 3.04E-04]Training epoch 44:   8%|▊         | 9/112 [00:00<00:01, 54.70it/s, Epoch: 44, Batch: 10,Loss: -1.825,Avg.Loss: -1.588,LR: 3.04E-04]Training epoch 44:   9%|▉         | 10/112 [00:00<00:01, 54.70it/s, Epoch: 44, Batch: 11,Loss: -1.735,Avg.Loss: -1.601,LR: 3.04E-04]Training epoch 44:  10%|▉         | 11/112 [00:00<00:01, 54.70it/s, Epoch: 44, Batch: 12,Loss: -2.099,Avg.Loss: -1.643,LR: 3.04E-04]Training epoch 44:  11%|█         | 12/112 [00:00<00:01, 52.82it/s, Epoch: 44, Batch: 12,Loss: -2.099,Avg.Loss: -1.643,LR: 3.04E-04]Training epoch 44:  11%|█         | 12/112 [00:00<00:01, 52.82it/s, Epoch: 44, Batch: 13,Loss: -1.693,Avg.Loss: -1.647,LR: 3.04E-04]Training epoch 44:  12%|█▏        | 13/112 [00:00<00:01, 52.82it/s, Epoch: 44, Batch: 14,Loss: 0.124,Avg.Loss: -1.520,LR: 3.04E-04] Training epoch 44:  12%|█▎        | 14/112 [00:00<00:01, 52.82it/s, Epoch: 44, Batch: 15,Loss: -0.758,Avg.Loss: -1.469,LR: 3.04E-04]Training epoch 44:  13%|█▎        | 15/112 [00:00<00:01, 52.82it/s, Epoch: 44, Batch: 16,Loss: -2.052,Avg.Loss: -1.506,LR: 3.03E-04]Training epoch 44:  14%|█▍        | 16/112 [00:00<00:01, 52.82it/s, Epoch: 44, Batch: 17,Loss: -1.260,Avg.Loss: -1.491,LR: 3.03E-04]Training epoch 44:  15%|█▌        | 17/112 [00:00<00:01, 52.82it/s, Epoch: 44, Batch: 18,Loss: -0.140,Avg.Loss: -1.416,LR: 3.03E-04]Training epoch 44:  16%|█▌        | 18/112 [00:00<00:01, 52.64it/s, Epoch: 44, Batch: 18,Loss: -0.140,Avg.Loss: -1.416,LR: 3.03E-04]Training epoch 44:  16%|█▌        | 18/112 [00:00<00:01, 52.64it/s, Epoch: 44, Batch: 19,Loss: -1.285,Avg.Loss: -1.409,LR: 3.03E-04]Training epoch 44:  17%|█▋        | 19/112 [00:00<00:01, 52.64it/s, Epoch: 44, Batch: 20,Loss: -2.162,Avg.Loss: -1.447,LR: 3.03E-04]Training epoch 44:  18%|█▊        | 20/112 [00:00<00:01, 52.64it/s, Epoch: 44, Batch: 21,Loss: -1.555,Avg.Loss: -1.452,LR: 3.03E-04]Training epoch 44:  19%|█▉        | 21/112 [00:00<00:01, 52.64it/s, Epoch: 44, Batch: 22,Loss: -0.298,Avg.Loss: -1.400,LR: 3.03E-04]Training epoch 44:  20%|█▉        | 22/112 [00:00<00:01, 52.64it/s, Epoch: 44, Batch: 23,Loss: -0.702,Avg.Loss: -1.369,LR: 3.03E-04]Training epoch 44:  21%|██        | 23/112 [00:00<00:01, 52.64it/s, Epoch: 44, Batch: 24,Loss: -1.990,Avg.Loss: -1.395,LR: 3.03E-04]Training epoch 44:  21%|██▏       | 24/112 [00:00<00:01, 52.26it/s, Epoch: 44, Batch: 24,Loss: -1.990,Avg.Loss: -1.395,LR: 3.03E-04]Training epoch 44:  21%|██▏       | 24/112 [00:00<00:01, 52.26it/s, Epoch: 44, Batch: 25,Loss: -1.998,Avg.Loss: -1.419,LR: 3.03E-04]Training epoch 44:  22%|██▏       | 25/112 [00:00<00:01, 52.26it/s, Epoch: 44, Batch: 26,Loss: -0.894,Avg.Loss: -1.399,LR: 3.03E-04]Training epoch 44:  23%|██▎       | 26/112 [00:00<00:01, 52.26it/s, Epoch: 44, Batch: 27,Loss: -1.768,Avg.Loss: -1.413,LR: 3.03E-04]Training epoch 44:  24%|██▍       | 27/112 [00:00<00:01, 52.26it/s, Epoch: 44, Batch: 28,Loss: -2.158,Avg.Loss: -1.439,LR: 3.03E-04]Training epoch 44:  25%|██▌       | 28/112 [00:00<00:01, 52.26it/s, Epoch: 44, Batch: 29,Loss: -1.809,Avg.Loss: -1.452,LR: 3.03E-04]Training epoch 44:  26%|██▌       | 29/112 [00:00<00:01, 52.26it/s, Epoch: 44, Batch: 30,Loss: -0.733,Avg.Loss: -1.428,LR: 3.02E-04]Training epoch 44:  27%|██▋       | 30/112 [00:00<00:01, 52.65it/s, Epoch: 44, Batch: 30,Loss: -0.733,Avg.Loss: -1.428,LR: 3.02E-04]Training epoch 44:  27%|██▋       | 30/112 [00:00<00:01, 52.65it/s, Epoch: 44, Batch: 31,Loss: -1.046,Avg.Loss: -1.416,LR: 3.02E-04]Training epoch 44:  28%|██▊       | 31/112 [00:00<00:01, 52.65it/s, Epoch: 44, Batch: 32,Loss: -2.254,Avg.Loss: -1.442,LR: 3.02E-04]Training epoch 44:  29%|██▊       | 32/112 [00:00<00:01, 52.65it/s, Epoch: 44, Batch: 33,Loss: -2.263,Avg.Loss: -1.467,LR: 3.02E-04]Training epoch 44:  29%|██▉       | 33/112 [00:00<00:01, 52.65it/s, Epoch: 44, Batch: 34,Loss: -1.338,Avg.Loss: -1.463,LR: 3.02E-04]Training epoch 44:  30%|███       | 34/112 [00:00<00:01, 52.65it/s, Epoch: 44, Batch: 35,Loss: -1.959,Avg.Loss: -1.477,LR: 3.02E-04]Training epoch 44:  31%|███▏      | 35/112 [00:00<00:01, 52.65it/s, Epoch: 44, Batch: 36,Loss: -2.491,Avg.Loss: -1.505,LR: 3.02E-04]Training epoch 44:  32%|███▏      | 36/112 [00:00<00:01, 52.78it/s, Epoch: 44, Batch: 36,Loss: -2.491,Avg.Loss: -1.505,LR: 3.02E-04]Training epoch 44:  32%|███▏      | 36/112 [00:00<00:01, 52.78it/s, Epoch: 44, Batch: 37,Loss: -1.874,Avg.Loss: -1.515,LR: 3.02E-04]Training epoch 44:  33%|███▎      | 37/112 [00:00<00:01, 52.78it/s, Epoch: 44, Batch: 38,Loss: -1.026,Avg.Loss: -1.502,LR: 3.02E-04]Training epoch 44:  34%|███▍      | 38/112 [00:00<00:01, 52.78it/s, Epoch: 44, Batch: 39,Loss: -1.622,Avg.Loss: -1.506,LR: 3.02E-04]Training epoch 44:  35%|███▍      | 39/112 [00:00<00:01, 52.78it/s, Epoch: 44, Batch: 40,Loss: -2.227,Avg.Loss: -1.524,LR: 3.02E-04]Training epoch 44:  36%|███▌      | 40/112 [00:00<00:01, 52.78it/s, Epoch: 44, Batch: 41,Loss: -1.819,Avg.Loss: -1.531,LR: 3.02E-04]Training epoch 44:  37%|███▋      | 41/112 [00:00<00:01, 52.78it/s, Epoch: 44, Batch: 42,Loss: -1.061,Avg.Loss: -1.520,LR: 3.02E-04]Training epoch 44:  38%|███▊      | 42/112 [00:00<00:01, 52.91it/s, Epoch: 44, Batch: 42,Loss: -1.061,Avg.Loss: -1.520,LR: 3.02E-04]Training epoch 44:  38%|███▊      | 42/112 [00:00<00:01, 52.91it/s, Epoch: 44, Batch: 43,Loss: -1.136,Avg.Loss: -1.511,LR: 3.02E-04]Training epoch 44:  38%|███▊      | 43/112 [00:00<00:01, 52.91it/s, Epoch: 44, Batch: 44,Loss: -2.417,Avg.Loss: -1.531,LR: 3.02E-04]Training epoch 44:  39%|███▉      | 44/112 [00:00<00:01, 52.91it/s, Epoch: 44, Batch: 45,Loss: -2.179,Avg.Loss: -1.546,LR: 3.01E-04]Training epoch 44:  40%|████      | 45/112 [00:00<00:01, 52.91it/s, Epoch: 44, Batch: 46,Loss: -1.057,Avg.Loss: -1.535,LR: 3.01E-04]Training epoch 44:  41%|████      | 46/112 [00:00<00:01, 52.91it/s, Epoch: 44, Batch: 47,Loss: -1.742,Avg.Loss: -1.539,LR: 3.01E-04]Training epoch 44:  42%|████▏     | 47/112 [00:00<00:01, 52.91it/s, Epoch: 44, Batch: 48,Loss: -2.588,Avg.Loss: -1.561,LR: 3.01E-04]Training epoch 44:  43%|████▎     | 48/112 [00:00<00:01, 53.00it/s, Epoch: 44, Batch: 48,Loss: -2.588,Avg.Loss: -1.561,LR: 3.01E-04]Training epoch 44:  43%|████▎     | 48/112 [00:00<00:01, 53.00it/s, Epoch: 44, Batch: 49,Loss: -1.788,Avg.Loss: -1.566,LR: 3.01E-04]Training epoch 44:  44%|████▍     | 49/112 [00:00<00:01, 53.00it/s, Epoch: 44, Batch: 50,Loss: -1.280,Avg.Loss: -1.560,LR: 3.01E-04]Training epoch 44:  45%|████▍     | 50/112 [00:00<00:01, 53.00it/s, Epoch: 44, Batch: 51,Loss: -1.328,Avg.Loss: -1.556,LR: 3.01E-04]Training epoch 44:  46%|████▌     | 51/112 [00:00<00:01, 53.00it/s, Epoch: 44, Batch: 52,Loss: -1.777,Avg.Loss: -1.560,LR: 3.01E-04]Training epoch 44:  46%|████▋     | 52/112 [00:01<00:01, 53.00it/s, Epoch: 44, Batch: 53,Loss: -2.391,Avg.Loss: -1.576,LR: 3.01E-04]Training epoch 44:  47%|████▋     | 53/112 [00:01<00:01, 53.00it/s, Epoch: 44, Batch: 54,Loss: -1.626,Avg.Loss: -1.577,LR: 3.01E-04]Training epoch 44:  48%|████▊     | 54/112 [00:01<00:01, 52.92it/s, Epoch: 44, Batch: 54,Loss: -1.626,Avg.Loss: -1.577,LR: 3.01E-04]Training epoch 44:  48%|████▊     | 54/112 [00:01<00:01, 52.92it/s, Epoch: 44, Batch: 55,Loss: -1.427,Avg.Loss: -1.574,LR: 3.01E-04]Training epoch 44:  49%|████▉     | 55/112 [00:01<00:01, 52.92it/s, Epoch: 44, Batch: 56,Loss: -2.140,Avg.Loss: -1.584,LR: 3.01E-04]Training epoch 44:  50%|█████     | 56/112 [00:01<00:01, 52.92it/s, Epoch: 44, Batch: 57,Loss: -1.713,Avg.Loss: -1.586,LR: 3.01E-04]Training epoch 44:  51%|█████     | 57/112 [00:01<00:01, 52.92it/s, Epoch: 44, Batch: 58,Loss: -1.015,Avg.Loss: -1.576,LR: 3.01E-04]Training epoch 44:  52%|█████▏    | 58/112 [00:01<00:01, 52.92it/s, Epoch: 44, Batch: 59,Loss: -0.810,Avg.Loss: -1.563,LR: 3.00E-04]Training epoch 44:  53%|█████▎    | 59/112 [00:01<00:01, 52.92it/s, Epoch: 44, Batch: 60,Loss: -2.307,Avg.Loss: -1.576,LR: 3.00E-04]Training epoch 44:  54%|█████▎    | 60/112 [00:01<00:00, 52.79it/s, Epoch: 44, Batch: 60,Loss: -2.307,Avg.Loss: -1.576,LR: 3.00E-04]Training epoch 44:  54%|█████▎    | 60/112 [00:01<00:00, 52.79it/s, Epoch: 44, Batch: 61,Loss: -2.175,Avg.Loss: -1.586,LR: 3.00E-04]Training epoch 44:  54%|█████▍    | 61/112 [00:01<00:00, 52.79it/s, Epoch: 44, Batch: 62,Loss: -1.477,Avg.Loss: -1.584,LR: 3.00E-04]Training epoch 44:  55%|█████▌    | 62/112 [00:01<00:00, 52.79it/s, Epoch: 44, Batch: 63,Loss: -1.660,Avg.Loss: -1.585,LR: 3.00E-04]Training epoch 44:  56%|█████▋    | 63/112 [00:01<00:00, 52.79it/s, Epoch: 44, Batch: 64,Loss: -1.981,Avg.Loss: -1.591,LR: 3.00E-04]Training epoch 44:  57%|█████▋    | 64/112 [00:01<00:00, 52.79it/s, Epoch: 44, Batch: 65,Loss: -2.058,Avg.Loss: -1.598,LR: 3.00E-04]Training epoch 44:  58%|█████▊    | 65/112 [00:01<00:00, 52.79it/s, Epoch: 44, Batch: 66,Loss: -1.215,Avg.Loss: -1.593,LR: 3.00E-04]Training epoch 44:  59%|█████▉    | 66/112 [00:01<00:00, 53.51it/s, Epoch: 44, Batch: 66,Loss: -1.215,Avg.Loss: -1.593,LR: 3.00E-04]Training epoch 44:  59%|█████▉    | 66/112 [00:01<00:00, 53.51it/s, Epoch: 44, Batch: 67,Loss: -1.256,Avg.Loss: -1.588,LR: 3.00E-04]Training epoch 44:  60%|█████▉    | 67/112 [00:01<00:00, 53.51it/s, Epoch: 44, Batch: 68,Loss: -2.138,Avg.Loss: -1.596,LR: 3.00E-04]Training epoch 44:  61%|██████    | 68/112 [00:01<00:00, 53.51it/s, Epoch: 44, Batch: 69,Loss: -2.042,Avg.Loss: -1.602,LR: 3.00E-04]Training epoch 44:  62%|██████▏   | 69/112 [00:01<00:00, 53.51it/s, Epoch: 44, Batch: 70,Loss: -1.552,Avg.Loss: -1.601,LR: 3.00E-04]Training epoch 44:  62%|██████▎   | 70/112 [00:01<00:00, 53.51it/s, Epoch: 44, Batch: 71,Loss: -1.847,Avg.Loss: -1.605,LR: 3.00E-04]Training epoch 44:  63%|██████▎   | 71/112 [00:01<00:00, 53.51it/s, Epoch: 44, Batch: 72,Loss: -2.306,Avg.Loss: -1.615,LR: 3.00E-04]Training epoch 44:  64%|██████▍   | 72/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 72,Loss: -2.306,Avg.Loss: -1.615,LR: 3.00E-04]Training epoch 44:  64%|██████▍   | 72/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 73,Loss: -1.828,Avg.Loss: -1.618,LR: 3.00E-04]Training epoch 44:  65%|██████▌   | 73/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 74,Loss: -0.828,Avg.Loss: -1.607,LR: 2.99E-04]Training epoch 44:  66%|██████▌   | 74/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 75,Loss: -1.636,Avg.Loss: -1.607,LR: 2.99E-04]Training epoch 44:  67%|██████▋   | 75/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 76,Loss: -1.916,Avg.Loss: -1.611,LR: 2.99E-04]Training epoch 44:  68%|██████▊   | 76/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 77,Loss: -1.883,Avg.Loss: -1.615,LR: 2.99E-04]Training epoch 44:  69%|██████▉   | 77/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 78,Loss: -1.453,Avg.Loss: -1.613,LR: 2.99E-04]Training epoch 44:  70%|██████▉   | 78/112 [00:01<00:00, 53.54it/s, Epoch: 44, Batch: 78,Loss: -1.453,Avg.Loss: -1.613,LR: 2.99E-04]Training epoch 44:  70%|██████▉   | 78/112 [00:01<00:00, 53.54it/s, Epoch: 44, Batch: 79,Loss: -1.483,Avg.Loss: -1.611,LR: 2.99E-04]Training epoch 44:  71%|███████   | 79/112 [00:01<00:00, 53.54it/s, Epoch: 44, Batch: 80,Loss: -2.092,Avg.Loss: -1.617,LR: 2.99E-04]Training epoch 44:  71%|███████▏  | 80/112 [00:01<00:00, 53.54it/s, Epoch: 44, Batch: 81,Loss: -1.823,Avg.Loss: -1.620,LR: 2.99E-04]Training epoch 44:  72%|███████▏  | 81/112 [00:01<00:00, 53.54it/s, Epoch: 44, Batch: 82,Loss: -1.440,Avg.Loss: -1.617,LR: 2.99E-04]Training epoch 44:  73%|███████▎  | 82/112 [00:01<00:00, 53.54it/s, Epoch: 44, Batch: 83,Loss: -1.246,Avg.Loss: -1.613,LR: 2.99E-04]Training epoch 44:  74%|███████▍  | 83/112 [00:01<00:00, 53.54it/s, Epoch: 44, Batch: 84,Loss: -2.619,Avg.Loss: -1.625,LR: 2.99E-04]Training epoch 44:  75%|███████▌  | 84/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 84,Loss: -2.619,Avg.Loss: -1.625,LR: 2.99E-04]Training epoch 44:  75%|███████▌  | 84/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 85,Loss: -2.122,Avg.Loss: -1.631,LR: 2.99E-04]Training epoch 44:  76%|███████▌  | 85/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 86,Loss: -1.117,Avg.Loss: -1.625,LR: 2.99E-04]Training epoch 44:  77%|███████▋  | 86/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 87,Loss: -1.447,Avg.Loss: -1.623,LR: 2.99E-04]Training epoch 44:  78%|███████▊  | 87/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 88,Loss: -2.489,Avg.Loss: -1.633,LR: 2.98E-04]Training epoch 44:  79%|███████▊  | 88/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 89,Loss: -1.963,Avg.Loss: -1.636,LR: 2.98E-04]Training epoch 44:  79%|███████▉  | 89/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 90,Loss: -0.777,Avg.Loss: -1.627,LR: 2.98E-04]Training epoch 44:  80%|████████  | 90/112 [00:01<00:00, 53.56it/s, Epoch: 44, Batch: 90,Loss: -0.777,Avg.Loss: -1.627,LR: 2.98E-04]Training epoch 44:  80%|████████  | 90/112 [00:01<00:00, 53.56it/s, Epoch: 44, Batch: 91,Loss: -1.477,Avg.Loss: -1.625,LR: 2.98E-04]Training epoch 44:  81%|████████▏ | 91/112 [00:01<00:00, 53.56it/s, Epoch: 44, Batch: 92,Loss: -2.112,Avg.Loss: -1.630,LR: 2.98E-04]Training epoch 44:  82%|████████▏ | 92/112 [00:01<00:00, 53.56it/s, Epoch: 44, Batch: 93,Loss: -1.910,Avg.Loss: -1.633,LR: 2.98E-04]Training epoch 44:  83%|████████▎ | 93/112 [00:01<00:00, 53.56it/s, Epoch: 44, Batch: 94,Loss: -1.309,Avg.Loss: -1.630,LR: 2.98E-04]Training epoch 44:  84%|████████▍ | 94/112 [00:01<00:00, 53.56it/s, Epoch: 44, Batch: 95,Loss: -1.437,Avg.Loss: -1.628,LR: 2.98E-04]Training epoch 44:  85%|████████▍ | 95/112 [00:01<00:00, 53.56it/s, Epoch: 44, Batch: 96,Loss: -2.103,Avg.Loss: -1.633,LR: 2.98E-04]Training epoch 44:  86%|████████▌ | 96/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 96,Loss: -2.103,Avg.Loss: -1.633,LR: 2.98E-04]Training epoch 44:  86%|████████▌ | 96/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 97,Loss: -2.285,Avg.Loss: -1.640,LR: 2.98E-04]Training epoch 44:  87%|████████▋ | 97/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 98,Loss: -1.368,Avg.Loss: -1.637,LR: 2.98E-04]Training epoch 44:  88%|████████▊ | 98/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 99,Loss: -1.964,Avg.Loss: -1.640,LR: 2.98E-04]Training epoch 44:  88%|████████▊ | 99/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 100,Loss: -2.126,Avg.Loss: -1.645,LR: 2.98E-04]Training epoch 44:  89%|████████▉ | 100/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 101,Loss: -2.006,Avg.Loss: -1.649,LR: 2.98E-04]Training epoch 44:  90%|█████████ | 101/112 [00:01<00:00, 53.61it/s, Epoch: 44, Batch: 102,Loss: -0.863,Avg.Loss: -1.641,LR: 2.98E-04]Training epoch 44:  91%|█████████ | 102/112 [00:01<00:00, 53.66it/s, Epoch: 44, Batch: 102,Loss: -0.863,Avg.Loss: -1.641,LR: 2.98E-04]Training epoch 44:  91%|█████████ | 102/112 [00:01<00:00, 53.66it/s, Epoch: 44, Batch: 103,Loss: -1.196,Avg.Loss: -1.637,LR: 2.97E-04]Training epoch 44:  92%|█████████▏| 103/112 [00:01<00:00, 53.66it/s, Epoch: 44, Batch: 104,Loss: -2.222,Avg.Loss: -1.642,LR: 2.97E-04]Training epoch 44:  93%|█████████▎| 104/112 [00:01<00:00, 53.66it/s, Epoch: 44, Batch: 105,Loss: -2.103,Avg.Loss: -1.647,LR: 2.97E-04]Training epoch 44:  94%|█████████▍| 105/112 [00:01<00:00, 53.66it/s, Epoch: 44, Batch: 106,Loss: -1.804,Avg.Loss: -1.648,LR: 2.97E-04]Training epoch 44:  95%|█████████▍| 106/112 [00:02<00:00, 53.66it/s, Epoch: 44, Batch: 107,Loss: -2.112,Avg.Loss: -1.652,LR: 2.97E-04]Training epoch 44:  96%|█████████▌| 107/112 [00:02<00:00, 53.66it/s, Epoch: 44, Batch: 108,Loss: -2.201,Avg.Loss: -1.658,LR: 2.97E-04]Training epoch 44:  96%|█████████▋| 108/112 [00:02<00:00, 53.57it/s, Epoch: 44, Batch: 108,Loss: -2.201,Avg.Loss: -1.658,LR: 2.97E-04]Training epoch 44:  96%|█████████▋| 108/112 [00:02<00:00, 53.57it/s, Epoch: 44, Batch: 109,Loss: -1.733,Avg.Loss: -1.658,LR: 2.97E-04]Training epoch 44:  97%|█████████▋| 109/112 [00:02<00:00, 53.57it/s, Epoch: 44, Batch: 110,Loss: -0.949,Avg.Loss: -1.652,LR: 2.97E-04]Training epoch 44:  98%|█████████▊| 110/112 [00:02<00:00, 53.57it/s, Epoch: 44, Batch: 111,Loss: -1.462,Avg.Loss: -1.650,LR: 2.97E-04]Training epoch 44:  99%|█████████▉| 111/112 [00:02<00:00, 53.57it/s, Epoch: 44, Batch: 112,Loss: -1.609,Avg.Loss: -1.650,LR: 2.97E-04]Training epoch 44: 100%|██████████| 112/112 [00:02<00:00, 53.18it/s, Epoch: 44, Batch: 112,Loss: -1.609,Avg.Loss: -1.650,LR: 2.97E-04]
Training epoch 45:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 45:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 45, Batch: 1,Loss: -2.281,Avg.Loss: -2.281,LR: 2.97E-04]Training epoch 45:   1%|          | 1/112 [00:00<00:03, 28.26it/s, Epoch: 45, Batch: 2,Loss: -1.436,Avg.Loss: -1.858,LR: 2.97E-04]Training epoch 45:   2%|▏         | 2/112 [00:00<00:02, 37.82it/s, Epoch: 45, Batch: 3,Loss: -1.516,Avg.Loss: -1.744,LR: 2.97E-04]Training epoch 45:   3%|▎         | 3/112 [00:00<00:02, 42.80it/s, Epoch: 45, Batch: 4,Loss: -2.507,Avg.Loss: -1.935,LR: 2.97E-04]Training epoch 45:   4%|▎         | 4/112 [00:00<00:02, 45.99it/s, Epoch: 45, Batch: 5,Loss: -1.934,Avg.Loss: -1.935,LR: 2.97E-04]Training epoch 45:   4%|▍         | 5/112 [00:00<00:02, 48.32it/s, Epoch: 45, Batch: 6,Loss: -0.955,Avg.Loss: -1.771,LR: 2.96E-04]Training epoch 45:   5%|▌         | 6/112 [00:00<00:01, 57.90it/s, Epoch: 45, Batch: 6,Loss: -0.955,Avg.Loss: -1.771,LR: 2.96E-04]Training epoch 45:   5%|▌         | 6/112 [00:00<00:01, 57.90it/s, Epoch: 45, Batch: 7,Loss: -1.313,Avg.Loss: -1.706,LR: 2.96E-04]Training epoch 45:   6%|▋         | 7/112 [00:00<00:01, 57.90it/s, Epoch: 45, Batch: 8,Loss: -1.716,Avg.Loss: -1.707,LR: 2.96E-04]Training epoch 45:   7%|▋         | 8/112 [00:00<00:01, 57.90it/s, Epoch: 45, Batch: 9,Loss: -2.210,Avg.Loss: -1.763,LR: 2.96E-04]Training epoch 45:   8%|▊         | 9/112 [00:00<00:01, 57.90it/s, Epoch: 45, Batch: 10,Loss: -1.683,Avg.Loss: -1.755,LR: 2.96E-04]Training epoch 45:   9%|▉         | 10/112 [00:00<00:01, 57.90it/s, Epoch: 45, Batch: 11,Loss: -0.777,Avg.Loss: -1.666,LR: 2.96E-04]Training epoch 45:  10%|▉         | 11/112 [00:00<00:01, 57.90it/s, Epoch: 45, Batch: 12,Loss: -1.685,Avg.Loss: -1.668,LR: 2.96E-04]Training epoch 45:  11%|█         | 12/112 [00:00<00:01, 55.10it/s, Epoch: 45, Batch: 12,Loss: -1.685,Avg.Loss: -1.668,LR: 2.96E-04]Training epoch 45:  11%|█         | 12/112 [00:00<00:01, 55.10it/s, Epoch: 45, Batch: 13,Loss: -2.430,Avg.Loss: -1.726,LR: 2.96E-04]Training epoch 45:  12%|█▏        | 13/112 [00:00<00:01, 55.10it/s, Epoch: 45, Batch: 14,Loss: -1.962,Avg.Loss: -1.743,LR: 2.96E-04]Training epoch 45:  12%|█▎        | 14/112 [00:00<00:01, 55.10it/s, Epoch: 45, Batch: 15,Loss: -0.397,Avg.Loss: -1.653,LR: 2.96E-04]Training epoch 45:  13%|█▎        | 15/112 [00:00<00:01, 55.10it/s, Epoch: 45, Batch: 16,Loss: 0.097,Avg.Loss: -1.544,LR: 2.96E-04] Training epoch 45:  14%|█▍        | 16/112 [00:00<00:01, 55.10it/s, Epoch: 45, Batch: 17,Loss: -0.859,Avg.Loss: -1.504,LR: 2.96E-04]Training epoch 45:  15%|█▌        | 17/112 [00:00<00:01, 55.10it/s, Epoch: 45, Batch: 18,Loss: -1.499,Avg.Loss: -1.503,LR: 2.96E-04]Training epoch 45:  16%|█▌        | 18/112 [00:00<00:01, 54.12it/s, Epoch: 45, Batch: 18,Loss: -1.499,Avg.Loss: -1.503,LR: 2.96E-04]Training epoch 45:  16%|█▌        | 18/112 [00:00<00:01, 54.12it/s, Epoch: 45, Batch: 19,Loss: -1.934,Avg.Loss: -1.526,LR: 2.96E-04]Training epoch 45:  17%|█▋        | 19/112 [00:00<00:01, 54.12it/s, Epoch: 45, Batch: 20,Loss: -1.779,Avg.Loss: -1.539,LR: 2.95E-04]Training epoch 45:  18%|█▊        | 20/112 [00:00<00:01, 54.12it/s, Epoch: 45, Batch: 21,Loss: -1.344,Avg.Loss: -1.529,LR: 2.95E-04]Training epoch 45:  19%|█▉        | 21/112 [00:00<00:01, 54.12it/s, Epoch: 45, Batch: 22,Loss: -1.213,Avg.Loss: -1.515,LR: 2.95E-04]Training epoch 45:  20%|█▉        | 22/112 [00:00<00:01, 54.12it/s, Epoch: 45, Batch: 23,Loss: -1.160,Avg.Loss: -1.500,LR: 2.95E-04]Training epoch 45:  21%|██        | 23/112 [00:00<00:01, 54.12it/s, Epoch: 45, Batch: 24,Loss: -1.721,Avg.Loss: -1.509,LR: 2.95E-04]Training epoch 45:  21%|██▏       | 24/112 [00:00<00:01, 52.75it/s, Epoch: 45, Batch: 24,Loss: -1.721,Avg.Loss: -1.509,LR: 2.95E-04]Training epoch 45:  21%|██▏       | 24/112 [00:00<00:01, 52.75it/s, Epoch: 45, Batch: 25,Loss: -1.933,Avg.Loss: -1.526,LR: 2.95E-04]Training epoch 45:  22%|██▏       | 25/112 [00:00<00:01, 52.75it/s, Epoch: 45, Batch: 26,Loss: -2.334,Avg.Loss: -1.557,LR: 2.95E-04]Training epoch 45:  23%|██▎       | 26/112 [00:00<00:01, 52.75it/s, Epoch: 45, Batch: 27,Loss: -1.889,Avg.Loss: -1.569,LR: 2.95E-04]Training epoch 45:  24%|██▍       | 27/112 [00:00<00:01, 52.75it/s, Epoch: 45, Batch: 28,Loss: -1.832,Avg.Loss: -1.579,LR: 2.95E-04]Training epoch 45:  25%|██▌       | 28/112 [00:00<00:01, 52.75it/s, Epoch: 45, Batch: 29,Loss: -2.043,Avg.Loss: -1.595,LR: 2.95E-04]Training epoch 45:  26%|██▌       | 29/112 [00:00<00:01, 52.75it/s, Epoch: 45, Batch: 30,Loss: -1.565,Avg.Loss: -1.594,LR: 2.95E-04]Training epoch 45:  27%|██▋       | 30/112 [00:00<00:01, 52.98it/s, Epoch: 45, Batch: 30,Loss: -1.565,Avg.Loss: -1.594,LR: 2.95E-04]Training epoch 45:  27%|██▋       | 30/112 [00:00<00:01, 52.98it/s, Epoch: 45, Batch: 31,Loss: -2.065,Avg.Loss: -1.609,LR: 2.95E-04]Training epoch 45:  28%|██▊       | 31/112 [00:00<00:01, 52.98it/s, Epoch: 45, Batch: 32,Loss: -1.917,Avg.Loss: -1.618,LR: 2.95E-04]Training epoch 45:  29%|██▊       | 32/112 [00:00<00:01, 52.98it/s, Epoch: 45, Batch: 33,Loss: -1.658,Avg.Loss: -1.620,LR: 2.95E-04]Training epoch 45:  29%|██▉       | 33/112 [00:00<00:01, 52.98it/s, Epoch: 45, Batch: 34,Loss: -1.885,Avg.Loss: -1.627,LR: 2.95E-04]Training epoch 45:  30%|███       | 34/112 [00:00<00:01, 52.98it/s, Epoch: 45, Batch: 35,Loss: -1.580,Avg.Loss: -1.626,LR: 2.94E-04]Training epoch 45:  31%|███▏      | 35/112 [00:00<00:01, 52.98it/s, Epoch: 45, Batch: 36,Loss: -1.468,Avg.Loss: -1.622,LR: 2.94E-04]Training epoch 45:  32%|███▏      | 36/112 [00:00<00:01, 53.10it/s, Epoch: 45, Batch: 36,Loss: -1.468,Avg.Loss: -1.622,LR: 2.94E-04]Training epoch 45:  32%|███▏      | 36/112 [00:00<00:01, 53.10it/s, Epoch: 45, Batch: 37,Loss: -1.669,Avg.Loss: -1.623,LR: 2.94E-04]Training epoch 45:  33%|███▎      | 37/112 [00:00<00:01, 53.10it/s, Epoch: 45, Batch: 38,Loss: -1.726,Avg.Loss: -1.626,LR: 2.94E-04]Training epoch 45:  34%|███▍      | 38/112 [00:00<00:01, 53.10it/s, Epoch: 45, Batch: 39,Loss: -1.624,Avg.Loss: -1.626,LR: 2.94E-04]Training epoch 45:  35%|███▍      | 39/112 [00:00<00:01, 53.10it/s, Epoch: 45, Batch: 40,Loss: -1.796,Avg.Loss: -1.630,LR: 2.94E-04]Training epoch 45:  36%|███▌      | 40/112 [00:00<00:01, 53.10it/s, Epoch: 45, Batch: 41,Loss: -2.149,Avg.Loss: -1.643,LR: 2.94E-04]Training epoch 45:  37%|███▋      | 41/112 [00:00<00:01, 53.10it/s, Epoch: 45, Batch: 42,Loss: -1.928,Avg.Loss: -1.649,LR: 2.94E-04]Training epoch 45:  38%|███▊      | 42/112 [00:00<00:01, 53.14it/s, Epoch: 45, Batch: 42,Loss: -1.928,Avg.Loss: -1.649,LR: 2.94E-04]Training epoch 45:  38%|███▊      | 42/112 [00:00<00:01, 53.14it/s, Epoch: 45, Batch: 43,Loss: -1.746,Avg.Loss: -1.652,LR: 2.94E-04]Training epoch 45:  38%|███▊      | 43/112 [00:00<00:01, 53.14it/s, Epoch: 45, Batch: 44,Loss: -1.866,Avg.Loss: -1.656,LR: 2.94E-04]Training epoch 45:  39%|███▉      | 44/112 [00:00<00:01, 53.14it/s, Epoch: 45, Batch: 45,Loss: -1.290,Avg.Loss: -1.648,LR: 2.94E-04]Training epoch 45:  40%|████      | 45/112 [00:00<00:01, 53.14it/s, Epoch: 45, Batch: 46,Loss: -1.933,Avg.Loss: -1.655,LR: 2.94E-04]Training epoch 45:  41%|████      | 46/112 [00:00<00:01, 53.14it/s, Epoch: 45, Batch: 47,Loss: -1.833,Avg.Loss: -1.658,LR: 2.94E-04]Training epoch 45:  42%|████▏     | 47/112 [00:00<00:01, 53.14it/s, Epoch: 45, Batch: 48,Loss: -1.959,Avg.Loss: -1.665,LR: 2.94E-04]Training epoch 45:  43%|████▎     | 48/112 [00:00<00:01, 53.26it/s, Epoch: 45, Batch: 48,Loss: -1.959,Avg.Loss: -1.665,LR: 2.94E-04]Training epoch 45:  43%|████▎     | 48/112 [00:00<00:01, 53.26it/s, Epoch: 45, Batch: 49,Loss: -2.117,Avg.Loss: -1.674,LR: 2.93E-04]Training epoch 45:  44%|████▍     | 49/112 [00:00<00:01, 53.26it/s, Epoch: 45, Batch: 50,Loss: -2.031,Avg.Loss: -1.681,LR: 2.93E-04]Training epoch 45:  45%|████▍     | 50/112 [00:00<00:01, 53.26it/s, Epoch: 45, Batch: 51,Loss: -1.675,Avg.Loss: -1.681,LR: 2.93E-04]Training epoch 45:  46%|████▌     | 51/112 [00:00<00:01, 53.26it/s, Epoch: 45, Batch: 52,Loss: -1.981,Avg.Loss: -1.687,LR: 2.93E-04]Training epoch 45:  46%|████▋     | 52/112 [00:00<00:01, 53.26it/s, Epoch: 45, Batch: 53,Loss: -2.463,Avg.Loss: -1.701,LR: 2.93E-04]Training epoch 45:  47%|████▋     | 53/112 [00:01<00:01, 53.26it/s, Epoch: 45, Batch: 54,Loss: -1.706,Avg.Loss: -1.701,LR: 2.93E-04]Training epoch 45:  48%|████▊     | 54/112 [00:01<00:01, 53.35it/s, Epoch: 45, Batch: 54,Loss: -1.706,Avg.Loss: -1.701,LR: 2.93E-04]Training epoch 45:  48%|████▊     | 54/112 [00:01<00:01, 53.35it/s, Epoch: 45, Batch: 55,Loss: -2.195,Avg.Loss: -1.710,LR: 2.93E-04]Training epoch 45:  49%|████▉     | 55/112 [00:01<00:01, 53.35it/s, Epoch: 45, Batch: 56,Loss: -2.157,Avg.Loss: -1.718,LR: 2.93E-04]Training epoch 45:  50%|█████     | 56/112 [00:01<00:01, 53.35it/s, Epoch: 45, Batch: 57,Loss: -1.985,Avg.Loss: -1.723,LR: 2.93E-04]Training epoch 45:  51%|█████     | 57/112 [00:01<00:01, 53.35it/s, Epoch: 45, Batch: 58,Loss: -2.173,Avg.Loss: -1.731,LR: 2.93E-04]Training epoch 45:  52%|█████▏    | 58/112 [00:01<00:01, 53.35it/s, Epoch: 45, Batch: 59,Loss: -2.100,Avg.Loss: -1.737,LR: 2.93E-04]Training epoch 45:  53%|█████▎    | 59/112 [00:01<00:00, 53.35it/s, Epoch: 45, Batch: 60,Loss: -1.683,Avg.Loss: -1.736,LR: 2.93E-04]Training epoch 45:  54%|█████▎    | 60/112 [00:01<00:00, 53.38it/s, Epoch: 45, Batch: 60,Loss: -1.683,Avg.Loss: -1.736,LR: 2.93E-04]Training epoch 45:  54%|█████▎    | 60/112 [00:01<00:00, 53.38it/s, Epoch: 45, Batch: 61,Loss: -2.283,Avg.Loss: -1.745,LR: 2.93E-04]Training epoch 45:  54%|█████▍    | 61/112 [00:01<00:00, 53.38it/s, Epoch: 45, Batch: 62,Loss: -2.355,Avg.Loss: -1.755,LR: 2.93E-04]Training epoch 45:  55%|█████▌    | 62/112 [00:01<00:00, 53.38it/s, Epoch: 45, Batch: 63,Loss: -1.995,Avg.Loss: -1.759,LR: 2.92E-04]Training epoch 45:  56%|█████▋    | 63/112 [00:01<00:00, 53.38it/s, Epoch: 45, Batch: 64,Loss: -2.156,Avg.Loss: -1.765,LR: 2.92E-04]Training epoch 45:  57%|█████▋    | 64/112 [00:01<00:00, 53.38it/s, Epoch: 45, Batch: 65,Loss: -2.045,Avg.Loss: -1.769,LR: 2.92E-04]Training epoch 45:  58%|█████▊    | 65/112 [00:01<00:00, 53.38it/s, Epoch: 45, Batch: 66,Loss: -2.099,Avg.Loss: -1.774,LR: 2.92E-04]Training epoch 45:  59%|█████▉    | 66/112 [00:01<00:00, 53.35it/s, Epoch: 45, Batch: 66,Loss: -2.099,Avg.Loss: -1.774,LR: 2.92E-04]Training epoch 45:  59%|█████▉    | 66/112 [00:01<00:00, 53.35it/s, Epoch: 45, Batch: 67,Loss: -2.229,Avg.Loss: -1.781,LR: 2.92E-04]Training epoch 45:  60%|█████▉    | 67/112 [00:01<00:00, 53.35it/s, Epoch: 45, Batch: 68,Loss: -2.053,Avg.Loss: -1.785,LR: 2.92E-04]Training epoch 45:  61%|██████    | 68/112 [00:01<00:00, 53.35it/s, Epoch: 45, Batch: 69,Loss: -2.002,Avg.Loss: -1.788,LR: 2.92E-04]Training epoch 45:  62%|██████▏   | 69/112 [00:01<00:00, 53.35it/s, Epoch: 45, Batch: 70,Loss: -2.601,Avg.Loss: -1.800,LR: 2.92E-04]Training epoch 45:  62%|██████▎   | 70/112 [00:01<00:00, 53.35it/s, Epoch: 45, Batch: 71,Loss: -2.276,Avg.Loss: -1.806,LR: 2.92E-04]Training epoch 45:  63%|██████▎   | 71/112 [00:01<00:00, 53.35it/s, Epoch: 45, Batch: 72,Loss: -1.659,Avg.Loss: -1.804,LR: 2.92E-04]Training epoch 45:  64%|██████▍   | 72/112 [00:01<00:00, 53.39it/s, Epoch: 45, Batch: 72,Loss: -1.659,Avg.Loss: -1.804,LR: 2.92E-04]Training epoch 45:  64%|██████▍   | 72/112 [00:01<00:00, 53.39it/s, Epoch: 45, Batch: 73,Loss: -1.917,Avg.Loss: -1.806,LR: 2.92E-04]Training epoch 45:  65%|██████▌   | 73/112 [00:01<00:00, 53.39it/s, Epoch: 45, Batch: 74,Loss: -2.392,Avg.Loss: -1.814,LR: 2.92E-04]Training epoch 45:  66%|██████▌   | 74/112 [00:01<00:00, 53.39it/s, Epoch: 45, Batch: 75,Loss: -1.964,Avg.Loss: -1.816,LR: 2.92E-04]Training epoch 45:  67%|██████▋   | 75/112 [00:01<00:00, 53.39it/s, Epoch: 45, Batch: 76,Loss: -2.583,Avg.Loss: -1.826,LR: 2.92E-04]Training epoch 45:  68%|██████▊   | 76/112 [00:01<00:00, 53.39it/s, Epoch: 45, Batch: 77,Loss: -2.272,Avg.Loss: -1.832,LR: 2.92E-04]Training epoch 45:  69%|██████▉   | 77/112 [00:01<00:00, 53.39it/s, Epoch: 45, Batch: 78,Loss: -1.844,Avg.Loss: -1.832,LR: 2.91E-04]Training epoch 45:  70%|██████▉   | 78/112 [00:01<00:00, 53.93it/s, Epoch: 45, Batch: 78,Loss: -1.844,Avg.Loss: -1.832,LR: 2.91E-04]Training epoch 45:  70%|██████▉   | 78/112 [00:01<00:00, 53.93it/s, Epoch: 45, Batch: 79,Loss: -2.244,Avg.Loss: -1.837,LR: 2.91E-04]Training epoch 45:  71%|███████   | 79/112 [00:01<00:00, 53.93it/s, Epoch: 45, Batch: 80,Loss: -2.318,Avg.Loss: -1.843,LR: 2.91E-04]Training epoch 45:  71%|███████▏  | 80/112 [00:01<00:00, 53.93it/s, Epoch: 45, Batch: 81,Loss: -1.944,Avg.Loss: -1.844,LR: 2.91E-04]Training epoch 45:  72%|███████▏  | 81/112 [00:01<00:00, 53.93it/s, Epoch: 45, Batch: 82,Loss: -2.556,Avg.Loss: -1.853,LR: 2.91E-04]Training epoch 45:  73%|███████▎  | 82/112 [00:01<00:00, 53.93it/s, Epoch: 45, Batch: 83,Loss: -2.163,Avg.Loss: -1.857,LR: 2.91E-04]Training epoch 45:  74%|███████▍  | 83/112 [00:01<00:00, 53.93it/s, Epoch: 45, Batch: 84,Loss: -1.766,Avg.Loss: -1.856,LR: 2.91E-04]Training epoch 45:  75%|███████▌  | 84/112 [00:01<00:00, 53.69it/s, Epoch: 45, Batch: 84,Loss: -1.766,Avg.Loss: -1.856,LR: 2.91E-04]Training epoch 45:  75%|███████▌  | 84/112 [00:01<00:00, 53.69it/s, Epoch: 45, Batch: 85,Loss: -2.266,Avg.Loss: -1.861,LR: 2.91E-04]Training epoch 45:  76%|███████▌  | 85/112 [00:01<00:00, 53.69it/s, Epoch: 45, Batch: 86,Loss: -2.268,Avg.Loss: -1.865,LR: 2.91E-04]Training epoch 45:  77%|███████▋  | 86/112 [00:01<00:00, 53.69it/s, Epoch: 45, Batch: 87,Loss: -1.967,Avg.Loss: -1.866,LR: 2.91E-04]Training epoch 45:  78%|███████▊  | 87/112 [00:01<00:00, 53.69it/s, Epoch: 45, Batch: 88,Loss: -2.386,Avg.Loss: -1.872,LR: 2.91E-04]Training epoch 45:  79%|███████▊  | 88/112 [00:01<00:00, 53.69it/s, Epoch: 45, Batch: 89,Loss: -2.321,Avg.Loss: -1.877,LR: 2.91E-04]Training epoch 45:  79%|███████▉  | 89/112 [00:01<00:00, 53.69it/s, Epoch: 45, Batch: 90,Loss: -1.882,Avg.Loss: -1.877,LR: 2.91E-04]Training epoch 45:  80%|████████  | 90/112 [00:01<00:00, 53.78it/s, Epoch: 45, Batch: 90,Loss: -1.882,Avg.Loss: -1.877,LR: 2.91E-04]Training epoch 45:  80%|████████  | 90/112 [00:01<00:00, 53.78it/s, Epoch: 45, Batch: 91,Loss: -1.942,Avg.Loss: -1.878,LR: 2.91E-04]Training epoch 45:  81%|████████▏ | 91/112 [00:01<00:00, 53.78it/s, Epoch: 45, Batch: 92,Loss: -2.482,Avg.Loss: -1.885,LR: 2.90E-04]Training epoch 45:  82%|████████▏ | 92/112 [00:01<00:00, 53.78it/s, Epoch: 45, Batch: 93,Loss: -1.475,Avg.Loss: -1.880,LR: 2.90E-04]Training epoch 45:  83%|████████▎ | 93/112 [00:01<00:00, 53.78it/s, Epoch: 45, Batch: 94,Loss: -2.486,Avg.Loss: -1.887,LR: 2.90E-04]Training epoch 45:  84%|████████▍ | 94/112 [00:01<00:00, 53.78it/s, Epoch: 45, Batch: 95,Loss: -2.211,Avg.Loss: -1.890,LR: 2.90E-04]Training epoch 45:  85%|████████▍ | 95/112 [00:01<00:00, 53.78it/s, Epoch: 45, Batch: 96,Loss: -1.967,Avg.Loss: -1.891,LR: 2.90E-04]Training epoch 45:  86%|████████▌ | 96/112 [00:01<00:00, 53.87it/s, Epoch: 45, Batch: 96,Loss: -1.967,Avg.Loss: -1.891,LR: 2.90E-04]Training epoch 45:  86%|████████▌ | 96/112 [00:01<00:00, 53.87it/s, Epoch: 45, Batch: 97,Loss: -2.343,Avg.Loss: -1.896,LR: 2.90E-04]Training epoch 45:  87%|████████▋ | 97/112 [00:01<00:00, 53.87it/s, Epoch: 45, Batch: 98,Loss: -2.243,Avg.Loss: -1.899,LR: 2.90E-04]Training epoch 45:  88%|████████▊ | 98/112 [00:01<00:00, 53.87it/s, Epoch: 45, Batch: 99,Loss: -1.858,Avg.Loss: -1.899,LR: 2.90E-04]Training epoch 45:  88%|████████▊ | 99/112 [00:01<00:00, 53.87it/s, Epoch: 45, Batch: 100,Loss: -2.718,Avg.Loss: -1.907,LR: 2.90E-04]Training epoch 45:  89%|████████▉ | 100/112 [00:01<00:00, 53.87it/s, Epoch: 45, Batch: 101,Loss: -2.281,Avg.Loss: -1.911,LR: 2.90E-04]Training epoch 45:  90%|█████████ | 101/112 [00:01<00:00, 53.87it/s, Epoch: 45, Batch: 102,Loss: -2.206,Avg.Loss: -1.914,LR: 2.90E-04]Training epoch 45:  91%|█████████ | 102/112 [00:01<00:00, 53.68it/s, Epoch: 45, Batch: 102,Loss: -2.206,Avg.Loss: -1.914,LR: 2.90E-04]Training epoch 45:  91%|█████████ | 102/112 [00:01<00:00, 53.68it/s, Epoch: 45, Batch: 103,Loss: -2.427,Avg.Loss: -1.919,LR: 2.90E-04]Training epoch 45:  92%|█████████▏| 103/112 [00:01<00:00, 53.68it/s, Epoch: 45, Batch: 104,Loss: -2.132,Avg.Loss: -1.921,LR: 2.90E-04]Training epoch 45:  93%|█████████▎| 104/112 [00:01<00:00, 53.68it/s, Epoch: 45, Batch: 105,Loss: -1.558,Avg.Loss: -1.917,LR: 2.90E-04]Training epoch 45:  94%|█████████▍| 105/112 [00:01<00:00, 53.68it/s, Epoch: 45, Batch: 106,Loss: -2.094,Avg.Loss: -1.919,LR: 2.90E-04]Training epoch 45:  95%|█████████▍| 106/112 [00:01<00:00, 53.68it/s, Epoch: 45, Batch: 107,Loss: -2.359,Avg.Loss: -1.923,LR: 2.89E-04]Training epoch 45:  96%|█████████▌| 107/112 [00:02<00:00, 53.68it/s, Epoch: 45, Batch: 108,Loss: -1.961,Avg.Loss: -1.923,LR: 2.89E-04]Training epoch 45:  96%|█████████▋| 108/112 [00:02<00:00, 53.72it/s, Epoch: 45, Batch: 108,Loss: -1.961,Avg.Loss: -1.923,LR: 2.89E-04]Training epoch 45:  96%|█████████▋| 108/112 [00:02<00:00, 53.72it/s, Epoch: 45, Batch: 109,Loss: -2.541,Avg.Loss: -1.929,LR: 2.89E-04]Training epoch 45:  97%|█████████▋| 109/112 [00:02<00:00, 53.72it/s, Epoch: 45, Batch: 110,Loss: -2.184,Avg.Loss: -1.931,LR: 2.89E-04]Training epoch 45:  98%|█████████▊| 110/112 [00:02<00:00, 53.72it/s, Epoch: 45, Batch: 111,Loss: -1.890,Avg.Loss: -1.931,LR: 2.89E-04]Training epoch 45:  99%|█████████▉| 111/112 [00:02<00:00, 53.72it/s, Epoch: 45, Batch: 112,Loss: -3.952,Avg.Loss: -1.949,LR: 2.89E-04]Training epoch 45: 100%|██████████| 112/112 [00:02<00:00, 53.55it/s, Epoch: 45, Batch: 112,Loss: -3.952,Avg.Loss: -1.949,LR: 2.89E-04]
Training epoch 46:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 46:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 46, Batch: 1,Loss: -2.469,Avg.Loss: -2.469,LR: 2.89E-04]Training epoch 46:   1%|          | 1/112 [00:00<00:04, 23.89it/s, Epoch: 46, Batch: 2,Loss: -2.229,Avg.Loss: -2.349,LR: 2.89E-04]Training epoch 46:   2%|▏         | 2/112 [00:00<00:03, 34.49it/s, Epoch: 46, Batch: 3,Loss: -1.884,Avg.Loss: -2.194,LR: 2.89E-04]Training epoch 46:   3%|▎         | 3/112 [00:00<00:02, 41.18it/s, Epoch: 46, Batch: 4,Loss: -0.887,Avg.Loss: -1.867,LR: 2.89E-04]Training epoch 46:   4%|▎         | 4/112 [00:00<00:02, 43.89it/s, Epoch: 46, Batch: 5,Loss: -0.754,Avg.Loss: -1.645,LR: 2.89E-04]Training epoch 46:   4%|▍         | 5/112 [00:00<00:02, 45.38it/s, Epoch: 46, Batch: 6,Loss: -2.286,Avg.Loss: -1.752,LR: 2.89E-04]Training epoch 46:   5%|▌         | 6/112 [00:00<00:01, 54.36it/s, Epoch: 46, Batch: 6,Loss: -2.286,Avg.Loss: -1.752,LR: 2.89E-04]Training epoch 46:   5%|▌         | 6/112 [00:00<00:01, 54.36it/s, Epoch: 46, Batch: 7,Loss: -2.026,Avg.Loss: -1.791,LR: 2.89E-04]Training epoch 46:   6%|▋         | 7/112 [00:00<00:01, 54.36it/s, Epoch: 46, Batch: 8,Loss: -0.700,Avg.Loss: -1.654,LR: 2.89E-04]Training epoch 46:   7%|▋         | 8/112 [00:00<00:01, 54.36it/s, Epoch: 46, Batch: 9,Loss: -1.863,Avg.Loss: -1.678,LR: 2.88E-04]Training epoch 46:   8%|▊         | 9/112 [00:00<00:01, 54.36it/s, Epoch: 46, Batch: 10,Loss: -1.518,Avg.Loss: -1.662,LR: 2.88E-04]Training epoch 46:   9%|▉         | 10/112 [00:00<00:01, 54.36it/s, Epoch: 46, Batch: 11,Loss: -2.264,Avg.Loss: -1.716,LR: 2.88E-04]Training epoch 46:  10%|▉         | 11/112 [00:00<00:01, 54.36it/s, Epoch: 46, Batch: 12,Loss: -2.234,Avg.Loss: -1.759,LR: 2.88E-04]Training epoch 46:  11%|█         | 12/112 [00:00<00:01, 53.56it/s, Epoch: 46, Batch: 12,Loss: -2.234,Avg.Loss: -1.759,LR: 2.88E-04]Training epoch 46:  11%|█         | 12/112 [00:00<00:01, 53.56it/s, Epoch: 46, Batch: 13,Loss: -1.901,Avg.Loss: -1.770,LR: 2.88E-04]Training epoch 46:  12%|█▏        | 13/112 [00:00<00:01, 53.56it/s, Epoch: 46, Batch: 14,Loss: -1.571,Avg.Loss: -1.756,LR: 2.88E-04]Training epoch 46:  12%|█▎        | 14/112 [00:00<00:01, 53.56it/s, Epoch: 46, Batch: 15,Loss: -1.279,Avg.Loss: -1.724,LR: 2.88E-04]Training epoch 46:  13%|█▎        | 15/112 [00:00<00:01, 53.56it/s, Epoch: 46, Batch: 16,Loss: -1.862,Avg.Loss: -1.733,LR: 2.88E-04]Training epoch 46:  14%|█▍        | 16/112 [00:00<00:01, 53.56it/s, Epoch: 46, Batch: 17,Loss: -2.008,Avg.Loss: -1.749,LR: 2.88E-04]Training epoch 46:  15%|█▌        | 17/112 [00:00<00:01, 53.56it/s, Epoch: 46, Batch: 18,Loss: -2.431,Avg.Loss: -1.787,LR: 2.88E-04]Training epoch 46:  16%|█▌        | 18/112 [00:00<00:01, 53.18it/s, Epoch: 46, Batch: 18,Loss: -2.431,Avg.Loss: -1.787,LR: 2.88E-04]Training epoch 46:  16%|█▌        | 18/112 [00:00<00:01, 53.18it/s, Epoch: 46, Batch: 19,Loss: -2.112,Avg.Loss: -1.804,LR: 2.88E-04]Training epoch 46:  17%|█▋        | 19/112 [00:00<00:01, 53.18it/s, Epoch: 46, Batch: 20,Loss: -2.098,Avg.Loss: -1.819,LR: 2.88E-04]Training epoch 46:  18%|█▊        | 20/112 [00:00<00:01, 53.18it/s, Epoch: 46, Batch: 21,Loss: -1.737,Avg.Loss: -1.815,LR: 2.88E-04]Training epoch 46:  19%|█▉        | 21/112 [00:00<00:01, 53.18it/s, Epoch: 46, Batch: 22,Loss: -2.179,Avg.Loss: -1.831,LR: 2.88E-04]Training epoch 46:  20%|█▉        | 22/112 [00:00<00:01, 53.18it/s, Epoch: 46, Batch: 23,Loss: -1.969,Avg.Loss: -1.837,LR: 2.88E-04]Training epoch 46:  21%|██        | 23/112 [00:00<00:01, 53.18it/s, Epoch: 46, Batch: 24,Loss: -2.485,Avg.Loss: -1.864,LR: 2.87E-04]Training epoch 46:  21%|██▏       | 24/112 [00:00<00:01, 52.91it/s, Epoch: 46, Batch: 24,Loss: -2.485,Avg.Loss: -1.864,LR: 2.87E-04]Training epoch 46:  21%|██▏       | 24/112 [00:00<00:01, 52.91it/s, Epoch: 46, Batch: 25,Loss: -2.227,Avg.Loss: -1.879,LR: 2.87E-04]Training epoch 46:  22%|██▏       | 25/112 [00:00<00:01, 52.91it/s, Epoch: 46, Batch: 26,Loss: -2.384,Avg.Loss: -1.898,LR: 2.87E-04]Training epoch 46:  23%|██▎       | 26/112 [00:00<00:01, 52.91it/s, Epoch: 46, Batch: 27,Loss: -2.083,Avg.Loss: -1.905,LR: 2.87E-04]Training epoch 46:  24%|██▍       | 27/112 [00:00<00:01, 52.91it/s, Epoch: 46, Batch: 28,Loss: -2.491,Avg.Loss: -1.926,LR: 2.87E-04]Training epoch 46:  25%|██▌       | 28/112 [00:00<00:01, 52.91it/s, Epoch: 46, Batch: 29,Loss: -2.802,Avg.Loss: -1.956,LR: 2.87E-04]Training epoch 46:  26%|██▌       | 29/112 [00:00<00:01, 52.91it/s, Epoch: 46, Batch: 30,Loss: -2.001,Avg.Loss: -1.958,LR: 2.87E-04]Training epoch 46:  27%|██▋       | 30/112 [00:00<00:01, 52.98it/s, Epoch: 46, Batch: 30,Loss: -2.001,Avg.Loss: -1.958,LR: 2.87E-04]Training epoch 46:  27%|██▋       | 30/112 [00:00<00:01, 52.98it/s, Epoch: 46, Batch: 31,Loss: -2.036,Avg.Loss: -1.960,LR: 2.87E-04]Training epoch 46:  28%|██▊       | 31/112 [00:00<00:01, 52.98it/s, Epoch: 46, Batch: 32,Loss: -2.515,Avg.Loss: -1.978,LR: 2.87E-04]Training epoch 46:  29%|██▊       | 32/112 [00:00<00:01, 52.98it/s, Epoch: 46, Batch: 33,Loss: -1.270,Avg.Loss: -1.956,LR: 2.87E-04]Training epoch 46:  29%|██▉       | 33/112 [00:00<00:01, 52.98it/s, Epoch: 46, Batch: 34,Loss: -0.211,Avg.Loss: -1.905,LR: 2.87E-04]Training epoch 46:  30%|███       | 34/112 [00:00<00:01, 52.98it/s, Epoch: 46, Batch: 35,Loss: -0.485,Avg.Loss: -1.864,LR: 2.87E-04]Training epoch 46:  31%|███▏      | 35/112 [00:00<00:01, 52.98it/s, Epoch: 46, Batch: 36,Loss: -2.019,Avg.Loss: -1.869,LR: 2.87E-04]Training epoch 46:  32%|███▏      | 36/112 [00:00<00:01, 52.65it/s, Epoch: 46, Batch: 36,Loss: -2.019,Avg.Loss: -1.869,LR: 2.87E-04]Training epoch 46:  32%|███▏      | 36/112 [00:00<00:01, 52.65it/s, Epoch: 46, Batch: 37,Loss: -1.257,Avg.Loss: -1.852,LR: 2.87E-04]Training epoch 46:  33%|███▎      | 37/112 [00:00<00:01, 52.65it/s, Epoch: 46, Batch: 38,Loss: 0.352,Avg.Loss: -1.794,LR: 2.86E-04] Training epoch 46:  34%|███▍      | 38/112 [00:00<00:01, 52.65it/s, Epoch: 46, Batch: 39,Loss: 0.014,Avg.Loss: -1.748,LR: 2.86E-04]Training epoch 46:  35%|███▍      | 39/112 [00:00<00:01, 52.65it/s, Epoch: 46, Batch: 40,Loss: -0.605,Avg.Loss: -1.719,LR: 2.86E-04]Training epoch 46:  36%|███▌      | 40/112 [00:00<00:01, 52.65it/s, Epoch: 46, Batch: 41,Loss: -1.651,Avg.Loss: -1.717,LR: 2.86E-04]Training epoch 46:  37%|███▋      | 41/112 [00:00<00:01, 52.65it/s, Epoch: 46, Batch: 42,Loss: -1.001,Avg.Loss: -1.700,LR: 2.86E-04]Training epoch 46:  38%|███▊      | 42/112 [00:00<00:01, 52.74it/s, Epoch: 46, Batch: 42,Loss: -1.001,Avg.Loss: -1.700,LR: 2.86E-04]Training epoch 46:  38%|███▊      | 42/112 [00:00<00:01, 52.74it/s, Epoch: 46, Batch: 43,Loss: 0.000,Avg.Loss: -1.661,LR: 2.86E-04] Training epoch 46:  38%|███▊      | 43/112 [00:00<00:01, 52.74it/s, Epoch: 46, Batch: 44,Loss: -1.856,Avg.Loss: -1.665,LR: 2.86E-04]Training epoch 46:  39%|███▉      | 44/112 [00:00<00:01, 52.74it/s, Epoch: 46, Batch: 45,Loss: -2.274,Avg.Loss: -1.679,LR: 2.86E-04]Training epoch 46:  40%|████      | 45/112 [00:00<00:01, 52.74it/s, Epoch: 46, Batch: 46,Loss: -1.642,Avg.Loss: -1.678,LR: 2.86E-04]Training epoch 46:  41%|████      | 46/112 [00:00<00:01, 52.74it/s, Epoch: 46, Batch: 47,Loss: -1.867,Avg.Loss: -1.682,LR: 2.86E-04]Training epoch 46:  42%|████▏     | 47/112 [00:00<00:01, 52.74it/s, Epoch: 46, Batch: 48,Loss: -1.509,Avg.Loss: -1.678,LR: 2.86E-04]Training epoch 46:  43%|████▎     | 48/112 [00:00<00:01, 52.86it/s, Epoch: 46, Batch: 48,Loss: -1.509,Avg.Loss: -1.678,LR: 2.86E-04]Training epoch 46:  43%|████▎     | 48/112 [00:00<00:01, 52.86it/s, Epoch: 46, Batch: 49,Loss: -2.459,Avg.Loss: -1.694,LR: 2.86E-04]Training epoch 46:  44%|████▍     | 49/112 [00:00<00:01, 52.86it/s, Epoch: 46, Batch: 50,Loss: -2.716,Avg.Loss: -1.715,LR: 2.86E-04]Training epoch 46:  45%|████▍     | 50/112 [00:00<00:01, 52.86it/s, Epoch: 46, Batch: 51,Loss: -2.074,Avg.Loss: -1.722,LR: 2.86E-04]Training epoch 46:  46%|████▌     | 51/112 [00:00<00:01, 52.86it/s, Epoch: 46, Batch: 52,Loss: -2.166,Avg.Loss: -1.730,LR: 2.86E-04]Training epoch 46:  46%|████▋     | 52/112 [00:01<00:01, 52.86it/s, Epoch: 46, Batch: 53,Loss: -2.465,Avg.Loss: -1.744,LR: 2.85E-04]Training epoch 46:  47%|████▋     | 53/112 [00:01<00:01, 52.86it/s, Epoch: 46, Batch: 54,Loss: -1.867,Avg.Loss: -1.747,LR: 2.85E-04]Training epoch 46:  48%|████▊     | 54/112 [00:01<00:01, 52.92it/s, Epoch: 46, Batch: 54,Loss: -1.867,Avg.Loss: -1.747,LR: 2.85E-04]Training epoch 46:  48%|████▊     | 54/112 [00:01<00:01, 52.92it/s, Epoch: 46, Batch: 55,Loss: -0.710,Avg.Loss: -1.728,LR: 2.85E-04]Training epoch 46:  49%|████▉     | 55/112 [00:01<00:01, 52.92it/s, Epoch: 46, Batch: 56,Loss: -1.480,Avg.Loss: -1.723,LR: 2.85E-04]Training epoch 46:  50%|█████     | 56/112 [00:01<00:01, 52.92it/s, Epoch: 46, Batch: 57,Loss: -2.004,Avg.Loss: -1.728,LR: 2.85E-04]Training epoch 46:  51%|█████     | 57/112 [00:01<00:01, 52.92it/s, Epoch: 46, Batch: 58,Loss: -1.585,Avg.Loss: -1.726,LR: 2.85E-04]Training epoch 46:  52%|█████▏    | 58/112 [00:01<00:01, 52.92it/s, Epoch: 46, Batch: 59,Loss: -2.197,Avg.Loss: -1.734,LR: 2.85E-04]Training epoch 46:  53%|█████▎    | 59/112 [00:01<00:01, 52.92it/s, Epoch: 46, Batch: 60,Loss: -2.178,Avg.Loss: -1.741,LR: 2.85E-04]Training epoch 46:  54%|█████▎    | 60/112 [00:01<00:00, 52.95it/s, Epoch: 46, Batch: 60,Loss: -2.178,Avg.Loss: -1.741,LR: 2.85E-04]Training epoch 46:  54%|█████▎    | 60/112 [00:01<00:00, 52.95it/s, Epoch: 46, Batch: 61,Loss: -2.030,Avg.Loss: -1.746,LR: 2.85E-04]Training epoch 46:  54%|█████▍    | 61/112 [00:01<00:00, 52.95it/s, Epoch: 46, Batch: 62,Loss: -1.924,Avg.Loss: -1.749,LR: 2.85E-04]Training epoch 46:  55%|█████▌    | 62/112 [00:01<00:00, 52.95it/s, Epoch: 46, Batch: 63,Loss: -2.165,Avg.Loss: -1.755,LR: 2.85E-04]Training epoch 46:  56%|█████▋    | 63/112 [00:01<00:00, 52.95it/s, Epoch: 46, Batch: 64,Loss: -2.340,Avg.Loss: -1.764,LR: 2.85E-04]Training epoch 46:  57%|█████▋    | 64/112 [00:01<00:00, 52.95it/s, Epoch: 46, Batch: 65,Loss: -1.782,Avg.Loss: -1.765,LR: 2.85E-04]Training epoch 46:  58%|█████▊    | 65/112 [00:01<00:00, 52.95it/s, Epoch: 46, Batch: 66,Loss: -1.350,Avg.Loss: -1.758,LR: 2.85E-04]Training epoch 46:  59%|█████▉    | 66/112 [00:01<00:00, 52.98it/s, Epoch: 46, Batch: 66,Loss: -1.350,Avg.Loss: -1.758,LR: 2.85E-04]Training epoch 46:  59%|█████▉    | 66/112 [00:01<00:00, 52.98it/s, Epoch: 46, Batch: 67,Loss: -1.847,Avg.Loss: -1.760,LR: 2.84E-04]Training epoch 46:  60%|█████▉    | 67/112 [00:01<00:00, 52.98it/s, Epoch: 46, Batch: 68,Loss: -2.374,Avg.Loss: -1.769,LR: 2.84E-04]Training epoch 46:  61%|██████    | 68/112 [00:01<00:00, 52.98it/s, Epoch: 46, Batch: 69,Loss: -2.370,Avg.Loss: -1.778,LR: 2.84E-04]Training epoch 46:  62%|██████▏   | 69/112 [00:01<00:00, 52.98it/s, Epoch: 46, Batch: 70,Loss: -2.435,Avg.Loss: -1.787,LR: 2.84E-04]Training epoch 46:  62%|██████▎   | 70/112 [00:01<00:00, 52.98it/s, Epoch: 46, Batch: 71,Loss: -2.455,Avg.Loss: -1.796,LR: 2.84E-04]Training epoch 46:  63%|██████▎   | 71/112 [00:01<00:00, 52.98it/s, Epoch: 46, Batch: 72,Loss: -2.313,Avg.Loss: -1.803,LR: 2.84E-04]Training epoch 46:  64%|██████▍   | 72/112 [00:01<00:00, 53.00it/s, Epoch: 46, Batch: 72,Loss: -2.313,Avg.Loss: -1.803,LR: 2.84E-04]Training epoch 46:  64%|██████▍   | 72/112 [00:01<00:00, 53.00it/s, Epoch: 46, Batch: 73,Loss: -2.510,Avg.Loss: -1.813,LR: 2.84E-04]Training epoch 46:  65%|██████▌   | 73/112 [00:01<00:00, 53.00it/s, Epoch: 46, Batch: 74,Loss: -2.212,Avg.Loss: -1.819,LR: 2.84E-04]Training epoch 46:  66%|██████▌   | 74/112 [00:01<00:00, 53.00it/s, Epoch: 46, Batch: 75,Loss: -1.262,Avg.Loss: -1.811,LR: 2.84E-04]Training epoch 46:  67%|██████▋   | 75/112 [00:01<00:00, 53.00it/s, Epoch: 46, Batch: 76,Loss: -1.944,Avg.Loss: -1.813,LR: 2.84E-04]Training epoch 46:  68%|██████▊   | 76/112 [00:01<00:00, 53.00it/s, Epoch: 46, Batch: 77,Loss: -1.837,Avg.Loss: -1.813,LR: 2.84E-04]Training epoch 46:  69%|██████▉   | 77/112 [00:01<00:00, 53.00it/s, Epoch: 46, Batch: 78,Loss: -1.757,Avg.Loss: -1.812,LR: 2.84E-04]Training epoch 46:  70%|██████▉   | 78/112 [00:01<00:00, 53.03it/s, Epoch: 46, Batch: 78,Loss: -1.757,Avg.Loss: -1.812,LR: 2.84E-04]Training epoch 46:  70%|██████▉   | 78/112 [00:01<00:00, 53.03it/s, Epoch: 46, Batch: 79,Loss: -2.347,Avg.Loss: -1.819,LR: 2.84E-04]Training epoch 46:  71%|███████   | 79/112 [00:01<00:00, 53.03it/s, Epoch: 46, Batch: 80,Loss: -1.952,Avg.Loss: -1.821,LR: 2.84E-04]Training epoch 46:  71%|███████▏  | 80/112 [00:01<00:00, 53.03it/s, Epoch: 46, Batch: 81,Loss: -1.049,Avg.Loss: -1.811,LR: 2.83E-04]Training epoch 46:  72%|███████▏  | 81/112 [00:01<00:00, 53.03it/s, Epoch: 46, Batch: 82,Loss: -2.008,Avg.Loss: -1.814,LR: 2.83E-04]Training epoch 46:  73%|███████▎  | 82/112 [00:01<00:00, 53.03it/s, Epoch: 46, Batch: 83,Loss: -2.736,Avg.Loss: -1.825,LR: 2.83E-04]Training epoch 46:  74%|███████▍  | 83/112 [00:01<00:00, 53.03it/s, Epoch: 46, Batch: 84,Loss: -2.583,Avg.Loss: -1.834,LR: 2.83E-04]Training epoch 46:  75%|███████▌  | 84/112 [00:01<00:00, 52.74it/s, Epoch: 46, Batch: 84,Loss: -2.583,Avg.Loss: -1.834,LR: 2.83E-04]Training epoch 46:  75%|███████▌  | 84/112 [00:01<00:00, 52.74it/s, Epoch: 46, Batch: 85,Loss: -2.569,Avg.Loss: -1.843,LR: 2.83E-04]Training epoch 46:  76%|███████▌  | 85/112 [00:01<00:00, 52.74it/s, Epoch: 46, Batch: 86,Loss: -2.124,Avg.Loss: -1.846,LR: 2.83E-04]Training epoch 46:  77%|███████▋  | 86/112 [00:01<00:00, 52.74it/s, Epoch: 46, Batch: 87,Loss: -2.792,Avg.Loss: -1.857,LR: 2.83E-04]Training epoch 46:  78%|███████▊  | 87/112 [00:01<00:00, 52.74it/s, Epoch: 46, Batch: 88,Loss: -2.845,Avg.Loss: -1.868,LR: 2.83E-04]Training epoch 46:  79%|███████▊  | 88/112 [00:01<00:00, 52.74it/s, Epoch: 46, Batch: 89,Loss: -2.550,Avg.Loss: -1.876,LR: 2.83E-04]Training epoch 46:  79%|███████▉  | 89/112 [00:01<00:00, 52.74it/s, Epoch: 46, Batch: 90,Loss: -1.926,Avg.Loss: -1.876,LR: 2.83E-04]Training epoch 46:  80%|████████  | 90/112 [00:01<00:00, 52.71it/s, Epoch: 46, Batch: 90,Loss: -1.926,Avg.Loss: -1.876,LR: 2.83E-04]Training epoch 46:  80%|████████  | 90/112 [00:01<00:00, 52.71it/s, Epoch: 46, Batch: 91,Loss: -2.220,Avg.Loss: -1.880,LR: 2.83E-04]Training epoch 46:  81%|████████▏ | 91/112 [00:01<00:00, 52.71it/s, Epoch: 46, Batch: 92,Loss: -2.647,Avg.Loss: -1.888,LR: 2.83E-04]Training epoch 46:  82%|████████▏ | 92/112 [00:01<00:00, 52.71it/s, Epoch: 46, Batch: 93,Loss: -2.248,Avg.Loss: -1.892,LR: 2.83E-04]Training epoch 46:  83%|████████▎ | 93/112 [00:01<00:00, 52.71it/s, Epoch: 46, Batch: 94,Loss: -1.058,Avg.Loss: -1.883,LR: 2.83E-04]Training epoch 46:  84%|████████▍ | 94/112 [00:01<00:00, 52.71it/s, Epoch: 46, Batch: 95,Loss: -1.814,Avg.Loss: -1.883,LR: 2.83E-04]Training epoch 46:  85%|████████▍ | 95/112 [00:01<00:00, 52.71it/s, Epoch: 46, Batch: 96,Loss: -0.813,Avg.Loss: -1.871,LR: 2.82E-04]Training epoch 46:  86%|████████▌ | 96/112 [00:01<00:00, 52.76it/s, Epoch: 46, Batch: 96,Loss: -0.813,Avg.Loss: -1.871,LR: 2.82E-04]Training epoch 46:  86%|████████▌ | 96/112 [00:01<00:00, 52.76it/s, Epoch: 46, Batch: 97,Loss: -1.171,Avg.Loss: -1.864,LR: 2.82E-04]Training epoch 46:  87%|████████▋ | 97/112 [00:01<00:00, 52.76it/s, Epoch: 46, Batch: 98,Loss: -1.614,Avg.Loss: -1.862,LR: 2.82E-04]Training epoch 46:  88%|████████▊ | 98/112 [00:01<00:00, 52.76it/s, Epoch: 46, Batch: 99,Loss: -1.897,Avg.Loss: -1.862,LR: 2.82E-04]Training epoch 46:  88%|████████▊ | 99/112 [00:01<00:00, 52.76it/s, Epoch: 46, Batch: 100,Loss: -1.004,Avg.Loss: -1.853,LR: 2.82E-04]Training epoch 46:  89%|████████▉ | 100/112 [00:01<00:00, 52.76it/s, Epoch: 46, Batch: 101,Loss: -1.993,Avg.Loss: -1.855,LR: 2.82E-04]Training epoch 46:  90%|█████████ | 101/112 [00:01<00:00, 52.76it/s, Epoch: 46, Batch: 102,Loss: -2.028,Avg.Loss: -1.856,LR: 2.82E-04]Training epoch 46:  91%|█████████ | 102/112 [00:01<00:00, 52.83it/s, Epoch: 46, Batch: 102,Loss: -2.028,Avg.Loss: -1.856,LR: 2.82E-04]Training epoch 46:  91%|█████████ | 102/112 [00:01<00:00, 52.83it/s, Epoch: 46, Batch: 103,Loss: -2.681,Avg.Loss: -1.864,LR: 2.82E-04]Training epoch 46:  92%|█████████▏| 103/112 [00:01<00:00, 52.83it/s, Epoch: 46, Batch: 104,Loss: -2.314,Avg.Loss: -1.869,LR: 2.82E-04]Training epoch 46:  93%|█████████▎| 104/112 [00:01<00:00, 52.83it/s, Epoch: 46, Batch: 105,Loss: -2.421,Avg.Loss: -1.874,LR: 2.82E-04]Training epoch 46:  94%|█████████▍| 105/112 [00:02<00:00, 52.83it/s, Epoch: 46, Batch: 106,Loss: -2.038,Avg.Loss: -1.876,LR: 2.82E-04]Training epoch 46:  95%|█████████▍| 106/112 [00:02<00:00, 52.83it/s, Epoch: 46, Batch: 107,Loss: -2.313,Avg.Loss: -1.880,LR: 2.82E-04]Training epoch 46:  96%|█████████▌| 107/112 [00:02<00:00, 52.83it/s, Epoch: 46, Batch: 108,Loss: -2.680,Avg.Loss: -1.887,LR: 2.82E-04]Training epoch 46:  96%|█████████▋| 108/112 [00:02<00:00, 52.92it/s, Epoch: 46, Batch: 108,Loss: -2.680,Avg.Loss: -1.887,LR: 2.82E-04]Training epoch 46:  96%|█████████▋| 108/112 [00:02<00:00, 52.92it/s, Epoch: 46, Batch: 109,Loss: -2.239,Avg.Loss: -1.890,LR: 2.82E-04]Training epoch 46:  97%|█████████▋| 109/112 [00:02<00:00, 52.92it/s, Epoch: 46, Batch: 110,Loss: -2.299,Avg.Loss: -1.894,LR: 2.81E-04]Training epoch 46:  98%|█████████▊| 110/112 [00:02<00:00, 52.92it/s, Epoch: 46, Batch: 111,Loss: -2.395,Avg.Loss: -1.899,LR: 2.81E-04]Training epoch 46:  99%|█████████▉| 111/112 [00:02<00:00, 52.92it/s, Epoch: 46, Batch: 112,Loss: -3.304,Avg.Loss: -1.911,LR: 2.81E-04]Training epoch 46: 100%|██████████| 112/112 [00:02<00:00, 52.82it/s, Epoch: 46, Batch: 112,Loss: -3.304,Avg.Loss: -1.911,LR: 2.81E-04]
Training epoch 47:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 47:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 47, Batch: 1,Loss: -2.553,Avg.Loss: -2.553,LR: 2.81E-04]Training epoch 47:   1%|          | 1/112 [00:00<00:03, 29.40it/s, Epoch: 47, Batch: 2,Loss: -1.402,Avg.Loss: -1.978,LR: 2.81E-04]Training epoch 47:   2%|▏         | 2/112 [00:00<00:02, 42.67it/s, Epoch: 47, Batch: 3,Loss: -1.902,Avg.Loss: -1.952,LR: 2.81E-04]Training epoch 47:   3%|▎         | 3/112 [00:00<00:02, 49.56it/s, Epoch: 47, Batch: 4,Loss: -2.549,Avg.Loss: -2.101,LR: 2.81E-04]Training epoch 47:   4%|▎         | 4/112 [00:00<00:01, 54.36it/s, Epoch: 47, Batch: 5,Loss: -0.588,Avg.Loss: -1.799,LR: 2.81E-04]Training epoch 47:   4%|▍         | 5/112 [00:00<00:01, 55.03it/s, Epoch: 47, Batch: 6,Loss: 0.293,Avg.Loss: -1.450,LR: 2.81E-04] Training epoch 47:   5%|▌         | 6/112 [00:00<00:01, 55.46it/s, Epoch: 47, Batch: 7,Loss: 0.147,Avg.Loss: -1.222,LR: 2.81E-04]Training epoch 47:   6%|▋         | 7/112 [00:00<00:01, 64.60it/s, Epoch: 47, Batch: 7,Loss: 0.147,Avg.Loss: -1.222,LR: 2.81E-04]Training epoch 47:   6%|▋         | 7/112 [00:00<00:01, 64.60it/s, Epoch: 47, Batch: 8,Loss: -1.098,Avg.Loss: -1.206,LR: 2.81E-04]Training epoch 47:   7%|▋         | 8/112 [00:00<00:01, 64.60it/s, Epoch: 47, Batch: 9,Loss: -0.957,Avg.Loss: -1.179,LR: 2.81E-04]Training epoch 47:   8%|▊         | 9/112 [00:00<00:01, 64.60it/s, Epoch: 47, Batch: 10,Loss: 2.792,Avg.Loss: -0.782,LR: 2.81E-04]Training epoch 47:   9%|▉         | 10/112 [00:00<00:01, 64.60it/s, Epoch: 47, Batch: 11,Loss: 2.217,Avg.Loss: -0.509,LR: 2.81E-04]Training epoch 47:  10%|▉         | 11/112 [00:00<00:01, 64.60it/s, Epoch: 47, Batch: 12,Loss: -0.402,Avg.Loss: -0.500,LR: 2.80E-04]Training epoch 47:  11%|█         | 12/112 [00:00<00:01, 64.60it/s, Epoch: 47, Batch: 13,Loss: -2.033,Avg.Loss: -0.618,LR: 2.80E-04]Training epoch 47:  12%|█▏        | 13/112 [00:00<00:01, 64.60it/s, Epoch: 47, Batch: 14,Loss: -1.664,Avg.Loss: -0.693,LR: 2.80E-04]Training epoch 47:  12%|█▎        | 14/112 [00:00<00:01, 57.22it/s, Epoch: 47, Batch: 14,Loss: -1.664,Avg.Loss: -0.693,LR: 2.80E-04]Training epoch 47:  12%|█▎        | 14/112 [00:00<00:01, 57.22it/s, Epoch: 47, Batch: 15,Loss: -1.436,Avg.Loss: -0.742,LR: 2.80E-04]Training epoch 47:  13%|█▎        | 15/112 [00:00<00:01, 57.22it/s, Epoch: 47, Batch: 16,Loss: -2.342,Avg.Loss: -0.842,LR: 2.80E-04]Training epoch 47:  14%|█▍        | 16/112 [00:00<00:01, 57.22it/s, Epoch: 47, Batch: 17,Loss: -2.047,Avg.Loss: -0.913,LR: 2.80E-04]Training epoch 47:  15%|█▌        | 17/112 [00:00<00:01, 57.22it/s, Epoch: 47, Batch: 18,Loss: -0.109,Avg.Loss: -0.868,LR: 2.80E-04]Training epoch 47:  16%|█▌        | 18/112 [00:00<00:01, 57.22it/s, Epoch: 47, Batch: 19,Loss: -0.943,Avg.Loss: -0.872,LR: 2.80E-04]Training epoch 47:  17%|█▋        | 19/112 [00:00<00:01, 57.22it/s, Epoch: 47, Batch: 20,Loss: -1.414,Avg.Loss: -0.899,LR: 2.80E-04]Training epoch 47:  18%|█▊        | 20/112 [00:00<00:01, 55.25it/s, Epoch: 47, Batch: 20,Loss: -1.414,Avg.Loss: -0.899,LR: 2.80E-04]Training epoch 47:  18%|█▊        | 20/112 [00:00<00:01, 55.25it/s, Epoch: 47, Batch: 21,Loss: -1.562,Avg.Loss: -0.931,LR: 2.80E-04]Training epoch 47:  19%|█▉        | 21/112 [00:00<00:01, 55.25it/s, Epoch: 47, Batch: 22,Loss: -1.271,Avg.Loss: -0.946,LR: 2.80E-04]Training epoch 47:  20%|█▉        | 22/112 [00:00<00:01, 55.25it/s, Epoch: 47, Batch: 23,Loss: -2.499,Avg.Loss: -1.014,LR: 2.80E-04]Training epoch 47:  21%|██        | 23/112 [00:00<00:01, 55.25it/s, Epoch: 47, Batch: 24,Loss: -1.750,Avg.Loss: -1.045,LR: 2.80E-04]Training epoch 47:  21%|██▏       | 24/112 [00:00<00:01, 55.25it/s, Epoch: 47, Batch: 25,Loss: -0.926,Avg.Loss: -1.040,LR: 2.80E-04]Training epoch 47:  22%|██▏       | 25/112 [00:00<00:01, 55.25it/s, Epoch: 47, Batch: 26,Loss: -2.254,Avg.Loss: -1.087,LR: 2.80E-04]Training epoch 47:  23%|██▎       | 26/112 [00:00<00:01, 54.18it/s, Epoch: 47, Batch: 26,Loss: -2.254,Avg.Loss: -1.087,LR: 2.80E-04]Training epoch 47:  23%|██▎       | 26/112 [00:00<00:01, 54.18it/s, Epoch: 47, Batch: 27,Loss: -2.097,Avg.Loss: -1.124,LR: 2.79E-04]Training epoch 47:  24%|██▍       | 27/112 [00:00<00:01, 54.18it/s, Epoch: 47, Batch: 28,Loss: -1.770,Avg.Loss: -1.147,LR: 2.79E-04]Training epoch 47:  25%|██▌       | 28/112 [00:00<00:01, 54.18it/s, Epoch: 47, Batch: 29,Loss: -2.525,Avg.Loss: -1.195,LR: 2.79E-04]Training epoch 47:  26%|██▌       | 29/112 [00:00<00:01, 54.18it/s, Epoch: 47, Batch: 30,Loss: -2.219,Avg.Loss: -1.229,LR: 2.79E-04]Training epoch 47:  27%|██▋       | 30/112 [00:00<00:01, 54.18it/s, Epoch: 47, Batch: 31,Loss: -1.731,Avg.Loss: -1.245,LR: 2.79E-04]Training epoch 47:  28%|██▊       | 31/112 [00:00<00:01, 54.18it/s, Epoch: 47, Batch: 32,Loss: -1.567,Avg.Loss: -1.255,LR: 2.79E-04]Training epoch 47:  29%|██▊       | 32/112 [00:00<00:01, 53.55it/s, Epoch: 47, Batch: 32,Loss: -1.567,Avg.Loss: -1.255,LR: 2.79E-04]Training epoch 47:  29%|██▊       | 32/112 [00:00<00:01, 53.55it/s, Epoch: 47, Batch: 33,Loss: -2.158,Avg.Loss: -1.282,LR: 2.79E-04]Training epoch 47:  29%|██▉       | 33/112 [00:00<00:01, 53.55it/s, Epoch: 47, Batch: 34,Loss: -1.813,Avg.Loss: -1.298,LR: 2.79E-04]Training epoch 47:  30%|███       | 34/112 [00:00<00:01, 53.55it/s, Epoch: 47, Batch: 35,Loss: -2.679,Avg.Loss: -1.337,LR: 2.79E-04]Training epoch 47:  31%|███▏      | 35/112 [00:00<00:01, 53.55it/s, Epoch: 47, Batch: 36,Loss: -1.725,Avg.Loss: -1.348,LR: 2.79E-04]Training epoch 47:  32%|███▏      | 36/112 [00:00<00:01, 53.55it/s, Epoch: 47, Batch: 37,Loss: -0.076,Avg.Loss: -1.314,LR: 2.79E-04]Training epoch 47:  33%|███▎      | 37/112 [00:00<00:01, 53.55it/s, Epoch: 47, Batch: 38,Loss: -1.384,Avg.Loss: -1.316,LR: 2.79E-04]Training epoch 47:  34%|███▍      | 38/112 [00:00<00:01, 53.35it/s, Epoch: 47, Batch: 38,Loss: -1.384,Avg.Loss: -1.316,LR: 2.79E-04]Training epoch 47:  34%|███▍      | 38/112 [00:00<00:01, 53.35it/s, Epoch: 47, Batch: 39,Loss: -1.674,Avg.Loss: -1.325,LR: 2.79E-04]Training epoch 47:  35%|███▍      | 39/112 [00:00<00:01, 53.35it/s, Epoch: 47, Batch: 40,Loss: -1.544,Avg.Loss: -1.330,LR: 2.79E-04]Training epoch 47:  36%|███▌      | 40/112 [00:00<00:01, 53.35it/s, Epoch: 47, Batch: 41,Loss: -1.758,Avg.Loss: -1.341,LR: 2.78E-04]Training epoch 47:  37%|███▋      | 41/112 [00:00<00:01, 53.35it/s, Epoch: 47, Batch: 42,Loss: -2.340,Avg.Loss: -1.365,LR: 2.78E-04]Training epoch 47:  38%|███▊      | 42/112 [00:00<00:01, 53.35it/s, Epoch: 47, Batch: 43,Loss: -1.989,Avg.Loss: -1.379,LR: 2.78E-04]Training epoch 47:  38%|███▊      | 43/112 [00:00<00:01, 53.35it/s, Epoch: 47, Batch: 44,Loss: -1.906,Avg.Loss: -1.391,LR: 2.78E-04]Training epoch 47:  39%|███▉      | 44/112 [00:00<00:01, 53.20it/s, Epoch: 47, Batch: 44,Loss: -1.906,Avg.Loss: -1.391,LR: 2.78E-04]Training epoch 47:  39%|███▉      | 44/112 [00:00<00:01, 53.20it/s, Epoch: 47, Batch: 45,Loss: -1.511,Avg.Loss: -1.394,LR: 2.78E-04]Training epoch 47:  40%|████      | 45/112 [00:00<00:01, 53.20it/s, Epoch: 47, Batch: 46,Loss: -1.417,Avg.Loss: -1.394,LR: 2.78E-04]Training epoch 47:  41%|████      | 46/112 [00:00<00:01, 53.20it/s, Epoch: 47, Batch: 47,Loss: -2.127,Avg.Loss: -1.410,LR: 2.78E-04]Training epoch 47:  42%|████▏     | 47/112 [00:00<00:01, 53.20it/s, Epoch: 47, Batch: 48,Loss: -2.193,Avg.Loss: -1.426,LR: 2.78E-04]Training epoch 47:  43%|████▎     | 48/112 [00:00<00:01, 53.20it/s, Epoch: 47, Batch: 49,Loss: -2.870,Avg.Loss: -1.456,LR: 2.78E-04]Training epoch 47:  44%|████▍     | 49/112 [00:00<00:01, 53.20it/s, Epoch: 47, Batch: 50,Loss: -2.305,Avg.Loss: -1.473,LR: 2.78E-04]Training epoch 47:  45%|████▍     | 50/112 [00:00<00:01, 53.16it/s, Epoch: 47, Batch: 50,Loss: -2.305,Avg.Loss: -1.473,LR: 2.78E-04]Training epoch 47:  45%|████▍     | 50/112 [00:00<00:01, 53.16it/s, Epoch: 47, Batch: 51,Loss: -2.353,Avg.Loss: -1.490,LR: 2.78E-04]Training epoch 47:  46%|████▌     | 51/112 [00:00<00:01, 53.16it/s, Epoch: 47, Batch: 52,Loss: -2.253,Avg.Loss: -1.505,LR: 2.78E-04]Training epoch 47:  46%|████▋     | 52/112 [00:00<00:01, 53.16it/s, Epoch: 47, Batch: 53,Loss: -2.363,Avg.Loss: -1.521,LR: 2.78E-04]Training epoch 47:  47%|████▋     | 53/112 [00:00<00:01, 53.16it/s, Epoch: 47, Batch: 54,Loss: -2.619,Avg.Loss: -1.541,LR: 2.78E-04]Training epoch 47:  48%|████▊     | 54/112 [00:01<00:01, 53.16it/s, Epoch: 47, Batch: 55,Loss: -2.423,Avg.Loss: -1.557,LR: 2.78E-04]Training epoch 47:  49%|████▉     | 55/112 [00:01<00:01, 53.16it/s, Epoch: 47, Batch: 56,Loss: -1.598,Avg.Loss: -1.558,LR: 2.77E-04]Training epoch 47:  50%|█████     | 56/112 [00:01<00:01, 53.20it/s, Epoch: 47, Batch: 56,Loss: -1.598,Avg.Loss: -1.558,LR: 2.77E-04]Training epoch 47:  50%|█████     | 56/112 [00:01<00:01, 53.20it/s, Epoch: 47, Batch: 57,Loss: -2.188,Avg.Loss: -1.569,LR: 2.77E-04]Training epoch 47:  51%|█████     | 57/112 [00:01<00:01, 53.20it/s, Epoch: 47, Batch: 58,Loss: -2.301,Avg.Loss: -1.582,LR: 2.77E-04]Training epoch 47:  52%|█████▏    | 58/112 [00:01<00:01, 53.20it/s, Epoch: 47, Batch: 59,Loss: -2.792,Avg.Loss: -1.602,LR: 2.77E-04]Training epoch 47:  53%|█████▎    | 59/112 [00:01<00:00, 53.20it/s, Epoch: 47, Batch: 60,Loss: -3.059,Avg.Loss: -1.626,LR: 2.77E-04]Training epoch 47:  54%|█████▎    | 60/112 [00:01<00:00, 53.20it/s, Epoch: 47, Batch: 61,Loss: -2.153,Avg.Loss: -1.635,LR: 2.77E-04]Training epoch 47:  54%|█████▍    | 61/112 [00:01<00:00, 53.20it/s, Epoch: 47, Batch: 62,Loss: -1.931,Avg.Loss: -1.640,LR: 2.77E-04]Training epoch 47:  55%|█████▌    | 62/112 [00:01<00:00, 53.24it/s, Epoch: 47, Batch: 62,Loss: -1.931,Avg.Loss: -1.640,LR: 2.77E-04]Training epoch 47:  55%|█████▌    | 62/112 [00:01<00:00, 53.24it/s, Epoch: 47, Batch: 63,Loss: -2.605,Avg.Loss: -1.655,LR: 2.77E-04]Training epoch 47:  56%|█████▋    | 63/112 [00:01<00:00, 53.24it/s, Epoch: 47, Batch: 64,Loss: -2.734,Avg.Loss: -1.672,LR: 2.77E-04]Training epoch 47:  57%|█████▋    | 64/112 [00:01<00:00, 53.24it/s, Epoch: 47, Batch: 65,Loss: -2.475,Avg.Loss: -1.684,LR: 2.77E-04]Training epoch 47:  58%|█████▊    | 65/112 [00:01<00:00, 53.24it/s, Epoch: 47, Batch: 66,Loss: -1.969,Avg.Loss: -1.689,LR: 2.77E-04]Training epoch 47:  59%|█████▉    | 66/112 [00:01<00:00, 53.24it/s, Epoch: 47, Batch: 67,Loss: -1.746,Avg.Loss: -1.689,LR: 2.77E-04]Training epoch 47:  60%|█████▉    | 67/112 [00:01<00:00, 53.24it/s, Epoch: 47, Batch: 68,Loss: -2.127,Avg.Loss: -1.696,LR: 2.77E-04]Training epoch 47:  61%|██████    | 68/112 [00:01<00:00, 53.22it/s, Epoch: 47, Batch: 68,Loss: -2.127,Avg.Loss: -1.696,LR: 2.77E-04]Training epoch 47:  61%|██████    | 68/112 [00:01<00:00, 53.22it/s, Epoch: 47, Batch: 69,Loss: -1.974,Avg.Loss: -1.700,LR: 2.77E-04]Training epoch 47:  62%|██████▏   | 69/112 [00:01<00:00, 53.22it/s, Epoch: 47, Batch: 70,Loss: -2.255,Avg.Loss: -1.708,LR: 2.76E-04]Training epoch 47:  62%|██████▎   | 70/112 [00:01<00:00, 53.22it/s, Epoch: 47, Batch: 71,Loss: -2.528,Avg.Loss: -1.719,LR: 2.76E-04]Training epoch 47:  63%|██████▎   | 71/112 [00:01<00:00, 53.22it/s, Epoch: 47, Batch: 72,Loss: -2.184,Avg.Loss: -1.726,LR: 2.76E-04]Training epoch 47:  64%|██████▍   | 72/112 [00:01<00:00, 53.22it/s, Epoch: 47, Batch: 73,Loss: -2.340,Avg.Loss: -1.734,LR: 2.76E-04]Training epoch 47:  65%|██████▌   | 73/112 [00:01<00:00, 53.22it/s, Epoch: 47, Batch: 74,Loss: -2.808,Avg.Loss: -1.749,LR: 2.76E-04]Training epoch 47:  66%|██████▌   | 74/112 [00:01<00:00, 53.39it/s, Epoch: 47, Batch: 74,Loss: -2.808,Avg.Loss: -1.749,LR: 2.76E-04]Training epoch 47:  66%|██████▌   | 74/112 [00:01<00:00, 53.39it/s, Epoch: 47, Batch: 75,Loss: -2.296,Avg.Loss: -1.756,LR: 2.76E-04]Training epoch 47:  67%|██████▋   | 75/112 [00:01<00:00, 53.39it/s, Epoch: 47, Batch: 76,Loss: -2.543,Avg.Loss: -1.766,LR: 2.76E-04]Training epoch 47:  68%|██████▊   | 76/112 [00:01<00:00, 53.39it/s, Epoch: 47, Batch: 77,Loss: -2.802,Avg.Loss: -1.780,LR: 2.76E-04]Training epoch 47:  69%|██████▉   | 77/112 [00:01<00:00, 53.39it/s, Epoch: 47, Batch: 78,Loss: -2.634,Avg.Loss: -1.791,LR: 2.76E-04]Training epoch 47:  70%|██████▉   | 78/112 [00:01<00:00, 53.39it/s, Epoch: 47, Batch: 79,Loss: -2.264,Avg.Loss: -1.797,LR: 2.76E-04]Training epoch 47:  71%|███████   | 79/112 [00:01<00:00, 53.39it/s, Epoch: 47, Batch: 80,Loss: -2.346,Avg.Loss: -1.804,LR: 2.76E-04]Training epoch 47:  71%|███████▏  | 80/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 80,Loss: -2.346,Avg.Loss: -1.804,LR: 2.76E-04]Training epoch 47:  71%|███████▏  | 80/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 81,Loss: -3.001,Avg.Loss: -1.818,LR: 2.76E-04]Training epoch 47:  72%|███████▏  | 81/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 82,Loss: -2.735,Avg.Loss: -1.830,LR: 2.76E-04]Training epoch 47:  73%|███████▎  | 82/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 83,Loss: -2.161,Avg.Loss: -1.834,LR: 2.76E-04]Training epoch 47:  74%|███████▍  | 83/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 84,Loss: -2.235,Avg.Loss: -1.838,LR: 2.75E-04]Training epoch 47:  75%|███████▌  | 84/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 85,Loss: -2.464,Avg.Loss: -1.846,LR: 2.75E-04]Training epoch 47:  76%|███████▌  | 85/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 86,Loss: -2.932,Avg.Loss: -1.858,LR: 2.75E-04]Training epoch 47:  77%|███████▋  | 86/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 86,Loss: -2.932,Avg.Loss: -1.858,LR: 2.75E-04]Training epoch 47:  77%|███████▋  | 86/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 87,Loss: -2.508,Avg.Loss: -1.866,LR: 2.75E-04]Training epoch 47:  78%|███████▊  | 87/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 88,Loss: -2.273,Avg.Loss: -1.870,LR: 2.75E-04]Training epoch 47:  79%|███████▊  | 88/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 89,Loss: -2.285,Avg.Loss: -1.875,LR: 2.75E-04]Training epoch 47:  79%|███████▉  | 89/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 90,Loss: -2.248,Avg.Loss: -1.879,LR: 2.75E-04]Training epoch 47:  80%|████████  | 90/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 91,Loss: -2.567,Avg.Loss: -1.887,LR: 2.75E-04]Training epoch 47:  81%|████████▏ | 91/112 [00:01<00:00, 53.47it/s, Epoch: 47, Batch: 92,Loss: -2.916,Avg.Loss: -1.898,LR: 2.75E-04]Training epoch 47:  82%|████████▏ | 92/112 [00:01<00:00, 53.55it/s, Epoch: 47, Batch: 92,Loss: -2.916,Avg.Loss: -1.898,LR: 2.75E-04]Training epoch 47:  82%|████████▏ | 92/112 [00:01<00:00, 53.55it/s, Epoch: 47, Batch: 93,Loss: -2.372,Avg.Loss: -1.903,LR: 2.75E-04]Training epoch 47:  83%|████████▎ | 93/112 [00:01<00:00, 53.55it/s, Epoch: 47, Batch: 94,Loss: -1.608,Avg.Loss: -1.900,LR: 2.75E-04]Training epoch 47:  84%|████████▍ | 94/112 [00:01<00:00, 53.55it/s, Epoch: 47, Batch: 95,Loss: -1.670,Avg.Loss: -1.898,LR: 2.75E-04]Training epoch 47:  85%|████████▍ | 95/112 [00:01<00:00, 53.55it/s, Epoch: 47, Batch: 96,Loss: -1.925,Avg.Loss: -1.898,LR: 2.75E-04]Training epoch 47:  86%|████████▌ | 96/112 [00:01<00:00, 53.55it/s, Epoch: 47, Batch: 97,Loss: -1.562,Avg.Loss: -1.894,LR: 2.75E-04]Training epoch 47:  87%|████████▋ | 97/112 [00:01<00:00, 53.55it/s, Epoch: 47, Batch: 98,Loss: -2.058,Avg.Loss: -1.896,LR: 2.75E-04]Training epoch 47:  88%|████████▊ | 98/112 [00:01<00:00, 53.62it/s, Epoch: 47, Batch: 98,Loss: -2.058,Avg.Loss: -1.896,LR: 2.75E-04]Training epoch 47:  88%|████████▊ | 98/112 [00:01<00:00, 53.62it/s, Epoch: 47, Batch: 99,Loss: -2.478,Avg.Loss: -1.902,LR: 2.74E-04]Training epoch 47:  88%|████████▊ | 99/112 [00:01<00:00, 53.62it/s, Epoch: 47, Batch: 100,Loss: -2.658,Avg.Loss: -1.909,LR: 2.74E-04]Training epoch 47:  89%|████████▉ | 100/112 [00:01<00:00, 53.62it/s, Epoch: 47, Batch: 101,Loss: -2.536,Avg.Loss: -1.916,LR: 2.74E-04]Training epoch 47:  90%|█████████ | 101/112 [00:01<00:00, 53.62it/s, Epoch: 47, Batch: 102,Loss: -2.197,Avg.Loss: -1.918,LR: 2.74E-04]Training epoch 47:  91%|█████████ | 102/112 [00:01<00:00, 53.62it/s, Epoch: 47, Batch: 103,Loss: -2.337,Avg.Loss: -1.922,LR: 2.74E-04]Training epoch 47:  92%|█████████▏| 103/112 [00:01<00:00, 53.62it/s, Epoch: 47, Batch: 104,Loss: -2.608,Avg.Loss: -1.929,LR: 2.74E-04]Training epoch 47:  93%|█████████▎| 104/112 [00:01<00:00, 53.78it/s, Epoch: 47, Batch: 104,Loss: -2.608,Avg.Loss: -1.929,LR: 2.74E-04]Training epoch 47:  93%|█████████▎| 104/112 [00:01<00:00, 53.78it/s, Epoch: 47, Batch: 105,Loss: -2.267,Avg.Loss: -1.932,LR: 2.74E-04]Training epoch 47:  94%|█████████▍| 105/112 [00:01<00:00, 53.78it/s, Epoch: 47, Batch: 106,Loss: -1.971,Avg.Loss: -1.933,LR: 2.74E-04]Training epoch 47:  95%|█████████▍| 106/112 [00:01<00:00, 53.78it/s, Epoch: 47, Batch: 107,Loss: -1.428,Avg.Loss: -1.928,LR: 2.74E-04]Training epoch 47:  96%|█████████▌| 107/112 [00:02<00:00, 53.78it/s, Epoch: 47, Batch: 108,Loss: -0.465,Avg.Loss: -1.914,LR: 2.74E-04]Training epoch 47:  96%|█████████▋| 108/112 [00:02<00:00, 53.78it/s, Epoch: 47, Batch: 109,Loss: -1.134,Avg.Loss: -1.907,LR: 2.74E-04]Training epoch 47:  97%|█████████▋| 109/112 [00:02<00:00, 53.78it/s, Epoch: 47, Batch: 110,Loss: -1.645,Avg.Loss: -1.905,LR: 2.74E-04]Training epoch 47:  98%|█████████▊| 110/112 [00:02<00:00, 53.71it/s, Epoch: 47, Batch: 110,Loss: -1.645,Avg.Loss: -1.905,LR: 2.74E-04]Training epoch 47:  98%|█████████▊| 110/112 [00:02<00:00, 53.71it/s, Epoch: 47, Batch: 111,Loss: -1.964,Avg.Loss: -1.905,LR: 2.74E-04]Training epoch 47:  99%|█████████▉| 111/112 [00:02<00:00, 53.71it/s, Epoch: 47, Batch: 112,Loss: -2.696,Avg.Loss: -1.912,LR: 2.74E-04]Training epoch 47: 100%|██████████| 112/112 [00:02<00:00, 53.74it/s, Epoch: 47, Batch: 112,Loss: -2.696,Avg.Loss: -1.912,LR: 2.74E-04]
Training epoch 48:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 48:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 48, Batch: 1,Loss: 2.238,Avg.Loss: 2.238,LR: 2.73E-04]Training epoch 48:   1%|          | 1/112 [00:00<00:03, 28.18it/s, Epoch: 48, Batch: 2,Loss: 4.462,Avg.Loss: 3.350,LR: 2.73E-04]Training epoch 48:   2%|▏         | 2/112 [00:00<00:02, 38.30it/s, Epoch: 48, Batch: 3,Loss: 2.909,Avg.Loss: 3.203,LR: 2.73E-04]Training epoch 48:   3%|▎         | 3/112 [00:00<00:02, 42.89it/s, Epoch: 48, Batch: 4,Loss: -1.452,Avg.Loss: 2.039,LR: 2.73E-04]Training epoch 48:   4%|▎         | 4/112 [00:00<00:02, 44.90it/s, Epoch: 48, Batch: 5,Loss: -1.911,Avg.Loss: 1.249,LR: 2.73E-04]Training epoch 48:   4%|▍         | 5/112 [00:00<00:02, 46.21it/s, Epoch: 48, Batch: 6,Loss: 1.727,Avg.Loss: 1.329,LR: 2.73E-04] Training epoch 48:   5%|▌         | 6/112 [00:00<00:01, 55.35it/s, Epoch: 48, Batch: 6,Loss: 1.727,Avg.Loss: 1.329,LR: 2.73E-04]Training epoch 48:   5%|▌         | 6/112 [00:00<00:01, 55.35it/s, Epoch: 48, Batch: 7,Loss: 0.057,Avg.Loss: 1.147,LR: 2.73E-04]Training epoch 48:   6%|▋         | 7/112 [00:00<00:01, 55.35it/s, Epoch: 48, Batch: 8,Loss: -1.492,Avg.Loss: 0.817,LR: 2.73E-04]Training epoch 48:   7%|▋         | 8/112 [00:00<00:01, 55.35it/s, Epoch: 48, Batch: 9,Loss: -1.437,Avg.Loss: 0.567,LR: 2.73E-04]Training epoch 48:   8%|▊         | 9/112 [00:00<00:01, 55.35it/s, Epoch: 48, Batch: 10,Loss: -0.232,Avg.Loss: 0.487,LR: 2.73E-04]Training epoch 48:   9%|▉         | 10/112 [00:00<00:01, 55.35it/s, Epoch: 48, Batch: 11,Loss: -1.506,Avg.Loss: 0.306,LR: 2.73E-04]Training epoch 48:  10%|▉         | 11/112 [00:00<00:01, 55.35it/s, Epoch: 48, Batch: 12,Loss: -2.717,Avg.Loss: 0.054,LR: 2.73E-04]Training epoch 48:  11%|█         | 12/112 [00:00<00:01, 54.00it/s, Epoch: 48, Batch: 12,Loss: -2.717,Avg.Loss: 0.054,LR: 2.73E-04]Training epoch 48:  11%|█         | 12/112 [00:00<00:01, 54.00it/s, Epoch: 48, Batch: 13,Loss: -2.740,Avg.Loss: -0.161,LR: 2.73E-04]Training epoch 48:  12%|█▏        | 13/112 [00:00<00:01, 54.00it/s, Epoch: 48, Batch: 14,Loss: -2.196,Avg.Loss: -0.306,LR: 2.73E-04]Training epoch 48:  12%|█▎        | 14/112 [00:00<00:01, 54.00it/s, Epoch: 48, Batch: 15,Loss: -1.781,Avg.Loss: -0.405,LR: 2.72E-04]Training epoch 48:  13%|█▎        | 15/112 [00:00<00:01, 54.00it/s, Epoch: 48, Batch: 16,Loss: -1.591,Avg.Loss: -0.479,LR: 2.72E-04]Training epoch 48:  14%|█▍        | 16/112 [00:00<00:01, 54.00it/s, Epoch: 48, Batch: 17,Loss: -2.224,Avg.Loss: -0.581,LR: 2.72E-04]Training epoch 48:  15%|█▌        | 17/112 [00:00<00:01, 54.00it/s, Epoch: 48, Batch: 18,Loss: -1.671,Avg.Loss: -0.642,LR: 2.72E-04]Training epoch 48:  16%|█▌        | 18/112 [00:00<00:01, 53.70it/s, Epoch: 48, Batch: 18,Loss: -1.671,Avg.Loss: -0.642,LR: 2.72E-04]Training epoch 48:  16%|█▌        | 18/112 [00:00<00:01, 53.70it/s, Epoch: 48, Batch: 19,Loss: -1.783,Avg.Loss: -0.702,LR: 2.72E-04]Training epoch 48:  17%|█▋        | 19/112 [00:00<00:01, 53.70it/s, Epoch: 48, Batch: 20,Loss: -1.284,Avg.Loss: -0.731,LR: 2.72E-04]Training epoch 48:  18%|█▊        | 20/112 [00:00<00:01, 53.70it/s, Epoch: 48, Batch: 21,Loss: -1.222,Avg.Loss: -0.755,LR: 2.72E-04]Training epoch 48:  19%|█▉        | 21/112 [00:00<00:01, 53.70it/s, Epoch: 48, Batch: 22,Loss: -1.762,Avg.Loss: -0.800,LR: 2.72E-04]Training epoch 48:  20%|█▉        | 22/112 [00:00<00:01, 53.70it/s, Epoch: 48, Batch: 23,Loss: -2.803,Avg.Loss: -0.887,LR: 2.72E-04]Training epoch 48:  21%|██        | 23/112 [00:00<00:01, 53.70it/s, Epoch: 48, Batch: 24,Loss: -1.349,Avg.Loss: -0.907,LR: 2.72E-04]Training epoch 48:  21%|██▏       | 24/112 [00:00<00:01, 53.38it/s, Epoch: 48, Batch: 24,Loss: -1.349,Avg.Loss: -0.907,LR: 2.72E-04]Training epoch 48:  21%|██▏       | 24/112 [00:00<00:01, 53.38it/s, Epoch: 48, Batch: 25,Loss: 0.230,Avg.Loss: -0.861,LR: 2.72E-04] Training epoch 48:  22%|██▏       | 25/112 [00:00<00:01, 53.38it/s, Epoch: 48, Batch: 26,Loss: 0.351,Avg.Loss: -0.815,LR: 2.72E-04]Training epoch 48:  23%|██▎       | 26/112 [00:00<00:01, 53.38it/s, Epoch: 48, Batch: 27,Loss: -1.745,Avg.Loss: -0.849,LR: 2.72E-04]Training epoch 48:  24%|██▍       | 27/112 [00:00<00:01, 53.38it/s, Epoch: 48, Batch: 28,Loss: -0.699,Avg.Loss: -0.844,LR: 2.72E-04]Training epoch 48:  25%|██▌       | 28/112 [00:00<00:01, 53.38it/s, Epoch: 48, Batch: 29,Loss: 0.578,Avg.Loss: -0.795,LR: 2.72E-04] Training epoch 48:  26%|██▌       | 29/112 [00:00<00:01, 53.38it/s, Epoch: 48, Batch: 30,Loss: 0.348,Avg.Loss: -0.757,LR: 2.71E-04]Training epoch 48:  27%|██▋       | 30/112 [00:00<00:01, 53.33it/s, Epoch: 48, Batch: 30,Loss: 0.348,Avg.Loss: -0.757,LR: 2.71E-04]Training epoch 48:  27%|██▋       | 30/112 [00:00<00:01, 53.33it/s, Epoch: 48, Batch: 31,Loss: -1.373,Avg.Loss: -0.776,LR: 2.71E-04]Training epoch 48:  28%|██▊       | 31/112 [00:00<00:01, 53.33it/s, Epoch: 48, Batch: 32,Loss: -2.809,Avg.Loss: -0.840,LR: 2.71E-04]Training epoch 48:  29%|██▊       | 32/112 [00:00<00:01, 53.33it/s, Epoch: 48, Batch: 33,Loss: -1.610,Avg.Loss: -0.863,LR: 2.71E-04]Training epoch 48:  29%|██▉       | 33/112 [00:00<00:01, 53.33it/s, Epoch: 48, Batch: 34,Loss: -1.551,Avg.Loss: -0.883,LR: 2.71E-04]Training epoch 48:  30%|███       | 34/112 [00:00<00:01, 53.33it/s, Epoch: 48, Batch: 35,Loss: -2.114,Avg.Loss: -0.919,LR: 2.71E-04]Training epoch 48:  31%|███▏      | 35/112 [00:00<00:01, 53.33it/s, Epoch: 48, Batch: 36,Loss: -1.820,Avg.Loss: -0.944,LR: 2.71E-04]Training epoch 48:  32%|███▏      | 36/112 [00:00<00:01, 53.28it/s, Epoch: 48, Batch: 36,Loss: -1.820,Avg.Loss: -0.944,LR: 2.71E-04]Training epoch 48:  32%|███▏      | 36/112 [00:00<00:01, 53.28it/s, Epoch: 48, Batch: 37,Loss: -1.295,Avg.Loss: -0.953,LR: 2.71E-04]Training epoch 48:  33%|███▎      | 37/112 [00:00<00:01, 53.28it/s, Epoch: 48, Batch: 38,Loss: -1.708,Avg.Loss: -0.973,LR: 2.71E-04]Training epoch 48:  34%|███▍      | 38/112 [00:00<00:01, 53.28it/s, Epoch: 48, Batch: 39,Loss: -2.536,Avg.Loss: -1.013,LR: 2.71E-04]Training epoch 48:  35%|███▍      | 39/112 [00:00<00:01, 53.28it/s, Epoch: 48, Batch: 40,Loss: -2.365,Avg.Loss: -1.047,LR: 2.71E-04]Training epoch 48:  36%|███▌      | 40/112 [00:00<00:01, 53.28it/s, Epoch: 48, Batch: 41,Loss: -2.403,Avg.Loss: -1.080,LR: 2.71E-04]Training epoch 48:  37%|███▋      | 41/112 [00:00<00:01, 53.28it/s, Epoch: 48, Batch: 42,Loss: -2.504,Avg.Loss: -1.114,LR: 2.71E-04]Training epoch 48:  38%|███▊      | 42/112 [00:00<00:01, 53.37it/s, Epoch: 48, Batch: 42,Loss: -2.504,Avg.Loss: -1.114,LR: 2.71E-04]Training epoch 48:  38%|███▊      | 42/112 [00:00<00:01, 53.37it/s, Epoch: 48, Batch: 43,Loss: -2.789,Avg.Loss: -1.153,LR: 2.71E-04]Training epoch 48:  38%|███▊      | 43/112 [00:00<00:01, 53.37it/s, Epoch: 48, Batch: 44,Loss: -2.554,Avg.Loss: -1.185,LR: 2.70E-04]Training epoch 48:  39%|███▉      | 44/112 [00:00<00:01, 53.37it/s, Epoch: 48, Batch: 45,Loss: -2.362,Avg.Loss: -1.211,LR: 2.70E-04]Training epoch 48:  40%|████      | 45/112 [00:00<00:01, 53.37it/s, Epoch: 48, Batch: 46,Loss: -2.231,Avg.Loss: -1.233,LR: 2.70E-04]Training epoch 48:  41%|████      | 46/112 [00:00<00:01, 53.37it/s, Epoch: 48, Batch: 47,Loss: -2.374,Avg.Loss: -1.257,LR: 2.70E-04]Training epoch 48:  42%|████▏     | 47/112 [00:00<00:01, 53.37it/s, Epoch: 48, Batch: 48,Loss: -2.745,Avg.Loss: -1.288,LR: 2.70E-04]Training epoch 48:  43%|████▎     | 48/112 [00:00<00:01, 53.45it/s, Epoch: 48, Batch: 48,Loss: -2.745,Avg.Loss: -1.288,LR: 2.70E-04]Training epoch 48:  43%|████▎     | 48/112 [00:00<00:01, 53.45it/s, Epoch: 48, Batch: 49,Loss: -2.641,Avg.Loss: -1.316,LR: 2.70E-04]Training epoch 48:  44%|████▍     | 49/112 [00:00<00:01, 53.45it/s, Epoch: 48, Batch: 50,Loss: -2.054,Avg.Loss: -1.331,LR: 2.70E-04]Training epoch 48:  45%|████▍     | 50/112 [00:00<00:01, 53.45it/s, Epoch: 48, Batch: 51,Loss: -2.455,Avg.Loss: -1.353,LR: 2.70E-04]Training epoch 48:  46%|████▌     | 51/112 [00:00<00:01, 53.45it/s, Epoch: 48, Batch: 52,Loss: -2.657,Avg.Loss: -1.378,LR: 2.70E-04]Training epoch 48:  46%|████▋     | 52/112 [00:00<00:01, 53.45it/s, Epoch: 48, Batch: 53,Loss: -2.475,Avg.Loss: -1.398,LR: 2.70E-04]Training epoch 48:  47%|████▋     | 53/112 [00:01<00:01, 53.45it/s, Epoch: 48, Batch: 54,Loss: -2.732,Avg.Loss: -1.423,LR: 2.70E-04]Training epoch 48:  48%|████▊     | 54/112 [00:01<00:01, 53.47it/s, Epoch: 48, Batch: 54,Loss: -2.732,Avg.Loss: -1.423,LR: 2.70E-04]Training epoch 48:  48%|████▊     | 54/112 [00:01<00:01, 53.47it/s, Epoch: 48, Batch: 55,Loss: -2.402,Avg.Loss: -1.441,LR: 2.70E-04]Training epoch 48:  49%|████▉     | 55/112 [00:01<00:01, 53.47it/s, Epoch: 48, Batch: 56,Loss: -2.711,Avg.Loss: -1.464,LR: 2.70E-04]Training epoch 48:  50%|█████     | 56/112 [00:01<00:01, 53.47it/s, Epoch: 48, Batch: 57,Loss: -2.062,Avg.Loss: -1.474,LR: 2.70E-04]Training epoch 48:  51%|█████     | 57/112 [00:01<00:01, 53.47it/s, Epoch: 48, Batch: 58,Loss: -2.070,Avg.Loss: -1.484,LR: 2.69E-04]Training epoch 48:  52%|█████▏    | 58/112 [00:01<00:01, 53.47it/s, Epoch: 48, Batch: 59,Loss: -2.640,Avg.Loss: -1.504,LR: 2.69E-04]Training epoch 48:  53%|█████▎    | 59/112 [00:01<00:00, 53.47it/s, Epoch: 48, Batch: 60,Loss: -1.405,Avg.Loss: -1.502,LR: 2.69E-04]Training epoch 48:  54%|█████▎    | 60/112 [00:01<00:00, 53.33it/s, Epoch: 48, Batch: 60,Loss: -1.405,Avg.Loss: -1.502,LR: 2.69E-04]Training epoch 48:  54%|█████▎    | 60/112 [00:01<00:00, 53.33it/s, Epoch: 48, Batch: 61,Loss: -0.595,Avg.Loss: -1.487,LR: 2.69E-04]Training epoch 48:  54%|█████▍    | 61/112 [00:01<00:00, 53.33it/s, Epoch: 48, Batch: 62,Loss: -1.210,Avg.Loss: -1.483,LR: 2.69E-04]Training epoch 48:  55%|█████▌    | 62/112 [00:01<00:00, 53.33it/s, Epoch: 48, Batch: 63,Loss: -2.387,Avg.Loss: -1.497,LR: 2.69E-04]Training epoch 48:  56%|█████▋    | 63/112 [00:01<00:00, 53.33it/s, Epoch: 48, Batch: 64,Loss: -2.614,Avg.Loss: -1.515,LR: 2.69E-04]Training epoch 48:  57%|█████▋    | 64/112 [00:01<00:00, 53.33it/s, Epoch: 48, Batch: 65,Loss: -2.563,Avg.Loss: -1.531,LR: 2.69E-04]Training epoch 48:  58%|█████▊    | 65/112 [00:01<00:00, 53.33it/s, Epoch: 48, Batch: 66,Loss: -1.988,Avg.Loss: -1.538,LR: 2.69E-04]Training epoch 48:  59%|█████▉    | 66/112 [00:01<00:00, 53.47it/s, Epoch: 48, Batch: 66,Loss: -1.988,Avg.Loss: -1.538,LR: 2.69E-04]Training epoch 48:  59%|█████▉    | 66/112 [00:01<00:00, 53.47it/s, Epoch: 48, Batch: 67,Loss: -2.088,Avg.Loss: -1.546,LR: 2.69E-04]Training epoch 48:  60%|█████▉    | 67/112 [00:01<00:00, 53.47it/s, Epoch: 48, Batch: 68,Loss: -2.568,Avg.Loss: -1.561,LR: 2.69E-04]Training epoch 48:  61%|██████    | 68/112 [00:01<00:00, 53.47it/s, Epoch: 48, Batch: 69,Loss: -2.692,Avg.Loss: -1.578,LR: 2.69E-04]Training epoch 48:  62%|██████▏   | 69/112 [00:01<00:00, 53.47it/s, Epoch: 48, Batch: 70,Loss: -2.177,Avg.Loss: -1.586,LR: 2.69E-04]Training epoch 48:  62%|██████▎   | 70/112 [00:01<00:00, 53.47it/s, Epoch: 48, Batch: 71,Loss: -2.223,Avg.Loss: -1.595,LR: 2.69E-04]Training epoch 48:  63%|██████▎   | 71/112 [00:01<00:00, 53.47it/s, Epoch: 48, Batch: 72,Loss: -2.551,Avg.Loss: -1.608,LR: 2.68E-04]Training epoch 48:  64%|██████▍   | 72/112 [00:01<00:00, 53.43it/s, Epoch: 48, Batch: 72,Loss: -2.551,Avg.Loss: -1.608,LR: 2.68E-04]Training epoch 48:  64%|██████▍   | 72/112 [00:01<00:00, 53.43it/s, Epoch: 48, Batch: 73,Loss: -2.770,Avg.Loss: -1.624,LR: 2.68E-04]Training epoch 48:  65%|██████▌   | 73/112 [00:01<00:00, 53.43it/s, Epoch: 48, Batch: 74,Loss: -2.153,Avg.Loss: -1.631,LR: 2.68E-04]Training epoch 48:  66%|██████▌   | 74/112 [00:01<00:00, 53.43it/s, Epoch: 48, Batch: 75,Loss: -2.144,Avg.Loss: -1.638,LR: 2.68E-04]Training epoch 48:  67%|██████▋   | 75/112 [00:01<00:00, 53.43it/s, Epoch: 48, Batch: 76,Loss: -2.336,Avg.Loss: -1.647,LR: 2.68E-04]Training epoch 48:  68%|██████▊   | 76/112 [00:01<00:00, 53.43it/s, Epoch: 48, Batch: 77,Loss: -1.898,Avg.Loss: -1.651,LR: 2.68E-04]Training epoch 48:  69%|██████▉   | 77/112 [00:01<00:00, 53.43it/s, Epoch: 48, Batch: 78,Loss: -2.200,Avg.Loss: -1.658,LR: 2.68E-04]Training epoch 48:  70%|██████▉   | 78/112 [00:01<00:00, 53.35it/s, Epoch: 48, Batch: 78,Loss: -2.200,Avg.Loss: -1.658,LR: 2.68E-04]Training epoch 48:  70%|██████▉   | 78/112 [00:01<00:00, 53.35it/s, Epoch: 48, Batch: 79,Loss: -2.604,Avg.Loss: -1.670,LR: 2.68E-04]Training epoch 48:  71%|███████   | 79/112 [00:01<00:00, 53.35it/s, Epoch: 48, Batch: 80,Loss: -1.287,Avg.Loss: -1.665,LR: 2.68E-04]Training epoch 48:  71%|███████▏  | 80/112 [00:01<00:00, 53.35it/s, Epoch: 48, Batch: 81,Loss: 0.232,Avg.Loss: -1.641,LR: 2.68E-04] Training epoch 48:  72%|███████▏  | 81/112 [00:01<00:00, 53.35it/s, Epoch: 48, Batch: 82,Loss: -1.259,Avg.Loss: -1.637,LR: 2.68E-04]Training epoch 48:  73%|███████▎  | 82/112 [00:01<00:00, 53.35it/s, Epoch: 48, Batch: 83,Loss: -2.180,Avg.Loss: -1.643,LR: 2.68E-04]Training epoch 48:  74%|███████▍  | 83/112 [00:01<00:00, 53.35it/s, Epoch: 48, Batch: 84,Loss: -0.842,Avg.Loss: -1.634,LR: 2.68E-04]Training epoch 48:  75%|███████▌  | 84/112 [00:01<00:00, 53.41it/s, Epoch: 48, Batch: 84,Loss: -0.842,Avg.Loss: -1.634,LR: 2.68E-04]Training epoch 48:  75%|███████▌  | 84/112 [00:01<00:00, 53.41it/s, Epoch: 48, Batch: 85,Loss: 2.742,Avg.Loss: -1.582,LR: 2.68E-04] Training epoch 48:  76%|███████▌  | 85/112 [00:01<00:00, 53.41it/s, Epoch: 48, Batch: 86,Loss: 2.205,Avg.Loss: -1.538,LR: 2.68E-04]Training epoch 48:  77%|███████▋  | 86/112 [00:01<00:00, 53.41it/s, Epoch: 48, Batch: 87,Loss: -0.119,Avg.Loss: -1.522,LR: 2.67E-04]Training epoch 48:  78%|███████▊  | 87/112 [00:01<00:00, 53.41it/s, Epoch: 48, Batch: 88,Loss: -2.657,Avg.Loss: -1.535,LR: 2.67E-04]Training epoch 48:  79%|███████▊  | 88/112 [00:01<00:00, 53.41it/s, Epoch: 48, Batch: 89,Loss: -1.221,Avg.Loss: -1.531,LR: 2.67E-04]Training epoch 48:  79%|███████▉  | 89/112 [00:01<00:00, 53.41it/s, Epoch: 48, Batch: 90,Loss: 1.342,Avg.Loss: -1.499,LR: 2.67E-04] Training epoch 48:  80%|████████  | 90/112 [00:01<00:00, 53.25it/s, Epoch: 48, Batch: 90,Loss: 1.342,Avg.Loss: -1.499,LR: 2.67E-04]Training epoch 48:  80%|████████  | 90/112 [00:01<00:00, 53.25it/s, Epoch: 48, Batch: 91,Loss: 1.574,Avg.Loss: -1.466,LR: 2.67E-04]Training epoch 48:  81%|████████▏ | 91/112 [00:01<00:00, 53.25it/s, Epoch: 48, Batch: 92,Loss: -0.008,Avg.Loss: -1.450,LR: 2.67E-04]Training epoch 48:  82%|████████▏ | 92/112 [00:01<00:00, 53.25it/s, Epoch: 48, Batch: 93,Loss: 1.031,Avg.Loss: -1.423,LR: 2.67E-04] Training epoch 48:  83%|████████▎ | 93/112 [00:01<00:00, 53.25it/s, Epoch: 48, Batch: 94,Loss: 2.185,Avg.Loss: -1.385,LR: 2.67E-04]Training epoch 48:  84%|████████▍ | 94/112 [00:01<00:00, 53.25it/s, Epoch: 48, Batch: 95,Loss: 1.220,Avg.Loss: -1.357,LR: 2.67E-04]Training epoch 48:  85%|████████▍ | 95/112 [00:01<00:00, 53.25it/s, Epoch: 48, Batch: 96,Loss: -0.823,Avg.Loss: -1.352,LR: 2.67E-04]Training epoch 48:  86%|████████▌ | 96/112 [00:01<00:00, 53.44it/s, Epoch: 48, Batch: 96,Loss: -0.823,Avg.Loss: -1.352,LR: 2.67E-04]Training epoch 48:  86%|████████▌ | 96/112 [00:01<00:00, 53.44it/s, Epoch: 48, Batch: 97,Loss: -1.546,Avg.Loss: -1.354,LR: 2.67E-04]Training epoch 48:  87%|████████▋ | 97/112 [00:01<00:00, 53.44it/s, Epoch: 48, Batch: 98,Loss: -0.989,Avg.Loss: -1.350,LR: 2.67E-04]Training epoch 48:  88%|████████▊ | 98/112 [00:01<00:00, 53.44it/s, Epoch: 48, Batch: 99,Loss: -0.857,Avg.Loss: -1.345,LR: 2.67E-04]Training epoch 48:  88%|████████▊ | 99/112 [00:01<00:00, 53.44it/s, Epoch: 48, Batch: 100,Loss: -1.066,Avg.Loss: -1.342,LR: 2.67E-04]Training epoch 48:  89%|████████▉ | 100/112 [00:01<00:00, 53.44it/s, Epoch: 48, Batch: 101,Loss: -1.288,Avg.Loss: -1.342,LR: 2.66E-04]Training epoch 48:  90%|█████████ | 101/112 [00:01<00:00, 53.44it/s, Epoch: 48, Batch: 102,Loss: 0.060,Avg.Loss: -1.328,LR: 2.66E-04] Training epoch 48:  91%|█████████ | 102/112 [00:01<00:00, 53.45it/s, Epoch: 48, Batch: 102,Loss: 0.060,Avg.Loss: -1.328,LR: 2.66E-04]Training epoch 48:  91%|█████████ | 102/112 [00:01<00:00, 53.45it/s, Epoch: 48, Batch: 103,Loss: -0.195,Avg.Loss: -1.317,LR: 2.66E-04]Training epoch 48:  92%|█████████▏| 103/112 [00:01<00:00, 53.45it/s, Epoch: 48, Batch: 104,Loss: -1.676,Avg.Loss: -1.320,LR: 2.66E-04]Training epoch 48:  93%|█████████▎| 104/112 [00:01<00:00, 53.45it/s, Epoch: 48, Batch: 105,Loss: -1.960,Avg.Loss: -1.327,LR: 2.66E-04]Training epoch 48:  94%|█████████▍| 105/112 [00:01<00:00, 53.45it/s, Epoch: 48, Batch: 106,Loss: -2.010,Avg.Loss: -1.333,LR: 2.66E-04]Training epoch 48:  95%|█████████▍| 106/112 [00:02<00:00, 53.45it/s, Epoch: 48, Batch: 107,Loss: -2.283,Avg.Loss: -1.342,LR: 2.66E-04]Training epoch 48:  96%|█████████▌| 107/112 [00:02<00:00, 53.45it/s, Epoch: 48, Batch: 108,Loss: -2.774,Avg.Loss: -1.355,LR: 2.66E-04]Training epoch 48:  96%|█████████▋| 108/112 [00:02<00:00, 53.60it/s, Epoch: 48, Batch: 108,Loss: -2.774,Avg.Loss: -1.355,LR: 2.66E-04]Training epoch 48:  96%|█████████▋| 108/112 [00:02<00:00, 53.60it/s, Epoch: 48, Batch: 109,Loss: -2.069,Avg.Loss: -1.362,LR: 2.66E-04]Training epoch 48:  97%|█████████▋| 109/112 [00:02<00:00, 53.60it/s, Epoch: 48, Batch: 110,Loss: -2.469,Avg.Loss: -1.372,LR: 2.66E-04]Training epoch 48:  98%|█████████▊| 110/112 [00:02<00:00, 53.60it/s, Epoch: 48, Batch: 111,Loss: -3.032,Avg.Loss: -1.387,LR: 2.66E-04]Training epoch 48:  99%|█████████▉| 111/112 [00:02<00:00, 53.60it/s, Epoch: 48, Batch: 112,Loss: -2.223,Avg.Loss: -1.394,LR: 2.66E-04]Training epoch 48: 100%|██████████| 112/112 [00:02<00:00, 53.45it/s, Epoch: 48, Batch: 112,Loss: -2.223,Avg.Loss: -1.394,LR: 2.66E-04]
Training epoch 49:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 49:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 49, Batch: 1,Loss: -2.390,Avg.Loss: -2.390,LR: 2.66E-04]Training epoch 49:   1%|          | 1/112 [00:00<00:04, 27.00it/s, Epoch: 49, Batch: 2,Loss: -2.901,Avg.Loss: -2.646,LR: 2.66E-04]Training epoch 49:   2%|▏         | 2/112 [00:00<00:02, 37.36it/s, Epoch: 49, Batch: 3,Loss: -2.004,Avg.Loss: -2.432,LR: 2.65E-04]Training epoch 49:   3%|▎         | 3/112 [00:00<00:02, 42.37it/s, Epoch: 49, Batch: 4,Loss: -1.996,Avg.Loss: -2.323,LR: 2.65E-04]Training epoch 49:   4%|▎         | 4/112 [00:00<00:02, 45.26it/s, Epoch: 49, Batch: 5,Loss: -2.539,Avg.Loss: -2.366,LR: 2.65E-04]Training epoch 49:   4%|▍         | 5/112 [00:00<00:02, 46.64it/s, Epoch: 49, Batch: 6,Loss: -1.248,Avg.Loss: -2.180,LR: 2.65E-04]Training epoch 49:   5%|▌         | 6/112 [00:00<00:01, 55.87it/s, Epoch: 49, Batch: 6,Loss: -1.248,Avg.Loss: -2.180,LR: 2.65E-04]Training epoch 49:   5%|▌         | 6/112 [00:00<00:01, 55.87it/s, Epoch: 49, Batch: 7,Loss: -0.273,Avg.Loss: -1.907,LR: 2.65E-04]Training epoch 49:   6%|▋         | 7/112 [00:00<00:01, 55.87it/s, Epoch: 49, Batch: 8,Loss: -0.166,Avg.Loss: -1.690,LR: 2.65E-04]Training epoch 49:   7%|▋         | 8/112 [00:00<00:01, 55.87it/s, Epoch: 49, Batch: 9,Loss: -2.343,Avg.Loss: -1.762,LR: 2.65E-04]Training epoch 49:   8%|▊         | 9/112 [00:00<00:01, 55.87it/s, Epoch: 49, Batch: 10,Loss: -1.985,Avg.Loss: -1.785,LR: 2.65E-04]Training epoch 49:   9%|▉         | 10/112 [00:00<00:01, 55.87it/s, Epoch: 49, Batch: 11,Loss: -1.103,Avg.Loss: -1.723,LR: 2.65E-04]Training epoch 49:  10%|▉         | 11/112 [00:00<00:01, 55.87it/s, Epoch: 49, Batch: 12,Loss: -0.903,Avg.Loss: -1.654,LR: 2.65E-04]Training epoch 49:  11%|█         | 12/112 [00:00<00:01, 53.92it/s, Epoch: 49, Batch: 12,Loss: -0.903,Avg.Loss: -1.654,LR: 2.65E-04]Training epoch 49:  11%|█         | 12/112 [00:00<00:01, 53.92it/s, Epoch: 49, Batch: 13,Loss: -2.334,Avg.Loss: -1.707,LR: 2.65E-04]Training epoch 49:  12%|█▏        | 13/112 [00:00<00:01, 53.92it/s, Epoch: 49, Batch: 14,Loss: -1.909,Avg.Loss: -1.721,LR: 2.65E-04]Training epoch 49:  12%|█▎        | 14/112 [00:00<00:01, 53.92it/s, Epoch: 49, Batch: 15,Loss: -0.643,Avg.Loss: -1.649,LR: 2.65E-04]Training epoch 49:  13%|█▎        | 15/112 [00:00<00:01, 53.92it/s, Epoch: 49, Batch: 16,Loss: -1.174,Avg.Loss: -1.619,LR: 2.65E-04]Training epoch 49:  14%|█▍        | 16/112 [00:00<00:01, 53.92it/s, Epoch: 49, Batch: 17,Loss: -2.488,Avg.Loss: -1.670,LR: 2.65E-04]Training epoch 49:  15%|█▌        | 17/112 [00:00<00:01, 53.92it/s, Epoch: 49, Batch: 18,Loss: -1.742,Avg.Loss: -1.674,LR: 2.64E-04]Training epoch 49:  16%|█▌        | 18/112 [00:00<00:01, 53.40it/s, Epoch: 49, Batch: 18,Loss: -1.742,Avg.Loss: -1.674,LR: 2.64E-04]Training epoch 49:  16%|█▌        | 18/112 [00:00<00:01, 53.40it/s, Epoch: 49, Batch: 19,Loss: -0.428,Avg.Loss: -1.609,LR: 2.64E-04]Training epoch 49:  17%|█▋        | 19/112 [00:00<00:01, 53.40it/s, Epoch: 49, Batch: 20,Loss: -1.104,Avg.Loss: -1.584,LR: 2.64E-04]Training epoch 49:  18%|█▊        | 20/112 [00:00<00:01, 53.40it/s, Epoch: 49, Batch: 21,Loss: -2.469,Avg.Loss: -1.626,LR: 2.64E-04]Training epoch 49:  19%|█▉        | 21/112 [00:00<00:01, 53.40it/s, Epoch: 49, Batch: 22,Loss: -2.172,Avg.Loss: -1.651,LR: 2.64E-04]Training epoch 49:  20%|█▉        | 22/112 [00:00<00:01, 53.40it/s, Epoch: 49, Batch: 23,Loss: -1.645,Avg.Loss: -1.650,LR: 2.64E-04]Training epoch 49:  21%|██        | 23/112 [00:00<00:01, 53.40it/s, Epoch: 49, Batch: 24,Loss: -1.616,Avg.Loss: -1.649,LR: 2.64E-04]Training epoch 49:  21%|██▏       | 24/112 [00:00<00:01, 53.17it/s, Epoch: 49, Batch: 24,Loss: -1.616,Avg.Loss: -1.649,LR: 2.64E-04]Training epoch 49:  21%|██▏       | 24/112 [00:00<00:01, 53.17it/s, Epoch: 49, Batch: 25,Loss: -2.510,Avg.Loss: -1.683,LR: 2.64E-04]Training epoch 49:  22%|██▏       | 25/112 [00:00<00:01, 53.17it/s, Epoch: 49, Batch: 26,Loss: -2.123,Avg.Loss: -1.700,LR: 2.64E-04]Training epoch 49:  23%|██▎       | 26/112 [00:00<00:01, 53.17it/s, Epoch: 49, Batch: 27,Loss: -1.154,Avg.Loss: -1.680,LR: 2.64E-04]Training epoch 49:  24%|██▍       | 27/112 [00:00<00:01, 53.17it/s, Epoch: 49, Batch: 28,Loss: -1.446,Avg.Loss: -1.672,LR: 2.64E-04]Training epoch 49:  25%|██▌       | 28/112 [00:00<00:01, 53.17it/s, Epoch: 49, Batch: 29,Loss: -2.648,Avg.Loss: -1.705,LR: 2.64E-04]Training epoch 49:  26%|██▌       | 29/112 [00:00<00:01, 53.17it/s, Epoch: 49, Batch: 30,Loss: -1.829,Avg.Loss: -1.709,LR: 2.64E-04]Training epoch 49:  27%|██▋       | 30/112 [00:00<00:01, 53.12it/s, Epoch: 49, Batch: 30,Loss: -1.829,Avg.Loss: -1.709,LR: 2.64E-04]Training epoch 49:  27%|██▋       | 30/112 [00:00<00:01, 53.12it/s, Epoch: 49, Batch: 31,Loss: -0.623,Avg.Loss: -1.674,LR: 2.64E-04]Training epoch 49:  28%|██▊       | 31/112 [00:00<00:01, 53.12it/s, Epoch: 49, Batch: 32,Loss: -0.969,Avg.Loss: -1.652,LR: 2.63E-04]Training epoch 49:  29%|██▊       | 32/112 [00:00<00:01, 53.12it/s, Epoch: 49, Batch: 33,Loss: -2.602,Avg.Loss: -1.681,LR: 2.63E-04]Training epoch 49:  29%|██▉       | 33/112 [00:00<00:01, 53.12it/s, Epoch: 49, Batch: 34,Loss: -2.224,Avg.Loss: -1.697,LR: 2.63E-04]Training epoch 49:  30%|███       | 34/112 [00:00<00:01, 53.12it/s, Epoch: 49, Batch: 35,Loss: -1.266,Avg.Loss: -1.685,LR: 2.63E-04]Training epoch 49:  31%|███▏      | 35/112 [00:00<00:01, 53.12it/s, Epoch: 49, Batch: 36,Loss: -1.997,Avg.Loss: -1.693,LR: 2.63E-04]Training epoch 49:  32%|███▏      | 36/112 [00:00<00:01, 53.20it/s, Epoch: 49, Batch: 36,Loss: -1.997,Avg.Loss: -1.693,LR: 2.63E-04]Training epoch 49:  32%|███▏      | 36/112 [00:00<00:01, 53.20it/s, Epoch: 49, Batch: 37,Loss: -2.518,Avg.Loss: -1.716,LR: 2.63E-04]Training epoch 49:  33%|███▎      | 37/112 [00:00<00:01, 53.20it/s, Epoch: 49, Batch: 38,Loss: -2.165,Avg.Loss: -1.728,LR: 2.63E-04]Training epoch 49:  34%|███▍      | 38/112 [00:00<00:01, 53.20it/s, Epoch: 49, Batch: 39,Loss: -0.810,Avg.Loss: -1.704,LR: 2.63E-04]Training epoch 49:  35%|███▍      | 39/112 [00:00<00:01, 53.20it/s, Epoch: 49, Batch: 40,Loss: -1.260,Avg.Loss: -1.693,LR: 2.63E-04]Training epoch 49:  36%|███▌      | 40/112 [00:00<00:01, 53.20it/s, Epoch: 49, Batch: 41,Loss: -2.524,Avg.Loss: -1.713,LR: 2.63E-04]Training epoch 49:  37%|███▋      | 41/112 [00:00<00:01, 53.20it/s, Epoch: 49, Batch: 42,Loss: -2.017,Avg.Loss: -1.720,LR: 2.63E-04]Training epoch 49:  38%|███▊      | 42/112 [00:00<00:01, 53.09it/s, Epoch: 49, Batch: 42,Loss: -2.017,Avg.Loss: -1.720,LR: 2.63E-04]Training epoch 49:  38%|███▊      | 42/112 [00:00<00:01, 53.09it/s, Epoch: 49, Batch: 43,Loss: -1.402,Avg.Loss: -1.713,LR: 2.63E-04]Training epoch 49:  38%|███▊      | 43/112 [00:00<00:01, 53.09it/s, Epoch: 49, Batch: 44,Loss: -1.812,Avg.Loss: -1.715,LR: 2.63E-04]Training epoch 49:  39%|███▉      | 44/112 [00:00<00:01, 53.09it/s, Epoch: 49, Batch: 45,Loss: -2.601,Avg.Loss: -1.735,LR: 2.63E-04]Training epoch 49:  40%|████      | 45/112 [00:00<00:01, 53.09it/s, Epoch: 49, Batch: 46,Loss: -1.950,Avg.Loss: -1.740,LR: 2.62E-04]Training epoch 49:  41%|████      | 46/112 [00:00<00:01, 53.09it/s, Epoch: 49, Batch: 47,Loss: -0.603,Avg.Loss: -1.715,LR: 2.62E-04]Training epoch 49:  42%|████▏     | 47/112 [00:00<00:01, 53.09it/s, Epoch: 49, Batch: 48,Loss: -1.190,Avg.Loss: -1.704,LR: 2.62E-04]Training epoch 49:  43%|████▎     | 48/112 [00:00<00:01, 52.85it/s, Epoch: 49, Batch: 48,Loss: -1.190,Avg.Loss: -1.704,LR: 2.62E-04]Training epoch 49:  43%|████▎     | 48/112 [00:00<00:01, 52.85it/s, Epoch: 49, Batch: 49,Loss: -2.459,Avg.Loss: -1.720,LR: 2.62E-04]Training epoch 49:  44%|████▍     | 49/112 [00:00<00:01, 52.85it/s, Epoch: 49, Batch: 50,Loss: -2.395,Avg.Loss: -1.733,LR: 2.62E-04]Training epoch 49:  45%|████▍     | 50/112 [00:00<00:01, 52.85it/s, Epoch: 49, Batch: 51,Loss: -1.629,Avg.Loss: -1.731,LR: 2.62E-04]Training epoch 49:  46%|████▌     | 51/112 [00:00<00:01, 52.85it/s, Epoch: 49, Batch: 52,Loss: -2.031,Avg.Loss: -1.737,LR: 2.62E-04]Training epoch 49:  46%|████▋     | 52/112 [00:00<00:01, 52.85it/s, Epoch: 49, Batch: 53,Loss: -2.320,Avg.Loss: -1.748,LR: 2.62E-04]Training epoch 49:  47%|████▋     | 53/112 [00:01<00:01, 52.85it/s, Epoch: 49, Batch: 54,Loss: -1.933,Avg.Loss: -1.752,LR: 2.62E-04]Training epoch 49:  48%|████▊     | 54/112 [00:01<00:01, 52.98it/s, Epoch: 49, Batch: 54,Loss: -1.933,Avg.Loss: -1.752,LR: 2.62E-04]Training epoch 49:  48%|████▊     | 54/112 [00:01<00:01, 52.98it/s, Epoch: 49, Batch: 55,Loss: -1.125,Avg.Loss: -1.740,LR: 2.62E-04]Training epoch 49:  49%|████▉     | 55/112 [00:01<00:01, 52.98it/s, Epoch: 49, Batch: 56,Loss: -1.170,Avg.Loss: -1.730,LR: 2.62E-04]Training epoch 49:  50%|█████     | 56/112 [00:01<00:01, 52.98it/s, Epoch: 49, Batch: 57,Loss: -2.471,Avg.Loss: -1.743,LR: 2.62E-04]Training epoch 49:  51%|█████     | 57/112 [00:01<00:01, 52.98it/s, Epoch: 49, Batch: 58,Loss: -2.450,Avg.Loss: -1.755,LR: 2.62E-04]Training epoch 49:  52%|█████▏    | 58/112 [00:01<00:01, 52.98it/s, Epoch: 49, Batch: 59,Loss: -1.546,Avg.Loss: -1.752,LR: 2.62E-04]Training epoch 49:  53%|█████▎    | 59/112 [00:01<00:01, 52.98it/s, Epoch: 49, Batch: 60,Loss: -2.019,Avg.Loss: -1.756,LR: 2.61E-04]Training epoch 49:  54%|█████▎    | 60/112 [00:01<00:00, 53.01it/s, Epoch: 49, Batch: 60,Loss: -2.019,Avg.Loss: -1.756,LR: 2.61E-04]Training epoch 49:  54%|█████▎    | 60/112 [00:01<00:00, 53.01it/s, Epoch: 49, Batch: 61,Loss: -2.602,Avg.Loss: -1.770,LR: 2.61E-04]Training epoch 49:  54%|█████▍    | 61/112 [00:01<00:00, 53.01it/s, Epoch: 49, Batch: 62,Loss: -2.136,Avg.Loss: -1.776,LR: 2.61E-04]Training epoch 49:  55%|█████▌    | 62/112 [00:01<00:00, 53.01it/s, Epoch: 49, Batch: 63,Loss: -0.676,Avg.Loss: -1.758,LR: 2.61E-04]Training epoch 49:  56%|█████▋    | 63/112 [00:01<00:00, 53.01it/s, Epoch: 49, Batch: 64,Loss: -1.364,Avg.Loss: -1.752,LR: 2.61E-04]Training epoch 49:  57%|█████▋    | 64/112 [00:01<00:00, 53.01it/s, Epoch: 49, Batch: 65,Loss: -2.353,Avg.Loss: -1.761,LR: 2.61E-04]Training epoch 49:  58%|█████▊    | 65/112 [00:01<00:00, 53.01it/s, Epoch: 49, Batch: 66,Loss: -2.225,Avg.Loss: -1.768,LR: 2.61E-04]Training epoch 49:  59%|█████▉    | 66/112 [00:01<00:00, 52.97it/s, Epoch: 49, Batch: 66,Loss: -2.225,Avg.Loss: -1.768,LR: 2.61E-04]Training epoch 49:  59%|█████▉    | 66/112 [00:01<00:00, 52.97it/s, Epoch: 49, Batch: 67,Loss: -1.386,Avg.Loss: -1.763,LR: 2.61E-04]Training epoch 49:  60%|█████▉    | 67/112 [00:01<00:00, 52.97it/s, Epoch: 49, Batch: 68,Loss: -1.468,Avg.Loss: -1.758,LR: 2.61E-04]Training epoch 49:  61%|██████    | 68/112 [00:01<00:00, 52.97it/s, Epoch: 49, Batch: 69,Loss: -2.630,Avg.Loss: -1.771,LR: 2.61E-04]Training epoch 49:  62%|██████▏   | 69/112 [00:01<00:00, 52.97it/s, Epoch: 49, Batch: 70,Loss: -2.187,Avg.Loss: -1.777,LR: 2.61E-04]Training epoch 49:  62%|██████▎   | 70/112 [00:01<00:00, 52.97it/s, Epoch: 49, Batch: 71,Loss: -1.176,Avg.Loss: -1.769,LR: 2.61E-04]Training epoch 49:  63%|██████▎   | 71/112 [00:01<00:00, 52.97it/s, Epoch: 49, Batch: 72,Loss: -1.685,Avg.Loss: -1.767,LR: 2.61E-04]Training epoch 49:  64%|██████▍   | 72/112 [00:01<00:00, 52.83it/s, Epoch: 49, Batch: 72,Loss: -1.685,Avg.Loss: -1.767,LR: 2.61E-04]Training epoch 49:  64%|██████▍   | 72/112 [00:01<00:00, 52.83it/s, Epoch: 49, Batch: 73,Loss: -2.513,Avg.Loss: -1.778,LR: 2.61E-04]Training epoch 49:  65%|██████▌   | 73/112 [00:01<00:00, 52.83it/s, Epoch: 49, Batch: 74,Loss: -2.479,Avg.Loss: -1.787,LR: 2.61E-04]Training epoch 49:  66%|██████▌   | 74/112 [00:01<00:00, 52.83it/s, Epoch: 49, Batch: 75,Loss: -1.011,Avg.Loss: -1.777,LR: 2.60E-04]Training epoch 49:  67%|██████▋   | 75/112 [00:01<00:00, 52.83it/s, Epoch: 49, Batch: 76,Loss: -1.664,Avg.Loss: -1.775,LR: 2.60E-04]Training epoch 49:  68%|██████▊   | 76/112 [00:01<00:00, 52.83it/s, Epoch: 49, Batch: 77,Loss: -2.699,Avg.Loss: -1.787,LR: 2.60E-04]Training epoch 49:  69%|██████▉   | 77/112 [00:01<00:00, 52.83it/s, Epoch: 49, Batch: 78,Loss: -1.948,Avg.Loss: -1.789,LR: 2.60E-04]Training epoch 49:  70%|██████▉   | 78/112 [00:01<00:00, 52.92it/s, Epoch: 49, Batch: 78,Loss: -1.948,Avg.Loss: -1.789,LR: 2.60E-04]Training epoch 49:  70%|██████▉   | 78/112 [00:01<00:00, 52.92it/s, Epoch: 49, Batch: 79,Loss: -1.417,Avg.Loss: -1.785,LR: 2.60E-04]Training epoch 49:  71%|███████   | 79/112 [00:01<00:00, 52.92it/s, Epoch: 49, Batch: 80,Loss: -1.781,Avg.Loss: -1.785,LR: 2.60E-04]Training epoch 49:  71%|███████▏  | 80/112 [00:01<00:00, 52.92it/s, Epoch: 49, Batch: 81,Loss: -2.606,Avg.Loss: -1.795,LR: 2.60E-04]Training epoch 49:  72%|███████▏  | 81/112 [00:01<00:00, 52.92it/s, Epoch: 49, Batch: 82,Loss: -2.201,Avg.Loss: -1.800,LR: 2.60E-04]Training epoch 49:  73%|███████▎  | 82/112 [00:01<00:00, 52.92it/s, Epoch: 49, Batch: 83,Loss: -1.567,Avg.Loss: -1.797,LR: 2.60E-04]Training epoch 49:  74%|███████▍  | 83/112 [00:01<00:00, 52.92it/s, Epoch: 49, Batch: 84,Loss: -1.308,Avg.Loss: -1.791,LR: 2.60E-04]Training epoch 49:  75%|███████▌  | 84/112 [00:01<00:00, 53.10it/s, Epoch: 49, Batch: 84,Loss: -1.308,Avg.Loss: -1.791,LR: 2.60E-04]Training epoch 49:  75%|███████▌  | 84/112 [00:01<00:00, 53.10it/s, Epoch: 49, Batch: 85,Loss: -2.543,Avg.Loss: -1.800,LR: 2.60E-04]Training epoch 49:  76%|███████▌  | 85/112 [00:01<00:00, 53.10it/s, Epoch: 49, Batch: 86,Loss: -2.079,Avg.Loss: -1.803,LR: 2.60E-04]Training epoch 49:  77%|███████▋  | 86/112 [00:01<00:00, 53.10it/s, Epoch: 49, Batch: 87,Loss: -0.966,Avg.Loss: -1.794,LR: 2.60E-04]Training epoch 49:  78%|███████▊  | 87/112 [00:01<00:00, 53.10it/s, Epoch: 49, Batch: 88,Loss: -1.425,Avg.Loss: -1.789,LR: 2.60E-04]Training epoch 49:  79%|███████▊  | 88/112 [00:01<00:00, 53.10it/s, Epoch: 49, Batch: 89,Loss: -2.589,Avg.Loss: -1.798,LR: 2.59E-04]Training epoch 49:  79%|███████▉  | 89/112 [00:01<00:00, 53.10it/s, Epoch: 49, Batch: 90,Loss: -1.895,Avg.Loss: -1.799,LR: 2.59E-04]Training epoch 49:  80%|████████  | 90/112 [00:01<00:00, 53.18it/s, Epoch: 49, Batch: 90,Loss: -1.895,Avg.Loss: -1.799,LR: 2.59E-04]Training epoch 49:  80%|████████  | 90/112 [00:01<00:00, 53.18it/s, Epoch: 49, Batch: 91,Loss: -1.529,Avg.Loss: -1.796,LR: 2.59E-04]Training epoch 49:  81%|████████▏ | 91/112 [00:01<00:00, 53.18it/s, Epoch: 49, Batch: 92,Loss: -1.697,Avg.Loss: -1.795,LR: 2.59E-04]Training epoch 49:  82%|████████▏ | 92/112 [00:01<00:00, 53.18it/s, Epoch: 49, Batch: 93,Loss: -2.704,Avg.Loss: -1.805,LR: 2.59E-04]Training epoch 49:  83%|████████▎ | 93/112 [00:01<00:00, 53.18it/s, Epoch: 49, Batch: 94,Loss: -2.256,Avg.Loss: -1.810,LR: 2.59E-04]Training epoch 49:  84%|████████▍ | 94/112 [00:01<00:00, 53.18it/s, Epoch: 49, Batch: 95,Loss: -1.592,Avg.Loss: -1.808,LR: 2.59E-04]Training epoch 49:  85%|████████▍ | 95/112 [00:01<00:00, 53.18it/s, Epoch: 49, Batch: 96,Loss: -1.469,Avg.Loss: -1.804,LR: 2.59E-04]Training epoch 49:  86%|████████▌ | 96/112 [00:01<00:00, 53.26it/s, Epoch: 49, Batch: 96,Loss: -1.469,Avg.Loss: -1.804,LR: 2.59E-04]Training epoch 49:  86%|████████▌ | 96/112 [00:01<00:00, 53.26it/s, Epoch: 49, Batch: 97,Loss: -2.628,Avg.Loss: -1.813,LR: 2.59E-04]Training epoch 49:  87%|████████▋ | 97/112 [00:01<00:00, 53.26it/s, Epoch: 49, Batch: 98,Loss: -1.969,Avg.Loss: -1.814,LR: 2.59E-04]Training epoch 49:  88%|████████▊ | 98/112 [00:01<00:00, 53.26it/s, Epoch: 49, Batch: 99,Loss: -1.607,Avg.Loss: -1.812,LR: 2.59E-04]Training epoch 49:  88%|████████▊ | 99/112 [00:01<00:00, 53.26it/s, Epoch: 49, Batch: 100,Loss: -1.353,Avg.Loss: -1.807,LR: 2.59E-04]Training epoch 49:  89%|████████▉ | 100/112 [00:01<00:00, 53.26it/s, Epoch: 49, Batch: 101,Loss: -2.261,Avg.Loss: -1.812,LR: 2.59E-04]Training epoch 49:  90%|█████████ | 101/112 [00:01<00:00, 53.26it/s, Epoch: 49, Batch: 102,Loss: -2.440,Avg.Loss: -1.818,LR: 2.59E-04]Training epoch 49:  91%|█████████ | 102/112 [00:01<00:00, 53.32it/s, Epoch: 49, Batch: 102,Loss: -2.440,Avg.Loss: -1.818,LR: 2.59E-04]Training epoch 49:  91%|█████████ | 102/112 [00:01<00:00, 53.32it/s, Epoch: 49, Batch: 103,Loss: -1.781,Avg.Loss: -1.818,LR: 2.58E-04]Training epoch 49:  92%|█████████▏| 103/112 [00:01<00:00, 53.32it/s, Epoch: 49, Batch: 104,Loss: -2.254,Avg.Loss: -1.822,LR: 2.58E-04]Training epoch 49:  93%|█████████▎| 104/112 [00:01<00:00, 53.32it/s, Epoch: 49, Batch: 105,Loss: -2.476,Avg.Loss: -1.828,LR: 2.58E-04]Training epoch 49:  94%|█████████▍| 105/112 [00:01<00:00, 53.32it/s, Epoch: 49, Batch: 106,Loss: -1.965,Avg.Loss: -1.829,LR: 2.58E-04]Training epoch 49:  95%|█████████▍| 106/112 [00:02<00:00, 53.32it/s, Epoch: 49, Batch: 107,Loss: -1.870,Avg.Loss: -1.830,LR: 2.58E-04]Training epoch 49:  96%|█████████▌| 107/112 [00:02<00:00, 53.32it/s, Epoch: 49, Batch: 108,Loss: -1.709,Avg.Loss: -1.829,LR: 2.58E-04]Training epoch 49:  96%|█████████▋| 108/112 [00:02<00:00, 53.13it/s, Epoch: 49, Batch: 108,Loss: -1.709,Avg.Loss: -1.829,LR: 2.58E-04]Training epoch 49:  96%|█████████▋| 108/112 [00:02<00:00, 53.13it/s, Epoch: 49, Batch: 109,Loss: -2.375,Avg.Loss: -1.834,LR: 2.58E-04]Training epoch 49:  97%|█████████▋| 109/112 [00:02<00:00, 53.13it/s, Epoch: 49, Batch: 110,Loss: -1.907,Avg.Loss: -1.834,LR: 2.58E-04]Training epoch 49:  98%|█████████▊| 110/112 [00:02<00:00, 53.13it/s, Epoch: 49, Batch: 111,Loss: -0.855,Avg.Loss: -1.826,LR: 2.58E-04]Training epoch 49:  99%|█████████▉| 111/112 [00:02<00:00, 53.13it/s, Epoch: 49, Batch: 112,Loss: -1.803,Avg.Loss: -1.825,LR: 2.58E-04]Training epoch 49: 100%|██████████| 112/112 [00:02<00:00, 53.08it/s, Epoch: 49, Batch: 112,Loss: -1.803,Avg.Loss: -1.825,LR: 2.58E-04]
Training epoch 50:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 50:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 50, Batch: 1,Loss: -2.433,Avg.Loss: -2.433,LR: 2.58E-04]Training epoch 50:   1%|          | 1/112 [00:00<00:04, 27.61it/s, Epoch: 50, Batch: 2,Loss: -2.410,Avg.Loss: -2.421,LR: 2.58E-04]Training epoch 50:   2%|▏         | 2/112 [00:00<00:02, 37.41it/s, Epoch: 50, Batch: 3,Loss: -1.935,Avg.Loss: -2.259,LR: 2.58E-04]Training epoch 50:   3%|▎         | 3/112 [00:00<00:02, 42.17it/s, Epoch: 50, Batch: 4,Loss: -2.249,Avg.Loss: -2.257,LR: 2.58E-04]Training epoch 50:   4%|▎         | 4/112 [00:00<00:02, 44.52it/s, Epoch: 50, Batch: 5,Loss: -2.425,Avg.Loss: -2.290,LR: 2.58E-04]Training epoch 50:   4%|▍         | 5/112 [00:00<00:02, 45.95it/s, Epoch: 50, Batch: 6,Loss: -1.633,Avg.Loss: -2.181,LR: 2.57E-04]Training epoch 50:   5%|▌         | 6/112 [00:00<00:01, 55.04it/s, Epoch: 50, Batch: 6,Loss: -1.633,Avg.Loss: -2.181,LR: 2.57E-04]Training epoch 50:   5%|▌         | 6/112 [00:00<00:01, 55.04it/s, Epoch: 50, Batch: 7,Loss: -1.229,Avg.Loss: -2.045,LR: 2.57E-04]Training epoch 50:   6%|▋         | 7/112 [00:00<00:01, 55.04it/s, Epoch: 50, Batch: 8,Loss: -1.163,Avg.Loss: -1.935,LR: 2.57E-04]Training epoch 50:   7%|▋         | 8/112 [00:00<00:01, 55.04it/s, Epoch: 50, Batch: 9,Loss: -2.243,Avg.Loss: -1.969,LR: 2.57E-04]Training epoch 50:   8%|▊         | 9/112 [00:00<00:01, 55.04it/s, Epoch: 50, Batch: 10,Loss: -1.953,Avg.Loss: -1.967,LR: 2.57E-04]Training epoch 50:   9%|▉         | 10/112 [00:00<00:01, 55.04it/s, Epoch: 50, Batch: 11,Loss: -1.680,Avg.Loss: -1.941,LR: 2.57E-04]Training epoch 50:  10%|▉         | 11/112 [00:00<00:01, 55.04it/s, Epoch: 50, Batch: 12,Loss: -2.076,Avg.Loss: -1.952,LR: 2.57E-04]Training epoch 50:  11%|█         | 12/112 [00:00<00:01, 53.88it/s, Epoch: 50, Batch: 12,Loss: -2.076,Avg.Loss: -1.952,LR: 2.57E-04]Training epoch 50:  11%|█         | 12/112 [00:00<00:01, 53.88it/s, Epoch: 50, Batch: 13,Loss: -2.347,Avg.Loss: -1.983,LR: 2.57E-04]Training epoch 50:  12%|█▏        | 13/112 [00:00<00:01, 53.88it/s, Epoch: 50, Batch: 14,Loss: -2.256,Avg.Loss: -2.002,LR: 2.57E-04]Training epoch 50:  12%|█▎        | 14/112 [00:00<00:01, 53.88it/s, Epoch: 50, Batch: 15,Loss: -1.516,Avg.Loss: -1.970,LR: 2.57E-04]Training epoch 50:  13%|█▎        | 15/112 [00:00<00:01, 53.88it/s, Epoch: 50, Batch: 16,Loss: -1.939,Avg.Loss: -1.968,LR: 2.57E-04]Training epoch 50:  14%|█▍        | 16/112 [00:00<00:01, 53.88it/s, Epoch: 50, Batch: 17,Loss: -2.332,Avg.Loss: -1.989,LR: 2.57E-04]Training epoch 50:  15%|█▌        | 17/112 [00:00<00:01, 53.88it/s, Epoch: 50, Batch: 18,Loss: -1.957,Avg.Loss: -1.988,LR: 2.57E-04]Training epoch 50:  16%|█▌        | 18/112 [00:00<00:01, 53.45it/s, Epoch: 50, Batch: 18,Loss: -1.957,Avg.Loss: -1.988,LR: 2.57E-04]Training epoch 50:  16%|█▌        | 18/112 [00:00<00:01, 53.45it/s, Epoch: 50, Batch: 19,Loss: -1.348,Avg.Loss: -1.954,LR: 2.57E-04]Training epoch 50:  17%|█▋        | 19/112 [00:00<00:01, 53.45it/s, Epoch: 50, Batch: 20,Loss: -1.739,Avg.Loss: -1.943,LR: 2.56E-04]Training epoch 50:  18%|█▊        | 20/112 [00:00<00:01, 53.45it/s, Epoch: 50, Batch: 21,Loss: -2.247,Avg.Loss: -1.958,LR: 2.56E-04]Training epoch 50:  19%|█▉        | 21/112 [00:00<00:01, 53.45it/s, Epoch: 50, Batch: 22,Loss: -1.477,Avg.Loss: -1.936,LR: 2.56E-04]Training epoch 50:  20%|█▉        | 22/112 [00:00<00:01, 53.45it/s, Epoch: 50, Batch: 23,Loss: -1.057,Avg.Loss: -1.897,LR: 2.56E-04]Training epoch 50:  21%|██        | 23/112 [00:00<00:01, 53.45it/s, Epoch: 50, Batch: 24,Loss: -1.743,Avg.Loss: -1.891,LR: 2.56E-04]Training epoch 50:  21%|██▏       | 24/112 [00:00<00:01, 53.08it/s, Epoch: 50, Batch: 24,Loss: -1.743,Avg.Loss: -1.891,LR: 2.56E-04]Training epoch 50:  21%|██▏       | 24/112 [00:00<00:01, 53.08it/s, Epoch: 50, Batch: 25,Loss: -2.017,Avg.Loss: -1.896,LR: 2.56E-04]Training epoch 50:  22%|██▏       | 25/112 [00:00<00:01, 53.08it/s, Epoch: 50, Batch: 26,Loss: -2.116,Avg.Loss: -1.905,LR: 2.56E-04]Training epoch 50:  23%|██▎       | 26/112 [00:00<00:01, 53.08it/s, Epoch: 50, Batch: 27,Loss: -1.657,Avg.Loss: -1.895,LR: 2.56E-04]Training epoch 50:  24%|██▍       | 27/112 [00:00<00:01, 53.08it/s, Epoch: 50, Batch: 28,Loss: -1.936,Avg.Loss: -1.897,LR: 2.56E-04]Training epoch 50:  25%|██▌       | 28/112 [00:00<00:01, 53.08it/s, Epoch: 50, Batch: 29,Loss: -2.474,Avg.Loss: -1.917,LR: 2.56E-04]Training epoch 50:  26%|██▌       | 29/112 [00:00<00:01, 53.08it/s, Epoch: 50, Batch: 30,Loss: -2.073,Avg.Loss: -1.922,LR: 2.56E-04]Training epoch 50:  27%|██▋       | 30/112 [00:00<00:01, 53.25it/s, Epoch: 50, Batch: 30,Loss: -2.073,Avg.Loss: -1.922,LR: 2.56E-04]Training epoch 50:  27%|██▋       | 30/112 [00:00<00:01, 53.25it/s, Epoch: 50, Batch: 31,Loss: -1.245,Avg.Loss: -1.900,LR: 2.56E-04]Training epoch 50:  28%|██▊       | 31/112 [00:00<00:01, 53.25it/s, Epoch: 50, Batch: 32,Loss: -1.717,Avg.Loss: -1.894,LR: 2.56E-04]Training epoch 50:  29%|██▊       | 32/112 [00:00<00:01, 53.25it/s, Epoch: 50, Batch: 33,Loss: -2.572,Avg.Loss: -1.915,LR: 2.56E-04]Training epoch 50:  29%|██▉       | 33/112 [00:00<00:01, 53.25it/s, Epoch: 50, Batch: 34,Loss: -2.327,Avg.Loss: -1.927,LR: 2.55E-04]Training epoch 50:  30%|███       | 34/112 [00:00<00:01, 53.25it/s, Epoch: 50, Batch: 35,Loss: -1.444,Avg.Loss: -1.913,LR: 2.55E-04]Training epoch 50:  31%|███▏      | 35/112 [00:00<00:01, 53.25it/s, Epoch: 50, Batch: 36,Loss: -1.670,Avg.Loss: -1.906,LR: 2.55E-04]Training epoch 50:  32%|███▏      | 36/112 [00:00<00:01, 53.31it/s, Epoch: 50, Batch: 36,Loss: -1.670,Avg.Loss: -1.906,LR: 2.55E-04]Training epoch 50:  32%|███▏      | 36/112 [00:00<00:01, 53.31it/s, Epoch: 50, Batch: 37,Loss: -2.474,Avg.Loss: -1.922,LR: 2.55E-04]Training epoch 50:  33%|███▎      | 37/112 [00:00<00:01, 53.31it/s, Epoch: 50, Batch: 38,Loss: -2.472,Avg.Loss: -1.936,LR: 2.55E-04]Training epoch 50:  34%|███▍      | 38/112 [00:00<00:01, 53.31it/s, Epoch: 50, Batch: 39,Loss: -1.404,Avg.Loss: -1.923,LR: 2.55E-04]Training epoch 50:  35%|███▍      | 39/112 [00:00<00:01, 53.31it/s, Epoch: 50, Batch: 40,Loss: -1.840,Avg.Loss: -1.921,LR: 2.55E-04]Training epoch 50:  36%|███▌      | 40/112 [00:00<00:01, 53.31it/s, Epoch: 50, Batch: 41,Loss: -2.618,Avg.Loss: -1.938,LR: 2.55E-04]Training epoch 50:  37%|███▋      | 41/112 [00:00<00:01, 53.31it/s, Epoch: 50, Batch: 42,Loss: -1.931,Avg.Loss: -1.937,LR: 2.55E-04]Training epoch 50:  38%|███▊      | 42/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 42,Loss: -1.931,Avg.Loss: -1.937,LR: 2.55E-04]Training epoch 50:  38%|███▊      | 42/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 43,Loss: -1.537,Avg.Loss: -1.928,LR: 2.55E-04]Training epoch 50:  38%|███▊      | 43/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 44,Loss: -1.816,Avg.Loss: -1.926,LR: 2.55E-04]Training epoch 50:  39%|███▉      | 44/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 45,Loss: -2.412,Avg.Loss: -1.936,LR: 2.55E-04]Training epoch 50:  40%|████      | 45/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 46,Loss: -2.298,Avg.Loss: -1.944,LR: 2.55E-04]Training epoch 50:  41%|████      | 46/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 47,Loss: -1.218,Avg.Loss: -1.929,LR: 2.55E-04]Training epoch 50:  42%|████▏     | 47/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 48,Loss: -1.376,Avg.Loss: -1.917,LR: 2.54E-04]Training epoch 50:  43%|████▎     | 48/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 48,Loss: -1.376,Avg.Loss: -1.917,LR: 2.54E-04]Training epoch 50:  43%|████▎     | 48/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 49,Loss: -1.980,Avg.Loss: -1.919,LR: 2.54E-04]Training epoch 50:  44%|████▍     | 49/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 50,Loss: -2.064,Avg.Loss: -1.921,LR: 2.54E-04]Training epoch 50:  45%|████▍     | 50/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 51,Loss: -1.855,Avg.Loss: -1.920,LR: 2.54E-04]Training epoch 50:  46%|████▌     | 51/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 52,Loss: -1.709,Avg.Loss: -1.916,LR: 2.54E-04]Training epoch 50:  46%|████▋     | 52/112 [00:00<00:01, 53.27it/s, Epoch: 50, Batch: 53,Loss: -2.569,Avg.Loss: -1.928,LR: 2.54E-04]Training epoch 50:  47%|████▋     | 53/112 [00:01<00:01, 53.27it/s, Epoch: 50, Batch: 54,Loss: -2.349,Avg.Loss: -1.936,LR: 2.54E-04]Training epoch 50:  48%|████▊     | 54/112 [00:01<00:01, 53.40it/s, Epoch: 50, Batch: 54,Loss: -2.349,Avg.Loss: -1.936,LR: 2.54E-04]Training epoch 50:  48%|████▊     | 54/112 [00:01<00:01, 53.40it/s, Epoch: 50, Batch: 55,Loss: -1.686,Avg.Loss: -1.932,LR: 2.54E-04]Training epoch 50:  49%|████▉     | 55/112 [00:01<00:01, 53.40it/s, Epoch: 50, Batch: 56,Loss: -1.512,Avg.Loss: -1.924,LR: 2.54E-04]Training epoch 50:  50%|█████     | 56/112 [00:01<00:01, 53.40it/s, Epoch: 50, Batch: 57,Loss: -2.544,Avg.Loss: -1.935,LR: 2.54E-04]Training epoch 50:  51%|█████     | 57/112 [00:01<00:01, 53.40it/s, Epoch: 50, Batch: 58,Loss: -2.187,Avg.Loss: -1.939,LR: 2.54E-04]Training epoch 50:  52%|█████▏    | 58/112 [00:01<00:01, 53.40it/s, Epoch: 50, Batch: 59,Loss: -1.098,Avg.Loss: -1.925,LR: 2.54E-04]Training epoch 50:  53%|█████▎    | 59/112 [00:01<00:00, 53.40it/s, Epoch: 50, Batch: 60,Loss: -1.456,Avg.Loss: -1.917,LR: 2.54E-04]Training epoch 50:  54%|█████▎    | 60/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 60,Loss: -1.456,Avg.Loss: -1.917,LR: 2.54E-04]Training epoch 50:  54%|█████▎    | 60/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 61,Loss: -2.351,Avg.Loss: -1.924,LR: 2.54E-04]Training epoch 50:  54%|█████▍    | 61/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 62,Loss: -2.740,Avg.Loss: -1.938,LR: 2.54E-04]Training epoch 50:  55%|█████▌    | 62/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 63,Loss: -1.851,Avg.Loss: -1.936,LR: 2.53E-04]Training epoch 50:  56%|█████▋    | 63/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 64,Loss: -2.021,Avg.Loss: -1.938,LR: 2.53E-04]Training epoch 50:  57%|█████▋    | 64/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 65,Loss: -2.473,Avg.Loss: -1.946,LR: 2.53E-04]Training epoch 50:  58%|█████▊    | 65/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 66,Loss: -2.174,Avg.Loss: -1.949,LR: 2.53E-04]Training epoch 50:  59%|█████▉    | 66/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 66,Loss: -2.174,Avg.Loss: -1.949,LR: 2.53E-04]Training epoch 50:  59%|█████▉    | 66/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 67,Loss: -1.548,Avg.Loss: -1.943,LR: 2.53E-04]Training epoch 50:  60%|█████▉    | 67/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 68,Loss: -1.795,Avg.Loss: -1.941,LR: 2.53E-04]Training epoch 50:  61%|██████    | 68/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 69,Loss: -2.449,Avg.Loss: -1.948,LR: 2.53E-04]Training epoch 50:  62%|██████▏   | 69/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 70,Loss: -2.410,Avg.Loss: -1.955,LR: 2.53E-04]Training epoch 50:  62%|██████▎   | 70/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 71,Loss: -1.407,Avg.Loss: -1.947,LR: 2.53E-04]Training epoch 50:  63%|██████▎   | 71/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 72,Loss: -1.637,Avg.Loss: -1.943,LR: 2.53E-04]Training epoch 50:  64%|██████▍   | 72/112 [00:01<00:00, 53.22it/s, Epoch: 50, Batch: 72,Loss: -1.637,Avg.Loss: -1.943,LR: 2.53E-04]Training epoch 50:  64%|██████▍   | 72/112 [00:01<00:00, 53.22it/s, Epoch: 50, Batch: 73,Loss: -2.483,Avg.Loss: -1.950,LR: 2.53E-04]Training epoch 50:  65%|██████▌   | 73/112 [00:01<00:00, 53.22it/s, Epoch: 50, Batch: 74,Loss: -2.173,Avg.Loss: -1.953,LR: 2.53E-04]Training epoch 50:  66%|██████▌   | 74/112 [00:01<00:00, 53.22it/s, Epoch: 50, Batch: 75,Loss: -1.610,Avg.Loss: -1.949,LR: 2.53E-04]Training epoch 50:  67%|██████▋   | 75/112 [00:01<00:00, 53.22it/s, Epoch: 50, Batch: 76,Loss: -2.024,Avg.Loss: -1.950,LR: 2.53E-04]Training epoch 50:  68%|██████▊   | 76/112 [00:01<00:00, 53.22it/s, Epoch: 50, Batch: 77,Loss: -2.165,Avg.Loss: -1.953,LR: 2.52E-04]Training epoch 50:  69%|██████▉   | 77/112 [00:01<00:00, 53.22it/s, Epoch: 50, Batch: 78,Loss: -1.734,Avg.Loss: -1.950,LR: 2.52E-04]Training epoch 50:  70%|██████▉   | 78/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 78,Loss: -1.734,Avg.Loss: -1.950,LR: 2.52E-04]Training epoch 50:  70%|██████▉   | 78/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 79,Loss: -0.975,Avg.Loss: -1.937,LR: 2.52E-04]Training epoch 50:  71%|███████   | 79/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 80,Loss: -1.091,Avg.Loss: -1.927,LR: 2.52E-04]Training epoch 50:  71%|███████▏  | 80/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 81,Loss: -2.569,Avg.Loss: -1.935,LR: 2.52E-04]Training epoch 50:  72%|███████▏  | 81/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 82,Loss: -2.227,Avg.Loss: -1.938,LR: 2.52E-04]Training epoch 50:  73%|███████▎  | 82/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 83,Loss: -1.489,Avg.Loss: -1.933,LR: 2.52E-04]Training epoch 50:  74%|███████▍  | 83/112 [00:01<00:00, 53.33it/s, Epoch: 50, Batch: 84,Loss: -1.407,Avg.Loss: -1.927,LR: 2.52E-04]Training epoch 50:  75%|███████▌  | 84/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 84,Loss: -1.407,Avg.Loss: -1.927,LR: 2.52E-04]Training epoch 50:  75%|███████▌  | 84/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 85,Loss: -2.400,Avg.Loss: -1.932,LR: 2.52E-04]Training epoch 50:  76%|███████▌  | 85/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 86,Loss: -2.449,Avg.Loss: -1.938,LR: 2.52E-04]Training epoch 50:  77%|███████▋  | 86/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 87,Loss: -1.855,Avg.Loss: -1.937,LR: 2.52E-04]Training epoch 50:  78%|███████▊  | 87/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 88,Loss: -2.000,Avg.Loss: -1.938,LR: 2.52E-04]Training epoch 50:  79%|███████▊  | 88/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 89,Loss: -2.613,Avg.Loss: -1.946,LR: 2.52E-04]Training epoch 50:  79%|███████▉  | 89/112 [00:01<00:00, 53.35it/s, Epoch: 50, Batch: 90,Loss: -2.182,Avg.Loss: -1.948,LR: 2.52E-04]Training epoch 50:  80%|████████  | 90/112 [00:01<00:00, 53.44it/s, Epoch: 50, Batch: 90,Loss: -2.182,Avg.Loss: -1.948,LR: 2.52E-04]Training epoch 50:  80%|████████  | 90/112 [00:01<00:00, 53.44it/s, Epoch: 50, Batch: 91,Loss: -1.079,Avg.Loss: -1.939,LR: 2.51E-04]Training epoch 50:  81%|████████▏ | 91/112 [00:01<00:00, 53.44it/s, Epoch: 50, Batch: 92,Loss: -1.493,Avg.Loss: -1.934,LR: 2.51E-04]Training epoch 50:  82%|████████▏ | 92/112 [00:01<00:00, 53.44it/s, Epoch: 50, Batch: 93,Loss: -2.003,Avg.Loss: -1.935,LR: 2.51E-04]Training epoch 50:  83%|████████▎ | 93/112 [00:01<00:00, 53.44it/s, Epoch: 50, Batch: 94,Loss: -2.130,Avg.Loss: -1.937,LR: 2.51E-04]Training epoch 50:  84%|████████▍ | 94/112 [00:01<00:00, 53.44it/s, Epoch: 50, Batch: 95,Loss: -2.289,Avg.Loss: -1.940,LR: 2.51E-04]Training epoch 50:  85%|████████▍ | 95/112 [00:01<00:00, 53.44it/s, Epoch: 50, Batch: 96,Loss: -2.071,Avg.Loss: -1.942,LR: 2.51E-04]Training epoch 50:  86%|████████▌ | 96/112 [00:01<00:00, 53.46it/s, Epoch: 50, Batch: 96,Loss: -2.071,Avg.Loss: -1.942,LR: 2.51E-04]Training epoch 50:  86%|████████▌ | 96/112 [00:01<00:00, 53.46it/s, Epoch: 50, Batch: 97,Loss: -2.565,Avg.Loss: -1.948,LR: 2.51E-04]Training epoch 50:  87%|████████▋ | 97/112 [00:01<00:00, 53.46it/s, Epoch: 50, Batch: 98,Loss: -2.275,Avg.Loss: -1.951,LR: 2.51E-04]Training epoch 50:  88%|████████▊ | 98/112 [00:01<00:00, 53.46it/s, Epoch: 50, Batch: 99,Loss: -2.257,Avg.Loss: -1.955,LR: 2.51E-04]Training epoch 50:  88%|████████▊ | 99/112 [00:01<00:00, 53.46it/s, Epoch: 50, Batch: 100,Loss: -2.048,Avg.Loss: -1.956,LR: 2.51E-04]Training epoch 50:  89%|████████▉ | 100/112 [00:01<00:00, 53.46it/s, Epoch: 50, Batch: 101,Loss: -1.950,Avg.Loss: -1.955,LR: 2.51E-04]Training epoch 50:  90%|█████████ | 101/112 [00:01<00:00, 53.46it/s, Epoch: 50, Batch: 102,Loss: -2.235,Avg.Loss: -1.958,LR: 2.51E-04]Training epoch 50:  91%|█████████ | 102/112 [00:01<00:00, 53.48it/s, Epoch: 50, Batch: 102,Loss: -2.235,Avg.Loss: -1.958,LR: 2.51E-04]Training epoch 50:  91%|█████████ | 102/112 [00:01<00:00, 53.48it/s, Epoch: 50, Batch: 103,Loss: -2.627,Avg.Loss: -1.965,LR: 2.51E-04]Training epoch 50:  92%|█████████▏| 103/112 [00:01<00:00, 53.48it/s, Epoch: 50, Batch: 104,Loss: -2.254,Avg.Loss: -1.967,LR: 2.51E-04]Training epoch 50:  93%|█████████▎| 104/112 [00:01<00:00, 53.48it/s, Epoch: 50, Batch: 105,Loss: -2.046,Avg.Loss: -1.968,LR: 2.50E-04]Training epoch 50:  94%|█████████▍| 105/112 [00:01<00:00, 53.48it/s, Epoch: 50, Batch: 106,Loss: -1.892,Avg.Loss: -1.967,LR: 2.50E-04]Training epoch 50:  95%|█████████▍| 106/112 [00:02<00:00, 53.48it/s, Epoch: 50, Batch: 107,Loss: -2.361,Avg.Loss: -1.971,LR: 2.50E-04]Training epoch 50:  96%|█████████▌| 107/112 [00:02<00:00, 53.48it/s, Epoch: 50, Batch: 108,Loss: -2.235,Avg.Loss: -1.974,LR: 2.50E-04]Training epoch 50:  96%|█████████▋| 108/112 [00:02<00:00, 53.25it/s, Epoch: 50, Batch: 108,Loss: -2.235,Avg.Loss: -1.974,LR: 2.50E-04]Training epoch 50:  96%|█████████▋| 108/112 [00:02<00:00, 53.25it/s, Epoch: 50, Batch: 109,Loss: -2.483,Avg.Loss: -1.978,LR: 2.50E-04]Training epoch 50:  97%|█████████▋| 109/112 [00:02<00:00, 53.25it/s, Epoch: 50, Batch: 110,Loss: -2.749,Avg.Loss: -1.985,LR: 2.50E-04]Training epoch 50:  98%|█████████▊| 110/112 [00:02<00:00, 53.25it/s, Epoch: 50, Batch: 111,Loss: -2.156,Avg.Loss: -1.987,LR: 2.50E-04]Training epoch 50:  99%|█████████▉| 111/112 [00:02<00:00, 53.25it/s, Epoch: 50, Batch: 112,Loss: -2.006,Avg.Loss: -1.987,LR: 2.50E-04]Training epoch 50: 100%|██████████| 112/112 [00:02<00:00, 53.30it/s, Epoch: 50, Batch: 112,Loss: -2.006,Avg.Loss: -1.987,LR: 2.50E-04]
Training epoch 51:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 51:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 51, Batch: 1,Loss: -1.869,Avg.Loss: -1.869,LR: 2.50E-04]Training epoch 51:   1%|          | 1/112 [00:00<00:04, 27.61it/s, Epoch: 51, Batch: 2,Loss: -2.021,Avg.Loss: -1.945,LR: 2.50E-04]Training epoch 51:   2%|▏         | 2/112 [00:00<00:02, 37.10it/s, Epoch: 51, Batch: 3,Loss: -1.608,Avg.Loss: -1.833,LR: 2.50E-04]Training epoch 51:   3%|▎         | 3/112 [00:00<00:02, 42.33it/s, Epoch: 51, Batch: 4,Loss: -1.167,Avg.Loss: -1.666,LR: 2.50E-04]Training epoch 51:   4%|▎         | 4/112 [00:00<00:02, 44.46it/s, Epoch: 51, Batch: 5,Loss: -1.513,Avg.Loss: -1.636,LR: 2.50E-04]Training epoch 51:   4%|▍         | 5/112 [00:00<00:02, 45.90it/s, Epoch: 51, Batch: 6,Loss: -1.584,Avg.Loss: -1.627,LR: 2.50E-04]Training epoch 51:   5%|▌         | 6/112 [00:00<00:01, 54.99it/s, Epoch: 51, Batch: 6,Loss: -1.584,Avg.Loss: -1.627,LR: 2.50E-04]Training epoch 51:   5%|▌         | 6/112 [00:00<00:01, 54.99it/s, Epoch: 51, Batch: 7,Loss: -2.216,Avg.Loss: -1.711,LR: 2.50E-04]Training epoch 51:   6%|▋         | 7/112 [00:00<00:01, 54.99it/s, Epoch: 51, Batch: 8,Loss: -2.021,Avg.Loss: -1.750,LR: 2.49E-04]Training epoch 51:   7%|▋         | 8/112 [00:00<00:01, 54.99it/s, Epoch: 51, Batch: 9,Loss: -2.102,Avg.Loss: -1.789,LR: 2.49E-04]Training epoch 51:   8%|▊         | 9/112 [00:00<00:01, 54.99it/s, Epoch: 51, Batch: 10,Loss: -1.655,Avg.Loss: -1.776,LR: 2.49E-04]Training epoch 51:   9%|▉         | 10/112 [00:00<00:01, 54.99it/s, Epoch: 51, Batch: 11,Loss: -0.948,Avg.Loss: -1.700,LR: 2.49E-04]Training epoch 51:  10%|▉         | 11/112 [00:00<00:01, 54.99it/s, Epoch: 51, Batch: 12,Loss: -0.756,Avg.Loss: -1.622,LR: 2.49E-04]Training epoch 51:  11%|█         | 12/112 [00:00<00:01, 52.72it/s, Epoch: 51, Batch: 12,Loss: -0.756,Avg.Loss: -1.622,LR: 2.49E-04]Training epoch 51:  11%|█         | 12/112 [00:00<00:01, 52.72it/s, Epoch: 51, Batch: 13,Loss: -1.190,Avg.Loss: -1.588,LR: 2.49E-04]Training epoch 51:  12%|█▏        | 13/112 [00:00<00:01, 52.72it/s, Epoch: 51, Batch: 14,Loss: -2.097,Avg.Loss: -1.625,LR: 2.49E-04]Training epoch 51:  12%|█▎        | 14/112 [00:00<00:01, 52.72it/s, Epoch: 51, Batch: 15,Loss: -1.841,Avg.Loss: -1.639,LR: 2.49E-04]Training epoch 51:  13%|█▎        | 15/112 [00:00<00:01, 52.72it/s, Epoch: 51, Batch: 16,Loss: -2.006,Avg.Loss: -1.662,LR: 2.49E-04]Training epoch 51:  14%|█▍        | 16/112 [00:00<00:01, 52.72it/s, Epoch: 51, Batch: 17,Loss: -1.898,Avg.Loss: -1.676,LR: 2.49E-04]Training epoch 51:  15%|█▌        | 17/112 [00:00<00:01, 52.72it/s, Epoch: 51, Batch: 18,Loss: -1.798,Avg.Loss: -1.683,LR: 2.49E-04]Training epoch 51:  16%|█▌        | 18/112 [00:00<00:01, 52.80it/s, Epoch: 51, Batch: 18,Loss: -1.798,Avg.Loss: -1.683,LR: 2.49E-04]Training epoch 51:  16%|█▌        | 18/112 [00:00<00:01, 52.80it/s, Epoch: 51, Batch: 19,Loss: -2.275,Avg.Loss: -1.714,LR: 2.49E-04]Training epoch 51:  17%|█▋        | 19/112 [00:00<00:01, 52.80it/s, Epoch: 51, Batch: 20,Loss: -2.310,Avg.Loss: -1.744,LR: 2.49E-04]Training epoch 51:  18%|█▊        | 20/112 [00:00<00:01, 52.80it/s, Epoch: 51, Batch: 21,Loss: -2.370,Avg.Loss: -1.774,LR: 2.49E-04]Training epoch 51:  19%|█▉        | 21/112 [00:00<00:01, 52.80it/s, Epoch: 51, Batch: 22,Loss: -2.084,Avg.Loss: -1.788,LR: 2.48E-04]Training epoch 51:  20%|█▉        | 22/112 [00:00<00:01, 52.80it/s, Epoch: 51, Batch: 23,Loss: -1.475,Avg.Loss: -1.774,LR: 2.48E-04]Training epoch 51:  21%|██        | 23/112 [00:00<00:01, 52.80it/s, Epoch: 51, Batch: 24,Loss: -1.572,Avg.Loss: -1.766,LR: 2.48E-04]Training epoch 51:  21%|██▏       | 24/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 24,Loss: -1.572,Avg.Loss: -1.766,LR: 2.48E-04]Training epoch 51:  21%|██▏       | 24/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 25,Loss: -2.092,Avg.Loss: -1.779,LR: 2.48E-04]Training epoch 51:  22%|██▏       | 25/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 26,Loss: -1.837,Avg.Loss: -1.781,LR: 2.48E-04]Training epoch 51:  23%|██▎       | 26/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 27,Loss: -2.542,Avg.Loss: -1.809,LR: 2.48E-04]Training epoch 51:  24%|██▍       | 27/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 28,Loss: -2.444,Avg.Loss: -1.832,LR: 2.48E-04]Training epoch 51:  25%|██▌       | 28/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 29,Loss: -1.938,Avg.Loss: -1.835,LR: 2.48E-04]Training epoch 51:  26%|██▌       | 29/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 30,Loss: -2.199,Avg.Loss: -1.848,LR: 2.48E-04]Training epoch 51:  27%|██▋       | 30/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 30,Loss: -2.199,Avg.Loss: -1.848,LR: 2.48E-04]Training epoch 51:  27%|██▋       | 30/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 31,Loss: -2.289,Avg.Loss: -1.862,LR: 2.48E-04]Training epoch 51:  28%|██▊       | 31/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 32,Loss: -2.359,Avg.Loss: -1.877,LR: 2.48E-04]Training epoch 51:  29%|██▊       | 32/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 33,Loss: -2.122,Avg.Loss: -1.885,LR: 2.48E-04]Training epoch 51:  29%|██▉       | 33/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 34,Loss: -1.844,Avg.Loss: -1.884,LR: 2.48E-04]Training epoch 51:  30%|███       | 34/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 35,Loss: -2.574,Avg.Loss: -1.903,LR: 2.48E-04]Training epoch 51:  31%|███▏      | 35/112 [00:00<00:01, 52.02it/s, Epoch: 51, Batch: 36,Loss: -1.471,Avg.Loss: -1.891,LR: 2.47E-04]Training epoch 51:  32%|███▏      | 36/112 [00:00<00:01, 52.53it/s, Epoch: 51, Batch: 36,Loss: -1.471,Avg.Loss: -1.891,LR: 2.47E-04]Training epoch 51:  32%|███▏      | 36/112 [00:00<00:01, 52.53it/s, Epoch: 51, Batch: 37,Loss: -1.213,Avg.Loss: -1.873,LR: 2.47E-04]Training epoch 51:  33%|███▎      | 37/112 [00:00<00:01, 52.53it/s, Epoch: 51, Batch: 38,Loss: -1.631,Avg.Loss: -1.867,LR: 2.47E-04]Training epoch 51:  34%|███▍      | 38/112 [00:00<00:01, 52.53it/s, Epoch: 51, Batch: 39,Loss: -2.424,Avg.Loss: -1.881,LR: 2.47E-04]Training epoch 51:  35%|███▍      | 39/112 [00:00<00:01, 52.53it/s, Epoch: 51, Batch: 40,Loss: -2.345,Avg.Loss: -1.892,LR: 2.47E-04]Training epoch 51:  36%|███▌      | 40/112 [00:00<00:01, 52.53it/s, Epoch: 51, Batch: 41,Loss: -2.703,Avg.Loss: -1.912,LR: 2.47E-04]Training epoch 51:  37%|███▋      | 41/112 [00:00<00:01, 52.53it/s, Epoch: 51, Batch: 42,Loss: -2.320,Avg.Loss: -1.922,LR: 2.47E-04]Training epoch 51:  38%|███▊      | 42/112 [00:00<00:01, 52.82it/s, Epoch: 51, Batch: 42,Loss: -2.320,Avg.Loss: -1.922,LR: 2.47E-04]Training epoch 51:  38%|███▊      | 42/112 [00:00<00:01, 52.82it/s, Epoch: 51, Batch: 43,Loss: -2.268,Avg.Loss: -1.930,LR: 2.47E-04]Training epoch 51:  38%|███▊      | 43/112 [00:00<00:01, 52.82it/s, Epoch: 51, Batch: 44,Loss: -2.378,Avg.Loss: -1.940,LR: 2.47E-04]Training epoch 51:  39%|███▉      | 44/112 [00:00<00:01, 52.82it/s, Epoch: 51, Batch: 45,Loss: -2.045,Avg.Loss: -1.943,LR: 2.47E-04]Training epoch 51:  40%|████      | 45/112 [00:00<00:01, 52.82it/s, Epoch: 51, Batch: 46,Loss: -1.931,Avg.Loss: -1.942,LR: 2.47E-04]Training epoch 51:  41%|████      | 46/112 [00:00<00:01, 52.82it/s, Epoch: 51, Batch: 47,Loss: -2.567,Avg.Loss: -1.956,LR: 2.47E-04]Training epoch 51:  42%|████▏     | 47/112 [00:00<00:01, 52.82it/s, Epoch: 51, Batch: 48,Loss: -2.559,Avg.Loss: -1.968,LR: 2.47E-04]Training epoch 51:  43%|████▎     | 48/112 [00:00<00:01, 52.96it/s, Epoch: 51, Batch: 48,Loss: -2.559,Avg.Loss: -1.968,LR: 2.47E-04]Training epoch 51:  43%|████▎     | 48/112 [00:00<00:01, 52.96it/s, Epoch: 51, Batch: 49,Loss: -2.299,Avg.Loss: -1.975,LR: 2.47E-04]Training epoch 51:  44%|████▍     | 49/112 [00:00<00:01, 52.96it/s, Epoch: 51, Batch: 50,Loss: -2.364,Avg.Loss: -1.983,LR: 2.46E-04]Training epoch 51:  45%|████▍     | 50/112 [00:00<00:01, 52.96it/s, Epoch: 51, Batch: 51,Loss: -2.302,Avg.Loss: -1.989,LR: 2.46E-04]Training epoch 51:  46%|████▌     | 51/112 [00:00<00:01, 52.96it/s, Epoch: 51, Batch: 52,Loss: -2.721,Avg.Loss: -2.003,LR: 2.46E-04]Training epoch 51:  46%|████▋     | 52/112 [00:01<00:01, 52.96it/s, Epoch: 51, Batch: 53,Loss: -2.341,Avg.Loss: -2.009,LR: 2.46E-04]Training epoch 51:  47%|████▋     | 53/112 [00:01<00:01, 52.96it/s, Epoch: 51, Batch: 54,Loss: -2.582,Avg.Loss: -2.020,LR: 2.46E-04]Training epoch 51:  48%|████▊     | 54/112 [00:01<00:01, 53.01it/s, Epoch: 51, Batch: 54,Loss: -2.582,Avg.Loss: -2.020,LR: 2.46E-04]Training epoch 51:  48%|████▊     | 54/112 [00:01<00:01, 53.01it/s, Epoch: 51, Batch: 55,Loss: -2.437,Avg.Loss: -2.028,LR: 2.46E-04]Training epoch 51:  49%|████▉     | 55/112 [00:01<00:01, 53.01it/s, Epoch: 51, Batch: 56,Loss: -2.897,Avg.Loss: -2.043,LR: 2.46E-04]Training epoch 51:  50%|█████     | 56/112 [00:01<00:01, 53.01it/s, Epoch: 51, Batch: 57,Loss: -2.638,Avg.Loss: -2.054,LR: 2.46E-04]Training epoch 51:  51%|█████     | 57/112 [00:01<00:01, 53.01it/s, Epoch: 51, Batch: 58,Loss: -2.450,Avg.Loss: -2.060,LR: 2.46E-04]Training epoch 51:  52%|█████▏    | 58/112 [00:01<00:01, 53.01it/s, Epoch: 51, Batch: 59,Loss: -2.521,Avg.Loss: -2.068,LR: 2.46E-04]Training epoch 51:  53%|█████▎    | 59/112 [00:01<00:00, 53.01it/s, Epoch: 51, Batch: 60,Loss: -2.728,Avg.Loss: -2.079,LR: 2.46E-04]Training epoch 51:  54%|█████▎    | 60/112 [00:01<00:00, 53.06it/s, Epoch: 51, Batch: 60,Loss: -2.728,Avg.Loss: -2.079,LR: 2.46E-04]Training epoch 51:  54%|█████▎    | 60/112 [00:01<00:00, 53.06it/s, Epoch: 51, Batch: 61,Loss: -2.906,Avg.Loss: -2.093,LR: 2.46E-04]Training epoch 51:  54%|█████▍    | 61/112 [00:01<00:00, 53.06it/s, Epoch: 51, Batch: 62,Loss: -2.130,Avg.Loss: -2.093,LR: 2.46E-04]Training epoch 51:  55%|█████▌    | 62/112 [00:01<00:00, 53.06it/s, Epoch: 51, Batch: 63,Loss: -1.760,Avg.Loss: -2.088,LR: 2.46E-04]Training epoch 51:  56%|█████▋    | 63/112 [00:01<00:00, 53.06it/s, Epoch: 51, Batch: 64,Loss: -0.880,Avg.Loss: -2.069,LR: 2.46E-04]Training epoch 51:  57%|█████▋    | 64/112 [00:01<00:00, 53.06it/s, Epoch: 51, Batch: 65,Loss: -1.143,Avg.Loss: -2.055,LR: 2.45E-04]Training epoch 51:  58%|█████▊    | 65/112 [00:01<00:00, 53.06it/s, Epoch: 51, Batch: 66,Loss: -2.529,Avg.Loss: -2.062,LR: 2.45E-04]Training epoch 51:  59%|█████▉    | 66/112 [00:01<00:00, 53.00it/s, Epoch: 51, Batch: 66,Loss: -2.529,Avg.Loss: -2.062,LR: 2.45E-04]Training epoch 51:  59%|█████▉    | 66/112 [00:01<00:00, 53.00it/s, Epoch: 51, Batch: 67,Loss: -0.803,Avg.Loss: -2.043,LR: 2.45E-04]Training epoch 51:  60%|█████▉    | 67/112 [00:01<00:00, 53.00it/s, Epoch: 51, Batch: 68,Loss: 0.302,Avg.Loss: -2.009,LR: 2.45E-04] Training epoch 51:  61%|██████    | 68/112 [00:01<00:00, 53.00it/s, Epoch: 51, Batch: 69,Loss: -0.581,Avg.Loss: -1.988,LR: 2.45E-04]Training epoch 51:  62%|██████▏   | 69/112 [00:01<00:00, 53.00it/s, Epoch: 51, Batch: 70,Loss: -2.267,Avg.Loss: -1.992,LR: 2.45E-04]Training epoch 51:  62%|██████▎   | 70/112 [00:01<00:00, 53.00it/s, Epoch: 51, Batch: 71,Loss: -1.117,Avg.Loss: -1.980,LR: 2.45E-04]Training epoch 51:  63%|██████▎   | 71/112 [00:01<00:00, 53.00it/s, Epoch: 51, Batch: 72,Loss: 0.830,Avg.Loss: -1.941,LR: 2.45E-04] Training epoch 51:  64%|██████▍   | 72/112 [00:01<00:00, 52.96it/s, Epoch: 51, Batch: 72,Loss: 0.830,Avg.Loss: -1.941,LR: 2.45E-04]Training epoch 51:  64%|██████▍   | 72/112 [00:01<00:00, 52.96it/s, Epoch: 51, Batch: 73,Loss: 0.559,Avg.Loss: -1.906,LR: 2.45E-04]Training epoch 51:  65%|██████▌   | 73/112 [00:01<00:00, 52.96it/s, Epoch: 51, Batch: 74,Loss: -1.248,Avg.Loss: -1.898,LR: 2.45E-04]Training epoch 51:  66%|██████▌   | 74/112 [00:01<00:00, 52.96it/s, Epoch: 51, Batch: 75,Loss: -2.374,Avg.Loss: -1.904,LR: 2.45E-04]Training epoch 51:  67%|██████▋   | 75/112 [00:01<00:00, 52.96it/s, Epoch: 51, Batch: 76,Loss: -1.911,Avg.Loss: -1.904,LR: 2.45E-04]Training epoch 51:  68%|██████▊   | 76/112 [00:01<00:00, 52.96it/s, Epoch: 51, Batch: 77,Loss: -1.914,Avg.Loss: -1.904,LR: 2.45E-04]Training epoch 51:  69%|██████▉   | 77/112 [00:01<00:00, 52.96it/s, Epoch: 51, Batch: 78,Loss: -2.636,Avg.Loss: -1.914,LR: 2.45E-04]Training epoch 51:  70%|██████▉   | 78/112 [00:01<00:00, 53.04it/s, Epoch: 51, Batch: 78,Loss: -2.636,Avg.Loss: -1.914,LR: 2.45E-04]Training epoch 51:  70%|██████▉   | 78/112 [00:01<00:00, 53.04it/s, Epoch: 51, Batch: 79,Loss: -1.097,Avg.Loss: -1.903,LR: 2.44E-04]Training epoch 51:  71%|███████   | 79/112 [00:01<00:00, 53.04it/s, Epoch: 51, Batch: 80,Loss: 0.708,Avg.Loss: -1.871,LR: 2.44E-04] Training epoch 51:  71%|███████▏  | 80/112 [00:01<00:00, 53.04it/s, Epoch: 51, Batch: 81,Loss: -0.868,Avg.Loss: -1.858,LR: 2.44E-04]Training epoch 51:  72%|███████▏  | 81/112 [00:01<00:00, 53.04it/s, Epoch: 51, Batch: 82,Loss: -2.312,Avg.Loss: -1.864,LR: 2.44E-04]Training epoch 51:  73%|███████▎  | 82/112 [00:01<00:00, 53.04it/s, Epoch: 51, Batch: 83,Loss: -2.134,Avg.Loss: -1.867,LR: 2.44E-04]Training epoch 51:  74%|███████▍  | 83/112 [00:01<00:00, 53.04it/s, Epoch: 51, Batch: 84,Loss: -2.358,Avg.Loss: -1.873,LR: 2.44E-04]Training epoch 51:  75%|███████▌  | 84/112 [00:01<00:00, 53.12it/s, Epoch: 51, Batch: 84,Loss: -2.358,Avg.Loss: -1.873,LR: 2.44E-04]Training epoch 51:  75%|███████▌  | 84/112 [00:01<00:00, 53.12it/s, Epoch: 51, Batch: 85,Loss: -2.452,Avg.Loss: -1.880,LR: 2.44E-04]Training epoch 51:  76%|███████▌  | 85/112 [00:01<00:00, 53.12it/s, Epoch: 51, Batch: 86,Loss: -2.762,Avg.Loss: -1.890,LR: 2.44E-04]Training epoch 51:  77%|███████▋  | 86/112 [00:01<00:00, 53.12it/s, Epoch: 51, Batch: 87,Loss: -2.699,Avg.Loss: -1.899,LR: 2.44E-04]Training epoch 51:  78%|███████▊  | 87/112 [00:01<00:00, 53.12it/s, Epoch: 51, Batch: 88,Loss: -2.370,Avg.Loss: -1.905,LR: 2.44E-04]Training epoch 51:  79%|███████▊  | 88/112 [00:01<00:00, 53.12it/s, Epoch: 51, Batch: 89,Loss: -2.129,Avg.Loss: -1.907,LR: 2.44E-04]Training epoch 51:  79%|███████▉  | 89/112 [00:01<00:00, 53.12it/s, Epoch: 51, Batch: 90,Loss: -2.409,Avg.Loss: -1.913,LR: 2.44E-04]Training epoch 51:  80%|████████  | 90/112 [00:01<00:00, 53.44it/s, Epoch: 51, Batch: 90,Loss: -2.409,Avg.Loss: -1.913,LR: 2.44E-04]Training epoch 51:  80%|████████  | 90/112 [00:01<00:00, 53.44it/s, Epoch: 51, Batch: 91,Loss: -1.947,Avg.Loss: -1.913,LR: 2.44E-04]Training epoch 51:  81%|████████▏ | 91/112 [00:01<00:00, 53.44it/s, Epoch: 51, Batch: 92,Loss: -1.408,Avg.Loss: -1.908,LR: 2.44E-04]Training epoch 51:  82%|████████▏ | 92/112 [00:01<00:00, 53.44it/s, Epoch: 51, Batch: 93,Loss: -1.408,Avg.Loss: -1.902,LR: 2.43E-04]Training epoch 51:  83%|████████▎ | 93/112 [00:01<00:00, 53.44it/s, Epoch: 51, Batch: 94,Loss: -2.006,Avg.Loss: -1.903,LR: 2.43E-04]Training epoch 51:  84%|████████▍ | 94/112 [00:01<00:00, 53.44it/s, Epoch: 51, Batch: 95,Loss: -1.394,Avg.Loss: -1.898,LR: 2.43E-04]Training epoch 51:  85%|████████▍ | 95/112 [00:01<00:00, 53.44it/s, Epoch: 51, Batch: 96,Loss: -1.092,Avg.Loss: -1.890,LR: 2.43E-04]Training epoch 51:  86%|████████▌ | 96/112 [00:01<00:00, 52.33it/s, Epoch: 51, Batch: 96,Loss: -1.092,Avg.Loss: -1.890,LR: 2.43E-04]Training epoch 51:  86%|████████▌ | 96/112 [00:01<00:00, 52.33it/s, Epoch: 51, Batch: 97,Loss: -0.821,Avg.Loss: -1.879,LR: 2.43E-04]Training epoch 51:  87%|████████▋ | 97/112 [00:01<00:00, 52.33it/s, Epoch: 51, Batch: 98,Loss: -1.145,Avg.Loss: -1.871,LR: 2.43E-04]Training epoch 51:  88%|████████▊ | 98/112 [00:01<00:00, 52.33it/s, Epoch: 51, Batch: 99,Loss: -1.341,Avg.Loss: -1.866,LR: 2.43E-04]Training epoch 51:  88%|████████▊ | 99/112 [00:01<00:00, 52.33it/s, Epoch: 51, Batch: 100,Loss: -2.480,Avg.Loss: -1.872,LR: 2.43E-04]Training epoch 51:  89%|████████▉ | 100/112 [00:01<00:00, 52.33it/s, Epoch: 51, Batch: 101,Loss: -2.813,Avg.Loss: -1.881,LR: 2.43E-04]Training epoch 51:  90%|█████████ | 101/112 [00:01<00:00, 52.33it/s, Epoch: 51, Batch: 102,Loss: -2.507,Avg.Loss: -1.887,LR: 2.43E-04]Training epoch 51:  91%|█████████ | 102/112 [00:01<00:00, 52.71it/s, Epoch: 51, Batch: 102,Loss: -2.507,Avg.Loss: -1.887,LR: 2.43E-04]Training epoch 51:  91%|█████████ | 102/112 [00:01<00:00, 52.71it/s, Epoch: 51, Batch: 103,Loss: -2.548,Avg.Loss: -1.894,LR: 2.43E-04]Training epoch 51:  92%|█████████▏| 103/112 [00:01<00:00, 52.71it/s, Epoch: 51, Batch: 104,Loss: -2.141,Avg.Loss: -1.896,LR: 2.43E-04]Training epoch 51:  93%|█████████▎| 104/112 [00:01<00:00, 52.71it/s, Epoch: 51, Batch: 105,Loss: -1.323,Avg.Loss: -1.891,LR: 2.43E-04]Training epoch 51:  94%|█████████▍| 105/112 [00:02<00:00, 52.71it/s, Epoch: 51, Batch: 106,Loss: -2.288,Avg.Loss: -1.894,LR: 2.43E-04]Training epoch 51:  95%|█████████▍| 106/112 [00:02<00:00, 52.71it/s, Epoch: 51, Batch: 107,Loss: -2.438,Avg.Loss: -1.899,LR: 2.42E-04]Training epoch 51:  96%|█████████▌| 107/112 [00:02<00:00, 52.71it/s, Epoch: 51, Batch: 108,Loss: -2.145,Avg.Loss: -1.902,LR: 2.42E-04]Training epoch 51:  96%|█████████▋| 108/112 [00:02<00:00, 52.55it/s, Epoch: 51, Batch: 108,Loss: -2.145,Avg.Loss: -1.902,LR: 2.42E-04]Training epoch 51:  96%|█████████▋| 108/112 [00:02<00:00, 52.55it/s, Epoch: 51, Batch: 109,Loss: -3.196,Avg.Loss: -1.914,LR: 2.42E-04]Training epoch 51:  97%|█████████▋| 109/112 [00:02<00:00, 52.55it/s, Epoch: 51, Batch: 110,Loss: -2.390,Avg.Loss: -1.918,LR: 2.42E-04]Training epoch 51:  98%|█████████▊| 110/112 [00:02<00:00, 52.55it/s, Epoch: 51, Batch: 111,Loss: -2.240,Avg.Loss: -1.921,LR: 2.42E-04]Training epoch 51:  99%|█████████▉| 111/112 [00:02<00:00, 52.55it/s, Epoch: 51, Batch: 112,Loss: -3.019,Avg.Loss: -1.931,LR: 2.42E-04]Training epoch 51: 100%|██████████| 112/112 [00:02<00:00, 52.74it/s, Epoch: 51, Batch: 112,Loss: -3.019,Avg.Loss: -1.931,LR: 2.42E-04]
Training epoch 52:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 52:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 52, Batch: 1,Loss: -2.273,Avg.Loss: -2.273,LR: 2.42E-04]Training epoch 52:   1%|          | 1/112 [00:00<00:03, 29.11it/s, Epoch: 52, Batch: 2,Loss: -1.956,Avg.Loss: -2.114,LR: 2.42E-04]Training epoch 52:   2%|▏         | 2/112 [00:00<00:02, 40.32it/s, Epoch: 52, Batch: 3,Loss: -2.298,Avg.Loss: -2.176,LR: 2.42E-04]Training epoch 52:   3%|▎         | 3/112 [00:00<00:02, 47.72it/s, Epoch: 52, Batch: 4,Loss: -2.657,Avg.Loss: -2.296,LR: 2.42E-04]Training epoch 52:   4%|▎         | 4/112 [00:00<00:02, 50.28it/s, Epoch: 52, Batch: 5,Loss: -1.914,Avg.Loss: -2.220,LR: 2.42E-04]Training epoch 52:   4%|▍         | 5/112 [00:00<00:02, 51.83it/s, Epoch: 52, Batch: 6,Loss: -2.615,Avg.Loss: -2.285,LR: 2.42E-04]Training epoch 52:   5%|▌         | 6/112 [00:00<00:02, 52.90it/s, Epoch: 52, Batch: 7,Loss: -2.464,Avg.Loss: -2.311,LR: 2.42E-04]Training epoch 52:   6%|▋         | 7/112 [00:00<00:01, 61.61it/s, Epoch: 52, Batch: 7,Loss: -2.464,Avg.Loss: -2.311,LR: 2.42E-04]Training epoch 52:   6%|▋         | 7/112 [00:00<00:01, 61.61it/s, Epoch: 52, Batch: 8,Loss: -2.204,Avg.Loss: -2.298,LR: 2.42E-04]Training epoch 52:   7%|▋         | 8/112 [00:00<00:01, 61.61it/s, Epoch: 52, Batch: 9,Loss: -3.012,Avg.Loss: -2.377,LR: 2.42E-04]Training epoch 52:   8%|▊         | 9/112 [00:00<00:01, 61.61it/s, Epoch: 52, Batch: 10,Loss: -2.433,Avg.Loss: -2.383,LR: 2.41E-04]Training epoch 52:   9%|▉         | 10/112 [00:00<00:01, 61.61it/s, Epoch: 52, Batch: 11,Loss: -2.071,Avg.Loss: -2.354,LR: 2.41E-04]Training epoch 52:  10%|▉         | 11/112 [00:00<00:01, 61.61it/s, Epoch: 52, Batch: 12,Loss: -2.219,Avg.Loss: -2.343,LR: 2.41E-04]Training epoch 52:  11%|█         | 12/112 [00:00<00:01, 61.61it/s, Epoch: 52, Batch: 13,Loss: -2.753,Avg.Loss: -2.375,LR: 2.41E-04]Training epoch 52:  12%|█▏        | 13/112 [00:00<00:01, 61.61it/s, Epoch: 52, Batch: 14,Loss: -2.507,Avg.Loss: -2.384,LR: 2.41E-04]Training epoch 52:  12%|█▎        | 14/112 [00:00<00:01, 56.97it/s, Epoch: 52, Batch: 14,Loss: -2.507,Avg.Loss: -2.384,LR: 2.41E-04]Training epoch 52:  12%|█▎        | 14/112 [00:00<00:01, 56.97it/s, Epoch: 52, Batch: 15,Loss: -2.912,Avg.Loss: -2.419,LR: 2.41E-04]Training epoch 52:  13%|█▎        | 15/112 [00:00<00:01, 56.97it/s, Epoch: 52, Batch: 16,Loss: -2.152,Avg.Loss: -2.403,LR: 2.41E-04]Training epoch 52:  14%|█▍        | 16/112 [00:00<00:01, 56.97it/s, Epoch: 52, Batch: 17,Loss: -2.172,Avg.Loss: -2.389,LR: 2.41E-04]Training epoch 52:  15%|█▌        | 17/112 [00:00<00:01, 56.97it/s, Epoch: 52, Batch: 18,Loss: -2.783,Avg.Loss: -2.411,LR: 2.41E-04]Training epoch 52:  16%|█▌        | 18/112 [00:00<00:01, 56.97it/s, Epoch: 52, Batch: 19,Loss: -2.478,Avg.Loss: -2.414,LR: 2.41E-04]Training epoch 52:  17%|█▋        | 19/112 [00:00<00:01, 56.97it/s, Epoch: 52, Batch: 20,Loss: -2.384,Avg.Loss: -2.413,LR: 2.41E-04]Training epoch 52:  18%|█▊        | 20/112 [00:00<00:01, 56.04it/s, Epoch: 52, Batch: 20,Loss: -2.384,Avg.Loss: -2.413,LR: 2.41E-04]Training epoch 52:  18%|█▊        | 20/112 [00:00<00:01, 56.04it/s, Epoch: 52, Batch: 21,Loss: -2.754,Avg.Loss: -2.429,LR: 2.41E-04]Training epoch 52:  19%|█▉        | 21/112 [00:00<00:01, 56.04it/s, Epoch: 52, Batch: 22,Loss: -2.533,Avg.Loss: -2.434,LR: 2.41E-04]Training epoch 52:  20%|█▉        | 22/112 [00:00<00:01, 56.04it/s, Epoch: 52, Batch: 23,Loss: -1.832,Avg.Loss: -2.408,LR: 2.41E-04]Training epoch 52:  21%|██        | 23/112 [00:00<00:01, 56.04it/s, Epoch: 52, Batch: 24,Loss: -2.412,Avg.Loss: -2.408,LR: 2.40E-04]Training epoch 52:  21%|██▏       | 24/112 [00:00<00:01, 56.04it/s, Epoch: 52, Batch: 25,Loss: -2.577,Avg.Loss: -2.415,LR: 2.40E-04]Training epoch 52:  22%|██▏       | 25/112 [00:00<00:01, 56.04it/s, Epoch: 52, Batch: 26,Loss: -2.473,Avg.Loss: -2.417,LR: 2.40E-04]Training epoch 52:  23%|██▎       | 26/112 [00:00<00:01, 55.30it/s, Epoch: 52, Batch: 26,Loss: -2.473,Avg.Loss: -2.417,LR: 2.40E-04]Training epoch 52:  23%|██▎       | 26/112 [00:00<00:01, 55.30it/s, Epoch: 52, Batch: 27,Loss: -2.876,Avg.Loss: -2.434,LR: 2.40E-04]Training epoch 52:  24%|██▍       | 27/112 [00:00<00:01, 55.30it/s, Epoch: 52, Batch: 28,Loss: -2.309,Avg.Loss: -2.429,LR: 2.40E-04]Training epoch 52:  25%|██▌       | 28/112 [00:00<00:01, 55.30it/s, Epoch: 52, Batch: 29,Loss: -2.327,Avg.Loss: -2.426,LR: 2.40E-04]Training epoch 52:  26%|██▌       | 29/112 [00:00<00:01, 55.30it/s, Epoch: 52, Batch: 30,Loss: -2.362,Avg.Loss: -2.424,LR: 2.40E-04]Training epoch 52:  27%|██▋       | 30/112 [00:00<00:01, 55.30it/s, Epoch: 52, Batch: 31,Loss: -2.362,Avg.Loss: -2.422,LR: 2.40E-04]Training epoch 52:  28%|██▊       | 31/112 [00:00<00:01, 55.30it/s, Epoch: 52, Batch: 32,Loss: -2.287,Avg.Loss: -2.418,LR: 2.40E-04]Training epoch 52:  29%|██▊       | 32/112 [00:00<00:01, 54.74it/s, Epoch: 52, Batch: 32,Loss: -2.287,Avg.Loss: -2.418,LR: 2.40E-04]Training epoch 52:  29%|██▊       | 32/112 [00:00<00:01, 54.74it/s, Epoch: 52, Batch: 33,Loss: -2.549,Avg.Loss: -2.422,LR: 2.40E-04]Training epoch 52:  29%|██▉       | 33/112 [00:00<00:01, 54.74it/s, Epoch: 52, Batch: 34,Loss: -2.333,Avg.Loss: -2.419,LR: 2.40E-04]Training epoch 52:  30%|███       | 34/112 [00:00<00:01, 54.74it/s, Epoch: 52, Batch: 35,Loss: -2.087,Avg.Loss: -2.409,LR: 2.40E-04]Training epoch 52:  31%|███▏      | 35/112 [00:00<00:01, 54.74it/s, Epoch: 52, Batch: 36,Loss: -2.448,Avg.Loss: -2.410,LR: 2.40E-04]Training epoch 52:  32%|███▏      | 36/112 [00:00<00:01, 54.74it/s, Epoch: 52, Batch: 37,Loss: -2.587,Avg.Loss: -2.415,LR: 2.40E-04]Training epoch 52:  33%|███▎      | 37/112 [00:00<00:01, 54.74it/s, Epoch: 52, Batch: 38,Loss: -2.503,Avg.Loss: -2.418,LR: 2.39E-04]Training epoch 52:  34%|███▍      | 38/112 [00:00<00:01, 54.51it/s, Epoch: 52, Batch: 38,Loss: -2.503,Avg.Loss: -2.418,LR: 2.39E-04]Training epoch 52:  34%|███▍      | 38/112 [00:00<00:01, 54.51it/s, Epoch: 52, Batch: 39,Loss: -2.775,Avg.Loss: -2.427,LR: 2.39E-04]Training epoch 52:  35%|███▍      | 39/112 [00:00<00:01, 54.51it/s, Epoch: 52, Batch: 40,Loss: -2.352,Avg.Loss: -2.425,LR: 2.39E-04]Training epoch 52:  36%|███▌      | 40/112 [00:00<00:01, 54.51it/s, Epoch: 52, Batch: 41,Loss: -2.238,Avg.Loss: -2.420,LR: 2.39E-04]Training epoch 52:  37%|███▋      | 41/112 [00:00<00:01, 54.51it/s, Epoch: 52, Batch: 42,Loss: -2.629,Avg.Loss: -2.425,LR: 2.39E-04]Training epoch 52:  38%|███▊      | 42/112 [00:00<00:01, 54.51it/s, Epoch: 52, Batch: 43,Loss: -2.366,Avg.Loss: -2.424,LR: 2.39E-04]Training epoch 52:  38%|███▊      | 43/112 [00:00<00:01, 54.51it/s, Epoch: 52, Batch: 44,Loss: -2.146,Avg.Loss: -2.418,LR: 2.39E-04]Training epoch 52:  39%|███▉      | 44/112 [00:00<00:01, 54.41it/s, Epoch: 52, Batch: 44,Loss: -2.146,Avg.Loss: -2.418,LR: 2.39E-04]Training epoch 52:  39%|███▉      | 44/112 [00:00<00:01, 54.41it/s, Epoch: 52, Batch: 45,Loss: -2.757,Avg.Loss: -2.425,LR: 2.39E-04]Training epoch 52:  40%|████      | 45/112 [00:00<00:01, 54.41it/s, Epoch: 52, Batch: 46,Loss: -2.303,Avg.Loss: -2.422,LR: 2.39E-04]Training epoch 52:  41%|████      | 46/112 [00:00<00:01, 54.41it/s, Epoch: 52, Batch: 47,Loss: -1.914,Avg.Loss: -2.412,LR: 2.39E-04]Training epoch 52:  42%|████▏     | 47/112 [00:00<00:01, 54.41it/s, Epoch: 52, Batch: 48,Loss: -2.201,Avg.Loss: -2.407,LR: 2.39E-04]Training epoch 52:  43%|████▎     | 48/112 [00:00<00:01, 54.41it/s, Epoch: 52, Batch: 49,Loss: -2.534,Avg.Loss: -2.410,LR: 2.39E-04]Training epoch 52:  44%|████▍     | 49/112 [00:00<00:01, 54.41it/s, Epoch: 52, Batch: 50,Loss: -2.492,Avg.Loss: -2.411,LR: 2.39E-04]Training epoch 52:  45%|████▍     | 50/112 [00:00<00:01, 54.34it/s, Epoch: 52, Batch: 50,Loss: -2.492,Avg.Loss: -2.411,LR: 2.39E-04]Training epoch 52:  45%|████▍     | 50/112 [00:00<00:01, 54.34it/s, Epoch: 52, Batch: 51,Loss: -2.602,Avg.Loss: -2.415,LR: 2.39E-04]Training epoch 52:  46%|████▌     | 51/112 [00:00<00:01, 54.34it/s, Epoch: 52, Batch: 52,Loss: -2.499,Avg.Loss: -2.417,LR: 2.39E-04]Training epoch 52:  46%|████▋     | 52/112 [00:00<00:01, 54.34it/s, Epoch: 52, Batch: 53,Loss: -2.421,Avg.Loss: -2.417,LR: 2.38E-04]Training epoch 52:  47%|████▋     | 53/112 [00:00<00:01, 54.34it/s, Epoch: 52, Batch: 54,Loss: -2.784,Avg.Loss: -2.424,LR: 2.38E-04]Training epoch 52:  48%|████▊     | 54/112 [00:01<00:01, 54.34it/s, Epoch: 52, Batch: 55,Loss: -2.352,Avg.Loss: -2.422,LR: 2.38E-04]Training epoch 52:  49%|████▉     | 55/112 [00:01<00:01, 54.34it/s, Epoch: 52, Batch: 56,Loss: -1.970,Avg.Loss: -2.414,LR: 2.38E-04]Training epoch 52:  50%|█████     | 56/112 [00:01<00:01, 54.07it/s, Epoch: 52, Batch: 56,Loss: -1.970,Avg.Loss: -2.414,LR: 2.38E-04]Training epoch 52:  50%|█████     | 56/112 [00:01<00:01, 54.07it/s, Epoch: 52, Batch: 57,Loss: -2.496,Avg.Loss: -2.416,LR: 2.38E-04]Training epoch 52:  51%|█████     | 57/112 [00:01<00:01, 54.07it/s, Epoch: 52, Batch: 58,Loss: -2.290,Avg.Loss: -2.414,LR: 2.38E-04]Training epoch 52:  52%|█████▏    | 58/112 [00:01<00:00, 54.07it/s, Epoch: 52, Batch: 59,Loss: -1.890,Avg.Loss: -2.405,LR: 2.38E-04]Training epoch 52:  53%|█████▎    | 59/112 [00:01<00:00, 54.07it/s, Epoch: 52, Batch: 60,Loss: -2.455,Avg.Loss: -2.406,LR: 2.38E-04]Training epoch 52:  54%|█████▎    | 60/112 [00:01<00:00, 54.07it/s, Epoch: 52, Batch: 61,Loss: -2.429,Avg.Loss: -2.406,LR: 2.38E-04]Training epoch 52:  54%|█████▍    | 61/112 [00:01<00:00, 54.07it/s, Epoch: 52, Batch: 62,Loss: -2.492,Avg.Loss: -2.407,LR: 2.38E-04]Training epoch 52:  55%|█████▌    | 62/112 [00:01<00:00, 54.14it/s, Epoch: 52, Batch: 62,Loss: -2.492,Avg.Loss: -2.407,LR: 2.38E-04]Training epoch 52:  55%|█████▌    | 62/112 [00:01<00:00, 54.14it/s, Epoch: 52, Batch: 63,Loss: -2.789,Avg.Loss: -2.413,LR: 2.38E-04]Training epoch 52:  56%|█████▋    | 63/112 [00:01<00:00, 54.14it/s, Epoch: 52, Batch: 64,Loss: -2.680,Avg.Loss: -2.418,LR: 2.38E-04]Training epoch 52:  57%|█████▋    | 64/112 [00:01<00:00, 54.14it/s, Epoch: 52, Batch: 65,Loss: -2.512,Avg.Loss: -2.419,LR: 2.38E-04]Training epoch 52:  58%|█████▊    | 65/112 [00:01<00:00, 54.14it/s, Epoch: 52, Batch: 66,Loss: -2.541,Avg.Loss: -2.421,LR: 2.38E-04]Training epoch 52:  59%|█████▉    | 66/112 [00:01<00:00, 54.14it/s, Epoch: 52, Batch: 67,Loss: -2.445,Avg.Loss: -2.421,LR: 2.37E-04]Training epoch 52:  60%|█████▉    | 67/112 [00:01<00:00, 54.14it/s, Epoch: 52, Batch: 68,Loss: -1.959,Avg.Loss: -2.414,LR: 2.37E-04]Training epoch 52:  61%|██████    | 68/112 [00:01<00:00, 54.06it/s, Epoch: 52, Batch: 68,Loss: -1.959,Avg.Loss: -2.414,LR: 2.37E-04]Training epoch 52:  61%|██████    | 68/112 [00:01<00:00, 54.06it/s, Epoch: 52, Batch: 69,Loss: -2.542,Avg.Loss: -2.416,LR: 2.37E-04]Training epoch 52:  62%|██████▏   | 69/112 [00:01<00:00, 54.06it/s, Epoch: 52, Batch: 70,Loss: -2.542,Avg.Loss: -2.418,LR: 2.37E-04]Training epoch 52:  62%|██████▎   | 70/112 [00:01<00:00, 54.06it/s, Epoch: 52, Batch: 71,Loss: -2.609,Avg.Loss: -2.421,LR: 2.37E-04]Training epoch 52:  63%|██████▎   | 71/112 [00:01<00:00, 54.06it/s, Epoch: 52, Batch: 72,Loss: -2.825,Avg.Loss: -2.426,LR: 2.37E-04]Training epoch 52:  64%|██████▍   | 72/112 [00:01<00:00, 54.06it/s, Epoch: 52, Batch: 73,Loss: -2.455,Avg.Loss: -2.427,LR: 2.37E-04]Training epoch 52:  65%|██████▌   | 73/112 [00:01<00:00, 54.06it/s, Epoch: 52, Batch: 74,Loss: -2.012,Avg.Loss: -2.421,LR: 2.37E-04]Training epoch 52:  66%|██████▌   | 74/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 74,Loss: -2.012,Avg.Loss: -2.421,LR: 2.37E-04]Training epoch 52:  66%|██████▌   | 74/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 75,Loss: -2.415,Avg.Loss: -2.421,LR: 2.37E-04]Training epoch 52:  67%|██████▋   | 75/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 76,Loss: -2.832,Avg.Loss: -2.426,LR: 2.37E-04]Training epoch 52:  68%|██████▊   | 76/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 77,Loss: -2.568,Avg.Loss: -2.428,LR: 2.37E-04]Training epoch 52:  69%|██████▉   | 77/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 78,Loss: -2.880,Avg.Loss: -2.434,LR: 2.37E-04]Training epoch 52:  70%|██████▉   | 78/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 79,Loss: -2.060,Avg.Loss: -2.429,LR: 2.37E-04]Training epoch 52:  71%|███████   | 79/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 80,Loss: -2.195,Avg.Loss: -2.426,LR: 2.37E-04]Training epoch 52:  71%|███████▏  | 80/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 80,Loss: -2.195,Avg.Loss: -2.426,LR: 2.37E-04]Training epoch 52:  71%|███████▏  | 80/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 81,Loss: -2.240,Avg.Loss: -2.424,LR: 2.36E-04]Training epoch 52:  72%|███████▏  | 81/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 82,Loss: -2.512,Avg.Loss: -2.425,LR: 2.36E-04]Training epoch 52:  73%|███████▎  | 82/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 83,Loss: -2.501,Avg.Loss: -2.426,LR: 2.36E-04]Training epoch 52:  74%|███████▍  | 83/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 84,Loss: -2.668,Avg.Loss: -2.429,LR: 2.36E-04]Training epoch 52:  75%|███████▌  | 84/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 85,Loss: -2.179,Avg.Loss: -2.426,LR: 2.36E-04]Training epoch 52:  76%|███████▌  | 85/112 [00:01<00:00, 53.90it/s, Epoch: 52, Batch: 86,Loss: -2.416,Avg.Loss: -2.426,LR: 2.36E-04]Training epoch 52:  77%|███████▋  | 86/112 [00:01<00:00, 53.75it/s, Epoch: 52, Batch: 86,Loss: -2.416,Avg.Loss: -2.426,LR: 2.36E-04]Training epoch 52:  77%|███████▋  | 86/112 [00:01<00:00, 53.75it/s, Epoch: 52, Batch: 87,Loss: -2.793,Avg.Loss: -2.430,LR: 2.36E-04]Training epoch 52:  78%|███████▊  | 87/112 [00:01<00:00, 53.75it/s, Epoch: 52, Batch: 88,Loss: -2.552,Avg.Loss: -2.432,LR: 2.36E-04]Training epoch 52:  79%|███████▊  | 88/112 [00:01<00:00, 53.75it/s, Epoch: 52, Batch: 89,Loss: -2.365,Avg.Loss: -2.431,LR: 2.36E-04]Training epoch 52:  79%|███████▉  | 89/112 [00:01<00:00, 53.75it/s, Epoch: 52, Batch: 90,Loss: -2.182,Avg.Loss: -2.428,LR: 2.36E-04]Training epoch 52:  80%|████████  | 90/112 [00:01<00:00, 53.75it/s, Epoch: 52, Batch: 91,Loss: -2.406,Avg.Loss: -2.428,LR: 2.36E-04]Training epoch 52:  81%|████████▏ | 91/112 [00:01<00:00, 53.75it/s, Epoch: 52, Batch: 92,Loss: -2.879,Avg.Loss: -2.433,LR: 2.36E-04]Training epoch 52:  82%|████████▏ | 92/112 [00:01<00:00, 53.64it/s, Epoch: 52, Batch: 92,Loss: -2.879,Avg.Loss: -2.433,LR: 2.36E-04]Training epoch 52:  82%|████████▏ | 92/112 [00:01<00:00, 53.64it/s, Epoch: 52, Batch: 93,Loss: -2.957,Avg.Loss: -2.438,LR: 2.36E-04]Training epoch 52:  83%|████████▎ | 93/112 [00:01<00:00, 53.64it/s, Epoch: 52, Batch: 94,Loss: -2.572,Avg.Loss: -2.440,LR: 2.36E-04]Training epoch 52:  84%|████████▍ | 94/112 [00:01<00:00, 53.64it/s, Epoch: 52, Batch: 95,Loss: -2.315,Avg.Loss: -2.438,LR: 2.35E-04]Training epoch 52:  85%|████████▍ | 95/112 [00:01<00:00, 53.64it/s, Epoch: 52, Batch: 96,Loss: -1.992,Avg.Loss: -2.434,LR: 2.35E-04]Training epoch 52:  86%|████████▌ | 96/112 [00:01<00:00, 53.64it/s, Epoch: 52, Batch: 97,Loss: -2.649,Avg.Loss: -2.436,LR: 2.35E-04]Training epoch 52:  87%|████████▋ | 97/112 [00:01<00:00, 53.64it/s, Epoch: 52, Batch: 98,Loss: -2.755,Avg.Loss: -2.439,LR: 2.35E-04]Training epoch 52:  88%|████████▊ | 98/112 [00:01<00:00, 53.81it/s, Epoch: 52, Batch: 98,Loss: -2.755,Avg.Loss: -2.439,LR: 2.35E-04]Training epoch 52:  88%|████████▊ | 98/112 [00:01<00:00, 53.81it/s, Epoch: 52, Batch: 99,Loss: -2.901,Avg.Loss: -2.444,LR: 2.35E-04]Training epoch 52:  88%|████████▊ | 99/112 [00:01<00:00, 53.81it/s, Epoch: 52, Batch: 100,Loss: -2.388,Avg.Loss: -2.443,LR: 2.35E-04]Training epoch 52:  89%|████████▉ | 100/112 [00:01<00:00, 53.81it/s, Epoch: 52, Batch: 101,Loss: -1.602,Avg.Loss: -2.435,LR: 2.35E-04]Training epoch 52:  90%|█████████ | 101/112 [00:01<00:00, 53.81it/s, Epoch: 52, Batch: 102,Loss: -1.911,Avg.Loss: -2.430,LR: 2.35E-04]Training epoch 52:  91%|█████████ | 102/112 [00:01<00:00, 53.81it/s, Epoch: 52, Batch: 103,Loss: -2.495,Avg.Loss: -2.431,LR: 2.35E-04]Training epoch 52:  92%|█████████▏| 103/112 [00:01<00:00, 53.81it/s, Epoch: 52, Batch: 104,Loss: -2.850,Avg.Loss: -2.435,LR: 2.35E-04]Training epoch 52:  93%|█████████▎| 104/112 [00:01<00:00, 53.82it/s, Epoch: 52, Batch: 104,Loss: -2.850,Avg.Loss: -2.435,LR: 2.35E-04]Training epoch 52:  93%|█████████▎| 104/112 [00:01<00:00, 53.82it/s, Epoch: 52, Batch: 105,Loss: -2.678,Avg.Loss: -2.437,LR: 2.35E-04]Training epoch 52:  94%|█████████▍| 105/112 [00:01<00:00, 53.82it/s, Epoch: 52, Batch: 106,Loss: -2.169,Avg.Loss: -2.434,LR: 2.35E-04]Training epoch 52:  95%|█████████▍| 106/112 [00:01<00:00, 53.82it/s, Epoch: 52, Batch: 107,Loss: -1.816,Avg.Loss: -2.429,LR: 2.35E-04]Training epoch 52:  96%|█████████▌| 107/112 [00:01<00:00, 53.82it/s, Epoch: 52, Batch: 108,Loss: -2.112,Avg.Loss: -2.426,LR: 2.35E-04]Training epoch 52:  96%|█████████▋| 108/112 [00:02<00:00, 53.82it/s, Epoch: 52, Batch: 109,Loss: -2.257,Avg.Loss: -2.424,LR: 2.35E-04]Training epoch 52:  97%|█████████▋| 109/112 [00:02<00:00, 53.82it/s, Epoch: 52, Batch: 110,Loss: -2.273,Avg.Loss: -2.423,LR: 2.34E-04]Training epoch 52:  98%|█████████▊| 110/112 [00:02<00:00, 53.41it/s, Epoch: 52, Batch: 110,Loss: -2.273,Avg.Loss: -2.423,LR: 2.34E-04]Training epoch 52:  98%|█████████▊| 110/112 [00:02<00:00, 53.41it/s, Epoch: 52, Batch: 111,Loss: -2.714,Avg.Loss: -2.425,LR: 2.34E-04]Training epoch 52:  99%|█████████▉| 111/112 [00:02<00:00, 53.41it/s, Epoch: 52, Batch: 112,Loss: -2.110,Avg.Loss: -2.423,LR: 2.34E-04]Training epoch 52: 100%|██████████| 112/112 [00:02<00:00, 54.17it/s, Epoch: 52, Batch: 112,Loss: -2.110,Avg.Loss: -2.423,LR: 2.34E-04]
Training epoch 53:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 53:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 53, Batch: 1,Loss: -1.553,Avg.Loss: -1.553,LR: 2.34E-04]Training epoch 53:   1%|          | 1/112 [00:00<00:04, 27.29it/s, Epoch: 53, Batch: 2,Loss: -1.607,Avg.Loss: -1.580,LR: 2.34E-04]Training epoch 53:   2%|▏         | 2/112 [00:00<00:02, 39.78it/s, Epoch: 53, Batch: 3,Loss: -1.945,Avg.Loss: -1.701,LR: 2.34E-04]Training epoch 53:   3%|▎         | 3/112 [00:00<00:02, 44.31it/s, Epoch: 53, Batch: 4,Loss: -2.687,Avg.Loss: -1.948,LR: 2.34E-04]Training epoch 53:   4%|▎         | 4/112 [00:00<00:02, 47.32it/s, Epoch: 53, Batch: 5,Loss: -2.177,Avg.Loss: -1.994,LR: 2.34E-04]Training epoch 53:   4%|▍         | 5/112 [00:00<00:02, 48.86it/s, Epoch: 53, Batch: 6,Loss: -2.150,Avg.Loss: -2.020,LR: 2.34E-04]Training epoch 53:   5%|▌         | 6/112 [00:00<00:01, 58.54it/s, Epoch: 53, Batch: 6,Loss: -2.150,Avg.Loss: -2.020,LR: 2.34E-04]Training epoch 53:   5%|▌         | 6/112 [00:00<00:01, 58.54it/s, Epoch: 53, Batch: 7,Loss: -0.684,Avg.Loss: -1.829,LR: 2.34E-04]Training epoch 53:   6%|▋         | 7/112 [00:00<00:01, 58.54it/s, Epoch: 53, Batch: 8,Loss: -0.785,Avg.Loss: -1.698,LR: 2.34E-04]Training epoch 53:   7%|▋         | 8/112 [00:00<00:01, 58.54it/s, Epoch: 53, Batch: 9,Loss: -1.293,Avg.Loss: -1.653,LR: 2.34E-04]Training epoch 53:   8%|▊         | 9/112 [00:00<00:01, 58.54it/s, Epoch: 53, Batch: 10,Loss: -1.557,Avg.Loss: -1.644,LR: 2.34E-04]Training epoch 53:   9%|▉         | 10/112 [00:00<00:01, 58.54it/s, Epoch: 53, Batch: 11,Loss: -2.072,Avg.Loss: -1.683,LR: 2.34E-04]Training epoch 53:  10%|▉         | 11/112 [00:00<00:01, 58.54it/s, Epoch: 53, Batch: 12,Loss: -2.439,Avg.Loss: -1.746,LR: 2.33E-04]Training epoch 53:  11%|█         | 12/112 [00:00<00:01, 55.48it/s, Epoch: 53, Batch: 12,Loss: -2.439,Avg.Loss: -1.746,LR: 2.33E-04]Training epoch 53:  11%|█         | 12/112 [00:00<00:01, 55.48it/s, Epoch: 53, Batch: 13,Loss: -2.894,Avg.Loss: -1.834,LR: 2.33E-04]Training epoch 53:  12%|█▏        | 13/112 [00:00<00:01, 55.48it/s, Epoch: 53, Batch: 14,Loss: -2.444,Avg.Loss: -1.878,LR: 2.33E-04]Training epoch 53:  12%|█▎        | 14/112 [00:00<00:01, 55.48it/s, Epoch: 53, Batch: 15,Loss: -1.875,Avg.Loss: -1.877,LR: 2.33E-04]Training epoch 53:  13%|█▎        | 15/112 [00:00<00:01, 55.48it/s, Epoch: 53, Batch: 16,Loss: -1.498,Avg.Loss: -1.854,LR: 2.33E-04]Training epoch 53:  14%|█▍        | 16/112 [00:00<00:01, 55.48it/s, Epoch: 53, Batch: 17,Loss: -1.396,Avg.Loss: -1.827,LR: 2.33E-04]Training epoch 53:  15%|█▌        | 17/112 [00:00<00:01, 55.48it/s, Epoch: 53, Batch: 18,Loss: -0.924,Avg.Loss: -1.777,LR: 2.33E-04]Training epoch 53:  16%|█▌        | 18/112 [00:00<00:01, 54.31it/s, Epoch: 53, Batch: 18,Loss: -0.924,Avg.Loss: -1.777,LR: 2.33E-04]Training epoch 53:  16%|█▌        | 18/112 [00:00<00:01, 54.31it/s, Epoch: 53, Batch: 19,Loss: -1.691,Avg.Loss: -1.772,LR: 2.33E-04]Training epoch 53:  17%|█▋        | 19/112 [00:00<00:01, 54.31it/s, Epoch: 53, Batch: 20,Loss: -0.574,Avg.Loss: -1.712,LR: 2.33E-04]Training epoch 53:  18%|█▊        | 20/112 [00:00<00:01, 54.31it/s, Epoch: 53, Batch: 21,Loss: 0.193,Avg.Loss: -1.621,LR: 2.33E-04] Training epoch 53:  19%|█▉        | 21/112 [00:00<00:01, 54.31it/s, Epoch: 53, Batch: 22,Loss: -1.313,Avg.Loss: -1.607,LR: 2.33E-04]Training epoch 53:  20%|█▉        | 22/112 [00:00<00:01, 54.31it/s, Epoch: 53, Batch: 23,Loss: -1.525,Avg.Loss: -1.604,LR: 2.33E-04]Training epoch 53:  21%|██        | 23/112 [00:00<00:01, 54.31it/s, Epoch: 53, Batch: 24,Loss: -1.256,Avg.Loss: -1.589,LR: 2.33E-04]Training epoch 53:  21%|██▏       | 24/112 [00:00<00:01, 53.26it/s, Epoch: 53, Batch: 24,Loss: -1.256,Avg.Loss: -1.589,LR: 2.33E-04]Training epoch 53:  21%|██▏       | 24/112 [00:00<00:01, 53.26it/s, Epoch: 53, Batch: 25,Loss: -1.027,Avg.Loss: -1.567,LR: 2.33E-04]Training epoch 53:  22%|██▏       | 25/112 [00:00<00:01, 53.26it/s, Epoch: 53, Batch: 26,Loss: -2.679,Avg.Loss: -1.610,LR: 2.32E-04]Training epoch 53:  23%|██▎       | 26/112 [00:00<00:01, 53.26it/s, Epoch: 53, Batch: 27,Loss: -2.565,Avg.Loss: -1.645,LR: 2.32E-04]Training epoch 53:  24%|██▍       | 27/112 [00:00<00:01, 53.26it/s, Epoch: 53, Batch: 28,Loss: -2.408,Avg.Loss: -1.672,LR: 2.32E-04]Training epoch 53:  25%|██▌       | 28/112 [00:00<00:01, 53.26it/s, Epoch: 53, Batch: 29,Loss: -2.529,Avg.Loss: -1.702,LR: 2.32E-04]Training epoch 53:  26%|██▌       | 29/112 [00:00<00:01, 53.26it/s, Epoch: 53, Batch: 30,Loss: -2.123,Avg.Loss: -1.716,LR: 2.32E-04]Training epoch 53:  27%|██▋       | 30/112 [00:00<00:01, 53.41it/s, Epoch: 53, Batch: 30,Loss: -2.123,Avg.Loss: -1.716,LR: 2.32E-04]Training epoch 53:  27%|██▋       | 30/112 [00:00<00:01, 53.41it/s, Epoch: 53, Batch: 31,Loss: -2.689,Avg.Loss: -1.747,LR: 2.32E-04]Training epoch 53:  28%|██▊       | 31/112 [00:00<00:01, 53.41it/s, Epoch: 53, Batch: 32,Loss: -2.468,Avg.Loss: -1.770,LR: 2.32E-04]Training epoch 53:  29%|██▊       | 32/112 [00:00<00:01, 53.41it/s, Epoch: 53, Batch: 33,Loss: -2.669,Avg.Loss: -1.797,LR: 2.32E-04]Training epoch 53:  29%|██▉       | 33/112 [00:00<00:01, 53.41it/s, Epoch: 53, Batch: 34,Loss: -2.665,Avg.Loss: -1.823,LR: 2.32E-04]Training epoch 53:  30%|███       | 34/112 [00:00<00:01, 53.41it/s, Epoch: 53, Batch: 35,Loss: -2.683,Avg.Loss: -1.847,LR: 2.32E-04]Training epoch 53:  31%|███▏      | 35/112 [00:00<00:01, 53.41it/s, Epoch: 53, Batch: 36,Loss: -2.643,Avg.Loss: -1.869,LR: 2.32E-04]Training epoch 53:  32%|███▏      | 36/112 [00:00<00:01, 53.27it/s, Epoch: 53, Batch: 36,Loss: -2.643,Avg.Loss: -1.869,LR: 2.32E-04]Training epoch 53:  32%|███▏      | 36/112 [00:00<00:01, 53.27it/s, Epoch: 53, Batch: 37,Loss: -2.682,Avg.Loss: -1.891,LR: 2.32E-04]Training epoch 53:  33%|███▎      | 37/112 [00:00<00:01, 53.27it/s, Epoch: 53, Batch: 38,Loss: -2.657,Avg.Loss: -1.911,LR: 2.32E-04]Training epoch 53:  34%|███▍      | 38/112 [00:00<00:01, 53.27it/s, Epoch: 53, Batch: 39,Loss: -2.620,Avg.Loss: -1.929,LR: 2.32E-04]Training epoch 53:  35%|███▍      | 39/112 [00:00<00:01, 53.27it/s, Epoch: 53, Batch: 40,Loss: -2.638,Avg.Loss: -1.947,LR: 2.32E-04]Training epoch 53:  36%|███▌      | 40/112 [00:00<00:01, 53.27it/s, Epoch: 53, Batch: 41,Loss: -2.167,Avg.Loss: -1.953,LR: 2.31E-04]Training epoch 53:  37%|███▋      | 41/112 [00:00<00:01, 53.27it/s, Epoch: 53, Batch: 42,Loss: -2.296,Avg.Loss: -1.961,LR: 2.31E-04]Training epoch 53:  38%|███▊      | 42/112 [00:00<00:01, 53.08it/s, Epoch: 53, Batch: 42,Loss: -2.296,Avg.Loss: -1.961,LR: 2.31E-04]Training epoch 53:  38%|███▊      | 42/112 [00:00<00:01, 53.08it/s, Epoch: 53, Batch: 43,Loss: -2.494,Avg.Loss: -1.973,LR: 2.31E-04]Training epoch 53:  38%|███▊      | 43/112 [00:00<00:01, 53.08it/s, Epoch: 53, Batch: 44,Loss: -2.577,Avg.Loss: -1.987,LR: 2.31E-04]Training epoch 53:  39%|███▉      | 44/112 [00:00<00:01, 53.08it/s, Epoch: 53, Batch: 45,Loss: -2.796,Avg.Loss: -2.005,LR: 2.31E-04]Training epoch 53:  40%|████      | 45/112 [00:00<00:01, 53.08it/s, Epoch: 53, Batch: 46,Loss: -1.987,Avg.Loss: -2.004,LR: 2.31E-04]Training epoch 53:  41%|████      | 46/112 [00:00<00:01, 53.08it/s, Epoch: 53, Batch: 47,Loss: -2.768,Avg.Loss: -2.021,LR: 2.31E-04]Training epoch 53:  42%|████▏     | 47/112 [00:00<00:01, 53.08it/s, Epoch: 53, Batch: 48,Loss: -2.860,Avg.Loss: -2.038,LR: 2.31E-04]Training epoch 53:  43%|████▎     | 48/112 [00:00<00:01, 53.35it/s, Epoch: 53, Batch: 48,Loss: -2.860,Avg.Loss: -2.038,LR: 2.31E-04]Training epoch 53:  43%|████▎     | 48/112 [00:00<00:01, 53.35it/s, Epoch: 53, Batch: 49,Loss: -2.235,Avg.Loss: -2.042,LR: 2.31E-04]Training epoch 53:  44%|████▍     | 49/112 [00:00<00:01, 53.35it/s, Epoch: 53, Batch: 50,Loss: -2.564,Avg.Loss: -2.053,LR: 2.31E-04]Training epoch 53:  45%|████▍     | 50/112 [00:00<00:01, 53.35it/s, Epoch: 53, Batch: 51,Loss: -2.277,Avg.Loss: -2.057,LR: 2.31E-04]Training epoch 53:  46%|████▌     | 51/112 [00:00<00:01, 53.35it/s, Epoch: 53, Batch: 52,Loss: -1.918,Avg.Loss: -2.054,LR: 2.31E-04]Training epoch 53:  46%|████▋     | 52/112 [00:00<00:01, 53.35it/s, Epoch: 53, Batch: 53,Loss: -2.999,Avg.Loss: -2.072,LR: 2.31E-04]Training epoch 53:  47%|████▋     | 53/112 [00:01<00:01, 53.35it/s, Epoch: 53, Batch: 54,Loss: -2.853,Avg.Loss: -2.087,LR: 2.31E-04]Training epoch 53:  48%|████▊     | 54/112 [00:01<00:01, 53.46it/s, Epoch: 53, Batch: 54,Loss: -2.853,Avg.Loss: -2.087,LR: 2.31E-04]Training epoch 53:  48%|████▊     | 54/112 [00:01<00:01, 53.46it/s, Epoch: 53, Batch: 55,Loss: -2.514,Avg.Loss: -2.094,LR: 2.30E-04]Training epoch 53:  49%|████▉     | 55/112 [00:01<00:01, 53.46it/s, Epoch: 53, Batch: 56,Loss: -2.676,Avg.Loss: -2.105,LR: 2.30E-04]Training epoch 53:  50%|█████     | 56/112 [00:01<00:01, 53.46it/s, Epoch: 53, Batch: 57,Loss: -2.615,Avg.Loss: -2.114,LR: 2.30E-04]Training epoch 53:  51%|█████     | 57/112 [00:01<00:01, 53.46it/s, Epoch: 53, Batch: 58,Loss: -2.577,Avg.Loss: -2.122,LR: 2.30E-04]Training epoch 53:  52%|█████▏    | 58/112 [00:01<00:01, 53.46it/s, Epoch: 53, Batch: 59,Loss: -2.967,Avg.Loss: -2.136,LR: 2.30E-04]Training epoch 53:  53%|█████▎    | 59/112 [00:01<00:00, 53.46it/s, Epoch: 53, Batch: 60,Loss: -2.574,Avg.Loss: -2.143,LR: 2.30E-04]Training epoch 53:  54%|█████▎    | 60/112 [00:01<00:00, 53.48it/s, Epoch: 53, Batch: 60,Loss: -2.574,Avg.Loss: -2.143,LR: 2.30E-04]Training epoch 53:  54%|█████▎    | 60/112 [00:01<00:00, 53.48it/s, Epoch: 53, Batch: 61,Loss: -2.834,Avg.Loss: -2.155,LR: 2.30E-04]Training epoch 53:  54%|█████▍    | 61/112 [00:01<00:00, 53.48it/s, Epoch: 53, Batch: 62,Loss: -2.727,Avg.Loss: -2.164,LR: 2.30E-04]Training epoch 53:  55%|█████▌    | 62/112 [00:01<00:00, 53.48it/s, Epoch: 53, Batch: 63,Loss: -2.922,Avg.Loss: -2.176,LR: 2.30E-04]Training epoch 53:  56%|█████▋    | 63/112 [00:01<00:00, 53.48it/s, Epoch: 53, Batch: 64,Loss: -2.593,Avg.Loss: -2.182,LR: 2.30E-04]Training epoch 53:  57%|█████▋    | 64/112 [00:01<00:00, 53.48it/s, Epoch: 53, Batch: 65,Loss: -2.280,Avg.Loss: -2.184,LR: 2.30E-04]Training epoch 53:  58%|█████▊    | 65/112 [00:01<00:00, 53.48it/s, Epoch: 53, Batch: 66,Loss: -2.626,Avg.Loss: -2.191,LR: 2.30E-04]Training epoch 53:  59%|█████▉    | 66/112 [00:01<00:00, 52.37it/s, Epoch: 53, Batch: 66,Loss: -2.626,Avg.Loss: -2.191,LR: 2.30E-04]Training epoch 53:  59%|█████▉    | 66/112 [00:01<00:00, 52.37it/s, Epoch: 53, Batch: 67,Loss: -1.930,Avg.Loss: -2.187,LR: 2.30E-04]Training epoch 53:  60%|█████▉    | 67/112 [00:01<00:00, 52.37it/s, Epoch: 53, Batch: 68,Loss: -2.624,Avg.Loss: -2.193,LR: 2.30E-04]Training epoch 53:  61%|██████    | 68/112 [00:01<00:00, 52.37it/s, Epoch: 53, Batch: 69,Loss: -2.424,Avg.Loss: -2.197,LR: 2.29E-04]Training epoch 53:  62%|██████▏   | 69/112 [00:01<00:00, 52.37it/s, Epoch: 53, Batch: 70,Loss: -1.627,Avg.Loss: -2.188,LR: 2.29E-04]Training epoch 53:  62%|██████▎   | 70/112 [00:01<00:00, 52.37it/s, Epoch: 53, Batch: 71,Loss: -0.492,Avg.Loss: -2.165,LR: 2.29E-04]Training epoch 53:  63%|██████▎   | 71/112 [00:01<00:00, 52.37it/s, Epoch: 53, Batch: 72,Loss: -1.662,Avg.Loss: -2.158,LR: 2.29E-04]Training epoch 53:  64%|██████▍   | 72/112 [00:01<00:00, 52.88it/s, Epoch: 53, Batch: 72,Loss: -1.662,Avg.Loss: -2.158,LR: 2.29E-04]Training epoch 53:  64%|██████▍   | 72/112 [00:01<00:00, 52.88it/s, Epoch: 53, Batch: 73,Loss: -3.061,Avg.Loss: -2.170,LR: 2.29E-04]Training epoch 53:  65%|██████▌   | 73/112 [00:01<00:00, 52.88it/s, Epoch: 53, Batch: 74,Loss: -0.905,Avg.Loss: -2.153,LR: 2.29E-04]Training epoch 53:  66%|██████▌   | 74/112 [00:01<00:00, 52.88it/s, Epoch: 53, Batch: 75,Loss: 2.615,Avg.Loss: -2.089,LR: 2.29E-04] Training epoch 53:  67%|██████▋   | 75/112 [00:01<00:00, 52.88it/s, Epoch: 53, Batch: 76,Loss: 0.742,Avg.Loss: -2.052,LR: 2.29E-04]Training epoch 53:  68%|██████▊   | 76/112 [00:01<00:00, 52.88it/s, Epoch: 53, Batch: 77,Loss: -0.954,Avg.Loss: -2.038,LR: 2.29E-04]Training epoch 53:  69%|██████▉   | 77/112 [00:01<00:00, 52.88it/s, Epoch: 53, Batch: 78,Loss: -2.894,Avg.Loss: -2.049,LR: 2.29E-04]Training epoch 53:  70%|██████▉   | 78/112 [00:01<00:00, 53.11it/s, Epoch: 53, Batch: 78,Loss: -2.894,Avg.Loss: -2.049,LR: 2.29E-04]Training epoch 53:  70%|██████▉   | 78/112 [00:01<00:00, 53.11it/s, Epoch: 53, Batch: 79,Loss: -2.158,Avg.Loss: -2.050,LR: 2.29E-04]Training epoch 53:  71%|███████   | 79/112 [00:01<00:00, 53.11it/s, Epoch: 53, Batch: 80,Loss: -2.725,Avg.Loss: -2.059,LR: 2.29E-04]Training epoch 53:  71%|███████▏  | 80/112 [00:01<00:00, 53.11it/s, Epoch: 53, Batch: 81,Loss: -2.934,Avg.Loss: -2.069,LR: 2.29E-04]Training epoch 53:  72%|███████▏  | 81/112 [00:01<00:00, 53.11it/s, Epoch: 53, Batch: 82,Loss: -2.595,Avg.Loss: -2.076,LR: 2.29E-04]Training epoch 53:  73%|███████▎  | 82/112 [00:01<00:00, 53.11it/s, Epoch: 53, Batch: 83,Loss: -2.907,Avg.Loss: -2.086,LR: 2.28E-04]Training epoch 53:  74%|███████▍  | 83/112 [00:01<00:00, 53.11it/s, Epoch: 53, Batch: 84,Loss: -3.312,Avg.Loss: -2.100,LR: 2.28E-04]Training epoch 53:  75%|███████▌  | 84/112 [00:01<00:00, 53.39it/s, Epoch: 53, Batch: 84,Loss: -3.312,Avg.Loss: -2.100,LR: 2.28E-04]Training epoch 53:  75%|███████▌  | 84/112 [00:01<00:00, 53.39it/s, Epoch: 53, Batch: 85,Loss: -2.427,Avg.Loss: -2.104,LR: 2.28E-04]Training epoch 53:  76%|███████▌  | 85/112 [00:01<00:00, 53.39it/s, Epoch: 53, Batch: 86,Loss: -2.135,Avg.Loss: -2.105,LR: 2.28E-04]Training epoch 53:  77%|███████▋  | 86/112 [00:01<00:00, 53.39it/s, Epoch: 53, Batch: 87,Loss: -2.969,Avg.Loss: -2.115,LR: 2.28E-04]Training epoch 53:  78%|███████▊  | 87/112 [00:01<00:00, 53.39it/s, Epoch: 53, Batch: 88,Loss: -1.201,Avg.Loss: -2.104,LR: 2.28E-04]Training epoch 53:  79%|███████▊  | 88/112 [00:01<00:00, 53.39it/s, Epoch: 53, Batch: 89,Loss: -0.114,Avg.Loss: -2.082,LR: 2.28E-04]Training epoch 53:  79%|███████▉  | 89/112 [00:01<00:00, 53.39it/s, Epoch: 53, Batch: 90,Loss: -1.112,Avg.Loss: -2.071,LR: 2.28E-04]Training epoch 53:  80%|████████  | 90/112 [00:01<00:00, 53.47it/s, Epoch: 53, Batch: 90,Loss: -1.112,Avg.Loss: -2.071,LR: 2.28E-04]Training epoch 53:  80%|████████  | 90/112 [00:01<00:00, 53.47it/s, Epoch: 53, Batch: 91,Loss: -2.536,Avg.Loss: -2.076,LR: 2.28E-04]Training epoch 53:  81%|████████▏ | 91/112 [00:01<00:00, 53.47it/s, Epoch: 53, Batch: 92,Loss: -1.427,Avg.Loss: -2.069,LR: 2.28E-04]Training epoch 53:  82%|████████▏ | 92/112 [00:01<00:00, 53.47it/s, Epoch: 53, Batch: 93,Loss: 1.214,Avg.Loss: -2.034,LR: 2.28E-04] Training epoch 53:  83%|████████▎ | 93/112 [00:01<00:00, 53.47it/s, Epoch: 53, Batch: 94,Loss: -0.729,Avg.Loss: -2.020,LR: 2.28E-04]Training epoch 53:  84%|████████▍ | 94/112 [00:01<00:00, 53.47it/s, Epoch: 53, Batch: 95,Loss: -1.031,Avg.Loss: -2.009,LR: 2.28E-04]Training epoch 53:  85%|████████▍ | 95/112 [00:01<00:00, 53.47it/s, Epoch: 53, Batch: 96,Loss: -2.606,Avg.Loss: -2.016,LR: 2.28E-04]Training epoch 53:  86%|████████▌ | 96/112 [00:01<00:00, 53.79it/s, Epoch: 53, Batch: 96,Loss: -2.606,Avg.Loss: -2.016,LR: 2.28E-04]Training epoch 53:  86%|████████▌ | 96/112 [00:01<00:00, 53.79it/s, Epoch: 53, Batch: 97,Loss: -1.583,Avg.Loss: -2.011,LR: 2.28E-04]Training epoch 53:  87%|████████▋ | 97/112 [00:01<00:00, 53.79it/s, Epoch: 53, Batch: 98,Loss: -1.975,Avg.Loss: -2.011,LR: 2.27E-04]Training epoch 53:  88%|████████▊ | 98/112 [00:01<00:00, 53.79it/s, Epoch: 53, Batch: 99,Loss: -3.026,Avg.Loss: -2.021,LR: 2.27E-04]Training epoch 53:  88%|████████▊ | 99/112 [00:01<00:00, 53.79it/s, Epoch: 53, Batch: 100,Loss: -1.406,Avg.Loss: -2.015,LR: 2.27E-04]Training epoch 53:  89%|████████▉ | 100/112 [00:01<00:00, 53.79it/s, Epoch: 53, Batch: 101,Loss: 1.025,Avg.Loss: -1.985,LR: 2.27E-04]Training epoch 53:  90%|█████████ | 101/112 [00:01<00:00, 53.79it/s, Epoch: 53, Batch: 102,Loss: 0.644,Avg.Loss: -1.959,LR: 2.27E-04]Training epoch 53:  91%|█████████ | 102/112 [00:01<00:00, 53.70it/s, Epoch: 53, Batch: 102,Loss: 0.644,Avg.Loss: -1.959,LR: 2.27E-04]Training epoch 53:  91%|█████████ | 102/112 [00:01<00:00, 53.70it/s, Epoch: 53, Batch: 103,Loss: -2.759,Avg.Loss: -1.967,LR: 2.27E-04]Training epoch 53:  92%|█████████▏| 103/112 [00:01<00:00, 53.70it/s, Epoch: 53, Batch: 104,Loss: -2.450,Avg.Loss: -1.971,LR: 2.27E-04]Training epoch 53:  93%|█████████▎| 104/112 [00:01<00:00, 53.70it/s, Epoch: 53, Batch: 105,Loss: -1.254,Avg.Loss: -1.965,LR: 2.27E-04]Training epoch 53:  94%|█████████▍| 105/112 [00:01<00:00, 53.70it/s, Epoch: 53, Batch: 106,Loss: -1.437,Avg.Loss: -1.960,LR: 2.27E-04]Training epoch 53:  95%|█████████▍| 106/112 [00:02<00:00, 53.70it/s, Epoch: 53, Batch: 107,Loss: -3.247,Avg.Loss: -1.972,LR: 2.27E-04]Training epoch 53:  96%|█████████▌| 107/112 [00:02<00:00, 53.70it/s, Epoch: 53, Batch: 108,Loss: -2.750,Avg.Loss: -1.979,LR: 2.27E-04]Training epoch 53:  96%|█████████▋| 108/112 [00:02<00:00, 53.40it/s, Epoch: 53, Batch: 108,Loss: -2.750,Avg.Loss: -1.979,LR: 2.27E-04]Training epoch 53:  96%|█████████▋| 108/112 [00:02<00:00, 53.40it/s, Epoch: 53, Batch: 109,Loss: -2.705,Avg.Loss: -1.986,LR: 2.27E-04]Training epoch 53:  97%|█████████▋| 109/112 [00:02<00:00, 53.40it/s, Epoch: 53, Batch: 110,Loss: -2.369,Avg.Loss: -1.989,LR: 2.27E-04]Training epoch 53:  98%|█████████▊| 110/112 [00:02<00:00, 53.40it/s, Epoch: 53, Batch: 111,Loss: -2.104,Avg.Loss: -1.990,LR: 2.27E-04]Training epoch 53:  99%|█████████▉| 111/112 [00:02<00:00, 53.40it/s, Epoch: 53, Batch: 112,Loss: -1.827,Avg.Loss: -1.989,LR: 2.26E-04]Training epoch 53: 100%|██████████| 112/112 [00:02<00:00, 53.38it/s, Epoch: 53, Batch: 112,Loss: -1.827,Avg.Loss: -1.989,LR: 2.26E-04]
Training epoch 54:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 54:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 54, Batch: 1,Loss: -2.108,Avg.Loss: -2.108,LR: 2.26E-04]Training epoch 54:   1%|          | 1/112 [00:00<00:04, 26.50it/s, Epoch: 54, Batch: 2,Loss: -2.259,Avg.Loss: -2.183,LR: 2.26E-04]Training epoch 54:   2%|▏         | 2/112 [00:00<00:03, 35.70it/s, Epoch: 54, Batch: 3,Loss: -2.935,Avg.Loss: -2.434,LR: 2.26E-04]Training epoch 54:   3%|▎         | 3/112 [00:00<00:02, 40.42it/s, Epoch: 54, Batch: 4,Loss: -2.887,Avg.Loss: -2.547,LR: 2.26E-04]Training epoch 54:   4%|▎         | 4/112 [00:00<00:02, 43.07it/s, Epoch: 54, Batch: 5,Loss: -2.603,Avg.Loss: -2.558,LR: 2.26E-04]Training epoch 54:   4%|▍         | 5/112 [00:00<00:02, 44.64it/s, Epoch: 54, Batch: 6,Loss: -2.451,Avg.Loss: -2.540,LR: 2.26E-04]Training epoch 54:   5%|▌         | 6/112 [00:00<00:01, 53.48it/s, Epoch: 54, Batch: 6,Loss: -2.451,Avg.Loss: -2.540,LR: 2.26E-04]Training epoch 54:   5%|▌         | 6/112 [00:00<00:01, 53.48it/s, Epoch: 54, Batch: 7,Loss: -2.382,Avg.Loss: -2.518,LR: 2.26E-04]Training epoch 54:   6%|▋         | 7/112 [00:00<00:01, 53.48it/s, Epoch: 54, Batch: 8,Loss: -2.593,Avg.Loss: -2.527,LR: 2.26E-04]Training epoch 54:   7%|▋         | 8/112 [00:00<00:01, 53.48it/s, Epoch: 54, Batch: 9,Loss: -2.399,Avg.Loss: -2.513,LR: 2.26E-04]Training epoch 54:   8%|▊         | 9/112 [00:00<00:01, 53.48it/s, Epoch: 54, Batch: 10,Loss: -1.752,Avg.Loss: -2.437,LR: 2.26E-04]Training epoch 54:   9%|▉         | 10/112 [00:00<00:01, 53.48it/s, Epoch: 54, Batch: 11,Loss: -2.294,Avg.Loss: -2.424,LR: 2.26E-04]Training epoch 54:  10%|▉         | 11/112 [00:00<00:01, 53.48it/s, Epoch: 54, Batch: 12,Loss: -2.322,Avg.Loss: -2.415,LR: 2.26E-04]Training epoch 54:  11%|█         | 12/112 [00:00<00:01, 52.93it/s, Epoch: 54, Batch: 12,Loss: -2.322,Avg.Loss: -2.415,LR: 2.26E-04]Training epoch 54:  11%|█         | 12/112 [00:00<00:01, 52.93it/s, Epoch: 54, Batch: 13,Loss: -2.564,Avg.Loss: -2.427,LR: 2.26E-04]Training epoch 54:  12%|█▏        | 13/112 [00:00<00:01, 52.93it/s, Epoch: 54, Batch: 14,Loss: -2.720,Avg.Loss: -2.448,LR: 2.25E-04]Training epoch 54:  12%|█▎        | 14/112 [00:00<00:01, 52.93it/s, Epoch: 54, Batch: 15,Loss: -2.483,Avg.Loss: -2.450,LR: 2.25E-04]Training epoch 54:  13%|█▎        | 15/112 [00:00<00:01, 52.93it/s, Epoch: 54, Batch: 16,Loss: -2.402,Avg.Loss: -2.447,LR: 2.25E-04]Training epoch 54:  14%|█▍        | 16/112 [00:00<00:01, 52.93it/s, Epoch: 54, Batch: 17,Loss: -2.479,Avg.Loss: -2.449,LR: 2.25E-04]Training epoch 54:  15%|█▌        | 17/112 [00:00<00:01, 52.93it/s, Epoch: 54, Batch: 18,Loss: -2.234,Avg.Loss: -2.437,LR: 2.25E-04]Training epoch 54:  16%|█▌        | 18/112 [00:00<00:01, 52.94it/s, Epoch: 54, Batch: 18,Loss: -2.234,Avg.Loss: -2.437,LR: 2.25E-04]Training epoch 54:  16%|█▌        | 18/112 [00:00<00:01, 52.94it/s, Epoch: 54, Batch: 19,Loss: -3.036,Avg.Loss: -2.469,LR: 2.25E-04]Training epoch 54:  17%|█▋        | 19/112 [00:00<00:01, 52.94it/s, Epoch: 54, Batch: 20,Loss: -3.192,Avg.Loss: -2.505,LR: 2.25E-04]Training epoch 54:  18%|█▊        | 20/112 [00:00<00:01, 52.94it/s, Epoch: 54, Batch: 21,Loss: -2.883,Avg.Loss: -2.523,LR: 2.25E-04]Training epoch 54:  19%|█▉        | 21/112 [00:00<00:01, 52.94it/s, Epoch: 54, Batch: 22,Loss: -2.836,Avg.Loss: -2.537,LR: 2.25E-04]Training epoch 54:  20%|█▉        | 22/112 [00:00<00:01, 52.94it/s, Epoch: 54, Batch: 23,Loss: -2.615,Avg.Loss: -2.540,LR: 2.25E-04]Training epoch 54:  21%|██        | 23/112 [00:00<00:01, 52.94it/s, Epoch: 54, Batch: 24,Loss: -2.058,Avg.Loss: -2.520,LR: 2.25E-04]Training epoch 54:  21%|██▏       | 24/112 [00:00<00:01, 52.37it/s, Epoch: 54, Batch: 24,Loss: -2.058,Avg.Loss: -2.520,LR: 2.25E-04]Training epoch 54:  21%|██▏       | 24/112 [00:00<00:01, 52.37it/s, Epoch: 54, Batch: 25,Loss: -2.797,Avg.Loss: -2.531,LR: 2.25E-04]Training epoch 54:  22%|██▏       | 25/112 [00:00<00:01, 52.37it/s, Epoch: 54, Batch: 26,Loss: -2.533,Avg.Loss: -2.531,LR: 2.25E-04]Training epoch 54:  23%|██▎       | 26/112 [00:00<00:01, 52.37it/s, Epoch: 54, Batch: 27,Loss: -3.094,Avg.Loss: -2.552,LR: 2.25E-04]Training epoch 54:  24%|██▍       | 27/112 [00:00<00:01, 52.37it/s, Epoch: 54, Batch: 28,Loss: -3.164,Avg.Loss: -2.574,LR: 2.25E-04]Training epoch 54:  25%|██▌       | 28/112 [00:00<00:01, 52.37it/s, Epoch: 54, Batch: 29,Loss: -3.010,Avg.Loss: -2.589,LR: 2.24E-04]Training epoch 54:  26%|██▌       | 29/112 [00:00<00:01, 52.37it/s, Epoch: 54, Batch: 30,Loss: -2.626,Avg.Loss: -2.590,LR: 2.24E-04]Training epoch 54:  27%|██▋       | 30/112 [00:00<00:01, 52.57it/s, Epoch: 54, Batch: 30,Loss: -2.626,Avg.Loss: -2.590,LR: 2.24E-04]Training epoch 54:  27%|██▋       | 30/112 [00:00<00:01, 52.57it/s, Epoch: 54, Batch: 31,Loss: -2.545,Avg.Loss: -2.589,LR: 2.24E-04]Training epoch 54:  28%|██▊       | 31/112 [00:00<00:01, 52.57it/s, Epoch: 54, Batch: 32,Loss: -2.471,Avg.Loss: -2.585,LR: 2.24E-04]Training epoch 54:  29%|██▊       | 32/112 [00:00<00:01, 52.57it/s, Epoch: 54, Batch: 33,Loss: -2.978,Avg.Loss: -2.597,LR: 2.24E-04]Training epoch 54:  29%|██▉       | 33/112 [00:00<00:01, 52.57it/s, Epoch: 54, Batch: 34,Loss: -2.644,Avg.Loss: -2.598,LR: 2.24E-04]Training epoch 54:  30%|███       | 34/112 [00:00<00:01, 52.57it/s, Epoch: 54, Batch: 35,Loss: -3.071,Avg.Loss: -2.612,LR: 2.24E-04]Training epoch 54:  31%|███▏      | 35/112 [00:00<00:01, 52.57it/s, Epoch: 54, Batch: 36,Loss: -2.862,Avg.Loss: -2.619,LR: 2.24E-04]Training epoch 54:  32%|███▏      | 36/112 [00:00<00:01, 52.74it/s, Epoch: 54, Batch: 36,Loss: -2.862,Avg.Loss: -2.619,LR: 2.24E-04]Training epoch 54:  32%|███▏      | 36/112 [00:00<00:01, 52.74it/s, Epoch: 54, Batch: 37,Loss: -2.948,Avg.Loss: -2.628,LR: 2.24E-04]Training epoch 54:  33%|███▎      | 37/112 [00:00<00:01, 52.74it/s, Epoch: 54, Batch: 38,Loss: -2.434,Avg.Loss: -2.623,LR: 2.24E-04]Training epoch 54:  34%|███▍      | 38/112 [00:00<00:01, 52.74it/s, Epoch: 54, Batch: 39,Loss: -2.139,Avg.Loss: -2.610,LR: 2.24E-04]Training epoch 54:  35%|███▍      | 39/112 [00:00<00:01, 52.74it/s, Epoch: 54, Batch: 40,Loss: -2.572,Avg.Loss: -2.609,LR: 2.24E-04]Training epoch 54:  36%|███▌      | 40/112 [00:00<00:01, 52.74it/s, Epoch: 54, Batch: 41,Loss: -2.407,Avg.Loss: -2.604,LR: 2.24E-04]Training epoch 54:  37%|███▋      | 41/112 [00:00<00:01, 52.74it/s, Epoch: 54, Batch: 42,Loss: -2.260,Avg.Loss: -2.596,LR: 2.24E-04]Training epoch 54:  38%|███▊      | 42/112 [00:00<00:01, 53.09it/s, Epoch: 54, Batch: 42,Loss: -2.260,Avg.Loss: -2.596,LR: 2.24E-04]Training epoch 54:  38%|███▊      | 42/112 [00:00<00:01, 53.09it/s, Epoch: 54, Batch: 43,Loss: -2.253,Avg.Loss: -2.588,LR: 2.23E-04]Training epoch 54:  38%|███▊      | 43/112 [00:00<00:01, 53.09it/s, Epoch: 54, Batch: 44,Loss: -2.418,Avg.Loss: -2.584,LR: 2.23E-04]Training epoch 54:  39%|███▉      | 44/112 [00:00<00:01, 53.09it/s, Epoch: 54, Batch: 45,Loss: -2.132,Avg.Loss: -2.574,LR: 2.23E-04]Training epoch 54:  40%|████      | 45/112 [00:00<00:01, 53.09it/s, Epoch: 54, Batch: 46,Loss: -1.864,Avg.Loss: -2.559,LR: 2.23E-04]Training epoch 54:  41%|████      | 46/112 [00:00<00:01, 53.09it/s, Epoch: 54, Batch: 47,Loss: -2.505,Avg.Loss: -2.558,LR: 2.23E-04]Training epoch 54:  42%|████▏     | 47/112 [00:00<00:01, 53.09it/s, Epoch: 54, Batch: 48,Loss: -2.127,Avg.Loss: -2.549,LR: 2.23E-04]Training epoch 54:  43%|████▎     | 48/112 [00:00<00:01, 53.13it/s, Epoch: 54, Batch: 48,Loss: -2.127,Avg.Loss: -2.549,LR: 2.23E-04]Training epoch 54:  43%|████▎     | 48/112 [00:00<00:01, 53.13it/s, Epoch: 54, Batch: 49,Loss: -2.857,Avg.Loss: -2.555,LR: 2.23E-04]Training epoch 54:  44%|████▍     | 49/112 [00:00<00:01, 53.13it/s, Epoch: 54, Batch: 50,Loss: -2.843,Avg.Loss: -2.561,LR: 2.23E-04]Training epoch 54:  45%|████▍     | 50/112 [00:00<00:01, 53.13it/s, Epoch: 54, Batch: 51,Loss: -2.951,Avg.Loss: -2.568,LR: 2.23E-04]Training epoch 54:  46%|████▌     | 51/112 [00:00<00:01, 53.13it/s, Epoch: 54, Batch: 52,Loss: -2.471,Avg.Loss: -2.567,LR: 2.23E-04]Training epoch 54:  46%|████▋     | 52/112 [00:01<00:01, 53.13it/s, Epoch: 54, Batch: 53,Loss: -2.807,Avg.Loss: -2.571,LR: 2.23E-04]Training epoch 54:  47%|████▋     | 53/112 [00:01<00:01, 53.13it/s, Epoch: 54, Batch: 54,Loss: -3.031,Avg.Loss: -2.580,LR: 2.23E-04]Training epoch 54:  48%|████▊     | 54/112 [00:01<00:01, 53.12it/s, Epoch: 54, Batch: 54,Loss: -3.031,Avg.Loss: -2.580,LR: 2.23E-04]Training epoch 54:  48%|████▊     | 54/112 [00:01<00:01, 53.12it/s, Epoch: 54, Batch: 55,Loss: -2.531,Avg.Loss: -2.579,LR: 2.23E-04]Training epoch 54:  49%|████▉     | 55/112 [00:01<00:01, 53.12it/s, Epoch: 54, Batch: 56,Loss: -2.549,Avg.Loss: -2.578,LR: 2.23E-04]Training epoch 54:  50%|█████     | 56/112 [00:01<00:01, 53.12it/s, Epoch: 54, Batch: 57,Loss: -2.741,Avg.Loss: -2.581,LR: 2.22E-04]Training epoch 54:  51%|█████     | 57/112 [00:01<00:01, 53.12it/s, Epoch: 54, Batch: 58,Loss: -2.680,Avg.Loss: -2.583,LR: 2.22E-04]Training epoch 54:  52%|█████▏    | 58/112 [00:01<00:01, 53.12it/s, Epoch: 54, Batch: 59,Loss: -2.718,Avg.Loss: -2.585,LR: 2.22E-04]Training epoch 54:  53%|█████▎    | 59/112 [00:01<00:00, 53.12it/s, Epoch: 54, Batch: 60,Loss: -2.812,Avg.Loss: -2.589,LR: 2.22E-04]Training epoch 54:  54%|█████▎    | 60/112 [00:01<00:00, 53.42it/s, Epoch: 54, Batch: 60,Loss: -2.812,Avg.Loss: -2.589,LR: 2.22E-04]Training epoch 54:  54%|█████▎    | 60/112 [00:01<00:00, 53.42it/s, Epoch: 54, Batch: 61,Loss: -2.849,Avg.Loss: -2.593,LR: 2.22E-04]Training epoch 54:  54%|█████▍    | 61/112 [00:01<00:00, 53.42it/s, Epoch: 54, Batch: 62,Loss: -3.046,Avg.Loss: -2.600,LR: 2.22E-04]Training epoch 54:  55%|█████▌    | 62/112 [00:01<00:00, 53.42it/s, Epoch: 54, Batch: 63,Loss: -2.718,Avg.Loss: -2.602,LR: 2.22E-04]Training epoch 54:  56%|█████▋    | 63/112 [00:01<00:00, 53.42it/s, Epoch: 54, Batch: 64,Loss: -3.013,Avg.Loss: -2.609,LR: 2.22E-04]Training epoch 54:  57%|█████▋    | 64/112 [00:01<00:00, 53.42it/s, Epoch: 54, Batch: 65,Loss: -2.656,Avg.Loss: -2.609,LR: 2.22E-04]Training epoch 54:  58%|█████▊    | 65/112 [00:01<00:00, 53.42it/s, Epoch: 54, Batch: 66,Loss: -2.996,Avg.Loss: -2.615,LR: 2.22E-04]Training epoch 54:  59%|█████▉    | 66/112 [00:01<00:00, 53.41it/s, Epoch: 54, Batch: 66,Loss: -2.996,Avg.Loss: -2.615,LR: 2.22E-04]Training epoch 54:  59%|█████▉    | 66/112 [00:01<00:00, 53.41it/s, Epoch: 54, Batch: 67,Loss: -2.577,Avg.Loss: -2.615,LR: 2.22E-04]Training epoch 54:  60%|█████▉    | 67/112 [00:01<00:00, 53.41it/s, Epoch: 54, Batch: 68,Loss: -2.908,Avg.Loss: -2.619,LR: 2.22E-04]Training epoch 54:  61%|██████    | 68/112 [00:01<00:00, 53.41it/s, Epoch: 54, Batch: 69,Loss: -2.698,Avg.Loss: -2.620,LR: 2.22E-04]Training epoch 54:  62%|██████▏   | 69/112 [00:01<00:00, 53.41it/s, Epoch: 54, Batch: 70,Loss: -3.216,Avg.Loss: -2.629,LR: 2.22E-04]Training epoch 54:  62%|██████▎   | 70/112 [00:01<00:00, 53.41it/s, Epoch: 54, Batch: 71,Loss: -3.105,Avg.Loss: -2.635,LR: 2.22E-04]Training epoch 54:  63%|██████▎   | 71/112 [00:01<00:00, 53.41it/s, Epoch: 54, Batch: 72,Loss: -3.219,Avg.Loss: -2.644,LR: 2.21E-04]Training epoch 54:  64%|██████▍   | 72/112 [00:01<00:00, 53.62it/s, Epoch: 54, Batch: 72,Loss: -3.219,Avg.Loss: -2.644,LR: 2.21E-04]Training epoch 54:  64%|██████▍   | 72/112 [00:01<00:00, 53.62it/s, Epoch: 54, Batch: 73,Loss: -2.993,Avg.Loss: -2.648,LR: 2.21E-04]Training epoch 54:  65%|██████▌   | 73/112 [00:01<00:00, 53.62it/s, Epoch: 54, Batch: 74,Loss: -2.960,Avg.Loss: -2.653,LR: 2.21E-04]Training epoch 54:  66%|██████▌   | 74/112 [00:01<00:00, 53.62it/s, Epoch: 54, Batch: 75,Loss: -2.884,Avg.Loss: -2.656,LR: 2.21E-04]Training epoch 54:  67%|██████▋   | 75/112 [00:01<00:00, 53.62it/s, Epoch: 54, Batch: 76,Loss: -3.070,Avg.Loss: -2.661,LR: 2.21E-04]Training epoch 54:  68%|██████▊   | 76/112 [00:01<00:00, 53.62it/s, Epoch: 54, Batch: 77,Loss: -3.077,Avg.Loss: -2.666,LR: 2.21E-04]Training epoch 54:  69%|██████▉   | 77/112 [00:01<00:00, 53.62it/s, Epoch: 54, Batch: 78,Loss: -2.739,Avg.Loss: -2.667,LR: 2.21E-04]Training epoch 54:  70%|██████▉   | 78/112 [00:01<00:00, 53.71it/s, Epoch: 54, Batch: 78,Loss: -2.739,Avg.Loss: -2.667,LR: 2.21E-04]Training epoch 54:  70%|██████▉   | 78/112 [00:01<00:00, 53.71it/s, Epoch: 54, Batch: 79,Loss: -2.900,Avg.Loss: -2.670,LR: 2.21E-04]Training epoch 54:  71%|███████   | 79/112 [00:01<00:00, 53.71it/s, Epoch: 54, Batch: 80,Loss: -2.819,Avg.Loss: -2.672,LR: 2.21E-04]Training epoch 54:  71%|███████▏  | 80/112 [00:01<00:00, 53.71it/s, Epoch: 54, Batch: 81,Loss: -2.795,Avg.Loss: -2.674,LR: 2.21E-04]Training epoch 54:  72%|███████▏  | 81/112 [00:01<00:00, 53.71it/s, Epoch: 54, Batch: 82,Loss: -2.983,Avg.Loss: -2.677,LR: 2.21E-04]Training epoch 54:  73%|███████▎  | 82/112 [00:01<00:00, 53.71it/s, Epoch: 54, Batch: 83,Loss: -3.042,Avg.Loss: -2.682,LR: 2.21E-04]Training epoch 54:  74%|███████▍  | 83/112 [00:01<00:00, 53.71it/s, Epoch: 54, Batch: 84,Loss: -2.847,Avg.Loss: -2.684,LR: 2.21E-04]Training epoch 54:  75%|███████▌  | 84/112 [00:01<00:00, 53.74it/s, Epoch: 54, Batch: 84,Loss: -2.847,Avg.Loss: -2.684,LR: 2.21E-04]Training epoch 54:  75%|███████▌  | 84/112 [00:01<00:00, 53.74it/s, Epoch: 54, Batch: 85,Loss: -2.963,Avg.Loss: -2.687,LR: 2.21E-04]Training epoch 54:  76%|███████▌  | 85/112 [00:01<00:00, 53.74it/s, Epoch: 54, Batch: 86,Loss: -2.771,Avg.Loss: -2.688,LR: 2.20E-04]Training epoch 54:  77%|███████▋  | 86/112 [00:01<00:00, 53.74it/s, Epoch: 54, Batch: 87,Loss: -2.782,Avg.Loss: -2.689,LR: 2.20E-04]Training epoch 54:  78%|███████▊  | 87/112 [00:01<00:00, 53.74it/s, Epoch: 54, Batch: 88,Loss: -2.831,Avg.Loss: -2.691,LR: 2.20E-04]Training epoch 54:  79%|███████▊  | 88/112 [00:01<00:00, 53.74it/s, Epoch: 54, Batch: 89,Loss: -2.869,Avg.Loss: -2.693,LR: 2.20E-04]Training epoch 54:  79%|███████▉  | 89/112 [00:01<00:00, 53.74it/s, Epoch: 54, Batch: 90,Loss: -2.908,Avg.Loss: -2.695,LR: 2.20E-04]Training epoch 54:  80%|████████  | 90/112 [00:01<00:00, 53.89it/s, Epoch: 54, Batch: 90,Loss: -2.908,Avg.Loss: -2.695,LR: 2.20E-04]Training epoch 54:  80%|████████  | 90/112 [00:01<00:00, 53.89it/s, Epoch: 54, Batch: 91,Loss: -2.746,Avg.Loss: -2.696,LR: 2.20E-04]Training epoch 54:  81%|████████▏ | 91/112 [00:01<00:00, 53.89it/s, Epoch: 54, Batch: 92,Loss: -2.681,Avg.Loss: -2.696,LR: 2.20E-04]Training epoch 54:  82%|████████▏ | 92/112 [00:01<00:00, 53.89it/s, Epoch: 54, Batch: 93,Loss: -3.119,Avg.Loss: -2.700,LR: 2.20E-04]Training epoch 54:  83%|████████▎ | 93/112 [00:01<00:00, 53.89it/s, Epoch: 54, Batch: 94,Loss: -2.960,Avg.Loss: -2.703,LR: 2.20E-04]Training epoch 54:  84%|████████▍ | 94/112 [00:01<00:00, 53.89it/s, Epoch: 54, Batch: 95,Loss: -3.230,Avg.Loss: -2.708,LR: 2.20E-04]Training epoch 54:  85%|████████▍ | 95/112 [00:01<00:00, 53.89it/s, Epoch: 54, Batch: 96,Loss: -2.667,Avg.Loss: -2.708,LR: 2.20E-04]Training epoch 54:  86%|████████▌ | 96/112 [00:01<00:00, 53.99it/s, Epoch: 54, Batch: 96,Loss: -2.667,Avg.Loss: -2.708,LR: 2.20E-04]Training epoch 54:  86%|████████▌ | 96/112 [00:01<00:00, 53.99it/s, Epoch: 54, Batch: 97,Loss: -2.863,Avg.Loss: -2.710,LR: 2.20E-04]Training epoch 54:  87%|████████▋ | 97/112 [00:01<00:00, 53.99it/s, Epoch: 54, Batch: 98,Loss: -3.071,Avg.Loss: -2.713,LR: 2.20E-04]Training epoch 54:  88%|████████▊ | 98/112 [00:01<00:00, 53.99it/s, Epoch: 54, Batch: 99,Loss: -2.870,Avg.Loss: -2.715,LR: 2.20E-04]Training epoch 54:  88%|████████▊ | 99/112 [00:01<00:00, 53.99it/s, Epoch: 54, Batch: 100,Loss: -3.063,Avg.Loss: -2.718,LR: 2.20E-04]Training epoch 54:  89%|████████▉ | 100/112 [00:01<00:00, 53.99it/s, Epoch: 54, Batch: 101,Loss: -2.816,Avg.Loss: -2.719,LR: 2.19E-04]Training epoch 54:  90%|█████████ | 101/112 [00:01<00:00, 53.99it/s, Epoch: 54, Batch: 102,Loss: -2.431,Avg.Loss: -2.716,LR: 2.19E-04]Training epoch 54:  91%|█████████ | 102/112 [00:01<00:00, 54.04it/s, Epoch: 54, Batch: 102,Loss: -2.431,Avg.Loss: -2.716,LR: 2.19E-04]Training epoch 54:  91%|█████████ | 102/112 [00:01<00:00, 54.04it/s, Epoch: 54, Batch: 103,Loss: -2.647,Avg.Loss: -2.716,LR: 2.19E-04]Training epoch 54:  92%|█████████▏| 103/112 [00:01<00:00, 54.04it/s, Epoch: 54, Batch: 104,Loss: -3.023,Avg.Loss: -2.719,LR: 2.19E-04]Training epoch 54:  93%|█████████▎| 104/112 [00:01<00:00, 54.04it/s, Epoch: 54, Batch: 105,Loss: -1.137,Avg.Loss: -2.704,LR: 2.19E-04]Training epoch 54:  94%|█████████▍| 105/112 [00:01<00:00, 54.04it/s, Epoch: 54, Batch: 106,Loss: 0.879,Avg.Loss: -2.670,LR: 2.19E-04] Training epoch 54:  95%|█████████▍| 106/112 [00:02<00:00, 54.04it/s, Epoch: 54, Batch: 107,Loss: 0.243,Avg.Loss: -2.643,LR: 2.19E-04]Training epoch 54:  96%|█████████▌| 107/112 [00:02<00:00, 54.04it/s, Epoch: 54, Batch: 108,Loss: -2.036,Avg.Loss: -2.637,LR: 2.19E-04]Training epoch 54:  96%|█████████▋| 108/112 [00:02<00:00, 53.77it/s, Epoch: 54, Batch: 108,Loss: -2.036,Avg.Loss: -2.637,LR: 2.19E-04]Training epoch 54:  96%|█████████▋| 108/112 [00:02<00:00, 53.77it/s, Epoch: 54, Batch: 109,Loss: -0.922,Avg.Loss: -2.621,LR: 2.19E-04]Training epoch 54:  97%|█████████▋| 109/112 [00:02<00:00, 53.77it/s, Epoch: 54, Batch: 110,Loss: -0.232,Avg.Loss: -2.600,LR: 2.19E-04]Training epoch 54:  98%|█████████▊| 110/112 [00:02<00:00, 53.77it/s, Epoch: 54, Batch: 111,Loss: -0.777,Avg.Loss: -2.583,LR: 2.19E-04]Training epoch 54:  99%|█████████▉| 111/112 [00:02<00:00, 53.77it/s, Epoch: 54, Batch: 112,Loss: -1.183,Avg.Loss: -2.571,LR: 2.19E-04]Training epoch 54: 100%|██████████| 112/112 [00:02<00:00, 53.37it/s, Epoch: 54, Batch: 112,Loss: -1.183,Avg.Loss: -2.571,LR: 2.19E-04]
Training epoch 55:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 55:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 55, Batch: 1,Loss: -2.925,Avg.Loss: -2.925,LR: 2.19E-04]Training epoch 55:   1%|          | 1/112 [00:00<00:03, 30.26it/s, Epoch: 55, Batch: 2,Loss: -2.041,Avg.Loss: -2.483,LR: 2.19E-04]Training epoch 55:   2%|▏         | 2/112 [00:00<00:02, 42.95it/s, Epoch: 55, Batch: 3,Loss: -2.353,Avg.Loss: -2.439,LR: 2.18E-04]Training epoch 55:   3%|▎         | 3/112 [00:00<00:02, 46.92it/s, Epoch: 55, Batch: 4,Loss: -2.803,Avg.Loss: -2.530,LR: 2.18E-04]Training epoch 55:   4%|▎         | 4/112 [00:00<00:02, 48.48it/s, Epoch: 55, Batch: 5,Loss: -2.949,Avg.Loss: -2.614,LR: 2.18E-04]Training epoch 55:   4%|▍         | 5/112 [00:00<00:02, 49.47it/s, Epoch: 55, Batch: 6,Loss: -3.057,Avg.Loss: -2.688,LR: 2.18E-04]Training epoch 55:   5%|▌         | 6/112 [00:00<00:01, 59.25it/s, Epoch: 55, Batch: 6,Loss: -3.057,Avg.Loss: -2.688,LR: 2.18E-04]Training epoch 55:   5%|▌         | 6/112 [00:00<00:01, 59.25it/s, Epoch: 55, Batch: 7,Loss: -3.040,Avg.Loss: -2.738,LR: 2.18E-04]Training epoch 55:   6%|▋         | 7/112 [00:00<00:01, 59.25it/s, Epoch: 55, Batch: 8,Loss: -2.367,Avg.Loss: -2.692,LR: 2.18E-04]Training epoch 55:   7%|▋         | 8/112 [00:00<00:01, 59.25it/s, Epoch: 55, Batch: 9,Loss: -2.104,Avg.Loss: -2.626,LR: 2.18E-04]Training epoch 55:   8%|▊         | 9/112 [00:00<00:01, 59.25it/s, Epoch: 55, Batch: 10,Loss: -2.824,Avg.Loss: -2.646,LR: 2.18E-04]Training epoch 55:   9%|▉         | 10/112 [00:00<00:01, 59.25it/s, Epoch: 55, Batch: 11,Loss: -2.323,Avg.Loss: -2.617,LR: 2.18E-04]Training epoch 55:  10%|▉         | 11/112 [00:00<00:01, 59.25it/s, Epoch: 55, Batch: 12,Loss: -0.878,Avg.Loss: -2.472,LR: 2.18E-04]Training epoch 55:  11%|█         | 12/112 [00:00<00:01, 55.33it/s, Epoch: 55, Batch: 12,Loss: -0.878,Avg.Loss: -2.472,LR: 2.18E-04]Training epoch 55:  11%|█         | 12/112 [00:00<00:01, 55.33it/s, Epoch: 55, Batch: 13,Loss: -1.308,Avg.Loss: -2.382,LR: 2.18E-04]Training epoch 55:  12%|█▏        | 13/112 [00:00<00:01, 55.33it/s, Epoch: 55, Batch: 14,Loss: -2.894,Avg.Loss: -2.419,LR: 2.18E-04]Training epoch 55:  12%|█▎        | 14/112 [00:00<00:01, 55.33it/s, Epoch: 55, Batch: 15,Loss: -2.361,Avg.Loss: -2.415,LR: 2.18E-04]Training epoch 55:  13%|█▎        | 15/112 [00:00<00:01, 55.33it/s, Epoch: 55, Batch: 16,Loss: -2.622,Avg.Loss: -2.428,LR: 2.18E-04]Training epoch 55:  14%|█▍        | 16/112 [00:00<00:01, 55.33it/s, Epoch: 55, Batch: 17,Loss: -2.315,Avg.Loss: -2.421,LR: 2.17E-04]Training epoch 55:  15%|█▌        | 17/112 [00:00<00:01, 55.33it/s, Epoch: 55, Batch: 18,Loss: -2.231,Avg.Loss: -2.411,LR: 2.17E-04]Training epoch 55:  16%|█▌        | 18/112 [00:00<00:01, 54.30it/s, Epoch: 55, Batch: 18,Loss: -2.231,Avg.Loss: -2.411,LR: 2.17E-04]Training epoch 55:  16%|█▌        | 18/112 [00:00<00:01, 54.30it/s, Epoch: 55, Batch: 19,Loss: -2.953,Avg.Loss: -2.439,LR: 2.17E-04]Training epoch 55:  17%|█▋        | 19/112 [00:00<00:01, 54.30it/s, Epoch: 55, Batch: 20,Loss: -2.268,Avg.Loss: -2.431,LR: 2.17E-04]Training epoch 55:  18%|█▊        | 20/112 [00:00<00:01, 54.30it/s, Epoch: 55, Batch: 21,Loss: -2.341,Avg.Loss: -2.426,LR: 2.17E-04]Training epoch 55:  19%|█▉        | 21/112 [00:00<00:01, 54.30it/s, Epoch: 55, Batch: 22,Loss: -2.342,Avg.Loss: -2.423,LR: 2.17E-04]Training epoch 55:  20%|█▉        | 22/112 [00:00<00:01, 54.30it/s, Epoch: 55, Batch: 23,Loss: -1.808,Avg.Loss: -2.396,LR: 2.17E-04]Training epoch 55:  21%|██        | 23/112 [00:00<00:01, 54.30it/s, Epoch: 55, Batch: 24,Loss: -1.654,Avg.Loss: -2.365,LR: 2.17E-04]Training epoch 55:  21%|██▏       | 24/112 [00:00<00:01, 53.49it/s, Epoch: 55, Batch: 24,Loss: -1.654,Avg.Loss: -2.365,LR: 2.17E-04]Training epoch 55:  21%|██▏       | 24/112 [00:00<00:01, 53.49it/s, Epoch: 55, Batch: 25,Loss: -1.785,Avg.Loss: -2.342,LR: 2.17E-04]Training epoch 55:  22%|██▏       | 25/112 [00:00<00:01, 53.49it/s, Epoch: 55, Batch: 26,Loss: -2.614,Avg.Loss: -2.352,LR: 2.17E-04]Training epoch 55:  23%|██▎       | 26/112 [00:00<00:01, 53.49it/s, Epoch: 55, Batch: 27,Loss: -2.365,Avg.Loss: -2.353,LR: 2.17E-04]Training epoch 55:  24%|██▍       | 27/112 [00:00<00:01, 53.49it/s, Epoch: 55, Batch: 28,Loss: -2.524,Avg.Loss: -2.359,LR: 2.17E-04]Training epoch 55:  25%|██▌       | 28/112 [00:00<00:01, 53.49it/s, Epoch: 55, Batch: 29,Loss: -2.722,Avg.Loss: -2.371,LR: 2.17E-04]Training epoch 55:  26%|██▌       | 29/112 [00:00<00:01, 53.49it/s, Epoch: 55, Batch: 30,Loss: -2.542,Avg.Loss: -2.377,LR: 2.17E-04]Training epoch 55:  27%|██▋       | 30/112 [00:00<00:01, 52.86it/s, Epoch: 55, Batch: 30,Loss: -2.542,Avg.Loss: -2.377,LR: 2.17E-04]Training epoch 55:  27%|██▋       | 30/112 [00:00<00:01, 52.86it/s, Epoch: 55, Batch: 31,Loss: -2.900,Avg.Loss: -2.394,LR: 2.17E-04]Training epoch 55:  28%|██▊       | 31/112 [00:00<00:01, 52.86it/s, Epoch: 55, Batch: 32,Loss: -2.105,Avg.Loss: -2.385,LR: 2.16E-04]Training epoch 55:  29%|██▊       | 32/112 [00:00<00:01, 52.86it/s, Epoch: 55, Batch: 33,Loss: -0.731,Avg.Loss: -2.335,LR: 2.16E-04]Training epoch 55:  29%|██▉       | 33/112 [00:00<00:01, 52.86it/s, Epoch: 55, Batch: 34,Loss: -1.506,Avg.Loss: -2.310,LR: 2.16E-04]Training epoch 55:  30%|███       | 34/112 [00:00<00:01, 52.86it/s, Epoch: 55, Batch: 35,Loss: -2.858,Avg.Loss: -2.326,LR: 2.16E-04]Training epoch 55:  31%|███▏      | 35/112 [00:00<00:01, 52.86it/s, Epoch: 55, Batch: 36,Loss: -1.263,Avg.Loss: -2.297,LR: 2.16E-04]Training epoch 55:  32%|███▏      | 36/112 [00:00<00:01, 52.68it/s, Epoch: 55, Batch: 36,Loss: -1.263,Avg.Loss: -2.297,LR: 2.16E-04]Training epoch 55:  32%|███▏      | 36/112 [00:00<00:01, 52.68it/s, Epoch: 55, Batch: 37,Loss: 2.481,Avg.Loss: -2.167,LR: 2.16E-04] Training epoch 55:  33%|███▎      | 37/112 [00:00<00:01, 52.68it/s, Epoch: 55, Batch: 38,Loss: 1.012,Avg.Loss: -2.084,LR: 2.16E-04]Training epoch 55:  34%|███▍      | 38/112 [00:00<00:01, 52.68it/s, Epoch: 55, Batch: 39,Loss: -0.526,Avg.Loss: -2.044,LR: 2.16E-04]Training epoch 55:  35%|███▍      | 39/112 [00:00<00:01, 52.68it/s, Epoch: 55, Batch: 40,Loss: -2.742,Avg.Loss: -2.061,LR: 2.16E-04]Training epoch 55:  36%|███▌      | 40/112 [00:00<00:01, 52.68it/s, Epoch: 55, Batch: 41,Loss: -1.233,Avg.Loss: -2.041,LR: 2.16E-04]Training epoch 55:  37%|███▋      | 41/112 [00:00<00:01, 52.68it/s, Epoch: 55, Batch: 42,Loss: -0.948,Avg.Loss: -2.015,LR: 2.16E-04]Training epoch 55:  38%|███▊      | 42/112 [00:00<00:01, 53.06it/s, Epoch: 55, Batch: 42,Loss: -0.948,Avg.Loss: -2.015,LR: 2.16E-04]Training epoch 55:  38%|███▊      | 42/112 [00:00<00:01, 53.06it/s, Epoch: 55, Batch: 43,Loss: -1.674,Avg.Loss: -2.007,LR: 2.16E-04]Training epoch 55:  38%|███▊      | 43/112 [00:00<00:01, 53.06it/s, Epoch: 55, Batch: 44,Loss: -3.032,Avg.Loss: -2.030,LR: 2.16E-04]Training epoch 55:  39%|███▉      | 44/112 [00:00<00:01, 53.06it/s, Epoch: 55, Batch: 45,Loss: -1.831,Avg.Loss: -2.026,LR: 2.16E-04]Training epoch 55:  40%|████      | 45/112 [00:00<00:01, 53.06it/s, Epoch: 55, Batch: 46,Loss: -2.918,Avg.Loss: -2.045,LR: 2.15E-04]Training epoch 55:  41%|████      | 46/112 [00:00<00:01, 53.06it/s, Epoch: 55, Batch: 47,Loss: -2.701,Avg.Loss: -2.059,LR: 2.15E-04]Training epoch 55:  42%|████▏     | 47/112 [00:00<00:01, 53.06it/s, Epoch: 55, Batch: 48,Loss: -2.818,Avg.Loss: -2.075,LR: 2.15E-04]Training epoch 55:  43%|████▎     | 48/112 [00:00<00:01, 53.05it/s, Epoch: 55, Batch: 48,Loss: -2.818,Avg.Loss: -2.075,LR: 2.15E-04]Training epoch 55:  43%|████▎     | 48/112 [00:00<00:01, 53.05it/s, Epoch: 55, Batch: 49,Loss: -2.811,Avg.Loss: -2.090,LR: 2.15E-04]Training epoch 55:  44%|████▍     | 49/112 [00:00<00:01, 53.05it/s, Epoch: 55, Batch: 50,Loss: -3.076,Avg.Loss: -2.110,LR: 2.15E-04]Training epoch 55:  45%|████▍     | 50/112 [00:00<00:01, 53.05it/s, Epoch: 55, Batch: 51,Loss: -2.656,Avg.Loss: -2.121,LR: 2.15E-04]Training epoch 55:  46%|████▌     | 51/112 [00:00<00:01, 53.05it/s, Epoch: 55, Batch: 52,Loss: -2.738,Avg.Loss: -2.132,LR: 2.15E-04]Training epoch 55:  46%|████▋     | 52/112 [00:00<00:01, 53.05it/s, Epoch: 55, Batch: 53,Loss: -2.718,Avg.Loss: -2.143,LR: 2.15E-04]Training epoch 55:  47%|████▋     | 53/112 [00:01<00:01, 53.05it/s, Epoch: 55, Batch: 54,Loss: -3.005,Avg.Loss: -2.159,LR: 2.15E-04]Training epoch 55:  48%|████▊     | 54/112 [00:01<00:01, 53.37it/s, Epoch: 55, Batch: 54,Loss: -3.005,Avg.Loss: -2.159,LR: 2.15E-04]Training epoch 55:  48%|████▊     | 54/112 [00:01<00:01, 53.37it/s, Epoch: 55, Batch: 55,Loss: -2.938,Avg.Loss: -2.174,LR: 2.15E-04]Training epoch 55:  49%|████▉     | 55/112 [00:01<00:01, 53.37it/s, Epoch: 55, Batch: 56,Loss: -2.880,Avg.Loss: -2.186,LR: 2.15E-04]Training epoch 55:  50%|█████     | 56/112 [00:01<00:01, 53.37it/s, Epoch: 55, Batch: 57,Loss: -2.022,Avg.Loss: -2.183,LR: 2.15E-04]Training epoch 55:  51%|█████     | 57/112 [00:01<00:01, 53.37it/s, Epoch: 55, Batch: 58,Loss: -2.564,Avg.Loss: -2.190,LR: 2.15E-04]Training epoch 55:  52%|█████▏    | 58/112 [00:01<00:01, 53.37it/s, Epoch: 55, Batch: 59,Loss: -3.280,Avg.Loss: -2.208,LR: 2.15E-04]Training epoch 55:  53%|█████▎    | 59/112 [00:01<00:00, 53.37it/s, Epoch: 55, Batch: 60,Loss: -2.944,Avg.Loss: -2.221,LR: 2.14E-04]Training epoch 55:  54%|█████▎    | 60/112 [00:01<00:00, 53.05it/s, Epoch: 55, Batch: 60,Loss: -2.944,Avg.Loss: -2.221,LR: 2.14E-04]Training epoch 55:  54%|█████▎    | 60/112 [00:01<00:00, 53.05it/s, Epoch: 55, Batch: 61,Loss: -2.736,Avg.Loss: -2.229,LR: 2.14E-04]Training epoch 55:  54%|█████▍    | 61/112 [00:01<00:00, 53.05it/s, Epoch: 55, Batch: 62,Loss: -2.900,Avg.Loss: -2.240,LR: 2.14E-04]Training epoch 55:  55%|█████▌    | 62/112 [00:01<00:00, 53.05it/s, Epoch: 55, Batch: 63,Loss: -2.966,Avg.Loss: -2.251,LR: 2.14E-04]Training epoch 55:  56%|█████▋    | 63/112 [00:01<00:00, 53.05it/s, Epoch: 55, Batch: 64,Loss: -2.874,Avg.Loss: -2.261,LR: 2.14E-04]Training epoch 55:  57%|█████▋    | 64/112 [00:01<00:00, 53.05it/s, Epoch: 55, Batch: 65,Loss: -2.568,Avg.Loss: -2.266,LR: 2.14E-04]Training epoch 55:  58%|█████▊    | 65/112 [00:01<00:00, 53.05it/s, Epoch: 55, Batch: 66,Loss: -2.883,Avg.Loss: -2.275,LR: 2.14E-04]Training epoch 55:  59%|█████▉    | 66/112 [00:01<00:00, 52.96it/s, Epoch: 55, Batch: 66,Loss: -2.883,Avg.Loss: -2.275,LR: 2.14E-04]Training epoch 55:  59%|█████▉    | 66/112 [00:01<00:00, 52.96it/s, Epoch: 55, Batch: 67,Loss: -2.802,Avg.Loss: -2.283,LR: 2.14E-04]Training epoch 55:  60%|█████▉    | 67/112 [00:01<00:00, 52.96it/s, Epoch: 55, Batch: 68,Loss: -2.848,Avg.Loss: -2.291,LR: 2.14E-04]Training epoch 55:  61%|██████    | 68/112 [00:01<00:00, 52.96it/s, Epoch: 55, Batch: 69,Loss: -2.677,Avg.Loss: -2.297,LR: 2.14E-04]Training epoch 55:  62%|██████▏   | 69/112 [00:01<00:00, 52.96it/s, Epoch: 55, Batch: 70,Loss: -2.703,Avg.Loss: -2.303,LR: 2.14E-04]Training epoch 55:  62%|██████▎   | 70/112 [00:01<00:00, 52.96it/s, Epoch: 55, Batch: 71,Loss: -3.230,Avg.Loss: -2.316,LR: 2.14E-04]Training epoch 55:  63%|██████▎   | 71/112 [00:01<00:00, 52.96it/s, Epoch: 55, Batch: 72,Loss: -3.506,Avg.Loss: -2.332,LR: 2.14E-04]Training epoch 55:  64%|██████▍   | 72/112 [00:01<00:00, 53.16it/s, Epoch: 55, Batch: 72,Loss: -3.506,Avg.Loss: -2.332,LR: 2.14E-04]Training epoch 55:  64%|██████▍   | 72/112 [00:01<00:00, 53.16it/s, Epoch: 55, Batch: 73,Loss: -2.826,Avg.Loss: -2.339,LR: 2.14E-04]Training epoch 55:  65%|██████▌   | 73/112 [00:01<00:00, 53.16it/s, Epoch: 55, Batch: 74,Loss: -2.283,Avg.Loss: -2.338,LR: 2.14E-04]Training epoch 55:  66%|██████▌   | 74/112 [00:01<00:00, 53.16it/s, Epoch: 55, Batch: 75,Loss: -2.670,Avg.Loss: -2.343,LR: 2.13E-04]Training epoch 55:  67%|██████▋   | 75/112 [00:01<00:00, 53.16it/s, Epoch: 55, Batch: 76,Loss: -2.390,Avg.Loss: -2.343,LR: 2.13E-04]Training epoch 55:  68%|██████▊   | 76/112 [00:01<00:00, 53.16it/s, Epoch: 55, Batch: 77,Loss: -3.057,Avg.Loss: -2.353,LR: 2.13E-04]Training epoch 55:  69%|██████▉   | 77/112 [00:01<00:00, 53.16it/s, Epoch: 55, Batch: 78,Loss: -2.945,Avg.Loss: -2.360,LR: 2.13E-04]Training epoch 55:  70%|██████▉   | 78/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 78,Loss: -2.945,Avg.Loss: -2.360,LR: 2.13E-04]Training epoch 55:  70%|██████▉   | 78/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 79,Loss: -2.270,Avg.Loss: -2.359,LR: 2.13E-04]Training epoch 55:  71%|███████   | 79/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 80,Loss: -2.429,Avg.Loss: -2.360,LR: 2.13E-04]Training epoch 55:  71%|███████▏  | 80/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 81,Loss: -2.811,Avg.Loss: -2.366,LR: 2.13E-04]Training epoch 55:  72%|███████▏  | 81/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 82,Loss: -2.546,Avg.Loss: -2.368,LR: 2.13E-04]Training epoch 55:  73%|███████▎  | 82/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 83,Loss: -2.716,Avg.Loss: -2.372,LR: 2.13E-04]Training epoch 55:  74%|███████▍  | 83/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 84,Loss: -2.721,Avg.Loss: -2.376,LR: 2.13E-04]Training epoch 55:  75%|███████▌  | 84/112 [00:01<00:00, 53.24it/s, Epoch: 55, Batch: 84,Loss: -2.721,Avg.Loss: -2.376,LR: 2.13E-04]Training epoch 55:  75%|███████▌  | 84/112 [00:01<00:00, 53.24it/s, Epoch: 55, Batch: 85,Loss: -2.419,Avg.Loss: -2.377,LR: 2.13E-04]Training epoch 55:  76%|███████▌  | 85/112 [00:01<00:00, 53.24it/s, Epoch: 55, Batch: 86,Loss: -2.453,Avg.Loss: -2.378,LR: 2.13E-04]Training epoch 55:  77%|███████▋  | 86/112 [00:01<00:00, 53.24it/s, Epoch: 55, Batch: 87,Loss: -1.993,Avg.Loss: -2.373,LR: 2.13E-04]Training epoch 55:  78%|███████▊  | 87/112 [00:01<00:00, 53.24it/s, Epoch: 55, Batch: 88,Loss: -1.610,Avg.Loss: -2.364,LR: 2.13E-04]Training epoch 55:  79%|███████▊  | 88/112 [00:01<00:00, 53.24it/s, Epoch: 55, Batch: 89,Loss: -1.108,Avg.Loss: -2.350,LR: 2.12E-04]Training epoch 55:  79%|███████▉  | 89/112 [00:01<00:00, 53.24it/s, Epoch: 55, Batch: 90,Loss: -1.976,Avg.Loss: -2.346,LR: 2.12E-04]Training epoch 55:  80%|████████  | 90/112 [00:01<00:00, 53.33it/s, Epoch: 55, Batch: 90,Loss: -1.976,Avg.Loss: -2.346,LR: 2.12E-04]Training epoch 55:  80%|████████  | 90/112 [00:01<00:00, 53.33it/s, Epoch: 55, Batch: 91,Loss: -2.640,Avg.Loss: -2.349,LR: 2.12E-04]Training epoch 55:  81%|████████▏ | 91/112 [00:01<00:00, 53.33it/s, Epoch: 55, Batch: 92,Loss: -2.474,Avg.Loss: -2.351,LR: 2.12E-04]Training epoch 55:  82%|████████▏ | 92/112 [00:01<00:00, 53.33it/s, Epoch: 55, Batch: 93,Loss: -2.220,Avg.Loss: -2.349,LR: 2.12E-04]Training epoch 55:  83%|████████▎ | 93/112 [00:01<00:00, 53.33it/s, Epoch: 55, Batch: 94,Loss: -2.023,Avg.Loss: -2.346,LR: 2.12E-04]Training epoch 55:  84%|████████▍ | 94/112 [00:01<00:00, 53.33it/s, Epoch: 55, Batch: 95,Loss: -2.687,Avg.Loss: -2.349,LR: 2.12E-04]Training epoch 55:  85%|████████▍ | 95/112 [00:01<00:00, 53.33it/s, Epoch: 55, Batch: 96,Loss: -2.460,Avg.Loss: -2.351,LR: 2.12E-04]Training epoch 55:  86%|████████▌ | 96/112 [00:01<00:00, 53.31it/s, Epoch: 55, Batch: 96,Loss: -2.460,Avg.Loss: -2.351,LR: 2.12E-04]Training epoch 55:  86%|████████▌ | 96/112 [00:01<00:00, 53.31it/s, Epoch: 55, Batch: 97,Loss: -2.638,Avg.Loss: -2.354,LR: 2.12E-04]Training epoch 55:  87%|████████▋ | 97/112 [00:01<00:00, 53.31it/s, Epoch: 55, Batch: 98,Loss: -1.964,Avg.Loss: -2.350,LR: 2.12E-04]Training epoch 55:  88%|████████▊ | 98/112 [00:01<00:00, 53.31it/s, Epoch: 55, Batch: 99,Loss: -1.424,Avg.Loss: -2.340,LR: 2.12E-04]Training epoch 55:  88%|████████▊ | 99/112 [00:01<00:00, 53.31it/s, Epoch: 55, Batch: 100,Loss: -0.259,Avg.Loss: -2.319,LR: 2.12E-04]Training epoch 55:  89%|████████▉ | 100/112 [00:01<00:00, 53.31it/s, Epoch: 55, Batch: 101,Loss: -0.801,Avg.Loss: -2.304,LR: 2.12E-04]Training epoch 55:  90%|█████████ | 101/112 [00:01<00:00, 53.31it/s, Epoch: 55, Batch: 102,Loss: -2.513,Avg.Loss: -2.306,LR: 2.12E-04]Training epoch 55:  91%|█████████ | 102/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 102,Loss: -2.513,Avg.Loss: -2.306,LR: 2.12E-04]Training epoch 55:  91%|█████████ | 102/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 103,Loss: -1.382,Avg.Loss: -2.297,LR: 2.12E-04]Training epoch 55:  92%|█████████▏| 103/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 104,Loss: 0.358,Avg.Loss: -2.272,LR: 2.11E-04] Training epoch 55:  93%|█████████▎| 104/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 105,Loss: -0.654,Avg.Loss: -2.257,LR: 2.11E-04]Training epoch 55:  94%|█████████▍| 105/112 [00:01<00:00, 53.39it/s, Epoch: 55, Batch: 106,Loss: -2.163,Avg.Loss: -2.256,LR: 2.11E-04]Training epoch 55:  95%|█████████▍| 106/112 [00:02<00:00, 53.39it/s, Epoch: 55, Batch: 107,Loss: -2.463,Avg.Loss: -2.258,LR: 2.11E-04]Training epoch 55:  96%|█████████▌| 107/112 [00:02<00:00, 53.39it/s, Epoch: 55, Batch: 108,Loss: -0.969,Avg.Loss: -2.246,LR: 2.11E-04]Training epoch 55:  96%|█████████▋| 108/112 [00:02<00:00, 53.56it/s, Epoch: 55, Batch: 108,Loss: -0.969,Avg.Loss: -2.246,LR: 2.11E-04]Training epoch 55:  96%|█████████▋| 108/112 [00:02<00:00, 53.56it/s, Epoch: 55, Batch: 109,Loss: -1.875,Avg.Loss: -2.242,LR: 2.11E-04]Training epoch 55:  97%|█████████▋| 109/112 [00:02<00:00, 53.56it/s, Epoch: 55, Batch: 110,Loss: -2.782,Avg.Loss: -2.247,LR: 2.11E-04]Training epoch 55:  98%|█████████▊| 110/112 [00:02<00:00, 53.56it/s, Epoch: 55, Batch: 111,Loss: -1.226,Avg.Loss: -2.238,LR: 2.11E-04]Training epoch 55:  99%|█████████▉| 111/112 [00:02<00:00, 53.56it/s, Epoch: 55, Batch: 112,Loss: 1.100,Avg.Loss: -2.208,LR: 2.11E-04] Training epoch 55: 100%|██████████| 112/112 [00:02<00:00, 53.34it/s, Epoch: 55, Batch: 112,Loss: 1.100,Avg.Loss: -2.208,LR: 2.11E-04]
Training epoch 56:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 56:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 56, Batch: 1,Loss: 0.032,Avg.Loss: 0.032,LR: 2.11E-04]Training epoch 56:   1%|          | 1/112 [00:00<00:04, 24.74it/s, Epoch: 56, Batch: 2,Loss: -1.720,Avg.Loss: -0.844,LR: 2.11E-04]Training epoch 56:   2%|▏         | 2/112 [00:00<00:02, 37.41it/s, Epoch: 56, Batch: 3,Loss: -2.880,Avg.Loss: -1.523,LR: 2.11E-04]Training epoch 56:   3%|▎         | 3/112 [00:00<00:02, 43.22it/s, Epoch: 56, Batch: 4,Loss: -1.921,Avg.Loss: -1.622,LR: 2.11E-04]Training epoch 56:   4%|▎         | 4/112 [00:00<00:02, 47.35it/s, Epoch: 56, Batch: 5,Loss: -1.722,Avg.Loss: -1.642,LR: 2.11E-04]Training epoch 56:   4%|▍         | 5/112 [00:00<00:02, 48.57it/s, Epoch: 56, Batch: 6,Loss: -2.927,Avg.Loss: -1.856,LR: 2.10E-04]Training epoch 56:   5%|▌         | 6/112 [00:00<00:01, 58.18it/s, Epoch: 56, Batch: 6,Loss: -2.927,Avg.Loss: -1.856,LR: 2.10E-04]Training epoch 56:   5%|▌         | 6/112 [00:00<00:01, 58.18it/s, Epoch: 56, Batch: 7,Loss: -1.947,Avg.Loss: -1.869,LR: 2.10E-04]Training epoch 56:   6%|▋         | 7/112 [00:00<00:01, 58.18it/s, Epoch: 56, Batch: 8,Loss: -0.502,Avg.Loss: -1.698,LR: 2.10E-04]Training epoch 56:   7%|▋         | 8/112 [00:00<00:01, 58.18it/s, Epoch: 56, Batch: 9,Loss: -0.786,Avg.Loss: -1.597,LR: 2.10E-04]Training epoch 56:   8%|▊         | 9/112 [00:00<00:01, 58.18it/s, Epoch: 56, Batch: 10,Loss: -2.512,Avg.Loss: -1.689,LR: 2.10E-04]Training epoch 56:   9%|▉         | 10/112 [00:00<00:01, 58.18it/s, Epoch: 56, Batch: 11,Loss: -2.097,Avg.Loss: -1.726,LR: 2.10E-04]Training epoch 56:  10%|▉         | 11/112 [00:00<00:01, 58.18it/s, Epoch: 56, Batch: 12,Loss: -1.164,Avg.Loss: -1.679,LR: 2.10E-04]Training epoch 56:  11%|█         | 12/112 [00:00<00:01, 55.47it/s, Epoch: 56, Batch: 12,Loss: -1.164,Avg.Loss: -1.679,LR: 2.10E-04]Training epoch 56:  11%|█         | 12/112 [00:00<00:01, 55.47it/s, Epoch: 56, Batch: 13,Loss: -1.128,Avg.Loss: -1.636,LR: 2.10E-04]Training epoch 56:  12%|█▏        | 13/112 [00:00<00:01, 55.47it/s, Epoch: 56, Batch: 14,Loss: -2.816,Avg.Loss: -1.721,LR: 2.10E-04]Training epoch 56:  12%|█▎        | 14/112 [00:00<00:01, 55.47it/s, Epoch: 56, Batch: 15,Loss: -2.043,Avg.Loss: -1.742,LR: 2.10E-04]Training epoch 56:  13%|█▎        | 15/112 [00:00<00:01, 55.47it/s, Epoch: 56, Batch: 16,Loss: -0.789,Avg.Loss: -1.683,LR: 2.10E-04]Training epoch 56:  14%|█▍        | 16/112 [00:00<00:01, 55.47it/s, Epoch: 56, Batch: 17,Loss: -1.201,Avg.Loss: -1.654,LR: 2.10E-04]Training epoch 56:  15%|█▌        | 17/112 [00:00<00:01, 55.47it/s, Epoch: 56, Batch: 18,Loss: -2.418,Avg.Loss: -1.697,LR: 2.10E-04]Training epoch 56:  16%|█▌        | 18/112 [00:00<00:01, 54.76it/s, Epoch: 56, Batch: 18,Loss: -2.418,Avg.Loss: -1.697,LR: 2.10E-04]Training epoch 56:  16%|█▌        | 18/112 [00:00<00:01, 54.76it/s, Epoch: 56, Batch: 19,Loss: -2.776,Avg.Loss: -1.754,LR: 2.10E-04]Training epoch 56:  17%|█▋        | 19/112 [00:00<00:01, 54.76it/s, Epoch: 56, Batch: 20,Loss: -1.289,Avg.Loss: -1.730,LR: 2.10E-04]Training epoch 56:  18%|█▊        | 20/112 [00:00<00:01, 54.76it/s, Epoch: 56, Batch: 21,Loss: -1.931,Avg.Loss: -1.740,LR: 2.09E-04]Training epoch 56:  19%|█▉        | 21/112 [00:00<00:01, 54.76it/s, Epoch: 56, Batch: 22,Loss: -2.317,Avg.Loss: -1.766,LR: 2.09E-04]Training epoch 56:  20%|█▉        | 22/112 [00:00<00:01, 54.76it/s, Epoch: 56, Batch: 23,Loss: -2.500,Avg.Loss: -1.798,LR: 2.09E-04]Training epoch 56:  21%|██        | 23/112 [00:00<00:01, 54.76it/s, Epoch: 56, Batch: 24,Loss: -1.630,Avg.Loss: -1.791,LR: 2.09E-04]Training epoch 56:  21%|██▏       | 24/112 [00:00<00:01, 52.32it/s, Epoch: 56, Batch: 24,Loss: -1.630,Avg.Loss: -1.791,LR: 2.09E-04]Training epoch 56:  21%|██▏       | 24/112 [00:00<00:01, 52.32it/s, Epoch: 56, Batch: 25,Loss: -1.987,Avg.Loss: -1.799,LR: 2.09E-04]Training epoch 56:  22%|██▏       | 25/112 [00:00<00:01, 52.32it/s, Epoch: 56, Batch: 26,Loss: -2.745,Avg.Loss: -1.835,LR: 2.09E-04]Training epoch 56:  23%|██▎       | 26/112 [00:00<00:01, 52.32it/s, Epoch: 56, Batch: 27,Loss: -2.041,Avg.Loss: -1.843,LR: 2.09E-04]Training epoch 56:  24%|██▍       | 27/112 [00:00<00:01, 52.32it/s, Epoch: 56, Batch: 28,Loss: -0.749,Avg.Loss: -1.804,LR: 2.09E-04]Training epoch 56:  25%|██▌       | 28/112 [00:00<00:01, 52.32it/s, Epoch: 56, Batch: 29,Loss: -1.286,Avg.Loss: -1.786,LR: 2.09E-04]Training epoch 56:  26%|██▌       | 29/112 [00:00<00:01, 52.32it/s, Epoch: 56, Batch: 30,Loss: -2.449,Avg.Loss: -1.808,LR: 2.09E-04]Training epoch 56:  27%|██▋       | 30/112 [00:00<00:01, 52.24it/s, Epoch: 56, Batch: 30,Loss: -2.449,Avg.Loss: -1.808,LR: 2.09E-04]Training epoch 56:  27%|██▋       | 30/112 [00:00<00:01, 52.24it/s, Epoch: 56, Batch: 31,Loss: -2.872,Avg.Loss: -1.842,LR: 2.09E-04]Training epoch 56:  28%|██▊       | 31/112 [00:00<00:01, 52.24it/s, Epoch: 56, Batch: 32,Loss: -1.753,Avg.Loss: -1.840,LR: 2.09E-04]Training epoch 56:  29%|██▊       | 32/112 [00:00<00:01, 52.24it/s, Epoch: 56, Batch: 33,Loss: -1.965,Avg.Loss: -1.843,LR: 2.09E-04]Training epoch 56:  29%|██▉       | 33/112 [00:00<00:01, 52.24it/s, Epoch: 56, Batch: 34,Loss: -2.519,Avg.Loss: -1.863,LR: 2.09E-04]Training epoch 56:  30%|███       | 34/112 [00:00<00:01, 52.24it/s, Epoch: 56, Batch: 35,Loss: -2.320,Avg.Loss: -1.876,LR: 2.08E-04]Training epoch 56:  31%|███▏      | 35/112 [00:00<00:01, 52.24it/s, Epoch: 56, Batch: 36,Loss: -1.064,Avg.Loss: -1.854,LR: 2.08E-04]Training epoch 56:  32%|███▏      | 36/112 [00:00<00:01, 52.37it/s, Epoch: 56, Batch: 36,Loss: -1.064,Avg.Loss: -1.854,LR: 2.08E-04]Training epoch 56:  32%|███▏      | 36/112 [00:00<00:01, 52.37it/s, Epoch: 56, Batch: 37,Loss: -1.667,Avg.Loss: -1.849,LR: 2.08E-04]Training epoch 56:  33%|███▎      | 37/112 [00:00<00:01, 52.37it/s, Epoch: 56, Batch: 38,Loss: -2.698,Avg.Loss: -1.871,LR: 2.08E-04]Training epoch 56:  34%|███▍      | 38/112 [00:00<00:01, 52.37it/s, Epoch: 56, Batch: 39,Loss: -2.491,Avg.Loss: -1.887,LR: 2.08E-04]Training epoch 56:  35%|███▍      | 39/112 [00:00<00:01, 52.37it/s, Epoch: 56, Batch: 40,Loss: -1.565,Avg.Loss: -1.879,LR: 2.08E-04]Training epoch 56:  36%|███▌      | 40/112 [00:00<00:01, 52.37it/s, Epoch: 56, Batch: 41,Loss: -1.877,Avg.Loss: -1.879,LR: 2.08E-04]Training epoch 56:  37%|███▋      | 41/112 [00:00<00:01, 52.37it/s, Epoch: 56, Batch: 42,Loss: -3.141,Avg.Loss: -1.909,LR: 2.08E-04]Training epoch 56:  38%|███▊      | 42/112 [00:00<00:01, 52.62it/s, Epoch: 56, Batch: 42,Loss: -3.141,Avg.Loss: -1.909,LR: 2.08E-04]Training epoch 56:  38%|███▊      | 42/112 [00:00<00:01, 52.62it/s, Epoch: 56, Batch: 43,Loss: -2.010,Avg.Loss: -1.911,LR: 2.08E-04]Training epoch 56:  38%|███▊      | 43/112 [00:00<00:01, 52.62it/s, Epoch: 56, Batch: 44,Loss: -0.612,Avg.Loss: -1.882,LR: 2.08E-04]Training epoch 56:  39%|███▉      | 44/112 [00:00<00:01, 52.62it/s, Epoch: 56, Batch: 45,Loss: -1.851,Avg.Loss: -1.881,LR: 2.08E-04]Training epoch 56:  40%|████      | 45/112 [00:00<00:01, 52.62it/s, Epoch: 56, Batch: 46,Loss: -2.474,Avg.Loss: -1.894,LR: 2.08E-04]Training epoch 56:  41%|████      | 46/112 [00:00<00:01, 52.62it/s, Epoch: 56, Batch: 47,Loss: -2.411,Avg.Loss: -1.905,LR: 2.08E-04]Training epoch 56:  42%|████▏     | 47/112 [00:00<00:01, 52.62it/s, Epoch: 56, Batch: 48,Loss: -1.327,Avg.Loss: -1.893,LR: 2.08E-04]Training epoch 56:  43%|████▎     | 48/112 [00:00<00:01, 52.90it/s, Epoch: 56, Batch: 48,Loss: -1.327,Avg.Loss: -1.893,LR: 2.08E-04]Training epoch 56:  43%|████▎     | 48/112 [00:00<00:01, 52.90it/s, Epoch: 56, Batch: 49,Loss: -1.878,Avg.Loss: -1.893,LR: 2.08E-04]Training epoch 56:  44%|████▍     | 49/112 [00:00<00:01, 52.90it/s, Epoch: 56, Batch: 50,Loss: -2.574,Avg.Loss: -1.906,LR: 2.07E-04]Training epoch 56:  45%|████▍     | 50/112 [00:00<00:01, 52.90it/s, Epoch: 56, Batch: 51,Loss: -2.474,Avg.Loss: -1.917,LR: 2.07E-04]Training epoch 56:  46%|████▌     | 51/112 [00:00<00:01, 52.90it/s, Epoch: 56, Batch: 52,Loss: -1.710,Avg.Loss: -1.913,LR: 2.07E-04]Training epoch 56:  46%|████▋     | 52/112 [00:00<00:01, 52.90it/s, Epoch: 56, Batch: 53,Loss: -1.763,Avg.Loss: -1.911,LR: 2.07E-04]Training epoch 56:  47%|████▋     | 53/112 [00:01<00:01, 52.90it/s, Epoch: 56, Batch: 54,Loss: -2.585,Avg.Loss: -1.923,LR: 2.07E-04]Training epoch 56:  48%|████▊     | 54/112 [00:01<00:01, 53.30it/s, Epoch: 56, Batch: 54,Loss: -2.585,Avg.Loss: -1.923,LR: 2.07E-04]Training epoch 56:  48%|████▊     | 54/112 [00:01<00:01, 53.30it/s, Epoch: 56, Batch: 55,Loss: -1.924,Avg.Loss: -1.923,LR: 2.07E-04]Training epoch 56:  49%|████▉     | 55/112 [00:01<00:01, 53.30it/s, Epoch: 56, Batch: 56,Loss: -1.193,Avg.Loss: -1.910,LR: 2.07E-04]Training epoch 56:  50%|█████     | 56/112 [00:01<00:01, 53.30it/s, Epoch: 56, Batch: 57,Loss: -1.321,Avg.Loss: -1.900,LR: 2.07E-04]Training epoch 56:  51%|█████     | 57/112 [00:01<00:01, 53.30it/s, Epoch: 56, Batch: 58,Loss: -3.011,Avg.Loss: -1.919,LR: 2.07E-04]Training epoch 56:  52%|█████▏    | 58/112 [00:01<00:01, 53.30it/s, Epoch: 56, Batch: 59,Loss: -2.620,Avg.Loss: -1.931,LR: 2.07E-04]Training epoch 56:  53%|█████▎    | 59/112 [00:01<00:00, 53.30it/s, Epoch: 56, Batch: 60,Loss: -1.475,Avg.Loss: -1.923,LR: 2.07E-04]Training epoch 56:  54%|█████▎    | 60/112 [00:01<00:00, 53.17it/s, Epoch: 56, Batch: 60,Loss: -1.475,Avg.Loss: -1.923,LR: 2.07E-04]Training epoch 56:  54%|█████▎    | 60/112 [00:01<00:00, 53.17it/s, Epoch: 56, Batch: 61,Loss: -1.937,Avg.Loss: -1.923,LR: 2.07E-04]Training epoch 56:  54%|█████▍    | 61/112 [00:01<00:00, 53.17it/s, Epoch: 56, Batch: 62,Loss: -2.801,Avg.Loss: -1.938,LR: 2.07E-04]Training epoch 56:  55%|█████▌    | 62/112 [00:01<00:00, 53.17it/s, Epoch: 56, Batch: 63,Loss: -2.543,Avg.Loss: -1.947,LR: 2.07E-04]Training epoch 56:  56%|█████▋    | 63/112 [00:01<00:00, 53.17it/s, Epoch: 56, Batch: 64,Loss: -1.420,Avg.Loss: -1.939,LR: 2.06E-04]Training epoch 56:  57%|█████▋    | 64/112 [00:01<00:00, 53.17it/s, Epoch: 56, Batch: 65,Loss: -2.219,Avg.Loss: -1.943,LR: 2.06E-04]Training epoch 56:  58%|█████▊    | 65/112 [00:01<00:00, 53.17it/s, Epoch: 56, Batch: 66,Loss: -2.866,Avg.Loss: -1.957,LR: 2.06E-04]Training epoch 56:  59%|█████▉    | 66/112 [00:01<00:00, 53.23it/s, Epoch: 56, Batch: 66,Loss: -2.866,Avg.Loss: -1.957,LR: 2.06E-04]Training epoch 56:  59%|█████▉    | 66/112 [00:01<00:00, 53.23it/s, Epoch: 56, Batch: 67,Loss: -2.057,Avg.Loss: -1.959,LR: 2.06E-04]Training epoch 56:  60%|█████▉    | 67/112 [00:01<00:00, 53.23it/s, Epoch: 56, Batch: 68,Loss: -1.615,Avg.Loss: -1.954,LR: 2.06E-04]Training epoch 56:  61%|██████    | 68/112 [00:01<00:00, 53.23it/s, Epoch: 56, Batch: 69,Loss: -1.255,Avg.Loss: -1.943,LR: 2.06E-04]Training epoch 56:  62%|██████▏   | 69/112 [00:01<00:00, 53.23it/s, Epoch: 56, Batch: 70,Loss: -2.742,Avg.Loss: -1.955,LR: 2.06E-04]Training epoch 56:  62%|██████▎   | 70/112 [00:01<00:00, 53.23it/s, Epoch: 56, Batch: 71,Loss: -2.670,Avg.Loss: -1.965,LR: 2.06E-04]Training epoch 56:  63%|██████▎   | 71/112 [00:01<00:00, 53.23it/s, Epoch: 56, Batch: 72,Loss: -2.044,Avg.Loss: -1.966,LR: 2.06E-04]Training epoch 56:  64%|██████▍   | 72/112 [00:01<00:00, 53.39it/s, Epoch: 56, Batch: 72,Loss: -2.044,Avg.Loss: -1.966,LR: 2.06E-04]Training epoch 56:  64%|██████▍   | 72/112 [00:01<00:00, 53.39it/s, Epoch: 56, Batch: 73,Loss: -2.198,Avg.Loss: -1.969,LR: 2.06E-04]Training epoch 56:  65%|██████▌   | 73/112 [00:01<00:00, 53.39it/s, Epoch: 56, Batch: 74,Loss: -2.652,Avg.Loss: -1.978,LR: 2.06E-04]Training epoch 56:  66%|██████▌   | 74/112 [00:01<00:00, 53.39it/s, Epoch: 56, Batch: 75,Loss: -2.005,Avg.Loss: -1.979,LR: 2.06E-04]Training epoch 56:  67%|██████▋   | 75/112 [00:01<00:00, 53.39it/s, Epoch: 56, Batch: 76,Loss: -1.224,Avg.Loss: -1.969,LR: 2.06E-04]Training epoch 56:  68%|██████▊   | 76/112 [00:01<00:00, 53.39it/s, Epoch: 56, Batch: 77,Loss: -1.007,Avg.Loss: -1.956,LR: 2.06E-04]Training epoch 56:  69%|██████▉   | 77/112 [00:01<00:00, 53.39it/s, Epoch: 56, Batch: 78,Loss: -2.588,Avg.Loss: -1.965,LR: 2.05E-04]Training epoch 56:  70%|██████▉   | 78/112 [00:01<00:00, 53.41it/s, Epoch: 56, Batch: 78,Loss: -2.588,Avg.Loss: -1.965,LR: 2.05E-04]Training epoch 56:  70%|██████▉   | 78/112 [00:01<00:00, 53.41it/s, Epoch: 56, Batch: 79,Loss: -2.699,Avg.Loss: -1.974,LR: 2.05E-04]Training epoch 56:  71%|███████   | 79/112 [00:01<00:00, 53.41it/s, Epoch: 56, Batch: 80,Loss: -2.090,Avg.Loss: -1.975,LR: 2.05E-04]Training epoch 56:  71%|███████▏  | 80/112 [00:01<00:00, 53.41it/s, Epoch: 56, Batch: 81,Loss: -2.048,Avg.Loss: -1.976,LR: 2.05E-04]Training epoch 56:  72%|███████▏  | 81/112 [00:01<00:00, 53.41it/s, Epoch: 56, Batch: 82,Loss: -2.851,Avg.Loss: -1.987,LR: 2.05E-04]Training epoch 56:  73%|███████▎  | 82/112 [00:01<00:00, 53.41it/s, Epoch: 56, Batch: 83,Loss: -1.890,Avg.Loss: -1.986,LR: 2.05E-04]Training epoch 56:  74%|███████▍  | 83/112 [00:01<00:00, 53.41it/s, Epoch: 56, Batch: 84,Loss: -0.548,Avg.Loss: -1.969,LR: 2.05E-04]Training epoch 56:  75%|███████▌  | 84/112 [00:01<00:00, 53.48it/s, Epoch: 56, Batch: 84,Loss: -0.548,Avg.Loss: -1.969,LR: 2.05E-04]Training epoch 56:  75%|███████▌  | 84/112 [00:01<00:00, 53.48it/s, Epoch: 56, Batch: 85,Loss: -1.033,Avg.Loss: -1.958,LR: 2.05E-04]Training epoch 56:  76%|███████▌  | 85/112 [00:01<00:00, 53.48it/s, Epoch: 56, Batch: 86,Loss: -2.292,Avg.Loss: -1.961,LR: 2.05E-04]Training epoch 56:  77%|███████▋  | 86/112 [00:01<00:00, 53.48it/s, Epoch: 56, Batch: 87,Loss: -2.563,Avg.Loss: -1.968,LR: 2.05E-04]Training epoch 56:  78%|███████▊  | 87/112 [00:01<00:00, 53.48it/s, Epoch: 56, Batch: 88,Loss: -2.211,Avg.Loss: -1.971,LR: 2.05E-04]Training epoch 56:  79%|███████▊  | 88/112 [00:01<00:00, 53.48it/s, Epoch: 56, Batch: 89,Loss: -2.552,Avg.Loss: -1.978,LR: 2.05E-04]Training epoch 56:  79%|███████▉  | 89/112 [00:01<00:00, 53.48it/s, Epoch: 56, Batch: 90,Loss: -2.909,Avg.Loss: -1.988,LR: 2.05E-04]Training epoch 56:  80%|████████  | 90/112 [00:01<00:00, 53.44it/s, Epoch: 56, Batch: 90,Loss: -2.909,Avg.Loss: -1.988,LR: 2.05E-04]Training epoch 56:  80%|████████  | 90/112 [00:01<00:00, 53.44it/s, Epoch: 56, Batch: 91,Loss: -2.154,Avg.Loss: -1.990,LR: 2.05E-04]Training epoch 56:  81%|████████▏ | 91/112 [00:01<00:00, 53.44it/s, Epoch: 56, Batch: 92,Loss: -0.134,Avg.Loss: -1.970,LR: 2.05E-04]Training epoch 56:  82%|████████▏ | 92/112 [00:01<00:00, 53.44it/s, Epoch: 56, Batch: 93,Loss: -1.307,Avg.Loss: -1.963,LR: 2.04E-04]Training epoch 56:  83%|████████▎ | 93/112 [00:01<00:00, 53.44it/s, Epoch: 56, Batch: 94,Loss: -2.857,Avg.Loss: -1.972,LR: 2.04E-04]Training epoch 56:  84%|████████▍ | 94/112 [00:01<00:00, 53.44it/s, Epoch: 56, Batch: 95,Loss: -2.292,Avg.Loss: -1.975,LR: 2.04E-04]Training epoch 56:  85%|████████▍ | 95/112 [00:01<00:00, 53.44it/s, Epoch: 56, Batch: 96,Loss: -1.282,Avg.Loss: -1.968,LR: 2.04E-04]Training epoch 56:  86%|████████▌ | 96/112 [00:01<00:00, 53.49it/s, Epoch: 56, Batch: 96,Loss: -1.282,Avg.Loss: -1.968,LR: 2.04E-04]Training epoch 56:  86%|████████▌ | 96/112 [00:01<00:00, 53.49it/s, Epoch: 56, Batch: 97,Loss: -1.838,Avg.Loss: -1.967,LR: 2.04E-04]Training epoch 56:  87%|████████▋ | 97/112 [00:01<00:00, 53.49it/s, Epoch: 56, Batch: 98,Loss: -2.599,Avg.Loss: -1.973,LR: 2.04E-04]Training epoch 56:  88%|████████▊ | 98/112 [00:01<00:00, 53.49it/s, Epoch: 56, Batch: 99,Loss: -2.476,Avg.Loss: -1.978,LR: 2.04E-04]Training epoch 56:  88%|████████▊ | 99/112 [00:01<00:00, 53.49it/s, Epoch: 56, Batch: 100,Loss: -1.470,Avg.Loss: -1.973,LR: 2.04E-04]Training epoch 56:  89%|████████▉ | 100/112 [00:01<00:00, 53.49it/s, Epoch: 56, Batch: 101,Loss: -1.702,Avg.Loss: -1.971,LR: 2.04E-04]Training epoch 56:  90%|█████████ | 101/112 [00:01<00:00, 53.49it/s, Epoch: 56, Batch: 102,Loss: -2.544,Avg.Loss: -1.976,LR: 2.04E-04]Training epoch 56:  91%|█████████ | 102/112 [00:01<00:00, 53.19it/s, Epoch: 56, Batch: 102,Loss: -2.544,Avg.Loss: -1.976,LR: 2.04E-04]Training epoch 56:  91%|█████████ | 102/112 [00:01<00:00, 53.19it/s, Epoch: 56, Batch: 103,Loss: -2.438,Avg.Loss: -1.981,LR: 2.04E-04]Training epoch 56:  92%|█████████▏| 103/112 [00:01<00:00, 53.19it/s, Epoch: 56, Batch: 104,Loss: -1.286,Avg.Loss: -1.974,LR: 2.04E-04]Training epoch 56:  93%|█████████▎| 104/112 [00:01<00:00, 53.19it/s, Epoch: 56, Batch: 105,Loss: -2.042,Avg.Loss: -1.975,LR: 2.04E-04]Training epoch 56:  94%|█████████▍| 105/112 [00:01<00:00, 53.19it/s, Epoch: 56, Batch: 106,Loss: -2.751,Avg.Loss: -1.982,LR: 2.04E-04]Training epoch 56:  95%|█████████▍| 106/112 [00:02<00:00, 53.19it/s, Epoch: 56, Batch: 107,Loss: -2.922,Avg.Loss: -1.991,LR: 2.03E-04]Training epoch 56:  96%|█████████▌| 107/112 [00:02<00:00, 53.19it/s, Epoch: 56, Batch: 108,Loss: -1.751,Avg.Loss: -1.989,LR: 2.03E-04]Training epoch 56:  96%|█████████▋| 108/112 [00:02<00:00, 53.11it/s, Epoch: 56, Batch: 108,Loss: -1.751,Avg.Loss: -1.989,LR: 2.03E-04]Training epoch 56:  96%|█████████▋| 108/112 [00:02<00:00, 53.11it/s, Epoch: 56, Batch: 109,Loss: -2.393,Avg.Loss: -1.992,LR: 2.03E-04]Training epoch 56:  97%|█████████▋| 109/112 [00:02<00:00, 53.11it/s, Epoch: 56, Batch: 110,Loss: -2.579,Avg.Loss: -1.998,LR: 2.03E-04]Training epoch 56:  98%|█████████▊| 110/112 [00:02<00:00, 53.11it/s, Epoch: 56, Batch: 111,Loss: -2.092,Avg.Loss: -1.998,LR: 2.03E-04]Training epoch 56:  99%|█████████▉| 111/112 [00:02<00:00, 53.11it/s, Epoch: 56, Batch: 112,Loss: -0.991,Avg.Loss: -1.989,LR: 2.03E-04]Training epoch 56: 100%|██████████| 112/112 [00:02<00:00, 53.21it/s, Epoch: 56, Batch: 112,Loss: -0.991,Avg.Loss: -1.989,LR: 2.03E-04]
Training epoch 57:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 57:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 57, Batch: 1,Loss: -1.815,Avg.Loss: -1.815,LR: 2.03E-04]Training epoch 57:   1%|          | 1/112 [00:00<00:04, 25.68it/s, Epoch: 57, Batch: 2,Loss: -2.230,Avg.Loss: -2.023,LR: 2.03E-04]Training epoch 57:   2%|▏         | 2/112 [00:00<00:02, 37.90it/s, Epoch: 57, Batch: 3,Loss: -2.589,Avg.Loss: -2.211,LR: 2.03E-04]Training epoch 57:   3%|▎         | 3/112 [00:00<00:02, 42.27it/s, Epoch: 57, Batch: 4,Loss: -1.659,Avg.Loss: -2.073,LR: 2.03E-04]Training epoch 57:   4%|▎         | 4/112 [00:00<00:02, 44.63it/s, Epoch: 57, Batch: 5,Loss: -1.690,Avg.Loss: -1.997,LR: 2.03E-04]Training epoch 57:   4%|▍         | 5/112 [00:00<00:02, 45.74it/s, Epoch: 57, Batch: 6,Loss: -3.064,Avg.Loss: -2.174,LR: 2.03E-04]Training epoch 57:   5%|▌         | 6/112 [00:00<00:01, 54.79it/s, Epoch: 57, Batch: 6,Loss: -3.064,Avg.Loss: -2.174,LR: 2.03E-04]Training epoch 57:   5%|▌         | 6/112 [00:00<00:01, 54.79it/s, Epoch: 57, Batch: 7,Loss: -1.877,Avg.Loss: -2.132,LR: 2.03E-04]Training epoch 57:   6%|▋         | 7/112 [00:00<00:01, 54.79it/s, Epoch: 57, Batch: 8,Loss: -1.499,Avg.Loss: -2.053,LR: 2.03E-04]Training epoch 57:   7%|▋         | 8/112 [00:00<00:01, 54.79it/s, Epoch: 57, Batch: 9,Loss: -2.270,Avg.Loss: -2.077,LR: 2.03E-04]Training epoch 57:   8%|▊         | 9/112 [00:00<00:01, 54.79it/s, Epoch: 57, Batch: 10,Loss: -2.696,Avg.Loss: -2.139,LR: 2.02E-04]Training epoch 57:   9%|▉         | 10/112 [00:00<00:01, 54.79it/s, Epoch: 57, Batch: 11,Loss: -2.684,Avg.Loss: -2.188,LR: 2.02E-04]Training epoch 57:  10%|▉         | 11/112 [00:00<00:01, 54.79it/s, Epoch: 57, Batch: 12,Loss: -1.984,Avg.Loss: -2.171,LR: 2.02E-04]Training epoch 57:  11%|█         | 12/112 [00:00<00:01, 53.92it/s, Epoch: 57, Batch: 12,Loss: -1.984,Avg.Loss: -2.171,LR: 2.02E-04]Training epoch 57:  11%|█         | 12/112 [00:00<00:01, 53.92it/s, Epoch: 57, Batch: 13,Loss: -1.582,Avg.Loss: -2.126,LR: 2.02E-04]Training epoch 57:  12%|█▏        | 13/112 [00:00<00:01, 53.92it/s, Epoch: 57, Batch: 14,Loss: -2.471,Avg.Loss: -2.151,LR: 2.02E-04]Training epoch 57:  12%|█▎        | 14/112 [00:00<00:01, 53.92it/s, Epoch: 57, Batch: 15,Loss: -2.343,Avg.Loss: -2.164,LR: 2.02E-04]Training epoch 57:  13%|█▎        | 15/112 [00:00<00:01, 53.92it/s, Epoch: 57, Batch: 16,Loss: -1.486,Avg.Loss: -2.121,LR: 2.02E-04]Training epoch 57:  14%|█▍        | 16/112 [00:00<00:01, 53.92it/s, Epoch: 57, Batch: 17,Loss: -1.873,Avg.Loss: -2.107,LR: 2.02E-04]Training epoch 57:  15%|█▌        | 17/112 [00:00<00:01, 53.92it/s, Epoch: 57, Batch: 18,Loss: -2.593,Avg.Loss: -2.134,LR: 2.02E-04]Training epoch 57:  16%|█▌        | 18/112 [00:00<00:01, 53.62it/s, Epoch: 57, Batch: 18,Loss: -2.593,Avg.Loss: -2.134,LR: 2.02E-04]Training epoch 57:  16%|█▌        | 18/112 [00:00<00:01, 53.62it/s, Epoch: 57, Batch: 19,Loss: -2.504,Avg.Loss: -2.153,LR: 2.02E-04]Training epoch 57:  17%|█▋        | 19/112 [00:00<00:01, 53.62it/s, Epoch: 57, Batch: 20,Loss: -1.600,Avg.Loss: -2.125,LR: 2.02E-04]Training epoch 57:  18%|█▊        | 20/112 [00:00<00:01, 53.62it/s, Epoch: 57, Batch: 21,Loss: -2.169,Avg.Loss: -2.127,LR: 2.02E-04]Training epoch 57:  19%|█▉        | 21/112 [00:00<00:01, 53.62it/s, Epoch: 57, Batch: 22,Loss: -2.540,Avg.Loss: -2.146,LR: 2.02E-04]Training epoch 57:  20%|█▉        | 22/112 [00:00<00:01, 53.62it/s, Epoch: 57, Batch: 23,Loss: -2.504,Avg.Loss: -2.162,LR: 2.02E-04]Training epoch 57:  21%|██        | 23/112 [00:00<00:01, 53.62it/s, Epoch: 57, Batch: 24,Loss: -2.000,Avg.Loss: -2.155,LR: 2.02E-04]Training epoch 57:  21%|██▏       | 24/112 [00:00<00:01, 51.75it/s, Epoch: 57, Batch: 24,Loss: -2.000,Avg.Loss: -2.155,LR: 2.02E-04]Training epoch 57:  21%|██▏       | 24/112 [00:00<00:01, 51.75it/s, Epoch: 57, Batch: 25,Loss: -2.021,Avg.Loss: -2.150,LR: 2.01E-04]Training epoch 57:  22%|██▏       | 25/112 [00:00<00:01, 51.75it/s, Epoch: 57, Batch: 26,Loss: -2.616,Avg.Loss: -2.168,LR: 2.01E-04]Training epoch 57:  23%|██▎       | 26/112 [00:00<00:01, 51.75it/s, Epoch: 57, Batch: 27,Loss: -2.341,Avg.Loss: -2.174,LR: 2.01E-04]Training epoch 57:  24%|██▍       | 27/112 [00:00<00:01, 51.75it/s, Epoch: 57, Batch: 28,Loss: -1.315,Avg.Loss: -2.143,LR: 2.01E-04]Training epoch 57:  25%|██▌       | 28/112 [00:00<00:01, 51.75it/s, Epoch: 57, Batch: 29,Loss: -1.788,Avg.Loss: -2.131,LR: 2.01E-04]Training epoch 57:  26%|██▌       | 29/112 [00:00<00:01, 51.75it/s, Epoch: 57, Batch: 30,Loss: -2.463,Avg.Loss: -2.142,LR: 2.01E-04]Training epoch 57:  27%|██▋       | 30/112 [00:00<00:01, 50.40it/s, Epoch: 57, Batch: 30,Loss: -2.463,Avg.Loss: -2.142,LR: 2.01E-04]Training epoch 57:  27%|██▋       | 30/112 [00:00<00:01, 50.40it/s, Epoch: 57, Batch: 31,Loss: -2.663,Avg.Loss: -2.159,LR: 2.01E-04]Training epoch 57:  28%|██▊       | 31/112 [00:00<00:01, 50.40it/s, Epoch: 57, Batch: 32,Loss: -2.054,Avg.Loss: -2.156,LR: 2.01E-04]Training epoch 57:  29%|██▊       | 32/112 [00:00<00:01, 50.40it/s, Epoch: 57, Batch: 33,Loss: -2.135,Avg.Loss: -2.155,LR: 2.01E-04]Training epoch 57:  29%|██▉       | 33/112 [00:00<00:01, 50.40it/s, Epoch: 57, Batch: 34,Loss: -2.697,Avg.Loss: -2.171,LR: 2.01E-04]Training epoch 57:  30%|███       | 34/112 [00:00<00:01, 50.40it/s, Epoch: 57, Batch: 35,Loss: -2.351,Avg.Loss: -2.176,LR: 2.01E-04]Training epoch 57:  31%|███▏      | 35/112 [00:00<00:01, 50.40it/s, Epoch: 57, Batch: 36,Loss: -0.966,Avg.Loss: -2.143,LR: 2.01E-04]Training epoch 57:  32%|███▏      | 36/112 [00:00<00:01, 50.88it/s, Epoch: 57, Batch: 36,Loss: -0.966,Avg.Loss: -2.143,LR: 2.01E-04]Training epoch 57:  32%|███▏      | 36/112 [00:00<00:01, 50.88it/s, Epoch: 57, Batch: 37,Loss: -1.703,Avg.Loss: -2.131,LR: 2.01E-04]Training epoch 57:  33%|███▎      | 37/112 [00:00<00:01, 50.88it/s, Epoch: 57, Batch: 38,Loss: -2.545,Avg.Loss: -2.142,LR: 2.01E-04]Training epoch 57:  34%|███▍      | 38/112 [00:00<00:01, 50.88it/s, Epoch: 57, Batch: 39,Loss: -2.781,Avg.Loss: -2.158,LR: 2.00E-04]Training epoch 57:  35%|███▍      | 39/112 [00:00<00:01, 50.88it/s, Epoch: 57, Batch: 40,Loss: -2.211,Avg.Loss: -2.159,LR: 2.00E-04]Training epoch 57:  36%|███▌      | 40/112 [00:00<00:01, 50.88it/s, Epoch: 57, Batch: 41,Loss: -2.081,Avg.Loss: -2.157,LR: 2.00E-04]Training epoch 57:  37%|███▋      | 41/112 [00:00<00:01, 50.88it/s, Epoch: 57, Batch: 42,Loss: -2.793,Avg.Loss: -2.173,LR: 2.00E-04]Training epoch 57:  38%|███▊      | 42/112 [00:00<00:01, 51.63it/s, Epoch: 57, Batch: 42,Loss: -2.793,Avg.Loss: -2.173,LR: 2.00E-04]Training epoch 57:  38%|███▊      | 42/112 [00:00<00:01, 51.63it/s, Epoch: 57, Batch: 43,Loss: -2.289,Avg.Loss: -2.175,LR: 2.00E-04]Training epoch 57:  38%|███▊      | 43/112 [00:00<00:01, 51.63it/s, Epoch: 57, Batch: 44,Loss: -1.534,Avg.Loss: -2.161,LR: 2.00E-04]Training epoch 57:  39%|███▉      | 44/112 [00:00<00:01, 51.63it/s, Epoch: 57, Batch: 45,Loss: -2.170,Avg.Loss: -2.161,LR: 2.00E-04]Training epoch 57:  40%|████      | 45/112 [00:00<00:01, 51.63it/s, Epoch: 57, Batch: 46,Loss: -2.640,Avg.Loss: -2.171,LR: 2.00E-04]Training epoch 57:  41%|████      | 46/112 [00:00<00:01, 51.63it/s, Epoch: 57, Batch: 47,Loss: -2.730,Avg.Loss: -2.183,LR: 2.00E-04]Training epoch 57:  42%|████▏     | 47/112 [00:00<00:01, 51.63it/s, Epoch: 57, Batch: 48,Loss: -1.791,Avg.Loss: -2.175,LR: 2.00E-04]Training epoch 57:  43%|████▎     | 48/112 [00:00<00:01, 52.17it/s, Epoch: 57, Batch: 48,Loss: -1.791,Avg.Loss: -2.175,LR: 2.00E-04]Training epoch 57:  43%|████▎     | 48/112 [00:00<00:01, 52.17it/s, Epoch: 57, Batch: 49,Loss: -1.861,Avg.Loss: -2.169,LR: 2.00E-04]Training epoch 57:  44%|████▍     | 49/112 [00:00<00:01, 52.17it/s, Epoch: 57, Batch: 50,Loss: -2.801,Avg.Loss: -2.181,LR: 2.00E-04]Training epoch 57:  45%|████▍     | 50/112 [00:00<00:01, 52.17it/s, Epoch: 57, Batch: 51,Loss: -2.381,Avg.Loss: -2.185,LR: 2.00E-04]Training epoch 57:  46%|████▌     | 51/112 [00:00<00:01, 52.17it/s, Epoch: 57, Batch: 52,Loss: -1.670,Avg.Loss: -2.175,LR: 2.00E-04]Training epoch 57:  46%|████▋     | 52/112 [00:01<00:01, 52.17it/s, Epoch: 57, Batch: 53,Loss: -2.014,Avg.Loss: -2.172,LR: 2.00E-04]Training epoch 57:  47%|████▋     | 53/112 [00:01<00:01, 52.17it/s, Epoch: 57, Batch: 54,Loss: -2.911,Avg.Loss: -2.186,LR: 1.99E-04]Training epoch 57:  48%|████▊     | 54/112 [00:01<00:01, 52.53it/s, Epoch: 57, Batch: 54,Loss: -2.911,Avg.Loss: -2.186,LR: 1.99E-04]Training epoch 57:  48%|████▊     | 54/112 [00:01<00:01, 52.53it/s, Epoch: 57, Batch: 55,Loss: -2.312,Avg.Loss: -2.188,LR: 1.99E-04]Training epoch 57:  49%|████▉     | 55/112 [00:01<00:01, 52.53it/s, Epoch: 57, Batch: 56,Loss: -1.783,Avg.Loss: -2.181,LR: 1.99E-04]Training epoch 57:  50%|█████     | 56/112 [00:01<00:01, 52.53it/s, Epoch: 57, Batch: 57,Loss: -1.798,Avg.Loss: -2.174,LR: 1.99E-04]Training epoch 57:  51%|█████     | 57/112 [00:01<00:01, 52.53it/s, Epoch: 57, Batch: 58,Loss: -2.677,Avg.Loss: -2.183,LR: 1.99E-04]Training epoch 57:  52%|█████▏    | 58/112 [00:01<00:01, 52.53it/s, Epoch: 57, Batch: 59,Loss: -2.766,Avg.Loss: -2.193,LR: 1.99E-04]Training epoch 57:  53%|█████▎    | 59/112 [00:01<00:01, 52.53it/s, Epoch: 57, Batch: 60,Loss: -2.031,Avg.Loss: -2.190,LR: 1.99E-04]Training epoch 57:  54%|█████▎    | 60/112 [00:01<00:00, 52.77it/s, Epoch: 57, Batch: 60,Loss: -2.031,Avg.Loss: -2.190,LR: 1.99E-04]Training epoch 57:  54%|█████▎    | 60/112 [00:01<00:00, 52.77it/s, Epoch: 57, Batch: 61,Loss: -1.864,Avg.Loss: -2.185,LR: 1.99E-04]Training epoch 57:  54%|█████▍    | 61/112 [00:01<00:00, 52.77it/s, Epoch: 57, Batch: 62,Loss: -2.558,Avg.Loss: -2.191,LR: 1.99E-04]Training epoch 57:  55%|█████▌    | 62/112 [00:01<00:00, 52.77it/s, Epoch: 57, Batch: 63,Loss: -2.242,Avg.Loss: -2.192,LR: 1.99E-04]Training epoch 57:  56%|█████▋    | 63/112 [00:01<00:00, 52.77it/s, Epoch: 57, Batch: 64,Loss: -0.979,Avg.Loss: -2.173,LR: 1.99E-04]Training epoch 57:  57%|█████▋    | 64/112 [00:01<00:00, 52.77it/s, Epoch: 57, Batch: 65,Loss: -1.826,Avg.Loss: -2.167,LR: 1.99E-04]Training epoch 57:  58%|█████▊    | 65/112 [00:01<00:00, 52.77it/s, Epoch: 57, Batch: 66,Loss: -2.747,Avg.Loss: -2.176,LR: 1.99E-04]Training epoch 57:  59%|█████▉    | 66/112 [00:01<00:00, 53.08it/s, Epoch: 57, Batch: 66,Loss: -2.747,Avg.Loss: -2.176,LR: 1.99E-04]Training epoch 57:  59%|█████▉    | 66/112 [00:01<00:00, 53.08it/s, Epoch: 57, Batch: 67,Loss: -2.342,Avg.Loss: -2.179,LR: 1.99E-04]Training epoch 57:  60%|█████▉    | 67/112 [00:01<00:00, 53.08it/s, Epoch: 57, Batch: 68,Loss: -1.991,Avg.Loss: -2.176,LR: 1.98E-04]Training epoch 57:  61%|██████    | 68/112 [00:01<00:00, 53.08it/s, Epoch: 57, Batch: 69,Loss: -2.304,Avg.Loss: -2.178,LR: 1.98E-04]Training epoch 57:  62%|██████▏   | 69/112 [00:01<00:00, 53.08it/s, Epoch: 57, Batch: 70,Loss: -2.862,Avg.Loss: -2.187,LR: 1.98E-04]Training epoch 57:  62%|██████▎   | 70/112 [00:01<00:00, 53.08it/s, Epoch: 57, Batch: 71,Loss: -2.685,Avg.Loss: -2.194,LR: 1.98E-04]Training epoch 57:  63%|██████▎   | 71/112 [00:01<00:00, 53.08it/s, Epoch: 57, Batch: 72,Loss: -1.896,Avg.Loss: -2.190,LR: 1.98E-04]Training epoch 57:  64%|██████▍   | 72/112 [00:01<00:00, 53.21it/s, Epoch: 57, Batch: 72,Loss: -1.896,Avg.Loss: -2.190,LR: 1.98E-04]Training epoch 57:  64%|██████▍   | 72/112 [00:01<00:00, 53.21it/s, Epoch: 57, Batch: 73,Loss: -2.117,Avg.Loss: -2.189,LR: 1.98E-04]Training epoch 57:  65%|██████▌   | 73/112 [00:01<00:00, 53.21it/s, Epoch: 57, Batch: 74,Loss: -2.810,Avg.Loss: -2.198,LR: 1.98E-04]Training epoch 57:  66%|██████▌   | 74/112 [00:01<00:00, 53.21it/s, Epoch: 57, Batch: 75,Loss: -2.258,Avg.Loss: -2.198,LR: 1.98E-04]Training epoch 57:  67%|██████▋   | 75/112 [00:01<00:00, 53.21it/s, Epoch: 57, Batch: 76,Loss: -1.602,Avg.Loss: -2.191,LR: 1.98E-04]Training epoch 57:  68%|██████▊   | 76/112 [00:01<00:00, 53.21it/s, Epoch: 57, Batch: 77,Loss: -2.041,Avg.Loss: -2.189,LR: 1.98E-04]Training epoch 57:  69%|██████▉   | 77/112 [00:01<00:00, 53.21it/s, Epoch: 57, Batch: 78,Loss: -2.702,Avg.Loss: -2.195,LR: 1.98E-04]Training epoch 57:  70%|██████▉   | 78/112 [00:01<00:00, 53.36it/s, Epoch: 57, Batch: 78,Loss: -2.702,Avg.Loss: -2.195,LR: 1.98E-04]Training epoch 57:  70%|██████▉   | 78/112 [00:01<00:00, 53.36it/s, Epoch: 57, Batch: 79,Loss: -2.391,Avg.Loss: -2.198,LR: 1.98E-04]Training epoch 57:  71%|███████   | 79/112 [00:01<00:00, 53.36it/s, Epoch: 57, Batch: 80,Loss: -1.911,Avg.Loss: -2.194,LR: 1.98E-04]Training epoch 57:  71%|███████▏  | 80/112 [00:01<00:00, 53.36it/s, Epoch: 57, Batch: 81,Loss: -1.694,Avg.Loss: -2.188,LR: 1.98E-04]Training epoch 57:  72%|███████▏  | 81/112 [00:01<00:00, 53.36it/s, Epoch: 57, Batch: 82,Loss: -2.716,Avg.Loss: -2.194,LR: 1.98E-04]Training epoch 57:  73%|███████▎  | 82/112 [00:01<00:00, 53.36it/s, Epoch: 57, Batch: 83,Loss: -2.468,Avg.Loss: -2.198,LR: 1.97E-04]Training epoch 57:  74%|███████▍  | 83/112 [00:01<00:00, 53.36it/s, Epoch: 57, Batch: 84,Loss: -1.640,Avg.Loss: -2.191,LR: 1.97E-04]Training epoch 57:  75%|███████▌  | 84/112 [00:01<00:00, 53.07it/s, Epoch: 57, Batch: 84,Loss: -1.640,Avg.Loss: -2.191,LR: 1.97E-04]Training epoch 57:  75%|███████▌  | 84/112 [00:01<00:00, 53.07it/s, Epoch: 57, Batch: 85,Loss: -2.021,Avg.Loss: -2.189,LR: 1.97E-04]Training epoch 57:  76%|███████▌  | 85/112 [00:01<00:00, 53.07it/s, Epoch: 57, Batch: 86,Loss: -2.657,Avg.Loss: -2.195,LR: 1.97E-04]Training epoch 57:  77%|███████▋  | 86/112 [00:01<00:00, 53.07it/s, Epoch: 57, Batch: 87,Loss: -2.796,Avg.Loss: -2.201,LR: 1.97E-04]Training epoch 57:  78%|███████▊  | 87/112 [00:01<00:00, 53.07it/s, Epoch: 57, Batch: 88,Loss: -1.976,Avg.Loss: -2.199,LR: 1.97E-04]Training epoch 57:  79%|███████▊  | 88/112 [00:01<00:00, 53.07it/s, Epoch: 57, Batch: 89,Loss: -1.732,Avg.Loss: -2.194,LR: 1.97E-04]Training epoch 57:  79%|███████▉  | 89/112 [00:01<00:00, 53.07it/s, Epoch: 57, Batch: 90,Loss: -2.872,Avg.Loss: -2.201,LR: 1.97E-04]Training epoch 57:  80%|████████  | 90/112 [00:01<00:00, 53.32it/s, Epoch: 57, Batch: 90,Loss: -2.872,Avg.Loss: -2.201,LR: 1.97E-04]Training epoch 57:  80%|████████  | 90/112 [00:01<00:00, 53.32it/s, Epoch: 57, Batch: 91,Loss: -2.441,Avg.Loss: -2.204,LR: 1.97E-04]Training epoch 57:  81%|████████▏ | 91/112 [00:01<00:00, 53.32it/s, Epoch: 57, Batch: 92,Loss: -2.087,Avg.Loss: -2.203,LR: 1.97E-04]Training epoch 57:  82%|████████▏ | 92/112 [00:01<00:00, 53.32it/s, Epoch: 57, Batch: 93,Loss: -1.844,Avg.Loss: -2.199,LR: 1.97E-04]Training epoch 57:  83%|████████▎ | 93/112 [00:01<00:00, 53.32it/s, Epoch: 57, Batch: 94,Loss: -2.694,Avg.Loss: -2.204,LR: 1.97E-04]Training epoch 57:  84%|████████▍ | 94/112 [00:01<00:00, 53.32it/s, Epoch: 57, Batch: 95,Loss: -2.365,Avg.Loss: -2.206,LR: 1.97E-04]Training epoch 57:  85%|████████▍ | 95/112 [00:01<00:00, 53.32it/s, Epoch: 57, Batch: 96,Loss: -2.156,Avg.Loss: -2.205,LR: 1.97E-04]Training epoch 57:  86%|████████▌ | 96/112 [00:01<00:00, 53.35it/s, Epoch: 57, Batch: 96,Loss: -2.156,Avg.Loss: -2.205,LR: 1.97E-04]Training epoch 57:  86%|████████▌ | 96/112 [00:01<00:00, 53.35it/s, Epoch: 57, Batch: 97,Loss: -2.037,Avg.Loss: -2.203,LR: 1.96E-04]Training epoch 57:  87%|████████▋ | 97/112 [00:01<00:00, 53.35it/s, Epoch: 57, Batch: 98,Loss: -2.839,Avg.Loss: -2.210,LR: 1.96E-04]Training epoch 57:  88%|████████▊ | 98/112 [00:01<00:00, 53.35it/s, Epoch: 57, Batch: 99,Loss: -2.254,Avg.Loss: -2.210,LR: 1.96E-04]Training epoch 57:  88%|████████▊ | 99/112 [00:01<00:00, 53.35it/s, Epoch: 57, Batch: 100,Loss: -1.656,Avg.Loss: -2.205,LR: 1.96E-04]Training epoch 57:  89%|████████▉ | 100/112 [00:01<00:00, 53.35it/s, Epoch: 57, Batch: 101,Loss: -1.404,Avg.Loss: -2.197,LR: 1.96E-04]Training epoch 57:  90%|█████████ | 101/112 [00:01<00:00, 53.35it/s, Epoch: 57, Batch: 102,Loss: -2.352,Avg.Loss: -2.198,LR: 1.96E-04]Training epoch 57:  91%|█████████ | 102/112 [00:01<00:00, 53.30it/s, Epoch: 57, Batch: 102,Loss: -2.352,Avg.Loss: -2.198,LR: 1.96E-04]Training epoch 57:  91%|█████████ | 102/112 [00:01<00:00, 53.30it/s, Epoch: 57, Batch: 103,Loss: -2.748,Avg.Loss: -2.204,LR: 1.96E-04]Training epoch 57:  92%|█████████▏| 103/112 [00:01<00:00, 53.30it/s, Epoch: 57, Batch: 104,Loss: -2.221,Avg.Loss: -2.204,LR: 1.96E-04]Training epoch 57:  93%|█████████▎| 104/112 [00:01<00:00, 53.30it/s, Epoch: 57, Batch: 105,Loss: -2.346,Avg.Loss: -2.205,LR: 1.96E-04]Training epoch 57:  94%|█████████▍| 105/112 [00:02<00:00, 53.30it/s, Epoch: 57, Batch: 106,Loss: -2.779,Avg.Loss: -2.211,LR: 1.96E-04]Training epoch 57:  95%|█████████▍| 106/112 [00:02<00:00, 53.30it/s, Epoch: 57, Batch: 107,Loss: -2.258,Avg.Loss: -2.211,LR: 1.96E-04]Training epoch 57:  96%|█████████▌| 107/112 [00:02<00:00, 53.30it/s, Epoch: 57, Batch: 108,Loss: -1.419,Avg.Loss: -2.204,LR: 1.96E-04]Training epoch 57:  96%|█████████▋| 108/112 [00:02<00:00, 53.67it/s, Epoch: 57, Batch: 108,Loss: -1.419,Avg.Loss: -2.204,LR: 1.96E-04]Training epoch 57:  96%|█████████▋| 108/112 [00:02<00:00, 53.67it/s, Epoch: 57, Batch: 109,Loss: -1.758,Avg.Loss: -2.200,LR: 1.96E-04]Training epoch 57:  97%|█████████▋| 109/112 [00:02<00:00, 53.67it/s, Epoch: 57, Batch: 110,Loss: -2.531,Avg.Loss: -2.203,LR: 1.96E-04]Training epoch 57:  98%|█████████▊| 110/112 [00:02<00:00, 53.67it/s, Epoch: 57, Batch: 111,Loss: -2.396,Avg.Loss: -2.204,LR: 1.96E-04]Training epoch 57:  99%|█████████▉| 111/112 [00:02<00:00, 53.67it/s, Epoch: 57, Batch: 112,Loss: -1.420,Avg.Loss: -2.197,LR: 1.95E-04]Training epoch 57: 100%|██████████| 112/112 [00:02<00:00, 52.80it/s, Epoch: 57, Batch: 112,Loss: -1.420,Avg.Loss: -2.197,LR: 1.95E-04]
Training epoch 58:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 58:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 58, Batch: 1,Loss: -1.953,Avg.Loss: -1.953,LR: 1.95E-04]Training epoch 58:   1%|          | 1/112 [00:00<00:04, 24.70it/s, Epoch: 58, Batch: 2,Loss: -2.588,Avg.Loss: -2.270,LR: 1.95E-04]Training epoch 58:   2%|▏         | 2/112 [00:00<00:03, 35.21it/s, Epoch: 58, Batch: 3,Loss: -2.141,Avg.Loss: -2.227,LR: 1.95E-04]Training epoch 58:   3%|▎         | 3/112 [00:00<00:02, 42.95it/s, Epoch: 58, Batch: 4,Loss: -2.043,Avg.Loss: -2.181,LR: 1.95E-04]Training epoch 58:   4%|▎         | 4/112 [00:00<00:02, 45.69it/s, Epoch: 58, Batch: 5,Loss: -2.074,Avg.Loss: -2.160,LR: 1.95E-04]Training epoch 58:   4%|▍         | 5/112 [00:00<00:02, 47.10it/s, Epoch: 58, Batch: 6,Loss: -2.577,Avg.Loss: -2.229,LR: 1.95E-04]Training epoch 58:   5%|▌         | 6/112 [00:00<00:01, 56.42it/s, Epoch: 58, Batch: 6,Loss: -2.577,Avg.Loss: -2.229,LR: 1.95E-04]Training epoch 58:   5%|▌         | 6/112 [00:00<00:01, 56.42it/s, Epoch: 58, Batch: 7,Loss: -2.799,Avg.Loss: -2.311,LR: 1.95E-04]Training epoch 58:   6%|▋         | 7/112 [00:00<00:01, 56.42it/s, Epoch: 58, Batch: 8,Loss: -1.868,Avg.Loss: -2.255,LR: 1.95E-04]Training epoch 58:   7%|▋         | 8/112 [00:00<00:01, 56.42it/s, Epoch: 58, Batch: 9,Loss: -2.450,Avg.Loss: -2.277,LR: 1.95E-04]Training epoch 58:   8%|▊         | 9/112 [00:00<00:01, 56.42it/s, Epoch: 58, Batch: 10,Loss: -2.175,Avg.Loss: -2.267,LR: 1.95E-04]Training epoch 58:   9%|▉         | 10/112 [00:00<00:01, 56.42it/s, Epoch: 58, Batch: 11,Loss: -2.605,Avg.Loss: -2.297,LR: 1.95E-04]Training epoch 58:  10%|▉         | 11/112 [00:00<00:01, 56.42it/s, Epoch: 58, Batch: 12,Loss: -1.605,Avg.Loss: -2.240,LR: 1.95E-04]Training epoch 58:  11%|█         | 12/112 [00:00<00:01, 55.14it/s, Epoch: 58, Batch: 12,Loss: -1.605,Avg.Loss: -2.240,LR: 1.95E-04]Training epoch 58:  11%|█         | 12/112 [00:00<00:01, 55.14it/s, Epoch: 58, Batch: 13,Loss: -2.245,Avg.Loss: -2.240,LR: 1.95E-04]Training epoch 58:  12%|█▏        | 13/112 [00:00<00:01, 55.14it/s, Epoch: 58, Batch: 14,Loss: -2.960,Avg.Loss: -2.292,LR: 1.95E-04]Training epoch 58:  12%|█▎        | 14/112 [00:00<00:01, 55.14it/s, Epoch: 58, Batch: 15,Loss: -2.384,Avg.Loss: -2.298,LR: 1.94E-04]Training epoch 58:  13%|█▎        | 15/112 [00:00<00:01, 55.14it/s, Epoch: 58, Batch: 16,Loss: -1.693,Avg.Loss: -2.260,LR: 1.94E-04]Training epoch 58:  14%|█▍        | 16/112 [00:00<00:01, 55.14it/s, Epoch: 58, Batch: 17,Loss: -1.971,Avg.Loss: -2.243,LR: 1.94E-04]Training epoch 58:  15%|█▌        | 17/112 [00:00<00:01, 55.14it/s, Epoch: 58, Batch: 18,Loss: -2.439,Avg.Loss: -2.254,LR: 1.94E-04]Training epoch 58:  16%|█▌        | 18/112 [00:00<00:01, 53.91it/s, Epoch: 58, Batch: 18,Loss: -2.439,Avg.Loss: -2.254,LR: 1.94E-04]Training epoch 58:  16%|█▌        | 18/112 [00:00<00:01, 53.91it/s, Epoch: 58, Batch: 19,Loss: -2.559,Avg.Loss: -2.270,LR: 1.94E-04]Training epoch 58:  17%|█▋        | 19/112 [00:00<00:01, 53.91it/s, Epoch: 58, Batch: 20,Loss: -1.746,Avg.Loss: -2.244,LR: 1.94E-04]Training epoch 58:  18%|█▊        | 20/112 [00:00<00:01, 53.91it/s, Epoch: 58, Batch: 21,Loss: -2.274,Avg.Loss: -2.245,LR: 1.94E-04]Training epoch 58:  19%|█▉        | 21/112 [00:00<00:01, 53.91it/s, Epoch: 58, Batch: 22,Loss: -2.962,Avg.Loss: -2.278,LR: 1.94E-04]Training epoch 58:  20%|█▉        | 22/112 [00:00<00:01, 53.91it/s, Epoch: 58, Batch: 23,Loss: -2.493,Avg.Loss: -2.287,LR: 1.94E-04]Training epoch 58:  21%|██        | 23/112 [00:00<00:01, 53.91it/s, Epoch: 58, Batch: 24,Loss: -2.279,Avg.Loss: -2.287,LR: 1.94E-04]Training epoch 58:  21%|██▏       | 24/112 [00:00<00:01, 53.20it/s, Epoch: 58, Batch: 24,Loss: -2.279,Avg.Loss: -2.287,LR: 1.94E-04]Training epoch 58:  21%|██▏       | 24/112 [00:00<00:01, 53.20it/s, Epoch: 58, Batch: 25,Loss: -2.024,Avg.Loss: -2.276,LR: 1.94E-04]Training epoch 58:  22%|██▏       | 25/112 [00:00<00:01, 53.20it/s, Epoch: 58, Batch: 26,Loss: -2.602,Avg.Loss: -2.289,LR: 1.94E-04]Training epoch 58:  23%|██▎       | 26/112 [00:00<00:01, 53.20it/s, Epoch: 58, Batch: 27,Loss: -2.324,Avg.Loss: -2.290,LR: 1.94E-04]Training epoch 58:  24%|██▍       | 27/112 [00:00<00:01, 53.20it/s, Epoch: 58, Batch: 28,Loss: -1.366,Avg.Loss: -2.257,LR: 1.94E-04]Training epoch 58:  25%|██▌       | 28/112 [00:00<00:01, 53.20it/s, Epoch: 58, Batch: 29,Loss: -2.003,Avg.Loss: -2.248,LR: 1.93E-04]Training epoch 58:  26%|██▌       | 29/112 [00:00<00:01, 53.20it/s, Epoch: 58, Batch: 30,Loss: -2.477,Avg.Loss: -2.256,LR: 1.93E-04]Training epoch 58:  27%|██▋       | 30/112 [00:00<00:01, 52.82it/s, Epoch: 58, Batch: 30,Loss: -2.477,Avg.Loss: -2.256,LR: 1.93E-04]Training epoch 58:  27%|██▋       | 30/112 [00:00<00:01, 52.82it/s, Epoch: 58, Batch: 31,Loss: -2.686,Avg.Loss: -2.270,LR: 1.93E-04]Training epoch 58:  28%|██▊       | 31/112 [00:00<00:01, 52.82it/s, Epoch: 58, Batch: 32,Loss: -1.926,Avg.Loss: -2.259,LR: 1.93E-04]Training epoch 58:  29%|██▊       | 32/112 [00:00<00:01, 52.82it/s, Epoch: 58, Batch: 33,Loss: -1.822,Avg.Loss: -2.246,LR: 1.93E-04]Training epoch 58:  29%|██▉       | 33/112 [00:00<00:01, 52.82it/s, Epoch: 58, Batch: 34,Loss: -2.921,Avg.Loss: -2.266,LR: 1.93E-04]Training epoch 58:  30%|███       | 34/112 [00:00<00:01, 52.82it/s, Epoch: 58, Batch: 35,Loss: -2.752,Avg.Loss: -2.280,LR: 1.93E-04]Training epoch 58:  31%|███▏      | 35/112 [00:00<00:01, 52.82it/s, Epoch: 58, Batch: 36,Loss: -1.901,Avg.Loss: -2.269,LR: 1.93E-04]Training epoch 58:  32%|███▏      | 36/112 [00:00<00:01, 53.03it/s, Epoch: 58, Batch: 36,Loss: -1.901,Avg.Loss: -2.269,LR: 1.93E-04]Training epoch 58:  32%|███▏      | 36/112 [00:00<00:01, 53.03it/s, Epoch: 58, Batch: 37,Loss: -2.119,Avg.Loss: -2.265,LR: 1.93E-04]Training epoch 58:  33%|███▎      | 37/112 [00:00<00:01, 53.03it/s, Epoch: 58, Batch: 38,Loss: -3.028,Avg.Loss: -2.285,LR: 1.93E-04]Training epoch 58:  34%|███▍      | 38/112 [00:00<00:01, 53.03it/s, Epoch: 58, Batch: 39,Loss: -2.797,Avg.Loss: -2.298,LR: 1.93E-04]Training epoch 58:  35%|███▍      | 39/112 [00:00<00:01, 53.03it/s, Epoch: 58, Batch: 40,Loss: -2.201,Avg.Loss: -2.296,LR: 1.93E-04]Training epoch 58:  36%|███▌      | 40/112 [00:00<00:01, 53.03it/s, Epoch: 58, Batch: 41,Loss: -2.241,Avg.Loss: -2.294,LR: 1.93E-04]Training epoch 58:  37%|███▋      | 41/112 [00:00<00:01, 53.03it/s, Epoch: 58, Batch: 42,Loss: -3.244,Avg.Loss: -2.317,LR: 1.93E-04]Training epoch 58:  38%|███▊      | 42/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 42,Loss: -3.244,Avg.Loss: -2.317,LR: 1.93E-04]Training epoch 58:  38%|███▊      | 42/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 43,Loss: -2.491,Avg.Loss: -2.321,LR: 1.93E-04]Training epoch 58:  38%|███▊      | 43/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 44,Loss: -1.763,Avg.Loss: -2.308,LR: 1.92E-04]Training epoch 58:  39%|███▉      | 44/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 45,Loss: -1.793,Avg.Loss: -2.297,LR: 1.92E-04]Training epoch 58:  40%|████      | 45/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 46,Loss: -3.073,Avg.Loss: -2.314,LR: 1.92E-04]Training epoch 58:  41%|████      | 46/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 47,Loss: -2.440,Avg.Loss: -2.317,LR: 1.92E-04]Training epoch 58:  42%|████▏     | 47/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 48,Loss: -2.128,Avg.Loss: -2.313,LR: 1.92E-04]Training epoch 58:  43%|████▎     | 48/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 48,Loss: -2.128,Avg.Loss: -2.313,LR: 1.92E-04]Training epoch 58:  43%|████▎     | 48/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 49,Loss: -2.490,Avg.Loss: -2.316,LR: 1.92E-04]Training epoch 58:  44%|████▍     | 49/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 50,Loss: -2.569,Avg.Loss: -2.321,LR: 1.92E-04]Training epoch 58:  45%|████▍     | 50/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 51,Loss: -2.504,Avg.Loss: -2.325,LR: 1.92E-04]Training epoch 58:  46%|████▌     | 51/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 52,Loss: -1.539,Avg.Loss: -2.310,LR: 1.92E-04]Training epoch 58:  46%|████▋     | 52/112 [00:00<00:01, 53.30it/s, Epoch: 58, Batch: 53,Loss: -1.815,Avg.Loss: -2.300,LR: 1.92E-04]Training epoch 58:  47%|████▋     | 53/112 [00:01<00:01, 53.30it/s, Epoch: 58, Batch: 54,Loss: -2.997,Avg.Loss: -2.313,LR: 1.92E-04]Training epoch 58:  48%|████▊     | 54/112 [00:01<00:01, 53.66it/s, Epoch: 58, Batch: 54,Loss: -2.997,Avg.Loss: -2.313,LR: 1.92E-04]Training epoch 58:  48%|████▊     | 54/112 [00:01<00:01, 53.66it/s, Epoch: 58, Batch: 55,Loss: -2.589,Avg.Loss: -2.318,LR: 1.92E-04]Training epoch 58:  49%|████▉     | 55/112 [00:01<00:01, 53.66it/s, Epoch: 58, Batch: 56,Loss: -1.887,Avg.Loss: -2.311,LR: 1.92E-04]Training epoch 58:  50%|█████     | 56/112 [00:01<00:01, 53.66it/s, Epoch: 58, Batch: 57,Loss: -2.218,Avg.Loss: -2.309,LR: 1.92E-04]Training epoch 58:  51%|█████     | 57/112 [00:01<00:01, 53.66it/s, Epoch: 58, Batch: 58,Loss: -2.714,Avg.Loss: -2.316,LR: 1.92E-04]Training epoch 58:  52%|█████▏    | 58/112 [00:01<00:01, 53.66it/s, Epoch: 58, Batch: 59,Loss: -2.658,Avg.Loss: -2.322,LR: 1.91E-04]Training epoch 58:  53%|█████▎    | 59/112 [00:01<00:00, 53.66it/s, Epoch: 58, Batch: 60,Loss: -1.174,Avg.Loss: -2.303,LR: 1.91E-04]Training epoch 58:  54%|█████▎    | 60/112 [00:01<00:00, 53.86it/s, Epoch: 58, Batch: 60,Loss: -1.174,Avg.Loss: -2.303,LR: 1.91E-04]Training epoch 58:  54%|█████▎    | 60/112 [00:01<00:00, 53.86it/s, Epoch: 58, Batch: 61,Loss: -1.585,Avg.Loss: -2.291,LR: 1.91E-04]Training epoch 58:  54%|█████▍    | 61/112 [00:01<00:00, 53.86it/s, Epoch: 58, Batch: 62,Loss: -2.415,Avg.Loss: -2.293,LR: 1.91E-04]Training epoch 58:  55%|█████▌    | 62/112 [00:01<00:00, 53.86it/s, Epoch: 58, Batch: 63,Loss: -2.300,Avg.Loss: -2.293,LR: 1.91E-04]Training epoch 58:  56%|█████▋    | 63/112 [00:01<00:00, 53.86it/s, Epoch: 58, Batch: 64,Loss: -2.004,Avg.Loss: -2.288,LR: 1.91E-04]Training epoch 58:  57%|█████▋    | 64/112 [00:01<00:00, 53.86it/s, Epoch: 58, Batch: 65,Loss: -1.961,Avg.Loss: -2.283,LR: 1.91E-04]Training epoch 58:  58%|█████▊    | 65/112 [00:01<00:00, 53.86it/s, Epoch: 58, Batch: 66,Loss: -2.442,Avg.Loss: -2.286,LR: 1.91E-04]Training epoch 58:  59%|█████▉    | 66/112 [00:01<00:00, 53.78it/s, Epoch: 58, Batch: 66,Loss: -2.442,Avg.Loss: -2.286,LR: 1.91E-04]Training epoch 58:  59%|█████▉    | 66/112 [00:01<00:00, 53.78it/s, Epoch: 58, Batch: 67,Loss: -2.532,Avg.Loss: -2.290,LR: 1.91E-04]Training epoch 58:  60%|█████▉    | 67/112 [00:01<00:00, 53.78it/s, Epoch: 58, Batch: 68,Loss: -1.770,Avg.Loss: -2.282,LR: 1.91E-04]Training epoch 58:  61%|██████    | 68/112 [00:01<00:00, 53.78it/s, Epoch: 58, Batch: 69,Loss: -1.916,Avg.Loss: -2.277,LR: 1.91E-04]Training epoch 58:  62%|██████▏   | 69/112 [00:01<00:00, 53.78it/s, Epoch: 58, Batch: 70,Loss: -2.944,Avg.Loss: -2.286,LR: 1.91E-04]Training epoch 58:  62%|██████▎   | 70/112 [00:01<00:00, 53.78it/s, Epoch: 58, Batch: 71,Loss: -2.049,Avg.Loss: -2.283,LR: 1.91E-04]Training epoch 58:  63%|██████▎   | 71/112 [00:01<00:00, 53.78it/s, Epoch: 58, Batch: 72,Loss: -1.678,Avg.Loss: -2.274,LR: 1.91E-04]Training epoch 58:  64%|██████▍   | 72/112 [00:01<00:00, 53.69it/s, Epoch: 58, Batch: 72,Loss: -1.678,Avg.Loss: -2.274,LR: 1.91E-04]Training epoch 58:  64%|██████▍   | 72/112 [00:01<00:00, 53.69it/s, Epoch: 58, Batch: 73,Loss: -1.889,Avg.Loss: -2.269,LR: 1.90E-04]Training epoch 58:  65%|██████▌   | 73/112 [00:01<00:00, 53.69it/s, Epoch: 58, Batch: 74,Loss: -2.749,Avg.Loss: -2.276,LR: 1.90E-04]Training epoch 58:  66%|██████▌   | 74/112 [00:01<00:00, 53.69it/s, Epoch: 58, Batch: 75,Loss: -2.472,Avg.Loss: -2.278,LR: 1.90E-04]Training epoch 58:  67%|██████▋   | 75/112 [00:01<00:00, 53.69it/s, Epoch: 58, Batch: 76,Loss: -1.433,Avg.Loss: -2.267,LR: 1.90E-04]Training epoch 58:  68%|██████▊   | 76/112 [00:01<00:00, 53.69it/s, Epoch: 58, Batch: 77,Loss: -1.894,Avg.Loss: -2.262,LR: 1.90E-04]Training epoch 58:  69%|██████▉   | 77/112 [00:01<00:00, 53.69it/s, Epoch: 58, Batch: 78,Loss: -2.686,Avg.Loss: -2.268,LR: 1.90E-04]Training epoch 58:  70%|██████▉   | 78/112 [00:01<00:00, 54.02it/s, Epoch: 58, Batch: 78,Loss: -2.686,Avg.Loss: -2.268,LR: 1.90E-04]Training epoch 58:  70%|██████▉   | 78/112 [00:01<00:00, 54.02it/s, Epoch: 58, Batch: 79,Loss: -2.337,Avg.Loss: -2.269,LR: 1.90E-04]Training epoch 58:  71%|███████   | 79/112 [00:01<00:00, 54.02it/s, Epoch: 58, Batch: 80,Loss: -1.797,Avg.Loss: -2.263,LR: 1.90E-04]Training epoch 58:  71%|███████▏  | 80/112 [00:01<00:00, 54.02it/s, Epoch: 58, Batch: 81,Loss: -2.221,Avg.Loss: -2.262,LR: 1.90E-04]Training epoch 58:  72%|███████▏  | 81/112 [00:01<00:00, 54.02it/s, Epoch: 58, Batch: 82,Loss: -2.740,Avg.Loss: -2.268,LR: 1.90E-04]Training epoch 58:  73%|███████▎  | 82/112 [00:01<00:00, 54.02it/s, Epoch: 58, Batch: 83,Loss: -2.180,Avg.Loss: -2.267,LR: 1.90E-04]Training epoch 58:  74%|███████▍  | 83/112 [00:01<00:00, 54.02it/s, Epoch: 58, Batch: 84,Loss: -2.204,Avg.Loss: -2.266,LR: 1.90E-04]Training epoch 58:  75%|███████▌  | 84/112 [00:01<00:00, 53.99it/s, Epoch: 58, Batch: 84,Loss: -2.204,Avg.Loss: -2.266,LR: 1.90E-04]Training epoch 58:  75%|███████▌  | 84/112 [00:01<00:00, 53.99it/s, Epoch: 58, Batch: 85,Loss: -2.101,Avg.Loss: -2.264,LR: 1.90E-04]Training epoch 58:  76%|███████▌  | 85/112 [00:01<00:00, 53.99it/s, Epoch: 58, Batch: 86,Loss: -2.582,Avg.Loss: -2.268,LR: 1.90E-04]Training epoch 58:  77%|███████▋  | 86/112 [00:01<00:00, 53.99it/s, Epoch: 58, Batch: 87,Loss: -2.519,Avg.Loss: -2.271,LR: 1.90E-04]Training epoch 58:  78%|███████▊  | 87/112 [00:01<00:00, 53.99it/s, Epoch: 58, Batch: 88,Loss: -2.319,Avg.Loss: -2.271,LR: 1.89E-04]Training epoch 58:  79%|███████▊  | 88/112 [00:01<00:00, 53.99it/s, Epoch: 58, Batch: 89,Loss: -2.306,Avg.Loss: -2.272,LR: 1.89E-04]Training epoch 58:  79%|███████▉  | 89/112 [00:01<00:00, 53.99it/s, Epoch: 58, Batch: 90,Loss: -3.057,Avg.Loss: -2.280,LR: 1.89E-04]Training epoch 58:  80%|████████  | 90/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 90,Loss: -3.057,Avg.Loss: -2.280,LR: 1.89E-04]Training epoch 58:  80%|████████  | 90/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 91,Loss: -2.208,Avg.Loss: -2.280,LR: 1.89E-04]Training epoch 58:  81%|████████▏ | 91/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 92,Loss: -1.661,Avg.Loss: -2.273,LR: 1.89E-04]Training epoch 58:  82%|████████▏ | 92/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 93,Loss: -2.072,Avg.Loss: -2.271,LR: 1.89E-04]Training epoch 58:  83%|████████▎ | 93/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 94,Loss: -2.728,Avg.Loss: -2.276,LR: 1.89E-04]Training epoch 58:  84%|████████▍ | 94/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 95,Loss: -2.368,Avg.Loss: -2.277,LR: 1.89E-04]Training epoch 58:  85%|████████▍ | 95/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 96,Loss: -1.653,Avg.Loss: -2.270,LR: 1.89E-04]Training epoch 58:  86%|████████▌ | 96/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 96,Loss: -1.653,Avg.Loss: -2.270,LR: 1.89E-04]Training epoch 58:  86%|████████▌ | 96/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 97,Loss: -1.839,Avg.Loss: -2.266,LR: 1.89E-04]Training epoch 58:  87%|████████▋ | 97/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 98,Loss: -2.752,Avg.Loss: -2.271,LR: 1.89E-04]Training epoch 58:  88%|████████▊ | 98/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 99,Loss: -2.751,Avg.Loss: -2.276,LR: 1.89E-04]Training epoch 58:  88%|████████▊ | 99/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 100,Loss: -1.964,Avg.Loss: -2.272,LR: 1.89E-04]Training epoch 58:  89%|████████▉ | 100/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 101,Loss: -1.954,Avg.Loss: -2.269,LR: 1.89E-04]Training epoch 58:  90%|█████████ | 101/112 [00:01<00:00, 53.95it/s, Epoch: 58, Batch: 102,Loss: -2.793,Avg.Loss: -2.274,LR: 1.89E-04]Training epoch 58:  91%|█████████ | 102/112 [00:01<00:00, 53.91it/s, Epoch: 58, Batch: 102,Loss: -2.793,Avg.Loss: -2.274,LR: 1.89E-04]Training epoch 58:  91%|█████████ | 102/112 [00:01<00:00, 53.91it/s, Epoch: 58, Batch: 103,Loss: -2.340,Avg.Loss: -2.275,LR: 1.88E-04]Training epoch 58:  92%|█████████▏| 103/112 [00:01<00:00, 53.91it/s, Epoch: 58, Batch: 104,Loss: -2.278,Avg.Loss: -2.275,LR: 1.88E-04]Training epoch 58:  93%|█████████▎| 104/112 [00:01<00:00, 53.91it/s, Epoch: 58, Batch: 105,Loss: -2.370,Avg.Loss: -2.276,LR: 1.88E-04]Training epoch 58:  94%|█████████▍| 105/112 [00:01<00:00, 53.91it/s, Epoch: 58, Batch: 106,Loss: -3.055,Avg.Loss: -2.283,LR: 1.88E-04]Training epoch 58:  95%|█████████▍| 106/112 [00:01<00:00, 53.91it/s, Epoch: 58, Batch: 107,Loss: -2.280,Avg.Loss: -2.283,LR: 1.88E-04]Training epoch 58:  96%|█████████▌| 107/112 [00:02<00:00, 53.91it/s, Epoch: 58, Batch: 108,Loss: -1.735,Avg.Loss: -2.278,LR: 1.88E-04]Training epoch 58:  96%|█████████▋| 108/112 [00:02<00:00, 54.16it/s, Epoch: 58, Batch: 108,Loss: -1.735,Avg.Loss: -2.278,LR: 1.88E-04]Training epoch 58:  96%|█████████▋| 108/112 [00:02<00:00, 54.16it/s, Epoch: 58, Batch: 109,Loss: -1.768,Avg.Loss: -2.274,LR: 1.88E-04]Training epoch 58:  97%|█████████▋| 109/112 [00:02<00:00, 54.16it/s, Epoch: 58, Batch: 110,Loss: -2.658,Avg.Loss: -2.277,LR: 1.88E-04]Training epoch 58:  98%|█████████▊| 110/112 [00:02<00:00, 54.16it/s, Epoch: 58, Batch: 111,Loss: -2.625,Avg.Loss: -2.280,LR: 1.88E-04]Training epoch 58:  99%|█████████▉| 111/112 [00:02<00:00, 54.16it/s, Epoch: 58, Batch: 112,Loss: -1.704,Avg.Loss: -2.275,LR: 1.88E-04]Training epoch 58: 100%|██████████| 112/112 [00:02<00:00, 53.76it/s, Epoch: 58, Batch: 112,Loss: -1.704,Avg.Loss: -2.275,LR: 1.88E-04]
Training epoch 59:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 59:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 59, Batch: 1,Loss: -2.196,Avg.Loss: -2.196,LR: 1.88E-04]Training epoch 59:   1%|          | 1/112 [00:00<00:03, 31.83it/s, Epoch: 59, Batch: 2,Loss: -2.287,Avg.Loss: -2.241,LR: 1.88E-04]Training epoch 59:   2%|▏         | 2/112 [00:00<00:02, 44.55it/s, Epoch: 59, Batch: 3,Loss: -1.234,Avg.Loss: -1.906,LR: 1.88E-04]Training epoch 59:   3%|▎         | 3/112 [00:00<00:02, 50.62it/s, Epoch: 59, Batch: 4,Loss: -0.495,Avg.Loss: -1.553,LR: 1.88E-04]Training epoch 59:   4%|▎         | 4/112 [00:00<00:02, 52.48it/s, Epoch: 59, Batch: 5,Loss: -1.578,Avg.Loss: -1.558,LR: 1.87E-04]Training epoch 59:   4%|▍         | 5/112 [00:00<00:01, 53.65it/s, Epoch: 59, Batch: 6,Loss: -2.274,Avg.Loss: -1.677,LR: 1.87E-04]Training epoch 59:   5%|▌         | 6/112 [00:00<00:01, 53.36it/s, Epoch: 59, Batch: 7,Loss: -2.387,Avg.Loss: -1.779,LR: 1.87E-04]Training epoch 59:   6%|▋         | 7/112 [00:00<00:01, 62.15it/s, Epoch: 59, Batch: 7,Loss: -2.387,Avg.Loss: -1.779,LR: 1.87E-04]Training epoch 59:   6%|▋         | 7/112 [00:00<00:01, 62.15it/s, Epoch: 59, Batch: 8,Loss: -1.842,Avg.Loss: -1.787,LR: 1.87E-04]Training epoch 59:   7%|▋         | 8/112 [00:00<00:01, 62.15it/s, Epoch: 59, Batch: 9,Loss: -1.491,Avg.Loss: -1.754,LR: 1.87E-04]Training epoch 59:   8%|▊         | 9/112 [00:00<00:01, 62.15it/s, Epoch: 59, Batch: 10,Loss: -1.407,Avg.Loss: -1.719,LR: 1.87E-04]Training epoch 59:   9%|▉         | 10/112 [00:00<00:01, 62.15it/s, Epoch: 59, Batch: 11,Loss: -1.670,Avg.Loss: -1.715,LR: 1.87E-04]Training epoch 59:  10%|▉         | 11/112 [00:00<00:01, 62.15it/s, Epoch: 59, Batch: 12,Loss: -2.584,Avg.Loss: -1.787,LR: 1.87E-04]Training epoch 59:  11%|█         | 12/112 [00:00<00:01, 62.15it/s, Epoch: 59, Batch: 13,Loss: -2.697,Avg.Loss: -1.857,LR: 1.87E-04]Training epoch 59:  12%|█▏        | 13/112 [00:00<00:01, 62.15it/s, Epoch: 59, Batch: 14,Loss: -2.561,Avg.Loss: -1.907,LR: 1.87E-04]Training epoch 59:  12%|█▎        | 14/112 [00:00<00:01, 56.47it/s, Epoch: 59, Batch: 14,Loss: -2.561,Avg.Loss: -1.907,LR: 1.87E-04]Training epoch 59:  12%|█▎        | 14/112 [00:00<00:01, 56.47it/s, Epoch: 59, Batch: 15,Loss: -2.162,Avg.Loss: -1.924,LR: 1.87E-04]Training epoch 59:  13%|█▎        | 15/112 [00:00<00:01, 56.47it/s, Epoch: 59, Batch: 16,Loss: -2.139,Avg.Loss: -1.938,LR: 1.87E-04]Training epoch 59:  14%|█▍        | 16/112 [00:00<00:01, 56.47it/s, Epoch: 59, Batch: 17,Loss: -2.459,Avg.Loss: -1.968,LR: 1.87E-04]Training epoch 59:  15%|█▌        | 17/112 [00:00<00:01, 56.47it/s, Epoch: 59, Batch: 18,Loss: -2.286,Avg.Loss: -1.986,LR: 1.87E-04]Training epoch 59:  16%|█▌        | 18/112 [00:00<00:01, 56.47it/s, Epoch: 59, Batch: 19,Loss: -2.825,Avg.Loss: -2.030,LR: 1.87E-04]Training epoch 59:  17%|█▋        | 19/112 [00:00<00:01, 56.47it/s, Epoch: 59, Batch: 20,Loss: -2.391,Avg.Loss: -2.048,LR: 1.86E-04]Training epoch 59:  18%|█▊        | 20/112 [00:00<00:01, 54.95it/s, Epoch: 59, Batch: 20,Loss: -2.391,Avg.Loss: -2.048,LR: 1.86E-04]Training epoch 59:  18%|█▊        | 20/112 [00:00<00:01, 54.95it/s, Epoch: 59, Batch: 21,Loss: -2.486,Avg.Loss: -2.069,LR: 1.86E-04]Training epoch 59:  19%|█▉        | 21/112 [00:00<00:01, 54.95it/s, Epoch: 59, Batch: 22,Loss: -2.151,Avg.Loss: -2.073,LR: 1.86E-04]Training epoch 59:  20%|█▉        | 22/112 [00:00<00:01, 54.95it/s, Epoch: 59, Batch: 23,Loss: -1.343,Avg.Loss: -2.041,LR: 1.86E-04]Training epoch 59:  21%|██        | 23/112 [00:00<00:01, 54.95it/s, Epoch: 59, Batch: 24,Loss: -2.265,Avg.Loss: -2.050,LR: 1.86E-04]Training epoch 59:  21%|██▏       | 24/112 [00:00<00:01, 54.95it/s, Epoch: 59, Batch: 25,Loss: -2.630,Avg.Loss: -2.074,LR: 1.86E-04]Training epoch 59:  22%|██▏       | 25/112 [00:00<00:01, 54.95it/s, Epoch: 59, Batch: 26,Loss: -2.572,Avg.Loss: -2.093,LR: 1.86E-04]Training epoch 59:  23%|██▎       | 26/112 [00:00<00:01, 53.42it/s, Epoch: 59, Batch: 26,Loss: -2.572,Avg.Loss: -2.093,LR: 1.86E-04]Training epoch 59:  23%|██▎       | 26/112 [00:00<00:01, 53.42it/s, Epoch: 59, Batch: 27,Loss: -2.019,Avg.Loss: -2.090,LR: 1.86E-04]Training epoch 59:  24%|██▍       | 27/112 [00:00<00:01, 53.42it/s, Epoch: 59, Batch: 28,Loss: -2.378,Avg.Loss: -2.100,LR: 1.86E-04]Training epoch 59:  25%|██▌       | 28/112 [00:00<00:01, 53.42it/s, Epoch: 59, Batch: 29,Loss: -2.536,Avg.Loss: -2.115,LR: 1.86E-04]Training epoch 59:  26%|██▌       | 29/112 [00:00<00:01, 53.42it/s, Epoch: 59, Batch: 30,Loss: -1.866,Avg.Loss: -2.107,LR: 1.86E-04]Training epoch 59:  27%|██▋       | 30/112 [00:00<00:01, 53.42it/s, Epoch: 59, Batch: 31,Loss: -1.884,Avg.Loss: -2.100,LR: 1.86E-04]Training epoch 59:  28%|██▊       | 31/112 [00:00<00:01, 53.42it/s, Epoch: 59, Batch: 32,Loss: -2.417,Avg.Loss: -2.110,LR: 1.86E-04]Training epoch 59:  29%|██▊       | 32/112 [00:00<00:01, 53.12it/s, Epoch: 59, Batch: 32,Loss: -2.417,Avg.Loss: -2.110,LR: 1.86E-04]Training epoch 59:  29%|██▊       | 32/112 [00:00<00:01, 53.12it/s, Epoch: 59, Batch: 33,Loss: -2.539,Avg.Loss: -2.123,LR: 1.86E-04]Training epoch 59:  29%|██▉       | 33/112 [00:00<00:01, 53.12it/s, Epoch: 59, Batch: 34,Loss: -2.836,Avg.Loss: -2.144,LR: 1.86E-04]Training epoch 59:  30%|███       | 34/112 [00:00<00:01, 53.12it/s, Epoch: 59, Batch: 35,Loss: -2.504,Avg.Loss: -2.154,LR: 1.85E-04]Training epoch 59:  31%|███▏      | 35/112 [00:00<00:01, 53.12it/s, Epoch: 59, Batch: 36,Loss: -2.420,Avg.Loss: -2.161,LR: 1.85E-04]Training epoch 59:  32%|███▏      | 36/112 [00:00<00:01, 53.12it/s, Epoch: 59, Batch: 37,Loss: -2.600,Avg.Loss: -2.173,LR: 1.85E-04]Training epoch 59:  33%|███▎      | 37/112 [00:00<00:01, 53.12it/s, Epoch: 59, Batch: 38,Loss: -2.304,Avg.Loss: -2.177,LR: 1.85E-04]Training epoch 59:  34%|███▍      | 38/112 [00:00<00:01, 53.25it/s, Epoch: 59, Batch: 38,Loss: -2.304,Avg.Loss: -2.177,LR: 1.85E-04]Training epoch 59:  34%|███▍      | 38/112 [00:00<00:01, 53.25it/s, Epoch: 59, Batch: 39,Loss: -2.556,Avg.Loss: -2.186,LR: 1.85E-04]Training epoch 59:  35%|███▍      | 39/112 [00:00<00:01, 53.25it/s, Epoch: 59, Batch: 40,Loss: -2.521,Avg.Loss: -2.195,LR: 1.85E-04]Training epoch 59:  36%|███▌      | 40/112 [00:00<00:01, 53.25it/s, Epoch: 59, Batch: 41,Loss: -2.378,Avg.Loss: -2.199,LR: 1.85E-04]Training epoch 59:  37%|███▋      | 41/112 [00:00<00:01, 53.25it/s, Epoch: 59, Batch: 42,Loss: -2.599,Avg.Loss: -2.209,LR: 1.85E-04]Training epoch 59:  38%|███▊      | 42/112 [00:00<00:01, 53.25it/s, Epoch: 59, Batch: 43,Loss: -2.917,Avg.Loss: -2.225,LR: 1.85E-04]Training epoch 59:  38%|███▊      | 43/112 [00:00<00:01, 53.25it/s, Epoch: 59, Batch: 44,Loss: -2.502,Avg.Loss: -2.232,LR: 1.85E-04]Training epoch 59:  39%|███▉      | 44/112 [00:00<00:01, 53.48it/s, Epoch: 59, Batch: 44,Loss: -2.502,Avg.Loss: -2.232,LR: 1.85E-04]Training epoch 59:  39%|███▉      | 44/112 [00:00<00:01, 53.48it/s, Epoch: 59, Batch: 45,Loss: -2.089,Avg.Loss: -2.228,LR: 1.85E-04]Training epoch 59:  40%|████      | 45/112 [00:00<00:01, 53.48it/s, Epoch: 59, Batch: 46,Loss: -1.934,Avg.Loss: -2.222,LR: 1.85E-04]Training epoch 59:  41%|████      | 46/112 [00:00<00:01, 53.48it/s, Epoch: 59, Batch: 47,Loss: -2.212,Avg.Loss: -2.222,LR: 1.85E-04]Training epoch 59:  42%|████▏     | 47/112 [00:00<00:01, 53.48it/s, Epoch: 59, Batch: 48,Loss: -2.266,Avg.Loss: -2.223,LR: 1.85E-04]Training epoch 59:  43%|████▎     | 48/112 [00:00<00:01, 53.48it/s, Epoch: 59, Batch: 49,Loss: -2.734,Avg.Loss: -2.233,LR: 1.85E-04]Training epoch 59:  44%|████▍     | 49/112 [00:00<00:01, 53.48it/s, Epoch: 59, Batch: 50,Loss: -2.502,Avg.Loss: -2.239,LR: 1.84E-04]Training epoch 59:  45%|████▍     | 50/112 [00:00<00:01, 53.47it/s, Epoch: 59, Batch: 50,Loss: -2.502,Avg.Loss: -2.239,LR: 1.84E-04]Training epoch 59:  45%|████▍     | 50/112 [00:00<00:01, 53.47it/s, Epoch: 59, Batch: 51,Loss: -2.747,Avg.Loss: -2.249,LR: 1.84E-04]Training epoch 59:  46%|████▌     | 51/112 [00:00<00:01, 53.47it/s, Epoch: 59, Batch: 52,Loss: -2.847,Avg.Loss: -2.260,LR: 1.84E-04]Training epoch 59:  46%|████▋     | 52/112 [00:00<00:01, 53.47it/s, Epoch: 59, Batch: 53,Loss: -2.730,Avg.Loss: -2.269,LR: 1.84E-04]Training epoch 59:  47%|████▋     | 53/112 [00:01<00:01, 53.47it/s, Epoch: 59, Batch: 54,Loss: -2.977,Avg.Loss: -2.282,LR: 1.84E-04]Training epoch 59:  48%|████▊     | 54/112 [00:01<00:01, 53.47it/s, Epoch: 59, Batch: 55,Loss: -2.869,Avg.Loss: -2.293,LR: 1.84E-04]Training epoch 59:  49%|████▉     | 55/112 [00:01<00:01, 53.47it/s, Epoch: 59, Batch: 56,Loss: -2.625,Avg.Loss: -2.299,LR: 1.84E-04]Training epoch 59:  50%|█████     | 56/112 [00:01<00:01, 53.31it/s, Epoch: 59, Batch: 56,Loss: -2.625,Avg.Loss: -2.299,LR: 1.84E-04]Training epoch 59:  50%|█████     | 56/112 [00:01<00:01, 53.31it/s, Epoch: 59, Batch: 57,Loss: -2.560,Avg.Loss: -2.303,LR: 1.84E-04]Training epoch 59:  51%|█████     | 57/112 [00:01<00:01, 53.31it/s, Epoch: 59, Batch: 58,Loss: -2.768,Avg.Loss: -2.311,LR: 1.84E-04]Training epoch 59:  52%|█████▏    | 58/112 [00:01<00:01, 53.31it/s, Epoch: 59, Batch: 59,Loss: -2.607,Avg.Loss: -2.316,LR: 1.84E-04]Training epoch 59:  53%|█████▎    | 59/112 [00:01<00:00, 53.31it/s, Epoch: 59, Batch: 60,Loss: -2.851,Avg.Loss: -2.325,LR: 1.84E-04]Training epoch 59:  54%|█████▎    | 60/112 [00:01<00:00, 53.31it/s, Epoch: 59, Batch: 61,Loss: -2.886,Avg.Loss: -2.334,LR: 1.84E-04]Training epoch 59:  54%|█████▍    | 61/112 [00:01<00:00, 53.31it/s, Epoch: 59, Batch: 62,Loss: -2.818,Avg.Loss: -2.342,LR: 1.84E-04]Training epoch 59:  55%|█████▌    | 62/112 [00:01<00:00, 53.26it/s, Epoch: 59, Batch: 62,Loss: -2.818,Avg.Loss: -2.342,LR: 1.84E-04]Training epoch 59:  55%|█████▌    | 62/112 [00:01<00:00, 53.26it/s, Epoch: 59, Batch: 63,Loss: -2.173,Avg.Loss: -2.339,LR: 1.84E-04]Training epoch 59:  56%|█████▋    | 63/112 [00:01<00:00, 53.26it/s, Epoch: 59, Batch: 64,Loss: -2.630,Avg.Loss: -2.344,LR: 1.83E-04]Training epoch 59:  57%|█████▋    | 64/112 [00:01<00:00, 53.26it/s, Epoch: 59, Batch: 65,Loss: -2.694,Avg.Loss: -2.349,LR: 1.83E-04]Training epoch 59:  58%|█████▊    | 65/112 [00:01<00:00, 53.26it/s, Epoch: 59, Batch: 66,Loss: -2.201,Avg.Loss: -2.347,LR: 1.83E-04]Training epoch 59:  59%|█████▉    | 66/112 [00:01<00:00, 53.26it/s, Epoch: 59, Batch: 67,Loss: -1.661,Avg.Loss: -2.337,LR: 1.83E-04]Training epoch 59:  60%|█████▉    | 67/112 [00:01<00:00, 53.26it/s, Epoch: 59, Batch: 68,Loss: -2.176,Avg.Loss: -2.335,LR: 1.83E-04]Training epoch 59:  61%|██████    | 68/112 [00:01<00:00, 53.48it/s, Epoch: 59, Batch: 68,Loss: -2.176,Avg.Loss: -2.335,LR: 1.83E-04]Training epoch 59:  61%|██████    | 68/112 [00:01<00:00, 53.48it/s, Epoch: 59, Batch: 69,Loss: -2.816,Avg.Loss: -2.341,LR: 1.83E-04]Training epoch 59:  62%|██████▏   | 69/112 [00:01<00:00, 53.48it/s, Epoch: 59, Batch: 70,Loss: -2.734,Avg.Loss: -2.347,LR: 1.83E-04]Training epoch 59:  62%|██████▎   | 70/112 [00:01<00:00, 53.48it/s, Epoch: 59, Batch: 71,Loss: -2.347,Avg.Loss: -2.347,LR: 1.83E-04]Training epoch 59:  63%|██████▎   | 71/112 [00:01<00:00, 53.48it/s, Epoch: 59, Batch: 72,Loss: -2.589,Avg.Loss: -2.350,LR: 1.83E-04]Training epoch 59:  64%|██████▍   | 72/112 [00:01<00:00, 53.48it/s, Epoch: 59, Batch: 73,Loss: -2.703,Avg.Loss: -2.355,LR: 1.83E-04]Training epoch 59:  65%|██████▌   | 73/112 [00:01<00:00, 53.48it/s, Epoch: 59, Batch: 74,Loss: -2.523,Avg.Loss: -2.358,LR: 1.83E-04]Training epoch 59:  66%|██████▌   | 74/112 [00:01<00:00, 53.60it/s, Epoch: 59, Batch: 74,Loss: -2.523,Avg.Loss: -2.358,LR: 1.83E-04]Training epoch 59:  66%|██████▌   | 74/112 [00:01<00:00, 53.60it/s, Epoch: 59, Batch: 75,Loss: -2.780,Avg.Loss: -2.363,LR: 1.83E-04]Training epoch 59:  67%|██████▋   | 75/112 [00:01<00:00, 53.60it/s, Epoch: 59, Batch: 76,Loss: -2.532,Avg.Loss: -2.365,LR: 1.83E-04]Training epoch 59:  68%|██████▊   | 76/112 [00:01<00:00, 53.60it/s, Epoch: 59, Batch: 77,Loss: -2.328,Avg.Loss: -2.365,LR: 1.83E-04]Training epoch 59:  69%|██████▉   | 77/112 [00:01<00:00, 53.60it/s, Epoch: 59, Batch: 78,Loss: -2.222,Avg.Loss: -2.363,LR: 1.83E-04]Training epoch 59:  70%|██████▉   | 78/112 [00:01<00:00, 53.60it/s, Epoch: 59, Batch: 79,Loss: -2.825,Avg.Loss: -2.369,LR: 1.82E-04]Training epoch 59:  71%|███████   | 79/112 [00:01<00:00, 53.60it/s, Epoch: 59, Batch: 80,Loss: -2.737,Avg.Loss: -2.374,LR: 1.82E-04]Training epoch 59:  71%|███████▏  | 80/112 [00:01<00:00, 53.91it/s, Epoch: 59, Batch: 80,Loss: -2.737,Avg.Loss: -2.374,LR: 1.82E-04]Training epoch 59:  71%|███████▏  | 80/112 [00:01<00:00, 53.91it/s, Epoch: 59, Batch: 81,Loss: -2.609,Avg.Loss: -2.376,LR: 1.82E-04]Training epoch 59:  72%|███████▏  | 81/112 [00:01<00:00, 53.91it/s, Epoch: 59, Batch: 82,Loss: -2.079,Avg.Loss: -2.373,LR: 1.82E-04]Training epoch 59:  73%|███████▎  | 82/112 [00:01<00:00, 53.91it/s, Epoch: 59, Batch: 83,Loss: -2.103,Avg.Loss: -2.370,LR: 1.82E-04]Training epoch 59:  74%|███████▍  | 83/112 [00:01<00:00, 53.91it/s, Epoch: 59, Batch: 84,Loss: -2.383,Avg.Loss: -2.370,LR: 1.82E-04]Training epoch 59:  75%|███████▌  | 84/112 [00:01<00:00, 53.91it/s, Epoch: 59, Batch: 85,Loss: -2.355,Avg.Loss: -2.370,LR: 1.82E-04]Training epoch 59:  76%|███████▌  | 85/112 [00:01<00:00, 53.91it/s, Epoch: 59, Batch: 86,Loss: -2.635,Avg.Loss: -2.373,LR: 1.82E-04]Training epoch 59:  77%|███████▋  | 86/112 [00:01<00:00, 54.11it/s, Epoch: 59, Batch: 86,Loss: -2.635,Avg.Loss: -2.373,LR: 1.82E-04]Training epoch 59:  77%|███████▋  | 86/112 [00:01<00:00, 54.11it/s, Epoch: 59, Batch: 87,Loss: -2.549,Avg.Loss: -2.375,LR: 1.82E-04]Training epoch 59:  78%|███████▊  | 87/112 [00:01<00:00, 54.11it/s, Epoch: 59, Batch: 88,Loss: -1.888,Avg.Loss: -2.369,LR: 1.82E-04]Training epoch 59:  79%|███████▊  | 88/112 [00:01<00:00, 54.11it/s, Epoch: 59, Batch: 89,Loss: -1.840,Avg.Loss: -2.363,LR: 1.82E-04]Training epoch 59:  79%|███████▉  | 89/112 [00:01<00:00, 54.11it/s, Epoch: 59, Batch: 90,Loss: -2.286,Avg.Loss: -2.362,LR: 1.82E-04]Training epoch 59:  80%|████████  | 90/112 [00:01<00:00, 54.11it/s, Epoch: 59, Batch: 91,Loss: -2.715,Avg.Loss: -2.366,LR: 1.82E-04]Training epoch 59:  81%|████████▏ | 91/112 [00:01<00:00, 54.11it/s, Epoch: 59, Batch: 92,Loss: -2.523,Avg.Loss: -2.368,LR: 1.82E-04]Training epoch 59:  82%|████████▏ | 92/112 [00:01<00:00, 54.32it/s, Epoch: 59, Batch: 92,Loss: -2.523,Avg.Loss: -2.368,LR: 1.82E-04]Training epoch 59:  82%|████████▏ | 92/112 [00:01<00:00, 54.32it/s, Epoch: 59, Batch: 93,Loss: -2.581,Avg.Loss: -2.370,LR: 1.82E-04]Training epoch 59:  83%|████████▎ | 93/112 [00:01<00:00, 54.32it/s, Epoch: 59, Batch: 94,Loss: -2.182,Avg.Loss: -2.368,LR: 1.81E-04]Training epoch 59:  84%|████████▍ | 94/112 [00:01<00:00, 54.32it/s, Epoch: 59, Batch: 95,Loss: -2.583,Avg.Loss: -2.370,LR: 1.81E-04]Training epoch 59:  85%|████████▍ | 95/112 [00:01<00:00, 54.32it/s, Epoch: 59, Batch: 96,Loss: -2.814,Avg.Loss: -2.375,LR: 1.81E-04]Training epoch 59:  86%|████████▌ | 96/112 [00:01<00:00, 54.32it/s, Epoch: 59, Batch: 97,Loss: -2.293,Avg.Loss: -2.374,LR: 1.81E-04]Training epoch 59:  87%|████████▋ | 97/112 [00:01<00:00, 54.32it/s, Epoch: 59, Batch: 98,Loss: -2.010,Avg.Loss: -2.371,LR: 1.81E-04]Training epoch 59:  88%|████████▊ | 98/112 [00:01<00:00, 53.95it/s, Epoch: 59, Batch: 98,Loss: -2.010,Avg.Loss: -2.371,LR: 1.81E-04]Training epoch 59:  88%|████████▊ | 98/112 [00:01<00:00, 53.95it/s, Epoch: 59, Batch: 99,Loss: -1.966,Avg.Loss: -2.366,LR: 1.81E-04]Training epoch 59:  88%|████████▊ | 99/112 [00:01<00:00, 53.95it/s, Epoch: 59, Batch: 100,Loss: -2.728,Avg.Loss: -2.370,LR: 1.81E-04]Training epoch 59:  89%|████████▉ | 100/112 [00:01<00:00, 53.95it/s, Epoch: 59, Batch: 101,Loss: -2.809,Avg.Loss: -2.374,LR: 1.81E-04]Training epoch 59:  90%|█████████ | 101/112 [00:01<00:00, 53.95it/s, Epoch: 59, Batch: 102,Loss: -2.525,Avg.Loss: -2.376,LR: 1.81E-04]Training epoch 59:  91%|█████████ | 102/112 [00:01<00:00, 53.95it/s, Epoch: 59, Batch: 103,Loss: -2.217,Avg.Loss: -2.374,LR: 1.81E-04]Training epoch 59:  92%|█████████▏| 103/112 [00:01<00:00, 53.95it/s, Epoch: 59, Batch: 104,Loss: -2.408,Avg.Loss: -2.375,LR: 1.81E-04]Training epoch 59:  93%|█████████▎| 104/112 [00:01<00:00, 53.84it/s, Epoch: 59, Batch: 104,Loss: -2.408,Avg.Loss: -2.375,LR: 1.81E-04]Training epoch 59:  93%|█████████▎| 104/112 [00:01<00:00, 53.84it/s, Epoch: 59, Batch: 105,Loss: -2.782,Avg.Loss: -2.379,LR: 1.81E-04]Training epoch 59:  94%|█████████▍| 105/112 [00:01<00:00, 53.84it/s, Epoch: 59, Batch: 106,Loss: -2.740,Avg.Loss: -2.382,LR: 1.81E-04]Training epoch 59:  95%|█████████▍| 106/112 [00:01<00:00, 53.84it/s, Epoch: 59, Batch: 107,Loss: -2.427,Avg.Loss: -2.382,LR: 1.81E-04]Training epoch 59:  96%|█████████▌| 107/112 [00:02<00:00, 53.84it/s, Epoch: 59, Batch: 108,Loss: -2.949,Avg.Loss: -2.388,LR: 1.81E-04]Training epoch 59:  96%|█████████▋| 108/112 [00:02<00:00, 53.84it/s, Epoch: 59, Batch: 109,Loss: -2.797,Avg.Loss: -2.391,LR: 1.80E-04]Training epoch 59:  97%|█████████▋| 109/112 [00:02<00:00, 53.84it/s, Epoch: 59, Batch: 110,Loss: -2.228,Avg.Loss: -2.390,LR: 1.80E-04]Training epoch 59:  98%|█████████▊| 110/112 [00:02<00:00, 53.31it/s, Epoch: 59, Batch: 110,Loss: -2.228,Avg.Loss: -2.390,LR: 1.80E-04]Training epoch 59:  98%|█████████▊| 110/112 [00:02<00:00, 53.31it/s, Epoch: 59, Batch: 111,Loss: -2.708,Avg.Loss: -2.393,LR: 1.80E-04]Training epoch 59:  99%|█████████▉| 111/112 [00:02<00:00, 53.31it/s, Epoch: 59, Batch: 112,Loss: -1.463,Avg.Loss: -2.384,LR: 1.80E-04]Training epoch 59: 100%|██████████| 112/112 [00:02<00:00, 53.73it/s, Epoch: 59, Batch: 112,Loss: -1.463,Avg.Loss: -2.384,LR: 1.80E-04]
Training epoch 60:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 60:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 60, Batch: 1,Loss: -2.480,Avg.Loss: -2.480,LR: 1.80E-04]Training epoch 60:   1%|          | 1/112 [00:00<00:04, 26.97it/s, Epoch: 60, Batch: 2,Loss: -2.842,Avg.Loss: -2.661,LR: 1.80E-04]Training epoch 60:   2%|▏         | 2/112 [00:00<00:02, 39.94it/s, Epoch: 60, Batch: 3,Loss: -2.485,Avg.Loss: -2.602,LR: 1.80E-04]Training epoch 60:   3%|▎         | 3/112 [00:00<00:02, 44.68it/s, Epoch: 60, Batch: 4,Loss: -2.624,Avg.Loss: -2.608,LR: 1.80E-04]Training epoch 60:   4%|▎         | 4/112 [00:00<00:02, 47.20it/s, Epoch: 60, Batch: 5,Loss: -2.995,Avg.Loss: -2.685,LR: 1.80E-04]Training epoch 60:   4%|▍         | 5/112 [00:00<00:02, 48.25it/s, Epoch: 60, Batch: 6,Loss: -2.500,Avg.Loss: -2.654,LR: 1.80E-04]Training epoch 60:   5%|▌         | 6/112 [00:00<00:01, 57.80it/s, Epoch: 60, Batch: 6,Loss: -2.500,Avg.Loss: -2.654,LR: 1.80E-04]Training epoch 60:   5%|▌         | 6/112 [00:00<00:01, 57.80it/s, Epoch: 60, Batch: 7,Loss: -2.478,Avg.Loss: -2.629,LR: 1.80E-04]Training epoch 60:   6%|▋         | 7/112 [00:00<00:01, 57.80it/s, Epoch: 60, Batch: 8,Loss: -2.697,Avg.Loss: -2.638,LR: 1.80E-04]Training epoch 60:   7%|▋         | 8/112 [00:00<00:01, 57.80it/s, Epoch: 60, Batch: 9,Loss: -2.599,Avg.Loss: -2.633,LR: 1.80E-04]Training epoch 60:   8%|▊         | 9/112 [00:00<00:01, 57.80it/s, Epoch: 60, Batch: 10,Loss: -2.644,Avg.Loss: -2.634,LR: 1.80E-04]Training epoch 60:   9%|▉         | 10/112 [00:00<00:01, 57.80it/s, Epoch: 60, Batch: 11,Loss: -3.133,Avg.Loss: -2.680,LR: 1.80E-04]Training epoch 60:  10%|▉         | 11/112 [00:00<00:01, 57.80it/s, Epoch: 60, Batch: 12,Loss: -2.521,Avg.Loss: -2.667,LR: 1.79E-04]Training epoch 60:  11%|█         | 12/112 [00:00<00:01, 55.16it/s, Epoch: 60, Batch: 12,Loss: -2.521,Avg.Loss: -2.667,LR: 1.79E-04]Training epoch 60:  11%|█         | 12/112 [00:00<00:01, 55.16it/s, Epoch: 60, Batch: 13,Loss: -1.937,Avg.Loss: -2.610,LR: 1.79E-04]Training epoch 60:  12%|█▏        | 13/112 [00:00<00:01, 55.16it/s, Epoch: 60, Batch: 14,Loss: -2.766,Avg.Loss: -2.621,LR: 1.79E-04]Training epoch 60:  12%|█▎        | 14/112 [00:00<00:01, 55.16it/s, Epoch: 60, Batch: 15,Loss: -2.490,Avg.Loss: -2.613,LR: 1.79E-04]Training epoch 60:  13%|█▎        | 15/112 [00:00<00:01, 55.16it/s, Epoch: 60, Batch: 16,Loss: -2.276,Avg.Loss: -2.592,LR: 1.79E-04]Training epoch 60:  14%|█▍        | 16/112 [00:00<00:01, 55.16it/s, Epoch: 60, Batch: 17,Loss: -2.568,Avg.Loss: -2.590,LR: 1.79E-04]Training epoch 60:  15%|█▌        | 17/112 [00:00<00:01, 55.16it/s, Epoch: 60, Batch: 18,Loss: -2.930,Avg.Loss: -2.609,LR: 1.79E-04]Training epoch 60:  16%|█▌        | 18/112 [00:00<00:01, 54.81it/s, Epoch: 60, Batch: 18,Loss: -2.930,Avg.Loss: -2.609,LR: 1.79E-04]Training epoch 60:  16%|█▌        | 18/112 [00:00<00:01, 54.81it/s, Epoch: 60, Batch: 19,Loss: -2.822,Avg.Loss: -2.620,LR: 1.79E-04]Training epoch 60:  17%|█▋        | 19/112 [00:00<00:01, 54.81it/s, Epoch: 60, Batch: 20,Loss: -2.657,Avg.Loss: -2.622,LR: 1.79E-04]Training epoch 60:  18%|█▊        | 20/112 [00:00<00:01, 54.81it/s, Epoch: 60, Batch: 21,Loss: -2.600,Avg.Loss: -2.621,LR: 1.79E-04]Training epoch 60:  19%|█▉        | 21/112 [00:00<00:01, 54.81it/s, Epoch: 60, Batch: 22,Loss: -2.773,Avg.Loss: -2.628,LR: 1.79E-04]Training epoch 60:  20%|█▉        | 22/112 [00:00<00:01, 54.81it/s, Epoch: 60, Batch: 23,Loss: -3.011,Avg.Loss: -2.645,LR: 1.79E-04]Training epoch 60:  21%|██        | 23/112 [00:00<00:01, 54.81it/s, Epoch: 60, Batch: 24,Loss: -2.983,Avg.Loss: -2.659,LR: 1.79E-04]Training epoch 60:  21%|██▏       | 24/112 [00:00<00:01, 54.11it/s, Epoch: 60, Batch: 24,Loss: -2.983,Avg.Loss: -2.659,LR: 1.79E-04]Training epoch 60:  21%|██▏       | 24/112 [00:00<00:01, 54.11it/s, Epoch: 60, Batch: 25,Loss: -2.207,Avg.Loss: -2.641,LR: 1.79E-04]Training epoch 60:  22%|██▏       | 25/112 [00:00<00:01, 54.11it/s, Epoch: 60, Batch: 26,Loss: -2.892,Avg.Loss: -2.650,LR: 1.79E-04]Training epoch 60:  23%|██▎       | 26/112 [00:00<00:01, 54.11it/s, Epoch: 60, Batch: 27,Loss: -3.012,Avg.Loss: -2.664,LR: 1.78E-04]Training epoch 60:  24%|██▍       | 27/112 [00:00<00:01, 54.11it/s, Epoch: 60, Batch: 28,Loss: -2.874,Avg.Loss: -2.671,LR: 1.78E-04]Training epoch 60:  25%|██▌       | 28/112 [00:00<00:01, 54.11it/s, Epoch: 60, Batch: 29,Loss: -3.131,Avg.Loss: -2.687,LR: 1.78E-04]Training epoch 60:  26%|██▌       | 29/112 [00:00<00:01, 54.11it/s, Epoch: 60, Batch: 30,Loss: -2.552,Avg.Loss: -2.683,LR: 1.78E-04]Training epoch 60:  27%|██▋       | 30/112 [00:00<00:01, 54.07it/s, Epoch: 60, Batch: 30,Loss: -2.552,Avg.Loss: -2.683,LR: 1.78E-04]Training epoch 60:  27%|██▋       | 30/112 [00:00<00:01, 54.07it/s, Epoch: 60, Batch: 31,Loss: -2.254,Avg.Loss: -2.669,LR: 1.78E-04]Training epoch 60:  28%|██▊       | 31/112 [00:00<00:01, 54.07it/s, Epoch: 60, Batch: 32,Loss: -2.651,Avg.Loss: -2.668,LR: 1.78E-04]Training epoch 60:  29%|██▊       | 32/112 [00:00<00:01, 54.07it/s, Epoch: 60, Batch: 33,Loss: -2.700,Avg.Loss: -2.669,LR: 1.78E-04]Training epoch 60:  29%|██▉       | 33/112 [00:00<00:01, 54.07it/s, Epoch: 60, Batch: 34,Loss: -2.920,Avg.Loss: -2.677,LR: 1.78E-04]Training epoch 60:  30%|███       | 34/112 [00:00<00:01, 54.07it/s, Epoch: 60, Batch: 35,Loss: -2.990,Avg.Loss: -2.686,LR: 1.78E-04]Training epoch 60:  31%|███▏      | 35/112 [00:00<00:01, 54.07it/s, Epoch: 60, Batch: 36,Loss: -2.586,Avg.Loss: -2.683,LR: 1.78E-04]Training epoch 60:  32%|███▏      | 36/112 [00:00<00:01, 53.88it/s, Epoch: 60, Batch: 36,Loss: -2.586,Avg.Loss: -2.683,LR: 1.78E-04]Training epoch 60:  32%|███▏      | 36/112 [00:00<00:01, 53.88it/s, Epoch: 60, Batch: 37,Loss: -2.559,Avg.Loss: -2.679,LR: 1.78E-04]Training epoch 60:  33%|███▎      | 37/112 [00:00<00:01, 53.88it/s, Epoch: 60, Batch: 38,Loss: -2.660,Avg.Loss: -2.679,LR: 1.78E-04]Training epoch 60:  34%|███▍      | 38/112 [00:00<00:01, 53.88it/s, Epoch: 60, Batch: 39,Loss: -3.228,Avg.Loss: -2.693,LR: 1.78E-04]Training epoch 60:  35%|███▍      | 39/112 [00:00<00:01, 53.88it/s, Epoch: 60, Batch: 40,Loss: -2.973,Avg.Loss: -2.700,LR: 1.78E-04]Training epoch 60:  36%|███▌      | 40/112 [00:00<00:01, 53.88it/s, Epoch: 60, Batch: 41,Loss: -3.169,Avg.Loss: -2.711,LR: 1.77E-04]Training epoch 60:  37%|███▋      | 41/112 [00:00<00:01, 53.88it/s, Epoch: 60, Batch: 42,Loss: -2.577,Avg.Loss: -2.708,LR: 1.77E-04]Training epoch 60:  38%|███▊      | 42/112 [00:00<00:01, 53.68it/s, Epoch: 60, Batch: 42,Loss: -2.577,Avg.Loss: -2.708,LR: 1.77E-04]Training epoch 60:  38%|███▊      | 42/112 [00:00<00:01, 53.68it/s, Epoch: 60, Batch: 43,Loss: -2.092,Avg.Loss: -2.694,LR: 1.77E-04]Training epoch 60:  38%|███▊      | 43/112 [00:00<00:01, 53.68it/s, Epoch: 60, Batch: 44,Loss: -2.211,Avg.Loss: -2.683,LR: 1.77E-04]Training epoch 60:  39%|███▉      | 44/112 [00:00<00:01, 53.68it/s, Epoch: 60, Batch: 45,Loss: -3.014,Avg.Loss: -2.690,LR: 1.77E-04]Training epoch 60:  40%|████      | 45/112 [00:00<00:01, 53.68it/s, Epoch: 60, Batch: 46,Loss: -2.782,Avg.Loss: -2.692,LR: 1.77E-04]Training epoch 60:  41%|████      | 46/112 [00:00<00:01, 53.68it/s, Epoch: 60, Batch: 47,Loss: -3.119,Avg.Loss: -2.701,LR: 1.77E-04]Training epoch 60:  42%|████▏     | 47/112 [00:00<00:01, 53.68it/s, Epoch: 60, Batch: 48,Loss: -2.671,Avg.Loss: -2.701,LR: 1.77E-04]Training epoch 60:  43%|████▎     | 48/112 [00:00<00:01, 50.42it/s, Epoch: 60, Batch: 48,Loss: -2.671,Avg.Loss: -2.701,LR: 1.77E-04]Training epoch 60:  43%|████▎     | 48/112 [00:00<00:01, 50.42it/s, Epoch: 60, Batch: 49,Loss: -2.329,Avg.Loss: -2.693,LR: 1.77E-04]Training epoch 60:  44%|████▍     | 49/112 [00:00<00:01, 50.42it/s, Epoch: 60, Batch: 50,Loss: -2.548,Avg.Loss: -2.690,LR: 1.77E-04]Training epoch 60:  45%|████▍     | 50/112 [00:00<00:01, 50.42it/s, Epoch: 60, Batch: 51,Loss: -2.900,Avg.Loss: -2.694,LR: 1.77E-04]Training epoch 60:  46%|████▌     | 51/112 [00:01<00:01, 50.42it/s, Epoch: 60, Batch: 52,Loss: -2.128,Avg.Loss: -2.683,LR: 1.77E-04]Training epoch 60:  46%|████▋     | 52/112 [00:01<00:01, 50.42it/s, Epoch: 60, Batch: 53,Loss: -2.787,Avg.Loss: -2.685,LR: 1.77E-04]Training epoch 60:  47%|████▋     | 53/112 [00:01<00:01, 50.42it/s, Epoch: 60, Batch: 54,Loss: -3.136,Avg.Loss: -2.694,LR: 1.77E-04]Training epoch 60:  48%|████▊     | 54/112 [00:01<00:01, 48.82it/s, Epoch: 60, Batch: 54,Loss: -3.136,Avg.Loss: -2.694,LR: 1.77E-04]Training epoch 60:  48%|████▊     | 54/112 [00:01<00:01, 48.82it/s, Epoch: 60, Batch: 55,Loss: -2.831,Avg.Loss: -2.696,LR: 1.77E-04]Training epoch 60:  49%|████▉     | 55/112 [00:01<00:01, 48.82it/s, Epoch: 60, Batch: 56,Loss: -2.877,Avg.Loss: -2.699,LR: 1.76E-04]Training epoch 60:  50%|█████     | 56/112 [00:01<00:01, 48.82it/s, Epoch: 60, Batch: 57,Loss: -2.920,Avg.Loss: -2.703,LR: 1.76E-04]Training epoch 60:  51%|█████     | 57/112 [00:01<00:01, 48.82it/s, Epoch: 60, Batch: 58,Loss: -1.850,Avg.Loss: -2.689,LR: 1.76E-04]Training epoch 60:  52%|█████▏    | 58/112 [00:01<00:01, 48.82it/s, Epoch: 60, Batch: 59,Loss: -2.704,Avg.Loss: -2.689,LR: 1.76E-04]Training epoch 60:  53%|█████▎    | 59/112 [00:01<00:01, 48.82it/s, Epoch: 60, Batch: 60,Loss: -2.987,Avg.Loss: -2.694,LR: 1.76E-04]Training epoch 60:  54%|█████▎    | 60/112 [00:01<00:01, 49.98it/s, Epoch: 60, Batch: 60,Loss: -2.987,Avg.Loss: -2.694,LR: 1.76E-04]Training epoch 60:  54%|█████▎    | 60/112 [00:01<00:01, 49.98it/s, Epoch: 60, Batch: 61,Loss: -2.874,Avg.Loss: -2.697,LR: 1.76E-04]Training epoch 60:  54%|█████▍    | 61/112 [00:01<00:01, 49.98it/s, Epoch: 60, Batch: 62,Loss: -2.921,Avg.Loss: -2.700,LR: 1.76E-04]Training epoch 60:  55%|█████▌    | 62/112 [00:01<00:01, 49.98it/s, Epoch: 60, Batch: 63,Loss: -2.562,Avg.Loss: -2.698,LR: 1.76E-04]Training epoch 60:  56%|█████▋    | 63/112 [00:01<00:00, 49.98it/s, Epoch: 60, Batch: 64,Loss: -2.273,Avg.Loss: -2.692,LR: 1.76E-04]Training epoch 60:  57%|█████▋    | 64/112 [00:01<00:00, 49.98it/s, Epoch: 60, Batch: 65,Loss: -2.810,Avg.Loss: -2.693,LR: 1.76E-04]Training epoch 60:  58%|█████▊    | 65/112 [00:01<00:00, 49.98it/s, Epoch: 60, Batch: 66,Loss: -2.786,Avg.Loss: -2.695,LR: 1.76E-04]Training epoch 60:  59%|█████▉    | 66/112 [00:01<00:00, 50.88it/s, Epoch: 60, Batch: 66,Loss: -2.786,Avg.Loss: -2.695,LR: 1.76E-04]Training epoch 60:  59%|█████▉    | 66/112 [00:01<00:00, 50.88it/s, Epoch: 60, Batch: 67,Loss: -2.863,Avg.Loss: -2.697,LR: 1.76E-04]Training epoch 60:  60%|█████▉    | 67/112 [00:01<00:00, 50.88it/s, Epoch: 60, Batch: 68,Loss: -3.187,Avg.Loss: -2.705,LR: 1.76E-04]Training epoch 60:  61%|██████    | 68/112 [00:01<00:00, 50.88it/s, Epoch: 60, Batch: 69,Loss: -2.623,Avg.Loss: -2.703,LR: 1.76E-04]Training epoch 60:  62%|██████▏   | 69/112 [00:01<00:00, 50.88it/s, Epoch: 60, Batch: 70,Loss: -2.598,Avg.Loss: -2.702,LR: 1.76E-04]Training epoch 60:  62%|██████▎   | 70/112 [00:01<00:00, 50.88it/s, Epoch: 60, Batch: 71,Loss: -3.008,Avg.Loss: -2.706,LR: 1.75E-04]Training epoch 60:  63%|██████▎   | 71/112 [00:01<00:00, 50.88it/s, Epoch: 60, Batch: 72,Loss: -2.340,Avg.Loss: -2.701,LR: 1.75E-04]Training epoch 60:  64%|██████▍   | 72/112 [00:01<00:00, 51.67it/s, Epoch: 60, Batch: 72,Loss: -2.340,Avg.Loss: -2.701,LR: 1.75E-04]Training epoch 60:  64%|██████▍   | 72/112 [00:01<00:00, 51.67it/s, Epoch: 60, Batch: 73,Loss: -2.565,Avg.Loss: -2.699,LR: 1.75E-04]Training epoch 60:  65%|██████▌   | 73/112 [00:01<00:00, 51.67it/s, Epoch: 60, Batch: 74,Loss: -3.256,Avg.Loss: -2.707,LR: 1.75E-04]Training epoch 60:  66%|██████▌   | 74/112 [00:01<00:00, 51.67it/s, Epoch: 60, Batch: 75,Loss: -2.751,Avg.Loss: -2.707,LR: 1.75E-04]Training epoch 60:  67%|██████▋   | 75/112 [00:01<00:00, 51.67it/s, Epoch: 60, Batch: 76,Loss: -2.398,Avg.Loss: -2.703,LR: 1.75E-04]Training epoch 60:  68%|██████▊   | 76/112 [00:01<00:00, 51.67it/s, Epoch: 60, Batch: 77,Loss: -2.767,Avg.Loss: -2.704,LR: 1.75E-04]Training epoch 60:  69%|██████▉   | 77/112 [00:01<00:00, 51.67it/s, Epoch: 60, Batch: 78,Loss: -2.819,Avg.Loss: -2.706,LR: 1.75E-04]Training epoch 60:  70%|██████▉   | 78/112 [00:01<00:00, 52.44it/s, Epoch: 60, Batch: 78,Loss: -2.819,Avg.Loss: -2.706,LR: 1.75E-04]Training epoch 60:  70%|██████▉   | 78/112 [00:01<00:00, 52.44it/s, Epoch: 60, Batch: 79,Loss: -2.352,Avg.Loss: -2.701,LR: 1.75E-04]Training epoch 60:  71%|███████   | 79/112 [00:01<00:00, 52.44it/s, Epoch: 60, Batch: 80,Loss: -2.829,Avg.Loss: -2.703,LR: 1.75E-04]Training epoch 60:  71%|███████▏  | 80/112 [00:01<00:00, 52.44it/s, Epoch: 60, Batch: 81,Loss: -2.990,Avg.Loss: -2.706,LR: 1.75E-04]Training epoch 60:  72%|███████▏  | 81/112 [00:01<00:00, 52.44it/s, Epoch: 60, Batch: 82,Loss: -2.650,Avg.Loss: -2.706,LR: 1.75E-04]Training epoch 60:  73%|███████▎  | 82/112 [00:01<00:00, 52.44it/s, Epoch: 60, Batch: 83,Loss: -2.971,Avg.Loss: -2.709,LR: 1.75E-04]Training epoch 60:  74%|███████▍  | 83/112 [00:01<00:00, 52.44it/s, Epoch: 60, Batch: 84,Loss: -2.504,Avg.Loss: -2.706,LR: 1.75E-04]Training epoch 60:  75%|███████▌  | 84/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 84,Loss: -2.504,Avg.Loss: -2.706,LR: 1.75E-04]Training epoch 60:  75%|███████▌  | 84/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 85,Loss: -2.548,Avg.Loss: -2.704,LR: 1.75E-04]Training epoch 60:  76%|███████▌  | 85/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 86,Loss: -2.845,Avg.Loss: -2.706,LR: 1.74E-04]Training epoch 60:  77%|███████▋  | 86/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 87,Loss: -3.046,Avg.Loss: -2.710,LR: 1.74E-04]Training epoch 60:  78%|███████▊  | 87/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 88,Loss: -2.721,Avg.Loss: -2.710,LR: 1.74E-04]Training epoch 60:  79%|███████▊  | 88/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 89,Loss: -3.128,Avg.Loss: -2.715,LR: 1.74E-04]Training epoch 60:  79%|███████▉  | 89/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 90,Loss: -2.958,Avg.Loss: -2.718,LR: 1.74E-04]Training epoch 60:  80%|████████  | 90/112 [00:01<00:00, 52.98it/s, Epoch: 60, Batch: 90,Loss: -2.958,Avg.Loss: -2.718,LR: 1.74E-04]Training epoch 60:  80%|████████  | 90/112 [00:01<00:00, 52.98it/s, Epoch: 60, Batch: 91,Loss: -2.508,Avg.Loss: -2.715,LR: 1.74E-04]Training epoch 60:  81%|████████▏ | 91/112 [00:01<00:00, 52.98it/s, Epoch: 60, Batch: 92,Loss: -2.977,Avg.Loss: -2.718,LR: 1.74E-04]Training epoch 60:  82%|████████▏ | 92/112 [00:01<00:00, 52.98it/s, Epoch: 60, Batch: 93,Loss: -2.714,Avg.Loss: -2.718,LR: 1.74E-04]Training epoch 60:  83%|████████▎ | 93/112 [00:01<00:00, 52.98it/s, Epoch: 60, Batch: 94,Loss: -2.572,Avg.Loss: -2.716,LR: 1.74E-04]Training epoch 60:  84%|████████▍ | 94/112 [00:01<00:00, 52.98it/s, Epoch: 60, Batch: 95,Loss: -2.939,Avg.Loss: -2.719,LR: 1.74E-04]Training epoch 60:  85%|████████▍ | 95/112 [00:01<00:00, 52.98it/s, Epoch: 60, Batch: 96,Loss: -3.158,Avg.Loss: -2.723,LR: 1.74E-04]Training epoch 60:  86%|████████▌ | 96/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 96,Loss: -3.158,Avg.Loss: -2.723,LR: 1.74E-04]Training epoch 60:  86%|████████▌ | 96/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 97,Loss: -2.001,Avg.Loss: -2.716,LR: 1.74E-04]Training epoch 60:  87%|████████▋ | 97/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 98,Loss: -2.779,Avg.Loss: -2.717,LR: 1.74E-04]Training epoch 60:  88%|████████▊ | 98/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 99,Loss: -3.184,Avg.Loss: -2.721,LR: 1.74E-04]Training epoch 60:  88%|████████▊ | 99/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 100,Loss: -2.926,Avg.Loss: -2.723,LR: 1.74E-04]Training epoch 60:  89%|████████▉ | 100/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 101,Loss: -2.821,Avg.Loss: -2.724,LR: 1.73E-04]Training epoch 60:  90%|█████████ | 101/112 [00:01<00:00, 52.80it/s, Epoch: 60, Batch: 102,Loss: -2.304,Avg.Loss: -2.720,LR: 1.73E-04]Training epoch 60:  91%|█████████ | 102/112 [00:01<00:00, 53.08it/s, Epoch: 60, Batch: 102,Loss: -2.304,Avg.Loss: -2.720,LR: 1.73E-04]Training epoch 60:  91%|█████████ | 102/112 [00:01<00:00, 53.08it/s, Epoch: 60, Batch: 103,Loss: -2.419,Avg.Loss: -2.717,LR: 1.73E-04]Training epoch 60:  92%|█████████▏| 103/112 [00:01<00:00, 53.08it/s, Epoch: 60, Batch: 104,Loss: -2.546,Avg.Loss: -2.716,LR: 1.73E-04]Training epoch 60:  93%|█████████▎| 104/112 [00:01<00:00, 53.08it/s, Epoch: 60, Batch: 105,Loss: -3.072,Avg.Loss: -2.719,LR: 1.73E-04]Training epoch 60:  94%|█████████▍| 105/112 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 106,Loss: -2.607,Avg.Loss: -2.718,LR: 1.73E-04]Training epoch 60:  95%|█████████▍| 106/112 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 107,Loss: -2.881,Avg.Loss: -2.719,LR: 1.73E-04]Training epoch 60:  96%|█████████▌| 107/112 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 108,Loss: -2.696,Avg.Loss: -2.719,LR: 1.73E-04]Training epoch 60:  96%|█████████▋| 108/112 [00:02<00:00, 53.39it/s, Epoch: 60, Batch: 108,Loss: -2.696,Avg.Loss: -2.719,LR: 1.73E-04]Training epoch 60:  96%|█████████▋| 108/112 [00:02<00:00, 53.39it/s, Epoch: 60, Batch: 109,Loss: -2.787,Avg.Loss: -2.720,LR: 1.73E-04]Training epoch 60:  97%|█████████▋| 109/112 [00:02<00:00, 53.39it/s, Epoch: 60, Batch: 110,Loss: -3.189,Avg.Loss: -2.724,LR: 1.73E-04]Training epoch 60:  98%|█████████▊| 110/112 [00:02<00:00, 53.39it/s, Epoch: 60, Batch: 111,Loss: -3.138,Avg.Loss: -2.728,LR: 1.73E-04]Training epoch 60:  99%|█████████▉| 111/112 [00:02<00:00, 53.39it/s, Epoch: 60, Batch: 112,Loss: -3.063,Avg.Loss: -2.731,LR: 1.73E-04]Training epoch 60: 100%|██████████| 112/112 [00:02<00:00, 52.62it/s, Epoch: 60, Batch: 112,Loss: -3.063,Avg.Loss: -2.731,LR: 1.73E-04]
Training epoch 61:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 61:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 61, Batch: 1,Loss: -3.042,Avg.Loss: -3.042,LR: 1.73E-04]Training epoch 61:   1%|          | 1/112 [00:00<00:04, 23.78it/s, Epoch: 61, Batch: 2,Loss: -2.820,Avg.Loss: -2.931,LR: 1.73E-04]Training epoch 61:   2%|▏         | 2/112 [00:00<00:03, 35.25it/s, Epoch: 61, Batch: 3,Loss: -2.479,Avg.Loss: -2.780,LR: 1.73E-04]Training epoch 61:   3%|▎         | 3/112 [00:00<00:02, 40.61it/s, Epoch: 61, Batch: 4,Loss: -2.994,Avg.Loss: -2.834,LR: 1.72E-04]Training epoch 61:   4%|▎         | 4/112 [00:00<00:02, 43.49it/s, Epoch: 61, Batch: 5,Loss: -2.961,Avg.Loss: -2.859,LR: 1.72E-04]Training epoch 61:   4%|▍         | 5/112 [00:00<00:02, 45.15it/s, Epoch: 61, Batch: 6,Loss: -2.653,Avg.Loss: -2.825,LR: 1.72E-04]Training epoch 61:   5%|▌         | 6/112 [00:00<00:01, 54.08it/s, Epoch: 61, Batch: 6,Loss: -2.653,Avg.Loss: -2.825,LR: 1.72E-04]Training epoch 61:   5%|▌         | 6/112 [00:00<00:01, 54.08it/s, Epoch: 61, Batch: 7,Loss: -2.707,Avg.Loss: -2.808,LR: 1.72E-04]Training epoch 61:   6%|▋         | 7/112 [00:00<00:01, 54.08it/s, Epoch: 61, Batch: 8,Loss: -3.065,Avg.Loss: -2.840,LR: 1.72E-04]Training epoch 61:   7%|▋         | 8/112 [00:00<00:01, 54.08it/s, Epoch: 61, Batch: 9,Loss: -2.565,Avg.Loss: -2.810,LR: 1.72E-04]Training epoch 61:   8%|▊         | 9/112 [00:00<00:01, 54.08it/s, Epoch: 61, Batch: 10,Loss: -2.940,Avg.Loss: -2.823,LR: 1.72E-04]Training epoch 61:   9%|▉         | 10/112 [00:00<00:01, 54.08it/s, Epoch: 61, Batch: 11,Loss: -2.781,Avg.Loss: -2.819,LR: 1.72E-04]Training epoch 61:  10%|▉         | 11/112 [00:00<00:01, 54.08it/s, Epoch: 61, Batch: 12,Loss: -2.916,Avg.Loss: -2.827,LR: 1.72E-04]Training epoch 61:  11%|█         | 12/112 [00:00<00:01, 52.77it/s, Epoch: 61, Batch: 12,Loss: -2.916,Avg.Loss: -2.827,LR: 1.72E-04]Training epoch 61:  11%|█         | 12/112 [00:00<00:01, 52.77it/s, Epoch: 61, Batch: 13,Loss: -2.585,Avg.Loss: -2.808,LR: 1.72E-04]Training epoch 61:  12%|█▏        | 13/112 [00:00<00:01, 52.77it/s, Epoch: 61, Batch: 14,Loss: -2.671,Avg.Loss: -2.799,LR: 1.72E-04]Training epoch 61:  12%|█▎        | 14/112 [00:00<00:01, 52.77it/s, Epoch: 61, Batch: 15,Loss: -2.464,Avg.Loss: -2.776,LR: 1.72E-04]Training epoch 61:  13%|█▎        | 15/112 [00:00<00:01, 52.77it/s, Epoch: 61, Batch: 16,Loss: -3.001,Avg.Loss: -2.790,LR: 1.72E-04]Training epoch 61:  14%|█▍        | 16/112 [00:00<00:01, 52.77it/s, Epoch: 61, Batch: 17,Loss: -3.051,Avg.Loss: -2.806,LR: 1.72E-04]Training epoch 61:  15%|█▌        | 17/112 [00:00<00:01, 52.77it/s, Epoch: 61, Batch: 18,Loss: -3.064,Avg.Loss: -2.820,LR: 1.72E-04]Training epoch 61:  16%|█▌        | 18/112 [00:00<00:01, 52.76it/s, Epoch: 61, Batch: 18,Loss: -3.064,Avg.Loss: -2.820,LR: 1.72E-04]Training epoch 61:  16%|█▌        | 18/112 [00:00<00:01, 52.76it/s, Epoch: 61, Batch: 19,Loss: -2.997,Avg.Loss: -2.829,LR: 1.71E-04]Training epoch 61:  17%|█▋        | 19/112 [00:00<00:01, 52.76it/s, Epoch: 61, Batch: 20,Loss: -2.680,Avg.Loss: -2.822,LR: 1.71E-04]Training epoch 61:  18%|█▊        | 20/112 [00:00<00:01, 52.76it/s, Epoch: 61, Batch: 21,Loss: -2.502,Avg.Loss: -2.807,LR: 1.71E-04]Training epoch 61:  19%|█▉        | 21/112 [00:00<00:01, 52.76it/s, Epoch: 61, Batch: 22,Loss: -2.939,Avg.Loss: -2.813,LR: 1.71E-04]Training epoch 61:  20%|█▉        | 22/112 [00:00<00:01, 52.76it/s, Epoch: 61, Batch: 23,Loss: -2.803,Avg.Loss: -2.812,LR: 1.71E-04]Training epoch 61:  21%|██        | 23/112 [00:00<00:01, 52.76it/s, Epoch: 61, Batch: 24,Loss: -2.727,Avg.Loss: -2.809,LR: 1.71E-04]Training epoch 61:  21%|██▏       | 24/112 [00:00<00:01, 51.94it/s, Epoch: 61, Batch: 24,Loss: -2.727,Avg.Loss: -2.809,LR: 1.71E-04]Training epoch 61:  21%|██▏       | 24/112 [00:00<00:01, 51.94it/s, Epoch: 61, Batch: 25,Loss: -2.960,Avg.Loss: -2.815,LR: 1.71E-04]Training epoch 61:  22%|██▏       | 25/112 [00:00<00:01, 51.94it/s, Epoch: 61, Batch: 26,Loss: -3.061,Avg.Loss: -2.824,LR: 1.71E-04]Training epoch 61:  23%|██▎       | 26/112 [00:00<00:01, 51.94it/s, Epoch: 61, Batch: 27,Loss: -2.824,Avg.Loss: -2.824,LR: 1.71E-04]Training epoch 61:  24%|██▍       | 27/112 [00:00<00:01, 51.94it/s, Epoch: 61, Batch: 28,Loss: -2.942,Avg.Loss: -2.828,LR: 1.71E-04]Training epoch 61:  25%|██▌       | 28/112 [00:00<00:01, 51.94it/s, Epoch: 61, Batch: 29,Loss: -2.813,Avg.Loss: -2.828,LR: 1.71E-04]Training epoch 61:  26%|██▌       | 29/112 [00:00<00:01, 51.94it/s, Epoch: 61, Batch: 30,Loss: -2.230,Avg.Loss: -2.808,LR: 1.71E-04]Training epoch 61:  27%|██▋       | 30/112 [00:00<00:01, 51.90it/s, Epoch: 61, Batch: 30,Loss: -2.230,Avg.Loss: -2.808,LR: 1.71E-04]Training epoch 61:  27%|██▋       | 30/112 [00:00<00:01, 51.90it/s, Epoch: 61, Batch: 31,Loss: -3.057,Avg.Loss: -2.816,LR: 1.71E-04]Training epoch 61:  28%|██▊       | 31/112 [00:00<00:01, 51.90it/s, Epoch: 61, Batch: 32,Loss: -2.589,Avg.Loss: -2.809,LR: 1.71E-04]Training epoch 61:  29%|██▊       | 32/112 [00:00<00:01, 51.90it/s, Epoch: 61, Batch: 33,Loss: -3.015,Avg.Loss: -2.815,LR: 1.71E-04]Training epoch 61:  29%|██▉       | 33/112 [00:00<00:01, 51.90it/s, Epoch: 61, Batch: 34,Loss: -3.226,Avg.Loss: -2.827,LR: 1.70E-04]Training epoch 61:  30%|███       | 34/112 [00:00<00:01, 51.90it/s, Epoch: 61, Batch: 35,Loss: -2.800,Avg.Loss: -2.826,LR: 1.70E-04]Training epoch 61:  31%|███▏      | 35/112 [00:00<00:01, 51.90it/s, Epoch: 61, Batch: 36,Loss: -2.402,Avg.Loss: -2.815,LR: 1.70E-04]Training epoch 61:  32%|███▏      | 36/112 [00:00<00:01, 52.18it/s, Epoch: 61, Batch: 36,Loss: -2.402,Avg.Loss: -2.815,LR: 1.70E-04]Training epoch 61:  32%|███▏      | 36/112 [00:00<00:01, 52.18it/s, Epoch: 61, Batch: 37,Loss: -2.452,Avg.Loss: -2.805,LR: 1.70E-04]Training epoch 61:  33%|███▎      | 37/112 [00:00<00:01, 52.18it/s, Epoch: 61, Batch: 38,Loss: -2.853,Avg.Loss: -2.806,LR: 1.70E-04]Training epoch 61:  34%|███▍      | 38/112 [00:00<00:01, 52.18it/s, Epoch: 61, Batch: 39,Loss: -2.322,Avg.Loss: -2.794,LR: 1.70E-04]Training epoch 61:  35%|███▍      | 39/112 [00:00<00:01, 52.18it/s, Epoch: 61, Batch: 40,Loss: -2.616,Avg.Loss: -2.789,LR: 1.70E-04]Training epoch 61:  36%|███▌      | 40/112 [00:00<00:01, 52.18it/s, Epoch: 61, Batch: 41,Loss: -3.001,Avg.Loss: -2.794,LR: 1.70E-04]Training epoch 61:  37%|███▋      | 41/112 [00:00<00:01, 52.18it/s, Epoch: 61, Batch: 42,Loss: -2.982,Avg.Loss: -2.799,LR: 1.70E-04]Training epoch 61:  38%|███▊      | 42/112 [00:00<00:01, 52.50it/s, Epoch: 61, Batch: 42,Loss: -2.982,Avg.Loss: -2.799,LR: 1.70E-04]Training epoch 61:  38%|███▊      | 42/112 [00:00<00:01, 52.50it/s, Epoch: 61, Batch: 43,Loss: -3.150,Avg.Loss: -2.807,LR: 1.70E-04]Training epoch 61:  38%|███▊      | 43/112 [00:00<00:01, 52.50it/s, Epoch: 61, Batch: 44,Loss: -2.985,Avg.Loss: -2.811,LR: 1.70E-04]Training epoch 61:  39%|███▉      | 44/112 [00:00<00:01, 52.50it/s, Epoch: 61, Batch: 45,Loss: -2.378,Avg.Loss: -2.802,LR: 1.70E-04]Training epoch 61:  40%|████      | 45/112 [00:00<00:01, 52.50it/s, Epoch: 61, Batch: 46,Loss: -2.907,Avg.Loss: -2.804,LR: 1.70E-04]Training epoch 61:  41%|████      | 46/112 [00:00<00:01, 52.50it/s, Epoch: 61, Batch: 47,Loss: -2.793,Avg.Loss: -2.804,LR: 1.70E-04]Training epoch 61:  42%|████▏     | 47/112 [00:00<00:01, 52.50it/s, Epoch: 61, Batch: 48,Loss: -1.758,Avg.Loss: -2.782,LR: 1.70E-04]Training epoch 61:  43%|████▎     | 48/112 [00:00<00:01, 52.94it/s, Epoch: 61, Batch: 48,Loss: -1.758,Avg.Loss: -2.782,LR: 1.70E-04]Training epoch 61:  43%|████▎     | 48/112 [00:00<00:01, 52.94it/s, Epoch: 61, Batch: 49,Loss: -2.407,Avg.Loss: -2.774,LR: 1.69E-04]Training epoch 61:  44%|████▍     | 49/112 [00:00<00:01, 52.94it/s, Epoch: 61, Batch: 50,Loss: -2.874,Avg.Loss: -2.776,LR: 1.69E-04]Training epoch 61:  45%|████▍     | 50/112 [00:00<00:01, 52.94it/s, Epoch: 61, Batch: 51,Loss: -2.490,Avg.Loss: -2.771,LR: 1.69E-04]Training epoch 61:  46%|████▌     | 51/112 [00:00<00:01, 52.94it/s, Epoch: 61, Batch: 52,Loss: -3.003,Avg.Loss: -2.775,LR: 1.69E-04]Training epoch 61:  46%|████▋     | 52/112 [00:01<00:01, 52.94it/s, Epoch: 61, Batch: 53,Loss: -3.537,Avg.Loss: -2.789,LR: 1.69E-04]Training epoch 61:  47%|████▋     | 53/112 [00:01<00:01, 52.94it/s, Epoch: 61, Batch: 54,Loss: -2.681,Avg.Loss: -2.787,LR: 1.69E-04]Training epoch 61:  48%|████▊     | 54/112 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 54,Loss: -2.681,Avg.Loss: -2.787,LR: 1.69E-04]Training epoch 61:  48%|████▊     | 54/112 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 55,Loss: -2.913,Avg.Loss: -2.790,LR: 1.69E-04]Training epoch 61:  49%|████▉     | 55/112 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 56,Loss: -3.070,Avg.Loss: -2.795,LR: 1.69E-04]Training epoch 61:  50%|█████     | 56/112 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 57,Loss: -2.395,Avg.Loss: -2.788,LR: 1.69E-04]Training epoch 61:  51%|█████     | 57/112 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 58,Loss: -2.085,Avg.Loss: -2.776,LR: 1.69E-04]Training epoch 61:  52%|█████▏    | 58/112 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 59,Loss: -2.464,Avg.Loss: -2.770,LR: 1.69E-04]Training epoch 61:  53%|█████▎    | 59/112 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 60,Loss: -2.402,Avg.Loss: -2.764,LR: 1.69E-04]Training epoch 61:  54%|█████▎    | 60/112 [00:01<00:00, 53.11it/s, Epoch: 61, Batch: 60,Loss: -2.402,Avg.Loss: -2.764,LR: 1.69E-04]Training epoch 61:  54%|█████▎    | 60/112 [00:01<00:00, 53.11it/s, Epoch: 61, Batch: 61,Loss: -2.121,Avg.Loss: -2.754,LR: 1.69E-04]Training epoch 61:  54%|█████▍    | 61/112 [00:01<00:00, 53.11it/s, Epoch: 61, Batch: 62,Loss: -2.318,Avg.Loss: -2.747,LR: 1.69E-04]Training epoch 61:  55%|█████▌    | 62/112 [00:01<00:00, 53.11it/s, Epoch: 61, Batch: 63,Loss: -2.632,Avg.Loss: -2.745,LR: 1.69E-04]Training epoch 61:  56%|█████▋    | 63/112 [00:01<00:00, 53.11it/s, Epoch: 61, Batch: 64,Loss: -2.133,Avg.Loss: -2.735,LR: 1.68E-04]Training epoch 61:  57%|█████▋    | 64/112 [00:01<00:00, 53.11it/s, Epoch: 61, Batch: 65,Loss: -2.958,Avg.Loss: -2.739,LR: 1.68E-04]Training epoch 61:  58%|█████▊    | 65/112 [00:01<00:00, 53.11it/s, Epoch: 61, Batch: 66,Loss: -2.571,Avg.Loss: -2.736,LR: 1.68E-04]Training epoch 61:  59%|█████▉    | 66/112 [00:01<00:00, 53.19it/s, Epoch: 61, Batch: 66,Loss: -2.571,Avg.Loss: -2.736,LR: 1.68E-04]Training epoch 61:  59%|█████▉    | 66/112 [00:01<00:00, 53.19it/s, Epoch: 61, Batch: 67,Loss: -2.989,Avg.Loss: -2.740,LR: 1.68E-04]Training epoch 61:  60%|█████▉    | 67/112 [00:01<00:00, 53.19it/s, Epoch: 61, Batch: 68,Loss: -2.954,Avg.Loss: -2.743,LR: 1.68E-04]Training epoch 61:  61%|██████    | 68/112 [00:01<00:00, 53.19it/s, Epoch: 61, Batch: 69,Loss: -2.849,Avg.Loss: -2.745,LR: 1.68E-04]Training epoch 61:  62%|██████▏   | 69/112 [00:01<00:00, 53.19it/s, Epoch: 61, Batch: 70,Loss: -2.597,Avg.Loss: -2.742,LR: 1.68E-04]Training epoch 61:  62%|██████▎   | 70/112 [00:01<00:00, 53.19it/s, Epoch: 61, Batch: 71,Loss: -2.074,Avg.Loss: -2.733,LR: 1.68E-04]Training epoch 61:  63%|██████▎   | 71/112 [00:01<00:00, 53.19it/s, Epoch: 61, Batch: 72,Loss: -3.333,Avg.Loss: -2.741,LR: 1.68E-04]Training epoch 61:  64%|██████▍   | 72/112 [00:01<00:00, 53.22it/s, Epoch: 61, Batch: 72,Loss: -3.333,Avg.Loss: -2.741,LR: 1.68E-04]Training epoch 61:  64%|██████▍   | 72/112 [00:01<00:00, 53.22it/s, Epoch: 61, Batch: 73,Loss: -2.145,Avg.Loss: -2.733,LR: 1.68E-04]Training epoch 61:  65%|██████▌   | 73/112 [00:01<00:00, 53.22it/s, Epoch: 61, Batch: 74,Loss: -1.544,Avg.Loss: -2.717,LR: 1.68E-04]Training epoch 61:  66%|██████▌   | 74/112 [00:01<00:00, 53.22it/s, Epoch: 61, Batch: 75,Loss: -1.809,Avg.Loss: -2.705,LR: 1.68E-04]Training epoch 61:  67%|██████▋   | 75/112 [00:01<00:00, 53.22it/s, Epoch: 61, Batch: 76,Loss: -2.608,Avg.Loss: -2.704,LR: 1.68E-04]Training epoch 61:  68%|██████▊   | 76/112 [00:01<00:00, 53.22it/s, Epoch: 61, Batch: 77,Loss: -2.396,Avg.Loss: -2.700,LR: 1.68E-04]Training epoch 61:  69%|██████▉   | 77/112 [00:01<00:00, 53.22it/s, Epoch: 61, Batch: 78,Loss: -0.934,Avg.Loss: -2.677,LR: 1.68E-04]Training epoch 61:  70%|██████▉   | 78/112 [00:01<00:00, 53.50it/s, Epoch: 61, Batch: 78,Loss: -0.934,Avg.Loss: -2.677,LR: 1.68E-04]Training epoch 61:  70%|██████▉   | 78/112 [00:01<00:00, 53.50it/s, Epoch: 61, Batch: 79,Loss: -0.919,Avg.Loss: -2.655,LR: 1.67E-04]Training epoch 61:  71%|███████   | 79/112 [00:01<00:00, 53.50it/s, Epoch: 61, Batch: 80,Loss: -2.116,Avg.Loss: -2.648,LR: 1.67E-04]Training epoch 61:  71%|███████▏  | 80/112 [00:01<00:00, 53.50it/s, Epoch: 61, Batch: 81,Loss: -2.979,Avg.Loss: -2.652,LR: 1.67E-04]Training epoch 61:  72%|███████▏  | 81/112 [00:01<00:00, 53.50it/s, Epoch: 61, Batch: 82,Loss: -2.446,Avg.Loss: -2.650,LR: 1.67E-04]Training epoch 61:  73%|███████▎  | 82/112 [00:01<00:00, 53.50it/s, Epoch: 61, Batch: 83,Loss: -2.867,Avg.Loss: -2.652,LR: 1.67E-04]Training epoch 61:  74%|███████▍  | 83/112 [00:01<00:00, 53.50it/s, Epoch: 61, Batch: 84,Loss: -3.174,Avg.Loss: -2.658,LR: 1.67E-04]Training epoch 61:  75%|███████▌  | 84/112 [00:01<00:00, 53.54it/s, Epoch: 61, Batch: 84,Loss: -3.174,Avg.Loss: -2.658,LR: 1.67E-04]Training epoch 61:  75%|███████▌  | 84/112 [00:01<00:00, 53.54it/s, Epoch: 61, Batch: 85,Loss: -2.857,Avg.Loss: -2.661,LR: 1.67E-04]Training epoch 61:  76%|███████▌  | 85/112 [00:01<00:00, 53.54it/s, Epoch: 61, Batch: 86,Loss: -3.282,Avg.Loss: -2.668,LR: 1.67E-04]Training epoch 61:  77%|███████▋  | 86/112 [00:01<00:00, 53.54it/s, Epoch: 61, Batch: 87,Loss: -2.772,Avg.Loss: -2.669,LR: 1.67E-04]Training epoch 61:  78%|███████▊  | 87/112 [00:01<00:00, 53.54it/s, Epoch: 61, Batch: 88,Loss: -2.957,Avg.Loss: -2.673,LR: 1.67E-04]Training epoch 61:  79%|███████▊  | 88/112 [00:01<00:00, 53.54it/s, Epoch: 61, Batch: 89,Loss: -2.924,Avg.Loss: -2.675,LR: 1.67E-04]Training epoch 61:  79%|███████▉  | 89/112 [00:01<00:00, 53.54it/s, Epoch: 61, Batch: 90,Loss: -3.159,Avg.Loss: -2.681,LR: 1.67E-04]Training epoch 61:  80%|████████  | 90/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 90,Loss: -3.159,Avg.Loss: -2.681,LR: 1.67E-04]Training epoch 61:  80%|████████  | 90/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 91,Loss: -3.064,Avg.Loss: -2.685,LR: 1.67E-04]Training epoch 61:  81%|████████▏ | 91/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 92,Loss: -3.052,Avg.Loss: -2.689,LR: 1.67E-04]Training epoch 61:  82%|████████▏ | 92/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 93,Loss: -3.196,Avg.Loss: -2.694,LR: 1.67E-04]Training epoch 61:  83%|████████▎ | 93/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 94,Loss: -3.149,Avg.Loss: -2.699,LR: 1.67E-04]Training epoch 61:  84%|████████▍ | 94/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 95,Loss: -2.917,Avg.Loss: -2.701,LR: 1.66E-04]Training epoch 61:  85%|████████▍ | 95/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 96,Loss: -3.115,Avg.Loss: -2.706,LR: 1.66E-04]Training epoch 61:  86%|████████▌ | 96/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 96,Loss: -3.115,Avg.Loss: -2.706,LR: 1.66E-04]Training epoch 61:  86%|████████▌ | 96/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 97,Loss: -3.244,Avg.Loss: -2.711,LR: 1.66E-04]Training epoch 61:  87%|████████▋ | 97/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 98,Loss: -3.170,Avg.Loss: -2.716,LR: 1.66E-04]Training epoch 61:  88%|████████▊ | 98/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 99,Loss: -2.930,Avg.Loss: -2.718,LR: 1.66E-04]Training epoch 61:  88%|████████▊ | 99/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 100,Loss: -2.916,Avg.Loss: -2.720,LR: 1.66E-04]Training epoch 61:  89%|████████▉ | 100/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 101,Loss: -3.114,Avg.Loss: -2.724,LR: 1.66E-04]Training epoch 61:  90%|█████████ | 101/112 [00:01<00:00, 53.53it/s, Epoch: 61, Batch: 102,Loss: -3.331,Avg.Loss: -2.730,LR: 1.66E-04]Training epoch 61:  91%|█████████ | 102/112 [00:01<00:00, 53.73it/s, Epoch: 61, Batch: 102,Loss: -3.331,Avg.Loss: -2.730,LR: 1.66E-04]Training epoch 61:  91%|█████████ | 102/112 [00:01<00:00, 53.73it/s, Epoch: 61, Batch: 103,Loss: -2.967,Avg.Loss: -2.732,LR: 1.66E-04]Training epoch 61:  92%|█████████▏| 103/112 [00:01<00:00, 53.73it/s, Epoch: 61, Batch: 104,Loss: -3.072,Avg.Loss: -2.736,LR: 1.66E-04]Training epoch 61:  93%|█████████▎| 104/112 [00:01<00:00, 53.73it/s, Epoch: 61, Batch: 105,Loss: -2.927,Avg.Loss: -2.737,LR: 1.66E-04]Training epoch 61:  94%|█████████▍| 105/112 [00:01<00:00, 53.73it/s, Epoch: 61, Batch: 106,Loss: -2.989,Avg.Loss: -2.740,LR: 1.66E-04]Training epoch 61:  95%|█████████▍| 106/112 [00:02<00:00, 53.73it/s, Epoch: 61, Batch: 107,Loss: -2.888,Avg.Loss: -2.741,LR: 1.66E-04]Training epoch 61:  96%|█████████▌| 107/112 [00:02<00:00, 53.73it/s, Epoch: 61, Batch: 108,Loss: -3.008,Avg.Loss: -2.744,LR: 1.66E-04]Training epoch 61:  96%|█████████▋| 108/112 [00:02<00:00, 53.92it/s, Epoch: 61, Batch: 108,Loss: -3.008,Avg.Loss: -2.744,LR: 1.66E-04]Training epoch 61:  96%|█████████▋| 108/112 [00:02<00:00, 53.92it/s, Epoch: 61, Batch: 109,Loss: -3.129,Avg.Loss: -2.747,LR: 1.66E-04]Training epoch 61:  97%|█████████▋| 109/112 [00:02<00:00, 53.92it/s, Epoch: 61, Batch: 110,Loss: -3.212,Avg.Loss: -2.751,LR: 1.65E-04]Training epoch 61:  98%|█████████▊| 110/112 [00:02<00:00, 53.92it/s, Epoch: 61, Batch: 111,Loss: -2.872,Avg.Loss: -2.752,LR: 1.65E-04]Training epoch 61:  99%|█████████▉| 111/112 [00:02<00:00, 53.92it/s, Epoch: 61, Batch: 112,Loss: -3.714,Avg.Loss: -2.761,LR: 1.65E-04]Training epoch 61: 100%|██████████| 112/112 [00:02<00:00, 53.15it/s, Epoch: 61, Batch: 112,Loss: -3.714,Avg.Loss: -2.761,LR: 1.65E-04]
Training epoch 62:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 62:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 62, Batch: 1,Loss: -3.269,Avg.Loss: -3.269,LR: 1.65E-04]Training epoch 62:   1%|          | 1/112 [00:00<00:04, 24.71it/s, Epoch: 62, Batch: 2,Loss: -3.150,Avg.Loss: -3.210,LR: 1.65E-04]Training epoch 62:   2%|▏         | 2/112 [00:00<00:03, 34.42it/s, Epoch: 62, Batch: 3,Loss: -3.142,Avg.Loss: -3.187,LR: 1.65E-04]Training epoch 62:   3%|▎         | 3/112 [00:00<00:02, 40.11it/s, Epoch: 62, Batch: 4,Loss: -2.601,Avg.Loss: -3.041,LR: 1.65E-04]Training epoch 62:   4%|▎         | 4/112 [00:00<00:02, 42.85it/s, Epoch: 62, Batch: 5,Loss: -3.094,Avg.Loss: -3.051,LR: 1.65E-04]Training epoch 62:   4%|▍         | 5/112 [00:00<00:02, 44.61it/s, Epoch: 62, Batch: 6,Loss: -3.067,Avg.Loss: -3.054,LR: 1.65E-04]Training epoch 62:   5%|▌         | 6/112 [00:00<00:01, 53.45it/s, Epoch: 62, Batch: 6,Loss: -3.067,Avg.Loss: -3.054,LR: 1.65E-04]Training epoch 62:   5%|▌         | 6/112 [00:00<00:01, 53.45it/s, Epoch: 62, Batch: 7,Loss: -3.142,Avg.Loss: -3.067,LR: 1.65E-04]Training epoch 62:   6%|▋         | 7/112 [00:00<00:01, 53.45it/s, Epoch: 62, Batch: 8,Loss: -3.065,Avg.Loss: -3.066,LR: 1.65E-04]Training epoch 62:   7%|▋         | 8/112 [00:00<00:01, 53.45it/s, Epoch: 62, Batch: 9,Loss: -3.128,Avg.Loss: -3.073,LR: 1.65E-04]Training epoch 62:   8%|▊         | 9/112 [00:00<00:01, 53.45it/s, Epoch: 62, Batch: 10,Loss: -3.097,Avg.Loss: -3.076,LR: 1.65E-04]Training epoch 62:   9%|▉         | 10/112 [00:00<00:01, 53.45it/s, Epoch: 62, Batch: 11,Loss: -3.205,Avg.Loss: -3.087,LR: 1.65E-04]Training epoch 62:  10%|▉         | 11/112 [00:00<00:01, 53.45it/s, Epoch: 62, Batch: 12,Loss: -3.761,Avg.Loss: -3.143,LR: 1.65E-04]Training epoch 62:  11%|█         | 12/112 [00:00<00:01, 53.41it/s, Epoch: 62, Batch: 12,Loss: -3.761,Avg.Loss: -3.143,LR: 1.65E-04]Training epoch 62:  11%|█         | 12/112 [00:00<00:01, 53.41it/s, Epoch: 62, Batch: 13,Loss: -3.025,Avg.Loss: -3.134,LR: 1.64E-04]Training epoch 62:  12%|█▏        | 13/112 [00:00<00:01, 53.41it/s, Epoch: 62, Batch: 14,Loss: -3.124,Avg.Loss: -3.134,LR: 1.64E-04]Training epoch 62:  12%|█▎        | 14/112 [00:00<00:01, 53.41it/s, Epoch: 62, Batch: 15,Loss: -3.374,Avg.Loss: -3.150,LR: 1.64E-04]Training epoch 62:  13%|█▎        | 15/112 [00:00<00:01, 53.41it/s, Epoch: 62, Batch: 16,Loss: -3.355,Avg.Loss: -3.162,LR: 1.64E-04]Training epoch 62:  14%|█▍        | 16/112 [00:00<00:01, 53.41it/s, Epoch: 62, Batch: 17,Loss: -2.778,Avg.Loss: -3.140,LR: 1.64E-04]Training epoch 62:  15%|█▌        | 17/112 [00:00<00:01, 53.41it/s, Epoch: 62, Batch: 18,Loss: -2.757,Avg.Loss: -3.119,LR: 1.64E-04]Training epoch 62:  16%|█▌        | 18/112 [00:00<00:01, 53.87it/s, Epoch: 62, Batch: 18,Loss: -2.757,Avg.Loss: -3.119,LR: 1.64E-04]Training epoch 62:  16%|█▌        | 18/112 [00:00<00:01, 53.87it/s, Epoch: 62, Batch: 19,Loss: -2.975,Avg.Loss: -3.111,LR: 1.64E-04]Training epoch 62:  17%|█▋        | 19/112 [00:00<00:01, 53.87it/s, Epoch: 62, Batch: 20,Loss: -3.412,Avg.Loss: -3.126,LR: 1.64E-04]Training epoch 62:  18%|█▊        | 20/112 [00:00<00:01, 53.87it/s, Epoch: 62, Batch: 21,Loss: -2.845,Avg.Loss: -3.113,LR: 1.64E-04]Training epoch 62:  19%|█▉        | 21/112 [00:00<00:01, 53.87it/s, Epoch: 62, Batch: 22,Loss: -3.054,Avg.Loss: -3.110,LR: 1.64E-04]Training epoch 62:  20%|█▉        | 22/112 [00:00<00:01, 53.87it/s, Epoch: 62, Batch: 23,Loss: -3.261,Avg.Loss: -3.117,LR: 1.64E-04]Training epoch 62:  21%|██        | 23/112 [00:00<00:01, 53.87it/s, Epoch: 62, Batch: 24,Loss: -3.608,Avg.Loss: -3.137,LR: 1.64E-04]Training epoch 62:  21%|██▏       | 24/112 [00:00<00:01, 52.76it/s, Epoch: 62, Batch: 24,Loss: -3.608,Avg.Loss: -3.137,LR: 1.64E-04]Training epoch 62:  21%|██▏       | 24/112 [00:00<00:01, 52.76it/s, Epoch: 62, Batch: 25,Loss: -3.363,Avg.Loss: -3.146,LR: 1.64E-04]Training epoch 62:  22%|██▏       | 25/112 [00:00<00:01, 52.76it/s, Epoch: 62, Batch: 26,Loss: -3.005,Avg.Loss: -3.141,LR: 1.64E-04]Training epoch 62:  23%|██▎       | 26/112 [00:00<00:01, 52.76it/s, Epoch: 62, Batch: 27,Loss: -2.652,Avg.Loss: -3.123,LR: 1.64E-04]Training epoch 62:  24%|██▍       | 27/112 [00:00<00:01, 52.76it/s, Epoch: 62, Batch: 28,Loss: -2.605,Avg.Loss: -3.104,LR: 1.63E-04]Training epoch 62:  25%|██▌       | 28/112 [00:00<00:01, 52.76it/s, Epoch: 62, Batch: 29,Loss: -3.123,Avg.Loss: -3.105,LR: 1.63E-04]Training epoch 62:  26%|██▌       | 29/112 [00:00<00:01, 52.76it/s, Epoch: 62, Batch: 30,Loss: -1.511,Avg.Loss: -3.052,LR: 1.63E-04]Training epoch 62:  27%|██▋       | 30/112 [00:00<00:01, 52.71it/s, Epoch: 62, Batch: 30,Loss: -1.511,Avg.Loss: -3.052,LR: 1.63E-04]Training epoch 62:  27%|██▋       | 30/112 [00:00<00:01, 52.71it/s, Epoch: 62, Batch: 31,Loss: -0.936,Avg.Loss: -2.983,LR: 1.63E-04]Training epoch 62:  28%|██▊       | 31/112 [00:00<00:01, 52.71it/s, Epoch: 62, Batch: 32,Loss: -1.675,Avg.Loss: -2.942,LR: 1.63E-04]Training epoch 62:  29%|██▊       | 32/112 [00:00<00:01, 52.71it/s, Epoch: 62, Batch: 33,Loss: -1.861,Avg.Loss: -2.910,LR: 1.63E-04]Training epoch 62:  29%|██▉       | 33/112 [00:00<00:01, 52.71it/s, Epoch: 62, Batch: 34,Loss: -1.575,Avg.Loss: -2.870,LR: 1.63E-04]Training epoch 62:  30%|███       | 34/112 [00:00<00:01, 52.71it/s, Epoch: 62, Batch: 35,Loss: 0.117,Avg.Loss: -2.785,LR: 1.63E-04] Training epoch 62:  31%|███▏      | 35/112 [00:00<00:01, 52.71it/s, Epoch: 62, Batch: 36,Loss: 0.874,Avg.Loss: -2.683,LR: 1.63E-04]Training epoch 62:  32%|███▏      | 36/112 [00:00<00:01, 53.03it/s, Epoch: 62, Batch: 36,Loss: 0.874,Avg.Loss: -2.683,LR: 1.63E-04]Training epoch 62:  32%|███▏      | 36/112 [00:00<00:01, 53.03it/s, Epoch: 62, Batch: 37,Loss: -2.382,Avg.Loss: -2.675,LR: 1.63E-04]Training epoch 62:  33%|███▎      | 37/112 [00:00<00:01, 53.03it/s, Epoch: 62, Batch: 38,Loss: -3.339,Avg.Loss: -2.693,LR: 1.63E-04]Training epoch 62:  34%|███▍      | 38/112 [00:00<00:01, 53.03it/s, Epoch: 62, Batch: 39,Loss: -1.674,Avg.Loss: -2.667,LR: 1.63E-04]Training epoch 62:  35%|███▍      | 39/112 [00:00<00:01, 53.03it/s, Epoch: 62, Batch: 40,Loss: 2.445,Avg.Loss: -2.539,LR: 1.63E-04] Training epoch 62:  36%|███▌      | 40/112 [00:00<00:01, 53.03it/s, Epoch: 62, Batch: 41,Loss: 0.834,Avg.Loss: -2.457,LR: 1.63E-04]Training epoch 62:  37%|███▋      | 41/112 [00:00<00:01, 53.03it/s, Epoch: 62, Batch: 42,Loss: -0.482,Avg.Loss: -2.410,LR: 1.63E-04]Training epoch 62:  38%|███▊      | 42/112 [00:00<00:01, 53.21it/s, Epoch: 62, Batch: 42,Loss: -0.482,Avg.Loss: -2.410,LR: 1.63E-04]Training epoch 62:  38%|███▊      | 42/112 [00:00<00:01, 53.21it/s, Epoch: 62, Batch: 43,Loss: -1.835,Avg.Loss: -2.396,LR: 1.62E-04]Training epoch 62:  38%|███▊      | 43/112 [00:00<00:01, 53.21it/s, Epoch: 62, Batch: 44,Loss: -2.132,Avg.Loss: -2.390,LR: 1.62E-04]Training epoch 62:  39%|███▉      | 44/112 [00:00<00:01, 53.21it/s, Epoch: 62, Batch: 45,Loss: -0.755,Avg.Loss: -2.354,LR: 1.62E-04]Training epoch 62:  40%|████      | 45/112 [00:00<00:01, 53.21it/s, Epoch: 62, Batch: 46,Loss: -2.083,Avg.Loss: -2.348,LR: 1.62E-04]Training epoch 62:  41%|████      | 46/112 [00:00<00:01, 53.21it/s, Epoch: 62, Batch: 47,Loss: -2.683,Avg.Loss: -2.355,LR: 1.62E-04]Training epoch 62:  42%|████▏     | 47/112 [00:00<00:01, 53.21it/s, Epoch: 62, Batch: 48,Loss: -1.930,Avg.Loss: -2.346,LR: 1.62E-04]Training epoch 62:  43%|████▎     | 48/112 [00:00<00:01, 53.75it/s, Epoch: 62, Batch: 48,Loss: -1.930,Avg.Loss: -2.346,LR: 1.62E-04]Training epoch 62:  43%|████▎     | 48/112 [00:00<00:01, 53.75it/s, Epoch: 62, Batch: 49,Loss: -0.279,Avg.Loss: -2.304,LR: 1.62E-04]Training epoch 62:  44%|████▍     | 49/112 [00:00<00:01, 53.75it/s, Epoch: 62, Batch: 50,Loss: -0.568,Avg.Loss: -2.269,LR: 1.62E-04]Training epoch 62:  45%|████▍     | 50/112 [00:00<00:01, 53.75it/s, Epoch: 62, Batch: 51,Loss: -2.702,Avg.Loss: -2.278,LR: 1.62E-04]Training epoch 62:  46%|████▌     | 51/112 [00:00<00:01, 53.75it/s, Epoch: 62, Batch: 52,Loss: -2.062,Avg.Loss: -2.274,LR: 1.62E-04]Training epoch 62:  46%|████▋     | 52/112 [00:00<00:01, 53.75it/s, Epoch: 62, Batch: 53,Loss: -1.606,Avg.Loss: -2.261,LR: 1.62E-04]Training epoch 62:  47%|████▋     | 53/112 [00:01<00:01, 53.75it/s, Epoch: 62, Batch: 54,Loss: -2.318,Avg.Loss: -2.262,LR: 1.62E-04]Training epoch 62:  48%|████▊     | 54/112 [00:01<00:01, 53.65it/s, Epoch: 62, Batch: 54,Loss: -2.318,Avg.Loss: -2.262,LR: 1.62E-04]Training epoch 62:  48%|████▊     | 54/112 [00:01<00:01, 53.65it/s, Epoch: 62, Batch: 55,Loss: -3.114,Avg.Loss: -2.278,LR: 1.62E-04]Training epoch 62:  49%|████▉     | 55/112 [00:01<00:01, 53.65it/s, Epoch: 62, Batch: 56,Loss: -2.203,Avg.Loss: -2.276,LR: 1.62E-04]Training epoch 62:  50%|█████     | 56/112 [00:01<00:01, 53.65it/s, Epoch: 62, Batch: 57,Loss: -0.930,Avg.Loss: -2.253,LR: 1.62E-04]Training epoch 62:  51%|█████     | 57/112 [00:01<00:01, 53.65it/s, Epoch: 62, Batch: 58,Loss: -1.367,Avg.Loss: -2.237,LR: 1.62E-04]Training epoch 62:  52%|█████▏    | 58/112 [00:01<00:01, 53.65it/s, Epoch: 62, Batch: 59,Loss: -1.907,Avg.Loss: -2.232,LR: 1.61E-04]Training epoch 62:  53%|█████▎    | 59/112 [00:01<00:00, 53.65it/s, Epoch: 62, Batch: 60,Loss: -2.374,Avg.Loss: -2.234,LR: 1.61E-04]Training epoch 62:  54%|█████▎    | 60/112 [00:01<00:00, 53.76it/s, Epoch: 62, Batch: 60,Loss: -2.374,Avg.Loss: -2.234,LR: 1.61E-04]Training epoch 62:  54%|█████▎    | 60/112 [00:01<00:00, 53.76it/s, Epoch: 62, Batch: 61,Loss: -1.813,Avg.Loss: -2.227,LR: 1.61E-04]Training epoch 62:  54%|█████▍    | 61/112 [00:01<00:00, 53.76it/s, Epoch: 62, Batch: 62,Loss: -2.003,Avg.Loss: -2.224,LR: 1.61E-04]Training epoch 62:  55%|█████▌    | 62/112 [00:01<00:00, 53.76it/s, Epoch: 62, Batch: 63,Loss: -2.791,Avg.Loss: -2.233,LR: 1.61E-04]Training epoch 62:  56%|█████▋    | 63/112 [00:01<00:00, 53.76it/s, Epoch: 62, Batch: 64,Loss: -2.052,Avg.Loss: -2.230,LR: 1.61E-04]Training epoch 62:  57%|█████▋    | 64/112 [00:01<00:00, 53.76it/s, Epoch: 62, Batch: 65,Loss: -0.798,Avg.Loss: -2.208,LR: 1.61E-04]Training epoch 62:  58%|█████▊    | 65/112 [00:01<00:00, 53.76it/s, Epoch: 62, Batch: 66,Loss: -1.295,Avg.Loss: -2.194,LR: 1.61E-04]Training epoch 62:  59%|█████▉    | 66/112 [00:01<00:00, 53.20it/s, Epoch: 62, Batch: 66,Loss: -1.295,Avg.Loss: -2.194,LR: 1.61E-04]Training epoch 62:  59%|█████▉    | 66/112 [00:01<00:00, 53.20it/s, Epoch: 62, Batch: 67,Loss: -2.726,Avg.Loss: -2.202,LR: 1.61E-04]Training epoch 62:  60%|█████▉    | 67/112 [00:01<00:00, 53.20it/s, Epoch: 62, Batch: 68,Loss: -2.630,Avg.Loss: -2.208,LR: 1.61E-04]Training epoch 62:  61%|██████    | 68/112 [00:01<00:00, 53.20it/s, Epoch: 62, Batch: 69,Loss: -1.366,Avg.Loss: -2.196,LR: 1.61E-04]Training epoch 62:  62%|██████▏   | 69/112 [00:01<00:00, 53.20it/s, Epoch: 62, Batch: 70,Loss: -2.339,Avg.Loss: -2.198,LR: 1.61E-04]Training epoch 62:  62%|██████▎   | 70/112 [00:01<00:00, 53.20it/s, Epoch: 62, Batch: 71,Loss: -3.086,Avg.Loss: -2.211,LR: 1.61E-04]Training epoch 62:  63%|██████▎   | 71/112 [00:01<00:00, 53.20it/s, Epoch: 62, Batch: 72,Loss: -2.352,Avg.Loss: -2.212,LR: 1.61E-04]Training epoch 62:  64%|██████▍   | 72/112 [00:01<00:00, 53.21it/s, Epoch: 62, Batch: 72,Loss: -2.352,Avg.Loss: -2.212,LR: 1.61E-04]Training epoch 62:  64%|██████▍   | 72/112 [00:01<00:00, 53.21it/s, Epoch: 62, Batch: 73,Loss: -2.179,Avg.Loss: -2.212,LR: 1.61E-04]Training epoch 62:  65%|██████▌   | 73/112 [00:01<00:00, 53.21it/s, Epoch: 62, Batch: 74,Loss: -2.537,Avg.Loss: -2.216,LR: 1.60E-04]Training epoch 62:  66%|██████▌   | 74/112 [00:01<00:00, 53.21it/s, Epoch: 62, Batch: 75,Loss: -3.180,Avg.Loss: -2.229,LR: 1.60E-04]Training epoch 62:  67%|██████▋   | 75/112 [00:01<00:00, 53.21it/s, Epoch: 62, Batch: 76,Loss: -1.618,Avg.Loss: -2.221,LR: 1.60E-04]Training epoch 62:  68%|██████▊   | 76/112 [00:01<00:00, 53.21it/s, Epoch: 62, Batch: 77,Loss: -0.588,Avg.Loss: -2.200,LR: 1.60E-04]Training epoch 62:  69%|██████▉   | 77/112 [00:01<00:00, 53.21it/s, Epoch: 62, Batch: 78,Loss: -0.599,Avg.Loss: -2.179,LR: 1.60E-04]Training epoch 62:  70%|██████▉   | 78/112 [00:01<00:00, 53.36it/s, Epoch: 62, Batch: 78,Loss: -0.599,Avg.Loss: -2.179,LR: 1.60E-04]Training epoch 62:  70%|██████▉   | 78/112 [00:01<00:00, 53.36it/s, Epoch: 62, Batch: 79,Loss: -2.469,Avg.Loss: -2.183,LR: 1.60E-04]Training epoch 62:  71%|███████   | 79/112 [00:01<00:00, 53.36it/s, Epoch: 62, Batch: 80,Loss: -2.974,Avg.Loss: -2.193,LR: 1.60E-04]Training epoch 62:  71%|███████▏  | 80/112 [00:01<00:00, 53.36it/s, Epoch: 62, Batch: 81,Loss: -2.478,Avg.Loss: -2.197,LR: 1.60E-04]Training epoch 62:  72%|███████▏  | 81/112 [00:01<00:00, 53.36it/s, Epoch: 62, Batch: 82,Loss: -2.857,Avg.Loss: -2.205,LR: 1.60E-04]Training epoch 62:  73%|███████▎  | 82/112 [00:01<00:00, 53.36it/s, Epoch: 62, Batch: 83,Loss: -3.073,Avg.Loss: -2.215,LR: 1.60E-04]Training epoch 62:  74%|███████▍  | 83/112 [00:01<00:00, 53.36it/s, Epoch: 62, Batch: 84,Loss: -2.006,Avg.Loss: -2.213,LR: 1.60E-04]Training epoch 62:  75%|███████▌  | 84/112 [00:01<00:00, 53.61it/s, Epoch: 62, Batch: 84,Loss: -2.006,Avg.Loss: -2.213,LR: 1.60E-04]Training epoch 62:  75%|███████▌  | 84/112 [00:01<00:00, 53.61it/s, Epoch: 62, Batch: 85,Loss: -0.815,Avg.Loss: -2.196,LR: 1.60E-04]Training epoch 62:  76%|███████▌  | 85/112 [00:01<00:00, 53.61it/s, Epoch: 62, Batch: 86,Loss: -0.653,Avg.Loss: -2.178,LR: 1.60E-04]Training epoch 62:  77%|███████▋  | 86/112 [00:01<00:00, 53.61it/s, Epoch: 62, Batch: 87,Loss: -2.213,Avg.Loss: -2.179,LR: 1.60E-04]Training epoch 62:  78%|███████▊  | 87/112 [00:01<00:00, 53.61it/s, Epoch: 62, Batch: 88,Loss: -2.618,Avg.Loss: -2.184,LR: 1.60E-04]Training epoch 62:  79%|███████▊  | 88/112 [00:01<00:00, 53.61it/s, Epoch: 62, Batch: 89,Loss: -2.238,Avg.Loss: -2.184,LR: 1.59E-04]Training epoch 62:  79%|███████▉  | 89/112 [00:01<00:00, 53.61it/s, Epoch: 62, Batch: 90,Loss: -2.309,Avg.Loss: -2.186,LR: 1.59E-04]Training epoch 62:  80%|████████  | 90/112 [00:01<00:00, 53.44it/s, Epoch: 62, Batch: 90,Loss: -2.309,Avg.Loss: -2.186,LR: 1.59E-04]Training epoch 62:  80%|████████  | 90/112 [00:01<00:00, 53.44it/s, Epoch: 62, Batch: 91,Loss: -3.160,Avg.Loss: -2.196,LR: 1.59E-04]Training epoch 62:  81%|████████▏ | 91/112 [00:01<00:00, 53.44it/s, Epoch: 62, Batch: 92,Loss: -2.320,Avg.Loss: -2.198,LR: 1.59E-04]Training epoch 62:  82%|████████▏ | 92/112 [00:01<00:00, 53.44it/s, Epoch: 62, Batch: 93,Loss: -1.057,Avg.Loss: -2.185,LR: 1.59E-04]Training epoch 62:  83%|████████▎ | 93/112 [00:01<00:00, 53.44it/s, Epoch: 62, Batch: 94,Loss: -1.580,Avg.Loss: -2.179,LR: 1.59E-04]Training epoch 62:  84%|████████▍ | 94/112 [00:01<00:00, 53.44it/s, Epoch: 62, Batch: 95,Loss: -2.726,Avg.Loss: -2.185,LR: 1.59E-04]Training epoch 62:  85%|████████▍ | 95/112 [00:01<00:00, 53.44it/s, Epoch: 62, Batch: 96,Loss: -2.568,Avg.Loss: -2.189,LR: 1.59E-04]Training epoch 62:  86%|████████▌ | 96/112 [00:01<00:00, 53.68it/s, Epoch: 62, Batch: 96,Loss: -2.568,Avg.Loss: -2.189,LR: 1.59E-04]Training epoch 62:  86%|████████▌ | 96/112 [00:01<00:00, 53.68it/s, Epoch: 62, Batch: 97,Loss: -1.618,Avg.Loss: -2.183,LR: 1.59E-04]Training epoch 62:  87%|████████▋ | 97/112 [00:01<00:00, 53.68it/s, Epoch: 62, Batch: 98,Loss: -2.399,Avg.Loss: -2.185,LR: 1.59E-04]Training epoch 62:  88%|████████▊ | 98/112 [00:01<00:00, 53.68it/s, Epoch: 62, Batch: 99,Loss: -3.216,Avg.Loss: -2.195,LR: 1.59E-04]Training epoch 62:  88%|████████▊ | 99/112 [00:01<00:00, 53.68it/s, Epoch: 62, Batch: 100,Loss: -2.402,Avg.Loss: -2.198,LR: 1.59E-04]Training epoch 62:  89%|████████▉ | 100/112 [00:01<00:00, 53.68it/s, Epoch: 62, Batch: 101,Loss: -1.493,Avg.Loss: -2.191,LR: 1.59E-04]Training epoch 62:  90%|█████████ | 101/112 [00:01<00:00, 53.68it/s, Epoch: 62, Batch: 102,Loss: -1.191,Avg.Loss: -2.181,LR: 1.59E-04]Training epoch 62:  91%|█████████ | 102/112 [00:01<00:00, 53.73it/s, Epoch: 62, Batch: 102,Loss: -1.191,Avg.Loss: -2.181,LR: 1.59E-04]Training epoch 62:  91%|█████████ | 102/112 [00:01<00:00, 53.73it/s, Epoch: 62, Batch: 103,Loss: -2.539,Avg.Loss: -2.184,LR: 1.59E-04]Training epoch 62:  92%|█████████▏| 103/112 [00:01<00:00, 53.73it/s, Epoch: 62, Batch: 104,Loss: -2.751,Avg.Loss: -2.190,LR: 1.58E-04]Training epoch 62:  93%|█████████▎| 104/112 [00:01<00:00, 53.73it/s, Epoch: 62, Batch: 105,Loss: -2.545,Avg.Loss: -2.193,LR: 1.58E-04]Training epoch 62:  94%|█████████▍| 105/112 [00:01<00:00, 53.73it/s, Epoch: 62, Batch: 106,Loss: -2.358,Avg.Loss: -2.195,LR: 1.58E-04]Training epoch 62:  95%|█████████▍| 106/112 [00:01<00:00, 53.73it/s, Epoch: 62, Batch: 107,Loss: -2.987,Avg.Loss: -2.202,LR: 1.58E-04]Training epoch 62:  96%|█████████▌| 107/112 [00:02<00:00, 53.73it/s, Epoch: 62, Batch: 108,Loss: -2.462,Avg.Loss: -2.204,LR: 1.58E-04]Training epoch 62:  96%|█████████▋| 108/112 [00:02<00:00, 54.07it/s, Epoch: 62, Batch: 108,Loss: -2.462,Avg.Loss: -2.204,LR: 1.58E-04]Training epoch 62:  96%|█████████▋| 108/112 [00:02<00:00, 54.07it/s, Epoch: 62, Batch: 109,Loss: -1.059,Avg.Loss: -2.194,LR: 1.58E-04]Training epoch 62:  97%|█████████▋| 109/112 [00:02<00:00, 54.07it/s, Epoch: 62, Batch: 110,Loss: -2.230,Avg.Loss: -2.194,LR: 1.58E-04]Training epoch 62:  98%|█████████▊| 110/112 [00:02<00:00, 54.07it/s, Epoch: 62, Batch: 111,Loss: -2.910,Avg.Loss: -2.201,LR: 1.58E-04]Training epoch 62:  99%|█████████▉| 111/112 [00:02<00:00, 54.07it/s, Epoch: 62, Batch: 112,Loss: -2.692,Avg.Loss: -2.205,LR: 1.58E-04]Training epoch 62: 100%|██████████| 112/112 [00:02<00:00, 53.47it/s, Epoch: 62, Batch: 112,Loss: -2.692,Avg.Loss: -2.205,LR: 1.58E-04]
Training epoch 63:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 63:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 63, Batch: 1,Loss: -2.565,Avg.Loss: -2.565,LR: 1.58E-04]Training epoch 63:   1%|          | 1/112 [00:00<00:04, 27.41it/s, Epoch: 63, Batch: 2,Loss: -2.325,Avg.Loss: -2.445,LR: 1.58E-04]Training epoch 63:   2%|▏         | 2/112 [00:00<00:02, 40.14it/s, Epoch: 63, Batch: 3,Loss: -2.949,Avg.Loss: -2.613,LR: 1.58E-04]Training epoch 63:   3%|▎         | 3/112 [00:00<00:02, 45.45it/s, Epoch: 63, Batch: 4,Loss: -2.550,Avg.Loss: -2.597,LR: 1.58E-04]Training epoch 63:   4%|▎         | 4/112 [00:00<00:02, 47.78it/s, Epoch: 63, Batch: 5,Loss: -1.779,Avg.Loss: -2.434,LR: 1.58E-04]Training epoch 63:   4%|▍         | 5/112 [00:00<00:02, 49.48it/s, Epoch: 63, Batch: 6,Loss: -1.518,Avg.Loss: -2.281,LR: 1.58E-04]Training epoch 63:   5%|▌         | 6/112 [00:00<00:01, 59.29it/s, Epoch: 63, Batch: 6,Loss: -1.518,Avg.Loss: -2.281,LR: 1.58E-04]Training epoch 63:   5%|▌         | 6/112 [00:00<00:01, 59.29it/s, Epoch: 63, Batch: 7,Loss: -2.646,Avg.Loss: -2.333,LR: 1.58E-04]Training epoch 63:   6%|▋         | 7/112 [00:00<00:01, 59.29it/s, Epoch: 63, Batch: 8,Loss: -2.632,Avg.Loss: -2.371,LR: 1.57E-04]Training epoch 63:   7%|▋         | 8/112 [00:00<00:01, 59.29it/s, Epoch: 63, Batch: 9,Loss: -1.661,Avg.Loss: -2.292,LR: 1.57E-04]Training epoch 63:   8%|▊         | 9/112 [00:00<00:01, 59.29it/s, Epoch: 63, Batch: 10,Loss: -1.514,Avg.Loss: -2.214,LR: 1.57E-04]Training epoch 63:   9%|▉         | 10/112 [00:00<00:01, 59.29it/s, Epoch: 63, Batch: 11,Loss: -2.984,Avg.Loss: -2.284,LR: 1.57E-04]Training epoch 63:  10%|▉         | 11/112 [00:00<00:01, 59.29it/s, Epoch: 63, Batch: 12,Loss: -2.803,Avg.Loss: -2.327,LR: 1.57E-04]Training epoch 63:  11%|█         | 12/112 [00:00<00:01, 55.38it/s, Epoch: 63, Batch: 12,Loss: -2.803,Avg.Loss: -2.327,LR: 1.57E-04]Training epoch 63:  11%|█         | 12/112 [00:00<00:01, 55.38it/s, Epoch: 63, Batch: 13,Loss: -1.740,Avg.Loss: -2.282,LR: 1.57E-04]Training epoch 63:  12%|█▏        | 13/112 [00:00<00:01, 55.38it/s, Epoch: 63, Batch: 14,Loss: -2.603,Avg.Loss: -2.305,LR: 1.57E-04]Training epoch 63:  12%|█▎        | 14/112 [00:00<00:01, 55.38it/s, Epoch: 63, Batch: 15,Loss: -2.954,Avg.Loss: -2.348,LR: 1.57E-04]Training epoch 63:  13%|█▎        | 15/112 [00:00<00:01, 55.38it/s, Epoch: 63, Batch: 16,Loss: -2.036,Avg.Loss: -2.329,LR: 1.57E-04]Training epoch 63:  14%|█▍        | 16/112 [00:00<00:01, 55.38it/s, Epoch: 63, Batch: 17,Loss: -1.233,Avg.Loss: -2.264,LR: 1.57E-04]Training epoch 63:  15%|█▌        | 17/112 [00:00<00:01, 55.38it/s, Epoch: 63, Batch: 18,Loss: -1.486,Avg.Loss: -2.221,LR: 1.57E-04]Training epoch 63:  16%|█▌        | 18/112 [00:00<00:01, 54.34it/s, Epoch: 63, Batch: 18,Loss: -1.486,Avg.Loss: -2.221,LR: 1.57E-04]Training epoch 63:  16%|█▌        | 18/112 [00:00<00:01, 54.34it/s, Epoch: 63, Batch: 19,Loss: -2.443,Avg.Loss: -2.233,LR: 1.57E-04]Training epoch 63:  17%|█▋        | 19/112 [00:00<00:01, 54.34it/s, Epoch: 63, Batch: 20,Loss: -3.345,Avg.Loss: -2.288,LR: 1.57E-04]Training epoch 63:  18%|█▊        | 20/112 [00:00<00:01, 54.34it/s, Epoch: 63, Batch: 21,Loss: -1.983,Avg.Loss: -2.274,LR: 1.57E-04]Training epoch 63:  19%|█▉        | 21/112 [00:00<00:01, 54.34it/s, Epoch: 63, Batch: 22,Loss: -2.713,Avg.Loss: -2.294,LR: 1.57E-04]Training epoch 63:  20%|█▉        | 22/112 [00:00<00:01, 54.34it/s, Epoch: 63, Batch: 23,Loss: -3.054,Avg.Loss: -2.327,LR: 1.56E-04]Training epoch 63:  21%|██        | 23/112 [00:00<00:01, 54.34it/s, Epoch: 63, Batch: 24,Loss: -2.711,Avg.Loss: -2.343,LR: 1.56E-04]Training epoch 63:  21%|██▏       | 24/112 [00:00<00:01, 53.52it/s, Epoch: 63, Batch: 24,Loss: -2.711,Avg.Loss: -2.343,LR: 1.56E-04]Training epoch 63:  21%|██▏       | 24/112 [00:00<00:01, 53.52it/s, Epoch: 63, Batch: 25,Loss: -1.940,Avg.Loss: -2.327,LR: 1.56E-04]Training epoch 63:  22%|██▏       | 25/112 [00:00<00:01, 53.52it/s, Epoch: 63, Batch: 26,Loss: -2.108,Avg.Loss: -2.318,LR: 1.56E-04]Training epoch 63:  23%|██▎       | 26/112 [00:00<00:01, 53.52it/s, Epoch: 63, Batch: 27,Loss: -3.050,Avg.Loss: -2.345,LR: 1.56E-04]Training epoch 63:  24%|██▍       | 27/112 [00:00<00:01, 53.52it/s, Epoch: 63, Batch: 28,Loss: -2.442,Avg.Loss: -2.349,LR: 1.56E-04]Training epoch 63:  25%|██▌       | 28/112 [00:00<00:01, 53.52it/s, Epoch: 63, Batch: 29,Loss: -1.714,Avg.Loss: -2.327,LR: 1.56E-04]Training epoch 63:  26%|██▌       | 29/112 [00:00<00:01, 53.52it/s, Epoch: 63, Batch: 30,Loss: -2.011,Avg.Loss: -2.316,LR: 1.56E-04]Training epoch 63:  27%|██▋       | 30/112 [00:00<00:01, 53.28it/s, Epoch: 63, Batch: 30,Loss: -2.011,Avg.Loss: -2.316,LR: 1.56E-04]Training epoch 63:  27%|██▋       | 30/112 [00:00<00:01, 53.28it/s, Epoch: 63, Batch: 31,Loss: -2.974,Avg.Loss: -2.338,LR: 1.56E-04]Training epoch 63:  28%|██▊       | 31/112 [00:00<00:01, 53.28it/s, Epoch: 63, Batch: 32,Loss: -3.022,Avg.Loss: -2.359,LR: 1.56E-04]Training epoch 63:  29%|██▊       | 32/112 [00:00<00:01, 53.28it/s, Epoch: 63, Batch: 33,Loss: -1.682,Avg.Loss: -2.338,LR: 1.56E-04]Training epoch 63:  29%|██▉       | 33/112 [00:00<00:01, 53.28it/s, Epoch: 63, Batch: 34,Loss: -2.278,Avg.Loss: -2.337,LR: 1.56E-04]Training epoch 63:  30%|███       | 34/112 [00:00<00:01, 53.28it/s, Epoch: 63, Batch: 35,Loss: -2.705,Avg.Loss: -2.347,LR: 1.56E-04]Training epoch 63:  31%|███▏      | 35/112 [00:00<00:01, 53.28it/s, Epoch: 63, Batch: 36,Loss: -2.449,Avg.Loss: -2.350,LR: 1.56E-04]Training epoch 63:  32%|███▏      | 36/112 [00:00<00:01, 53.35it/s, Epoch: 63, Batch: 36,Loss: -2.449,Avg.Loss: -2.350,LR: 1.56E-04]Training epoch 63:  32%|███▏      | 36/112 [00:00<00:01, 53.35it/s, Epoch: 63, Batch: 37,Loss: -1.424,Avg.Loss: -2.325,LR: 1.56E-04]Training epoch 63:  33%|███▎      | 37/112 [00:00<00:01, 53.35it/s, Epoch: 63, Batch: 38,Loss: -2.479,Avg.Loss: -2.329,LR: 1.55E-04]Training epoch 63:  34%|███▍      | 38/112 [00:00<00:01, 53.35it/s, Epoch: 63, Batch: 39,Loss: -3.083,Avg.Loss: -2.348,LR: 1.55E-04]Training epoch 63:  35%|███▍      | 39/112 [00:00<00:01, 53.35it/s, Epoch: 63, Batch: 40,Loss: -2.399,Avg.Loss: -2.350,LR: 1.55E-04]Training epoch 63:  36%|███▌      | 40/112 [00:00<00:01, 53.35it/s, Epoch: 63, Batch: 41,Loss: -1.640,Avg.Loss: -2.332,LR: 1.55E-04]Training epoch 63:  37%|███▋      | 41/112 [00:00<00:01, 53.35it/s, Epoch: 63, Batch: 42,Loss: -2.537,Avg.Loss: -2.337,LR: 1.55E-04]Training epoch 63:  38%|███▊      | 42/112 [00:00<00:01, 53.62it/s, Epoch: 63, Batch: 42,Loss: -2.537,Avg.Loss: -2.337,LR: 1.55E-04]Training epoch 63:  38%|███▊      | 42/112 [00:00<00:01, 53.62it/s, Epoch: 63, Batch: 43,Loss: -2.880,Avg.Loss: -2.350,LR: 1.55E-04]Training epoch 63:  38%|███▊      | 43/112 [00:00<00:01, 53.62it/s, Epoch: 63, Batch: 44,Loss: -2.807,Avg.Loss: -2.360,LR: 1.55E-04]Training epoch 63:  39%|███▉      | 44/112 [00:00<00:01, 53.62it/s, Epoch: 63, Batch: 45,Loss: -2.038,Avg.Loss: -2.353,LR: 1.55E-04]Training epoch 63:  40%|████      | 45/112 [00:00<00:01, 53.62it/s, Epoch: 63, Batch: 46,Loss: -2.434,Avg.Loss: -2.355,LR: 1.55E-04]Training epoch 63:  41%|████      | 46/112 [00:00<00:01, 53.62it/s, Epoch: 63, Batch: 47,Loss: -3.039,Avg.Loss: -2.369,LR: 1.55E-04]Training epoch 63:  42%|████▏     | 47/112 [00:00<00:01, 53.62it/s, Epoch: 63, Batch: 48,Loss: -2.595,Avg.Loss: -2.374,LR: 1.55E-04]Training epoch 63:  43%|████▎     | 48/112 [00:00<00:01, 53.49it/s, Epoch: 63, Batch: 48,Loss: -2.595,Avg.Loss: -2.374,LR: 1.55E-04]Training epoch 63:  43%|████▎     | 48/112 [00:00<00:01, 53.49it/s, Epoch: 63, Batch: 49,Loss: -1.753,Avg.Loss: -2.361,LR: 1.55E-04]Training epoch 63:  44%|████▍     | 49/112 [00:00<00:01, 53.49it/s, Epoch: 63, Batch: 50,Loss: -2.050,Avg.Loss: -2.355,LR: 1.55E-04]Training epoch 63:  45%|████▍     | 50/112 [00:00<00:01, 53.49it/s, Epoch: 63, Batch: 51,Loss: -3.019,Avg.Loss: -2.368,LR: 1.55E-04]Training epoch 63:  46%|████▌     | 51/112 [00:00<00:01, 53.49it/s, Epoch: 63, Batch: 52,Loss: -2.582,Avg.Loss: -2.372,LR: 1.55E-04]Training epoch 63:  46%|████▋     | 52/112 [00:00<00:01, 53.49it/s, Epoch: 63, Batch: 53,Loss: -2.338,Avg.Loss: -2.372,LR: 1.55E-04]Training epoch 63:  47%|████▋     | 53/112 [00:01<00:01, 53.49it/s, Epoch: 63, Batch: 54,Loss: -2.512,Avg.Loss: -2.374,LR: 1.54E-04]Training epoch 63:  48%|████▊     | 54/112 [00:01<00:01, 53.32it/s, Epoch: 63, Batch: 54,Loss: -2.512,Avg.Loss: -2.374,LR: 1.54E-04]Training epoch 63:  48%|████▊     | 54/112 [00:01<00:01, 53.32it/s, Epoch: 63, Batch: 55,Loss: -3.129,Avg.Loss: -2.388,LR: 1.54E-04]Training epoch 63:  49%|████▉     | 55/112 [00:01<00:01, 53.32it/s, Epoch: 63, Batch: 56,Loss: -2.610,Avg.Loss: -2.392,LR: 1.54E-04]Training epoch 63:  50%|█████     | 56/112 [00:01<00:01, 53.32it/s, Epoch: 63, Batch: 57,Loss: -2.171,Avg.Loss: -2.388,LR: 1.54E-04]Training epoch 63:  51%|█████     | 57/112 [00:01<00:01, 53.32it/s, Epoch: 63, Batch: 58,Loss: -2.131,Avg.Loss: -2.384,LR: 1.54E-04]Training epoch 63:  52%|█████▏    | 58/112 [00:01<00:01, 53.32it/s, Epoch: 63, Batch: 59,Loss: -2.609,Avg.Loss: -2.387,LR: 1.54E-04]Training epoch 63:  53%|█████▎    | 59/112 [00:01<00:00, 53.32it/s, Epoch: 63, Batch: 60,Loss: -2.784,Avg.Loss: -2.394,LR: 1.54E-04]Training epoch 63:  54%|█████▎    | 60/112 [00:01<00:00, 53.26it/s, Epoch: 63, Batch: 60,Loss: -2.784,Avg.Loss: -2.394,LR: 1.54E-04]Training epoch 63:  54%|█████▎    | 60/112 [00:01<00:00, 53.26it/s, Epoch: 63, Batch: 61,Loss: -2.024,Avg.Loss: -2.388,LR: 1.54E-04]Training epoch 63:  54%|█████▍    | 61/112 [00:01<00:00, 53.26it/s, Epoch: 63, Batch: 62,Loss: -2.247,Avg.Loss: -2.386,LR: 1.54E-04]Training epoch 63:  55%|█████▌    | 62/112 [00:01<00:00, 53.26it/s, Epoch: 63, Batch: 63,Loss: -2.842,Avg.Loss: -2.393,LR: 1.54E-04]Training epoch 63:  56%|█████▋    | 63/112 [00:01<00:00, 53.26it/s, Epoch: 63, Batch: 64,Loss: -2.471,Avg.Loss: -2.394,LR: 1.54E-04]Training epoch 63:  57%|█████▋    | 64/112 [00:01<00:00, 53.26it/s, Epoch: 63, Batch: 65,Loss: -2.262,Avg.Loss: -2.392,LR: 1.54E-04]Training epoch 63:  58%|█████▊    | 65/112 [00:01<00:00, 53.26it/s, Epoch: 63, Batch: 66,Loss: -2.441,Avg.Loss: -2.393,LR: 1.54E-04]Training epoch 63:  59%|█████▉    | 66/112 [00:01<00:00, 53.31it/s, Epoch: 63, Batch: 66,Loss: -2.441,Avg.Loss: -2.393,LR: 1.54E-04]Training epoch 63:  59%|█████▉    | 66/112 [00:01<00:00, 53.31it/s, Epoch: 63, Batch: 67,Loss: -2.917,Avg.Loss: -2.401,LR: 1.54E-04]Training epoch 63:  60%|█████▉    | 67/112 [00:01<00:00, 53.31it/s, Epoch: 63, Batch: 68,Loss: -2.385,Avg.Loss: -2.401,LR: 1.54E-04]Training epoch 63:  61%|██████    | 68/112 [00:01<00:00, 53.31it/s, Epoch: 63, Batch: 69,Loss: -2.037,Avg.Loss: -2.395,LR: 1.53E-04]Training epoch 63:  62%|██████▏   | 69/112 [00:01<00:00, 53.31it/s, Epoch: 63, Batch: 70,Loss: -1.921,Avg.Loss: -2.388,LR: 1.53E-04]Training epoch 63:  62%|██████▎   | 70/112 [00:01<00:00, 53.31it/s, Epoch: 63, Batch: 71,Loss: -2.864,Avg.Loss: -2.395,LR: 1.53E-04]Training epoch 63:  63%|██████▎   | 71/112 [00:01<00:00, 53.31it/s, Epoch: 63, Batch: 72,Loss: -2.723,Avg.Loss: -2.400,LR: 1.53E-04]Training epoch 63:  64%|██████▍   | 72/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 72,Loss: -2.723,Avg.Loss: -2.400,LR: 1.53E-04]Training epoch 63:  64%|██████▍   | 72/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 73,Loss: -2.253,Avg.Loss: -2.398,LR: 1.53E-04]Training epoch 63:  65%|██████▌   | 73/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 74,Loss: -2.612,Avg.Loss: -2.401,LR: 1.53E-04]Training epoch 63:  66%|██████▌   | 74/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 75,Loss: -3.127,Avg.Loss: -2.410,LR: 1.53E-04]Training epoch 63:  67%|██████▋   | 75/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 76,Loss: -2.423,Avg.Loss: -2.410,LR: 1.53E-04]Training epoch 63:  68%|██████▊   | 76/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 77,Loss: -1.402,Avg.Loss: -2.397,LR: 1.53E-04]Training epoch 63:  69%|██████▉   | 77/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 78,Loss: -1.848,Avg.Loss: -2.390,LR: 1.53E-04]Training epoch 63:  70%|██████▉   | 78/112 [00:01<00:00, 53.30it/s, Epoch: 63, Batch: 78,Loss: -1.848,Avg.Loss: -2.390,LR: 1.53E-04]Training epoch 63:  70%|██████▉   | 78/112 [00:01<00:00, 53.30it/s, Epoch: 63, Batch: 79,Loss: -3.025,Avg.Loss: -2.398,LR: 1.53E-04]Training epoch 63:  71%|███████   | 79/112 [00:01<00:00, 53.30it/s, Epoch: 63, Batch: 80,Loss: -2.437,Avg.Loss: -2.399,LR: 1.53E-04]Training epoch 63:  71%|███████▏  | 80/112 [00:01<00:00, 53.30it/s, Epoch: 63, Batch: 81,Loss: -2.071,Avg.Loss: -2.395,LR: 1.53E-04]Training epoch 63:  72%|███████▏  | 81/112 [00:01<00:00, 53.30it/s, Epoch: 63, Batch: 82,Loss: -2.102,Avg.Loss: -2.391,LR: 1.53E-04]Training epoch 63:  73%|███████▎  | 82/112 [00:01<00:00, 53.30it/s, Epoch: 63, Batch: 83,Loss: -2.888,Avg.Loss: -2.397,LR: 1.53E-04]Training epoch 63:  74%|███████▍  | 83/112 [00:01<00:00, 53.30it/s, Epoch: 63, Batch: 84,Loss: -2.688,Avg.Loss: -2.401,LR: 1.53E-04]Training epoch 63:  75%|███████▌  | 84/112 [00:01<00:00, 53.47it/s, Epoch: 63, Batch: 84,Loss: -2.688,Avg.Loss: -2.401,LR: 1.53E-04]Training epoch 63:  75%|███████▌  | 84/112 [00:01<00:00, 53.47it/s, Epoch: 63, Batch: 85,Loss: -2.563,Avg.Loss: -2.403,LR: 1.52E-04]Training epoch 63:  76%|███████▌  | 85/112 [00:01<00:00, 53.47it/s, Epoch: 63, Batch: 86,Loss: -2.376,Avg.Loss: -2.402,LR: 1.52E-04]Training epoch 63:  77%|███████▋  | 86/112 [00:01<00:00, 53.47it/s, Epoch: 63, Batch: 87,Loss: -3.043,Avg.Loss: -2.410,LR: 1.52E-04]Training epoch 63:  78%|███████▊  | 87/112 [00:01<00:00, 53.47it/s, Epoch: 63, Batch: 88,Loss: -2.511,Avg.Loss: -2.411,LR: 1.52E-04]Training epoch 63:  79%|███████▊  | 88/112 [00:01<00:00, 53.47it/s, Epoch: 63, Batch: 89,Loss: -2.116,Avg.Loss: -2.407,LR: 1.52E-04]Training epoch 63:  79%|███████▉  | 89/112 [00:01<00:00, 53.47it/s, Epoch: 63, Batch: 90,Loss: -2.523,Avg.Loss: -2.409,LR: 1.52E-04]Training epoch 63:  80%|████████  | 90/112 [00:01<00:00, 53.50it/s, Epoch: 63, Batch: 90,Loss: -2.523,Avg.Loss: -2.409,LR: 1.52E-04]Training epoch 63:  80%|████████  | 90/112 [00:01<00:00, 53.50it/s, Epoch: 63, Batch: 91,Loss: -2.856,Avg.Loss: -2.414,LR: 1.52E-04]Training epoch 63:  81%|████████▏ | 91/112 [00:01<00:00, 53.50it/s, Epoch: 63, Batch: 92,Loss: -2.655,Avg.Loss: -2.416,LR: 1.52E-04]Training epoch 63:  82%|████████▏ | 92/112 [00:01<00:00, 53.50it/s, Epoch: 63, Batch: 93,Loss: -1.811,Avg.Loss: -2.410,LR: 1.52E-04]Training epoch 63:  83%|████████▎ | 93/112 [00:01<00:00, 53.50it/s, Epoch: 63, Batch: 94,Loss: -2.272,Avg.Loss: -2.408,LR: 1.52E-04]Training epoch 63:  84%|████████▍ | 94/112 [00:01<00:00, 53.50it/s, Epoch: 63, Batch: 95,Loss: -2.743,Avg.Loss: -2.412,LR: 1.52E-04]Training epoch 63:  85%|████████▍ | 95/112 [00:01<00:00, 53.50it/s, Epoch: 63, Batch: 96,Loss: -2.659,Avg.Loss: -2.414,LR: 1.52E-04]Training epoch 63:  86%|████████▌ | 96/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 96,Loss: -2.659,Avg.Loss: -2.414,LR: 1.52E-04]Training epoch 63:  86%|████████▌ | 96/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 97,Loss: -1.928,Avg.Loss: -2.409,LR: 1.52E-04]Training epoch 63:  87%|████████▋ | 97/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 98,Loss: -2.278,Avg.Loss: -2.408,LR: 1.52E-04]Training epoch 63:  88%|████████▊ | 98/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 99,Loss: -3.076,Avg.Loss: -2.415,LR: 1.52E-04]Training epoch 63:  88%|████████▊ | 99/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 100,Loss: -3.063,Avg.Loss: -2.421,LR: 1.51E-04]Training epoch 63:  89%|████████▉ | 100/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 101,Loss: -2.703,Avg.Loss: -2.424,LR: 1.51E-04]Training epoch 63:  90%|█████████ | 101/112 [00:01<00:00, 53.45it/s, Epoch: 63, Batch: 102,Loss: -2.383,Avg.Loss: -2.424,LR: 1.51E-04]Training epoch 63:  91%|█████████ | 102/112 [00:01<00:00, 53.61it/s, Epoch: 63, Batch: 102,Loss: -2.383,Avg.Loss: -2.424,LR: 1.51E-04]Training epoch 63:  91%|█████████ | 102/112 [00:01<00:00, 53.61it/s, Epoch: 63, Batch: 103,Loss: -2.876,Avg.Loss: -2.428,LR: 1.51E-04]Training epoch 63:  92%|█████████▏| 103/112 [00:01<00:00, 53.61it/s, Epoch: 63, Batch: 104,Loss: -2.785,Avg.Loss: -2.432,LR: 1.51E-04]Training epoch 63:  93%|█████████▎| 104/112 [00:01<00:00, 53.61it/s, Epoch: 63, Batch: 105,Loss: -2.307,Avg.Loss: -2.430,LR: 1.51E-04]Training epoch 63:  94%|█████████▍| 105/112 [00:01<00:00, 53.61it/s, Epoch: 63, Batch: 106,Loss: -2.338,Avg.Loss: -2.429,LR: 1.51E-04]Training epoch 63:  95%|█████████▍| 106/112 [00:01<00:00, 53.61it/s, Epoch: 63, Batch: 107,Loss: -3.113,Avg.Loss: -2.436,LR: 1.51E-04]Training epoch 63:  96%|█████████▌| 107/112 [00:02<00:00, 53.61it/s, Epoch: 63, Batch: 108,Loss: -2.868,Avg.Loss: -2.440,LR: 1.51E-04]Training epoch 63:  96%|█████████▋| 108/112 [00:02<00:00, 53.54it/s, Epoch: 63, Batch: 108,Loss: -2.868,Avg.Loss: -2.440,LR: 1.51E-04]Training epoch 63:  96%|█████████▋| 108/112 [00:02<00:00, 53.54it/s, Epoch: 63, Batch: 109,Loss: -2.063,Avg.Loss: -2.436,LR: 1.51E-04]Training epoch 63:  97%|█████████▋| 109/112 [00:02<00:00, 53.54it/s, Epoch: 63, Batch: 110,Loss: -2.880,Avg.Loss: -2.440,LR: 1.51E-04]Training epoch 63:  98%|█████████▊| 110/112 [00:02<00:00, 53.54it/s, Epoch: 63, Batch: 111,Loss: -2.320,Avg.Loss: -2.439,LR: 1.51E-04]Training epoch 63:  99%|█████████▉| 111/112 [00:02<00:00, 53.54it/s, Epoch: 63, Batch: 112,Loss: -3.291,Avg.Loss: -2.447,LR: 1.51E-04]Training epoch 63: 100%|██████████| 112/112 [00:02<00:00, 53.55it/s, Epoch: 63, Batch: 112,Loss: -3.291,Avg.Loss: -2.447,LR: 1.51E-04]
Training epoch 64:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 64:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 64, Batch: 1,Loss: -2.715,Avg.Loss: -2.715,LR: 1.51E-04]Training epoch 64:   1%|          | 1/112 [00:00<00:04, 24.52it/s, Epoch: 64, Batch: 2,Loss: -2.743,Avg.Loss: -2.729,LR: 1.51E-04]Training epoch 64:   2%|▏         | 2/112 [00:00<00:03, 34.44it/s, Epoch: 64, Batch: 3,Loss: -3.192,Avg.Loss: -2.883,LR: 1.51E-04]Training epoch 64:   3%|▎         | 3/112 [00:00<00:02, 39.75it/s, Epoch: 64, Batch: 4,Loss: -3.230,Avg.Loss: -2.970,LR: 1.50E-04]Training epoch 64:   4%|▎         | 4/112 [00:00<00:02, 43.22it/s, Epoch: 64, Batch: 5,Loss: -2.495,Avg.Loss: -2.875,LR: 1.50E-04]Training epoch 64:   4%|▍         | 5/112 [00:00<00:02, 45.12it/s, Epoch: 64, Batch: 6,Loss: -3.088,Avg.Loss: -2.911,LR: 1.50E-04]Training epoch 64:   5%|▌         | 6/112 [00:00<00:01, 54.07it/s, Epoch: 64, Batch: 6,Loss: -3.088,Avg.Loss: -2.911,LR: 1.50E-04]Training epoch 64:   5%|▌         | 6/112 [00:00<00:01, 54.07it/s, Epoch: 64, Batch: 7,Loss: -2.848,Avg.Loss: -2.902,LR: 1.50E-04]Training epoch 64:   6%|▋         | 7/112 [00:00<00:01, 54.07it/s, Epoch: 64, Batch: 8,Loss: -2.867,Avg.Loss: -2.897,LR: 1.50E-04]Training epoch 64:   7%|▋         | 8/112 [00:00<00:01, 54.07it/s, Epoch: 64, Batch: 9,Loss: -2.462,Avg.Loss: -2.849,LR: 1.50E-04]Training epoch 64:   8%|▊         | 9/112 [00:00<00:01, 54.07it/s, Epoch: 64, Batch: 10,Loss: -2.222,Avg.Loss: -2.786,LR: 1.50E-04]Training epoch 64:   9%|▉         | 10/112 [00:00<00:01, 54.07it/s, Epoch: 64, Batch: 11,Loss: -3.123,Avg.Loss: -2.817,LR: 1.50E-04]Training epoch 64:  10%|▉         | 11/112 [00:00<00:01, 54.07it/s, Epoch: 64, Batch: 12,Loss: -2.994,Avg.Loss: -2.832,LR: 1.50E-04]Training epoch 64:  11%|█         | 12/112 [00:00<00:01, 53.25it/s, Epoch: 64, Batch: 12,Loss: -2.994,Avg.Loss: -2.832,LR: 1.50E-04]Training epoch 64:  11%|█         | 12/112 [00:00<00:01, 53.25it/s, Epoch: 64, Batch: 13,Loss: -2.650,Avg.Loss: -2.818,LR: 1.50E-04]Training epoch 64:  12%|█▏        | 13/112 [00:00<00:01, 53.25it/s, Epoch: 64, Batch: 14,Loss: -2.515,Avg.Loss: -2.796,LR: 1.50E-04]Training epoch 64:  12%|█▎        | 14/112 [00:00<00:01, 53.25it/s, Epoch: 64, Batch: 15,Loss: -2.039,Avg.Loss: -2.746,LR: 1.50E-04]Training epoch 64:  13%|█▎        | 15/112 [00:00<00:01, 53.25it/s, Epoch: 64, Batch: 16,Loss: -3.076,Avg.Loss: -2.766,LR: 1.50E-04]Training epoch 64:  14%|█▍        | 16/112 [00:00<00:01, 53.25it/s, Epoch: 64, Batch: 17,Loss: -2.620,Avg.Loss: -2.758,LR: 1.50E-04]Training epoch 64:  15%|█▌        | 17/112 [00:00<00:01, 53.25it/s, Epoch: 64, Batch: 18,Loss: -3.071,Avg.Loss: -2.775,LR: 1.50E-04]Training epoch 64:  16%|█▌        | 18/112 [00:00<00:01, 53.26it/s, Epoch: 64, Batch: 18,Loss: -3.071,Avg.Loss: -2.775,LR: 1.50E-04]Training epoch 64:  16%|█▌        | 18/112 [00:00<00:01, 53.26it/s, Epoch: 64, Batch: 19,Loss: -2.762,Avg.Loss: -2.774,LR: 1.49E-04]Training epoch 64:  17%|█▋        | 19/112 [00:00<00:01, 53.26it/s, Epoch: 64, Batch: 20,Loss: -2.309,Avg.Loss: -2.751,LR: 1.49E-04]Training epoch 64:  18%|█▊        | 20/112 [00:00<00:01, 53.26it/s, Epoch: 64, Batch: 21,Loss: -2.652,Avg.Loss: -2.747,LR: 1.49E-04]Training epoch 64:  19%|█▉        | 21/112 [00:00<00:01, 53.26it/s, Epoch: 64, Batch: 22,Loss: -2.635,Avg.Loss: -2.741,LR: 1.49E-04]Training epoch 64:  20%|█▉        | 22/112 [00:00<00:01, 53.26it/s, Epoch: 64, Batch: 23,Loss: -2.875,Avg.Loss: -2.747,LR: 1.49E-04]Training epoch 64:  21%|██        | 23/112 [00:00<00:01, 53.26it/s, Epoch: 64, Batch: 24,Loss: -3.166,Avg.Loss: -2.765,LR: 1.49E-04]Training epoch 64:  21%|██▏       | 24/112 [00:00<00:01, 50.76it/s, Epoch: 64, Batch: 24,Loss: -3.166,Avg.Loss: -2.765,LR: 1.49E-04]Training epoch 64:  21%|██▏       | 24/112 [00:00<00:01, 50.76it/s, Epoch: 64, Batch: 25,Loss: -3.094,Avg.Loss: -2.778,LR: 1.49E-04]Training epoch 64:  22%|██▏       | 25/112 [00:00<00:01, 50.76it/s, Epoch: 64, Batch: 26,Loss: -3.256,Avg.Loss: -2.796,LR: 1.49E-04]Training epoch 64:  23%|██▎       | 26/112 [00:00<00:01, 50.76it/s, Epoch: 64, Batch: 27,Loss: -2.538,Avg.Loss: -2.787,LR: 1.49E-04]Training epoch 64:  24%|██▍       | 27/112 [00:00<00:01, 50.76it/s, Epoch: 64, Batch: 28,Loss: -2.033,Avg.Loss: -2.760,LR: 1.49E-04]Training epoch 64:  25%|██▌       | 28/112 [00:00<00:01, 50.76it/s, Epoch: 64, Batch: 29,Loss: -2.588,Avg.Loss: -2.754,LR: 1.49E-04]Training epoch 64:  26%|██▌       | 29/112 [00:00<00:01, 50.76it/s, Epoch: 64, Batch: 30,Loss: -2.390,Avg.Loss: -2.742,LR: 1.49E-04]Training epoch 64:  27%|██▋       | 30/112 [00:00<00:01, 50.87it/s, Epoch: 64, Batch: 30,Loss: -2.390,Avg.Loss: -2.742,LR: 1.49E-04]Training epoch 64:  27%|██▋       | 30/112 [00:00<00:01, 50.87it/s, Epoch: 64, Batch: 31,Loss: -2.844,Avg.Loss: -2.745,LR: 1.49E-04]Training epoch 64:  28%|██▊       | 31/112 [00:00<00:01, 50.87it/s, Epoch: 64, Batch: 32,Loss: -3.218,Avg.Loss: -2.760,LR: 1.49E-04]Training epoch 64:  29%|██▊       | 32/112 [00:00<00:01, 50.87it/s, Epoch: 64, Batch: 33,Loss: -3.156,Avg.Loss: -2.772,LR: 1.49E-04]Training epoch 64:  29%|██▉       | 33/112 [00:00<00:01, 50.87it/s, Epoch: 64, Batch: 34,Loss: -2.757,Avg.Loss: -2.771,LR: 1.49E-04]Training epoch 64:  30%|███       | 34/112 [00:00<00:01, 50.87it/s, Epoch: 64, Batch: 35,Loss: -2.580,Avg.Loss: -2.766,LR: 1.48E-04]Training epoch 64:  31%|███▏      | 35/112 [00:00<00:01, 50.87it/s, Epoch: 64, Batch: 36,Loss: -2.699,Avg.Loss: -2.764,LR: 1.48E-04]Training epoch 64:  32%|███▏      | 36/112 [00:00<00:01, 51.49it/s, Epoch: 64, Batch: 36,Loss: -2.699,Avg.Loss: -2.764,LR: 1.48E-04]Training epoch 64:  32%|███▏      | 36/112 [00:00<00:01, 51.49it/s, Epoch: 64, Batch: 37,Loss: -2.395,Avg.Loss: -2.754,LR: 1.48E-04]Training epoch 64:  33%|███▎      | 37/112 [00:00<00:01, 51.49it/s, Epoch: 64, Batch: 38,Loss: -1.563,Avg.Loss: -2.723,LR: 1.48E-04]Training epoch 64:  34%|███▍      | 38/112 [00:00<00:01, 51.49it/s, Epoch: 64, Batch: 39,Loss: -1.818,Avg.Loss: -2.700,LR: 1.48E-04]Training epoch 64:  35%|███▍      | 39/112 [00:00<00:01, 51.49it/s, Epoch: 64, Batch: 40,Loss: -2.701,Avg.Loss: -2.700,LR: 1.48E-04]Training epoch 64:  36%|███▌      | 40/112 [00:00<00:01, 51.49it/s, Epoch: 64, Batch: 41,Loss: -2.430,Avg.Loss: -2.693,LR: 1.48E-04]Training epoch 64:  37%|███▋      | 41/112 [00:00<00:01, 51.49it/s, Epoch: 64, Batch: 42,Loss: -1.371,Avg.Loss: -2.661,LR: 1.48E-04]Training epoch 64:  38%|███▊      | 42/112 [00:00<00:01, 52.01it/s, Epoch: 64, Batch: 42,Loss: -1.371,Avg.Loss: -2.661,LR: 1.48E-04]Training epoch 64:  38%|███▊      | 42/112 [00:00<00:01, 52.01it/s, Epoch: 64, Batch: 43,Loss: -2.113,Avg.Loss: -2.649,LR: 1.48E-04]Training epoch 64:  38%|███▊      | 43/112 [00:00<00:01, 52.01it/s, Epoch: 64, Batch: 44,Loss: -2.955,Avg.Loss: -2.656,LR: 1.48E-04]Training epoch 64:  39%|███▉      | 44/112 [00:00<00:01, 52.01it/s, Epoch: 64, Batch: 45,Loss: -2.136,Avg.Loss: -2.644,LR: 1.48E-04]Training epoch 64:  40%|████      | 45/112 [00:00<00:01, 52.01it/s, Epoch: 64, Batch: 46,Loss: -0.952,Avg.Loss: -2.607,LR: 1.48E-04]Training epoch 64:  41%|████      | 46/112 [00:00<00:01, 52.01it/s, Epoch: 64, Batch: 47,Loss: -2.163,Avg.Loss: -2.598,LR: 1.48E-04]Training epoch 64:  42%|████▏     | 47/112 [00:00<00:01, 52.01it/s, Epoch: 64, Batch: 48,Loss: -2.740,Avg.Loss: -2.601,LR: 1.48E-04]Training epoch 64:  43%|████▎     | 48/112 [00:00<00:01, 52.48it/s, Epoch: 64, Batch: 48,Loss: -2.740,Avg.Loss: -2.601,LR: 1.48E-04]Training epoch 64:  43%|████▎     | 48/112 [00:00<00:01, 52.48it/s, Epoch: 64, Batch: 49,Loss: -2.505,Avg.Loss: -2.599,LR: 1.48E-04]Training epoch 64:  44%|████▍     | 49/112 [00:00<00:01, 52.48it/s, Epoch: 64, Batch: 50,Loss: -1.950,Avg.Loss: -2.586,LR: 1.48E-04]Training epoch 64:  45%|████▍     | 50/112 [00:00<00:01, 52.48it/s, Epoch: 64, Batch: 51,Loss: -2.340,Avg.Loss: -2.581,LR: 1.47E-04]Training epoch 64:  46%|████▌     | 51/112 [00:00<00:01, 52.48it/s, Epoch: 64, Batch: 52,Loss: -2.987,Avg.Loss: -2.589,LR: 1.47E-04]Training epoch 64:  46%|████▋     | 52/112 [00:01<00:01, 52.48it/s, Epoch: 64, Batch: 53,Loss: -2.417,Avg.Loss: -2.586,LR: 1.47E-04]Training epoch 64:  47%|████▋     | 53/112 [00:01<00:01, 52.48it/s, Epoch: 64, Batch: 54,Loss: -1.332,Avg.Loss: -2.562,LR: 1.47E-04]Training epoch 64:  48%|████▊     | 54/112 [00:01<00:01, 52.68it/s, Epoch: 64, Batch: 54,Loss: -1.332,Avg.Loss: -2.562,LR: 1.47E-04]Training epoch 64:  48%|████▊     | 54/112 [00:01<00:01, 52.68it/s, Epoch: 64, Batch: 55,Loss: -1.700,Avg.Loss: -2.547,LR: 1.47E-04]Training epoch 64:  49%|████▉     | 55/112 [00:01<00:01, 52.68it/s, Epoch: 64, Batch: 56,Loss: -2.268,Avg.Loss: -2.542,LR: 1.47E-04]Training epoch 64:  50%|█████     | 56/112 [00:01<00:01, 52.68it/s, Epoch: 64, Batch: 57,Loss: -2.724,Avg.Loss: -2.545,LR: 1.47E-04]Training epoch 64:  51%|█████     | 57/112 [00:01<00:01, 52.68it/s, Epoch: 64, Batch: 58,Loss: -2.335,Avg.Loss: -2.541,LR: 1.47E-04]Training epoch 64:  52%|█████▏    | 58/112 [00:01<00:01, 52.68it/s, Epoch: 64, Batch: 59,Loss: -2.459,Avg.Loss: -2.540,LR: 1.47E-04]Training epoch 64:  53%|█████▎    | 59/112 [00:01<00:01, 52.68it/s, Epoch: 64, Batch: 60,Loss: -3.141,Avg.Loss: -2.550,LR: 1.47E-04]Training epoch 64:  54%|█████▎    | 60/112 [00:01<00:00, 52.92it/s, Epoch: 64, Batch: 60,Loss: -3.141,Avg.Loss: -2.550,LR: 1.47E-04]Training epoch 64:  54%|█████▎    | 60/112 [00:01<00:00, 52.92it/s, Epoch: 64, Batch: 61,Loss: -3.072,Avg.Loss: -2.559,LR: 1.47E-04]Training epoch 64:  54%|█████▍    | 61/112 [00:01<00:00, 52.92it/s, Epoch: 64, Batch: 62,Loss: -2.819,Avg.Loss: -2.563,LR: 1.47E-04]Training epoch 64:  55%|█████▌    | 62/112 [00:01<00:00, 52.92it/s, Epoch: 64, Batch: 63,Loss: -3.276,Avg.Loss: -2.574,LR: 1.47E-04]Training epoch 64:  56%|█████▋    | 63/112 [00:01<00:00, 52.92it/s, Epoch: 64, Batch: 64,Loss: -2.743,Avg.Loss: -2.577,LR: 1.47E-04]Training epoch 64:  57%|█████▋    | 64/112 [00:01<00:00, 52.92it/s, Epoch: 64, Batch: 65,Loss: -3.158,Avg.Loss: -2.586,LR: 1.47E-04]Training epoch 64:  58%|█████▊    | 65/112 [00:01<00:00, 52.92it/s, Epoch: 64, Batch: 66,Loss: -2.874,Avg.Loss: -2.590,LR: 1.46E-04]Training epoch 64:  59%|█████▉    | 66/112 [00:01<00:00, 53.07it/s, Epoch: 64, Batch: 66,Loss: -2.874,Avg.Loss: -2.590,LR: 1.46E-04]Training epoch 64:  59%|█████▉    | 66/112 [00:01<00:00, 53.07it/s, Epoch: 64, Batch: 67,Loss: -3.043,Avg.Loss: -2.597,LR: 1.46E-04]Training epoch 64:  60%|█████▉    | 67/112 [00:01<00:00, 53.07it/s, Epoch: 64, Batch: 68,Loss: -2.809,Avg.Loss: -2.600,LR: 1.46E-04]Training epoch 64:  61%|██████    | 68/112 [00:01<00:00, 53.07it/s, Epoch: 64, Batch: 69,Loss: -2.873,Avg.Loss: -2.604,LR: 1.46E-04]Training epoch 64:  62%|██████▏   | 69/112 [00:01<00:00, 53.07it/s, Epoch: 64, Batch: 70,Loss: -2.915,Avg.Loss: -2.608,LR: 1.46E-04]Training epoch 64:  62%|██████▎   | 70/112 [00:01<00:00, 53.07it/s, Epoch: 64, Batch: 71,Loss: -2.793,Avg.Loss: -2.611,LR: 1.46E-04]Training epoch 64:  63%|██████▎   | 71/112 [00:01<00:00, 53.07it/s, Epoch: 64, Batch: 72,Loss: -3.254,Avg.Loss: -2.620,LR: 1.46E-04]Training epoch 64:  64%|██████▍   | 72/112 [00:01<00:00, 53.24it/s, Epoch: 64, Batch: 72,Loss: -3.254,Avg.Loss: -2.620,LR: 1.46E-04]Training epoch 64:  64%|██████▍   | 72/112 [00:01<00:00, 53.24it/s, Epoch: 64, Batch: 73,Loss: -2.973,Avg.Loss: -2.625,LR: 1.46E-04]Training epoch 64:  65%|██████▌   | 73/112 [00:01<00:00, 53.24it/s, Epoch: 64, Batch: 74,Loss: -3.163,Avg.Loss: -2.632,LR: 1.46E-04]Training epoch 64:  66%|██████▌   | 74/112 [00:01<00:00, 53.24it/s, Epoch: 64, Batch: 75,Loss: -2.868,Avg.Loss: -2.635,LR: 1.46E-04]Training epoch 64:  67%|██████▋   | 75/112 [00:01<00:00, 53.24it/s, Epoch: 64, Batch: 76,Loss: -3.045,Avg.Loss: -2.640,LR: 1.46E-04]Training epoch 64:  68%|██████▊   | 76/112 [00:01<00:00, 53.24it/s, Epoch: 64, Batch: 77,Loss: -3.138,Avg.Loss: -2.647,LR: 1.46E-04]Training epoch 64:  69%|██████▉   | 77/112 [00:01<00:00, 53.24it/s, Epoch: 64, Batch: 78,Loss: -3.059,Avg.Loss: -2.652,LR: 1.46E-04]Training epoch 64:  70%|██████▉   | 78/112 [00:01<00:00, 53.22it/s, Epoch: 64, Batch: 78,Loss: -3.059,Avg.Loss: -2.652,LR: 1.46E-04]Training epoch 64:  70%|██████▉   | 78/112 [00:01<00:00, 53.22it/s, Epoch: 64, Batch: 79,Loss: -2.911,Avg.Loss: -2.656,LR: 1.46E-04]Training epoch 64:  71%|███████   | 79/112 [00:01<00:00, 53.22it/s, Epoch: 64, Batch: 80,Loss: -3.146,Avg.Loss: -2.662,LR: 1.46E-04]Training epoch 64:  71%|███████▏  | 80/112 [00:01<00:00, 53.22it/s, Epoch: 64, Batch: 81,Loss: -3.088,Avg.Loss: -2.667,LR: 1.46E-04]Training epoch 64:  72%|███████▏  | 81/112 [00:01<00:00, 53.22it/s, Epoch: 64, Batch: 82,Loss: -3.282,Avg.Loss: -2.674,LR: 1.45E-04]Training epoch 64:  73%|███████▎  | 82/112 [00:01<00:00, 53.22it/s, Epoch: 64, Batch: 83,Loss: -3.093,Avg.Loss: -2.679,LR: 1.45E-04]Training epoch 64:  74%|███████▍  | 83/112 [00:01<00:00, 53.22it/s, Epoch: 64, Batch: 84,Loss: -2.881,Avg.Loss: -2.682,LR: 1.45E-04]Training epoch 64:  75%|███████▌  | 84/112 [00:01<00:00, 52.25it/s, Epoch: 64, Batch: 84,Loss: -2.881,Avg.Loss: -2.682,LR: 1.45E-04]Training epoch 64:  75%|███████▌  | 84/112 [00:01<00:00, 52.25it/s, Epoch: 64, Batch: 85,Loss: -2.638,Avg.Loss: -2.681,LR: 1.45E-04]Training epoch 64:  76%|███████▌  | 85/112 [00:01<00:00, 52.25it/s, Epoch: 64, Batch: 86,Loss: -2.927,Avg.Loss: -2.684,LR: 1.45E-04]Training epoch 64:  77%|███████▋  | 86/112 [00:01<00:00, 52.25it/s, Epoch: 64, Batch: 87,Loss: -2.796,Avg.Loss: -2.685,LR: 1.45E-04]Training epoch 64:  78%|███████▊  | 87/112 [00:01<00:00, 52.25it/s, Epoch: 64, Batch: 88,Loss: -2.901,Avg.Loss: -2.688,LR: 1.45E-04]Training epoch 64:  79%|███████▊  | 88/112 [00:01<00:00, 52.25it/s, Epoch: 64, Batch: 89,Loss: -3.222,Avg.Loss: -2.694,LR: 1.45E-04]Training epoch 64:  79%|███████▉  | 89/112 [00:01<00:00, 52.25it/s, Epoch: 64, Batch: 90,Loss: -2.614,Avg.Loss: -2.693,LR: 1.45E-04]Training epoch 64:  80%|████████  | 90/112 [00:01<00:00, 52.18it/s, Epoch: 64, Batch: 90,Loss: -2.614,Avg.Loss: -2.693,LR: 1.45E-04]Training epoch 64:  80%|████████  | 90/112 [00:01<00:00, 52.18it/s, Epoch: 64, Batch: 91,Loss: -2.482,Avg.Loss: -2.691,LR: 1.45E-04]Training epoch 64:  81%|████████▏ | 91/112 [00:01<00:00, 52.18it/s, Epoch: 64, Batch: 92,Loss: -3.517,Avg.Loss: -2.700,LR: 1.45E-04]Training epoch 64:  82%|████████▏ | 92/112 [00:01<00:00, 52.18it/s, Epoch: 64, Batch: 93,Loss: -2.594,Avg.Loss: -2.699,LR: 1.45E-04]Training epoch 64:  83%|████████▎ | 93/112 [00:01<00:00, 52.18it/s, Epoch: 64, Batch: 94,Loss: -2.209,Avg.Loss: -2.693,LR: 1.45E-04]Training epoch 64:  84%|████████▍ | 94/112 [00:01<00:00, 52.18it/s, Epoch: 64, Batch: 95,Loss: -2.837,Avg.Loss: -2.695,LR: 1.45E-04]Training epoch 64:  85%|████████▍ | 95/112 [00:01<00:00, 52.18it/s, Epoch: 64, Batch: 96,Loss: -2.955,Avg.Loss: -2.698,LR: 1.45E-04]Training epoch 64:  86%|████████▌ | 96/112 [00:01<00:00, 52.53it/s, Epoch: 64, Batch: 96,Loss: -2.955,Avg.Loss: -2.698,LR: 1.45E-04]Training epoch 64:  86%|████████▌ | 96/112 [00:01<00:00, 52.53it/s, Epoch: 64, Batch: 97,Loss: -3.119,Avg.Loss: -2.702,LR: 1.45E-04]Training epoch 64:  87%|████████▋ | 97/112 [00:01<00:00, 52.53it/s, Epoch: 64, Batch: 98,Loss: -3.195,Avg.Loss: -2.707,LR: 1.44E-04]Training epoch 64:  88%|████████▊ | 98/112 [00:01<00:00, 52.53it/s, Epoch: 64, Batch: 99,Loss: -2.402,Avg.Loss: -2.704,LR: 1.44E-04]Training epoch 64:  88%|████████▊ | 99/112 [00:01<00:00, 52.53it/s, Epoch: 64, Batch: 100,Loss: -2.467,Avg.Loss: -2.702,LR: 1.44E-04]Training epoch 64:  89%|████████▉ | 100/112 [00:01<00:00, 52.53it/s, Epoch: 64, Batch: 101,Loss: -3.006,Avg.Loss: -2.705,LR: 1.44E-04]Training epoch 64:  90%|█████████ | 101/112 [00:01<00:00, 52.53it/s, Epoch: 64, Batch: 102,Loss: -3.141,Avg.Loss: -2.709,LR: 1.44E-04]Training epoch 64:  91%|█████████ | 102/112 [00:01<00:00, 52.76it/s, Epoch: 64, Batch: 102,Loss: -3.141,Avg.Loss: -2.709,LR: 1.44E-04]Training epoch 64:  91%|█████████ | 102/112 [00:01<00:00, 52.76it/s, Epoch: 64, Batch: 103,Loss: -2.904,Avg.Loss: -2.711,LR: 1.44E-04]Training epoch 64:  92%|█████████▏| 103/112 [00:01<00:00, 52.76it/s, Epoch: 64, Batch: 104,Loss: -3.099,Avg.Loss: -2.714,LR: 1.44E-04]Training epoch 64:  93%|█████████▎| 104/112 [00:01<00:00, 52.76it/s, Epoch: 64, Batch: 105,Loss: -3.074,Avg.Loss: -2.718,LR: 1.44E-04]Training epoch 64:  94%|█████████▍| 105/112 [00:02<00:00, 52.76it/s, Epoch: 64, Batch: 106,Loss: -2.337,Avg.Loss: -2.714,LR: 1.44E-04]Training epoch 64:  95%|█████████▍| 106/112 [00:02<00:00, 52.76it/s, Epoch: 64, Batch: 107,Loss: -2.838,Avg.Loss: -2.715,LR: 1.44E-04]Training epoch 64:  96%|█████████▌| 107/112 [00:02<00:00, 52.76it/s, Epoch: 64, Batch: 108,Loss: -2.244,Avg.Loss: -2.711,LR: 1.44E-04]Training epoch 64:  96%|█████████▋| 108/112 [00:02<00:00, 53.10it/s, Epoch: 64, Batch: 108,Loss: -2.244,Avg.Loss: -2.711,LR: 1.44E-04]Training epoch 64:  96%|█████████▋| 108/112 [00:02<00:00, 53.10it/s, Epoch: 64, Batch: 109,Loss: -2.503,Avg.Loss: -2.709,LR: 1.44E-04]Training epoch 64:  97%|█████████▋| 109/112 [00:02<00:00, 53.10it/s, Epoch: 64, Batch: 110,Loss: -2.877,Avg.Loss: -2.711,LR: 1.44E-04]Training epoch 64:  98%|█████████▊| 110/112 [00:02<00:00, 53.10it/s, Epoch: 64, Batch: 111,Loss: -3.010,Avg.Loss: -2.713,LR: 1.44E-04]Training epoch 64:  99%|█████████▉| 111/112 [00:02<00:00, 53.10it/s, Epoch: 64, Batch: 112,Loss: -3.154,Avg.Loss: -2.717,LR: 1.44E-04]Training epoch 64: 100%|██████████| 112/112 [00:02<00:00, 52.66it/s, Epoch: 64, Batch: 112,Loss: -3.154,Avg.Loss: -2.717,LR: 1.44E-04]
Training epoch 65:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 65:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 65, Batch: 1,Loss: -3.126,Avg.Loss: -3.126,LR: 1.43E-04]Training epoch 65:   1%|          | 1/112 [00:00<00:04, 26.60it/s, Epoch: 65, Batch: 2,Loss: -2.932,Avg.Loss: -3.029,LR: 1.43E-04]Training epoch 65:   2%|▏         | 2/112 [00:00<00:02, 39.15it/s, Epoch: 65, Batch: 3,Loss: -3.044,Avg.Loss: -3.034,LR: 1.43E-04]Training epoch 65:   3%|▎         | 3/112 [00:00<00:02, 44.37it/s, Epoch: 65, Batch: 4,Loss: -3.162,Avg.Loss: -3.066,LR: 1.43E-04]Training epoch 65:   4%|▎         | 4/112 [00:00<00:02, 46.91it/s, Epoch: 65, Batch: 5,Loss: -3.209,Avg.Loss: -3.095,LR: 1.43E-04]Training epoch 65:   4%|▍         | 5/112 [00:00<00:02, 48.02it/s, Epoch: 65, Batch: 6,Loss: -3.248,Avg.Loss: -3.120,LR: 1.43E-04]Training epoch 65:   5%|▌         | 6/112 [00:00<00:01, 57.51it/s, Epoch: 65, Batch: 6,Loss: -3.248,Avg.Loss: -3.120,LR: 1.43E-04]Training epoch 65:   5%|▌         | 6/112 [00:00<00:01, 57.51it/s, Epoch: 65, Batch: 7,Loss: -2.753,Avg.Loss: -3.068,LR: 1.43E-04]Training epoch 65:   6%|▋         | 7/112 [00:00<00:01, 57.51it/s, Epoch: 65, Batch: 8,Loss: -2.928,Avg.Loss: -3.050,LR: 1.43E-04]Training epoch 65:   7%|▋         | 8/112 [00:00<00:01, 57.51it/s, Epoch: 65, Batch: 9,Loss: -3.430,Avg.Loss: -3.093,LR: 1.43E-04]Training epoch 65:   8%|▊         | 9/112 [00:00<00:01, 57.51it/s, Epoch: 65, Batch: 10,Loss: -3.193,Avg.Loss: -3.103,LR: 1.43E-04]Training epoch 65:   9%|▉         | 10/112 [00:00<00:01, 57.51it/s, Epoch: 65, Batch: 11,Loss: -3.151,Avg.Loss: -3.107,LR: 1.43E-04]Training epoch 65:  10%|▉         | 11/112 [00:00<00:01, 57.51it/s, Epoch: 65, Batch: 12,Loss: -3.105,Avg.Loss: -3.107,LR: 1.43E-04]Training epoch 65:  11%|█         | 12/112 [00:00<00:01, 54.74it/s, Epoch: 65, Batch: 12,Loss: -3.105,Avg.Loss: -3.107,LR: 1.43E-04]Training epoch 65:  11%|█         | 12/112 [00:00<00:01, 54.74it/s, Epoch: 65, Batch: 13,Loss: -3.130,Avg.Loss: -3.109,LR: 1.43E-04]Training epoch 65:  12%|█▏        | 13/112 [00:00<00:01, 54.74it/s, Epoch: 65, Batch: 14,Loss: -3.036,Avg.Loss: -3.103,LR: 1.43E-04]Training epoch 65:  12%|█▎        | 14/112 [00:00<00:01, 54.74it/s, Epoch: 65, Batch: 15,Loss: -2.413,Avg.Loss: -3.057,LR: 1.43E-04]Training epoch 65:  13%|█▎        | 15/112 [00:00<00:01, 54.74it/s, Epoch: 65, Batch: 16,Loss: -2.693,Avg.Loss: -3.035,LR: 1.43E-04]Training epoch 65:  14%|█▍        | 16/112 [00:00<00:01, 54.74it/s, Epoch: 65, Batch: 17,Loss: -2.483,Avg.Loss: -3.002,LR: 1.42E-04]Training epoch 65:  15%|█▌        | 17/112 [00:00<00:01, 54.74it/s, Epoch: 65, Batch: 18,Loss: -3.237,Avg.Loss: -3.015,LR: 1.42E-04]Training epoch 65:  16%|█▌        | 18/112 [00:00<00:01, 53.68it/s, Epoch: 65, Batch: 18,Loss: -3.237,Avg.Loss: -3.015,LR: 1.42E-04]Training epoch 65:  16%|█▌        | 18/112 [00:00<00:01, 53.68it/s, Epoch: 65, Batch: 19,Loss: -3.049,Avg.Loss: -3.017,LR: 1.42E-04]Training epoch 65:  17%|█▋        | 19/112 [00:00<00:01, 53.68it/s, Epoch: 65, Batch: 20,Loss: -3.140,Avg.Loss: -3.023,LR: 1.42E-04]Training epoch 65:  18%|█▊        | 20/112 [00:00<00:01, 53.68it/s, Epoch: 65, Batch: 21,Loss: -2.490,Avg.Loss: -2.998,LR: 1.42E-04]Training epoch 65:  19%|█▉        | 21/112 [00:00<00:01, 53.68it/s, Epoch: 65, Batch: 22,Loss: -2.804,Avg.Loss: -2.989,LR: 1.42E-04]Training epoch 65:  20%|█▉        | 22/112 [00:00<00:01, 53.68it/s, Epoch: 65, Batch: 23,Loss: -2.984,Avg.Loss: -2.989,LR: 1.42E-04]Training epoch 65:  21%|██        | 23/112 [00:00<00:01, 53.68it/s, Epoch: 65, Batch: 24,Loss: -3.195,Avg.Loss: -2.997,LR: 1.42E-04]Training epoch 65:  21%|██▏       | 24/112 [00:00<00:01, 52.69it/s, Epoch: 65, Batch: 24,Loss: -3.195,Avg.Loss: -2.997,LR: 1.42E-04]Training epoch 65:  21%|██▏       | 24/112 [00:00<00:01, 52.69it/s, Epoch: 65, Batch: 25,Loss: -2.661,Avg.Loss: -2.984,LR: 1.42E-04]Training epoch 65:  22%|██▏       | 25/112 [00:00<00:01, 52.69it/s, Epoch: 65, Batch: 26,Loss: -2.398,Avg.Loss: -2.961,LR: 1.42E-04]Training epoch 65:  23%|██▎       | 26/112 [00:00<00:01, 52.69it/s, Epoch: 65, Batch: 27,Loss: -2.431,Avg.Loss: -2.942,LR: 1.42E-04]Training epoch 65:  24%|██▍       | 27/112 [00:00<00:01, 52.69it/s, Epoch: 65, Batch: 28,Loss: -2.275,Avg.Loss: -2.918,LR: 1.42E-04]Training epoch 65:  25%|██▌       | 28/112 [00:00<00:01, 52.69it/s, Epoch: 65, Batch: 29,Loss: -2.264,Avg.Loss: -2.895,LR: 1.42E-04]Training epoch 65:  26%|██▌       | 29/112 [00:00<00:01, 52.69it/s, Epoch: 65, Batch: 30,Loss: -1.800,Avg.Loss: -2.859,LR: 1.42E-04]Training epoch 65:  27%|██▋       | 30/112 [00:00<00:01, 52.15it/s, Epoch: 65, Batch: 30,Loss: -1.800,Avg.Loss: -2.859,LR: 1.42E-04]Training epoch 65:  27%|██▋       | 30/112 [00:00<00:01, 52.15it/s, Epoch: 65, Batch: 31,Loss: -2.565,Avg.Loss: -2.849,LR: 1.42E-04]Training epoch 65:  28%|██▊       | 31/112 [00:00<00:01, 52.15it/s, Epoch: 65, Batch: 32,Loss: -3.045,Avg.Loss: -2.855,LR: 1.42E-04]Training epoch 65:  29%|██▊       | 32/112 [00:00<00:01, 52.15it/s, Epoch: 65, Batch: 33,Loss: -2.828,Avg.Loss: -2.855,LR: 1.41E-04]Training epoch 65:  29%|██▉       | 33/112 [00:00<00:01, 52.15it/s, Epoch: 65, Batch: 34,Loss: -3.320,Avg.Loss: -2.868,LR: 1.41E-04]Training epoch 65:  30%|███       | 34/112 [00:00<00:01, 52.15it/s, Epoch: 65, Batch: 35,Loss: -2.893,Avg.Loss: -2.869,LR: 1.41E-04]Training epoch 65:  31%|███▏      | 35/112 [00:00<00:01, 52.15it/s, Epoch: 65, Batch: 36,Loss: -2.451,Avg.Loss: -2.857,LR: 1.41E-04]Training epoch 65:  32%|███▏      | 36/112 [00:00<00:01, 52.57it/s, Epoch: 65, Batch: 36,Loss: -2.451,Avg.Loss: -2.857,LR: 1.41E-04]Training epoch 65:  32%|███▏      | 36/112 [00:00<00:01, 52.57it/s, Epoch: 65, Batch: 37,Loss: -3.397,Avg.Loss: -2.872,LR: 1.41E-04]Training epoch 65:  33%|███▎      | 37/112 [00:00<00:01, 52.57it/s, Epoch: 65, Batch: 38,Loss: -2.199,Avg.Loss: -2.854,LR: 1.41E-04]Training epoch 65:  34%|███▍      | 38/112 [00:00<00:01, 52.57it/s, Epoch: 65, Batch: 39,Loss: -2.366,Avg.Loss: -2.842,LR: 1.41E-04]Training epoch 65:  35%|███▍      | 39/112 [00:00<00:01, 52.57it/s, Epoch: 65, Batch: 40,Loss: -3.254,Avg.Loss: -2.852,LR: 1.41E-04]Training epoch 65:  36%|███▌      | 40/112 [00:00<00:01, 52.57it/s, Epoch: 65, Batch: 41,Loss: -2.395,Avg.Loss: -2.841,LR: 1.41E-04]Training epoch 65:  37%|███▋      | 41/112 [00:00<00:01, 52.57it/s, Epoch: 65, Batch: 42,Loss: -3.043,Avg.Loss: -2.846,LR: 1.41E-04]Training epoch 65:  38%|███▊      | 42/112 [00:00<00:01, 52.91it/s, Epoch: 65, Batch: 42,Loss: -3.043,Avg.Loss: -2.846,LR: 1.41E-04]Training epoch 65:  38%|███▊      | 42/112 [00:00<00:01, 52.91it/s, Epoch: 65, Batch: 43,Loss: -2.979,Avg.Loss: -2.849,LR: 1.41E-04]Training epoch 65:  38%|███▊      | 43/112 [00:00<00:01, 52.91it/s, Epoch: 65, Batch: 44,Loss: -3.006,Avg.Loss: -2.852,LR: 1.41E-04]Training epoch 65:  39%|███▉      | 44/112 [00:00<00:01, 52.91it/s, Epoch: 65, Batch: 45,Loss: -2.585,Avg.Loss: -2.846,LR: 1.41E-04]Training epoch 65:  40%|████      | 45/112 [00:00<00:01, 52.91it/s, Epoch: 65, Batch: 46,Loss: -3.241,Avg.Loss: -2.855,LR: 1.41E-04]Training epoch 65:  41%|████      | 46/112 [00:00<00:01, 52.91it/s, Epoch: 65, Batch: 47,Loss: -2.751,Avg.Loss: -2.853,LR: 1.41E-04]Training epoch 65:  42%|████▏     | 47/112 [00:00<00:01, 52.91it/s, Epoch: 65, Batch: 48,Loss: -2.200,Avg.Loss: -2.839,LR: 1.41E-04]Training epoch 65:  43%|████▎     | 48/112 [00:00<00:01, 53.33it/s, Epoch: 65, Batch: 48,Loss: -2.200,Avg.Loss: -2.839,LR: 1.41E-04]Training epoch 65:  43%|████▎     | 48/112 [00:00<00:01, 53.33it/s, Epoch: 65, Batch: 49,Loss: -2.856,Avg.Loss: -2.839,LR: 1.40E-04]Training epoch 65:  44%|████▍     | 49/112 [00:00<00:01, 53.33it/s, Epoch: 65, Batch: 50,Loss: -3.147,Avg.Loss: -2.846,LR: 1.40E-04]Training epoch 65:  45%|████▍     | 50/112 [00:00<00:01, 53.33it/s, Epoch: 65, Batch: 51,Loss: -3.185,Avg.Loss: -2.852,LR: 1.40E-04]Training epoch 65:  46%|████▌     | 51/112 [00:00<00:01, 53.33it/s, Epoch: 65, Batch: 52,Loss: -3.293,Avg.Loss: -2.861,LR: 1.40E-04]Training epoch 65:  46%|████▋     | 52/112 [00:00<00:01, 53.33it/s, Epoch: 65, Batch: 53,Loss: -2.965,Avg.Loss: -2.863,LR: 1.40E-04]Training epoch 65:  47%|████▋     | 53/112 [00:01<00:01, 53.33it/s, Epoch: 65, Batch: 54,Loss: -3.207,Avg.Loss: -2.869,LR: 1.40E-04]Training epoch 65:  48%|████▊     | 54/112 [00:01<00:01, 53.50it/s, Epoch: 65, Batch: 54,Loss: -3.207,Avg.Loss: -2.869,LR: 1.40E-04]Training epoch 65:  48%|████▊     | 54/112 [00:01<00:01, 53.50it/s, Epoch: 65, Batch: 55,Loss: -3.360,Avg.Loss: -2.878,LR: 1.40E-04]Training epoch 65:  49%|████▉     | 55/112 [00:01<00:01, 53.50it/s, Epoch: 65, Batch: 56,Loss: -3.167,Avg.Loss: -2.883,LR: 1.40E-04]Training epoch 65:  50%|█████     | 56/112 [00:01<00:01, 53.50it/s, Epoch: 65, Batch: 57,Loss: -3.261,Avg.Loss: -2.890,LR: 1.40E-04]Training epoch 65:  51%|█████     | 57/112 [00:01<00:01, 53.50it/s, Epoch: 65, Batch: 58,Loss: -3.011,Avg.Loss: -2.892,LR: 1.40E-04]Training epoch 65:  52%|█████▏    | 58/112 [00:01<00:01, 53.50it/s, Epoch: 65, Batch: 59,Loss: -3.096,Avg.Loss: -2.895,LR: 1.40E-04]Training epoch 65:  53%|█████▎    | 59/112 [00:01<00:00, 53.50it/s, Epoch: 65, Batch: 60,Loss: -3.242,Avg.Loss: -2.901,LR: 1.40E-04]Training epoch 65:  54%|█████▎    | 60/112 [00:01<00:00, 53.35it/s, Epoch: 65, Batch: 60,Loss: -3.242,Avg.Loss: -2.901,LR: 1.40E-04]Training epoch 65:  54%|█████▎    | 60/112 [00:01<00:00, 53.35it/s, Epoch: 65, Batch: 61,Loss: -3.323,Avg.Loss: -2.908,LR: 1.40E-04]Training epoch 65:  54%|█████▍    | 61/112 [00:01<00:00, 53.35it/s, Epoch: 65, Batch: 62,Loss: -2.657,Avg.Loss: -2.904,LR: 1.40E-04]Training epoch 65:  55%|█████▌    | 62/112 [00:01<00:00, 53.35it/s, Epoch: 65, Batch: 63,Loss: -2.232,Avg.Loss: -2.893,LR: 1.40E-04]Training epoch 65:  56%|█████▋    | 63/112 [00:01<00:00, 53.35it/s, Epoch: 65, Batch: 64,Loss: -2.937,Avg.Loss: -2.894,LR: 1.40E-04]Training epoch 65:  57%|█████▋    | 64/112 [00:01<00:00, 53.35it/s, Epoch: 65, Batch: 65,Loss: -2.643,Avg.Loss: -2.890,LR: 1.39E-04]Training epoch 65:  58%|█████▊    | 65/112 [00:01<00:00, 53.35it/s, Epoch: 65, Batch: 66,Loss: -2.242,Avg.Loss: -2.880,LR: 1.39E-04]Training epoch 65:  59%|█████▉    | 66/112 [00:01<00:00, 53.44it/s, Epoch: 65, Batch: 66,Loss: -2.242,Avg.Loss: -2.880,LR: 1.39E-04]Training epoch 65:  59%|█████▉    | 66/112 [00:01<00:00, 53.44it/s, Epoch: 65, Batch: 67,Loss: -2.298,Avg.Loss: -2.872,LR: 1.39E-04]Training epoch 65:  60%|█████▉    | 67/112 [00:01<00:00, 53.44it/s, Epoch: 65, Batch: 68,Loss: -3.366,Avg.Loss: -2.879,LR: 1.39E-04]Training epoch 65:  61%|██████    | 68/112 [00:01<00:00, 53.44it/s, Epoch: 65, Batch: 69,Loss: -2.480,Avg.Loss: -2.873,LR: 1.39E-04]Training epoch 65:  62%|██████▏   | 69/112 [00:01<00:00, 53.44it/s, Epoch: 65, Batch: 70,Loss: -2.870,Avg.Loss: -2.873,LR: 1.39E-04]Training epoch 65:  62%|██████▎   | 70/112 [00:01<00:00, 53.44it/s, Epoch: 65, Batch: 71,Loss: -3.422,Avg.Loss: -2.881,LR: 1.39E-04]Training epoch 65:  63%|██████▎   | 71/112 [00:01<00:00, 53.44it/s, Epoch: 65, Batch: 72,Loss: -3.118,Avg.Loss: -2.884,LR: 1.39E-04]Training epoch 65:  64%|██████▍   | 72/112 [00:01<00:00, 53.50it/s, Epoch: 65, Batch: 72,Loss: -3.118,Avg.Loss: -2.884,LR: 1.39E-04]Training epoch 65:  64%|██████▍   | 72/112 [00:01<00:00, 53.50it/s, Epoch: 65, Batch: 73,Loss: -3.166,Avg.Loss: -2.888,LR: 1.39E-04]Training epoch 65:  65%|██████▌   | 73/112 [00:01<00:00, 53.50it/s, Epoch: 65, Batch: 74,Loss: -2.739,Avg.Loss: -2.886,LR: 1.39E-04]Training epoch 65:  66%|██████▌   | 74/112 [00:01<00:00, 53.50it/s, Epoch: 65, Batch: 75,Loss: -2.571,Avg.Loss: -2.882,LR: 1.39E-04]Training epoch 65:  67%|██████▋   | 75/112 [00:01<00:00, 53.50it/s, Epoch: 65, Batch: 76,Loss: -3.220,Avg.Loss: -2.886,LR: 1.39E-04]Training epoch 65:  68%|██████▊   | 76/112 [00:01<00:00, 53.50it/s, Epoch: 65, Batch: 77,Loss: -2.698,Avg.Loss: -2.884,LR: 1.39E-04]Training epoch 65:  69%|██████▉   | 77/112 [00:01<00:00, 53.50it/s, Epoch: 65, Batch: 78,Loss: -3.091,Avg.Loss: -2.886,LR: 1.39E-04]Training epoch 65:  70%|██████▉   | 78/112 [00:01<00:00, 53.64it/s, Epoch: 65, Batch: 78,Loss: -3.091,Avg.Loss: -2.886,LR: 1.39E-04]Training epoch 65:  70%|██████▉   | 78/112 [00:01<00:00, 53.64it/s, Epoch: 65, Batch: 79,Loss: -3.050,Avg.Loss: -2.889,LR: 1.39E-04]Training epoch 65:  71%|███████   | 79/112 [00:01<00:00, 53.64it/s, Epoch: 65, Batch: 80,Loss: -3.254,Avg.Loss: -2.893,LR: 1.39E-04]Training epoch 65:  71%|███████▏  | 80/112 [00:01<00:00, 53.64it/s, Epoch: 65, Batch: 81,Loss: -3.107,Avg.Loss: -2.896,LR: 1.38E-04]Training epoch 65:  72%|███████▏  | 81/112 [00:01<00:00, 53.64it/s, Epoch: 65, Batch: 82,Loss: -3.158,Avg.Loss: -2.899,LR: 1.38E-04]Training epoch 65:  73%|███████▎  | 82/112 [00:01<00:00, 53.64it/s, Epoch: 65, Batch: 83,Loss: -3.256,Avg.Loss: -2.903,LR: 1.38E-04]Training epoch 65:  74%|███████▍  | 83/112 [00:01<00:00, 53.64it/s, Epoch: 65, Batch: 84,Loss: -3.204,Avg.Loss: -2.907,LR: 1.38E-04]Training epoch 65:  75%|███████▌  | 84/112 [00:01<00:00, 53.28it/s, Epoch: 65, Batch: 84,Loss: -3.204,Avg.Loss: -2.907,LR: 1.38E-04]Training epoch 65:  75%|███████▌  | 84/112 [00:01<00:00, 53.28it/s, Epoch: 65, Batch: 85,Loss: -3.619,Avg.Loss: -2.915,LR: 1.38E-04]Training epoch 65:  76%|███████▌  | 85/112 [00:01<00:00, 53.28it/s, Epoch: 65, Batch: 86,Loss: -3.681,Avg.Loss: -2.924,LR: 1.38E-04]Training epoch 65:  77%|███████▋  | 86/112 [00:01<00:00, 53.28it/s, Epoch: 65, Batch: 87,Loss: -3.114,Avg.Loss: -2.926,LR: 1.38E-04]Training epoch 65:  78%|███████▊  | 87/112 [00:01<00:00, 53.28it/s, Epoch: 65, Batch: 88,Loss: -2.854,Avg.Loss: -2.925,LR: 1.38E-04]Training epoch 65:  79%|███████▊  | 88/112 [00:01<00:00, 53.28it/s, Epoch: 65, Batch: 89,Loss: -3.014,Avg.Loss: -2.926,LR: 1.38E-04]Training epoch 65:  79%|███████▉  | 89/112 [00:01<00:00, 53.28it/s, Epoch: 65, Batch: 90,Loss: -3.583,Avg.Loss: -2.934,LR: 1.38E-04]Training epoch 65:  80%|████████  | 90/112 [00:01<00:00, 53.61it/s, Epoch: 65, Batch: 90,Loss: -3.583,Avg.Loss: -2.934,LR: 1.38E-04]Training epoch 65:  80%|████████  | 90/112 [00:01<00:00, 53.61it/s, Epoch: 65, Batch: 91,Loss: -2.617,Avg.Loss: -2.930,LR: 1.38E-04]Training epoch 65:  81%|████████▏ | 91/112 [00:01<00:00, 53.61it/s, Epoch: 65, Batch: 92,Loss: -3.069,Avg.Loss: -2.932,LR: 1.38E-04]Training epoch 65:  82%|████████▏ | 92/112 [00:01<00:00, 53.61it/s, Epoch: 65, Batch: 93,Loss: -3.031,Avg.Loss: -2.933,LR: 1.38E-04]Training epoch 65:  83%|████████▎ | 93/112 [00:01<00:00, 53.61it/s, Epoch: 65, Batch: 94,Loss: -2.153,Avg.Loss: -2.925,LR: 1.38E-04]Training epoch 65:  84%|████████▍ | 94/112 [00:01<00:00, 53.61it/s, Epoch: 65, Batch: 95,Loss: -1.738,Avg.Loss: -2.912,LR: 1.38E-04]Training epoch 65:  85%|████████▍ | 95/112 [00:01<00:00, 53.61it/s, Epoch: 65, Batch: 96,Loss: -2.629,Avg.Loss: -2.909,LR: 1.38E-04]Training epoch 65:  86%|████████▌ | 96/112 [00:01<00:00, 54.23it/s, Epoch: 65, Batch: 96,Loss: -2.629,Avg.Loss: -2.909,LR: 1.38E-04]Training epoch 65:  86%|████████▌ | 96/112 [00:01<00:00, 54.23it/s, Epoch: 65, Batch: 97,Loss: -2.797,Avg.Loss: -2.908,LR: 1.37E-04]Training epoch 65:  87%|████████▋ | 97/112 [00:01<00:00, 54.23it/s, Epoch: 65, Batch: 98,Loss: -2.536,Avg.Loss: -2.904,LR: 1.37E-04]Training epoch 65:  88%|████████▊ | 98/112 [00:01<00:00, 54.23it/s, Epoch: 65, Batch: 99,Loss: -3.088,Avg.Loss: -2.906,LR: 1.37E-04]Training epoch 65:  88%|████████▊ | 99/112 [00:01<00:00, 54.23it/s, Epoch: 65, Batch: 100,Loss: -3.124,Avg.Loss: -2.908,LR: 1.37E-04]Training epoch 65:  89%|████████▉ | 100/112 [00:01<00:00, 54.23it/s, Epoch: 65, Batch: 101,Loss: -3.031,Avg.Loss: -2.909,LR: 1.37E-04]Training epoch 65:  90%|█████████ | 101/112 [00:01<00:00, 54.23it/s, Epoch: 65, Batch: 102,Loss: -3.276,Avg.Loss: -2.913,LR: 1.37E-04]Training epoch 65:  91%|█████████ | 102/112 [00:01<00:00, 54.01it/s, Epoch: 65, Batch: 102,Loss: -3.276,Avg.Loss: -2.913,LR: 1.37E-04]Training epoch 65:  91%|█████████ | 102/112 [00:01<00:00, 54.01it/s, Epoch: 65, Batch: 103,Loss: -3.190,Avg.Loss: -2.916,LR: 1.37E-04]Training epoch 65:  92%|█████████▏| 103/112 [00:01<00:00, 54.01it/s, Epoch: 65, Batch: 104,Loss: -2.778,Avg.Loss: -2.914,LR: 1.37E-04]Training epoch 65:  93%|█████████▎| 104/112 [00:01<00:00, 54.01it/s, Epoch: 65, Batch: 105,Loss: -2.901,Avg.Loss: -2.914,LR: 1.37E-04]Training epoch 65:  94%|█████████▍| 105/112 [00:01<00:00, 54.01it/s, Epoch: 65, Batch: 106,Loss: -3.012,Avg.Loss: -2.915,LR: 1.37E-04]Training epoch 65:  95%|█████████▍| 106/112 [00:01<00:00, 54.01it/s, Epoch: 65, Batch: 107,Loss: -2.694,Avg.Loss: -2.913,LR: 1.37E-04]Training epoch 65:  96%|█████████▌| 107/112 [00:02<00:00, 54.01it/s, Epoch: 65, Batch: 108,Loss: -2.429,Avg.Loss: -2.909,LR: 1.37E-04]Training epoch 65:  96%|█████████▋| 108/112 [00:02<00:00, 53.98it/s, Epoch: 65, Batch: 108,Loss: -2.429,Avg.Loss: -2.909,LR: 1.37E-04]Training epoch 65:  96%|█████████▋| 108/112 [00:02<00:00, 53.98it/s, Epoch: 65, Batch: 109,Loss: -3.081,Avg.Loss: -2.910,LR: 1.37E-04]Training epoch 65:  97%|█████████▋| 109/112 [00:02<00:00, 53.98it/s, Epoch: 65, Batch: 110,Loss: -2.304,Avg.Loss: -2.905,LR: 1.37E-04]Training epoch 65:  98%|█████████▊| 110/112 [00:02<00:00, 53.98it/s, Epoch: 65, Batch: 111,Loss: -2.323,Avg.Loss: -2.899,LR: 1.37E-04]Training epoch 65:  99%|█████████▉| 111/112 [00:02<00:00, 53.98it/s, Epoch: 65, Batch: 112,Loss: -3.903,Avg.Loss: -2.908,LR: 1.37E-04]Training epoch 65: 100%|██████████| 112/112 [00:02<00:00, 53.46it/s, Epoch: 65, Batch: 112,Loss: -3.903,Avg.Loss: -2.908,LR: 1.37E-04]
Training epoch 66:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 66:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 66, Batch: 1,Loss: -1.929,Avg.Loss: -1.929,LR: 1.36E-04]Training epoch 66:   1%|          | 1/112 [00:00<00:04, 25.03it/s, Epoch: 66, Batch: 2,Loss: -2.403,Avg.Loss: -2.166,LR: 1.36E-04]Training epoch 66:   2%|▏         | 2/112 [00:00<00:03, 35.45it/s, Epoch: 66, Batch: 3,Loss: -2.228,Avg.Loss: -2.186,LR: 1.36E-04]Training epoch 66:   3%|▎         | 3/112 [00:00<00:02, 40.66it/s, Epoch: 66, Batch: 4,Loss: -3.666,Avg.Loss: -2.556,LR: 1.36E-04]Training epoch 66:   4%|▎         | 4/112 [00:00<00:02, 43.57it/s, Epoch: 66, Batch: 5,Loss: -3.269,Avg.Loss: -2.699,LR: 1.36E-04]Training epoch 66:   4%|▍         | 5/112 [00:00<00:02, 45.24it/s, Epoch: 66, Batch: 6,Loss: -2.896,Avg.Loss: -2.732,LR: 1.36E-04]Training epoch 66:   5%|▌         | 6/112 [00:00<00:01, 54.19it/s, Epoch: 66, Batch: 6,Loss: -2.896,Avg.Loss: -2.732,LR: 1.36E-04]Training epoch 66:   5%|▌         | 6/112 [00:00<00:01, 54.19it/s, Epoch: 66, Batch: 7,Loss: -3.356,Avg.Loss: -2.821,LR: 1.36E-04]Training epoch 66:   6%|▋         | 7/112 [00:00<00:01, 54.19it/s, Epoch: 66, Batch: 8,Loss: -3.061,Avg.Loss: -2.851,LR: 1.36E-04]Training epoch 66:   7%|▋         | 8/112 [00:00<00:01, 54.19it/s, Epoch: 66, Batch: 9,Loss: -2.595,Avg.Loss: -2.823,LR: 1.36E-04]Training epoch 66:   8%|▊         | 9/112 [00:00<00:01, 54.19it/s, Epoch: 66, Batch: 10,Loss: -3.244,Avg.Loss: -2.865,LR: 1.36E-04]Training epoch 66:   9%|▉         | 10/112 [00:00<00:01, 54.19it/s, Epoch: 66, Batch: 11,Loss: -2.979,Avg.Loss: -2.875,LR: 1.36E-04]Training epoch 66:  10%|▉         | 11/112 [00:00<00:01, 54.19it/s, Epoch: 66, Batch: 12,Loss: -2.344,Avg.Loss: -2.831,LR: 1.36E-04]Training epoch 66:  11%|█         | 12/112 [00:00<00:01, 53.65it/s, Epoch: 66, Batch: 12,Loss: -2.344,Avg.Loss: -2.831,LR: 1.36E-04]Training epoch 66:  11%|█         | 12/112 [00:00<00:01, 53.65it/s, Epoch: 66, Batch: 13,Loss: -3.148,Avg.Loss: -2.855,LR: 1.36E-04]Training epoch 66:  12%|█▏        | 13/112 [00:00<00:01, 53.65it/s, Epoch: 66, Batch: 14,Loss: -2.749,Avg.Loss: -2.848,LR: 1.36E-04]Training epoch 66:  12%|█▎        | 14/112 [00:00<00:01, 53.65it/s, Epoch: 66, Batch: 15,Loss: -2.314,Avg.Loss: -2.812,LR: 1.36E-04]Training epoch 66:  13%|█▎        | 15/112 [00:00<00:01, 53.65it/s, Epoch: 66, Batch: 16,Loss: -2.356,Avg.Loss: -2.784,LR: 1.36E-04]Training epoch 66:  14%|█▍        | 16/112 [00:00<00:01, 53.65it/s, Epoch: 66, Batch: 17,Loss: -2.525,Avg.Loss: -2.768,LR: 1.35E-04]Training epoch 66:  15%|█▌        | 17/112 [00:00<00:01, 53.65it/s, Epoch: 66, Batch: 18,Loss: -2.340,Avg.Loss: -2.745,LR: 1.35E-04]Training epoch 66:  16%|█▌        | 18/112 [00:00<00:01, 51.28it/s, Epoch: 66, Batch: 18,Loss: -2.340,Avg.Loss: -2.745,LR: 1.35E-04]Training epoch 66:  16%|█▌        | 18/112 [00:00<00:01, 51.28it/s, Epoch: 66, Batch: 19,Loss: -3.464,Avg.Loss: -2.782,LR: 1.35E-04]Training epoch 66:  17%|█▋        | 19/112 [00:00<00:01, 51.28it/s, Epoch: 66, Batch: 20,Loss: -3.133,Avg.Loss: -2.800,LR: 1.35E-04]Training epoch 66:  18%|█▊        | 20/112 [00:00<00:01, 51.28it/s, Epoch: 66, Batch: 21,Loss: -2.365,Avg.Loss: -2.779,LR: 1.35E-04]Training epoch 66:  19%|█▉        | 21/112 [00:00<00:01, 51.28it/s, Epoch: 66, Batch: 22,Loss: -2.976,Avg.Loss: -2.788,LR: 1.35E-04]Training epoch 66:  20%|█▉        | 22/112 [00:00<00:01, 51.28it/s, Epoch: 66, Batch: 23,Loss: -2.895,Avg.Loss: -2.793,LR: 1.35E-04]Training epoch 66:  21%|██        | 23/112 [00:00<00:01, 51.28it/s, Epoch: 66, Batch: 24,Loss: -2.990,Avg.Loss: -2.801,LR: 1.35E-04]Training epoch 66:  21%|██▏       | 24/112 [00:00<00:01, 51.84it/s, Epoch: 66, Batch: 24,Loss: -2.990,Avg.Loss: -2.801,LR: 1.35E-04]Training epoch 66:  21%|██▏       | 24/112 [00:00<00:01, 51.84it/s, Epoch: 66, Batch: 25,Loss: -3.705,Avg.Loss: -2.837,LR: 1.35E-04]Training epoch 66:  22%|██▏       | 25/112 [00:00<00:01, 51.84it/s, Epoch: 66, Batch: 26,Loss: -2.312,Avg.Loss: -2.817,LR: 1.35E-04]Training epoch 66:  23%|██▎       | 26/112 [00:00<00:01, 51.84it/s, Epoch: 66, Batch: 27,Loss: -2.574,Avg.Loss: -2.808,LR: 1.35E-04]Training epoch 66:  24%|██▍       | 27/112 [00:00<00:01, 51.84it/s, Epoch: 66, Batch: 28,Loss: -2.784,Avg.Loss: -2.807,LR: 1.35E-04]Training epoch 66:  25%|██▌       | 28/112 [00:00<00:01, 51.84it/s, Epoch: 66, Batch: 29,Loss: -3.183,Avg.Loss: -2.820,LR: 1.35E-04]Training epoch 66:  26%|██▌       | 29/112 [00:00<00:01, 51.84it/s, Epoch: 66, Batch: 30,Loss: -2.234,Avg.Loss: -2.801,LR: 1.35E-04]Training epoch 66:  27%|██▋       | 30/112 [00:00<00:01, 53.02it/s, Epoch: 66, Batch: 30,Loss: -2.234,Avg.Loss: -2.801,LR: 1.35E-04]Training epoch 66:  27%|██▋       | 30/112 [00:00<00:01, 53.02it/s, Epoch: 66, Batch: 31,Loss: -3.105,Avg.Loss: -2.810,LR: 1.35E-04]Training epoch 66:  28%|██▊       | 31/112 [00:00<00:01, 53.02it/s, Epoch: 66, Batch: 32,Loss: -2.802,Avg.Loss: -2.810,LR: 1.35E-04]Training epoch 66:  29%|██▊       | 32/112 [00:00<00:01, 53.02it/s, Epoch: 66, Batch: 33,Loss: -3.089,Avg.Loss: -2.819,LR: 1.34E-04]Training epoch 66:  29%|██▉       | 33/112 [00:00<00:01, 53.02it/s, Epoch: 66, Batch: 34,Loss: -3.070,Avg.Loss: -2.826,LR: 1.34E-04]Training epoch 66:  30%|███       | 34/112 [00:00<00:01, 53.02it/s, Epoch: 66, Batch: 35,Loss: -3.365,Avg.Loss: -2.841,LR: 1.34E-04]Training epoch 66:  31%|███▏      | 35/112 [00:00<00:01, 53.02it/s, Epoch: 66, Batch: 36,Loss: -2.950,Avg.Loss: -2.844,LR: 1.34E-04]Training epoch 66:  32%|███▏      | 36/112 [00:00<00:01, 52.58it/s, Epoch: 66, Batch: 36,Loss: -2.950,Avg.Loss: -2.844,LR: 1.34E-04]Training epoch 66:  32%|███▏      | 36/112 [00:00<00:01, 52.58it/s, Epoch: 66, Batch: 37,Loss: -3.169,Avg.Loss: -2.853,LR: 1.34E-04]Training epoch 66:  33%|███▎      | 37/112 [00:00<00:01, 52.58it/s, Epoch: 66, Batch: 38,Loss: -2.947,Avg.Loss: -2.856,LR: 1.34E-04]Training epoch 66:  34%|███▍      | 38/112 [00:00<00:01, 52.58it/s, Epoch: 66, Batch: 39,Loss: -2.499,Avg.Loss: -2.847,LR: 1.34E-04]Training epoch 66:  35%|███▍      | 39/112 [00:00<00:01, 52.58it/s, Epoch: 66, Batch: 40,Loss: -2.896,Avg.Loss: -2.848,LR: 1.34E-04]Training epoch 66:  36%|███▌      | 40/112 [00:00<00:01, 52.58it/s, Epoch: 66, Batch: 41,Loss: -2.877,Avg.Loss: -2.848,LR: 1.34E-04]Training epoch 66:  37%|███▋      | 41/112 [00:00<00:01, 52.58it/s, Epoch: 66, Batch: 42,Loss: -2.799,Avg.Loss: -2.847,LR: 1.34E-04]Training epoch 66:  38%|███▊      | 42/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 42,Loss: -2.799,Avg.Loss: -2.847,LR: 1.34E-04]Training epoch 66:  38%|███▊      | 42/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 43,Loss: -3.007,Avg.Loss: -2.851,LR: 1.34E-04]Training epoch 66:  38%|███▊      | 43/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 44,Loss: -3.151,Avg.Loss: -2.858,LR: 1.34E-04]Training epoch 66:  39%|███▉      | 44/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 45,Loss: -2.573,Avg.Loss: -2.851,LR: 1.34E-04]Training epoch 66:  40%|████      | 45/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 46,Loss: -3.414,Avg.Loss: -2.864,LR: 1.34E-04]Training epoch 66:  41%|████      | 46/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 47,Loss: -3.228,Avg.Loss: -2.871,LR: 1.34E-04]Training epoch 66:  42%|████▏     | 47/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 48,Loss: -2.778,Avg.Loss: -2.870,LR: 1.34E-04]Training epoch 66:  43%|████▎     | 48/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 48,Loss: -2.778,Avg.Loss: -2.870,LR: 1.34E-04]Training epoch 66:  43%|████▎     | 48/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 49,Loss: -3.079,Avg.Loss: -2.874,LR: 1.33E-04]Training epoch 66:  44%|████▍     | 49/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 50,Loss: -2.881,Avg.Loss: -2.874,LR: 1.33E-04]Training epoch 66:  45%|████▍     | 50/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 51,Loss: -3.005,Avg.Loss: -2.877,LR: 1.33E-04]Training epoch 66:  46%|████▌     | 51/112 [00:00<00:01, 52.90it/s, Epoch: 66, Batch: 52,Loss: -2.925,Avg.Loss: -2.877,LR: 1.33E-04]Training epoch 66:  46%|████▋     | 52/112 [00:01<00:01, 52.90it/s, Epoch: 66, Batch: 53,Loss: -3.556,Avg.Loss: -2.890,LR: 1.33E-04]Training epoch 66:  47%|████▋     | 53/112 [00:01<00:01, 52.90it/s, Epoch: 66, Batch: 54,Loss: -2.874,Avg.Loss: -2.890,LR: 1.33E-04]Training epoch 66:  48%|████▊     | 54/112 [00:01<00:01, 52.87it/s, Epoch: 66, Batch: 54,Loss: -2.874,Avg.Loss: -2.890,LR: 1.33E-04]Training epoch 66:  48%|████▊     | 54/112 [00:01<00:01, 52.87it/s, Epoch: 66, Batch: 55,Loss: -3.653,Avg.Loss: -2.904,LR: 1.33E-04]Training epoch 66:  49%|████▉     | 55/112 [00:01<00:01, 52.87it/s, Epoch: 66, Batch: 56,Loss: -2.630,Avg.Loss: -2.899,LR: 1.33E-04]Training epoch 66:  50%|█████     | 56/112 [00:01<00:01, 52.87it/s, Epoch: 66, Batch: 57,Loss: -2.648,Avg.Loss: -2.895,LR: 1.33E-04]Training epoch 66:  51%|█████     | 57/112 [00:01<00:01, 52.87it/s, Epoch: 66, Batch: 58,Loss: -3.039,Avg.Loss: -2.897,LR: 1.33E-04]Training epoch 66:  52%|█████▏    | 58/112 [00:01<00:01, 52.87it/s, Epoch: 66, Batch: 59,Loss: -3.012,Avg.Loss: -2.899,LR: 1.33E-04]Training epoch 66:  53%|█████▎    | 59/112 [00:01<00:01, 52.87it/s, Epoch: 66, Batch: 60,Loss: -2.868,Avg.Loss: -2.898,LR: 1.33E-04]Training epoch 66:  54%|█████▎    | 60/112 [00:01<00:00, 53.17it/s, Epoch: 66, Batch: 60,Loss: -2.868,Avg.Loss: -2.898,LR: 1.33E-04]Training epoch 66:  54%|█████▎    | 60/112 [00:01<00:00, 53.17it/s, Epoch: 66, Batch: 61,Loss: -3.160,Avg.Loss: -2.903,LR: 1.33E-04]Training epoch 66:  54%|█████▍    | 61/112 [00:01<00:00, 53.17it/s, Epoch: 66, Batch: 62,Loss: -2.707,Avg.Loss: -2.900,LR: 1.33E-04]Training epoch 66:  55%|█████▌    | 62/112 [00:01<00:00, 53.17it/s, Epoch: 66, Batch: 63,Loss: -3.166,Avg.Loss: -2.904,LR: 1.33E-04]Training epoch 66:  56%|█████▋    | 63/112 [00:01<00:00, 53.17it/s, Epoch: 66, Batch: 64,Loss: -3.153,Avg.Loss: -2.908,LR: 1.33E-04]Training epoch 66:  57%|█████▋    | 64/112 [00:01<00:00, 53.17it/s, Epoch: 66, Batch: 65,Loss: -3.006,Avg.Loss: -2.909,LR: 1.32E-04]Training epoch 66:  58%|█████▊    | 65/112 [00:01<00:00, 53.17it/s, Epoch: 66, Batch: 66,Loss: -2.497,Avg.Loss: -2.903,LR: 1.32E-04]Training epoch 66:  59%|█████▉    | 66/112 [00:01<00:00, 53.04it/s, Epoch: 66, Batch: 66,Loss: -2.497,Avg.Loss: -2.903,LR: 1.32E-04]Training epoch 66:  59%|█████▉    | 66/112 [00:01<00:00, 53.04it/s, Epoch: 66, Batch: 67,Loss: -3.009,Avg.Loss: -2.905,LR: 1.32E-04]Training epoch 66:  60%|█████▉    | 67/112 [00:01<00:00, 53.04it/s, Epoch: 66, Batch: 68,Loss: -3.319,Avg.Loss: -2.911,LR: 1.32E-04]Training epoch 66:  61%|██████    | 68/112 [00:01<00:00, 53.04it/s, Epoch: 66, Batch: 69,Loss: -2.876,Avg.Loss: -2.910,LR: 1.32E-04]Training epoch 66:  62%|██████▏   | 69/112 [00:01<00:00, 53.04it/s, Epoch: 66, Batch: 70,Loss: -3.117,Avg.Loss: -2.913,LR: 1.32E-04]Training epoch 66:  62%|██████▎   | 70/112 [00:01<00:00, 53.04it/s, Epoch: 66, Batch: 71,Loss: -2.758,Avg.Loss: -2.911,LR: 1.32E-04]Training epoch 66:  63%|██████▎   | 71/112 [00:01<00:00, 53.04it/s, Epoch: 66, Batch: 72,Loss: -1.486,Avg.Loss: -2.891,LR: 1.32E-04]Training epoch 66:  64%|██████▍   | 72/112 [00:01<00:00, 53.03it/s, Epoch: 66, Batch: 72,Loss: -1.486,Avg.Loss: -2.891,LR: 1.32E-04]Training epoch 66:  64%|██████▍   | 72/112 [00:01<00:00, 53.03it/s, Epoch: 66, Batch: 73,Loss: -2.744,Avg.Loss: -2.889,LR: 1.32E-04]Training epoch 66:  65%|██████▌   | 73/112 [00:01<00:00, 53.03it/s, Epoch: 66, Batch: 74,Loss: -3.136,Avg.Loss: -2.892,LR: 1.32E-04]Training epoch 66:  66%|██████▌   | 74/112 [00:01<00:00, 53.03it/s, Epoch: 66, Batch: 75,Loss: -3.501,Avg.Loss: -2.901,LR: 1.32E-04]Training epoch 66:  67%|██████▋   | 75/112 [00:01<00:00, 53.03it/s, Epoch: 66, Batch: 76,Loss: -3.095,Avg.Loss: -2.903,LR: 1.32E-04]Training epoch 66:  68%|██████▊   | 76/112 [00:01<00:00, 53.03it/s, Epoch: 66, Batch: 77,Loss: -3.463,Avg.Loss: -2.910,LR: 1.32E-04]Training epoch 66:  69%|██████▉   | 77/112 [00:01<00:00, 53.03it/s, Epoch: 66, Batch: 78,Loss: -3.427,Avg.Loss: -2.917,LR: 1.32E-04]Training epoch 66:  70%|██████▉   | 78/112 [00:01<00:00, 53.11it/s, Epoch: 66, Batch: 78,Loss: -3.427,Avg.Loss: -2.917,LR: 1.32E-04]Training epoch 66:  70%|██████▉   | 78/112 [00:01<00:00, 53.11it/s, Epoch: 66, Batch: 79,Loss: -3.611,Avg.Loss: -2.926,LR: 1.32E-04]Training epoch 66:  71%|███████   | 79/112 [00:01<00:00, 53.11it/s, Epoch: 66, Batch: 80,Loss: -3.293,Avg.Loss: -2.930,LR: 1.32E-04]Training epoch 66:  71%|███████▏  | 80/112 [00:01<00:00, 53.11it/s, Epoch: 66, Batch: 81,Loss: -3.374,Avg.Loss: -2.936,LR: 1.31E-04]Training epoch 66:  72%|███████▏  | 81/112 [00:01<00:00, 53.11it/s, Epoch: 66, Batch: 82,Loss: -2.751,Avg.Loss: -2.934,LR: 1.31E-04]Training epoch 66:  73%|███████▎  | 82/112 [00:01<00:00, 53.11it/s, Epoch: 66, Batch: 83,Loss: -2.548,Avg.Loss: -2.929,LR: 1.31E-04]Training epoch 66:  74%|███████▍  | 83/112 [00:01<00:00, 53.11it/s, Epoch: 66, Batch: 84,Loss: -2.931,Avg.Loss: -2.929,LR: 1.31E-04]Training epoch 66:  75%|███████▌  | 84/112 [00:01<00:00, 52.99it/s, Epoch: 66, Batch: 84,Loss: -2.931,Avg.Loss: -2.929,LR: 1.31E-04]Training epoch 66:  75%|███████▌  | 84/112 [00:01<00:00, 52.99it/s, Epoch: 66, Batch: 85,Loss: -1.923,Avg.Loss: -2.917,LR: 1.31E-04]Training epoch 66:  76%|███████▌  | 85/112 [00:01<00:00, 52.99it/s, Epoch: 66, Batch: 86,Loss: -1.870,Avg.Loss: -2.905,LR: 1.31E-04]Training epoch 66:  77%|███████▋  | 86/112 [00:01<00:00, 52.99it/s, Epoch: 66, Batch: 87,Loss: -2.974,Avg.Loss: -2.906,LR: 1.31E-04]Training epoch 66:  78%|███████▊  | 87/112 [00:01<00:00, 52.99it/s, Epoch: 66, Batch: 88,Loss: -3.489,Avg.Loss: -2.912,LR: 1.31E-04]Training epoch 66:  79%|███████▊  | 88/112 [00:01<00:00, 52.99it/s, Epoch: 66, Batch: 89,Loss: -3.344,Avg.Loss: -2.917,LR: 1.31E-04]Training epoch 66:  79%|███████▉  | 89/112 [00:01<00:00, 52.99it/s, Epoch: 66, Batch: 90,Loss: -2.762,Avg.Loss: -2.916,LR: 1.31E-04]Training epoch 66:  80%|████████  | 90/112 [00:01<00:00, 51.60it/s, Epoch: 66, Batch: 90,Loss: -2.762,Avg.Loss: -2.916,LR: 1.31E-04]Training epoch 66:  80%|████████  | 90/112 [00:01<00:00, 51.60it/s, Epoch: 66, Batch: 91,Loss: -3.428,Avg.Loss: -2.921,LR: 1.31E-04]Training epoch 66:  81%|████████▏ | 91/112 [00:01<00:00, 51.60it/s, Epoch: 66, Batch: 92,Loss: -3.042,Avg.Loss: -2.922,LR: 1.31E-04]Training epoch 66:  82%|████████▏ | 92/112 [00:01<00:00, 51.60it/s, Epoch: 66, Batch: 93,Loss: -2.881,Avg.Loss: -2.922,LR: 1.31E-04]Training epoch 66:  83%|████████▎ | 93/112 [00:01<00:00, 51.60it/s, Epoch: 66, Batch: 94,Loss: -3.072,Avg.Loss: -2.924,LR: 1.31E-04]Training epoch 66:  84%|████████▍ | 94/112 [00:01<00:00, 51.60it/s, Epoch: 66, Batch: 95,Loss: -3.106,Avg.Loss: -2.926,LR: 1.31E-04]Training epoch 66:  85%|████████▍ | 95/112 [00:01<00:00, 51.60it/s, Epoch: 66, Batch: 96,Loss: -2.846,Avg.Loss: -2.925,LR: 1.31E-04]Training epoch 66:  86%|████████▌ | 96/112 [00:01<00:00, 50.46it/s, Epoch: 66, Batch: 96,Loss: -2.846,Avg.Loss: -2.925,LR: 1.31E-04]Training epoch 66:  86%|████████▌ | 96/112 [00:01<00:00, 50.46it/s, Epoch: 66, Batch: 97,Loss: -2.549,Avg.Loss: -2.921,LR: 1.30E-04]Training epoch 66:  87%|████████▋ | 97/112 [00:01<00:00, 50.46it/s, Epoch: 66, Batch: 98,Loss: -2.552,Avg.Loss: -2.917,LR: 1.30E-04]Training epoch 66:  88%|████████▊ | 98/112 [00:01<00:00, 50.46it/s, Epoch: 66, Batch: 99,Loss: -3.138,Avg.Loss: -2.919,LR: 1.30E-04]Training epoch 66:  88%|████████▊ | 99/112 [00:01<00:00, 50.46it/s, Epoch: 66, Batch: 100,Loss: -2.783,Avg.Loss: -2.918,LR: 1.30E-04]Training epoch 66:  89%|████████▉ | 100/112 [00:01<00:00, 50.46it/s, Epoch: 66, Batch: 101,Loss: -2.865,Avg.Loss: -2.917,LR: 1.30E-04]Training epoch 66:  90%|█████████ | 101/112 [00:01<00:00, 50.46it/s, Epoch: 66, Batch: 102,Loss: -2.980,Avg.Loss: -2.918,LR: 1.30E-04]Training epoch 66:  91%|█████████ | 102/112 [00:01<00:00, 51.69it/s, Epoch: 66, Batch: 102,Loss: -2.980,Avg.Loss: -2.918,LR: 1.30E-04]Training epoch 66:  91%|█████████ | 102/112 [00:01<00:00, 51.69it/s, Epoch: 66, Batch: 103,Loss: -2.685,Avg.Loss: -2.916,LR: 1.30E-04]Training epoch 66:  92%|█████████▏| 103/112 [00:01<00:00, 51.69it/s, Epoch: 66, Batch: 104,Loss: -2.553,Avg.Loss: -2.912,LR: 1.30E-04]Training epoch 66:  93%|█████████▎| 104/112 [00:02<00:00, 51.69it/s, Epoch: 66, Batch: 105,Loss: -2.721,Avg.Loss: -2.910,LR: 1.30E-04]Training epoch 66:  94%|█████████▍| 105/112 [00:02<00:00, 51.69it/s, Epoch: 66, Batch: 106,Loss: -2.813,Avg.Loss: -2.910,LR: 1.30E-04]Training epoch 66:  95%|█████████▍| 106/112 [00:02<00:00, 51.69it/s, Epoch: 66, Batch: 107,Loss: -2.872,Avg.Loss: -2.909,LR: 1.30E-04]Training epoch 66:  96%|█████████▌| 107/112 [00:02<00:00, 51.69it/s, Epoch: 66, Batch: 108,Loss: -3.371,Avg.Loss: -2.913,LR: 1.30E-04]Training epoch 66:  96%|█████████▋| 108/112 [00:02<00:00, 52.18it/s, Epoch: 66, Batch: 108,Loss: -3.371,Avg.Loss: -2.913,LR: 1.30E-04]Training epoch 66:  96%|█████████▋| 108/112 [00:02<00:00, 52.18it/s, Epoch: 66, Batch: 109,Loss: -3.142,Avg.Loss: -2.916,LR: 1.30E-04]Training epoch 66:  97%|█████████▋| 109/112 [00:02<00:00, 52.18it/s, Epoch: 66, Batch: 110,Loss: -2.622,Avg.Loss: -2.913,LR: 1.30E-04]Training epoch 66:  98%|█████████▊| 110/112 [00:02<00:00, 52.18it/s, Epoch: 66, Batch: 111,Loss: -2.823,Avg.Loss: -2.912,LR: 1.30E-04]Training epoch 66:  99%|█████████▉| 111/112 [00:02<00:00, 52.18it/s, Epoch: 66, Batch: 112,Loss: -3.346,Avg.Loss: -2.916,LR: 1.30E-04]Training epoch 66: 100%|██████████| 112/112 [00:02<00:00, 52.42it/s, Epoch: 66, Batch: 112,Loss: -3.346,Avg.Loss: -2.916,LR: 1.30E-04]
Training epoch 67:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 67:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 67, Batch: 1,Loss: -2.074,Avg.Loss: -2.074,LR: 1.30E-04]Training epoch 67:   1%|          | 1/112 [00:00<00:03, 32.57it/s, Epoch: 67, Batch: 2,Loss: -0.383,Avg.Loss: -1.228,LR: 1.29E-04]Training epoch 67:   2%|▏         | 2/112 [00:00<00:02, 45.47it/s, Epoch: 67, Batch: 3,Loss: -1.308,Avg.Loss: -1.255,LR: 1.29E-04]Training epoch 67:   3%|▎         | 3/112 [00:00<00:02, 49.22it/s, Epoch: 67, Batch: 4,Loss: -2.282,Avg.Loss: -1.512,LR: 1.29E-04]Training epoch 67:   4%|▎         | 4/112 [00:00<00:02, 51.32it/s, Epoch: 67, Batch: 5,Loss: -2.590,Avg.Loss: -1.728,LR: 1.29E-04]Training epoch 67:   4%|▍         | 5/112 [00:00<00:02, 52.00it/s, Epoch: 67, Batch: 6,Loss: -2.627,Avg.Loss: -1.877,LR: 1.29E-04]Training epoch 67:   5%|▌         | 6/112 [00:00<00:02, 52.19it/s, Epoch: 67, Batch: 7,Loss: -2.801,Avg.Loss: -2.009,LR: 1.29E-04]Training epoch 67:   6%|▋         | 7/112 [00:00<00:01, 60.80it/s, Epoch: 67, Batch: 7,Loss: -2.801,Avg.Loss: -2.009,LR: 1.29E-04]Training epoch 67:   6%|▋         | 7/112 [00:00<00:01, 60.80it/s, Epoch: 67, Batch: 8,Loss: -2.832,Avg.Loss: -2.112,LR: 1.29E-04]Training epoch 67:   7%|▋         | 8/112 [00:00<00:01, 60.80it/s, Epoch: 67, Batch: 9,Loss: -2.602,Avg.Loss: -2.167,LR: 1.29E-04]Training epoch 67:   8%|▊         | 9/112 [00:00<00:01, 60.80it/s, Epoch: 67, Batch: 10,Loss: -2.335,Avg.Loss: -2.183,LR: 1.29E-04]Training epoch 67:   9%|▉         | 10/112 [00:00<00:01, 60.80it/s, Epoch: 67, Batch: 11,Loss: -2.860,Avg.Loss: -2.245,LR: 1.29E-04]Training epoch 67:  10%|▉         | 11/112 [00:00<00:01, 60.80it/s, Epoch: 67, Batch: 12,Loss: -2.713,Avg.Loss: -2.284,LR: 1.29E-04]Training epoch 67:  11%|█         | 12/112 [00:00<00:01, 60.80it/s, Epoch: 67, Batch: 13,Loss: -2.796,Avg.Loss: -2.323,LR: 1.29E-04]Training epoch 67:  12%|█▏        | 13/112 [00:00<00:01, 60.80it/s, Epoch: 67, Batch: 14,Loss: -3.244,Avg.Loss: -2.389,LR: 1.29E-04]Training epoch 67:  12%|█▎        | 14/112 [00:00<00:01, 55.99it/s, Epoch: 67, Batch: 14,Loss: -3.244,Avg.Loss: -2.389,LR: 1.29E-04]Training epoch 67:  12%|█▎        | 14/112 [00:00<00:01, 55.99it/s, Epoch: 67, Batch: 15,Loss: -3.497,Avg.Loss: -2.463,LR: 1.29E-04]Training epoch 67:  13%|█▎        | 15/112 [00:00<00:01, 55.99it/s, Epoch: 67, Batch: 16,Loss: -2.862,Avg.Loss: -2.488,LR: 1.29E-04]Training epoch 67:  14%|█▍        | 16/112 [00:00<00:01, 55.99it/s, Epoch: 67, Batch: 17,Loss: -2.444,Avg.Loss: -2.485,LR: 1.29E-04]Training epoch 67:  15%|█▌        | 17/112 [00:00<00:01, 55.99it/s, Epoch: 67, Batch: 18,Loss: -2.701,Avg.Loss: -2.497,LR: 1.28E-04]Training epoch 67:  16%|█▌        | 18/112 [00:00<00:01, 55.99it/s, Epoch: 67, Batch: 19,Loss: -1.997,Avg.Loss: -2.471,LR: 1.28E-04]Training epoch 67:  17%|█▋        | 19/112 [00:00<00:01, 55.99it/s, Epoch: 67, Batch: 20,Loss: -2.714,Avg.Loss: -2.483,LR: 1.28E-04]Training epoch 67:  18%|█▊        | 20/112 [00:00<00:01, 54.88it/s, Epoch: 67, Batch: 20,Loss: -2.714,Avg.Loss: -2.483,LR: 1.28E-04]Training epoch 67:  18%|█▊        | 20/112 [00:00<00:01, 54.88it/s, Epoch: 67, Batch: 21,Loss: -3.092,Avg.Loss: -2.512,LR: 1.28E-04]Training epoch 67:  19%|█▉        | 21/112 [00:00<00:01, 54.88it/s, Epoch: 67, Batch: 22,Loss: -3.151,Avg.Loss: -2.541,LR: 1.28E-04]Training epoch 67:  20%|█▉        | 22/112 [00:00<00:01, 54.88it/s, Epoch: 67, Batch: 23,Loss: -3.005,Avg.Loss: -2.561,LR: 1.28E-04]Training epoch 67:  21%|██        | 23/112 [00:00<00:01, 54.88it/s, Epoch: 67, Batch: 24,Loss: -3.076,Avg.Loss: -2.583,LR: 1.28E-04]Training epoch 67:  21%|██▏       | 24/112 [00:00<00:01, 54.88it/s, Epoch: 67, Batch: 25,Loss: -3.097,Avg.Loss: -2.603,LR: 1.28E-04]Training epoch 67:  22%|██▏       | 25/112 [00:00<00:01, 54.88it/s, Epoch: 67, Batch: 26,Loss: -2.867,Avg.Loss: -2.613,LR: 1.28E-04]Training epoch 67:  23%|██▎       | 26/112 [00:00<00:01, 52.97it/s, Epoch: 67, Batch: 26,Loss: -2.867,Avg.Loss: -2.613,LR: 1.28E-04]Training epoch 67:  23%|██▎       | 26/112 [00:00<00:01, 52.97it/s, Epoch: 67, Batch: 27,Loss: -2.938,Avg.Loss: -2.625,LR: 1.28E-04]Training epoch 67:  24%|██▍       | 27/112 [00:00<00:01, 52.97it/s, Epoch: 67, Batch: 28,Loss: -2.590,Avg.Loss: -2.624,LR: 1.28E-04]Training epoch 67:  25%|██▌       | 28/112 [00:00<00:01, 52.97it/s, Epoch: 67, Batch: 29,Loss: -2.478,Avg.Loss: -2.619,LR: 1.28E-04]Training epoch 67:  26%|██▌       | 29/112 [00:00<00:01, 52.97it/s, Epoch: 67, Batch: 30,Loss: -2.876,Avg.Loss: -2.628,LR: 1.28E-04]Training epoch 67:  27%|██▋       | 30/112 [00:00<00:01, 52.97it/s, Epoch: 67, Batch: 31,Loss: -1.539,Avg.Loss: -2.593,LR: 1.28E-04]Training epoch 67:  28%|██▊       | 31/112 [00:00<00:01, 52.97it/s, Epoch: 67, Batch: 32,Loss: -2.674,Avg.Loss: -2.595,LR: 1.28E-04]Training epoch 67:  29%|██▊       | 32/112 [00:00<00:01, 52.96it/s, Epoch: 67, Batch: 32,Loss: -2.674,Avg.Loss: -2.595,LR: 1.28E-04]Training epoch 67:  29%|██▊       | 32/112 [00:00<00:01, 52.96it/s, Epoch: 67, Batch: 33,Loss: -3.302,Avg.Loss: -2.617,LR: 1.28E-04]Training epoch 67:  29%|██▉       | 33/112 [00:00<00:01, 52.96it/s, Epoch: 67, Batch: 34,Loss: -1.095,Avg.Loss: -2.572,LR: 1.27E-04]Training epoch 67:  30%|███       | 34/112 [00:00<00:01, 52.96it/s, Epoch: 67, Batch: 35,Loss: -0.078,Avg.Loss: -2.501,LR: 1.27E-04]Training epoch 67:  31%|███▏      | 35/112 [00:00<00:01, 52.96it/s, Epoch: 67, Batch: 36,Loss: 0.437,Avg.Loss: -2.419,LR: 1.27E-04] Training epoch 67:  32%|███▏      | 36/112 [00:00<00:01, 52.96it/s, Epoch: 67, Batch: 37,Loss: -1.609,Avg.Loss: -2.397,LR: 1.27E-04]Training epoch 67:  33%|███▎      | 37/112 [00:00<00:01, 52.96it/s, Epoch: 67, Batch: 38,Loss: -1.989,Avg.Loss: -2.386,LR: 1.27E-04]Training epoch 67:  34%|███▍      | 38/112 [00:00<00:01, 52.81it/s, Epoch: 67, Batch: 38,Loss: -1.989,Avg.Loss: -2.386,LR: 1.27E-04]Training epoch 67:  34%|███▍      | 38/112 [00:00<00:01, 52.81it/s, Epoch: 67, Batch: 39,Loss: -1.617,Avg.Loss: -2.367,LR: 1.27E-04]Training epoch 67:  35%|███▍      | 39/112 [00:00<00:01, 52.81it/s, Epoch: 67, Batch: 40,Loss: -2.237,Avg.Loss: -2.363,LR: 1.27E-04]Training epoch 67:  36%|███▌      | 40/112 [00:00<00:01, 52.81it/s, Epoch: 67, Batch: 41,Loss: -2.358,Avg.Loss: -2.363,LR: 1.27E-04]Training epoch 67:  37%|███▋      | 41/112 [00:00<00:01, 52.81it/s, Epoch: 67, Batch: 42,Loss: -2.163,Avg.Loss: -2.359,LR: 1.27E-04]Training epoch 67:  38%|███▊      | 42/112 [00:00<00:01, 52.81it/s, Epoch: 67, Batch: 43,Loss: -1.568,Avg.Loss: -2.340,LR: 1.27E-04]Training epoch 67:  38%|███▊      | 43/112 [00:00<00:01, 52.81it/s, Epoch: 67, Batch: 44,Loss: -2.233,Avg.Loss: -2.338,LR: 1.27E-04]Training epoch 67:  39%|███▉      | 44/112 [00:00<00:01, 52.88it/s, Epoch: 67, Batch: 44,Loss: -2.233,Avg.Loss: -2.338,LR: 1.27E-04]Training epoch 67:  39%|███▉      | 44/112 [00:00<00:01, 52.88it/s, Epoch: 67, Batch: 45,Loss: -2.247,Avg.Loss: -2.336,LR: 1.27E-04]Training epoch 67:  40%|████      | 45/112 [00:00<00:01, 52.88it/s, Epoch: 67, Batch: 46,Loss: -2.300,Avg.Loss: -2.335,LR: 1.27E-04]Training epoch 67:  41%|████      | 46/112 [00:00<00:01, 52.88it/s, Epoch: 67, Batch: 47,Loss: -2.255,Avg.Loss: -2.333,LR: 1.27E-04]Training epoch 67:  42%|████▏     | 47/112 [00:00<00:01, 52.88it/s, Epoch: 67, Batch: 48,Loss: -2.753,Avg.Loss: -2.342,LR: 1.27E-04]Training epoch 67:  43%|████▎     | 48/112 [00:00<00:01, 52.88it/s, Epoch: 67, Batch: 49,Loss: -3.215,Avg.Loss: -2.360,LR: 1.27E-04]Training epoch 67:  44%|████▍     | 49/112 [00:00<00:01, 52.88it/s, Epoch: 67, Batch: 50,Loss: -2.870,Avg.Loss: -2.370,LR: 1.27E-04]Training epoch 67:  45%|████▍     | 50/112 [00:00<00:01, 52.99it/s, Epoch: 67, Batch: 50,Loss: -2.870,Avg.Loss: -2.370,LR: 1.27E-04]Training epoch 67:  45%|████▍     | 50/112 [00:00<00:01, 52.99it/s, Epoch: 67, Batch: 51,Loss: -3.558,Avg.Loss: -2.393,LR: 1.26E-04]Training epoch 67:  46%|████▌     | 51/112 [00:00<00:01, 52.99it/s, Epoch: 67, Batch: 52,Loss: -2.765,Avg.Loss: -2.400,LR: 1.26E-04]Training epoch 67:  46%|████▋     | 52/112 [00:00<00:01, 52.99it/s, Epoch: 67, Batch: 53,Loss: -2.612,Avg.Loss: -2.404,LR: 1.26E-04]Training epoch 67:  47%|████▋     | 53/112 [00:01<00:01, 52.99it/s, Epoch: 67, Batch: 54,Loss: -2.900,Avg.Loss: -2.414,LR: 1.26E-04]Training epoch 67:  48%|████▊     | 54/112 [00:01<00:01, 52.99it/s, Epoch: 67, Batch: 55,Loss: -2.738,Avg.Loss: -2.420,LR: 1.26E-04]Training epoch 67:  49%|████▉     | 55/112 [00:01<00:01, 52.99it/s, Epoch: 67, Batch: 56,Loss: -1.906,Avg.Loss: -2.410,LR: 1.26E-04]Training epoch 67:  50%|█████     | 56/112 [00:01<00:01, 53.09it/s, Epoch: 67, Batch: 56,Loss: -1.906,Avg.Loss: -2.410,LR: 1.26E-04]Training epoch 67:  50%|█████     | 56/112 [00:01<00:01, 53.09it/s, Epoch: 67, Batch: 57,Loss: -2.600,Avg.Loss: -2.414,LR: 1.26E-04]Training epoch 67:  51%|█████     | 57/112 [00:01<00:01, 53.09it/s, Epoch: 67, Batch: 58,Loss: -3.200,Avg.Loss: -2.427,LR: 1.26E-04]Training epoch 67:  52%|█████▏    | 58/112 [00:01<00:01, 53.09it/s, Epoch: 67, Batch: 59,Loss: -3.211,Avg.Loss: -2.440,LR: 1.26E-04]Training epoch 67:  53%|█████▎    | 59/112 [00:01<00:00, 53.09it/s, Epoch: 67, Batch: 60,Loss: -3.091,Avg.Loss: -2.451,LR: 1.26E-04]Training epoch 67:  54%|█████▎    | 60/112 [00:01<00:00, 53.09it/s, Epoch: 67, Batch: 61,Loss: -3.481,Avg.Loss: -2.468,LR: 1.26E-04]Training epoch 67:  54%|█████▍    | 61/112 [00:01<00:00, 53.09it/s, Epoch: 67, Batch: 62,Loss: -3.224,Avg.Loss: -2.480,LR: 1.26E-04]Training epoch 67:  55%|█████▌    | 62/112 [00:01<00:00, 53.07it/s, Epoch: 67, Batch: 62,Loss: -3.224,Avg.Loss: -2.480,LR: 1.26E-04]Training epoch 67:  55%|█████▌    | 62/112 [00:01<00:00, 53.07it/s, Epoch: 67, Batch: 63,Loss: -3.362,Avg.Loss: -2.494,LR: 1.26E-04]Training epoch 67:  56%|█████▋    | 63/112 [00:01<00:00, 53.07it/s, Epoch: 67, Batch: 64,Loss: -3.313,Avg.Loss: -2.507,LR: 1.26E-04]Training epoch 67:  57%|█████▋    | 64/112 [00:01<00:00, 53.07it/s, Epoch: 67, Batch: 65,Loss: -3.289,Avg.Loss: -2.519,LR: 1.26E-04]Training epoch 67:  58%|█████▊    | 65/112 [00:01<00:00, 53.07it/s, Epoch: 67, Batch: 66,Loss: -3.159,Avg.Loss: -2.529,LR: 1.26E-04]Training epoch 67:  59%|█████▉    | 66/112 [00:01<00:00, 53.07it/s, Epoch: 67, Batch: 67,Loss: -3.381,Avg.Loss: -2.542,LR: 1.25E-04]Training epoch 67:  60%|█████▉    | 67/112 [00:01<00:00, 53.07it/s, Epoch: 67, Batch: 68,Loss: -3.601,Avg.Loss: -2.557,LR: 1.25E-04]Training epoch 67:  61%|██████    | 68/112 [00:01<00:00, 52.99it/s, Epoch: 67, Batch: 68,Loss: -3.601,Avg.Loss: -2.557,LR: 1.25E-04]Training epoch 67:  61%|██████    | 68/112 [00:01<00:00, 52.99it/s, Epoch: 67, Batch: 69,Loss: -3.493,Avg.Loss: -2.571,LR: 1.25E-04]Training epoch 67:  62%|██████▏   | 69/112 [00:01<00:00, 52.99it/s, Epoch: 67, Batch: 70,Loss: -3.213,Avg.Loss: -2.580,LR: 1.25E-04]Training epoch 67:  62%|██████▎   | 70/112 [00:01<00:00, 52.99it/s, Epoch: 67, Batch: 71,Loss: -3.241,Avg.Loss: -2.589,LR: 1.25E-04]Training epoch 67:  63%|██████▎   | 71/112 [00:01<00:00, 52.99it/s, Epoch: 67, Batch: 72,Loss: -2.938,Avg.Loss: -2.594,LR: 1.25E-04]Training epoch 67:  64%|██████▍   | 72/112 [00:01<00:00, 52.99it/s, Epoch: 67, Batch: 73,Loss: -2.490,Avg.Loss: -2.593,LR: 1.25E-04]Training epoch 67:  65%|██████▌   | 73/112 [00:01<00:00, 52.99it/s, Epoch: 67, Batch: 74,Loss: -3.042,Avg.Loss: -2.599,LR: 1.25E-04]Training epoch 67:  66%|██████▌   | 74/112 [00:01<00:00, 52.04it/s, Epoch: 67, Batch: 74,Loss: -3.042,Avg.Loss: -2.599,LR: 1.25E-04]Training epoch 67:  66%|██████▌   | 74/112 [00:01<00:00, 52.04it/s, Epoch: 67, Batch: 75,Loss: -2.988,Avg.Loss: -2.604,LR: 1.25E-04]Training epoch 67:  67%|██████▋   | 75/112 [00:01<00:00, 52.04it/s, Epoch: 67, Batch: 76,Loss: -2.343,Avg.Loss: -2.601,LR: 1.25E-04]Training epoch 67:  68%|██████▊   | 76/112 [00:01<00:00, 52.04it/s, Epoch: 67, Batch: 77,Loss: -3.031,Avg.Loss: -2.606,LR: 1.25E-04]Training epoch 67:  69%|██████▉   | 77/112 [00:01<00:00, 52.04it/s, Epoch: 67, Batch: 78,Loss: -3.239,Avg.Loss: -2.614,LR: 1.25E-04]Training epoch 67:  70%|██████▉   | 78/112 [00:01<00:00, 52.04it/s, Epoch: 67, Batch: 79,Loss: -2.819,Avg.Loss: -2.617,LR: 1.25E-04]Training epoch 67:  71%|███████   | 79/112 [00:01<00:00, 52.04it/s, Epoch: 67, Batch: 80,Loss: -3.452,Avg.Loss: -2.627,LR: 1.25E-04]Training epoch 67:  71%|███████▏  | 80/112 [00:01<00:00, 52.16it/s, Epoch: 67, Batch: 80,Loss: -3.452,Avg.Loss: -2.627,LR: 1.25E-04]Training epoch 67:  71%|███████▏  | 80/112 [00:01<00:00, 52.16it/s, Epoch: 67, Batch: 81,Loss: -3.218,Avg.Loss: -2.635,LR: 1.25E-04]Training epoch 67:  72%|███████▏  | 81/112 [00:01<00:00, 52.16it/s, Epoch: 67, Batch: 82,Loss: -2.915,Avg.Loss: -2.638,LR: 1.25E-04]Training epoch 67:  73%|███████▎  | 82/112 [00:01<00:00, 52.16it/s, Epoch: 67, Batch: 83,Loss: -3.023,Avg.Loss: -2.643,LR: 1.24E-04]Training epoch 67:  74%|███████▍  | 83/112 [00:01<00:00, 52.16it/s, Epoch: 67, Batch: 84,Loss: -2.875,Avg.Loss: -2.645,LR: 1.24E-04]Training epoch 67:  75%|███████▌  | 84/112 [00:01<00:00, 52.16it/s, Epoch: 67, Batch: 85,Loss: -2.814,Avg.Loss: -2.647,LR: 1.24E-04]Training epoch 67:  76%|███████▌  | 85/112 [00:01<00:00, 52.16it/s, Epoch: 67, Batch: 86,Loss: -2.495,Avg.Loss: -2.646,LR: 1.24E-04]Training epoch 67:  77%|███████▋  | 86/112 [00:01<00:00, 52.57it/s, Epoch: 67, Batch: 86,Loss: -2.495,Avg.Loss: -2.646,LR: 1.24E-04]Training epoch 67:  77%|███████▋  | 86/112 [00:01<00:00, 52.57it/s, Epoch: 67, Batch: 87,Loss: -3.216,Avg.Loss: -2.652,LR: 1.24E-04]Training epoch 67:  78%|███████▊  | 87/112 [00:01<00:00, 52.57it/s, Epoch: 67, Batch: 88,Loss: -2.970,Avg.Loss: -2.656,LR: 1.24E-04]Training epoch 67:  79%|███████▊  | 88/112 [00:01<00:00, 52.57it/s, Epoch: 67, Batch: 89,Loss: -3.073,Avg.Loss: -2.660,LR: 1.24E-04]Training epoch 67:  79%|███████▉  | 89/112 [00:01<00:00, 52.57it/s, Epoch: 67, Batch: 90,Loss: -2.557,Avg.Loss: -2.659,LR: 1.24E-04]Training epoch 67:  80%|████████  | 90/112 [00:01<00:00, 52.57it/s, Epoch: 67, Batch: 91,Loss: -2.717,Avg.Loss: -2.660,LR: 1.24E-04]Training epoch 67:  81%|████████▏ | 91/112 [00:01<00:00, 52.57it/s, Epoch: 67, Batch: 92,Loss: -3.047,Avg.Loss: -2.664,LR: 1.24E-04]Training epoch 67:  82%|████████▏ | 92/112 [00:01<00:00, 52.78it/s, Epoch: 67, Batch: 92,Loss: -3.047,Avg.Loss: -2.664,LR: 1.24E-04]Training epoch 67:  82%|████████▏ | 92/112 [00:01<00:00, 52.78it/s, Epoch: 67, Batch: 93,Loss: -3.070,Avg.Loss: -2.668,LR: 1.24E-04]Training epoch 67:  83%|████████▎ | 93/112 [00:01<00:00, 52.78it/s, Epoch: 67, Batch: 94,Loss: -3.005,Avg.Loss: -2.672,LR: 1.24E-04]Training epoch 67:  84%|████████▍ | 94/112 [00:01<00:00, 52.78it/s, Epoch: 67, Batch: 95,Loss: -3.495,Avg.Loss: -2.681,LR: 1.24E-04]Training epoch 67:  85%|████████▍ | 95/112 [00:01<00:00, 52.78it/s, Epoch: 67, Batch: 96,Loss: -3.061,Avg.Loss: -2.685,LR: 1.24E-04]Training epoch 67:  86%|████████▌ | 96/112 [00:01<00:00, 52.78it/s, Epoch: 67, Batch: 97,Loss: -2.295,Avg.Loss: -2.681,LR: 1.24E-04]Training epoch 67:  87%|████████▋ | 97/112 [00:01<00:00, 52.78it/s, Epoch: 67, Batch: 98,Loss: -3.328,Avg.Loss: -2.687,LR: 1.24E-04]Training epoch 67:  88%|████████▊ | 98/112 [00:01<00:00, 52.95it/s, Epoch: 67, Batch: 98,Loss: -3.328,Avg.Loss: -2.687,LR: 1.24E-04]Training epoch 67:  88%|████████▊ | 98/112 [00:01<00:00, 52.95it/s, Epoch: 67, Batch: 99,Loss: -3.104,Avg.Loss: -2.691,LR: 1.24E-04]Training epoch 67:  88%|████████▊ | 99/112 [00:01<00:00, 52.95it/s, Epoch: 67, Batch: 100,Loss: -2.743,Avg.Loss: -2.692,LR: 1.23E-04]Training epoch 67:  89%|████████▉ | 100/112 [00:01<00:00, 52.95it/s, Epoch: 67, Batch: 101,Loss: -3.291,Avg.Loss: -2.698,LR: 1.23E-04]Training epoch 67:  90%|█████████ | 101/112 [00:01<00:00, 52.95it/s, Epoch: 67, Batch: 102,Loss: -3.181,Avg.Loss: -2.703,LR: 1.23E-04]Training epoch 67:  91%|█████████ | 102/112 [00:01<00:00, 52.95it/s, Epoch: 67, Batch: 103,Loss: -2.756,Avg.Loss: -2.703,LR: 1.23E-04]Training epoch 67:  92%|█████████▏| 103/112 [00:01<00:00, 52.95it/s, Epoch: 67, Batch: 104,Loss: -3.304,Avg.Loss: -2.709,LR: 1.23E-04]Training epoch 67:  93%|█████████▎| 104/112 [00:01<00:00, 52.89it/s, Epoch: 67, Batch: 104,Loss: -3.304,Avg.Loss: -2.709,LR: 1.23E-04]Training epoch 67:  93%|█████████▎| 104/112 [00:01<00:00, 52.89it/s, Epoch: 67, Batch: 105,Loss: -3.079,Avg.Loss: -2.712,LR: 1.23E-04]Training epoch 67:  94%|█████████▍| 105/112 [00:01<00:00, 52.89it/s, Epoch: 67, Batch: 106,Loss: -2.641,Avg.Loss: -2.712,LR: 1.23E-04]Training epoch 67:  95%|█████████▍| 106/112 [00:02<00:00, 52.89it/s, Epoch: 67, Batch: 107,Loss: -3.366,Avg.Loss: -2.718,LR: 1.23E-04]Training epoch 67:  96%|█████████▌| 107/112 [00:02<00:00, 52.89it/s, Epoch: 67, Batch: 108,Loss: -2.847,Avg.Loss: -2.719,LR: 1.23E-04]Training epoch 67:  96%|█████████▋| 108/112 [00:02<00:00, 52.89it/s, Epoch: 67, Batch: 109,Loss: -2.803,Avg.Loss: -2.720,LR: 1.23E-04]Training epoch 67:  97%|█████████▋| 109/112 [00:02<00:00, 52.89it/s, Epoch: 67, Batch: 110,Loss: -3.355,Avg.Loss: -2.726,LR: 1.23E-04]Training epoch 67:  98%|█████████▊| 110/112 [00:02<00:00, 52.95it/s, Epoch: 67, Batch: 110,Loss: -3.355,Avg.Loss: -2.726,LR: 1.23E-04]Training epoch 67:  98%|█████████▊| 110/112 [00:02<00:00, 52.95it/s, Epoch: 67, Batch: 111,Loss: -3.109,Avg.Loss: -2.729,LR: 1.23E-04]Training epoch 67:  99%|█████████▉| 111/112 [00:02<00:00, 52.95it/s, Epoch: 67, Batch: 112,Loss: -2.214,Avg.Loss: -2.725,LR: 1.23E-04]Training epoch 67: 100%|██████████| 112/112 [00:02<00:00, 53.04it/s, Epoch: 67, Batch: 112,Loss: -2.214,Avg.Loss: -2.725,LR: 1.23E-04]
Training epoch 68:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 68:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 68, Batch: 1,Loss: -3.323,Avg.Loss: -3.323,LR: 1.23E-04]Training epoch 68:   1%|          | 1/112 [00:00<00:03, 31.17it/s, Epoch: 68, Batch: 2,Loss: -2.823,Avg.Loss: -3.073,LR: 1.23E-04]Training epoch 68:   2%|▏         | 2/112 [00:00<00:02, 44.70it/s, Epoch: 68, Batch: 3,Loss: -2.623,Avg.Loss: -2.923,LR: 1.23E-04]Training epoch 68:   3%|▎         | 3/112 [00:00<00:02, 48.86it/s, Epoch: 68, Batch: 4,Loss: -3.155,Avg.Loss: -2.981,LR: 1.22E-04]Training epoch 68:   4%|▎         | 4/112 [00:00<00:02, 50.23it/s, Epoch: 68, Batch: 5,Loss: -3.265,Avg.Loss: -3.038,LR: 1.22E-04]Training epoch 68:   4%|▍         | 5/112 [00:00<00:02, 51.57it/s, Epoch: 68, Batch: 6,Loss: -3.080,Avg.Loss: -3.045,LR: 1.22E-04]Training epoch 68:   5%|▌         | 6/112 [00:00<00:02, 52.23it/s, Epoch: 68, Batch: 7,Loss: -2.982,Avg.Loss: -3.036,LR: 1.22E-04]Training epoch 68:   6%|▋         | 7/112 [00:00<00:01, 60.86it/s, Epoch: 68, Batch: 7,Loss: -2.982,Avg.Loss: -3.036,LR: 1.22E-04]Training epoch 68:   6%|▋         | 7/112 [00:00<00:01, 60.86it/s, Epoch: 68, Batch: 8,Loss: -3.046,Avg.Loss: -3.037,LR: 1.22E-04]Training epoch 68:   7%|▋         | 8/112 [00:00<00:01, 60.86it/s, Epoch: 68, Batch: 9,Loss: -2.832,Avg.Loss: -3.014,LR: 1.22E-04]Training epoch 68:   8%|▊         | 9/112 [00:00<00:01, 60.86it/s, Epoch: 68, Batch: 10,Loss: -2.916,Avg.Loss: -3.004,LR: 1.22E-04]Training epoch 68:   9%|▉         | 10/112 [00:00<00:01, 60.86it/s, Epoch: 68, Batch: 11,Loss: -3.203,Avg.Loss: -3.023,LR: 1.22E-04]Training epoch 68:  10%|▉         | 11/112 [00:00<00:01, 60.86it/s, Epoch: 68, Batch: 12,Loss: -2.849,Avg.Loss: -3.008,LR: 1.22E-04]Training epoch 68:  11%|█         | 12/112 [00:00<00:01, 60.86it/s, Epoch: 68, Batch: 13,Loss: -3.361,Avg.Loss: -3.035,LR: 1.22E-04]Training epoch 68:  12%|█▏        | 13/112 [00:00<00:01, 60.86it/s, Epoch: 68, Batch: 14,Loss: -2.734,Avg.Loss: -3.014,LR: 1.22E-04]Training epoch 68:  12%|█▎        | 14/112 [00:00<00:01, 55.87it/s, Epoch: 68, Batch: 14,Loss: -2.734,Avg.Loss: -3.014,LR: 1.22E-04]Training epoch 68:  12%|█▎        | 14/112 [00:00<00:01, 55.87it/s, Epoch: 68, Batch: 15,Loss: -3.502,Avg.Loss: -3.046,LR: 1.22E-04]Training epoch 68:  13%|█▎        | 15/112 [00:00<00:01, 55.87it/s, Epoch: 68, Batch: 16,Loss: -3.164,Avg.Loss: -3.054,LR: 1.22E-04]Training epoch 68:  14%|█▍        | 16/112 [00:00<00:01, 55.87it/s, Epoch: 68, Batch: 17,Loss: -3.054,Avg.Loss: -3.054,LR: 1.22E-04]Training epoch 68:  15%|█▌        | 17/112 [00:00<00:01, 55.87it/s, Epoch: 68, Batch: 18,Loss: -3.275,Avg.Loss: -3.066,LR: 1.22E-04]Training epoch 68:  16%|█▌        | 18/112 [00:00<00:01, 55.87it/s, Epoch: 68, Batch: 19,Loss: -3.228,Avg.Loss: -3.074,LR: 1.22E-04]Training epoch 68:  17%|█▋        | 19/112 [00:00<00:01, 55.87it/s, Epoch: 68, Batch: 20,Loss: -3.530,Avg.Loss: -3.097,LR: 1.22E-04]Training epoch 68:  18%|█▊        | 20/112 [00:00<00:01, 54.72it/s, Epoch: 68, Batch: 20,Loss: -3.530,Avg.Loss: -3.097,LR: 1.22E-04]Training epoch 68:  18%|█▊        | 20/112 [00:00<00:01, 54.72it/s, Epoch: 68, Batch: 21,Loss: -3.086,Avg.Loss: -3.097,LR: 1.21E-04]Training epoch 68:  19%|█▉        | 21/112 [00:00<00:01, 54.72it/s, Epoch: 68, Batch: 22,Loss: -2.995,Avg.Loss: -3.092,LR: 1.21E-04]Training epoch 68:  20%|█▉        | 22/112 [00:00<00:01, 54.72it/s, Epoch: 68, Batch: 23,Loss: -2.846,Avg.Loss: -3.081,LR: 1.21E-04]Training epoch 68:  21%|██        | 23/112 [00:00<00:01, 54.72it/s, Epoch: 68, Batch: 24,Loss: -3.260,Avg.Loss: -3.089,LR: 1.21E-04]Training epoch 68:  21%|██▏       | 24/112 [00:00<00:01, 54.72it/s, Epoch: 68, Batch: 25,Loss: -3.118,Avg.Loss: -3.090,LR: 1.21E-04]Training epoch 68:  22%|██▏       | 25/112 [00:00<00:01, 54.72it/s, Epoch: 68, Batch: 26,Loss: -3.013,Avg.Loss: -3.087,LR: 1.21E-04]Training epoch 68:  23%|██▎       | 26/112 [00:00<00:01, 53.79it/s, Epoch: 68, Batch: 26,Loss: -3.013,Avg.Loss: -3.087,LR: 1.21E-04]Training epoch 68:  23%|██▎       | 26/112 [00:00<00:01, 53.79it/s, Epoch: 68, Batch: 27,Loss: -2.767,Avg.Loss: -3.075,LR: 1.21E-04]Training epoch 68:  24%|██▍       | 27/112 [00:00<00:01, 53.79it/s, Epoch: 68, Batch: 28,Loss: -3.133,Avg.Loss: -3.077,LR: 1.21E-04]Training epoch 68:  25%|██▌       | 28/112 [00:00<00:01, 53.79it/s, Epoch: 68, Batch: 29,Loss: -2.236,Avg.Loss: -3.048,LR: 1.21E-04]Training epoch 68:  26%|██▌       | 29/112 [00:00<00:01, 53.79it/s, Epoch: 68, Batch: 30,Loss: -1.318,Avg.Loss: -2.990,LR: 1.21E-04]Training epoch 68:  27%|██▋       | 30/112 [00:00<00:01, 53.79it/s, Epoch: 68, Batch: 31,Loss: -1.951,Avg.Loss: -2.957,LR: 1.21E-04]Training epoch 68:  28%|██▊       | 31/112 [00:00<00:01, 53.79it/s, Epoch: 68, Batch: 32,Loss: -3.050,Avg.Loss: -2.960,LR: 1.21E-04]Training epoch 68:  29%|██▊       | 32/112 [00:00<00:01, 53.47it/s, Epoch: 68, Batch: 32,Loss: -3.050,Avg.Loss: -2.960,LR: 1.21E-04]Training epoch 68:  29%|██▊       | 32/112 [00:00<00:01, 53.47it/s, Epoch: 68, Batch: 33,Loss: -2.892,Avg.Loss: -2.958,LR: 1.21E-04]Training epoch 68:  29%|██▉       | 33/112 [00:00<00:01, 53.47it/s, Epoch: 68, Batch: 34,Loss: -1.216,Avg.Loss: -2.907,LR: 1.21E-04]Training epoch 68:  30%|███       | 34/112 [00:00<00:01, 53.47it/s, Epoch: 68, Batch: 35,Loss: -1.525,Avg.Loss: -2.867,LR: 1.21E-04]Training epoch 68:  31%|███▏      | 35/112 [00:00<00:01, 53.47it/s, Epoch: 68, Batch: 36,Loss: -2.232,Avg.Loss: -2.849,LR: 1.21E-04]Training epoch 68:  32%|███▏      | 36/112 [00:00<00:01, 53.47it/s, Epoch: 68, Batch: 37,Loss: -3.103,Avg.Loss: -2.856,LR: 1.21E-04]Training epoch 68:  33%|███▎      | 37/112 [00:00<00:01, 53.47it/s, Epoch: 68, Batch: 38,Loss: -2.921,Avg.Loss: -2.858,LR: 1.20E-04]Training epoch 68:  34%|███▍      | 38/112 [00:00<00:01, 53.33it/s, Epoch: 68, Batch: 38,Loss: -2.921,Avg.Loss: -2.858,LR: 1.20E-04]Training epoch 68:  34%|███▍      | 38/112 [00:00<00:01, 53.33it/s, Epoch: 68, Batch: 39,Loss: -3.220,Avg.Loss: -2.867,LR: 1.20E-04]Training epoch 68:  35%|███▍      | 39/112 [00:00<00:01, 53.33it/s, Epoch: 68, Batch: 40,Loss: -3.261,Avg.Loss: -2.877,LR: 1.20E-04]Training epoch 68:  36%|███▌      | 40/112 [00:00<00:01, 53.33it/s, Epoch: 68, Batch: 41,Loss: -3.381,Avg.Loss: -2.889,LR: 1.20E-04]Training epoch 68:  37%|███▋      | 41/112 [00:00<00:01, 53.33it/s, Epoch: 68, Batch: 42,Loss: -3.391,Avg.Loss: -2.901,LR: 1.20E-04]Training epoch 68:  38%|███▊      | 42/112 [00:00<00:01, 53.33it/s, Epoch: 68, Batch: 43,Loss: -3.385,Avg.Loss: -2.913,LR: 1.20E-04]Training epoch 68:  38%|███▊      | 43/112 [00:00<00:01, 53.33it/s, Epoch: 68, Batch: 44,Loss: -3.518,Avg.Loss: -2.926,LR: 1.20E-04]Training epoch 68:  39%|███▉      | 44/112 [00:00<00:01, 53.16it/s, Epoch: 68, Batch: 44,Loss: -3.518,Avg.Loss: -2.926,LR: 1.20E-04]Training epoch 68:  39%|███▉      | 44/112 [00:00<00:01, 53.16it/s, Epoch: 68, Batch: 45,Loss: -3.168,Avg.Loss: -2.932,LR: 1.20E-04]Training epoch 68:  40%|████      | 45/112 [00:00<00:01, 53.16it/s, Epoch: 68, Batch: 46,Loss: -3.209,Avg.Loss: -2.938,LR: 1.20E-04]Training epoch 68:  41%|████      | 46/112 [00:00<00:01, 53.16it/s, Epoch: 68, Batch: 47,Loss: -3.384,Avg.Loss: -2.947,LR: 1.20E-04]Training epoch 68:  42%|████▏     | 47/112 [00:00<00:01, 53.16it/s, Epoch: 68, Batch: 48,Loss: -3.338,Avg.Loss: -2.955,LR: 1.20E-04]Training epoch 68:  43%|████▎     | 48/112 [00:00<00:01, 53.16it/s, Epoch: 68, Batch: 49,Loss: -3.399,Avg.Loss: -2.964,LR: 1.20E-04]Training epoch 68:  44%|████▍     | 49/112 [00:00<00:01, 53.16it/s, Epoch: 68, Batch: 50,Loss: -3.174,Avg.Loss: -2.969,LR: 1.20E-04]Training epoch 68:  45%|████▍     | 50/112 [00:00<00:01, 53.18it/s, Epoch: 68, Batch: 50,Loss: -3.174,Avg.Loss: -2.969,LR: 1.20E-04]Training epoch 68:  45%|████▍     | 50/112 [00:00<00:01, 53.18it/s, Epoch: 68, Batch: 51,Loss: -3.568,Avg.Loss: -2.980,LR: 1.20E-04]Training epoch 68:  46%|████▌     | 51/112 [00:00<00:01, 53.18it/s, Epoch: 68, Batch: 52,Loss: -2.700,Avg.Loss: -2.975,LR: 1.20E-04]Training epoch 68:  46%|████▋     | 52/112 [00:00<00:01, 53.18it/s, Epoch: 68, Batch: 53,Loss: -2.502,Avg.Loss: -2.966,LR: 1.20E-04]Training epoch 68:  47%|████▋     | 53/112 [00:01<00:01, 53.18it/s, Epoch: 68, Batch: 54,Loss: -2.693,Avg.Loss: -2.961,LR: 1.19E-04]Training epoch 68:  48%|████▊     | 54/112 [00:01<00:01, 53.18it/s, Epoch: 68, Batch: 55,Loss: -3.264,Avg.Loss: -2.967,LR: 1.19E-04]Training epoch 68:  49%|████▉     | 55/112 [00:01<00:01, 53.18it/s, Epoch: 68, Batch: 56,Loss: -3.003,Avg.Loss: -2.967,LR: 1.19E-04]Training epoch 68:  50%|█████     | 56/112 [00:01<00:01, 53.15it/s, Epoch: 68, Batch: 56,Loss: -3.003,Avg.Loss: -2.967,LR: 1.19E-04]Training epoch 68:  50%|█████     | 56/112 [00:01<00:01, 53.15it/s, Epoch: 68, Batch: 57,Loss: -3.160,Avg.Loss: -2.971,LR: 1.19E-04]Training epoch 68:  51%|█████     | 57/112 [00:01<00:01, 53.15it/s, Epoch: 68, Batch: 58,Loss: -2.866,Avg.Loss: -2.969,LR: 1.19E-04]Training epoch 68:  52%|█████▏    | 58/112 [00:01<00:01, 53.15it/s, Epoch: 68, Batch: 59,Loss: -3.102,Avg.Loss: -2.971,LR: 1.19E-04]Training epoch 68:  53%|█████▎    | 59/112 [00:01<00:00, 53.15it/s, Epoch: 68, Batch: 60,Loss: -2.532,Avg.Loss: -2.964,LR: 1.19E-04]Training epoch 68:  54%|█████▎    | 60/112 [00:01<00:00, 53.15it/s, Epoch: 68, Batch: 61,Loss: -3.360,Avg.Loss: -2.970,LR: 1.19E-04]Training epoch 68:  54%|█████▍    | 61/112 [00:01<00:00, 53.15it/s, Epoch: 68, Batch: 62,Loss: -3.082,Avg.Loss: -2.972,LR: 1.19E-04]Training epoch 68:  55%|█████▌    | 62/112 [00:01<00:00, 53.31it/s, Epoch: 68, Batch: 62,Loss: -3.082,Avg.Loss: -2.972,LR: 1.19E-04]Training epoch 68:  55%|█████▌    | 62/112 [00:01<00:00, 53.31it/s, Epoch: 68, Batch: 63,Loss: -3.308,Avg.Loss: -2.977,LR: 1.19E-04]Training epoch 68:  56%|█████▋    | 63/112 [00:01<00:00, 53.31it/s, Epoch: 68, Batch: 64,Loss: -2.765,Avg.Loss: -2.974,LR: 1.19E-04]Training epoch 68:  57%|█████▋    | 64/112 [00:01<00:00, 53.31it/s, Epoch: 68, Batch: 65,Loss: -2.322,Avg.Loss: -2.964,LR: 1.19E-04]Training epoch 68:  58%|█████▊    | 65/112 [00:01<00:00, 53.31it/s, Epoch: 68, Batch: 66,Loss: -2.933,Avg.Loss: -2.963,LR: 1.19E-04]Training epoch 68:  59%|█████▉    | 66/112 [00:01<00:00, 53.31it/s, Epoch: 68, Batch: 67,Loss: -3.186,Avg.Loss: -2.967,LR: 1.19E-04]Training epoch 68:  60%|█████▉    | 67/112 [00:01<00:00, 53.31it/s, Epoch: 68, Batch: 68,Loss: -3.140,Avg.Loss: -2.969,LR: 1.19E-04]Training epoch 68:  61%|██████    | 68/112 [00:01<00:00, 53.35it/s, Epoch: 68, Batch: 68,Loss: -3.140,Avg.Loss: -2.969,LR: 1.19E-04]Training epoch 68:  61%|██████    | 68/112 [00:01<00:00, 53.35it/s, Epoch: 68, Batch: 69,Loss: -3.410,Avg.Loss: -2.976,LR: 1.19E-04]Training epoch 68:  62%|██████▏   | 69/112 [00:01<00:00, 53.35it/s, Epoch: 68, Batch: 70,Loss: -3.569,Avg.Loss: -2.984,LR: 1.19E-04]Training epoch 68:  62%|██████▎   | 70/112 [00:01<00:00, 53.35it/s, Epoch: 68, Batch: 71,Loss: -3.412,Avg.Loss: -2.990,LR: 1.18E-04]Training epoch 68:  63%|██████▎   | 71/112 [00:01<00:00, 53.35it/s, Epoch: 68, Batch: 72,Loss: -2.901,Avg.Loss: -2.989,LR: 1.18E-04]Training epoch 68:  64%|██████▍   | 72/112 [00:01<00:00, 53.35it/s, Epoch: 68, Batch: 73,Loss: -3.014,Avg.Loss: -2.989,LR: 1.18E-04]Training epoch 68:  65%|██████▌   | 73/112 [00:01<00:00, 53.35it/s, Epoch: 68, Batch: 74,Loss: -3.304,Avg.Loss: -2.994,LR: 1.18E-04]Training epoch 68:  66%|██████▌   | 74/112 [00:01<00:00, 53.33it/s, Epoch: 68, Batch: 74,Loss: -3.304,Avg.Loss: -2.994,LR: 1.18E-04]Training epoch 68:  66%|██████▌   | 74/112 [00:01<00:00, 53.33it/s, Epoch: 68, Batch: 75,Loss: -3.020,Avg.Loss: -2.994,LR: 1.18E-04]Training epoch 68:  67%|██████▋   | 75/112 [00:01<00:00, 53.33it/s, Epoch: 68, Batch: 76,Loss: -3.216,Avg.Loss: -2.997,LR: 1.18E-04]Training epoch 68:  68%|██████▊   | 76/112 [00:01<00:00, 53.33it/s, Epoch: 68, Batch: 77,Loss: -3.508,Avg.Loss: -3.004,LR: 1.18E-04]Training epoch 68:  69%|██████▉   | 77/112 [00:01<00:00, 53.33it/s, Epoch: 68, Batch: 78,Loss: -3.142,Avg.Loss: -3.005,LR: 1.18E-04]Training epoch 68:  70%|██████▉   | 78/112 [00:01<00:00, 53.33it/s, Epoch: 68, Batch: 79,Loss: -3.289,Avg.Loss: -3.009,LR: 1.18E-04]Training epoch 68:  71%|███████   | 79/112 [00:01<00:00, 53.33it/s, Epoch: 68, Batch: 80,Loss: -3.227,Avg.Loss: -3.012,LR: 1.18E-04]Training epoch 68:  71%|███████▏  | 80/112 [00:01<00:00, 53.17it/s, Epoch: 68, Batch: 80,Loss: -3.227,Avg.Loss: -3.012,LR: 1.18E-04]Training epoch 68:  71%|███████▏  | 80/112 [00:01<00:00, 53.17it/s, Epoch: 68, Batch: 81,Loss: -3.131,Avg.Loss: -3.013,LR: 1.18E-04]Training epoch 68:  72%|███████▏  | 81/112 [00:01<00:00, 53.17it/s, Epoch: 68, Batch: 82,Loss: -3.359,Avg.Loss: -3.017,LR: 1.18E-04]Training epoch 68:  73%|███████▎  | 82/112 [00:01<00:00, 53.17it/s, Epoch: 68, Batch: 83,Loss: -3.266,Avg.Loss: -3.020,LR: 1.18E-04]Training epoch 68:  74%|███████▍  | 83/112 [00:01<00:00, 53.17it/s, Epoch: 68, Batch: 84,Loss: -2.942,Avg.Loss: -3.019,LR: 1.18E-04]Training epoch 68:  75%|███████▌  | 84/112 [00:01<00:00, 53.17it/s, Epoch: 68, Batch: 85,Loss: -2.686,Avg.Loss: -3.015,LR: 1.18E-04]Training epoch 68:  76%|███████▌  | 85/112 [00:01<00:00, 53.17it/s, Epoch: 68, Batch: 86,Loss: -3.007,Avg.Loss: -3.015,LR: 1.18E-04]Training epoch 68:  77%|███████▋  | 86/112 [00:01<00:00, 53.29it/s, Epoch: 68, Batch: 86,Loss: -3.007,Avg.Loss: -3.015,LR: 1.18E-04]Training epoch 68:  77%|███████▋  | 86/112 [00:01<00:00, 53.29it/s, Epoch: 68, Batch: 87,Loss: -2.920,Avg.Loss: -3.014,LR: 1.18E-04]Training epoch 68:  78%|███████▊  | 87/112 [00:01<00:00, 53.29it/s, Epoch: 68, Batch: 88,Loss: -2.692,Avg.Loss: -3.011,LR: 1.17E-04]Training epoch 68:  79%|███████▊  | 88/112 [00:01<00:00, 53.29it/s, Epoch: 68, Batch: 89,Loss: -3.207,Avg.Loss: -3.013,LR: 1.17E-04]Training epoch 68:  79%|███████▉  | 89/112 [00:01<00:00, 53.29it/s, Epoch: 68, Batch: 90,Loss: -2.923,Avg.Loss: -3.012,LR: 1.17E-04]Training epoch 68:  80%|████████  | 90/112 [00:01<00:00, 53.29it/s, Epoch: 68, Batch: 91,Loss: -2.567,Avg.Loss: -3.007,LR: 1.17E-04]Training epoch 68:  81%|████████▏ | 91/112 [00:01<00:00, 53.29it/s, Epoch: 68, Batch: 92,Loss: -2.518,Avg.Loss: -3.002,LR: 1.17E-04]Training epoch 68:  82%|████████▏ | 92/112 [00:01<00:00, 53.58it/s, Epoch: 68, Batch: 92,Loss: -2.518,Avg.Loss: -3.002,LR: 1.17E-04]Training epoch 68:  82%|████████▏ | 92/112 [00:01<00:00, 53.58it/s, Epoch: 68, Batch: 93,Loss: -3.291,Avg.Loss: -3.005,LR: 1.17E-04]Training epoch 68:  83%|████████▎ | 93/112 [00:01<00:00, 53.58it/s, Epoch: 68, Batch: 94,Loss: -2.716,Avg.Loss: -3.002,LR: 1.17E-04]Training epoch 68:  84%|████████▍ | 94/112 [00:01<00:00, 53.58it/s, Epoch: 68, Batch: 95,Loss: -3.270,Avg.Loss: -3.004,LR: 1.17E-04]Training epoch 68:  85%|████████▍ | 95/112 [00:01<00:00, 53.58it/s, Epoch: 68, Batch: 96,Loss: -3.065,Avg.Loss: -3.005,LR: 1.17E-04]Training epoch 68:  86%|████████▌ | 96/112 [00:01<00:00, 53.58it/s, Epoch: 68, Batch: 97,Loss: -2.141,Avg.Loss: -2.996,LR: 1.17E-04]Training epoch 68:  87%|████████▋ | 97/112 [00:01<00:00, 53.58it/s, Epoch: 68, Batch: 98,Loss: -3.040,Avg.Loss: -2.997,LR: 1.17E-04]Training epoch 68:  88%|████████▊ | 98/112 [00:01<00:00, 53.46it/s, Epoch: 68, Batch: 98,Loss: -3.040,Avg.Loss: -2.997,LR: 1.17E-04]Training epoch 68:  88%|████████▊ | 98/112 [00:01<00:00, 53.46it/s, Epoch: 68, Batch: 99,Loss: -2.501,Avg.Loss: -2.992,LR: 1.17E-04]Training epoch 68:  88%|████████▊ | 99/112 [00:01<00:00, 53.46it/s, Epoch: 68, Batch: 100,Loss: -2.253,Avg.Loss: -2.984,LR: 1.17E-04]Training epoch 68:  89%|████████▉ | 100/112 [00:01<00:00, 53.46it/s, Epoch: 68, Batch: 101,Loss: -3.108,Avg.Loss: -2.985,LR: 1.17E-04]Training epoch 68:  90%|█████████ | 101/112 [00:01<00:00, 53.46it/s, Epoch: 68, Batch: 102,Loss: -2.983,Avg.Loss: -2.985,LR: 1.17E-04]Training epoch 68:  91%|█████████ | 102/112 [00:01<00:00, 53.46it/s, Epoch: 68, Batch: 103,Loss: -3.059,Avg.Loss: -2.986,LR: 1.17E-04]Training epoch 68:  92%|█████████▏| 103/112 [00:01<00:00, 53.46it/s, Epoch: 68, Batch: 104,Loss: -3.449,Avg.Loss: -2.991,LR: 1.17E-04]Training epoch 68:  93%|█████████▎| 104/112 [00:01<00:00, 53.73it/s, Epoch: 68, Batch: 104,Loss: -3.449,Avg.Loss: -2.991,LR: 1.17E-04]Training epoch 68:  93%|█████████▎| 104/112 [00:01<00:00, 53.73it/s, Epoch: 68, Batch: 105,Loss: -3.011,Avg.Loss: -2.991,LR: 1.16E-04]Training epoch 68:  94%|█████████▍| 105/112 [00:01<00:00, 53.73it/s, Epoch: 68, Batch: 106,Loss: -2.883,Avg.Loss: -2.990,LR: 1.16E-04]Training epoch 68:  95%|█████████▍| 106/112 [00:01<00:00, 53.73it/s, Epoch: 68, Batch: 107,Loss: -2.847,Avg.Loss: -2.988,LR: 1.16E-04]Training epoch 68:  96%|█████████▌| 107/112 [00:02<00:00, 53.73it/s, Epoch: 68, Batch: 108,Loss: -3.047,Avg.Loss: -2.989,LR: 1.16E-04]Training epoch 68:  96%|█████████▋| 108/112 [00:02<00:00, 53.73it/s, Epoch: 68, Batch: 109,Loss: -2.453,Avg.Loss: -2.984,LR: 1.16E-04]Training epoch 68:  97%|█████████▋| 109/112 [00:02<00:00, 53.73it/s, Epoch: 68, Batch: 110,Loss: -3.238,Avg.Loss: -2.986,LR: 1.16E-04]Training epoch 68:  98%|█████████▊| 110/112 [00:02<00:00, 53.62it/s, Epoch: 68, Batch: 110,Loss: -3.238,Avg.Loss: -2.986,LR: 1.16E-04]Training epoch 68:  98%|█████████▊| 110/112 [00:02<00:00, 53.62it/s, Epoch: 68, Batch: 111,Loss: -3.095,Avg.Loss: -2.987,LR: 1.16E-04]Training epoch 68:  99%|█████████▉| 111/112 [00:02<00:00, 53.62it/s, Epoch: 68, Batch: 112,Loss: -3.603,Avg.Loss: -2.993,LR: 1.16E-04]Training epoch 68: 100%|██████████| 112/112 [00:02<00:00, 53.59it/s, Epoch: 68, Batch: 112,Loss: -3.603,Avg.Loss: -2.993,LR: 1.16E-04]
Training epoch 69:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 69:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 69, Batch: 1,Loss: -3.130,Avg.Loss: -3.130,LR: 1.16E-04]Training epoch 69:   1%|          | 1/112 [00:00<00:03, 31.41it/s, Epoch: 69, Batch: 2,Loss: -3.248,Avg.Loss: -3.189,LR: 1.16E-04]Training epoch 69:   2%|▏         | 2/112 [00:00<00:02, 45.00it/s, Epoch: 69, Batch: 3,Loss: -3.123,Avg.Loss: -3.167,LR: 1.16E-04]Training epoch 69:   3%|▎         | 3/112 [00:00<00:02, 51.59it/s, Epoch: 69, Batch: 4,Loss: -2.633,Avg.Loss: -3.033,LR: 1.16E-04]Training epoch 69:   4%|▎         | 4/112 [00:00<00:01, 55.24it/s, Epoch: 69, Batch: 5,Loss: -2.133,Avg.Loss: -2.853,LR: 1.16E-04]Training epoch 69:   4%|▍         | 5/112 [00:00<00:01, 57.36it/s, Epoch: 69, Batch: 6,Loss: -2.534,Avg.Loss: -2.800,LR: 1.16E-04]Training epoch 69:   5%|▌         | 6/112 [00:00<00:01, 56.55it/s, Epoch: 69, Batch: 7,Loss: -1.521,Avg.Loss: -2.617,LR: 1.16E-04]Training epoch 69:   6%|▋         | 7/112 [00:00<00:01, 65.86it/s, Epoch: 69, Batch: 7,Loss: -1.521,Avg.Loss: -2.617,LR: 1.16E-04]Training epoch 69:   6%|▋         | 7/112 [00:00<00:01, 65.86it/s, Epoch: 69, Batch: 8,Loss: -2.852,Avg.Loss: -2.647,LR: 1.16E-04]Training epoch 69:   7%|▋         | 8/112 [00:00<00:01, 65.86it/s, Epoch: 69, Batch: 9,Loss: -3.046,Avg.Loss: -2.691,LR: 1.16E-04]Training epoch 69:   8%|▊         | 9/112 [00:00<00:01, 65.86it/s, Epoch: 69, Batch: 10,Loss: -3.139,Avg.Loss: -2.736,LR: 1.15E-04]Training epoch 69:   9%|▉         | 10/112 [00:00<00:01, 65.86it/s, Epoch: 69, Batch: 11,Loss: -3.113,Avg.Loss: -2.770,LR: 1.15E-04]Training epoch 69:  10%|▉         | 11/112 [00:00<00:01, 65.86it/s, Epoch: 69, Batch: 12,Loss: -2.716,Avg.Loss: -2.766,LR: 1.15E-04]Training epoch 69:  11%|█         | 12/112 [00:00<00:01, 65.86it/s, Epoch: 69, Batch: 13,Loss: -3.030,Avg.Loss: -2.786,LR: 1.15E-04]Training epoch 69:  12%|█▏        | 13/112 [00:00<00:01, 65.86it/s, Epoch: 69, Batch: 14,Loss: -3.372,Avg.Loss: -2.828,LR: 1.15E-04]Training epoch 69:  12%|█▎        | 14/112 [00:00<00:01, 59.66it/s, Epoch: 69, Batch: 14,Loss: -3.372,Avg.Loss: -2.828,LR: 1.15E-04]Training epoch 69:  12%|█▎        | 14/112 [00:00<00:01, 59.66it/s, Epoch: 69, Batch: 15,Loss: -2.965,Avg.Loss: -2.837,LR: 1.15E-04]Training epoch 69:  13%|█▎        | 15/112 [00:00<00:01, 59.66it/s, Epoch: 69, Batch: 16,Loss: -2.840,Avg.Loss: -2.837,LR: 1.15E-04]Training epoch 69:  14%|█▍        | 16/112 [00:00<00:01, 59.66it/s, Epoch: 69, Batch: 17,Loss: -2.724,Avg.Loss: -2.831,LR: 1.15E-04]Training epoch 69:  15%|█▌        | 17/112 [00:00<00:01, 59.66it/s, Epoch: 69, Batch: 18,Loss: -3.297,Avg.Loss: -2.856,LR: 1.15E-04]Training epoch 69:  16%|█▌        | 18/112 [00:00<00:01, 59.66it/s, Epoch: 69, Batch: 19,Loss: -2.882,Avg.Loss: -2.858,LR: 1.15E-04]Training epoch 69:  17%|█▋        | 19/112 [00:00<00:01, 59.66it/s, Epoch: 69, Batch: 20,Loss: -2.511,Avg.Loss: -2.840,LR: 1.15E-04]Training epoch 69:  18%|█▊        | 20/112 [00:00<00:01, 59.66it/s, Epoch: 69, Batch: 21,Loss: -2.917,Avg.Loss: -2.844,LR: 1.15E-04]Training epoch 69:  19%|█▉        | 21/112 [00:00<00:01, 56.31it/s, Epoch: 69, Batch: 21,Loss: -2.917,Avg.Loss: -2.844,LR: 1.15E-04]Training epoch 69:  19%|█▉        | 21/112 [00:00<00:01, 56.31it/s, Epoch: 69, Batch: 22,Loss: -2.154,Avg.Loss: -2.813,LR: 1.15E-04]Training epoch 69:  20%|█▉        | 22/112 [00:00<00:01, 56.31it/s, Epoch: 69, Batch: 23,Loss: -2.295,Avg.Loss: -2.790,LR: 1.15E-04]Training epoch 69:  21%|██        | 23/112 [00:00<00:01, 56.31it/s, Epoch: 69, Batch: 24,Loss: -2.502,Avg.Loss: -2.778,LR: 1.15E-04]Training epoch 69:  21%|██▏       | 24/112 [00:00<00:01, 56.31it/s, Epoch: 69, Batch: 25,Loss: -3.387,Avg.Loss: -2.803,LR: 1.15E-04]Training epoch 69:  22%|██▏       | 25/112 [00:00<00:01, 56.31it/s, Epoch: 69, Batch: 26,Loss: -2.932,Avg.Loss: -2.807,LR: 1.15E-04]Training epoch 69:  23%|██▎       | 26/112 [00:00<00:01, 56.31it/s, Epoch: 69, Batch: 27,Loss: -3.593,Avg.Loss: -2.837,LR: 1.14E-04]Training epoch 69:  24%|██▍       | 27/112 [00:00<00:01, 54.71it/s, Epoch: 69, Batch: 27,Loss: -3.593,Avg.Loss: -2.837,LR: 1.14E-04]Training epoch 69:  24%|██▍       | 27/112 [00:00<00:01, 54.71it/s, Epoch: 69, Batch: 28,Loss: -3.077,Avg.Loss: -2.845,LR: 1.14E-04]Training epoch 69:  25%|██▌       | 28/112 [00:00<00:01, 54.71it/s, Epoch: 69, Batch: 29,Loss: -2.895,Avg.Loss: -2.847,LR: 1.14E-04]Training epoch 69:  26%|██▌       | 29/112 [00:00<00:01, 54.71it/s, Epoch: 69, Batch: 30,Loss: -3.358,Avg.Loss: -2.864,LR: 1.14E-04]Training epoch 69:  27%|██▋       | 30/112 [00:00<00:01, 54.71it/s, Epoch: 69, Batch: 31,Loss: -3.103,Avg.Loss: -2.872,LR: 1.14E-04]Training epoch 69:  28%|██▊       | 31/112 [00:00<00:01, 54.71it/s, Epoch: 69, Batch: 32,Loss: -2.568,Avg.Loss: -2.862,LR: 1.14E-04]Training epoch 69:  29%|██▊       | 32/112 [00:00<00:01, 54.71it/s, Epoch: 69, Batch: 33,Loss: -3.068,Avg.Loss: -2.868,LR: 1.14E-04]Training epoch 69:  29%|██▉       | 33/112 [00:00<00:01, 53.95it/s, Epoch: 69, Batch: 33,Loss: -3.068,Avg.Loss: -2.868,LR: 1.14E-04]Training epoch 69:  29%|██▉       | 33/112 [00:00<00:01, 53.95it/s, Epoch: 69, Batch: 34,Loss: -3.436,Avg.Loss: -2.885,LR: 1.14E-04]Training epoch 69:  30%|███       | 34/112 [00:00<00:01, 53.95it/s, Epoch: 69, Batch: 35,Loss: -3.245,Avg.Loss: -2.895,LR: 1.14E-04]Training epoch 69:  31%|███▏      | 35/112 [00:00<00:01, 53.95it/s, Epoch: 69, Batch: 36,Loss: -3.222,Avg.Loss: -2.904,LR: 1.14E-04]Training epoch 69:  32%|███▏      | 36/112 [00:00<00:01, 53.95it/s, Epoch: 69, Batch: 37,Loss: -2.781,Avg.Loss: -2.901,LR: 1.14E-04]Training epoch 69:  33%|███▎      | 37/112 [00:00<00:01, 53.95it/s, Epoch: 69, Batch: 38,Loss: -3.167,Avg.Loss: -2.908,LR: 1.14E-04]Training epoch 69:  34%|███▍      | 38/112 [00:00<00:01, 53.95it/s, Epoch: 69, Batch: 39,Loss: -3.217,Avg.Loss: -2.916,LR: 1.14E-04]Training epoch 69:  35%|███▍      | 39/112 [00:00<00:01, 53.74it/s, Epoch: 69, Batch: 39,Loss: -3.217,Avg.Loss: -2.916,LR: 1.14E-04]Training epoch 69:  35%|███▍      | 39/112 [00:00<00:01, 53.74it/s, Epoch: 69, Batch: 40,Loss: -2.950,Avg.Loss: -2.917,LR: 1.14E-04]Training epoch 69:  36%|███▌      | 40/112 [00:00<00:01, 53.74it/s, Epoch: 69, Batch: 41,Loss: -2.872,Avg.Loss: -2.916,LR: 1.14E-04]Training epoch 69:  37%|███▋      | 41/112 [00:00<00:01, 53.74it/s, Epoch: 69, Batch: 42,Loss: -3.256,Avg.Loss: -2.924,LR: 1.14E-04]Training epoch 69:  38%|███▊      | 42/112 [00:00<00:01, 53.74it/s, Epoch: 69, Batch: 43,Loss: -2.640,Avg.Loss: -2.917,LR: 1.14E-04]Training epoch 69:  38%|███▊      | 43/112 [00:00<00:01, 53.74it/s, Epoch: 69, Batch: 44,Loss: -2.397,Avg.Loss: -2.905,LR: 1.13E-04]Training epoch 69:  39%|███▉      | 44/112 [00:00<00:01, 53.74it/s, Epoch: 69, Batch: 45,Loss: -3.115,Avg.Loss: -2.910,LR: 1.13E-04]Training epoch 69:  40%|████      | 45/112 [00:00<00:01, 53.46it/s, Epoch: 69, Batch: 45,Loss: -3.115,Avg.Loss: -2.910,LR: 1.13E-04]Training epoch 69:  40%|████      | 45/112 [00:00<00:01, 53.46it/s, Epoch: 69, Batch: 46,Loss: -3.162,Avg.Loss: -2.916,LR: 1.13E-04]Training epoch 69:  41%|████      | 46/112 [00:00<00:01, 53.46it/s, Epoch: 69, Batch: 47,Loss: -2.535,Avg.Loss: -2.907,LR: 1.13E-04]Training epoch 69:  42%|████▏     | 47/112 [00:00<00:01, 53.46it/s, Epoch: 69, Batch: 48,Loss: -0.280,Avg.Loss: -2.853,LR: 1.13E-04]Training epoch 69:  43%|████▎     | 48/112 [00:00<00:01, 53.46it/s, Epoch: 69, Batch: 49,Loss: 0.040,Avg.Loss: -2.794,LR: 1.13E-04] Training epoch 69:  44%|████▍     | 49/112 [00:00<00:01, 53.46it/s, Epoch: 69, Batch: 50,Loss: -2.246,Avg.Loss: -2.783,LR: 1.13E-04]Training epoch 69:  45%|████▍     | 50/112 [00:00<00:01, 53.46it/s, Epoch: 69, Batch: 51,Loss: -3.218,Avg.Loss: -2.791,LR: 1.13E-04]Training epoch 69:  46%|████▌     | 51/112 [00:00<00:01, 53.22it/s, Epoch: 69, Batch: 51,Loss: -3.218,Avg.Loss: -2.791,LR: 1.13E-04]Training epoch 69:  46%|████▌     | 51/112 [00:00<00:01, 53.22it/s, Epoch: 69, Batch: 52,Loss: -2.176,Avg.Loss: -2.779,LR: 1.13E-04]Training epoch 69:  46%|████▋     | 52/112 [00:00<00:01, 53.22it/s, Epoch: 69, Batch: 53,Loss: -0.322,Avg.Loss: -2.733,LR: 1.13E-04]Training epoch 69:  47%|████▋     | 53/112 [00:00<00:01, 53.22it/s, Epoch: 69, Batch: 54,Loss: 0.158,Avg.Loss: -2.679,LR: 1.13E-04] Training epoch 69:  48%|████▊     | 54/112 [00:01<00:01, 53.22it/s, Epoch: 69, Batch: 55,Loss: -0.488,Avg.Loss: -2.640,LR: 1.13E-04]Training epoch 69:  49%|████▉     | 55/112 [00:01<00:01, 53.22it/s, Epoch: 69, Batch: 56,Loss: -2.997,Avg.Loss: -2.646,LR: 1.13E-04]Training epoch 69:  50%|█████     | 56/112 [00:01<00:01, 53.22it/s, Epoch: 69, Batch: 57,Loss: -2.620,Avg.Loss: -2.646,LR: 1.13E-04]Training epoch 69:  51%|█████     | 57/112 [00:01<00:01, 53.08it/s, Epoch: 69, Batch: 57,Loss: -2.620,Avg.Loss: -2.646,LR: 1.13E-04]Training epoch 69:  51%|█████     | 57/112 [00:01<00:01, 53.08it/s, Epoch: 69, Batch: 58,Loss: -1.889,Avg.Loss: -2.633,LR: 1.13E-04]Training epoch 69:  52%|█████▏    | 58/112 [00:01<00:01, 53.08it/s, Epoch: 69, Batch: 59,Loss: -1.669,Avg.Loss: -2.616,LR: 1.13E-04]Training epoch 69:  53%|█████▎    | 59/112 [00:01<00:00, 53.08it/s, Epoch: 69, Batch: 60,Loss: -2.643,Avg.Loss: -2.617,LR: 1.13E-04]Training epoch 69:  54%|█████▎    | 60/112 [00:01<00:00, 53.08it/s, Epoch: 69, Batch: 61,Loss: -2.963,Avg.Loss: -2.622,LR: 1.12E-04]Training epoch 69:  54%|█████▍    | 61/112 [00:01<00:00, 53.08it/s, Epoch: 69, Batch: 62,Loss: -1.800,Avg.Loss: -2.609,LR: 1.12E-04]Training epoch 69:  55%|█████▌    | 62/112 [00:01<00:00, 53.08it/s, Epoch: 69, Batch: 63,Loss: -0.842,Avg.Loss: -2.581,LR: 1.12E-04]Training epoch 69:  56%|█████▋    | 63/112 [00:01<00:00, 52.94it/s, Epoch: 69, Batch: 63,Loss: -0.842,Avg.Loss: -2.581,LR: 1.12E-04]Training epoch 69:  56%|█████▋    | 63/112 [00:01<00:00, 52.94it/s, Epoch: 69, Batch: 64,Loss: -0.743,Avg.Loss: -2.552,LR: 1.12E-04]Training epoch 69:  57%|█████▋    | 64/112 [00:01<00:00, 52.94it/s, Epoch: 69, Batch: 65,Loss: -2.076,Avg.Loss: -2.545,LR: 1.12E-04]Training epoch 69:  58%|█████▊    | 65/112 [00:01<00:00, 52.94it/s, Epoch: 69, Batch: 66,Loss: -1.874,Avg.Loss: -2.535,LR: 1.12E-04]Training epoch 69:  59%|█████▉    | 66/112 [00:01<00:00, 52.94it/s, Epoch: 69, Batch: 67,Loss: -2.037,Avg.Loss: -2.527,LR: 1.12E-04]Training epoch 69:  60%|█████▉    | 67/112 [00:01<00:00, 52.94it/s, Epoch: 69, Batch: 68,Loss: -1.766,Avg.Loss: -2.516,LR: 1.12E-04]Training epoch 69:  61%|██████    | 68/112 [00:01<00:00, 52.94it/s, Epoch: 69, Batch: 69,Loss: -2.246,Avg.Loss: -2.512,LR: 1.12E-04]Training epoch 69:  62%|██████▏   | 69/112 [00:01<00:00, 52.98it/s, Epoch: 69, Batch: 69,Loss: -2.246,Avg.Loss: -2.512,LR: 1.12E-04]Training epoch 69:  62%|██████▏   | 69/112 [00:01<00:00, 52.98it/s, Epoch: 69, Batch: 70,Loss: -3.193,Avg.Loss: -2.522,LR: 1.12E-04]Training epoch 69:  62%|██████▎   | 70/112 [00:01<00:00, 52.98it/s, Epoch: 69, Batch: 71,Loss: -1.844,Avg.Loss: -2.512,LR: 1.12E-04]Training epoch 69:  63%|██████▎   | 71/112 [00:01<00:00, 52.98it/s, Epoch: 69, Batch: 72,Loss: -1.106,Avg.Loss: -2.493,LR: 1.12E-04]Training epoch 69:  64%|██████▍   | 72/112 [00:01<00:00, 52.98it/s, Epoch: 69, Batch: 73,Loss: -0.223,Avg.Loss: -2.462,LR: 1.12E-04]Training epoch 69:  65%|██████▌   | 73/112 [00:01<00:00, 52.98it/s, Epoch: 69, Batch: 74,Loss: -0.960,Avg.Loss: -2.442,LR: 1.12E-04]Training epoch 69:  66%|██████▌   | 74/112 [00:01<00:00, 52.98it/s, Epoch: 69, Batch: 75,Loss: -2.360,Avg.Loss: -2.440,LR: 1.12E-04]Training epoch 69:  67%|██████▋   | 75/112 [00:01<00:00, 52.68it/s, Epoch: 69, Batch: 75,Loss: -2.360,Avg.Loss: -2.440,LR: 1.12E-04]Training epoch 69:  67%|██████▋   | 75/112 [00:01<00:00, 52.68it/s, Epoch: 69, Batch: 76,Loss: -2.258,Avg.Loss: -2.438,LR: 1.12E-04]Training epoch 69:  68%|██████▊   | 76/112 [00:01<00:00, 52.68it/s, Epoch: 69, Batch: 77,Loss: -1.370,Avg.Loss: -2.424,LR: 1.12E-04]Training epoch 69:  69%|██████▉   | 77/112 [00:01<00:00, 52.68it/s, Epoch: 69, Batch: 78,Loss: -2.280,Avg.Loss: -2.422,LR: 1.11E-04]Training epoch 69:  70%|██████▉   | 78/112 [00:01<00:00, 52.68it/s, Epoch: 69, Batch: 79,Loss: -3.134,Avg.Loss: -2.431,LR: 1.11E-04]Training epoch 69:  71%|███████   | 79/112 [00:01<00:00, 52.68it/s, Epoch: 69, Batch: 80,Loss: -2.251,Avg.Loss: -2.429,LR: 1.11E-04]Training epoch 69:  71%|███████▏  | 80/112 [00:01<00:00, 52.68it/s, Epoch: 69, Batch: 81,Loss: -1.488,Avg.Loss: -2.417,LR: 1.11E-04]Training epoch 69:  72%|███████▏  | 81/112 [00:01<00:00, 52.83it/s, Epoch: 69, Batch: 81,Loss: -1.488,Avg.Loss: -2.417,LR: 1.11E-04]Training epoch 69:  72%|███████▏  | 81/112 [00:01<00:00, 52.83it/s, Epoch: 69, Batch: 82,Loss: -1.908,Avg.Loss: -2.411,LR: 1.11E-04]Training epoch 69:  73%|███████▎  | 82/112 [00:01<00:00, 52.83it/s, Epoch: 69, Batch: 83,Loss: -2.461,Avg.Loss: -2.412,LR: 1.11E-04]Training epoch 69:  74%|███████▍  | 83/112 [00:01<00:00, 52.83it/s, Epoch: 69, Batch: 84,Loss: -2.420,Avg.Loss: -2.412,LR: 1.11E-04]Training epoch 69:  75%|███████▌  | 84/112 [00:01<00:00, 52.83it/s, Epoch: 69, Batch: 85,Loss: -1.918,Avg.Loss: -2.406,LR: 1.11E-04]Training epoch 69:  76%|███████▌  | 85/112 [00:01<00:00, 52.83it/s, Epoch: 69, Batch: 86,Loss: -2.430,Avg.Loss: -2.406,LR: 1.11E-04]Training epoch 69:  77%|███████▋  | 86/112 [00:01<00:00, 52.83it/s, Epoch: 69, Batch: 87,Loss: -3.160,Avg.Loss: -2.415,LR: 1.11E-04]Training epoch 69:  78%|███████▊  | 87/112 [00:01<00:00, 53.37it/s, Epoch: 69, Batch: 87,Loss: -3.160,Avg.Loss: -2.415,LR: 1.11E-04]Training epoch 69:  78%|███████▊  | 87/112 [00:01<00:00, 53.37it/s, Epoch: 69, Batch: 88,Loss: -2.961,Avg.Loss: -2.421,LR: 1.11E-04]Training epoch 69:  79%|███████▊  | 88/112 [00:01<00:00, 53.37it/s, Epoch: 69, Batch: 89,Loss: -2.888,Avg.Loss: -2.427,LR: 1.11E-04]Training epoch 69:  79%|███████▉  | 89/112 [00:01<00:00, 53.37it/s, Epoch: 69, Batch: 90,Loss: -2.888,Avg.Loss: -2.432,LR: 1.11E-04]Training epoch 69:  80%|████████  | 90/112 [00:01<00:00, 53.37it/s, Epoch: 69, Batch: 91,Loss: -3.207,Avg.Loss: -2.440,LR: 1.11E-04]Training epoch 69:  81%|████████▏ | 91/112 [00:01<00:00, 53.37it/s, Epoch: 69, Batch: 92,Loss: -3.271,Avg.Loss: -2.449,LR: 1.11E-04]Training epoch 69:  82%|████████▏ | 92/112 [00:01<00:00, 53.37it/s, Epoch: 69, Batch: 93,Loss: -3.295,Avg.Loss: -2.458,LR: 1.11E-04]Training epoch 69:  83%|████████▎ | 93/112 [00:01<00:00, 53.55it/s, Epoch: 69, Batch: 93,Loss: -3.295,Avg.Loss: -2.458,LR: 1.11E-04]Training epoch 69:  83%|████████▎ | 93/112 [00:01<00:00, 53.55it/s, Epoch: 69, Batch: 94,Loss: -3.004,Avg.Loss: -2.464,LR: 1.11E-04]Training epoch 69:  84%|████████▍ | 94/112 [00:01<00:00, 53.55it/s, Epoch: 69, Batch: 95,Loss: -3.046,Avg.Loss: -2.470,LR: 1.10E-04]Training epoch 69:  85%|████████▍ | 95/112 [00:01<00:00, 53.55it/s, Epoch: 69, Batch: 96,Loss: -3.064,Avg.Loss: -2.476,LR: 1.10E-04]Training epoch 69:  86%|████████▌ | 96/112 [00:01<00:00, 53.55it/s, Epoch: 69, Batch: 97,Loss: -3.275,Avg.Loss: -2.485,LR: 1.10E-04]Training epoch 69:  87%|████████▋ | 97/112 [00:01<00:00, 53.55it/s, Epoch: 69, Batch: 98,Loss: -3.199,Avg.Loss: -2.492,LR: 1.10E-04]Training epoch 69:  88%|████████▊ | 98/112 [00:01<00:00, 53.55it/s, Epoch: 69, Batch: 99,Loss: -3.105,Avg.Loss: -2.498,LR: 1.10E-04]Training epoch 69:  88%|████████▊ | 99/112 [00:01<00:00, 53.02it/s, Epoch: 69, Batch: 99,Loss: -3.105,Avg.Loss: -2.498,LR: 1.10E-04]Training epoch 69:  88%|████████▊ | 99/112 [00:01<00:00, 53.02it/s, Epoch: 69, Batch: 100,Loss: -3.129,Avg.Loss: -2.504,LR: 1.10E-04]Training epoch 69:  89%|████████▉ | 100/112 [00:01<00:00, 53.02it/s, Epoch: 69, Batch: 101,Loss: -2.748,Avg.Loss: -2.507,LR: 1.10E-04]Training epoch 69:  90%|█████████ | 101/112 [00:01<00:00, 53.02it/s, Epoch: 69, Batch: 102,Loss: -3.601,Avg.Loss: -2.518,LR: 1.10E-04]Training epoch 69:  91%|█████████ | 102/112 [00:01<00:00, 53.02it/s, Epoch: 69, Batch: 103,Loss: -3.096,Avg.Loss: -2.523,LR: 1.10E-04]Training epoch 69:  92%|█████████▏| 103/112 [00:01<00:00, 53.02it/s, Epoch: 69, Batch: 104,Loss: -2.612,Avg.Loss: -2.524,LR: 1.10E-04]Training epoch 69:  93%|█████████▎| 104/112 [00:01<00:00, 53.02it/s, Epoch: 69, Batch: 105,Loss: -3.244,Avg.Loss: -2.531,LR: 1.10E-04]Training epoch 69:  94%|█████████▍| 105/112 [00:01<00:00, 53.09it/s, Epoch: 69, Batch: 105,Loss: -3.244,Avg.Loss: -2.531,LR: 1.10E-04]Training epoch 69:  94%|█████████▍| 105/112 [00:01<00:00, 53.09it/s, Epoch: 69, Batch: 106,Loss: -3.223,Avg.Loss: -2.537,LR: 1.10E-04]Training epoch 69:  95%|█████████▍| 106/112 [00:01<00:00, 53.09it/s, Epoch: 69, Batch: 107,Loss: -3.124,Avg.Loss: -2.543,LR: 1.10E-04]Training epoch 69:  96%|█████████▌| 107/112 [00:02<00:00, 53.09it/s, Epoch: 69, Batch: 108,Loss: -3.517,Avg.Loss: -2.552,LR: 1.10E-04]Training epoch 69:  96%|█████████▋| 108/112 [00:02<00:00, 53.09it/s, Epoch: 69, Batch: 109,Loss: -2.891,Avg.Loss: -2.555,LR: 1.10E-04]Training epoch 69:  97%|█████████▋| 109/112 [00:02<00:00, 53.09it/s, Epoch: 69, Batch: 110,Loss: -2.721,Avg.Loss: -2.557,LR: 1.10E-04]Training epoch 69:  98%|█████████▊| 110/112 [00:02<00:00, 53.09it/s, Epoch: 69, Batch: 111,Loss: -2.579,Avg.Loss: -2.557,LR: 1.10E-04]Training epoch 69:  99%|█████████▉| 111/112 [00:02<00:00, 53.16it/s, Epoch: 69, Batch: 111,Loss: -2.579,Avg.Loss: -2.557,LR: 1.10E-04]Training epoch 69:  99%|█████████▉| 111/112 [00:02<00:00, 53.16it/s, Epoch: 69, Batch: 112,Loss: -2.119,Avg.Loss: -2.553,LR: 1.09E-04]Training epoch 69: 100%|██████████| 112/112 [00:02<00:00, 53.68it/s, Epoch: 69, Batch: 112,Loss: -2.119,Avg.Loss: -2.553,LR: 1.09E-04]
Training epoch 70:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 70:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 70, Batch: 1,Loss: -2.288,Avg.Loss: -2.288,LR: 1.09E-04]Training epoch 70:   1%|          | 1/112 [00:00<00:04, 25.88it/s, Epoch: 70, Batch: 2,Loss: -2.598,Avg.Loss: -2.443,LR: 1.09E-04]Training epoch 70:   2%|▏         | 2/112 [00:00<00:02, 38.96it/s, Epoch: 70, Batch: 3,Loss: -3.057,Avg.Loss: -2.648,LR: 1.09E-04]Training epoch 70:   3%|▎         | 3/112 [00:00<00:02, 44.17it/s, Epoch: 70, Batch: 4,Loss: -2.535,Avg.Loss: -2.620,LR: 1.09E-04]Training epoch 70:   4%|▎         | 4/112 [00:00<00:02, 45.72it/s, Epoch: 70, Batch: 5,Loss: -1.764,Avg.Loss: -2.449,LR: 1.09E-04]Training epoch 70:   4%|▍         | 5/112 [00:00<00:02, 46.86it/s, Epoch: 70, Batch: 6,Loss: -2.130,Avg.Loss: -2.395,LR: 1.09E-04]Training epoch 70:   5%|▌         | 6/112 [00:00<00:01, 56.14it/s, Epoch: 70, Batch: 6,Loss: -2.130,Avg.Loss: -2.395,LR: 1.09E-04]Training epoch 70:   5%|▌         | 6/112 [00:00<00:01, 56.14it/s, Epoch: 70, Batch: 7,Loss: -2.586,Avg.Loss: -2.423,LR: 1.09E-04]Training epoch 70:   6%|▋         | 7/112 [00:00<00:01, 56.14it/s, Epoch: 70, Batch: 8,Loss: -3.103,Avg.Loss: -2.508,LR: 1.09E-04]Training epoch 70:   7%|▋         | 8/112 [00:00<00:01, 56.14it/s, Epoch: 70, Batch: 9,Loss: -2.615,Avg.Loss: -2.520,LR: 1.09E-04]Training epoch 70:   8%|▊         | 9/112 [00:00<00:01, 56.14it/s, Epoch: 70, Batch: 10,Loss: -2.640,Avg.Loss: -2.532,LR: 1.09E-04]Training epoch 70:   9%|▉         | 10/112 [00:00<00:01, 56.14it/s, Epoch: 70, Batch: 11,Loss: -3.286,Avg.Loss: -2.600,LR: 1.09E-04]Training epoch 70:  10%|▉         | 11/112 [00:00<00:01, 56.14it/s, Epoch: 70, Batch: 12,Loss: -3.079,Avg.Loss: -2.640,LR: 1.09E-04]Training epoch 70:  11%|█         | 12/112 [00:00<00:01, 54.10it/s, Epoch: 70, Batch: 12,Loss: -3.079,Avg.Loss: -2.640,LR: 1.09E-04]Training epoch 70:  11%|█         | 12/112 [00:00<00:01, 54.10it/s, Epoch: 70, Batch: 13,Loss: -3.165,Avg.Loss: -2.680,LR: 1.09E-04]Training epoch 70:  12%|█▏        | 13/112 [00:00<00:01, 54.10it/s, Epoch: 70, Batch: 14,Loss: -3.593,Avg.Loss: -2.746,LR: 1.09E-04]Training epoch 70:  12%|█▎        | 14/112 [00:00<00:01, 54.10it/s, Epoch: 70, Batch: 15,Loss: -2.952,Avg.Loss: -2.759,LR: 1.09E-04]Training epoch 70:  13%|█▎        | 15/112 [00:00<00:01, 54.10it/s, Epoch: 70, Batch: 16,Loss: -3.121,Avg.Loss: -2.782,LR: 1.09E-04]Training epoch 70:  14%|█▍        | 16/112 [00:00<00:01, 54.10it/s, Epoch: 70, Batch: 17,Loss: -3.319,Avg.Loss: -2.814,LR: 1.08E-04]Training epoch 70:  15%|█▌        | 17/112 [00:00<00:01, 54.10it/s, Epoch: 70, Batch: 18,Loss: -3.264,Avg.Loss: -2.839,LR: 1.08E-04]Training epoch 70:  16%|█▌        | 18/112 [00:00<00:01, 53.76it/s, Epoch: 70, Batch: 18,Loss: -3.264,Avg.Loss: -2.839,LR: 1.08E-04]Training epoch 70:  16%|█▌        | 18/112 [00:00<00:01, 53.76it/s, Epoch: 70, Batch: 19,Loss: -3.259,Avg.Loss: -2.861,LR: 1.08E-04]Training epoch 70:  17%|█▋        | 19/112 [00:00<00:01, 53.76it/s, Epoch: 70, Batch: 20,Loss: -3.396,Avg.Loss: -2.887,LR: 1.08E-04]Training epoch 70:  18%|█▊        | 20/112 [00:00<00:01, 53.76it/s, Epoch: 70, Batch: 21,Loss: -3.397,Avg.Loss: -2.912,LR: 1.08E-04]Training epoch 70:  19%|█▉        | 21/112 [00:00<00:01, 53.76it/s, Epoch: 70, Batch: 22,Loss: -3.298,Avg.Loss: -2.929,LR: 1.08E-04]Training epoch 70:  20%|█▉        | 22/112 [00:00<00:01, 53.76it/s, Epoch: 70, Batch: 23,Loss: -2.720,Avg.Loss: -2.920,LR: 1.08E-04]Training epoch 70:  21%|██        | 23/112 [00:00<00:01, 53.76it/s, Epoch: 70, Batch: 24,Loss: -2.667,Avg.Loss: -2.910,LR: 1.08E-04]Training epoch 70:  21%|██▏       | 24/112 [00:00<00:01, 52.81it/s, Epoch: 70, Batch: 24,Loss: -2.667,Avg.Loss: -2.910,LR: 1.08E-04]Training epoch 70:  21%|██▏       | 24/112 [00:00<00:01, 52.81it/s, Epoch: 70, Batch: 25,Loss: -2.591,Avg.Loss: -2.897,LR: 1.08E-04]Training epoch 70:  22%|██▏       | 25/112 [00:00<00:01, 52.81it/s, Epoch: 70, Batch: 26,Loss: -2.673,Avg.Loss: -2.888,LR: 1.08E-04]Training epoch 70:  23%|██▎       | 26/112 [00:00<00:01, 52.81it/s, Epoch: 70, Batch: 27,Loss: -3.268,Avg.Loss: -2.902,LR: 1.08E-04]Training epoch 70:  24%|██▍       | 27/112 [00:00<00:01, 52.81it/s, Epoch: 70, Batch: 28,Loss: -3.149,Avg.Loss: -2.911,LR: 1.08E-04]Training epoch 70:  25%|██▌       | 28/112 [00:00<00:01, 52.81it/s, Epoch: 70, Batch: 29,Loss: -3.319,Avg.Loss: -2.925,LR: 1.08E-04]Training epoch 70:  26%|██▌       | 29/112 [00:00<00:01, 52.81it/s, Epoch: 70, Batch: 30,Loss: -2.816,Avg.Loss: -2.922,LR: 1.08E-04]Training epoch 70:  27%|██▋       | 30/112 [00:00<00:01, 52.32it/s, Epoch: 70, Batch: 30,Loss: -2.816,Avg.Loss: -2.922,LR: 1.08E-04]Training epoch 70:  27%|██▋       | 30/112 [00:00<00:01, 52.32it/s, Epoch: 70, Batch: 31,Loss: -2.790,Avg.Loss: -2.917,LR: 1.08E-04]Training epoch 70:  28%|██▊       | 31/112 [00:00<00:01, 52.32it/s, Epoch: 70, Batch: 32,Loss: -3.324,Avg.Loss: -2.930,LR: 1.08E-04]Training epoch 70:  29%|██▊       | 32/112 [00:00<00:01, 52.32it/s, Epoch: 70, Batch: 33,Loss: -2.213,Avg.Loss: -2.908,LR: 1.08E-04]Training epoch 70:  29%|██▉       | 33/112 [00:00<00:01, 52.32it/s, Epoch: 70, Batch: 34,Loss: -2.143,Avg.Loss: -2.886,LR: 1.08E-04]Training epoch 70:  30%|███       | 34/112 [00:00<00:01, 52.32it/s, Epoch: 70, Batch: 35,Loss: -2.567,Avg.Loss: -2.877,LR: 1.07E-04]Training epoch 70:  31%|███▏      | 35/112 [00:00<00:01, 52.32it/s, Epoch: 70, Batch: 36,Loss: -3.402,Avg.Loss: -2.891,LR: 1.07E-04]Training epoch 70:  32%|███▏      | 36/112 [00:00<00:01, 52.01it/s, Epoch: 70, Batch: 36,Loss: -3.402,Avg.Loss: -2.891,LR: 1.07E-04]Training epoch 70:  32%|███▏      | 36/112 [00:00<00:01, 52.01it/s, Epoch: 70, Batch: 37,Loss: -3.075,Avg.Loss: -2.896,LR: 1.07E-04]Training epoch 70:  33%|███▎      | 37/112 [00:00<00:01, 52.01it/s, Epoch: 70, Batch: 38,Loss: -3.258,Avg.Loss: -2.906,LR: 1.07E-04]Training epoch 70:  34%|███▍      | 38/112 [00:00<00:01, 52.01it/s, Epoch: 70, Batch: 39,Loss: -2.925,Avg.Loss: -2.906,LR: 1.07E-04]Training epoch 70:  35%|███▍      | 39/112 [00:00<00:01, 52.01it/s, Epoch: 70, Batch: 40,Loss: -2.818,Avg.Loss: -2.904,LR: 1.07E-04]Training epoch 70:  36%|███▌      | 40/112 [00:00<00:01, 52.01it/s, Epoch: 70, Batch: 41,Loss: -3.008,Avg.Loss: -2.907,LR: 1.07E-04]Training epoch 70:  37%|███▋      | 41/112 [00:00<00:01, 52.01it/s, Epoch: 70, Batch: 42,Loss: -3.420,Avg.Loss: -2.919,LR: 1.07E-04]Training epoch 70:  38%|███▊      | 42/112 [00:00<00:01, 52.50it/s, Epoch: 70, Batch: 42,Loss: -3.420,Avg.Loss: -2.919,LR: 1.07E-04]Training epoch 70:  38%|███▊      | 42/112 [00:00<00:01, 52.50it/s, Epoch: 70, Batch: 43,Loss: -3.026,Avg.Loss: -2.921,LR: 1.07E-04]Training epoch 70:  38%|███▊      | 43/112 [00:00<00:01, 52.50it/s, Epoch: 70, Batch: 44,Loss: -3.154,Avg.Loss: -2.927,LR: 1.07E-04]Training epoch 70:  39%|███▉      | 44/112 [00:00<00:01, 52.50it/s, Epoch: 70, Batch: 45,Loss: -3.067,Avg.Loss: -2.930,LR: 1.07E-04]Training epoch 70:  40%|████      | 45/112 [00:00<00:01, 52.50it/s, Epoch: 70, Batch: 46,Loss: -2.782,Avg.Loss: -2.927,LR: 1.07E-04]Training epoch 70:  41%|████      | 46/112 [00:00<00:01, 52.50it/s, Epoch: 70, Batch: 47,Loss: -2.615,Avg.Loss: -2.920,LR: 1.07E-04]Training epoch 70:  42%|████▏     | 47/112 [00:00<00:01, 52.50it/s, Epoch: 70, Batch: 48,Loss: -2.936,Avg.Loss: -2.920,LR: 1.07E-04]Training epoch 70:  43%|████▎     | 48/112 [00:00<00:01, 52.53it/s, Epoch: 70, Batch: 48,Loss: -2.936,Avg.Loss: -2.920,LR: 1.07E-04]Training epoch 70:  43%|████▎     | 48/112 [00:00<00:01, 52.53it/s, Epoch: 70, Batch: 49,Loss: -3.223,Avg.Loss: -2.926,LR: 1.07E-04]Training epoch 70:  44%|████▍     | 49/112 [00:00<00:01, 52.53it/s, Epoch: 70, Batch: 50,Loss: -3.466,Avg.Loss: -2.937,LR: 1.07E-04]Training epoch 70:  45%|████▍     | 50/112 [00:00<00:01, 52.53it/s, Epoch: 70, Batch: 51,Loss: -3.143,Avg.Loss: -2.941,LR: 1.07E-04]Training epoch 70:  46%|████▌     | 51/112 [00:00<00:01, 52.53it/s, Epoch: 70, Batch: 52,Loss: -3.020,Avg.Loss: -2.943,LR: 1.06E-04]Training epoch 70:  46%|████▋     | 52/112 [00:01<00:01, 52.53it/s, Epoch: 70, Batch: 53,Loss: -3.040,Avg.Loss: -2.945,LR: 1.06E-04]Training epoch 70:  47%|████▋     | 53/112 [00:01<00:01, 52.53it/s, Epoch: 70, Batch: 54,Loss: -2.390,Avg.Loss: -2.934,LR: 1.06E-04]Training epoch 70:  48%|████▊     | 54/112 [00:01<00:01, 52.80it/s, Epoch: 70, Batch: 54,Loss: -2.390,Avg.Loss: -2.934,LR: 1.06E-04]Training epoch 70:  48%|████▊     | 54/112 [00:01<00:01, 52.80it/s, Epoch: 70, Batch: 55,Loss: -2.827,Avg.Loss: -2.932,LR: 1.06E-04]Training epoch 70:  49%|████▉     | 55/112 [00:01<00:01, 52.80it/s, Epoch: 70, Batch: 56,Loss: -3.551,Avg.Loss: -2.943,LR: 1.06E-04]Training epoch 70:  50%|█████     | 56/112 [00:01<00:01, 52.80it/s, Epoch: 70, Batch: 57,Loss: -3.062,Avg.Loss: -2.945,LR: 1.06E-04]Training epoch 70:  51%|█████     | 57/112 [00:01<00:01, 52.80it/s, Epoch: 70, Batch: 58,Loss: -2.865,Avg.Loss: -2.944,LR: 1.06E-04]Training epoch 70:  52%|█████▏    | 58/112 [00:01<00:01, 52.80it/s, Epoch: 70, Batch: 59,Loss: -2.855,Avg.Loss: -2.943,LR: 1.06E-04]Training epoch 70:  53%|█████▎    | 59/112 [00:01<00:01, 52.80it/s, Epoch: 70, Batch: 60,Loss: -2.824,Avg.Loss: -2.941,LR: 1.06E-04]Training epoch 70:  54%|█████▎    | 60/112 [00:01<00:00, 53.08it/s, Epoch: 70, Batch: 60,Loss: -2.824,Avg.Loss: -2.941,LR: 1.06E-04]Training epoch 70:  54%|█████▎    | 60/112 [00:01<00:00, 53.08it/s, Epoch: 70, Batch: 61,Loss: -3.023,Avg.Loss: -2.942,LR: 1.06E-04]Training epoch 70:  54%|█████▍    | 61/112 [00:01<00:00, 53.08it/s, Epoch: 70, Batch: 62,Loss: -2.935,Avg.Loss: -2.942,LR: 1.06E-04]Training epoch 70:  55%|█████▌    | 62/112 [00:01<00:00, 53.08it/s, Epoch: 70, Batch: 63,Loss: -3.243,Avg.Loss: -2.947,LR: 1.06E-04]Training epoch 70:  56%|█████▋    | 63/112 [00:01<00:00, 53.08it/s, Epoch: 70, Batch: 64,Loss: -2.661,Avg.Loss: -2.942,LR: 1.06E-04]Training epoch 70:  57%|█████▋    | 64/112 [00:01<00:00, 53.08it/s, Epoch: 70, Batch: 65,Loss: -3.248,Avg.Loss: -2.947,LR: 1.06E-04]Training epoch 70:  58%|█████▊    | 65/112 [00:01<00:00, 53.08it/s, Epoch: 70, Batch: 66,Loss: -2.988,Avg.Loss: -2.948,LR: 1.06E-04]Training epoch 70:  59%|█████▉    | 66/112 [00:01<00:00, 53.32it/s, Epoch: 70, Batch: 66,Loss: -2.988,Avg.Loss: -2.948,LR: 1.06E-04]Training epoch 70:  59%|█████▉    | 66/112 [00:01<00:00, 53.32it/s, Epoch: 70, Batch: 67,Loss: -2.702,Avg.Loss: -2.944,LR: 1.06E-04]Training epoch 70:  60%|█████▉    | 67/112 [00:01<00:00, 53.32it/s, Epoch: 70, Batch: 68,Loss: -3.297,Avg.Loss: -2.949,LR: 1.06E-04]Training epoch 70:  61%|██████    | 68/112 [00:01<00:00, 53.32it/s, Epoch: 70, Batch: 69,Loss: -3.552,Avg.Loss: -2.958,LR: 1.06E-04]Training epoch 70:  62%|██████▏   | 69/112 [00:01<00:00, 53.32it/s, Epoch: 70, Batch: 70,Loss: -2.690,Avg.Loss: -2.954,LR: 1.05E-04]Training epoch 70:  62%|██████▎   | 70/112 [00:01<00:00, 53.32it/s, Epoch: 70, Batch: 71,Loss: -3.290,Avg.Loss: -2.959,LR: 1.05E-04]Training epoch 70:  63%|██████▎   | 71/112 [00:01<00:00, 53.32it/s, Epoch: 70, Batch: 72,Loss: -3.418,Avg.Loss: -2.965,LR: 1.05E-04]Training epoch 70:  64%|██████▍   | 72/112 [00:01<00:00, 53.24it/s, Epoch: 70, Batch: 72,Loss: -3.418,Avg.Loss: -2.965,LR: 1.05E-04]Training epoch 70:  64%|██████▍   | 72/112 [00:01<00:00, 53.24it/s, Epoch: 70, Batch: 73,Loss: -3.771,Avg.Loss: -2.976,LR: 1.05E-04]Training epoch 70:  65%|██████▌   | 73/112 [00:01<00:00, 53.24it/s, Epoch: 70, Batch: 74,Loss: -3.417,Avg.Loss: -2.982,LR: 1.05E-04]Training epoch 70:  66%|██████▌   | 74/112 [00:01<00:00, 53.24it/s, Epoch: 70, Batch: 75,Loss: -2.168,Avg.Loss: -2.971,LR: 1.05E-04]Training epoch 70:  67%|██████▋   | 75/112 [00:01<00:00, 53.24it/s, Epoch: 70, Batch: 76,Loss: -3.227,Avg.Loss: -2.975,LR: 1.05E-04]Training epoch 70:  68%|██████▊   | 76/112 [00:01<00:00, 53.24it/s, Epoch: 70, Batch: 77,Loss: -3.314,Avg.Loss: -2.979,LR: 1.05E-04]Training epoch 70:  69%|██████▉   | 77/112 [00:01<00:00, 53.24it/s, Epoch: 70, Batch: 78,Loss: -2.985,Avg.Loss: -2.979,LR: 1.05E-04]Training epoch 70:  70%|██████▉   | 78/112 [00:01<00:00, 53.35it/s, Epoch: 70, Batch: 78,Loss: -2.985,Avg.Loss: -2.979,LR: 1.05E-04]Training epoch 70:  70%|██████▉   | 78/112 [00:01<00:00, 53.35it/s, Epoch: 70, Batch: 79,Loss: -3.187,Avg.Loss: -2.982,LR: 1.05E-04]Training epoch 70:  71%|███████   | 79/112 [00:01<00:00, 53.35it/s, Epoch: 70, Batch: 80,Loss: -3.057,Avg.Loss: -2.983,LR: 1.05E-04]Training epoch 70:  71%|███████▏  | 80/112 [00:01<00:00, 53.35it/s, Epoch: 70, Batch: 81,Loss: -2.646,Avg.Loss: -2.978,LR: 1.05E-04]Training epoch 70:  72%|███████▏  | 81/112 [00:01<00:00, 53.35it/s, Epoch: 70, Batch: 82,Loss: -1.820,Avg.Loss: -2.964,LR: 1.05E-04]Training epoch 70:  73%|███████▎  | 82/112 [00:01<00:00, 53.35it/s, Epoch: 70, Batch: 83,Loss: -2.817,Avg.Loss: -2.963,LR: 1.05E-04]Training epoch 70:  74%|███████▍  | 83/112 [00:01<00:00, 53.35it/s, Epoch: 70, Batch: 84,Loss: -2.058,Avg.Loss: -2.952,LR: 1.05E-04]Training epoch 70:  75%|███████▌  | 84/112 [00:01<00:00, 53.44it/s, Epoch: 70, Batch: 84,Loss: -2.058,Avg.Loss: -2.952,LR: 1.05E-04]Training epoch 70:  75%|███████▌  | 84/112 [00:01<00:00, 53.44it/s, Epoch: 70, Batch: 85,Loss: -2.084,Avg.Loss: -2.942,LR: 1.05E-04]Training epoch 70:  76%|███████▌  | 85/112 [00:01<00:00, 53.44it/s, Epoch: 70, Batch: 86,Loss: -3.015,Avg.Loss: -2.942,LR: 1.05E-04]Training epoch 70:  77%|███████▋  | 86/112 [00:01<00:00, 53.44it/s, Epoch: 70, Batch: 87,Loss: -2.462,Avg.Loss: -2.937,LR: 1.04E-04]Training epoch 70:  78%|███████▊  | 87/112 [00:01<00:00, 53.44it/s, Epoch: 70, Batch: 88,Loss: -2.750,Avg.Loss: -2.935,LR: 1.04E-04]Training epoch 70:  79%|███████▊  | 88/112 [00:01<00:00, 53.44it/s, Epoch: 70, Batch: 89,Loss: -3.049,Avg.Loss: -2.936,LR: 1.04E-04]Training epoch 70:  79%|███████▉  | 89/112 [00:01<00:00, 53.44it/s, Epoch: 70, Batch: 90,Loss: -3.579,Avg.Loss: -2.943,LR: 1.04E-04]Training epoch 70:  80%|████████  | 90/112 [00:01<00:00, 53.61it/s, Epoch: 70, Batch: 90,Loss: -3.579,Avg.Loss: -2.943,LR: 1.04E-04]Training epoch 70:  80%|████████  | 90/112 [00:01<00:00, 53.61it/s, Epoch: 70, Batch: 91,Loss: -2.656,Avg.Loss: -2.940,LR: 1.04E-04]Training epoch 70:  81%|████████▏ | 91/112 [00:01<00:00, 53.61it/s, Epoch: 70, Batch: 92,Loss: -2.028,Avg.Loss: -2.930,LR: 1.04E-04]Training epoch 70:  82%|████████▏ | 92/112 [00:01<00:00, 53.61it/s, Epoch: 70, Batch: 93,Loss: -1.830,Avg.Loss: -2.918,LR: 1.04E-04]Training epoch 70:  83%|████████▎ | 93/112 [00:01<00:00, 53.61it/s, Epoch: 70, Batch: 94,Loss: -2.500,Avg.Loss: -2.914,LR: 1.04E-04]Training epoch 70:  84%|████████▍ | 94/112 [00:01<00:00, 53.61it/s, Epoch: 70, Batch: 95,Loss: -2.376,Avg.Loss: -2.908,LR: 1.04E-04]Training epoch 70:  85%|████████▍ | 95/112 [00:01<00:00, 53.61it/s, Epoch: 70, Batch: 96,Loss: -1.794,Avg.Loss: -2.897,LR: 1.04E-04]Training epoch 70:  86%|████████▌ | 96/112 [00:01<00:00, 53.51it/s, Epoch: 70, Batch: 96,Loss: -1.794,Avg.Loss: -2.897,LR: 1.04E-04]Training epoch 70:  86%|████████▌ | 96/112 [00:01<00:00, 53.51it/s, Epoch: 70, Batch: 97,Loss: -2.357,Avg.Loss: -2.891,LR: 1.04E-04]Training epoch 70:  87%|████████▋ | 97/112 [00:01<00:00, 53.51it/s, Epoch: 70, Batch: 98,Loss: -3.073,Avg.Loss: -2.893,LR: 1.04E-04]Training epoch 70:  88%|████████▊ | 98/112 [00:01<00:00, 53.51it/s, Epoch: 70, Batch: 99,Loss: -2.533,Avg.Loss: -2.889,LR: 1.04E-04]Training epoch 70:  88%|████████▊ | 99/112 [00:01<00:00, 53.51it/s, Epoch: 70, Batch: 100,Loss: -1.865,Avg.Loss: -2.879,LR: 1.04E-04]Training epoch 70:  89%|████████▉ | 100/112 [00:01<00:00, 53.51it/s, Epoch: 70, Batch: 101,Loss: -2.780,Avg.Loss: -2.878,LR: 1.04E-04]Training epoch 70:  90%|█████████ | 101/112 [00:01<00:00, 53.51it/s, Epoch: 70, Batch: 102,Loss: -3.041,Avg.Loss: -2.880,LR: 1.04E-04]Training epoch 70:  91%|█████████ | 102/112 [00:01<00:00, 53.55it/s, Epoch: 70, Batch: 102,Loss: -3.041,Avg.Loss: -2.880,LR: 1.04E-04]Training epoch 70:  91%|█████████ | 102/112 [00:01<00:00, 53.55it/s, Epoch: 70, Batch: 103,Loss: -3.226,Avg.Loss: -2.883,LR: 1.04E-04]Training epoch 70:  92%|█████████▏| 103/112 [00:01<00:00, 53.55it/s, Epoch: 70, Batch: 104,Loss: -2.237,Avg.Loss: -2.877,LR: 1.04E-04]Training epoch 70:  93%|█████████▎| 104/112 [00:01<00:00, 53.55it/s, Epoch: 70, Batch: 105,Loss: -2.357,Avg.Loss: -2.872,LR: 1.03E-04]Training epoch 70:  94%|█████████▍| 105/112 [00:01<00:00, 53.55it/s, Epoch: 70, Batch: 106,Loss: -3.052,Avg.Loss: -2.874,LR: 1.03E-04]Training epoch 70:  95%|█████████▍| 106/112 [00:02<00:00, 53.55it/s, Epoch: 70, Batch: 107,Loss: -3.294,Avg.Loss: -2.877,LR: 1.03E-04]Training epoch 70:  96%|█████████▌| 107/112 [00:02<00:00, 53.55it/s, Epoch: 70, Batch: 108,Loss: -2.619,Avg.Loss: -2.875,LR: 1.03E-04]Training epoch 70:  96%|█████████▋| 108/112 [00:02<00:00, 53.57it/s, Epoch: 70, Batch: 108,Loss: -2.619,Avg.Loss: -2.875,LR: 1.03E-04]Training epoch 70:  96%|█████████▋| 108/112 [00:02<00:00, 53.57it/s, Epoch: 70, Batch: 109,Loss: -2.810,Avg.Loss: -2.874,LR: 1.03E-04]Training epoch 70:  97%|█████████▋| 109/112 [00:02<00:00, 53.57it/s, Epoch: 70, Batch: 110,Loss: -2.920,Avg.Loss: -2.875,LR: 1.03E-04]Training epoch 70:  98%|█████████▊| 110/112 [00:02<00:00, 53.57it/s, Epoch: 70, Batch: 111,Loss: -2.682,Avg.Loss: -2.873,LR: 1.03E-04]Training epoch 70:  99%|█████████▉| 111/112 [00:02<00:00, 53.57it/s, Epoch: 70, Batch: 112,Loss: -1.432,Avg.Loss: -2.860,LR: 1.03E-04]Training epoch 70: 100%|██████████| 112/112 [00:02<00:00, 53.16it/s, Epoch: 70, Batch: 112,Loss: -1.432,Avg.Loss: -2.860,LR: 1.03E-04]
Training epoch 71:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 71:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 71, Batch: 1,Loss: -2.412,Avg.Loss: -2.412,LR: 1.03E-04]Training epoch 71:   1%|          | 1/112 [00:00<00:04, 23.90it/s, Epoch: 71, Batch: 2,Loss: -3.417,Avg.Loss: -2.914,LR: 1.03E-04]Training epoch 71:   2%|▏         | 2/112 [00:00<00:03, 33.68it/s, Epoch: 71, Batch: 3,Loss: -2.907,Avg.Loss: -2.912,LR: 1.03E-04]Training epoch 71:   3%|▎         | 3/112 [00:00<00:02, 39.50it/s, Epoch: 71, Batch: 4,Loss: -2.468,Avg.Loss: -2.801,LR: 1.03E-04]Training epoch 71:   4%|▎         | 4/112 [00:00<00:02, 42.75it/s, Epoch: 71, Batch: 5,Loss: -2.667,Avg.Loss: -2.774,LR: 1.03E-04]Training epoch 71:   4%|▍         | 5/112 [00:00<00:02, 44.58it/s, Epoch: 71, Batch: 6,Loss: -2.877,Avg.Loss: -2.791,LR: 1.03E-04]Training epoch 71:   5%|▌         | 6/112 [00:00<00:01, 53.41it/s, Epoch: 71, Batch: 6,Loss: -2.877,Avg.Loss: -2.791,LR: 1.03E-04]Training epoch 71:   5%|▌         | 6/112 [00:00<00:01, 53.41it/s, Epoch: 71, Batch: 7,Loss: -2.766,Avg.Loss: -2.788,LR: 1.03E-04]Training epoch 71:   6%|▋         | 7/112 [00:00<00:01, 53.41it/s, Epoch: 71, Batch: 8,Loss: -2.152,Avg.Loss: -2.708,LR: 1.03E-04]Training epoch 71:   7%|▋         | 8/112 [00:00<00:01, 53.41it/s, Epoch: 71, Batch: 9,Loss: -2.497,Avg.Loss: -2.685,LR: 1.03E-04]Training epoch 71:   8%|▊         | 9/112 [00:00<00:01, 53.41it/s, Epoch: 71, Batch: 10,Loss: -3.573,Avg.Loss: -2.774,LR: 1.02E-04]Training epoch 71:   9%|▉         | 10/112 [00:00<00:01, 53.41it/s, Epoch: 71, Batch: 11,Loss: -3.122,Avg.Loss: -2.805,LR: 1.02E-04]Training epoch 71:  10%|▉         | 11/112 [00:00<00:01, 53.41it/s, Epoch: 71, Batch: 12,Loss: -2.136,Avg.Loss: -2.749,LR: 1.02E-04]Training epoch 71:  11%|█         | 12/112 [00:00<00:01, 53.68it/s, Epoch: 71, Batch: 12,Loss: -2.136,Avg.Loss: -2.749,LR: 1.02E-04]Training epoch 71:  11%|█         | 12/112 [00:00<00:01, 53.68it/s, Epoch: 71, Batch: 13,Loss: -2.562,Avg.Loss: -2.735,LR: 1.02E-04]Training epoch 71:  12%|█▏        | 13/112 [00:00<00:01, 53.68it/s, Epoch: 71, Batch: 14,Loss: -2.555,Avg.Loss: -2.722,LR: 1.02E-04]Training epoch 71:  12%|█▎        | 14/112 [00:00<00:01, 53.68it/s, Epoch: 71, Batch: 15,Loss: -2.931,Avg.Loss: -2.736,LR: 1.02E-04]Training epoch 71:  13%|█▎        | 15/112 [00:00<00:01, 53.68it/s, Epoch: 71, Batch: 16,Loss: -2.513,Avg.Loss: -2.722,LR: 1.02E-04]Training epoch 71:  14%|█▍        | 16/112 [00:00<00:01, 53.68it/s, Epoch: 71, Batch: 17,Loss: -2.973,Avg.Loss: -2.737,LR: 1.02E-04]Training epoch 71:  15%|█▌        | 17/112 [00:00<00:01, 53.68it/s, Epoch: 71, Batch: 18,Loss: -3.083,Avg.Loss: -2.756,LR: 1.02E-04]Training epoch 71:  16%|█▌        | 18/112 [00:00<00:01, 53.51it/s, Epoch: 71, Batch: 18,Loss: -3.083,Avg.Loss: -2.756,LR: 1.02E-04]Training epoch 71:  16%|█▌        | 18/112 [00:00<00:01, 53.51it/s, Epoch: 71, Batch: 19,Loss: -2.963,Avg.Loss: -2.767,LR: 1.02E-04]Training epoch 71:  17%|█▋        | 19/112 [00:00<00:01, 53.51it/s, Epoch: 71, Batch: 20,Loss: -2.599,Avg.Loss: -2.759,LR: 1.02E-04]Training epoch 71:  18%|█▊        | 20/112 [00:00<00:01, 53.51it/s, Epoch: 71, Batch: 21,Loss: -2.072,Avg.Loss: -2.726,LR: 1.02E-04]Training epoch 71:  19%|█▉        | 21/112 [00:00<00:01, 53.51it/s, Epoch: 71, Batch: 22,Loss: -3.131,Avg.Loss: -2.744,LR: 1.02E-04]Training epoch 71:  20%|█▉        | 22/112 [00:00<00:01, 53.51it/s, Epoch: 71, Batch: 23,Loss: -3.226,Avg.Loss: -2.765,LR: 1.02E-04]Training epoch 71:  21%|██        | 23/112 [00:00<00:01, 53.51it/s, Epoch: 71, Batch: 24,Loss: -2.697,Avg.Loss: -2.762,LR: 1.02E-04]Training epoch 71:  21%|██▏       | 24/112 [00:00<00:01, 52.40it/s, Epoch: 71, Batch: 24,Loss: -2.697,Avg.Loss: -2.762,LR: 1.02E-04]Training epoch 71:  21%|██▏       | 24/112 [00:00<00:01, 52.40it/s, Epoch: 71, Batch: 25,Loss: -2.278,Avg.Loss: -2.743,LR: 1.02E-04]Training epoch 71:  22%|██▏       | 25/112 [00:00<00:01, 52.40it/s, Epoch: 71, Batch: 26,Loss: -3.452,Avg.Loss: -2.770,LR: 1.02E-04]Training epoch 71:  23%|██▎       | 26/112 [00:00<00:01, 52.40it/s, Epoch: 71, Batch: 27,Loss: -3.018,Avg.Loss: -2.779,LR: 1.02E-04]Training epoch 71:  24%|██▍       | 27/112 [00:00<00:01, 52.40it/s, Epoch: 71, Batch: 28,Loss: -2.276,Avg.Loss: -2.761,LR: 1.01E-04]Training epoch 71:  25%|██▌       | 28/112 [00:00<00:01, 52.40it/s, Epoch: 71, Batch: 29,Loss: -1.906,Avg.Loss: -2.732,LR: 1.01E-04]Training epoch 71:  26%|██▌       | 29/112 [00:00<00:01, 52.40it/s, Epoch: 71, Batch: 30,Loss: -3.411,Avg.Loss: -2.755,LR: 1.01E-04]Training epoch 71:  27%|██▋       | 30/112 [00:00<00:01, 52.13it/s, Epoch: 71, Batch: 30,Loss: -3.411,Avg.Loss: -2.755,LR: 1.01E-04]Training epoch 71:  27%|██▋       | 30/112 [00:00<00:01, 52.13it/s, Epoch: 71, Batch: 31,Loss: -3.074,Avg.Loss: -2.765,LR: 1.01E-04]Training epoch 71:  28%|██▊       | 31/112 [00:00<00:01, 52.13it/s, Epoch: 71, Batch: 32,Loss: -2.801,Avg.Loss: -2.766,LR: 1.01E-04]Training epoch 71:  29%|██▊       | 32/112 [00:00<00:01, 52.13it/s, Epoch: 71, Batch: 33,Loss: -2.990,Avg.Loss: -2.773,LR: 1.01E-04]Training epoch 71:  29%|██▉       | 33/112 [00:00<00:01, 52.13it/s, Epoch: 71, Batch: 34,Loss: -3.099,Avg.Loss: -2.782,LR: 1.01E-04]Training epoch 71:  30%|███       | 34/112 [00:00<00:01, 52.13it/s, Epoch: 71, Batch: 35,Loss: -2.910,Avg.Loss: -2.786,LR: 1.01E-04]Training epoch 71:  31%|███▏      | 35/112 [00:00<00:01, 52.13it/s, Epoch: 71, Batch: 36,Loss: -2.460,Avg.Loss: -2.777,LR: 1.01E-04]Training epoch 71:  32%|███▏      | 36/112 [00:00<00:01, 52.56it/s, Epoch: 71, Batch: 36,Loss: -2.460,Avg.Loss: -2.777,LR: 1.01E-04]Training epoch 71:  32%|███▏      | 36/112 [00:00<00:01, 52.56it/s, Epoch: 71, Batch: 37,Loss: -2.650,Avg.Loss: -2.774,LR: 1.01E-04]Training epoch 71:  33%|███▎      | 37/112 [00:00<00:01, 52.56it/s, Epoch: 71, Batch: 38,Loss: -3.419,Avg.Loss: -2.791,LR: 1.01E-04]Training epoch 71:  34%|███▍      | 38/112 [00:00<00:01, 52.56it/s, Epoch: 71, Batch: 39,Loss: -3.168,Avg.Loss: -2.800,LR: 1.01E-04]Training epoch 71:  35%|███▍      | 39/112 [00:00<00:01, 52.56it/s, Epoch: 71, Batch: 40,Loss: -2.763,Avg.Loss: -2.799,LR: 1.01E-04]Training epoch 71:  36%|███▌      | 40/112 [00:00<00:01, 52.56it/s, Epoch: 71, Batch: 41,Loss: -2.884,Avg.Loss: -2.801,LR: 1.01E-04]Training epoch 71:  37%|███▋      | 41/112 [00:00<00:01, 52.56it/s, Epoch: 71, Batch: 42,Loss: -3.216,Avg.Loss: -2.811,LR: 1.01E-04]Training epoch 71:  38%|███▊      | 42/112 [00:00<00:01, 52.74it/s, Epoch: 71, Batch: 42,Loss: -3.216,Avg.Loss: -2.811,LR: 1.01E-04]Training epoch 71:  38%|███▊      | 42/112 [00:00<00:01, 52.74it/s, Epoch: 71, Batch: 43,Loss: -2.976,Avg.Loss: -2.815,LR: 1.01E-04]Training epoch 71:  38%|███▊      | 43/112 [00:00<00:01, 52.74it/s, Epoch: 71, Batch: 44,Loss: -2.124,Avg.Loss: -2.799,LR: 1.01E-04]Training epoch 71:  39%|███▉      | 44/112 [00:00<00:01, 52.74it/s, Epoch: 71, Batch: 45,Loss: -2.401,Avg.Loss: -2.791,LR: 1.01E-04]Training epoch 71:  40%|████      | 45/112 [00:00<00:01, 52.74it/s, Epoch: 71, Batch: 46,Loss: -3.052,Avg.Loss: -2.796,LR: 1.00E-04]Training epoch 71:  41%|████      | 46/112 [00:00<00:01, 52.74it/s, Epoch: 71, Batch: 47,Loss: -3.444,Avg.Loss: -2.810,LR: 1.00E-04]Training epoch 71:  42%|████▏     | 47/112 [00:00<00:01, 52.74it/s, Epoch: 71, Batch: 48,Loss: -2.604,Avg.Loss: -2.806,LR: 1.00E-04]Training epoch 71:  43%|████▎     | 48/112 [00:00<00:01, 52.87it/s, Epoch: 71, Batch: 48,Loss: -2.604,Avg.Loss: -2.806,LR: 1.00E-04]Training epoch 71:  43%|████▎     | 48/112 [00:00<00:01, 52.87it/s, Epoch: 71, Batch: 49,Loss: -2.713,Avg.Loss: -2.804,LR: 1.00E-04]Training epoch 71:  44%|████▍     | 49/112 [00:00<00:01, 52.87it/s, Epoch: 71, Batch: 50,Loss: -3.273,Avg.Loss: -2.813,LR: 1.00E-04]Training epoch 71:  45%|████▍     | 50/112 [00:00<00:01, 52.87it/s, Epoch: 71, Batch: 51,Loss: -3.062,Avg.Loss: -2.818,LR: 1.00E-04]Training epoch 71:  46%|████▌     | 51/112 [00:00<00:01, 52.87it/s, Epoch: 71, Batch: 52,Loss: -2.826,Avg.Loss: -2.818,LR: 1.00E-04]Training epoch 71:  46%|████▋     | 52/112 [00:01<00:01, 52.87it/s, Epoch: 71, Batch: 53,Loss: -2.215,Avg.Loss: -2.807,LR: 1.00E-04]Training epoch 71:  47%|████▋     | 53/112 [00:01<00:01, 52.87it/s, Epoch: 71, Batch: 54,Loss: -3.249,Avg.Loss: -2.815,LR: 1.00E-04]Training epoch 71:  48%|████▊     | 54/112 [00:01<00:01, 52.96it/s, Epoch: 71, Batch: 54,Loss: -3.249,Avg.Loss: -2.815,LR: 1.00E-04]Training epoch 71:  48%|████▊     | 54/112 [00:01<00:01, 52.96it/s, Epoch: 71, Batch: 55,Loss: -3.200,Avg.Loss: -2.822,LR: 1.00E-04]Training epoch 71:  49%|████▉     | 55/112 [00:01<00:01, 52.96it/s, Epoch: 71, Batch: 56,Loss: -2.355,Avg.Loss: -2.814,LR: 9.99E-05]Training epoch 71:  50%|█████     | 56/112 [00:01<00:01, 52.96it/s, Epoch: 71, Batch: 57,Loss: -2.912,Avg.Loss: -2.815,LR: 9.98E-05]Training epoch 71:  51%|█████     | 57/112 [00:01<00:01, 52.96it/s, Epoch: 71, Batch: 58,Loss: -2.893,Avg.Loss: -2.817,LR: 9.98E-05]Training epoch 71:  52%|█████▏    | 58/112 [00:01<00:01, 52.96it/s, Epoch: 71, Batch: 59,Loss: -3.160,Avg.Loss: -2.823,LR: 9.97E-05]Training epoch 71:  53%|█████▎    | 59/112 [00:01<00:01, 52.96it/s, Epoch: 71, Batch: 60,Loss: -2.600,Avg.Loss: -2.819,LR: 9.97E-05]Training epoch 71:  54%|█████▎    | 60/112 [00:01<00:00, 53.18it/s, Epoch: 71, Batch: 60,Loss: -2.600,Avg.Loss: -2.819,LR: 9.97E-05]Training epoch 71:  54%|█████▎    | 60/112 [00:01<00:00, 53.18it/s, Epoch: 71, Batch: 61,Loss: -2.824,Avg.Loss: -2.819,LR: 9.96E-05]Training epoch 71:  54%|█████▍    | 61/112 [00:01<00:00, 53.18it/s, Epoch: 71, Batch: 62,Loss: -3.230,Avg.Loss: -2.826,LR: 9.96E-05]Training epoch 71:  55%|█████▌    | 62/112 [00:01<00:00, 53.18it/s, Epoch: 71, Batch: 63,Loss: -3.355,Avg.Loss: -2.834,LR: 9.95E-05]Training epoch 71:  56%|█████▋    | 63/112 [00:01<00:00, 53.18it/s, Epoch: 71, Batch: 64,Loss: -2.583,Avg.Loss: -2.830,LR: 9.94E-05]Training epoch 71:  57%|█████▋    | 64/112 [00:01<00:00, 53.18it/s, Epoch: 71, Batch: 65,Loss: -2.317,Avg.Loss: -2.822,LR: 9.94E-05]Training epoch 71:  58%|█████▊    | 65/112 [00:01<00:00, 53.18it/s, Epoch: 71, Batch: 66,Loss: -3.211,Avg.Loss: -2.828,LR: 9.93E-05]Training epoch 71:  59%|█████▉    | 66/112 [00:01<00:00, 53.21it/s, Epoch: 71, Batch: 66,Loss: -3.211,Avg.Loss: -2.828,LR: 9.93E-05]Training epoch 71:  59%|█████▉    | 66/112 [00:01<00:00, 53.21it/s, Epoch: 71, Batch: 67,Loss: -3.291,Avg.Loss: -2.835,LR: 9.93E-05]Training epoch 71:  60%|█████▉    | 67/112 [00:01<00:00, 53.21it/s, Epoch: 71, Batch: 68,Loss: -2.520,Avg.Loss: -2.830,LR: 9.92E-05]Training epoch 71:  61%|██████    | 68/112 [00:01<00:00, 53.21it/s, Epoch: 71, Batch: 69,Loss: -2.551,Avg.Loss: -2.826,LR: 9.92E-05]Training epoch 71:  62%|██████▏   | 69/112 [00:01<00:00, 53.21it/s, Epoch: 71, Batch: 70,Loss: -3.587,Avg.Loss: -2.837,LR: 9.91E-05]Training epoch 71:  62%|██████▎   | 70/112 [00:01<00:00, 53.21it/s, Epoch: 71, Batch: 71,Loss: -3.055,Avg.Loss: -2.840,LR: 9.91E-05]Training epoch 71:  63%|██████▎   | 71/112 [00:01<00:00, 53.21it/s, Epoch: 71, Batch: 72,Loss: -2.767,Avg.Loss: -2.839,LR: 9.90E-05]Training epoch 71:  64%|██████▍   | 72/112 [00:01<00:00, 52.63it/s, Epoch: 71, Batch: 72,Loss: -2.767,Avg.Loss: -2.839,LR: 9.90E-05]Training epoch 71:  64%|██████▍   | 72/112 [00:01<00:00, 52.63it/s, Epoch: 71, Batch: 73,Loss: -2.890,Avg.Loss: -2.840,LR: 9.89E-05]Training epoch 71:  65%|██████▌   | 73/112 [00:01<00:00, 52.63it/s, Epoch: 71, Batch: 74,Loss: -3.463,Avg.Loss: -2.848,LR: 9.89E-05]Training epoch 71:  66%|██████▌   | 74/112 [00:01<00:00, 52.63it/s, Epoch: 71, Batch: 75,Loss: -2.945,Avg.Loss: -2.850,LR: 9.88E-05]Training epoch 71:  67%|██████▋   | 75/112 [00:01<00:00, 52.63it/s, Epoch: 71, Batch: 76,Loss: -2.376,Avg.Loss: -2.843,LR: 9.88E-05]Training epoch 71:  68%|██████▊   | 76/112 [00:01<00:00, 52.63it/s, Epoch: 71, Batch: 77,Loss: -2.500,Avg.Loss: -2.839,LR: 9.87E-05]Training epoch 71:  69%|██████▉   | 77/112 [00:01<00:00, 52.63it/s, Epoch: 71, Batch: 78,Loss: -3.222,Avg.Loss: -2.844,LR: 9.87E-05]Training epoch 71:  70%|██████▉   | 78/112 [00:01<00:00, 52.83it/s, Epoch: 71, Batch: 78,Loss: -3.222,Avg.Loss: -2.844,LR: 9.87E-05]Training epoch 71:  70%|██████▉   | 78/112 [00:01<00:00, 52.83it/s, Epoch: 71, Batch: 79,Loss: -3.020,Avg.Loss: -2.846,LR: 9.86E-05]Training epoch 71:  71%|███████   | 79/112 [00:01<00:00, 52.83it/s, Epoch: 71, Batch: 80,Loss: -2.532,Avg.Loss: -2.842,LR: 9.86E-05]Training epoch 71:  71%|███████▏  | 80/112 [00:01<00:00, 52.83it/s, Epoch: 71, Batch: 81,Loss: -2.953,Avg.Loss: -2.844,LR: 9.85E-05]Training epoch 71:  72%|███████▏  | 81/112 [00:01<00:00, 52.83it/s, Epoch: 71, Batch: 82,Loss: -3.419,Avg.Loss: -2.851,LR: 9.84E-05]Training epoch 71:  73%|███████▎  | 82/112 [00:01<00:00, 52.83it/s, Epoch: 71, Batch: 83,Loss: -3.035,Avg.Loss: -2.853,LR: 9.84E-05]Training epoch 71:  74%|███████▍  | 83/112 [00:01<00:00, 52.83it/s, Epoch: 71, Batch: 84,Loss: -2.520,Avg.Loss: -2.849,LR: 9.83E-05]Training epoch 71:  75%|███████▌  | 84/112 [00:01<00:00, 53.20it/s, Epoch: 71, Batch: 84,Loss: -2.520,Avg.Loss: -2.849,LR: 9.83E-05]Training epoch 71:  75%|███████▌  | 84/112 [00:01<00:00, 53.20it/s, Epoch: 71, Batch: 85,Loss: -2.907,Avg.Loss: -2.850,LR: 9.83E-05]Training epoch 71:  76%|███████▌  | 85/112 [00:01<00:00, 53.20it/s, Epoch: 71, Batch: 86,Loss: -3.550,Avg.Loss: -2.858,LR: 9.82E-05]Training epoch 71:  77%|███████▋  | 86/112 [00:01<00:00, 53.20it/s, Epoch: 71, Batch: 87,Loss: -3.233,Avg.Loss: -2.862,LR: 9.82E-05]Training epoch 71:  78%|███████▊  | 87/112 [00:01<00:00, 53.20it/s, Epoch: 71, Batch: 88,Loss: -2.409,Avg.Loss: -2.857,LR: 9.81E-05]Training epoch 71:  79%|███████▊  | 88/112 [00:01<00:00, 53.20it/s, Epoch: 71, Batch: 89,Loss: -2.384,Avg.Loss: -2.852,LR: 9.81E-05]Training epoch 71:  79%|███████▉  | 89/112 [00:01<00:00, 53.20it/s, Epoch: 71, Batch: 90,Loss: -3.038,Avg.Loss: -2.854,LR: 9.80E-05]Training epoch 71:  80%|████████  | 90/112 [00:01<00:00, 53.45it/s, Epoch: 71, Batch: 90,Loss: -3.038,Avg.Loss: -2.854,LR: 9.80E-05]Training epoch 71:  80%|████████  | 90/112 [00:01<00:00, 53.45it/s, Epoch: 71, Batch: 91,Loss: -3.340,Avg.Loss: -2.859,LR: 9.79E-05]Training epoch 71:  81%|████████▏ | 91/112 [00:01<00:00, 53.45it/s, Epoch: 71, Batch: 92,Loss: -2.976,Avg.Loss: -2.860,LR: 9.79E-05]Training epoch 71:  82%|████████▏ | 92/112 [00:01<00:00, 53.45it/s, Epoch: 71, Batch: 93,Loss: -2.845,Avg.Loss: -2.860,LR: 9.78E-05]Training epoch 71:  83%|████████▎ | 93/112 [00:01<00:00, 53.45it/s, Epoch: 71, Batch: 94,Loss: -3.496,Avg.Loss: -2.867,LR: 9.78E-05]Training epoch 71:  84%|████████▍ | 94/112 [00:01<00:00, 53.45it/s, Epoch: 71, Batch: 95,Loss: -3.132,Avg.Loss: -2.870,LR: 9.77E-05]Training epoch 71:  85%|████████▍ | 95/112 [00:01<00:00, 53.45it/s, Epoch: 71, Batch: 96,Loss: -2.738,Avg.Loss: -2.868,LR: 9.77E-05]Training epoch 71:  86%|████████▌ | 96/112 [00:01<00:00, 53.52it/s, Epoch: 71, Batch: 96,Loss: -2.738,Avg.Loss: -2.868,LR: 9.77E-05]Training epoch 71:  86%|████████▌ | 96/112 [00:01<00:00, 53.52it/s, Epoch: 71, Batch: 97,Loss: -2.055,Avg.Loss: -2.860,LR: 9.76E-05]Training epoch 71:  87%|████████▋ | 97/112 [00:01<00:00, 53.52it/s, Epoch: 71, Batch: 98,Loss: -3.072,Avg.Loss: -2.862,LR: 9.76E-05]Training epoch 71:  88%|████████▊ | 98/112 [00:01<00:00, 53.52it/s, Epoch: 71, Batch: 99,Loss: -3.281,Avg.Loss: -2.866,LR: 9.75E-05]Training epoch 71:  88%|████████▊ | 99/112 [00:01<00:00, 53.52it/s, Epoch: 71, Batch: 100,Loss: -2.892,Avg.Loss: -2.866,LR: 9.74E-05]Training epoch 71:  89%|████████▉ | 100/112 [00:01<00:00, 53.52it/s, Epoch: 71, Batch: 101,Loss: -2.673,Avg.Loss: -2.865,LR: 9.74E-05]Training epoch 71:  90%|█████████ | 101/112 [00:01<00:00, 53.52it/s, Epoch: 71, Batch: 102,Loss: -3.185,Avg.Loss: -2.868,LR: 9.73E-05]Training epoch 71:  91%|█████████ | 102/112 [00:01<00:00, 53.64it/s, Epoch: 71, Batch: 102,Loss: -3.185,Avg.Loss: -2.868,LR: 9.73E-05]Training epoch 71:  91%|█████████ | 102/112 [00:01<00:00, 53.64it/s, Epoch: 71, Batch: 103,Loss: -3.007,Avg.Loss: -2.869,LR: 9.73E-05]Training epoch 71:  92%|█████████▏| 103/112 [00:01<00:00, 53.64it/s, Epoch: 71, Batch: 104,Loss: -2.546,Avg.Loss: -2.866,LR: 9.72E-05]Training epoch 71:  93%|█████████▎| 104/112 [00:01<00:00, 53.64it/s, Epoch: 71, Batch: 105,Loss: -2.502,Avg.Loss: -2.862,LR: 9.72E-05]Training epoch 71:  94%|█████████▍| 105/112 [00:01<00:00, 53.64it/s, Epoch: 71, Batch: 106,Loss: -3.323,Avg.Loss: -2.867,LR: 9.71E-05]Training epoch 71:  95%|█████████▍| 106/112 [00:02<00:00, 53.64it/s, Epoch: 71, Batch: 107,Loss: -3.408,Avg.Loss: -2.872,LR: 9.71E-05]Training epoch 71:  96%|█████████▌| 107/112 [00:02<00:00, 53.64it/s, Epoch: 71, Batch: 108,Loss: -2.804,Avg.Loss: -2.871,LR: 9.70E-05]Training epoch 71:  96%|█████████▋| 108/112 [00:02<00:00, 53.56it/s, Epoch: 71, Batch: 108,Loss: -2.804,Avg.Loss: -2.871,LR: 9.70E-05]Training epoch 71:  96%|█████████▋| 108/112 [00:02<00:00, 53.56it/s, Epoch: 71, Batch: 109,Loss: -2.730,Avg.Loss: -2.870,LR: 9.69E-05]Training epoch 71:  97%|█████████▋| 109/112 [00:02<00:00, 53.56it/s, Epoch: 71, Batch: 110,Loss: -3.224,Avg.Loss: -2.873,LR: 9.69E-05]Training epoch 71:  98%|█████████▊| 110/112 [00:02<00:00, 53.56it/s, Epoch: 71, Batch: 111,Loss: -3.278,Avg.Loss: -2.877,LR: 9.68E-05]Training epoch 71:  99%|█████████▉| 111/112 [00:02<00:00, 53.56it/s, Epoch: 71, Batch: 112,Loss: -2.067,Avg.Loss: -2.870,LR: 9.68E-05]Training epoch 71: 100%|██████████| 112/112 [00:02<00:00, 53.08it/s, Epoch: 71, Batch: 112,Loss: -2.067,Avg.Loss: -2.870,LR: 9.68E-05]
Training epoch 72:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 72:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 72, Batch: 1,Loss: -2.602,Avg.Loss: -2.602,LR: 9.67E-05]Training epoch 72:   1%|          | 1/112 [00:00<00:04, 26.50it/s, Epoch: 72, Batch: 2,Loss: -3.132,Avg.Loss: -2.867,LR: 9.67E-05]Training epoch 72:   2%|▏         | 2/112 [00:00<00:02, 39.19it/s, Epoch: 72, Batch: 3,Loss: -3.143,Avg.Loss: -2.959,LR: 9.66E-05]Training epoch 72:   3%|▎         | 3/112 [00:00<00:02, 44.56it/s, Epoch: 72, Batch: 4,Loss: -2.235,Avg.Loss: -2.778,LR: 9.66E-05]Training epoch 72:   4%|▎         | 4/112 [00:00<00:02, 46.98it/s, Epoch: 72, Batch: 5,Loss: -3.185,Avg.Loss: -2.860,LR: 9.65E-05]Training epoch 72:   4%|▍         | 5/112 [00:00<00:02, 48.20it/s, Epoch: 72, Batch: 6,Loss: -3.401,Avg.Loss: -2.950,LR: 9.64E-05]Training epoch 72:   5%|▌         | 6/112 [00:00<00:01, 57.74it/s, Epoch: 72, Batch: 6,Loss: -3.401,Avg.Loss: -2.950,LR: 9.64E-05]Training epoch 72:   5%|▌         | 6/112 [00:00<00:01, 57.74it/s, Epoch: 72, Batch: 7,Loss: -3.244,Avg.Loss: -2.992,LR: 9.64E-05]Training epoch 72:   6%|▋         | 7/112 [00:00<00:01, 57.74it/s, Epoch: 72, Batch: 8,Loss: -2.755,Avg.Loss: -2.962,LR: 9.63E-05]Training epoch 72:   7%|▋         | 8/112 [00:00<00:01, 57.74it/s, Epoch: 72, Batch: 9,Loss: -2.742,Avg.Loss: -2.938,LR: 9.63E-05]Training epoch 72:   8%|▊         | 9/112 [00:00<00:01, 57.74it/s, Epoch: 72, Batch: 10,Loss: -3.334,Avg.Loss: -2.977,LR: 9.62E-05]Training epoch 72:   9%|▉         | 10/112 [00:00<00:01, 57.74it/s, Epoch: 72, Batch: 11,Loss: -2.947,Avg.Loss: -2.975,LR: 9.62E-05]Training epoch 72:  10%|▉         | 11/112 [00:00<00:01, 57.74it/s, Epoch: 72, Batch: 12,Loss: -2.522,Avg.Loss: -2.937,LR: 9.61E-05]Training epoch 72:  11%|█         | 12/112 [00:00<00:01, 55.81it/s, Epoch: 72, Batch: 12,Loss: -2.522,Avg.Loss: -2.937,LR: 9.61E-05]Training epoch 72:  11%|█         | 12/112 [00:00<00:01, 55.81it/s, Epoch: 72, Batch: 13,Loss: -2.432,Avg.Loss: -2.898,LR: 9.61E-05]Training epoch 72:  12%|█▏        | 13/112 [00:00<00:01, 55.81it/s, Epoch: 72, Batch: 14,Loss: -3.466,Avg.Loss: -2.939,LR: 9.60E-05]Training epoch 72:  12%|█▎        | 14/112 [00:00<00:01, 55.81it/s, Epoch: 72, Batch: 15,Loss: -2.914,Avg.Loss: -2.937,LR: 9.59E-05]Training epoch 72:  13%|█▎        | 15/112 [00:00<00:01, 55.81it/s, Epoch: 72, Batch: 16,Loss: -2.360,Avg.Loss: -2.901,LR: 9.59E-05]Training epoch 72:  14%|█▍        | 16/112 [00:00<00:01, 55.81it/s, Epoch: 72, Batch: 17,Loss: -2.705,Avg.Loss: -2.889,LR: 9.58E-05]Training epoch 72:  15%|█▌        | 17/112 [00:00<00:01, 55.81it/s, Epoch: 72, Batch: 18,Loss: -3.080,Avg.Loss: -2.900,LR: 9.58E-05]Training epoch 72:  16%|█▌        | 18/112 [00:00<00:01, 55.41it/s, Epoch: 72, Batch: 18,Loss: -3.080,Avg.Loss: -2.900,LR: 9.58E-05]Training epoch 72:  16%|█▌        | 18/112 [00:00<00:01, 55.41it/s, Epoch: 72, Batch: 19,Loss: -3.126,Avg.Loss: -2.912,LR: 9.57E-05]Training epoch 72:  17%|█▋        | 19/112 [00:00<00:01, 55.41it/s, Epoch: 72, Batch: 20,Loss: -2.978,Avg.Loss: -2.915,LR: 9.57E-05]Training epoch 72:  18%|█▊        | 20/112 [00:00<00:01, 55.41it/s, Epoch: 72, Batch: 21,Loss: -3.233,Avg.Loss: -2.930,LR: 9.56E-05]Training epoch 72:  19%|█▉        | 21/112 [00:00<00:01, 55.41it/s, Epoch: 72, Batch: 22,Loss: -3.508,Avg.Loss: -2.957,LR: 9.56E-05]Training epoch 72:  20%|█▉        | 22/112 [00:00<00:01, 55.41it/s, Epoch: 72, Batch: 23,Loss: -2.890,Avg.Loss: -2.954,LR: 9.55E-05]Training epoch 72:  21%|██        | 23/112 [00:00<00:01, 55.41it/s, Epoch: 72, Batch: 24,Loss: -2.179,Avg.Loss: -2.921,LR: 9.54E-05]Training epoch 72:  21%|██▏       | 24/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 24,Loss: -2.179,Avg.Loss: -2.921,LR: 9.54E-05]Training epoch 72:  21%|██▏       | 24/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 25,Loss: -2.259,Avg.Loss: -2.895,LR: 9.54E-05]Training epoch 72:  22%|██▏       | 25/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 26,Loss: -2.914,Avg.Loss: -2.896,LR: 9.53E-05]Training epoch 72:  23%|██▎       | 26/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 27,Loss: -3.421,Avg.Loss: -2.915,LR: 9.53E-05]Training epoch 72:  24%|██▍       | 27/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 28,Loss: -2.883,Avg.Loss: -2.914,LR: 9.52E-05]Training epoch 72:  25%|██▌       | 28/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 29,Loss: -2.918,Avg.Loss: -2.914,LR: 9.52E-05]Training epoch 72:  26%|██▌       | 29/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 30,Loss: -3.281,Avg.Loss: -2.926,LR: 9.51E-05]Training epoch 72:  27%|██▋       | 30/112 [00:00<00:01, 53.69it/s, Epoch: 72, Batch: 30,Loss: -3.281,Avg.Loss: -2.926,LR: 9.51E-05]Training epoch 72:  27%|██▋       | 30/112 [00:00<00:01, 53.69it/s, Epoch: 72, Batch: 31,Loss: -2.730,Avg.Loss: -2.920,LR: 9.51E-05]Training epoch 72:  28%|██▊       | 31/112 [00:00<00:01, 53.69it/s, Epoch: 72, Batch: 32,Loss: -2.932,Avg.Loss: -2.920,LR: 9.50E-05]Training epoch 72:  29%|██▊       | 32/112 [00:00<00:01, 53.69it/s, Epoch: 72, Batch: 33,Loss: -2.904,Avg.Loss: -2.920,LR: 9.50E-05]Training epoch 72:  29%|██▉       | 33/112 [00:00<00:01, 53.69it/s, Epoch: 72, Batch: 34,Loss: -3.250,Avg.Loss: -2.930,LR: 9.49E-05]Training epoch 72:  30%|███       | 34/112 [00:00<00:01, 53.69it/s, Epoch: 72, Batch: 35,Loss: -3.181,Avg.Loss: -2.937,LR: 9.48E-05]Training epoch 72:  31%|███▏      | 35/112 [00:00<00:01, 53.69it/s, Epoch: 72, Batch: 36,Loss: -2.716,Avg.Loss: -2.931,LR: 9.48E-05]Training epoch 72:  32%|███▏      | 36/112 [00:00<00:01, 53.86it/s, Epoch: 72, Batch: 36,Loss: -2.716,Avg.Loss: -2.931,LR: 9.48E-05]Training epoch 72:  32%|███▏      | 36/112 [00:00<00:01, 53.86it/s, Epoch: 72, Batch: 37,Loss: -2.580,Avg.Loss: -2.921,LR: 9.47E-05]Training epoch 72:  33%|███▎      | 37/112 [00:00<00:01, 53.86it/s, Epoch: 72, Batch: 38,Loss: -3.322,Avg.Loss: -2.932,LR: 9.47E-05]Training epoch 72:  34%|███▍      | 38/112 [00:00<00:01, 53.86it/s, Epoch: 72, Batch: 39,Loss: -3.432,Avg.Loss: -2.944,LR: 9.46E-05]Training epoch 72:  35%|███▍      | 39/112 [00:00<00:01, 53.86it/s, Epoch: 72, Batch: 40,Loss: -2.465,Avg.Loss: -2.932,LR: 9.46E-05]Training epoch 72:  36%|███▌      | 40/112 [00:00<00:01, 53.86it/s, Epoch: 72, Batch: 41,Loss: -3.212,Avg.Loss: -2.939,LR: 9.45E-05]Training epoch 72:  37%|███▋      | 41/112 [00:00<00:01, 53.86it/s, Epoch: 72, Batch: 42,Loss: -3.430,Avg.Loss: -2.951,LR: 9.45E-05]Training epoch 72:  38%|███▊      | 42/112 [00:00<00:01, 54.00it/s, Epoch: 72, Batch: 42,Loss: -3.430,Avg.Loss: -2.951,LR: 9.45E-05]Training epoch 72:  38%|███▊      | 42/112 [00:00<00:01, 54.00it/s, Epoch: 72, Batch: 43,Loss: -3.064,Avg.Loss: -2.954,LR: 9.44E-05]Training epoch 72:  38%|███▊      | 43/112 [00:00<00:01, 54.00it/s, Epoch: 72, Batch: 44,Loss: -2.434,Avg.Loss: -2.942,LR: 9.43E-05]Training epoch 72:  39%|███▉      | 44/112 [00:00<00:01, 54.00it/s, Epoch: 72, Batch: 45,Loss: -2.469,Avg.Loss: -2.931,LR: 9.43E-05]Training epoch 72:  40%|████      | 45/112 [00:00<00:01, 54.00it/s, Epoch: 72, Batch: 46,Loss: -3.144,Avg.Loss: -2.936,LR: 9.42E-05]Training epoch 72:  41%|████      | 46/112 [00:00<00:01, 54.00it/s, Epoch: 72, Batch: 47,Loss: -3.380,Avg.Loss: -2.945,LR: 9.42E-05]Training epoch 72:  42%|████▏     | 47/112 [00:00<00:01, 54.00it/s, Epoch: 72, Batch: 48,Loss: -2.430,Avg.Loss: -2.935,LR: 9.41E-05]Training epoch 72:  43%|████▎     | 48/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 48,Loss: -2.430,Avg.Loss: -2.935,LR: 9.41E-05]Training epoch 72:  43%|████▎     | 48/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 49,Loss: -3.357,Avg.Loss: -2.943,LR: 9.41E-05]Training epoch 72:  44%|████▍     | 49/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 50,Loss: -3.163,Avg.Loss: -2.948,LR: 9.40E-05]Training epoch 72:  45%|████▍     | 50/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 51,Loss: -2.885,Avg.Loss: -2.946,LR: 9.40E-05]Training epoch 72:  46%|████▌     | 51/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 52,Loss: -2.984,Avg.Loss: -2.947,LR: 9.39E-05]Training epoch 72:  46%|████▋     | 52/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 53,Loss: -3.173,Avg.Loss: -2.951,LR: 9.39E-05]Training epoch 72:  47%|████▋     | 53/112 [00:00<00:01, 54.23it/s, Epoch: 72, Batch: 54,Loss: -2.991,Avg.Loss: -2.952,LR: 9.38E-05]Training epoch 72:  48%|████▊     | 54/112 [00:00<00:01, 54.37it/s, Epoch: 72, Batch: 54,Loss: -2.991,Avg.Loss: -2.952,LR: 9.38E-05]Training epoch 72:  48%|████▊     | 54/112 [00:01<00:01, 54.37it/s, Epoch: 72, Batch: 55,Loss: -3.033,Avg.Loss: -2.954,LR: 9.37E-05]Training epoch 72:  49%|████▉     | 55/112 [00:01<00:01, 54.37it/s, Epoch: 72, Batch: 56,Loss: -2.709,Avg.Loss: -2.949,LR: 9.37E-05]Training epoch 72:  50%|█████     | 56/112 [00:01<00:01, 54.37it/s, Epoch: 72, Batch: 57,Loss: -2.948,Avg.Loss: -2.949,LR: 9.36E-05]Training epoch 72:  51%|█████     | 57/112 [00:01<00:01, 54.37it/s, Epoch: 72, Batch: 58,Loss: -3.136,Avg.Loss: -2.952,LR: 9.36E-05]Training epoch 72:  52%|█████▏    | 58/112 [00:01<00:00, 54.37it/s, Epoch: 72, Batch: 59,Loss: -3.346,Avg.Loss: -2.959,LR: 9.35E-05]Training epoch 72:  53%|█████▎    | 59/112 [00:01<00:00, 54.37it/s, Epoch: 72, Batch: 60,Loss: -2.575,Avg.Loss: -2.953,LR: 9.35E-05]Training epoch 72:  54%|█████▎    | 60/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 60,Loss: -2.575,Avg.Loss: -2.953,LR: 9.35E-05]Training epoch 72:  54%|█████▎    | 60/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 61,Loss: -2.613,Avg.Loss: -2.947,LR: 9.34E-05]Training epoch 72:  54%|█████▍    | 61/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 62,Loss: -3.312,Avg.Loss: -2.953,LR: 9.34E-05]Training epoch 72:  55%|█████▌    | 62/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 63,Loss: -2.879,Avg.Loss: -2.952,LR: 9.33E-05]Training epoch 72:  56%|█████▋    | 63/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 64,Loss: -2.627,Avg.Loss: -2.947,LR: 9.33E-05]Training epoch 72:  57%|█████▋    | 64/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 65,Loss: -2.788,Avg.Loss: -2.944,LR: 9.32E-05]Training epoch 72:  58%|█████▊    | 65/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 66,Loss: -3.502,Avg.Loss: -2.953,LR: 9.31E-05]Training epoch 72:  59%|█████▉    | 66/112 [00:01<00:00, 54.56it/s, Epoch: 72, Batch: 66,Loss: -3.502,Avg.Loss: -2.953,LR: 9.31E-05]Training epoch 72:  59%|█████▉    | 66/112 [00:01<00:00, 54.56it/s, Epoch: 72, Batch: 67,Loss: -3.206,Avg.Loss: -2.957,LR: 9.31E-05]Training epoch 72:  60%|█████▉    | 67/112 [00:01<00:00, 54.56it/s, Epoch: 72, Batch: 68,Loss: -2.078,Avg.Loss: -2.944,LR: 9.30E-05]Training epoch 72:  61%|██████    | 68/112 [00:01<00:00, 54.56it/s, Epoch: 72, Batch: 69,Loss: -2.086,Avg.Loss: -2.931,LR: 9.30E-05]Training epoch 72:  62%|██████▏   | 69/112 [00:01<00:00, 54.56it/s, Epoch: 72, Batch: 70,Loss: -3.367,Avg.Loss: -2.937,LR: 9.29E-05]Training epoch 72:  62%|██████▎   | 70/112 [00:01<00:00, 54.56it/s, Epoch: 72, Batch: 71,Loss: -3.157,Avg.Loss: -2.941,LR: 9.29E-05]Training epoch 72:  63%|██████▎   | 71/112 [00:01<00:00, 54.56it/s, Epoch: 72, Batch: 72,Loss: -2.795,Avg.Loss: -2.939,LR: 9.28E-05]Training epoch 72:  64%|██████▍   | 72/112 [00:01<00:00, 54.01it/s, Epoch: 72, Batch: 72,Loss: -2.795,Avg.Loss: -2.939,LR: 9.28E-05]Training epoch 72:  64%|██████▍   | 72/112 [00:01<00:00, 54.01it/s, Epoch: 72, Batch: 73,Loss: -3.160,Avg.Loss: -2.942,LR: 9.28E-05]Training epoch 72:  65%|██████▌   | 73/112 [00:01<00:00, 54.01it/s, Epoch: 72, Batch: 74,Loss: -3.103,Avg.Loss: -2.944,LR: 9.27E-05]Training epoch 72:  66%|██████▌   | 74/112 [00:01<00:00, 54.01it/s, Epoch: 72, Batch: 75,Loss: -2.882,Avg.Loss: -2.943,LR: 9.27E-05]Training epoch 72:  67%|██████▋   | 75/112 [00:01<00:00, 54.01it/s, Epoch: 72, Batch: 76,Loss: -2.011,Avg.Loss: -2.931,LR: 9.26E-05]Training epoch 72:  68%|██████▊   | 76/112 [00:01<00:00, 54.01it/s, Epoch: 72, Batch: 77,Loss: -2.705,Avg.Loss: -2.928,LR: 9.25E-05]Training epoch 72:  69%|██████▉   | 77/112 [00:01<00:00, 54.01it/s, Epoch: 72, Batch: 78,Loss: -3.351,Avg.Loss: -2.933,LR: 9.25E-05]Training epoch 72:  70%|██████▉   | 78/112 [00:01<00:00, 53.87it/s, Epoch: 72, Batch: 78,Loss: -3.351,Avg.Loss: -2.933,LR: 9.25E-05]Training epoch 72:  70%|██████▉   | 78/112 [00:01<00:00, 53.87it/s, Epoch: 72, Batch: 79,Loss: -3.331,Avg.Loss: -2.938,LR: 9.24E-05]Training epoch 72:  71%|███████   | 79/112 [00:01<00:00, 53.87it/s, Epoch: 72, Batch: 80,Loss: -2.603,Avg.Loss: -2.934,LR: 9.24E-05]Training epoch 72:  71%|███████▏  | 80/112 [00:01<00:00, 53.87it/s, Epoch: 72, Batch: 81,Loss: -3.105,Avg.Loss: -2.936,LR: 9.23E-05]Training epoch 72:  72%|███████▏  | 81/112 [00:01<00:00, 53.87it/s, Epoch: 72, Batch: 82,Loss: -3.462,Avg.Loss: -2.942,LR: 9.23E-05]Training epoch 72:  73%|███████▎  | 82/112 [00:01<00:00, 53.87it/s, Epoch: 72, Batch: 83,Loss: -2.901,Avg.Loss: -2.942,LR: 9.22E-05]Training epoch 72:  74%|███████▍  | 83/112 [00:01<00:00, 53.87it/s, Epoch: 72, Batch: 84,Loss: -2.391,Avg.Loss: -2.935,LR: 9.22E-05]Training epoch 72:  75%|███████▌  | 84/112 [00:01<00:00, 54.16it/s, Epoch: 72, Batch: 84,Loss: -2.391,Avg.Loss: -2.935,LR: 9.22E-05]Training epoch 72:  75%|███████▌  | 84/112 [00:01<00:00, 54.16it/s, Epoch: 72, Batch: 85,Loss: -2.526,Avg.Loss: -2.931,LR: 9.21E-05]Training epoch 72:  76%|███████▌  | 85/112 [00:01<00:00, 54.16it/s, Epoch: 72, Batch: 86,Loss: -3.214,Avg.Loss: -2.934,LR: 9.21E-05]Training epoch 72:  77%|███████▋  | 86/112 [00:01<00:00, 54.16it/s, Epoch: 72, Batch: 87,Loss: -2.581,Avg.Loss: -2.930,LR: 9.20E-05]Training epoch 72:  78%|███████▊  | 87/112 [00:01<00:00, 54.16it/s, Epoch: 72, Batch: 88,Loss: -2.735,Avg.Loss: -2.928,LR: 9.19E-05]Training epoch 72:  79%|███████▊  | 88/112 [00:01<00:00, 54.16it/s, Epoch: 72, Batch: 89,Loss: -3.010,Avg.Loss: -2.929,LR: 9.19E-05]Training epoch 72:  79%|███████▉  | 89/112 [00:01<00:00, 54.16it/s, Epoch: 72, Batch: 90,Loss: -3.401,Avg.Loss: -2.934,LR: 9.18E-05]Training epoch 72:  80%|████████  | 90/112 [00:01<00:00, 54.33it/s, Epoch: 72, Batch: 90,Loss: -3.401,Avg.Loss: -2.934,LR: 9.18E-05]Training epoch 72:  80%|████████  | 90/112 [00:01<00:00, 54.33it/s, Epoch: 72, Batch: 91,Loss: -3.452,Avg.Loss: -2.940,LR: 9.18E-05]Training epoch 72:  81%|████████▏ | 91/112 [00:01<00:00, 54.33it/s, Epoch: 72, Batch: 92,Loss: -2.582,Avg.Loss: -2.936,LR: 9.17E-05]Training epoch 72:  82%|████████▏ | 92/112 [00:01<00:00, 54.33it/s, Epoch: 72, Batch: 93,Loss: -2.663,Avg.Loss: -2.933,LR: 9.17E-05]Training epoch 72:  83%|████████▎ | 93/112 [00:01<00:00, 54.33it/s, Epoch: 72, Batch: 94,Loss: -3.189,Avg.Loss: -2.935,LR: 9.16E-05]Training epoch 72:  84%|████████▍ | 94/112 [00:01<00:00, 54.33it/s, Epoch: 72, Batch: 95,Loss: -3.056,Avg.Loss: -2.937,LR: 9.16E-05]Training epoch 72:  85%|████████▍ | 95/112 [00:01<00:00, 54.33it/s, Epoch: 72, Batch: 96,Loss: -2.826,Avg.Loss: -2.936,LR: 9.15E-05]Training epoch 72:  86%|████████▌ | 96/112 [00:01<00:00, 54.38it/s, Epoch: 72, Batch: 96,Loss: -2.826,Avg.Loss: -2.936,LR: 9.15E-05]Training epoch 72:  86%|████████▌ | 96/112 [00:01<00:00, 54.38it/s, Epoch: 72, Batch: 97,Loss: -2.526,Avg.Loss: -2.931,LR: 9.15E-05]Training epoch 72:  87%|████████▋ | 97/112 [00:01<00:00, 54.38it/s, Epoch: 72, Batch: 98,Loss: -3.269,Avg.Loss: -2.935,LR: 9.14E-05]Training epoch 72:  88%|████████▊ | 98/112 [00:01<00:00, 54.38it/s, Epoch: 72, Batch: 99,Loss: -3.165,Avg.Loss: -2.937,LR: 9.13E-05]Training epoch 72:  88%|████████▊ | 99/112 [00:01<00:00, 54.38it/s, Epoch: 72, Batch: 100,Loss: -2.527,Avg.Loss: -2.933,LR: 9.13E-05]Training epoch 72:  89%|████████▉ | 100/112 [00:01<00:00, 54.38it/s, Epoch: 72, Batch: 101,Loss: -2.800,Avg.Loss: -2.932,LR: 9.12E-05]Training epoch 72:  90%|█████████ | 101/112 [00:01<00:00, 54.38it/s, Epoch: 72, Batch: 102,Loss: -3.242,Avg.Loss: -2.935,LR: 9.12E-05]Training epoch 72:  91%|█████████ | 102/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 102,Loss: -3.242,Avg.Loss: -2.935,LR: 9.12E-05]Training epoch 72:  91%|█████████ | 102/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 103,Loss: -3.148,Avg.Loss: -2.937,LR: 9.11E-05]Training epoch 72:  92%|█████████▏| 103/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 104,Loss: -2.707,Avg.Loss: -2.935,LR: 9.11E-05]Training epoch 72:  93%|█████████▎| 104/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 105,Loss: -2.642,Avg.Loss: -2.932,LR: 9.10E-05]Training epoch 72:  94%|█████████▍| 105/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 106,Loss: -3.041,Avg.Loss: -2.933,LR: 9.10E-05]Training epoch 72:  95%|█████████▍| 106/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 107,Loss: -3.075,Avg.Loss: -2.934,LR: 9.09E-05]Training epoch 72:  96%|█████████▌| 107/112 [00:01<00:00, 54.45it/s, Epoch: 72, Batch: 108,Loss: -2.811,Avg.Loss: -2.933,LR: 9.09E-05]Training epoch 72:  96%|█████████▋| 108/112 [00:01<00:00, 52.92it/s, Epoch: 72, Batch: 108,Loss: -2.811,Avg.Loss: -2.933,LR: 9.09E-05]Training epoch 72:  96%|█████████▋| 108/112 [00:02<00:00, 52.92it/s, Epoch: 72, Batch: 109,Loss: -2.732,Avg.Loss: -2.931,LR: 9.08E-05]Training epoch 72:  97%|█████████▋| 109/112 [00:02<00:00, 52.92it/s, Epoch: 72, Batch: 110,Loss: -3.201,Avg.Loss: -2.934,LR: 9.08E-05]Training epoch 72:  98%|█████████▊| 110/112 [00:02<00:00, 52.92it/s, Epoch: 72, Batch: 111,Loss: -2.738,Avg.Loss: -2.932,LR: 9.07E-05]Training epoch 72:  99%|█████████▉| 111/112 [00:02<00:00, 52.92it/s, Epoch: 72, Batch: 112,Loss: -2.830,Avg.Loss: -2.931,LR: 9.06E-05]Training epoch 72: 100%|██████████| 112/112 [00:02<00:00, 54.03it/s, Epoch: 72, Batch: 112,Loss: -2.830,Avg.Loss: -2.931,LR: 9.06E-05]
Training epoch 73:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 73:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 73, Batch: 1,Loss: -2.379,Avg.Loss: -2.379,LR: 9.06E-05]Training epoch 73:   1%|          | 1/112 [00:00<00:03, 29.35it/s, Epoch: 73, Batch: 2,Loss: -3.362,Avg.Loss: -2.871,LR: 9.05E-05]Training epoch 73:   2%|▏         | 2/112 [00:00<00:02, 41.15it/s, Epoch: 73, Batch: 3,Loss: -2.837,Avg.Loss: -2.860,LR: 9.05E-05]Training epoch 73:   3%|▎         | 3/112 [00:00<00:02, 45.59it/s, Epoch: 73, Batch: 4,Loss: -2.278,Avg.Loss: -2.714,LR: 9.04E-05]Training epoch 73:   4%|▎         | 4/112 [00:00<00:02, 47.85it/s, Epoch: 73, Batch: 5,Loss: -2.940,Avg.Loss: -2.759,LR: 9.04E-05]Training epoch 73:   4%|▍         | 5/112 [00:00<00:02, 49.37it/s, Epoch: 73, Batch: 6,Loss: -3.131,Avg.Loss: -2.821,LR: 9.03E-05]Training epoch 73:   5%|▌         | 6/112 [00:00<00:01, 59.15it/s, Epoch: 73, Batch: 6,Loss: -3.131,Avg.Loss: -2.821,LR: 9.03E-05]Training epoch 73:   5%|▌         | 6/112 [00:00<00:01, 59.15it/s, Epoch: 73, Batch: 7,Loss: -2.950,Avg.Loss: -2.840,LR: 9.03E-05]Training epoch 73:   6%|▋         | 7/112 [00:00<00:01, 59.15it/s, Epoch: 73, Batch: 8,Loss: -2.888,Avg.Loss: -2.846,LR: 9.02E-05]Training epoch 73:   7%|▋         | 8/112 [00:00<00:01, 59.15it/s, Epoch: 73, Batch: 9,Loss: -2.861,Avg.Loss: -2.847,LR: 9.02E-05]Training epoch 73:   8%|▊         | 9/112 [00:00<00:01, 59.15it/s, Epoch: 73, Batch: 10,Loss: -3.088,Avg.Loss: -2.871,LR: 9.01E-05]Training epoch 73:   9%|▉         | 10/112 [00:00<00:01, 59.15it/s, Epoch: 73, Batch: 11,Loss: -2.735,Avg.Loss: -2.859,LR: 9.01E-05]Training epoch 73:  10%|▉         | 11/112 [00:00<00:01, 59.15it/s, Epoch: 73, Batch: 12,Loss: -2.475,Avg.Loss: -2.827,LR: 9.00E-05]Training epoch 73:  11%|█         | 12/112 [00:00<00:01, 55.74it/s, Epoch: 73, Batch: 12,Loss: -2.475,Avg.Loss: -2.827,LR: 9.00E-05]Training epoch 73:  11%|█         | 12/112 [00:00<00:01, 55.74it/s, Epoch: 73, Batch: 13,Loss: -2.750,Avg.Loss: -2.821,LR: 8.99E-05]Training epoch 73:  12%|█▏        | 13/112 [00:00<00:01, 55.74it/s, Epoch: 73, Batch: 14,Loss: -3.154,Avg.Loss: -2.845,LR: 8.99E-05]Training epoch 73:  12%|█▎        | 14/112 [00:00<00:01, 55.74it/s, Epoch: 73, Batch: 15,Loss: -3.120,Avg.Loss: -2.863,LR: 8.98E-05]Training epoch 73:  13%|█▎        | 15/112 [00:00<00:01, 55.74it/s, Epoch: 73, Batch: 16,Loss: -2.740,Avg.Loss: -2.856,LR: 8.98E-05]Training epoch 73:  14%|█▍        | 16/112 [00:00<00:01, 55.74it/s, Epoch: 73, Batch: 17,Loss: -2.855,Avg.Loss: -2.856,LR: 8.97E-05]Training epoch 73:  15%|█▌        | 17/112 [00:00<00:01, 55.74it/s, Epoch: 73, Batch: 18,Loss: -3.122,Avg.Loss: -2.870,LR: 8.97E-05]Training epoch 73:  16%|█▌        | 18/112 [00:00<00:01, 54.72it/s, Epoch: 73, Batch: 18,Loss: -3.122,Avg.Loss: -2.870,LR: 8.97E-05]Training epoch 73:  16%|█▌        | 18/112 [00:00<00:01, 54.72it/s, Epoch: 73, Batch: 19,Loss: -3.289,Avg.Loss: -2.892,LR: 8.96E-05]Training epoch 73:  17%|█▋        | 19/112 [00:00<00:01, 54.72it/s, Epoch: 73, Batch: 20,Loss: -2.731,Avg.Loss: -2.884,LR: 8.96E-05]Training epoch 73:  18%|█▊        | 20/112 [00:00<00:01, 54.72it/s, Epoch: 73, Batch: 21,Loss: -2.921,Avg.Loss: -2.886,LR: 8.95E-05]Training epoch 73:  19%|█▉        | 21/112 [00:00<00:01, 54.72it/s, Epoch: 73, Batch: 22,Loss: -3.130,Avg.Loss: -2.897,LR: 8.95E-05]Training epoch 73:  20%|█▉        | 22/112 [00:00<00:01, 54.72it/s, Epoch: 73, Batch: 23,Loss: -3.113,Avg.Loss: -2.907,LR: 8.94E-05]Training epoch 73:  21%|██        | 23/112 [00:00<00:01, 54.72it/s, Epoch: 73, Batch: 24,Loss: -2.864,Avg.Loss: -2.905,LR: 8.94E-05]Training epoch 73:  21%|██▏       | 24/112 [00:00<00:01, 52.28it/s, Epoch: 73, Batch: 24,Loss: -2.864,Avg.Loss: -2.905,LR: 8.94E-05]Training epoch 73:  21%|██▏       | 24/112 [00:00<00:01, 52.28it/s, Epoch: 73, Batch: 25,Loss: -3.077,Avg.Loss: -2.912,LR: 8.93E-05]Training epoch 73:  22%|██▏       | 25/112 [00:00<00:01, 52.28it/s, Epoch: 73, Batch: 26,Loss: -3.377,Avg.Loss: -2.930,LR: 8.92E-05]Training epoch 73:  23%|██▎       | 26/112 [00:00<00:01, 52.28it/s, Epoch: 73, Batch: 27,Loss: -3.042,Avg.Loss: -2.934,LR: 8.92E-05]Training epoch 73:  24%|██▍       | 27/112 [00:00<00:01, 52.28it/s, Epoch: 73, Batch: 28,Loss: -2.751,Avg.Loss: -2.927,LR: 8.91E-05]Training epoch 73:  25%|██▌       | 28/112 [00:00<00:01, 52.28it/s, Epoch: 73, Batch: 29,Loss: -2.888,Avg.Loss: -2.926,LR: 8.91E-05]Training epoch 73:  26%|██▌       | 29/112 [00:00<00:01, 52.28it/s, Epoch: 73, Batch: 30,Loss: -3.229,Avg.Loss: -2.936,LR: 8.90E-05]Training epoch 73:  27%|██▋       | 30/112 [00:00<00:01, 51.16it/s, Epoch: 73, Batch: 30,Loss: -3.229,Avg.Loss: -2.936,LR: 8.90E-05]Training epoch 73:  27%|██▋       | 30/112 [00:00<00:01, 51.16it/s, Epoch: 73, Batch: 31,Loss: -3.312,Avg.Loss: -2.948,LR: 8.90E-05]Training epoch 73:  28%|██▊       | 31/112 [00:00<00:01, 51.16it/s, Epoch: 73, Batch: 32,Loss: -2.713,Avg.Loss: -2.941,LR: 8.89E-05]Training epoch 73:  29%|██▊       | 32/112 [00:00<00:01, 51.16it/s, Epoch: 73, Batch: 33,Loss: -3.068,Avg.Loss: -2.945,LR: 8.89E-05]Training epoch 73:  29%|██▉       | 33/112 [00:00<00:01, 51.16it/s, Epoch: 73, Batch: 34,Loss: -3.424,Avg.Loss: -2.959,LR: 8.88E-05]Training epoch 73:  30%|███       | 34/112 [00:00<00:01, 51.16it/s, Epoch: 73, Batch: 35,Loss: -3.261,Avg.Loss: -2.967,LR: 8.88E-05]Training epoch 73:  31%|███▏      | 35/112 [00:00<00:01, 51.16it/s, Epoch: 73, Batch: 36,Loss: -3.046,Avg.Loss: -2.969,LR: 8.87E-05]Training epoch 73:  32%|███▏      | 36/112 [00:00<00:01, 50.85it/s, Epoch: 73, Batch: 36,Loss: -3.046,Avg.Loss: -2.969,LR: 8.87E-05]Training epoch 73:  32%|███▏      | 36/112 [00:00<00:01, 50.85it/s, Epoch: 73, Batch: 37,Loss: -3.229,Avg.Loss: -2.976,LR: 8.87E-05]Training epoch 73:  33%|███▎      | 37/112 [00:00<00:01, 50.85it/s, Epoch: 73, Batch: 38,Loss: -3.424,Avg.Loss: -2.988,LR: 8.86E-05]Training epoch 73:  34%|███▍      | 38/112 [00:00<00:01, 50.85it/s, Epoch: 73, Batch: 39,Loss: -3.115,Avg.Loss: -2.992,LR: 8.85E-05]Training epoch 73:  35%|███▍      | 39/112 [00:00<00:01, 50.85it/s, Epoch: 73, Batch: 40,Loss: -2.479,Avg.Loss: -2.979,LR: 8.85E-05]Training epoch 73:  36%|███▌      | 40/112 [00:00<00:01, 50.85it/s, Epoch: 73, Batch: 41,Loss: -2.752,Avg.Loss: -2.973,LR: 8.84E-05]Training epoch 73:  37%|███▋      | 41/112 [00:00<00:01, 50.85it/s, Epoch: 73, Batch: 42,Loss: -3.289,Avg.Loss: -2.981,LR: 8.84E-05]Training epoch 73:  38%|███▊      | 42/112 [00:00<00:01, 51.47it/s, Epoch: 73, Batch: 42,Loss: -3.289,Avg.Loss: -2.981,LR: 8.84E-05]Training epoch 73:  38%|███▊      | 42/112 [00:00<00:01, 51.47it/s, Epoch: 73, Batch: 43,Loss: -3.141,Avg.Loss: -2.984,LR: 8.83E-05]Training epoch 73:  38%|███▊      | 43/112 [00:00<00:01, 51.47it/s, Epoch: 73, Batch: 44,Loss: -2.860,Avg.Loss: -2.982,LR: 8.83E-05]Training epoch 73:  39%|███▉      | 44/112 [00:00<00:01, 51.47it/s, Epoch: 73, Batch: 45,Loss: -3.190,Avg.Loss: -2.986,LR: 8.82E-05]Training epoch 73:  40%|████      | 45/112 [00:00<00:01, 51.47it/s, Epoch: 73, Batch: 46,Loss: -3.022,Avg.Loss: -2.987,LR: 8.82E-05]Training epoch 73:  41%|████      | 46/112 [00:00<00:01, 51.47it/s, Epoch: 73, Batch: 47,Loss: -3.088,Avg.Loss: -2.989,LR: 8.81E-05]Training epoch 73:  42%|████▏     | 47/112 [00:00<00:01, 51.47it/s, Epoch: 73, Batch: 48,Loss: -2.511,Avg.Loss: -2.979,LR: 8.81E-05]Training epoch 73:  43%|████▎     | 48/112 [00:00<00:01, 52.09it/s, Epoch: 73, Batch: 48,Loss: -2.511,Avg.Loss: -2.979,LR: 8.81E-05]Training epoch 73:  43%|████▎     | 48/112 [00:00<00:01, 52.09it/s, Epoch: 73, Batch: 49,Loss: -3.049,Avg.Loss: -2.981,LR: 8.80E-05]Training epoch 73:  44%|████▍     | 49/112 [00:00<00:01, 52.09it/s, Epoch: 73, Batch: 50,Loss: -3.426,Avg.Loss: -2.990,LR: 8.80E-05]Training epoch 73:  45%|████▍     | 50/112 [00:00<00:01, 52.09it/s, Epoch: 73, Batch: 51,Loss: -3.231,Avg.Loss: -2.994,LR: 8.79E-05]Training epoch 73:  46%|████▌     | 51/112 [00:00<00:01, 52.09it/s, Epoch: 73, Batch: 52,Loss: -3.015,Avg.Loss: -2.995,LR: 8.79E-05]Training epoch 73:  46%|████▋     | 52/112 [00:01<00:01, 52.09it/s, Epoch: 73, Batch: 53,Loss: -2.686,Avg.Loss: -2.989,LR: 8.78E-05]Training epoch 73:  47%|████▋     | 53/112 [00:01<00:01, 52.09it/s, Epoch: 73, Batch: 54,Loss: -3.500,Avg.Loss: -2.998,LR: 8.77E-05]Training epoch 73:  48%|████▊     | 54/112 [00:01<00:01, 52.43it/s, Epoch: 73, Batch: 54,Loss: -3.500,Avg.Loss: -2.998,LR: 8.77E-05]Training epoch 73:  48%|████▊     | 54/112 [00:01<00:01, 52.43it/s, Epoch: 73, Batch: 55,Loss: -3.253,Avg.Loss: -3.003,LR: 8.77E-05]Training epoch 73:  49%|████▉     | 55/112 [00:01<00:01, 52.43it/s, Epoch: 73, Batch: 56,Loss: -2.706,Avg.Loss: -2.998,LR: 8.76E-05]Training epoch 73:  50%|█████     | 56/112 [00:01<00:01, 52.43it/s, Epoch: 73, Batch: 57,Loss: -3.295,Avg.Loss: -3.003,LR: 8.76E-05]Training epoch 73:  51%|█████     | 57/112 [00:01<00:01, 52.43it/s, Epoch: 73, Batch: 58,Loss: -3.165,Avg.Loss: -3.006,LR: 8.75E-05]Training epoch 73:  52%|█████▏    | 58/112 [00:01<00:01, 52.43it/s, Epoch: 73, Batch: 59,Loss: -2.890,Avg.Loss: -3.004,LR: 8.75E-05]Training epoch 73:  53%|█████▎    | 59/112 [00:01<00:01, 52.43it/s, Epoch: 73, Batch: 60,Loss: -2.811,Avg.Loss: -3.000,LR: 8.74E-05]Training epoch 73:  54%|█████▎    | 60/112 [00:01<00:00, 52.64it/s, Epoch: 73, Batch: 60,Loss: -2.811,Avg.Loss: -3.000,LR: 8.74E-05]Training epoch 73:  54%|█████▎    | 60/112 [00:01<00:00, 52.64it/s, Epoch: 73, Batch: 61,Loss: -2.805,Avg.Loss: -2.997,LR: 8.74E-05]Training epoch 73:  54%|█████▍    | 61/112 [00:01<00:00, 52.64it/s, Epoch: 73, Batch: 62,Loss: -3.041,Avg.Loss: -2.998,LR: 8.73E-05]Training epoch 73:  55%|█████▌    | 62/112 [00:01<00:00, 52.64it/s, Epoch: 73, Batch: 63,Loss: -3.594,Avg.Loss: -3.007,LR: 8.73E-05]Training epoch 73:  56%|█████▋    | 63/112 [00:01<00:00, 52.64it/s, Epoch: 73, Batch: 64,Loss: -2.679,Avg.Loss: -3.002,LR: 8.72E-05]Training epoch 73:  57%|█████▋    | 64/112 [00:01<00:00, 52.64it/s, Epoch: 73, Batch: 65,Loss: -2.756,Avg.Loss: -2.999,LR: 8.72E-05]Training epoch 73:  58%|█████▊    | 65/112 [00:01<00:00, 52.64it/s, Epoch: 73, Batch: 66,Loss: -3.367,Avg.Loss: -3.004,LR: 8.71E-05]Training epoch 73:  59%|█████▉    | 66/112 [00:01<00:00, 52.58it/s, Epoch: 73, Batch: 66,Loss: -3.367,Avg.Loss: -3.004,LR: 8.71E-05]Training epoch 73:  59%|█████▉    | 66/112 [00:01<00:00, 52.58it/s, Epoch: 73, Batch: 67,Loss: -2.869,Avg.Loss: -3.002,LR: 8.71E-05]Training epoch 73:  60%|█████▉    | 67/112 [00:01<00:00, 52.58it/s, Epoch: 73, Batch: 68,Loss: -3.377,Avg.Loss: -3.008,LR: 8.70E-05]Training epoch 73:  61%|██████    | 68/112 [00:01<00:00, 52.58it/s, Epoch: 73, Batch: 69,Loss: -3.202,Avg.Loss: -3.010,LR: 8.69E-05]Training epoch 73:  62%|██████▏   | 69/112 [00:01<00:00, 52.58it/s, Epoch: 73, Batch: 70,Loss: -3.394,Avg.Loss: -3.016,LR: 8.69E-05]Training epoch 73:  62%|██████▎   | 70/112 [00:01<00:00, 52.58it/s, Epoch: 73, Batch: 71,Loss: -3.323,Avg.Loss: -3.020,LR: 8.68E-05]Training epoch 73:  63%|██████▎   | 71/112 [00:01<00:00, 52.58it/s, Epoch: 73, Batch: 72,Loss: -2.836,Avg.Loss: -3.018,LR: 8.68E-05]Training epoch 73:  64%|██████▍   | 72/112 [00:01<00:00, 52.49it/s, Epoch: 73, Batch: 72,Loss: -2.836,Avg.Loss: -3.018,LR: 8.68E-05]Training epoch 73:  64%|██████▍   | 72/112 [00:01<00:00, 52.49it/s, Epoch: 73, Batch: 73,Loss: -3.231,Avg.Loss: -3.021,LR: 8.67E-05]Training epoch 73:  65%|██████▌   | 73/112 [00:01<00:00, 52.49it/s, Epoch: 73, Batch: 74,Loss: -2.963,Avg.Loss: -3.020,LR: 8.67E-05]Training epoch 73:  66%|██████▌   | 74/112 [00:01<00:00, 52.49it/s, Epoch: 73, Batch: 75,Loss: -2.878,Avg.Loss: -3.018,LR: 8.66E-05]Training epoch 73:  67%|██████▋   | 75/112 [00:01<00:00, 52.49it/s, Epoch: 73, Batch: 76,Loss: -2.701,Avg.Loss: -3.014,LR: 8.66E-05]Training epoch 73:  68%|██████▊   | 76/112 [00:01<00:00, 52.49it/s, Epoch: 73, Batch: 77,Loss: -3.249,Avg.Loss: -3.017,LR: 8.65E-05]Training epoch 73:  69%|██████▉   | 77/112 [00:01<00:00, 52.49it/s, Epoch: 73, Batch: 78,Loss: -3.248,Avg.Loss: -3.020,LR: 8.65E-05]Training epoch 73:  70%|██████▉   | 78/112 [00:01<00:00, 53.14it/s, Epoch: 73, Batch: 78,Loss: -3.248,Avg.Loss: -3.020,LR: 8.65E-05]Training epoch 73:  70%|██████▉   | 78/112 [00:01<00:00, 53.14it/s, Epoch: 73, Batch: 79,Loss: -2.620,Avg.Loss: -3.015,LR: 8.64E-05]Training epoch 73:  71%|███████   | 79/112 [00:01<00:00, 53.14it/s, Epoch: 73, Batch: 80,Loss: -3.278,Avg.Loss: -3.018,LR: 8.64E-05]Training epoch 73:  71%|███████▏  | 80/112 [00:01<00:00, 53.14it/s, Epoch: 73, Batch: 81,Loss: -3.283,Avg.Loss: -3.021,LR: 8.63E-05]Training epoch 73:  72%|███████▏  | 81/112 [00:01<00:00, 53.14it/s, Epoch: 73, Batch: 82,Loss: -3.470,Avg.Loss: -3.027,LR: 8.63E-05]Training epoch 73:  73%|███████▎  | 82/112 [00:01<00:00, 53.14it/s, Epoch: 73, Batch: 83,Loss: -3.156,Avg.Loss: -3.028,LR: 8.62E-05]Training epoch 73:  74%|███████▍  | 83/112 [00:01<00:00, 53.14it/s, Epoch: 73, Batch: 84,Loss: -3.230,Avg.Loss: -3.031,LR: 8.61E-05]Training epoch 73:  75%|███████▌  | 84/112 [00:01<00:00, 53.26it/s, Epoch: 73, Batch: 84,Loss: -3.230,Avg.Loss: -3.031,LR: 8.61E-05]Training epoch 73:  75%|███████▌  | 84/112 [00:01<00:00, 53.26it/s, Epoch: 73, Batch: 85,Loss: -3.314,Avg.Loss: -3.034,LR: 8.61E-05]Training epoch 73:  76%|███████▌  | 85/112 [00:01<00:00, 53.26it/s, Epoch: 73, Batch: 86,Loss: -3.215,Avg.Loss: -3.036,LR: 8.60E-05]Training epoch 73:  77%|███████▋  | 86/112 [00:01<00:00, 53.26it/s, Epoch: 73, Batch: 87,Loss: -2.991,Avg.Loss: -3.036,LR: 8.60E-05]Training epoch 73:  78%|███████▊  | 87/112 [00:01<00:00, 53.26it/s, Epoch: 73, Batch: 88,Loss: -2.846,Avg.Loss: -3.033,LR: 8.59E-05]Training epoch 73:  79%|███████▊  | 88/112 [00:01<00:00, 53.26it/s, Epoch: 73, Batch: 89,Loss: -2.899,Avg.Loss: -3.032,LR: 8.59E-05]Training epoch 73:  79%|███████▉  | 89/112 [00:01<00:00, 53.26it/s, Epoch: 73, Batch: 90,Loss: -2.981,Avg.Loss: -3.031,LR: 8.58E-05]Training epoch 73:  80%|████████  | 90/112 [00:01<00:00, 53.50it/s, Epoch: 73, Batch: 90,Loss: -2.981,Avg.Loss: -3.031,LR: 8.58E-05]Training epoch 73:  80%|████████  | 90/112 [00:01<00:00, 53.50it/s, Epoch: 73, Batch: 91,Loss: -2.955,Avg.Loss: -3.031,LR: 8.58E-05]Training epoch 73:  81%|████████▏ | 91/112 [00:01<00:00, 53.50it/s, Epoch: 73, Batch: 92,Loss: -2.827,Avg.Loss: -3.028,LR: 8.57E-05]Training epoch 73:  82%|████████▏ | 92/112 [00:01<00:00, 53.50it/s, Epoch: 73, Batch: 93,Loss: -3.014,Avg.Loss: -3.028,LR: 8.57E-05]Training epoch 73:  83%|████████▎ | 93/112 [00:01<00:00, 53.50it/s, Epoch: 73, Batch: 94,Loss: -3.228,Avg.Loss: -3.030,LR: 8.56E-05]Training epoch 73:  84%|████████▍ | 94/112 [00:01<00:00, 53.50it/s, Epoch: 73, Batch: 95,Loss: -3.223,Avg.Loss: -3.032,LR: 8.56E-05]Training epoch 73:  85%|████████▍ | 95/112 [00:01<00:00, 53.50it/s, Epoch: 73, Batch: 96,Loss: -3.250,Avg.Loss: -3.035,LR: 8.55E-05]Training epoch 73:  86%|████████▌ | 96/112 [00:01<00:00, 53.73it/s, Epoch: 73, Batch: 96,Loss: -3.250,Avg.Loss: -3.035,LR: 8.55E-05]Training epoch 73:  86%|████████▌ | 96/112 [00:01<00:00, 53.73it/s, Epoch: 73, Batch: 97,Loss: -3.474,Avg.Loss: -3.039,LR: 8.55E-05]Training epoch 73:  87%|████████▋ | 97/112 [00:01<00:00, 53.73it/s, Epoch: 73, Batch: 98,Loss: -3.384,Avg.Loss: -3.043,LR: 8.54E-05]Training epoch 73:  88%|████████▊ | 98/112 [00:01<00:00, 53.73it/s, Epoch: 73, Batch: 99,Loss: -2.914,Avg.Loss: -3.041,LR: 8.54E-05]Training epoch 73:  88%|████████▊ | 99/112 [00:01<00:00, 53.73it/s, Epoch: 73, Batch: 100,Loss: -3.619,Avg.Loss: -3.047,LR: 8.53E-05]Training epoch 73:  89%|████████▉ | 100/112 [00:01<00:00, 53.73it/s, Epoch: 73, Batch: 101,Loss: -3.000,Avg.Loss: -3.047,LR: 8.53E-05]Training epoch 73:  90%|█████████ | 101/112 [00:01<00:00, 53.73it/s, Epoch: 73, Batch: 102,Loss: -3.318,Avg.Loss: -3.049,LR: 8.52E-05]Training epoch 73:  91%|█████████ | 102/112 [00:01<00:00, 53.72it/s, Epoch: 73, Batch: 102,Loss: -3.318,Avg.Loss: -3.049,LR: 8.52E-05]Training epoch 73:  91%|█████████ | 102/112 [00:01<00:00, 53.72it/s, Epoch: 73, Batch: 103,Loss: -2.930,Avg.Loss: -3.048,LR: 8.51E-05]Training epoch 73:  92%|█████████▏| 103/112 [00:01<00:00, 53.72it/s, Epoch: 73, Batch: 104,Loss: -2.971,Avg.Loss: -3.047,LR: 8.51E-05]Training epoch 73:  93%|█████████▎| 104/112 [00:01<00:00, 53.72it/s, Epoch: 73, Batch: 105,Loss: -3.141,Avg.Loss: -3.048,LR: 8.50E-05]Training epoch 73:  94%|█████████▍| 105/112 [00:01<00:00, 53.72it/s, Epoch: 73, Batch: 106,Loss: -2.562,Avg.Loss: -3.044,LR: 8.50E-05]Training epoch 73:  95%|█████████▍| 106/112 [00:02<00:00, 53.72it/s, Epoch: 73, Batch: 107,Loss: -2.640,Avg.Loss: -3.040,LR: 8.49E-05]Training epoch 73:  96%|█████████▌| 107/112 [00:02<00:00, 53.72it/s, Epoch: 73, Batch: 108,Loss: -3.001,Avg.Loss: -3.040,LR: 8.49E-05]Training epoch 73:  96%|█████████▋| 108/112 [00:02<00:00, 53.67it/s, Epoch: 73, Batch: 108,Loss: -3.001,Avg.Loss: -3.040,LR: 8.49E-05]Training epoch 73:  96%|█████████▋| 108/112 [00:02<00:00, 53.67it/s, Epoch: 73, Batch: 109,Loss: -3.154,Avg.Loss: -3.041,LR: 8.48E-05]Training epoch 73:  97%|█████████▋| 109/112 [00:02<00:00, 53.67it/s, Epoch: 73, Batch: 110,Loss: -2.848,Avg.Loss: -3.039,LR: 8.48E-05]Training epoch 73:  98%|█████████▊| 110/112 [00:02<00:00, 53.67it/s, Epoch: 73, Batch: 111,Loss: -2.823,Avg.Loss: -3.037,LR: 8.47E-05]Training epoch 73:  99%|█████████▉| 111/112 [00:02<00:00, 53.67it/s, Epoch: 73, Batch: 112,Loss: -4.382,Avg.Loss: -3.049,LR: 8.47E-05]Training epoch 73: 100%|██████████| 112/112 [00:02<00:00, 53.00it/s, Epoch: 73, Batch: 112,Loss: -4.382,Avg.Loss: -3.049,LR: 8.47E-05]
Training epoch 74:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 74:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 74, Batch: 1,Loss: -2.960,Avg.Loss: -2.960,LR: 8.46E-05]Training epoch 74:   1%|          | 1/112 [00:00<00:04, 26.58it/s, Epoch: 74, Batch: 2,Loss: -1.896,Avg.Loss: -2.428,LR: 8.46E-05]Training epoch 74:   2%|▏         | 2/112 [00:00<00:02, 38.65it/s, Epoch: 74, Batch: 3,Loss: -1.841,Avg.Loss: -2.232,LR: 8.45E-05]Training epoch 74:   3%|▎         | 3/112 [00:00<00:02, 43.94it/s, Epoch: 74, Batch: 4,Loss: -2.371,Avg.Loss: -2.267,LR: 8.45E-05]Training epoch 74:   4%|▎         | 4/112 [00:00<00:02, 46.84it/s, Epoch: 74, Batch: 5,Loss: -3.304,Avg.Loss: -2.474,LR: 8.44E-05]Training epoch 74:   4%|▍         | 5/112 [00:00<00:02, 48.65it/s, Epoch: 74, Batch: 6,Loss: -2.590,Avg.Loss: -2.493,LR: 8.44E-05]Training epoch 74:   5%|▌         | 6/112 [00:00<00:01, 58.27it/s, Epoch: 74, Batch: 6,Loss: -2.590,Avg.Loss: -2.493,LR: 8.44E-05]Training epoch 74:   5%|▌         | 6/112 [00:00<00:01, 58.27it/s, Epoch: 74, Batch: 7,Loss: -1.662,Avg.Loss: -2.375,LR: 8.43E-05]Training epoch 74:   6%|▋         | 7/112 [00:00<00:01, 58.27it/s, Epoch: 74, Batch: 8,Loss: -1.156,Avg.Loss: -2.222,LR: 8.43E-05]Training epoch 74:   7%|▋         | 8/112 [00:00<00:01, 58.27it/s, Epoch: 74, Batch: 9,Loss: -1.295,Avg.Loss: -2.119,LR: 8.42E-05]Training epoch 74:   8%|▊         | 9/112 [00:00<00:01, 58.27it/s, Epoch: 74, Batch: 10,Loss: -3.174,Avg.Loss: -2.225,LR: 8.41E-05]Training epoch 74:   9%|▉         | 10/112 [00:00<00:01, 58.27it/s, Epoch: 74, Batch: 11,Loss: -3.365,Avg.Loss: -2.328,LR: 8.41E-05]Training epoch 74:  10%|▉         | 11/112 [00:00<00:01, 58.27it/s, Epoch: 74, Batch: 12,Loss: -2.678,Avg.Loss: -2.358,LR: 8.40E-05]Training epoch 74:  11%|█         | 12/112 [00:00<00:01, 55.27it/s, Epoch: 74, Batch: 12,Loss: -2.678,Avg.Loss: -2.358,LR: 8.40E-05]Training epoch 74:  11%|█         | 12/112 [00:00<00:01, 55.27it/s, Epoch: 74, Batch: 13,Loss: -2.260,Avg.Loss: -2.350,LR: 8.40E-05]Training epoch 74:  12%|█▏        | 13/112 [00:00<00:01, 55.27it/s, Epoch: 74, Batch: 14,Loss: -3.283,Avg.Loss: -2.417,LR: 8.39E-05]Training epoch 74:  12%|█▎        | 14/112 [00:00<00:01, 55.27it/s, Epoch: 74, Batch: 15,Loss: -3.192,Avg.Loss: -2.468,LR: 8.39E-05]Training epoch 74:  13%|█▎        | 15/112 [00:00<00:01, 55.27it/s, Epoch: 74, Batch: 16,Loss: -2.940,Avg.Loss: -2.498,LR: 8.38E-05]Training epoch 74:  14%|█▍        | 16/112 [00:00<00:01, 55.27it/s, Epoch: 74, Batch: 17,Loss: -3.216,Avg.Loss: -2.540,LR: 8.38E-05]Training epoch 74:  15%|█▌        | 17/112 [00:00<00:01, 55.27it/s, Epoch: 74, Batch: 18,Loss: -3.282,Avg.Loss: -2.581,LR: 8.37E-05]Training epoch 74:  16%|█▌        | 18/112 [00:00<00:01, 54.44it/s, Epoch: 74, Batch: 18,Loss: -3.282,Avg.Loss: -2.581,LR: 8.37E-05]Training epoch 74:  16%|█▌        | 18/112 [00:00<00:01, 54.44it/s, Epoch: 74, Batch: 19,Loss: -3.316,Avg.Loss: -2.620,LR: 8.37E-05]Training epoch 74:  17%|█▋        | 19/112 [00:00<00:01, 54.44it/s, Epoch: 74, Batch: 20,Loss: -2.735,Avg.Loss: -2.626,LR: 8.36E-05]Training epoch 74:  18%|█▊        | 20/112 [00:00<00:01, 54.44it/s, Epoch: 74, Batch: 21,Loss: -2.557,Avg.Loss: -2.623,LR: 8.36E-05]Training epoch 74:  19%|█▉        | 21/112 [00:00<00:01, 54.44it/s, Epoch: 74, Batch: 22,Loss: -2.921,Avg.Loss: -2.636,LR: 8.35E-05]Training epoch 74:  20%|█▉        | 22/112 [00:00<00:01, 54.44it/s, Epoch: 74, Batch: 23,Loss: -2.946,Avg.Loss: -2.650,LR: 8.35E-05]Training epoch 74:  21%|██        | 23/112 [00:00<00:01, 54.44it/s, Epoch: 74, Batch: 24,Loss: -2.955,Avg.Loss: -2.662,LR: 8.34E-05]Training epoch 74:  21%|██▏       | 24/112 [00:00<00:01, 53.46it/s, Epoch: 74, Batch: 24,Loss: -2.955,Avg.Loss: -2.662,LR: 8.34E-05]Training epoch 74:  21%|██▏       | 24/112 [00:00<00:01, 53.46it/s, Epoch: 74, Batch: 25,Loss: -3.118,Avg.Loss: -2.681,LR: 8.34E-05]Training epoch 74:  22%|██▏       | 25/112 [00:00<00:01, 53.46it/s, Epoch: 74, Batch: 26,Loss: -3.015,Avg.Loss: -2.693,LR: 8.33E-05]Training epoch 74:  23%|██▎       | 26/112 [00:00<00:01, 53.46it/s, Epoch: 74, Batch: 27,Loss: -2.863,Avg.Loss: -2.700,LR: 8.33E-05]Training epoch 74:  24%|██▍       | 27/112 [00:00<00:01, 53.46it/s, Epoch: 74, Batch: 28,Loss: -2.584,Avg.Loss: -2.696,LR: 8.32E-05]Training epoch 74:  25%|██▌       | 28/112 [00:00<00:01, 53.46it/s, Epoch: 74, Batch: 29,Loss: -2.850,Avg.Loss: -2.701,LR: 8.32E-05]Training epoch 74:  26%|██▌       | 29/112 [00:00<00:01, 53.46it/s, Epoch: 74, Batch: 30,Loss: -3.042,Avg.Loss: -2.712,LR: 8.31E-05]Training epoch 74:  27%|██▋       | 30/112 [00:00<00:01, 53.37it/s, Epoch: 74, Batch: 30,Loss: -3.042,Avg.Loss: -2.712,LR: 8.31E-05]Training epoch 74:  27%|██▋       | 30/112 [00:00<00:01, 53.37it/s, Epoch: 74, Batch: 31,Loss: -3.223,Avg.Loss: -2.729,LR: 8.30E-05]Training epoch 74:  28%|██▊       | 31/112 [00:00<00:01, 53.37it/s, Epoch: 74, Batch: 32,Loss: -3.253,Avg.Loss: -2.745,LR: 8.30E-05]Training epoch 74:  29%|██▊       | 32/112 [00:00<00:01, 53.37it/s, Epoch: 74, Batch: 33,Loss: -2.992,Avg.Loss: -2.753,LR: 8.29E-05]Training epoch 74:  29%|██▉       | 33/112 [00:00<00:01, 53.37it/s, Epoch: 74, Batch: 34,Loss: -3.052,Avg.Loss: -2.761,LR: 8.29E-05]Training epoch 74:  30%|███       | 34/112 [00:00<00:01, 53.37it/s, Epoch: 74, Batch: 35,Loss: -3.252,Avg.Loss: -2.775,LR: 8.28E-05]Training epoch 74:  31%|███▏      | 35/112 [00:00<00:01, 53.37it/s, Epoch: 74, Batch: 36,Loss: -3.215,Avg.Loss: -2.788,LR: 8.28E-05]Training epoch 74:  32%|███▏      | 36/112 [00:00<00:01, 53.48it/s, Epoch: 74, Batch: 36,Loss: -3.215,Avg.Loss: -2.788,LR: 8.28E-05]Training epoch 74:  32%|███▏      | 36/112 [00:00<00:01, 53.48it/s, Epoch: 74, Batch: 37,Loss: -3.351,Avg.Loss: -2.803,LR: 8.27E-05]Training epoch 74:  33%|███▎      | 37/112 [00:00<00:01, 53.48it/s, Epoch: 74, Batch: 38,Loss: -2.978,Avg.Loss: -2.807,LR: 8.27E-05]Training epoch 74:  34%|███▍      | 38/112 [00:00<00:01, 53.48it/s, Epoch: 74, Batch: 39,Loss: -3.435,Avg.Loss: -2.824,LR: 8.26E-05]Training epoch 74:  35%|███▍      | 39/112 [00:00<00:01, 53.48it/s, Epoch: 74, Batch: 40,Loss: -3.012,Avg.Loss: -2.828,LR: 8.26E-05]Training epoch 74:  36%|███▌      | 40/112 [00:00<00:01, 53.48it/s, Epoch: 74, Batch: 41,Loss: -3.017,Avg.Loss: -2.833,LR: 8.25E-05]Training epoch 74:  37%|███▋      | 41/112 [00:00<00:01, 53.48it/s, Epoch: 74, Batch: 42,Loss: -3.299,Avg.Loss: -2.844,LR: 8.25E-05]Training epoch 74:  38%|███▊      | 42/112 [00:00<00:01, 53.49it/s, Epoch: 74, Batch: 42,Loss: -3.299,Avg.Loss: -2.844,LR: 8.25E-05]Training epoch 74:  38%|███▊      | 42/112 [00:00<00:01, 53.49it/s, Epoch: 74, Batch: 43,Loss: -2.899,Avg.Loss: -2.845,LR: 8.24E-05]Training epoch 74:  38%|███▊      | 43/112 [00:00<00:01, 53.49it/s, Epoch: 74, Batch: 44,Loss: -3.261,Avg.Loss: -2.855,LR: 8.24E-05]Training epoch 74:  39%|███▉      | 44/112 [00:00<00:01, 53.49it/s, Epoch: 74, Batch: 45,Loss: -2.857,Avg.Loss: -2.855,LR: 8.23E-05]Training epoch 74:  40%|████      | 45/112 [00:00<00:01, 53.49it/s, Epoch: 74, Batch: 46,Loss: -3.546,Avg.Loss: -2.870,LR: 8.23E-05]Training epoch 74:  41%|████      | 46/112 [00:00<00:01, 53.49it/s, Epoch: 74, Batch: 47,Loss: -3.123,Avg.Loss: -2.875,LR: 8.22E-05]Training epoch 74:  42%|████▏     | 47/112 [00:00<00:01, 53.49it/s, Epoch: 74, Batch: 48,Loss: -3.613,Avg.Loss: -2.891,LR: 8.22E-05]Training epoch 74:  43%|████▎     | 48/112 [00:00<00:01, 53.17it/s, Epoch: 74, Batch: 48,Loss: -3.613,Avg.Loss: -2.891,LR: 8.22E-05]Training epoch 74:  43%|████▎     | 48/112 [00:00<00:01, 53.17it/s, Epoch: 74, Batch: 49,Loss: -3.339,Avg.Loss: -2.900,LR: 8.21E-05]Training epoch 74:  44%|████▍     | 49/112 [00:00<00:01, 53.17it/s, Epoch: 74, Batch: 50,Loss: -3.770,Avg.Loss: -2.917,LR: 8.21E-05]Training epoch 74:  45%|████▍     | 50/112 [00:00<00:01, 53.17it/s, Epoch: 74, Batch: 51,Loss: -3.452,Avg.Loss: -2.928,LR: 8.20E-05]Training epoch 74:  46%|████▌     | 51/112 [00:00<00:01, 53.17it/s, Epoch: 74, Batch: 52,Loss: -3.086,Avg.Loss: -2.931,LR: 8.20E-05]Training epoch 74:  46%|████▋     | 52/112 [00:00<00:01, 53.17it/s, Epoch: 74, Batch: 53,Loss: -3.024,Avg.Loss: -2.932,LR: 8.19E-05]Training epoch 74:  47%|████▋     | 53/112 [00:01<00:01, 53.17it/s, Epoch: 74, Batch: 54,Loss: -2.913,Avg.Loss: -2.932,LR: 8.19E-05]Training epoch 74:  48%|████▊     | 54/112 [00:01<00:01, 53.22it/s, Epoch: 74, Batch: 54,Loss: -2.913,Avg.Loss: -2.932,LR: 8.19E-05]Training epoch 74:  48%|████▊     | 54/112 [00:01<00:01, 53.22it/s, Epoch: 74, Batch: 55,Loss: -3.191,Avg.Loss: -2.937,LR: 8.18E-05]Training epoch 74:  49%|████▉     | 55/112 [00:01<00:01, 53.22it/s, Epoch: 74, Batch: 56,Loss: -3.000,Avg.Loss: -2.938,LR: 8.17E-05]Training epoch 74:  50%|█████     | 56/112 [00:01<00:01, 53.22it/s, Epoch: 74, Batch: 57,Loss: -3.200,Avg.Loss: -2.942,LR: 8.17E-05]Training epoch 74:  51%|█████     | 57/112 [00:01<00:01, 53.22it/s, Epoch: 74, Batch: 58,Loss: -3.173,Avg.Loss: -2.946,LR: 8.16E-05]Training epoch 74:  52%|█████▏    | 58/112 [00:01<00:01, 53.22it/s, Epoch: 74, Batch: 59,Loss: -3.522,Avg.Loss: -2.956,LR: 8.16E-05]Training epoch 74:  53%|█████▎    | 59/112 [00:01<00:00, 53.22it/s, Epoch: 74, Batch: 60,Loss: -3.131,Avg.Loss: -2.959,LR: 8.15E-05]Training epoch 74:  54%|█████▎    | 60/112 [00:01<00:00, 53.21it/s, Epoch: 74, Batch: 60,Loss: -3.131,Avg.Loss: -2.959,LR: 8.15E-05]Training epoch 74:  54%|█████▎    | 60/112 [00:01<00:00, 53.21it/s, Epoch: 74, Batch: 61,Loss: -3.431,Avg.Loss: -2.967,LR: 8.15E-05]Training epoch 74:  54%|█████▍    | 61/112 [00:01<00:00, 53.21it/s, Epoch: 74, Batch: 62,Loss: -2.847,Avg.Loss: -2.965,LR: 8.14E-05]Training epoch 74:  55%|█████▌    | 62/112 [00:01<00:00, 53.21it/s, Epoch: 74, Batch: 63,Loss: -2.909,Avg.Loss: -2.964,LR: 8.14E-05]Training epoch 74:  56%|█████▋    | 63/112 [00:01<00:00, 53.21it/s, Epoch: 74, Batch: 64,Loss: -2.877,Avg.Loss: -2.963,LR: 8.13E-05]Training epoch 74:  57%|█████▋    | 64/112 [00:01<00:00, 53.21it/s, Epoch: 74, Batch: 65,Loss: -2.585,Avg.Loss: -2.957,LR: 8.13E-05]Training epoch 74:  58%|█████▊    | 65/112 [00:01<00:00, 53.21it/s, Epoch: 74, Batch: 66,Loss: -3.217,Avg.Loss: -2.961,LR: 8.12E-05]Training epoch 74:  59%|█████▉    | 66/112 [00:01<00:00, 53.01it/s, Epoch: 74, Batch: 66,Loss: -3.217,Avg.Loss: -2.961,LR: 8.12E-05]Training epoch 74:  59%|█████▉    | 66/112 [00:01<00:00, 53.01it/s, Epoch: 74, Batch: 67,Loss: -2.870,Avg.Loss: -2.959,LR: 8.12E-05]Training epoch 74:  60%|█████▉    | 67/112 [00:01<00:00, 53.01it/s, Epoch: 74, Batch: 68,Loss: -2.709,Avg.Loss: -2.956,LR: 8.11E-05]Training epoch 74:  61%|██████    | 68/112 [00:01<00:00, 53.01it/s, Epoch: 74, Batch: 69,Loss: -2.291,Avg.Loss: -2.946,LR: 8.11E-05]Training epoch 74:  62%|██████▏   | 69/112 [00:01<00:00, 53.01it/s, Epoch: 74, Batch: 70,Loss: -2.793,Avg.Loss: -2.944,LR: 8.10E-05]Training epoch 74:  62%|██████▎   | 70/112 [00:01<00:00, 53.01it/s, Epoch: 74, Batch: 71,Loss: -2.957,Avg.Loss: -2.944,LR: 8.10E-05]Training epoch 74:  63%|██████▎   | 71/112 [00:01<00:00, 53.01it/s, Epoch: 74, Batch: 72,Loss: -3.129,Avg.Loss: -2.947,LR: 8.09E-05]Training epoch 74:  64%|██████▍   | 72/112 [00:01<00:00, 53.05it/s, Epoch: 74, Batch: 72,Loss: -3.129,Avg.Loss: -2.947,LR: 8.09E-05]Training epoch 74:  64%|██████▍   | 72/112 [00:01<00:00, 53.05it/s, Epoch: 74, Batch: 73,Loss: -2.463,Avg.Loss: -2.940,LR: 8.09E-05]Training epoch 74:  65%|██████▌   | 73/112 [00:01<00:00, 53.05it/s, Epoch: 74, Batch: 74,Loss: -2.807,Avg.Loss: -2.938,LR: 8.08E-05]Training epoch 74:  66%|██████▌   | 74/112 [00:01<00:00, 53.05it/s, Epoch: 74, Batch: 75,Loss: -3.345,Avg.Loss: -2.944,LR: 8.08E-05]Training epoch 74:  67%|██████▋   | 75/112 [00:01<00:00, 53.05it/s, Epoch: 74, Batch: 76,Loss: -3.139,Avg.Loss: -2.946,LR: 8.07E-05]Training epoch 74:  68%|██████▊   | 76/112 [00:01<00:00, 53.05it/s, Epoch: 74, Batch: 77,Loss: -3.148,Avg.Loss: -2.949,LR: 8.07E-05]Training epoch 74:  69%|██████▉   | 77/112 [00:01<00:00, 53.05it/s, Epoch: 74, Batch: 78,Loss: -2.196,Avg.Loss: -2.939,LR: 8.06E-05]Training epoch 74:  70%|██████▉   | 78/112 [00:01<00:00, 52.96it/s, Epoch: 74, Batch: 78,Loss: -2.196,Avg.Loss: -2.939,LR: 8.06E-05]Training epoch 74:  70%|██████▉   | 78/112 [00:01<00:00, 52.96it/s, Epoch: 74, Batch: 79,Loss: -3.127,Avg.Loss: -2.942,LR: 8.06E-05]Training epoch 74:  71%|███████   | 79/112 [00:01<00:00, 52.96it/s, Epoch: 74, Batch: 80,Loss: -2.953,Avg.Loss: -2.942,LR: 8.05E-05]Training epoch 74:  71%|███████▏  | 80/112 [00:01<00:00, 52.96it/s, Epoch: 74, Batch: 81,Loss: -2.716,Avg.Loss: -2.939,LR: 8.05E-05]Training epoch 74:  72%|███████▏  | 81/112 [00:01<00:00, 52.96it/s, Epoch: 74, Batch: 82,Loss: -3.322,Avg.Loss: -2.944,LR: 8.04E-05]Training epoch 74:  73%|███████▎  | 82/112 [00:01<00:00, 52.96it/s, Epoch: 74, Batch: 83,Loss: -3.412,Avg.Loss: -2.949,LR: 8.04E-05]Training epoch 74:  74%|███████▍  | 83/112 [00:01<00:00, 52.96it/s, Epoch: 74, Batch: 84,Loss: -3.330,Avg.Loss: -2.954,LR: 8.03E-05]Training epoch 74:  75%|███████▌  | 84/112 [00:01<00:00, 53.29it/s, Epoch: 74, Batch: 84,Loss: -3.330,Avg.Loss: -2.954,LR: 8.03E-05]Training epoch 74:  75%|███████▌  | 84/112 [00:01<00:00, 53.29it/s, Epoch: 74, Batch: 85,Loss: -3.015,Avg.Loss: -2.955,LR: 8.02E-05]Training epoch 74:  76%|███████▌  | 85/112 [00:01<00:00, 53.29it/s, Epoch: 74, Batch: 86,Loss: -2.784,Avg.Loss: -2.953,LR: 8.02E-05]Training epoch 74:  77%|███████▋  | 86/112 [00:01<00:00, 53.29it/s, Epoch: 74, Batch: 87,Loss: -3.112,Avg.Loss: -2.954,LR: 8.01E-05]Training epoch 74:  78%|███████▊  | 87/112 [00:01<00:00, 53.29it/s, Epoch: 74, Batch: 88,Loss: -3.285,Avg.Loss: -2.958,LR: 8.01E-05]Training epoch 74:  79%|███████▊  | 88/112 [00:01<00:00, 53.29it/s, Epoch: 74, Batch: 89,Loss: -2.543,Avg.Loss: -2.953,LR: 8.00E-05]Training epoch 74:  79%|███████▉  | 89/112 [00:01<00:00, 53.29it/s, Epoch: 74, Batch: 90,Loss: -2.165,Avg.Loss: -2.945,LR: 8.00E-05]Training epoch 74:  80%|████████  | 90/112 [00:01<00:00, 50.26it/s, Epoch: 74, Batch: 90,Loss: -2.165,Avg.Loss: -2.945,LR: 8.00E-05]Training epoch 74:  80%|████████  | 90/112 [00:01<00:00, 50.26it/s, Epoch: 74, Batch: 91,Loss: -3.302,Avg.Loss: -2.949,LR: 7.99E-05]Training epoch 74:  81%|████████▏ | 91/112 [00:01<00:00, 50.26it/s, Epoch: 74, Batch: 92,Loss: -3.195,Avg.Loss: -2.951,LR: 7.99E-05]Training epoch 74:  82%|████████▏ | 92/112 [00:01<00:00, 50.26it/s, Epoch: 74, Batch: 93,Loss: -2.927,Avg.Loss: -2.951,LR: 7.98E-05]Training epoch 74:  83%|████████▎ | 93/112 [00:01<00:00, 50.26it/s, Epoch: 74, Batch: 94,Loss: -2.233,Avg.Loss: -2.943,LR: 7.98E-05]Training epoch 74:  84%|████████▍ | 94/112 [00:01<00:00, 50.26it/s, Epoch: 74, Batch: 95,Loss: -3.291,Avg.Loss: -2.947,LR: 7.97E-05]Training epoch 74:  85%|████████▍ | 95/112 [00:01<00:00, 50.26it/s, Epoch: 74, Batch: 96,Loss: -3.280,Avg.Loss: -2.951,LR: 7.97E-05]Training epoch 74:  86%|████████▌ | 96/112 [00:01<00:00, 51.16it/s, Epoch: 74, Batch: 96,Loss: -3.280,Avg.Loss: -2.951,LR: 7.97E-05]Training epoch 74:  86%|████████▌ | 96/112 [00:01<00:00, 51.16it/s, Epoch: 74, Batch: 97,Loss: -2.996,Avg.Loss: -2.951,LR: 7.96E-05]Training epoch 74:  87%|████████▋ | 97/112 [00:01<00:00, 51.16it/s, Epoch: 74, Batch: 98,Loss: -2.604,Avg.Loss: -2.947,LR: 7.96E-05]Training epoch 74:  88%|████████▊ | 98/112 [00:01<00:00, 51.16it/s, Epoch: 74, Batch: 99,Loss: -3.374,Avg.Loss: -2.952,LR: 7.95E-05]Training epoch 74:  88%|████████▊ | 99/112 [00:01<00:00, 51.16it/s, Epoch: 74, Batch: 100,Loss: -3.345,Avg.Loss: -2.956,LR: 7.95E-05]Training epoch 74:  89%|████████▉ | 100/112 [00:01<00:00, 51.16it/s, Epoch: 74, Batch: 101,Loss: -2.744,Avg.Loss: -2.954,LR: 7.94E-05]Training epoch 74:  90%|█████████ | 101/112 [00:01<00:00, 51.16it/s, Epoch: 74, Batch: 102,Loss: -2.737,Avg.Loss: -2.951,LR: 7.94E-05]Training epoch 74:  91%|█████████ | 102/112 [00:01<00:00, 51.83it/s, Epoch: 74, Batch: 102,Loss: -2.737,Avg.Loss: -2.951,LR: 7.94E-05]Training epoch 74:  91%|█████████ | 102/112 [00:01<00:00, 51.83it/s, Epoch: 74, Batch: 103,Loss: -3.082,Avg.Loss: -2.953,LR: 7.93E-05]Training epoch 74:  92%|█████████▏| 103/112 [00:01<00:00, 51.83it/s, Epoch: 74, Batch: 104,Loss: -3.225,Avg.Loss: -2.955,LR: 7.93E-05]Training epoch 74:  93%|█████████▎| 104/112 [00:01<00:00, 51.83it/s, Epoch: 74, Batch: 105,Loss: -2.551,Avg.Loss: -2.952,LR: 7.92E-05]Training epoch 74:  94%|█████████▍| 105/112 [00:02<00:00, 51.83it/s, Epoch: 74, Batch: 106,Loss: -2.927,Avg.Loss: -2.951,LR: 7.92E-05]Training epoch 74:  95%|█████████▍| 106/112 [00:02<00:00, 51.83it/s, Epoch: 74, Batch: 107,Loss: -3.372,Avg.Loss: -2.955,LR: 7.91E-05]Training epoch 74:  96%|█████████▌| 107/112 [00:02<00:00, 51.83it/s, Epoch: 74, Batch: 108,Loss: -3.246,Avg.Loss: -2.958,LR: 7.91E-05]Training epoch 74:  96%|█████████▋| 108/112 [00:02<00:00, 52.04it/s, Epoch: 74, Batch: 108,Loss: -3.246,Avg.Loss: -2.958,LR: 7.91E-05]Training epoch 74:  96%|█████████▋| 108/112 [00:02<00:00, 52.04it/s, Epoch: 74, Batch: 109,Loss: -2.785,Avg.Loss: -2.956,LR: 7.90E-05]Training epoch 74:  97%|█████████▋| 109/112 [00:02<00:00, 52.04it/s, Epoch: 74, Batch: 110,Loss: -2.860,Avg.Loss: -2.955,LR: 7.90E-05]Training epoch 74:  98%|█████████▊| 110/112 [00:02<00:00, 52.04it/s, Epoch: 74, Batch: 111,Loss: -3.349,Avg.Loss: -2.959,LR: 7.89E-05]Training epoch 74:  99%|█████████▉| 111/112 [00:02<00:00, 52.04it/s, Epoch: 74, Batch: 112,Loss: -2.404,Avg.Loss: -2.954,LR: 7.89E-05]Training epoch 74: 100%|██████████| 112/112 [00:02<00:00, 52.75it/s, Epoch: 74, Batch: 112,Loss: -2.404,Avg.Loss: -2.954,LR: 7.89E-05]
Training epoch 75:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 75:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 75, Batch: 1,Loss: -2.758,Avg.Loss: -2.758,LR: 7.88E-05]Training epoch 75:   1%|          | 1/112 [00:00<00:04, 23.53it/s, Epoch: 75, Batch: 2,Loss: -3.036,Avg.Loss: -2.897,LR: 7.88E-05]Training epoch 75:   2%|▏         | 2/112 [00:00<00:03, 33.81it/s, Epoch: 75, Batch: 3,Loss: -3.003,Avg.Loss: -2.932,LR: 7.87E-05]Training epoch 75:   3%|▎         | 3/112 [00:00<00:02, 39.44it/s, Epoch: 75, Batch: 4,Loss: -3.206,Avg.Loss: -3.001,LR: 7.87E-05]Training epoch 75:   4%|▎         | 4/112 [00:00<00:02, 42.82it/s, Epoch: 75, Batch: 5,Loss: -2.779,Avg.Loss: -2.956,LR: 7.86E-05]Training epoch 75:   4%|▍         | 5/112 [00:00<00:02, 44.97it/s, Epoch: 75, Batch: 6,Loss: -2.824,Avg.Loss: -2.934,LR: 7.86E-05]Training epoch 75:   5%|▌         | 6/112 [00:00<00:01, 53.90it/s, Epoch: 75, Batch: 6,Loss: -2.824,Avg.Loss: -2.934,LR: 7.86E-05]Training epoch 75:   5%|▌         | 6/112 [00:00<00:01, 53.90it/s, Epoch: 75, Batch: 7,Loss: -3.683,Avg.Loss: -3.041,LR: 7.85E-05]Training epoch 75:   6%|▋         | 7/112 [00:00<00:01, 53.90it/s, Epoch: 75, Batch: 8,Loss: -3.045,Avg.Loss: -3.042,LR: 7.85E-05]Training epoch 75:   7%|▋         | 8/112 [00:00<00:01, 53.90it/s, Epoch: 75, Batch: 9,Loss: -2.211,Avg.Loss: -2.949,LR: 7.84E-05]Training epoch 75:   8%|▊         | 9/112 [00:00<00:01, 53.90it/s, Epoch: 75, Batch: 10,Loss: -2.878,Avg.Loss: -2.942,LR: 7.84E-05]Training epoch 75:   9%|▉         | 10/112 [00:00<00:01, 53.90it/s, Epoch: 75, Batch: 11,Loss: -3.359,Avg.Loss: -2.980,LR: 7.83E-05]Training epoch 75:  10%|▉         | 11/112 [00:00<00:01, 53.90it/s, Epoch: 75, Batch: 12,Loss: -3.328,Avg.Loss: -3.009,LR: 7.83E-05]Training epoch 75:  11%|█         | 12/112 [00:00<00:01, 53.19it/s, Epoch: 75, Batch: 12,Loss: -3.328,Avg.Loss: -3.009,LR: 7.83E-05]Training epoch 75:  11%|█         | 12/112 [00:00<00:01, 53.19it/s, Epoch: 75, Batch: 13,Loss: -2.525,Avg.Loss: -2.972,LR: 7.82E-05]Training epoch 75:  12%|█▏        | 13/112 [00:00<00:01, 53.19it/s, Epoch: 75, Batch: 14,Loss: -2.827,Avg.Loss: -2.962,LR: 7.81E-05]Training epoch 75:  12%|█▎        | 14/112 [00:00<00:01, 53.19it/s, Epoch: 75, Batch: 15,Loss: -3.299,Avg.Loss: -2.984,LR: 7.81E-05]Training epoch 75:  13%|█▎        | 15/112 [00:00<00:01, 53.19it/s, Epoch: 75, Batch: 16,Loss: -3.182,Avg.Loss: -2.996,LR: 7.80E-05]Training epoch 75:  14%|█▍        | 16/112 [00:00<00:01, 53.19it/s, Epoch: 75, Batch: 17,Loss: -3.149,Avg.Loss: -3.005,LR: 7.80E-05]Training epoch 75:  15%|█▌        | 17/112 [00:00<00:01, 53.19it/s, Epoch: 75, Batch: 18,Loss: -2.906,Avg.Loss: -3.000,LR: 7.79E-05]Training epoch 75:  16%|█▌        | 18/112 [00:00<00:01, 53.04it/s, Epoch: 75, Batch: 18,Loss: -2.906,Avg.Loss: -3.000,LR: 7.79E-05]Training epoch 75:  16%|█▌        | 18/112 [00:00<00:01, 53.04it/s, Epoch: 75, Batch: 19,Loss: -3.485,Avg.Loss: -3.025,LR: 7.79E-05]Training epoch 75:  17%|█▋        | 19/112 [00:00<00:01, 53.04it/s, Epoch: 75, Batch: 20,Loss: -2.974,Avg.Loss: -3.023,LR: 7.78E-05]Training epoch 75:  18%|█▊        | 20/112 [00:00<00:01, 53.04it/s, Epoch: 75, Batch: 21,Loss: -2.439,Avg.Loss: -2.995,LR: 7.78E-05]Training epoch 75:  19%|█▉        | 21/112 [00:00<00:01, 53.04it/s, Epoch: 75, Batch: 22,Loss: -2.570,Avg.Loss: -2.976,LR: 7.77E-05]Training epoch 75:  20%|█▉        | 22/112 [00:00<00:01, 53.04it/s, Epoch: 75, Batch: 23,Loss: -3.134,Avg.Loss: -2.983,LR: 7.77E-05]Training epoch 75:  21%|██        | 23/112 [00:00<00:01, 53.04it/s, Epoch: 75, Batch: 24,Loss: -3.330,Avg.Loss: -2.997,LR: 7.76E-05]Training epoch 75:  21%|██▏       | 24/112 [00:00<00:01, 52.11it/s, Epoch: 75, Batch: 24,Loss: -3.330,Avg.Loss: -2.997,LR: 7.76E-05]Training epoch 75:  21%|██▏       | 24/112 [00:00<00:01, 52.11it/s, Epoch: 75, Batch: 25,Loss: -3.153,Avg.Loss: -3.003,LR: 7.76E-05]Training epoch 75:  22%|██▏       | 25/112 [00:00<00:01, 52.11it/s, Epoch: 75, Batch: 26,Loss: -3.253,Avg.Loss: -3.013,LR: 7.75E-05]Training epoch 75:  23%|██▎       | 26/112 [00:00<00:01, 52.11it/s, Epoch: 75, Batch: 27,Loss: -3.253,Avg.Loss: -3.022,LR: 7.75E-05]Training epoch 75:  24%|██▍       | 27/112 [00:00<00:01, 52.11it/s, Epoch: 75, Batch: 28,Loss: -3.276,Avg.Loss: -3.031,LR: 7.74E-05]Training epoch 75:  25%|██▌       | 28/112 [00:00<00:01, 52.11it/s, Epoch: 75, Batch: 29,Loss: -2.824,Avg.Loss: -3.024,LR: 7.74E-05]Training epoch 75:  26%|██▌       | 29/112 [00:00<00:01, 52.11it/s, Epoch: 75, Batch: 30,Loss: -2.903,Avg.Loss: -3.020,LR: 7.73E-05]Training epoch 75:  27%|██▋       | 30/112 [00:00<00:01, 52.28it/s, Epoch: 75, Batch: 30,Loss: -2.903,Avg.Loss: -3.020,LR: 7.73E-05]Training epoch 75:  27%|██▋       | 30/112 [00:00<00:01, 52.28it/s, Epoch: 75, Batch: 31,Loss: -3.386,Avg.Loss: -3.032,LR: 7.73E-05]Training epoch 75:  28%|██▊       | 31/112 [00:00<00:01, 52.28it/s, Epoch: 75, Batch: 32,Loss: -3.372,Avg.Loss: -3.042,LR: 7.72E-05]Training epoch 75:  29%|██▊       | 32/112 [00:00<00:01, 52.28it/s, Epoch: 75, Batch: 33,Loss: -2.670,Avg.Loss: -3.031,LR: 7.72E-05]Training epoch 75:  29%|██▉       | 33/112 [00:00<00:01, 52.28it/s, Epoch: 75, Batch: 34,Loss: -2.954,Avg.Loss: -3.029,LR: 7.71E-05]Training epoch 75:  30%|███       | 34/112 [00:00<00:01, 52.28it/s, Epoch: 75, Batch: 35,Loss: -3.690,Avg.Loss: -3.048,LR: 7.71E-05]Training epoch 75:  31%|███▏      | 35/112 [00:00<00:01, 52.28it/s, Epoch: 75, Batch: 36,Loss: -3.344,Avg.Loss: -3.056,LR: 7.70E-05]Training epoch 75:  32%|███▏      | 36/112 [00:00<00:01, 52.78it/s, Epoch: 75, Batch: 36,Loss: -3.344,Avg.Loss: -3.056,LR: 7.70E-05]Training epoch 75:  32%|███▏      | 36/112 [00:00<00:01, 52.78it/s, Epoch: 75, Batch: 37,Loss: -2.922,Avg.Loss: -3.052,LR: 7.70E-05]Training epoch 75:  33%|███▎      | 37/112 [00:00<00:01, 52.78it/s, Epoch: 75, Batch: 38,Loss: -3.066,Avg.Loss: -3.053,LR: 7.69E-05]Training epoch 75:  34%|███▍      | 38/112 [00:00<00:01, 52.78it/s, Epoch: 75, Batch: 39,Loss: -3.666,Avg.Loss: -3.068,LR: 7.69E-05]Training epoch 75:  35%|███▍      | 39/112 [00:00<00:01, 52.78it/s, Epoch: 75, Batch: 40,Loss: -3.585,Avg.Loss: -3.081,LR: 7.68E-05]Training epoch 75:  36%|███▌      | 40/112 [00:00<00:01, 52.78it/s, Epoch: 75, Batch: 41,Loss: -2.531,Avg.Loss: -3.068,LR: 7.68E-05]Training epoch 75:  37%|███▋      | 41/112 [00:00<00:01, 52.78it/s, Epoch: 75, Batch: 42,Loss: -3.281,Avg.Loss: -3.073,LR: 7.67E-05]Training epoch 75:  38%|███▊      | 42/112 [00:00<00:01, 52.94it/s, Epoch: 75, Batch: 42,Loss: -3.281,Avg.Loss: -3.073,LR: 7.67E-05]Training epoch 75:  38%|███▊      | 42/112 [00:00<00:01, 52.94it/s, Epoch: 75, Batch: 43,Loss: -3.368,Avg.Loss: -3.080,LR: 7.67E-05]Training epoch 75:  38%|███▊      | 43/112 [00:00<00:01, 52.94it/s, Epoch: 75, Batch: 44,Loss: -3.150,Avg.Loss: -3.081,LR: 7.66E-05]Training epoch 75:  39%|███▉      | 44/112 [00:00<00:01, 52.94it/s, Epoch: 75, Batch: 45,Loss: -3.037,Avg.Loss: -3.080,LR: 7.66E-05]Training epoch 75:  40%|████      | 45/112 [00:00<00:01, 52.94it/s, Epoch: 75, Batch: 46,Loss: -3.001,Avg.Loss: -3.079,LR: 7.65E-05]Training epoch 75:  41%|████      | 46/112 [00:00<00:01, 52.94it/s, Epoch: 75, Batch: 47,Loss: -3.181,Avg.Loss: -3.081,LR: 7.65E-05]Training epoch 75:  42%|████▏     | 47/112 [00:00<00:01, 52.94it/s, Epoch: 75, Batch: 48,Loss: -3.452,Avg.Loss: -3.089,LR: 7.64E-05]Training epoch 75:  43%|████▎     | 48/112 [00:00<00:01, 53.28it/s, Epoch: 75, Batch: 48,Loss: -3.452,Avg.Loss: -3.089,LR: 7.64E-05]Training epoch 75:  43%|████▎     | 48/112 [00:00<00:01, 53.28it/s, Epoch: 75, Batch: 49,Loss: -2.528,Avg.Loss: -3.077,LR: 7.64E-05]Training epoch 75:  44%|████▍     | 49/112 [00:00<00:01, 53.28it/s, Epoch: 75, Batch: 50,Loss: -2.781,Avg.Loss: -3.071,LR: 7.63E-05]Training epoch 75:  45%|████▍     | 50/112 [00:00<00:01, 53.28it/s, Epoch: 75, Batch: 51,Loss: -3.300,Avg.Loss: -3.076,LR: 7.63E-05]Training epoch 75:  46%|████▌     | 51/112 [00:00<00:01, 53.28it/s, Epoch: 75, Batch: 52,Loss: -3.266,Avg.Loss: -3.079,LR: 7.62E-05]Training epoch 75:  46%|████▋     | 52/112 [00:00<00:01, 53.28it/s, Epoch: 75, Batch: 53,Loss: -2.907,Avg.Loss: -3.076,LR: 7.62E-05]Training epoch 75:  47%|████▋     | 53/112 [00:01<00:01, 53.28it/s, Epoch: 75, Batch: 54,Loss: -2.876,Avg.Loss: -3.072,LR: 7.61E-05]Training epoch 75:  48%|████▊     | 54/112 [00:01<00:01, 53.40it/s, Epoch: 75, Batch: 54,Loss: -2.876,Avg.Loss: -3.072,LR: 7.61E-05]Training epoch 75:  48%|████▊     | 54/112 [00:01<00:01, 53.40it/s, Epoch: 75, Batch: 55,Loss: -3.628,Avg.Loss: -3.082,LR: 7.61E-05]Training epoch 75:  49%|████▉     | 55/112 [00:01<00:01, 53.40it/s, Epoch: 75, Batch: 56,Loss: -3.442,Avg.Loss: -3.089,LR: 7.60E-05]Training epoch 75:  50%|█████     | 56/112 [00:01<00:01, 53.40it/s, Epoch: 75, Batch: 57,Loss: -2.577,Avg.Loss: -3.080,LR: 7.60E-05]Training epoch 75:  51%|█████     | 57/112 [00:01<00:01, 53.40it/s, Epoch: 75, Batch: 58,Loss: -3.137,Avg.Loss: -3.081,LR: 7.59E-05]Training epoch 75:  52%|█████▏    | 58/112 [00:01<00:01, 53.40it/s, Epoch: 75, Batch: 59,Loss: -3.285,Avg.Loss: -3.084,LR: 7.59E-05]Training epoch 75:  53%|█████▎    | 59/112 [00:01<00:00, 53.40it/s, Epoch: 75, Batch: 60,Loss: -3.226,Avg.Loss: -3.087,LR: 7.58E-05]Training epoch 75:  54%|█████▎    | 60/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 60,Loss: -3.226,Avg.Loss: -3.087,LR: 7.58E-05]Training epoch 75:  54%|█████▎    | 60/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 61,Loss: -2.790,Avg.Loss: -3.082,LR: 7.58E-05]Training epoch 75:  54%|█████▍    | 61/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 62,Loss: -3.454,Avg.Loss: -3.088,LR: 7.57E-05]Training epoch 75:  55%|█████▌    | 62/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 63,Loss: -3.173,Avg.Loss: -3.089,LR: 7.57E-05]Training epoch 75:  56%|█████▋    | 63/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 64,Loss: -3.055,Avg.Loss: -3.089,LR: 7.56E-05]Training epoch 75:  57%|█████▋    | 64/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 65,Loss: -2.904,Avg.Loss: -3.086,LR: 7.56E-05]Training epoch 75:  58%|█████▊    | 65/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 66,Loss: -2.964,Avg.Loss: -3.084,LR: 7.55E-05]Training epoch 75:  59%|█████▉    | 66/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 66,Loss: -2.964,Avg.Loss: -3.084,LR: 7.55E-05]Training epoch 75:  59%|█████▉    | 66/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 67,Loss: -3.221,Avg.Loss: -3.086,LR: 7.55E-05]Training epoch 75:  60%|█████▉    | 67/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 68,Loss: -3.241,Avg.Loss: -3.088,LR: 7.54E-05]Training epoch 75:  61%|██████    | 68/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 69,Loss: -2.665,Avg.Loss: -3.082,LR: 7.54E-05]Training epoch 75:  62%|██████▏   | 69/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 70,Loss: -3.244,Avg.Loss: -3.084,LR: 7.53E-05]Training epoch 75:  62%|██████▎   | 70/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 71,Loss: -3.341,Avg.Loss: -3.088,LR: 7.53E-05]Training epoch 75:  63%|██████▎   | 71/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 72,Loss: -3.170,Avg.Loss: -3.089,LR: 7.52E-05]Training epoch 75:  64%|██████▍   | 72/112 [00:01<00:00, 53.64it/s, Epoch: 75, Batch: 72,Loss: -3.170,Avg.Loss: -3.089,LR: 7.52E-05]Training epoch 75:  64%|██████▍   | 72/112 [00:01<00:00, 53.64it/s, Epoch: 75, Batch: 73,Loss: -3.335,Avg.Loss: -3.093,LR: 7.52E-05]Training epoch 75:  65%|██████▌   | 73/112 [00:01<00:00, 53.64it/s, Epoch: 75, Batch: 74,Loss: -2.863,Avg.Loss: -3.089,LR: 7.51E-05]Training epoch 75:  66%|██████▌   | 74/112 [00:01<00:00, 53.64it/s, Epoch: 75, Batch: 75,Loss: -3.412,Avg.Loss: -3.094,LR: 7.51E-05]Training epoch 75:  67%|██████▋   | 75/112 [00:01<00:00, 53.64it/s, Epoch: 75, Batch: 76,Loss: -3.239,Avg.Loss: -3.096,LR: 7.50E-05]Training epoch 75:  68%|██████▊   | 76/112 [00:01<00:00, 53.64it/s, Epoch: 75, Batch: 77,Loss: -2.948,Avg.Loss: -3.094,LR: 7.50E-05]Training epoch 75:  69%|██████▉   | 77/112 [00:01<00:00, 53.64it/s, Epoch: 75, Batch: 78,Loss: -2.883,Avg.Loss: -3.091,LR: 7.49E-05]Training epoch 75:  70%|██████▉   | 78/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 78,Loss: -2.883,Avg.Loss: -3.091,LR: 7.49E-05]Training epoch 75:  70%|██████▉   | 78/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 79,Loss: -3.222,Avg.Loss: -3.093,LR: 7.49E-05]Training epoch 75:  71%|███████   | 79/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 80,Loss: -3.011,Avg.Loss: -3.092,LR: 7.48E-05]Training epoch 75:  71%|███████▏  | 80/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 81,Loss: -2.608,Avg.Loss: -3.086,LR: 7.48E-05]Training epoch 75:  72%|███████▏  | 81/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 82,Loss: -2.940,Avg.Loss: -3.084,LR: 7.47E-05]Training epoch 75:  73%|███████▎  | 82/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 83,Loss: -3.211,Avg.Loss: -3.085,LR: 7.47E-05]Training epoch 75:  74%|███████▍  | 83/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 84,Loss: -3.368,Avg.Loss: -3.089,LR: 7.46E-05]Training epoch 75:  75%|███████▌  | 84/112 [00:01<00:00, 53.63it/s, Epoch: 75, Batch: 84,Loss: -3.368,Avg.Loss: -3.089,LR: 7.46E-05]Training epoch 75:  75%|███████▌  | 84/112 [00:01<00:00, 53.63it/s, Epoch: 75, Batch: 85,Loss: -2.933,Avg.Loss: -3.087,LR: 7.46E-05]Training epoch 75:  76%|███████▌  | 85/112 [00:01<00:00, 53.63it/s, Epoch: 75, Batch: 86,Loss: -2.845,Avg.Loss: -3.084,LR: 7.45E-05]Training epoch 75:  77%|███████▋  | 86/112 [00:01<00:00, 53.63it/s, Epoch: 75, Batch: 87,Loss: -3.435,Avg.Loss: -3.088,LR: 7.45E-05]Training epoch 75:  78%|███████▊  | 87/112 [00:01<00:00, 53.63it/s, Epoch: 75, Batch: 88,Loss: -2.841,Avg.Loss: -3.085,LR: 7.44E-05]Training epoch 75:  79%|███████▊  | 88/112 [00:01<00:00, 53.63it/s, Epoch: 75, Batch: 89,Loss: -2.788,Avg.Loss: -3.082,LR: 7.44E-05]Training epoch 75:  79%|███████▉  | 89/112 [00:01<00:00, 53.63it/s, Epoch: 75, Batch: 90,Loss: -2.864,Avg.Loss: -3.080,LR: 7.43E-05]Training epoch 75:  80%|████████  | 90/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 90,Loss: -2.864,Avg.Loss: -3.080,LR: 7.43E-05]Training epoch 75:  80%|████████  | 90/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 91,Loss: -3.404,Avg.Loss: -3.083,LR: 7.43E-05]Training epoch 75:  81%|████████▏ | 91/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 92,Loss: -3.489,Avg.Loss: -3.088,LR: 7.42E-05]Training epoch 75:  82%|████████▏ | 92/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 93,Loss: -3.076,Avg.Loss: -3.088,LR: 7.42E-05]Training epoch 75:  83%|████████▎ | 93/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 94,Loss: -3.014,Avg.Loss: -3.087,LR: 7.41E-05]Training epoch 75:  84%|████████▍ | 94/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 95,Loss: -3.221,Avg.Loss: -3.088,LR: 7.41E-05]Training epoch 75:  85%|████████▍ | 95/112 [00:01<00:00, 53.61it/s, Epoch: 75, Batch: 96,Loss: -3.337,Avg.Loss: -3.091,LR: 7.40E-05]Training epoch 75:  86%|████████▌ | 96/112 [00:01<00:00, 53.71it/s, Epoch: 75, Batch: 96,Loss: -3.337,Avg.Loss: -3.091,LR: 7.40E-05]Training epoch 75:  86%|████████▌ | 96/112 [00:01<00:00, 53.71it/s, Epoch: 75, Batch: 97,Loss: -2.569,Avg.Loss: -3.085,LR: 7.40E-05]Training epoch 75:  87%|████████▋ | 97/112 [00:01<00:00, 53.71it/s, Epoch: 75, Batch: 98,Loss: -2.779,Avg.Loss: -3.082,LR: 7.39E-05]Training epoch 75:  88%|████████▊ | 98/112 [00:01<00:00, 53.71it/s, Epoch: 75, Batch: 99,Loss: -3.402,Avg.Loss: -3.085,LR: 7.39E-05]Training epoch 75:  88%|████████▊ | 99/112 [00:01<00:00, 53.71it/s, Epoch: 75, Batch: 100,Loss: -3.265,Avg.Loss: -3.087,LR: 7.38E-05]Training epoch 75:  89%|████████▉ | 100/112 [00:01<00:00, 53.71it/s, Epoch: 75, Batch: 101,Loss: -2.945,Avg.Loss: -3.086,LR: 7.38E-05]Training epoch 75:  90%|█████████ | 101/112 [00:01<00:00, 53.71it/s, Epoch: 75, Batch: 102,Loss: -3.012,Avg.Loss: -3.085,LR: 7.37E-05]Training epoch 75:  91%|█████████ | 102/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 102,Loss: -3.012,Avg.Loss: -3.085,LR: 7.37E-05]Training epoch 75:  91%|█████████ | 102/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 103,Loss: -3.389,Avg.Loss: -3.088,LR: 7.37E-05]Training epoch 75:  92%|█████████▏| 103/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 104,Loss: -3.516,Avg.Loss: -3.092,LR: 7.36E-05]Training epoch 75:  93%|█████████▎| 104/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 105,Loss: -3.172,Avg.Loss: -3.093,LR: 7.36E-05]Training epoch 75:  94%|█████████▍| 105/112 [00:01<00:00, 53.59it/s, Epoch: 75, Batch: 106,Loss: -3.106,Avg.Loss: -3.093,LR: 7.35E-05]Training epoch 75:  95%|█████████▍| 106/112 [00:02<00:00, 53.59it/s, Epoch: 75, Batch: 107,Loss: -3.719,Avg.Loss: -3.099,LR: 7.35E-05]Training epoch 75:  96%|█████████▌| 107/112 [00:02<00:00, 53.59it/s, Epoch: 75, Batch: 108,Loss: -3.304,Avg.Loss: -3.101,LR: 7.34E-05]Training epoch 75:  96%|█████████▋| 108/112 [00:02<00:00, 53.52it/s, Epoch: 75, Batch: 108,Loss: -3.304,Avg.Loss: -3.101,LR: 7.34E-05]Training epoch 75:  96%|█████████▋| 108/112 [00:02<00:00, 53.52it/s, Epoch: 75, Batch: 109,Loss: -2.832,Avg.Loss: -3.098,LR: 7.34E-05]Training epoch 75:  97%|█████████▋| 109/112 [00:02<00:00, 53.52it/s, Epoch: 75, Batch: 110,Loss: -2.594,Avg.Loss: -3.094,LR: 7.33E-05]Training epoch 75:  98%|█████████▊| 110/112 [00:02<00:00, 53.52it/s, Epoch: 75, Batch: 111,Loss: -3.399,Avg.Loss: -3.097,LR: 7.33E-05]Training epoch 75:  99%|█████████▉| 111/112 [00:02<00:00, 53.52it/s, Epoch: 75, Batch: 112,Loss: -2.039,Avg.Loss: -3.087,LR: 7.32E-05]Training epoch 75: 100%|██████████| 112/112 [00:02<00:00, 53.26it/s, Epoch: 75, Batch: 112,Loss: -2.039,Avg.Loss: -3.087,LR: 7.32E-05]
Training epoch 76:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 76:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 76, Batch: 1,Loss: -1.163,Avg.Loss: -1.163,LR: 7.32E-05]Training epoch 76:   1%|          | 1/112 [00:00<00:03, 29.16it/s, Epoch: 76, Batch: 2,Loss: 0.719,Avg.Loss: -0.222,LR: 7.31E-05]Training epoch 76:   2%|▏         | 2/112 [00:00<00:02, 38.27it/s, Epoch: 76, Batch: 3,Loss: 1.265,Avg.Loss: 0.274,LR: 7.31E-05] Training epoch 76:   3%|▎         | 3/112 [00:00<00:02, 45.48it/s, Epoch: 76, Batch: 4,Loss: 0.408,Avg.Loss: 0.307,LR: 7.30E-05]Training epoch 76:   4%|▎         | 4/112 [00:00<00:02, 47.88it/s, Epoch: 76, Batch: 5,Loss: -1.486,Avg.Loss: -0.051,LR: 7.30E-05]Training epoch 76:   4%|▍         | 5/112 [00:00<00:02, 49.47it/s, Epoch: 76, Batch: 6,Loss: -2.643,Avg.Loss: -0.483,LR: 7.29E-05]Training epoch 76:   5%|▌         | 6/112 [00:00<00:01, 59.29it/s, Epoch: 76, Batch: 6,Loss: -2.643,Avg.Loss: -0.483,LR: 7.29E-05]Training epoch 76:   5%|▌         | 6/112 [00:00<00:01, 59.29it/s, Epoch: 76, Batch: 7,Loss: -2.922,Avg.Loss: -0.832,LR: 7.29E-05]Training epoch 76:   6%|▋         | 7/112 [00:00<00:01, 59.29it/s, Epoch: 76, Batch: 8,Loss: -1.882,Avg.Loss: -0.963,LR: 7.28E-05]Training epoch 76:   7%|▋         | 8/112 [00:00<00:01, 59.29it/s, Epoch: 76, Batch: 9,Loss: -0.584,Avg.Loss: -0.921,LR: 7.28E-05]Training epoch 76:   8%|▊         | 9/112 [00:00<00:01, 59.29it/s, Epoch: 76, Batch: 10,Loss: -1.911,Avg.Loss: -1.020,LR: 7.27E-05]Training epoch 76:   9%|▉         | 10/112 [00:00<00:01, 59.29it/s, Epoch: 76, Batch: 11,Loss: -2.098,Avg.Loss: -1.118,LR: 7.27E-05]Training epoch 76:  10%|▉         | 11/112 [00:00<00:01, 59.29it/s, Epoch: 76, Batch: 12,Loss: -3.194,Avg.Loss: -1.291,LR: 7.26E-05]Training epoch 76:  11%|█         | 12/112 [00:00<00:01, 55.35it/s, Epoch: 76, Batch: 12,Loss: -3.194,Avg.Loss: -1.291,LR: 7.26E-05]Training epoch 76:  11%|█         | 12/112 [00:00<00:01, 55.35it/s, Epoch: 76, Batch: 13,Loss: -2.649,Avg.Loss: -1.396,LR: 7.26E-05]Training epoch 76:  12%|█▏        | 13/112 [00:00<00:01, 55.35it/s, Epoch: 76, Batch: 14,Loss: -1.313,Avg.Loss: -1.390,LR: 7.25E-05]Training epoch 76:  12%|█▎        | 14/112 [00:00<00:01, 55.35it/s, Epoch: 76, Batch: 15,Loss: -1.362,Avg.Loss: -1.388,LR: 7.25E-05]Training epoch 76:  13%|█▎        | 15/112 [00:00<00:01, 55.35it/s, Epoch: 76, Batch: 16,Loss: -2.007,Avg.Loss: -1.426,LR: 7.24E-05]Training epoch 76:  14%|█▍        | 16/112 [00:00<00:01, 55.35it/s, Epoch: 76, Batch: 17,Loss: -2.395,Avg.Loss: -1.483,LR: 7.24E-05]Training epoch 76:  15%|█▌        | 17/112 [00:00<00:01, 55.35it/s, Epoch: 76, Batch: 18,Loss: -3.648,Avg.Loss: -1.604,LR: 7.23E-05]Training epoch 76:  16%|█▌        | 18/112 [00:00<00:01, 54.27it/s, Epoch: 76, Batch: 18,Loss: -3.648,Avg.Loss: -1.604,LR: 7.23E-05]Training epoch 76:  16%|█▌        | 18/112 [00:00<00:01, 54.27it/s, Epoch: 76, Batch: 19,Loss: -2.563,Avg.Loss: -1.654,LR: 7.23E-05]Training epoch 76:  17%|█▋        | 19/112 [00:00<00:01, 54.27it/s, Epoch: 76, Batch: 20,Loss: -1.417,Avg.Loss: -1.642,LR: 7.22E-05]Training epoch 76:  18%|█▊        | 20/112 [00:00<00:01, 54.27it/s, Epoch: 76, Batch: 21,Loss: -0.227,Avg.Loss: -1.575,LR: 7.22E-05]Training epoch 76:  19%|█▉        | 21/112 [00:00<00:01, 54.27it/s, Epoch: 76, Batch: 22,Loss: -1.121,Avg.Loss: -1.554,LR: 7.21E-05]Training epoch 76:  20%|█▉        | 22/112 [00:00<00:01, 54.27it/s, Epoch: 76, Batch: 23,Loss: -2.152,Avg.Loss: -1.580,LR: 7.21E-05]Training epoch 76:  21%|██        | 23/112 [00:00<00:01, 54.27it/s, Epoch: 76, Batch: 24,Loss: -3.059,Avg.Loss: -1.642,LR: 7.20E-05]Training epoch 76:  21%|██▏       | 24/112 [00:00<00:01, 53.56it/s, Epoch: 76, Batch: 24,Loss: -3.059,Avg.Loss: -1.642,LR: 7.20E-05]Training epoch 76:  21%|██▏       | 24/112 [00:00<00:01, 53.56it/s, Epoch: 76, Batch: 25,Loss: -2.824,Avg.Loss: -1.689,LR: 7.20E-05]Training epoch 76:  22%|██▏       | 25/112 [00:00<00:01, 53.56it/s, Epoch: 76, Batch: 26,Loss: -1.744,Avg.Loss: -1.691,LR: 7.19E-05]Training epoch 76:  23%|██▎       | 26/112 [00:00<00:01, 53.56it/s, Epoch: 76, Batch: 27,Loss: -0.967,Avg.Loss: -1.664,LR: 7.19E-05]Training epoch 76:  24%|██▍       | 27/112 [00:00<00:01, 53.56it/s, Epoch: 76, Batch: 28,Loss: -1.323,Avg.Loss: -1.652,LR: 7.18E-05]Training epoch 76:  25%|██▌       | 28/112 [00:00<00:01, 53.56it/s, Epoch: 76, Batch: 29,Loss: -2.153,Avg.Loss: -1.670,LR: 7.18E-05]Training epoch 76:  26%|██▌       | 29/112 [00:00<00:01, 53.56it/s, Epoch: 76, Batch: 30,Loss: -3.288,Avg.Loss: -1.723,LR: 7.17E-05]Training epoch 76:  27%|██▋       | 30/112 [00:00<00:01, 53.08it/s, Epoch: 76, Batch: 30,Loss: -3.288,Avg.Loss: -1.723,LR: 7.17E-05]Training epoch 76:  27%|██▋       | 30/112 [00:00<00:01, 53.08it/s, Epoch: 76, Batch: 31,Loss: -2.355,Avg.Loss: -1.744,LR: 7.17E-05]Training epoch 76:  28%|██▊       | 31/112 [00:00<00:01, 53.08it/s, Epoch: 76, Batch: 32,Loss: -1.080,Avg.Loss: -1.723,LR: 7.16E-05]Training epoch 76:  29%|██▊       | 32/112 [00:00<00:01, 53.08it/s, Epoch: 76, Batch: 33,Loss: -1.070,Avg.Loss: -1.703,LR: 7.16E-05]Training epoch 76:  29%|██▉       | 33/112 [00:00<00:01, 53.08it/s, Epoch: 76, Batch: 34,Loss: -1.950,Avg.Loss: -1.711,LR: 7.15E-05]Training epoch 76:  30%|███       | 34/112 [00:00<00:01, 53.08it/s, Epoch: 76, Batch: 35,Loss: -2.391,Avg.Loss: -1.730,LR: 7.15E-05]Training epoch 76:  31%|███▏      | 35/112 [00:00<00:01, 53.08it/s, Epoch: 76, Batch: 36,Loss: -3.431,Avg.Loss: -1.777,LR: 7.14E-05]Training epoch 76:  32%|███▏      | 36/112 [00:00<00:01, 53.54it/s, Epoch: 76, Batch: 36,Loss: -3.431,Avg.Loss: -1.777,LR: 7.14E-05]Training epoch 76:  32%|███▏      | 36/112 [00:00<00:01, 53.54it/s, Epoch: 76, Batch: 37,Loss: -2.631,Avg.Loss: -1.800,LR: 7.14E-05]Training epoch 76:  33%|███▎      | 37/112 [00:00<00:01, 53.54it/s, Epoch: 76, Batch: 38,Loss: -1.501,Avg.Loss: -1.792,LR: 7.13E-05]Training epoch 76:  34%|███▍      | 38/112 [00:00<00:01, 53.54it/s, Epoch: 76, Batch: 39,Loss: -1.172,Avg.Loss: -1.777,LR: 7.13E-05]Training epoch 76:  35%|███▍      | 39/112 [00:00<00:01, 53.54it/s, Epoch: 76, Batch: 40,Loss: -1.562,Avg.Loss: -1.771,LR: 7.13E-05]Training epoch 76:  36%|███▌      | 40/112 [00:00<00:01, 53.54it/s, Epoch: 76, Batch: 41,Loss: -2.590,Avg.Loss: -1.791,LR: 7.12E-05]Training epoch 76:  37%|███▋      | 41/112 [00:00<00:01, 53.54it/s, Epoch: 76, Batch: 42,Loss: -3.762,Avg.Loss: -1.838,LR: 7.12E-05]Training epoch 76:  38%|███▊      | 42/112 [00:00<00:01, 53.50it/s, Epoch: 76, Batch: 42,Loss: -3.762,Avg.Loss: -1.838,LR: 7.12E-05]Training epoch 76:  38%|███▊      | 42/112 [00:00<00:01, 53.50it/s, Epoch: 76, Batch: 43,Loss: -2.454,Avg.Loss: -1.852,LR: 7.11E-05]Training epoch 76:  38%|███▊      | 43/112 [00:00<00:01, 53.50it/s, Epoch: 76, Batch: 44,Loss: -1.267,Avg.Loss: -1.839,LR: 7.11E-05]Training epoch 76:  39%|███▉      | 44/112 [00:00<00:01, 53.50it/s, Epoch: 76, Batch: 45,Loss: -1.365,Avg.Loss: -1.829,LR: 7.10E-05]Training epoch 76:  40%|████      | 45/112 [00:00<00:01, 53.50it/s, Epoch: 76, Batch: 46,Loss: -1.527,Avg.Loss: -1.822,LR: 7.10E-05]Training epoch 76:  41%|████      | 46/112 [00:00<00:01, 53.50it/s, Epoch: 76, Batch: 47,Loss: -2.599,Avg.Loss: -1.838,LR: 7.09E-05]Training epoch 76:  42%|████▏     | 47/112 [00:00<00:01, 53.50it/s, Epoch: 76, Batch: 48,Loss: -3.280,Avg.Loss: -1.869,LR: 7.09E-05]Training epoch 76:  43%|████▎     | 48/112 [00:00<00:01, 53.59it/s, Epoch: 76, Batch: 48,Loss: -3.280,Avg.Loss: -1.869,LR: 7.09E-05]Training epoch 76:  43%|████▎     | 48/112 [00:00<00:01, 53.59it/s, Epoch: 76, Batch: 49,Loss: -2.607,Avg.Loss: -1.884,LR: 7.08E-05]Training epoch 76:  44%|████▍     | 49/112 [00:00<00:01, 53.59it/s, Epoch: 76, Batch: 50,Loss: -1.437,Avg.Loss: -1.875,LR: 7.08E-05]Training epoch 76:  45%|████▍     | 50/112 [00:00<00:01, 53.59it/s, Epoch: 76, Batch: 51,Loss: -1.433,Avg.Loss: -1.866,LR: 7.07E-05]Training epoch 76:  46%|████▌     | 51/112 [00:00<00:01, 53.59it/s, Epoch: 76, Batch: 52,Loss: -2.065,Avg.Loss: -1.870,LR: 7.07E-05]Training epoch 76:  46%|████▋     | 52/112 [00:00<00:01, 53.59it/s, Epoch: 76, Batch: 53,Loss: -2.963,Avg.Loss: -1.890,LR: 7.06E-05]Training epoch 76:  47%|████▋     | 53/112 [00:01<00:01, 53.59it/s, Epoch: 76, Batch: 54,Loss: -3.427,Avg.Loss: -1.919,LR: 7.06E-05]Training epoch 76:  48%|████▊     | 54/112 [00:01<00:01, 53.89it/s, Epoch: 76, Batch: 54,Loss: -3.427,Avg.Loss: -1.919,LR: 7.06E-05]Training epoch 76:  48%|████▊     | 54/112 [00:01<00:01, 53.89it/s, Epoch: 76, Batch: 55,Loss: -3.168,Avg.Loss: -1.942,LR: 7.05E-05]Training epoch 76:  49%|████▉     | 55/112 [00:01<00:01, 53.89it/s, Epoch: 76, Batch: 56,Loss: -3.631,Avg.Loss: -1.972,LR: 7.05E-05]Training epoch 76:  50%|█████     | 56/112 [00:01<00:01, 53.89it/s, Epoch: 76, Batch: 57,Loss: -3.335,Avg.Loss: -1.996,LR: 7.04E-05]Training epoch 76:  51%|█████     | 57/112 [00:01<00:01, 53.89it/s, Epoch: 76, Batch: 58,Loss: -3.173,Avg.Loss: -2.016,LR: 7.04E-05]Training epoch 76:  52%|█████▏    | 58/112 [00:01<00:01, 53.89it/s, Epoch: 76, Batch: 59,Loss: -2.967,Avg.Loss: -2.032,LR: 7.03E-05]Training epoch 76:  53%|█████▎    | 59/112 [00:01<00:00, 53.89it/s, Epoch: 76, Batch: 60,Loss: -3.308,Avg.Loss: -2.053,LR: 7.03E-05]Training epoch 76:  54%|█████▎    | 60/112 [00:01<00:00, 53.65it/s, Epoch: 76, Batch: 60,Loss: -3.308,Avg.Loss: -2.053,LR: 7.03E-05]Training epoch 76:  54%|█████▎    | 60/112 [00:01<00:00, 53.65it/s, Epoch: 76, Batch: 61,Loss: -3.503,Avg.Loss: -2.077,LR: 7.02E-05]Training epoch 76:  54%|█████▍    | 61/112 [00:01<00:00, 53.65it/s, Epoch: 76, Batch: 62,Loss: -3.167,Avg.Loss: -2.095,LR: 7.02E-05]Training epoch 76:  55%|█████▌    | 62/112 [00:01<00:00, 53.65it/s, Epoch: 76, Batch: 63,Loss: -3.647,Avg.Loss: -2.119,LR: 7.01E-05]Training epoch 76:  56%|█████▋    | 63/112 [00:01<00:00, 53.65it/s, Epoch: 76, Batch: 64,Loss: -3.156,Avg.Loss: -2.136,LR: 7.01E-05]Training epoch 76:  57%|█████▋    | 64/112 [00:01<00:00, 53.65it/s, Epoch: 76, Batch: 65,Loss: -3.055,Avg.Loss: -2.150,LR: 7.00E-05]Training epoch 76:  58%|█████▊    | 65/112 [00:01<00:00, 53.65it/s, Epoch: 76, Batch: 66,Loss: -3.565,Avg.Loss: -2.171,LR: 7.00E-05]Training epoch 76:  59%|█████▉    | 66/112 [00:01<00:00, 53.74it/s, Epoch: 76, Batch: 66,Loss: -3.565,Avg.Loss: -2.171,LR: 7.00E-05]Training epoch 76:  59%|█████▉    | 66/112 [00:01<00:00, 53.74it/s, Epoch: 76, Batch: 67,Loss: -2.842,Avg.Loss: -2.181,LR: 6.99E-05]Training epoch 76:  60%|█████▉    | 67/112 [00:01<00:00, 53.74it/s, Epoch: 76, Batch: 68,Loss: -3.387,Avg.Loss: -2.199,LR: 6.99E-05]Training epoch 76:  61%|██████    | 68/112 [00:01<00:00, 53.74it/s, Epoch: 76, Batch: 69,Loss: -3.051,Avg.Loss: -2.211,LR: 6.98E-05]Training epoch 76:  62%|██████▏   | 69/112 [00:01<00:00, 53.74it/s, Epoch: 76, Batch: 70,Loss: -3.287,Avg.Loss: -2.227,LR: 6.98E-05]Training epoch 76:  62%|██████▎   | 70/112 [00:01<00:00, 53.74it/s, Epoch: 76, Batch: 71,Loss: -3.325,Avg.Loss: -2.242,LR: 6.97E-05]Training epoch 76:  63%|██████▎   | 71/112 [00:01<00:00, 53.74it/s, Epoch: 76, Batch: 72,Loss: -3.564,Avg.Loss: -2.260,LR: 6.97E-05]Training epoch 76:  64%|██████▍   | 72/112 [00:01<00:00, 53.90it/s, Epoch: 76, Batch: 72,Loss: -3.564,Avg.Loss: -2.260,LR: 6.97E-05]Training epoch 76:  64%|██████▍   | 72/112 [00:01<00:00, 53.90it/s, Epoch: 76, Batch: 73,Loss: -2.952,Avg.Loss: -2.270,LR: 6.96E-05]Training epoch 76:  65%|██████▌   | 73/112 [00:01<00:00, 53.90it/s, Epoch: 76, Batch: 74,Loss: -3.074,Avg.Loss: -2.281,LR: 6.96E-05]Training epoch 76:  66%|██████▌   | 74/112 [00:01<00:00, 53.90it/s, Epoch: 76, Batch: 75,Loss: -3.582,Avg.Loss: -2.298,LR: 6.95E-05]Training epoch 76:  67%|██████▋   | 75/112 [00:01<00:00, 53.90it/s, Epoch: 76, Batch: 76,Loss: -3.358,Avg.Loss: -2.312,LR: 6.95E-05]Training epoch 76:  68%|██████▊   | 76/112 [00:01<00:00, 53.90it/s, Epoch: 76, Batch: 77,Loss: -3.182,Avg.Loss: -2.323,LR: 6.94E-05]Training epoch 76:  69%|██████▉   | 77/112 [00:01<00:00, 53.90it/s, Epoch: 76, Batch: 78,Loss: -3.369,Avg.Loss: -2.337,LR: 6.94E-05]Training epoch 76:  70%|██████▉   | 78/112 [00:01<00:00, 53.87it/s, Epoch: 76, Batch: 78,Loss: -3.369,Avg.Loss: -2.337,LR: 6.94E-05]Training epoch 76:  70%|██████▉   | 78/112 [00:01<00:00, 53.87it/s, Epoch: 76, Batch: 79,Loss: -2.864,Avg.Loss: -2.343,LR: 6.93E-05]Training epoch 76:  71%|███████   | 79/112 [00:01<00:00, 53.87it/s, Epoch: 76, Batch: 80,Loss: -3.541,Avg.Loss: -2.358,LR: 6.93E-05]Training epoch 76:  71%|███████▏  | 80/112 [00:01<00:00, 53.87it/s, Epoch: 76, Batch: 81,Loss: -3.425,Avg.Loss: -2.372,LR: 6.93E-05]Training epoch 76:  72%|███████▏  | 81/112 [00:01<00:00, 53.87it/s, Epoch: 76, Batch: 82,Loss: -3.602,Avg.Loss: -2.387,LR: 6.92E-05]Training epoch 76:  73%|███████▎  | 82/112 [00:01<00:00, 53.87it/s, Epoch: 76, Batch: 83,Loss: -3.679,Avg.Loss: -2.402,LR: 6.92E-05]Training epoch 76:  74%|███████▍  | 83/112 [00:01<00:00, 53.87it/s, Epoch: 76, Batch: 84,Loss: -3.336,Avg.Loss: -2.413,LR: 6.91E-05]Training epoch 76:  75%|███████▌  | 84/112 [00:01<00:00, 53.97it/s, Epoch: 76, Batch: 84,Loss: -3.336,Avg.Loss: -2.413,LR: 6.91E-05]Training epoch 76:  75%|███████▌  | 84/112 [00:01<00:00, 53.97it/s, Epoch: 76, Batch: 85,Loss: -3.321,Avg.Loss: -2.424,LR: 6.91E-05]Training epoch 76:  76%|███████▌  | 85/112 [00:01<00:00, 53.97it/s, Epoch: 76, Batch: 86,Loss: -3.653,Avg.Loss: -2.438,LR: 6.90E-05]Training epoch 76:  77%|███████▋  | 86/112 [00:01<00:00, 53.97it/s, Epoch: 76, Batch: 87,Loss: -3.185,Avg.Loss: -2.447,LR: 6.90E-05]Training epoch 76:  78%|███████▊  | 87/112 [00:01<00:00, 53.97it/s, Epoch: 76, Batch: 88,Loss: -3.064,Avg.Loss: -2.454,LR: 6.89E-05]Training epoch 76:  79%|███████▊  | 88/112 [00:01<00:00, 53.97it/s, Epoch: 76, Batch: 89,Loss: -3.366,Avg.Loss: -2.464,LR: 6.89E-05]Training epoch 76:  79%|███████▉  | 89/112 [00:01<00:00, 53.97it/s, Epoch: 76, Batch: 90,Loss: -3.357,Avg.Loss: -2.474,LR: 6.88E-05]Training epoch 76:  80%|████████  | 90/112 [00:01<00:00, 54.08it/s, Epoch: 76, Batch: 90,Loss: -3.357,Avg.Loss: -2.474,LR: 6.88E-05]Training epoch 76:  80%|████████  | 90/112 [00:01<00:00, 54.08it/s, Epoch: 76, Batch: 91,Loss: -3.144,Avg.Loss: -2.481,LR: 6.88E-05]Training epoch 76:  81%|████████▏ | 91/112 [00:01<00:00, 54.08it/s, Epoch: 76, Batch: 92,Loss: -3.339,Avg.Loss: -2.491,LR: 6.87E-05]Training epoch 76:  82%|████████▏ | 92/112 [00:01<00:00, 54.08it/s, Epoch: 76, Batch: 93,Loss: -3.059,Avg.Loss: -2.497,LR: 6.87E-05]Training epoch 76:  83%|████████▎ | 93/112 [00:01<00:00, 54.08it/s, Epoch: 76, Batch: 94,Loss: -3.116,Avg.Loss: -2.503,LR: 6.86E-05]Training epoch 76:  84%|████████▍ | 94/112 [00:01<00:00, 54.08it/s, Epoch: 76, Batch: 95,Loss: -3.603,Avg.Loss: -2.515,LR: 6.86E-05]Training epoch 76:  85%|████████▍ | 95/112 [00:01<00:00, 54.08it/s, Epoch: 76, Batch: 96,Loss: -3.367,Avg.Loss: -2.524,LR: 6.85E-05]Training epoch 76:  86%|████████▌ | 96/112 [00:01<00:00, 53.96it/s, Epoch: 76, Batch: 96,Loss: -3.367,Avg.Loss: -2.524,LR: 6.85E-05]Training epoch 76:  86%|████████▌ | 96/112 [00:01<00:00, 53.96it/s, Epoch: 76, Batch: 97,Loss: -3.149,Avg.Loss: -2.530,LR: 6.85E-05]Training epoch 76:  87%|████████▋ | 97/112 [00:01<00:00, 53.96it/s, Epoch: 76, Batch: 98,Loss: -3.406,Avg.Loss: -2.539,LR: 6.84E-05]Training epoch 76:  88%|████████▊ | 98/112 [00:01<00:00, 53.96it/s, Epoch: 76, Batch: 99,Loss: -3.276,Avg.Loss: -2.547,LR: 6.84E-05]Training epoch 76:  88%|████████▊ | 99/112 [00:01<00:00, 53.96it/s, Epoch: 76, Batch: 100,Loss: -3.239,Avg.Loss: -2.554,LR: 6.83E-05]Training epoch 76:  89%|████████▉ | 100/112 [00:01<00:00, 53.96it/s, Epoch: 76, Batch: 101,Loss: -3.130,Avg.Loss: -2.559,LR: 6.83E-05]Training epoch 76:  90%|█████████ | 101/112 [00:01<00:00, 53.96it/s, Epoch: 76, Batch: 102,Loss: -2.839,Avg.Loss: -2.562,LR: 6.82E-05]Training epoch 76:  91%|█████████ | 102/112 [00:01<00:00, 53.23it/s, Epoch: 76, Batch: 102,Loss: -2.839,Avg.Loss: -2.562,LR: 6.82E-05]Training epoch 76:  91%|█████████ | 102/112 [00:01<00:00, 53.23it/s, Epoch: 76, Batch: 103,Loss: -2.809,Avg.Loss: -2.564,LR: 6.82E-05]Training epoch 76:  92%|█████████▏| 103/112 [00:01<00:00, 53.23it/s, Epoch: 76, Batch: 104,Loss: -2.951,Avg.Loss: -2.568,LR: 6.81E-05]Training epoch 76:  93%|█████████▎| 104/112 [00:01<00:00, 53.23it/s, Epoch: 76, Batch: 105,Loss: -3.143,Avg.Loss: -2.574,LR: 6.81E-05]Training epoch 76:  94%|█████████▍| 105/112 [00:01<00:00, 53.23it/s, Epoch: 76, Batch: 106,Loss: -3.293,Avg.Loss: -2.580,LR: 6.80E-05]Training epoch 76:  95%|█████████▍| 106/112 [00:01<00:00, 53.23it/s, Epoch: 76, Batch: 107,Loss: -3.330,Avg.Loss: -2.587,LR: 6.80E-05]Training epoch 76:  96%|█████████▌| 107/112 [00:02<00:00, 53.23it/s, Epoch: 76, Batch: 108,Loss: -2.939,Avg.Loss: -2.591,LR: 6.79E-05]Training epoch 76:  96%|█████████▋| 108/112 [00:02<00:00, 53.49it/s, Epoch: 76, Batch: 108,Loss: -2.939,Avg.Loss: -2.591,LR: 6.79E-05]Training epoch 76:  96%|█████████▋| 108/112 [00:02<00:00, 53.49it/s, Epoch: 76, Batch: 109,Loss: -2.903,Avg.Loss: -2.594,LR: 6.79E-05]Training epoch 76:  97%|█████████▋| 109/112 [00:02<00:00, 53.49it/s, Epoch: 76, Batch: 110,Loss: -2.979,Avg.Loss: -2.597,LR: 6.79E-05]Training epoch 76:  98%|█████████▊| 110/112 [00:02<00:00, 53.49it/s, Epoch: 76, Batch: 111,Loss: -3.562,Avg.Loss: -2.606,LR: 6.78E-05]Training epoch 76:  99%|█████████▉| 111/112 [00:02<00:00, 53.49it/s, Epoch: 76, Batch: 112,Loss: -3.576,Avg.Loss: -2.614,LR: 6.78E-05]Training epoch 76: 100%|██████████| 112/112 [00:02<00:00, 53.70it/s, Epoch: 76, Batch: 112,Loss: -3.576,Avg.Loss: -2.614,LR: 6.78E-05]
Training epoch 77:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 77:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 77, Batch: 1,Loss: -3.053,Avg.Loss: -3.053,LR: 6.77E-05]Training epoch 77:   1%|          | 1/112 [00:00<00:04, 26.88it/s, Epoch: 77, Batch: 2,Loss: -3.386,Avg.Loss: -3.220,LR: 6.77E-05]Training epoch 77:   2%|▏         | 2/112 [00:00<00:02, 38.98it/s, Epoch: 77, Batch: 3,Loss: -2.684,Avg.Loss: -3.041,LR: 6.76E-05]Training epoch 77:   3%|▎         | 3/112 [00:00<00:02, 44.25it/s, Epoch: 77, Batch: 4,Loss: -2.959,Avg.Loss: -3.021,LR: 6.76E-05]Training epoch 77:   4%|▎         | 4/112 [00:00<00:02, 46.52it/s, Epoch: 77, Batch: 5,Loss: -3.042,Avg.Loss: -3.025,LR: 6.75E-05]Training epoch 77:   4%|▍         | 5/112 [00:00<00:02, 47.89it/s, Epoch: 77, Batch: 6,Loss: -3.206,Avg.Loss: -3.055,LR: 6.75E-05]Training epoch 77:   5%|▌         | 6/112 [00:00<00:01, 57.37it/s, Epoch: 77, Batch: 6,Loss: -3.206,Avg.Loss: -3.055,LR: 6.75E-05]Training epoch 77:   5%|▌         | 6/112 [00:00<00:01, 57.37it/s, Epoch: 77, Batch: 7,Loss: -3.223,Avg.Loss: -3.079,LR: 6.74E-05]Training epoch 77:   6%|▋         | 7/112 [00:00<00:01, 57.37it/s, Epoch: 77, Batch: 8,Loss: -3.568,Avg.Loss: -3.140,LR: 6.74E-05]Training epoch 77:   7%|▋         | 8/112 [00:00<00:01, 57.37it/s, Epoch: 77, Batch: 9,Loss: -3.157,Avg.Loss: -3.142,LR: 6.73E-05]Training epoch 77:   8%|▊         | 9/112 [00:00<00:01, 57.37it/s, Epoch: 77, Batch: 10,Loss: -3.164,Avg.Loss: -3.144,LR: 6.73E-05]Training epoch 77:   9%|▉         | 10/112 [00:00<00:01, 57.37it/s, Epoch: 77, Batch: 11,Loss: -3.066,Avg.Loss: -3.137,LR: 6.72E-05]Training epoch 77:  10%|▉         | 11/112 [00:00<00:01, 57.37it/s, Epoch: 77, Batch: 12,Loss: -3.445,Avg.Loss: -3.163,LR: 6.72E-05]Training epoch 77:  11%|█         | 12/112 [00:00<00:01, 54.85it/s, Epoch: 77, Batch: 12,Loss: -3.445,Avg.Loss: -3.163,LR: 6.72E-05]Training epoch 77:  11%|█         | 12/112 [00:00<00:01, 54.85it/s, Epoch: 77, Batch: 13,Loss: -3.285,Avg.Loss: -3.172,LR: 6.71E-05]Training epoch 77:  12%|█▏        | 13/112 [00:00<00:01, 54.85it/s, Epoch: 77, Batch: 14,Loss: -3.268,Avg.Loss: -3.179,LR: 6.71E-05]Training epoch 77:  12%|█▎        | 14/112 [00:00<00:01, 54.85it/s, Epoch: 77, Batch: 15,Loss: -3.602,Avg.Loss: -3.207,LR: 6.70E-05]Training epoch 77:  13%|█▎        | 15/112 [00:00<00:01, 54.85it/s, Epoch: 77, Batch: 16,Loss: -3.256,Avg.Loss: -3.210,LR: 6.70E-05]Training epoch 77:  14%|█▍        | 16/112 [00:00<00:01, 54.85it/s, Epoch: 77, Batch: 17,Loss: -3.365,Avg.Loss: -3.219,LR: 6.69E-05]Training epoch 77:  15%|█▌        | 17/112 [00:00<00:01, 54.85it/s, Epoch: 77, Batch: 18,Loss: -3.449,Avg.Loss: -3.232,LR: 6.69E-05]Training epoch 77:  16%|█▌        | 18/112 [00:00<00:01, 54.46it/s, Epoch: 77, Batch: 18,Loss: -3.449,Avg.Loss: -3.232,LR: 6.69E-05]Training epoch 77:  16%|█▌        | 18/112 [00:00<00:01, 54.46it/s, Epoch: 77, Batch: 19,Loss: -3.086,Avg.Loss: -3.224,LR: 6.68E-05]Training epoch 77:  17%|█▋        | 19/112 [00:00<00:01, 54.46it/s, Epoch: 77, Batch: 20,Loss: -2.739,Avg.Loss: -3.200,LR: 6.68E-05]Training epoch 77:  18%|█▊        | 20/112 [00:00<00:01, 54.46it/s, Epoch: 77, Batch: 21,Loss: -3.304,Avg.Loss: -3.205,LR: 6.68E-05]Training epoch 77:  19%|█▉        | 21/112 [00:00<00:01, 54.46it/s, Epoch: 77, Batch: 22,Loss: -3.317,Avg.Loss: -3.210,LR: 6.67E-05]Training epoch 77:  20%|█▉        | 22/112 [00:00<00:01, 54.46it/s, Epoch: 77, Batch: 23,Loss: -2.535,Avg.Loss: -3.181,LR: 6.67E-05]Training epoch 77:  21%|██        | 23/112 [00:00<00:01, 54.46it/s, Epoch: 77, Batch: 24,Loss: -2.546,Avg.Loss: -3.154,LR: 6.66E-05]Training epoch 77:  21%|██▏       | 24/112 [00:00<00:01, 53.34it/s, Epoch: 77, Batch: 24,Loss: -2.546,Avg.Loss: -3.154,LR: 6.66E-05]Training epoch 77:  21%|██▏       | 24/112 [00:00<00:01, 53.34it/s, Epoch: 77, Batch: 25,Loss: -2.304,Avg.Loss: -3.120,LR: 6.66E-05]Training epoch 77:  22%|██▏       | 25/112 [00:00<00:01, 53.34it/s, Epoch: 77, Batch: 26,Loss: -2.829,Avg.Loss: -3.109,LR: 6.65E-05]Training epoch 77:  23%|██▎       | 26/112 [00:00<00:01, 53.34it/s, Epoch: 77, Batch: 27,Loss: -3.508,Avg.Loss: -3.124,LR: 6.65E-05]Training epoch 77:  24%|██▍       | 27/112 [00:00<00:01, 53.34it/s, Epoch: 77, Batch: 28,Loss: -3.046,Avg.Loss: -3.121,LR: 6.64E-05]Training epoch 77:  25%|██▌       | 28/112 [00:00<00:01, 53.34it/s, Epoch: 77, Batch: 29,Loss: -3.876,Avg.Loss: -3.147,LR: 6.64E-05]Training epoch 77:  26%|██▌       | 29/112 [00:00<00:01, 53.34it/s, Epoch: 77, Batch: 30,Loss: -3.397,Avg.Loss: -3.155,LR: 6.63E-05]Training epoch 77:  27%|██▋       | 30/112 [00:00<00:01, 52.60it/s, Epoch: 77, Batch: 30,Loss: -3.397,Avg.Loss: -3.155,LR: 6.63E-05]Training epoch 77:  27%|██▋       | 30/112 [00:00<00:01, 52.60it/s, Epoch: 77, Batch: 31,Loss: -3.457,Avg.Loss: -3.165,LR: 6.63E-05]Training epoch 77:  28%|██▊       | 31/112 [00:00<00:01, 52.60it/s, Epoch: 77, Batch: 32,Loss: -3.681,Avg.Loss: -3.181,LR: 6.62E-05]Training epoch 77:  29%|██▊       | 32/112 [00:00<00:01, 52.60it/s, Epoch: 77, Batch: 33,Loss: -3.036,Avg.Loss: -3.177,LR: 6.62E-05]Training epoch 77:  29%|██▉       | 33/112 [00:00<00:01, 52.60it/s, Epoch: 77, Batch: 34,Loss: -3.452,Avg.Loss: -3.185,LR: 6.61E-05]Training epoch 77:  30%|███       | 34/112 [00:00<00:01, 52.60it/s, Epoch: 77, Batch: 35,Loss: -3.330,Avg.Loss: -3.189,LR: 6.61E-05]Training epoch 77:  31%|███▏      | 35/112 [00:00<00:01, 52.60it/s, Epoch: 77, Batch: 36,Loss: -3.266,Avg.Loss: -3.191,LR: 6.60E-05]Training epoch 77:  32%|███▏      | 36/112 [00:00<00:01, 52.98it/s, Epoch: 77, Batch: 36,Loss: -3.266,Avg.Loss: -3.191,LR: 6.60E-05]Training epoch 77:  32%|███▏      | 36/112 [00:00<00:01, 52.98it/s, Epoch: 77, Batch: 37,Loss: -3.531,Avg.Loss: -3.200,LR: 6.60E-05]Training epoch 77:  33%|███▎      | 37/112 [00:00<00:01, 52.98it/s, Epoch: 77, Batch: 38,Loss: -3.331,Avg.Loss: -3.204,LR: 6.59E-05]Training epoch 77:  34%|███▍      | 38/112 [00:00<00:01, 52.98it/s, Epoch: 77, Batch: 39,Loss: -3.699,Avg.Loss: -3.217,LR: 6.59E-05]Training epoch 77:  35%|███▍      | 39/112 [00:00<00:01, 52.98it/s, Epoch: 77, Batch: 40,Loss: -3.360,Avg.Loss: -3.220,LR: 6.58E-05]Training epoch 77:  36%|███▌      | 40/112 [00:00<00:01, 52.98it/s, Epoch: 77, Batch: 41,Loss: -3.664,Avg.Loss: -3.231,LR: 6.58E-05]Training epoch 77:  37%|███▋      | 41/112 [00:00<00:01, 52.98it/s, Epoch: 77, Batch: 42,Loss: -3.809,Avg.Loss: -3.245,LR: 6.58E-05]Training epoch 77:  38%|███▊      | 42/112 [00:00<00:01, 53.10it/s, Epoch: 77, Batch: 42,Loss: -3.809,Avg.Loss: -3.245,LR: 6.58E-05]Training epoch 77:  38%|███▊      | 42/112 [00:00<00:01, 53.10it/s, Epoch: 77, Batch: 43,Loss: -3.212,Avg.Loss: -3.244,LR: 6.57E-05]Training epoch 77:  38%|███▊      | 43/112 [00:00<00:01, 53.10it/s, Epoch: 77, Batch: 44,Loss: -3.437,Avg.Loss: -3.248,LR: 6.57E-05]Training epoch 77:  39%|███▉      | 44/112 [00:00<00:01, 53.10it/s, Epoch: 77, Batch: 45,Loss: -3.717,Avg.Loss: -3.259,LR: 6.56E-05]Training epoch 77:  40%|████      | 45/112 [00:00<00:01, 53.10it/s, Epoch: 77, Batch: 46,Loss: -3.328,Avg.Loss: -3.260,LR: 6.56E-05]Training epoch 77:  41%|████      | 46/112 [00:00<00:01, 53.10it/s, Epoch: 77, Batch: 47,Loss: -3.514,Avg.Loss: -3.266,LR: 6.55E-05]Training epoch 77:  42%|████▏     | 47/112 [00:00<00:01, 53.10it/s, Epoch: 77, Batch: 48,Loss: -3.539,Avg.Loss: -3.271,LR: 6.55E-05]Training epoch 77:  43%|████▎     | 48/112 [00:00<00:01, 52.62it/s, Epoch: 77, Batch: 48,Loss: -3.539,Avg.Loss: -3.271,LR: 6.55E-05]Training epoch 77:  43%|████▎     | 48/112 [00:00<00:01, 52.62it/s, Epoch: 77, Batch: 49,Loss: -3.334,Avg.Loss: -3.273,LR: 6.54E-05]Training epoch 77:  44%|████▍     | 49/112 [00:00<00:01, 52.62it/s, Epoch: 77, Batch: 50,Loss: -3.178,Avg.Loss: -3.271,LR: 6.54E-05]Training epoch 77:  45%|████▍     | 50/112 [00:00<00:01, 52.62it/s, Epoch: 77, Batch: 51,Loss: -2.591,Avg.Loss: -3.257,LR: 6.53E-05]Training epoch 77:  46%|████▌     | 51/112 [00:00<00:01, 52.62it/s, Epoch: 77, Batch: 52,Loss: -2.580,Avg.Loss: -3.244,LR: 6.53E-05]Training epoch 77:  46%|████▋     | 52/112 [00:00<00:01, 52.62it/s, Epoch: 77, Batch: 53,Loss: -3.257,Avg.Loss: -3.245,LR: 6.52E-05]Training epoch 77:  47%|████▋     | 53/112 [00:01<00:01, 52.62it/s, Epoch: 77, Batch: 54,Loss: -3.135,Avg.Loss: -3.243,LR: 6.52E-05]Training epoch 77:  48%|████▊     | 54/112 [00:01<00:01, 52.70it/s, Epoch: 77, Batch: 54,Loss: -3.135,Avg.Loss: -3.243,LR: 6.52E-05]Training epoch 77:  48%|████▊     | 54/112 [00:01<00:01, 52.70it/s, Epoch: 77, Batch: 55,Loss: -2.598,Avg.Loss: -3.231,LR: 6.51E-05]Training epoch 77:  49%|████▉     | 55/112 [00:01<00:01, 52.70it/s, Epoch: 77, Batch: 56,Loss: -3.106,Avg.Loss: -3.229,LR: 6.51E-05]Training epoch 77:  50%|█████     | 56/112 [00:01<00:01, 52.70it/s, Epoch: 77, Batch: 57,Loss: -3.293,Avg.Loss: -3.230,LR: 6.50E-05]Training epoch 77:  51%|█████     | 57/112 [00:01<00:01, 52.70it/s, Epoch: 77, Batch: 58,Loss: -3.523,Avg.Loss: -3.235,LR: 6.50E-05]Training epoch 77:  52%|█████▏    | 58/112 [00:01<00:01, 52.70it/s, Epoch: 77, Batch: 59,Loss: -3.520,Avg.Loss: -3.240,LR: 6.50E-05]Training epoch 77:  53%|█████▎    | 59/112 [00:01<00:01, 52.70it/s, Epoch: 77, Batch: 60,Loss: -3.667,Avg.Loss: -3.247,LR: 6.49E-05]Training epoch 77:  54%|█████▎    | 60/112 [00:01<00:00, 52.62it/s, Epoch: 77, Batch: 60,Loss: -3.667,Avg.Loss: -3.247,LR: 6.49E-05]Training epoch 77:  54%|█████▎    | 60/112 [00:01<00:00, 52.62it/s, Epoch: 77, Batch: 61,Loss: -3.519,Avg.Loss: -3.251,LR: 6.49E-05]Training epoch 77:  54%|█████▍    | 61/112 [00:01<00:00, 52.62it/s, Epoch: 77, Batch: 62,Loss: -3.436,Avg.Loss: -3.254,LR: 6.48E-05]Training epoch 77:  55%|█████▌    | 62/112 [00:01<00:00, 52.62it/s, Epoch: 77, Batch: 63,Loss: -3.311,Avg.Loss: -3.255,LR: 6.48E-05]Training epoch 77:  56%|█████▋    | 63/112 [00:01<00:00, 52.62it/s, Epoch: 77, Batch: 64,Loss: -3.246,Avg.Loss: -3.255,LR: 6.47E-05]Training epoch 77:  57%|█████▋    | 64/112 [00:01<00:00, 52.62it/s, Epoch: 77, Batch: 65,Loss: -3.557,Avg.Loss: -3.260,LR: 6.47E-05]Training epoch 77:  58%|█████▊    | 65/112 [00:01<00:00, 52.62it/s, Epoch: 77, Batch: 66,Loss: -3.795,Avg.Loss: -3.268,LR: 6.46E-05]Training epoch 77:  59%|█████▉    | 66/112 [00:01<00:00, 52.64it/s, Epoch: 77, Batch: 66,Loss: -3.795,Avg.Loss: -3.268,LR: 6.46E-05]Training epoch 77:  59%|█████▉    | 66/112 [00:01<00:00, 52.64it/s, Epoch: 77, Batch: 67,Loss: -3.119,Avg.Loss: -3.266,LR: 6.46E-05]Training epoch 77:  60%|█████▉    | 67/112 [00:01<00:00, 52.64it/s, Epoch: 77, Batch: 68,Loss: -3.656,Avg.Loss: -3.271,LR: 6.45E-05]Training epoch 77:  61%|██████    | 68/112 [00:01<00:00, 52.64it/s, Epoch: 77, Batch: 69,Loss: -3.112,Avg.Loss: -3.269,LR: 6.45E-05]Training epoch 77:  62%|██████▏   | 69/112 [00:01<00:00, 52.64it/s, Epoch: 77, Batch: 70,Loss: -3.535,Avg.Loss: -3.273,LR: 6.44E-05]Training epoch 77:  62%|██████▎   | 70/112 [00:01<00:00, 52.64it/s, Epoch: 77, Batch: 71,Loss: -3.187,Avg.Loss: -3.272,LR: 6.44E-05]Training epoch 77:  63%|██████▎   | 71/112 [00:01<00:00, 52.64it/s, Epoch: 77, Batch: 72,Loss: -3.589,Avg.Loss: -3.276,LR: 6.43E-05]Training epoch 77:  64%|██████▍   | 72/112 [00:01<00:00, 52.84it/s, Epoch: 77, Batch: 72,Loss: -3.589,Avg.Loss: -3.276,LR: 6.43E-05]Training epoch 77:  64%|██████▍   | 72/112 [00:01<00:00, 52.84it/s, Epoch: 77, Batch: 73,Loss: -3.100,Avg.Loss: -3.274,LR: 6.43E-05]Training epoch 77:  65%|██████▌   | 73/112 [00:01<00:00, 52.84it/s, Epoch: 77, Batch: 74,Loss: -3.159,Avg.Loss: -3.272,LR: 6.42E-05]Training epoch 77:  66%|██████▌   | 74/112 [00:01<00:00, 52.84it/s, Epoch: 77, Batch: 75,Loss: -2.941,Avg.Loss: -3.268,LR: 6.42E-05]Training epoch 77:  67%|██████▋   | 75/112 [00:01<00:00, 52.84it/s, Epoch: 77, Batch: 76,Loss: -2.921,Avg.Loss: -3.263,LR: 6.42E-05]Training epoch 77:  68%|██████▊   | 76/112 [00:01<00:00, 52.84it/s, Epoch: 77, Batch: 77,Loss: -3.372,Avg.Loss: -3.264,LR: 6.41E-05]Training epoch 77:  69%|██████▉   | 77/112 [00:01<00:00, 52.84it/s, Epoch: 77, Batch: 78,Loss: -3.730,Avg.Loss: -3.270,LR: 6.41E-05]Training epoch 77:  70%|██████▉   | 78/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 78,Loss: -3.730,Avg.Loss: -3.270,LR: 6.41E-05]Training epoch 77:  70%|██████▉   | 78/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 79,Loss: -2.687,Avg.Loss: -3.263,LR: 6.40E-05]Training epoch 77:  71%|███████   | 79/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 80,Loss: -2.068,Avg.Loss: -3.248,LR: 6.40E-05]Training epoch 77:  71%|███████▏  | 80/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 81,Loss: -2.766,Avg.Loss: -3.242,LR: 6.39E-05]Training epoch 77:  72%|███████▏  | 81/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 82,Loss: -2.591,Avg.Loss: -3.234,LR: 6.39E-05]Training epoch 77:  73%|███████▎  | 82/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 83,Loss: -2.923,Avg.Loss: -3.230,LR: 6.38E-05]Training epoch 77:  74%|███████▍  | 83/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 84,Loss: -3.316,Avg.Loss: -3.231,LR: 6.38E-05]Training epoch 77:  75%|███████▌  | 84/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 84,Loss: -3.316,Avg.Loss: -3.231,LR: 6.38E-05]Training epoch 77:  75%|███████▌  | 84/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 85,Loss: -3.225,Avg.Loss: -3.231,LR: 6.37E-05]Training epoch 77:  76%|███████▌  | 85/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 86,Loss: -3.418,Avg.Loss: -3.234,LR: 6.37E-05]Training epoch 77:  77%|███████▋  | 86/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 87,Loss: -2.848,Avg.Loss: -3.229,LR: 6.36E-05]Training epoch 77:  78%|███████▊  | 87/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 88,Loss: -2.835,Avg.Loss: -3.225,LR: 6.36E-05]Training epoch 77:  79%|███████▊  | 88/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 89,Loss: -3.053,Avg.Loss: -3.223,LR: 6.35E-05]Training epoch 77:  79%|███████▉  | 89/112 [00:01<00:00, 52.95it/s, Epoch: 77, Batch: 90,Loss: -2.905,Avg.Loss: -3.219,LR: 6.35E-05]Training epoch 77:  80%|████████  | 90/112 [00:01<00:00, 53.16it/s, Epoch: 77, Batch: 90,Loss: -2.905,Avg.Loss: -3.219,LR: 6.35E-05]Training epoch 77:  80%|████████  | 90/112 [00:01<00:00, 53.16it/s, Epoch: 77, Batch: 91,Loss: -2.423,Avg.Loss: -3.210,LR: 6.34E-05]Training epoch 77:  81%|████████▏ | 91/112 [00:01<00:00, 53.16it/s, Epoch: 77, Batch: 92,Loss: -3.203,Avg.Loss: -3.210,LR: 6.34E-05]Training epoch 77:  82%|████████▏ | 92/112 [00:01<00:00, 53.16it/s, Epoch: 77, Batch: 93,Loss: -3.189,Avg.Loss: -3.210,LR: 6.34E-05]Training epoch 77:  83%|████████▎ | 93/112 [00:01<00:00, 53.16it/s, Epoch: 77, Batch: 94,Loss: -3.337,Avg.Loss: -3.212,LR: 6.33E-05]Training epoch 77:  84%|████████▍ | 94/112 [00:01<00:00, 53.16it/s, Epoch: 77, Batch: 95,Loss: -2.050,Avg.Loss: -3.199,LR: 6.33E-05]Training epoch 77:  85%|████████▍ | 95/112 [00:01<00:00, 53.16it/s, Epoch: 77, Batch: 96,Loss: -2.647,Avg.Loss: -3.194,LR: 6.32E-05]Training epoch 77:  86%|████████▌ | 96/112 [00:01<00:00, 53.29it/s, Epoch: 77, Batch: 96,Loss: -2.647,Avg.Loss: -3.194,LR: 6.32E-05]Training epoch 77:  86%|████████▌ | 96/112 [00:01<00:00, 53.29it/s, Epoch: 77, Batch: 97,Loss: -2.877,Avg.Loss: -3.190,LR: 6.32E-05]Training epoch 77:  87%|████████▋ | 97/112 [00:01<00:00, 53.29it/s, Epoch: 77, Batch: 98,Loss: -3.297,Avg.Loss: -3.191,LR: 6.31E-05]Training epoch 77:  88%|████████▊ | 98/112 [00:01<00:00, 53.29it/s, Epoch: 77, Batch: 99,Loss: -2.999,Avg.Loss: -3.189,LR: 6.31E-05]Training epoch 77:  88%|████████▊ | 99/112 [00:01<00:00, 53.29it/s, Epoch: 77, Batch: 100,Loss: -2.866,Avg.Loss: -3.186,LR: 6.30E-05]Training epoch 77:  89%|████████▉ | 100/112 [00:01<00:00, 53.29it/s, Epoch: 77, Batch: 101,Loss: -3.068,Avg.Loss: -3.185,LR: 6.30E-05]Training epoch 77:  90%|█████████ | 101/112 [00:01<00:00, 53.29it/s, Epoch: 77, Batch: 102,Loss: -3.338,Avg.Loss: -3.187,LR: 6.29E-05]Training epoch 77:  91%|█████████ | 102/112 [00:01<00:00, 53.26it/s, Epoch: 77, Batch: 102,Loss: -3.338,Avg.Loss: -3.187,LR: 6.29E-05]Training epoch 77:  91%|█████████ | 102/112 [00:01<00:00, 53.26it/s, Epoch: 77, Batch: 103,Loss: -3.101,Avg.Loss: -3.186,LR: 6.29E-05]Training epoch 77:  92%|█████████▏| 103/112 [00:01<00:00, 53.26it/s, Epoch: 77, Batch: 104,Loss: -3.019,Avg.Loss: -3.184,LR: 6.28E-05]Training epoch 77:  93%|█████████▎| 104/112 [00:01<00:00, 53.26it/s, Epoch: 77, Batch: 105,Loss: -3.118,Avg.Loss: -3.183,LR: 6.28E-05]Training epoch 77:  94%|█████████▍| 105/112 [00:01<00:00, 53.26it/s, Epoch: 77, Batch: 106,Loss: -2.554,Avg.Loss: -3.178,LR: 6.28E-05]Training epoch 77:  95%|█████████▍| 106/112 [00:02<00:00, 53.26it/s, Epoch: 77, Batch: 107,Loss: -2.185,Avg.Loss: -3.168,LR: 6.27E-05]Training epoch 77:  96%|█████████▌| 107/112 [00:02<00:00, 53.26it/s, Epoch: 77, Batch: 108,Loss: -2.616,Avg.Loss: -3.163,LR: 6.27E-05]Training epoch 77:  96%|█████████▋| 108/112 [00:02<00:00, 53.33it/s, Epoch: 77, Batch: 108,Loss: -2.616,Avg.Loss: -3.163,LR: 6.27E-05]Training epoch 77:  96%|█████████▋| 108/112 [00:02<00:00, 53.33it/s, Epoch: 77, Batch: 109,Loss: -3.019,Avg.Loss: -3.162,LR: 6.26E-05]Training epoch 77:  97%|█████████▋| 109/112 [00:02<00:00, 53.33it/s, Epoch: 77, Batch: 110,Loss: -3.250,Avg.Loss: -3.163,LR: 6.26E-05]Training epoch 77:  98%|█████████▊| 110/112 [00:02<00:00, 53.33it/s, Epoch: 77, Batch: 111,Loss: -3.215,Avg.Loss: -3.163,LR: 6.25E-05]Training epoch 77:  99%|█████████▉| 111/112 [00:02<00:00, 53.33it/s, Epoch: 77, Batch: 112,Loss: -3.408,Avg.Loss: -3.165,LR: 6.25E-05]Training epoch 77: 100%|██████████| 112/112 [00:02<00:00, 53.11it/s, Epoch: 77, Batch: 112,Loss: -3.408,Avg.Loss: -3.165,LR: 6.25E-05]
Training epoch 78:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 78:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 78, Batch: 1,Loss: -3.315,Avg.Loss: -3.315,LR: 6.24E-05]Training epoch 78:   1%|          | 1/112 [00:00<00:04, 27.58it/s, Epoch: 78, Batch: 2,Loss: -2.748,Avg.Loss: -3.032,LR: 6.24E-05]Training epoch 78:   2%|▏         | 2/112 [00:00<00:02, 37.14it/s, Epoch: 78, Batch: 3,Loss: -3.202,Avg.Loss: -3.088,LR: 6.23E-05]Training epoch 78:   3%|▎         | 3/112 [00:00<00:02, 44.05it/s, Epoch: 78, Batch: 4,Loss: -3.358,Avg.Loss: -3.156,LR: 6.23E-05]Training epoch 78:   4%|▎         | 4/112 [00:00<00:02, 46.77it/s, Epoch: 78, Batch: 5,Loss: -3.505,Avg.Loss: -3.225,LR: 6.22E-05]Training epoch 78:   4%|▍         | 5/112 [00:00<00:02, 47.76it/s, Epoch: 78, Batch: 6,Loss: -3.430,Avg.Loss: -3.260,LR: 6.22E-05]Training epoch 78:   5%|▌         | 6/112 [00:00<00:01, 57.21it/s, Epoch: 78, Batch: 6,Loss: -3.430,Avg.Loss: -3.260,LR: 6.22E-05]Training epoch 78:   5%|▌         | 6/112 [00:00<00:01, 57.21it/s, Epoch: 78, Batch: 7,Loss: -2.999,Avg.Loss: -3.222,LR: 6.21E-05]Training epoch 78:   6%|▋         | 7/112 [00:00<00:01, 57.21it/s, Epoch: 78, Batch: 8,Loss: -3.527,Avg.Loss: -3.260,LR: 6.21E-05]Training epoch 78:   7%|▋         | 8/112 [00:00<00:01, 57.21it/s, Epoch: 78, Batch: 9,Loss: -2.831,Avg.Loss: -3.213,LR: 6.21E-05]Training epoch 78:   8%|▊         | 9/112 [00:00<00:01, 57.21it/s, Epoch: 78, Batch: 10,Loss: -3.041,Avg.Loss: -3.196,LR: 6.20E-05]Training epoch 78:   9%|▉         | 10/112 [00:00<00:01, 57.21it/s, Epoch: 78, Batch: 11,Loss: -2.526,Avg.Loss: -3.135,LR: 6.20E-05]Training epoch 78:  10%|▉         | 11/112 [00:00<00:01, 57.21it/s, Epoch: 78, Batch: 12,Loss: -2.662,Avg.Loss: -3.095,LR: 6.19E-05]Training epoch 78:  11%|█         | 12/112 [00:00<00:01, 54.64it/s, Epoch: 78, Batch: 12,Loss: -2.662,Avg.Loss: -3.095,LR: 6.19E-05]Training epoch 78:  11%|█         | 12/112 [00:00<00:01, 54.64it/s, Epoch: 78, Batch: 13,Loss: -3.113,Avg.Loss: -3.097,LR: 6.19E-05]Training epoch 78:  12%|█▏        | 13/112 [00:00<00:01, 54.64it/s, Epoch: 78, Batch: 14,Loss: -2.698,Avg.Loss: -3.068,LR: 6.18E-05]Training epoch 78:  12%|█▎        | 14/112 [00:00<00:01, 54.64it/s, Epoch: 78, Batch: 15,Loss: -2.601,Avg.Loss: -3.037,LR: 6.18E-05]Training epoch 78:  13%|█▎        | 15/112 [00:00<00:01, 54.64it/s, Epoch: 78, Batch: 16,Loss: -3.118,Avg.Loss: -3.042,LR: 6.17E-05]Training epoch 78:  14%|█▍        | 16/112 [00:00<00:01, 54.64it/s, Epoch: 78, Batch: 17,Loss: -3.336,Avg.Loss: -3.059,LR: 6.17E-05]Training epoch 78:  15%|█▌        | 17/112 [00:00<00:01, 54.64it/s, Epoch: 78, Batch: 18,Loss: -2.608,Avg.Loss: -3.034,LR: 6.16E-05]Training epoch 78:  16%|█▌        | 18/112 [00:00<00:01, 53.80it/s, Epoch: 78, Batch: 18,Loss: -2.608,Avg.Loss: -3.034,LR: 6.16E-05]Training epoch 78:  16%|█▌        | 18/112 [00:00<00:01, 53.80it/s, Epoch: 78, Batch: 19,Loss: -2.532,Avg.Loss: -3.008,LR: 6.16E-05]Training epoch 78:  17%|█▋        | 19/112 [00:00<00:01, 53.80it/s, Epoch: 78, Batch: 20,Loss: -3.366,Avg.Loss: -3.026,LR: 6.15E-05]Training epoch 78:  18%|█▊        | 20/112 [00:00<00:01, 53.80it/s, Epoch: 78, Batch: 21,Loss: -3.181,Avg.Loss: -3.033,LR: 6.15E-05]Training epoch 78:  19%|█▉        | 21/112 [00:00<00:01, 53.80it/s, Epoch: 78, Batch: 22,Loss: -2.932,Avg.Loss: -3.029,LR: 6.15E-05]Training epoch 78:  20%|█▉        | 22/112 [00:00<00:01, 53.80it/s, Epoch: 78, Batch: 23,Loss: -2.961,Avg.Loss: -3.026,LR: 6.14E-05]Training epoch 78:  21%|██        | 23/112 [00:00<00:01, 53.80it/s, Epoch: 78, Batch: 24,Loss: -3.588,Avg.Loss: -3.049,LR: 6.14E-05]Training epoch 78:  21%|██▏       | 24/112 [00:00<00:01, 51.84it/s, Epoch: 78, Batch: 24,Loss: -3.588,Avg.Loss: -3.049,LR: 6.14E-05]Training epoch 78:  21%|██▏       | 24/112 [00:00<00:01, 51.84it/s, Epoch: 78, Batch: 25,Loss: -3.420,Avg.Loss: -3.064,LR: 6.13E-05]Training epoch 78:  22%|██▏       | 25/112 [00:00<00:01, 51.84it/s, Epoch: 78, Batch: 26,Loss: -2.903,Avg.Loss: -3.058,LR: 6.13E-05]Training epoch 78:  23%|██▎       | 26/112 [00:00<00:01, 51.84it/s, Epoch: 78, Batch: 27,Loss: -3.516,Avg.Loss: -3.075,LR: 6.12E-05]Training epoch 78:  24%|██▍       | 27/112 [00:00<00:01, 51.84it/s, Epoch: 78, Batch: 28,Loss: -3.110,Avg.Loss: -3.076,LR: 6.12E-05]Training epoch 78:  25%|██▌       | 28/112 [00:00<00:01, 51.84it/s, Epoch: 78, Batch: 29,Loss: -3.163,Avg.Loss: -3.079,LR: 6.11E-05]Training epoch 78:  26%|██▌       | 29/112 [00:00<00:01, 51.84it/s, Epoch: 78, Batch: 30,Loss: -2.569,Avg.Loss: -3.062,LR: 6.11E-05]Training epoch 78:  27%|██▋       | 30/112 [00:00<00:01, 51.97it/s, Epoch: 78, Batch: 30,Loss: -2.569,Avg.Loss: -3.062,LR: 6.11E-05]Training epoch 78:  27%|██▋       | 30/112 [00:00<00:01, 51.97it/s, Epoch: 78, Batch: 31,Loss: -2.312,Avg.Loss: -3.038,LR: 6.10E-05]Training epoch 78:  28%|██▊       | 31/112 [00:00<00:01, 51.97it/s, Epoch: 78, Batch: 32,Loss: -3.612,Avg.Loss: -3.056,LR: 6.10E-05]Training epoch 78:  29%|██▊       | 32/112 [00:00<00:01, 51.97it/s, Epoch: 78, Batch: 33,Loss: -3.575,Avg.Loss: -3.071,LR: 6.09E-05]Training epoch 78:  29%|██▉       | 33/112 [00:00<00:01, 51.97it/s, Epoch: 78, Batch: 34,Loss: -3.030,Avg.Loss: -3.070,LR: 6.09E-05]Training epoch 78:  30%|███       | 34/112 [00:00<00:01, 51.97it/s, Epoch: 78, Batch: 35,Loss: -3.466,Avg.Loss: -3.082,LR: 6.09E-05]Training epoch 78:  31%|███▏      | 35/112 [00:00<00:01, 51.97it/s, Epoch: 78, Batch: 36,Loss: -3.773,Avg.Loss: -3.101,LR: 6.08E-05]Training epoch 78:  32%|███▏      | 36/112 [00:00<00:01, 52.34it/s, Epoch: 78, Batch: 36,Loss: -3.773,Avg.Loss: -3.101,LR: 6.08E-05]Training epoch 78:  32%|███▏      | 36/112 [00:00<00:01, 52.34it/s, Epoch: 78, Batch: 37,Loss: -3.925,Avg.Loss: -3.123,LR: 6.08E-05]Training epoch 78:  33%|███▎      | 37/112 [00:00<00:01, 52.34it/s, Epoch: 78, Batch: 38,Loss: -3.431,Avg.Loss: -3.131,LR: 6.07E-05]Training epoch 78:  34%|███▍      | 38/112 [00:00<00:01, 52.34it/s, Epoch: 78, Batch: 39,Loss: -2.907,Avg.Loss: -3.125,LR: 6.07E-05]Training epoch 78:  35%|███▍      | 39/112 [00:00<00:01, 52.34it/s, Epoch: 78, Batch: 40,Loss: -3.184,Avg.Loss: -3.127,LR: 6.06E-05]Training epoch 78:  36%|███▌      | 40/112 [00:00<00:01, 52.34it/s, Epoch: 78, Batch: 41,Loss: -3.445,Avg.Loss: -3.135,LR: 6.06E-05]Training epoch 78:  37%|███▋      | 41/112 [00:00<00:01, 52.34it/s, Epoch: 78, Batch: 42,Loss: -2.892,Avg.Loss: -3.129,LR: 6.05E-05]Training epoch 78:  38%|███▊      | 42/112 [00:00<00:01, 52.61it/s, Epoch: 78, Batch: 42,Loss: -2.892,Avg.Loss: -3.129,LR: 6.05E-05]Training epoch 78:  38%|███▊      | 42/112 [00:00<00:01, 52.61it/s, Epoch: 78, Batch: 43,Loss: -3.401,Avg.Loss: -3.135,LR: 6.05E-05]Training epoch 78:  38%|███▊      | 43/112 [00:00<00:01, 52.61it/s, Epoch: 78, Batch: 44,Loss: -3.021,Avg.Loss: -3.133,LR: 6.04E-05]Training epoch 78:  39%|███▉      | 44/112 [00:00<00:01, 52.61it/s, Epoch: 78, Batch: 45,Loss: -3.086,Avg.Loss: -3.132,LR: 6.04E-05]Training epoch 78:  40%|████      | 45/112 [00:00<00:01, 52.61it/s, Epoch: 78, Batch: 46,Loss: -3.442,Avg.Loss: -3.138,LR: 6.04E-05]Training epoch 78:  41%|████      | 46/112 [00:00<00:01, 52.61it/s, Epoch: 78, Batch: 47,Loss: -3.114,Avg.Loss: -3.138,LR: 6.03E-05]Training epoch 78:  42%|████▏     | 47/112 [00:00<00:01, 52.61it/s, Epoch: 78, Batch: 48,Loss: -3.420,Avg.Loss: -3.144,LR: 6.03E-05]Training epoch 78:  43%|████▎     | 48/112 [00:00<00:01, 52.82it/s, Epoch: 78, Batch: 48,Loss: -3.420,Avg.Loss: -3.144,LR: 6.03E-05]Training epoch 78:  43%|████▎     | 48/112 [00:00<00:01, 52.82it/s, Epoch: 78, Batch: 49,Loss: -3.636,Avg.Loss: -3.154,LR: 6.02E-05]Training epoch 78:  44%|████▍     | 49/112 [00:00<00:01, 52.82it/s, Epoch: 78, Batch: 50,Loss: -3.235,Avg.Loss: -3.155,LR: 6.02E-05]Training epoch 78:  45%|████▍     | 50/112 [00:00<00:01, 52.82it/s, Epoch: 78, Batch: 51,Loss: -2.899,Avg.Loss: -3.150,LR: 6.01E-05]Training epoch 78:  46%|████▌     | 51/112 [00:00<00:01, 52.82it/s, Epoch: 78, Batch: 52,Loss: -3.437,Avg.Loss: -3.156,LR: 6.01E-05]Training epoch 78:  46%|████▋     | 52/112 [00:01<00:01, 52.82it/s, Epoch: 78, Batch: 53,Loss: -3.068,Avg.Loss: -3.154,LR: 6.00E-05]Training epoch 78:  47%|████▋     | 53/112 [00:01<00:01, 52.82it/s, Epoch: 78, Batch: 54,Loss: -3.685,Avg.Loss: -3.164,LR: 6.00E-05]Training epoch 78:  48%|████▊     | 54/112 [00:01<00:01, 53.06it/s, Epoch: 78, Batch: 54,Loss: -3.685,Avg.Loss: -3.164,LR: 6.00E-05]Training epoch 78:  48%|████▊     | 54/112 [00:01<00:01, 53.06it/s, Epoch: 78, Batch: 55,Loss: -3.674,Avg.Loss: -3.173,LR: 5.99E-05]Training epoch 78:  49%|████▉     | 55/112 [00:01<00:01, 53.06it/s, Epoch: 78, Batch: 56,Loss: -3.288,Avg.Loss: -3.175,LR: 5.99E-05]Training epoch 78:  50%|█████     | 56/112 [00:01<00:01, 53.06it/s, Epoch: 78, Batch: 57,Loss: -3.600,Avg.Loss: -3.183,LR: 5.99E-05]Training epoch 78:  51%|█████     | 57/112 [00:01<00:01, 53.06it/s, Epoch: 78, Batch: 58,Loss: -2.852,Avg.Loss: -3.177,LR: 5.98E-05]Training epoch 78:  52%|█████▏    | 58/112 [00:01<00:01, 53.06it/s, Epoch: 78, Batch: 59,Loss: -3.246,Avg.Loss: -3.178,LR: 5.98E-05]Training epoch 78:  53%|█████▎    | 59/112 [00:01<00:00, 53.06it/s, Epoch: 78, Batch: 60,Loss: -3.285,Avg.Loss: -3.180,LR: 5.97E-05]Training epoch 78:  54%|█████▎    | 60/112 [00:01<00:00, 52.79it/s, Epoch: 78, Batch: 60,Loss: -3.285,Avg.Loss: -3.180,LR: 5.97E-05]Training epoch 78:  54%|█████▎    | 60/112 [00:01<00:00, 52.79it/s, Epoch: 78, Batch: 61,Loss: -3.027,Avg.Loss: -3.177,LR: 5.97E-05]Training epoch 78:  54%|█████▍    | 61/112 [00:01<00:00, 52.79it/s, Epoch: 78, Batch: 62,Loss: -3.348,Avg.Loss: -3.180,LR: 5.96E-05]Training epoch 78:  55%|█████▌    | 62/112 [00:01<00:00, 52.79it/s, Epoch: 78, Batch: 63,Loss: -3.282,Avg.Loss: -3.182,LR: 5.96E-05]Training epoch 78:  56%|█████▋    | 63/112 [00:01<00:00, 52.79it/s, Epoch: 78, Batch: 64,Loss: -3.503,Avg.Loss: -3.187,LR: 5.95E-05]Training epoch 78:  57%|█████▋    | 64/112 [00:01<00:00, 52.79it/s, Epoch: 78, Batch: 65,Loss: -3.530,Avg.Loss: -3.192,LR: 5.95E-05]Training epoch 78:  58%|█████▊    | 65/112 [00:01<00:00, 52.79it/s, Epoch: 78, Batch: 66,Loss: -3.292,Avg.Loss: -3.194,LR: 5.94E-05]Training epoch 78:  59%|█████▉    | 66/112 [00:01<00:00, 52.97it/s, Epoch: 78, Batch: 66,Loss: -3.292,Avg.Loss: -3.194,LR: 5.94E-05]Training epoch 78:  59%|█████▉    | 66/112 [00:01<00:00, 52.97it/s, Epoch: 78, Batch: 67,Loss: -3.103,Avg.Loss: -3.192,LR: 5.94E-05]Training epoch 78:  60%|█████▉    | 67/112 [00:01<00:00, 52.97it/s, Epoch: 78, Batch: 68,Loss: -3.552,Avg.Loss: -3.198,LR: 5.94E-05]Training epoch 78:  61%|██████    | 68/112 [00:01<00:00, 52.97it/s, Epoch: 78, Batch: 69,Loss: -3.667,Avg.Loss: -3.204,LR: 5.93E-05]Training epoch 78:  62%|██████▏   | 69/112 [00:01<00:00, 52.97it/s, Epoch: 78, Batch: 70,Loss: -3.647,Avg.Loss: -3.211,LR: 5.93E-05]Training epoch 78:  62%|██████▎   | 70/112 [00:01<00:00, 52.97it/s, Epoch: 78, Batch: 71,Loss: -3.847,Avg.Loss: -3.220,LR: 5.92E-05]Training epoch 78:  63%|██████▎   | 71/112 [00:01<00:00, 52.97it/s, Epoch: 78, Batch: 72,Loss: -3.253,Avg.Loss: -3.220,LR: 5.92E-05]Training epoch 78:  64%|██████▍   | 72/112 [00:01<00:00, 53.03it/s, Epoch: 78, Batch: 72,Loss: -3.253,Avg.Loss: -3.220,LR: 5.92E-05]Training epoch 78:  64%|██████▍   | 72/112 [00:01<00:00, 53.03it/s, Epoch: 78, Batch: 73,Loss: -2.565,Avg.Loss: -3.211,LR: 5.91E-05]Training epoch 78:  65%|██████▌   | 73/112 [00:01<00:00, 53.03it/s, Epoch: 78, Batch: 74,Loss: -3.361,Avg.Loss: -3.213,LR: 5.91E-05]Training epoch 78:  66%|██████▌   | 74/112 [00:01<00:00, 53.03it/s, Epoch: 78, Batch: 75,Loss: -3.177,Avg.Loss: -3.213,LR: 5.90E-05]Training epoch 78:  67%|██████▋   | 75/112 [00:01<00:00, 53.03it/s, Epoch: 78, Batch: 76,Loss: -3.223,Avg.Loss: -3.213,LR: 5.90E-05]Training epoch 78:  68%|██████▊   | 76/112 [00:01<00:00, 53.03it/s, Epoch: 78, Batch: 77,Loss: -3.628,Avg.Loss: -3.218,LR: 5.89E-05]Training epoch 78:  69%|██████▉   | 77/112 [00:01<00:00, 53.03it/s, Epoch: 78, Batch: 78,Loss: -3.048,Avg.Loss: -3.216,LR: 5.89E-05]Training epoch 78:  70%|██████▉   | 78/112 [00:01<00:00, 53.16it/s, Epoch: 78, Batch: 78,Loss: -3.048,Avg.Loss: -3.216,LR: 5.89E-05]Training epoch 78:  70%|██████▉   | 78/112 [00:01<00:00, 53.16it/s, Epoch: 78, Batch: 79,Loss: -3.533,Avg.Loss: -3.220,LR: 5.89E-05]Training epoch 78:  71%|███████   | 79/112 [00:01<00:00, 53.16it/s, Epoch: 78, Batch: 80,Loss: -3.208,Avg.Loss: -3.220,LR: 5.88E-05]Training epoch 78:  71%|███████▏  | 80/112 [00:01<00:00, 53.16it/s, Epoch: 78, Batch: 81,Loss: -3.358,Avg.Loss: -3.222,LR: 5.88E-05]Training epoch 78:  72%|███████▏  | 81/112 [00:01<00:00, 53.16it/s, Epoch: 78, Batch: 82,Loss: -3.235,Avg.Loss: -3.222,LR: 5.87E-05]Training epoch 78:  73%|███████▎  | 82/112 [00:01<00:00, 53.16it/s, Epoch: 78, Batch: 83,Loss: -3.577,Avg.Loss: -3.226,LR: 5.87E-05]Training epoch 78:  74%|███████▍  | 83/112 [00:01<00:00, 53.16it/s, Epoch: 78, Batch: 84,Loss: -3.354,Avg.Loss: -3.228,LR: 5.86E-05]Training epoch 78:  75%|███████▌  | 84/112 [00:01<00:00, 53.31it/s, Epoch: 78, Batch: 84,Loss: -3.354,Avg.Loss: -3.228,LR: 5.86E-05]Training epoch 78:  75%|███████▌  | 84/112 [00:01<00:00, 53.31it/s, Epoch: 78, Batch: 85,Loss: -3.479,Avg.Loss: -3.231,LR: 5.86E-05]Training epoch 78:  76%|███████▌  | 85/112 [00:01<00:00, 53.31it/s, Epoch: 78, Batch: 86,Loss: -3.653,Avg.Loss: -3.235,LR: 5.85E-05]Training epoch 78:  77%|███████▋  | 86/112 [00:01<00:00, 53.31it/s, Epoch: 78, Batch: 87,Loss: -3.870,Avg.Loss: -3.243,LR: 5.85E-05]Training epoch 78:  78%|███████▊  | 87/112 [00:01<00:00, 53.31it/s, Epoch: 78, Batch: 88,Loss: -3.461,Avg.Loss: -3.245,LR: 5.84E-05]Training epoch 78:  79%|███████▊  | 88/112 [00:01<00:00, 53.31it/s, Epoch: 78, Batch: 89,Loss: -3.662,Avg.Loss: -3.250,LR: 5.84E-05]Training epoch 78:  79%|███████▉  | 89/112 [00:01<00:00, 53.31it/s, Epoch: 78, Batch: 90,Loss: -3.580,Avg.Loss: -3.254,LR: 5.84E-05]Training epoch 78:  80%|████████  | 90/112 [00:01<00:00, 53.51it/s, Epoch: 78, Batch: 90,Loss: -3.580,Avg.Loss: -3.254,LR: 5.84E-05]Training epoch 78:  80%|████████  | 90/112 [00:01<00:00, 53.51it/s, Epoch: 78, Batch: 91,Loss: -3.150,Avg.Loss: -3.252,LR: 5.83E-05]Training epoch 78:  81%|████████▏ | 91/112 [00:01<00:00, 53.51it/s, Epoch: 78, Batch: 92,Loss: -3.479,Avg.Loss: -3.255,LR: 5.83E-05]Training epoch 78:  82%|████████▏ | 92/112 [00:01<00:00, 53.51it/s, Epoch: 78, Batch: 93,Loss: -3.159,Avg.Loss: -3.254,LR: 5.82E-05]Training epoch 78:  83%|████████▎ | 93/112 [00:01<00:00, 53.51it/s, Epoch: 78, Batch: 94,Loss: -3.281,Avg.Loss: -3.254,LR: 5.82E-05]Training epoch 78:  84%|████████▍ | 94/112 [00:01<00:00, 53.51it/s, Epoch: 78, Batch: 95,Loss: -3.495,Avg.Loss: -3.257,LR: 5.81E-05]Training epoch 78:  85%|████████▍ | 95/112 [00:01<00:00, 53.51it/s, Epoch: 78, Batch: 96,Loss: -3.442,Avg.Loss: -3.259,LR: 5.81E-05]Training epoch 78:  86%|████████▌ | 96/112 [00:01<00:00, 53.50it/s, Epoch: 78, Batch: 96,Loss: -3.442,Avg.Loss: -3.259,LR: 5.81E-05]Training epoch 78:  86%|████████▌ | 96/112 [00:01<00:00, 53.50it/s, Epoch: 78, Batch: 97,Loss: -3.343,Avg.Loss: -3.260,LR: 5.80E-05]Training epoch 78:  87%|████████▋ | 97/112 [00:01<00:00, 53.50it/s, Epoch: 78, Batch: 98,Loss: -3.733,Avg.Loss: -3.264,LR: 5.80E-05]Training epoch 78:  88%|████████▊ | 98/112 [00:01<00:00, 53.50it/s, Epoch: 78, Batch: 99,Loss: -2.966,Avg.Loss: -3.261,LR: 5.80E-05]Training epoch 78:  88%|████████▊ | 99/112 [00:01<00:00, 53.50it/s, Epoch: 78, Batch: 100,Loss: -3.208,Avg.Loss: -3.261,LR: 5.79E-05]Training epoch 78:  89%|████████▉ | 100/112 [00:01<00:00, 53.50it/s, Epoch: 78, Batch: 101,Loss: -3.070,Avg.Loss: -3.259,LR: 5.79E-05]Training epoch 78:  90%|█████████ | 101/112 [00:01<00:00, 53.50it/s, Epoch: 78, Batch: 102,Loss: -3.442,Avg.Loss: -3.261,LR: 5.78E-05]Training epoch 78:  91%|█████████ | 102/112 [00:01<00:00, 53.48it/s, Epoch: 78, Batch: 102,Loss: -3.442,Avg.Loss: -3.261,LR: 5.78E-05]Training epoch 78:  91%|█████████ | 102/112 [00:01<00:00, 53.48it/s, Epoch: 78, Batch: 103,Loss: -3.585,Avg.Loss: -3.264,LR: 5.78E-05]Training epoch 78:  92%|█████████▏| 103/112 [00:01<00:00, 53.48it/s, Epoch: 78, Batch: 104,Loss: -3.827,Avg.Loss: -3.269,LR: 5.77E-05]Training epoch 78:  93%|█████████▎| 104/112 [00:01<00:00, 53.48it/s, Epoch: 78, Batch: 105,Loss: -3.498,Avg.Loss: -3.271,LR: 5.77E-05]Training epoch 78:  94%|█████████▍| 105/112 [00:01<00:00, 53.48it/s, Epoch: 78, Batch: 106,Loss: -2.743,Avg.Loss: -3.266,LR: 5.76E-05]Training epoch 78:  95%|█████████▍| 106/112 [00:02<00:00, 53.48it/s, Epoch: 78, Batch: 107,Loss: -2.778,Avg.Loss: -3.262,LR: 5.76E-05]Training epoch 78:  96%|█████████▌| 107/112 [00:02<00:00, 53.48it/s, Epoch: 78, Batch: 108,Loss: -3.246,Avg.Loss: -3.262,LR: 5.76E-05]Training epoch 78:  96%|█████████▋| 108/112 [00:02<00:00, 53.42it/s, Epoch: 78, Batch: 108,Loss: -3.246,Avg.Loss: -3.262,LR: 5.76E-05]Training epoch 78:  96%|█████████▋| 108/112 [00:02<00:00, 53.42it/s, Epoch: 78, Batch: 109,Loss: -3.420,Avg.Loss: -3.263,LR: 5.75E-05]Training epoch 78:  97%|█████████▋| 109/112 [00:02<00:00, 53.42it/s, Epoch: 78, Batch: 110,Loss: -2.716,Avg.Loss: -3.258,LR: 5.75E-05]Training epoch 78:  98%|█████████▊| 110/112 [00:02<00:00, 53.42it/s, Epoch: 78, Batch: 111,Loss: -3.174,Avg.Loss: -3.257,LR: 5.74E-05]Training epoch 78:  99%|█████████▉| 111/112 [00:02<00:00, 53.42it/s, Epoch: 78, Batch: 112,Loss: -2.109,Avg.Loss: -3.247,LR: 5.74E-05]Training epoch 78: 100%|██████████| 112/112 [00:02<00:00, 53.10it/s, Epoch: 78, Batch: 112,Loss: -2.109,Avg.Loss: -3.247,LR: 5.74E-05]
Training epoch 79:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 79:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 79, Batch: 1,Loss: -3.286,Avg.Loss: -3.286,LR: 5.73E-05]Training epoch 79:   1%|          | 1/112 [00:00<00:04, 24.62it/s, Epoch: 79, Batch: 2,Loss: -3.359,Avg.Loss: -3.323,LR: 5.73E-05]Training epoch 79:   2%|▏         | 2/112 [00:00<00:02, 37.23it/s, Epoch: 79, Batch: 3,Loss: -3.580,Avg.Loss: -3.408,LR: 5.72E-05]Training epoch 79:   3%|▎         | 3/112 [00:00<00:02, 42.63it/s, Epoch: 79, Batch: 4,Loss: -3.573,Avg.Loss: -3.450,LR: 5.72E-05]Training epoch 79:   4%|▎         | 4/112 [00:00<00:02, 45.66it/s, Epoch: 79, Batch: 5,Loss: -3.016,Avg.Loss: -3.363,LR: 5.71E-05]Training epoch 79:   4%|▍         | 5/112 [00:00<00:02, 47.11it/s, Epoch: 79, Batch: 6,Loss: -2.750,Avg.Loss: -3.261,LR: 5.71E-05]Training epoch 79:   5%|▌         | 6/112 [00:00<00:01, 56.44it/s, Epoch: 79, Batch: 6,Loss: -2.750,Avg.Loss: -3.261,LR: 5.71E-05]Training epoch 79:   5%|▌         | 6/112 [00:00<00:01, 56.44it/s, Epoch: 79, Batch: 7,Loss: -2.722,Avg.Loss: -3.184,LR: 5.71E-05]Training epoch 79:   6%|▋         | 7/112 [00:00<00:01, 56.44it/s, Epoch: 79, Batch: 8,Loss: -2.423,Avg.Loss: -3.089,LR: 5.70E-05]Training epoch 79:   7%|▋         | 8/112 [00:00<00:01, 56.44it/s, Epoch: 79, Batch: 9,Loss: -3.727,Avg.Loss: -3.160,LR: 5.70E-05]Training epoch 79:   8%|▊         | 9/112 [00:00<00:01, 56.44it/s, Epoch: 79, Batch: 10,Loss: -3.471,Avg.Loss: -3.191,LR: 5.69E-05]Training epoch 79:   9%|▉         | 10/112 [00:00<00:01, 56.44it/s, Epoch: 79, Batch: 11,Loss: -2.695,Avg.Loss: -3.146,LR: 5.69E-05]Training epoch 79:  10%|▉         | 11/112 [00:00<00:01, 56.44it/s, Epoch: 79, Batch: 12,Loss: -3.515,Avg.Loss: -3.177,LR: 5.68E-05]Training epoch 79:  11%|█         | 12/112 [00:00<00:01, 55.11it/s, Epoch: 79, Batch: 12,Loss: -3.515,Avg.Loss: -3.177,LR: 5.68E-05]Training epoch 79:  11%|█         | 12/112 [00:00<00:01, 55.11it/s, Epoch: 79, Batch: 13,Loss: -3.440,Avg.Loss: -3.197,LR: 5.68E-05]Training epoch 79:  12%|█▏        | 13/112 [00:00<00:01, 55.11it/s, Epoch: 79, Batch: 14,Loss: -3.388,Avg.Loss: -3.210,LR: 5.67E-05]Training epoch 79:  12%|█▎        | 14/112 [00:00<00:01, 55.11it/s, Epoch: 79, Batch: 15,Loss: -2.938,Avg.Loss: -3.192,LR: 5.67E-05]Training epoch 79:  13%|█▎        | 15/112 [00:00<00:01, 55.11it/s, Epoch: 79, Batch: 16,Loss: -3.579,Avg.Loss: -3.216,LR: 5.67E-05]Training epoch 79:  14%|█▍        | 16/112 [00:00<00:01, 55.11it/s, Epoch: 79, Batch: 17,Loss: -3.362,Avg.Loss: -3.225,LR: 5.66E-05]Training epoch 79:  15%|█▌        | 17/112 [00:00<00:01, 55.11it/s, Epoch: 79, Batch: 18,Loss: -2.864,Avg.Loss: -3.205,LR: 5.66E-05]Training epoch 79:  16%|█▌        | 18/112 [00:00<00:01, 54.97it/s, Epoch: 79, Batch: 18,Loss: -2.864,Avg.Loss: -3.205,LR: 5.66E-05]Training epoch 79:  16%|█▌        | 18/112 [00:00<00:01, 54.97it/s, Epoch: 79, Batch: 19,Loss: -2.839,Avg.Loss: -3.186,LR: 5.65E-05]Training epoch 79:  17%|█▋        | 19/112 [00:00<00:01, 54.97it/s, Epoch: 79, Batch: 20,Loss: -3.571,Avg.Loss: -3.205,LR: 5.65E-05]Training epoch 79:  18%|█▊        | 20/112 [00:00<00:01, 54.97it/s, Epoch: 79, Batch: 21,Loss: -3.036,Avg.Loss: -3.197,LR: 5.64E-05]Training epoch 79:  19%|█▉        | 21/112 [00:00<00:01, 54.97it/s, Epoch: 79, Batch: 22,Loss: -3.005,Avg.Loss: -3.188,LR: 5.64E-05]Training epoch 79:  20%|█▉        | 22/112 [00:00<00:01, 54.97it/s, Epoch: 79, Batch: 23,Loss: -3.204,Avg.Loss: -3.189,LR: 5.63E-05]Training epoch 79:  21%|██        | 23/112 [00:00<00:01, 54.97it/s, Epoch: 79, Batch: 24,Loss: -3.607,Avg.Loss: -3.206,LR: 5.63E-05]Training epoch 79:  21%|██▏       | 24/112 [00:00<00:01, 53.98it/s, Epoch: 79, Batch: 24,Loss: -3.607,Avg.Loss: -3.206,LR: 5.63E-05]Training epoch 79:  21%|██▏       | 24/112 [00:00<00:01, 53.98it/s, Epoch: 79, Batch: 25,Loss: -3.239,Avg.Loss: -3.208,LR: 5.63E-05]Training epoch 79:  22%|██▏       | 25/112 [00:00<00:01, 53.98it/s, Epoch: 79, Batch: 26,Loss: -2.951,Avg.Loss: -3.198,LR: 5.62E-05]Training epoch 79:  23%|██▎       | 26/112 [00:00<00:01, 53.98it/s, Epoch: 79, Batch: 27,Loss: -3.312,Avg.Loss: -3.202,LR: 5.62E-05]Training epoch 79:  24%|██▍       | 27/112 [00:00<00:01, 53.98it/s, Epoch: 79, Batch: 28,Loss: -2.841,Avg.Loss: -3.189,LR: 5.61E-05]Training epoch 79:  25%|██▌       | 28/112 [00:00<00:01, 53.98it/s, Epoch: 79, Batch: 29,Loss: -3.574,Avg.Loss: -3.202,LR: 5.61E-05]Training epoch 79:  26%|██▌       | 29/112 [00:00<00:01, 53.98it/s, Epoch: 79, Batch: 30,Loss: -3.080,Avg.Loss: -3.198,LR: 5.60E-05]Training epoch 79:  27%|██▋       | 30/112 [00:00<00:01, 53.42it/s, Epoch: 79, Batch: 30,Loss: -3.080,Avg.Loss: -3.198,LR: 5.60E-05]Training epoch 79:  27%|██▋       | 30/112 [00:00<00:01, 53.42it/s, Epoch: 79, Batch: 31,Loss: -3.162,Avg.Loss: -3.197,LR: 5.60E-05]Training epoch 79:  28%|██▊       | 31/112 [00:00<00:01, 53.42it/s, Epoch: 79, Batch: 32,Loss: -3.200,Avg.Loss: -3.197,LR: 5.59E-05]Training epoch 79:  29%|██▊       | 32/112 [00:00<00:01, 53.42it/s, Epoch: 79, Batch: 33,Loss: -3.902,Avg.Loss: -3.218,LR: 5.59E-05]Training epoch 79:  29%|██▉       | 33/112 [00:00<00:01, 53.42it/s, Epoch: 79, Batch: 34,Loss: -3.301,Avg.Loss: -3.221,LR: 5.59E-05]Training epoch 79:  30%|███       | 34/112 [00:00<00:01, 53.42it/s, Epoch: 79, Batch: 35,Loss: -3.013,Avg.Loss: -3.215,LR: 5.58E-05]Training epoch 79:  31%|███▏      | 35/112 [00:00<00:01, 53.42it/s, Epoch: 79, Batch: 36,Loss: -3.716,Avg.Loss: -3.229,LR: 5.58E-05]Training epoch 79:  32%|███▏      | 36/112 [00:00<00:01, 53.28it/s, Epoch: 79, Batch: 36,Loss: -3.716,Avg.Loss: -3.229,LR: 5.58E-05]Training epoch 79:  32%|███▏      | 36/112 [00:00<00:01, 53.28it/s, Epoch: 79, Batch: 37,Loss: -3.700,Avg.Loss: -3.242,LR: 5.57E-05]Training epoch 79:  33%|███▎      | 37/112 [00:00<00:01, 53.28it/s, Epoch: 79, Batch: 38,Loss: -3.344,Avg.Loss: -3.244,LR: 5.57E-05]Training epoch 79:  34%|███▍      | 38/112 [00:00<00:01, 53.28it/s, Epoch: 79, Batch: 39,Loss: -3.217,Avg.Loss: -3.244,LR: 5.56E-05]Training epoch 79:  35%|███▍      | 39/112 [00:00<00:01, 53.28it/s, Epoch: 79, Batch: 40,Loss: -3.670,Avg.Loss: -3.254,LR: 5.56E-05]Training epoch 79:  36%|███▌      | 40/112 [00:00<00:01, 53.28it/s, Epoch: 79, Batch: 41,Loss: -3.349,Avg.Loss: -3.257,LR: 5.56E-05]Training epoch 79:  37%|███▋      | 41/112 [00:00<00:01, 53.28it/s, Epoch: 79, Batch: 42,Loss: -2.902,Avg.Loss: -3.248,LR: 5.55E-05]Training epoch 79:  38%|███▊      | 42/112 [00:00<00:01, 53.35it/s, Epoch: 79, Batch: 42,Loss: -2.902,Avg.Loss: -3.248,LR: 5.55E-05]Training epoch 79:  38%|███▊      | 42/112 [00:00<00:01, 53.35it/s, Epoch: 79, Batch: 43,Loss: -2.997,Avg.Loss: -3.242,LR: 5.55E-05]Training epoch 79:  38%|███▊      | 43/112 [00:00<00:01, 53.35it/s, Epoch: 79, Batch: 44,Loss: -3.242,Avg.Loss: -3.242,LR: 5.54E-05]Training epoch 79:  39%|███▉      | 44/112 [00:00<00:01, 53.35it/s, Epoch: 79, Batch: 45,Loss: -2.967,Avg.Loss: -3.236,LR: 5.54E-05]Training epoch 79:  40%|████      | 45/112 [00:00<00:01, 53.35it/s, Epoch: 79, Batch: 46,Loss: -2.560,Avg.Loss: -3.222,LR: 5.53E-05]Training epoch 79:  41%|████      | 46/112 [00:00<00:01, 53.35it/s, Epoch: 79, Batch: 47,Loss: -2.870,Avg.Loss: -3.214,LR: 5.53E-05]Training epoch 79:  42%|████▏     | 47/112 [00:00<00:01, 53.35it/s, Epoch: 79, Batch: 48,Loss: -3.512,Avg.Loss: -3.220,LR: 5.52E-05]Training epoch 79:  43%|████▎     | 48/112 [00:00<00:01, 53.17it/s, Epoch: 79, Batch: 48,Loss: -3.512,Avg.Loss: -3.220,LR: 5.52E-05]Training epoch 79:  43%|████▎     | 48/112 [00:00<00:01, 53.17it/s, Epoch: 79, Batch: 49,Loss: -3.567,Avg.Loss: -3.227,LR: 5.52E-05]Training epoch 79:  44%|████▍     | 49/112 [00:00<00:01, 53.17it/s, Epoch: 79, Batch: 50,Loss: -3.337,Avg.Loss: -3.230,LR: 5.52E-05]Training epoch 79:  45%|████▍     | 50/112 [00:00<00:01, 53.17it/s, Epoch: 79, Batch: 51,Loss: -3.280,Avg.Loss: -3.231,LR: 5.51E-05]Training epoch 79:  46%|████▌     | 51/112 [00:00<00:01, 53.17it/s, Epoch: 79, Batch: 52,Loss: -3.835,Avg.Loss: -3.242,LR: 5.51E-05]Training epoch 79:  46%|████▋     | 52/112 [00:00<00:01, 53.17it/s, Epoch: 79, Batch: 53,Loss: -3.813,Avg.Loss: -3.253,LR: 5.50E-05]Training epoch 79:  47%|████▋     | 53/112 [00:01<00:01, 53.17it/s, Epoch: 79, Batch: 54,Loss: -3.615,Avg.Loss: -3.260,LR: 5.50E-05]Training epoch 79:  48%|████▊     | 54/112 [00:01<00:01, 52.93it/s, Epoch: 79, Batch: 54,Loss: -3.615,Avg.Loss: -3.260,LR: 5.50E-05]Training epoch 79:  48%|████▊     | 54/112 [00:01<00:01, 52.93it/s, Epoch: 79, Batch: 55,Loss: -3.285,Avg.Loss: -3.260,LR: 5.49E-05]Training epoch 79:  49%|████▉     | 55/112 [00:01<00:01, 52.93it/s, Epoch: 79, Batch: 56,Loss: -3.594,Avg.Loss: -3.266,LR: 5.49E-05]Training epoch 79:  50%|█████     | 56/112 [00:01<00:01, 52.93it/s, Epoch: 79, Batch: 57,Loss: -3.478,Avg.Loss: -3.270,LR: 5.48E-05]Training epoch 79:  51%|█████     | 57/112 [00:01<00:01, 52.93it/s, Epoch: 79, Batch: 58,Loss: -3.402,Avg.Loss: -3.272,LR: 5.48E-05]Training epoch 79:  52%|█████▏    | 58/112 [00:01<00:01, 52.93it/s, Epoch: 79, Batch: 59,Loss: -2.948,Avg.Loss: -3.267,LR: 5.48E-05]Training epoch 79:  53%|█████▎    | 59/112 [00:01<00:01, 52.93it/s, Epoch: 79, Batch: 60,Loss: -3.433,Avg.Loss: -3.269,LR: 5.47E-05]Training epoch 79:  54%|█████▎    | 60/112 [00:01<00:00, 52.97it/s, Epoch: 79, Batch: 60,Loss: -3.433,Avg.Loss: -3.269,LR: 5.47E-05]Training epoch 79:  54%|█████▎    | 60/112 [00:01<00:00, 52.97it/s, Epoch: 79, Batch: 61,Loss: -3.338,Avg.Loss: -3.270,LR: 5.47E-05]Training epoch 79:  54%|█████▍    | 61/112 [00:01<00:00, 52.97it/s, Epoch: 79, Batch: 62,Loss: -3.013,Avg.Loss: -3.266,LR: 5.46E-05]Training epoch 79:  55%|█████▌    | 62/112 [00:01<00:00, 52.97it/s, Epoch: 79, Batch: 63,Loss: -2.879,Avg.Loss: -3.260,LR: 5.46E-05]Training epoch 79:  56%|█████▋    | 63/112 [00:01<00:00, 52.97it/s, Epoch: 79, Batch: 64,Loss: -3.492,Avg.Loss: -3.264,LR: 5.45E-05]Training epoch 79:  57%|█████▋    | 64/112 [00:01<00:00, 52.97it/s, Epoch: 79, Batch: 65,Loss: -2.756,Avg.Loss: -3.256,LR: 5.45E-05]Training epoch 79:  58%|█████▊    | 65/112 [00:01<00:00, 52.97it/s, Epoch: 79, Batch: 66,Loss: -2.616,Avg.Loss: -3.246,LR: 5.45E-05]Training epoch 79:  59%|█████▉    | 66/112 [00:01<00:00, 52.83it/s, Epoch: 79, Batch: 66,Loss: -2.616,Avg.Loss: -3.246,LR: 5.45E-05]Training epoch 79:  59%|█████▉    | 66/112 [00:01<00:00, 52.83it/s, Epoch: 79, Batch: 67,Loss: -3.190,Avg.Loss: -3.245,LR: 5.44E-05]Training epoch 79:  60%|█████▉    | 67/112 [00:01<00:00, 52.83it/s, Epoch: 79, Batch: 68,Loss: -3.282,Avg.Loss: -3.246,LR: 5.44E-05]Training epoch 79:  61%|██████    | 68/112 [00:01<00:00, 52.83it/s, Epoch: 79, Batch: 69,Loss: -3.711,Avg.Loss: -3.253,LR: 5.43E-05]Training epoch 79:  62%|██████▏   | 69/112 [00:01<00:00, 52.83it/s, Epoch: 79, Batch: 70,Loss: -3.556,Avg.Loss: -3.257,LR: 5.43E-05]Training epoch 79:  62%|██████▎   | 70/112 [00:01<00:00, 52.83it/s, Epoch: 79, Batch: 71,Loss: -3.094,Avg.Loss: -3.255,LR: 5.42E-05]Training epoch 79:  63%|██████▎   | 71/112 [00:01<00:00, 52.83it/s, Epoch: 79, Batch: 72,Loss: -3.611,Avg.Loss: -3.260,LR: 5.42E-05]Training epoch 79:  64%|██████▍   | 72/112 [00:01<00:00, 52.66it/s, Epoch: 79, Batch: 72,Loss: -3.611,Avg.Loss: -3.260,LR: 5.42E-05]Training epoch 79:  64%|██████▍   | 72/112 [00:01<00:00, 52.66it/s, Epoch: 79, Batch: 73,Loss: -3.538,Avg.Loss: -3.263,LR: 5.41E-05]Training epoch 79:  65%|██████▌   | 73/112 [00:01<00:00, 52.66it/s, Epoch: 79, Batch: 74,Loss: -3.212,Avg.Loss: -3.263,LR: 5.41E-05]Training epoch 79:  66%|██████▌   | 74/112 [00:01<00:00, 52.66it/s, Epoch: 79, Batch: 75,Loss: -2.988,Avg.Loss: -3.259,LR: 5.41E-05]Training epoch 79:  67%|██████▋   | 75/112 [00:01<00:00, 52.66it/s, Epoch: 79, Batch: 76,Loss: -3.404,Avg.Loss: -3.261,LR: 5.40E-05]Training epoch 79:  68%|██████▊   | 76/112 [00:01<00:00, 52.66it/s, Epoch: 79, Batch: 77,Loss: -3.064,Avg.Loss: -3.258,LR: 5.40E-05]Training epoch 79:  69%|██████▉   | 77/112 [00:01<00:00, 52.66it/s, Epoch: 79, Batch: 78,Loss: -3.294,Avg.Loss: -3.259,LR: 5.39E-05]Training epoch 79:  70%|██████▉   | 78/112 [00:01<00:00, 52.60it/s, Epoch: 79, Batch: 78,Loss: -3.294,Avg.Loss: -3.259,LR: 5.39E-05]Training epoch 79:  70%|██████▉   | 78/112 [00:01<00:00, 52.60it/s, Epoch: 79, Batch: 79,Loss: -3.435,Avg.Loss: -3.261,LR: 5.39E-05]Training epoch 79:  71%|███████   | 79/112 [00:01<00:00, 52.60it/s, Epoch: 79, Batch: 80,Loss: -3.502,Avg.Loss: -3.264,LR: 5.38E-05]Training epoch 79:  71%|███████▏  | 80/112 [00:01<00:00, 52.60it/s, Epoch: 79, Batch: 81,Loss: -3.757,Avg.Loss: -3.270,LR: 5.38E-05]Training epoch 79:  72%|███████▏  | 81/112 [00:01<00:00, 52.60it/s, Epoch: 79, Batch: 82,Loss: -3.559,Avg.Loss: -3.274,LR: 5.38E-05]Training epoch 79:  73%|███████▎  | 82/112 [00:01<00:00, 52.60it/s, Epoch: 79, Batch: 83,Loss: -3.733,Avg.Loss: -3.279,LR: 5.37E-05]Training epoch 79:  74%|███████▍  | 83/112 [00:01<00:00, 52.60it/s, Epoch: 79, Batch: 84,Loss: -3.671,Avg.Loss: -3.284,LR: 5.37E-05]Training epoch 79:  75%|███████▌  | 84/112 [00:01<00:00, 53.40it/s, Epoch: 79, Batch: 84,Loss: -3.671,Avg.Loss: -3.284,LR: 5.37E-05]Training epoch 79:  75%|███████▌  | 84/112 [00:01<00:00, 53.40it/s, Epoch: 79, Batch: 85,Loss: -3.325,Avg.Loss: -3.284,LR: 5.36E-05]Training epoch 79:  76%|███████▌  | 85/112 [00:01<00:00, 53.40it/s, Epoch: 79, Batch: 86,Loss: -3.171,Avg.Loss: -3.283,LR: 5.36E-05]Training epoch 79:  77%|███████▋  | 86/112 [00:01<00:00, 53.40it/s, Epoch: 79, Batch: 87,Loss: -3.431,Avg.Loss: -3.285,LR: 5.35E-05]Training epoch 79:  78%|███████▊  | 87/112 [00:01<00:00, 53.40it/s, Epoch: 79, Batch: 88,Loss: -3.121,Avg.Loss: -3.283,LR: 5.35E-05]Training epoch 79:  79%|███████▊  | 88/112 [00:01<00:00, 53.40it/s, Epoch: 79, Batch: 89,Loss: -3.641,Avg.Loss: -3.287,LR: 5.35E-05]Training epoch 79:  79%|███████▉  | 89/112 [00:01<00:00, 53.40it/s, Epoch: 79, Batch: 90,Loss: -3.002,Avg.Loss: -3.284,LR: 5.34E-05]Training epoch 79:  80%|████████  | 90/112 [00:01<00:00, 53.64it/s, Epoch: 79, Batch: 90,Loss: -3.002,Avg.Loss: -3.284,LR: 5.34E-05]Training epoch 79:  80%|████████  | 90/112 [00:01<00:00, 53.64it/s, Epoch: 79, Batch: 91,Loss: -2.629,Avg.Loss: -3.277,LR: 5.34E-05]Training epoch 79:  81%|████████▏ | 91/112 [00:01<00:00, 53.64it/s, Epoch: 79, Batch: 92,Loss: -2.298,Avg.Loss: -3.266,LR: 5.33E-05]Training epoch 79:  82%|████████▏ | 92/112 [00:01<00:00, 53.64it/s, Epoch: 79, Batch: 93,Loss: -2.546,Avg.Loss: -3.258,LR: 5.33E-05]Training epoch 79:  83%|████████▎ | 93/112 [00:01<00:00, 53.64it/s, Epoch: 79, Batch: 94,Loss: -2.441,Avg.Loss: -3.250,LR: 5.32E-05]Training epoch 79:  84%|████████▍ | 94/112 [00:01<00:00, 53.64it/s, Epoch: 79, Batch: 95,Loss: -2.821,Avg.Loss: -3.245,LR: 5.32E-05]Training epoch 79:  85%|████████▍ | 95/112 [00:01<00:00, 53.64it/s, Epoch: 79, Batch: 96,Loss: -3.577,Avg.Loss: -3.249,LR: 5.32E-05]Training epoch 79:  86%|████████▌ | 96/112 [00:01<00:00, 53.98it/s, Epoch: 79, Batch: 96,Loss: -3.577,Avg.Loss: -3.249,LR: 5.32E-05]Training epoch 79:  86%|████████▌ | 96/112 [00:01<00:00, 53.98it/s, Epoch: 79, Batch: 97,Loss: -2.987,Avg.Loss: -3.246,LR: 5.31E-05]Training epoch 79:  87%|████████▋ | 97/112 [00:01<00:00, 53.98it/s, Epoch: 79, Batch: 98,Loss: -2.980,Avg.Loss: -3.243,LR: 5.31E-05]Training epoch 79:  88%|████████▊ | 98/112 [00:01<00:00, 53.98it/s, Epoch: 79, Batch: 99,Loss: -3.178,Avg.Loss: -3.242,LR: 5.30E-05]Training epoch 79:  88%|████████▊ | 99/112 [00:01<00:00, 53.98it/s, Epoch: 79, Batch: 100,Loss: -3.295,Avg.Loss: -3.243,LR: 5.30E-05]Training epoch 79:  89%|████████▉ | 100/112 [00:01<00:00, 53.98it/s, Epoch: 79, Batch: 101,Loss: -3.111,Avg.Loss: -3.242,LR: 5.29E-05]Training epoch 79:  90%|█████████ | 101/112 [00:01<00:00, 53.98it/s, Epoch: 79, Batch: 102,Loss: -2.963,Avg.Loss: -3.239,LR: 5.29E-05]Training epoch 79:  91%|█████████ | 102/112 [00:01<00:00, 53.83it/s, Epoch: 79, Batch: 102,Loss: -2.963,Avg.Loss: -3.239,LR: 5.29E-05]Training epoch 79:  91%|█████████ | 102/112 [00:01<00:00, 53.83it/s, Epoch: 79, Batch: 103,Loss: -2.744,Avg.Loss: -3.234,LR: 5.28E-05]Training epoch 79:  92%|█████████▏| 103/112 [00:01<00:00, 53.83it/s, Epoch: 79, Batch: 104,Loss: -3.193,Avg.Loss: -3.234,LR: 5.28E-05]Training epoch 79:  93%|█████████▎| 104/112 [00:01<00:00, 53.83it/s, Epoch: 79, Batch: 105,Loss: -3.295,Avg.Loss: -3.234,LR: 5.28E-05]Training epoch 79:  94%|█████████▍| 105/112 [00:01<00:00, 53.83it/s, Epoch: 79, Batch: 106,Loss: -3.369,Avg.Loss: -3.236,LR: 5.27E-05]Training epoch 79:  95%|█████████▍| 106/112 [00:01<00:00, 53.83it/s, Epoch: 79, Batch: 107,Loss: -3.163,Avg.Loss: -3.235,LR: 5.27E-05]Training epoch 79:  96%|█████████▌| 107/112 [00:02<00:00, 53.83it/s, Epoch: 79, Batch: 108,Loss: -3.507,Avg.Loss: -3.237,LR: 5.26E-05]Training epoch 79:  96%|█████████▋| 108/112 [00:02<00:00, 53.85it/s, Epoch: 79, Batch: 108,Loss: -3.507,Avg.Loss: -3.237,LR: 5.26E-05]Training epoch 79:  96%|█████████▋| 108/112 [00:02<00:00, 53.85it/s, Epoch: 79, Batch: 109,Loss: -2.399,Avg.Loss: -3.230,LR: 5.26E-05]Training epoch 79:  97%|█████████▋| 109/112 [00:02<00:00, 53.85it/s, Epoch: 79, Batch: 110,Loss: -2.780,Avg.Loss: -3.226,LR: 5.25E-05]Training epoch 79:  98%|█████████▊| 110/112 [00:02<00:00, 53.85it/s, Epoch: 79, Batch: 111,Loss: -2.733,Avg.Loss: -3.221,LR: 5.25E-05]Training epoch 79:  99%|█████████▉| 111/112 [00:02<00:00, 53.85it/s, Epoch: 79, Batch: 112,Loss: -4.195,Avg.Loss: -3.230,LR: 5.25E-05]Training epoch 79: 100%|██████████| 112/112 [00:02<00:00, 53.46it/s, Epoch: 79, Batch: 112,Loss: -4.195,Avg.Loss: -3.230,LR: 5.25E-05]
Training epoch 80:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 80:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 80, Batch: 1,Loss: -3.120,Avg.Loss: -3.120,LR: 5.24E-05]Training epoch 80:   1%|          | 1/112 [00:00<00:03, 28.87it/s, Epoch: 80, Batch: 2,Loss: -3.425,Avg.Loss: -3.273,LR: 5.24E-05]Training epoch 80:   2%|▏         | 2/112 [00:00<00:02, 41.48it/s, Epoch: 80, Batch: 3,Loss: -3.562,Avg.Loss: -3.369,LR: 5.23E-05]Training epoch 80:   3%|▎         | 3/112 [00:00<00:02, 49.21it/s, Epoch: 80, Batch: 4,Loss: -3.542,Avg.Loss: -3.412,LR: 5.23E-05]Training epoch 80:   4%|▎         | 4/112 [00:00<00:02, 51.02it/s, Epoch: 80, Batch: 5,Loss: -3.480,Avg.Loss: -3.426,LR: 5.22E-05]Training epoch 80:   4%|▍         | 5/112 [00:00<00:01, 54.27it/s, Epoch: 80, Batch: 6,Loss: -3.665,Avg.Loss: -3.466,LR: 5.22E-05]Training epoch 80:   5%|▌         | 6/112 [00:00<00:01, 54.71it/s, Epoch: 80, Batch: 7,Loss: -3.285,Avg.Loss: -3.440,LR: 5.22E-05]Training epoch 80:   6%|▋         | 7/112 [00:00<00:01, 63.72it/s, Epoch: 80, Batch: 7,Loss: -3.285,Avg.Loss: -3.440,LR: 5.22E-05]Training epoch 80:   6%|▋         | 7/112 [00:00<00:01, 63.72it/s, Epoch: 80, Batch: 8,Loss: -3.339,Avg.Loss: -3.427,LR: 5.21E-05]Training epoch 80:   7%|▋         | 8/112 [00:00<00:01, 63.72it/s, Epoch: 80, Batch: 9,Loss: -3.345,Avg.Loss: -3.418,LR: 5.21E-05]Training epoch 80:   8%|▊         | 9/112 [00:00<00:01, 63.72it/s, Epoch: 80, Batch: 10,Loss: -3.181,Avg.Loss: -3.394,LR: 5.20E-05]Training epoch 80:   9%|▉         | 10/112 [00:00<00:01, 63.72it/s, Epoch: 80, Batch: 11,Loss: -3.262,Avg.Loss: -3.382,LR: 5.20E-05]Training epoch 80:  10%|▉         | 11/112 [00:00<00:01, 63.72it/s, Epoch: 80, Batch: 12,Loss: -3.376,Avg.Loss: -3.382,LR: 5.19E-05]Training epoch 80:  11%|█         | 12/112 [00:00<00:01, 63.72it/s, Epoch: 80, Batch: 13,Loss: -3.255,Avg.Loss: -3.372,LR: 5.19E-05]Training epoch 80:  12%|█▏        | 13/112 [00:00<00:01, 63.72it/s, Epoch: 80, Batch: 14,Loss: -3.454,Avg.Loss: -3.378,LR: 5.19E-05]Training epoch 80:  12%|█▎        | 14/112 [00:00<00:01, 57.01it/s, Epoch: 80, Batch: 14,Loss: -3.454,Avg.Loss: -3.378,LR: 5.19E-05]Training epoch 80:  12%|█▎        | 14/112 [00:00<00:01, 57.01it/s, Epoch: 80, Batch: 15,Loss: -3.282,Avg.Loss: -3.372,LR: 5.18E-05]Training epoch 80:  13%|█▎        | 15/112 [00:00<00:01, 57.01it/s, Epoch: 80, Batch: 16,Loss: -3.769,Avg.Loss: -3.396,LR: 5.18E-05]Training epoch 80:  14%|█▍        | 16/112 [00:00<00:01, 57.01it/s, Epoch: 80, Batch: 17,Loss: -3.247,Avg.Loss: -3.388,LR: 5.17E-05]Training epoch 80:  15%|█▌        | 17/112 [00:00<00:01, 57.01it/s, Epoch: 80, Batch: 18,Loss: -3.334,Avg.Loss: -3.385,LR: 5.17E-05]Training epoch 80:  16%|█▌        | 18/112 [00:00<00:01, 57.01it/s, Epoch: 80, Batch: 19,Loss: -3.008,Avg.Loss: -3.365,LR: 5.16E-05]Training epoch 80:  17%|█▋        | 19/112 [00:00<00:01, 57.01it/s, Epoch: 80, Batch: 20,Loss: -3.181,Avg.Loss: -3.356,LR: 5.16E-05]Training epoch 80:  18%|█▊        | 20/112 [00:00<00:01, 55.71it/s, Epoch: 80, Batch: 20,Loss: -3.181,Avg.Loss: -3.356,LR: 5.16E-05]Training epoch 80:  18%|█▊        | 20/112 [00:00<00:01, 55.71it/s, Epoch: 80, Batch: 21,Loss: -3.283,Avg.Loss: -3.352,LR: 5.16E-05]Training epoch 80:  19%|█▉        | 21/112 [00:00<00:01, 55.71it/s, Epoch: 80, Batch: 22,Loss: -3.187,Avg.Loss: -3.345,LR: 5.15E-05]Training epoch 80:  20%|█▉        | 22/112 [00:00<00:01, 55.71it/s, Epoch: 80, Batch: 23,Loss: -3.389,Avg.Loss: -3.347,LR: 5.15E-05]Training epoch 80:  21%|██        | 23/112 [00:00<00:01, 55.71it/s, Epoch: 80, Batch: 24,Loss: -3.420,Avg.Loss: -3.350,LR: 5.14E-05]Training epoch 80:  21%|██▏       | 24/112 [00:00<00:01, 55.71it/s, Epoch: 80, Batch: 25,Loss: -3.743,Avg.Loss: -3.365,LR: 5.14E-05]Training epoch 80:  22%|██▏       | 25/112 [00:00<00:01, 55.71it/s, Epoch: 80, Batch: 26,Loss: -3.237,Avg.Loss: -3.360,LR: 5.13E-05]Training epoch 80:  23%|██▎       | 26/112 [00:00<00:01, 54.26it/s, Epoch: 80, Batch: 26,Loss: -3.237,Avg.Loss: -3.360,LR: 5.13E-05]Training epoch 80:  23%|██▎       | 26/112 [00:00<00:01, 54.26it/s, Epoch: 80, Batch: 27,Loss: -3.710,Avg.Loss: -3.373,LR: 5.13E-05]Training epoch 80:  24%|██▍       | 27/112 [00:00<00:01, 54.26it/s, Epoch: 80, Batch: 28,Loss: -3.489,Avg.Loss: -3.377,LR: 5.13E-05]Training epoch 80:  25%|██▌       | 28/112 [00:00<00:01, 54.26it/s, Epoch: 80, Batch: 29,Loss: -3.334,Avg.Loss: -3.376,LR: 5.12E-05]Training epoch 80:  26%|██▌       | 29/112 [00:00<00:01, 54.26it/s, Epoch: 80, Batch: 30,Loss: -3.536,Avg.Loss: -3.381,LR: 5.12E-05]Training epoch 80:  27%|██▋       | 30/112 [00:00<00:01, 54.26it/s, Epoch: 80, Batch: 31,Loss: -3.389,Avg.Loss: -3.382,LR: 5.11E-05]Training epoch 80:  28%|██▊       | 31/112 [00:00<00:01, 54.26it/s, Epoch: 80, Batch: 32,Loss: -3.645,Avg.Loss: -3.390,LR: 5.11E-05]Training epoch 80:  29%|██▊       | 32/112 [00:00<00:01, 53.56it/s, Epoch: 80, Batch: 32,Loss: -3.645,Avg.Loss: -3.390,LR: 5.11E-05]Training epoch 80:  29%|██▊       | 32/112 [00:00<00:01, 53.56it/s, Epoch: 80, Batch: 33,Loss: -3.438,Avg.Loss: -3.391,LR: 5.11E-05]Training epoch 80:  29%|██▉       | 33/112 [00:00<00:01, 53.56it/s, Epoch: 80, Batch: 34,Loss: -3.864,Avg.Loss: -3.405,LR: 5.10E-05]Training epoch 80:  30%|███       | 34/112 [00:00<00:01, 53.56it/s, Epoch: 80, Batch: 35,Loss: -3.189,Avg.Loss: -3.399,LR: 5.10E-05]Training epoch 80:  31%|███▏      | 35/112 [00:00<00:01, 53.56it/s, Epoch: 80, Batch: 36,Loss: -3.398,Avg.Loss: -3.399,LR: 5.09E-05]Training epoch 80:  32%|███▏      | 36/112 [00:00<00:01, 53.56it/s, Epoch: 80, Batch: 37,Loss: -3.330,Avg.Loss: -3.397,LR: 5.09E-05]Training epoch 80:  33%|███▎      | 37/112 [00:00<00:01, 53.56it/s, Epoch: 80, Batch: 38,Loss: -3.214,Avg.Loss: -3.392,LR: 5.08E-05]Training epoch 80:  34%|███▍      | 38/112 [00:00<00:01, 53.40it/s, Epoch: 80, Batch: 38,Loss: -3.214,Avg.Loss: -3.392,LR: 5.08E-05]Training epoch 80:  34%|███▍      | 38/112 [00:00<00:01, 53.40it/s, Epoch: 80, Batch: 39,Loss: -3.275,Avg.Loss: -3.389,LR: 5.08E-05]Training epoch 80:  35%|███▍      | 39/112 [00:00<00:01, 53.40it/s, Epoch: 80, Batch: 40,Loss: -3.743,Avg.Loss: -3.398,LR: 5.08E-05]Training epoch 80:  36%|███▌      | 40/112 [00:00<00:01, 53.40it/s, Epoch: 80, Batch: 41,Loss: -3.347,Avg.Loss: -3.397,LR: 5.07E-05]Training epoch 80:  37%|███▋      | 41/112 [00:00<00:01, 53.40it/s, Epoch: 80, Batch: 42,Loss: -3.604,Avg.Loss: -3.402,LR: 5.07E-05]Training epoch 80:  38%|███▊      | 42/112 [00:00<00:01, 53.40it/s, Epoch: 80, Batch: 43,Loss: -3.245,Avg.Loss: -3.398,LR: 5.06E-05]Training epoch 80:  38%|███▊      | 43/112 [00:00<00:01, 53.40it/s, Epoch: 80, Batch: 44,Loss: -3.227,Avg.Loss: -3.394,LR: 5.06E-05]Training epoch 80:  39%|███▉      | 44/112 [00:00<00:01, 53.32it/s, Epoch: 80, Batch: 44,Loss: -3.227,Avg.Loss: -3.394,LR: 5.06E-05]Training epoch 80:  39%|███▉      | 44/112 [00:00<00:01, 53.32it/s, Epoch: 80, Batch: 45,Loss: -3.307,Avg.Loss: -3.392,LR: 5.05E-05]Training epoch 80:  40%|████      | 45/112 [00:00<00:01, 53.32it/s, Epoch: 80, Batch: 46,Loss: -3.669,Avg.Loss: -3.398,LR: 5.05E-05]Training epoch 80:  41%|████      | 46/112 [00:00<00:01, 53.32it/s, Epoch: 80, Batch: 47,Loss: -3.551,Avg.Loss: -3.402,LR: 5.05E-05]Training epoch 80:  42%|████▏     | 47/112 [00:00<00:01, 53.32it/s, Epoch: 80, Batch: 48,Loss: -3.616,Avg.Loss: -3.406,LR: 5.04E-05]Training epoch 80:  43%|████▎     | 48/112 [00:00<00:01, 53.32it/s, Epoch: 80, Batch: 49,Loss: -3.090,Avg.Loss: -3.400,LR: 5.04E-05]Training epoch 80:  44%|████▍     | 49/112 [00:00<00:01, 53.32it/s, Epoch: 80, Batch: 50,Loss: -3.181,Avg.Loss: -3.395,LR: 5.03E-05]Training epoch 80:  45%|████▍     | 50/112 [00:00<00:01, 53.44it/s, Epoch: 80, Batch: 50,Loss: -3.181,Avg.Loss: -3.395,LR: 5.03E-05]Training epoch 80:  45%|████▍     | 50/112 [00:00<00:01, 53.44it/s, Epoch: 80, Batch: 51,Loss: -2.670,Avg.Loss: -3.381,LR: 5.03E-05]Training epoch 80:  46%|████▌     | 51/112 [00:00<00:01, 53.44it/s, Epoch: 80, Batch: 52,Loss: -3.180,Avg.Loss: -3.377,LR: 5.02E-05]Training epoch 80:  46%|████▋     | 52/112 [00:00<00:01, 53.44it/s, Epoch: 80, Batch: 53,Loss: -3.435,Avg.Loss: -3.378,LR: 5.02E-05]Training epoch 80:  47%|████▋     | 53/112 [00:00<00:01, 53.44it/s, Epoch: 80, Batch: 54,Loss: -3.030,Avg.Loss: -3.372,LR: 5.02E-05]Training epoch 80:  48%|████▊     | 54/112 [00:01<00:01, 53.44it/s, Epoch: 80, Batch: 55,Loss: -2.702,Avg.Loss: -3.360,LR: 5.01E-05]Training epoch 80:  49%|████▉     | 55/112 [00:01<00:01, 53.44it/s, Epoch: 80, Batch: 56,Loss: -3.096,Avg.Loss: -3.355,LR: 5.01E-05]Training epoch 80:  50%|█████     | 56/112 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 56,Loss: -3.096,Avg.Loss: -3.355,LR: 5.01E-05]Training epoch 80:  50%|█████     | 56/112 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 57,Loss: -3.606,Avg.Loss: -3.359,LR: 5.00E-05]Training epoch 80:  51%|█████     | 57/112 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 58,Loss: -3.244,Avg.Loss: -3.357,LR: 5.00E-05]Training epoch 80:  52%|█████▏    | 58/112 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 59,Loss: -2.936,Avg.Loss: -3.350,LR: 5.00E-05]Training epoch 80:  53%|█████▎    | 59/112 [00:01<00:00, 53.17it/s, Epoch: 80, Batch: 60,Loss: -2.855,Avg.Loss: -3.342,LR: 4.99E-05]Training epoch 80:  54%|█████▎    | 60/112 [00:01<00:00, 53.17it/s, Epoch: 80, Batch: 61,Loss: -2.950,Avg.Loss: -3.335,LR: 4.99E-05]Training epoch 80:  54%|█████▍    | 61/112 [00:01<00:00, 53.17it/s, Epoch: 80, Batch: 62,Loss: -2.922,Avg.Loss: -3.329,LR: 4.98E-05]Training epoch 80:  55%|█████▌    | 62/112 [00:01<00:00, 53.30it/s, Epoch: 80, Batch: 62,Loss: -2.922,Avg.Loss: -3.329,LR: 4.98E-05]Training epoch 80:  55%|█████▌    | 62/112 [00:01<00:00, 53.30it/s, Epoch: 80, Batch: 63,Loss: -2.743,Avg.Loss: -3.320,LR: 4.98E-05]Training epoch 80:  56%|█████▋    | 63/112 [00:01<00:00, 53.30it/s, Epoch: 80, Batch: 64,Loss: -3.057,Avg.Loss: -3.315,LR: 4.97E-05]Training epoch 80:  57%|█████▋    | 64/112 [00:01<00:00, 53.30it/s, Epoch: 80, Batch: 65,Loss: -3.347,Avg.Loss: -3.316,LR: 4.97E-05]Training epoch 80:  58%|█████▊    | 65/112 [00:01<00:00, 53.30it/s, Epoch: 80, Batch: 66,Loss: -3.238,Avg.Loss: -3.315,LR: 4.97E-05]Training epoch 80:  59%|█████▉    | 66/112 [00:01<00:00, 53.30it/s, Epoch: 80, Batch: 67,Loss: -2.838,Avg.Loss: -3.308,LR: 4.96E-05]Training epoch 80:  60%|█████▉    | 67/112 [00:01<00:00, 53.30it/s, Epoch: 80, Batch: 68,Loss: -2.816,Avg.Loss: -3.300,LR: 4.96E-05]Training epoch 80:  61%|██████    | 68/112 [00:01<00:00, 53.29it/s, Epoch: 80, Batch: 68,Loss: -2.816,Avg.Loss: -3.300,LR: 4.96E-05]Training epoch 80:  61%|██████    | 68/112 [00:01<00:00, 53.29it/s, Epoch: 80, Batch: 69,Loss: -3.837,Avg.Loss: -3.308,LR: 4.95E-05]Training epoch 80:  62%|██████▏   | 69/112 [00:01<00:00, 53.29it/s, Epoch: 80, Batch: 70,Loss: -2.897,Avg.Loss: -3.302,LR: 4.95E-05]Training epoch 80:  62%|██████▎   | 70/112 [00:01<00:00, 53.29it/s, Epoch: 80, Batch: 71,Loss: -2.823,Avg.Loss: -3.296,LR: 4.94E-05]Training epoch 80:  63%|██████▎   | 71/112 [00:01<00:00, 53.29it/s, Epoch: 80, Batch: 72,Loss: -2.641,Avg.Loss: -3.286,LR: 4.94E-05]Training epoch 80:  64%|██████▍   | 72/112 [00:01<00:00, 53.29it/s, Epoch: 80, Batch: 73,Loss: -2.877,Avg.Loss: -3.281,LR: 4.94E-05]Training epoch 80:  65%|██████▌   | 73/112 [00:01<00:00, 53.29it/s, Epoch: 80, Batch: 74,Loss: -3.277,Avg.Loss: -3.281,LR: 4.93E-05]Training epoch 80:  66%|██████▌   | 74/112 [00:01<00:00, 53.50it/s, Epoch: 80, Batch: 74,Loss: -3.277,Avg.Loss: -3.281,LR: 4.93E-05]Training epoch 80:  66%|██████▌   | 74/112 [00:01<00:00, 53.50it/s, Epoch: 80, Batch: 75,Loss: -3.285,Avg.Loss: -3.281,LR: 4.93E-05]Training epoch 80:  67%|██████▋   | 75/112 [00:01<00:00, 53.50it/s, Epoch: 80, Batch: 76,Loss: -3.816,Avg.Loss: -3.288,LR: 4.92E-05]Training epoch 80:  68%|██████▊   | 76/112 [00:01<00:00, 53.50it/s, Epoch: 80, Batch: 77,Loss: -3.584,Avg.Loss: -3.292,LR: 4.92E-05]Training epoch 80:  69%|██████▉   | 77/112 [00:01<00:00, 53.50it/s, Epoch: 80, Batch: 78,Loss: -3.296,Avg.Loss: -3.292,LR: 4.92E-05]Training epoch 80:  70%|██████▉   | 78/112 [00:01<00:00, 53.50it/s, Epoch: 80, Batch: 79,Loss: -2.933,Avg.Loss: -3.287,LR: 4.91E-05]Training epoch 80:  71%|███████   | 79/112 [00:01<00:00, 53.50it/s, Epoch: 80, Batch: 80,Loss: -2.862,Avg.Loss: -3.282,LR: 4.91E-05]Training epoch 80:  71%|███████▏  | 80/112 [00:01<00:00, 53.47it/s, Epoch: 80, Batch: 80,Loss: -2.862,Avg.Loss: -3.282,LR: 4.91E-05]Training epoch 80:  71%|███████▏  | 80/112 [00:01<00:00, 53.47it/s, Epoch: 80, Batch: 81,Loss: -3.226,Avg.Loss: -3.281,LR: 4.90E-05]Training epoch 80:  72%|███████▏  | 81/112 [00:01<00:00, 53.47it/s, Epoch: 80, Batch: 82,Loss: -3.259,Avg.Loss: -3.281,LR: 4.90E-05]Training epoch 80:  73%|███████▎  | 82/112 [00:01<00:00, 53.47it/s, Epoch: 80, Batch: 83,Loss: -2.901,Avg.Loss: -3.276,LR: 4.89E-05]Training epoch 80:  74%|███████▍  | 83/112 [00:01<00:00, 53.47it/s, Epoch: 80, Batch: 84,Loss: -3.261,Avg.Loss: -3.276,LR: 4.89E-05]Training epoch 80:  75%|███████▌  | 84/112 [00:01<00:00, 53.47it/s, Epoch: 80, Batch: 85,Loss: -3.631,Avg.Loss: -3.280,LR: 4.89E-05]Training epoch 80:  76%|███████▌  | 85/112 [00:01<00:00, 53.47it/s, Epoch: 80, Batch: 86,Loss: -3.519,Avg.Loss: -3.283,LR: 4.88E-05]Training epoch 80:  77%|███████▋  | 86/112 [00:01<00:00, 53.65it/s, Epoch: 80, Batch: 86,Loss: -3.519,Avg.Loss: -3.283,LR: 4.88E-05]Training epoch 80:  77%|███████▋  | 86/112 [00:01<00:00, 53.65it/s, Epoch: 80, Batch: 87,Loss: -3.181,Avg.Loss: -3.282,LR: 4.88E-05]Training epoch 80:  78%|███████▊  | 87/112 [00:01<00:00, 53.65it/s, Epoch: 80, Batch: 88,Loss: -3.387,Avg.Loss: -3.283,LR: 4.87E-05]Training epoch 80:  79%|███████▊  | 88/112 [00:01<00:00, 53.65it/s, Epoch: 80, Batch: 89,Loss: -3.018,Avg.Loss: -3.280,LR: 4.87E-05]Training epoch 80:  79%|███████▉  | 89/112 [00:01<00:00, 53.65it/s, Epoch: 80, Batch: 90,Loss: -3.563,Avg.Loss: -3.283,LR: 4.87E-05]Training epoch 80:  80%|████████  | 90/112 [00:01<00:00, 53.65it/s, Epoch: 80, Batch: 91,Loss: -3.248,Avg.Loss: -3.283,LR: 4.86E-05]Training epoch 80:  81%|████████▏ | 91/112 [00:01<00:00, 53.65it/s, Epoch: 80, Batch: 92,Loss: -3.540,Avg.Loss: -3.286,LR: 4.86E-05]Training epoch 80:  82%|████████▏ | 92/112 [00:01<00:00, 53.74it/s, Epoch: 80, Batch: 92,Loss: -3.540,Avg.Loss: -3.286,LR: 4.86E-05]Training epoch 80:  82%|████████▏ | 92/112 [00:01<00:00, 53.74it/s, Epoch: 80, Batch: 93,Loss: -3.295,Avg.Loss: -3.286,LR: 4.85E-05]Training epoch 80:  83%|████████▎ | 93/112 [00:01<00:00, 53.74it/s, Epoch: 80, Batch: 94,Loss: -3.282,Avg.Loss: -3.286,LR: 4.85E-05]Training epoch 80:  84%|████████▍ | 94/112 [00:01<00:00, 53.74it/s, Epoch: 80, Batch: 95,Loss: -3.263,Avg.Loss: -3.286,LR: 4.84E-05]Training epoch 80:  85%|████████▍ | 95/112 [00:01<00:00, 53.74it/s, Epoch: 80, Batch: 96,Loss: -2.751,Avg.Loss: -3.280,LR: 4.84E-05]Training epoch 80:  86%|████████▌ | 96/112 [00:01<00:00, 53.74it/s, Epoch: 80, Batch: 97,Loss: -3.141,Avg.Loss: -3.279,LR: 4.84E-05]Training epoch 80:  87%|████████▋ | 97/112 [00:01<00:00, 53.74it/s, Epoch: 80, Batch: 98,Loss: -3.330,Avg.Loss: -3.279,LR: 4.83E-05]Training epoch 80:  88%|████████▊ | 98/112 [00:01<00:00, 54.01it/s, Epoch: 80, Batch: 98,Loss: -3.330,Avg.Loss: -3.279,LR: 4.83E-05]Training epoch 80:  88%|████████▊ | 98/112 [00:01<00:00, 54.01it/s, Epoch: 80, Batch: 99,Loss: -3.433,Avg.Loss: -3.281,LR: 4.83E-05]Training epoch 80:  88%|████████▊ | 99/112 [00:01<00:00, 54.01it/s, Epoch: 80, Batch: 100,Loss: -3.038,Avg.Loss: -3.278,LR: 4.82E-05]Training epoch 80:  89%|████████▉ | 100/112 [00:01<00:00, 54.01it/s, Epoch: 80, Batch: 101,Loss: -3.420,Avg.Loss: -3.280,LR: 4.82E-05]Training epoch 80:  90%|█████████ | 101/112 [00:01<00:00, 54.01it/s, Epoch: 80, Batch: 102,Loss: -2.932,Avg.Loss: -3.276,LR: 4.82E-05]Training epoch 80:  91%|█████████ | 102/112 [00:01<00:00, 54.01it/s, Epoch: 80, Batch: 103,Loss: -3.655,Avg.Loss: -3.280,LR: 4.81E-05]Training epoch 80:  92%|█████████▏| 103/112 [00:01<00:00, 54.01it/s, Epoch: 80, Batch: 104,Loss: -3.152,Avg.Loss: -3.279,LR: 4.81E-05]Training epoch 80:  93%|█████████▎| 104/112 [00:01<00:00, 53.99it/s, Epoch: 80, Batch: 104,Loss: -3.152,Avg.Loss: -3.279,LR: 4.81E-05]Training epoch 80:  93%|█████████▎| 104/112 [00:01<00:00, 53.99it/s, Epoch: 80, Batch: 105,Loss: -3.404,Avg.Loss: -3.280,LR: 4.80E-05]Training epoch 80:  94%|█████████▍| 105/112 [00:01<00:00, 53.99it/s, Epoch: 80, Batch: 106,Loss: -3.345,Avg.Loss: -3.280,LR: 4.80E-05]Training epoch 80:  95%|█████████▍| 106/112 [00:01<00:00, 53.99it/s, Epoch: 80, Batch: 107,Loss: -3.561,Avg.Loss: -3.283,LR: 4.80E-05]Training epoch 80:  96%|█████████▌| 107/112 [00:01<00:00, 53.99it/s, Epoch: 80, Batch: 108,Loss: -3.147,Avg.Loss: -3.282,LR: 4.79E-05]Training epoch 80:  96%|█████████▋| 108/112 [00:02<00:00, 53.99it/s, Epoch: 80, Batch: 109,Loss: -3.406,Avg.Loss: -3.283,LR: 4.79E-05]Training epoch 80:  97%|█████████▋| 109/112 [00:02<00:00, 53.99it/s, Epoch: 80, Batch: 110,Loss: -3.854,Avg.Loss: -3.288,LR: 4.78E-05]Training epoch 80:  98%|█████████▊| 110/112 [00:02<00:00, 54.09it/s, Epoch: 80, Batch: 110,Loss: -3.854,Avg.Loss: -3.288,LR: 4.78E-05]Training epoch 80:  98%|█████████▊| 110/112 [00:02<00:00, 54.09it/s, Epoch: 80, Batch: 111,Loss: -3.831,Avg.Loss: -3.293,LR: 4.78E-05]Training epoch 80:  99%|█████████▉| 111/112 [00:02<00:00, 54.09it/s, Epoch: 80, Batch: 112,Loss: -3.900,Avg.Loss: -3.298,LR: 4.77E-05]Training epoch 80: 100%|██████████| 112/112 [00:02<00:00, 53.93it/s, Epoch: 80, Batch: 112,Loss: -3.900,Avg.Loss: -3.298,LR: 4.77E-05]
Training epoch 81:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 81:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 81, Batch: 1,Loss: -2.936,Avg.Loss: -2.936,LR: 4.77E-05]Training epoch 81:   1%|          | 1/112 [00:00<00:03, 31.24it/s, Epoch: 81, Batch: 2,Loss: -2.870,Avg.Loss: -2.903,LR: 4.77E-05]Training epoch 81:   2%|▏         | 2/112 [00:00<00:02, 43.33it/s, Epoch: 81, Batch: 3,Loss: -3.079,Avg.Loss: -2.961,LR: 4.76E-05]Training epoch 81:   3%|▎         | 3/112 [00:00<00:02, 50.86it/s, Epoch: 81, Batch: 4,Loss: -3.521,Avg.Loss: -3.101,LR: 4.76E-05]Training epoch 81:   4%|▎         | 4/112 [00:00<00:02, 51.80it/s, Epoch: 81, Batch: 5,Loss: -3.379,Avg.Loss: -3.157,LR: 4.75E-05]Training epoch 81:   4%|▍         | 5/112 [00:00<00:02, 52.09it/s, Epoch: 81, Batch: 6,Loss: -3.464,Avg.Loss: -3.208,LR: 4.75E-05]Training epoch 81:   5%|▌         | 6/112 [00:00<00:02, 52.13it/s, Epoch: 81, Batch: 7,Loss: -3.469,Avg.Loss: -3.245,LR: 4.75E-05]Training epoch 81:   6%|▋         | 7/112 [00:00<00:01, 60.73it/s, Epoch: 81, Batch: 7,Loss: -3.469,Avg.Loss: -3.245,LR: 4.75E-05]Training epoch 81:   6%|▋         | 7/112 [00:00<00:01, 60.73it/s, Epoch: 81, Batch: 8,Loss: -3.185,Avg.Loss: -3.238,LR: 4.74E-05]Training epoch 81:   7%|▋         | 8/112 [00:00<00:01, 60.73it/s, Epoch: 81, Batch: 9,Loss: -3.387,Avg.Loss: -3.254,LR: 4.74E-05]Training epoch 81:   8%|▊         | 9/112 [00:00<00:01, 60.73it/s, Epoch: 81, Batch: 10,Loss: -3.375,Avg.Loss: -3.266,LR: 4.73E-05]Training epoch 81:   9%|▉         | 10/112 [00:00<00:01, 60.73it/s, Epoch: 81, Batch: 11,Loss: -3.704,Avg.Loss: -3.306,LR: 4.73E-05]Training epoch 81:  10%|▉         | 11/112 [00:00<00:01, 60.73it/s, Epoch: 81, Batch: 12,Loss: -3.924,Avg.Loss: -3.358,LR: 4.73E-05]Training epoch 81:  11%|█         | 12/112 [00:00<00:01, 60.73it/s, Epoch: 81, Batch: 13,Loss: -3.382,Avg.Loss: -3.360,LR: 4.72E-05]Training epoch 81:  12%|█▏        | 13/112 [00:00<00:01, 60.73it/s, Epoch: 81, Batch: 14,Loss: -3.262,Avg.Loss: -3.353,LR: 4.72E-05]Training epoch 81:  12%|█▎        | 14/112 [00:00<00:01, 55.78it/s, Epoch: 81, Batch: 14,Loss: -3.262,Avg.Loss: -3.353,LR: 4.72E-05]Training epoch 81:  12%|█▎        | 14/112 [00:00<00:01, 55.78it/s, Epoch: 81, Batch: 15,Loss: -3.278,Avg.Loss: -3.348,LR: 4.71E-05]Training epoch 81:  13%|█▎        | 15/112 [00:00<00:01, 55.78it/s, Epoch: 81, Batch: 16,Loss: -3.695,Avg.Loss: -3.369,LR: 4.71E-05]Training epoch 81:  14%|█▍        | 16/112 [00:00<00:01, 55.78it/s, Epoch: 81, Batch: 17,Loss: -3.916,Avg.Loss: -3.401,LR: 4.70E-05]Training epoch 81:  15%|█▌        | 17/112 [00:00<00:01, 55.78it/s, Epoch: 81, Batch: 18,Loss: -3.575,Avg.Loss: -3.411,LR: 4.70E-05]Training epoch 81:  16%|█▌        | 18/112 [00:00<00:01, 55.78it/s, Epoch: 81, Batch: 19,Loss: -3.672,Avg.Loss: -3.425,LR: 4.70E-05]Training epoch 81:  17%|█▋        | 19/112 [00:00<00:01, 55.78it/s, Epoch: 81, Batch: 20,Loss: -2.952,Avg.Loss: -3.401,LR: 4.69E-05]Training epoch 81:  18%|█▊        | 20/112 [00:00<00:01, 54.79it/s, Epoch: 81, Batch: 20,Loss: -2.952,Avg.Loss: -3.401,LR: 4.69E-05]Training epoch 81:  18%|█▊        | 20/112 [00:00<00:01, 54.79it/s, Epoch: 81, Batch: 21,Loss: -3.096,Avg.Loss: -3.387,LR: 4.69E-05]Training epoch 81:  19%|█▉        | 21/112 [00:00<00:01, 54.79it/s, Epoch: 81, Batch: 22,Loss: -3.227,Avg.Loss: -3.379,LR: 4.68E-05]Training epoch 81:  20%|█▉        | 22/112 [00:00<00:01, 54.79it/s, Epoch: 81, Batch: 23,Loss: -3.152,Avg.Loss: -3.370,LR: 4.68E-05]Training epoch 81:  21%|██        | 23/112 [00:00<00:01, 54.79it/s, Epoch: 81, Batch: 24,Loss: -3.310,Avg.Loss: -3.367,LR: 4.68E-05]Training epoch 81:  21%|██▏       | 24/112 [00:00<00:01, 54.79it/s, Epoch: 81, Batch: 25,Loss: -3.321,Avg.Loss: -3.365,LR: 4.67E-05]Training epoch 81:  22%|██▏       | 25/112 [00:00<00:01, 54.79it/s, Epoch: 81, Batch: 26,Loss: -2.876,Avg.Loss: -3.346,LR: 4.67E-05]Training epoch 81:  23%|██▎       | 26/112 [00:00<00:01, 53.68it/s, Epoch: 81, Batch: 26,Loss: -2.876,Avg.Loss: -3.346,LR: 4.67E-05]Training epoch 81:  23%|██▎       | 26/112 [00:00<00:01, 53.68it/s, Epoch: 81, Batch: 27,Loss: -2.835,Avg.Loss: -3.327,LR: 4.66E-05]Training epoch 81:  24%|██▍       | 27/112 [00:00<00:01, 53.68it/s, Epoch: 81, Batch: 28,Loss: -3.684,Avg.Loss: -3.340,LR: 4.66E-05]Training epoch 81:  25%|██▌       | 28/112 [00:00<00:01, 53.68it/s, Epoch: 81, Batch: 29,Loss: -3.548,Avg.Loss: -3.347,LR: 4.66E-05]Training epoch 81:  26%|██▌       | 29/112 [00:00<00:01, 53.68it/s, Epoch: 81, Batch: 30,Loss: -3.570,Avg.Loss: -3.355,LR: 4.65E-05]Training epoch 81:  27%|██▋       | 30/112 [00:00<00:01, 53.68it/s, Epoch: 81, Batch: 31,Loss: -2.918,Avg.Loss: -3.341,LR: 4.65E-05]Training epoch 81:  28%|██▊       | 31/112 [00:00<00:01, 53.68it/s, Epoch: 81, Batch: 32,Loss: -3.558,Avg.Loss: -3.348,LR: 4.64E-05]Training epoch 81:  29%|██▊       | 32/112 [00:00<00:01, 53.48it/s, Epoch: 81, Batch: 32,Loss: -3.558,Avg.Loss: -3.348,LR: 4.64E-05]Training epoch 81:  29%|██▊       | 32/112 [00:00<00:01, 53.48it/s, Epoch: 81, Batch: 33,Loss: -3.610,Avg.Loss: -3.355,LR: 4.64E-05]Training epoch 81:  29%|██▉       | 33/112 [00:00<00:01, 53.48it/s, Epoch: 81, Batch: 34,Loss: -3.390,Avg.Loss: -3.356,LR: 4.64E-05]Training epoch 81:  30%|███       | 34/112 [00:00<00:01, 53.48it/s, Epoch: 81, Batch: 35,Loss: -3.229,Avg.Loss: -3.353,LR: 4.63E-05]Training epoch 81:  31%|███▏      | 35/112 [00:00<00:01, 53.48it/s, Epoch: 81, Batch: 36,Loss: -3.564,Avg.Loss: -3.359,LR: 4.63E-05]Training epoch 81:  32%|███▏      | 36/112 [00:00<00:01, 53.48it/s, Epoch: 81, Batch: 37,Loss: -3.681,Avg.Loss: -3.367,LR: 4.62E-05]Training epoch 81:  33%|███▎      | 37/112 [00:00<00:01, 53.48it/s, Epoch: 81, Batch: 38,Loss: -3.283,Avg.Loss: -3.365,LR: 4.62E-05]Training epoch 81:  34%|███▍      | 38/112 [00:00<00:01, 53.36it/s, Epoch: 81, Batch: 38,Loss: -3.283,Avg.Loss: -3.365,LR: 4.62E-05]Training epoch 81:  34%|███▍      | 38/112 [00:00<00:01, 53.36it/s, Epoch: 81, Batch: 39,Loss: -3.484,Avg.Loss: -3.368,LR: 4.62E-05]Training epoch 81:  35%|███▍      | 39/112 [00:00<00:01, 53.36it/s, Epoch: 81, Batch: 40,Loss: -3.409,Avg.Loss: -3.369,LR: 4.61E-05]Training epoch 81:  36%|███▌      | 40/112 [00:00<00:01, 53.36it/s, Epoch: 81, Batch: 41,Loss: -3.331,Avg.Loss: -3.368,LR: 4.61E-05]Training epoch 81:  37%|███▋      | 41/112 [00:00<00:01, 53.36it/s, Epoch: 81, Batch: 42,Loss: -3.338,Avg.Loss: -3.368,LR: 4.60E-05]Training epoch 81:  38%|███▊      | 42/112 [00:00<00:01, 53.36it/s, Epoch: 81, Batch: 43,Loss: -3.574,Avg.Loss: -3.372,LR: 4.60E-05]Training epoch 81:  38%|███▊      | 43/112 [00:00<00:01, 53.36it/s, Epoch: 81, Batch: 44,Loss: -3.772,Avg.Loss: -3.381,LR: 4.59E-05]Training epoch 81:  39%|███▉      | 44/112 [00:00<00:01, 53.31it/s, Epoch: 81, Batch: 44,Loss: -3.772,Avg.Loss: -3.381,LR: 4.59E-05]Training epoch 81:  39%|███▉      | 44/112 [00:00<00:01, 53.31it/s, Epoch: 81, Batch: 45,Loss: -3.228,Avg.Loss: -3.378,LR: 4.59E-05]Training epoch 81:  40%|████      | 45/112 [00:00<00:01, 53.31it/s, Epoch: 81, Batch: 46,Loss: -2.874,Avg.Loss: -3.367,LR: 4.59E-05]Training epoch 81:  41%|████      | 46/112 [00:00<00:01, 53.31it/s, Epoch: 81, Batch: 47,Loss: -3.118,Avg.Loss: -3.362,LR: 4.58E-05]Training epoch 81:  42%|████▏     | 47/112 [00:00<00:01, 53.31it/s, Epoch: 81, Batch: 48,Loss: -3.042,Avg.Loss: -3.355,LR: 4.58E-05]Training epoch 81:  43%|████▎     | 48/112 [00:00<00:01, 53.31it/s, Epoch: 81, Batch: 49,Loss: -3.373,Avg.Loss: -3.356,LR: 4.57E-05]Training epoch 81:  44%|████▍     | 49/112 [00:00<00:01, 53.31it/s, Epoch: 81, Batch: 50,Loss: -2.890,Avg.Loss: -3.346,LR: 4.57E-05]Training epoch 81:  45%|████▍     | 50/112 [00:00<00:01, 53.04it/s, Epoch: 81, Batch: 50,Loss: -2.890,Avg.Loss: -3.346,LR: 4.57E-05]Training epoch 81:  45%|████▍     | 50/112 [00:00<00:01, 53.04it/s, Epoch: 81, Batch: 51,Loss: -2.912,Avg.Loss: -3.338,LR: 4.57E-05]Training epoch 81:  46%|████▌     | 51/112 [00:00<00:01, 53.04it/s, Epoch: 81, Batch: 52,Loss: -3.685,Avg.Loss: -3.344,LR: 4.56E-05]Training epoch 81:  46%|████▋     | 52/112 [00:00<00:01, 53.04it/s, Epoch: 81, Batch: 53,Loss: -3.456,Avg.Loss: -3.346,LR: 4.56E-05]Training epoch 81:  47%|████▋     | 53/112 [00:01<00:01, 53.04it/s, Epoch: 81, Batch: 54,Loss: -3.420,Avg.Loss: -3.348,LR: 4.55E-05]Training epoch 81:  48%|████▊     | 54/112 [00:01<00:01, 53.04it/s, Epoch: 81, Batch: 55,Loss: -3.462,Avg.Loss: -3.350,LR: 4.55E-05]Training epoch 81:  49%|████▉     | 55/112 [00:01<00:01, 53.04it/s, Epoch: 81, Batch: 56,Loss: -3.464,Avg.Loss: -3.352,LR: 4.55E-05]Training epoch 81:  50%|█████     | 56/112 [00:01<00:01, 52.82it/s, Epoch: 81, Batch: 56,Loss: -3.464,Avg.Loss: -3.352,LR: 4.55E-05]Training epoch 81:  50%|█████     | 56/112 [00:01<00:01, 52.82it/s, Epoch: 81, Batch: 57,Loss: -3.193,Avg.Loss: -3.349,LR: 4.54E-05]Training epoch 81:  51%|█████     | 57/112 [00:01<00:01, 52.82it/s, Epoch: 81, Batch: 58,Loss: -3.165,Avg.Loss: -3.346,LR: 4.54E-05]Training epoch 81:  52%|█████▏    | 58/112 [00:01<00:01, 52.82it/s, Epoch: 81, Batch: 59,Loss: -3.069,Avg.Loss: -3.341,LR: 4.53E-05]Training epoch 81:  53%|█████▎    | 59/112 [00:01<00:01, 52.82it/s, Epoch: 81, Batch: 60,Loss: -3.083,Avg.Loss: -3.337,LR: 4.53E-05]Training epoch 81:  54%|█████▎    | 60/112 [00:01<00:00, 52.82it/s, Epoch: 81, Batch: 61,Loss: -3.536,Avg.Loss: -3.340,LR: 4.53E-05]Training epoch 81:  54%|█████▍    | 61/112 [00:01<00:00, 52.82it/s, Epoch: 81, Batch: 62,Loss: -2.745,Avg.Loss: -3.331,LR: 4.52E-05]Training epoch 81:  55%|█████▌    | 62/112 [00:01<00:00, 52.84it/s, Epoch: 81, Batch: 62,Loss: -2.745,Avg.Loss: -3.331,LR: 4.52E-05]Training epoch 81:  55%|█████▌    | 62/112 [00:01<00:00, 52.84it/s, Epoch: 81, Batch: 63,Loss: -3.101,Avg.Loss: -3.327,LR: 4.52E-05]Training epoch 81:  56%|█████▋    | 63/112 [00:01<00:00, 52.84it/s, Epoch: 81, Batch: 64,Loss: -3.143,Avg.Loss: -3.324,LR: 4.51E-05]Training epoch 81:  57%|█████▋    | 64/112 [00:01<00:00, 52.84it/s, Epoch: 81, Batch: 65,Loss: -3.255,Avg.Loss: -3.323,LR: 4.51E-05]Training epoch 81:  58%|█████▊    | 65/112 [00:01<00:00, 52.84it/s, Epoch: 81, Batch: 66,Loss: -3.282,Avg.Loss: -3.322,LR: 4.51E-05]Training epoch 81:  59%|█████▉    | 66/112 [00:01<00:00, 52.84it/s, Epoch: 81, Batch: 67,Loss: -3.759,Avg.Loss: -3.329,LR: 4.50E-05]Training epoch 81:  60%|█████▉    | 67/112 [00:01<00:00, 52.84it/s, Epoch: 81, Batch: 68,Loss: -3.249,Avg.Loss: -3.328,LR: 4.50E-05]Training epoch 81:  61%|██████    | 68/112 [00:01<00:00, 52.93it/s, Epoch: 81, Batch: 68,Loss: -3.249,Avg.Loss: -3.328,LR: 4.50E-05]Training epoch 81:  61%|██████    | 68/112 [00:01<00:00, 52.93it/s, Epoch: 81, Batch: 69,Loss: -3.426,Avg.Loss: -3.329,LR: 4.49E-05]Training epoch 81:  62%|██████▏   | 69/112 [00:01<00:00, 52.93it/s, Epoch: 81, Batch: 70,Loss: -3.306,Avg.Loss: -3.329,LR: 4.49E-05]Training epoch 81:  62%|██████▎   | 70/112 [00:01<00:00, 52.93it/s, Epoch: 81, Batch: 71,Loss: -3.185,Avg.Loss: -3.327,LR: 4.49E-05]Training epoch 81:  63%|██████▎   | 71/112 [00:01<00:00, 52.93it/s, Epoch: 81, Batch: 72,Loss: -3.392,Avg.Loss: -3.328,LR: 4.48E-05]Training epoch 81:  64%|██████▍   | 72/112 [00:01<00:00, 52.93it/s, Epoch: 81, Batch: 73,Loss: -3.629,Avg.Loss: -3.332,LR: 4.48E-05]Training epoch 81:  65%|██████▌   | 73/112 [00:01<00:00, 52.93it/s, Epoch: 81, Batch: 74,Loss: -3.816,Avg.Loss: -3.338,LR: 4.47E-05]Training epoch 81:  66%|██████▌   | 74/112 [00:01<00:00, 52.96it/s, Epoch: 81, Batch: 74,Loss: -3.816,Avg.Loss: -3.338,LR: 4.47E-05]Training epoch 81:  66%|██████▌   | 74/112 [00:01<00:00, 52.96it/s, Epoch: 81, Batch: 75,Loss: -3.388,Avg.Loss: -3.339,LR: 4.47E-05]Training epoch 81:  67%|██████▋   | 75/112 [00:01<00:00, 52.96it/s, Epoch: 81, Batch: 76,Loss: -3.620,Avg.Loss: -3.343,LR: 4.47E-05]Training epoch 81:  68%|██████▊   | 76/112 [00:01<00:00, 52.96it/s, Epoch: 81, Batch: 77,Loss: -3.483,Avg.Loss: -3.345,LR: 4.46E-05]Training epoch 81:  69%|██████▉   | 77/112 [00:01<00:00, 52.96it/s, Epoch: 81, Batch: 78,Loss: -3.590,Avg.Loss: -3.348,LR: 4.46E-05]Training epoch 81:  70%|██████▉   | 78/112 [00:01<00:00, 52.96it/s, Epoch: 81, Batch: 79,Loss: -3.400,Avg.Loss: -3.348,LR: 4.45E-05]Training epoch 81:  71%|███████   | 79/112 [00:01<00:00, 52.96it/s, Epoch: 81, Batch: 80,Loss: -3.308,Avg.Loss: -3.348,LR: 4.45E-05]Training epoch 81:  71%|███████▏  | 80/112 [00:01<00:00, 52.79it/s, Epoch: 81, Batch: 80,Loss: -3.308,Avg.Loss: -3.348,LR: 4.45E-05]Training epoch 81:  71%|███████▏  | 80/112 [00:01<00:00, 52.79it/s, Epoch: 81, Batch: 81,Loss: -3.366,Avg.Loss: -3.348,LR: 4.45E-05]Training epoch 81:  72%|███████▏  | 81/112 [00:01<00:00, 52.79it/s, Epoch: 81, Batch: 82,Loss: -3.388,Avg.Loss: -3.349,LR: 4.44E-05]Training epoch 81:  73%|███████▎  | 82/112 [00:01<00:00, 52.79it/s, Epoch: 81, Batch: 83,Loss: -3.605,Avg.Loss: -3.352,LR: 4.44E-05]Training epoch 81:  74%|███████▍  | 83/112 [00:01<00:00, 52.79it/s, Epoch: 81, Batch: 84,Loss: -3.472,Avg.Loss: -3.353,LR: 4.43E-05]Training epoch 81:  75%|███████▌  | 84/112 [00:01<00:00, 52.79it/s, Epoch: 81, Batch: 85,Loss: -3.416,Avg.Loss: -3.354,LR: 4.43E-05]Training epoch 81:  76%|███████▌  | 85/112 [00:01<00:00, 52.79it/s, Epoch: 81, Batch: 86,Loss: -2.776,Avg.Loss: -3.347,LR: 4.43E-05]Training epoch 81:  77%|███████▋  | 86/112 [00:01<00:00, 53.10it/s, Epoch: 81, Batch: 86,Loss: -2.776,Avg.Loss: -3.347,LR: 4.43E-05]Training epoch 81:  77%|███████▋  | 86/112 [00:01<00:00, 53.10it/s, Epoch: 81, Batch: 87,Loss: -3.295,Avg.Loss: -3.347,LR: 4.42E-05]Training epoch 81:  78%|███████▊  | 87/112 [00:01<00:00, 53.10it/s, Epoch: 81, Batch: 88,Loss: -2.852,Avg.Loss: -3.341,LR: 4.42E-05]Training epoch 81:  79%|███████▊  | 88/112 [00:01<00:00, 53.10it/s, Epoch: 81, Batch: 89,Loss: -3.056,Avg.Loss: -3.338,LR: 4.41E-05]Training epoch 81:  79%|███████▉  | 89/112 [00:01<00:00, 53.10it/s, Epoch: 81, Batch: 90,Loss: -3.376,Avg.Loss: -3.338,LR: 4.41E-05]Training epoch 81:  80%|████████  | 90/112 [00:01<00:00, 53.10it/s, Epoch: 81, Batch: 91,Loss: -3.244,Avg.Loss: -3.337,LR: 4.41E-05]Training epoch 81:  81%|████████▏ | 91/112 [00:01<00:00, 53.10it/s, Epoch: 81, Batch: 92,Loss: -3.223,Avg.Loss: -3.336,LR: 4.40E-05]Training epoch 81:  82%|████████▏ | 92/112 [00:01<00:00, 53.03it/s, Epoch: 81, Batch: 92,Loss: -3.223,Avg.Loss: -3.336,LR: 4.40E-05]Training epoch 81:  82%|████████▏ | 92/112 [00:01<00:00, 53.03it/s, Epoch: 81, Batch: 93,Loss: -3.548,Avg.Loss: -3.338,LR: 4.40E-05]Training epoch 81:  83%|████████▎ | 93/112 [00:01<00:00, 53.03it/s, Epoch: 81, Batch: 94,Loss: -3.370,Avg.Loss: -3.339,LR: 4.39E-05]Training epoch 81:  84%|████████▍ | 94/112 [00:01<00:00, 53.03it/s, Epoch: 81, Batch: 95,Loss: -3.626,Avg.Loss: -3.342,LR: 4.39E-05]Training epoch 81:  85%|████████▍ | 95/112 [00:01<00:00, 53.03it/s, Epoch: 81, Batch: 96,Loss: -3.254,Avg.Loss: -3.341,LR: 4.39E-05]Training epoch 81:  86%|████████▌ | 96/112 [00:01<00:00, 53.03it/s, Epoch: 81, Batch: 97,Loss: -3.701,Avg.Loss: -3.344,LR: 4.38E-05]Training epoch 81:  87%|████████▋ | 97/112 [00:01<00:00, 53.03it/s, Epoch: 81, Batch: 98,Loss: -3.555,Avg.Loss: -3.346,LR: 4.38E-05]Training epoch 81:  88%|████████▊ | 98/112 [00:01<00:00, 53.69it/s, Epoch: 81, Batch: 98,Loss: -3.555,Avg.Loss: -3.346,LR: 4.38E-05]Training epoch 81:  88%|████████▊ | 98/112 [00:01<00:00, 53.69it/s, Epoch: 81, Batch: 99,Loss: -3.510,Avg.Loss: -3.348,LR: 4.37E-05]Training epoch 81:  88%|████████▊ | 99/112 [00:01<00:00, 53.69it/s, Epoch: 81, Batch: 100,Loss: -3.058,Avg.Loss: -3.345,LR: 4.37E-05]Training epoch 81:  89%|████████▉ | 100/112 [00:01<00:00, 53.69it/s, Epoch: 81, Batch: 101,Loss: -3.161,Avg.Loss: -3.343,LR: 4.37E-05]Training epoch 81:  90%|█████████ | 101/112 [00:01<00:00, 53.69it/s, Epoch: 81, Batch: 102,Loss: -3.371,Avg.Loss: -3.344,LR: 4.36E-05]Training epoch 81:  91%|█████████ | 102/112 [00:01<00:00, 53.69it/s, Epoch: 81, Batch: 103,Loss: -3.416,Avg.Loss: -3.344,LR: 4.36E-05]Training epoch 81:  92%|█████████▏| 103/112 [00:01<00:00, 53.69it/s, Epoch: 81, Batch: 104,Loss: -2.974,Avg.Loss: -3.341,LR: 4.35E-05]Training epoch 81:  93%|█████████▎| 104/112 [00:01<00:00, 53.57it/s, Epoch: 81, Batch: 104,Loss: -2.974,Avg.Loss: -3.341,LR: 4.35E-05]Training epoch 81:  93%|█████████▎| 104/112 [00:01<00:00, 53.57it/s, Epoch: 81, Batch: 105,Loss: -3.268,Avg.Loss: -3.340,LR: 4.35E-05]Training epoch 81:  94%|█████████▍| 105/112 [00:01<00:00, 53.57it/s, Epoch: 81, Batch: 106,Loss: -3.591,Avg.Loss: -3.342,LR: 4.35E-05]Training epoch 81:  95%|█████████▍| 106/112 [00:01<00:00, 53.57it/s, Epoch: 81, Batch: 107,Loss: -2.772,Avg.Loss: -3.337,LR: 4.34E-05]Training epoch 81:  96%|█████████▌| 107/112 [00:02<00:00, 53.57it/s, Epoch: 81, Batch: 108,Loss: -3.018,Avg.Loss: -3.334,LR: 4.34E-05]Training epoch 81:  96%|█████████▋| 108/112 [00:02<00:00, 53.57it/s, Epoch: 81, Batch: 109,Loss: -3.585,Avg.Loss: -3.337,LR: 4.33E-05]Training epoch 81:  97%|█████████▋| 109/112 [00:02<00:00, 53.57it/s, Epoch: 81, Batch: 110,Loss: -3.854,Avg.Loss: -3.341,LR: 4.33E-05]Training epoch 81:  98%|█████████▊| 110/112 [00:02<00:00, 53.59it/s, Epoch: 81, Batch: 110,Loss: -3.854,Avg.Loss: -3.341,LR: 4.33E-05]Training epoch 81:  98%|█████████▊| 110/112 [00:02<00:00, 53.59it/s, Epoch: 81, Batch: 111,Loss: -3.497,Avg.Loss: -3.343,LR: 4.33E-05]Training epoch 81:  99%|█████████▉| 111/112 [00:02<00:00, 53.59it/s, Epoch: 81, Batch: 112,Loss: -2.876,Avg.Loss: -3.338,LR: 4.32E-05]Training epoch 81: 100%|██████████| 112/112 [00:02<00:00, 53.43it/s, Epoch: 81, Batch: 112,Loss: -2.876,Avg.Loss: -3.338,LR: 4.32E-05]
Training epoch 82:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 82:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 82, Batch: 1,Loss: -2.722,Avg.Loss: -2.722,LR: 4.32E-05]Training epoch 82:   1%|          | 1/112 [00:00<00:04, 27.45it/s, Epoch: 82, Batch: 2,Loss: -3.788,Avg.Loss: -3.255,LR: 4.32E-05]Training epoch 82:   2%|▏         | 2/112 [00:00<00:02, 36.96it/s, Epoch: 82, Batch: 3,Loss: -3.276,Avg.Loss: -3.262,LR: 4.31E-05]Training epoch 82:   3%|▎         | 3/112 [00:00<00:02, 42.34it/s, Epoch: 82, Batch: 4,Loss: -3.492,Avg.Loss: -3.320,LR: 4.31E-05]Training epoch 82:   4%|▎         | 4/112 [00:00<00:02, 45.03it/s, Epoch: 82, Batch: 5,Loss: -3.352,Avg.Loss: -3.326,LR: 4.30E-05]Training epoch 82:   4%|▍         | 5/112 [00:00<00:02, 46.56it/s, Epoch: 82, Batch: 6,Loss: -3.396,Avg.Loss: -3.338,LR: 4.30E-05]Training epoch 82:   5%|▌         | 6/112 [00:00<00:01, 55.78it/s, Epoch: 82, Batch: 6,Loss: -3.396,Avg.Loss: -3.338,LR: 4.30E-05]Training epoch 82:   5%|▌         | 6/112 [00:00<00:01, 55.78it/s, Epoch: 82, Batch: 7,Loss: -3.559,Avg.Loss: -3.369,LR: 4.30E-05]Training epoch 82:   6%|▋         | 7/112 [00:00<00:01, 55.78it/s, Epoch: 82, Batch: 8,Loss: -3.140,Avg.Loss: -3.341,LR: 4.29E-05]Training epoch 82:   7%|▋         | 8/112 [00:00<00:01, 55.78it/s, Epoch: 82, Batch: 9,Loss: -3.362,Avg.Loss: -3.343,LR: 4.29E-05]Training epoch 82:   8%|▊         | 9/112 [00:00<00:01, 55.78it/s, Epoch: 82, Batch: 10,Loss: -3.372,Avg.Loss: -3.346,LR: 4.28E-05]Training epoch 82:   9%|▉         | 10/112 [00:00<00:01, 55.78it/s, Epoch: 82, Batch: 11,Loss: -3.475,Avg.Loss: -3.358,LR: 4.28E-05]Training epoch 82:  10%|▉         | 11/112 [00:00<00:01, 55.78it/s, Epoch: 82, Batch: 12,Loss: -3.648,Avg.Loss: -3.382,LR: 4.28E-05]Training epoch 82:  11%|█         | 12/112 [00:00<00:01, 53.82it/s, Epoch: 82, Batch: 12,Loss: -3.648,Avg.Loss: -3.382,LR: 4.28E-05]Training epoch 82:  11%|█         | 12/112 [00:00<00:01, 53.82it/s, Epoch: 82, Batch: 13,Loss: -3.303,Avg.Loss: -3.376,LR: 4.27E-05]Training epoch 82:  12%|█▏        | 13/112 [00:00<00:01, 53.82it/s, Epoch: 82, Batch: 14,Loss: -3.538,Avg.Loss: -3.388,LR: 4.27E-05]Training epoch 82:  12%|█▎        | 14/112 [00:00<00:01, 53.82it/s, Epoch: 82, Batch: 15,Loss: -3.670,Avg.Loss: -3.406,LR: 4.26E-05]Training epoch 82:  13%|█▎        | 15/112 [00:00<00:01, 53.82it/s, Epoch: 82, Batch: 16,Loss: -3.021,Avg.Loss: -3.382,LR: 4.26E-05]Training epoch 82:  14%|█▍        | 16/112 [00:00<00:01, 53.82it/s, Epoch: 82, Batch: 17,Loss: -3.302,Avg.Loss: -3.378,LR: 4.26E-05]Training epoch 82:  15%|█▌        | 17/112 [00:00<00:01, 53.82it/s, Epoch: 82, Batch: 18,Loss: -3.219,Avg.Loss: -3.369,LR: 4.25E-05]Training epoch 82:  16%|█▌        | 18/112 [00:00<00:01, 53.46it/s, Epoch: 82, Batch: 18,Loss: -3.219,Avg.Loss: -3.369,LR: 4.25E-05]Training epoch 82:  16%|█▌        | 18/112 [00:00<00:01, 53.46it/s, Epoch: 82, Batch: 19,Loss: -3.539,Avg.Loss: -3.378,LR: 4.25E-05]Training epoch 82:  17%|█▋        | 19/112 [00:00<00:01, 53.46it/s, Epoch: 82, Batch: 20,Loss: -3.797,Avg.Loss: -3.399,LR: 4.24E-05]Training epoch 82:  18%|█▊        | 20/112 [00:00<00:01, 53.46it/s, Epoch: 82, Batch: 21,Loss: -3.349,Avg.Loss: -3.396,LR: 4.24E-05]Training epoch 82:  19%|█▉        | 21/112 [00:00<00:01, 53.46it/s, Epoch: 82, Batch: 22,Loss: -3.714,Avg.Loss: -3.411,LR: 4.24E-05]Training epoch 82:  20%|█▉        | 22/112 [00:00<00:01, 53.46it/s, Epoch: 82, Batch: 23,Loss: -3.748,Avg.Loss: -3.425,LR: 4.23E-05]Training epoch 82:  21%|██        | 23/112 [00:00<00:01, 53.46it/s, Epoch: 82, Batch: 24,Loss: -3.509,Avg.Loss: -3.429,LR: 4.23E-05]Training epoch 82:  21%|██▏       | 24/112 [00:00<00:01, 52.17it/s, Epoch: 82, Batch: 24,Loss: -3.509,Avg.Loss: -3.429,LR: 4.23E-05]Training epoch 82:  21%|██▏       | 24/112 [00:00<00:01, 52.17it/s, Epoch: 82, Batch: 25,Loss: -3.612,Avg.Loss: -3.436,LR: 4.22E-05]Training epoch 82:  22%|██▏       | 25/112 [00:00<00:01, 52.17it/s, Epoch: 82, Batch: 26,Loss: -3.459,Avg.Loss: -3.437,LR: 4.22E-05]Training epoch 82:  23%|██▎       | 26/112 [00:00<00:01, 52.17it/s, Epoch: 82, Batch: 27,Loss: -3.430,Avg.Loss: -3.437,LR: 4.22E-05]Training epoch 82:  24%|██▍       | 27/112 [00:00<00:01, 52.17it/s, Epoch: 82, Batch: 28,Loss: -3.202,Avg.Loss: -3.428,LR: 4.21E-05]Training epoch 82:  25%|██▌       | 28/112 [00:00<00:01, 52.17it/s, Epoch: 82, Batch: 29,Loss: -2.972,Avg.Loss: -3.413,LR: 4.21E-05]Training epoch 82:  26%|██▌       | 29/112 [00:00<00:01, 52.17it/s, Epoch: 82, Batch: 30,Loss: -3.806,Avg.Loss: -3.426,LR: 4.21E-05]Training epoch 82:  27%|██▋       | 30/112 [00:00<00:01, 52.02it/s, Epoch: 82, Batch: 30,Loss: -3.806,Avg.Loss: -3.426,LR: 4.21E-05]Training epoch 82:  27%|██▋       | 30/112 [00:00<00:01, 52.02it/s, Epoch: 82, Batch: 31,Loss: -3.477,Avg.Loss: -3.427,LR: 4.20E-05]Training epoch 82:  28%|██▊       | 31/112 [00:00<00:01, 52.02it/s, Epoch: 82, Batch: 32,Loss: -3.475,Avg.Loss: -3.429,LR: 4.20E-05]Training epoch 82:  29%|██▊       | 32/112 [00:00<00:01, 52.02it/s, Epoch: 82, Batch: 33,Loss: -3.101,Avg.Loss: -3.419,LR: 4.19E-05]Training epoch 82:  29%|██▉       | 33/112 [00:00<00:01, 52.02it/s, Epoch: 82, Batch: 34,Loss: -3.602,Avg.Loss: -3.424,LR: 4.19E-05]Training epoch 82:  30%|███       | 34/112 [00:00<00:01, 52.02it/s, Epoch: 82, Batch: 35,Loss: -3.651,Avg.Loss: -3.431,LR: 4.19E-05]Training epoch 82:  31%|███▏      | 35/112 [00:00<00:01, 52.02it/s, Epoch: 82, Batch: 36,Loss: -3.430,Avg.Loss: -3.431,LR: 4.18E-05]Training epoch 82:  32%|███▏      | 36/112 [00:00<00:01, 52.22it/s, Epoch: 82, Batch: 36,Loss: -3.430,Avg.Loss: -3.431,LR: 4.18E-05]Training epoch 82:  32%|███▏      | 36/112 [00:00<00:01, 52.22it/s, Epoch: 82, Batch: 37,Loss: -3.296,Avg.Loss: -3.427,LR: 4.18E-05]Training epoch 82:  33%|███▎      | 37/112 [00:00<00:01, 52.22it/s, Epoch: 82, Batch: 38,Loss: -3.393,Avg.Loss: -3.426,LR: 4.17E-05]Training epoch 82:  34%|███▍      | 38/112 [00:00<00:01, 52.22it/s, Epoch: 82, Batch: 39,Loss: -3.515,Avg.Loss: -3.429,LR: 4.17E-05]Training epoch 82:  35%|███▍      | 39/112 [00:00<00:01, 52.22it/s, Epoch: 82, Batch: 40,Loss: -3.585,Avg.Loss: -3.433,LR: 4.17E-05]Training epoch 82:  36%|███▌      | 40/112 [00:00<00:01, 52.22it/s, Epoch: 82, Batch: 41,Loss: -3.394,Avg.Loss: -3.432,LR: 4.16E-05]Training epoch 82:  37%|███▋      | 41/112 [00:00<00:01, 52.22it/s, Epoch: 82, Batch: 42,Loss: -3.708,Avg.Loss: -3.438,LR: 4.16E-05]Training epoch 82:  38%|███▊      | 42/112 [00:00<00:01, 52.48it/s, Epoch: 82, Batch: 42,Loss: -3.708,Avg.Loss: -3.438,LR: 4.16E-05]Training epoch 82:  38%|███▊      | 42/112 [00:00<00:01, 52.48it/s, Epoch: 82, Batch: 43,Loss: -3.271,Avg.Loss: -3.434,LR: 4.16E-05]Training epoch 82:  38%|███▊      | 43/112 [00:00<00:01, 52.48it/s, Epoch: 82, Batch: 44,Loss: -3.837,Avg.Loss: -3.443,LR: 4.15E-05]Training epoch 82:  39%|███▉      | 44/112 [00:00<00:01, 52.48it/s, Epoch: 82, Batch: 45,Loss: -3.508,Avg.Loss: -3.445,LR: 4.15E-05]Training epoch 82:  40%|████      | 45/112 [00:00<00:01, 52.48it/s, Epoch: 82, Batch: 46,Loss: -3.663,Avg.Loss: -3.450,LR: 4.14E-05]Training epoch 82:  41%|████      | 46/112 [00:00<00:01, 52.48it/s, Epoch: 82, Batch: 47,Loss: -3.338,Avg.Loss: -3.447,LR: 4.14E-05]Training epoch 82:  42%|████▏     | 47/112 [00:00<00:01, 52.48it/s, Epoch: 82, Batch: 48,Loss: -3.599,Avg.Loss: -3.450,LR: 4.14E-05]Training epoch 82:  43%|████▎     | 48/112 [00:00<00:01, 52.52it/s, Epoch: 82, Batch: 48,Loss: -3.599,Avg.Loss: -3.450,LR: 4.14E-05]Training epoch 82:  43%|████▎     | 48/112 [00:00<00:01, 52.52it/s, Epoch: 82, Batch: 49,Loss: -3.556,Avg.Loss: -3.453,LR: 4.13E-05]Training epoch 82:  44%|████▍     | 49/112 [00:00<00:01, 52.52it/s, Epoch: 82, Batch: 50,Loss: -3.460,Avg.Loss: -3.453,LR: 4.13E-05]Training epoch 82:  45%|████▍     | 50/112 [00:00<00:01, 52.52it/s, Epoch: 82, Batch: 51,Loss: -3.722,Avg.Loss: -3.458,LR: 4.12E-05]Training epoch 82:  46%|████▌     | 51/112 [00:00<00:01, 52.52it/s, Epoch: 82, Batch: 52,Loss: -3.513,Avg.Loss: -3.459,LR: 4.12E-05]Training epoch 82:  46%|████▋     | 52/112 [00:01<00:01, 52.52it/s, Epoch: 82, Batch: 53,Loss: -2.972,Avg.Loss: -3.450,LR: 4.12E-05]Training epoch 82:  47%|████▋     | 53/112 [00:01<00:01, 52.52it/s, Epoch: 82, Batch: 54,Loss: -3.466,Avg.Loss: -3.450,LR: 4.11E-05]Training epoch 82:  48%|████▊     | 54/112 [00:01<00:01, 52.72it/s, Epoch: 82, Batch: 54,Loss: -3.466,Avg.Loss: -3.450,LR: 4.11E-05]Training epoch 82:  48%|████▊     | 54/112 [00:01<00:01, 52.72it/s, Epoch: 82, Batch: 55,Loss: -3.733,Avg.Loss: -3.455,LR: 4.11E-05]Training epoch 82:  49%|████▉     | 55/112 [00:01<00:01, 52.72it/s, Epoch: 82, Batch: 56,Loss: -3.441,Avg.Loss: -3.455,LR: 4.10E-05]Training epoch 82:  50%|█████     | 56/112 [00:01<00:01, 52.72it/s, Epoch: 82, Batch: 57,Loss: -3.636,Avg.Loss: -3.458,LR: 4.10E-05]Training epoch 82:  51%|█████     | 57/112 [00:01<00:01, 52.72it/s, Epoch: 82, Batch: 58,Loss: -3.395,Avg.Loss: -3.457,LR: 4.10E-05]Training epoch 82:  52%|█████▏    | 58/112 [00:01<00:01, 52.72it/s, Epoch: 82, Batch: 59,Loss: -3.103,Avg.Loss: -3.451,LR: 4.09E-05]Training epoch 82:  53%|█████▎    | 59/112 [00:01<00:01, 52.72it/s, Epoch: 82, Batch: 60,Loss: -3.166,Avg.Loss: -3.446,LR: 4.09E-05]Training epoch 82:  54%|█████▎    | 60/112 [00:01<00:00, 52.99it/s, Epoch: 82, Batch: 60,Loss: -3.166,Avg.Loss: -3.446,LR: 4.09E-05]Training epoch 82:  54%|█████▎    | 60/112 [00:01<00:00, 52.99it/s, Epoch: 82, Batch: 61,Loss: -3.904,Avg.Loss: -3.454,LR: 4.09E-05]Training epoch 82:  54%|█████▍    | 61/112 [00:01<00:00, 52.99it/s, Epoch: 82, Batch: 62,Loss: -3.216,Avg.Loss: -3.450,LR: 4.08E-05]Training epoch 82:  55%|█████▌    | 62/112 [00:01<00:00, 52.99it/s, Epoch: 82, Batch: 63,Loss: -3.642,Avg.Loss: -3.453,LR: 4.08E-05]Training epoch 82:  56%|█████▋    | 63/112 [00:01<00:00, 52.99it/s, Epoch: 82, Batch: 64,Loss: -3.686,Avg.Loss: -3.457,LR: 4.07E-05]Training epoch 82:  57%|█████▋    | 64/112 [00:01<00:00, 52.99it/s, Epoch: 82, Batch: 65,Loss: -3.447,Avg.Loss: -3.457,LR: 4.07E-05]Training epoch 82:  58%|█████▊    | 65/112 [00:01<00:00, 52.99it/s, Epoch: 82, Batch: 66,Loss: -3.152,Avg.Loss: -3.452,LR: 4.07E-05]Training epoch 82:  59%|█████▉    | 66/112 [00:01<00:00, 53.15it/s, Epoch: 82, Batch: 66,Loss: -3.152,Avg.Loss: -3.452,LR: 4.07E-05]Training epoch 82:  59%|█████▉    | 66/112 [00:01<00:00, 53.15it/s, Epoch: 82, Batch: 67,Loss: -3.425,Avg.Loss: -3.452,LR: 4.06E-05]Training epoch 82:  60%|█████▉    | 67/112 [00:01<00:00, 53.15it/s, Epoch: 82, Batch: 68,Loss: -3.873,Avg.Loss: -3.458,LR: 4.06E-05]Training epoch 82:  61%|██████    | 68/112 [00:01<00:00, 53.15it/s, Epoch: 82, Batch: 69,Loss: -3.670,Avg.Loss: -3.461,LR: 4.05E-05]Training epoch 82:  62%|██████▏   | 69/112 [00:01<00:00, 53.15it/s, Epoch: 82, Batch: 70,Loss: -3.426,Avg.Loss: -3.460,LR: 4.05E-05]Training epoch 82:  62%|██████▎   | 70/112 [00:01<00:00, 53.15it/s, Epoch: 82, Batch: 71,Loss: -3.137,Avg.Loss: -3.456,LR: 4.05E-05]Training epoch 82:  63%|██████▎   | 71/112 [00:01<00:00, 53.15it/s, Epoch: 82, Batch: 72,Loss: -3.195,Avg.Loss: -3.452,LR: 4.04E-05]Training epoch 82:  64%|██████▍   | 72/112 [00:01<00:00, 53.28it/s, Epoch: 82, Batch: 72,Loss: -3.195,Avg.Loss: -3.452,LR: 4.04E-05]Training epoch 82:  64%|██████▍   | 72/112 [00:01<00:00, 53.28it/s, Epoch: 82, Batch: 73,Loss: -3.675,Avg.Loss: -3.455,LR: 4.04E-05]Training epoch 82:  65%|██████▌   | 73/112 [00:01<00:00, 53.28it/s, Epoch: 82, Batch: 74,Loss: -3.408,Avg.Loss: -3.455,LR: 4.04E-05]Training epoch 82:  66%|██████▌   | 74/112 [00:01<00:00, 53.28it/s, Epoch: 82, Batch: 75,Loss: -3.145,Avg.Loss: -3.450,LR: 4.03E-05]Training epoch 82:  67%|██████▋   | 75/112 [00:01<00:00, 53.28it/s, Epoch: 82, Batch: 76,Loss: -3.381,Avg.Loss: -3.449,LR: 4.03E-05]Training epoch 82:  68%|██████▊   | 76/112 [00:01<00:00, 53.28it/s, Epoch: 82, Batch: 77,Loss: -3.314,Avg.Loss: -3.448,LR: 4.02E-05]Training epoch 82:  69%|██████▉   | 77/112 [00:01<00:00, 53.28it/s, Epoch: 82, Batch: 78,Loss: -3.763,Avg.Loss: -3.452,LR: 4.02E-05]Training epoch 82:  70%|██████▉   | 78/112 [00:01<00:00, 53.31it/s, Epoch: 82, Batch: 78,Loss: -3.763,Avg.Loss: -3.452,LR: 4.02E-05]Training epoch 82:  70%|██████▉   | 78/112 [00:01<00:00, 53.31it/s, Epoch: 82, Batch: 79,Loss: -3.815,Avg.Loss: -3.456,LR: 4.02E-05]Training epoch 82:  71%|███████   | 79/112 [00:01<00:00, 53.31it/s, Epoch: 82, Batch: 80,Loss: -3.500,Avg.Loss: -3.457,LR: 4.01E-05]Training epoch 82:  71%|███████▏  | 80/112 [00:01<00:00, 53.31it/s, Epoch: 82, Batch: 81,Loss: -3.695,Avg.Loss: -3.460,LR: 4.01E-05]Training epoch 82:  72%|███████▏  | 81/112 [00:01<00:00, 53.31it/s, Epoch: 82, Batch: 82,Loss: -3.896,Avg.Loss: -3.465,LR: 4.01E-05]Training epoch 82:  73%|███████▎  | 82/112 [00:01<00:00, 53.31it/s, Epoch: 82, Batch: 83,Loss: -3.234,Avg.Loss: -3.462,LR: 4.00E-05]Training epoch 82:  74%|███████▍  | 83/112 [00:01<00:00, 53.31it/s, Epoch: 82, Batch: 84,Loss: -3.235,Avg.Loss: -3.460,LR: 4.00E-05]Training epoch 82:  75%|███████▌  | 84/112 [00:01<00:00, 53.34it/s, Epoch: 82, Batch: 84,Loss: -3.235,Avg.Loss: -3.460,LR: 4.00E-05]Training epoch 82:  75%|███████▌  | 84/112 [00:01<00:00, 53.34it/s, Epoch: 82, Batch: 85,Loss: -3.197,Avg.Loss: -3.457,LR: 3.99E-05]Training epoch 82:  76%|███████▌  | 85/112 [00:01<00:00, 53.34it/s, Epoch: 82, Batch: 86,Loss: -3.819,Avg.Loss: -3.461,LR: 3.99E-05]Training epoch 82:  77%|███████▋  | 86/112 [00:01<00:00, 53.34it/s, Epoch: 82, Batch: 87,Loss: -3.498,Avg.Loss: -3.461,LR: 3.99E-05]Training epoch 82:  78%|███████▊  | 87/112 [00:01<00:00, 53.34it/s, Epoch: 82, Batch: 88,Loss: -3.503,Avg.Loss: -3.462,LR: 3.98E-05]Training epoch 82:  79%|███████▊  | 88/112 [00:01<00:00, 53.34it/s, Epoch: 82, Batch: 89,Loss: -3.463,Avg.Loss: -3.462,LR: 3.98E-05]Training epoch 82:  79%|███████▉  | 89/112 [00:01<00:00, 53.34it/s, Epoch: 82, Batch: 90,Loss: -3.661,Avg.Loss: -3.464,LR: 3.97E-05]Training epoch 82:  80%|████████  | 90/112 [00:01<00:00, 53.48it/s, Epoch: 82, Batch: 90,Loss: -3.661,Avg.Loss: -3.464,LR: 3.97E-05]Training epoch 82:  80%|████████  | 90/112 [00:01<00:00, 53.48it/s, Epoch: 82, Batch: 91,Loss: -3.922,Avg.Loss: -3.469,LR: 3.97E-05]Training epoch 82:  81%|████████▏ | 91/112 [00:01<00:00, 53.48it/s, Epoch: 82, Batch: 92,Loss: -3.498,Avg.Loss: -3.469,LR: 3.97E-05]Training epoch 82:  82%|████████▏ | 92/112 [00:01<00:00, 53.48it/s, Epoch: 82, Batch: 93,Loss: -3.356,Avg.Loss: -3.468,LR: 3.96E-05]Training epoch 82:  83%|████████▎ | 93/112 [00:01<00:00, 53.48it/s, Epoch: 82, Batch: 94,Loss: -3.502,Avg.Loss: -3.468,LR: 3.96E-05]Training epoch 82:  84%|████████▍ | 94/112 [00:01<00:00, 53.48it/s, Epoch: 82, Batch: 95,Loss: -3.498,Avg.Loss: -3.469,LR: 3.96E-05]Training epoch 82:  85%|████████▍ | 95/112 [00:01<00:00, 53.48it/s, Epoch: 82, Batch: 96,Loss: -4.013,Avg.Loss: -3.474,LR: 3.95E-05]Training epoch 82:  86%|████████▌ | 96/112 [00:01<00:00, 53.36it/s, Epoch: 82, Batch: 96,Loss: -4.013,Avg.Loss: -3.474,LR: 3.95E-05]Training epoch 82:  86%|████████▌ | 96/112 [00:01<00:00, 53.36it/s, Epoch: 82, Batch: 97,Loss: -3.577,Avg.Loss: -3.475,LR: 3.95E-05]Training epoch 82:  87%|████████▋ | 97/112 [00:01<00:00, 53.36it/s, Epoch: 82, Batch: 98,Loss: -3.501,Avg.Loss: -3.476,LR: 3.94E-05]Training epoch 82:  88%|████████▊ | 98/112 [00:01<00:00, 53.36it/s, Epoch: 82, Batch: 99,Loss: -3.172,Avg.Loss: -3.473,LR: 3.94E-05]Training epoch 82:  88%|████████▊ | 99/112 [00:01<00:00, 53.36it/s, Epoch: 82, Batch: 100,Loss: -3.302,Avg.Loss: -3.471,LR: 3.94E-05]Training epoch 82:  89%|████████▉ | 100/112 [00:01<00:00, 53.36it/s, Epoch: 82, Batch: 101,Loss: -3.754,Avg.Loss: -3.474,LR: 3.93E-05]Training epoch 82:  90%|█████████ | 101/112 [00:01<00:00, 53.36it/s, Epoch: 82, Batch: 102,Loss: -3.649,Avg.Loss: -3.475,LR: 3.93E-05]Training epoch 82:  91%|█████████ | 102/112 [00:01<00:00, 53.53it/s, Epoch: 82, Batch: 102,Loss: -3.649,Avg.Loss: -3.475,LR: 3.93E-05]Training epoch 82:  91%|█████████ | 102/112 [00:01<00:00, 53.53it/s, Epoch: 82, Batch: 103,Loss: -3.631,Avg.Loss: -3.477,LR: 3.93E-05]Training epoch 82:  92%|█████████▏| 103/112 [00:01<00:00, 53.53it/s, Epoch: 82, Batch: 104,Loss: -3.588,Avg.Loss: -3.478,LR: 3.92E-05]Training epoch 82:  93%|█████████▎| 104/112 [00:01<00:00, 53.53it/s, Epoch: 82, Batch: 105,Loss: -3.448,Avg.Loss: -3.478,LR: 3.92E-05]Training epoch 82:  94%|█████████▍| 105/112 [00:01<00:00, 53.53it/s, Epoch: 82, Batch: 106,Loss: -3.557,Avg.Loss: -3.479,LR: 3.91E-05]Training epoch 82:  95%|█████████▍| 106/112 [00:02<00:00, 53.53it/s, Epoch: 82, Batch: 107,Loss: -3.191,Avg.Loss: -3.476,LR: 3.91E-05]Training epoch 82:  96%|█████████▌| 107/112 [00:02<00:00, 53.53it/s, Epoch: 82, Batch: 108,Loss: -3.842,Avg.Loss: -3.479,LR: 3.91E-05]Training epoch 82:  96%|█████████▋| 108/112 [00:02<00:00, 53.82it/s, Epoch: 82, Batch: 108,Loss: -3.842,Avg.Loss: -3.479,LR: 3.91E-05]Training epoch 82:  96%|█████████▋| 108/112 [00:02<00:00, 53.82it/s, Epoch: 82, Batch: 109,Loss: -3.500,Avg.Loss: -3.479,LR: 3.90E-05]Training epoch 82:  97%|█████████▋| 109/112 [00:02<00:00, 53.82it/s, Epoch: 82, Batch: 110,Loss: -3.414,Avg.Loss: -3.479,LR: 3.90E-05]Training epoch 82:  98%|█████████▊| 110/112 [00:02<00:00, 53.82it/s, Epoch: 82, Batch: 111,Loss: -3.619,Avg.Loss: -3.480,LR: 3.90E-05]Training epoch 82:  99%|█████████▉| 111/112 [00:02<00:00, 53.82it/s, Epoch: 82, Batch: 112,Loss: -2.264,Avg.Loss: -3.469,LR: 3.89E-05]Training epoch 82: 100%|██████████| 112/112 [00:02<00:00, 53.10it/s, Epoch: 82, Batch: 112,Loss: -2.264,Avg.Loss: -3.469,LR: 3.89E-05]
Training epoch 83:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 83:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 83, Batch: 1,Loss: -3.777,Avg.Loss: -3.777,LR: 3.89E-05]Training epoch 83:   1%|          | 1/112 [00:00<00:04, 27.33it/s, Epoch: 83, Batch: 2,Loss: -3.446,Avg.Loss: -3.611,LR: 3.88E-05]Training epoch 83:   2%|▏         | 2/112 [00:00<00:02, 39.53it/s, Epoch: 83, Batch: 3,Loss: -3.385,Avg.Loss: -3.536,LR: 3.88E-05]Training epoch 83:   3%|▎         | 3/112 [00:00<00:02, 43.95it/s, Epoch: 83, Batch: 4,Loss: -3.764,Avg.Loss: -3.593,LR: 3.88E-05]Training epoch 83:   4%|▎         | 4/112 [00:00<00:02, 45.98it/s, Epoch: 83, Batch: 5,Loss: -3.343,Avg.Loss: -3.543,LR: 3.87E-05]Training epoch 83:   4%|▍         | 5/112 [00:00<00:02, 47.21it/s, Epoch: 83, Batch: 6,Loss: -3.533,Avg.Loss: -3.541,LR: 3.87E-05]Training epoch 83:   5%|▌         | 6/112 [00:00<00:01, 56.55it/s, Epoch: 83, Batch: 6,Loss: -3.533,Avg.Loss: -3.541,LR: 3.87E-05]Training epoch 83:   5%|▌         | 6/112 [00:00<00:01, 56.55it/s, Epoch: 83, Batch: 7,Loss: -3.352,Avg.Loss: -3.514,LR: 3.87E-05]Training epoch 83:   6%|▋         | 7/112 [00:00<00:01, 56.55it/s, Epoch: 83, Batch: 8,Loss: -3.648,Avg.Loss: -3.531,LR: 3.86E-05]Training epoch 83:   7%|▋         | 8/112 [00:00<00:01, 56.55it/s, Epoch: 83, Batch: 9,Loss: -3.580,Avg.Loss: -3.536,LR: 3.86E-05]Training epoch 83:   8%|▊         | 9/112 [00:00<00:01, 56.55it/s, Epoch: 83, Batch: 10,Loss: -3.485,Avg.Loss: -3.531,LR: 3.85E-05]Training epoch 83:   9%|▉         | 10/112 [00:00<00:01, 56.55it/s, Epoch: 83, Batch: 11,Loss: -3.116,Avg.Loss: -3.494,LR: 3.85E-05]Training epoch 83:  10%|▉         | 11/112 [00:00<00:01, 56.55it/s, Epoch: 83, Batch: 12,Loss: -2.940,Avg.Loss: -3.447,LR: 3.85E-05]Training epoch 83:  11%|█         | 12/112 [00:00<00:01, 54.33it/s, Epoch: 83, Batch: 12,Loss: -2.940,Avg.Loss: -3.447,LR: 3.85E-05]Training epoch 83:  11%|█         | 12/112 [00:00<00:01, 54.33it/s, Epoch: 83, Batch: 13,Loss: -3.168,Avg.Loss: -3.426,LR: 3.84E-05]Training epoch 83:  12%|█▏        | 13/112 [00:00<00:01, 54.33it/s, Epoch: 83, Batch: 14,Loss: -3.344,Avg.Loss: -3.420,LR: 3.84E-05]Training epoch 83:  12%|█▎        | 14/112 [00:00<00:01, 54.33it/s, Epoch: 83, Batch: 15,Loss: -3.612,Avg.Loss: -3.433,LR: 3.84E-05]Training epoch 83:  13%|█▎        | 15/112 [00:00<00:01, 54.33it/s, Epoch: 83, Batch: 16,Loss: -2.695,Avg.Loss: -3.387,LR: 3.83E-05]Training epoch 83:  14%|█▍        | 16/112 [00:00<00:01, 54.33it/s, Epoch: 83, Batch: 17,Loss: -3.526,Avg.Loss: -3.395,LR: 3.83E-05]Training epoch 83:  15%|█▌        | 17/112 [00:00<00:01, 54.33it/s, Epoch: 83, Batch: 18,Loss: -3.453,Avg.Loss: -3.398,LR: 3.82E-05]Training epoch 83:  16%|█▌        | 18/112 [00:00<00:01, 53.65it/s, Epoch: 83, Batch: 18,Loss: -3.453,Avg.Loss: -3.398,LR: 3.82E-05]Training epoch 83:  16%|█▌        | 18/112 [00:00<00:01, 53.65it/s, Epoch: 83, Batch: 19,Loss: -3.706,Avg.Loss: -3.414,LR: 3.82E-05]Training epoch 83:  17%|█▋        | 19/112 [00:00<00:01, 53.65it/s, Epoch: 83, Batch: 20,Loss: -3.773,Avg.Loss: -3.432,LR: 3.82E-05]Training epoch 83:  18%|█▊        | 20/112 [00:00<00:01, 53.65it/s, Epoch: 83, Batch: 21,Loss: -3.263,Avg.Loss: -3.424,LR: 3.81E-05]Training epoch 83:  19%|█▉        | 21/112 [00:00<00:01, 53.65it/s, Epoch: 83, Batch: 22,Loss: -3.626,Avg.Loss: -3.433,LR: 3.81E-05]Training epoch 83:  20%|█▉        | 22/112 [00:00<00:01, 53.65it/s, Epoch: 83, Batch: 23,Loss: -3.711,Avg.Loss: -3.445,LR: 3.81E-05]Training epoch 83:  21%|██        | 23/112 [00:00<00:01, 53.65it/s, Epoch: 83, Batch: 24,Loss: -3.298,Avg.Loss: -3.439,LR: 3.80E-05]Training epoch 83:  21%|██▏       | 24/112 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 24,Loss: -3.298,Avg.Loss: -3.439,LR: 3.80E-05]Training epoch 83:  21%|██▏       | 24/112 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 25,Loss: -3.585,Avg.Loss: -3.445,LR: 3.80E-05]Training epoch 83:  22%|██▏       | 25/112 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 26,Loss: -3.964,Avg.Loss: -3.465,LR: 3.79E-05]Training epoch 83:  23%|██▎       | 26/112 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 27,Loss: -3.280,Avg.Loss: -3.458,LR: 3.79E-05]Training epoch 83:  24%|██▍       | 27/112 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 28,Loss: -3.119,Avg.Loss: -3.446,LR: 3.79E-05]Training epoch 83:  25%|██▌       | 28/112 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 29,Loss: -3.099,Avg.Loss: -3.434,LR: 3.78E-05]Training epoch 83:  26%|██▌       | 29/112 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 30,Loss: -3.651,Avg.Loss: -3.441,LR: 3.78E-05]Training epoch 83:  27%|██▋       | 30/112 [00:00<00:01, 52.79it/s, Epoch: 83, Batch: 30,Loss: -3.651,Avg.Loss: -3.441,LR: 3.78E-05]Training epoch 83:  27%|██▋       | 30/112 [00:00<00:01, 52.79it/s, Epoch: 83, Batch: 31,Loss: -3.610,Avg.Loss: -3.447,LR: 3.78E-05]Training epoch 83:  28%|██▊       | 31/112 [00:00<00:01, 52.79it/s, Epoch: 83, Batch: 32,Loss: -3.642,Avg.Loss: -3.453,LR: 3.77E-05]Training epoch 83:  29%|██▊       | 32/112 [00:00<00:01, 52.79it/s, Epoch: 83, Batch: 33,Loss: -3.359,Avg.Loss: -3.450,LR: 3.77E-05]Training epoch 83:  29%|██▉       | 33/112 [00:00<00:01, 52.79it/s, Epoch: 83, Batch: 34,Loss: -3.242,Avg.Loss: -3.444,LR: 3.77E-05]Training epoch 83:  30%|███       | 34/112 [00:00<00:01, 52.79it/s, Epoch: 83, Batch: 35,Loss: -3.559,Avg.Loss: -3.447,LR: 3.76E-05]Training epoch 83:  31%|███▏      | 35/112 [00:00<00:01, 52.79it/s, Epoch: 83, Batch: 36,Loss: -3.660,Avg.Loss: -3.453,LR: 3.76E-05]Training epoch 83:  32%|███▏      | 36/112 [00:00<00:01, 53.37it/s, Epoch: 83, Batch: 36,Loss: -3.660,Avg.Loss: -3.453,LR: 3.76E-05]Training epoch 83:  32%|███▏      | 36/112 [00:00<00:01, 53.37it/s, Epoch: 83, Batch: 37,Loss: -3.793,Avg.Loss: -3.462,LR: 3.75E-05]Training epoch 83:  33%|███▎      | 37/112 [00:00<00:01, 53.37it/s, Epoch: 83, Batch: 38,Loss: -3.447,Avg.Loss: -3.462,LR: 3.75E-05]Training epoch 83:  34%|███▍      | 38/112 [00:00<00:01, 53.37it/s, Epoch: 83, Batch: 39,Loss: -3.868,Avg.Loss: -3.472,LR: 3.75E-05]Training epoch 83:  35%|███▍      | 39/112 [00:00<00:01, 53.37it/s, Epoch: 83, Batch: 40,Loss: -3.803,Avg.Loss: -3.481,LR: 3.74E-05]Training epoch 83:  36%|███▌      | 40/112 [00:00<00:01, 53.37it/s, Epoch: 83, Batch: 41,Loss: -3.402,Avg.Loss: -3.479,LR: 3.74E-05]Training epoch 83:  37%|███▋      | 41/112 [00:00<00:01, 53.37it/s, Epoch: 83, Batch: 42,Loss: -3.820,Avg.Loss: -3.487,LR: 3.74E-05]Training epoch 83:  38%|███▊      | 42/112 [00:00<00:01, 53.18it/s, Epoch: 83, Batch: 42,Loss: -3.820,Avg.Loss: -3.487,LR: 3.74E-05]Training epoch 83:  38%|███▊      | 42/112 [00:00<00:01, 53.18it/s, Epoch: 83, Batch: 43,Loss: -3.372,Avg.Loss: -3.484,LR: 3.73E-05]Training epoch 83:  38%|███▊      | 43/112 [00:00<00:01, 53.18it/s, Epoch: 83, Batch: 44,Loss: -3.535,Avg.Loss: -3.485,LR: 3.73E-05]Training epoch 83:  39%|███▉      | 44/112 [00:00<00:01, 53.18it/s, Epoch: 83, Batch: 45,Loss: -3.264,Avg.Loss: -3.480,LR: 3.72E-05]Training epoch 83:  40%|████      | 45/112 [00:00<00:01, 53.18it/s, Epoch: 83, Batch: 46,Loss: -3.857,Avg.Loss: -3.489,LR: 3.72E-05]Training epoch 83:  41%|████      | 46/112 [00:00<00:01, 53.18it/s, Epoch: 83, Batch: 47,Loss: -3.273,Avg.Loss: -3.484,LR: 3.72E-05]Training epoch 83:  42%|████▏     | 47/112 [00:00<00:01, 53.18it/s, Epoch: 83, Batch: 48,Loss: -3.495,Avg.Loss: -3.484,LR: 3.71E-05]Training epoch 83:  43%|████▎     | 48/112 [00:00<00:01, 52.76it/s, Epoch: 83, Batch: 48,Loss: -3.495,Avg.Loss: -3.484,LR: 3.71E-05]Training epoch 83:  43%|████▎     | 48/112 [00:00<00:01, 52.76it/s, Epoch: 83, Batch: 49,Loss: -3.298,Avg.Loss: -3.480,LR: 3.71E-05]Training epoch 83:  44%|████▍     | 49/112 [00:00<00:01, 52.76it/s, Epoch: 83, Batch: 50,Loss: -3.781,Avg.Loss: -3.486,LR: 3.71E-05]Training epoch 83:  45%|████▍     | 50/112 [00:00<00:01, 52.76it/s, Epoch: 83, Batch: 51,Loss: -3.400,Avg.Loss: -3.485,LR: 3.70E-05]Training epoch 83:  46%|████▌     | 51/112 [00:00<00:01, 52.76it/s, Epoch: 83, Batch: 52,Loss: -3.163,Avg.Loss: -3.479,LR: 3.70E-05]Training epoch 83:  46%|████▋     | 52/112 [00:01<00:01, 52.76it/s, Epoch: 83, Batch: 53,Loss: -3.182,Avg.Loss: -3.473,LR: 3.69E-05]Training epoch 83:  47%|████▋     | 53/112 [00:01<00:01, 52.76it/s, Epoch: 83, Batch: 54,Loss: -3.687,Avg.Loss: -3.477,LR: 3.69E-05]Training epoch 83:  48%|████▊     | 54/112 [00:01<00:01, 52.23it/s, Epoch: 83, Batch: 54,Loss: -3.687,Avg.Loss: -3.477,LR: 3.69E-05]Training epoch 83:  48%|████▊     | 54/112 [00:01<00:01, 52.23it/s, Epoch: 83, Batch: 55,Loss: -3.598,Avg.Loss: -3.479,LR: 3.69E-05]Training epoch 83:  49%|████▉     | 55/112 [00:01<00:01, 52.23it/s, Epoch: 83, Batch: 56,Loss: -3.203,Avg.Loss: -3.474,LR: 3.68E-05]Training epoch 83:  50%|█████     | 56/112 [00:01<00:01, 52.23it/s, Epoch: 83, Batch: 57,Loss: -3.564,Avg.Loss: -3.476,LR: 3.68E-05]Training epoch 83:  51%|█████     | 57/112 [00:01<00:01, 52.23it/s, Epoch: 83, Batch: 58,Loss: -3.648,Avg.Loss: -3.479,LR: 3.68E-05]Training epoch 83:  52%|█████▏    | 58/112 [00:01<00:01, 52.23it/s, Epoch: 83, Batch: 59,Loss: -3.924,Avg.Loss: -3.486,LR: 3.67E-05]Training epoch 83:  53%|█████▎    | 59/112 [00:01<00:01, 52.23it/s, Epoch: 83, Batch: 60,Loss: -3.253,Avg.Loss: -3.482,LR: 3.67E-05]Training epoch 83:  54%|█████▎    | 60/112 [00:01<00:01, 50.73it/s, Epoch: 83, Batch: 60,Loss: -3.253,Avg.Loss: -3.482,LR: 3.67E-05]Training epoch 83:  54%|█████▎    | 60/112 [00:01<00:01, 50.73it/s, Epoch: 83, Batch: 61,Loss: -3.295,Avg.Loss: -3.479,LR: 3.67E-05]Training epoch 83:  54%|█████▍    | 61/112 [00:01<00:01, 50.73it/s, Epoch: 83, Batch: 62,Loss: -3.728,Avg.Loss: -3.483,LR: 3.66E-05]Training epoch 83:  55%|█████▌    | 62/112 [00:01<00:00, 50.73it/s, Epoch: 83, Batch: 63,Loss: -3.588,Avg.Loss: -3.485,LR: 3.66E-05]Training epoch 83:  56%|█████▋    | 63/112 [00:01<00:00, 50.73it/s, Epoch: 83, Batch: 64,Loss: -3.367,Avg.Loss: -3.483,LR: 3.65E-05]Training epoch 83:  57%|█████▋    | 64/112 [00:01<00:00, 50.73it/s, Epoch: 83, Batch: 65,Loss: -3.660,Avg.Loss: -3.486,LR: 3.65E-05]Training epoch 83:  58%|█████▊    | 65/112 [00:01<00:00, 50.73it/s, Epoch: 83, Batch: 66,Loss: -3.449,Avg.Loss: -3.485,LR: 3.65E-05]Training epoch 83:  59%|█████▉    | 66/112 [00:01<00:00, 51.77it/s, Epoch: 83, Batch: 66,Loss: -3.449,Avg.Loss: -3.485,LR: 3.65E-05]Training epoch 83:  59%|█████▉    | 66/112 [00:01<00:00, 51.77it/s, Epoch: 83, Batch: 67,Loss: -3.603,Avg.Loss: -3.487,LR: 3.64E-05]Training epoch 83:  60%|█████▉    | 67/112 [00:01<00:00, 51.77it/s, Epoch: 83, Batch: 68,Loss: -3.840,Avg.Loss: -3.492,LR: 3.64E-05]Training epoch 83:  61%|██████    | 68/112 [00:01<00:00, 51.77it/s, Epoch: 83, Batch: 69,Loss: -3.399,Avg.Loss: -3.491,LR: 3.64E-05]Training epoch 83:  62%|██████▏   | 69/112 [00:01<00:00, 51.77it/s, Epoch: 83, Batch: 70,Loss: -3.418,Avg.Loss: -3.490,LR: 3.63E-05]Training epoch 83:  62%|██████▎   | 70/112 [00:01<00:00, 51.77it/s, Epoch: 83, Batch: 71,Loss: -3.140,Avg.Loss: -3.485,LR: 3.63E-05]Training epoch 83:  63%|██████▎   | 71/112 [00:01<00:00, 51.77it/s, Epoch: 83, Batch: 72,Loss: -3.329,Avg.Loss: -3.483,LR: 3.63E-05]Training epoch 83:  64%|██████▍   | 72/112 [00:01<00:00, 52.21it/s, Epoch: 83, Batch: 72,Loss: -3.329,Avg.Loss: -3.483,LR: 3.63E-05]Training epoch 83:  64%|██████▍   | 72/112 [00:01<00:00, 52.21it/s, Epoch: 83, Batch: 73,Loss: -3.342,Avg.Loss: -3.481,LR: 3.62E-05]Training epoch 83:  65%|██████▌   | 73/112 [00:01<00:00, 52.21it/s, Epoch: 83, Batch: 74,Loss: -3.758,Avg.Loss: -3.485,LR: 3.62E-05]Training epoch 83:  66%|██████▌   | 74/112 [00:01<00:00, 52.21it/s, Epoch: 83, Batch: 75,Loss: -3.654,Avg.Loss: -3.487,LR: 3.61E-05]Training epoch 83:  67%|██████▋   | 75/112 [00:01<00:00, 52.21it/s, Epoch: 83, Batch: 76,Loss: -3.205,Avg.Loss: -3.483,LR: 3.61E-05]Training epoch 83:  68%|██████▊   | 76/112 [00:01<00:00, 52.21it/s, Epoch: 83, Batch: 77,Loss: -3.455,Avg.Loss: -3.483,LR: 3.61E-05]Training epoch 83:  69%|██████▉   | 77/112 [00:01<00:00, 52.21it/s, Epoch: 83, Batch: 78,Loss: -3.336,Avg.Loss: -3.481,LR: 3.60E-05]Training epoch 83:  70%|██████▉   | 78/112 [00:01<00:00, 52.60it/s, Epoch: 83, Batch: 78,Loss: -3.336,Avg.Loss: -3.481,LR: 3.60E-05]Training epoch 83:  70%|██████▉   | 78/112 [00:01<00:00, 52.60it/s, Epoch: 83, Batch: 79,Loss: -3.862,Avg.Loss: -3.486,LR: 3.60E-05]Training epoch 83:  71%|███████   | 79/112 [00:01<00:00, 52.60it/s, Epoch: 83, Batch: 80,Loss: -3.911,Avg.Loss: -3.491,LR: 3.60E-05]Training epoch 83:  71%|███████▏  | 80/112 [00:01<00:00, 52.60it/s, Epoch: 83, Batch: 81,Loss: -3.679,Avg.Loss: -3.493,LR: 3.59E-05]Training epoch 83:  72%|███████▏  | 81/112 [00:01<00:00, 52.60it/s, Epoch: 83, Batch: 82,Loss: -3.480,Avg.Loss: -3.493,LR: 3.59E-05]Training epoch 83:  73%|███████▎  | 82/112 [00:01<00:00, 52.60it/s, Epoch: 83, Batch: 83,Loss: -3.666,Avg.Loss: -3.495,LR: 3.59E-05]Training epoch 83:  74%|███████▍  | 83/112 [00:01<00:00, 52.60it/s, Epoch: 83, Batch: 84,Loss: -3.008,Avg.Loss: -3.489,LR: 3.58E-05]Training epoch 83:  75%|███████▌  | 84/112 [00:01<00:00, 52.93it/s, Epoch: 83, Batch: 84,Loss: -3.008,Avg.Loss: -3.489,LR: 3.58E-05]Training epoch 83:  75%|███████▌  | 84/112 [00:01<00:00, 52.93it/s, Epoch: 83, Batch: 85,Loss: -3.178,Avg.Loss: -3.486,LR: 3.58E-05]Training epoch 83:  76%|███████▌  | 85/112 [00:01<00:00, 52.93it/s, Epoch: 83, Batch: 86,Loss: -3.440,Avg.Loss: -3.485,LR: 3.57E-05]Training epoch 83:  77%|███████▋  | 86/112 [00:01<00:00, 52.93it/s, Epoch: 83, Batch: 87,Loss: -3.667,Avg.Loss: -3.487,LR: 3.57E-05]Training epoch 83:  78%|███████▊  | 87/112 [00:01<00:00, 52.93it/s, Epoch: 83, Batch: 88,Loss: -3.602,Avg.Loss: -3.489,LR: 3.57E-05]Training epoch 83:  79%|███████▊  | 88/112 [00:01<00:00, 52.93it/s, Epoch: 83, Batch: 89,Loss: -3.569,Avg.Loss: -3.490,LR: 3.56E-05]Training epoch 83:  79%|███████▉  | 89/112 [00:01<00:00, 52.93it/s, Epoch: 83, Batch: 90,Loss: -3.353,Avg.Loss: -3.488,LR: 3.56E-05]Training epoch 83:  80%|████████  | 90/112 [00:01<00:00, 53.02it/s, Epoch: 83, Batch: 90,Loss: -3.353,Avg.Loss: -3.488,LR: 3.56E-05]Training epoch 83:  80%|████████  | 90/112 [00:01<00:00, 53.02it/s, Epoch: 83, Batch: 91,Loss: -3.593,Avg.Loss: -3.489,LR: 3.56E-05]Training epoch 83:  81%|████████▏ | 91/112 [00:01<00:00, 53.02it/s, Epoch: 83, Batch: 92,Loss: -3.333,Avg.Loss: -3.488,LR: 3.55E-05]Training epoch 83:  82%|████████▏ | 92/112 [00:01<00:00, 53.02it/s, Epoch: 83, Batch: 93,Loss: -3.570,Avg.Loss: -3.488,LR: 3.55E-05]Training epoch 83:  83%|████████▎ | 93/112 [00:01<00:00, 53.02it/s, Epoch: 83, Batch: 94,Loss: -3.760,Avg.Loss: -3.491,LR: 3.55E-05]Training epoch 83:  84%|████████▍ | 94/112 [00:01<00:00, 53.02it/s, Epoch: 83, Batch: 95,Loss: -2.872,Avg.Loss: -3.485,LR: 3.54E-05]Training epoch 83:  85%|████████▍ | 95/112 [00:01<00:00, 53.02it/s, Epoch: 83, Batch: 96,Loss: -3.455,Avg.Loss: -3.484,LR: 3.54E-05]Training epoch 83:  86%|████████▌ | 96/112 [00:01<00:00, 53.24it/s, Epoch: 83, Batch: 96,Loss: -3.455,Avg.Loss: -3.484,LR: 3.54E-05]Training epoch 83:  86%|████████▌ | 96/112 [00:01<00:00, 53.24it/s, Epoch: 83, Batch: 97,Loss: -3.330,Avg.Loss: -3.483,LR: 3.54E-05]Training epoch 83:  87%|████████▋ | 97/112 [00:01<00:00, 53.24it/s, Epoch: 83, Batch: 98,Loss: -3.704,Avg.Loss: -3.485,LR: 3.53E-05]Training epoch 83:  88%|████████▊ | 98/112 [00:01<00:00, 53.24it/s, Epoch: 83, Batch: 99,Loss: -3.731,Avg.Loss: -3.488,LR: 3.53E-05]Training epoch 83:  88%|████████▊ | 99/112 [00:01<00:00, 53.24it/s, Epoch: 83, Batch: 100,Loss: -3.598,Avg.Loss: -3.489,LR: 3.52E-05]Training epoch 83:  89%|████████▉ | 100/112 [00:01<00:00, 53.24it/s, Epoch: 83, Batch: 101,Loss: -3.347,Avg.Loss: -3.487,LR: 3.52E-05]Training epoch 83:  90%|█████████ | 101/112 [00:01<00:00, 53.24it/s, Epoch: 83, Batch: 102,Loss: -3.912,Avg.Loss: -3.491,LR: 3.52E-05]Training epoch 83:  91%|█████████ | 102/112 [00:01<00:00, 52.82it/s, Epoch: 83, Batch: 102,Loss: -3.912,Avg.Loss: -3.491,LR: 3.52E-05]Training epoch 83:  91%|█████████ | 102/112 [00:01<00:00, 52.82it/s, Epoch: 83, Batch: 103,Loss: -3.060,Avg.Loss: -3.487,LR: 3.51E-05]Training epoch 83:  92%|█████████▏| 103/112 [00:01<00:00, 52.82it/s, Epoch: 83, Batch: 104,Loss: -3.387,Avg.Loss: -3.486,LR: 3.51E-05]Training epoch 83:  93%|█████████▎| 104/112 [00:01<00:00, 52.82it/s, Epoch: 83, Batch: 105,Loss: -2.957,Avg.Loss: -3.481,LR: 3.51E-05]Training epoch 83:  94%|█████████▍| 105/112 [00:02<00:00, 52.82it/s, Epoch: 83, Batch: 106,Loss: -3.257,Avg.Loss: -3.479,LR: 3.50E-05]Training epoch 83:  95%|█████████▍| 106/112 [00:02<00:00, 52.82it/s, Epoch: 83, Batch: 107,Loss: -3.295,Avg.Loss: -3.477,LR: 3.50E-05]Training epoch 83:  96%|█████████▌| 107/112 [00:02<00:00, 52.82it/s, Epoch: 83, Batch: 108,Loss: -3.675,Avg.Loss: -3.479,LR: 3.50E-05]Training epoch 83:  96%|█████████▋| 108/112 [00:02<00:00, 53.13it/s, Epoch: 83, Batch: 108,Loss: -3.675,Avg.Loss: -3.479,LR: 3.50E-05]Training epoch 83:  96%|█████████▋| 108/112 [00:02<00:00, 53.13it/s, Epoch: 83, Batch: 109,Loss: -3.606,Avg.Loss: -3.480,LR: 3.49E-05]Training epoch 83:  97%|█████████▋| 109/112 [00:02<00:00, 53.13it/s, Epoch: 83, Batch: 110,Loss: -3.262,Avg.Loss: -3.478,LR: 3.49E-05]Training epoch 83:  98%|█████████▊| 110/112 [00:02<00:00, 53.13it/s, Epoch: 83, Batch: 111,Loss: -3.285,Avg.Loss: -3.477,LR: 3.49E-05]Training epoch 83:  99%|█████████▉| 111/112 [00:02<00:00, 53.13it/s, Epoch: 83, Batch: 112,Loss: -2.580,Avg.Loss: -3.469,LR: 3.48E-05]Training epoch 83: 100%|██████████| 112/112 [00:02<00:00, 52.70it/s, Epoch: 83, Batch: 112,Loss: -2.580,Avg.Loss: -3.469,LR: 3.48E-05]
Training epoch 84:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 84:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 84, Batch: 1,Loss: -3.436,Avg.Loss: -3.436,LR: 3.48E-05]Training epoch 84:   1%|          | 1/112 [00:00<00:04, 23.38it/s, Epoch: 84, Batch: 2,Loss: -3.682,Avg.Loss: -3.559,LR: 3.47E-05]Training epoch 84:   2%|▏         | 2/112 [00:00<00:03, 35.45it/s, Epoch: 84, Batch: 3,Loss: -3.594,Avg.Loss: -3.571,LR: 3.47E-05]Training epoch 84:   3%|▎         | 3/112 [00:00<00:02, 40.86it/s, Epoch: 84, Batch: 4,Loss: -3.397,Avg.Loss: -3.527,LR: 3.47E-05]Training epoch 84:   4%|▎         | 4/112 [00:00<00:02, 43.39it/s, Epoch: 84, Batch: 5,Loss: -3.486,Avg.Loss: -3.519,LR: 3.46E-05]Training epoch 84:   4%|▍         | 5/112 [00:00<00:02, 44.96it/s, Epoch: 84, Batch: 6,Loss: -3.425,Avg.Loss: -3.503,LR: 3.46E-05]Training epoch 84:   5%|▌         | 6/112 [00:00<00:01, 53.86it/s, Epoch: 84, Batch: 6,Loss: -3.425,Avg.Loss: -3.503,LR: 3.46E-05]Training epoch 84:   5%|▌         | 6/112 [00:00<00:01, 53.86it/s, Epoch: 84, Batch: 7,Loss: -3.618,Avg.Loss: -3.520,LR: 3.46E-05]Training epoch 84:   6%|▋         | 7/112 [00:00<00:01, 53.86it/s, Epoch: 84, Batch: 8,Loss: -3.271,Avg.Loss: -3.489,LR: 3.45E-05]Training epoch 84:   7%|▋         | 8/112 [00:00<00:01, 53.86it/s, Epoch: 84, Batch: 9,Loss: -3.353,Avg.Loss: -3.474,LR: 3.45E-05]Training epoch 84:   8%|▊         | 9/112 [00:00<00:01, 53.86it/s, Epoch: 84, Batch: 10,Loss: -3.777,Avg.Loss: -3.504,LR: 3.45E-05]Training epoch 84:   9%|▉         | 10/112 [00:00<00:01, 53.86it/s, Epoch: 84, Batch: 11,Loss: -3.613,Avg.Loss: -3.514,LR: 3.44E-05]Training epoch 84:  10%|▉         | 11/112 [00:00<00:01, 53.86it/s, Epoch: 84, Batch: 12,Loss: -3.461,Avg.Loss: -3.509,LR: 3.44E-05]Training epoch 84:  11%|█         | 12/112 [00:00<00:01, 53.21it/s, Epoch: 84, Batch: 12,Loss: -3.461,Avg.Loss: -3.509,LR: 3.44E-05]Training epoch 84:  11%|█         | 12/112 [00:00<00:01, 53.21it/s, Epoch: 84, Batch: 13,Loss: -3.541,Avg.Loss: -3.512,LR: 3.44E-05]Training epoch 84:  12%|█▏        | 13/112 [00:00<00:01, 53.21it/s, Epoch: 84, Batch: 14,Loss: -3.416,Avg.Loss: -3.505,LR: 3.43E-05]Training epoch 84:  12%|█▎        | 14/112 [00:00<00:01, 53.21it/s, Epoch: 84, Batch: 15,Loss: -3.674,Avg.Loss: -3.516,LR: 3.43E-05]Training epoch 84:  13%|█▎        | 15/112 [00:00<00:01, 53.21it/s, Epoch: 84, Batch: 16,Loss: -3.671,Avg.Loss: -3.526,LR: 3.42E-05]Training epoch 84:  14%|█▍        | 16/112 [00:00<00:01, 53.21it/s, Epoch: 84, Batch: 17,Loss: -3.875,Avg.Loss: -3.546,LR: 3.42E-05]Training epoch 84:  15%|█▌        | 17/112 [00:00<00:01, 53.21it/s, Epoch: 84, Batch: 18,Loss: -4.001,Avg.Loss: -3.572,LR: 3.42E-05]Training epoch 84:  16%|█▌        | 18/112 [00:00<00:01, 53.22it/s, Epoch: 84, Batch: 18,Loss: -4.001,Avg.Loss: -3.572,LR: 3.42E-05]Training epoch 84:  16%|█▌        | 18/112 [00:00<00:01, 53.22it/s, Epoch: 84, Batch: 19,Loss: -3.536,Avg.Loss: -3.570,LR: 3.41E-05]Training epoch 84:  17%|█▋        | 19/112 [00:00<00:01, 53.22it/s, Epoch: 84, Batch: 20,Loss: -3.665,Avg.Loss: -3.575,LR: 3.41E-05]Training epoch 84:  18%|█▊        | 20/112 [00:00<00:01, 53.22it/s, Epoch: 84, Batch: 21,Loss: -3.532,Avg.Loss: -3.573,LR: 3.41E-05]Training epoch 84:  19%|█▉        | 21/112 [00:00<00:01, 53.22it/s, Epoch: 84, Batch: 22,Loss: -3.641,Avg.Loss: -3.576,LR: 3.40E-05]Training epoch 84:  20%|█▉        | 22/112 [00:00<00:01, 53.22it/s, Epoch: 84, Batch: 23,Loss: -3.219,Avg.Loss: -3.560,LR: 3.40E-05]Training epoch 84:  21%|██        | 23/112 [00:00<00:01, 53.22it/s, Epoch: 84, Batch: 24,Loss: -2.852,Avg.Loss: -3.531,LR: 3.40E-05]Training epoch 84:  21%|██▏       | 24/112 [00:00<00:01, 52.97it/s, Epoch: 84, Batch: 24,Loss: -2.852,Avg.Loss: -3.531,LR: 3.40E-05]Training epoch 84:  21%|██▏       | 24/112 [00:00<00:01, 52.97it/s, Epoch: 84, Batch: 25,Loss: -3.463,Avg.Loss: -3.528,LR: 3.39E-05]Training epoch 84:  22%|██▏       | 25/112 [00:00<00:01, 52.97it/s, Epoch: 84, Batch: 26,Loss: -3.690,Avg.Loss: -3.534,LR: 3.39E-05]Training epoch 84:  23%|██▎       | 26/112 [00:00<00:01, 52.97it/s, Epoch: 84, Batch: 27,Loss: -3.430,Avg.Loss: -3.530,LR: 3.39E-05]Training epoch 84:  24%|██▍       | 27/112 [00:00<00:01, 52.97it/s, Epoch: 84, Batch: 28,Loss: -2.752,Avg.Loss: -3.502,LR: 3.38E-05]Training epoch 84:  25%|██▌       | 28/112 [00:00<00:01, 52.97it/s, Epoch: 84, Batch: 29,Loss: -3.117,Avg.Loss: -3.489,LR: 3.38E-05]Training epoch 84:  26%|██▌       | 29/112 [00:00<00:01, 52.97it/s, Epoch: 84, Batch: 30,Loss: -3.647,Avg.Loss: -3.494,LR: 3.38E-05]Training epoch 84:  27%|██▋       | 30/112 [00:00<00:01, 53.04it/s, Epoch: 84, Batch: 30,Loss: -3.647,Avg.Loss: -3.494,LR: 3.38E-05]Training epoch 84:  27%|██▋       | 30/112 [00:00<00:01, 53.04it/s, Epoch: 84, Batch: 31,Loss: -3.377,Avg.Loss: -3.491,LR: 3.37E-05]Training epoch 84:  28%|██▊       | 31/112 [00:00<00:01, 53.04it/s, Epoch: 84, Batch: 32,Loss: -3.438,Avg.Loss: -3.489,LR: 3.37E-05]Training epoch 84:  29%|██▊       | 32/112 [00:00<00:01, 53.04it/s, Epoch: 84, Batch: 33,Loss: -3.577,Avg.Loss: -3.492,LR: 3.36E-05]Training epoch 84:  29%|██▉       | 33/112 [00:00<00:01, 53.04it/s, Epoch: 84, Batch: 34,Loss: -3.392,Avg.Loss: -3.489,LR: 3.36E-05]Training epoch 84:  30%|███       | 34/112 [00:00<00:01, 53.04it/s, Epoch: 84, Batch: 35,Loss: -3.682,Avg.Loss: -3.494,LR: 3.36E-05]Training epoch 84:  31%|███▏      | 35/112 [00:00<00:01, 53.04it/s, Epoch: 84, Batch: 36,Loss: -3.511,Avg.Loss: -3.495,LR: 3.35E-05]Training epoch 84:  32%|███▏      | 36/112 [00:00<00:01, 53.15it/s, Epoch: 84, Batch: 36,Loss: -3.511,Avg.Loss: -3.495,LR: 3.35E-05]Training epoch 84:  32%|███▏      | 36/112 [00:00<00:01, 53.15it/s, Epoch: 84, Batch: 37,Loss: -3.591,Avg.Loss: -3.497,LR: 3.35E-05]Training epoch 84:  33%|███▎      | 37/112 [00:00<00:01, 53.15it/s, Epoch: 84, Batch: 38,Loss: -3.546,Avg.Loss: -3.499,LR: 3.35E-05]Training epoch 84:  34%|███▍      | 38/112 [00:00<00:01, 53.15it/s, Epoch: 84, Batch: 39,Loss: -3.512,Avg.Loss: -3.499,LR: 3.34E-05]Training epoch 84:  35%|███▍      | 39/112 [00:00<00:01, 53.15it/s, Epoch: 84, Batch: 40,Loss: -3.552,Avg.Loss: -3.500,LR: 3.34E-05]Training epoch 84:  36%|███▌      | 40/112 [00:00<00:01, 53.15it/s, Epoch: 84, Batch: 41,Loss: -3.270,Avg.Loss: -3.495,LR: 3.34E-05]Training epoch 84:  37%|███▋      | 41/112 [00:00<00:01, 53.15it/s, Epoch: 84, Batch: 42,Loss: -3.396,Avg.Loss: -3.492,LR: 3.33E-05]Training epoch 84:  38%|███▊      | 42/112 [00:00<00:01, 52.93it/s, Epoch: 84, Batch: 42,Loss: -3.396,Avg.Loss: -3.492,LR: 3.33E-05]Training epoch 84:  38%|███▊      | 42/112 [00:00<00:01, 52.93it/s, Epoch: 84, Batch: 43,Loss: -3.372,Avg.Loss: -3.490,LR: 3.33E-05]Training epoch 84:  38%|███▊      | 43/112 [00:00<00:01, 52.93it/s, Epoch: 84, Batch: 44,Loss: -3.914,Avg.Loss: -3.499,LR: 3.33E-05]Training epoch 84:  39%|███▉      | 44/112 [00:00<00:01, 52.93it/s, Epoch: 84, Batch: 45,Loss: -3.813,Avg.Loss: -3.506,LR: 3.32E-05]Training epoch 84:  40%|████      | 45/112 [00:00<00:01, 52.93it/s, Epoch: 84, Batch: 46,Loss: -3.648,Avg.Loss: -3.509,LR: 3.32E-05]Training epoch 84:  41%|████      | 46/112 [00:00<00:01, 52.93it/s, Epoch: 84, Batch: 47,Loss: -3.667,Avg.Loss: -3.513,LR: 3.32E-05]Training epoch 84:  42%|████▏     | 47/112 [00:00<00:01, 52.93it/s, Epoch: 84, Batch: 48,Loss: -4.179,Avg.Loss: -3.526,LR: 3.31E-05]Training epoch 84:  43%|████▎     | 48/112 [00:00<00:01, 52.49it/s, Epoch: 84, Batch: 48,Loss: -4.179,Avg.Loss: -3.526,LR: 3.31E-05]Training epoch 84:  43%|████▎     | 48/112 [00:00<00:01, 52.49it/s, Epoch: 84, Batch: 49,Loss: -3.350,Avg.Loss: -3.523,LR: 3.31E-05]Training epoch 84:  44%|████▍     | 49/112 [00:00<00:01, 52.49it/s, Epoch: 84, Batch: 50,Loss: -3.947,Avg.Loss: -3.531,LR: 3.31E-05]Training epoch 84:  45%|████▍     | 50/112 [00:00<00:01, 52.49it/s, Epoch: 84, Batch: 51,Loss: -3.689,Avg.Loss: -3.534,LR: 3.30E-05]Training epoch 84:  46%|████▌     | 51/112 [00:00<00:01, 52.49it/s, Epoch: 84, Batch: 52,Loss: -2.560,Avg.Loss: -3.516,LR: 3.30E-05]Training epoch 84:  46%|████▋     | 52/112 [00:01<00:01, 52.49it/s, Epoch: 84, Batch: 53,Loss: -3.612,Avg.Loss: -3.517,LR: 3.29E-05]Training epoch 84:  47%|████▋     | 53/112 [00:01<00:01, 52.49it/s, Epoch: 84, Batch: 54,Loss: -3.511,Avg.Loss: -3.517,LR: 3.29E-05]Training epoch 84:  48%|████▊     | 54/112 [00:01<00:01, 52.61it/s, Epoch: 84, Batch: 54,Loss: -3.511,Avg.Loss: -3.517,LR: 3.29E-05]Training epoch 84:  48%|████▊     | 54/112 [00:01<00:01, 52.61it/s, Epoch: 84, Batch: 55,Loss: -3.443,Avg.Loss: -3.516,LR: 3.29E-05]Training epoch 84:  49%|████▉     | 55/112 [00:01<00:01, 52.61it/s, Epoch: 84, Batch: 56,Loss: -3.397,Avg.Loss: -3.514,LR: 3.28E-05]Training epoch 84:  50%|█████     | 56/112 [00:01<00:01, 52.61it/s, Epoch: 84, Batch: 57,Loss: -3.151,Avg.Loss: -3.508,LR: 3.28E-05]Training epoch 84:  51%|█████     | 57/112 [00:01<00:01, 52.61it/s, Epoch: 84, Batch: 58,Loss: -3.688,Avg.Loss: -3.511,LR: 3.28E-05]Training epoch 84:  52%|█████▏    | 58/112 [00:01<00:01, 52.61it/s, Epoch: 84, Batch: 59,Loss: -3.978,Avg.Loss: -3.519,LR: 3.27E-05]Training epoch 84:  53%|█████▎    | 59/112 [00:01<00:01, 52.61it/s, Epoch: 84, Batch: 60,Loss: -3.977,Avg.Loss: -3.526,LR: 3.27E-05]Training epoch 84:  54%|█████▎    | 60/112 [00:01<00:00, 52.70it/s, Epoch: 84, Batch: 60,Loss: -3.977,Avg.Loss: -3.526,LR: 3.27E-05]Training epoch 84:  54%|█████▎    | 60/112 [00:01<00:00, 52.70it/s, Epoch: 84, Batch: 61,Loss: -3.218,Avg.Loss: -3.521,LR: 3.27E-05]Training epoch 84:  54%|█████▍    | 61/112 [00:01<00:00, 52.70it/s, Epoch: 84, Batch: 62,Loss: -3.305,Avg.Loss: -3.518,LR: 3.26E-05]Training epoch 84:  55%|█████▌    | 62/112 [00:01<00:00, 52.70it/s, Epoch: 84, Batch: 63,Loss: -3.373,Avg.Loss: -3.515,LR: 3.26E-05]Training epoch 84:  56%|█████▋    | 63/112 [00:01<00:00, 52.70it/s, Epoch: 84, Batch: 64,Loss: -3.207,Avg.Loss: -3.511,LR: 3.26E-05]Training epoch 84:  57%|█████▋    | 64/112 [00:01<00:00, 52.70it/s, Epoch: 84, Batch: 65,Loss: -3.753,Avg.Loss: -3.514,LR: 3.25E-05]Training epoch 84:  58%|█████▊    | 65/112 [00:01<00:00, 52.70it/s, Epoch: 84, Batch: 66,Loss: -3.758,Avg.Loss: -3.518,LR: 3.25E-05]Training epoch 84:  59%|█████▉    | 66/112 [00:01<00:00, 52.82it/s, Epoch: 84, Batch: 66,Loss: -3.758,Avg.Loss: -3.518,LR: 3.25E-05]Training epoch 84:  59%|█████▉    | 66/112 [00:01<00:00, 52.82it/s, Epoch: 84, Batch: 67,Loss: -3.553,Avg.Loss: -3.519,LR: 3.25E-05]Training epoch 84:  60%|█████▉    | 67/112 [00:01<00:00, 52.82it/s, Epoch: 84, Batch: 68,Loss: -3.649,Avg.Loss: -3.520,LR: 3.24E-05]Training epoch 84:  61%|██████    | 68/112 [00:01<00:00, 52.82it/s, Epoch: 84, Batch: 69,Loss: -3.709,Avg.Loss: -3.523,LR: 3.24E-05]Training epoch 84:  62%|██████▏   | 69/112 [00:01<00:00, 52.82it/s, Epoch: 84, Batch: 70,Loss: -3.574,Avg.Loss: -3.524,LR: 3.24E-05]Training epoch 84:  62%|██████▎   | 70/112 [00:01<00:00, 52.82it/s, Epoch: 84, Batch: 71,Loss: -3.967,Avg.Loss: -3.530,LR: 3.23E-05]Training epoch 84:  63%|██████▎   | 71/112 [00:01<00:00, 52.82it/s, Epoch: 84, Batch: 72,Loss: -2.929,Avg.Loss: -3.522,LR: 3.23E-05]Training epoch 84:  64%|██████▍   | 72/112 [00:01<00:00, 53.03it/s, Epoch: 84, Batch: 72,Loss: -2.929,Avg.Loss: -3.522,LR: 3.23E-05]Training epoch 84:  64%|██████▍   | 72/112 [00:01<00:00, 53.03it/s, Epoch: 84, Batch: 73,Loss: -3.293,Avg.Loss: -3.519,LR: 3.23E-05]Training epoch 84:  65%|██████▌   | 73/112 [00:01<00:00, 53.03it/s, Epoch: 84, Batch: 74,Loss: -3.452,Avg.Loss: -3.518,LR: 3.22E-05]Training epoch 84:  66%|██████▌   | 74/112 [00:01<00:00, 53.03it/s, Epoch: 84, Batch: 75,Loss: -3.576,Avg.Loss: -3.519,LR: 3.22E-05]Training epoch 84:  67%|██████▋   | 75/112 [00:01<00:00, 53.03it/s, Epoch: 84, Batch: 76,Loss: -3.365,Avg.Loss: -3.516,LR: 3.22E-05]Training epoch 84:  68%|██████▊   | 76/112 [00:01<00:00, 53.03it/s, Epoch: 84, Batch: 77,Loss: -3.273,Avg.Loss: -3.513,LR: 3.21E-05]Training epoch 84:  69%|██████▉   | 77/112 [00:01<00:00, 53.03it/s, Epoch: 84, Batch: 78,Loss: -3.778,Avg.Loss: -3.517,LR: 3.21E-05]Training epoch 84:  70%|██████▉   | 78/112 [00:01<00:00, 53.15it/s, Epoch: 84, Batch: 78,Loss: -3.778,Avg.Loss: -3.517,LR: 3.21E-05]Training epoch 84:  70%|██████▉   | 78/112 [00:01<00:00, 53.15it/s, Epoch: 84, Batch: 79,Loss: -3.996,Avg.Loss: -3.523,LR: 3.20E-05]Training epoch 84:  71%|███████   | 79/112 [00:01<00:00, 53.15it/s, Epoch: 84, Batch: 80,Loss: -3.665,Avg.Loss: -3.525,LR: 3.20E-05]Training epoch 84:  71%|███████▏  | 80/112 [00:01<00:00, 53.15it/s, Epoch: 84, Batch: 81,Loss: -3.909,Avg.Loss: -3.529,LR: 3.20E-05]Training epoch 84:  72%|███████▏  | 81/112 [00:01<00:00, 53.15it/s, Epoch: 84, Batch: 82,Loss: -3.783,Avg.Loss: -3.532,LR: 3.19E-05]Training epoch 84:  73%|███████▎  | 82/112 [00:01<00:00, 53.15it/s, Epoch: 84, Batch: 83,Loss: -3.472,Avg.Loss: -3.532,LR: 3.19E-05]Training epoch 84:  74%|███████▍  | 83/112 [00:01<00:00, 53.15it/s, Epoch: 84, Batch: 84,Loss: -3.472,Avg.Loss: -3.531,LR: 3.19E-05]Training epoch 84:  75%|███████▌  | 84/112 [00:01<00:00, 53.22it/s, Epoch: 84, Batch: 84,Loss: -3.472,Avg.Loss: -3.531,LR: 3.19E-05]Training epoch 84:  75%|███████▌  | 84/112 [00:01<00:00, 53.22it/s, Epoch: 84, Batch: 85,Loss: -3.273,Avg.Loss: -3.528,LR: 3.18E-05]Training epoch 84:  76%|███████▌  | 85/112 [00:01<00:00, 53.22it/s, Epoch: 84, Batch: 86,Loss: -3.748,Avg.Loss: -3.530,LR: 3.18E-05]Training epoch 84:  77%|███████▋  | 86/112 [00:01<00:00, 53.22it/s, Epoch: 84, Batch: 87,Loss: -3.768,Avg.Loss: -3.533,LR: 3.18E-05]Training epoch 84:  78%|███████▊  | 87/112 [00:01<00:00, 53.22it/s, Epoch: 84, Batch: 88,Loss: -3.533,Avg.Loss: -3.533,LR: 3.17E-05]Training epoch 84:  79%|███████▊  | 88/112 [00:01<00:00, 53.22it/s, Epoch: 84, Batch: 89,Loss: -3.823,Avg.Loss: -3.536,LR: 3.17E-05]Training epoch 84:  79%|███████▉  | 89/112 [00:01<00:00, 53.22it/s, Epoch: 84, Batch: 90,Loss: -3.916,Avg.Loss: -3.541,LR: 3.17E-05]Training epoch 84:  80%|████████  | 90/112 [00:01<00:00, 53.30it/s, Epoch: 84, Batch: 90,Loss: -3.916,Avg.Loss: -3.541,LR: 3.17E-05]Training epoch 84:  80%|████████  | 90/112 [00:01<00:00, 53.30it/s, Epoch: 84, Batch: 91,Loss: -3.429,Avg.Loss: -3.539,LR: 3.16E-05]Training epoch 84:  81%|████████▏ | 91/112 [00:01<00:00, 53.30it/s, Epoch: 84, Batch: 92,Loss: -3.754,Avg.Loss: -3.542,LR: 3.16E-05]Training epoch 84:  82%|████████▏ | 92/112 [00:01<00:00, 53.30it/s, Epoch: 84, Batch: 93,Loss: -3.564,Avg.Loss: -3.542,LR: 3.16E-05]Training epoch 84:  83%|████████▎ | 93/112 [00:01<00:00, 53.30it/s, Epoch: 84, Batch: 94,Loss: -3.117,Avg.Loss: -3.537,LR: 3.15E-05]Training epoch 84:  84%|████████▍ | 94/112 [00:01<00:00, 53.30it/s, Epoch: 84, Batch: 95,Loss: -3.987,Avg.Loss: -3.542,LR: 3.15E-05]Training epoch 84:  85%|████████▍ | 95/112 [00:01<00:00, 53.30it/s, Epoch: 84, Batch: 96,Loss: -3.506,Avg.Loss: -3.542,LR: 3.15E-05]Training epoch 84:  86%|████████▌ | 96/112 [00:01<00:00, 53.17it/s, Epoch: 84, Batch: 96,Loss: -3.506,Avg.Loss: -3.542,LR: 3.15E-05]Training epoch 84:  86%|████████▌ | 96/112 [00:01<00:00, 53.17it/s, Epoch: 84, Batch: 97,Loss: -3.374,Avg.Loss: -3.540,LR: 3.14E-05]Training epoch 84:  87%|████████▋ | 97/112 [00:01<00:00, 53.17it/s, Epoch: 84, Batch: 98,Loss: -3.704,Avg.Loss: -3.542,LR: 3.14E-05]Training epoch 84:  88%|████████▊ | 98/112 [00:01<00:00, 53.17it/s, Epoch: 84, Batch: 99,Loss: -3.861,Avg.Loss: -3.545,LR: 3.14E-05]Training epoch 84:  88%|████████▊ | 99/112 [00:01<00:00, 53.17it/s, Epoch: 84, Batch: 100,Loss: -3.401,Avg.Loss: -3.544,LR: 3.13E-05]Training epoch 84:  89%|████████▉ | 100/112 [00:01<00:00, 53.17it/s, Epoch: 84, Batch: 101,Loss: -3.161,Avg.Loss: -3.540,LR: 3.13E-05]Training epoch 84:  90%|█████████ | 101/112 [00:01<00:00, 53.17it/s, Epoch: 84, Batch: 102,Loss: -3.465,Avg.Loss: -3.539,LR: 3.13E-05]Training epoch 84:  91%|█████████ | 102/112 [00:01<00:00, 53.36it/s, Epoch: 84, Batch: 102,Loss: -3.465,Avg.Loss: -3.539,LR: 3.13E-05]Training epoch 84:  91%|█████████ | 102/112 [00:01<00:00, 53.36it/s, Epoch: 84, Batch: 103,Loss: -3.584,Avg.Loss: -3.539,LR: 3.12E-05]Training epoch 84:  92%|█████████▏| 103/112 [00:01<00:00, 53.36it/s, Epoch: 84, Batch: 104,Loss: -3.284,Avg.Loss: -3.537,LR: 3.12E-05]Training epoch 84:  93%|█████████▎| 104/112 [00:01<00:00, 53.36it/s, Epoch: 84, Batch: 105,Loss: -2.823,Avg.Loss: -3.530,LR: 3.12E-05]Training epoch 84:  94%|█████████▍| 105/112 [00:01<00:00, 53.36it/s, Epoch: 84, Batch: 106,Loss: -3.493,Avg.Loss: -3.530,LR: 3.11E-05]Training epoch 84:  95%|█████████▍| 106/112 [00:02<00:00, 53.36it/s, Epoch: 84, Batch: 107,Loss: -3.553,Avg.Loss: -3.530,LR: 3.11E-05]Training epoch 84:  96%|█████████▌| 107/112 [00:02<00:00, 53.36it/s, Epoch: 84, Batch: 108,Loss: -3.195,Avg.Loss: -3.527,LR: 3.11E-05]Training epoch 84:  96%|█████████▋| 108/112 [00:02<00:00, 53.45it/s, Epoch: 84, Batch: 108,Loss: -3.195,Avg.Loss: -3.527,LR: 3.11E-05]Training epoch 84:  96%|█████████▋| 108/112 [00:02<00:00, 53.45it/s, Epoch: 84, Batch: 109,Loss: -3.461,Avg.Loss: -3.526,LR: 3.10E-05]Training epoch 84:  97%|█████████▋| 109/112 [00:02<00:00, 53.45it/s, Epoch: 84, Batch: 110,Loss: -3.657,Avg.Loss: -3.528,LR: 3.10E-05]Training epoch 84:  98%|█████████▊| 110/112 [00:02<00:00, 53.45it/s, Epoch: 84, Batch: 111,Loss: -3.467,Avg.Loss: -3.527,LR: 3.10E-05]Training epoch 84:  99%|█████████▉| 111/112 [00:02<00:00, 53.45it/s, Epoch: 84, Batch: 112,Loss: -3.608,Avg.Loss: -3.528,LR: 3.09E-05]Training epoch 84: 100%|██████████| 112/112 [00:02<00:00, 53.05it/s, Epoch: 84, Batch: 112,Loss: -3.608,Avg.Loss: -3.528,LR: 3.09E-05]
Training epoch 85:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 85:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 85, Batch: 1,Loss: -2.882,Avg.Loss: -2.882,LR: 3.09E-05]Training epoch 85:   1%|          | 1/112 [00:00<00:04, 24.27it/s, Epoch: 85, Batch: 2,Loss: -3.452,Avg.Loss: -3.167,LR: 3.09E-05]Training epoch 85:   2%|▏         | 2/112 [00:00<00:03, 34.07it/s, Epoch: 85, Batch: 3,Loss: -3.347,Avg.Loss: -3.227,LR: 3.08E-05]Training epoch 85:   3%|▎         | 3/112 [00:00<00:02, 42.25it/s, Epoch: 85, Batch: 4,Loss: -3.849,Avg.Loss: -3.383,LR: 3.08E-05]Training epoch 85:   4%|▎         | 4/112 [00:00<00:02, 45.45it/s, Epoch: 85, Batch: 5,Loss: -3.740,Avg.Loss: -3.454,LR: 3.08E-05]Training epoch 85:   4%|▍         | 5/112 [00:00<00:02, 47.50it/s, Epoch: 85, Batch: 6,Loss: -3.224,Avg.Loss: -3.416,LR: 3.07E-05]Training epoch 85:   5%|▌         | 6/112 [00:00<00:01, 56.91it/s, Epoch: 85, Batch: 6,Loss: -3.224,Avg.Loss: -3.416,LR: 3.07E-05]Training epoch 85:   5%|▌         | 6/112 [00:00<00:01, 56.91it/s, Epoch: 85, Batch: 7,Loss: -3.894,Avg.Loss: -3.484,LR: 3.07E-05]Training epoch 85:   6%|▋         | 7/112 [00:00<00:01, 56.91it/s, Epoch: 85, Batch: 8,Loss: -3.338,Avg.Loss: -3.466,LR: 3.07E-05]Training epoch 85:   7%|▋         | 8/112 [00:00<00:01, 56.91it/s, Epoch: 85, Batch: 9,Loss: -3.373,Avg.Loss: -3.455,LR: 3.06E-05]Training epoch 85:   8%|▊         | 9/112 [00:00<00:01, 56.91it/s, Epoch: 85, Batch: 10,Loss: -3.827,Avg.Loss: -3.493,LR: 3.06E-05]Training epoch 85:   9%|▉         | 10/112 [00:00<00:01, 56.91it/s, Epoch: 85, Batch: 11,Loss: -4.004,Avg.Loss: -3.539,LR: 3.06E-05]Training epoch 85:  10%|▉         | 11/112 [00:00<00:01, 56.91it/s, Epoch: 85, Batch: 12,Loss: -3.343,Avg.Loss: -3.523,LR: 3.05E-05]Training epoch 85:  11%|█         | 12/112 [00:00<00:01, 55.32it/s, Epoch: 85, Batch: 12,Loss: -3.343,Avg.Loss: -3.523,LR: 3.05E-05]Training epoch 85:  11%|█         | 12/112 [00:00<00:01, 55.32it/s, Epoch: 85, Batch: 13,Loss: -3.375,Avg.Loss: -3.511,LR: 3.05E-05]Training epoch 85:  12%|█▏        | 13/112 [00:00<00:01, 55.32it/s, Epoch: 85, Batch: 14,Loss: -3.042,Avg.Loss: -3.478,LR: 3.05E-05]Training epoch 85:  12%|█▎        | 14/112 [00:00<00:01, 55.32it/s, Epoch: 85, Batch: 15,Loss: -3.665,Avg.Loss: -3.490,LR: 3.04E-05]Training epoch 85:  13%|█▎        | 15/112 [00:00<00:01, 55.32it/s, Epoch: 85, Batch: 16,Loss: -3.591,Avg.Loss: -3.497,LR: 3.04E-05]Training epoch 85:  14%|█▍        | 16/112 [00:00<00:01, 55.32it/s, Epoch: 85, Batch: 17,Loss: -3.280,Avg.Loss: -3.484,LR: 3.04E-05]Training epoch 85:  15%|█▌        | 17/112 [00:00<00:01, 55.32it/s, Epoch: 85, Batch: 18,Loss: -3.499,Avg.Loss: -3.485,LR: 3.03E-05]Training epoch 85:  16%|█▌        | 18/112 [00:00<00:01, 54.16it/s, Epoch: 85, Batch: 18,Loss: -3.499,Avg.Loss: -3.485,LR: 3.03E-05]Training epoch 85:  16%|█▌        | 18/112 [00:00<00:01, 54.16it/s, Epoch: 85, Batch: 19,Loss: -3.587,Avg.Loss: -3.490,LR: 3.03E-05]Training epoch 85:  17%|█▋        | 19/112 [00:00<00:01, 54.16it/s, Epoch: 85, Batch: 20,Loss: -3.084,Avg.Loss: -3.470,LR: 3.03E-05]Training epoch 85:  18%|█▊        | 20/112 [00:00<00:01, 54.16it/s, Epoch: 85, Batch: 21,Loss: -3.504,Avg.Loss: -3.471,LR: 3.02E-05]Training epoch 85:  19%|█▉        | 21/112 [00:00<00:01, 54.16it/s, Epoch: 85, Batch: 22,Loss: -3.267,Avg.Loss: -3.462,LR: 3.02E-05]Training epoch 85:  20%|█▉        | 22/112 [00:00<00:01, 54.16it/s, Epoch: 85, Batch: 23,Loss: -3.391,Avg.Loss: -3.459,LR: 3.02E-05]Training epoch 85:  21%|██        | 23/112 [00:00<00:01, 54.16it/s, Epoch: 85, Batch: 24,Loss: -3.685,Avg.Loss: -3.468,LR: 3.01E-05]Training epoch 85:  21%|██▏       | 24/112 [00:00<00:01, 51.99it/s, Epoch: 85, Batch: 24,Loss: -3.685,Avg.Loss: -3.468,LR: 3.01E-05]Training epoch 85:  21%|██▏       | 24/112 [00:00<00:01, 51.99it/s, Epoch: 85, Batch: 25,Loss: -3.776,Avg.Loss: -3.481,LR: 3.01E-05]Training epoch 85:  22%|██▏       | 25/112 [00:00<00:01, 51.99it/s, Epoch: 85, Batch: 26,Loss: -3.536,Avg.Loss: -3.483,LR: 3.01E-05]Training epoch 85:  23%|██▎       | 26/112 [00:00<00:01, 51.99it/s, Epoch: 85, Batch: 27,Loss: -3.337,Avg.Loss: -3.477,LR: 3.00E-05]Training epoch 85:  24%|██▍       | 27/112 [00:00<00:01, 51.99it/s, Epoch: 85, Batch: 28,Loss: -3.193,Avg.Loss: -3.467,LR: 3.00E-05]Training epoch 85:  25%|██▌       | 28/112 [00:00<00:01, 51.99it/s, Epoch: 85, Batch: 29,Loss: -3.718,Avg.Loss: -3.476,LR: 3.00E-05]Training epoch 85:  26%|██▌       | 29/112 [00:00<00:01, 51.99it/s, Epoch: 85, Batch: 30,Loss: -3.097,Avg.Loss: -3.463,LR: 2.99E-05]Training epoch 85:  27%|██▋       | 30/112 [00:00<00:01, 52.79it/s, Epoch: 85, Batch: 30,Loss: -3.097,Avg.Loss: -3.463,LR: 2.99E-05]Training epoch 85:  27%|██▋       | 30/112 [00:00<00:01, 52.79it/s, Epoch: 85, Batch: 31,Loss: -3.604,Avg.Loss: -3.468,LR: 2.99E-05]Training epoch 85:  28%|██▊       | 31/112 [00:00<00:01, 52.79it/s, Epoch: 85, Batch: 32,Loss: -3.650,Avg.Loss: -3.474,LR: 2.99E-05]Training epoch 85:  29%|██▊       | 32/112 [00:00<00:01, 52.79it/s, Epoch: 85, Batch: 33,Loss: -3.146,Avg.Loss: -3.464,LR: 2.98E-05]Training epoch 85:  29%|██▉       | 33/112 [00:00<00:01, 52.79it/s, Epoch: 85, Batch: 34,Loss: -3.291,Avg.Loss: -3.459,LR: 2.98E-05]Training epoch 85:  30%|███       | 34/112 [00:00<00:01, 52.79it/s, Epoch: 85, Batch: 35,Loss: -2.649,Avg.Loss: -3.435,LR: 2.98E-05]Training epoch 85:  31%|███▏      | 35/112 [00:00<00:01, 52.79it/s, Epoch: 85, Batch: 36,Loss: -3.707,Avg.Loss: -3.443,LR: 2.97E-05]Training epoch 85:  32%|███▏      | 36/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 36,Loss: -3.707,Avg.Loss: -3.443,LR: 2.97E-05]Training epoch 85:  32%|███▏      | 36/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 37,Loss: -3.541,Avg.Loss: -3.446,LR: 2.97E-05]Training epoch 85:  33%|███▎      | 37/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 38,Loss: -3.486,Avg.Loss: -3.447,LR: 2.97E-05]Training epoch 85:  34%|███▍      | 38/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 39,Loss: -3.583,Avg.Loss: -3.450,LR: 2.96E-05]Training epoch 85:  35%|███▍      | 39/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 40,Loss: -3.371,Avg.Loss: -3.448,LR: 2.96E-05]Training epoch 85:  36%|███▌      | 40/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 41,Loss: -3.418,Avg.Loss: -3.447,LR: 2.96E-05]Training epoch 85:  37%|███▋      | 41/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 42,Loss: -3.077,Avg.Loss: -3.439,LR: 2.95E-05]Training epoch 85:  38%|███▊      | 42/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 42,Loss: -3.077,Avg.Loss: -3.439,LR: 2.95E-05]Training epoch 85:  38%|███▊      | 42/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 43,Loss: -3.236,Avg.Loss: -3.434,LR: 2.95E-05]Training epoch 85:  38%|███▊      | 43/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 44,Loss: -3.442,Avg.Loss: -3.434,LR: 2.95E-05]Training epoch 85:  39%|███▉      | 44/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 45,Loss: -3.423,Avg.Loss: -3.434,LR: 2.94E-05]Training epoch 85:  40%|████      | 45/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 46,Loss: -3.157,Avg.Loss: -3.428,LR: 2.94E-05]Training epoch 85:  41%|████      | 46/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 47,Loss: -2.871,Avg.Loss: -3.416,LR: 2.94E-05]Training epoch 85:  42%|████▏     | 47/112 [00:00<00:01, 52.94it/s, Epoch: 85, Batch: 48,Loss: -3.321,Avg.Loss: -3.414,LR: 2.93E-05]Training epoch 85:  43%|████▎     | 48/112 [00:00<00:01, 52.96it/s, Epoch: 85, Batch: 48,Loss: -3.321,Avg.Loss: -3.414,LR: 2.93E-05]Training epoch 85:  43%|████▎     | 48/112 [00:00<00:01, 52.96it/s, Epoch: 85, Batch: 49,Loss: -3.315,Avg.Loss: -3.412,LR: 2.93E-05]Training epoch 85:  44%|████▍     | 49/112 [00:00<00:01, 52.96it/s, Epoch: 85, Batch: 50,Loss: -3.743,Avg.Loss: -3.419,LR: 2.93E-05]Training epoch 85:  45%|████▍     | 50/112 [00:00<00:01, 52.96it/s, Epoch: 85, Batch: 51,Loss: -3.574,Avg.Loss: -3.422,LR: 2.92E-05]Training epoch 85:  46%|████▌     | 51/112 [00:00<00:01, 52.96it/s, Epoch: 85, Batch: 52,Loss: -3.359,Avg.Loss: -3.420,LR: 2.92E-05]Training epoch 85:  46%|████▋     | 52/112 [00:00<00:01, 52.96it/s, Epoch: 85, Batch: 53,Loss: -3.065,Avg.Loss: -3.414,LR: 2.92E-05]Training epoch 85:  47%|████▋     | 53/112 [00:01<00:01, 52.96it/s, Epoch: 85, Batch: 54,Loss: -3.601,Avg.Loss: -3.417,LR: 2.91E-05]Training epoch 85:  48%|████▊     | 54/112 [00:01<00:01, 52.91it/s, Epoch: 85, Batch: 54,Loss: -3.601,Avg.Loss: -3.417,LR: 2.91E-05]Training epoch 85:  48%|████▊     | 54/112 [00:01<00:01, 52.91it/s, Epoch: 85, Batch: 55,Loss: -3.345,Avg.Loss: -3.416,LR: 2.91E-05]Training epoch 85:  49%|████▉     | 55/112 [00:01<00:01, 52.91it/s, Epoch: 85, Batch: 56,Loss: -3.428,Avg.Loss: -3.416,LR: 2.91E-05]Training epoch 85:  50%|█████     | 56/112 [00:01<00:01, 52.91it/s, Epoch: 85, Batch: 57,Loss: -3.117,Avg.Loss: -3.411,LR: 2.90E-05]Training epoch 85:  51%|█████     | 57/112 [00:01<00:01, 52.91it/s, Epoch: 85, Batch: 58,Loss: -3.372,Avg.Loss: -3.410,LR: 2.90E-05]Training epoch 85:  52%|█████▏    | 58/112 [00:01<00:01, 52.91it/s, Epoch: 85, Batch: 59,Loss: -2.712,Avg.Loss: -3.398,LR: 2.90E-05]Training epoch 85:  53%|█████▎    | 59/112 [00:01<00:01, 52.91it/s, Epoch: 85, Batch: 60,Loss: -3.680,Avg.Loss: -3.403,LR: 2.89E-05]Training epoch 85:  54%|█████▎    | 60/112 [00:01<00:00, 52.94it/s, Epoch: 85, Batch: 60,Loss: -3.680,Avg.Loss: -3.403,LR: 2.89E-05]Training epoch 85:  54%|█████▎    | 60/112 [00:01<00:00, 52.94it/s, Epoch: 85, Batch: 61,Loss: -3.665,Avg.Loss: -3.407,LR: 2.89E-05]Training epoch 85:  54%|█████▍    | 61/112 [00:01<00:00, 52.94it/s, Epoch: 85, Batch: 62,Loss: -3.772,Avg.Loss: -3.413,LR: 2.89E-05]Training epoch 85:  55%|█████▌    | 62/112 [00:01<00:00, 52.94it/s, Epoch: 85, Batch: 63,Loss: -3.354,Avg.Loss: -3.412,LR: 2.88E-05]Training epoch 85:  56%|█████▋    | 63/112 [00:01<00:00, 52.94it/s, Epoch: 85, Batch: 64,Loss: -2.981,Avg.Loss: -3.406,LR: 2.88E-05]Training epoch 85:  57%|█████▋    | 64/112 [00:01<00:00, 52.94it/s, Epoch: 85, Batch: 65,Loss: -3.787,Avg.Loss: -3.411,LR: 2.88E-05]Training epoch 85:  58%|█████▊    | 65/112 [00:01<00:00, 52.94it/s, Epoch: 85, Batch: 66,Loss: -3.483,Avg.Loss: -3.412,LR: 2.87E-05]Training epoch 85:  59%|█████▉    | 66/112 [00:01<00:00, 52.85it/s, Epoch: 85, Batch: 66,Loss: -3.483,Avg.Loss: -3.412,LR: 2.87E-05]Training epoch 85:  59%|█████▉    | 66/112 [00:01<00:00, 52.85it/s, Epoch: 85, Batch: 67,Loss: -3.545,Avg.Loss: -3.414,LR: 2.87E-05]Training epoch 85:  60%|█████▉    | 67/112 [00:01<00:00, 52.85it/s, Epoch: 85, Batch: 68,Loss: -3.539,Avg.Loss: -3.416,LR: 2.87E-05]Training epoch 85:  61%|██████    | 68/112 [00:01<00:00, 52.85it/s, Epoch: 85, Batch: 69,Loss: -3.299,Avg.Loss: -3.415,LR: 2.86E-05]Training epoch 85:  62%|██████▏   | 69/112 [00:01<00:00, 52.85it/s, Epoch: 85, Batch: 70,Loss: -3.627,Avg.Loss: -3.418,LR: 2.86E-05]Training epoch 85:  62%|██████▎   | 70/112 [00:01<00:00, 52.85it/s, Epoch: 85, Batch: 71,Loss: -3.666,Avg.Loss: -3.421,LR: 2.86E-05]Training epoch 85:  63%|██████▎   | 71/112 [00:01<00:00, 52.85it/s, Epoch: 85, Batch: 72,Loss: -3.741,Avg.Loss: -3.426,LR: 2.85E-05]Training epoch 85:  64%|██████▍   | 72/112 [00:01<00:00, 52.82it/s, Epoch: 85, Batch: 72,Loss: -3.741,Avg.Loss: -3.426,LR: 2.85E-05]Training epoch 85:  64%|██████▍   | 72/112 [00:01<00:00, 52.82it/s, Epoch: 85, Batch: 73,Loss: -3.705,Avg.Loss: -3.429,LR: 2.85E-05]Training epoch 85:  65%|██████▌   | 73/112 [00:01<00:00, 52.82it/s, Epoch: 85, Batch: 74,Loss: -3.442,Avg.Loss: -3.430,LR: 2.85E-05]Training epoch 85:  66%|██████▌   | 74/112 [00:01<00:00, 52.82it/s, Epoch: 85, Batch: 75,Loss: -3.412,Avg.Loss: -3.429,LR: 2.84E-05]Training epoch 85:  67%|██████▋   | 75/112 [00:01<00:00, 52.82it/s, Epoch: 85, Batch: 76,Loss: -3.225,Avg.Loss: -3.427,LR: 2.84E-05]Training epoch 85:  68%|██████▊   | 76/112 [00:01<00:00, 52.82it/s, Epoch: 85, Batch: 77,Loss: -3.663,Avg.Loss: -3.430,LR: 2.84E-05]Training epoch 85:  69%|██████▉   | 77/112 [00:01<00:00, 52.82it/s, Epoch: 85, Batch: 78,Loss: -3.491,Avg.Loss: -3.431,LR: 2.83E-05]Training epoch 85:  70%|██████▉   | 78/112 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 78,Loss: -3.491,Avg.Loss: -3.431,LR: 2.83E-05]Training epoch 85:  70%|██████▉   | 78/112 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 79,Loss: -3.180,Avg.Loss: -3.427,LR: 2.83E-05]Training epoch 85:  71%|███████   | 79/112 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 80,Loss: -3.372,Avg.Loss: -3.427,LR: 2.83E-05]Training epoch 85:  71%|███████▏  | 80/112 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 81,Loss: -3.717,Avg.Loss: -3.430,LR: 2.82E-05]Training epoch 85:  72%|███████▏  | 81/112 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 82,Loss: -3.878,Avg.Loss: -3.436,LR: 2.82E-05]Training epoch 85:  73%|███████▎  | 82/112 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 83,Loss: -2.985,Avg.Loss: -3.430,LR: 2.82E-05]Training epoch 85:  74%|███████▍  | 83/112 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 84,Loss: -3.427,Avg.Loss: -3.430,LR: 2.81E-05]Training epoch 85:  75%|███████▌  | 84/112 [00:01<00:00, 53.10it/s, Epoch: 85, Batch: 84,Loss: -3.427,Avg.Loss: -3.430,LR: 2.81E-05]Training epoch 85:  75%|███████▌  | 84/112 [00:01<00:00, 53.10it/s, Epoch: 85, Batch: 85,Loss: -3.566,Avg.Loss: -3.432,LR: 2.81E-05]Training epoch 85:  76%|███████▌  | 85/112 [00:01<00:00, 53.10it/s, Epoch: 85, Batch: 86,Loss: -3.682,Avg.Loss: -3.435,LR: 2.81E-05]Training epoch 85:  77%|███████▋  | 86/112 [00:01<00:00, 53.10it/s, Epoch: 85, Batch: 87,Loss: -3.845,Avg.Loss: -3.439,LR: 2.80E-05]Training epoch 85:  78%|███████▊  | 87/112 [00:01<00:00, 53.10it/s, Epoch: 85, Batch: 88,Loss: -3.132,Avg.Loss: -3.436,LR: 2.80E-05]Training epoch 85:  79%|███████▊  | 88/112 [00:01<00:00, 53.10it/s, Epoch: 85, Batch: 89,Loss: -3.510,Avg.Loss: -3.437,LR: 2.80E-05]Training epoch 85:  79%|███████▉  | 89/112 [00:01<00:00, 53.10it/s, Epoch: 85, Batch: 90,Loss: -3.874,Avg.Loss: -3.442,LR: 2.80E-05]Training epoch 85:  80%|████████  | 90/112 [00:01<00:00, 53.11it/s, Epoch: 85, Batch: 90,Loss: -3.874,Avg.Loss: -3.442,LR: 2.80E-05]Training epoch 85:  80%|████████  | 90/112 [00:01<00:00, 53.11it/s, Epoch: 85, Batch: 91,Loss: -3.587,Avg.Loss: -3.443,LR: 2.79E-05]Training epoch 85:  81%|████████▏ | 91/112 [00:01<00:00, 53.11it/s, Epoch: 85, Batch: 92,Loss: -3.715,Avg.Loss: -3.446,LR: 2.79E-05]Training epoch 85:  82%|████████▏ | 92/112 [00:01<00:00, 53.11it/s, Epoch: 85, Batch: 93,Loss: -4.071,Avg.Loss: -3.453,LR: 2.79E-05]Training epoch 85:  83%|████████▎ | 93/112 [00:01<00:00, 53.11it/s, Epoch: 85, Batch: 94,Loss: -3.328,Avg.Loss: -3.452,LR: 2.78E-05]Training epoch 85:  84%|████████▍ | 94/112 [00:01<00:00, 53.11it/s, Epoch: 85, Batch: 95,Loss: -3.797,Avg.Loss: -3.455,LR: 2.78E-05]Training epoch 85:  85%|████████▍ | 95/112 [00:01<00:00, 53.11it/s, Epoch: 85, Batch: 96,Loss: -3.412,Avg.Loss: -3.455,LR: 2.78E-05]Training epoch 85:  86%|████████▌ | 96/112 [00:01<00:00, 53.22it/s, Epoch: 85, Batch: 96,Loss: -3.412,Avg.Loss: -3.455,LR: 2.78E-05]Training epoch 85:  86%|████████▌ | 96/112 [00:01<00:00, 53.22it/s, Epoch: 85, Batch: 97,Loss: -3.328,Avg.Loss: -3.453,LR: 2.77E-05]Training epoch 85:  87%|████████▋ | 97/112 [00:01<00:00, 53.22it/s, Epoch: 85, Batch: 98,Loss: -3.813,Avg.Loss: -3.457,LR: 2.77E-05]Training epoch 85:  88%|████████▊ | 98/112 [00:01<00:00, 53.22it/s, Epoch: 85, Batch: 99,Loss: -3.553,Avg.Loss: -3.458,LR: 2.77E-05]Training epoch 85:  88%|████████▊ | 99/112 [00:01<00:00, 53.22it/s, Epoch: 85, Batch: 100,Loss: -3.666,Avg.Loss: -3.460,LR: 2.76E-05]Training epoch 85:  89%|████████▉ | 100/112 [00:01<00:00, 53.22it/s, Epoch: 85, Batch: 101,Loss: -3.772,Avg.Loss: -3.463,LR: 2.76E-05]Training epoch 85:  90%|█████████ | 101/112 [00:01<00:00, 53.22it/s, Epoch: 85, Batch: 102,Loss: -3.209,Avg.Loss: -3.461,LR: 2.76E-05]Training epoch 85:  91%|█████████ | 102/112 [00:01<00:00, 53.31it/s, Epoch: 85, Batch: 102,Loss: -3.209,Avg.Loss: -3.461,LR: 2.76E-05]Training epoch 85:  91%|█████████ | 102/112 [00:01<00:00, 53.31it/s, Epoch: 85, Batch: 103,Loss: -3.709,Avg.Loss: -3.463,LR: 2.75E-05]Training epoch 85:  92%|█████████▏| 103/112 [00:01<00:00, 53.31it/s, Epoch: 85, Batch: 104,Loss: -3.309,Avg.Loss: -3.462,LR: 2.75E-05]Training epoch 85:  93%|█████████▎| 104/112 [00:01<00:00, 53.31it/s, Epoch: 85, Batch: 105,Loss: -3.594,Avg.Loss: -3.463,LR: 2.75E-05]Training epoch 85:  94%|█████████▍| 105/112 [00:01<00:00, 53.31it/s, Epoch: 85, Batch: 106,Loss: -3.450,Avg.Loss: -3.463,LR: 2.74E-05]Training epoch 85:  95%|█████████▍| 106/112 [00:02<00:00, 53.31it/s, Epoch: 85, Batch: 107,Loss: -3.040,Avg.Loss: -3.459,LR: 2.74E-05]Training epoch 85:  96%|█████████▌| 107/112 [00:02<00:00, 53.31it/s, Epoch: 85, Batch: 108,Loss: -3.643,Avg.Loss: -3.461,LR: 2.74E-05]Training epoch 85:  96%|█████████▋| 108/112 [00:02<00:00, 53.34it/s, Epoch: 85, Batch: 108,Loss: -3.643,Avg.Loss: -3.461,LR: 2.74E-05]Training epoch 85:  96%|█████████▋| 108/112 [00:02<00:00, 53.34it/s, Epoch: 85, Batch: 109,Loss: -3.538,Avg.Loss: -3.461,LR: 2.73E-05]Training epoch 85:  97%|█████████▋| 109/112 [00:02<00:00, 53.34it/s, Epoch: 85, Batch: 110,Loss: -3.748,Avg.Loss: -3.464,LR: 2.73E-05]Training epoch 85:  98%|█████████▊| 110/112 [00:02<00:00, 53.34it/s, Epoch: 85, Batch: 111,Loss: -3.928,Avg.Loss: -3.468,LR: 2.73E-05]Training epoch 85:  99%|█████████▉| 111/112 [00:02<00:00, 53.34it/s, Epoch: 85, Batch: 112,Loss: -3.431,Avg.Loss: -3.468,LR: 2.72E-05]Training epoch 85: 100%|██████████| 112/112 [00:02<00:00, 53.10it/s, Epoch: 85, Batch: 112,Loss: -3.431,Avg.Loss: -3.468,LR: 2.72E-05]
Training epoch 86:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 86:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 86, Batch: 1,Loss: -3.373,Avg.Loss: -3.373,LR: 2.72E-05]Training epoch 86:   1%|          | 1/112 [00:00<00:04, 25.17it/s, Epoch: 86, Batch: 2,Loss: -3.622,Avg.Loss: -3.498,LR: 2.72E-05]Training epoch 86:   2%|▏         | 2/112 [00:00<00:02, 38.10it/s, Epoch: 86, Batch: 3,Loss: -3.163,Avg.Loss: -3.386,LR: 2.72E-05]Training epoch 86:   3%|▎         | 3/112 [00:00<00:02, 42.71it/s, Epoch: 86, Batch: 4,Loss: -3.568,Avg.Loss: -3.432,LR: 2.71E-05]Training epoch 86:   4%|▎         | 4/112 [00:00<00:02, 44.95it/s, Epoch: 86, Batch: 5,Loss: -3.239,Avg.Loss: -3.393,LR: 2.71E-05]Training epoch 86:   4%|▍         | 5/112 [00:00<00:02, 46.60it/s, Epoch: 86, Batch: 6,Loss: -3.400,Avg.Loss: -3.394,LR: 2.71E-05]Training epoch 86:   5%|▌         | 6/112 [00:00<00:01, 55.83it/s, Epoch: 86, Batch: 6,Loss: -3.400,Avg.Loss: -3.394,LR: 2.71E-05]Training epoch 86:   5%|▌         | 6/112 [00:00<00:01, 55.83it/s, Epoch: 86, Batch: 7,Loss: -3.928,Avg.Loss: -3.471,LR: 2.70E-05]Training epoch 86:   6%|▋         | 7/112 [00:00<00:01, 55.83it/s, Epoch: 86, Batch: 8,Loss: -2.908,Avg.Loss: -3.400,LR: 2.70E-05]Training epoch 86:   7%|▋         | 8/112 [00:00<00:01, 55.83it/s, Epoch: 86, Batch: 9,Loss: -3.412,Avg.Loss: -3.402,LR: 2.70E-05]Training epoch 86:   8%|▊         | 9/112 [00:00<00:01, 55.83it/s, Epoch: 86, Batch: 10,Loss: -4.053,Avg.Loss: -3.467,LR: 2.69E-05]Training epoch 86:   9%|▉         | 10/112 [00:00<00:01, 55.83it/s, Epoch: 86, Batch: 11,Loss: -3.262,Avg.Loss: -3.448,LR: 2.69E-05]Training epoch 86:  10%|▉         | 11/112 [00:00<00:01, 55.83it/s, Epoch: 86, Batch: 12,Loss: -3.472,Avg.Loss: -3.450,LR: 2.69E-05]Training epoch 86:  11%|█         | 12/112 [00:00<00:01, 53.58it/s, Epoch: 86, Batch: 12,Loss: -3.472,Avg.Loss: -3.450,LR: 2.69E-05]Training epoch 86:  11%|█         | 12/112 [00:00<00:01, 53.58it/s, Epoch: 86, Batch: 13,Loss: -3.295,Avg.Loss: -3.438,LR: 2.68E-05]Training epoch 86:  12%|█▏        | 13/112 [00:00<00:01, 53.58it/s, Epoch: 86, Batch: 14,Loss: -3.799,Avg.Loss: -3.464,LR: 2.68E-05]Training epoch 86:  12%|█▎        | 14/112 [00:00<00:01, 53.58it/s, Epoch: 86, Batch: 15,Loss: -3.543,Avg.Loss: -3.469,LR: 2.68E-05]Training epoch 86:  13%|█▎        | 15/112 [00:00<00:01, 53.58it/s, Epoch: 86, Batch: 16,Loss: -3.674,Avg.Loss: -3.482,LR: 2.67E-05]Training epoch 86:  14%|█▍        | 16/112 [00:00<00:01, 53.58it/s, Epoch: 86, Batch: 17,Loss: -3.555,Avg.Loss: -3.486,LR: 2.67E-05]Training epoch 86:  15%|█▌        | 17/112 [00:00<00:01, 53.58it/s, Epoch: 86, Batch: 18,Loss: -3.825,Avg.Loss: -3.505,LR: 2.67E-05]Training epoch 86:  16%|█▌        | 18/112 [00:00<00:01, 53.33it/s, Epoch: 86, Batch: 18,Loss: -3.825,Avg.Loss: -3.505,LR: 2.67E-05]Training epoch 86:  16%|█▌        | 18/112 [00:00<00:01, 53.33it/s, Epoch: 86, Batch: 19,Loss: -3.701,Avg.Loss: -3.515,LR: 2.66E-05]Training epoch 86:  17%|█▋        | 19/112 [00:00<00:01, 53.33it/s, Epoch: 86, Batch: 20,Loss: -3.262,Avg.Loss: -3.503,LR: 2.66E-05]Training epoch 86:  18%|█▊        | 20/112 [00:00<00:01, 53.33it/s, Epoch: 86, Batch: 21,Loss: -2.897,Avg.Loss: -3.474,LR: 2.66E-05]Training epoch 86:  19%|█▉        | 21/112 [00:00<00:01, 53.33it/s, Epoch: 86, Batch: 22,Loss: -3.197,Avg.Loss: -3.461,LR: 2.66E-05]Training epoch 86:  20%|█▉        | 22/112 [00:00<00:01, 53.33it/s, Epoch: 86, Batch: 23,Loss: -3.670,Avg.Loss: -3.470,LR: 2.65E-05]Training epoch 86:  21%|██        | 23/112 [00:00<00:01, 53.33it/s, Epoch: 86, Batch: 24,Loss: -3.419,Avg.Loss: -3.468,LR: 2.65E-05]Training epoch 86:  21%|██▏       | 24/112 [00:00<00:01, 52.76it/s, Epoch: 86, Batch: 24,Loss: -3.419,Avg.Loss: -3.468,LR: 2.65E-05]Training epoch 86:  21%|██▏       | 24/112 [00:00<00:01, 52.76it/s, Epoch: 86, Batch: 25,Loss: -3.979,Avg.Loss: -3.489,LR: 2.65E-05]Training epoch 86:  22%|██▏       | 25/112 [00:00<00:01, 52.76it/s, Epoch: 86, Batch: 26,Loss: -3.927,Avg.Loss: -3.506,LR: 2.64E-05]Training epoch 86:  23%|██▎       | 26/112 [00:00<00:01, 52.76it/s, Epoch: 86, Batch: 27,Loss: -3.477,Avg.Loss: -3.505,LR: 2.64E-05]Training epoch 86:  24%|██▍       | 27/112 [00:00<00:01, 52.76it/s, Epoch: 86, Batch: 28,Loss: -3.703,Avg.Loss: -3.512,LR: 2.64E-05]Training epoch 86:  25%|██▌       | 28/112 [00:00<00:01, 52.76it/s, Epoch: 86, Batch: 29,Loss: -2.942,Avg.Loss: -3.492,LR: 2.63E-05]Training epoch 86:  26%|██▌       | 29/112 [00:00<00:01, 52.76it/s, Epoch: 86, Batch: 30,Loss: -3.133,Avg.Loss: -3.480,LR: 2.63E-05]Training epoch 86:  27%|██▋       | 30/112 [00:00<00:01, 52.72it/s, Epoch: 86, Batch: 30,Loss: -3.133,Avg.Loss: -3.480,LR: 2.63E-05]Training epoch 86:  27%|██▋       | 30/112 [00:00<00:01, 52.72it/s, Epoch: 86, Batch: 31,Loss: -3.322,Avg.Loss: -3.475,LR: 2.63E-05]Training epoch 86:  28%|██▊       | 31/112 [00:00<00:01, 52.72it/s, Epoch: 86, Batch: 32,Loss: -3.377,Avg.Loss: -3.472,LR: 2.62E-05]Training epoch 86:  29%|██▊       | 32/112 [00:00<00:01, 52.72it/s, Epoch: 86, Batch: 33,Loss: -3.994,Avg.Loss: -3.488,LR: 2.62E-05]Training epoch 86:  29%|██▉       | 33/112 [00:00<00:01, 52.72it/s, Epoch: 86, Batch: 34,Loss: -3.801,Avg.Loss: -3.497,LR: 2.62E-05]Training epoch 86:  30%|███       | 34/112 [00:00<00:01, 52.72it/s, Epoch: 86, Batch: 35,Loss: -3.668,Avg.Loss: -3.502,LR: 2.61E-05]Training epoch 86:  31%|███▏      | 35/112 [00:00<00:01, 52.72it/s, Epoch: 86, Batch: 36,Loss: -3.564,Avg.Loss: -3.504,LR: 2.61E-05]Training epoch 86:  32%|███▏      | 36/112 [00:00<00:01, 53.07it/s, Epoch: 86, Batch: 36,Loss: -3.564,Avg.Loss: -3.504,LR: 2.61E-05]Training epoch 86:  32%|███▏      | 36/112 [00:00<00:01, 53.07it/s, Epoch: 86, Batch: 37,Loss: -3.754,Avg.Loss: -3.510,LR: 2.61E-05]Training epoch 86:  33%|███▎      | 37/112 [00:00<00:01, 53.07it/s, Epoch: 86, Batch: 38,Loss: -3.528,Avg.Loss: -3.511,LR: 2.61E-05]Training epoch 86:  34%|███▍      | 38/112 [00:00<00:01, 53.07it/s, Epoch: 86, Batch: 39,Loss: -3.485,Avg.Loss: -3.510,LR: 2.60E-05]Training epoch 86:  35%|███▍      | 39/112 [00:00<00:01, 53.07it/s, Epoch: 86, Batch: 40,Loss: -3.246,Avg.Loss: -3.504,LR: 2.60E-05]Training epoch 86:  36%|███▌      | 40/112 [00:00<00:01, 53.07it/s, Epoch: 86, Batch: 41,Loss: -3.595,Avg.Loss: -3.506,LR: 2.60E-05]Training epoch 86:  37%|███▋      | 41/112 [00:00<00:01, 53.07it/s, Epoch: 86, Batch: 42,Loss: -3.732,Avg.Loss: -3.511,LR: 2.59E-05]Training epoch 86:  38%|███▊      | 42/112 [00:00<00:01, 52.75it/s, Epoch: 86, Batch: 42,Loss: -3.732,Avg.Loss: -3.511,LR: 2.59E-05]Training epoch 86:  38%|███▊      | 42/112 [00:00<00:01, 52.75it/s, Epoch: 86, Batch: 43,Loss: -3.586,Avg.Loss: -3.513,LR: 2.59E-05]Training epoch 86:  38%|███▊      | 43/112 [00:00<00:01, 52.75it/s, Epoch: 86, Batch: 44,Loss: -3.478,Avg.Loss: -3.512,LR: 2.59E-05]Training epoch 86:  39%|███▉      | 44/112 [00:00<00:01, 52.75it/s, Epoch: 86, Batch: 45,Loss: -3.430,Avg.Loss: -3.510,LR: 2.58E-05]Training epoch 86:  40%|████      | 45/112 [00:00<00:01, 52.75it/s, Epoch: 86, Batch: 46,Loss: -3.787,Avg.Loss: -3.516,LR: 2.58E-05]Training epoch 86:  41%|████      | 46/112 [00:00<00:01, 52.75it/s, Epoch: 86, Batch: 47,Loss: -3.192,Avg.Loss: -3.509,LR: 2.58E-05]Training epoch 86:  42%|████▏     | 47/112 [00:00<00:01, 52.75it/s, Epoch: 86, Batch: 48,Loss: -3.955,Avg.Loss: -3.519,LR: 2.57E-05]Training epoch 86:  43%|████▎     | 48/112 [00:00<00:01, 52.82it/s, Epoch: 86, Batch: 48,Loss: -3.955,Avg.Loss: -3.519,LR: 2.57E-05]Training epoch 86:  43%|████▎     | 48/112 [00:00<00:01, 52.82it/s, Epoch: 86, Batch: 49,Loss: -3.328,Avg.Loss: -3.515,LR: 2.57E-05]Training epoch 86:  44%|████▍     | 49/112 [00:00<00:01, 52.82it/s, Epoch: 86, Batch: 50,Loss: -3.726,Avg.Loss: -3.519,LR: 2.57E-05]Training epoch 86:  45%|████▍     | 50/112 [00:00<00:01, 52.82it/s, Epoch: 86, Batch: 51,Loss: -3.593,Avg.Loss: -3.520,LR: 2.56E-05]Training epoch 86:  46%|████▌     | 51/112 [00:00<00:01, 52.82it/s, Epoch: 86, Batch: 52,Loss: -3.936,Avg.Loss: -3.528,LR: 2.56E-05]Training epoch 86:  46%|████▋     | 52/112 [00:01<00:01, 52.82it/s, Epoch: 86, Batch: 53,Loss: -3.758,Avg.Loss: -3.533,LR: 2.56E-05]Training epoch 86:  47%|████▋     | 53/112 [00:01<00:01, 52.82it/s, Epoch: 86, Batch: 54,Loss: -3.854,Avg.Loss: -3.539,LR: 2.56E-05]Training epoch 86:  48%|████▊     | 54/112 [00:01<00:01, 52.64it/s, Epoch: 86, Batch: 54,Loss: -3.854,Avg.Loss: -3.539,LR: 2.56E-05]Training epoch 86:  48%|████▊     | 54/112 [00:01<00:01, 52.64it/s, Epoch: 86, Batch: 55,Loss: -3.618,Avg.Loss: -3.540,LR: 2.55E-05]Training epoch 86:  49%|████▉     | 55/112 [00:01<00:01, 52.64it/s, Epoch: 86, Batch: 56,Loss: -3.884,Avg.Loss: -3.546,LR: 2.55E-05]Training epoch 86:  50%|█████     | 56/112 [00:01<00:01, 52.64it/s, Epoch: 86, Batch: 57,Loss: -3.471,Avg.Loss: -3.545,LR: 2.55E-05]Training epoch 86:  51%|█████     | 57/112 [00:01<00:01, 52.64it/s, Epoch: 86, Batch: 58,Loss: -3.559,Avg.Loss: -3.545,LR: 2.54E-05]Training epoch 86:  52%|█████▏    | 58/112 [00:01<00:01, 52.64it/s, Epoch: 86, Batch: 59,Loss: -4.116,Avg.Loss: -3.555,LR: 2.54E-05]Training epoch 86:  53%|█████▎    | 59/112 [00:01<00:01, 52.64it/s, Epoch: 86, Batch: 60,Loss: -3.523,Avg.Loss: -3.554,LR: 2.54E-05]Training epoch 86:  54%|█████▎    | 60/112 [00:01<00:00, 52.75it/s, Epoch: 86, Batch: 60,Loss: -3.523,Avg.Loss: -3.554,LR: 2.54E-05]Training epoch 86:  54%|█████▎    | 60/112 [00:01<00:00, 52.75it/s, Epoch: 86, Batch: 61,Loss: -3.657,Avg.Loss: -3.556,LR: 2.53E-05]Training epoch 86:  54%|█████▍    | 61/112 [00:01<00:00, 52.75it/s, Epoch: 86, Batch: 62,Loss: -3.670,Avg.Loss: -3.558,LR: 2.53E-05]Training epoch 86:  55%|█████▌    | 62/112 [00:01<00:00, 52.75it/s, Epoch: 86, Batch: 63,Loss: -3.312,Avg.Loss: -3.554,LR: 2.53E-05]Training epoch 86:  56%|█████▋    | 63/112 [00:01<00:00, 52.75it/s, Epoch: 86, Batch: 64,Loss: -3.433,Avg.Loss: -3.552,LR: 2.52E-05]Training epoch 86:  57%|█████▋    | 64/112 [00:01<00:00, 52.75it/s, Epoch: 86, Batch: 65,Loss: -3.885,Avg.Loss: -3.557,LR: 2.52E-05]Training epoch 86:  58%|█████▊    | 65/112 [00:01<00:00, 52.75it/s, Epoch: 86, Batch: 66,Loss: -3.614,Avg.Loss: -3.558,LR: 2.52E-05]Training epoch 86:  59%|█████▉    | 66/112 [00:01<00:00, 52.88it/s, Epoch: 86, Batch: 66,Loss: -3.614,Avg.Loss: -3.558,LR: 2.52E-05]Training epoch 86:  59%|█████▉    | 66/112 [00:01<00:00, 52.88it/s, Epoch: 86, Batch: 67,Loss: -3.514,Avg.Loss: -3.557,LR: 2.52E-05]Training epoch 86:  60%|█████▉    | 67/112 [00:01<00:00, 52.88it/s, Epoch: 86, Batch: 68,Loss: -3.524,Avg.Loss: -3.557,LR: 2.51E-05]Training epoch 86:  61%|██████    | 68/112 [00:01<00:00, 52.88it/s, Epoch: 86, Batch: 69,Loss: -3.657,Avg.Loss: -3.558,LR: 2.51E-05]Training epoch 86:  62%|██████▏   | 69/112 [00:01<00:00, 52.88it/s, Epoch: 86, Batch: 70,Loss: -3.520,Avg.Loss: -3.558,LR: 2.51E-05]Training epoch 86:  62%|██████▎   | 70/112 [00:01<00:00, 52.88it/s, Epoch: 86, Batch: 71,Loss: -3.435,Avg.Loss: -3.556,LR: 2.50E-05]Training epoch 86:  63%|██████▎   | 71/112 [00:01<00:00, 52.88it/s, Epoch: 86, Batch: 72,Loss: -3.795,Avg.Loss: -3.559,LR: 2.50E-05]Training epoch 86:  64%|██████▍   | 72/112 [00:01<00:00, 52.96it/s, Epoch: 86, Batch: 72,Loss: -3.795,Avg.Loss: -3.559,LR: 2.50E-05]Training epoch 86:  64%|██████▍   | 72/112 [00:01<00:00, 52.96it/s, Epoch: 86, Batch: 73,Loss: -3.689,Avg.Loss: -3.561,LR: 2.50E-05]Training epoch 86:  65%|██████▌   | 73/112 [00:01<00:00, 52.96it/s, Epoch: 86, Batch: 74,Loss: -3.788,Avg.Loss: -3.564,LR: 2.49E-05]Training epoch 86:  66%|██████▌   | 74/112 [00:01<00:00, 52.96it/s, Epoch: 86, Batch: 75,Loss: -3.838,Avg.Loss: -3.568,LR: 2.49E-05]Training epoch 86:  67%|██████▋   | 75/112 [00:01<00:00, 52.96it/s, Epoch: 86, Batch: 76,Loss: -3.237,Avg.Loss: -3.564,LR: 2.49E-05]Training epoch 86:  68%|██████▊   | 76/112 [00:01<00:00, 52.96it/s, Epoch: 86, Batch: 77,Loss: -3.527,Avg.Loss: -3.563,LR: 2.48E-05]Training epoch 86:  69%|██████▉   | 77/112 [00:01<00:00, 52.96it/s, Epoch: 86, Batch: 78,Loss: -3.730,Avg.Loss: -3.565,LR: 2.48E-05]Training epoch 86:  70%|██████▉   | 78/112 [00:01<00:00, 52.62it/s, Epoch: 86, Batch: 78,Loss: -3.730,Avg.Loss: -3.565,LR: 2.48E-05]Training epoch 86:  70%|██████▉   | 78/112 [00:01<00:00, 52.62it/s, Epoch: 86, Batch: 79,Loss: -3.097,Avg.Loss: -3.559,LR: 2.48E-05]Training epoch 86:  71%|███████   | 79/112 [00:01<00:00, 52.62it/s, Epoch: 86, Batch: 80,Loss: -3.614,Avg.Loss: -3.560,LR: 2.48E-05]Training epoch 86:  71%|███████▏  | 80/112 [00:01<00:00, 52.62it/s, Epoch: 86, Batch: 81,Loss: -2.997,Avg.Loss: -3.553,LR: 2.47E-05]Training epoch 86:  72%|███████▏  | 81/112 [00:01<00:00, 52.62it/s, Epoch: 86, Batch: 82,Loss: -3.307,Avg.Loss: -3.550,LR: 2.47E-05]Training epoch 86:  73%|███████▎  | 82/112 [00:01<00:00, 52.62it/s, Epoch: 86, Batch: 83,Loss: -3.737,Avg.Loss: -3.552,LR: 2.47E-05]Training epoch 86:  74%|███████▍  | 83/112 [00:01<00:00, 52.62it/s, Epoch: 86, Batch: 84,Loss: -3.798,Avg.Loss: -3.555,LR: 2.46E-05]Training epoch 86:  75%|███████▌  | 84/112 [00:01<00:00, 52.84it/s, Epoch: 86, Batch: 84,Loss: -3.798,Avg.Loss: -3.555,LR: 2.46E-05]Training epoch 86:  75%|███████▌  | 84/112 [00:01<00:00, 52.84it/s, Epoch: 86, Batch: 85,Loss: -3.427,Avg.Loss: -3.554,LR: 2.46E-05]Training epoch 86:  76%|███████▌  | 85/112 [00:01<00:00, 52.84it/s, Epoch: 86, Batch: 86,Loss: -3.687,Avg.Loss: -3.555,LR: 2.46E-05]Training epoch 86:  77%|███████▋  | 86/112 [00:01<00:00, 52.84it/s, Epoch: 86, Batch: 87,Loss: -3.631,Avg.Loss: -3.556,LR: 2.45E-05]Training epoch 86:  78%|███████▊  | 87/112 [00:01<00:00, 52.84it/s, Epoch: 86, Batch: 88,Loss: -3.757,Avg.Loss: -3.558,LR: 2.45E-05]Training epoch 86:  79%|███████▊  | 88/112 [00:01<00:00, 52.84it/s, Epoch: 86, Batch: 89,Loss: -3.481,Avg.Loss: -3.558,LR: 2.45E-05]Training epoch 86:  79%|███████▉  | 89/112 [00:01<00:00, 52.84it/s, Epoch: 86, Batch: 90,Loss: -4.035,Avg.Loss: -3.563,LR: 2.45E-05]Training epoch 86:  80%|████████  | 90/112 [00:01<00:00, 53.09it/s, Epoch: 86, Batch: 90,Loss: -4.035,Avg.Loss: -3.563,LR: 2.45E-05]Training epoch 86:  80%|████████  | 90/112 [00:01<00:00, 53.09it/s, Epoch: 86, Batch: 91,Loss: -3.642,Avg.Loss: -3.564,LR: 2.44E-05]Training epoch 86:  81%|████████▏ | 91/112 [00:01<00:00, 53.09it/s, Epoch: 86, Batch: 92,Loss: -3.356,Avg.Loss: -3.561,LR: 2.44E-05]Training epoch 86:  82%|████████▏ | 92/112 [00:01<00:00, 53.09it/s, Epoch: 86, Batch: 93,Loss: -3.505,Avg.Loss: -3.561,LR: 2.44E-05]Training epoch 86:  83%|████████▎ | 93/112 [00:01<00:00, 53.09it/s, Epoch: 86, Batch: 94,Loss: -3.659,Avg.Loss: -3.562,LR: 2.43E-05]Training epoch 86:  84%|████████▍ | 94/112 [00:01<00:00, 53.09it/s, Epoch: 86, Batch: 95,Loss: -3.341,Avg.Loss: -3.560,LR: 2.43E-05]Training epoch 86:  85%|████████▍ | 95/112 [00:01<00:00, 53.09it/s, Epoch: 86, Batch: 96,Loss: -3.452,Avg.Loss: -3.558,LR: 2.43E-05]Training epoch 86:  86%|████████▌ | 96/112 [00:01<00:00, 53.16it/s, Epoch: 86, Batch: 96,Loss: -3.452,Avg.Loss: -3.558,LR: 2.43E-05]Training epoch 86:  86%|████████▌ | 96/112 [00:01<00:00, 53.16it/s, Epoch: 86, Batch: 97,Loss: -3.015,Avg.Loss: -3.553,LR: 2.42E-05]Training epoch 86:  87%|████████▋ | 97/112 [00:01<00:00, 53.16it/s, Epoch: 86, Batch: 98,Loss: -3.381,Avg.Loss: -3.551,LR: 2.42E-05]Training epoch 86:  88%|████████▊ | 98/112 [00:01<00:00, 53.16it/s, Epoch: 86, Batch: 99,Loss: -3.697,Avg.Loss: -3.553,LR: 2.42E-05]Training epoch 86:  88%|████████▊ | 99/112 [00:01<00:00, 53.16it/s, Epoch: 86, Batch: 100,Loss: -3.600,Avg.Loss: -3.553,LR: 2.42E-05]Training epoch 86:  89%|████████▉ | 100/112 [00:01<00:00, 53.16it/s, Epoch: 86, Batch: 101,Loss: -3.623,Avg.Loss: -3.554,LR: 2.41E-05]Training epoch 86:  90%|█████████ | 101/112 [00:01<00:00, 53.16it/s, Epoch: 86, Batch: 102,Loss: -3.528,Avg.Loss: -3.554,LR: 2.41E-05]Training epoch 86:  91%|█████████ | 102/112 [00:01<00:00, 53.20it/s, Epoch: 86, Batch: 102,Loss: -3.528,Avg.Loss: -3.554,LR: 2.41E-05]Training epoch 86:  91%|█████████ | 102/112 [00:01<00:00, 53.20it/s, Epoch: 86, Batch: 103,Loss: -4.009,Avg.Loss: -3.558,LR: 2.41E-05]Training epoch 86:  92%|█████████▏| 103/112 [00:01<00:00, 53.20it/s, Epoch: 86, Batch: 104,Loss: -3.593,Avg.Loss: -3.558,LR: 2.40E-05]Training epoch 86:  93%|█████████▎| 104/112 [00:01<00:00, 53.20it/s, Epoch: 86, Batch: 105,Loss: -3.105,Avg.Loss: -3.554,LR: 2.40E-05]Training epoch 86:  94%|█████████▍| 105/112 [00:02<00:00, 53.20it/s, Epoch: 86, Batch: 106,Loss: -2.839,Avg.Loss: -3.547,LR: 2.40E-05]Training epoch 86:  95%|█████████▍| 106/112 [00:02<00:00, 53.20it/s, Epoch: 86, Batch: 107,Loss: -3.665,Avg.Loss: -3.548,LR: 2.39E-05]Training epoch 86:  96%|█████████▌| 107/112 [00:02<00:00, 53.20it/s, Epoch: 86, Batch: 108,Loss: -3.474,Avg.Loss: -3.548,LR: 2.39E-05]Training epoch 86:  96%|█████████▋| 108/112 [00:02<00:00, 52.44it/s, Epoch: 86, Batch: 108,Loss: -3.474,Avg.Loss: -3.548,LR: 2.39E-05]Training epoch 86:  96%|█████████▋| 108/112 [00:02<00:00, 52.44it/s, Epoch: 86, Batch: 109,Loss: -3.503,Avg.Loss: -3.547,LR: 2.39E-05]Training epoch 86:  97%|█████████▋| 109/112 [00:02<00:00, 52.44it/s, Epoch: 86, Batch: 110,Loss: -3.741,Avg.Loss: -3.549,LR: 2.39E-05]Training epoch 86:  98%|█████████▊| 110/112 [00:02<00:00, 52.44it/s, Epoch: 86, Batch: 111,Loss: -3.747,Avg.Loss: -3.551,LR: 2.38E-05]Training epoch 86:  99%|█████████▉| 111/112 [00:02<00:00, 52.44it/s, Epoch: 86, Batch: 112,Loss: -3.942,Avg.Loss: -3.554,LR: 2.38E-05]Training epoch 86: 100%|██████████| 112/112 [00:02<00:00, 52.82it/s, Epoch: 86, Batch: 112,Loss: -3.942,Avg.Loss: -3.554,LR: 2.38E-05]
Training epoch 87:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 87:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 87, Batch: 1,Loss: -3.599,Avg.Loss: -3.599,LR: 2.38E-05]Training epoch 87:   1%|          | 1/112 [00:00<00:04, 25.28it/s, Epoch: 87, Batch: 2,Loss: -3.178,Avg.Loss: -3.389,LR: 2.37E-05]Training epoch 87:   2%|▏         | 2/112 [00:00<00:03, 35.28it/s, Epoch: 87, Batch: 3,Loss: -3.070,Avg.Loss: -3.283,LR: 2.37E-05]Training epoch 87:   3%|▎         | 3/112 [00:00<00:02, 40.27it/s, Epoch: 87, Batch: 4,Loss: -3.135,Avg.Loss: -3.246,LR: 2.37E-05]Training epoch 87:   4%|▎         | 4/112 [00:00<00:02, 42.98it/s, Epoch: 87, Batch: 5,Loss: -2.699,Avg.Loss: -3.136,LR: 2.36E-05]Training epoch 87:   4%|▍         | 5/112 [00:00<00:02, 44.44it/s, Epoch: 87, Batch: 6,Loss: -3.301,Avg.Loss: -3.164,LR: 2.36E-05]Training epoch 87:   5%|▌         | 6/112 [00:00<00:01, 53.24it/s, Epoch: 87, Batch: 6,Loss: -3.301,Avg.Loss: -3.164,LR: 2.36E-05]Training epoch 87:   5%|▌         | 6/112 [00:00<00:01, 53.24it/s, Epoch: 87, Batch: 7,Loss: -3.607,Avg.Loss: -3.227,LR: 2.36E-05]Training epoch 87:   6%|▋         | 7/112 [00:00<00:01, 53.24it/s, Epoch: 87, Batch: 8,Loss: -3.350,Avg.Loss: -3.242,LR: 2.36E-05]Training epoch 87:   7%|▋         | 8/112 [00:00<00:01, 53.24it/s, Epoch: 87, Batch: 9,Loss: -3.439,Avg.Loss: -3.264,LR: 2.35E-05]Training epoch 87:   8%|▊         | 9/112 [00:00<00:01, 53.24it/s, Epoch: 87, Batch: 10,Loss: -3.887,Avg.Loss: -3.327,LR: 2.35E-05]Training epoch 87:   9%|▉         | 10/112 [00:00<00:01, 53.24it/s, Epoch: 87, Batch: 11,Loss: -3.574,Avg.Loss: -3.349,LR: 2.35E-05]Training epoch 87:  10%|▉         | 11/112 [00:00<00:01, 53.24it/s, Epoch: 87, Batch: 12,Loss: -3.770,Avg.Loss: -3.384,LR: 2.34E-05]Training epoch 87:  11%|█         | 12/112 [00:00<00:01, 53.08it/s, Epoch: 87, Batch: 12,Loss: -3.770,Avg.Loss: -3.384,LR: 2.34E-05]Training epoch 87:  11%|█         | 12/112 [00:00<00:01, 53.08it/s, Epoch: 87, Batch: 13,Loss: -3.698,Avg.Loss: -3.408,LR: 2.34E-05]Training epoch 87:  12%|█▏        | 13/112 [00:00<00:01, 53.08it/s, Epoch: 87, Batch: 14,Loss: -3.510,Avg.Loss: -3.416,LR: 2.34E-05]Training epoch 87:  12%|█▎        | 14/112 [00:00<00:01, 53.08it/s, Epoch: 87, Batch: 15,Loss: -4.035,Avg.Loss: -3.457,LR: 2.33E-05]Training epoch 87:  13%|█▎        | 15/112 [00:00<00:01, 53.08it/s, Epoch: 87, Batch: 16,Loss: -3.815,Avg.Loss: -3.479,LR: 2.33E-05]Training epoch 87:  14%|█▍        | 16/112 [00:00<00:01, 53.08it/s, Epoch: 87, Batch: 17,Loss: -3.598,Avg.Loss: -3.486,LR: 2.33E-05]Training epoch 87:  15%|█▌        | 17/112 [00:00<00:01, 53.08it/s, Epoch: 87, Batch: 18,Loss: -3.853,Avg.Loss: -3.507,LR: 2.33E-05]Training epoch 87:  16%|█▌        | 18/112 [00:00<00:01, 53.28it/s, Epoch: 87, Batch: 18,Loss: -3.853,Avg.Loss: -3.507,LR: 2.33E-05]Training epoch 87:  16%|█▌        | 18/112 [00:00<00:01, 53.28it/s, Epoch: 87, Batch: 19,Loss: -3.629,Avg.Loss: -3.513,LR: 2.32E-05]Training epoch 87:  17%|█▋        | 19/112 [00:00<00:01, 53.28it/s, Epoch: 87, Batch: 20,Loss: -3.692,Avg.Loss: -3.522,LR: 2.32E-05]Training epoch 87:  18%|█▊        | 20/112 [00:00<00:01, 53.28it/s, Epoch: 87, Batch: 21,Loss: -3.521,Avg.Loss: -3.522,LR: 2.32E-05]Training epoch 87:  19%|█▉        | 21/112 [00:00<00:01, 53.28it/s, Epoch: 87, Batch: 22,Loss: -3.804,Avg.Loss: -3.535,LR: 2.31E-05]Training epoch 87:  20%|█▉        | 22/112 [00:00<00:01, 53.28it/s, Epoch: 87, Batch: 23,Loss: -3.716,Avg.Loss: -3.543,LR: 2.31E-05]Training epoch 87:  21%|██        | 23/112 [00:00<00:01, 53.28it/s, Epoch: 87, Batch: 24,Loss: -3.779,Avg.Loss: -3.552,LR: 2.31E-05]Training epoch 87:  21%|██▏       | 24/112 [00:00<00:01, 52.71it/s, Epoch: 87, Batch: 24,Loss: -3.779,Avg.Loss: -3.552,LR: 2.31E-05]Training epoch 87:  21%|██▏       | 24/112 [00:00<00:01, 52.71it/s, Epoch: 87, Batch: 25,Loss: -3.364,Avg.Loss: -3.545,LR: 2.31E-05]Training epoch 87:  22%|██▏       | 25/112 [00:00<00:01, 52.71it/s, Epoch: 87, Batch: 26,Loss: -3.241,Avg.Loss: -3.533,LR: 2.30E-05]Training epoch 87:  23%|██▎       | 26/112 [00:00<00:01, 52.71it/s, Epoch: 87, Batch: 27,Loss: -3.648,Avg.Loss: -3.537,LR: 2.30E-05]Training epoch 87:  24%|██▍       | 27/112 [00:00<00:01, 52.71it/s, Epoch: 87, Batch: 28,Loss: -3.746,Avg.Loss: -3.545,LR: 2.30E-05]Training epoch 87:  25%|██▌       | 28/112 [00:00<00:01, 52.71it/s, Epoch: 87, Batch: 29,Loss: -3.851,Avg.Loss: -3.555,LR: 2.29E-05]Training epoch 87:  26%|██▌       | 29/112 [00:00<00:01, 52.71it/s, Epoch: 87, Batch: 30,Loss: -3.515,Avg.Loss: -3.554,LR: 2.29E-05]Training epoch 87:  27%|██▋       | 30/112 [00:00<00:01, 52.49it/s, Epoch: 87, Batch: 30,Loss: -3.515,Avg.Loss: -3.554,LR: 2.29E-05]Training epoch 87:  27%|██▋       | 30/112 [00:00<00:01, 52.49it/s, Epoch: 87, Batch: 31,Loss: -3.565,Avg.Loss: -3.554,LR: 2.29E-05]Training epoch 87:  28%|██▊       | 31/112 [00:00<00:01, 52.49it/s, Epoch: 87, Batch: 32,Loss: -3.417,Avg.Loss: -3.550,LR: 2.28E-05]Training epoch 87:  29%|██▊       | 32/112 [00:00<00:01, 52.49it/s, Epoch: 87, Batch: 33,Loss: -3.112,Avg.Loss: -3.537,LR: 2.28E-05]Training epoch 87:  29%|██▉       | 33/112 [00:00<00:01, 52.49it/s, Epoch: 87, Batch: 34,Loss: -3.878,Avg.Loss: -3.547,LR: 2.28E-05]Training epoch 87:  30%|███       | 34/112 [00:00<00:01, 52.49it/s, Epoch: 87, Batch: 35,Loss: -3.660,Avg.Loss: -3.550,LR: 2.28E-05]Training epoch 87:  31%|███▏      | 35/112 [00:00<00:01, 52.49it/s, Epoch: 87, Batch: 36,Loss: -4.105,Avg.Loss: -3.566,LR: 2.27E-05]Training epoch 87:  32%|███▏      | 36/112 [00:00<00:01, 52.38it/s, Epoch: 87, Batch: 36,Loss: -4.105,Avg.Loss: -3.566,LR: 2.27E-05]Training epoch 87:  32%|███▏      | 36/112 [00:00<00:01, 52.38it/s, Epoch: 87, Batch: 37,Loss: -3.553,Avg.Loss: -3.565,LR: 2.27E-05]Training epoch 87:  33%|███▎      | 37/112 [00:00<00:01, 52.38it/s, Epoch: 87, Batch: 38,Loss: -3.460,Avg.Loss: -3.562,LR: 2.27E-05]Training epoch 87:  34%|███▍      | 38/112 [00:00<00:01, 52.38it/s, Epoch: 87, Batch: 39,Loss: -3.574,Avg.Loss: -3.563,LR: 2.26E-05]Training epoch 87:  35%|███▍      | 39/112 [00:00<00:01, 52.38it/s, Epoch: 87, Batch: 40,Loss: -3.528,Avg.Loss: -3.562,LR: 2.26E-05]Training epoch 87:  36%|███▌      | 40/112 [00:00<00:01, 52.38it/s, Epoch: 87, Batch: 41,Loss: -2.892,Avg.Loss: -3.546,LR: 2.26E-05]Training epoch 87:  37%|███▋      | 41/112 [00:00<00:01, 52.38it/s, Epoch: 87, Batch: 42,Loss: -3.435,Avg.Loss: -3.543,LR: 2.26E-05]Training epoch 87:  38%|███▊      | 42/112 [00:00<00:01, 52.89it/s, Epoch: 87, Batch: 42,Loss: -3.435,Avg.Loss: -3.543,LR: 2.26E-05]Training epoch 87:  38%|███▊      | 42/112 [00:00<00:01, 52.89it/s, Epoch: 87, Batch: 43,Loss: -3.342,Avg.Loss: -3.538,LR: 2.25E-05]Training epoch 87:  38%|███▊      | 43/112 [00:00<00:01, 52.89it/s, Epoch: 87, Batch: 44,Loss: -3.773,Avg.Loss: -3.544,LR: 2.25E-05]Training epoch 87:  39%|███▉      | 44/112 [00:00<00:01, 52.89it/s, Epoch: 87, Batch: 45,Loss: -3.689,Avg.Loss: -3.547,LR: 2.25E-05]Training epoch 87:  40%|████      | 45/112 [00:00<00:01, 52.89it/s, Epoch: 87, Batch: 46,Loss: -3.758,Avg.Loss: -3.551,LR: 2.24E-05]Training epoch 87:  41%|████      | 46/112 [00:00<00:01, 52.89it/s, Epoch: 87, Batch: 47,Loss: -3.450,Avg.Loss: -3.549,LR: 2.24E-05]Training epoch 87:  42%|████▏     | 47/112 [00:00<00:01, 52.89it/s, Epoch: 87, Batch: 48,Loss: -3.267,Avg.Loss: -3.543,LR: 2.24E-05]Training epoch 87:  43%|████▎     | 48/112 [00:00<00:01, 53.09it/s, Epoch: 87, Batch: 48,Loss: -3.267,Avg.Loss: -3.543,LR: 2.24E-05]Training epoch 87:  43%|████▎     | 48/112 [00:00<00:01, 53.09it/s, Epoch: 87, Batch: 49,Loss: -3.380,Avg.Loss: -3.540,LR: 2.24E-05]Training epoch 87:  44%|████▍     | 49/112 [00:00<00:01, 53.09it/s, Epoch: 87, Batch: 50,Loss: -3.426,Avg.Loss: -3.538,LR: 2.23E-05]Training epoch 87:  45%|████▍     | 50/112 [00:00<00:01, 53.09it/s, Epoch: 87, Batch: 51,Loss: -3.396,Avg.Loss: -3.535,LR: 2.23E-05]Training epoch 87:  46%|████▌     | 51/112 [00:00<00:01, 53.09it/s, Epoch: 87, Batch: 52,Loss: -3.566,Avg.Loss: -3.536,LR: 2.23E-05]Training epoch 87:  46%|████▋     | 52/112 [00:01<00:01, 53.09it/s, Epoch: 87, Batch: 53,Loss: -3.730,Avg.Loss: -3.539,LR: 2.22E-05]Training epoch 87:  47%|████▋     | 53/112 [00:01<00:01, 53.09it/s, Epoch: 87, Batch: 54,Loss: -3.592,Avg.Loss: -3.540,LR: 2.22E-05]Training epoch 87:  48%|████▊     | 54/112 [00:01<00:01, 53.14it/s, Epoch: 87, Batch: 54,Loss: -3.592,Avg.Loss: -3.540,LR: 2.22E-05]Training epoch 87:  48%|████▊     | 54/112 [00:01<00:01, 53.14it/s, Epoch: 87, Batch: 55,Loss: -3.536,Avg.Loss: -3.540,LR: 2.22E-05]Training epoch 87:  49%|████▉     | 55/112 [00:01<00:01, 53.14it/s, Epoch: 87, Batch: 56,Loss: -3.575,Avg.Loss: -3.541,LR: 2.21E-05]Training epoch 87:  50%|█████     | 56/112 [00:01<00:01, 53.14it/s, Epoch: 87, Batch: 57,Loss: -4.013,Avg.Loss: -3.549,LR: 2.21E-05]Training epoch 87:  51%|█████     | 57/112 [00:01<00:01, 53.14it/s, Epoch: 87, Batch: 58,Loss: -3.562,Avg.Loss: -3.549,LR: 2.21E-05]Training epoch 87:  52%|█████▏    | 58/112 [00:01<00:01, 53.14it/s, Epoch: 87, Batch: 59,Loss: -3.465,Avg.Loss: -3.548,LR: 2.21E-05]Training epoch 87:  53%|█████▎    | 59/112 [00:01<00:00, 53.14it/s, Epoch: 87, Batch: 60,Loss: -3.844,Avg.Loss: -3.553,LR: 2.20E-05]Training epoch 87:  54%|█████▎    | 60/112 [00:01<00:00, 53.40it/s, Epoch: 87, Batch: 60,Loss: -3.844,Avg.Loss: -3.553,LR: 2.20E-05]Training epoch 87:  54%|█████▎    | 60/112 [00:01<00:00, 53.40it/s, Epoch: 87, Batch: 61,Loss: -3.625,Avg.Loss: -3.554,LR: 2.20E-05]Training epoch 87:  54%|█████▍    | 61/112 [00:01<00:00, 53.40it/s, Epoch: 87, Batch: 62,Loss: -3.293,Avg.Loss: -3.550,LR: 2.20E-05]Training epoch 87:  55%|█████▌    | 62/112 [00:01<00:00, 53.40it/s, Epoch: 87, Batch: 63,Loss: -3.174,Avg.Loss: -3.544,LR: 2.19E-05]Training epoch 87:  56%|█████▋    | 63/112 [00:01<00:00, 53.40it/s, Epoch: 87, Batch: 64,Loss: -3.977,Avg.Loss: -3.551,LR: 2.19E-05]Training epoch 87:  57%|█████▋    | 64/112 [00:01<00:00, 53.40it/s, Epoch: 87, Batch: 65,Loss: -3.488,Avg.Loss: -3.550,LR: 2.19E-05]Training epoch 87:  58%|█████▊    | 65/112 [00:01<00:00, 53.40it/s, Epoch: 87, Batch: 66,Loss: -3.695,Avg.Loss: -3.552,LR: 2.19E-05]Training epoch 87:  59%|█████▉    | 66/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 66,Loss: -3.695,Avg.Loss: -3.552,LR: 2.19E-05]Training epoch 87:  59%|█████▉    | 66/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 67,Loss: -3.581,Avg.Loss: -3.552,LR: 2.18E-05]Training epoch 87:  60%|█████▉    | 67/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 68,Loss: -3.381,Avg.Loss: -3.550,LR: 2.18E-05]Training epoch 87:  61%|██████    | 68/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 69,Loss: -3.501,Avg.Loss: -3.549,LR: 2.18E-05]Training epoch 87:  62%|██████▏   | 69/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 70,Loss: -4.089,Avg.Loss: -3.557,LR: 2.17E-05]Training epoch 87:  62%|██████▎   | 70/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 71,Loss: -3.677,Avg.Loss: -3.558,LR: 2.17E-05]Training epoch 87:  63%|██████▎   | 71/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 72,Loss: -2.931,Avg.Loss: -3.550,LR: 2.17E-05]Training epoch 87:  64%|██████▍   | 72/112 [00:01<00:00, 53.54it/s, Epoch: 87, Batch: 72,Loss: -2.931,Avg.Loss: -3.550,LR: 2.17E-05]Training epoch 87:  64%|██████▍   | 72/112 [00:01<00:00, 53.54it/s, Epoch: 87, Batch: 73,Loss: -3.304,Avg.Loss: -3.546,LR: 2.17E-05]Training epoch 87:  65%|██████▌   | 73/112 [00:01<00:00, 53.54it/s, Epoch: 87, Batch: 74,Loss: -3.277,Avg.Loss: -3.543,LR: 2.16E-05]Training epoch 87:  66%|██████▌   | 74/112 [00:01<00:00, 53.54it/s, Epoch: 87, Batch: 75,Loss: -3.950,Avg.Loss: -3.548,LR: 2.16E-05]Training epoch 87:  67%|██████▋   | 75/112 [00:01<00:00, 53.54it/s, Epoch: 87, Batch: 76,Loss: -3.959,Avg.Loss: -3.553,LR: 2.16E-05]Training epoch 87:  68%|██████▊   | 76/112 [00:01<00:00, 53.54it/s, Epoch: 87, Batch: 77,Loss: -3.675,Avg.Loss: -3.555,LR: 2.15E-05]Training epoch 87:  69%|██████▉   | 77/112 [00:01<00:00, 53.54it/s, Epoch: 87, Batch: 78,Loss: -3.758,Avg.Loss: -3.558,LR: 2.15E-05]Training epoch 87:  70%|██████▉   | 78/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 78,Loss: -3.758,Avg.Loss: -3.558,LR: 2.15E-05]Training epoch 87:  70%|██████▉   | 78/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 79,Loss: -3.399,Avg.Loss: -3.556,LR: 2.15E-05]Training epoch 87:  71%|███████   | 79/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 80,Loss: -3.029,Avg.Loss: -3.549,LR: 2.15E-05]Training epoch 87:  71%|███████▏  | 80/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 81,Loss: -3.288,Avg.Loss: -3.546,LR: 2.14E-05]Training epoch 87:  72%|███████▏  | 81/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 82,Loss: -3.716,Avg.Loss: -3.548,LR: 2.14E-05]Training epoch 87:  73%|███████▎  | 82/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 83,Loss: -3.744,Avg.Loss: -3.550,LR: 2.14E-05]Training epoch 87:  74%|███████▍  | 83/112 [00:01<00:00, 53.64it/s, Epoch: 87, Batch: 84,Loss: -3.824,Avg.Loss: -3.554,LR: 2.13E-05]Training epoch 87:  75%|███████▌  | 84/112 [00:01<00:00, 53.70it/s, Epoch: 87, Batch: 84,Loss: -3.824,Avg.Loss: -3.554,LR: 2.13E-05]Training epoch 87:  75%|███████▌  | 84/112 [00:01<00:00, 53.70it/s, Epoch: 87, Batch: 85,Loss: -3.454,Avg.Loss: -3.552,LR: 2.13E-05]Training epoch 87:  76%|███████▌  | 85/112 [00:01<00:00, 53.70it/s, Epoch: 87, Batch: 86,Loss: -3.854,Avg.Loss: -3.556,LR: 2.13E-05]Training epoch 87:  77%|███████▋  | 86/112 [00:01<00:00, 53.70it/s, Epoch: 87, Batch: 87,Loss: -3.114,Avg.Loss: -3.551,LR: 2.13E-05]Training epoch 87:  78%|███████▊  | 87/112 [00:01<00:00, 53.70it/s, Epoch: 87, Batch: 88,Loss: -3.578,Avg.Loss: -3.551,LR: 2.12E-05]Training epoch 87:  79%|███████▊  | 88/112 [00:01<00:00, 53.70it/s, Epoch: 87, Batch: 89,Loss: -3.722,Avg.Loss: -3.553,LR: 2.12E-05]Training epoch 87:  79%|███████▉  | 89/112 [00:01<00:00, 53.70it/s, Epoch: 87, Batch: 90,Loss: -3.616,Avg.Loss: -3.554,LR: 2.12E-05]Training epoch 87:  80%|████████  | 90/112 [00:01<00:00, 53.74it/s, Epoch: 87, Batch: 90,Loss: -3.616,Avg.Loss: -3.554,LR: 2.12E-05]Training epoch 87:  80%|████████  | 90/112 [00:01<00:00, 53.74it/s, Epoch: 87, Batch: 91,Loss: -3.783,Avg.Loss: -3.556,LR: 2.12E-05]Training epoch 87:  81%|████████▏ | 91/112 [00:01<00:00, 53.74it/s, Epoch: 87, Batch: 92,Loss: -3.835,Avg.Loss: -3.559,LR: 2.11E-05]Training epoch 87:  82%|████████▏ | 92/112 [00:01<00:00, 53.74it/s, Epoch: 87, Batch: 93,Loss: -3.161,Avg.Loss: -3.555,LR: 2.11E-05]Training epoch 87:  83%|████████▎ | 93/112 [00:01<00:00, 53.74it/s, Epoch: 87, Batch: 94,Loss: -3.625,Avg.Loss: -3.556,LR: 2.11E-05]Training epoch 87:  84%|████████▍ | 94/112 [00:01<00:00, 53.74it/s, Epoch: 87, Batch: 95,Loss: -3.809,Avg.Loss: -3.558,LR: 2.10E-05]Training epoch 87:  85%|████████▍ | 95/112 [00:01<00:00, 53.74it/s, Epoch: 87, Batch: 96,Loss: -3.594,Avg.Loss: -3.559,LR: 2.10E-05]Training epoch 87:  86%|████████▌ | 96/112 [00:01<00:00, 53.72it/s, Epoch: 87, Batch: 96,Loss: -3.594,Avg.Loss: -3.559,LR: 2.10E-05]Training epoch 87:  86%|████████▌ | 96/112 [00:01<00:00, 53.72it/s, Epoch: 87, Batch: 97,Loss: -3.788,Avg.Loss: -3.561,LR: 2.10E-05]Training epoch 87:  87%|████████▋ | 97/112 [00:01<00:00, 53.72it/s, Epoch: 87, Batch: 98,Loss: -3.751,Avg.Loss: -3.563,LR: 2.10E-05]Training epoch 87:  88%|████████▊ | 98/112 [00:01<00:00, 53.72it/s, Epoch: 87, Batch: 99,Loss: -3.546,Avg.Loss: -3.563,LR: 2.09E-05]Training epoch 87:  88%|████████▊ | 99/112 [00:01<00:00, 53.72it/s, Epoch: 87, Batch: 100,Loss: -3.439,Avg.Loss: -3.562,LR: 2.09E-05]Training epoch 87:  89%|████████▉ | 100/112 [00:01<00:00, 53.72it/s, Epoch: 87, Batch: 101,Loss: -3.873,Avg.Loss: -3.565,LR: 2.09E-05]Training epoch 87:  90%|█████████ | 101/112 [00:01<00:00, 53.72it/s, Epoch: 87, Batch: 102,Loss: -3.556,Avg.Loss: -3.565,LR: 2.08E-05]Training epoch 87:  91%|█████████ | 102/112 [00:01<00:00, 53.56it/s, Epoch: 87, Batch: 102,Loss: -3.556,Avg.Loss: -3.565,LR: 2.08E-05]Training epoch 87:  91%|█████████ | 102/112 [00:01<00:00, 53.56it/s, Epoch: 87, Batch: 103,Loss: -3.583,Avg.Loss: -3.565,LR: 2.08E-05]Training epoch 87:  92%|█████████▏| 103/112 [00:01<00:00, 53.56it/s, Epoch: 87, Batch: 104,Loss: -3.981,Avg.Loss: -3.569,LR: 2.08E-05]Training epoch 87:  93%|█████████▎| 104/112 [00:01<00:00, 53.56it/s, Epoch: 87, Batch: 105,Loss: -3.793,Avg.Loss: -3.571,LR: 2.08E-05]Training epoch 87:  94%|█████████▍| 105/112 [00:01<00:00, 53.56it/s, Epoch: 87, Batch: 106,Loss: -3.491,Avg.Loss: -3.570,LR: 2.07E-05]Training epoch 87:  95%|█████████▍| 106/112 [00:02<00:00, 53.56it/s, Epoch: 87, Batch: 107,Loss: -3.248,Avg.Loss: -3.567,LR: 2.07E-05]Training epoch 87:  96%|█████████▌| 107/112 [00:02<00:00, 53.56it/s, Epoch: 87, Batch: 108,Loss: -3.625,Avg.Loss: -3.568,LR: 2.07E-05]Training epoch 87:  96%|█████████▋| 108/112 [00:02<00:00, 53.53it/s, Epoch: 87, Batch: 108,Loss: -3.625,Avg.Loss: -3.568,LR: 2.07E-05]Training epoch 87:  96%|█████████▋| 108/112 [00:02<00:00, 53.53it/s, Epoch: 87, Batch: 109,Loss: -3.868,Avg.Loss: -3.571,LR: 2.06E-05]Training epoch 87:  97%|█████████▋| 109/112 [00:02<00:00, 53.53it/s, Epoch: 87, Batch: 110,Loss: -3.196,Avg.Loss: -3.567,LR: 2.06E-05]Training epoch 87:  98%|█████████▊| 110/112 [00:02<00:00, 53.53it/s, Epoch: 87, Batch: 111,Loss: -3.591,Avg.Loss: -3.567,LR: 2.06E-05]Training epoch 87:  99%|█████████▉| 111/112 [00:02<00:00, 53.53it/s, Epoch: 87, Batch: 112,Loss: -4.101,Avg.Loss: -3.572,LR: 2.06E-05]Training epoch 87: 100%|██████████| 112/112 [00:02<00:00, 53.19it/s, Epoch: 87, Batch: 112,Loss: -4.101,Avg.Loss: -3.572,LR: 2.06E-05]
Training epoch 88:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 88:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 88, Batch: 1,Loss: -3.034,Avg.Loss: -3.034,LR: 2.05E-05]Training epoch 88:   1%|          | 1/112 [00:00<00:04, 26.15it/s, Epoch: 88, Batch: 2,Loss: -2.899,Avg.Loss: -2.966,LR: 2.05E-05]Training epoch 88:   2%|▏         | 2/112 [00:00<00:03, 35.70it/s, Epoch: 88, Batch: 3,Loss: -3.019,Avg.Loss: -2.984,LR: 2.05E-05]Training epoch 88:   3%|▎         | 3/112 [00:00<00:02, 42.96it/s, Epoch: 88, Batch: 4,Loss: -3.362,Avg.Loss: -3.079,LR: 2.05E-05]Training epoch 88:   4%|▎         | 4/112 [00:00<00:02, 44.97it/s, Epoch: 88, Batch: 5,Loss: -3.169,Avg.Loss: -3.097,LR: 2.04E-05]Training epoch 88:   4%|▍         | 5/112 [00:00<00:02, 46.43it/s, Epoch: 88, Batch: 6,Loss: -3.413,Avg.Loss: -3.149,LR: 2.04E-05]Training epoch 88:   5%|▌         | 6/112 [00:00<00:01, 55.61it/s, Epoch: 88, Batch: 6,Loss: -3.413,Avg.Loss: -3.149,LR: 2.04E-05]Training epoch 88:   5%|▌         | 6/112 [00:00<00:01, 55.61it/s, Epoch: 88, Batch: 7,Loss: -3.727,Avg.Loss: -3.232,LR: 2.04E-05]Training epoch 88:   6%|▋         | 7/112 [00:00<00:01, 55.61it/s, Epoch: 88, Batch: 8,Loss: -3.472,Avg.Loss: -3.262,LR: 2.03E-05]Training epoch 88:   7%|▋         | 8/112 [00:00<00:01, 55.61it/s, Epoch: 88, Batch: 9,Loss: -3.699,Avg.Loss: -3.310,LR: 2.03E-05]Training epoch 88:   8%|▊         | 9/112 [00:00<00:01, 55.61it/s, Epoch: 88, Batch: 10,Loss: -3.164,Avg.Loss: -3.296,LR: 2.03E-05]Training epoch 88:   9%|▉         | 10/112 [00:00<00:01, 55.61it/s, Epoch: 88, Batch: 11,Loss: -4.044,Avg.Loss: -3.364,LR: 2.03E-05]Training epoch 88:  10%|▉         | 11/112 [00:00<00:01, 55.61it/s, Epoch: 88, Batch: 12,Loss: -3.682,Avg.Loss: -3.390,LR: 2.02E-05]Training epoch 88:  11%|█         | 12/112 [00:00<00:01, 53.69it/s, Epoch: 88, Batch: 12,Loss: -3.682,Avg.Loss: -3.390,LR: 2.02E-05]Training epoch 88:  11%|█         | 12/112 [00:00<00:01, 53.69it/s, Epoch: 88, Batch: 13,Loss: -3.492,Avg.Loss: -3.398,LR: 2.02E-05]Training epoch 88:  12%|█▏        | 13/112 [00:00<00:01, 53.69it/s, Epoch: 88, Batch: 14,Loss: -3.459,Avg.Loss: -3.403,LR: 2.02E-05]Training epoch 88:  12%|█▎        | 14/112 [00:00<00:01, 53.69it/s, Epoch: 88, Batch: 15,Loss: -3.593,Avg.Loss: -3.415,LR: 2.01E-05]Training epoch 88:  13%|█▎        | 15/112 [00:00<00:01, 53.69it/s, Epoch: 88, Batch: 16,Loss: -3.527,Avg.Loss: -3.422,LR: 2.01E-05]Training epoch 88:  14%|█▍        | 16/112 [00:00<00:01, 53.69it/s, Epoch: 88, Batch: 17,Loss: -3.968,Avg.Loss: -3.454,LR: 2.01E-05]Training epoch 88:  15%|█▌        | 17/112 [00:00<00:01, 53.69it/s, Epoch: 88, Batch: 18,Loss: -3.842,Avg.Loss: -3.476,LR: 2.01E-05]Training epoch 88:  16%|█▌        | 18/112 [00:00<00:01, 53.13it/s, Epoch: 88, Batch: 18,Loss: -3.842,Avg.Loss: -3.476,LR: 2.01E-05]Training epoch 88:  16%|█▌        | 18/112 [00:00<00:01, 53.13it/s, Epoch: 88, Batch: 19,Loss: -3.986,Avg.Loss: -3.503,LR: 2.00E-05]Training epoch 88:  17%|█▋        | 19/112 [00:00<00:01, 53.13it/s, Epoch: 88, Batch: 20,Loss: -3.510,Avg.Loss: -3.503,LR: 2.00E-05]Training epoch 88:  18%|█▊        | 20/112 [00:00<00:01, 53.13it/s, Epoch: 88, Batch: 21,Loss: -3.828,Avg.Loss: -3.519,LR: 2.00E-05]Training epoch 88:  19%|█▉        | 21/112 [00:00<00:01, 53.13it/s, Epoch: 88, Batch: 22,Loss: -4.133,Avg.Loss: -3.546,LR: 2.00E-05]Training epoch 88:  20%|█▉        | 22/112 [00:00<00:01, 53.13it/s, Epoch: 88, Batch: 23,Loss: -3.460,Avg.Loss: -3.543,LR: 1.99E-05]Training epoch 88:  21%|██        | 23/112 [00:00<00:01, 53.13it/s, Epoch: 88, Batch: 24,Loss: -3.739,Avg.Loss: -3.551,LR: 1.99E-05]Training epoch 88:  21%|██▏       | 24/112 [00:00<00:01, 52.80it/s, Epoch: 88, Batch: 24,Loss: -3.739,Avg.Loss: -3.551,LR: 1.99E-05]Training epoch 88:  21%|██▏       | 24/112 [00:00<00:01, 52.80it/s, Epoch: 88, Batch: 25,Loss: -3.122,Avg.Loss: -3.534,LR: 1.99E-05]Training epoch 88:  22%|██▏       | 25/112 [00:00<00:01, 52.80it/s, Epoch: 88, Batch: 26,Loss: -3.114,Avg.Loss: -3.518,LR: 1.98E-05]Training epoch 88:  23%|██▎       | 26/112 [00:00<00:01, 52.80it/s, Epoch: 88, Batch: 27,Loss: -3.393,Avg.Loss: -3.513,LR: 1.98E-05]Training epoch 88:  24%|██▍       | 27/112 [00:00<00:01, 52.80it/s, Epoch: 88, Batch: 28,Loss: -3.522,Avg.Loss: -3.513,LR: 1.98E-05]Training epoch 88:  25%|██▌       | 28/112 [00:00<00:01, 52.80it/s, Epoch: 88, Batch: 29,Loss: -3.663,Avg.Loss: -3.518,LR: 1.98E-05]Training epoch 88:  26%|██▌       | 29/112 [00:00<00:01, 52.80it/s, Epoch: 88, Batch: 30,Loss: -3.447,Avg.Loss: -3.516,LR: 1.97E-05]Training epoch 88:  27%|██▋       | 30/112 [00:00<00:01, 52.70it/s, Epoch: 88, Batch: 30,Loss: -3.447,Avg.Loss: -3.516,LR: 1.97E-05]Training epoch 88:  27%|██▋       | 30/112 [00:00<00:01, 52.70it/s, Epoch: 88, Batch: 31,Loss: -3.750,Avg.Loss: -3.524,LR: 1.97E-05]Training epoch 88:  28%|██▊       | 31/112 [00:00<00:01, 52.70it/s, Epoch: 88, Batch: 32,Loss: -3.761,Avg.Loss: -3.531,LR: 1.97E-05]Training epoch 88:  29%|██▊       | 32/112 [00:00<00:01, 52.70it/s, Epoch: 88, Batch: 33,Loss: -3.912,Avg.Loss: -3.543,LR: 1.97E-05]Training epoch 88:  29%|██▉       | 33/112 [00:00<00:01, 52.70it/s, Epoch: 88, Batch: 34,Loss: -3.868,Avg.Loss: -3.552,LR: 1.96E-05]Training epoch 88:  30%|███       | 34/112 [00:00<00:01, 52.70it/s, Epoch: 88, Batch: 35,Loss: -3.771,Avg.Loss: -3.558,LR: 1.96E-05]Training epoch 88:  31%|███▏      | 35/112 [00:00<00:01, 52.70it/s, Epoch: 88, Batch: 36,Loss: -3.749,Avg.Loss: -3.564,LR: 1.96E-05]Training epoch 88:  32%|███▏      | 36/112 [00:00<00:01, 52.35it/s, Epoch: 88, Batch: 36,Loss: -3.749,Avg.Loss: -3.564,LR: 1.96E-05]Training epoch 88:  32%|███▏      | 36/112 [00:00<00:01, 52.35it/s, Epoch: 88, Batch: 37,Loss: -3.826,Avg.Loss: -3.571,LR: 1.95E-05]Training epoch 88:  33%|███▎      | 37/112 [00:00<00:01, 52.35it/s, Epoch: 88, Batch: 38,Loss: -3.619,Avg.Loss: -3.572,LR: 1.95E-05]Training epoch 88:  34%|███▍      | 38/112 [00:00<00:01, 52.35it/s, Epoch: 88, Batch: 39,Loss: -3.547,Avg.Loss: -3.571,LR: 1.95E-05]Training epoch 88:  35%|███▍      | 39/112 [00:00<00:01, 52.35it/s, Epoch: 88, Batch: 40,Loss: -3.437,Avg.Loss: -3.568,LR: 1.95E-05]Training epoch 88:  36%|███▌      | 40/112 [00:00<00:01, 52.35it/s, Epoch: 88, Batch: 41,Loss: -3.091,Avg.Loss: -3.556,LR: 1.94E-05]Training epoch 88:  37%|███▋      | 41/112 [00:00<00:01, 52.35it/s, Epoch: 88, Batch: 42,Loss: -3.496,Avg.Loss: -3.555,LR: 1.94E-05]Training epoch 88:  38%|███▊      | 42/112 [00:00<00:01, 52.57it/s, Epoch: 88, Batch: 42,Loss: -3.496,Avg.Loss: -3.555,LR: 1.94E-05]Training epoch 88:  38%|███▊      | 42/112 [00:00<00:01, 52.57it/s, Epoch: 88, Batch: 43,Loss: -3.322,Avg.Loss: -3.550,LR: 1.94E-05]Training epoch 88:  38%|███▊      | 43/112 [00:00<00:01, 52.57it/s, Epoch: 88, Batch: 44,Loss: -3.377,Avg.Loss: -3.546,LR: 1.94E-05]Training epoch 88:  39%|███▉      | 44/112 [00:00<00:01, 52.57it/s, Epoch: 88, Batch: 45,Loss: -3.737,Avg.Loss: -3.550,LR: 1.93E-05]Training epoch 88:  40%|████      | 45/112 [00:00<00:01, 52.57it/s, Epoch: 88, Batch: 46,Loss: -3.428,Avg.Loss: -3.547,LR: 1.93E-05]Training epoch 88:  41%|████      | 46/112 [00:00<00:01, 52.57it/s, Epoch: 88, Batch: 47,Loss: -3.692,Avg.Loss: -3.550,LR: 1.93E-05]Training epoch 88:  42%|████▏     | 47/112 [00:00<00:01, 52.57it/s, Epoch: 88, Batch: 48,Loss: -3.686,Avg.Loss: -3.553,LR: 1.92E-05]Training epoch 88:  43%|████▎     | 48/112 [00:00<00:01, 52.79it/s, Epoch: 88, Batch: 48,Loss: -3.686,Avg.Loss: -3.553,LR: 1.92E-05]Training epoch 88:  43%|████▎     | 48/112 [00:00<00:01, 52.79it/s, Epoch: 88, Batch: 49,Loss: -3.680,Avg.Loss: -3.556,LR: 1.92E-05]Training epoch 88:  44%|████▍     | 49/112 [00:00<00:01, 52.79it/s, Epoch: 88, Batch: 50,Loss: -3.954,Avg.Loss: -3.564,LR: 1.92E-05]Training epoch 88:  45%|████▍     | 50/112 [00:00<00:01, 52.79it/s, Epoch: 88, Batch: 51,Loss: -3.844,Avg.Loss: -3.569,LR: 1.92E-05]Training epoch 88:  46%|████▌     | 51/112 [00:00<00:01, 52.79it/s, Epoch: 88, Batch: 52,Loss: -4.082,Avg.Loss: -3.579,LR: 1.91E-05]Training epoch 88:  46%|████▋     | 52/112 [00:01<00:01, 52.79it/s, Epoch: 88, Batch: 53,Loss: -3.681,Avg.Loss: -3.581,LR: 1.91E-05]Training epoch 88:  47%|████▋     | 53/112 [00:01<00:01, 52.79it/s, Epoch: 88, Batch: 54,Loss: -3.626,Avg.Loss: -3.582,LR: 1.91E-05]Training epoch 88:  48%|████▊     | 54/112 [00:01<00:01, 52.90it/s, Epoch: 88, Batch: 54,Loss: -3.626,Avg.Loss: -3.582,LR: 1.91E-05]Training epoch 88:  48%|████▊     | 54/112 [00:01<00:01, 52.90it/s, Epoch: 88, Batch: 55,Loss: -3.837,Avg.Loss: -3.586,LR: 1.91E-05]Training epoch 88:  49%|████▉     | 55/112 [00:01<00:01, 52.90it/s, Epoch: 88, Batch: 56,Loss: -3.370,Avg.Loss: -3.583,LR: 1.90E-05]Training epoch 88:  50%|█████     | 56/112 [00:01<00:01, 52.90it/s, Epoch: 88, Batch: 57,Loss: -3.215,Avg.Loss: -3.576,LR: 1.90E-05]Training epoch 88:  51%|█████     | 57/112 [00:01<00:01, 52.90it/s, Epoch: 88, Batch: 58,Loss: -3.468,Avg.Loss: -3.574,LR: 1.90E-05]Training epoch 88:  52%|█████▏    | 58/112 [00:01<00:01, 52.90it/s, Epoch: 88, Batch: 59,Loss: -3.901,Avg.Loss: -3.580,LR: 1.89E-05]Training epoch 88:  53%|█████▎    | 59/112 [00:01<00:01, 52.90it/s, Epoch: 88, Batch: 60,Loss: -3.573,Avg.Loss: -3.580,LR: 1.89E-05]Training epoch 88:  54%|█████▎    | 60/112 [00:01<00:00, 52.98it/s, Epoch: 88, Batch: 60,Loss: -3.573,Avg.Loss: -3.580,LR: 1.89E-05]Training epoch 88:  54%|█████▎    | 60/112 [00:01<00:00, 52.98it/s, Epoch: 88, Batch: 61,Loss: -3.559,Avg.Loss: -3.579,LR: 1.89E-05]Training epoch 88:  54%|█████▍    | 61/112 [00:01<00:00, 52.98it/s, Epoch: 88, Batch: 62,Loss: -3.866,Avg.Loss: -3.584,LR: 1.89E-05]Training epoch 88:  55%|█████▌    | 62/112 [00:01<00:00, 52.98it/s, Epoch: 88, Batch: 63,Loss: -3.423,Avg.Loss: -3.581,LR: 1.88E-05]Training epoch 88:  56%|█████▋    | 63/112 [00:01<00:00, 52.98it/s, Epoch: 88, Batch: 64,Loss: -3.916,Avg.Loss: -3.587,LR: 1.88E-05]Training epoch 88:  57%|█████▋    | 64/112 [00:01<00:00, 52.98it/s, Epoch: 88, Batch: 65,Loss: -3.524,Avg.Loss: -3.586,LR: 1.88E-05]Training epoch 88:  58%|█████▊    | 65/112 [00:01<00:00, 52.98it/s, Epoch: 88, Batch: 66,Loss: -3.416,Avg.Loss: -3.583,LR: 1.88E-05]Training epoch 88:  59%|█████▉    | 66/112 [00:01<00:00, 53.00it/s, Epoch: 88, Batch: 66,Loss: -3.416,Avg.Loss: -3.583,LR: 1.88E-05]Training epoch 88:  59%|█████▉    | 66/112 [00:01<00:00, 53.00it/s, Epoch: 88, Batch: 67,Loss: -3.752,Avg.Loss: -3.586,LR: 1.87E-05]Training epoch 88:  60%|█████▉    | 67/112 [00:01<00:00, 53.00it/s, Epoch: 88, Batch: 68,Loss: -3.499,Avg.Loss: -3.584,LR: 1.87E-05]Training epoch 88:  61%|██████    | 68/112 [00:01<00:00, 53.00it/s, Epoch: 88, Batch: 69,Loss: -4.045,Avg.Loss: -3.591,LR: 1.87E-05]Training epoch 88:  62%|██████▏   | 69/112 [00:01<00:00, 53.00it/s, Epoch: 88, Batch: 70,Loss: -3.833,Avg.Loss: -3.595,LR: 1.87E-05]Training epoch 88:  62%|██████▎   | 70/112 [00:01<00:00, 53.00it/s, Epoch: 88, Batch: 71,Loss: -3.303,Avg.Loss: -3.590,LR: 1.86E-05]Training epoch 88:  63%|██████▎   | 71/112 [00:01<00:00, 53.00it/s, Epoch: 88, Batch: 72,Loss: -3.862,Avg.Loss: -3.594,LR: 1.86E-05]Training epoch 88:  64%|██████▍   | 72/112 [00:01<00:00, 52.75it/s, Epoch: 88, Batch: 72,Loss: -3.862,Avg.Loss: -3.594,LR: 1.86E-05]Training epoch 88:  64%|██████▍   | 72/112 [00:01<00:00, 52.75it/s, Epoch: 88, Batch: 73,Loss: -3.810,Avg.Loss: -3.597,LR: 1.86E-05]Training epoch 88:  65%|██████▌   | 73/112 [00:01<00:00, 52.75it/s, Epoch: 88, Batch: 74,Loss: -3.891,Avg.Loss: -3.601,LR: 1.86E-05]Training epoch 88:  66%|██████▌   | 74/112 [00:01<00:00, 52.75it/s, Epoch: 88, Batch: 75,Loss: -3.653,Avg.Loss: -3.602,LR: 1.85E-05]Training epoch 88:  67%|██████▋   | 75/112 [00:01<00:00, 52.75it/s, Epoch: 88, Batch: 76,Loss: -3.871,Avg.Loss: -3.605,LR: 1.85E-05]Training epoch 88:  68%|██████▊   | 76/112 [00:01<00:00, 52.75it/s, Epoch: 88, Batch: 77,Loss: -3.938,Avg.Loss: -3.610,LR: 1.85E-05]Training epoch 88:  69%|██████▉   | 77/112 [00:01<00:00, 52.75it/s, Epoch: 88, Batch: 78,Loss: -4.031,Avg.Loss: -3.615,LR: 1.84E-05]Training epoch 88:  70%|██████▉   | 78/112 [00:01<00:00, 52.62it/s, Epoch: 88, Batch: 78,Loss: -4.031,Avg.Loss: -3.615,LR: 1.84E-05]Training epoch 88:  70%|██████▉   | 78/112 [00:01<00:00, 52.62it/s, Epoch: 88, Batch: 79,Loss: -3.620,Avg.Loss: -3.615,LR: 1.84E-05]Training epoch 88:  71%|███████   | 79/112 [00:01<00:00, 52.62it/s, Epoch: 88, Batch: 80,Loss: -3.562,Avg.Loss: -3.614,LR: 1.84E-05]Training epoch 88:  71%|███████▏  | 80/112 [00:01<00:00, 52.62it/s, Epoch: 88, Batch: 81,Loss: -3.703,Avg.Loss: -3.616,LR: 1.84E-05]Training epoch 88:  72%|███████▏  | 81/112 [00:01<00:00, 52.62it/s, Epoch: 88, Batch: 82,Loss: -2.846,Avg.Loss: -3.606,LR: 1.83E-05]Training epoch 88:  73%|███████▎  | 82/112 [00:01<00:00, 52.62it/s, Epoch: 88, Batch: 83,Loss: -3.315,Avg.Loss: -3.603,LR: 1.83E-05]Training epoch 88:  74%|███████▍  | 83/112 [00:01<00:00, 52.62it/s, Epoch: 88, Batch: 84,Loss: -3.360,Avg.Loss: -3.600,LR: 1.83E-05]Training epoch 88:  75%|███████▌  | 84/112 [00:01<00:00, 53.06it/s, Epoch: 88, Batch: 84,Loss: -3.360,Avg.Loss: -3.600,LR: 1.83E-05]Training epoch 88:  75%|███████▌  | 84/112 [00:01<00:00, 53.06it/s, Epoch: 88, Batch: 85,Loss: -3.225,Avg.Loss: -3.595,LR: 1.83E-05]Training epoch 88:  76%|███████▌  | 85/112 [00:01<00:00, 53.06it/s, Epoch: 88, Batch: 86,Loss: -3.612,Avg.Loss: -3.596,LR: 1.82E-05]Training epoch 88:  77%|███████▋  | 86/112 [00:01<00:00, 53.06it/s, Epoch: 88, Batch: 87,Loss: -3.331,Avg.Loss: -3.593,LR: 1.82E-05]Training epoch 88:  78%|███████▊  | 87/112 [00:01<00:00, 53.06it/s, Epoch: 88, Batch: 88,Loss: -3.792,Avg.Loss: -3.595,LR: 1.82E-05]Training epoch 88:  79%|███████▊  | 88/112 [00:01<00:00, 53.06it/s, Epoch: 88, Batch: 89,Loss: -3.885,Avg.Loss: -3.598,LR: 1.82E-05]Training epoch 88:  79%|███████▉  | 89/112 [00:01<00:00, 53.06it/s, Epoch: 88, Batch: 90,Loss: -3.396,Avg.Loss: -3.596,LR: 1.81E-05]Training epoch 88:  80%|████████  | 90/112 [00:01<00:00, 53.24it/s, Epoch: 88, Batch: 90,Loss: -3.396,Avg.Loss: -3.596,LR: 1.81E-05]Training epoch 88:  80%|████████  | 90/112 [00:01<00:00, 53.24it/s, Epoch: 88, Batch: 91,Loss: -3.658,Avg.Loss: -3.597,LR: 1.81E-05]Training epoch 88:  81%|████████▏ | 91/112 [00:01<00:00, 53.24it/s, Epoch: 88, Batch: 92,Loss: -3.908,Avg.Loss: -3.600,LR: 1.81E-05]Training epoch 88:  82%|████████▏ | 92/112 [00:01<00:00, 53.24it/s, Epoch: 88, Batch: 93,Loss: -3.429,Avg.Loss: -3.598,LR: 1.80E-05]Training epoch 88:  83%|████████▎ | 93/112 [00:01<00:00, 53.24it/s, Epoch: 88, Batch: 94,Loss: -3.489,Avg.Loss: -3.597,LR: 1.80E-05]Training epoch 88:  84%|████████▍ | 94/112 [00:01<00:00, 53.24it/s, Epoch: 88, Batch: 95,Loss: -3.672,Avg.Loss: -3.598,LR: 1.80E-05]Training epoch 88:  85%|████████▍ | 95/112 [00:01<00:00, 53.24it/s, Epoch: 88, Batch: 96,Loss: -3.530,Avg.Loss: -3.597,LR: 1.80E-05]Training epoch 88:  86%|████████▌ | 96/112 [00:01<00:00, 53.29it/s, Epoch: 88, Batch: 96,Loss: -3.530,Avg.Loss: -3.597,LR: 1.80E-05]Training epoch 88:  86%|████████▌ | 96/112 [00:01<00:00, 53.29it/s, Epoch: 88, Batch: 97,Loss: -3.385,Avg.Loss: -3.595,LR: 1.79E-05]Training epoch 88:  87%|████████▋ | 97/112 [00:01<00:00, 53.29it/s, Epoch: 88, Batch: 98,Loss: -3.396,Avg.Loss: -3.593,LR: 1.79E-05]Training epoch 88:  88%|████████▊ | 98/112 [00:01<00:00, 53.29it/s, Epoch: 88, Batch: 99,Loss: -3.489,Avg.Loss: -3.592,LR: 1.79E-05]Training epoch 88:  88%|████████▊ | 99/112 [00:01<00:00, 53.29it/s, Epoch: 88, Batch: 100,Loss: -3.324,Avg.Loss: -3.589,LR: 1.79E-05]Training epoch 88:  89%|████████▉ | 100/112 [00:01<00:00, 53.29it/s, Epoch: 88, Batch: 101,Loss: -3.773,Avg.Loss: -3.591,LR: 1.78E-05]Training epoch 88:  90%|█████████ | 101/112 [00:01<00:00, 53.29it/s, Epoch: 88, Batch: 102,Loss: -3.607,Avg.Loss: -3.591,LR: 1.78E-05]Training epoch 88:  91%|█████████ | 102/112 [00:01<00:00, 53.36it/s, Epoch: 88, Batch: 102,Loss: -3.607,Avg.Loss: -3.591,LR: 1.78E-05]Training epoch 88:  91%|█████████ | 102/112 [00:01<00:00, 53.36it/s, Epoch: 88, Batch: 103,Loss: -3.843,Avg.Loss: -3.593,LR: 1.78E-05]Training epoch 88:  92%|█████████▏| 103/112 [00:01<00:00, 53.36it/s, Epoch: 88, Batch: 104,Loss: -3.481,Avg.Loss: -3.592,LR: 1.78E-05]Training epoch 88:  93%|█████████▎| 104/112 [00:01<00:00, 53.36it/s, Epoch: 88, Batch: 105,Loss: -3.639,Avg.Loss: -3.593,LR: 1.77E-05]Training epoch 88:  94%|█████████▍| 105/112 [00:01<00:00, 53.36it/s, Epoch: 88, Batch: 106,Loss: -3.676,Avg.Loss: -3.594,LR: 1.77E-05]Training epoch 88:  95%|█████████▍| 106/112 [00:02<00:00, 53.36it/s, Epoch: 88, Batch: 107,Loss: -4.058,Avg.Loss: -3.598,LR: 1.77E-05]Training epoch 88:  96%|█████████▌| 107/112 [00:02<00:00, 53.36it/s, Epoch: 88, Batch: 108,Loss: -3.334,Avg.Loss: -3.596,LR: 1.77E-05]Training epoch 88:  96%|█████████▋| 108/112 [00:02<00:00, 53.29it/s, Epoch: 88, Batch: 108,Loss: -3.334,Avg.Loss: -3.596,LR: 1.77E-05]Training epoch 88:  96%|█████████▋| 108/112 [00:02<00:00, 53.29it/s, Epoch: 88, Batch: 109,Loss: -3.545,Avg.Loss: -3.595,LR: 1.76E-05]Training epoch 88:  97%|█████████▋| 109/112 [00:02<00:00, 53.29it/s, Epoch: 88, Batch: 110,Loss: -3.556,Avg.Loss: -3.595,LR: 1.76E-05]Training epoch 88:  98%|█████████▊| 110/112 [00:02<00:00, 53.29it/s, Epoch: 88, Batch: 111,Loss: -3.316,Avg.Loss: -3.592,LR: 1.76E-05]Training epoch 88:  99%|█████████▉| 111/112 [00:02<00:00, 53.29it/s, Epoch: 88, Batch: 112,Loss: -3.187,Avg.Loss: -3.589,LR: 1.76E-05]Training epoch 88: 100%|██████████| 112/112 [00:02<00:00, 52.97it/s, Epoch: 88, Batch: 112,Loss: -3.187,Avg.Loss: -3.589,LR: 1.76E-05]
Training epoch 89:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 89:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 89, Batch: 1,Loss: -3.463,Avg.Loss: -3.463,LR: 1.75E-05]Training epoch 89:   1%|          | 1/112 [00:00<00:03, 31.58it/s, Epoch: 89, Batch: 2,Loss: -3.712,Avg.Loss: -3.587,LR: 1.75E-05]Training epoch 89:   2%|▏         | 2/112 [00:00<00:02, 40.81it/s, Epoch: 89, Batch: 3,Loss: -3.439,Avg.Loss: -3.538,LR: 1.75E-05]Training epoch 89:   3%|▎         | 3/112 [00:00<00:02, 46.81it/s, Epoch: 89, Batch: 4,Loss: -3.860,Avg.Loss: -3.618,LR: 1.75E-05]Training epoch 89:   4%|▎         | 4/112 [00:00<00:02, 48.87it/s, Epoch: 89, Batch: 5,Loss: -3.621,Avg.Loss: -3.619,LR: 1.74E-05]Training epoch 89:   4%|▍         | 5/112 [00:00<00:02, 49.41it/s, Epoch: 89, Batch: 6,Loss: -3.659,Avg.Loss: -3.626,LR: 1.74E-05]Training epoch 89:   5%|▌         | 6/112 [00:00<00:01, 59.18it/s, Epoch: 89, Batch: 6,Loss: -3.659,Avg.Loss: -3.626,LR: 1.74E-05]Training epoch 89:   5%|▌         | 6/112 [00:00<00:01, 59.18it/s, Epoch: 89, Batch: 7,Loss: -3.442,Avg.Loss: -3.599,LR: 1.74E-05]Training epoch 89:   6%|▋         | 7/112 [00:00<00:01, 59.18it/s, Epoch: 89, Batch: 8,Loss: -3.638,Avg.Loss: -3.604,LR: 1.73E-05]Training epoch 89:   7%|▋         | 8/112 [00:00<00:01, 59.18it/s, Epoch: 89, Batch: 9,Loss: -3.900,Avg.Loss: -3.637,LR: 1.73E-05]Training epoch 89:   8%|▊         | 9/112 [00:00<00:01, 59.18it/s, Epoch: 89, Batch: 10,Loss: -3.197,Avg.Loss: -3.593,LR: 1.73E-05]Training epoch 89:   9%|▉         | 10/112 [00:00<00:01, 59.18it/s, Epoch: 89, Batch: 11,Loss: -3.540,Avg.Loss: -3.588,LR: 1.73E-05]Training epoch 89:  10%|▉         | 11/112 [00:00<00:01, 59.18it/s, Epoch: 89, Batch: 12,Loss: -3.839,Avg.Loss: -3.609,LR: 1.72E-05]Training epoch 89:  11%|█         | 12/112 [00:00<00:01, 55.27it/s, Epoch: 89, Batch: 12,Loss: -3.839,Avg.Loss: -3.609,LR: 1.72E-05]Training epoch 89:  11%|█         | 12/112 [00:00<00:01, 55.27it/s, Epoch: 89, Batch: 13,Loss: -3.798,Avg.Loss: -3.624,LR: 1.72E-05]Training epoch 89:  12%|█▏        | 13/112 [00:00<00:01, 55.27it/s, Epoch: 89, Batch: 14,Loss: -3.505,Avg.Loss: -3.615,LR: 1.72E-05]Training epoch 89:  12%|█▎        | 14/112 [00:00<00:01, 55.27it/s, Epoch: 89, Batch: 15,Loss: -3.452,Avg.Loss: -3.604,LR: 1.72E-05]Training epoch 89:  13%|█▎        | 15/112 [00:00<00:01, 55.27it/s, Epoch: 89, Batch: 16,Loss: -3.305,Avg.Loss: -3.586,LR: 1.71E-05]Training epoch 89:  14%|█▍        | 16/112 [00:00<00:01, 55.27it/s, Epoch: 89, Batch: 17,Loss: -3.419,Avg.Loss: -3.576,LR: 1.71E-05]Training epoch 89:  15%|█▌        | 17/112 [00:00<00:01, 55.27it/s, Epoch: 89, Batch: 18,Loss: -3.019,Avg.Loss: -3.545,LR: 1.71E-05]Training epoch 89:  16%|█▌        | 18/112 [00:00<00:01, 53.90it/s, Epoch: 89, Batch: 18,Loss: -3.019,Avg.Loss: -3.545,LR: 1.71E-05]Training epoch 89:  16%|█▌        | 18/112 [00:00<00:01, 53.90it/s, Epoch: 89, Batch: 19,Loss: -3.121,Avg.Loss: -3.523,LR: 1.71E-05]Training epoch 89:  17%|█▋        | 19/112 [00:00<00:01, 53.90it/s, Epoch: 89, Batch: 20,Loss: -3.937,Avg.Loss: -3.543,LR: 1.70E-05]Training epoch 89:  18%|█▊        | 20/112 [00:00<00:01, 53.90it/s, Epoch: 89, Batch: 21,Loss: -3.677,Avg.Loss: -3.550,LR: 1.70E-05]Training epoch 89:  19%|█▉        | 21/112 [00:00<00:01, 53.90it/s, Epoch: 89, Batch: 22,Loss: -3.987,Avg.Loss: -3.570,LR: 1.70E-05]Training epoch 89:  20%|█▉        | 22/112 [00:00<00:01, 53.90it/s, Epoch: 89, Batch: 23,Loss: -3.505,Avg.Loss: -3.567,LR: 1.70E-05]Training epoch 89:  21%|██        | 23/112 [00:00<00:01, 53.90it/s, Epoch: 89, Batch: 24,Loss: -3.761,Avg.Loss: -3.575,LR: 1.69E-05]Training epoch 89:  21%|██▏       | 24/112 [00:00<00:01, 52.12it/s, Epoch: 89, Batch: 24,Loss: -3.761,Avg.Loss: -3.575,LR: 1.69E-05]Training epoch 89:  21%|██▏       | 24/112 [00:00<00:01, 52.12it/s, Epoch: 89, Batch: 25,Loss: -3.605,Avg.Loss: -3.576,LR: 1.69E-05]Training epoch 89:  22%|██▏       | 25/112 [00:00<00:01, 52.12it/s, Epoch: 89, Batch: 26,Loss: -2.751,Avg.Loss: -3.544,LR: 1.69E-05]Training epoch 89:  23%|██▎       | 26/112 [00:00<00:01, 52.12it/s, Epoch: 89, Batch: 27,Loss: -3.810,Avg.Loss: -3.554,LR: 1.69E-05]Training epoch 89:  24%|██▍       | 27/112 [00:00<00:01, 52.12it/s, Epoch: 89, Batch: 28,Loss: -3.732,Avg.Loss: -3.560,LR: 1.68E-05]Training epoch 89:  25%|██▌       | 28/112 [00:00<00:01, 52.12it/s, Epoch: 89, Batch: 29,Loss: -3.755,Avg.Loss: -3.567,LR: 1.68E-05]Training epoch 89:  26%|██▌       | 29/112 [00:00<00:01, 52.12it/s, Epoch: 89, Batch: 30,Loss: -3.751,Avg.Loss: -3.573,LR: 1.68E-05]Training epoch 89:  27%|██▋       | 30/112 [00:00<00:01, 51.88it/s, Epoch: 89, Batch: 30,Loss: -3.751,Avg.Loss: -3.573,LR: 1.68E-05]Training epoch 89:  27%|██▋       | 30/112 [00:00<00:01, 51.88it/s, Epoch: 89, Batch: 31,Loss: -3.835,Avg.Loss: -3.582,LR: 1.68E-05]Training epoch 89:  28%|██▊       | 31/112 [00:00<00:01, 51.88it/s, Epoch: 89, Batch: 32,Loss: -3.498,Avg.Loss: -3.579,LR: 1.67E-05]Training epoch 89:  29%|██▊       | 32/112 [00:00<00:01, 51.88it/s, Epoch: 89, Batch: 33,Loss: -3.165,Avg.Loss: -3.567,LR: 1.67E-05]Training epoch 89:  29%|██▉       | 33/112 [00:00<00:01, 51.88it/s, Epoch: 89, Batch: 34,Loss: -3.511,Avg.Loss: -3.565,LR: 1.67E-05]Training epoch 89:  30%|███       | 34/112 [00:00<00:01, 51.88it/s, Epoch: 89, Batch: 35,Loss: -3.554,Avg.Loss: -3.565,LR: 1.67E-05]Training epoch 89:  31%|███▏      | 35/112 [00:00<00:01, 51.88it/s, Epoch: 89, Batch: 36,Loss: -3.851,Avg.Loss: -3.573,LR: 1.66E-05]Training epoch 89:  32%|███▏      | 36/112 [00:00<00:01, 52.27it/s, Epoch: 89, Batch: 36,Loss: -3.851,Avg.Loss: -3.573,LR: 1.66E-05]Training epoch 89:  32%|███▏      | 36/112 [00:00<00:01, 52.27it/s, Epoch: 89, Batch: 37,Loss: -3.945,Avg.Loss: -3.583,LR: 1.66E-05]Training epoch 89:  33%|███▎      | 37/112 [00:00<00:01, 52.27it/s, Epoch: 89, Batch: 38,Loss: -4.040,Avg.Loss: -3.595,LR: 1.66E-05]Training epoch 89:  34%|███▍      | 38/112 [00:00<00:01, 52.27it/s, Epoch: 89, Batch: 39,Loss: -3.832,Avg.Loss: -3.601,LR: 1.66E-05]Training epoch 89:  35%|███▍      | 39/112 [00:00<00:01, 52.27it/s, Epoch: 89, Batch: 40,Loss: -3.869,Avg.Loss: -3.608,LR: 1.65E-05]Training epoch 89:  36%|███▌      | 40/112 [00:00<00:01, 52.27it/s, Epoch: 89, Batch: 41,Loss: -3.856,Avg.Loss: -3.614,LR: 1.65E-05]Training epoch 89:  37%|███▋      | 41/112 [00:00<00:01, 52.27it/s, Epoch: 89, Batch: 42,Loss: -3.664,Avg.Loss: -3.615,LR: 1.65E-05]Training epoch 89:  38%|███▊      | 42/112 [00:00<00:01, 52.69it/s, Epoch: 89, Batch: 42,Loss: -3.664,Avg.Loss: -3.615,LR: 1.65E-05]Training epoch 89:  38%|███▊      | 42/112 [00:00<00:01, 52.69it/s, Epoch: 89, Batch: 43,Loss: -3.832,Avg.Loss: -3.620,LR: 1.65E-05]Training epoch 89:  38%|███▊      | 43/112 [00:00<00:01, 52.69it/s, Epoch: 89, Batch: 44,Loss: -3.593,Avg.Loss: -3.619,LR: 1.64E-05]Training epoch 89:  39%|███▉      | 44/112 [00:00<00:01, 52.69it/s, Epoch: 89, Batch: 45,Loss: -3.906,Avg.Loss: -3.626,LR: 1.64E-05]Training epoch 89:  40%|████      | 45/112 [00:00<00:01, 52.69it/s, Epoch: 89, Batch: 46,Loss: -3.807,Avg.Loss: -3.630,LR: 1.64E-05]Training epoch 89:  41%|████      | 46/112 [00:00<00:01, 52.69it/s, Epoch: 89, Batch: 47,Loss: -3.270,Avg.Loss: -3.622,LR: 1.64E-05]Training epoch 89:  42%|████▏     | 47/112 [00:00<00:01, 52.69it/s, Epoch: 89, Batch: 48,Loss: -3.750,Avg.Loss: -3.625,LR: 1.63E-05]Training epoch 89:  43%|████▎     | 48/112 [00:00<00:01, 52.80it/s, Epoch: 89, Batch: 48,Loss: -3.750,Avg.Loss: -3.625,LR: 1.63E-05]Training epoch 89:  43%|████▎     | 48/112 [00:00<00:01, 52.80it/s, Epoch: 89, Batch: 49,Loss: -3.701,Avg.Loss: -3.626,LR: 1.63E-05]Training epoch 89:  44%|████▍     | 49/112 [00:00<00:01, 52.80it/s, Epoch: 89, Batch: 50,Loss: -3.872,Avg.Loss: -3.631,LR: 1.63E-05]Training epoch 89:  45%|████▍     | 50/112 [00:00<00:01, 52.80it/s, Epoch: 89, Batch: 51,Loss: -3.801,Avg.Loss: -3.634,LR: 1.63E-05]Training epoch 89:  46%|████▌     | 51/112 [00:00<00:01, 52.80it/s, Epoch: 89, Batch: 52,Loss: -3.383,Avg.Loss: -3.630,LR: 1.62E-05]Training epoch 89:  46%|████▋     | 52/112 [00:00<00:01, 52.80it/s, Epoch: 89, Batch: 53,Loss: -2.851,Avg.Loss: -3.615,LR: 1.62E-05]Training epoch 89:  47%|████▋     | 53/112 [00:01<00:01, 52.80it/s, Epoch: 89, Batch: 54,Loss: -3.303,Avg.Loss: -3.609,LR: 1.62E-05]Training epoch 89:  48%|████▊     | 54/112 [00:01<00:01, 52.92it/s, Epoch: 89, Batch: 54,Loss: -3.303,Avg.Loss: -3.609,LR: 1.62E-05]Training epoch 89:  48%|████▊     | 54/112 [00:01<00:01, 52.92it/s, Epoch: 89, Batch: 55,Loss: -2.692,Avg.Loss: -3.592,LR: 1.62E-05]Training epoch 89:  49%|████▉     | 55/112 [00:01<00:01, 52.92it/s, Epoch: 89, Batch: 56,Loss: -3.637,Avg.Loss: -3.593,LR: 1.61E-05]Training epoch 89:  50%|█████     | 56/112 [00:01<00:01, 52.92it/s, Epoch: 89, Batch: 57,Loss: -3.570,Avg.Loss: -3.593,LR: 1.61E-05]Training epoch 89:  51%|█████     | 57/112 [00:01<00:01, 52.92it/s, Epoch: 89, Batch: 58,Loss: -3.565,Avg.Loss: -3.592,LR: 1.61E-05]Training epoch 89:  52%|█████▏    | 58/112 [00:01<00:01, 52.92it/s, Epoch: 89, Batch: 59,Loss: -3.163,Avg.Loss: -3.585,LR: 1.61E-05]Training epoch 89:  53%|█████▎    | 59/112 [00:01<00:01, 52.92it/s, Epoch: 89, Batch: 60,Loss: -3.317,Avg.Loss: -3.581,LR: 1.60E-05]Training epoch 89:  54%|█████▎    | 60/112 [00:01<00:00, 53.06it/s, Epoch: 89, Batch: 60,Loss: -3.317,Avg.Loss: -3.581,LR: 1.60E-05]Training epoch 89:  54%|█████▎    | 60/112 [00:01<00:00, 53.06it/s, Epoch: 89, Batch: 61,Loss: -3.605,Avg.Loss: -3.581,LR: 1.60E-05]Training epoch 89:  54%|█████▍    | 61/112 [00:01<00:00, 53.06it/s, Epoch: 89, Batch: 62,Loss: -3.676,Avg.Loss: -3.582,LR: 1.60E-05]Training epoch 89:  55%|█████▌    | 62/112 [00:01<00:00, 53.06it/s, Epoch: 89, Batch: 63,Loss: -3.933,Avg.Loss: -3.588,LR: 1.60E-05]Training epoch 89:  56%|█████▋    | 63/112 [00:01<00:00, 53.06it/s, Epoch: 89, Batch: 64,Loss: -3.988,Avg.Loss: -3.594,LR: 1.59E-05]Training epoch 89:  57%|█████▋    | 64/112 [00:01<00:00, 53.06it/s, Epoch: 89, Batch: 65,Loss: -3.338,Avg.Loss: -3.590,LR: 1.59E-05]Training epoch 89:  58%|█████▊    | 65/112 [00:01<00:00, 53.06it/s, Epoch: 89, Batch: 66,Loss: -3.539,Avg.Loss: -3.590,LR: 1.59E-05]Training epoch 89:  59%|█████▉    | 66/112 [00:01<00:00, 53.13it/s, Epoch: 89, Batch: 66,Loss: -3.539,Avg.Loss: -3.590,LR: 1.59E-05]Training epoch 89:  59%|█████▉    | 66/112 [00:01<00:00, 53.13it/s, Epoch: 89, Batch: 67,Loss: -3.401,Avg.Loss: -3.587,LR: 1.59E-05]Training epoch 89:  60%|█████▉    | 67/112 [00:01<00:00, 53.13it/s, Epoch: 89, Batch: 68,Loss: -3.853,Avg.Loss: -3.591,LR: 1.58E-05]Training epoch 89:  61%|██████    | 68/112 [00:01<00:00, 53.13it/s, Epoch: 89, Batch: 69,Loss: -3.603,Avg.Loss: -3.591,LR: 1.58E-05]Training epoch 89:  62%|██████▏   | 69/112 [00:01<00:00, 53.13it/s, Epoch: 89, Batch: 70,Loss: -3.461,Avg.Loss: -3.589,LR: 1.58E-05]Training epoch 89:  62%|██████▎   | 70/112 [00:01<00:00, 53.13it/s, Epoch: 89, Batch: 71,Loss: -3.704,Avg.Loss: -3.591,LR: 1.58E-05]Training epoch 89:  63%|██████▎   | 71/112 [00:01<00:00, 53.13it/s, Epoch: 89, Batch: 72,Loss: -3.811,Avg.Loss: -3.594,LR: 1.57E-05]Training epoch 89:  64%|██████▍   | 72/112 [00:01<00:00, 53.26it/s, Epoch: 89, Batch: 72,Loss: -3.811,Avg.Loss: -3.594,LR: 1.57E-05]Training epoch 89:  64%|██████▍   | 72/112 [00:01<00:00, 53.26it/s, Epoch: 89, Batch: 73,Loss: -3.527,Avg.Loss: -3.593,LR: 1.57E-05]Training epoch 89:  65%|██████▌   | 73/112 [00:01<00:00, 53.26it/s, Epoch: 89, Batch: 74,Loss: -3.801,Avg.Loss: -3.596,LR: 1.57E-05]Training epoch 89:  66%|██████▌   | 74/112 [00:01<00:00, 53.26it/s, Epoch: 89, Batch: 75,Loss: -3.597,Avg.Loss: -3.596,LR: 1.57E-05]Training epoch 89:  67%|██████▋   | 75/112 [00:01<00:00, 53.26it/s, Epoch: 89, Batch: 76,Loss: -4.017,Avg.Loss: -3.601,LR: 1.56E-05]Training epoch 89:  68%|██████▊   | 76/112 [00:01<00:00, 53.26it/s, Epoch: 89, Batch: 77,Loss: -3.824,Avg.Loss: -3.604,LR: 1.56E-05]Training epoch 89:  69%|██████▉   | 77/112 [00:01<00:00, 53.26it/s, Epoch: 89, Batch: 78,Loss: -3.716,Avg.Loss: -3.605,LR: 1.56E-05]Training epoch 89:  70%|██████▉   | 78/112 [00:01<00:00, 53.35it/s, Epoch: 89, Batch: 78,Loss: -3.716,Avg.Loss: -3.605,LR: 1.56E-05]Training epoch 89:  70%|██████▉   | 78/112 [00:01<00:00, 53.35it/s, Epoch: 89, Batch: 79,Loss: -3.916,Avg.Loss: -3.609,LR: 1.56E-05]Training epoch 89:  71%|███████   | 79/112 [00:01<00:00, 53.35it/s, Epoch: 89, Batch: 80,Loss: -3.697,Avg.Loss: -3.610,LR: 1.55E-05]Training epoch 89:  71%|███████▏  | 80/112 [00:01<00:00, 53.35it/s, Epoch: 89, Batch: 81,Loss: -3.671,Avg.Loss: -3.611,LR: 1.55E-05]Training epoch 89:  72%|███████▏  | 81/112 [00:01<00:00, 53.35it/s, Epoch: 89, Batch: 82,Loss: -3.448,Avg.Loss: -3.609,LR: 1.55E-05]Training epoch 89:  73%|███████▎  | 82/112 [00:01<00:00, 53.35it/s, Epoch: 89, Batch: 83,Loss: -3.797,Avg.Loss: -3.612,LR: 1.55E-05]Training epoch 89:  74%|███████▍  | 83/112 [00:01<00:00, 53.35it/s, Epoch: 89, Batch: 84,Loss: -3.879,Avg.Loss: -3.615,LR: 1.55E-05]Training epoch 89:  75%|███████▌  | 84/112 [00:01<00:00, 53.25it/s, Epoch: 89, Batch: 84,Loss: -3.879,Avg.Loss: -3.615,LR: 1.55E-05]Training epoch 89:  75%|███████▌  | 84/112 [00:01<00:00, 53.25it/s, Epoch: 89, Batch: 85,Loss: -3.411,Avg.Loss: -3.612,LR: 1.54E-05]Training epoch 89:  76%|███████▌  | 85/112 [00:01<00:00, 53.25it/s, Epoch: 89, Batch: 86,Loss: -3.703,Avg.Loss: -3.613,LR: 1.54E-05]Training epoch 89:  77%|███████▋  | 86/112 [00:01<00:00, 53.25it/s, Epoch: 89, Batch: 87,Loss: -3.634,Avg.Loss: -3.614,LR: 1.54E-05]Training epoch 89:  78%|███████▊  | 87/112 [00:01<00:00, 53.25it/s, Epoch: 89, Batch: 88,Loss: -3.429,Avg.Loss: -3.611,LR: 1.54E-05]Training epoch 89:  79%|███████▊  | 88/112 [00:01<00:00, 53.25it/s, Epoch: 89, Batch: 89,Loss: -3.260,Avg.Loss: -3.608,LR: 1.53E-05]Training epoch 89:  79%|███████▉  | 89/112 [00:01<00:00, 53.25it/s, Epoch: 89, Batch: 90,Loss: -3.077,Avg.Loss: -3.602,LR: 1.53E-05]Training epoch 89:  80%|████████  | 90/112 [00:01<00:00, 53.45it/s, Epoch: 89, Batch: 90,Loss: -3.077,Avg.Loss: -3.602,LR: 1.53E-05]Training epoch 89:  80%|████████  | 90/112 [00:01<00:00, 53.45it/s, Epoch: 89, Batch: 91,Loss: -3.657,Avg.Loss: -3.602,LR: 1.53E-05]Training epoch 89:  81%|████████▏ | 91/112 [00:01<00:00, 53.45it/s, Epoch: 89, Batch: 92,Loss: -3.536,Avg.Loss: -3.602,LR: 1.53E-05]Training epoch 89:  82%|████████▏ | 92/112 [00:01<00:00, 53.45it/s, Epoch: 89, Batch: 93,Loss: -3.868,Avg.Loss: -3.604,LR: 1.52E-05]Training epoch 89:  83%|████████▎ | 93/112 [00:01<00:00, 53.45it/s, Epoch: 89, Batch: 94,Loss: -3.361,Avg.Loss: -3.602,LR: 1.52E-05]Training epoch 89:  84%|████████▍ | 94/112 [00:01<00:00, 53.45it/s, Epoch: 89, Batch: 95,Loss: -3.968,Avg.Loss: -3.606,LR: 1.52E-05]Training epoch 89:  85%|████████▍ | 95/112 [00:01<00:00, 53.45it/s, Epoch: 89, Batch: 96,Loss: -3.714,Avg.Loss: -3.607,LR: 1.52E-05]Training epoch 89:  86%|████████▌ | 96/112 [00:01<00:00, 53.40it/s, Epoch: 89, Batch: 96,Loss: -3.714,Avg.Loss: -3.607,LR: 1.52E-05]Training epoch 89:  86%|████████▌ | 96/112 [00:01<00:00, 53.40it/s, Epoch: 89, Batch: 97,Loss: -3.809,Avg.Loss: -3.609,LR: 1.51E-05]Training epoch 89:  87%|████████▋ | 97/112 [00:01<00:00, 53.40it/s, Epoch: 89, Batch: 98,Loss: -3.598,Avg.Loss: -3.609,LR: 1.51E-05]Training epoch 89:  88%|████████▊ | 98/112 [00:01<00:00, 53.40it/s, Epoch: 89, Batch: 99,Loss: -2.716,Avg.Loss: -3.600,LR: 1.51E-05]Training epoch 89:  88%|████████▊ | 99/112 [00:01<00:00, 53.40it/s, Epoch: 89, Batch: 100,Loss: -3.510,Avg.Loss: -3.599,LR: 1.51E-05]Training epoch 89:  89%|████████▉ | 100/112 [00:01<00:00, 53.40it/s, Epoch: 89, Batch: 101,Loss: -3.616,Avg.Loss: -3.599,LR: 1.50E-05]Training epoch 89:  90%|█████████ | 101/112 [00:01<00:00, 53.40it/s, Epoch: 89, Batch: 102,Loss: -3.537,Avg.Loss: -3.598,LR: 1.50E-05]Training epoch 89:  91%|█████████ | 102/112 [00:01<00:00, 53.38it/s, Epoch: 89, Batch: 102,Loss: -3.537,Avg.Loss: -3.598,LR: 1.50E-05]Training epoch 89:  91%|█████████ | 102/112 [00:01<00:00, 53.38it/s, Epoch: 89, Batch: 103,Loss: -3.915,Avg.Loss: -3.601,LR: 1.50E-05]Training epoch 89:  92%|█████████▏| 103/112 [00:01<00:00, 53.38it/s, Epoch: 89, Batch: 104,Loss: -3.945,Avg.Loss: -3.605,LR: 1.50E-05]Training epoch 89:  93%|█████████▎| 104/112 [00:01<00:00, 53.38it/s, Epoch: 89, Batch: 105,Loss: -3.935,Avg.Loss: -3.608,LR: 1.49E-05]Training epoch 89:  94%|█████████▍| 105/112 [00:01<00:00, 53.38it/s, Epoch: 89, Batch: 106,Loss: -3.737,Avg.Loss: -3.609,LR: 1.49E-05]Training epoch 89:  95%|█████████▍| 106/112 [00:02<00:00, 53.38it/s, Epoch: 89, Batch: 107,Loss: -3.518,Avg.Loss: -3.608,LR: 1.49E-05]Training epoch 89:  96%|█████████▌| 107/112 [00:02<00:00, 53.38it/s, Epoch: 89, Batch: 108,Loss: -3.844,Avg.Loss: -3.610,LR: 1.49E-05]Training epoch 89:  96%|█████████▋| 108/112 [00:02<00:00, 53.50it/s, Epoch: 89, Batch: 108,Loss: -3.844,Avg.Loss: -3.610,LR: 1.49E-05]Training epoch 89:  96%|█████████▋| 108/112 [00:02<00:00, 53.50it/s, Epoch: 89, Batch: 109,Loss: -3.809,Avg.Loss: -3.612,LR: 1.49E-05]Training epoch 89:  97%|█████████▋| 109/112 [00:02<00:00, 53.50it/s, Epoch: 89, Batch: 110,Loss: -3.920,Avg.Loss: -3.615,LR: 1.48E-05]Training epoch 89:  98%|█████████▊| 110/112 [00:02<00:00, 53.50it/s, Epoch: 89, Batch: 111,Loss: -4.033,Avg.Loss: -3.619,LR: 1.48E-05]Training epoch 89:  99%|█████████▉| 111/112 [00:02<00:00, 53.50it/s, Epoch: 89, Batch: 112,Loss: -4.001,Avg.Loss: -3.622,LR: 1.48E-05]Training epoch 89: 100%|██████████| 112/112 [00:02<00:00, 53.17it/s, Epoch: 89, Batch: 112,Loss: -4.001,Avg.Loss: -3.622,LR: 1.48E-05]
Training epoch 90:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 90:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 90, Batch: 1,Loss: -3.954,Avg.Loss: -3.954,LR: 1.48E-05]Training epoch 90:   1%|          | 1/112 [00:00<00:04, 25.35it/s, Epoch: 90, Batch: 2,Loss: -3.417,Avg.Loss: -3.686,LR: 1.47E-05]Training epoch 90:   2%|▏         | 2/112 [00:00<00:02, 38.21it/s, Epoch: 90, Batch: 3,Loss: -3.192,Avg.Loss: -3.521,LR: 1.47E-05]Training epoch 90:   3%|▎         | 3/112 [00:00<00:02, 42.97it/s, Epoch: 90, Batch: 4,Loss: -4.017,Avg.Loss: -3.645,LR: 1.47E-05]Training epoch 90:   4%|▎         | 4/112 [00:00<00:02, 46.04it/s, Epoch: 90, Batch: 5,Loss: -3.407,Avg.Loss: -3.598,LR: 1.47E-05]Training epoch 90:   4%|▍         | 5/112 [00:00<00:02, 47.25it/s, Epoch: 90, Batch: 6,Loss: -3.513,Avg.Loss: -3.584,LR: 1.46E-05]Training epoch 90:   5%|▌         | 6/112 [00:00<00:01, 56.60it/s, Epoch: 90, Batch: 6,Loss: -3.513,Avg.Loss: -3.584,LR: 1.46E-05]Training epoch 90:   5%|▌         | 6/112 [00:00<00:01, 56.60it/s, Epoch: 90, Batch: 7,Loss: -3.479,Avg.Loss: -3.569,LR: 1.46E-05]Training epoch 90:   6%|▋         | 7/112 [00:00<00:01, 56.60it/s, Epoch: 90, Batch: 8,Loss: -3.629,Avg.Loss: -3.576,LR: 1.46E-05]Training epoch 90:   7%|▋         | 8/112 [00:00<00:01, 56.60it/s, Epoch: 90, Batch: 9,Loss: -3.428,Avg.Loss: -3.560,LR: 1.46E-05]Training epoch 90:   8%|▊         | 9/112 [00:00<00:01, 56.60it/s, Epoch: 90, Batch: 10,Loss: -3.705,Avg.Loss: -3.574,LR: 1.45E-05]Training epoch 90:   9%|▉         | 10/112 [00:00<00:01, 56.60it/s, Epoch: 90, Batch: 11,Loss: -3.869,Avg.Loss: -3.601,LR: 1.45E-05]Training epoch 90:  10%|▉         | 11/112 [00:00<00:01, 56.60it/s, Epoch: 90, Batch: 12,Loss: -3.827,Avg.Loss: -3.620,LR: 1.45E-05]Training epoch 90:  11%|█         | 12/112 [00:00<00:01, 54.50it/s, Epoch: 90, Batch: 12,Loss: -3.827,Avg.Loss: -3.620,LR: 1.45E-05]Training epoch 90:  11%|█         | 12/112 [00:00<00:01, 54.50it/s, Epoch: 90, Batch: 13,Loss: -4.140,Avg.Loss: -3.660,LR: 1.45E-05]Training epoch 90:  12%|█▏        | 13/112 [00:00<00:01, 54.50it/s, Epoch: 90, Batch: 14,Loss: -3.482,Avg.Loss: -3.647,LR: 1.44E-05]Training epoch 90:  12%|█▎        | 14/112 [00:00<00:01, 54.50it/s, Epoch: 90, Batch: 15,Loss: -3.642,Avg.Loss: -3.647,LR: 1.44E-05]Training epoch 90:  13%|█▎        | 15/112 [00:00<00:01, 54.50it/s, Epoch: 90, Batch: 16,Loss: -3.364,Avg.Loss: -3.629,LR: 1.44E-05]Training epoch 90:  14%|█▍        | 16/112 [00:00<00:01, 54.50it/s, Epoch: 90, Batch: 17,Loss: -3.479,Avg.Loss: -3.620,LR: 1.44E-05]Training epoch 90:  15%|█▌        | 17/112 [00:00<00:01, 54.50it/s, Epoch: 90, Batch: 18,Loss: -3.552,Avg.Loss: -3.617,LR: 1.44E-05]Training epoch 90:  16%|█▌        | 18/112 [00:00<00:01, 54.08it/s, Epoch: 90, Batch: 18,Loss: -3.552,Avg.Loss: -3.617,LR: 1.44E-05]Training epoch 90:  16%|█▌        | 18/112 [00:00<00:01, 54.08it/s, Epoch: 90, Batch: 19,Loss: -3.932,Avg.Loss: -3.633,LR: 1.43E-05]Training epoch 90:  17%|█▋        | 19/112 [00:00<00:01, 54.08it/s, Epoch: 90, Batch: 20,Loss: -3.477,Avg.Loss: -3.625,LR: 1.43E-05]Training epoch 90:  18%|█▊        | 20/112 [00:00<00:01, 54.08it/s, Epoch: 90, Batch: 21,Loss: -3.405,Avg.Loss: -3.615,LR: 1.43E-05]Training epoch 90:  19%|█▉        | 21/112 [00:00<00:01, 54.08it/s, Epoch: 90, Batch: 22,Loss: -3.484,Avg.Loss: -3.609,LR: 1.43E-05]Training epoch 90:  20%|█▉        | 22/112 [00:00<00:01, 54.08it/s, Epoch: 90, Batch: 23,Loss: -3.607,Avg.Loss: -3.609,LR: 1.42E-05]Training epoch 90:  21%|██        | 23/112 [00:00<00:01, 54.08it/s, Epoch: 90, Batch: 24,Loss: -3.722,Avg.Loss: -3.614,LR: 1.42E-05]Training epoch 90:  21%|██▏       | 24/112 [00:00<00:01, 53.65it/s, Epoch: 90, Batch: 24,Loss: -3.722,Avg.Loss: -3.614,LR: 1.42E-05]Training epoch 90:  21%|██▏       | 24/112 [00:00<00:01, 53.65it/s, Epoch: 90, Batch: 25,Loss: -3.675,Avg.Loss: -3.616,LR: 1.42E-05]Training epoch 90:  22%|██▏       | 25/112 [00:00<00:01, 53.65it/s, Epoch: 90, Batch: 26,Loss: -3.340,Avg.Loss: -3.605,LR: 1.42E-05]Training epoch 90:  23%|██▎       | 26/112 [00:00<00:01, 53.65it/s, Epoch: 90, Batch: 27,Loss: -3.216,Avg.Loss: -3.591,LR: 1.41E-05]Training epoch 90:  24%|██▍       | 27/112 [00:00<00:01, 53.65it/s, Epoch: 90, Batch: 28,Loss: -3.514,Avg.Loss: -3.588,LR: 1.41E-05]Training epoch 90:  25%|██▌       | 28/112 [00:00<00:01, 53.65it/s, Epoch: 90, Batch: 29,Loss: -3.283,Avg.Loss: -3.578,LR: 1.41E-05]Training epoch 90:  26%|██▌       | 29/112 [00:00<00:01, 53.65it/s, Epoch: 90, Batch: 30,Loss: -3.325,Avg.Loss: -3.569,LR: 1.41E-05]Training epoch 90:  27%|██▋       | 30/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 30,Loss: -3.325,Avg.Loss: -3.569,LR: 1.41E-05]Training epoch 90:  27%|██▋       | 30/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 31,Loss: -3.852,Avg.Loss: -3.578,LR: 1.41E-05]Training epoch 90:  28%|██▊       | 31/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 32,Loss: -3.880,Avg.Loss: -3.588,LR: 1.40E-05]Training epoch 90:  29%|██▊       | 32/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 33,Loss: -3.953,Avg.Loss: -3.599,LR: 1.40E-05]Training epoch 90:  29%|██▉       | 33/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 34,Loss: -3.480,Avg.Loss: -3.595,LR: 1.40E-05]Training epoch 90:  30%|███       | 34/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 35,Loss: -3.767,Avg.Loss: -3.600,LR: 1.40E-05]Training epoch 90:  31%|███▏      | 35/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 36,Loss: -3.983,Avg.Loss: -3.611,LR: 1.39E-05]Training epoch 90:  32%|███▏      | 36/112 [00:00<00:01, 53.15it/s, Epoch: 90, Batch: 36,Loss: -3.983,Avg.Loss: -3.611,LR: 1.39E-05]Training epoch 90:  32%|███▏      | 36/112 [00:00<00:01, 53.15it/s, Epoch: 90, Batch: 37,Loss: -4.057,Avg.Loss: -3.623,LR: 1.39E-05]Training epoch 90:  33%|███▎      | 37/112 [00:00<00:01, 53.15it/s, Epoch: 90, Batch: 38,Loss: -3.648,Avg.Loss: -3.624,LR: 1.39E-05]Training epoch 90:  34%|███▍      | 38/112 [00:00<00:01, 53.15it/s, Epoch: 90, Batch: 39,Loss: -3.031,Avg.Loss: -3.608,LR: 1.39E-05]Training epoch 90:  35%|███▍      | 39/112 [00:00<00:01, 53.15it/s, Epoch: 90, Batch: 40,Loss: -3.509,Avg.Loss: -3.606,LR: 1.38E-05]Training epoch 90:  36%|███▌      | 40/112 [00:00<00:01, 53.15it/s, Epoch: 90, Batch: 41,Loss: -3.685,Avg.Loss: -3.608,LR: 1.38E-05]Training epoch 90:  37%|███▋      | 41/112 [00:00<00:01, 53.15it/s, Epoch: 90, Batch: 42,Loss: -3.815,Avg.Loss: -3.613,LR: 1.38E-05]Training epoch 90:  38%|███▊      | 42/112 [00:00<00:01, 53.14it/s, Epoch: 90, Batch: 42,Loss: -3.815,Avg.Loss: -3.613,LR: 1.38E-05]Training epoch 90:  38%|███▊      | 42/112 [00:00<00:01, 53.14it/s, Epoch: 90, Batch: 43,Loss: -3.666,Avg.Loss: -3.614,LR: 1.38E-05]Training epoch 90:  38%|███▊      | 43/112 [00:00<00:01, 53.14it/s, Epoch: 90, Batch: 44,Loss: -3.704,Avg.Loss: -3.616,LR: 1.38E-05]Training epoch 90:  39%|███▉      | 44/112 [00:00<00:01, 53.14it/s, Epoch: 90, Batch: 45,Loss: -3.483,Avg.Loss: -3.613,LR: 1.37E-05]Training epoch 90:  40%|████      | 45/112 [00:00<00:01, 53.14it/s, Epoch: 90, Batch: 46,Loss: -3.301,Avg.Loss: -3.606,LR: 1.37E-05]Training epoch 90:  41%|████      | 46/112 [00:00<00:01, 53.14it/s, Epoch: 90, Batch: 47,Loss: -3.350,Avg.Loss: -3.601,LR: 1.37E-05]Training epoch 90:  42%|████▏     | 47/112 [00:00<00:01, 53.14it/s, Epoch: 90, Batch: 48,Loss: -3.213,Avg.Loss: -3.593,LR: 1.37E-05]Training epoch 90:  43%|████▎     | 48/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 48,Loss: -3.213,Avg.Loss: -3.593,LR: 1.37E-05]Training epoch 90:  43%|████▎     | 48/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 49,Loss: -3.574,Avg.Loss: -3.592,LR: 1.36E-05]Training epoch 90:  44%|████▍     | 49/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 50,Loss: -3.627,Avg.Loss: -3.593,LR: 1.36E-05]Training epoch 90:  45%|████▍     | 50/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 51,Loss: -3.574,Avg.Loss: -3.593,LR: 1.36E-05]Training epoch 90:  46%|████▌     | 51/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 52,Loss: -2.831,Avg.Loss: -3.578,LR: 1.36E-05]Training epoch 90:  46%|████▋     | 52/112 [00:00<00:01, 53.18it/s, Epoch: 90, Batch: 53,Loss: -3.354,Avg.Loss: -3.574,LR: 1.35E-05]Training epoch 90:  47%|████▋     | 53/112 [00:01<00:01, 53.18it/s, Epoch: 90, Batch: 54,Loss: -3.974,Avg.Loss: -3.581,LR: 1.35E-05]Training epoch 90:  48%|████▊     | 54/112 [00:01<00:01, 52.57it/s, Epoch: 90, Batch: 54,Loss: -3.974,Avg.Loss: -3.581,LR: 1.35E-05]Training epoch 90:  48%|████▊     | 54/112 [00:01<00:01, 52.57it/s, Epoch: 90, Batch: 55,Loss: -3.800,Avg.Loss: -3.585,LR: 1.35E-05]Training epoch 90:  49%|████▉     | 55/112 [00:01<00:01, 52.57it/s, Epoch: 90, Batch: 56,Loss: -3.716,Avg.Loss: -3.588,LR: 1.35E-05]Training epoch 90:  50%|█████     | 56/112 [00:01<00:01, 52.57it/s, Epoch: 90, Batch: 57,Loss: -3.606,Avg.Loss: -3.588,LR: 1.35E-05]Training epoch 90:  51%|█████     | 57/112 [00:01<00:01, 52.57it/s, Epoch: 90, Batch: 58,Loss: -3.727,Avg.Loss: -3.590,LR: 1.34E-05]Training epoch 90:  52%|█████▏    | 58/112 [00:01<00:01, 52.57it/s, Epoch: 90, Batch: 59,Loss: -3.840,Avg.Loss: -3.595,LR: 1.34E-05]Training epoch 90:  53%|█████▎    | 59/112 [00:01<00:01, 52.57it/s, Epoch: 90, Batch: 60,Loss: -3.898,Avg.Loss: -3.600,LR: 1.34E-05]Training epoch 90:  54%|█████▎    | 60/112 [00:01<00:00, 52.89it/s, Epoch: 90, Batch: 60,Loss: -3.898,Avg.Loss: -3.600,LR: 1.34E-05]Training epoch 90:  54%|█████▎    | 60/112 [00:01<00:00, 52.89it/s, Epoch: 90, Batch: 61,Loss: -3.804,Avg.Loss: -3.603,LR: 1.34E-05]Training epoch 90:  54%|█████▍    | 61/112 [00:01<00:00, 52.89it/s, Epoch: 90, Batch: 62,Loss: -3.782,Avg.Loss: -3.606,LR: 1.33E-05]Training epoch 90:  55%|█████▌    | 62/112 [00:01<00:00, 52.89it/s, Epoch: 90, Batch: 63,Loss: -3.638,Avg.Loss: -3.606,LR: 1.33E-05]Training epoch 90:  56%|█████▋    | 63/112 [00:01<00:00, 52.89it/s, Epoch: 90, Batch: 64,Loss: -3.702,Avg.Loss: -3.608,LR: 1.33E-05]Training epoch 90:  57%|█████▋    | 64/112 [00:01<00:00, 52.89it/s, Epoch: 90, Batch: 65,Loss: -3.587,Avg.Loss: -3.608,LR: 1.33E-05]Training epoch 90:  58%|█████▊    | 65/112 [00:01<00:00, 52.89it/s, Epoch: 90, Batch: 66,Loss: -3.548,Avg.Loss: -3.607,LR: 1.33E-05]Training epoch 90:  59%|█████▉    | 66/112 [00:01<00:00, 53.09it/s, Epoch: 90, Batch: 66,Loss: -3.548,Avg.Loss: -3.607,LR: 1.33E-05]Training epoch 90:  59%|█████▉    | 66/112 [00:01<00:00, 53.09it/s, Epoch: 90, Batch: 67,Loss: -3.967,Avg.Loss: -3.612,LR: 1.32E-05]Training epoch 90:  60%|█████▉    | 67/112 [00:01<00:00, 53.09it/s, Epoch: 90, Batch: 68,Loss: -2.785,Avg.Loss: -3.600,LR: 1.32E-05]Training epoch 90:  61%|██████    | 68/112 [00:01<00:00, 53.09it/s, Epoch: 90, Batch: 69,Loss: -3.549,Avg.Loss: -3.599,LR: 1.32E-05]Training epoch 90:  62%|██████▏   | 69/112 [00:01<00:00, 53.09it/s, Epoch: 90, Batch: 70,Loss: -3.595,Avg.Loss: -3.599,LR: 1.32E-05]Training epoch 90:  62%|██████▎   | 70/112 [00:01<00:00, 53.09it/s, Epoch: 90, Batch: 71,Loss: -4.053,Avg.Loss: -3.605,LR: 1.31E-05]Training epoch 90:  63%|██████▎   | 71/112 [00:01<00:00, 53.09it/s, Epoch: 90, Batch: 72,Loss: -3.409,Avg.Loss: -3.603,LR: 1.31E-05]Training epoch 90:  64%|██████▍   | 72/112 [00:01<00:00, 53.24it/s, Epoch: 90, Batch: 72,Loss: -3.409,Avg.Loss: -3.603,LR: 1.31E-05]Training epoch 90:  64%|██████▍   | 72/112 [00:01<00:00, 53.24it/s, Epoch: 90, Batch: 73,Loss: -3.756,Avg.Loss: -3.605,LR: 1.31E-05]Training epoch 90:  65%|██████▌   | 73/112 [00:01<00:00, 53.24it/s, Epoch: 90, Batch: 74,Loss: -3.414,Avg.Loss: -3.602,LR: 1.31E-05]Training epoch 90:  66%|██████▌   | 74/112 [00:01<00:00, 53.24it/s, Epoch: 90, Batch: 75,Loss: -3.648,Avg.Loss: -3.603,LR: 1.31E-05]Training epoch 90:  67%|██████▋   | 75/112 [00:01<00:00, 53.24it/s, Epoch: 90, Batch: 76,Loss: -4.068,Avg.Loss: -3.609,LR: 1.30E-05]Training epoch 90:  68%|██████▊   | 76/112 [00:01<00:00, 53.24it/s, Epoch: 90, Batch: 77,Loss: -3.777,Avg.Loss: -3.611,LR: 1.30E-05]Training epoch 90:  69%|██████▉   | 77/112 [00:01<00:00, 53.24it/s, Epoch: 90, Batch: 78,Loss: -3.947,Avg.Loss: -3.615,LR: 1.30E-05]Training epoch 90:  70%|██████▉   | 78/112 [00:01<00:00, 53.29it/s, Epoch: 90, Batch: 78,Loss: -3.947,Avg.Loss: -3.615,LR: 1.30E-05]Training epoch 90:  70%|██████▉   | 78/112 [00:01<00:00, 53.29it/s, Epoch: 90, Batch: 79,Loss: -3.675,Avg.Loss: -3.616,LR: 1.30E-05]Training epoch 90:  71%|███████   | 79/112 [00:01<00:00, 53.29it/s, Epoch: 90, Batch: 80,Loss: -3.982,Avg.Loss: -3.621,LR: 1.29E-05]Training epoch 90:  71%|███████▏  | 80/112 [00:01<00:00, 53.29it/s, Epoch: 90, Batch: 81,Loss: -3.817,Avg.Loss: -3.623,LR: 1.29E-05]Training epoch 90:  72%|███████▏  | 81/112 [00:01<00:00, 53.29it/s, Epoch: 90, Batch: 82,Loss: -3.822,Avg.Loss: -3.626,LR: 1.29E-05]Training epoch 90:  73%|███████▎  | 82/112 [00:01<00:00, 53.29it/s, Epoch: 90, Batch: 83,Loss: -3.577,Avg.Loss: -3.625,LR: 1.29E-05]Training epoch 90:  74%|███████▍  | 83/112 [00:01<00:00, 53.29it/s, Epoch: 90, Batch: 84,Loss: -3.544,Avg.Loss: -3.624,LR: 1.28E-05]Training epoch 90:  75%|███████▌  | 84/112 [00:01<00:00, 53.31it/s, Epoch: 90, Batch: 84,Loss: -3.544,Avg.Loss: -3.624,LR: 1.28E-05]Training epoch 90:  75%|███████▌  | 84/112 [00:01<00:00, 53.31it/s, Epoch: 90, Batch: 85,Loss: -3.654,Avg.Loss: -3.624,LR: 1.28E-05]Training epoch 90:  76%|███████▌  | 85/112 [00:01<00:00, 53.31it/s, Epoch: 90, Batch: 86,Loss: -3.528,Avg.Loss: -3.623,LR: 1.28E-05]Training epoch 90:  77%|███████▋  | 86/112 [00:01<00:00, 53.31it/s, Epoch: 90, Batch: 87,Loss: -3.577,Avg.Loss: -3.623,LR: 1.28E-05]Training epoch 90:  78%|███████▊  | 87/112 [00:01<00:00, 53.31it/s, Epoch: 90, Batch: 88,Loss: -3.999,Avg.Loss: -3.627,LR: 1.28E-05]Training epoch 90:  79%|███████▊  | 88/112 [00:01<00:00, 53.31it/s, Epoch: 90, Batch: 89,Loss: -3.416,Avg.Loss: -3.625,LR: 1.27E-05]Training epoch 90:  79%|███████▉  | 89/112 [00:01<00:00, 53.31it/s, Epoch: 90, Batch: 90,Loss: -3.670,Avg.Loss: -3.625,LR: 1.27E-05]Training epoch 90:  80%|████████  | 90/112 [00:01<00:00, 53.30it/s, Epoch: 90, Batch: 90,Loss: -3.670,Avg.Loss: -3.625,LR: 1.27E-05]Training epoch 90:  80%|████████  | 90/112 [00:01<00:00, 53.30it/s, Epoch: 90, Batch: 91,Loss: -3.116,Avg.Loss: -3.620,LR: 1.27E-05]Training epoch 90:  81%|████████▏ | 91/112 [00:01<00:00, 53.30it/s, Epoch: 90, Batch: 92,Loss: -3.571,Avg.Loss: -3.619,LR: 1.27E-05]Training epoch 90:  82%|████████▏ | 92/112 [00:01<00:00, 53.30it/s, Epoch: 90, Batch: 93,Loss: -3.837,Avg.Loss: -3.621,LR: 1.27E-05]Training epoch 90:  83%|████████▎ | 93/112 [00:01<00:00, 53.30it/s, Epoch: 90, Batch: 94,Loss: -4.043,Avg.Loss: -3.626,LR: 1.26E-05]Training epoch 90:  84%|████████▍ | 94/112 [00:01<00:00, 53.30it/s, Epoch: 90, Batch: 95,Loss: -3.988,Avg.Loss: -3.630,LR: 1.26E-05]Training epoch 90:  85%|████████▍ | 95/112 [00:01<00:00, 53.30it/s, Epoch: 90, Batch: 96,Loss: -3.445,Avg.Loss: -3.628,LR: 1.26E-05]Training epoch 90:  86%|████████▌ | 96/112 [00:01<00:00, 53.08it/s, Epoch: 90, Batch: 96,Loss: -3.445,Avg.Loss: -3.628,LR: 1.26E-05]Training epoch 90:  86%|████████▌ | 96/112 [00:01<00:00, 53.08it/s, Epoch: 90, Batch: 97,Loss: -3.685,Avg.Loss: -3.628,LR: 1.26E-05]Training epoch 90:  87%|████████▋ | 97/112 [00:01<00:00, 53.08it/s, Epoch: 90, Batch: 98,Loss: -3.569,Avg.Loss: -3.628,LR: 1.25E-05]Training epoch 90:  88%|████████▊ | 98/112 [00:01<00:00, 53.08it/s, Epoch: 90, Batch: 99,Loss: -3.802,Avg.Loss: -3.630,LR: 1.25E-05]Training epoch 90:  88%|████████▊ | 99/112 [00:01<00:00, 53.08it/s, Epoch: 90, Batch: 100,Loss: -3.456,Avg.Loss: -3.628,LR: 1.25E-05]Training epoch 90:  89%|████████▉ | 100/112 [00:01<00:00, 53.08it/s, Epoch: 90, Batch: 101,Loss: -3.574,Avg.Loss: -3.627,LR: 1.25E-05]Training epoch 90:  90%|█████████ | 101/112 [00:01<00:00, 53.08it/s, Epoch: 90, Batch: 102,Loss: -3.142,Avg.Loss: -3.623,LR: 1.25E-05]Training epoch 90:  91%|█████████ | 102/112 [00:01<00:00, 53.22it/s, Epoch: 90, Batch: 102,Loss: -3.142,Avg.Loss: -3.623,LR: 1.25E-05]Training epoch 90:  91%|█████████ | 102/112 [00:01<00:00, 53.22it/s, Epoch: 90, Batch: 103,Loss: -3.729,Avg.Loss: -3.624,LR: 1.24E-05]Training epoch 90:  92%|█████████▏| 103/112 [00:01<00:00, 53.22it/s, Epoch: 90, Batch: 104,Loss: -3.939,Avg.Loss: -3.627,LR: 1.24E-05]Training epoch 90:  93%|█████████▎| 104/112 [00:01<00:00, 53.22it/s, Epoch: 90, Batch: 105,Loss: -3.926,Avg.Loss: -3.629,LR: 1.24E-05]Training epoch 90:  94%|█████████▍| 105/112 [00:01<00:00, 53.22it/s, Epoch: 90, Batch: 106,Loss: -3.436,Avg.Loss: -3.628,LR: 1.24E-05]Training epoch 90:  95%|█████████▍| 106/112 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 107,Loss: -3.871,Avg.Loss: -3.630,LR: 1.23E-05]Training epoch 90:  96%|█████████▌| 107/112 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 108,Loss: -3.527,Avg.Loss: -3.629,LR: 1.23E-05]Training epoch 90:  96%|█████████▋| 108/112 [00:02<00:00, 52.12it/s, Epoch: 90, Batch: 108,Loss: -3.527,Avg.Loss: -3.629,LR: 1.23E-05]Training epoch 90:  96%|█████████▋| 108/112 [00:02<00:00, 52.12it/s, Epoch: 90, Batch: 109,Loss: -2.953,Avg.Loss: -3.623,LR: 1.23E-05]Training epoch 90:  97%|█████████▋| 109/112 [00:02<00:00, 52.12it/s, Epoch: 90, Batch: 110,Loss: -3.607,Avg.Loss: -3.623,LR: 1.23E-05]Training epoch 90:  98%|█████████▊| 110/112 [00:02<00:00, 52.12it/s, Epoch: 90, Batch: 111,Loss: -3.380,Avg.Loss: -3.620,LR: 1.23E-05]Training epoch 90:  99%|█████████▉| 111/112 [00:02<00:00, 52.12it/s, Epoch: 90, Batch: 112,Loss: -1.455,Avg.Loss: -3.601,LR: 1.22E-05]Training epoch 90: 100%|██████████| 112/112 [00:02<00:00, 52.95it/s, Epoch: 90, Batch: 112,Loss: -1.455,Avg.Loss: -3.601,LR: 1.22E-05]
Training epoch 91:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 91:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 91, Batch: 1,Loss: -3.382,Avg.Loss: -3.382,LR: 1.22E-05]Training epoch 91:   1%|          | 1/112 [00:00<00:03, 27.79it/s, Epoch: 91, Batch: 2,Loss: -3.756,Avg.Loss: -3.569,LR: 1.22E-05]Training epoch 91:   2%|▏         | 2/112 [00:00<00:02, 39.71it/s, Epoch: 91, Batch: 3,Loss: -3.300,Avg.Loss: -3.480,LR: 1.22E-05]Training epoch 91:   3%|▎         | 3/112 [00:00<00:02, 44.58it/s, Epoch: 91, Batch: 4,Loss: -4.023,Avg.Loss: -3.615,LR: 1.21E-05]Training epoch 91:   4%|▎         | 4/112 [00:00<00:02, 46.26it/s, Epoch: 91, Batch: 5,Loss: -3.607,Avg.Loss: -3.614,LR: 1.21E-05]Training epoch 91:   4%|▍         | 5/112 [00:00<00:02, 47.37it/s, Epoch: 91, Batch: 6,Loss: -3.783,Avg.Loss: -3.642,LR: 1.21E-05]Training epoch 91:   5%|▌         | 6/112 [00:00<00:01, 56.75it/s, Epoch: 91, Batch: 6,Loss: -3.783,Avg.Loss: -3.642,LR: 1.21E-05]Training epoch 91:   5%|▌         | 6/112 [00:00<00:01, 56.75it/s, Epoch: 91, Batch: 7,Loss: -3.383,Avg.Loss: -3.605,LR: 1.21E-05]Training epoch 91:   6%|▋         | 7/112 [00:00<00:01, 56.75it/s, Epoch: 91, Batch: 8,Loss: -3.965,Avg.Loss: -3.650,LR: 1.21E-05]Training epoch 91:   7%|▋         | 8/112 [00:00<00:01, 56.75it/s, Epoch: 91, Batch: 9,Loss: -3.733,Avg.Loss: -3.659,LR: 1.20E-05]Training epoch 91:   8%|▊         | 9/112 [00:00<00:01, 56.75it/s, Epoch: 91, Batch: 10,Loss: -3.665,Avg.Loss: -3.660,LR: 1.20E-05]Training epoch 91:   9%|▉         | 10/112 [00:00<00:01, 56.75it/s, Epoch: 91, Batch: 11,Loss: -3.710,Avg.Loss: -3.664,LR: 1.20E-05]Training epoch 91:  10%|▉         | 11/112 [00:00<00:01, 56.75it/s, Epoch: 91, Batch: 12,Loss: -3.810,Avg.Loss: -3.676,LR: 1.20E-05]Training epoch 91:  11%|█         | 12/112 [00:00<00:01, 54.69it/s, Epoch: 91, Batch: 12,Loss: -3.810,Avg.Loss: -3.676,LR: 1.20E-05]Training epoch 91:  11%|█         | 12/112 [00:00<00:01, 54.69it/s, Epoch: 91, Batch: 13,Loss: -3.646,Avg.Loss: -3.674,LR: 1.20E-05]Training epoch 91:  12%|█▏        | 13/112 [00:00<00:01, 54.69it/s, Epoch: 91, Batch: 14,Loss: -3.980,Avg.Loss: -3.696,LR: 1.19E-05]Training epoch 91:  12%|█▎        | 14/112 [00:00<00:01, 54.69it/s, Epoch: 91, Batch: 15,Loss: -3.711,Avg.Loss: -3.697,LR: 1.19E-05]Training epoch 91:  13%|█▎        | 15/112 [00:00<00:01, 54.69it/s, Epoch: 91, Batch: 16,Loss: -3.818,Avg.Loss: -3.704,LR: 1.19E-05]Training epoch 91:  14%|█▍        | 16/112 [00:00<00:01, 54.69it/s, Epoch: 91, Batch: 17,Loss: -3.374,Avg.Loss: -3.685,LR: 1.19E-05]Training epoch 91:  15%|█▌        | 17/112 [00:00<00:01, 54.69it/s, Epoch: 91, Batch: 18,Loss: -3.942,Avg.Loss: -3.699,LR: 1.18E-05]Training epoch 91:  16%|█▌        | 18/112 [00:00<00:01, 53.99it/s, Epoch: 91, Batch: 18,Loss: -3.942,Avg.Loss: -3.699,LR: 1.18E-05]Training epoch 91:  16%|█▌        | 18/112 [00:00<00:01, 53.99it/s, Epoch: 91, Batch: 19,Loss: -3.897,Avg.Loss: -3.710,LR: 1.18E-05]Training epoch 91:  17%|█▋        | 19/112 [00:00<00:01, 53.99it/s, Epoch: 91, Batch: 20,Loss: -3.412,Avg.Loss: -3.695,LR: 1.18E-05]Training epoch 91:  18%|█▊        | 20/112 [00:00<00:01, 53.99it/s, Epoch: 91, Batch: 21,Loss: -3.677,Avg.Loss: -3.694,LR: 1.18E-05]Training epoch 91:  19%|█▉        | 21/112 [00:00<00:01, 53.99it/s, Epoch: 91, Batch: 22,Loss: -3.390,Avg.Loss: -3.680,LR: 1.18E-05]Training epoch 91:  20%|█▉        | 22/112 [00:00<00:01, 53.99it/s, Epoch: 91, Batch: 23,Loss: -3.980,Avg.Loss: -3.693,LR: 1.17E-05]Training epoch 91:  21%|██        | 23/112 [00:00<00:01, 53.99it/s, Epoch: 91, Batch: 24,Loss: -3.858,Avg.Loss: -3.700,LR: 1.17E-05]Training epoch 91:  21%|██▏       | 24/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 24,Loss: -3.858,Avg.Loss: -3.700,LR: 1.17E-05]Training epoch 91:  21%|██▏       | 24/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 25,Loss: -3.661,Avg.Loss: -3.699,LR: 1.17E-05]Training epoch 91:  22%|██▏       | 25/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 26,Loss: -3.330,Avg.Loss: -3.684,LR: 1.17E-05]Training epoch 91:  23%|██▎       | 26/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 27,Loss: -3.822,Avg.Loss: -3.689,LR: 1.17E-05]Training epoch 91:  24%|██▍       | 27/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 28,Loss: -3.624,Avg.Loss: -3.687,LR: 1.16E-05]Training epoch 91:  25%|██▌       | 28/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 29,Loss: -2.881,Avg.Loss: -3.659,LR: 1.16E-05]Training epoch 91:  26%|██▌       | 29/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 30,Loss: -3.368,Avg.Loss: -3.650,LR: 1.16E-05]Training epoch 91:  27%|██▋       | 30/112 [00:00<00:01, 52.94it/s, Epoch: 91, Batch: 30,Loss: -3.368,Avg.Loss: -3.650,LR: 1.16E-05]Training epoch 91:  27%|██▋       | 30/112 [00:00<00:01, 52.94it/s, Epoch: 91, Batch: 31,Loss: -3.592,Avg.Loss: -3.648,LR: 1.16E-05]Training epoch 91:  28%|██▊       | 31/112 [00:00<00:01, 52.94it/s, Epoch: 91, Batch: 32,Loss: -3.491,Avg.Loss: -3.643,LR: 1.16E-05]Training epoch 91:  29%|██▊       | 32/112 [00:00<00:01, 52.94it/s, Epoch: 91, Batch: 33,Loss: -3.181,Avg.Loss: -3.629,LR: 1.15E-05]Training epoch 91:  29%|██▉       | 33/112 [00:00<00:01, 52.94it/s, Epoch: 91, Batch: 34,Loss: -3.915,Avg.Loss: -3.637,LR: 1.15E-05]Training epoch 91:  30%|███       | 34/112 [00:00<00:01, 52.94it/s, Epoch: 91, Batch: 35,Loss: -3.881,Avg.Loss: -3.644,LR: 1.15E-05]Training epoch 91:  31%|███▏      | 35/112 [00:00<00:01, 52.94it/s, Epoch: 91, Batch: 36,Loss: -3.617,Avg.Loss: -3.643,LR: 1.15E-05]Training epoch 91:  32%|███▏      | 36/112 [00:00<00:01, 52.96it/s, Epoch: 91, Batch: 36,Loss: -3.617,Avg.Loss: -3.643,LR: 1.15E-05]Training epoch 91:  32%|███▏      | 36/112 [00:00<00:01, 52.96it/s, Epoch: 91, Batch: 37,Loss: -3.501,Avg.Loss: -3.640,LR: 1.14E-05]Training epoch 91:  33%|███▎      | 37/112 [00:00<00:01, 52.96it/s, Epoch: 91, Batch: 38,Loss: -3.463,Avg.Loss: -3.635,LR: 1.14E-05]Training epoch 91:  34%|███▍      | 38/112 [00:00<00:01, 52.96it/s, Epoch: 91, Batch: 39,Loss: -3.214,Avg.Loss: -3.624,LR: 1.14E-05]Training epoch 91:  35%|███▍      | 39/112 [00:00<00:01, 52.96it/s, Epoch: 91, Batch: 40,Loss: -3.705,Avg.Loss: -3.626,LR: 1.14E-05]Training epoch 91:  36%|███▌      | 40/112 [00:00<00:01, 52.96it/s, Epoch: 91, Batch: 41,Loss: -3.496,Avg.Loss: -3.623,LR: 1.14E-05]Training epoch 91:  37%|███▋      | 41/112 [00:00<00:01, 52.96it/s, Epoch: 91, Batch: 42,Loss: -3.667,Avg.Loss: -3.624,LR: 1.13E-05]Training epoch 91:  38%|███▊      | 42/112 [00:00<00:01, 52.99it/s, Epoch: 91, Batch: 42,Loss: -3.667,Avg.Loss: -3.624,LR: 1.13E-05]Training epoch 91:  38%|███▊      | 42/112 [00:00<00:01, 52.99it/s, Epoch: 91, Batch: 43,Loss: -4.144,Avg.Loss: -3.636,LR: 1.13E-05]Training epoch 91:  38%|███▊      | 43/112 [00:00<00:01, 52.99it/s, Epoch: 91, Batch: 44,Loss: -3.440,Avg.Loss: -3.632,LR: 1.13E-05]Training epoch 91:  39%|███▉      | 44/112 [00:00<00:01, 52.99it/s, Epoch: 91, Batch: 45,Loss: -3.757,Avg.Loss: -3.634,LR: 1.13E-05]Training epoch 91:  40%|████      | 45/112 [00:00<00:01, 52.99it/s, Epoch: 91, Batch: 46,Loss: -3.555,Avg.Loss: -3.633,LR: 1.13E-05]Training epoch 91:  41%|████      | 46/112 [00:00<00:01, 52.99it/s, Epoch: 91, Batch: 47,Loss: -3.883,Avg.Loss: -3.638,LR: 1.12E-05]Training epoch 91:  42%|████▏     | 47/112 [00:00<00:01, 52.99it/s, Epoch: 91, Batch: 48,Loss: -3.955,Avg.Loss: -3.645,LR: 1.12E-05]Training epoch 91:  43%|████▎     | 48/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 48,Loss: -3.955,Avg.Loss: -3.645,LR: 1.12E-05]Training epoch 91:  43%|████▎     | 48/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 49,Loss: -3.563,Avg.Loss: -3.643,LR: 1.12E-05]Training epoch 91:  44%|████▍     | 49/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 50,Loss: -3.205,Avg.Loss: -3.634,LR: 1.12E-05]Training epoch 91:  45%|████▍     | 50/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 51,Loss: -3.910,Avg.Loss: -3.640,LR: 1.12E-05]Training epoch 91:  46%|████▌     | 51/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 52,Loss: -3.653,Avg.Loss: -3.640,LR: 1.11E-05]Training epoch 91:  46%|████▋     | 52/112 [00:00<00:01, 53.06it/s, Epoch: 91, Batch: 53,Loss: -3.721,Avg.Loss: -3.641,LR: 1.11E-05]Training epoch 91:  47%|████▋     | 53/112 [00:01<00:01, 53.06it/s, Epoch: 91, Batch: 54,Loss: -3.565,Avg.Loss: -3.640,LR: 1.11E-05]Training epoch 91:  48%|████▊     | 54/112 [00:01<00:01, 53.01it/s, Epoch: 91, Batch: 54,Loss: -3.565,Avg.Loss: -3.640,LR: 1.11E-05]Training epoch 91:  48%|████▊     | 54/112 [00:01<00:01, 53.01it/s, Epoch: 91, Batch: 55,Loss: -3.573,Avg.Loss: -3.639,LR: 1.11E-05]Training epoch 91:  49%|████▉     | 55/112 [00:01<00:01, 53.01it/s, Epoch: 91, Batch: 56,Loss: -3.872,Avg.Loss: -3.643,LR: 1.11E-05]Training epoch 91:  50%|█████     | 56/112 [00:01<00:01, 53.01it/s, Epoch: 91, Batch: 57,Loss: -3.464,Avg.Loss: -3.640,LR: 1.10E-05]Training epoch 91:  51%|█████     | 57/112 [00:01<00:01, 53.01it/s, Epoch: 91, Batch: 58,Loss: -3.911,Avg.Loss: -3.644,LR: 1.10E-05]Training epoch 91:  52%|█████▏    | 58/112 [00:01<00:01, 53.01it/s, Epoch: 91, Batch: 59,Loss: -3.555,Avg.Loss: -3.643,LR: 1.10E-05]Training epoch 91:  53%|█████▎    | 59/112 [00:01<00:00, 53.01it/s, Epoch: 91, Batch: 60,Loss: -3.824,Avg.Loss: -3.646,LR: 1.10E-05]Training epoch 91:  54%|█████▎    | 60/112 [00:01<00:00, 53.08it/s, Epoch: 91, Batch: 60,Loss: -3.824,Avg.Loss: -3.646,LR: 1.10E-05]Training epoch 91:  54%|█████▎    | 60/112 [00:01<00:00, 53.08it/s, Epoch: 91, Batch: 61,Loss: -3.449,Avg.Loss: -3.643,LR: 1.09E-05]Training epoch 91:  54%|█████▍    | 61/112 [00:01<00:00, 53.08it/s, Epoch: 91, Batch: 62,Loss: -3.401,Avg.Loss: -3.639,LR: 1.09E-05]Training epoch 91:  55%|█████▌    | 62/112 [00:01<00:00, 53.08it/s, Epoch: 91, Batch: 63,Loss: -3.533,Avg.Loss: -3.637,LR: 1.09E-05]Training epoch 91:  56%|█████▋    | 63/112 [00:01<00:00, 53.08it/s, Epoch: 91, Batch: 64,Loss: -3.994,Avg.Loss: -3.643,LR: 1.09E-05]Training epoch 91:  57%|█████▋    | 64/112 [00:01<00:00, 53.08it/s, Epoch: 91, Batch: 65,Loss: -3.488,Avg.Loss: -3.640,LR: 1.09E-05]Training epoch 91:  58%|█████▊    | 65/112 [00:01<00:00, 53.08it/s, Epoch: 91, Batch: 66,Loss: -3.968,Avg.Loss: -3.645,LR: 1.08E-05]Training epoch 91:  59%|█████▉    | 66/112 [00:01<00:00, 53.29it/s, Epoch: 91, Batch: 66,Loss: -3.968,Avg.Loss: -3.645,LR: 1.08E-05]Training epoch 91:  59%|█████▉    | 66/112 [00:01<00:00, 53.29it/s, Epoch: 91, Batch: 67,Loss: -3.361,Avg.Loss: -3.641,LR: 1.08E-05]Training epoch 91:  60%|█████▉    | 67/112 [00:01<00:00, 53.29it/s, Epoch: 91, Batch: 68,Loss: -3.861,Avg.Loss: -3.644,LR: 1.08E-05]Training epoch 91:  61%|██████    | 68/112 [00:01<00:00, 53.29it/s, Epoch: 91, Batch: 69,Loss: -3.384,Avg.Loss: -3.641,LR: 1.08E-05]Training epoch 91:  62%|██████▏   | 69/112 [00:01<00:00, 53.29it/s, Epoch: 91, Batch: 70,Loss: -3.485,Avg.Loss: -3.638,LR: 1.08E-05]Training epoch 91:  62%|██████▎   | 70/112 [00:01<00:00, 53.29it/s, Epoch: 91, Batch: 71,Loss: -3.074,Avg.Loss: -3.630,LR: 1.07E-05]Training epoch 91:  63%|██████▎   | 71/112 [00:01<00:00, 53.29it/s, Epoch: 91, Batch: 72,Loss: -3.502,Avg.Loss: -3.629,LR: 1.07E-05]Training epoch 91:  64%|██████▍   | 72/112 [00:01<00:00, 53.53it/s, Epoch: 91, Batch: 72,Loss: -3.502,Avg.Loss: -3.629,LR: 1.07E-05]Training epoch 91:  64%|██████▍   | 72/112 [00:01<00:00, 53.53it/s, Epoch: 91, Batch: 73,Loss: -3.859,Avg.Loss: -3.632,LR: 1.07E-05]Training epoch 91:  65%|██████▌   | 73/112 [00:01<00:00, 53.53it/s, Epoch: 91, Batch: 74,Loss: -3.771,Avg.Loss: -3.634,LR: 1.07E-05]Training epoch 91:  66%|██████▌   | 74/112 [00:01<00:00, 53.53it/s, Epoch: 91, Batch: 75,Loss: -3.670,Avg.Loss: -3.634,LR: 1.07E-05]Training epoch 91:  67%|██████▋   | 75/112 [00:01<00:00, 53.53it/s, Epoch: 91, Batch: 76,Loss: -3.576,Avg.Loss: -3.633,LR: 1.06E-05]Training epoch 91:  68%|██████▊   | 76/112 [00:01<00:00, 53.53it/s, Epoch: 91, Batch: 77,Loss: -3.676,Avg.Loss: -3.634,LR: 1.06E-05]Training epoch 91:  69%|██████▉   | 77/112 [00:01<00:00, 53.53it/s, Epoch: 91, Batch: 78,Loss: -3.761,Avg.Loss: -3.636,LR: 1.06E-05]Training epoch 91:  70%|██████▉   | 78/112 [00:01<00:00, 53.43it/s, Epoch: 91, Batch: 78,Loss: -3.761,Avg.Loss: -3.636,LR: 1.06E-05]Training epoch 91:  70%|██████▉   | 78/112 [00:01<00:00, 53.43it/s, Epoch: 91, Batch: 79,Loss: -3.654,Avg.Loss: -3.636,LR: 1.06E-05]Training epoch 91:  71%|███████   | 79/112 [00:01<00:00, 53.43it/s, Epoch: 91, Batch: 80,Loss: -3.737,Avg.Loss: -3.637,LR: 1.06E-05]Training epoch 91:  71%|███████▏  | 80/112 [00:01<00:00, 53.43it/s, Epoch: 91, Batch: 81,Loss: -3.596,Avg.Loss: -3.637,LR: 1.05E-05]Training epoch 91:  72%|███████▏  | 81/112 [00:01<00:00, 53.43it/s, Epoch: 91, Batch: 82,Loss: -3.670,Avg.Loss: -3.637,LR: 1.05E-05]Training epoch 91:  73%|███████▎  | 82/112 [00:01<00:00, 53.43it/s, Epoch: 91, Batch: 83,Loss: -3.595,Avg.Loss: -3.636,LR: 1.05E-05]Training epoch 91:  74%|███████▍  | 83/112 [00:01<00:00, 53.43it/s, Epoch: 91, Batch: 84,Loss: -3.587,Avg.Loss: -3.636,LR: 1.05E-05]Training epoch 91:  75%|███████▌  | 84/112 [00:01<00:00, 53.49it/s, Epoch: 91, Batch: 84,Loss: -3.587,Avg.Loss: -3.636,LR: 1.05E-05]Training epoch 91:  75%|███████▌  | 84/112 [00:01<00:00, 53.49it/s, Epoch: 91, Batch: 85,Loss: -3.606,Avg.Loss: -3.636,LR: 1.05E-05]Training epoch 91:  76%|███████▌  | 85/112 [00:01<00:00, 53.49it/s, Epoch: 91, Batch: 86,Loss: -2.956,Avg.Loss: -3.628,LR: 1.04E-05]Training epoch 91:  77%|███████▋  | 86/112 [00:01<00:00, 53.49it/s, Epoch: 91, Batch: 87,Loss: -3.822,Avg.Loss: -3.630,LR: 1.04E-05]Training epoch 91:  78%|███████▊  | 87/112 [00:01<00:00, 53.49it/s, Epoch: 91, Batch: 88,Loss: -4.004,Avg.Loss: -3.634,LR: 1.04E-05]Training epoch 91:  79%|███████▊  | 88/112 [00:01<00:00, 53.49it/s, Epoch: 91, Batch: 89,Loss: -3.862,Avg.Loss: -3.637,LR: 1.04E-05]Training epoch 91:  79%|███████▉  | 89/112 [00:01<00:00, 53.49it/s, Epoch: 91, Batch: 90,Loss: -3.359,Avg.Loss: -3.634,LR: 1.04E-05]Training epoch 91:  80%|████████  | 90/112 [00:01<00:00, 53.46it/s, Epoch: 91, Batch: 90,Loss: -3.359,Avg.Loss: -3.634,LR: 1.04E-05]Training epoch 91:  80%|████████  | 90/112 [00:01<00:00, 53.46it/s, Epoch: 91, Batch: 91,Loss: -3.401,Avg.Loss: -3.631,LR: 1.03E-05]Training epoch 91:  81%|████████▏ | 91/112 [00:01<00:00, 53.46it/s, Epoch: 91, Batch: 92,Loss: -3.480,Avg.Loss: -3.629,LR: 1.03E-05]Training epoch 91:  82%|████████▏ | 92/112 [00:01<00:00, 53.46it/s, Epoch: 91, Batch: 93,Loss: -3.560,Avg.Loss: -3.629,LR: 1.03E-05]Training epoch 91:  83%|████████▎ | 93/112 [00:01<00:00, 53.46it/s, Epoch: 91, Batch: 94,Loss: -3.147,Avg.Loss: -3.624,LR: 1.03E-05]Training epoch 91:  84%|████████▍ | 94/112 [00:01<00:00, 53.46it/s, Epoch: 91, Batch: 95,Loss: -3.950,Avg.Loss: -3.627,LR: 1.03E-05]Training epoch 91:  85%|████████▍ | 95/112 [00:01<00:00, 53.46it/s, Epoch: 91, Batch: 96,Loss: -3.817,Avg.Loss: -3.629,LR: 1.02E-05]Training epoch 91:  86%|████████▌ | 96/112 [00:01<00:00, 53.39it/s, Epoch: 91, Batch: 96,Loss: -3.817,Avg.Loss: -3.629,LR: 1.02E-05]Training epoch 91:  86%|████████▌ | 96/112 [00:01<00:00, 53.39it/s, Epoch: 91, Batch: 97,Loss: -3.175,Avg.Loss: -3.624,LR: 1.02E-05]Training epoch 91:  87%|████████▋ | 97/112 [00:01<00:00, 53.39it/s, Epoch: 91, Batch: 98,Loss: -3.685,Avg.Loss: -3.625,LR: 1.02E-05]Training epoch 91:  88%|████████▊ | 98/112 [00:01<00:00, 53.39it/s, Epoch: 91, Batch: 99,Loss: -3.636,Avg.Loss: -3.625,LR: 1.02E-05]Training epoch 91:  88%|████████▊ | 99/112 [00:01<00:00, 53.39it/s, Epoch: 91, Batch: 100,Loss: -3.398,Avg.Loss: -3.623,LR: 1.02E-05]Training epoch 91:  89%|████████▉ | 100/112 [00:01<00:00, 53.39it/s, Epoch: 91, Batch: 101,Loss: -3.564,Avg.Loss: -3.622,LR: 1.01E-05]Training epoch 91:  90%|█████████ | 101/112 [00:01<00:00, 53.39it/s, Epoch: 91, Batch: 102,Loss: -3.999,Avg.Loss: -3.626,LR: 1.01E-05]Training epoch 91:  91%|█████████ | 102/112 [00:01<00:00, 53.48it/s, Epoch: 91, Batch: 102,Loss: -3.999,Avg.Loss: -3.626,LR: 1.01E-05]Training epoch 91:  91%|█████████ | 102/112 [00:01<00:00, 53.48it/s, Epoch: 91, Batch: 103,Loss: -2.998,Avg.Loss: -3.620,LR: 1.01E-05]Training epoch 91:  92%|█████████▏| 103/112 [00:01<00:00, 53.48it/s, Epoch: 91, Batch: 104,Loss: -3.463,Avg.Loss: -3.618,LR: 1.01E-05]Training epoch 91:  93%|█████████▎| 104/112 [00:01<00:00, 53.48it/s, Epoch: 91, Batch: 105,Loss: -3.208,Avg.Loss: -3.614,LR: 1.01E-05]Training epoch 91:  94%|█████████▍| 105/112 [00:01<00:00, 53.48it/s, Epoch: 91, Batch: 106,Loss: -3.704,Avg.Loss: -3.615,LR: 1.00E-05]Training epoch 91:  95%|█████████▍| 106/112 [00:02<00:00, 53.48it/s, Epoch: 91, Batch: 107,Loss: -3.336,Avg.Loss: -3.613,LR: 1.00E-05]Training epoch 91:  96%|█████████▌| 107/112 [00:02<00:00, 53.48it/s, Epoch: 91, Batch: 108,Loss: -3.608,Avg.Loss: -3.613,LR: 1.00E-05]Training epoch 91:  96%|█████████▋| 108/112 [00:02<00:00, 53.54it/s, Epoch: 91, Batch: 108,Loss: -3.608,Avg.Loss: -3.613,LR: 1.00E-05]Training epoch 91:  96%|█████████▋| 108/112 [00:02<00:00, 53.54it/s, Epoch: 91, Batch: 109,Loss: -3.583,Avg.Loss: -3.612,LR: 9.99E-06]Training epoch 91:  97%|█████████▋| 109/112 [00:02<00:00, 53.54it/s, Epoch: 91, Batch: 110,Loss: -3.230,Avg.Loss: -3.609,LR: 9.97E-06]Training epoch 91:  98%|█████████▊| 110/112 [00:02<00:00, 53.54it/s, Epoch: 91, Batch: 111,Loss: -3.720,Avg.Loss: -3.610,LR: 9.95E-06]Training epoch 91:  99%|█████████▉| 111/112 [00:02<00:00, 53.54it/s, Epoch: 91, Batch: 112,Loss: -4.015,Avg.Loss: -3.613,LR: 9.93E-06]Training epoch 91: 100%|██████████| 112/112 [00:02<00:00, 53.32it/s, Epoch: 91, Batch: 112,Loss: -4.015,Avg.Loss: -3.613,LR: 9.93E-06]
Training epoch 92:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 92:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 92, Batch: 1,Loss: -3.978,Avg.Loss: -3.978,LR: 9.91E-06]Training epoch 92:   1%|          | 1/112 [00:00<00:04, 26.87it/s, Epoch: 92, Batch: 2,Loss: -4.059,Avg.Loss: -4.019,LR: 9.89E-06]Training epoch 92:   2%|▏         | 2/112 [00:00<00:02, 39.56it/s, Epoch: 92, Batch: 3,Loss: -3.594,Avg.Loss: -3.877,LR: 9.87E-06]Training epoch 92:   3%|▎         | 3/112 [00:00<00:02, 47.12it/s, Epoch: 92, Batch: 4,Loss: -3.247,Avg.Loss: -3.720,LR: 9.85E-06]Training epoch 92:   4%|▎         | 4/112 [00:00<00:02, 51.35it/s, Epoch: 92, Batch: 5,Loss: -3.716,Avg.Loss: -3.719,LR: 9.83E-06]Training epoch 92:   4%|▍         | 5/112 [00:00<00:02, 51.58it/s, Epoch: 92, Batch: 6,Loss: -3.256,Avg.Loss: -3.642,LR: 9.81E-06]Training epoch 92:   5%|▌         | 6/112 [00:00<00:02, 51.73it/s, Epoch: 92, Batch: 7,Loss: -4.115,Avg.Loss: -3.709,LR: 9.79E-06]Training epoch 92:   6%|▋         | 7/112 [00:00<00:01, 60.25it/s, Epoch: 92, Batch: 7,Loss: -4.115,Avg.Loss: -3.709,LR: 9.79E-06]Training epoch 92:   6%|▋         | 7/112 [00:00<00:01, 60.25it/s, Epoch: 92, Batch: 8,Loss: -3.280,Avg.Loss: -3.656,LR: 9.77E-06]Training epoch 92:   7%|▋         | 8/112 [00:00<00:01, 60.25it/s, Epoch: 92, Batch: 9,Loss: -3.692,Avg.Loss: -3.660,LR: 9.75E-06]Training epoch 92:   8%|▊         | 9/112 [00:00<00:01, 60.25it/s, Epoch: 92, Batch: 10,Loss: -3.783,Avg.Loss: -3.672,LR: 9.73E-06]Training epoch 92:   9%|▉         | 10/112 [00:00<00:01, 60.25it/s, Epoch: 92, Batch: 11,Loss: -3.553,Avg.Loss: -3.661,LR: 9.71E-06]Training epoch 92:  10%|▉         | 11/112 [00:00<00:01, 60.25it/s, Epoch: 92, Batch: 12,Loss: -3.819,Avg.Loss: -3.675,LR: 9.69E-06]Training epoch 92:  11%|█         | 12/112 [00:00<00:01, 60.25it/s, Epoch: 92, Batch: 13,Loss: -3.678,Avg.Loss: -3.675,LR: 9.67E-06]Training epoch 92:  12%|█▏        | 13/112 [00:00<00:01, 60.25it/s, Epoch: 92, Batch: 14,Loss: -3.733,Avg.Loss: -3.679,LR: 9.65E-06]Training epoch 92:  12%|█▎        | 14/112 [00:00<00:01, 54.64it/s, Epoch: 92, Batch: 14,Loss: -3.733,Avg.Loss: -3.679,LR: 9.65E-06]Training epoch 92:  12%|█▎        | 14/112 [00:00<00:01, 54.64it/s, Epoch: 92, Batch: 15,Loss: -3.603,Avg.Loss: -3.674,LR: 9.64E-06]Training epoch 92:  13%|█▎        | 15/112 [00:00<00:01, 54.64it/s, Epoch: 92, Batch: 16,Loss: -3.689,Avg.Loss: -3.675,LR: 9.62E-06]Training epoch 92:  14%|█▍        | 16/112 [00:00<00:01, 54.64it/s, Epoch: 92, Batch: 17,Loss: -3.478,Avg.Loss: -3.663,LR: 9.60E-06]Training epoch 92:  15%|█▌        | 17/112 [00:00<00:01, 54.64it/s, Epoch: 92, Batch: 18,Loss: -3.759,Avg.Loss: -3.669,LR: 9.58E-06]Training epoch 92:  16%|█▌        | 18/112 [00:00<00:01, 54.64it/s, Epoch: 92, Batch: 19,Loss: -4.044,Avg.Loss: -3.688,LR: 9.56E-06]Training epoch 92:  17%|█▋        | 19/112 [00:00<00:01, 54.64it/s, Epoch: 92, Batch: 20,Loss: -3.588,Avg.Loss: -3.683,LR: 9.54E-06]Training epoch 92:  18%|█▊        | 20/112 [00:00<00:01, 53.16it/s, Epoch: 92, Batch: 20,Loss: -3.588,Avg.Loss: -3.683,LR: 9.54E-06]Training epoch 92:  18%|█▊        | 20/112 [00:00<00:01, 53.16it/s, Epoch: 92, Batch: 21,Loss: -3.353,Avg.Loss: -3.668,LR: 9.52E-06]Training epoch 92:  19%|█▉        | 21/112 [00:00<00:01, 53.16it/s, Epoch: 92, Batch: 22,Loss: -3.805,Avg.Loss: -3.674,LR: 9.50E-06]Training epoch 92:  20%|█▉        | 22/112 [00:00<00:01, 53.16it/s, Epoch: 92, Batch: 23,Loss: -3.945,Avg.Loss: -3.686,LR: 9.48E-06]Training epoch 92:  21%|██        | 23/112 [00:00<00:01, 53.16it/s, Epoch: 92, Batch: 24,Loss: -3.690,Avg.Loss: -3.686,LR: 9.46E-06]Training epoch 92:  21%|██▏       | 24/112 [00:00<00:01, 53.16it/s, Epoch: 92, Batch: 25,Loss: -3.461,Avg.Loss: -3.677,LR: 9.44E-06]Training epoch 92:  22%|██▏       | 25/112 [00:00<00:01, 53.16it/s, Epoch: 92, Batch: 26,Loss: -3.260,Avg.Loss: -3.661,LR: 9.42E-06]Training epoch 92:  23%|██▎       | 26/112 [00:00<00:01, 52.98it/s, Epoch: 92, Batch: 26,Loss: -3.260,Avg.Loss: -3.661,LR: 9.42E-06]Training epoch 92:  23%|██▎       | 26/112 [00:00<00:01, 52.98it/s, Epoch: 92, Batch: 27,Loss: -3.804,Avg.Loss: -3.666,LR: 9.41E-06]Training epoch 92:  24%|██▍       | 27/112 [00:00<00:01, 52.98it/s, Epoch: 92, Batch: 28,Loss: -3.488,Avg.Loss: -3.660,LR: 9.39E-06]Training epoch 92:  25%|██▌       | 28/112 [00:00<00:01, 52.98it/s, Epoch: 92, Batch: 29,Loss: -3.653,Avg.Loss: -3.659,LR: 9.37E-06]Training epoch 92:  26%|██▌       | 29/112 [00:00<00:01, 52.98it/s, Epoch: 92, Batch: 30,Loss: -3.466,Avg.Loss: -3.653,LR: 9.35E-06]Training epoch 92:  27%|██▋       | 30/112 [00:00<00:01, 52.98it/s, Epoch: 92, Batch: 31,Loss: -3.815,Avg.Loss: -3.658,LR: 9.33E-06]Training epoch 92:  28%|██▊       | 31/112 [00:00<00:01, 52.98it/s, Epoch: 92, Batch: 32,Loss: -3.317,Avg.Loss: -3.648,LR: 9.31E-06]Training epoch 92:  29%|██▊       | 32/112 [00:00<00:01, 53.10it/s, Epoch: 92, Batch: 32,Loss: -3.317,Avg.Loss: -3.648,LR: 9.31E-06]Training epoch 92:  29%|██▊       | 32/112 [00:00<00:01, 53.10it/s, Epoch: 92, Batch: 33,Loss: -3.713,Avg.Loss: -3.650,LR: 9.29E-06]Training epoch 92:  29%|██▉       | 33/112 [00:00<00:01, 53.10it/s, Epoch: 92, Batch: 34,Loss: -4.012,Avg.Loss: -3.660,LR: 9.27E-06]Training epoch 92:  30%|███       | 34/112 [00:00<00:01, 53.10it/s, Epoch: 92, Batch: 35,Loss: -3.783,Avg.Loss: -3.664,LR: 9.25E-06]Training epoch 92:  31%|███▏      | 35/112 [00:00<00:01, 53.10it/s, Epoch: 92, Batch: 36,Loss: -2.978,Avg.Loss: -3.645,LR: 9.23E-06]Training epoch 92:  32%|███▏      | 36/112 [00:00<00:01, 53.10it/s, Epoch: 92, Batch: 37,Loss: -4.077,Avg.Loss: -3.656,LR: 9.22E-06]Training epoch 92:  33%|███▎      | 37/112 [00:00<00:01, 53.10it/s, Epoch: 92, Batch: 38,Loss: -3.999,Avg.Loss: -3.665,LR: 9.20E-06]Training epoch 92:  34%|███▍      | 38/112 [00:00<00:01, 53.23it/s, Epoch: 92, Batch: 38,Loss: -3.999,Avg.Loss: -3.665,LR: 9.20E-06]Training epoch 92:  34%|███▍      | 38/112 [00:00<00:01, 53.23it/s, Epoch: 92, Batch: 39,Loss: -3.619,Avg.Loss: -3.664,LR: 9.18E-06]Training epoch 92:  35%|███▍      | 39/112 [00:00<00:01, 53.23it/s, Epoch: 92, Batch: 40,Loss: -3.941,Avg.Loss: -3.671,LR: 9.16E-06]Training epoch 92:  36%|███▌      | 40/112 [00:00<00:01, 53.23it/s, Epoch: 92, Batch: 41,Loss: -3.729,Avg.Loss: -3.673,LR: 9.14E-06]Training epoch 92:  37%|███▋      | 41/112 [00:00<00:01, 53.23it/s, Epoch: 92, Batch: 42,Loss: -3.476,Avg.Loss: -3.668,LR: 9.12E-06]Training epoch 92:  38%|███▊      | 42/112 [00:00<00:01, 53.23it/s, Epoch: 92, Batch: 43,Loss: -3.655,Avg.Loss: -3.668,LR: 9.10E-06]Training epoch 92:  38%|███▊      | 43/112 [00:00<00:01, 53.23it/s, Epoch: 92, Batch: 44,Loss: -3.918,Avg.Loss: -3.673,LR: 9.08E-06]Training epoch 92:  39%|███▉      | 44/112 [00:00<00:01, 53.21it/s, Epoch: 92, Batch: 44,Loss: -3.918,Avg.Loss: -3.673,LR: 9.08E-06]Training epoch 92:  39%|███▉      | 44/112 [00:00<00:01, 53.21it/s, Epoch: 92, Batch: 45,Loss: -3.762,Avg.Loss: -3.675,LR: 9.07E-06]Training epoch 92:  40%|████      | 45/112 [00:00<00:01, 53.21it/s, Epoch: 92, Batch: 46,Loss: -3.871,Avg.Loss: -3.679,LR: 9.05E-06]Training epoch 92:  41%|████      | 46/112 [00:00<00:01, 53.21it/s, Epoch: 92, Batch: 47,Loss: -3.629,Avg.Loss: -3.678,LR: 9.03E-06]Training epoch 92:  42%|████▏     | 47/112 [00:00<00:01, 53.21it/s, Epoch: 92, Batch: 48,Loss: -3.559,Avg.Loss: -3.676,LR: 9.01E-06]Training epoch 92:  43%|████▎     | 48/112 [00:00<00:01, 53.21it/s, Epoch: 92, Batch: 49,Loss: -3.843,Avg.Loss: -3.679,LR: 8.99E-06]Training epoch 92:  44%|████▍     | 49/112 [00:00<00:01, 53.21it/s, Epoch: 92, Batch: 50,Loss: -3.770,Avg.Loss: -3.681,LR: 8.97E-06]Training epoch 92:  45%|████▍     | 50/112 [00:00<00:01, 53.19it/s, Epoch: 92, Batch: 50,Loss: -3.770,Avg.Loss: -3.681,LR: 8.97E-06]Training epoch 92:  45%|████▍     | 50/112 [00:00<00:01, 53.19it/s, Epoch: 92, Batch: 51,Loss: -3.522,Avg.Loss: -3.678,LR: 8.95E-06]Training epoch 92:  46%|████▌     | 51/112 [00:00<00:01, 53.19it/s, Epoch: 92, Batch: 52,Loss: -3.692,Avg.Loss: -3.678,LR: 8.93E-06]Training epoch 92:  46%|████▋     | 52/112 [00:00<00:01, 53.19it/s, Epoch: 92, Batch: 53,Loss: -3.455,Avg.Loss: -3.674,LR: 8.92E-06]Training epoch 92:  47%|████▋     | 53/112 [00:01<00:01, 53.19it/s, Epoch: 92, Batch: 54,Loss: -3.161,Avg.Loss: -3.665,LR: 8.90E-06]Training epoch 92:  48%|████▊     | 54/112 [00:01<00:01, 53.19it/s, Epoch: 92, Batch: 55,Loss: -3.766,Avg.Loss: -3.666,LR: 8.88E-06]Training epoch 92:  49%|████▉     | 55/112 [00:01<00:01, 53.19it/s, Epoch: 92, Batch: 56,Loss: -3.662,Avg.Loss: -3.666,LR: 8.86E-06]Training epoch 92:  50%|█████     | 56/112 [00:01<00:01, 52.83it/s, Epoch: 92, Batch: 56,Loss: -3.662,Avg.Loss: -3.666,LR: 8.86E-06]Training epoch 92:  50%|█████     | 56/112 [00:01<00:01, 52.83it/s, Epoch: 92, Batch: 57,Loss: -3.728,Avg.Loss: -3.667,LR: 8.84E-06]Training epoch 92:  51%|█████     | 57/112 [00:01<00:01, 52.83it/s, Epoch: 92, Batch: 58,Loss: -3.719,Avg.Loss: -3.668,LR: 8.82E-06]Training epoch 92:  52%|█████▏    | 58/112 [00:01<00:01, 52.83it/s, Epoch: 92, Batch: 59,Loss: -2.970,Avg.Loss: -3.656,LR: 8.81E-06]Training epoch 92:  53%|█████▎    | 59/112 [00:01<00:01, 52.83it/s, Epoch: 92, Batch: 60,Loss: -3.966,Avg.Loss: -3.662,LR: 8.79E-06]Training epoch 92:  54%|█████▎    | 60/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 61,Loss: -3.518,Avg.Loss: -3.659,LR: 8.77E-06]Training epoch 92:  54%|█████▍    | 61/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 62,Loss: -3.759,Avg.Loss: -3.661,LR: 8.75E-06]Training epoch 92:  55%|█████▌    | 62/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 62,Loss: -3.759,Avg.Loss: -3.661,LR: 8.75E-06]Training epoch 92:  55%|█████▌    | 62/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 63,Loss: -4.070,Avg.Loss: -3.667,LR: 8.73E-06]Training epoch 92:  56%|█████▋    | 63/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 64,Loss: -3.235,Avg.Loss: -3.661,LR: 8.71E-06]Training epoch 92:  57%|█████▋    | 64/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 65,Loss: -3.123,Avg.Loss: -3.652,LR: 8.69E-06]Training epoch 92:  58%|█████▊    | 65/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 66,Loss: -3.563,Avg.Loss: -3.651,LR: 8.68E-06]Training epoch 92:  59%|█████▉    | 66/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 67,Loss: -3.417,Avg.Loss: -3.648,LR: 8.66E-06]Training epoch 92:  60%|█████▉    | 67/112 [00:01<00:00, 52.83it/s, Epoch: 92, Batch: 68,Loss: -3.499,Avg.Loss: -3.645,LR: 8.64E-06]Training epoch 92:  61%|██████    | 68/112 [00:01<00:00, 52.64it/s, Epoch: 92, Batch: 68,Loss: -3.499,Avg.Loss: -3.645,LR: 8.64E-06]Training epoch 92:  61%|██████    | 68/112 [00:01<00:00, 52.64it/s, Epoch: 92, Batch: 69,Loss: -4.135,Avg.Loss: -3.652,LR: 8.62E-06]Training epoch 92:  62%|██████▏   | 69/112 [00:01<00:00, 52.64it/s, Epoch: 92, Batch: 70,Loss: -3.805,Avg.Loss: -3.655,LR: 8.60E-06]Training epoch 92:  62%|██████▎   | 70/112 [00:01<00:00, 52.64it/s, Epoch: 92, Batch: 71,Loss: -3.579,Avg.Loss: -3.654,LR: 8.59E-06]Training epoch 92:  63%|██████▎   | 71/112 [00:01<00:00, 52.64it/s, Epoch: 92, Batch: 72,Loss: -3.818,Avg.Loss: -3.656,LR: 8.57E-06]Training epoch 92:  64%|██████▍   | 72/112 [00:01<00:00, 52.64it/s, Epoch: 92, Batch: 73,Loss: -3.633,Avg.Loss: -3.655,LR: 8.55E-06]Training epoch 92:  65%|██████▌   | 73/112 [00:01<00:00, 52.64it/s, Epoch: 92, Batch: 74,Loss: -3.245,Avg.Loss: -3.650,LR: 8.53E-06]Training epoch 92:  66%|██████▌   | 74/112 [00:01<00:00, 52.79it/s, Epoch: 92, Batch: 74,Loss: -3.245,Avg.Loss: -3.650,LR: 8.53E-06]Training epoch 92:  66%|██████▌   | 74/112 [00:01<00:00, 52.79it/s, Epoch: 92, Batch: 75,Loss: -3.845,Avg.Loss: -3.653,LR: 8.51E-06]Training epoch 92:  67%|██████▋   | 75/112 [00:01<00:00, 52.79it/s, Epoch: 92, Batch: 76,Loss: -4.021,Avg.Loss: -3.657,LR: 8.49E-06]Training epoch 92:  68%|██████▊   | 76/112 [00:01<00:00, 52.79it/s, Epoch: 92, Batch: 77,Loss: -3.934,Avg.Loss: -3.661,LR: 8.48E-06]Training epoch 92:  69%|██████▉   | 77/112 [00:01<00:00, 52.79it/s, Epoch: 92, Batch: 78,Loss: -3.469,Avg.Loss: -3.659,LR: 8.46E-06]Training epoch 92:  70%|██████▉   | 78/112 [00:01<00:00, 52.79it/s, Epoch: 92, Batch: 79,Loss: -3.964,Avg.Loss: -3.662,LR: 8.44E-06]Training epoch 92:  71%|███████   | 79/112 [00:01<00:00, 52.79it/s, Epoch: 92, Batch: 80,Loss: -3.932,Avg.Loss: -3.666,LR: 8.42E-06]Training epoch 92:  71%|███████▏  | 80/112 [00:01<00:00, 52.93it/s, Epoch: 92, Batch: 80,Loss: -3.932,Avg.Loss: -3.666,LR: 8.42E-06]Training epoch 92:  71%|███████▏  | 80/112 [00:01<00:00, 52.93it/s, Epoch: 92, Batch: 81,Loss: -3.670,Avg.Loss: -3.666,LR: 8.40E-06]Training epoch 92:  72%|███████▏  | 81/112 [00:01<00:00, 52.93it/s, Epoch: 92, Batch: 82,Loss: -3.489,Avg.Loss: -3.664,LR: 8.39E-06]Training epoch 92:  73%|███████▎  | 82/112 [00:01<00:00, 52.93it/s, Epoch: 92, Batch: 83,Loss: -3.461,Avg.Loss: -3.661,LR: 8.37E-06]Training epoch 92:  74%|███████▍  | 83/112 [00:01<00:00, 52.93it/s, Epoch: 92, Batch: 84,Loss: -3.509,Avg.Loss: -3.659,LR: 8.35E-06]Training epoch 92:  75%|███████▌  | 84/112 [00:01<00:00, 52.93it/s, Epoch: 92, Batch: 85,Loss: -3.387,Avg.Loss: -3.656,LR: 8.33E-06]Training epoch 92:  76%|███████▌  | 85/112 [00:01<00:00, 52.93it/s, Epoch: 92, Batch: 86,Loss: -3.697,Avg.Loss: -3.657,LR: 8.31E-06]Training epoch 92:  77%|███████▋  | 86/112 [00:01<00:00, 53.10it/s, Epoch: 92, Batch: 86,Loss: -3.697,Avg.Loss: -3.657,LR: 8.31E-06]Training epoch 92:  77%|███████▋  | 86/112 [00:01<00:00, 53.10it/s, Epoch: 92, Batch: 87,Loss: -4.019,Avg.Loss: -3.661,LR: 8.30E-06]Training epoch 92:  78%|███████▊  | 87/112 [00:01<00:00, 53.10it/s, Epoch: 92, Batch: 88,Loss: -4.009,Avg.Loss: -3.665,LR: 8.28E-06]Training epoch 92:  79%|███████▊  | 88/112 [00:01<00:00, 53.10it/s, Epoch: 92, Batch: 89,Loss: -3.986,Avg.Loss: -3.668,LR: 8.26E-06]Training epoch 92:  79%|███████▉  | 89/112 [00:01<00:00, 53.10it/s, Epoch: 92, Batch: 90,Loss: -3.901,Avg.Loss: -3.671,LR: 8.24E-06]Training epoch 92:  80%|████████  | 90/112 [00:01<00:00, 53.10it/s, Epoch: 92, Batch: 91,Loss: -3.956,Avg.Loss: -3.674,LR: 8.22E-06]Training epoch 92:  81%|████████▏ | 91/112 [00:01<00:00, 53.10it/s, Epoch: 92, Batch: 92,Loss: -3.560,Avg.Loss: -3.673,LR: 8.21E-06]Training epoch 92:  82%|████████▏ | 92/112 [00:01<00:00, 53.28it/s, Epoch: 92, Batch: 92,Loss: -3.560,Avg.Loss: -3.673,LR: 8.21E-06]Training epoch 92:  82%|████████▏ | 92/112 [00:01<00:00, 53.28it/s, Epoch: 92, Batch: 93,Loss: -3.486,Avg.Loss: -3.671,LR: 8.19E-06]Training epoch 92:  83%|████████▎ | 93/112 [00:01<00:00, 53.28it/s, Epoch: 92, Batch: 94,Loss: -3.454,Avg.Loss: -3.669,LR: 8.17E-06]Training epoch 92:  84%|████████▍ | 94/112 [00:01<00:00, 53.28it/s, Epoch: 92, Batch: 95,Loss: -3.819,Avg.Loss: -3.670,LR: 8.15E-06]Training epoch 92:  85%|████████▍ | 95/112 [00:01<00:00, 53.28it/s, Epoch: 92, Batch: 96,Loss: -4.219,Avg.Loss: -3.676,LR: 8.14E-06]Training epoch 92:  86%|████████▌ | 96/112 [00:01<00:00, 53.28it/s, Epoch: 92, Batch: 97,Loss: -3.849,Avg.Loss: -3.678,LR: 8.12E-06]Training epoch 92:  87%|████████▋ | 97/112 [00:01<00:00, 53.28it/s, Epoch: 92, Batch: 98,Loss: -3.662,Avg.Loss: -3.677,LR: 8.10E-06]Training epoch 92:  88%|████████▊ | 98/112 [00:01<00:00, 53.38it/s, Epoch: 92, Batch: 98,Loss: -3.662,Avg.Loss: -3.677,LR: 8.10E-06]Training epoch 92:  88%|████████▊ | 98/112 [00:01<00:00, 53.38it/s, Epoch: 92, Batch: 99,Loss: -2.988,Avg.Loss: -3.671,LR: 8.08E-06]Training epoch 92:  88%|████████▊ | 99/112 [00:01<00:00, 53.38it/s, Epoch: 92, Batch: 100,Loss: -4.096,Avg.Loss: -3.675,LR: 8.06E-06]Training epoch 92:  89%|████████▉ | 100/112 [00:01<00:00, 53.38it/s, Epoch: 92, Batch: 101,Loss: -3.782,Avg.Loss: -3.676,LR: 8.05E-06]Training epoch 92:  90%|█████████ | 101/112 [00:01<00:00, 53.38it/s, Epoch: 92, Batch: 102,Loss: -3.628,Avg.Loss: -3.675,LR: 8.03E-06]Training epoch 92:  91%|█████████ | 102/112 [00:01<00:00, 53.38it/s, Epoch: 92, Batch: 103,Loss: -3.769,Avg.Loss: -3.676,LR: 8.01E-06]Training epoch 92:  92%|█████████▏| 103/112 [00:01<00:00, 53.38it/s, Epoch: 92, Batch: 104,Loss: -3.749,Avg.Loss: -3.677,LR: 7.99E-06]Training epoch 92:  93%|█████████▎| 104/112 [00:01<00:00, 53.56it/s, Epoch: 92, Batch: 104,Loss: -3.749,Avg.Loss: -3.677,LR: 7.99E-06]Training epoch 92:  93%|█████████▎| 104/112 [00:01<00:00, 53.56it/s, Epoch: 92, Batch: 105,Loss: -3.455,Avg.Loss: -3.675,LR: 7.98E-06]Training epoch 92:  94%|█████████▍| 105/112 [00:01<00:00, 53.56it/s, Epoch: 92, Batch: 106,Loss: -3.759,Avg.Loss: -3.676,LR: 7.96E-06]Training epoch 92:  95%|█████████▍| 106/112 [00:02<00:00, 53.56it/s, Epoch: 92, Batch: 107,Loss: -3.920,Avg.Loss: -3.678,LR: 7.94E-06]Training epoch 92:  96%|█████████▌| 107/112 [00:02<00:00, 53.56it/s, Epoch: 92, Batch: 108,Loss: -3.758,Avg.Loss: -3.679,LR: 7.92E-06]Training epoch 92:  96%|█████████▋| 108/112 [00:02<00:00, 53.56it/s, Epoch: 92, Batch: 109,Loss: -3.546,Avg.Loss: -3.677,LR: 7.91E-06]Training epoch 92:  97%|█████████▋| 109/112 [00:02<00:00, 53.56it/s, Epoch: 92, Batch: 110,Loss: -3.974,Avg.Loss: -3.680,LR: 7.89E-06]Training epoch 92:  98%|█████████▊| 110/112 [00:02<00:00, 53.64it/s, Epoch: 92, Batch: 110,Loss: -3.974,Avg.Loss: -3.680,LR: 7.89E-06]Training epoch 92:  98%|█████████▊| 110/112 [00:02<00:00, 53.64it/s, Epoch: 92, Batch: 111,Loss: -3.972,Avg.Loss: -3.683,LR: 7.87E-06]Training epoch 92:  99%|█████████▉| 111/112 [00:02<00:00, 53.64it/s, Epoch: 92, Batch: 112,Loss: -1.948,Avg.Loss: -3.667,LR: 7.85E-06]Training epoch 92: 100%|██████████| 112/112 [00:02<00:00, 53.27it/s, Epoch: 92, Batch: 112,Loss: -1.948,Avg.Loss: -3.667,LR: 7.85E-06]
Training epoch 93:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 93:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 93, Batch: 1,Loss: -3.538,Avg.Loss: -3.538,LR: 7.84E-06]Training epoch 93:   1%|          | 1/112 [00:00<00:04, 25.59it/s, Epoch: 93, Batch: 2,Loss: -3.776,Avg.Loss: -3.657,LR: 7.82E-06]Training epoch 93:   2%|▏         | 2/112 [00:00<00:02, 37.22it/s, Epoch: 93, Batch: 3,Loss: -3.631,Avg.Loss: -3.648,LR: 7.80E-06]Training epoch 93:   3%|▎         | 3/112 [00:00<00:02, 41.83it/s, Epoch: 93, Batch: 4,Loss: -3.309,Avg.Loss: -3.563,LR: 7.78E-06]Training epoch 93:   4%|▎         | 4/112 [00:00<00:02, 44.25it/s, Epoch: 93, Batch: 5,Loss: -3.867,Avg.Loss: -3.624,LR: 7.77E-06]Training epoch 93:   4%|▍         | 5/112 [00:00<00:02, 45.87it/s, Epoch: 93, Batch: 6,Loss: -3.897,Avg.Loss: -3.670,LR: 7.75E-06]Training epoch 93:   5%|▌         | 6/112 [00:00<00:01, 54.96it/s, Epoch: 93, Batch: 6,Loss: -3.897,Avg.Loss: -3.670,LR: 7.75E-06]Training epoch 93:   5%|▌         | 6/112 [00:00<00:01, 54.96it/s, Epoch: 93, Batch: 7,Loss: -3.349,Avg.Loss: -3.624,LR: 7.73E-06]Training epoch 93:   6%|▋         | 7/112 [00:00<00:01, 54.96it/s, Epoch: 93, Batch: 8,Loss: -3.161,Avg.Loss: -3.566,LR: 7.72E-06]Training epoch 93:   7%|▋         | 8/112 [00:00<00:01, 54.96it/s, Epoch: 93, Batch: 9,Loss: -3.230,Avg.Loss: -3.529,LR: 7.70E-06]Training epoch 93:   8%|▊         | 9/112 [00:00<00:01, 54.96it/s, Epoch: 93, Batch: 10,Loss: -3.914,Avg.Loss: -3.567,LR: 7.68E-06]Training epoch 93:   9%|▉         | 10/112 [00:00<00:01, 54.96it/s, Epoch: 93, Batch: 11,Loss: -3.646,Avg.Loss: -3.574,LR: 7.66E-06]Training epoch 93:  10%|▉         | 11/112 [00:00<00:01, 54.96it/s, Epoch: 93, Batch: 12,Loss: -3.710,Avg.Loss: -3.586,LR: 7.65E-06]Training epoch 93:  11%|█         | 12/112 [00:00<00:01, 52.89it/s, Epoch: 93, Batch: 12,Loss: -3.710,Avg.Loss: -3.586,LR: 7.65E-06]Training epoch 93:  11%|█         | 12/112 [00:00<00:01, 52.89it/s, Epoch: 93, Batch: 13,Loss: -3.678,Avg.Loss: -3.593,LR: 7.63E-06]Training epoch 93:  12%|█▏        | 13/112 [00:00<00:01, 52.89it/s, Epoch: 93, Batch: 14,Loss: -3.676,Avg.Loss: -3.599,LR: 7.61E-06]Training epoch 93:  12%|█▎        | 14/112 [00:00<00:01, 52.89it/s, Epoch: 93, Batch: 15,Loss: -3.495,Avg.Loss: -3.592,LR: 7.59E-06]Training epoch 93:  13%|█▎        | 15/112 [00:00<00:01, 52.89it/s, Epoch: 93, Batch: 16,Loss: -3.567,Avg.Loss: -3.590,LR: 7.58E-06]Training epoch 93:  14%|█▍        | 16/112 [00:00<00:01, 52.89it/s, Epoch: 93, Batch: 17,Loss: -4.106,Avg.Loss: -3.621,LR: 7.56E-06]Training epoch 93:  15%|█▌        | 17/112 [00:00<00:01, 52.89it/s, Epoch: 93, Batch: 18,Loss: -3.092,Avg.Loss: -3.591,LR: 7.54E-06]Training epoch 93:  16%|█▌        | 18/112 [00:00<00:01, 53.03it/s, Epoch: 93, Batch: 18,Loss: -3.092,Avg.Loss: -3.591,LR: 7.54E-06]Training epoch 93:  16%|█▌        | 18/112 [00:00<00:01, 53.03it/s, Epoch: 93, Batch: 19,Loss: -3.792,Avg.Loss: -3.602,LR: 7.53E-06]Training epoch 93:  17%|█▋        | 19/112 [00:00<00:01, 53.03it/s, Epoch: 93, Batch: 20,Loss: -4.007,Avg.Loss: -3.622,LR: 7.51E-06]Training epoch 93:  18%|█▊        | 20/112 [00:00<00:01, 53.03it/s, Epoch: 93, Batch: 21,Loss: -3.949,Avg.Loss: -3.638,LR: 7.49E-06]Training epoch 93:  19%|█▉        | 21/112 [00:00<00:01, 53.03it/s, Epoch: 93, Batch: 22,Loss: -4.183,Avg.Loss: -3.662,LR: 7.48E-06]Training epoch 93:  20%|█▉        | 22/112 [00:00<00:01, 53.03it/s, Epoch: 93, Batch: 23,Loss: -3.734,Avg.Loss: -3.665,LR: 7.46E-06]Training epoch 93:  21%|██        | 23/112 [00:00<00:01, 53.03it/s, Epoch: 93, Batch: 24,Loss: -3.499,Avg.Loss: -3.659,LR: 7.44E-06]Training epoch 93:  21%|██▏       | 24/112 [00:00<00:01, 52.65it/s, Epoch: 93, Batch: 24,Loss: -3.499,Avg.Loss: -3.659,LR: 7.44E-06]Training epoch 93:  21%|██▏       | 24/112 [00:00<00:01, 52.65it/s, Epoch: 93, Batch: 25,Loss: -3.880,Avg.Loss: -3.667,LR: 7.42E-06]Training epoch 93:  22%|██▏       | 25/112 [00:00<00:01, 52.65it/s, Epoch: 93, Batch: 26,Loss: -3.358,Avg.Loss: -3.655,LR: 7.41E-06]Training epoch 93:  23%|██▎       | 26/112 [00:00<00:01, 52.65it/s, Epoch: 93, Batch: 27,Loss: -3.443,Avg.Loss: -3.648,LR: 7.39E-06]Training epoch 93:  24%|██▍       | 27/112 [00:00<00:01, 52.65it/s, Epoch: 93, Batch: 28,Loss: -3.792,Avg.Loss: -3.653,LR: 7.37E-06]Training epoch 93:  25%|██▌       | 28/112 [00:00<00:01, 52.65it/s, Epoch: 93, Batch: 29,Loss: -3.936,Avg.Loss: -3.663,LR: 7.36E-06]Training epoch 93:  26%|██▌       | 29/112 [00:00<00:01, 52.65it/s, Epoch: 93, Batch: 30,Loss: -3.811,Avg.Loss: -3.667,LR: 7.34E-06]Training epoch 93:  27%|██▋       | 30/112 [00:00<00:01, 52.92it/s, Epoch: 93, Batch: 30,Loss: -3.811,Avg.Loss: -3.667,LR: 7.34E-06]Training epoch 93:  27%|██▋       | 30/112 [00:00<00:01, 52.92it/s, Epoch: 93, Batch: 31,Loss: -3.578,Avg.Loss: -3.665,LR: 7.32E-06]Training epoch 93:  28%|██▊       | 31/112 [00:00<00:01, 52.92it/s, Epoch: 93, Batch: 32,Loss: -3.697,Avg.Loss: -3.666,LR: 7.31E-06]Training epoch 93:  29%|██▊       | 32/112 [00:00<00:01, 52.92it/s, Epoch: 93, Batch: 33,Loss: -3.580,Avg.Loss: -3.663,LR: 7.29E-06]Training epoch 93:  29%|██▉       | 33/112 [00:00<00:01, 52.92it/s, Epoch: 93, Batch: 34,Loss: -3.250,Avg.Loss: -3.651,LR: 7.27E-06]Training epoch 93:  30%|███       | 34/112 [00:00<00:01, 52.92it/s, Epoch: 93, Batch: 35,Loss: -3.663,Avg.Loss: -3.651,LR: 7.26E-06]Training epoch 93:  31%|███▏      | 35/112 [00:00<00:01, 52.92it/s, Epoch: 93, Batch: 36,Loss: -3.866,Avg.Loss: -3.657,LR: 7.24E-06]Training epoch 93:  32%|███▏      | 36/112 [00:00<00:01, 52.99it/s, Epoch: 93, Batch: 36,Loss: -3.866,Avg.Loss: -3.657,LR: 7.24E-06]Training epoch 93:  32%|███▏      | 36/112 [00:00<00:01, 52.99it/s, Epoch: 93, Batch: 37,Loss: -3.980,Avg.Loss: -3.666,LR: 7.22E-06]Training epoch 93:  33%|███▎      | 37/112 [00:00<00:01, 52.99it/s, Epoch: 93, Batch: 38,Loss: -4.118,Avg.Loss: -3.678,LR: 7.21E-06]Training epoch 93:  34%|███▍      | 38/112 [00:00<00:01, 52.99it/s, Epoch: 93, Batch: 39,Loss: -3.608,Avg.Loss: -3.676,LR: 7.19E-06]Training epoch 93:  35%|███▍      | 39/112 [00:00<00:01, 52.99it/s, Epoch: 93, Batch: 40,Loss: -3.721,Avg.Loss: -3.677,LR: 7.17E-06]Training epoch 93:  36%|███▌      | 40/112 [00:00<00:01, 52.99it/s, Epoch: 93, Batch: 41,Loss: -3.538,Avg.Loss: -3.674,LR: 7.16E-06]Training epoch 93:  37%|███▋      | 41/112 [00:00<00:01, 52.99it/s, Epoch: 93, Batch: 42,Loss: -3.687,Avg.Loss: -3.674,LR: 7.14E-06]Training epoch 93:  38%|███▊      | 42/112 [00:00<00:01, 52.94it/s, Epoch: 93, Batch: 42,Loss: -3.687,Avg.Loss: -3.674,LR: 7.14E-06]Training epoch 93:  38%|███▊      | 42/112 [00:00<00:01, 52.94it/s, Epoch: 93, Batch: 43,Loss: -3.440,Avg.Loss: -3.669,LR: 7.12E-06]Training epoch 93:  38%|███▊      | 43/112 [00:00<00:01, 52.94it/s, Epoch: 93, Batch: 44,Loss: -3.965,Avg.Loss: -3.675,LR: 7.11E-06]Training epoch 93:  39%|███▉      | 44/112 [00:00<00:01, 52.94it/s, Epoch: 93, Batch: 45,Loss: -4.157,Avg.Loss: -3.686,LR: 7.09E-06]Training epoch 93:  40%|████      | 45/112 [00:00<00:01, 52.94it/s, Epoch: 93, Batch: 46,Loss: -3.929,Avg.Loss: -3.691,LR: 7.07E-06]Training epoch 93:  41%|████      | 46/112 [00:00<00:01, 52.94it/s, Epoch: 93, Batch: 47,Loss: -3.996,Avg.Loss: -3.698,LR: 7.06E-06]Training epoch 93:  42%|████▏     | 47/112 [00:00<00:01, 52.94it/s, Epoch: 93, Batch: 48,Loss: -3.670,Avg.Loss: -3.697,LR: 7.04E-06]Training epoch 93:  43%|████▎     | 48/112 [00:00<00:01, 52.97it/s, Epoch: 93, Batch: 48,Loss: -3.670,Avg.Loss: -3.697,LR: 7.04E-06]Training epoch 93:  43%|████▎     | 48/112 [00:00<00:01, 52.97it/s, Epoch: 93, Batch: 49,Loss: -3.903,Avg.Loss: -3.701,LR: 7.02E-06]Training epoch 93:  44%|████▍     | 49/112 [00:00<00:01, 52.97it/s, Epoch: 93, Batch: 50,Loss: -3.754,Avg.Loss: -3.703,LR: 7.01E-06]Training epoch 93:  45%|████▍     | 50/112 [00:00<00:01, 52.97it/s, Epoch: 93, Batch: 51,Loss: -3.539,Avg.Loss: -3.699,LR: 6.99E-06]Training epoch 93:  46%|████▌     | 51/112 [00:00<00:01, 52.97it/s, Epoch: 93, Batch: 52,Loss: -3.723,Avg.Loss: -3.700,LR: 6.97E-06]Training epoch 93:  46%|████▋     | 52/112 [00:01<00:01, 52.97it/s, Epoch: 93, Batch: 53,Loss: -3.332,Avg.Loss: -3.693,LR: 6.96E-06]Training epoch 93:  47%|████▋     | 53/112 [00:01<00:01, 52.97it/s, Epoch: 93, Batch: 54,Loss: -3.454,Avg.Loss: -3.688,LR: 6.94E-06]Training epoch 93:  48%|████▊     | 54/112 [00:01<00:01, 52.93it/s, Epoch: 93, Batch: 54,Loss: -3.454,Avg.Loss: -3.688,LR: 6.94E-06]Training epoch 93:  48%|████▊     | 54/112 [00:01<00:01, 52.93it/s, Epoch: 93, Batch: 55,Loss: -3.796,Avg.Loss: -3.690,LR: 6.92E-06]Training epoch 93:  49%|████▉     | 55/112 [00:01<00:01, 52.93it/s, Epoch: 93, Batch: 56,Loss: -3.695,Avg.Loss: -3.690,LR: 6.91E-06]Training epoch 93:  50%|█████     | 56/112 [00:01<00:01, 52.93it/s, Epoch: 93, Batch: 57,Loss: -3.827,Avg.Loss: -3.693,LR: 6.89E-06]Training epoch 93:  51%|█████     | 57/112 [00:01<00:01, 52.93it/s, Epoch: 93, Batch: 58,Loss: -3.742,Avg.Loss: -3.694,LR: 6.87E-06]Training epoch 93:  52%|█████▏    | 58/112 [00:01<00:01, 52.93it/s, Epoch: 93, Batch: 59,Loss: -3.789,Avg.Loss: -3.695,LR: 6.86E-06]Training epoch 93:  53%|█████▎    | 59/112 [00:01<00:01, 52.93it/s, Epoch: 93, Batch: 60,Loss: -3.997,Avg.Loss: -3.700,LR: 6.84E-06]Training epoch 93:  54%|█████▎    | 60/112 [00:01<00:00, 53.03it/s, Epoch: 93, Batch: 60,Loss: -3.997,Avg.Loss: -3.700,LR: 6.84E-06]Training epoch 93:  54%|█████▎    | 60/112 [00:01<00:00, 53.03it/s, Epoch: 93, Batch: 61,Loss: -3.451,Avg.Loss: -3.696,LR: 6.83E-06]Training epoch 93:  54%|█████▍    | 61/112 [00:01<00:00, 53.03it/s, Epoch: 93, Batch: 62,Loss: -3.691,Avg.Loss: -3.696,LR: 6.81E-06]Training epoch 93:  55%|█████▌    | 62/112 [00:01<00:00, 53.03it/s, Epoch: 93, Batch: 63,Loss: -3.536,Avg.Loss: -3.694,LR: 6.79E-06]Training epoch 93:  56%|█████▋    | 63/112 [00:01<00:00, 53.03it/s, Epoch: 93, Batch: 64,Loss: -3.780,Avg.Loss: -3.695,LR: 6.78E-06]Training epoch 93:  57%|█████▋    | 64/112 [00:01<00:00, 53.03it/s, Epoch: 93, Batch: 65,Loss: -3.582,Avg.Loss: -3.693,LR: 6.76E-06]Training epoch 93:  58%|█████▊    | 65/112 [00:01<00:00, 53.03it/s, Epoch: 93, Batch: 66,Loss: -3.585,Avg.Loss: -3.692,LR: 6.74E-06]Training epoch 93:  59%|█████▉    | 66/112 [00:01<00:00, 52.97it/s, Epoch: 93, Batch: 66,Loss: -3.585,Avg.Loss: -3.692,LR: 6.74E-06]Training epoch 93:  59%|█████▉    | 66/112 [00:01<00:00, 52.97it/s, Epoch: 93, Batch: 67,Loss: -3.734,Avg.Loss: -3.692,LR: 6.73E-06]Training epoch 93:  60%|█████▉    | 67/112 [00:01<00:00, 52.97it/s, Epoch: 93, Batch: 68,Loss: -3.748,Avg.Loss: -3.693,LR: 6.71E-06]Training epoch 93:  61%|██████    | 68/112 [00:01<00:00, 52.97it/s, Epoch: 93, Batch: 69,Loss: -3.890,Avg.Loss: -3.696,LR: 6.70E-06]Training epoch 93:  62%|██████▏   | 69/112 [00:01<00:00, 52.97it/s, Epoch: 93, Batch: 70,Loss: -3.650,Avg.Loss: -3.695,LR: 6.68E-06]Training epoch 93:  62%|██████▎   | 70/112 [00:01<00:00, 52.97it/s, Epoch: 93, Batch: 71,Loss: -3.685,Avg.Loss: -3.695,LR: 6.66E-06]Training epoch 93:  63%|██████▎   | 71/112 [00:01<00:00, 52.97it/s, Epoch: 93, Batch: 72,Loss: -4.111,Avg.Loss: -3.701,LR: 6.65E-06]Training epoch 93:  64%|██████▍   | 72/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 72,Loss: -4.111,Avg.Loss: -3.701,LR: 6.65E-06]Training epoch 93:  64%|██████▍   | 72/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 73,Loss: -3.950,Avg.Loss: -3.704,LR: 6.63E-06]Training epoch 93:  65%|██████▌   | 73/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 74,Loss: -3.730,Avg.Loss: -3.705,LR: 6.62E-06]Training epoch 93:  66%|██████▌   | 74/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 75,Loss: -3.728,Avg.Loss: -3.705,LR: 6.60E-06]Training epoch 93:  67%|██████▋   | 75/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 76,Loss: -3.581,Avg.Loss: -3.703,LR: 6.58E-06]Training epoch 93:  68%|██████▊   | 76/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 77,Loss: -4.000,Avg.Loss: -3.707,LR: 6.57E-06]Training epoch 93:  69%|██████▉   | 77/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 78,Loss: -3.718,Avg.Loss: -3.707,LR: 6.55E-06]Training epoch 93:  70%|██████▉   | 78/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 78,Loss: -3.718,Avg.Loss: -3.707,LR: 6.55E-06]Training epoch 93:  70%|██████▉   | 78/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 79,Loss: -3.524,Avg.Loss: -3.705,LR: 6.54E-06]Training epoch 93:  71%|███████   | 79/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 80,Loss: -3.798,Avg.Loss: -3.706,LR: 6.52E-06]Training epoch 93:  71%|███████▏  | 80/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 81,Loss: -3.468,Avg.Loss: -3.703,LR: 6.50E-06]Training epoch 93:  72%|███████▏  | 81/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 82,Loss: -3.675,Avg.Loss: -3.703,LR: 6.49E-06]Training epoch 93:  73%|███████▎  | 82/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 83,Loss: -3.495,Avg.Loss: -3.700,LR: 6.47E-06]Training epoch 93:  74%|███████▍  | 83/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 84,Loss: -3.938,Avg.Loss: -3.703,LR: 6.46E-06]Training epoch 93:  75%|███████▌  | 84/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 84,Loss: -3.938,Avg.Loss: -3.703,LR: 6.46E-06]Training epoch 93:  75%|███████▌  | 84/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 85,Loss: -3.927,Avg.Loss: -3.706,LR: 6.44E-06]Training epoch 93:  76%|███████▌  | 85/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 86,Loss: -3.636,Avg.Loss: -3.705,LR: 6.43E-06]Training epoch 93:  77%|███████▋  | 86/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 87,Loss: -3.453,Avg.Loss: -3.702,LR: 6.41E-06]Training epoch 93:  78%|███████▊  | 87/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 88,Loss: -3.159,Avg.Loss: -3.696,LR: 6.39E-06]Training epoch 93:  79%|███████▊  | 88/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 89,Loss: -3.212,Avg.Loss: -3.690,LR: 6.38E-06]Training epoch 93:  79%|███████▉  | 89/112 [00:01<00:00, 52.98it/s, Epoch: 93, Batch: 90,Loss: -3.471,Avg.Loss: -3.688,LR: 6.36E-06]Training epoch 93:  80%|████████  | 90/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 90,Loss: -3.471,Avg.Loss: -3.688,LR: 6.36E-06]Training epoch 93:  80%|████████  | 90/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 91,Loss: -3.888,Avg.Loss: -3.690,LR: 6.35E-06]Training epoch 93:  81%|████████▏ | 91/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 92,Loss: -3.759,Avg.Loss: -3.691,LR: 6.33E-06]Training epoch 93:  82%|████████▏ | 92/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 93,Loss: -3.548,Avg.Loss: -3.689,LR: 6.31E-06]Training epoch 93:  83%|████████▎ | 93/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 94,Loss: -3.907,Avg.Loss: -3.692,LR: 6.30E-06]Training epoch 93:  84%|████████▍ | 94/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 95,Loss: -3.730,Avg.Loss: -3.692,LR: 6.28E-06]Training epoch 93:  85%|████████▍ | 95/112 [00:01<00:00, 53.00it/s, Epoch: 93, Batch: 96,Loss: -3.943,Avg.Loss: -3.695,LR: 6.27E-06]Training epoch 93:  86%|████████▌ | 96/112 [00:01<00:00, 52.99it/s, Epoch: 93, Batch: 96,Loss: -3.943,Avg.Loss: -3.695,LR: 6.27E-06]Training epoch 93:  86%|████████▌ | 96/112 [00:01<00:00, 52.99it/s, Epoch: 93, Batch: 97,Loss: -3.362,Avg.Loss: -3.691,LR: 6.25E-06]Training epoch 93:  87%|████████▋ | 97/112 [00:01<00:00, 52.99it/s, Epoch: 93, Batch: 98,Loss: -3.816,Avg.Loss: -3.693,LR: 6.24E-06]Training epoch 93:  88%|████████▊ | 98/112 [00:01<00:00, 52.99it/s, Epoch: 93, Batch: 99,Loss: -3.538,Avg.Loss: -3.691,LR: 6.22E-06]Training epoch 93:  88%|████████▊ | 99/112 [00:01<00:00, 52.99it/s, Epoch: 93, Batch: 100,Loss: -3.868,Avg.Loss: -3.693,LR: 6.21E-06]Training epoch 93:  89%|████████▉ | 100/112 [00:01<00:00, 52.99it/s, Epoch: 93, Batch: 101,Loss: -3.985,Avg.Loss: -3.696,LR: 6.19E-06]Training epoch 93:  90%|█████████ | 101/112 [00:01<00:00, 52.99it/s, Epoch: 93, Batch: 102,Loss: -3.987,Avg.Loss: -3.699,LR: 6.17E-06]Training epoch 93:  91%|█████████ | 102/112 [00:01<00:00, 53.11it/s, Epoch: 93, Batch: 102,Loss: -3.987,Avg.Loss: -3.699,LR: 6.17E-06]Training epoch 93:  91%|█████████ | 102/112 [00:01<00:00, 53.11it/s, Epoch: 93, Batch: 103,Loss: -3.660,Avg.Loss: -3.698,LR: 6.16E-06]Training epoch 93:  92%|█████████▏| 103/112 [00:01<00:00, 53.11it/s, Epoch: 93, Batch: 104,Loss: -3.855,Avg.Loss: -3.700,LR: 6.14E-06]Training epoch 93:  93%|█████████▎| 104/112 [00:01<00:00, 53.11it/s, Epoch: 93, Batch: 105,Loss: -3.720,Avg.Loss: -3.700,LR: 6.13E-06]Training epoch 93:  94%|█████████▍| 105/112 [00:01<00:00, 53.11it/s, Epoch: 93, Batch: 106,Loss: -3.808,Avg.Loss: -3.701,LR: 6.11E-06]Training epoch 93:  95%|█████████▍| 106/112 [00:02<00:00, 53.11it/s, Epoch: 93, Batch: 107,Loss: -3.718,Avg.Loss: -3.701,LR: 6.10E-06]Training epoch 93:  96%|█████████▌| 107/112 [00:02<00:00, 53.11it/s, Epoch: 93, Batch: 108,Loss: -3.797,Avg.Loss: -3.702,LR: 6.08E-06]Training epoch 93:  96%|█████████▋| 108/112 [00:02<00:00, 53.11it/s, Epoch: 93, Batch: 108,Loss: -3.797,Avg.Loss: -3.702,LR: 6.08E-06]Training epoch 93:  96%|█████████▋| 108/112 [00:02<00:00, 53.11it/s, Epoch: 93, Batch: 109,Loss: -3.751,Avg.Loss: -3.702,LR: 6.07E-06]Training epoch 93:  97%|█████████▋| 109/112 [00:02<00:00, 53.11it/s, Epoch: 93, Batch: 110,Loss: -3.217,Avg.Loss: -3.698,LR: 6.05E-06]Training epoch 93:  98%|█████████▊| 110/112 [00:02<00:00, 53.11it/s, Epoch: 93, Batch: 111,Loss: -3.798,Avg.Loss: -3.699,LR: 6.04E-06]Training epoch 93:  99%|█████████▉| 111/112 [00:02<00:00, 53.11it/s, Epoch: 93, Batch: 112,Loss: -3.637,Avg.Loss: -3.698,LR: 6.02E-06]Training epoch 93: 100%|██████████| 112/112 [00:02<00:00, 52.97it/s, Epoch: 93, Batch: 112,Loss: -3.637,Avg.Loss: -3.698,LR: 6.02E-06]
Training epoch 94:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 94:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 94, Batch: 1,Loss: -3.917,Avg.Loss: -3.917,LR: 6.01E-06]Training epoch 94:   1%|          | 1/112 [00:00<00:04, 25.62it/s, Epoch: 94, Batch: 2,Loss: -3.792,Avg.Loss: -3.854,LR: 5.99E-06]Training epoch 94:   2%|▏         | 2/112 [00:00<00:02, 37.47it/s, Epoch: 94, Batch: 3,Loss: -3.571,Avg.Loss: -3.760,LR: 5.97E-06]Training epoch 94:   3%|▎         | 3/112 [00:00<00:02, 43.14it/s, Epoch: 94, Batch: 4,Loss: -3.523,Avg.Loss: -3.701,LR: 5.96E-06]Training epoch 94:   4%|▎         | 4/112 [00:00<00:02, 45.04it/s, Epoch: 94, Batch: 5,Loss: -3.664,Avg.Loss: -3.693,LR: 5.94E-06]Training epoch 94:   4%|▍         | 5/112 [00:00<00:02, 46.39it/s, Epoch: 94, Batch: 6,Loss: -3.804,Avg.Loss: -3.712,LR: 5.93E-06]Training epoch 94:   5%|▌         | 6/112 [00:00<00:01, 55.56it/s, Epoch: 94, Batch: 6,Loss: -3.804,Avg.Loss: -3.712,LR: 5.93E-06]Training epoch 94:   5%|▌         | 6/112 [00:00<00:01, 55.56it/s, Epoch: 94, Batch: 7,Loss: -3.945,Avg.Loss: -3.745,LR: 5.91E-06]Training epoch 94:   6%|▋         | 7/112 [00:00<00:01, 55.56it/s, Epoch: 94, Batch: 8,Loss: -3.842,Avg.Loss: -3.757,LR: 5.90E-06]Training epoch 94:   7%|▋         | 8/112 [00:00<00:01, 55.56it/s, Epoch: 94, Batch: 9,Loss: -3.948,Avg.Loss: -3.778,LR: 5.88E-06]Training epoch 94:   8%|▊         | 9/112 [00:00<00:01, 55.56it/s, Epoch: 94, Batch: 10,Loss: -3.660,Avg.Loss: -3.767,LR: 5.87E-06]Training epoch 94:   9%|▉         | 10/112 [00:00<00:01, 55.56it/s, Epoch: 94, Batch: 11,Loss: -3.778,Avg.Loss: -3.768,LR: 5.85E-06]Training epoch 94:  10%|▉         | 11/112 [00:00<00:01, 55.56it/s, Epoch: 94, Batch: 12,Loss: -3.621,Avg.Loss: -3.755,LR: 5.84E-06]Training epoch 94:  11%|█         | 12/112 [00:00<00:01, 53.76it/s, Epoch: 94, Batch: 12,Loss: -3.621,Avg.Loss: -3.755,LR: 5.84E-06]Training epoch 94:  11%|█         | 12/112 [00:00<00:01, 53.76it/s, Epoch: 94, Batch: 13,Loss: -3.428,Avg.Loss: -3.730,LR: 5.82E-06]Training epoch 94:  12%|█▏        | 13/112 [00:00<00:01, 53.76it/s, Epoch: 94, Batch: 14,Loss: -3.835,Avg.Loss: -3.738,LR: 5.81E-06]Training epoch 94:  12%|█▎        | 14/112 [00:00<00:01, 53.76it/s, Epoch: 94, Batch: 15,Loss: -4.002,Avg.Loss: -3.755,LR: 5.79E-06]Training epoch 94:  13%|█▎        | 15/112 [00:00<00:01, 53.76it/s, Epoch: 94, Batch: 16,Loss: -3.616,Avg.Loss: -3.747,LR: 5.78E-06]Training epoch 94:  14%|█▍        | 16/112 [00:00<00:01, 53.76it/s, Epoch: 94, Batch: 17,Loss: -3.218,Avg.Loss: -3.715,LR: 5.76E-06]Training epoch 94:  15%|█▌        | 17/112 [00:00<00:01, 53.76it/s, Epoch: 94, Batch: 18,Loss: -3.607,Avg.Loss: -3.709,LR: 5.75E-06]Training epoch 94:  16%|█▌        | 18/112 [00:00<00:01, 53.38it/s, Epoch: 94, Batch: 18,Loss: -3.607,Avg.Loss: -3.709,LR: 5.75E-06]Training epoch 94:  16%|█▌        | 18/112 [00:00<00:01, 53.38it/s, Epoch: 94, Batch: 19,Loss: -3.727,Avg.Loss: -3.710,LR: 5.73E-06]Training epoch 94:  17%|█▋        | 19/112 [00:00<00:01, 53.38it/s, Epoch: 94, Batch: 20,Loss: -3.548,Avg.Loss: -3.702,LR: 5.72E-06]Training epoch 94:  18%|█▊        | 20/112 [00:00<00:01, 53.38it/s, Epoch: 94, Batch: 21,Loss: -3.838,Avg.Loss: -3.709,LR: 5.70E-06]Training epoch 94:  19%|█▉        | 21/112 [00:00<00:01, 53.38it/s, Epoch: 94, Batch: 22,Loss: -3.911,Avg.Loss: -3.718,LR: 5.69E-06]Training epoch 94:  20%|█▉        | 22/112 [00:00<00:01, 53.38it/s, Epoch: 94, Batch: 23,Loss: -3.818,Avg.Loss: -3.722,LR: 5.67E-06]Training epoch 94:  21%|██        | 23/112 [00:00<00:01, 53.38it/s, Epoch: 94, Batch: 24,Loss: -4.036,Avg.Loss: -3.735,LR: 5.66E-06]Training epoch 94:  21%|██▏       | 24/112 [00:00<00:01, 52.55it/s, Epoch: 94, Batch: 24,Loss: -4.036,Avg.Loss: -3.735,LR: 5.66E-06]Training epoch 94:  21%|██▏       | 24/112 [00:00<00:01, 52.55it/s, Epoch: 94, Batch: 25,Loss: -3.336,Avg.Loss: -3.719,LR: 5.64E-06]Training epoch 94:  22%|██▏       | 25/112 [00:00<00:01, 52.55it/s, Epoch: 94, Batch: 26,Loss: -4.099,Avg.Loss: -3.734,LR: 5.63E-06]Training epoch 94:  23%|██▎       | 26/112 [00:00<00:01, 52.55it/s, Epoch: 94, Batch: 27,Loss: -4.066,Avg.Loss: -3.746,LR: 5.61E-06]Training epoch 94:  24%|██▍       | 27/112 [00:00<00:01, 52.55it/s, Epoch: 94, Batch: 28,Loss: -3.739,Avg.Loss: -3.746,LR: 5.60E-06]Training epoch 94:  25%|██▌       | 28/112 [00:00<00:01, 52.55it/s, Epoch: 94, Batch: 29,Loss: -3.540,Avg.Loss: -3.739,LR: 5.59E-06]Training epoch 94:  26%|██▌       | 29/112 [00:00<00:01, 52.55it/s, Epoch: 94, Batch: 30,Loss: -3.434,Avg.Loss: -3.729,LR: 5.57E-06]Training epoch 94:  27%|██▋       | 30/112 [00:00<00:01, 52.46it/s, Epoch: 94, Batch: 30,Loss: -3.434,Avg.Loss: -3.729,LR: 5.57E-06]Training epoch 94:  27%|██▋       | 30/112 [00:00<00:01, 52.46it/s, Epoch: 94, Batch: 31,Loss: -4.001,Avg.Loss: -3.737,LR: 5.56E-06]Training epoch 94:  28%|██▊       | 31/112 [00:00<00:01, 52.46it/s, Epoch: 94, Batch: 32,Loss: -3.576,Avg.Loss: -3.732,LR: 5.54E-06]Training epoch 94:  29%|██▊       | 32/112 [00:00<00:01, 52.46it/s, Epoch: 94, Batch: 33,Loss: -3.866,Avg.Loss: -3.737,LR: 5.53E-06]Training epoch 94:  29%|██▉       | 33/112 [00:00<00:01, 52.46it/s, Epoch: 94, Batch: 34,Loss: -3.820,Avg.Loss: -3.739,LR: 5.51E-06]Training epoch 94:  30%|███       | 34/112 [00:00<00:01, 52.46it/s, Epoch: 94, Batch: 35,Loss: -3.667,Avg.Loss: -3.737,LR: 5.50E-06]Training epoch 94:  31%|███▏      | 35/112 [00:00<00:01, 52.46it/s, Epoch: 94, Batch: 36,Loss: -3.845,Avg.Loss: -3.740,LR: 5.48E-06]Training epoch 94:  32%|███▏      | 36/112 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 36,Loss: -3.845,Avg.Loss: -3.740,LR: 5.48E-06]Training epoch 94:  32%|███▏      | 36/112 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 37,Loss: -3.822,Avg.Loss: -3.742,LR: 5.47E-06]Training epoch 94:  33%|███▎      | 37/112 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 38,Loss: -3.608,Avg.Loss: -3.739,LR: 5.45E-06]Training epoch 94:  34%|███▍      | 38/112 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 39,Loss: -3.615,Avg.Loss: -3.735,LR: 5.44E-06]Training epoch 94:  35%|███▍      | 39/112 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 40,Loss: -3.706,Avg.Loss: -3.735,LR: 5.42E-06]Training epoch 94:  36%|███▌      | 40/112 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 41,Loss: -3.736,Avg.Loss: -3.735,LR: 5.41E-06]Training epoch 94:  37%|███▋      | 41/112 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 42,Loss: -4.021,Avg.Loss: -3.742,LR: 5.40E-06]Training epoch 94:  38%|███▊      | 42/112 [00:00<00:01, 52.74it/s, Epoch: 94, Batch: 42,Loss: -4.021,Avg.Loss: -3.742,LR: 5.40E-06]Training epoch 94:  38%|███▊      | 42/112 [00:00<00:01, 52.74it/s, Epoch: 94, Batch: 43,Loss: -3.493,Avg.Loss: -3.736,LR: 5.38E-06]Training epoch 94:  38%|███▊      | 43/112 [00:00<00:01, 52.74it/s, Epoch: 94, Batch: 44,Loss: -3.754,Avg.Loss: -3.736,LR: 5.37E-06]Training epoch 94:  39%|███▉      | 44/112 [00:00<00:01, 52.74it/s, Epoch: 94, Batch: 45,Loss: -3.697,Avg.Loss: -3.735,LR: 5.35E-06]Training epoch 94:  40%|████      | 45/112 [00:00<00:01, 52.74it/s, Epoch: 94, Batch: 46,Loss: -3.995,Avg.Loss: -3.741,LR: 5.34E-06]Training epoch 94:  41%|████      | 46/112 [00:00<00:01, 52.74it/s, Epoch: 94, Batch: 47,Loss: -3.656,Avg.Loss: -3.739,LR: 5.32E-06]Training epoch 94:  42%|████▏     | 47/112 [00:00<00:01, 52.74it/s, Epoch: 94, Batch: 48,Loss: -3.803,Avg.Loss: -3.740,LR: 5.31E-06]Training epoch 94:  43%|████▎     | 48/112 [00:00<00:01, 52.90it/s, Epoch: 94, Batch: 48,Loss: -3.803,Avg.Loss: -3.740,LR: 5.31E-06]Training epoch 94:  43%|████▎     | 48/112 [00:00<00:01, 52.90it/s, Epoch: 94, Batch: 49,Loss: -3.864,Avg.Loss: -3.743,LR: 5.29E-06]Training epoch 94:  44%|████▍     | 49/112 [00:00<00:01, 52.90it/s, Epoch: 94, Batch: 50,Loss: -3.764,Avg.Loss: -3.743,LR: 5.28E-06]Training epoch 94:  45%|████▍     | 50/112 [00:00<00:01, 52.90it/s, Epoch: 94, Batch: 51,Loss: -3.837,Avg.Loss: -3.745,LR: 5.27E-06]Training epoch 94:  46%|████▌     | 51/112 [00:00<00:01, 52.90it/s, Epoch: 94, Batch: 52,Loss: -4.138,Avg.Loss: -3.753,LR: 5.25E-06]Training epoch 94:  46%|████▋     | 52/112 [00:00<00:01, 52.90it/s, Epoch: 94, Batch: 53,Loss: -4.010,Avg.Loss: -3.758,LR: 5.24E-06]Training epoch 94:  47%|████▋     | 53/112 [00:01<00:01, 52.90it/s, Epoch: 94, Batch: 54,Loss: -3.860,Avg.Loss: -3.760,LR: 5.22E-06]Training epoch 94:  48%|████▊     | 54/112 [00:01<00:01, 53.09it/s, Epoch: 94, Batch: 54,Loss: -3.860,Avg.Loss: -3.760,LR: 5.22E-06]Training epoch 94:  48%|████▊     | 54/112 [00:01<00:01, 53.09it/s, Epoch: 94, Batch: 55,Loss: -3.367,Avg.Loss: -3.752,LR: 5.21E-06]Training epoch 94:  49%|████▉     | 55/112 [00:01<00:01, 53.09it/s, Epoch: 94, Batch: 56,Loss: -3.950,Avg.Loss: -3.756,LR: 5.19E-06]Training epoch 94:  50%|█████     | 56/112 [00:01<00:01, 53.09it/s, Epoch: 94, Batch: 57,Loss: -3.715,Avg.Loss: -3.755,LR: 5.18E-06]Training epoch 94:  51%|█████     | 57/112 [00:01<00:01, 53.09it/s, Epoch: 94, Batch: 58,Loss: -3.513,Avg.Loss: -3.751,LR: 5.17E-06]Training epoch 94:  52%|█████▏    | 58/112 [00:01<00:01, 53.09it/s, Epoch: 94, Batch: 59,Loss: -3.852,Avg.Loss: -3.753,LR: 5.15E-06]Training epoch 94:  53%|█████▎    | 59/112 [00:01<00:00, 53.09it/s, Epoch: 94, Batch: 60,Loss: -3.859,Avg.Loss: -3.755,LR: 5.14E-06]Training epoch 94:  54%|█████▎    | 60/112 [00:01<00:00, 53.10it/s, Epoch: 94, Batch: 60,Loss: -3.859,Avg.Loss: -3.755,LR: 5.14E-06]Training epoch 94:  54%|█████▎    | 60/112 [00:01<00:00, 53.10it/s, Epoch: 94, Batch: 61,Loss: -3.809,Avg.Loss: -3.755,LR: 5.12E-06]Training epoch 94:  54%|█████▍    | 61/112 [00:01<00:00, 53.10it/s, Epoch: 94, Batch: 62,Loss: -3.273,Avg.Loss: -3.748,LR: 5.11E-06]Training epoch 94:  55%|█████▌    | 62/112 [00:01<00:00, 53.10it/s, Epoch: 94, Batch: 63,Loss: -3.529,Avg.Loss: -3.744,LR: 5.10E-06]Training epoch 94:  56%|█████▋    | 63/112 [00:01<00:00, 53.10it/s, Epoch: 94, Batch: 64,Loss: -3.587,Avg.Loss: -3.742,LR: 5.08E-06]Training epoch 94:  57%|█████▋    | 64/112 [00:01<00:00, 53.10it/s, Epoch: 94, Batch: 65,Loss: -3.316,Avg.Loss: -3.735,LR: 5.07E-06]Training epoch 94:  58%|█████▊    | 65/112 [00:01<00:00, 53.10it/s, Epoch: 94, Batch: 66,Loss: -3.634,Avg.Loss: -3.734,LR: 5.05E-06]Training epoch 94:  59%|█████▉    | 66/112 [00:01<00:00, 53.22it/s, Epoch: 94, Batch: 66,Loss: -3.634,Avg.Loss: -3.734,LR: 5.05E-06]Training epoch 94:  59%|█████▉    | 66/112 [00:01<00:00, 53.22it/s, Epoch: 94, Batch: 67,Loss: -3.872,Avg.Loss: -3.736,LR: 5.04E-06]Training epoch 94:  60%|█████▉    | 67/112 [00:01<00:00, 53.22it/s, Epoch: 94, Batch: 68,Loss: -3.824,Avg.Loss: -3.737,LR: 5.03E-06]Training epoch 94:  61%|██████    | 68/112 [00:01<00:00, 53.22it/s, Epoch: 94, Batch: 69,Loss: -3.970,Avg.Loss: -3.740,LR: 5.01E-06]Training epoch 94:  62%|██████▏   | 69/112 [00:01<00:00, 53.22it/s, Epoch: 94, Batch: 70,Loss: -3.295,Avg.Loss: -3.734,LR: 5.00E-06]Training epoch 94:  62%|██████▎   | 70/112 [00:01<00:00, 53.22it/s, Epoch: 94, Batch: 71,Loss: -3.680,Avg.Loss: -3.733,LR: 4.98E-06]Training epoch 94:  63%|██████▎   | 71/112 [00:01<00:00, 53.22it/s, Epoch: 94, Batch: 72,Loss: -3.674,Avg.Loss: -3.732,LR: 4.97E-06]Training epoch 94:  64%|██████▍   | 72/112 [00:01<00:00, 53.21it/s, Epoch: 94, Batch: 72,Loss: -3.674,Avg.Loss: -3.732,LR: 4.97E-06]Training epoch 94:  64%|██████▍   | 72/112 [00:01<00:00, 53.21it/s, Epoch: 94, Batch: 73,Loss: -3.617,Avg.Loss: -3.731,LR: 4.96E-06]Training epoch 94:  65%|██████▌   | 73/112 [00:01<00:00, 53.21it/s, Epoch: 94, Batch: 74,Loss: -3.969,Avg.Loss: -3.734,LR: 4.94E-06]Training epoch 94:  66%|██████▌   | 74/112 [00:01<00:00, 53.21it/s, Epoch: 94, Batch: 75,Loss: -3.964,Avg.Loss: -3.737,LR: 4.93E-06]Training epoch 94:  67%|██████▋   | 75/112 [00:01<00:00, 53.21it/s, Epoch: 94, Batch: 76,Loss: -4.031,Avg.Loss: -3.741,LR: 4.91E-06]Training epoch 94:  68%|██████▊   | 76/112 [00:01<00:00, 53.21it/s, Epoch: 94, Batch: 77,Loss: -3.705,Avg.Loss: -3.741,LR: 4.90E-06]Training epoch 94:  69%|██████▉   | 77/112 [00:01<00:00, 53.21it/s, Epoch: 94, Batch: 78,Loss: -4.152,Avg.Loss: -3.746,LR: 4.89E-06]Training epoch 94:  70%|██████▉   | 78/112 [00:01<00:00, 53.17it/s, Epoch: 94, Batch: 78,Loss: -4.152,Avg.Loss: -3.746,LR: 4.89E-06]Training epoch 94:  70%|██████▉   | 78/112 [00:01<00:00, 53.17it/s, Epoch: 94, Batch: 79,Loss: -3.148,Avg.Loss: -3.738,LR: 4.87E-06]Training epoch 94:  71%|███████   | 79/112 [00:01<00:00, 53.17it/s, Epoch: 94, Batch: 80,Loss: -3.295,Avg.Loss: -3.733,LR: 4.86E-06]Training epoch 94:  71%|███████▏  | 80/112 [00:01<00:00, 53.17it/s, Epoch: 94, Batch: 81,Loss: -3.556,Avg.Loss: -3.731,LR: 4.84E-06]Training epoch 94:  72%|███████▏  | 81/112 [00:01<00:00, 53.17it/s, Epoch: 94, Batch: 82,Loss: -3.541,Avg.Loss: -3.728,LR: 4.83E-06]Training epoch 94:  73%|███████▎  | 82/112 [00:01<00:00, 53.17it/s, Epoch: 94, Batch: 83,Loss: -3.710,Avg.Loss: -3.728,LR: 4.82E-06]Training epoch 94:  74%|███████▍  | 83/112 [00:01<00:00, 53.17it/s, Epoch: 94, Batch: 84,Loss: -3.657,Avg.Loss: -3.727,LR: 4.80E-06]Training epoch 94:  75%|███████▌  | 84/112 [00:01<00:00, 53.35it/s, Epoch: 94, Batch: 84,Loss: -3.657,Avg.Loss: -3.727,LR: 4.80E-06]Training epoch 94:  75%|███████▌  | 84/112 [00:01<00:00, 53.35it/s, Epoch: 94, Batch: 85,Loss: -3.898,Avg.Loss: -3.729,LR: 4.79E-06]Training epoch 94:  76%|███████▌  | 85/112 [00:01<00:00, 53.35it/s, Epoch: 94, Batch: 86,Loss: -3.828,Avg.Loss: -3.730,LR: 4.78E-06]Training epoch 94:  77%|███████▋  | 86/112 [00:01<00:00, 53.35it/s, Epoch: 94, Batch: 87,Loss: -3.612,Avg.Loss: -3.729,LR: 4.76E-06]Training epoch 94:  78%|███████▊  | 87/112 [00:01<00:00, 53.35it/s, Epoch: 94, Batch: 88,Loss: -3.432,Avg.Loss: -3.726,LR: 4.75E-06]Training epoch 94:  79%|███████▊  | 88/112 [00:01<00:00, 53.35it/s, Epoch: 94, Batch: 89,Loss: -3.650,Avg.Loss: -3.725,LR: 4.74E-06]Training epoch 94:  79%|███████▉  | 89/112 [00:01<00:00, 53.35it/s, Epoch: 94, Batch: 90,Loss: -3.863,Avg.Loss: -3.726,LR: 4.72E-06]Training epoch 94:  80%|████████  | 90/112 [00:01<00:00, 51.80it/s, Epoch: 94, Batch: 90,Loss: -3.863,Avg.Loss: -3.726,LR: 4.72E-06]Training epoch 94:  80%|████████  | 90/112 [00:01<00:00, 51.80it/s, Epoch: 94, Batch: 91,Loss: -3.971,Avg.Loss: -3.729,LR: 4.71E-06]Training epoch 94:  81%|████████▏ | 91/112 [00:01<00:00, 51.80it/s, Epoch: 94, Batch: 92,Loss: -3.255,Avg.Loss: -3.724,LR: 4.69E-06]Training epoch 94:  82%|████████▏ | 92/112 [00:01<00:00, 51.80it/s, Epoch: 94, Batch: 93,Loss: -3.454,Avg.Loss: -3.721,LR: 4.68E-06]Training epoch 94:  83%|████████▎ | 93/112 [00:01<00:00, 51.80it/s, Epoch: 94, Batch: 94,Loss: -3.662,Avg.Loss: -3.720,LR: 4.67E-06]Training epoch 94:  84%|████████▍ | 94/112 [00:01<00:00, 51.80it/s, Epoch: 94, Batch: 95,Loss: -3.726,Avg.Loss: -3.720,LR: 4.65E-06]Training epoch 94:  85%|████████▍ | 95/112 [00:01<00:00, 51.80it/s, Epoch: 94, Batch: 96,Loss: -3.295,Avg.Loss: -3.716,LR: 4.64E-06]Training epoch 94:  86%|████████▌ | 96/112 [00:01<00:00, 52.35it/s, Epoch: 94, Batch: 96,Loss: -3.295,Avg.Loss: -3.716,LR: 4.64E-06]Training epoch 94:  86%|████████▌ | 96/112 [00:01<00:00, 52.35it/s, Epoch: 94, Batch: 97,Loss: -3.883,Avg.Loss: -3.718,LR: 4.63E-06]Training epoch 94:  87%|████████▋ | 97/112 [00:01<00:00, 52.35it/s, Epoch: 94, Batch: 98,Loss: -3.742,Avg.Loss: -3.718,LR: 4.61E-06]Training epoch 94:  88%|████████▊ | 98/112 [00:01<00:00, 52.35it/s, Epoch: 94, Batch: 99,Loss: -3.607,Avg.Loss: -3.717,LR: 4.60E-06]Training epoch 94:  88%|████████▊ | 99/112 [00:01<00:00, 52.35it/s, Epoch: 94, Batch: 100,Loss: -3.342,Avg.Loss: -3.713,LR: 4.59E-06]Training epoch 94:  89%|████████▉ | 100/112 [00:01<00:00, 52.35it/s, Epoch: 94, Batch: 101,Loss: -3.900,Avg.Loss: -3.715,LR: 4.57E-06]Training epoch 94:  90%|█████████ | 101/112 [00:01<00:00, 52.35it/s, Epoch: 94, Batch: 102,Loss: -3.737,Avg.Loss: -3.715,LR: 4.56E-06]Training epoch 94:  91%|█████████ | 102/112 [00:01<00:00, 52.76it/s, Epoch: 94, Batch: 102,Loss: -3.737,Avg.Loss: -3.715,LR: 4.56E-06]Training epoch 94:  91%|█████████ | 102/112 [00:01<00:00, 52.76it/s, Epoch: 94, Batch: 103,Loss: -4.008,Avg.Loss: -3.718,LR: 4.55E-06]Training epoch 94:  92%|█████████▏| 103/112 [00:01<00:00, 52.76it/s, Epoch: 94, Batch: 104,Loss: -3.622,Avg.Loss: -3.717,LR: 4.53E-06]Training epoch 94:  93%|█████████▎| 104/112 [00:01<00:00, 52.76it/s, Epoch: 94, Batch: 105,Loss: -3.414,Avg.Loss: -3.714,LR: 4.52E-06]Training epoch 94:  94%|█████████▍| 105/112 [00:02<00:00, 52.76it/s, Epoch: 94, Batch: 106,Loss: -3.727,Avg.Loss: -3.714,LR: 4.51E-06]Training epoch 94:  95%|█████████▍| 106/112 [00:02<00:00, 52.76it/s, Epoch: 94, Batch: 107,Loss: -3.621,Avg.Loss: -3.713,LR: 4.49E-06]Training epoch 94:  96%|█████████▌| 107/112 [00:02<00:00, 52.76it/s, Epoch: 94, Batch: 108,Loss: -3.684,Avg.Loss: -3.713,LR: 4.48E-06]Training epoch 94:  96%|█████████▋| 108/112 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 108,Loss: -3.684,Avg.Loss: -3.713,LR: 4.48E-06]Training epoch 94:  96%|█████████▋| 108/112 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 109,Loss: -4.235,Avg.Loss: -3.718,LR: 4.47E-06]Training epoch 94:  97%|█████████▋| 109/112 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 110,Loss: -3.638,Avg.Loss: -3.717,LR: 4.45E-06]Training epoch 94:  98%|█████████▊| 110/112 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 111,Loss: -3.411,Avg.Loss: -3.714,LR: 4.44E-06]Training epoch 94:  99%|█████████▉| 111/112 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 112,Loss: -4.669,Avg.Loss: -3.723,LR: 4.43E-06]Training epoch 94: 100%|██████████| 112/112 [00:02<00:00, 52.91it/s, Epoch: 94, Batch: 112,Loss: -4.669,Avg.Loss: -3.723,LR: 4.43E-06]
Training epoch 95:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 95:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 95, Batch: 1,Loss: -3.672,Avg.Loss: -3.672,LR: 4.42E-06]Training epoch 95:   1%|          | 1/112 [00:00<00:04, 24.77it/s, Epoch: 95, Batch: 2,Loss: -4.154,Avg.Loss: -3.913,LR: 4.40E-06]Training epoch 95:   2%|▏         | 2/112 [00:00<00:02, 37.16it/s, Epoch: 95, Batch: 3,Loss: -3.964,Avg.Loss: -3.930,LR: 4.39E-06]Training epoch 95:   3%|▎         | 3/112 [00:00<00:02, 41.67it/s, Epoch: 95, Batch: 4,Loss: -3.766,Avg.Loss: -3.889,LR: 4.38E-06]Training epoch 95:   4%|▎         | 4/112 [00:00<00:02, 44.47it/s, Epoch: 95, Batch: 5,Loss: -2.993,Avg.Loss: -3.710,LR: 4.36E-06]Training epoch 95:   4%|▍         | 5/112 [00:00<00:02, 46.00it/s, Epoch: 95, Batch: 6,Loss: -3.458,Avg.Loss: -3.668,LR: 4.35E-06]Training epoch 95:   5%|▌         | 6/112 [00:00<00:01, 55.11it/s, Epoch: 95, Batch: 6,Loss: -3.458,Avg.Loss: -3.668,LR: 4.35E-06]Training epoch 95:   5%|▌         | 6/112 [00:00<00:01, 55.11it/s, Epoch: 95, Batch: 7,Loss: -3.436,Avg.Loss: -3.635,LR: 4.34E-06]Training epoch 95:   6%|▋         | 7/112 [00:00<00:01, 55.11it/s, Epoch: 95, Batch: 8,Loss: -3.912,Avg.Loss: -3.669,LR: 4.32E-06]Training epoch 95:   7%|▋         | 8/112 [00:00<00:01, 55.11it/s, Epoch: 95, Batch: 9,Loss: -3.899,Avg.Loss: -3.695,LR: 4.31E-06]Training epoch 95:   8%|▊         | 9/112 [00:00<00:01, 55.11it/s, Epoch: 95, Batch: 10,Loss: -3.914,Avg.Loss: -3.717,LR: 4.30E-06]Training epoch 95:   9%|▉         | 10/112 [00:00<00:01, 55.11it/s, Epoch: 95, Batch: 11,Loss: -3.664,Avg.Loss: -3.712,LR: 4.28E-06]Training epoch 95:  10%|▉         | 11/112 [00:00<00:01, 55.11it/s, Epoch: 95, Batch: 12,Loss: -3.614,Avg.Loss: -3.704,LR: 4.27E-06]Training epoch 95:  11%|█         | 12/112 [00:00<00:01, 54.72it/s, Epoch: 95, Batch: 12,Loss: -3.614,Avg.Loss: -3.704,LR: 4.27E-06]Training epoch 95:  11%|█         | 12/112 [00:00<00:01, 54.72it/s, Epoch: 95, Batch: 13,Loss: -3.642,Avg.Loss: -3.699,LR: 4.26E-06]Training epoch 95:  12%|█▏        | 13/112 [00:00<00:01, 54.72it/s, Epoch: 95, Batch: 14,Loss: -3.500,Avg.Loss: -3.685,LR: 4.25E-06]Training epoch 95:  12%|█▎        | 14/112 [00:00<00:01, 54.72it/s, Epoch: 95, Batch: 15,Loss: -3.749,Avg.Loss: -3.689,LR: 4.23E-06]Training epoch 95:  13%|█▎        | 15/112 [00:00<00:01, 54.72it/s, Epoch: 95, Batch: 16,Loss: -3.521,Avg.Loss: -3.679,LR: 4.22E-06]Training epoch 95:  14%|█▍        | 16/112 [00:00<00:01, 54.72it/s, Epoch: 95, Batch: 17,Loss: -3.826,Avg.Loss: -3.687,LR: 4.21E-06]Training epoch 95:  15%|█▌        | 17/112 [00:00<00:01, 54.72it/s, Epoch: 95, Batch: 18,Loss: -3.837,Avg.Loss: -3.696,LR: 4.19E-06]Training epoch 95:  16%|█▌        | 18/112 [00:00<00:01, 53.83it/s, Epoch: 95, Batch: 18,Loss: -3.837,Avg.Loss: -3.696,LR: 4.19E-06]Training epoch 95:  16%|█▌        | 18/112 [00:00<00:01, 53.83it/s, Epoch: 95, Batch: 19,Loss: -3.855,Avg.Loss: -3.704,LR: 4.18E-06]Training epoch 95:  17%|█▋        | 19/112 [00:00<00:01, 53.83it/s, Epoch: 95, Batch: 20,Loss: -4.022,Avg.Loss: -3.720,LR: 4.17E-06]Training epoch 95:  18%|█▊        | 20/112 [00:00<00:01, 53.83it/s, Epoch: 95, Batch: 21,Loss: -3.319,Avg.Loss: -3.701,LR: 4.16E-06]Training epoch 95:  19%|█▉        | 21/112 [00:00<00:01, 53.83it/s, Epoch: 95, Batch: 22,Loss: -3.973,Avg.Loss: -3.713,LR: 4.14E-06]Training epoch 95:  20%|█▉        | 22/112 [00:00<00:01, 53.83it/s, Epoch: 95, Batch: 23,Loss: -3.987,Avg.Loss: -3.725,LR: 4.13E-06]Training epoch 95:  21%|██        | 23/112 [00:00<00:01, 53.83it/s, Epoch: 95, Batch: 24,Loss: -3.662,Avg.Loss: -3.722,LR: 4.12E-06]Training epoch 95:  21%|██▏       | 24/112 [00:00<00:01, 52.43it/s, Epoch: 95, Batch: 24,Loss: -3.662,Avg.Loss: -3.722,LR: 4.12E-06]Training epoch 95:  21%|██▏       | 24/112 [00:00<00:01, 52.43it/s, Epoch: 95, Batch: 25,Loss: -4.161,Avg.Loss: -3.740,LR: 4.11E-06]Training epoch 95:  22%|██▏       | 25/112 [00:00<00:01, 52.43it/s, Epoch: 95, Batch: 26,Loss: -3.406,Avg.Loss: -3.727,LR: 4.09E-06]Training epoch 95:  23%|██▎       | 26/112 [00:00<00:01, 52.43it/s, Epoch: 95, Batch: 27,Loss: -3.568,Avg.Loss: -3.721,LR: 4.08E-06]Training epoch 95:  24%|██▍       | 27/112 [00:00<00:01, 52.43it/s, Epoch: 95, Batch: 28,Loss: -4.046,Avg.Loss: -3.733,LR: 4.07E-06]Training epoch 95:  25%|██▌       | 28/112 [00:00<00:01, 52.43it/s, Epoch: 95, Batch: 29,Loss: -4.050,Avg.Loss: -3.744,LR: 4.06E-06]Training epoch 95:  26%|██▌       | 29/112 [00:00<00:01, 52.43it/s, Epoch: 95, Batch: 30,Loss: -3.994,Avg.Loss: -3.752,LR: 4.04E-06]Training epoch 95:  27%|██▋       | 30/112 [00:00<00:01, 52.38it/s, Epoch: 95, Batch: 30,Loss: -3.994,Avg.Loss: -3.752,LR: 4.04E-06]Training epoch 95:  27%|██▋       | 30/112 [00:00<00:01, 52.38it/s, Epoch: 95, Batch: 31,Loss: -3.953,Avg.Loss: -3.759,LR: 4.03E-06]Training epoch 95:  28%|██▊       | 31/112 [00:00<00:01, 52.38it/s, Epoch: 95, Batch: 32,Loss: -3.534,Avg.Loss: -3.752,LR: 4.02E-06]Training epoch 95:  29%|██▊       | 32/112 [00:00<00:01, 52.38it/s, Epoch: 95, Batch: 33,Loss: -3.888,Avg.Loss: -3.756,LR: 4.01E-06]Training epoch 95:  29%|██▉       | 33/112 [00:00<00:01, 52.38it/s, Epoch: 95, Batch: 34,Loss: -3.697,Avg.Loss: -3.754,LR: 3.99E-06]Training epoch 95:  30%|███       | 34/112 [00:00<00:01, 52.38it/s, Epoch: 95, Batch: 35,Loss: -3.729,Avg.Loss: -3.753,LR: 3.98E-06]Training epoch 95:  31%|███▏      | 35/112 [00:00<00:01, 52.38it/s, Epoch: 95, Batch: 36,Loss: -3.581,Avg.Loss: -3.748,LR: 3.97E-06]Training epoch 95:  32%|███▏      | 36/112 [00:00<00:01, 52.69it/s, Epoch: 95, Batch: 36,Loss: -3.581,Avg.Loss: -3.748,LR: 3.97E-06]Training epoch 95:  32%|███▏      | 36/112 [00:00<00:01, 52.69it/s, Epoch: 95, Batch: 37,Loss: -3.972,Avg.Loss: -3.755,LR: 3.96E-06]Training epoch 95:  33%|███▎      | 37/112 [00:00<00:01, 52.69it/s, Epoch: 95, Batch: 38,Loss: -3.659,Avg.Loss: -3.752,LR: 3.94E-06]Training epoch 95:  34%|███▍      | 38/112 [00:00<00:01, 52.69it/s, Epoch: 95, Batch: 39,Loss: -3.277,Avg.Loss: -3.740,LR: 3.93E-06]Training epoch 95:  35%|███▍      | 39/112 [00:00<00:01, 52.69it/s, Epoch: 95, Batch: 40,Loss: -3.673,Avg.Loss: -3.738,LR: 3.92E-06]Training epoch 95:  36%|███▌      | 40/112 [00:00<00:01, 52.69it/s, Epoch: 95, Batch: 41,Loss: -3.778,Avg.Loss: -3.739,LR: 3.91E-06]Training epoch 95:  37%|███▋      | 41/112 [00:00<00:01, 52.69it/s, Epoch: 95, Batch: 42,Loss: -3.723,Avg.Loss: -3.739,LR: 3.89E-06]Training epoch 95:  38%|███▊      | 42/112 [00:00<00:01, 52.88it/s, Epoch: 95, Batch: 42,Loss: -3.723,Avg.Loss: -3.739,LR: 3.89E-06]Training epoch 95:  38%|███▊      | 42/112 [00:00<00:01, 52.88it/s, Epoch: 95, Batch: 43,Loss: -3.826,Avg.Loss: -3.741,LR: 3.88E-06]Training epoch 95:  38%|███▊      | 43/112 [00:00<00:01, 52.88it/s, Epoch: 95, Batch: 44,Loss: -3.711,Avg.Loss: -3.740,LR: 3.87E-06]Training epoch 95:  39%|███▉      | 44/112 [00:00<00:01, 52.88it/s, Epoch: 95, Batch: 45,Loss: -3.813,Avg.Loss: -3.742,LR: 3.86E-06]Training epoch 95:  40%|████      | 45/112 [00:00<00:01, 52.88it/s, Epoch: 95, Batch: 46,Loss: -3.570,Avg.Loss: -3.738,LR: 3.84E-06]Training epoch 95:  41%|████      | 46/112 [00:00<00:01, 52.88it/s, Epoch: 95, Batch: 47,Loss: -3.710,Avg.Loss: -3.737,LR: 3.83E-06]Training epoch 95:  42%|████▏     | 47/112 [00:00<00:01, 52.88it/s, Epoch: 95, Batch: 48,Loss: -3.408,Avg.Loss: -3.730,LR: 3.82E-06]Training epoch 95:  43%|████▎     | 48/112 [00:00<00:01, 52.72it/s, Epoch: 95, Batch: 48,Loss: -3.408,Avg.Loss: -3.730,LR: 3.82E-06]Training epoch 95:  43%|████▎     | 48/112 [00:00<00:01, 52.72it/s, Epoch: 95, Batch: 49,Loss: -3.758,Avg.Loss: -3.731,LR: 3.81E-06]Training epoch 95:  44%|████▍     | 49/112 [00:00<00:01, 52.72it/s, Epoch: 95, Batch: 50,Loss: -3.562,Avg.Loss: -3.728,LR: 3.80E-06]Training epoch 95:  45%|████▍     | 50/112 [00:00<00:01, 52.72it/s, Epoch: 95, Batch: 51,Loss: -3.947,Avg.Loss: -3.732,LR: 3.78E-06]Training epoch 95:  46%|████▌     | 51/112 [00:00<00:01, 52.72it/s, Epoch: 95, Batch: 52,Loss: -3.729,Avg.Loss: -3.732,LR: 3.77E-06]Training epoch 95:  46%|████▋     | 52/112 [00:00<00:01, 52.72it/s, Epoch: 95, Batch: 53,Loss: -3.705,Avg.Loss: -3.731,LR: 3.76E-06]Training epoch 95:  47%|████▋     | 53/112 [00:01<00:01, 52.72it/s, Epoch: 95, Batch: 54,Loss: -4.036,Avg.Loss: -3.737,LR: 3.75E-06]Training epoch 95:  48%|████▊     | 54/112 [00:01<00:01, 53.15it/s, Epoch: 95, Batch: 54,Loss: -4.036,Avg.Loss: -3.737,LR: 3.75E-06]Training epoch 95:  48%|████▊     | 54/112 [00:01<00:01, 53.15it/s, Epoch: 95, Batch: 55,Loss: -3.752,Avg.Loss: -3.737,LR: 3.73E-06]Training epoch 95:  49%|████▉     | 55/112 [00:01<00:01, 53.15it/s, Epoch: 95, Batch: 56,Loss: -4.027,Avg.Loss: -3.743,LR: 3.72E-06]Training epoch 95:  50%|█████     | 56/112 [00:01<00:01, 53.15it/s, Epoch: 95, Batch: 57,Loss: -3.942,Avg.Loss: -3.746,LR: 3.71E-06]Training epoch 95:  51%|█████     | 57/112 [00:01<00:01, 53.15it/s, Epoch: 95, Batch: 58,Loss: -3.273,Avg.Loss: -3.738,LR: 3.70E-06]Training epoch 95:  52%|█████▏    | 58/112 [00:01<00:01, 53.15it/s, Epoch: 95, Batch: 59,Loss: -3.276,Avg.Loss: -3.730,LR: 3.69E-06]Training epoch 95:  53%|█████▎    | 59/112 [00:01<00:00, 53.15it/s, Epoch: 95, Batch: 60,Loss: -3.552,Avg.Loss: -3.727,LR: 3.67E-06]Training epoch 95:  54%|█████▎    | 60/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 60,Loss: -3.552,Avg.Loss: -3.727,LR: 3.67E-06]Training epoch 95:  54%|█████▎    | 60/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 61,Loss: -3.893,Avg.Loss: -3.730,LR: 3.66E-06]Training epoch 95:  54%|█████▍    | 61/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 62,Loss: -3.316,Avg.Loss: -3.723,LR: 3.65E-06]Training epoch 95:  55%|█████▌    | 62/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 63,Loss: -3.906,Avg.Loss: -3.726,LR: 3.64E-06]Training epoch 95:  56%|█████▋    | 63/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 64,Loss: -3.135,Avg.Loss: -3.717,LR: 3.63E-06]Training epoch 95:  57%|█████▋    | 64/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 65,Loss: -3.710,Avg.Loss: -3.717,LR: 3.61E-06]Training epoch 95:  58%|█████▊    | 65/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 66,Loss: -3.425,Avg.Loss: -3.712,LR: 3.60E-06]Training epoch 95:  59%|█████▉    | 66/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 66,Loss: -3.425,Avg.Loss: -3.712,LR: 3.60E-06]Training epoch 95:  59%|█████▉    | 66/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 67,Loss: -3.393,Avg.Loss: -3.707,LR: 3.59E-06]Training epoch 95:  60%|█████▉    | 67/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 68,Loss: -3.839,Avg.Loss: -3.709,LR: 3.58E-06]Training epoch 95:  61%|██████    | 68/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 69,Loss: -3.500,Avg.Loss: -3.706,LR: 3.57E-06]Training epoch 95:  62%|██████▏   | 69/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 70,Loss: -4.069,Avg.Loss: -3.712,LR: 3.56E-06]Training epoch 95:  62%|██████▎   | 70/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 71,Loss: -3.678,Avg.Loss: -3.711,LR: 3.54E-06]Training epoch 95:  63%|██████▎   | 71/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 72,Loss: -3.624,Avg.Loss: -3.710,LR: 3.53E-06]Training epoch 95:  64%|██████▍   | 72/112 [00:01<00:00, 53.28it/s, Epoch: 95, Batch: 72,Loss: -3.624,Avg.Loss: -3.710,LR: 3.53E-06]Training epoch 95:  64%|██████▍   | 72/112 [00:01<00:00, 53.28it/s, Epoch: 95, Batch: 73,Loss: -4.147,Avg.Loss: -3.716,LR: 3.52E-06]Training epoch 95:  65%|██████▌   | 73/112 [00:01<00:00, 53.28it/s, Epoch: 95, Batch: 74,Loss: -3.987,Avg.Loss: -3.720,LR: 3.51E-06]Training epoch 95:  66%|██████▌   | 74/112 [00:01<00:00, 53.28it/s, Epoch: 95, Batch: 75,Loss: -3.609,Avg.Loss: -3.718,LR: 3.50E-06]Training epoch 95:  67%|██████▋   | 75/112 [00:01<00:00, 53.28it/s, Epoch: 95, Batch: 76,Loss: -3.658,Avg.Loss: -3.717,LR: 3.49E-06]Training epoch 95:  68%|██████▊   | 76/112 [00:01<00:00, 53.28it/s, Epoch: 95, Batch: 77,Loss: -3.619,Avg.Loss: -3.716,LR: 3.47E-06]Training epoch 95:  69%|██████▉   | 77/112 [00:01<00:00, 53.28it/s, Epoch: 95, Batch: 78,Loss: -3.498,Avg.Loss: -3.713,LR: 3.46E-06]Training epoch 95:  70%|██████▉   | 78/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 78,Loss: -3.498,Avg.Loss: -3.713,LR: 3.46E-06]Training epoch 95:  70%|██████▉   | 78/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 79,Loss: -3.946,Avg.Loss: -3.716,LR: 3.45E-06]Training epoch 95:  71%|███████   | 79/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 80,Loss: -3.566,Avg.Loss: -3.714,LR: 3.44E-06]Training epoch 95:  71%|███████▏  | 80/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 81,Loss: -3.670,Avg.Loss: -3.714,LR: 3.43E-06]Training epoch 95:  72%|███████▏  | 81/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 82,Loss: -2.721,Avg.Loss: -3.702,LR: 3.42E-06]Training epoch 95:  73%|███████▎  | 82/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 83,Loss: -3.665,Avg.Loss: -3.701,LR: 3.40E-06]Training epoch 95:  74%|███████▍  | 83/112 [00:01<00:00, 53.36it/s, Epoch: 95, Batch: 84,Loss: -3.799,Avg.Loss: -3.702,LR: 3.39E-06]Training epoch 95:  75%|███████▌  | 84/112 [00:01<00:00, 53.35it/s, Epoch: 95, Batch: 84,Loss: -3.799,Avg.Loss: -3.702,LR: 3.39E-06]Training epoch 95:  75%|███████▌  | 84/112 [00:01<00:00, 53.35it/s, Epoch: 95, Batch: 85,Loss: -3.633,Avg.Loss: -3.702,LR: 3.38E-06]Training epoch 95:  76%|███████▌  | 85/112 [00:01<00:00, 53.35it/s, Epoch: 95, Batch: 86,Loss: -3.778,Avg.Loss: -3.702,LR: 3.37E-06]Training epoch 95:  77%|███████▋  | 86/112 [00:01<00:00, 53.35it/s, Epoch: 95, Batch: 87,Loss: -3.922,Avg.Loss: -3.705,LR: 3.36E-06]Training epoch 95:  78%|███████▊  | 87/112 [00:01<00:00, 53.35it/s, Epoch: 95, Batch: 88,Loss: -3.694,Avg.Loss: -3.705,LR: 3.35E-06]Training epoch 95:  79%|███████▊  | 88/112 [00:01<00:00, 53.35it/s, Epoch: 95, Batch: 89,Loss: -3.959,Avg.Loss: -3.708,LR: 3.34E-06]Training epoch 95:  79%|███████▉  | 89/112 [00:01<00:00, 53.35it/s, Epoch: 95, Batch: 90,Loss: -3.836,Avg.Loss: -3.709,LR: 3.32E-06]Training epoch 95:  80%|████████  | 90/112 [00:01<00:00, 53.41it/s, Epoch: 95, Batch: 90,Loss: -3.836,Avg.Loss: -3.709,LR: 3.32E-06]Training epoch 95:  80%|████████  | 90/112 [00:01<00:00, 53.41it/s, Epoch: 95, Batch: 91,Loss: -3.867,Avg.Loss: -3.711,LR: 3.31E-06]Training epoch 95:  81%|████████▏ | 91/112 [00:01<00:00, 53.41it/s, Epoch: 95, Batch: 92,Loss: -3.410,Avg.Loss: -3.708,LR: 3.30E-06]Training epoch 95:  82%|████████▏ | 92/112 [00:01<00:00, 53.41it/s, Epoch: 95, Batch: 93,Loss: -4.090,Avg.Loss: -3.712,LR: 3.29E-06]Training epoch 95:  83%|████████▎ | 93/112 [00:01<00:00, 53.41it/s, Epoch: 95, Batch: 94,Loss: -3.611,Avg.Loss: -3.711,LR: 3.28E-06]Training epoch 95:  84%|████████▍ | 94/112 [00:01<00:00, 53.41it/s, Epoch: 95, Batch: 95,Loss: -3.840,Avg.Loss: -3.712,LR: 3.27E-06]Training epoch 95:  85%|████████▍ | 95/112 [00:01<00:00, 53.41it/s, Epoch: 95, Batch: 96,Loss: -3.829,Avg.Loss: -3.713,LR: 3.26E-06]Training epoch 95:  86%|████████▌ | 96/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 96,Loss: -3.829,Avg.Loss: -3.713,LR: 3.26E-06]Training epoch 95:  86%|████████▌ | 96/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 97,Loss: -4.049,Avg.Loss: -3.717,LR: 3.24E-06]Training epoch 95:  87%|████████▋ | 97/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 98,Loss: -3.727,Avg.Loss: -3.717,LR: 3.23E-06]Training epoch 95:  88%|████████▊ | 98/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 99,Loss: -3.678,Avg.Loss: -3.716,LR: 3.22E-06]Training epoch 95:  88%|████████▊ | 99/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 100,Loss: -3.542,Avg.Loss: -3.715,LR: 3.21E-06]Training epoch 95:  89%|████████▉ | 100/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 101,Loss: -3.609,Avg.Loss: -3.714,LR: 3.20E-06]Training epoch 95:  90%|█████████ | 101/112 [00:01<00:00, 53.30it/s, Epoch: 95, Batch: 102,Loss: -4.015,Avg.Loss: -3.717,LR: 3.19E-06]Training epoch 95:  91%|█████████ | 102/112 [00:01<00:00, 53.43it/s, Epoch: 95, Batch: 102,Loss: -4.015,Avg.Loss: -3.717,LR: 3.19E-06]Training epoch 95:  91%|█████████ | 102/112 [00:01<00:00, 53.43it/s, Epoch: 95, Batch: 103,Loss: -3.654,Avg.Loss: -3.716,LR: 3.18E-06]Training epoch 95:  92%|█████████▏| 103/112 [00:01<00:00, 53.43it/s, Epoch: 95, Batch: 104,Loss: -3.736,Avg.Loss: -3.716,LR: 3.17E-06]Training epoch 95:  93%|█████████▎| 104/112 [00:01<00:00, 53.43it/s, Epoch: 95, Batch: 105,Loss: -3.867,Avg.Loss: -3.718,LR: 3.16E-06]Training epoch 95:  94%|█████████▍| 105/112 [00:01<00:00, 53.43it/s, Epoch: 95, Batch: 106,Loss: -3.847,Avg.Loss: -3.719,LR: 3.14E-06]Training epoch 95:  95%|█████████▍| 106/112 [00:02<00:00, 53.43it/s, Epoch: 95, Batch: 107,Loss: -3.768,Avg.Loss: -3.719,LR: 3.13E-06]Training epoch 95:  96%|█████████▌| 107/112 [00:02<00:00, 53.43it/s, Epoch: 95, Batch: 108,Loss: -3.500,Avg.Loss: -3.717,LR: 3.12E-06]Training epoch 95:  96%|█████████▋| 108/112 [00:02<00:00, 53.50it/s, Epoch: 95, Batch: 108,Loss: -3.500,Avg.Loss: -3.717,LR: 3.12E-06]Training epoch 95:  96%|█████████▋| 108/112 [00:02<00:00, 53.50it/s, Epoch: 95, Batch: 109,Loss: -3.577,Avg.Loss: -3.716,LR: 3.11E-06]Training epoch 95:  97%|█████████▋| 109/112 [00:02<00:00, 53.50it/s, Epoch: 95, Batch: 110,Loss: -3.858,Avg.Loss: -3.717,LR: 3.10E-06]Training epoch 95:  98%|█████████▊| 110/112 [00:02<00:00, 53.50it/s, Epoch: 95, Batch: 111,Loss: -3.681,Avg.Loss: -3.717,LR: 3.09E-06]Training epoch 95:  99%|█████████▉| 111/112 [00:02<00:00, 53.50it/s, Epoch: 95, Batch: 112,Loss: -3.940,Avg.Loss: -3.719,LR: 3.08E-06]Training epoch 95: 100%|██████████| 112/112 [00:02<00:00, 53.20it/s, Epoch: 95, Batch: 112,Loss: -3.940,Avg.Loss: -3.719,LR: 3.08E-06]
Training epoch 96:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 96:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 96, Batch: 1,Loss: -3.988,Avg.Loss: -3.988,LR: 3.07E-06]Training epoch 96:   1%|          | 1/112 [00:00<00:04, 27.39it/s, Epoch: 96, Batch: 2,Loss: -3.593,Avg.Loss: -3.790,LR: 3.06E-06]Training epoch 96:   2%|▏         | 2/112 [00:00<00:02, 39.01it/s, Epoch: 96, Batch: 3,Loss: -3.610,Avg.Loss: -3.730,LR: 3.05E-06]Training epoch 96:   3%|▎         | 3/112 [00:00<00:02, 43.75it/s, Epoch: 96, Batch: 4,Loss: -3.394,Avg.Loss: -3.646,LR: 3.03E-06]Training epoch 96:   4%|▎         | 4/112 [00:00<00:02, 46.37it/s, Epoch: 96, Batch: 5,Loss: -3.996,Avg.Loss: -3.716,LR: 3.02E-06]Training epoch 96:   4%|▍         | 5/112 [00:00<00:02, 47.69it/s, Epoch: 96, Batch: 6,Loss: -3.679,Avg.Loss: -3.710,LR: 3.01E-06]Training epoch 96:   5%|▌         | 6/112 [00:00<00:01, 57.13it/s, Epoch: 96, Batch: 6,Loss: -3.679,Avg.Loss: -3.710,LR: 3.01E-06]Training epoch 96:   5%|▌         | 6/112 [00:00<00:01, 57.13it/s, Epoch: 96, Batch: 7,Loss: -3.819,Avg.Loss: -3.726,LR: 3.00E-06]Training epoch 96:   6%|▋         | 7/112 [00:00<00:01, 57.13it/s, Epoch: 96, Batch: 8,Loss: -4.059,Avg.Loss: -3.767,LR: 2.99E-06]Training epoch 96:   7%|▋         | 8/112 [00:00<00:01, 57.13it/s, Epoch: 96, Batch: 9,Loss: -3.721,Avg.Loss: -3.762,LR: 2.98E-06]Training epoch 96:   8%|▊         | 9/112 [00:00<00:01, 57.13it/s, Epoch: 96, Batch: 10,Loss: -3.921,Avg.Loss: -3.778,LR: 2.97E-06]Training epoch 96:   9%|▉         | 10/112 [00:00<00:01, 57.13it/s, Epoch: 96, Batch: 11,Loss: -3.607,Avg.Loss: -3.763,LR: 2.96E-06]Training epoch 96:  10%|▉         | 11/112 [00:00<00:01, 57.13it/s, Epoch: 96, Batch: 12,Loss: -3.632,Avg.Loss: -3.752,LR: 2.95E-06]Training epoch 96:  11%|█         | 12/112 [00:00<00:01, 54.49it/s, Epoch: 96, Batch: 12,Loss: -3.632,Avg.Loss: -3.752,LR: 2.95E-06]Training epoch 96:  11%|█         | 12/112 [00:00<00:01, 54.49it/s, Epoch: 96, Batch: 13,Loss: -3.610,Avg.Loss: -3.741,LR: 2.94E-06]Training epoch 96:  12%|█▏        | 13/112 [00:00<00:01, 54.49it/s, Epoch: 96, Batch: 14,Loss: -3.472,Avg.Loss: -3.722,LR: 2.93E-06]Training epoch 96:  12%|█▎        | 14/112 [00:00<00:01, 54.49it/s, Epoch: 96, Batch: 15,Loss: -3.115,Avg.Loss: -3.681,LR: 2.92E-06]Training epoch 96:  13%|█▎        | 15/112 [00:00<00:01, 54.49it/s, Epoch: 96, Batch: 16,Loss: -3.784,Avg.Loss: -3.688,LR: 2.90E-06]Training epoch 96:  14%|█▍        | 16/112 [00:00<00:01, 54.49it/s, Epoch: 96, Batch: 17,Loss: -3.700,Avg.Loss: -3.688,LR: 2.89E-06]Training epoch 96:  15%|█▌        | 17/112 [00:00<00:01, 54.49it/s, Epoch: 96, Batch: 18,Loss: -3.882,Avg.Loss: -3.699,LR: 2.88E-06]Training epoch 96:  16%|█▌        | 18/112 [00:00<00:01, 53.89it/s, Epoch: 96, Batch: 18,Loss: -3.882,Avg.Loss: -3.699,LR: 2.88E-06]Training epoch 96:  16%|█▌        | 18/112 [00:00<00:01, 53.89it/s, Epoch: 96, Batch: 19,Loss: -3.653,Avg.Loss: -3.697,LR: 2.87E-06]Training epoch 96:  17%|█▋        | 19/112 [00:00<00:01, 53.89it/s, Epoch: 96, Batch: 20,Loss: -3.513,Avg.Loss: -3.687,LR: 2.86E-06]Training epoch 96:  18%|█▊        | 20/112 [00:00<00:01, 53.89it/s, Epoch: 96, Batch: 21,Loss: -3.751,Avg.Loss: -3.690,LR: 2.85E-06]Training epoch 96:  19%|█▉        | 21/112 [00:00<00:01, 53.89it/s, Epoch: 96, Batch: 22,Loss: -3.670,Avg.Loss: -3.690,LR: 2.84E-06]Training epoch 96:  20%|█▉        | 22/112 [00:00<00:01, 53.89it/s, Epoch: 96, Batch: 23,Loss: -3.527,Avg.Loss: -3.682,LR: 2.83E-06]Training epoch 96:  21%|██        | 23/112 [00:00<00:01, 53.89it/s, Epoch: 96, Batch: 24,Loss: -3.569,Avg.Loss: -3.678,LR: 2.82E-06]Training epoch 96:  21%|██▏       | 24/112 [00:00<00:01, 51.74it/s, Epoch: 96, Batch: 24,Loss: -3.569,Avg.Loss: -3.678,LR: 2.82E-06]Training epoch 96:  21%|██▏       | 24/112 [00:00<00:01, 51.74it/s, Epoch: 96, Batch: 25,Loss: -3.909,Avg.Loss: -3.687,LR: 2.81E-06]Training epoch 96:  22%|██▏       | 25/112 [00:00<00:01, 51.74it/s, Epoch: 96, Batch: 26,Loss: -3.531,Avg.Loss: -3.681,LR: 2.80E-06]Training epoch 96:  23%|██▎       | 26/112 [00:00<00:01, 51.74it/s, Epoch: 96, Batch: 27,Loss: -3.423,Avg.Loss: -3.671,LR: 2.79E-06]Training epoch 96:  24%|██▍       | 27/112 [00:00<00:01, 51.74it/s, Epoch: 96, Batch: 28,Loss: -3.803,Avg.Loss: -3.676,LR: 2.78E-06]Training epoch 96:  25%|██▌       | 28/112 [00:00<00:01, 51.74it/s, Epoch: 96, Batch: 29,Loss: -3.941,Avg.Loss: -3.685,LR: 2.77E-06]Training epoch 96:  26%|██▌       | 29/112 [00:00<00:01, 51.74it/s, Epoch: 96, Batch: 30,Loss: -3.377,Avg.Loss: -3.675,LR: 2.76E-06]Training epoch 96:  27%|██▋       | 30/112 [00:00<00:01, 51.79it/s, Epoch: 96, Batch: 30,Loss: -3.377,Avg.Loss: -3.675,LR: 2.76E-06]Training epoch 96:  27%|██▋       | 30/112 [00:00<00:01, 51.79it/s, Epoch: 96, Batch: 31,Loss: -3.951,Avg.Loss: -3.684,LR: 2.75E-06]Training epoch 96:  28%|██▊       | 31/112 [00:00<00:01, 51.79it/s, Epoch: 96, Batch: 32,Loss: -3.842,Avg.Loss: -3.689,LR: 2.74E-06]Training epoch 96:  29%|██▊       | 32/112 [00:00<00:01, 51.79it/s, Epoch: 96, Batch: 33,Loss: -3.625,Avg.Loss: -3.687,LR: 2.73E-06]Training epoch 96:  29%|██▉       | 33/112 [00:00<00:01, 51.79it/s, Epoch: 96, Batch: 34,Loss: -3.838,Avg.Loss: -3.691,LR: 2.72E-06]Training epoch 96:  30%|███       | 34/112 [00:00<00:01, 51.79it/s, Epoch: 96, Batch: 35,Loss: -3.698,Avg.Loss: -3.692,LR: 2.71E-06]Training epoch 96:  31%|███▏      | 35/112 [00:00<00:01, 51.79it/s, Epoch: 96, Batch: 36,Loss: -3.968,Avg.Loss: -3.699,LR: 2.70E-06]Training epoch 96:  32%|███▏      | 36/112 [00:00<00:01, 52.09it/s, Epoch: 96, Batch: 36,Loss: -3.968,Avg.Loss: -3.699,LR: 2.70E-06]Training epoch 96:  32%|███▏      | 36/112 [00:00<00:01, 52.09it/s, Epoch: 96, Batch: 37,Loss: -3.912,Avg.Loss: -3.705,LR: 2.69E-06]Training epoch 96:  33%|███▎      | 37/112 [00:00<00:01, 52.09it/s, Epoch: 96, Batch: 38,Loss: -3.542,Avg.Loss: -3.701,LR: 2.68E-06]Training epoch 96:  34%|███▍      | 38/112 [00:00<00:01, 52.09it/s, Epoch: 96, Batch: 39,Loss: -3.854,Avg.Loss: -3.705,LR: 2.66E-06]Training epoch 96:  35%|███▍      | 39/112 [00:00<00:01, 52.09it/s, Epoch: 96, Batch: 40,Loss: -3.584,Avg.Loss: -3.702,LR: 2.65E-06]Training epoch 96:  36%|███▌      | 40/112 [00:00<00:01, 52.09it/s, Epoch: 96, Batch: 41,Loss: -3.804,Avg.Loss: -3.704,LR: 2.64E-06]Training epoch 96:  37%|███▋      | 41/112 [00:00<00:01, 52.09it/s, Epoch: 96, Batch: 42,Loss: -3.979,Avg.Loss: -3.711,LR: 2.63E-06]Training epoch 96:  38%|███▊      | 42/112 [00:00<00:01, 52.45it/s, Epoch: 96, Batch: 42,Loss: -3.979,Avg.Loss: -3.711,LR: 2.63E-06]Training epoch 96:  38%|███▊      | 42/112 [00:00<00:01, 52.45it/s, Epoch: 96, Batch: 43,Loss: -3.475,Avg.Loss: -3.705,LR: 2.62E-06]Training epoch 96:  38%|███▊      | 43/112 [00:00<00:01, 52.45it/s, Epoch: 96, Batch: 44,Loss: -3.851,Avg.Loss: -3.708,LR: 2.61E-06]Training epoch 96:  39%|███▉      | 44/112 [00:00<00:01, 52.45it/s, Epoch: 96, Batch: 45,Loss: -3.442,Avg.Loss: -3.703,LR: 2.60E-06]Training epoch 96:  40%|████      | 45/112 [00:00<00:01, 52.45it/s, Epoch: 96, Batch: 46,Loss: -3.552,Avg.Loss: -3.699,LR: 2.59E-06]Training epoch 96:  41%|████      | 46/112 [00:00<00:01, 52.45it/s, Epoch: 96, Batch: 47,Loss: -3.905,Avg.Loss: -3.704,LR: 2.58E-06]Training epoch 96:  42%|████▏     | 47/112 [00:00<00:01, 52.45it/s, Epoch: 96, Batch: 48,Loss: -4.123,Avg.Loss: -3.712,LR: 2.57E-06]Training epoch 96:  43%|████▎     | 48/112 [00:00<00:01, 52.48it/s, Epoch: 96, Batch: 48,Loss: -4.123,Avg.Loss: -3.712,LR: 2.57E-06]Training epoch 96:  43%|████▎     | 48/112 [00:00<00:01, 52.48it/s, Epoch: 96, Batch: 49,Loss: -3.626,Avg.Loss: -3.711,LR: 2.56E-06]Training epoch 96:  44%|████▍     | 49/112 [00:00<00:01, 52.48it/s, Epoch: 96, Batch: 50,Loss: -3.599,Avg.Loss: -3.708,LR: 2.55E-06]Training epoch 96:  45%|████▍     | 50/112 [00:00<00:01, 52.48it/s, Epoch: 96, Batch: 51,Loss: -3.622,Avg.Loss: -3.707,LR: 2.54E-06]Training epoch 96:  46%|████▌     | 51/112 [00:00<00:01, 52.48it/s, Epoch: 96, Batch: 52,Loss: -3.893,Avg.Loss: -3.710,LR: 2.53E-06]Training epoch 96:  46%|████▋     | 52/112 [00:01<00:01, 52.48it/s, Epoch: 96, Batch: 53,Loss: -3.446,Avg.Loss: -3.705,LR: 2.52E-06]Training epoch 96:  47%|████▋     | 53/112 [00:01<00:01, 52.48it/s, Epoch: 96, Batch: 54,Loss: -3.899,Avg.Loss: -3.709,LR: 2.51E-06]Training epoch 96:  48%|████▊     | 54/112 [00:01<00:01, 52.73it/s, Epoch: 96, Batch: 54,Loss: -3.899,Avg.Loss: -3.709,LR: 2.51E-06]Training epoch 96:  48%|████▊     | 54/112 [00:01<00:01, 52.73it/s, Epoch: 96, Batch: 55,Loss: -3.909,Avg.Loss: -3.713,LR: 2.50E-06]Training epoch 96:  49%|████▉     | 55/112 [00:01<00:01, 52.73it/s, Epoch: 96, Batch: 56,Loss: -3.848,Avg.Loss: -3.715,LR: 2.49E-06]Training epoch 96:  50%|█████     | 56/112 [00:01<00:01, 52.73it/s, Epoch: 96, Batch: 57,Loss: -3.894,Avg.Loss: -3.718,LR: 2.48E-06]Training epoch 96:  51%|█████     | 57/112 [00:01<00:01, 52.73it/s, Epoch: 96, Batch: 58,Loss: -3.799,Avg.Loss: -3.719,LR: 2.47E-06]Training epoch 96:  52%|█████▏    | 58/112 [00:01<00:01, 52.73it/s, Epoch: 96, Batch: 59,Loss: -3.900,Avg.Loss: -3.723,LR: 2.46E-06]Training epoch 96:  53%|█████▎    | 59/112 [00:01<00:01, 52.73it/s, Epoch: 96, Batch: 60,Loss: -3.359,Avg.Loss: -3.716,LR: 2.45E-06]Training epoch 96:  54%|█████▎    | 60/112 [00:01<00:00, 52.60it/s, Epoch: 96, Batch: 60,Loss: -3.359,Avg.Loss: -3.716,LR: 2.45E-06]Training epoch 96:  54%|█████▎    | 60/112 [00:01<00:00, 52.60it/s, Epoch: 96, Batch: 61,Loss: -3.581,Avg.Loss: -3.714,LR: 2.44E-06]Training epoch 96:  54%|█████▍    | 61/112 [00:01<00:00, 52.60it/s, Epoch: 96, Batch: 62,Loss: -3.411,Avg.Loss: -3.709,LR: 2.44E-06]Training epoch 96:  55%|█████▌    | 62/112 [00:01<00:00, 52.60it/s, Epoch: 96, Batch: 63,Loss: -3.570,Avg.Loss: -3.707,LR: 2.43E-06]Training epoch 96:  56%|█████▋    | 63/112 [00:01<00:00, 52.60it/s, Epoch: 96, Batch: 64,Loss: -3.718,Avg.Loss: -3.707,LR: 2.42E-06]Training epoch 96:  57%|█████▋    | 64/112 [00:01<00:00, 52.60it/s, Epoch: 96, Batch: 65,Loss: -3.735,Avg.Loss: -3.708,LR: 2.41E-06]Training epoch 96:  58%|█████▊    | 65/112 [00:01<00:00, 52.60it/s, Epoch: 96, Batch: 66,Loss: -3.726,Avg.Loss: -3.708,LR: 2.40E-06]Training epoch 96:  59%|█████▉    | 66/112 [00:01<00:00, 52.73it/s, Epoch: 96, Batch: 66,Loss: -3.726,Avg.Loss: -3.708,LR: 2.40E-06]Training epoch 96:  59%|█████▉    | 66/112 [00:01<00:00, 52.73it/s, Epoch: 96, Batch: 67,Loss: -3.767,Avg.Loss: -3.709,LR: 2.39E-06]Training epoch 96:  60%|█████▉    | 67/112 [00:01<00:00, 52.73it/s, Epoch: 96, Batch: 68,Loss: -3.252,Avg.Loss: -3.702,LR: 2.38E-06]Training epoch 96:  61%|██████    | 68/112 [00:01<00:00, 52.73it/s, Epoch: 96, Batch: 69,Loss: -3.490,Avg.Loss: -3.699,LR: 2.37E-06]Training epoch 96:  62%|██████▏   | 69/112 [00:01<00:00, 52.73it/s, Epoch: 96, Batch: 70,Loss: -3.317,Avg.Loss: -3.694,LR: 2.36E-06]Training epoch 96:  62%|██████▎   | 70/112 [00:01<00:00, 52.73it/s, Epoch: 96, Batch: 71,Loss: -3.666,Avg.Loss: -3.693,LR: 2.35E-06]Training epoch 96:  63%|██████▎   | 71/112 [00:01<00:00, 52.73it/s, Epoch: 96, Batch: 72,Loss: -3.734,Avg.Loss: -3.694,LR: 2.34E-06]Training epoch 96:  64%|██████▍   | 72/112 [00:01<00:00, 52.65it/s, Epoch: 96, Batch: 72,Loss: -3.734,Avg.Loss: -3.694,LR: 2.34E-06]Training epoch 96:  64%|██████▍   | 72/112 [00:01<00:00, 52.65it/s, Epoch: 96, Batch: 73,Loss: -3.733,Avg.Loss: -3.694,LR: 2.33E-06]Training epoch 96:  65%|██████▌   | 73/112 [00:01<00:00, 52.65it/s, Epoch: 96, Batch: 74,Loss: -4.254,Avg.Loss: -3.702,LR: 2.32E-06]Training epoch 96:  66%|██████▌   | 74/112 [00:01<00:00, 52.65it/s, Epoch: 96, Batch: 75,Loss: -3.621,Avg.Loss: -3.701,LR: 2.31E-06]Training epoch 96:  67%|██████▋   | 75/112 [00:01<00:00, 52.65it/s, Epoch: 96, Batch: 76,Loss: -3.972,Avg.Loss: -3.704,LR: 2.30E-06]Training epoch 96:  68%|██████▊   | 76/112 [00:01<00:00, 52.65it/s, Epoch: 96, Batch: 77,Loss: -3.768,Avg.Loss: -3.705,LR: 2.29E-06]Training epoch 96:  69%|██████▉   | 77/112 [00:01<00:00, 52.65it/s, Epoch: 96, Batch: 78,Loss: -3.643,Avg.Loss: -3.704,LR: 2.28E-06]Training epoch 96:  70%|██████▉   | 78/112 [00:01<00:00, 52.54it/s, Epoch: 96, Batch: 78,Loss: -3.643,Avg.Loss: -3.704,LR: 2.28E-06]Training epoch 96:  70%|██████▉   | 78/112 [00:01<00:00, 52.54it/s, Epoch: 96, Batch: 79,Loss: -3.948,Avg.Loss: -3.708,LR: 2.27E-06]Training epoch 96:  71%|███████   | 79/112 [00:01<00:00, 52.54it/s, Epoch: 96, Batch: 80,Loss: -3.841,Avg.Loss: -3.709,LR: 2.26E-06]Training epoch 96:  71%|███████▏  | 80/112 [00:01<00:00, 52.54it/s, Epoch: 96, Batch: 81,Loss: -3.410,Avg.Loss: -3.706,LR: 2.25E-06]Training epoch 96:  72%|███████▏  | 81/112 [00:01<00:00, 52.54it/s, Epoch: 96, Batch: 82,Loss: -3.502,Avg.Loss: -3.703,LR: 2.24E-06]Training epoch 96:  73%|███████▎  | 82/112 [00:01<00:00, 52.54it/s, Epoch: 96, Batch: 83,Loss: -3.842,Avg.Loss: -3.705,LR: 2.23E-06]Training epoch 96:  74%|███████▍  | 83/112 [00:01<00:00, 52.54it/s, Epoch: 96, Batch: 84,Loss: -3.967,Avg.Loss: -3.708,LR: 2.23E-06]Training epoch 96:  75%|███████▌  | 84/112 [00:01<00:00, 52.62it/s, Epoch: 96, Batch: 84,Loss: -3.967,Avg.Loss: -3.708,LR: 2.23E-06]Training epoch 96:  75%|███████▌  | 84/112 [00:01<00:00, 52.62it/s, Epoch: 96, Batch: 85,Loss: -3.808,Avg.Loss: -3.709,LR: 2.22E-06]Training epoch 96:  76%|███████▌  | 85/112 [00:01<00:00, 52.62it/s, Epoch: 96, Batch: 86,Loss: -3.730,Avg.Loss: -3.709,LR: 2.21E-06]Training epoch 96:  77%|███████▋  | 86/112 [00:01<00:00, 52.62it/s, Epoch: 96, Batch: 87,Loss: -3.610,Avg.Loss: -3.708,LR: 2.20E-06]Training epoch 96:  78%|███████▊  | 87/112 [00:01<00:00, 52.62it/s, Epoch: 96, Batch: 88,Loss: -3.856,Avg.Loss: -3.710,LR: 2.19E-06]Training epoch 96:  79%|███████▊  | 88/112 [00:01<00:00, 52.62it/s, Epoch: 96, Batch: 89,Loss: -3.707,Avg.Loss: -3.710,LR: 2.18E-06]Training epoch 96:  79%|███████▉  | 89/112 [00:01<00:00, 52.62it/s, Epoch: 96, Batch: 90,Loss: -4.031,Avg.Loss: -3.713,LR: 2.17E-06]Training epoch 96:  80%|████████  | 90/112 [00:01<00:00, 52.78it/s, Epoch: 96, Batch: 90,Loss: -4.031,Avg.Loss: -3.713,LR: 2.17E-06]Training epoch 96:  80%|████████  | 90/112 [00:01<00:00, 52.78it/s, Epoch: 96, Batch: 91,Loss: -3.695,Avg.Loss: -3.713,LR: 2.16E-06]Training epoch 96:  81%|████████▏ | 91/112 [00:01<00:00, 52.78it/s, Epoch: 96, Batch: 92,Loss: -3.812,Avg.Loss: -3.714,LR: 2.15E-06]Training epoch 96:  82%|████████▏ | 92/112 [00:01<00:00, 52.78it/s, Epoch: 96, Batch: 93,Loss: -3.858,Avg.Loss: -3.716,LR: 2.14E-06]Training epoch 96:  83%|████████▎ | 93/112 [00:01<00:00, 52.78it/s, Epoch: 96, Batch: 94,Loss: -3.844,Avg.Loss: -3.717,LR: 2.13E-06]Training epoch 96:  84%|████████▍ | 94/112 [00:01<00:00, 52.78it/s, Epoch: 96, Batch: 95,Loss: -3.588,Avg.Loss: -3.716,LR: 2.12E-06]Training epoch 96:  85%|████████▍ | 95/112 [00:01<00:00, 52.78it/s, Epoch: 96, Batch: 96,Loss: -3.682,Avg.Loss: -3.715,LR: 2.11E-06]Training epoch 96:  86%|████████▌ | 96/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 96,Loss: -3.682,Avg.Loss: -3.715,LR: 2.11E-06]Training epoch 96:  86%|████████▌ | 96/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 97,Loss: -3.672,Avg.Loss: -3.715,LR: 2.11E-06]Training epoch 96:  87%|████████▋ | 97/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 98,Loss: -3.872,Avg.Loss: -3.717,LR: 2.10E-06]Training epoch 96:  88%|████████▊ | 98/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 99,Loss: -3.870,Avg.Loss: -3.718,LR: 2.09E-06]Training epoch 96:  88%|████████▊ | 99/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 100,Loss: -3.581,Avg.Loss: -3.717,LR: 2.08E-06]Training epoch 96:  89%|████████▉ | 100/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 101,Loss: -3.792,Avg.Loss: -3.717,LR: 2.07E-06]Training epoch 96:  90%|█████████ | 101/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 102,Loss: -3.620,Avg.Loss: -3.717,LR: 2.06E-06]Training epoch 96:  91%|█████████ | 102/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 102,Loss: -3.620,Avg.Loss: -3.717,LR: 2.06E-06]Training epoch 96:  91%|█████████ | 102/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 103,Loss: -3.824,Avg.Loss: -3.718,LR: 2.05E-06]Training epoch 96:  92%|█████████▏| 103/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 104,Loss: -3.815,Avg.Loss: -3.719,LR: 2.04E-06]Training epoch 96:  93%|█████████▎| 104/112 [00:01<00:00, 52.90it/s, Epoch: 96, Batch: 105,Loss: -3.857,Avg.Loss: -3.720,LR: 2.03E-06]Training epoch 96:  94%|█████████▍| 105/112 [00:02<00:00, 52.90it/s, Epoch: 96, Batch: 106,Loss: -3.856,Avg.Loss: -3.721,LR: 2.02E-06]Training epoch 96:  95%|█████████▍| 106/112 [00:02<00:00, 52.90it/s, Epoch: 96, Batch: 107,Loss: -3.962,Avg.Loss: -3.723,LR: 2.02E-06]Training epoch 96:  96%|█████████▌| 107/112 [00:02<00:00, 52.90it/s, Epoch: 96, Batch: 108,Loss: -3.529,Avg.Loss: -3.722,LR: 2.01E-06]Training epoch 96:  96%|█████████▋| 108/112 [00:02<00:00, 53.02it/s, Epoch: 96, Batch: 108,Loss: -3.529,Avg.Loss: -3.722,LR: 2.01E-06]Training epoch 96:  96%|█████████▋| 108/112 [00:02<00:00, 53.02it/s, Epoch: 96, Batch: 109,Loss: -3.667,Avg.Loss: -3.721,LR: 2.00E-06]Training epoch 96:  97%|█████████▋| 109/112 [00:02<00:00, 53.02it/s, Epoch: 96, Batch: 110,Loss: -3.820,Avg.Loss: -3.722,LR: 1.99E-06]Training epoch 96:  98%|█████████▊| 110/112 [00:02<00:00, 53.02it/s, Epoch: 96, Batch: 111,Loss: -3.914,Avg.Loss: -3.724,LR: 1.98E-06]Training epoch 96:  99%|█████████▉| 111/112 [00:02<00:00, 53.02it/s, Epoch: 96, Batch: 112,Loss: -3.400,Avg.Loss: -3.721,LR: 1.97E-06]Training epoch 96: 100%|██████████| 112/112 [00:02<00:00, 52.96it/s, Epoch: 96, Batch: 112,Loss: -3.400,Avg.Loss: -3.721,LR: 1.97E-06]
Training epoch 97:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 97:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 97, Batch: 1,Loss: -3.419,Avg.Loss: -3.419,LR: 1.96E-06]Training epoch 97:   1%|          | 1/112 [00:00<00:03, 31.93it/s, Epoch: 97, Batch: 2,Loss: -3.643,Avg.Loss: -3.531,LR: 1.95E-06]Training epoch 97:   2%|▏         | 2/112 [00:00<00:02, 44.97it/s, Epoch: 97, Batch: 3,Loss: -3.829,Avg.Loss: -3.630,LR: 1.95E-06]Training epoch 97:   3%|▎         | 3/112 [00:00<00:02, 48.87it/s, Epoch: 97, Batch: 4,Loss: -3.945,Avg.Loss: -3.709,LR: 1.94E-06]Training epoch 97:   4%|▎         | 4/112 [00:00<00:02, 50.18it/s, Epoch: 97, Batch: 5,Loss: -4.030,Avg.Loss: -3.773,LR: 1.93E-06]Training epoch 97:   4%|▍         | 5/112 [00:00<00:02, 50.67it/s, Epoch: 97, Batch: 6,Loss: -3.537,Avg.Loss: -3.734,LR: 1.92E-06]Training epoch 97:   5%|▌         | 6/112 [00:00<00:02, 51.06it/s, Epoch: 97, Batch: 7,Loss: -3.839,Avg.Loss: -3.749,LR: 1.91E-06]Training epoch 97:   6%|▋         | 7/112 [00:00<00:01, 59.48it/s, Epoch: 97, Batch: 7,Loss: -3.839,Avg.Loss: -3.749,LR: 1.91E-06]Training epoch 97:   6%|▋         | 7/112 [00:00<00:01, 59.48it/s, Epoch: 97, Batch: 8,Loss: -3.575,Avg.Loss: -3.727,LR: 1.90E-06]Training epoch 97:   7%|▋         | 8/112 [00:00<00:01, 59.48it/s, Epoch: 97, Batch: 9,Loss: -3.988,Avg.Loss: -3.756,LR: 1.89E-06]Training epoch 97:   8%|▊         | 9/112 [00:00<00:01, 59.48it/s, Epoch: 97, Batch: 10,Loss: -3.679,Avg.Loss: -3.748,LR: 1.88E-06]Training epoch 97:   9%|▉         | 10/112 [00:00<00:01, 59.48it/s, Epoch: 97, Batch: 11,Loss: -3.499,Avg.Loss: -3.726,LR: 1.88E-06]Training epoch 97:  10%|▉         | 11/112 [00:00<00:01, 59.48it/s, Epoch: 97, Batch: 12,Loss: -3.538,Avg.Loss: -3.710,LR: 1.87E-06]Training epoch 97:  11%|█         | 12/112 [00:00<00:01, 59.48it/s, Epoch: 97, Batch: 13,Loss: -3.726,Avg.Loss: -3.711,LR: 1.86E-06]Training epoch 97:  12%|█▏        | 13/112 [00:00<00:01, 55.74it/s, Epoch: 97, Batch: 13,Loss: -3.726,Avg.Loss: -3.711,LR: 1.86E-06]Training epoch 97:  12%|█▏        | 13/112 [00:00<00:01, 55.74it/s, Epoch: 97, Batch: 14,Loss: -3.657,Avg.Loss: -3.707,LR: 1.85E-06]Training epoch 97:  12%|█▎        | 14/112 [00:00<00:01, 55.74it/s, Epoch: 97, Batch: 15,Loss: -3.605,Avg.Loss: -3.700,LR: 1.84E-06]Training epoch 97:  13%|█▎        | 15/112 [00:00<00:01, 55.74it/s, Epoch: 97, Batch: 16,Loss: -3.686,Avg.Loss: -3.700,LR: 1.83E-06]Training epoch 97:  14%|█▍        | 16/112 [00:00<00:01, 55.74it/s, Epoch: 97, Batch: 17,Loss: -3.576,Avg.Loss: -3.692,LR: 1.82E-06]Training epoch 97:  15%|█▌        | 17/112 [00:00<00:01, 55.74it/s, Epoch: 97, Batch: 18,Loss: -3.945,Avg.Loss: -3.706,LR: 1.82E-06]Training epoch 97:  16%|█▌        | 18/112 [00:00<00:01, 55.74it/s, Epoch: 97, Batch: 19,Loss: -3.909,Avg.Loss: -3.717,LR: 1.81E-06]Training epoch 97:  17%|█▋        | 19/112 [00:00<00:01, 54.59it/s, Epoch: 97, Batch: 19,Loss: -3.909,Avg.Loss: -3.717,LR: 1.81E-06]Training epoch 97:  17%|█▋        | 19/112 [00:00<00:01, 54.59it/s, Epoch: 97, Batch: 20,Loss: -3.550,Avg.Loss: -3.709,LR: 1.80E-06]Training epoch 97:  18%|█▊        | 20/112 [00:00<00:01, 54.59it/s, Epoch: 97, Batch: 21,Loss: -3.819,Avg.Loss: -3.714,LR: 1.79E-06]Training epoch 97:  19%|█▉        | 21/112 [00:00<00:01, 54.59it/s, Epoch: 97, Batch: 22,Loss: -3.383,Avg.Loss: -3.699,LR: 1.78E-06]Training epoch 97:  20%|█▉        | 22/112 [00:00<00:01, 54.59it/s, Epoch: 97, Batch: 23,Loss: -4.010,Avg.Loss: -3.712,LR: 1.77E-06]Training epoch 97:  21%|██        | 23/112 [00:00<00:01, 54.59it/s, Epoch: 97, Batch: 24,Loss: -3.708,Avg.Loss: -3.712,LR: 1.77E-06]Training epoch 97:  21%|██▏       | 24/112 [00:00<00:01, 54.59it/s, Epoch: 97, Batch: 25,Loss: -3.894,Avg.Loss: -3.719,LR: 1.76E-06]Training epoch 97:  22%|██▏       | 25/112 [00:00<00:01, 53.81it/s, Epoch: 97, Batch: 25,Loss: -3.894,Avg.Loss: -3.719,LR: 1.76E-06]Training epoch 97:  22%|██▏       | 25/112 [00:00<00:01, 53.81it/s, Epoch: 97, Batch: 26,Loss: -4.229,Avg.Loss: -3.739,LR: 1.75E-06]Training epoch 97:  23%|██▎       | 26/112 [00:00<00:01, 53.81it/s, Epoch: 97, Batch: 27,Loss: -3.681,Avg.Loss: -3.737,LR: 1.74E-06]Training epoch 97:  24%|██▍       | 27/112 [00:00<00:01, 53.81it/s, Epoch: 97, Batch: 28,Loss: -3.734,Avg.Loss: -3.737,LR: 1.73E-06]Training epoch 97:  25%|██▌       | 28/112 [00:00<00:01, 53.81it/s, Epoch: 97, Batch: 29,Loss: -3.835,Avg.Loss: -3.740,LR: 1.72E-06]Training epoch 97:  26%|██▌       | 29/112 [00:00<00:01, 53.81it/s, Epoch: 97, Batch: 30,Loss: -3.931,Avg.Loss: -3.747,LR: 1.72E-06]Training epoch 97:  27%|██▋       | 30/112 [00:00<00:01, 53.81it/s, Epoch: 97, Batch: 31,Loss: -3.995,Avg.Loss: -3.755,LR: 1.71E-06]Training epoch 97:  28%|██▊       | 31/112 [00:00<00:01, 53.48it/s, Epoch: 97, Batch: 31,Loss: -3.995,Avg.Loss: -3.755,LR: 1.71E-06]Training epoch 97:  28%|██▊       | 31/112 [00:00<00:01, 53.48it/s, Epoch: 97, Batch: 32,Loss: -4.013,Avg.Loss: -3.763,LR: 1.70E-06]Training epoch 97:  29%|██▊       | 32/112 [00:00<00:01, 53.48it/s, Epoch: 97, Batch: 33,Loss: -3.817,Avg.Loss: -3.764,LR: 1.69E-06]Training epoch 97:  29%|██▉       | 33/112 [00:00<00:01, 53.48it/s, Epoch: 97, Batch: 34,Loss: -3.366,Avg.Loss: -3.753,LR: 1.68E-06]Training epoch 97:  30%|███       | 34/112 [00:00<00:01, 53.48it/s, Epoch: 97, Batch: 35,Loss: -3.803,Avg.Loss: -3.754,LR: 1.68E-06]Training epoch 97:  31%|███▏      | 35/112 [00:00<00:01, 53.48it/s, Epoch: 97, Batch: 36,Loss: -3.733,Avg.Loss: -3.753,LR: 1.67E-06]Training epoch 97:  32%|███▏      | 36/112 [00:00<00:01, 53.48it/s, Epoch: 97, Batch: 37,Loss: -3.771,Avg.Loss: -3.754,LR: 1.66E-06]Training epoch 97:  33%|███▎      | 37/112 [00:00<00:01, 52.16it/s, Epoch: 97, Batch: 37,Loss: -3.771,Avg.Loss: -3.754,LR: 1.66E-06]Training epoch 97:  33%|███▎      | 37/112 [00:00<00:01, 52.16it/s, Epoch: 97, Batch: 38,Loss: -3.771,Avg.Loss: -3.754,LR: 1.65E-06]Training epoch 97:  34%|███▍      | 38/112 [00:00<00:01, 52.16it/s, Epoch: 97, Batch: 39,Loss: -4.060,Avg.Loss: -3.762,LR: 1.64E-06]Training epoch 97:  35%|███▍      | 39/112 [00:00<00:01, 52.16it/s, Epoch: 97, Batch: 40,Loss: -3.928,Avg.Loss: -3.766,LR: 1.64E-06]Training epoch 97:  36%|███▌      | 40/112 [00:00<00:01, 52.16it/s, Epoch: 97, Batch: 41,Loss: -3.960,Avg.Loss: -3.771,LR: 1.63E-06]Training epoch 97:  37%|███▋      | 41/112 [00:00<00:01, 52.16it/s, Epoch: 97, Batch: 42,Loss: -3.396,Avg.Loss: -3.762,LR: 1.62E-06]Training epoch 97:  38%|███▊      | 42/112 [00:00<00:01, 52.16it/s, Epoch: 97, Batch: 43,Loss: -3.507,Avg.Loss: -3.756,LR: 1.61E-06]Training epoch 97:  38%|███▊      | 43/112 [00:00<00:01, 52.09it/s, Epoch: 97, Batch: 43,Loss: -3.507,Avg.Loss: -3.756,LR: 1.61E-06]Training epoch 97:  38%|███▊      | 43/112 [00:00<00:01, 52.09it/s, Epoch: 97, Batch: 44,Loss: -3.458,Avg.Loss: -3.749,LR: 1.60E-06]Training epoch 97:  39%|███▉      | 44/112 [00:00<00:01, 52.09it/s, Epoch: 97, Batch: 45,Loss: -3.972,Avg.Loss: -3.754,LR: 1.60E-06]Training epoch 97:  40%|████      | 45/112 [00:00<00:01, 52.09it/s, Epoch: 97, Batch: 46,Loss: -3.947,Avg.Loss: -3.759,LR: 1.59E-06]Training epoch 97:  41%|████      | 46/112 [00:00<00:01, 52.09it/s, Epoch: 97, Batch: 47,Loss: -3.494,Avg.Loss: -3.753,LR: 1.58E-06]Training epoch 97:  42%|████▏     | 47/112 [00:00<00:01, 52.09it/s, Epoch: 97, Batch: 48,Loss: -4.211,Avg.Loss: -3.763,LR: 1.57E-06]Training epoch 97:  43%|████▎     | 48/112 [00:00<00:01, 52.09it/s, Epoch: 97, Batch: 49,Loss: -3.962,Avg.Loss: -3.767,LR: 1.56E-06]Training epoch 97:  44%|████▍     | 49/112 [00:00<00:01, 52.50it/s, Epoch: 97, Batch: 49,Loss: -3.962,Avg.Loss: -3.767,LR: 1.56E-06]Training epoch 97:  44%|████▍     | 49/112 [00:00<00:01, 52.50it/s, Epoch: 97, Batch: 50,Loss: -3.089,Avg.Loss: -3.753,LR: 1.56E-06]Training epoch 97:  45%|████▍     | 50/112 [00:00<00:01, 52.50it/s, Epoch: 97, Batch: 51,Loss: -3.961,Avg.Loss: -3.757,LR: 1.55E-06]Training epoch 97:  46%|████▌     | 51/112 [00:00<00:01, 52.50it/s, Epoch: 97, Batch: 52,Loss: -4.031,Avg.Loss: -3.762,LR: 1.54E-06]Training epoch 97:  46%|████▋     | 52/112 [00:00<00:01, 52.50it/s, Epoch: 97, Batch: 53,Loss: -3.736,Avg.Loss: -3.762,LR: 1.53E-06]Training epoch 97:  47%|████▋     | 53/112 [00:01<00:01, 52.50it/s, Epoch: 97, Batch: 54,Loss: -4.158,Avg.Loss: -3.769,LR: 1.53E-06]Training epoch 97:  48%|████▊     | 54/112 [00:01<00:01, 52.50it/s, Epoch: 97, Batch: 55,Loss: -3.956,Avg.Loss: -3.773,LR: 1.52E-06]Training epoch 97:  49%|████▉     | 55/112 [00:01<00:01, 52.75it/s, Epoch: 97, Batch: 55,Loss: -3.956,Avg.Loss: -3.773,LR: 1.52E-06]Training epoch 97:  49%|████▉     | 55/112 [00:01<00:01, 52.75it/s, Epoch: 97, Batch: 56,Loss: -3.685,Avg.Loss: -3.771,LR: 1.51E-06]Training epoch 97:  50%|█████     | 56/112 [00:01<00:01, 52.75it/s, Epoch: 97, Batch: 57,Loss: -3.986,Avg.Loss: -3.775,LR: 1.50E-06]Training epoch 97:  51%|█████     | 57/112 [00:01<00:01, 52.75it/s, Epoch: 97, Batch: 58,Loss: -3.564,Avg.Loss: -3.771,LR: 1.49E-06]Training epoch 97:  52%|█████▏    | 58/112 [00:01<00:01, 52.75it/s, Epoch: 97, Batch: 59,Loss: -3.916,Avg.Loss: -3.774,LR: 1.49E-06]Training epoch 97:  53%|█████▎    | 59/112 [00:01<00:01, 52.75it/s, Epoch: 97, Batch: 60,Loss: -3.680,Avg.Loss: -3.772,LR: 1.48E-06]Training epoch 97:  54%|█████▎    | 60/112 [00:01<00:00, 52.75it/s, Epoch: 97, Batch: 61,Loss: -3.486,Avg.Loss: -3.767,LR: 1.47E-06]Training epoch 97:  54%|█████▍    | 61/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 61,Loss: -3.486,Avg.Loss: -3.767,LR: 1.47E-06]Training epoch 97:  54%|█████▍    | 61/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 62,Loss: -3.988,Avg.Loss: -3.771,LR: 1.46E-06]Training epoch 97:  55%|█████▌    | 62/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 63,Loss: -3.341,Avg.Loss: -3.764,LR: 1.46E-06]Training epoch 97:  56%|█████▋    | 63/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 64,Loss: -3.015,Avg.Loss: -3.752,LR: 1.45E-06]Training epoch 97:  57%|█████▋    | 64/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 65,Loss: -3.863,Avg.Loss: -3.754,LR: 1.44E-06]Training epoch 97:  58%|█████▊    | 65/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 66,Loss: -3.206,Avg.Loss: -3.746,LR: 1.43E-06]Training epoch 97:  59%|█████▉    | 66/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 67,Loss: -3.855,Avg.Loss: -3.747,LR: 1.43E-06]Training epoch 97:  60%|█████▉    | 67/112 [00:01<00:00, 53.04it/s, Epoch: 97, Batch: 67,Loss: -3.855,Avg.Loss: -3.747,LR: 1.43E-06]Training epoch 97:  60%|█████▉    | 67/112 [00:01<00:00, 53.04it/s, Epoch: 97, Batch: 68,Loss: -4.026,Avg.Loss: -3.752,LR: 1.42E-06]Training epoch 97:  61%|██████    | 68/112 [00:01<00:00, 53.04it/s, Epoch: 97, Batch: 69,Loss: -3.171,Avg.Loss: -3.743,LR: 1.41E-06]Training epoch 97:  62%|██████▏   | 69/112 [00:01<00:00, 53.04it/s, Epoch: 97, Batch: 70,Loss: -3.756,Avg.Loss: -3.743,LR: 1.40E-06]Training epoch 97:  62%|██████▎   | 70/112 [00:01<00:00, 53.04it/s, Epoch: 97, Batch: 71,Loss: -3.611,Avg.Loss: -3.741,LR: 1.40E-06]Training epoch 97:  63%|██████▎   | 71/112 [00:01<00:00, 53.04it/s, Epoch: 97, Batch: 72,Loss: -4.000,Avg.Loss: -3.745,LR: 1.39E-06]Training epoch 97:  64%|██████▍   | 72/112 [00:01<00:00, 53.04it/s, Epoch: 97, Batch: 73,Loss: -3.394,Avg.Loss: -3.740,LR: 1.38E-06]Training epoch 97:  65%|██████▌   | 73/112 [00:01<00:00, 52.88it/s, Epoch: 97, Batch: 73,Loss: -3.394,Avg.Loss: -3.740,LR: 1.38E-06]Training epoch 97:  65%|██████▌   | 73/112 [00:01<00:00, 52.88it/s, Epoch: 97, Batch: 74,Loss: -4.010,Avg.Loss: -3.744,LR: 1.37E-06]Training epoch 97:  66%|██████▌   | 74/112 [00:01<00:00, 52.88it/s, Epoch: 97, Batch: 75,Loss: -3.876,Avg.Loss: -3.746,LR: 1.37E-06]Training epoch 97:  67%|██████▋   | 75/112 [00:01<00:00, 52.88it/s, Epoch: 97, Batch: 76,Loss: -3.717,Avg.Loss: -3.745,LR: 1.36E-06]Training epoch 97:  68%|██████▊   | 76/112 [00:01<00:00, 52.88it/s, Epoch: 97, Batch: 77,Loss: -3.871,Avg.Loss: -3.747,LR: 1.35E-06]Training epoch 97:  69%|██████▉   | 77/112 [00:01<00:00, 52.88it/s, Epoch: 97, Batch: 78,Loss: -3.342,Avg.Loss: -3.742,LR: 1.35E-06]Training epoch 97:  70%|██████▉   | 78/112 [00:01<00:00, 52.88it/s, Epoch: 97, Batch: 79,Loss: -4.122,Avg.Loss: -3.746,LR: 1.34E-06]Training epoch 97:  71%|███████   | 79/112 [00:01<00:00, 52.67it/s, Epoch: 97, Batch: 79,Loss: -4.122,Avg.Loss: -3.746,LR: 1.34E-06]Training epoch 97:  71%|███████   | 79/112 [00:01<00:00, 52.67it/s, Epoch: 97, Batch: 80,Loss: -3.884,Avg.Loss: -3.748,LR: 1.33E-06]Training epoch 97:  71%|███████▏  | 80/112 [00:01<00:00, 52.67it/s, Epoch: 97, Batch: 81,Loss: -3.842,Avg.Loss: -3.749,LR: 1.32E-06]Training epoch 97:  72%|███████▏  | 81/112 [00:01<00:00, 52.67it/s, Epoch: 97, Batch: 82,Loss: -3.832,Avg.Loss: -3.750,LR: 1.32E-06]Training epoch 97:  73%|███████▎  | 82/112 [00:01<00:00, 52.67it/s, Epoch: 97, Batch: 83,Loss: -3.344,Avg.Loss: -3.745,LR: 1.31E-06]Training epoch 97:  74%|███████▍  | 83/112 [00:01<00:00, 52.67it/s, Epoch: 97, Batch: 84,Loss: -3.688,Avg.Loss: -3.745,LR: 1.30E-06]Training epoch 97:  75%|███████▌  | 84/112 [00:01<00:00, 52.67it/s, Epoch: 97, Batch: 85,Loss: -3.652,Avg.Loss: -3.744,LR: 1.29E-06]Training epoch 97:  76%|███████▌  | 85/112 [00:01<00:00, 52.85it/s, Epoch: 97, Batch: 85,Loss: -3.652,Avg.Loss: -3.744,LR: 1.29E-06]Training epoch 97:  76%|███████▌  | 85/112 [00:01<00:00, 52.85it/s, Epoch: 97, Batch: 86,Loss: -3.803,Avg.Loss: -3.744,LR: 1.29E-06]Training epoch 97:  77%|███████▋  | 86/112 [00:01<00:00, 52.85it/s, Epoch: 97, Batch: 87,Loss: -3.488,Avg.Loss: -3.741,LR: 1.28E-06]Training epoch 97:  78%|███████▊  | 87/112 [00:01<00:00, 52.85it/s, Epoch: 97, Batch: 88,Loss: -3.215,Avg.Loss: -3.735,LR: 1.27E-06]Training epoch 97:  79%|███████▊  | 88/112 [00:01<00:00, 52.85it/s, Epoch: 97, Batch: 89,Loss: -3.612,Avg.Loss: -3.734,LR: 1.27E-06]Training epoch 97:  79%|███████▉  | 89/112 [00:01<00:00, 52.85it/s, Epoch: 97, Batch: 90,Loss: -3.653,Avg.Loss: -3.733,LR: 1.26E-06]Training epoch 97:  80%|████████  | 90/112 [00:01<00:00, 52.85it/s, Epoch: 97, Batch: 91,Loss: -3.384,Avg.Loss: -3.729,LR: 1.25E-06]Training epoch 97:  81%|████████▏ | 91/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 91,Loss: -3.384,Avg.Loss: -3.729,LR: 1.25E-06]Training epoch 97:  81%|████████▏ | 91/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 92,Loss: -3.767,Avg.Loss: -3.730,LR: 1.25E-06]Training epoch 97:  82%|████████▏ | 92/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 93,Loss: -3.802,Avg.Loss: -3.731,LR: 1.24E-06]Training epoch 97:  83%|████████▎ | 93/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 94,Loss: -3.923,Avg.Loss: -3.733,LR: 1.23E-06]Training epoch 97:  84%|████████▍ | 94/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 95,Loss: -3.831,Avg.Loss: -3.734,LR: 1.22E-06]Training epoch 97:  85%|████████▍ | 95/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 96,Loss: -3.630,Avg.Loss: -3.733,LR: 1.22E-06]Training epoch 97:  86%|████████▌ | 96/112 [00:01<00:00, 53.01it/s, Epoch: 97, Batch: 97,Loss: -3.992,Avg.Loss: -3.735,LR: 1.21E-06]Training epoch 97:  87%|████████▋ | 97/112 [00:01<00:00, 53.21it/s, Epoch: 97, Batch: 97,Loss: -3.992,Avg.Loss: -3.735,LR: 1.21E-06]Training epoch 97:  87%|████████▋ | 97/112 [00:01<00:00, 53.21it/s, Epoch: 97, Batch: 98,Loss: -3.787,Avg.Loss: -3.736,LR: 1.20E-06]Training epoch 97:  88%|████████▊ | 98/112 [00:01<00:00, 53.21it/s, Epoch: 97, Batch: 99,Loss: -3.479,Avg.Loss: -3.733,LR: 1.20E-06]Training epoch 97:  88%|████████▊ | 99/112 [00:01<00:00, 53.21it/s, Epoch: 97, Batch: 100,Loss: -3.227,Avg.Loss: -3.728,LR: 1.19E-06]Training epoch 97:  89%|████████▉ | 100/112 [00:01<00:00, 53.21it/s, Epoch: 97, Batch: 101,Loss: -3.883,Avg.Loss: -3.730,LR: 1.18E-06]Training epoch 97:  90%|█████████ | 101/112 [00:01<00:00, 53.21it/s, Epoch: 97, Batch: 102,Loss: -3.935,Avg.Loss: -3.732,LR: 1.18E-06]Training epoch 97:  91%|█████████ | 102/112 [00:01<00:00, 53.21it/s, Epoch: 97, Batch: 103,Loss: -3.766,Avg.Loss: -3.732,LR: 1.17E-06]Training epoch 97:  92%|█████████▏| 103/112 [00:01<00:00, 53.10it/s, Epoch: 97, Batch: 103,Loss: -3.766,Avg.Loss: -3.732,LR: 1.17E-06]Training epoch 97:  92%|█████████▏| 103/112 [00:01<00:00, 53.10it/s, Epoch: 97, Batch: 104,Loss: -3.541,Avg.Loss: -3.730,LR: 1.16E-06]Training epoch 97:  93%|█████████▎| 104/112 [00:01<00:00, 53.10it/s, Epoch: 97, Batch: 105,Loss: -3.741,Avg.Loss: -3.730,LR: 1.16E-06]Training epoch 97:  94%|█████████▍| 105/112 [00:01<00:00, 53.10it/s, Epoch: 97, Batch: 106,Loss: -4.163,Avg.Loss: -3.734,LR: 1.15E-06]Training epoch 97:  95%|█████████▍| 106/112 [00:02<00:00, 53.10it/s, Epoch: 97, Batch: 107,Loss: -3.690,Avg.Loss: -3.734,LR: 1.14E-06]Training epoch 97:  96%|█████████▌| 107/112 [00:02<00:00, 53.10it/s, Epoch: 97, Batch: 108,Loss: -3.849,Avg.Loss: -3.735,LR: 1.14E-06]Training epoch 97:  96%|█████████▋| 108/112 [00:02<00:00, 53.10it/s, Epoch: 97, Batch: 109,Loss: -3.801,Avg.Loss: -3.736,LR: 1.13E-06]Training epoch 97:  97%|█████████▋| 109/112 [00:02<00:00, 53.08it/s, Epoch: 97, Batch: 109,Loss: -3.801,Avg.Loss: -3.736,LR: 1.13E-06]Training epoch 97:  97%|█████████▋| 109/112 [00:02<00:00, 53.08it/s, Epoch: 97, Batch: 110,Loss: -3.600,Avg.Loss: -3.734,LR: 1.12E-06]Training epoch 97:  98%|█████████▊| 110/112 [00:02<00:00, 53.08it/s, Epoch: 97, Batch: 111,Loss: -3.996,Avg.Loss: -3.737,LR: 1.12E-06]Training epoch 97:  99%|█████████▉| 111/112 [00:02<00:00, 53.08it/s, Epoch: 97, Batch: 112,Loss: -4.285,Avg.Loss: -3.742,LR: 1.11E-06]Training epoch 97: 100%|██████████| 112/112 [00:02<00:00, 53.11it/s, Epoch: 97, Batch: 112,Loss: -4.285,Avg.Loss: -3.742,LR: 1.11E-06]
Training epoch 98:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 98:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 98, Batch: 1,Loss: -4.103,Avg.Loss: -4.103,LR: 1.10E-06]Training epoch 98:   1%|          | 1/112 [00:00<00:03, 29.73it/s, Epoch: 98, Batch: 2,Loss: -3.496,Avg.Loss: -3.799,LR: 1.10E-06]Training epoch 98:   2%|▏         | 2/112 [00:00<00:02, 39.26it/s, Epoch: 98, Batch: 3,Loss: -3.225,Avg.Loss: -3.608,LR: 1.09E-06]Training epoch 98:   3%|▎         | 3/112 [00:00<00:02, 43.76it/s, Epoch: 98, Batch: 4,Loss: -3.855,Avg.Loss: -3.670,LR: 1.08E-06]Training epoch 98:   4%|▎         | 4/112 [00:00<00:02, 46.52it/s, Epoch: 98, Batch: 5,Loss: -3.925,Avg.Loss: -3.721,LR: 1.08E-06]Training epoch 98:   4%|▍         | 5/112 [00:00<00:02, 48.09it/s, Epoch: 98, Batch: 6,Loss: -3.827,Avg.Loss: -3.739,LR: 1.07E-06]Training epoch 98:   5%|▌         | 6/112 [00:00<00:01, 57.60it/s, Epoch: 98, Batch: 6,Loss: -3.827,Avg.Loss: -3.739,LR: 1.07E-06]Training epoch 98:   5%|▌         | 6/112 [00:00<00:01, 57.60it/s, Epoch: 98, Batch: 7,Loss: -3.588,Avg.Loss: -3.717,LR: 1.06E-06]Training epoch 98:   6%|▋         | 7/112 [00:00<00:01, 57.60it/s, Epoch: 98, Batch: 8,Loss: -3.542,Avg.Loss: -3.695,LR: 1.06E-06]Training epoch 98:   7%|▋         | 8/112 [00:00<00:01, 57.60it/s, Epoch: 98, Batch: 9,Loss: -3.716,Avg.Loss: -3.698,LR: 1.05E-06]Training epoch 98:   8%|▊         | 9/112 [00:00<00:01, 57.60it/s, Epoch: 98, Batch: 10,Loss: -4.029,Avg.Loss: -3.731,LR: 1.04E-06]Training epoch 98:   9%|▉         | 10/112 [00:00<00:01, 57.60it/s, Epoch: 98, Batch: 11,Loss: -3.557,Avg.Loss: -3.715,LR: 1.04E-06]Training epoch 98:  10%|▉         | 11/112 [00:00<00:01, 57.60it/s, Epoch: 98, Batch: 12,Loss: -3.757,Avg.Loss: -3.718,LR: 1.03E-06]Training epoch 98:  11%|█         | 12/112 [00:00<00:01, 55.07it/s, Epoch: 98, Batch: 12,Loss: -3.757,Avg.Loss: -3.718,LR: 1.03E-06]Training epoch 98:  11%|█         | 12/112 [00:00<00:01, 55.07it/s, Epoch: 98, Batch: 13,Loss: -3.934,Avg.Loss: -3.735,LR: 1.03E-06]Training epoch 98:  12%|█▏        | 13/112 [00:00<00:01, 55.07it/s, Epoch: 98, Batch: 14,Loss: -3.894,Avg.Loss: -3.746,LR: 1.02E-06]Training epoch 98:  12%|█▎        | 14/112 [00:00<00:01, 55.07it/s, Epoch: 98, Batch: 15,Loss: -3.945,Avg.Loss: -3.759,LR: 1.01E-06]Training epoch 98:  13%|█▎        | 15/112 [00:00<00:01, 55.07it/s, Epoch: 98, Batch: 16,Loss: -3.638,Avg.Loss: -3.752,LR: 1.01E-06]Training epoch 98:  14%|█▍        | 16/112 [00:00<00:01, 55.07it/s, Epoch: 98, Batch: 17,Loss: -3.468,Avg.Loss: -3.735,LR: 1.00E-06]Training epoch 98:  15%|█▌        | 17/112 [00:00<00:01, 55.07it/s, Epoch: 98, Batch: 18,Loss: -4.128,Avg.Loss: -3.757,LR: 9.94E-07]Training epoch 98:  16%|█▌        | 18/112 [00:00<00:01, 54.32it/s, Epoch: 98, Batch: 18,Loss: -4.128,Avg.Loss: -3.757,LR: 9.94E-07]Training epoch 98:  16%|█▌        | 18/112 [00:00<00:01, 54.32it/s, Epoch: 98, Batch: 19,Loss: -3.635,Avg.Loss: -3.751,LR: 9.88E-07]Training epoch 98:  17%|█▋        | 19/112 [00:00<00:01, 54.32it/s, Epoch: 98, Batch: 20,Loss: -3.571,Avg.Loss: -3.742,LR: 9.81E-07]Training epoch 98:  18%|█▊        | 20/112 [00:00<00:01, 54.32it/s, Epoch: 98, Batch: 21,Loss: -3.649,Avg.Loss: -3.737,LR: 9.75E-07]Training epoch 98:  19%|█▉        | 21/112 [00:00<00:01, 54.32it/s, Epoch: 98, Batch: 22,Loss: -3.997,Avg.Loss: -3.749,LR: 9.69E-07]Training epoch 98:  20%|█▉        | 22/112 [00:00<00:01, 54.32it/s, Epoch: 98, Batch: 23,Loss: -4.112,Avg.Loss: -3.765,LR: 9.63E-07]Training epoch 98:  21%|██        | 23/112 [00:00<00:01, 54.32it/s, Epoch: 98, Batch: 24,Loss: -3.925,Avg.Loss: -3.771,LR: 9.57E-07]Training epoch 98:  21%|██▏       | 24/112 [00:00<00:01, 53.70it/s, Epoch: 98, Batch: 24,Loss: -3.925,Avg.Loss: -3.771,LR: 9.57E-07]Training epoch 98:  21%|██▏       | 24/112 [00:00<00:01, 53.70it/s, Epoch: 98, Batch: 25,Loss: -3.580,Avg.Loss: -3.764,LR: 9.51E-07]Training epoch 98:  22%|██▏       | 25/112 [00:00<00:01, 53.70it/s, Epoch: 98, Batch: 26,Loss: -3.796,Avg.Loss: -3.765,LR: 9.45E-07]Training epoch 98:  23%|██▎       | 26/112 [00:00<00:01, 53.70it/s, Epoch: 98, Batch: 27,Loss: -3.412,Avg.Loss: -3.752,LR: 9.38E-07]Training epoch 98:  24%|██▍       | 27/112 [00:00<00:01, 53.70it/s, Epoch: 98, Batch: 28,Loss: -3.842,Avg.Loss: -3.755,LR: 9.32E-07]Training epoch 98:  25%|██▌       | 28/112 [00:00<00:01, 53.70it/s, Epoch: 98, Batch: 29,Loss: -3.912,Avg.Loss: -3.761,LR: 9.26E-07]Training epoch 98:  26%|██▌       | 29/112 [00:00<00:01, 53.70it/s, Epoch: 98, Batch: 30,Loss: -3.758,Avg.Loss: -3.761,LR: 9.20E-07]Training epoch 98:  27%|██▋       | 30/112 [00:00<00:01, 53.18it/s, Epoch: 98, Batch: 30,Loss: -3.758,Avg.Loss: -3.761,LR: 9.20E-07]Training epoch 98:  27%|██▋       | 30/112 [00:00<00:01, 53.18it/s, Epoch: 98, Batch: 31,Loss: -3.935,Avg.Loss: -3.766,LR: 9.14E-07]Training epoch 98:  28%|██▊       | 31/112 [00:00<00:01, 53.18it/s, Epoch: 98, Batch: 32,Loss: -3.293,Avg.Loss: -3.751,LR: 9.08E-07]Training epoch 98:  29%|██▊       | 32/112 [00:00<00:01, 53.18it/s, Epoch: 98, Batch: 33,Loss: -3.713,Avg.Loss: -3.750,LR: 9.02E-07]Training epoch 98:  29%|██▉       | 33/112 [00:00<00:01, 53.18it/s, Epoch: 98, Batch: 34,Loss: -3.745,Avg.Loss: -3.750,LR: 8.96E-07]Training epoch 98:  30%|███       | 34/112 [00:00<00:01, 53.18it/s, Epoch: 98, Batch: 35,Loss: -3.834,Avg.Loss: -3.752,LR: 8.91E-07]Training epoch 98:  31%|███▏      | 35/112 [00:00<00:01, 53.18it/s, Epoch: 98, Batch: 36,Loss: -3.597,Avg.Loss: -3.748,LR: 8.85E-07]Training epoch 98:  32%|███▏      | 36/112 [00:00<00:01, 53.05it/s, Epoch: 98, Batch: 36,Loss: -3.597,Avg.Loss: -3.748,LR: 8.85E-07]Training epoch 98:  32%|███▏      | 36/112 [00:00<00:01, 53.05it/s, Epoch: 98, Batch: 37,Loss: -3.836,Avg.Loss: -3.751,LR: 8.79E-07]Training epoch 98:  33%|███▎      | 37/112 [00:00<00:01, 53.05it/s, Epoch: 98, Batch: 38,Loss: -3.770,Avg.Loss: -3.751,LR: 8.73E-07]Training epoch 98:  34%|███▍      | 38/112 [00:00<00:01, 53.05it/s, Epoch: 98, Batch: 39,Loss: -3.865,Avg.Loss: -3.754,LR: 8.67E-07]Training epoch 98:  35%|███▍      | 39/112 [00:00<00:01, 53.05it/s, Epoch: 98, Batch: 40,Loss: -3.765,Avg.Loss: -3.754,LR: 8.61E-07]Training epoch 98:  36%|███▌      | 40/112 [00:00<00:01, 53.05it/s, Epoch: 98, Batch: 41,Loss: -3.881,Avg.Loss: -3.757,LR: 8.55E-07]Training epoch 98:  37%|███▋      | 41/112 [00:00<00:01, 53.05it/s, Epoch: 98, Batch: 42,Loss: -3.797,Avg.Loss: -3.758,LR: 8.50E-07]Training epoch 98:  38%|███▊      | 42/112 [00:00<00:01, 53.11it/s, Epoch: 98, Batch: 42,Loss: -3.797,Avg.Loss: -3.758,LR: 8.50E-07]Training epoch 98:  38%|███▊      | 42/112 [00:00<00:01, 53.11it/s, Epoch: 98, Batch: 43,Loss: -3.880,Avg.Loss: -3.761,LR: 8.44E-07]Training epoch 98:  38%|███▊      | 43/112 [00:00<00:01, 53.11it/s, Epoch: 98, Batch: 44,Loss: -3.644,Avg.Loss: -3.758,LR: 8.38E-07]Training epoch 98:  39%|███▉      | 44/112 [00:00<00:01, 53.11it/s, Epoch: 98, Batch: 45,Loss: -3.561,Avg.Loss: -3.754,LR: 8.32E-07]Training epoch 98:  40%|████      | 45/112 [00:00<00:01, 53.11it/s, Epoch: 98, Batch: 46,Loss: -3.771,Avg.Loss: -3.754,LR: 8.27E-07]Training epoch 98:  41%|████      | 46/112 [00:00<00:01, 53.11it/s, Epoch: 98, Batch: 47,Loss: -3.258,Avg.Loss: -3.744,LR: 8.21E-07]Training epoch 98:  42%|████▏     | 47/112 [00:00<00:01, 53.11it/s, Epoch: 98, Batch: 48,Loss: -4.143,Avg.Loss: -3.752,LR: 8.15E-07]Training epoch 98:  43%|████▎     | 48/112 [00:00<00:01, 52.93it/s, Epoch: 98, Batch: 48,Loss: -4.143,Avg.Loss: -3.752,LR: 8.15E-07]Training epoch 98:  43%|████▎     | 48/112 [00:00<00:01, 52.93it/s, Epoch: 98, Batch: 49,Loss: -3.607,Avg.Loss: -3.749,LR: 8.10E-07]Training epoch 98:  44%|████▍     | 49/112 [00:00<00:01, 52.93it/s, Epoch: 98, Batch: 50,Loss: -3.841,Avg.Loss: -3.751,LR: 8.04E-07]Training epoch 98:  45%|████▍     | 50/112 [00:00<00:01, 52.93it/s, Epoch: 98, Batch: 51,Loss: -3.759,Avg.Loss: -3.751,LR: 7.98E-07]Training epoch 98:  46%|████▌     | 51/112 [00:00<00:01, 52.93it/s, Epoch: 98, Batch: 52,Loss: -3.613,Avg.Loss: -3.749,LR: 7.93E-07]Training epoch 98:  46%|████▋     | 52/112 [00:00<00:01, 52.93it/s, Epoch: 98, Batch: 53,Loss: -3.493,Avg.Loss: -3.744,LR: 7.87E-07]Training epoch 98:  47%|████▋     | 53/112 [00:01<00:01, 52.93it/s, Epoch: 98, Batch: 54,Loss: -3.543,Avg.Loss: -3.740,LR: 7.82E-07]Training epoch 98:  48%|████▊     | 54/112 [00:01<00:01, 53.02it/s, Epoch: 98, Batch: 54,Loss: -3.543,Avg.Loss: -3.740,LR: 7.82E-07]Training epoch 98:  48%|████▊     | 54/112 [00:01<00:01, 53.02it/s, Epoch: 98, Batch: 55,Loss: -3.891,Avg.Loss: -3.743,LR: 7.76E-07]Training epoch 98:  49%|████▉     | 55/112 [00:01<00:01, 53.02it/s, Epoch: 98, Batch: 56,Loss: -3.581,Avg.Loss: -3.740,LR: 7.71E-07]Training epoch 98:  50%|█████     | 56/112 [00:01<00:01, 53.02it/s, Epoch: 98, Batch: 57,Loss: -3.290,Avg.Loss: -3.732,LR: 7.65E-07]Training epoch 98:  51%|█████     | 57/112 [00:01<00:01, 53.02it/s, Epoch: 98, Batch: 58,Loss: -3.728,Avg.Loss: -3.732,LR: 7.60E-07]Training epoch 98:  52%|█████▏    | 58/112 [00:01<00:01, 53.02it/s, Epoch: 98, Batch: 59,Loss: -3.847,Avg.Loss: -3.734,LR: 7.54E-07]Training epoch 98:  53%|█████▎    | 59/112 [00:01<00:00, 53.02it/s, Epoch: 98, Batch: 60,Loss: -3.830,Avg.Loss: -3.735,LR: 7.49E-07]Training epoch 98:  54%|█████▎    | 60/112 [00:01<00:00, 53.03it/s, Epoch: 98, Batch: 60,Loss: -3.830,Avg.Loss: -3.735,LR: 7.49E-07]Training epoch 98:  54%|█████▎    | 60/112 [00:01<00:00, 53.03it/s, Epoch: 98, Batch: 61,Loss: -3.838,Avg.Loss: -3.737,LR: 7.43E-07]Training epoch 98:  54%|█████▍    | 61/112 [00:01<00:00, 53.03it/s, Epoch: 98, Batch: 62,Loss: -3.758,Avg.Loss: -3.737,LR: 7.38E-07]Training epoch 98:  55%|█████▌    | 62/112 [00:01<00:00, 53.03it/s, Epoch: 98, Batch: 63,Loss: -3.750,Avg.Loss: -3.738,LR: 7.33E-07]Training epoch 98:  56%|█████▋    | 63/112 [00:01<00:00, 53.03it/s, Epoch: 98, Batch: 64,Loss: -3.578,Avg.Loss: -3.735,LR: 7.27E-07]Training epoch 98:  57%|█████▋    | 64/112 [00:01<00:00, 53.03it/s, Epoch: 98, Batch: 65,Loss: -3.257,Avg.Loss: -3.728,LR: 7.22E-07]Training epoch 98:  58%|█████▊    | 65/112 [00:01<00:00, 53.03it/s, Epoch: 98, Batch: 66,Loss: -3.699,Avg.Loss: -3.727,LR: 7.17E-07]Training epoch 98:  59%|█████▉    | 66/112 [00:01<00:00, 53.01it/s, Epoch: 98, Batch: 66,Loss: -3.699,Avg.Loss: -3.727,LR: 7.17E-07]Training epoch 98:  59%|█████▉    | 66/112 [00:01<00:00, 53.01it/s, Epoch: 98, Batch: 67,Loss: -3.748,Avg.Loss: -3.728,LR: 7.11E-07]Training epoch 98:  60%|█████▉    | 67/112 [00:01<00:00, 53.01it/s, Epoch: 98, Batch: 68,Loss: -3.614,Avg.Loss: -3.726,LR: 7.06E-07]Training epoch 98:  61%|██████    | 68/112 [00:01<00:00, 53.01it/s, Epoch: 98, Batch: 69,Loss: -3.404,Avg.Loss: -3.721,LR: 7.01E-07]Training epoch 98:  62%|██████▏   | 69/112 [00:01<00:00, 53.01it/s, Epoch: 98, Batch: 70,Loss: -3.808,Avg.Loss: -3.723,LR: 6.96E-07]Training epoch 98:  62%|██████▎   | 70/112 [00:01<00:00, 53.01it/s, Epoch: 98, Batch: 71,Loss: -3.688,Avg.Loss: -3.722,LR: 6.90E-07]Training epoch 98:  63%|██████▎   | 71/112 [00:01<00:00, 53.01it/s, Epoch: 98, Batch: 72,Loss: -3.158,Avg.Loss: -3.714,LR: 6.85E-07]Training epoch 98:  64%|██████▍   | 72/112 [00:01<00:00, 53.12it/s, Epoch: 98, Batch: 72,Loss: -3.158,Avg.Loss: -3.714,LR: 6.85E-07]Training epoch 98:  64%|██████▍   | 72/112 [00:01<00:00, 53.12it/s, Epoch: 98, Batch: 73,Loss: -4.072,Avg.Loss: -3.719,LR: 6.80E-07]Training epoch 98:  65%|██████▌   | 73/112 [00:01<00:00, 53.12it/s, Epoch: 98, Batch: 74,Loss: -3.814,Avg.Loss: -3.720,LR: 6.75E-07]Training epoch 98:  66%|██████▌   | 74/112 [00:01<00:00, 53.12it/s, Epoch: 98, Batch: 75,Loss: -3.368,Avg.Loss: -3.716,LR: 6.70E-07]Training epoch 98:  67%|██████▋   | 75/112 [00:01<00:00, 53.12it/s, Epoch: 98, Batch: 76,Loss: -3.897,Avg.Loss: -3.718,LR: 6.65E-07]Training epoch 98:  68%|██████▊   | 76/112 [00:01<00:00, 53.12it/s, Epoch: 98, Batch: 77,Loss: -3.632,Avg.Loss: -3.717,LR: 6.59E-07]Training epoch 98:  69%|██████▉   | 77/112 [00:01<00:00, 53.12it/s, Epoch: 98, Batch: 78,Loss: -4.005,Avg.Loss: -3.721,LR: 6.54E-07]Training epoch 98:  70%|██████▉   | 78/112 [00:01<00:00, 53.21it/s, Epoch: 98, Batch: 78,Loss: -4.005,Avg.Loss: -3.721,LR: 6.54E-07]Training epoch 98:  70%|██████▉   | 78/112 [00:01<00:00, 53.21it/s, Epoch: 98, Batch: 79,Loss: -3.735,Avg.Loss: -3.721,LR: 6.49E-07]Training epoch 98:  71%|███████   | 79/112 [00:01<00:00, 53.21it/s, Epoch: 98, Batch: 80,Loss: -3.759,Avg.Loss: -3.721,LR: 6.44E-07]Training epoch 98:  71%|███████▏  | 80/112 [00:01<00:00, 53.21it/s, Epoch: 98, Batch: 81,Loss: -3.771,Avg.Loss: -3.722,LR: 6.39E-07]Training epoch 98:  72%|███████▏  | 81/112 [00:01<00:00, 53.21it/s, Epoch: 98, Batch: 82,Loss: -3.776,Avg.Loss: -3.723,LR: 6.34E-07]Training epoch 98:  73%|███████▎  | 82/112 [00:01<00:00, 53.21it/s, Epoch: 98, Batch: 83,Loss: -3.604,Avg.Loss: -3.721,LR: 6.29E-07]Training epoch 98:  74%|███████▍  | 83/112 [00:01<00:00, 53.21it/s, Epoch: 98, Batch: 84,Loss: -4.002,Avg.Loss: -3.725,LR: 6.24E-07]Training epoch 98:  75%|███████▌  | 84/112 [00:01<00:00, 53.34it/s, Epoch: 98, Batch: 84,Loss: -4.002,Avg.Loss: -3.725,LR: 6.24E-07]Training epoch 98:  75%|███████▌  | 84/112 [00:01<00:00, 53.34it/s, Epoch: 98, Batch: 85,Loss: -3.757,Avg.Loss: -3.725,LR: 6.19E-07]Training epoch 98:  76%|███████▌  | 85/112 [00:01<00:00, 53.34it/s, Epoch: 98, Batch: 86,Loss: -3.798,Avg.Loss: -3.726,LR: 6.14E-07]Training epoch 98:  77%|███████▋  | 86/112 [00:01<00:00, 53.34it/s, Epoch: 98, Batch: 87,Loss: -3.556,Avg.Loss: -3.724,LR: 6.10E-07]Training epoch 98:  78%|███████▊  | 87/112 [00:01<00:00, 53.34it/s, Epoch: 98, Batch: 88,Loss: -3.679,Avg.Loss: -3.723,LR: 6.05E-07]Training epoch 98:  79%|███████▊  | 88/112 [00:01<00:00, 53.34it/s, Epoch: 98, Batch: 89,Loss: -4.004,Avg.Loss: -3.726,LR: 6.00E-07]Training epoch 98:  79%|███████▉  | 89/112 [00:01<00:00, 53.34it/s, Epoch: 98, Batch: 90,Loss: -3.568,Avg.Loss: -3.725,LR: 5.95E-07]Training epoch 98:  80%|████████  | 90/112 [00:01<00:00, 53.54it/s, Epoch: 98, Batch: 90,Loss: -3.568,Avg.Loss: -3.725,LR: 5.95E-07]Training epoch 98:  80%|████████  | 90/112 [00:01<00:00, 53.54it/s, Epoch: 98, Batch: 91,Loss: -4.062,Avg.Loss: -3.728,LR: 5.90E-07]Training epoch 98:  81%|████████▏ | 91/112 [00:01<00:00, 53.54it/s, Epoch: 98, Batch: 92,Loss: -4.042,Avg.Loss: -3.732,LR: 5.85E-07]Training epoch 98:  82%|████████▏ | 92/112 [00:01<00:00, 53.54it/s, Epoch: 98, Batch: 93,Loss: -3.841,Avg.Loss: -3.733,LR: 5.81E-07]Training epoch 98:  83%|████████▎ | 93/112 [00:01<00:00, 53.54it/s, Epoch: 98, Batch: 94,Loss: -4.223,Avg.Loss: -3.738,LR: 5.76E-07]Training epoch 98:  84%|████████▍ | 94/112 [00:01<00:00, 53.54it/s, Epoch: 98, Batch: 95,Loss: -3.655,Avg.Loss: -3.737,LR: 5.71E-07]Training epoch 98:  85%|████████▍ | 95/112 [00:01<00:00, 53.54it/s, Epoch: 98, Batch: 96,Loss: -3.700,Avg.Loss: -3.737,LR: 5.66E-07]Training epoch 98:  86%|████████▌ | 96/112 [00:01<00:00, 53.53it/s, Epoch: 98, Batch: 96,Loss: -3.700,Avg.Loss: -3.737,LR: 5.66E-07]Training epoch 98:  86%|████████▌ | 96/112 [00:01<00:00, 53.53it/s, Epoch: 98, Batch: 97,Loss: -3.881,Avg.Loss: -3.738,LR: 5.62E-07]Training epoch 98:  87%|████████▋ | 97/112 [00:01<00:00, 53.53it/s, Epoch: 98, Batch: 98,Loss: -4.022,Avg.Loss: -3.741,LR: 5.57E-07]Training epoch 98:  88%|████████▊ | 98/112 [00:01<00:00, 53.53it/s, Epoch: 98, Batch: 99,Loss: -3.592,Avg.Loss: -3.740,LR: 5.52E-07]Training epoch 98:  88%|████████▊ | 99/112 [00:01<00:00, 53.53it/s, Epoch: 98, Batch: 100,Loss: -3.690,Avg.Loss: -3.739,LR: 5.48E-07]Training epoch 98:  89%|████████▉ | 100/112 [00:01<00:00, 53.53it/s, Epoch: 98, Batch: 101,Loss: -3.847,Avg.Loss: -3.740,LR: 5.43E-07]Training epoch 98:  90%|█████████ | 101/112 [00:01<00:00, 53.53it/s, Epoch: 98, Batch: 102,Loss: -3.571,Avg.Loss: -3.739,LR: 5.38E-07]Training epoch 98:  91%|█████████ | 102/112 [00:01<00:00, 53.57it/s, Epoch: 98, Batch: 102,Loss: -3.571,Avg.Loss: -3.739,LR: 5.38E-07]Training epoch 98:  91%|█████████ | 102/112 [00:01<00:00, 53.57it/s, Epoch: 98, Batch: 103,Loss: -3.549,Avg.Loss: -3.737,LR: 5.34E-07]Training epoch 98:  92%|█████████▏| 103/112 [00:01<00:00, 53.57it/s, Epoch: 98, Batch: 104,Loss: -3.737,Avg.Loss: -3.737,LR: 5.29E-07]Training epoch 98:  93%|█████████▎| 104/112 [00:01<00:00, 53.57it/s, Epoch: 98, Batch: 105,Loss: -3.448,Avg.Loss: -3.734,LR: 5.25E-07]Training epoch 98:  94%|█████████▍| 105/112 [00:01<00:00, 53.57it/s, Epoch: 98, Batch: 106,Loss: -3.760,Avg.Loss: -3.734,LR: 5.20E-07]Training epoch 98:  95%|█████████▍| 106/112 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 107,Loss: -4.047,Avg.Loss: -3.737,LR: 5.16E-07]Training epoch 98:  96%|█████████▌| 107/112 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 108,Loss: -3.982,Avg.Loss: -3.740,LR: 5.11E-07]Training epoch 98:  96%|█████████▋| 108/112 [00:02<00:00, 53.68it/s, Epoch: 98, Batch: 108,Loss: -3.982,Avg.Loss: -3.740,LR: 5.11E-07]Training epoch 98:  96%|█████████▋| 108/112 [00:02<00:00, 53.68it/s, Epoch: 98, Batch: 109,Loss: -3.729,Avg.Loss: -3.739,LR: 5.07E-07]Training epoch 98:  97%|█████████▋| 109/112 [00:02<00:00, 53.68it/s, Epoch: 98, Batch: 110,Loss: -4.088,Avg.Loss: -3.743,LR: 5.02E-07]Training epoch 98:  98%|█████████▊| 110/112 [00:02<00:00, 53.68it/s, Epoch: 98, Batch: 111,Loss: -3.702,Avg.Loss: -3.742,LR: 4.98E-07]Training epoch 98:  99%|█████████▉| 111/112 [00:02<00:00, 53.68it/s, Epoch: 98, Batch: 112,Loss: -3.622,Avg.Loss: -3.741,LR: 4.93E-07]Training epoch 98: 100%|██████████| 112/112 [00:02<00:00, 53.38it/s, Epoch: 98, Batch: 112,Loss: -3.622,Avg.Loss: -3.741,LR: 4.93E-07]
Training epoch 99:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 99:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 99, Batch: 1,Loss: -3.898,Avg.Loss: -3.898,LR: 4.89E-07]Training epoch 99:   1%|          | 1/112 [00:00<00:04, 26.63it/s, Epoch: 99, Batch: 2,Loss: -3.510,Avg.Loss: -3.704,LR: 4.85E-07]Training epoch 99:   2%|▏         | 2/112 [00:00<00:02, 38.46it/s, Epoch: 99, Batch: 3,Loss: -3.235,Avg.Loss: -3.548,LR: 4.80E-07]Training epoch 99:   3%|▎         | 3/112 [00:00<00:02, 42.64it/s, Epoch: 99, Batch: 4,Loss: -3.797,Avg.Loss: -3.610,LR: 4.76E-07]Training epoch 99:   4%|▎         | 4/112 [00:00<00:02, 44.72it/s, Epoch: 99, Batch: 5,Loss: -3.820,Avg.Loss: -3.652,LR: 4.72E-07]Training epoch 99:   4%|▍         | 5/112 [00:00<00:02, 45.85it/s, Epoch: 99, Batch: 6,Loss: -3.606,Avg.Loss: -3.644,LR: 4.67E-07]Training epoch 99:   5%|▌         | 6/112 [00:00<00:01, 54.92it/s, Epoch: 99, Batch: 6,Loss: -3.606,Avg.Loss: -3.644,LR: 4.67E-07]Training epoch 99:   5%|▌         | 6/112 [00:00<00:01, 54.92it/s, Epoch: 99, Batch: 7,Loss: -3.498,Avg.Loss: -3.624,LR: 4.63E-07]Training epoch 99:   6%|▋         | 7/112 [00:00<00:01, 54.92it/s, Epoch: 99, Batch: 8,Loss: -3.823,Avg.Loss: -3.648,LR: 4.59E-07]Training epoch 99:   7%|▋         | 8/112 [00:00<00:01, 54.92it/s, Epoch: 99, Batch: 9,Loss: -3.519,Avg.Loss: -3.634,LR: 4.54E-07]Training epoch 99:   8%|▊         | 9/112 [00:00<00:01, 54.92it/s, Epoch: 99, Batch: 10,Loss: -3.873,Avg.Loss: -3.658,LR: 4.50E-07]Training epoch 99:   9%|▉         | 10/112 [00:00<00:01, 54.92it/s, Epoch: 99, Batch: 11,Loss: -3.939,Avg.Loss: -3.684,LR: 4.46E-07]Training epoch 99:  10%|▉         | 11/112 [00:00<00:01, 54.92it/s, Epoch: 99, Batch: 12,Loss: -3.640,Avg.Loss: -3.680,LR: 4.42E-07]Training epoch 99:  11%|█         | 12/112 [00:00<00:01, 53.75it/s, Epoch: 99, Batch: 12,Loss: -3.640,Avg.Loss: -3.680,LR: 4.42E-07]Training epoch 99:  11%|█         | 12/112 [00:00<00:01, 53.75it/s, Epoch: 99, Batch: 13,Loss: -3.816,Avg.Loss: -3.690,LR: 4.38E-07]Training epoch 99:  12%|█▏        | 13/112 [00:00<00:01, 53.75it/s, Epoch: 99, Batch: 14,Loss: -3.818,Avg.Loss: -3.700,LR: 4.34E-07]Training epoch 99:  12%|█▎        | 14/112 [00:00<00:01, 53.75it/s, Epoch: 99, Batch: 15,Loss: -4.145,Avg.Loss: -3.729,LR: 4.29E-07]Training epoch 99:  13%|█▎        | 15/112 [00:00<00:01, 53.75it/s, Epoch: 99, Batch: 16,Loss: -3.582,Avg.Loss: -3.720,LR: 4.25E-07]Training epoch 99:  14%|█▍        | 16/112 [00:00<00:01, 53.75it/s, Epoch: 99, Batch: 17,Loss: -3.643,Avg.Loss: -3.715,LR: 4.21E-07]Training epoch 99:  15%|█▌        | 17/112 [00:00<00:01, 53.75it/s, Epoch: 99, Batch: 18,Loss: -4.072,Avg.Loss: -3.735,LR: 4.17E-07]Training epoch 99:  16%|█▌        | 18/112 [00:00<00:01, 53.48it/s, Epoch: 99, Batch: 18,Loss: -4.072,Avg.Loss: -3.735,LR: 4.17E-07]Training epoch 99:  16%|█▌        | 18/112 [00:00<00:01, 53.48it/s, Epoch: 99, Batch: 19,Loss: -3.889,Avg.Loss: -3.743,LR: 4.13E-07]Training epoch 99:  17%|█▋        | 19/112 [00:00<00:01, 53.48it/s, Epoch: 99, Batch: 20,Loss: -3.452,Avg.Loss: -3.729,LR: 4.09E-07]Training epoch 99:  18%|█▊        | 20/112 [00:00<00:01, 53.48it/s, Epoch: 99, Batch: 21,Loss: -3.887,Avg.Loss: -3.736,LR: 4.05E-07]Training epoch 99:  19%|█▉        | 21/112 [00:00<00:01, 53.48it/s, Epoch: 99, Batch: 22,Loss: -3.896,Avg.Loss: -3.744,LR: 4.01E-07]Training epoch 99:  20%|█▉        | 22/112 [00:00<00:01, 53.48it/s, Epoch: 99, Batch: 23,Loss: -4.059,Avg.Loss: -3.757,LR: 3.97E-07]Training epoch 99:  21%|██        | 23/112 [00:00<00:01, 53.48it/s, Epoch: 99, Batch: 24,Loss: -3.353,Avg.Loss: -3.741,LR: 3.93E-07]Training epoch 99:  21%|██▏       | 24/112 [00:00<00:01, 52.99it/s, Epoch: 99, Batch: 24,Loss: -3.353,Avg.Loss: -3.741,LR: 3.93E-07]Training epoch 99:  21%|██▏       | 24/112 [00:00<00:01, 52.99it/s, Epoch: 99, Batch: 25,Loss: -4.199,Avg.Loss: -3.759,LR: 3.89E-07]Training epoch 99:  22%|██▏       | 25/112 [00:00<00:01, 52.99it/s, Epoch: 99, Batch: 26,Loss: -3.880,Avg.Loss: -3.764,LR: 3.85E-07]Training epoch 99:  23%|██▎       | 26/112 [00:00<00:01, 52.99it/s, Epoch: 99, Batch: 27,Loss: -4.159,Avg.Loss: -3.778,LR: 3.82E-07]Training epoch 99:  24%|██▍       | 27/112 [00:00<00:01, 52.99it/s, Epoch: 99, Batch: 28,Loss: -3.626,Avg.Loss: -3.773,LR: 3.78E-07]Training epoch 99:  25%|██▌       | 28/112 [00:00<00:01, 52.99it/s, Epoch: 99, Batch: 29,Loss: -3.681,Avg.Loss: -3.770,LR: 3.74E-07]Training epoch 99:  26%|██▌       | 29/112 [00:00<00:01, 52.99it/s, Epoch: 99, Batch: 30,Loss: -3.156,Avg.Loss: -3.749,LR: 3.70E-07]Training epoch 99:  27%|██▋       | 30/112 [00:00<00:01, 53.05it/s, Epoch: 99, Batch: 30,Loss: -3.156,Avg.Loss: -3.749,LR: 3.70E-07]Training epoch 99:  27%|██▋       | 30/112 [00:00<00:01, 53.05it/s, Epoch: 99, Batch: 31,Loss: -3.976,Avg.Loss: -3.756,LR: 3.66E-07]Training epoch 99:  28%|██▊       | 31/112 [00:00<00:01, 53.05it/s, Epoch: 99, Batch: 32,Loss: -3.848,Avg.Loss: -3.759,LR: 3.62E-07]Training epoch 99:  29%|██▊       | 32/112 [00:00<00:01, 53.05it/s, Epoch: 99, Batch: 33,Loss: -3.904,Avg.Loss: -3.764,LR: 3.59E-07]Training epoch 99:  29%|██▉       | 33/112 [00:00<00:01, 53.05it/s, Epoch: 99, Batch: 34,Loss: -3.976,Avg.Loss: -3.770,LR: 3.55E-07]Training epoch 99:  30%|███       | 34/112 [00:00<00:01, 53.05it/s, Epoch: 99, Batch: 35,Loss: -3.622,Avg.Loss: -3.766,LR: 3.51E-07]Training epoch 99:  31%|███▏      | 35/112 [00:00<00:01, 53.05it/s, Epoch: 99, Batch: 36,Loss: -3.654,Avg.Loss: -3.763,LR: 3.48E-07]Training epoch 99:  32%|███▏      | 36/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 36,Loss: -3.654,Avg.Loss: -3.763,LR: 3.48E-07]Training epoch 99:  32%|███▏      | 36/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 37,Loss: -3.319,Avg.Loss: -3.751,LR: 3.44E-07]Training epoch 99:  33%|███▎      | 37/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 38,Loss: -3.895,Avg.Loss: -3.754,LR: 3.40E-07]Training epoch 99:  34%|███▍      | 38/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 39,Loss: -4.067,Avg.Loss: -3.762,LR: 3.37E-07]Training epoch 99:  35%|███▍      | 39/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 40,Loss: -3.723,Avg.Loss: -3.761,LR: 3.33E-07]Training epoch 99:  36%|███▌      | 40/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 41,Loss: -3.672,Avg.Loss: -3.759,LR: 3.29E-07]Training epoch 99:  37%|███▋      | 41/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 42,Loss: -3.205,Avg.Loss: -3.746,LR: 3.26E-07]Training epoch 99:  38%|███▊      | 42/112 [00:00<00:01, 53.22it/s, Epoch: 99, Batch: 42,Loss: -3.205,Avg.Loss: -3.746,LR: 3.26E-07]Training epoch 99:  38%|███▊      | 42/112 [00:00<00:01, 53.22it/s, Epoch: 99, Batch: 43,Loss: -3.261,Avg.Loss: -3.735,LR: 3.22E-07]Training epoch 99:  38%|███▊      | 43/112 [00:00<00:01, 53.22it/s, Epoch: 99, Batch: 44,Loss: -3.627,Avg.Loss: -3.732,LR: 3.19E-07]Training epoch 99:  39%|███▉      | 44/112 [00:00<00:01, 53.22it/s, Epoch: 99, Batch: 45,Loss: -3.985,Avg.Loss: -3.738,LR: 3.15E-07]Training epoch 99:  40%|████      | 45/112 [00:00<00:01, 53.22it/s, Epoch: 99, Batch: 46,Loss: -3.914,Avg.Loss: -3.742,LR: 3.12E-07]Training epoch 99:  41%|████      | 46/112 [00:00<00:01, 53.22it/s, Epoch: 99, Batch: 47,Loss: -3.916,Avg.Loss: -3.745,LR: 3.08E-07]Training epoch 99:  42%|████▏     | 47/112 [00:00<00:01, 53.22it/s, Epoch: 99, Batch: 48,Loss: -3.582,Avg.Loss: -3.742,LR: 3.05E-07]Training epoch 99:  43%|████▎     | 48/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 48,Loss: -3.582,Avg.Loss: -3.742,LR: 3.05E-07]Training epoch 99:  43%|████▎     | 48/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 49,Loss: -3.510,Avg.Loss: -3.737,LR: 3.01E-07]Training epoch 99:  44%|████▍     | 49/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 50,Loss: -3.713,Avg.Loss: -3.737,LR: 2.98E-07]Training epoch 99:  45%|████▍     | 50/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 51,Loss: -3.927,Avg.Loss: -3.741,LR: 2.94E-07]Training epoch 99:  46%|████▌     | 51/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 52,Loss: -3.177,Avg.Loss: -3.730,LR: 2.91E-07]Training epoch 99:  46%|████▋     | 52/112 [00:00<00:01, 53.16it/s, Epoch: 99, Batch: 53,Loss: -3.938,Avg.Loss: -3.734,LR: 2.88E-07]Training epoch 99:  47%|████▋     | 53/112 [00:01<00:01, 53.16it/s, Epoch: 99, Batch: 54,Loss: -3.458,Avg.Loss: -3.729,LR: 2.84E-07]Training epoch 99:  48%|████▊     | 54/112 [00:01<00:01, 53.04it/s, Epoch: 99, Batch: 54,Loss: -3.458,Avg.Loss: -3.729,LR: 2.84E-07]Training epoch 99:  48%|████▊     | 54/112 [00:01<00:01, 53.04it/s, Epoch: 99, Batch: 55,Loss: -4.029,Avg.Loss: -3.734,LR: 2.81E-07]Training epoch 99:  49%|████▉     | 55/112 [00:01<00:01, 53.04it/s, Epoch: 99, Batch: 56,Loss: -3.722,Avg.Loss: -3.734,LR: 2.78E-07]Training epoch 99:  50%|█████     | 56/112 [00:01<00:01, 53.04it/s, Epoch: 99, Batch: 57,Loss: -3.100,Avg.Loss: -3.723,LR: 2.74E-07]Training epoch 99:  51%|█████     | 57/112 [00:01<00:01, 53.04it/s, Epoch: 99, Batch: 58,Loss: -3.701,Avg.Loss: -3.722,LR: 2.71E-07]Training epoch 99:  52%|█████▏    | 58/112 [00:01<00:01, 53.04it/s, Epoch: 99, Batch: 59,Loss: -3.552,Avg.Loss: -3.719,LR: 2.68E-07]Training epoch 99:  53%|█████▎    | 59/112 [00:01<00:00, 53.04it/s, Epoch: 99, Batch: 60,Loss: -3.700,Avg.Loss: -3.719,LR: 2.64E-07]Training epoch 99:  54%|█████▎    | 60/112 [00:01<00:00, 52.91it/s, Epoch: 99, Batch: 60,Loss: -3.700,Avg.Loss: -3.719,LR: 2.64E-07]Training epoch 99:  54%|█████▎    | 60/112 [00:01<00:00, 52.91it/s, Epoch: 99, Batch: 61,Loss: -3.648,Avg.Loss: -3.718,LR: 2.61E-07]Training epoch 99:  54%|█████▍    | 61/112 [00:01<00:00, 52.91it/s, Epoch: 99, Batch: 62,Loss: -3.926,Avg.Loss: -3.721,LR: 2.58E-07]Training epoch 99:  55%|█████▌    | 62/112 [00:01<00:00, 52.91it/s, Epoch: 99, Batch: 63,Loss: -3.812,Avg.Loss: -3.723,LR: 2.55E-07]Training epoch 99:  56%|█████▋    | 63/112 [00:01<00:00, 52.91it/s, Epoch: 99, Batch: 64,Loss: -3.689,Avg.Loss: -3.722,LR: 2.52E-07]Training epoch 99:  57%|█████▋    | 64/112 [00:01<00:00, 52.91it/s, Epoch: 99, Batch: 65,Loss: -4.006,Avg.Loss: -3.727,LR: 2.49E-07]Training epoch 99:  58%|█████▊    | 65/112 [00:01<00:00, 52.91it/s, Epoch: 99, Batch: 66,Loss: -3.948,Avg.Loss: -3.730,LR: 2.45E-07]Training epoch 99:  59%|█████▉    | 66/112 [00:01<00:00, 53.41it/s, Epoch: 99, Batch: 66,Loss: -3.948,Avg.Loss: -3.730,LR: 2.45E-07]Training epoch 99:  59%|█████▉    | 66/112 [00:01<00:00, 53.41it/s, Epoch: 99, Batch: 67,Loss: -3.642,Avg.Loss: -3.729,LR: 2.42E-07]Training epoch 99:  60%|█████▉    | 67/112 [00:01<00:00, 53.41it/s, Epoch: 99, Batch: 68,Loss: -3.976,Avg.Loss: -3.732,LR: 2.39E-07]Training epoch 99:  61%|██████    | 68/112 [00:01<00:00, 53.41it/s, Epoch: 99, Batch: 69,Loss: -3.908,Avg.Loss: -3.735,LR: 2.36E-07]Training epoch 99:  62%|██████▏   | 69/112 [00:01<00:00, 53.41it/s, Epoch: 99, Batch: 70,Loss: -3.664,Avg.Loss: -3.734,LR: 2.33E-07]Training epoch 99:  62%|██████▎   | 70/112 [00:01<00:00, 53.41it/s, Epoch: 99, Batch: 71,Loss: -3.755,Avg.Loss: -3.734,LR: 2.30E-07]Training epoch 99:  63%|██████▎   | 71/112 [00:01<00:00, 53.41it/s, Epoch: 99, Batch: 72,Loss: -3.203,Avg.Loss: -3.727,LR: 2.27E-07]Training epoch 99:  64%|██████▍   | 72/112 [00:01<00:00, 53.30it/s, Epoch: 99, Batch: 72,Loss: -3.203,Avg.Loss: -3.727,LR: 2.27E-07]Training epoch 99:  64%|██████▍   | 72/112 [00:01<00:00, 53.30it/s, Epoch: 99, Batch: 73,Loss: -3.799,Avg.Loss: -3.728,LR: 2.24E-07]Training epoch 99:  65%|██████▌   | 73/112 [00:01<00:00, 53.30it/s, Epoch: 99, Batch: 74,Loss: -4.169,Avg.Loss: -3.734,LR: 2.21E-07]Training epoch 99:  66%|██████▌   | 74/112 [00:01<00:00, 53.30it/s, Epoch: 99, Batch: 75,Loss: -3.860,Avg.Loss: -3.735,LR: 2.18E-07]Training epoch 99:  67%|██████▋   | 75/112 [00:01<00:00, 53.30it/s, Epoch: 99, Batch: 76,Loss: -3.765,Avg.Loss: -3.736,LR: 2.15E-07]Training epoch 99:  68%|██████▊   | 76/112 [00:01<00:00, 53.30it/s, Epoch: 99, Batch: 77,Loss: -3.526,Avg.Loss: -3.733,LR: 2.12E-07]Training epoch 99:  69%|██████▉   | 77/112 [00:01<00:00, 53.30it/s, Epoch: 99, Batch: 78,Loss: -3.636,Avg.Loss: -3.732,LR: 2.10E-07]Training epoch 99:  70%|██████▉   | 78/112 [00:01<00:00, 52.97it/s, Epoch: 99, Batch: 78,Loss: -3.636,Avg.Loss: -3.732,LR: 2.10E-07]Training epoch 99:  70%|██████▉   | 78/112 [00:01<00:00, 52.97it/s, Epoch: 99, Batch: 79,Loss: -3.879,Avg.Loss: -3.734,LR: 2.07E-07]Training epoch 99:  71%|███████   | 79/112 [00:01<00:00, 52.97it/s, Epoch: 99, Batch: 80,Loss: -3.797,Avg.Loss: -3.734,LR: 2.04E-07]Training epoch 99:  71%|███████▏  | 80/112 [00:01<00:00, 52.97it/s, Epoch: 99, Batch: 81,Loss: -4.165,Avg.Loss: -3.740,LR: 2.01E-07]Training epoch 99:  72%|███████▏  | 81/112 [00:01<00:00, 52.97it/s, Epoch: 99, Batch: 82,Loss: -3.668,Avg.Loss: -3.739,LR: 1.98E-07]Training epoch 99:  73%|███████▎  | 82/112 [00:01<00:00, 52.97it/s, Epoch: 99, Batch: 83,Loss: -3.347,Avg.Loss: -3.734,LR: 1.96E-07]Training epoch 99:  74%|███████▍  | 83/112 [00:01<00:00, 52.97it/s, Epoch: 99, Batch: 84,Loss: -3.899,Avg.Loss: -3.736,LR: 1.93E-07]Training epoch 99:  75%|███████▌  | 84/112 [00:01<00:00, 52.84it/s, Epoch: 99, Batch: 84,Loss: -3.899,Avg.Loss: -3.736,LR: 1.93E-07]Training epoch 99:  75%|███████▌  | 84/112 [00:01<00:00, 52.84it/s, Epoch: 99, Batch: 85,Loss: -3.875,Avg.Loss: -3.738,LR: 1.90E-07]Training epoch 99:  76%|███████▌  | 85/112 [00:01<00:00, 52.84it/s, Epoch: 99, Batch: 86,Loss: -3.679,Avg.Loss: -3.737,LR: 1.87E-07]Training epoch 99:  77%|███████▋  | 86/112 [00:01<00:00, 52.84it/s, Epoch: 99, Batch: 87,Loss: -3.945,Avg.Loss: -3.739,LR: 1.85E-07]Training epoch 99:  78%|███████▊  | 87/112 [00:01<00:00, 52.84it/s, Epoch: 99, Batch: 88,Loss: -3.586,Avg.Loss: -3.738,LR: 1.82E-07]Training epoch 99:  79%|███████▊  | 88/112 [00:01<00:00, 52.84it/s, Epoch: 99, Batch: 89,Loss: -3.990,Avg.Loss: -3.741,LR: 1.79E-07]Training epoch 99:  79%|███████▉  | 89/112 [00:01<00:00, 52.84it/s, Epoch: 99, Batch: 90,Loss: -3.583,Avg.Loss: -3.739,LR: 1.77E-07]Training epoch 99:  80%|████████  | 90/112 [00:01<00:00, 53.03it/s, Epoch: 99, Batch: 90,Loss: -3.583,Avg.Loss: -3.739,LR: 1.77E-07]Training epoch 99:  80%|████████  | 90/112 [00:01<00:00, 53.03it/s, Epoch: 99, Batch: 91,Loss: -3.947,Avg.Loss: -3.741,LR: 1.74E-07]Training epoch 99:  81%|████████▏ | 91/112 [00:01<00:00, 53.03it/s, Epoch: 99, Batch: 92,Loss: -3.746,Avg.Loss: -3.741,LR: 1.71E-07]Training epoch 99:  82%|████████▏ | 92/112 [00:01<00:00, 53.03it/s, Epoch: 99, Batch: 93,Loss: -3.347,Avg.Loss: -3.737,LR: 1.69E-07]Training epoch 99:  83%|████████▎ | 93/112 [00:01<00:00, 53.03it/s, Epoch: 99, Batch: 94,Loss: -3.932,Avg.Loss: -3.739,LR: 1.66E-07]Training epoch 99:  84%|████████▍ | 94/112 [00:01<00:00, 53.03it/s, Epoch: 99, Batch: 95,Loss: -3.823,Avg.Loss: -3.740,LR: 1.64E-07]Training epoch 99:  85%|████████▍ | 95/112 [00:01<00:00, 53.03it/s, Epoch: 99, Batch: 96,Loss: -3.713,Avg.Loss: -3.740,LR: 1.61E-07]Training epoch 99:  86%|████████▌ | 96/112 [00:01<00:00, 53.36it/s, Epoch: 99, Batch: 96,Loss: -3.713,Avg.Loss: -3.740,LR: 1.61E-07]Training epoch 99:  86%|████████▌ | 96/112 [00:01<00:00, 53.36it/s, Epoch: 99, Batch: 97,Loss: -3.633,Avg.Loss: -3.738,LR: 1.59E-07]Training epoch 99:  87%|████████▋ | 97/112 [00:01<00:00, 53.36it/s, Epoch: 99, Batch: 98,Loss: -3.761,Avg.Loss: -3.739,LR: 1.56E-07]Training epoch 99:  88%|████████▊ | 98/112 [00:01<00:00, 53.36it/s, Epoch: 99, Batch: 99,Loss: -3.904,Avg.Loss: -3.740,LR: 1.54E-07]Training epoch 99:  88%|████████▊ | 99/112 [00:01<00:00, 53.36it/s, Epoch: 99, Batch: 100,Loss: -3.696,Avg.Loss: -3.740,LR: 1.51E-07]Training epoch 99:  89%|████████▉ | 100/112 [00:01<00:00, 53.36it/s, Epoch: 99, Batch: 101,Loss: -3.990,Avg.Loss: -3.742,LR: 1.49E-07]Training epoch 99:  90%|█████████ | 101/112 [00:01<00:00, 53.36it/s, Epoch: 99, Batch: 102,Loss: -3.833,Avg.Loss: -3.743,LR: 1.46E-07]Training epoch 99:  91%|█████████ | 102/112 [00:01<00:00, 53.21it/s, Epoch: 99, Batch: 102,Loss: -3.833,Avg.Loss: -3.743,LR: 1.46E-07]Training epoch 99:  91%|█████████ | 102/112 [00:01<00:00, 53.21it/s, Epoch: 99, Batch: 103,Loss: -3.820,Avg.Loss: -3.744,LR: 1.44E-07]Training epoch 99:  92%|█████████▏| 103/112 [00:01<00:00, 53.21it/s, Epoch: 99, Batch: 104,Loss: -3.724,Avg.Loss: -3.744,LR: 1.42E-07]Training epoch 99:  93%|█████████▎| 104/112 [00:01<00:00, 53.21it/s, Epoch: 99, Batch: 105,Loss: -3.918,Avg.Loss: -3.746,LR: 1.39E-07]Training epoch 99:  94%|█████████▍| 105/112 [00:01<00:00, 53.21it/s, Epoch: 99, Batch: 106,Loss: -3.733,Avg.Loss: -3.745,LR: 1.37E-07]Training epoch 99:  95%|█████████▍| 106/112 [00:02<00:00, 53.21it/s, Epoch: 99, Batch: 107,Loss: -3.864,Avg.Loss: -3.747,LR: 1.35E-07]Training epoch 99:  96%|█████████▌| 107/112 [00:02<00:00, 53.21it/s, Epoch: 99, Batch: 108,Loss: -3.643,Avg.Loss: -3.746,LR: 1.32E-07]Training epoch 99:  96%|█████████▋| 108/112 [00:02<00:00, 53.16it/s, Epoch: 99, Batch: 108,Loss: -3.643,Avg.Loss: -3.746,LR: 1.32E-07]Training epoch 99:  96%|█████████▋| 108/112 [00:02<00:00, 53.16it/s, Epoch: 99, Batch: 109,Loss: -4.174,Avg.Loss: -3.749,LR: 1.30E-07]Training epoch 99:  97%|█████████▋| 109/112 [00:02<00:00, 53.16it/s, Epoch: 99, Batch: 110,Loss: -3.995,Avg.Loss: -3.752,LR: 1.28E-07]Training epoch 99:  98%|█████████▊| 110/112 [00:02<00:00, 53.16it/s, Epoch: 99, Batch: 111,Loss: -3.278,Avg.Loss: -3.747,LR: 1.26E-07]Training epoch 99:  99%|█████████▉| 111/112 [00:02<00:00, 53.16it/s, Epoch: 99, Batch: 112,Loss: -1.083,Avg.Loss: -3.724,LR: 1.23E-07]Training epoch 99: 100%|██████████| 112/112 [00:02<00:00, 53.10it/s, Epoch: 99, Batch: 112,Loss: -1.083,Avg.Loss: -3.724,LR: 1.23E-07]
Training epoch 100:   0%|          | 0/112 [00:00<?, ?it/s]Training epoch 100:   0%|          | 0/112 [00:00<?, ?it/s, Epoch: 100, Batch: 1,Loss: -3.396,Avg.Loss: -3.396,LR: 1.21E-07]Training epoch 100:   1%|          | 1/112 [00:00<00:03, 32.61it/s, Epoch: 100, Batch: 2,Loss: -3.877,Avg.Loss: -3.637,LR: 1.19E-07]Training epoch 100:   2%|▏         | 2/112 [00:00<00:02, 45.31it/s, Epoch: 100, Batch: 3,Loss: -3.402,Avg.Loss: -3.558,LR: 1.17E-07]Training epoch 100:   3%|▎         | 3/112 [00:00<00:02, 49.10it/s, Epoch: 100, Batch: 4,Loss: -3.312,Avg.Loss: -3.497,LR: 1.15E-07]Training epoch 100:   4%|▎         | 4/112 [00:00<00:02, 51.00it/s, Epoch: 100, Batch: 5,Loss: -3.674,Avg.Loss: -3.532,LR: 1.13E-07]Training epoch 100:   4%|▍         | 5/112 [00:00<00:02, 51.09it/s, Epoch: 100, Batch: 6,Loss: -3.651,Avg.Loss: -3.552,LR: 1.10E-07]Training epoch 100:   5%|▌         | 6/112 [00:00<00:02, 51.23it/s, Epoch: 100, Batch: 7,Loss: -3.785,Avg.Loss: -3.585,LR: 1.08E-07]Training epoch 100:   6%|▋         | 7/112 [00:00<00:01, 59.67it/s, Epoch: 100, Batch: 7,Loss: -3.785,Avg.Loss: -3.585,LR: 1.08E-07]Training epoch 100:   6%|▋         | 7/112 [00:00<00:01, 59.67it/s, Epoch: 100, Batch: 8,Loss: -3.894,Avg.Loss: -3.624,LR: 1.06E-07]Training epoch 100:   7%|▋         | 8/112 [00:00<00:01, 59.67it/s, Epoch: 100, Batch: 9,Loss: -3.800,Avg.Loss: -3.643,LR: 1.04E-07]Training epoch 100:   8%|▊         | 9/112 [00:00<00:01, 59.67it/s, Epoch: 100, Batch: 10,Loss: -3.444,Avg.Loss: -3.623,LR: 1.02E-07]Training epoch 100:   9%|▉         | 10/112 [00:00<00:01, 59.67it/s, Epoch: 100, Batch: 11,Loss: -4.047,Avg.Loss: -3.662,LR: 1.00E-07]Training epoch 100:  10%|▉         | 11/112 [00:00<00:01, 59.67it/s, Epoch: 100, Batch: 12,Loss: -3.759,Avg.Loss: -3.670,LR: 9.83E-08]Training epoch 100:  11%|█         | 12/112 [00:00<00:01, 59.67it/s, Epoch: 100, Batch: 13,Loss: -3.788,Avg.Loss: -3.679,LR: 9.64E-08]Training epoch 100:  12%|█▏        | 13/112 [00:00<00:01, 55.71it/s, Epoch: 100, Batch: 13,Loss: -3.788,Avg.Loss: -3.679,LR: 9.64E-08]Training epoch 100:  12%|█▏        | 13/112 [00:00<00:01, 55.71it/s, Epoch: 100, Batch: 14,Loss: -3.875,Avg.Loss: -3.693,LR: 9.44E-08]Training epoch 100:  12%|█▎        | 14/112 [00:00<00:01, 55.71it/s, Epoch: 100, Batch: 15,Loss: -3.931,Avg.Loss: -3.709,LR: 9.25E-08]Training epoch 100:  13%|█▎        | 15/112 [00:00<00:01, 55.71it/s, Epoch: 100, Batch: 16,Loss: -3.912,Avg.Loss: -3.722,LR: 9.06E-08]Training epoch 100:  14%|█▍        | 16/112 [00:00<00:01, 55.71it/s, Epoch: 100, Batch: 17,Loss: -3.041,Avg.Loss: -3.682,LR: 8.88E-08]Training epoch 100:  15%|█▌        | 17/112 [00:00<00:01, 55.71it/s, Epoch: 100, Batch: 18,Loss: -3.614,Avg.Loss: -3.678,LR: 8.69E-08]Training epoch 100:  16%|█▌        | 18/112 [00:00<00:01, 55.71it/s, Epoch: 100, Batch: 19,Loss: -3.916,Avg.Loss: -3.690,LR: 8.51E-08]Training epoch 100:  17%|█▋        | 19/112 [00:00<00:01, 54.44it/s, Epoch: 100, Batch: 19,Loss: -3.916,Avg.Loss: -3.690,LR: 8.51E-08]Training epoch 100:  17%|█▋        | 19/112 [00:00<00:01, 54.44it/s, Epoch: 100, Batch: 20,Loss: -4.304,Avg.Loss: -3.721,LR: 8.32E-08]Training epoch 100:  18%|█▊        | 20/112 [00:00<00:01, 54.44it/s, Epoch: 100, Batch: 21,Loss: -3.627,Avg.Loss: -3.717,LR: 8.14E-08]Training epoch 100:  19%|█▉        | 21/112 [00:00<00:01, 54.44it/s, Epoch: 100, Batch: 22,Loss: -3.872,Avg.Loss: -3.724,LR: 7.97E-08]Training epoch 100:  20%|█▉        | 22/112 [00:00<00:01, 54.44it/s, Epoch: 100, Batch: 23,Loss: -3.850,Avg.Loss: -3.729,LR: 7.79E-08]Training epoch 100:  21%|██        | 23/112 [00:00<00:01, 54.44it/s, Epoch: 100, Batch: 24,Loss: -3.430,Avg.Loss: -3.717,LR: 7.62E-08]Training epoch 100:  21%|██▏       | 24/112 [00:00<00:01, 54.44it/s, Epoch: 100, Batch: 25,Loss: -3.734,Avg.Loss: -3.717,LR: 7.44E-08]Training epoch 100:  22%|██▏       | 25/112 [00:00<00:01, 53.50it/s, Epoch: 100, Batch: 25,Loss: -3.734,Avg.Loss: -3.717,LR: 7.44E-08]Training epoch 100:  22%|██▏       | 25/112 [00:00<00:01, 53.50it/s, Epoch: 100, Batch: 26,Loss: -3.835,Avg.Loss: -3.722,LR: 7.27E-08]Training epoch 100:  23%|██▎       | 26/112 [00:00<00:01, 53.50it/s, Epoch: 100, Batch: 27,Loss: -4.058,Avg.Loss: -3.734,LR: 7.10E-08]Training epoch 100:  24%|██▍       | 27/112 [00:00<00:01, 53.50it/s, Epoch: 100, Batch: 28,Loss: -3.703,Avg.Loss: -3.733,LR: 6.94E-08]Training epoch 100:  25%|██▌       | 28/112 [00:00<00:01, 53.50it/s, Epoch: 100, Batch: 29,Loss: -4.066,Avg.Loss: -3.745,LR: 6.78E-08]Training epoch 100:  26%|██▌       | 29/112 [00:00<00:01, 53.50it/s, Epoch: 100, Batch: 30,Loss: -3.868,Avg.Loss: -3.749,LR: 6.61E-08]Training epoch 100:  27%|██▋       | 30/112 [00:00<00:01, 53.50it/s, Epoch: 100, Batch: 31,Loss: -3.768,Avg.Loss: -3.749,LR: 6.45E-08]Training epoch 100:  28%|██▊       | 31/112 [00:00<00:01, 53.21it/s, Epoch: 100, Batch: 31,Loss: -3.768,Avg.Loss: -3.749,LR: 6.45E-08]Training epoch 100:  28%|██▊       | 31/112 [00:00<00:01, 53.21it/s, Epoch: 100, Batch: 32,Loss: -3.875,Avg.Loss: -3.753,LR: 6.29E-08]Training epoch 100:  29%|██▊       | 32/112 [00:00<00:01, 53.21it/s, Epoch: 100, Batch: 33,Loss: -3.575,Avg.Loss: -3.748,LR: 6.14E-08]Training epoch 100:  29%|██▉       | 33/112 [00:00<00:01, 53.21it/s, Epoch: 100, Batch: 34,Loss: -3.743,Avg.Loss: -3.748,LR: 5.98E-08]Training epoch 100:  30%|███       | 34/112 [00:00<00:01, 53.21it/s, Epoch: 100, Batch: 35,Loss: -3.591,Avg.Loss: -3.743,LR: 5.83E-08]Training epoch 100:  31%|███▏      | 35/112 [00:00<00:01, 53.21it/s, Epoch: 100, Batch: 36,Loss: -3.462,Avg.Loss: -3.736,LR: 5.68E-08]Training epoch 100:  32%|███▏      | 36/112 [00:00<00:01, 53.21it/s, Epoch: 100, Batch: 37,Loss: -3.639,Avg.Loss: -3.733,LR: 5.53E-08]Training epoch 100:  33%|███▎      | 37/112 [00:00<00:01, 53.16it/s, Epoch: 100, Batch: 37,Loss: -3.639,Avg.Loss: -3.733,LR: 5.53E-08]Training epoch 100:  33%|███▎      | 37/112 [00:00<00:01, 53.16it/s, Epoch: 100, Batch: 38,Loss: -3.917,Avg.Loss: -3.738,LR: 5.39E-08]Training epoch 100:  34%|███▍      | 38/112 [00:00<00:01, 53.16it/s, Epoch: 100, Batch: 39,Loss: -3.968,Avg.Loss: -3.744,LR: 5.24E-08]Training epoch 100:  35%|███▍      | 39/112 [00:00<00:01, 53.16it/s, Epoch: 100, Batch: 40,Loss: -3.840,Avg.Loss: -3.746,LR: 5.10E-08]Training epoch 100:  36%|███▌      | 40/112 [00:00<00:01, 53.16it/s, Epoch: 100, Batch: 41,Loss: -3.734,Avg.Loss: -3.746,LR: 4.96E-08]Training epoch 100:  37%|███▋      | 41/112 [00:00<00:01, 53.16it/s, Epoch: 100, Batch: 42,Loss: -3.870,Avg.Loss: -3.749,LR: 4.82E-08]Training epoch 100:  38%|███▊      | 42/112 [00:00<00:01, 53.16it/s, Epoch: 100, Batch: 43,Loss: -4.076,Avg.Loss: -3.756,LR: 4.68E-08]Training epoch 100:  38%|███▊      | 43/112 [00:00<00:01, 53.40it/s, Epoch: 100, Batch: 43,Loss: -4.076,Avg.Loss: -3.756,LR: 4.68E-08]Training epoch 100:  38%|███▊      | 43/112 [00:00<00:01, 53.40it/s, Epoch: 100, Batch: 44,Loss: -4.001,Avg.Loss: -3.762,LR: 4.55E-08]Training epoch 100:  39%|███▉      | 44/112 [00:00<00:01, 53.40it/s, Epoch: 100, Batch: 45,Loss: -3.311,Avg.Loss: -3.752,LR: 4.42E-08]Training epoch 100:  40%|████      | 45/112 [00:00<00:01, 53.40it/s, Epoch: 100, Batch: 46,Loss: -3.554,Avg.Loss: -3.748,LR: 4.28E-08]Training epoch 100:  41%|████      | 46/112 [00:00<00:01, 53.40it/s, Epoch: 100, Batch: 47,Loss: -3.990,Avg.Loss: -3.753,LR: 4.15E-08]Training epoch 100:  42%|████▏     | 47/112 [00:00<00:01, 53.40it/s, Epoch: 100, Batch: 48,Loss: -4.029,Avg.Loss: -3.759,LR: 4.03E-08]Training epoch 100:  43%|████▎     | 48/112 [00:00<00:01, 53.40it/s, Epoch: 100, Batch: 49,Loss: -4.133,Avg.Loss: -3.766,LR: 3.90E-08]Training epoch 100:  44%|████▍     | 49/112 [00:00<00:01, 53.30it/s, Epoch: 100, Batch: 49,Loss: -4.133,Avg.Loss: -3.766,LR: 3.90E-08]Training epoch 100:  44%|████▍     | 49/112 [00:00<00:01, 53.30it/s, Epoch: 100, Batch: 50,Loss: -2.971,Avg.Loss: -3.750,LR: 3.78E-08]Training epoch 100:  45%|████▍     | 50/112 [00:00<00:01, 53.30it/s, Epoch: 100, Batch: 51,Loss: -3.994,Avg.Loss: -3.755,LR: 3.66E-08]Training epoch 100:  46%|████▌     | 51/112 [00:00<00:01, 53.30it/s, Epoch: 100, Batch: 52,Loss: -3.758,Avg.Loss: -3.755,LR: 3.54E-08]Training epoch 100:  46%|████▋     | 52/112 [00:00<00:01, 53.30it/s, Epoch: 100, Batch: 53,Loss: -3.876,Avg.Loss: -3.757,LR: 3.42E-08]Training epoch 100:  47%|████▋     | 53/112 [00:01<00:01, 53.30it/s, Epoch: 100, Batch: 54,Loss: -3.605,Avg.Loss: -3.755,LR: 3.31E-08]Training epoch 100:  48%|████▊     | 54/112 [00:01<00:01, 53.30it/s, Epoch: 100, Batch: 55,Loss: -3.720,Avg.Loss: -3.754,LR: 3.19E-08]Training epoch 100:  49%|████▉     | 55/112 [00:01<00:01, 53.28it/s, Epoch: 100, Batch: 55,Loss: -3.720,Avg.Loss: -3.754,LR: 3.19E-08]Training epoch 100:  49%|████▉     | 55/112 [00:01<00:01, 53.28it/s, Epoch: 100, Batch: 56,Loss: -3.643,Avg.Loss: -3.752,LR: 3.08E-08]Training epoch 100:  50%|█████     | 56/112 [00:01<00:01, 53.28it/s, Epoch: 100, Batch: 57,Loss: -4.094,Avg.Loss: -3.758,LR: 2.97E-08]Training epoch 100:  51%|█████     | 57/112 [00:01<00:01, 53.28it/s, Epoch: 100, Batch: 58,Loss: -4.001,Avg.Loss: -3.762,LR: 2.87E-08]Training epoch 100:  52%|█████▏    | 58/112 [00:01<00:01, 53.28it/s, Epoch: 100, Batch: 59,Loss: -3.924,Avg.Loss: -3.765,LR: 2.76E-08]Training epoch 100:  53%|█████▎    | 59/112 [00:01<00:00, 53.28it/s, Epoch: 100, Batch: 60,Loss: -3.441,Avg.Loss: -3.759,LR: 2.66E-08]Training epoch 100:  54%|█████▎    | 60/112 [00:01<00:00, 53.28it/s, Epoch: 100, Batch: 61,Loss: -3.942,Avg.Loss: -3.762,LR: 2.56E-08]Training epoch 100:  54%|█████▍    | 61/112 [00:01<00:00, 53.01it/s, Epoch: 100, Batch: 61,Loss: -3.942,Avg.Loss: -3.762,LR: 2.56E-08]Training epoch 100:  54%|█████▍    | 61/112 [00:01<00:00, 53.01it/s, Epoch: 100, Batch: 62,Loss: -3.746,Avg.Loss: -3.762,LR: 2.46E-08]Training epoch 100:  55%|█████▌    | 62/112 [00:01<00:00, 53.01it/s, Epoch: 100, Batch: 63,Loss: -3.890,Avg.Loss: -3.764,LR: 2.36E-08]Training epoch 100:  56%|█████▋    | 63/112 [00:01<00:00, 53.01it/s, Epoch: 100, Batch: 64,Loss: -3.425,Avg.Loss: -3.759,LR: 2.27E-08]Training epoch 100:  57%|█████▋    | 64/112 [00:01<00:00, 53.01it/s, Epoch: 100, Batch: 65,Loss: -3.786,Avg.Loss: -3.759,LR: 2.17E-08]Training epoch 100:  58%|█████▊    | 65/112 [00:01<00:00, 53.01it/s, Epoch: 100, Batch: 66,Loss: -3.805,Avg.Loss: -3.760,LR: 2.08E-08]Training epoch 100:  59%|█████▉    | 66/112 [00:01<00:00, 53.01it/s, Epoch: 100, Batch: 67,Loss: -3.259,Avg.Loss: -3.753,LR: 1.99E-08]Training epoch 100:  60%|█████▉    | 67/112 [00:01<00:00, 53.27it/s, Epoch: 100, Batch: 67,Loss: -3.259,Avg.Loss: -3.753,LR: 1.99E-08]Training epoch 100:  60%|█████▉    | 67/112 [00:01<00:00, 53.27it/s, Epoch: 100, Batch: 68,Loss: -3.799,Avg.Loss: -3.753,LR: 1.90E-08]Training epoch 100:  61%|██████    | 68/112 [00:01<00:00, 53.27it/s, Epoch: 100, Batch: 69,Loss: -3.608,Avg.Loss: -3.751,LR: 1.82E-08]Training epoch 100:  62%|██████▏   | 69/112 [00:01<00:00, 53.27it/s, Epoch: 100, Batch: 70,Loss: -3.693,Avg.Loss: -3.750,LR: 1.73E-08]Training epoch 100:  62%|██████▎   | 70/112 [00:01<00:00, 53.27it/s, Epoch: 100, Batch: 71,Loss: -3.857,Avg.Loss: -3.752,LR: 1.65E-08]Training epoch 100:  63%|██████▎   | 71/112 [00:01<00:00, 53.27it/s, Epoch: 100, Batch: 72,Loss: -3.724,Avg.Loss: -3.751,LR: 1.57E-08]Training epoch 100:  64%|██████▍   | 72/112 [00:01<00:00, 53.27it/s, Epoch: 100, Batch: 73,Loss: -3.682,Avg.Loss: -3.751,LR: 1.50E-08]Training epoch 100:  65%|██████▌   | 73/112 [00:01<00:00, 53.30it/s, Epoch: 100, Batch: 73,Loss: -3.682,Avg.Loss: -3.751,LR: 1.50E-08]Training epoch 100:  65%|██████▌   | 73/112 [00:01<00:00, 53.30it/s, Epoch: 100, Batch: 74,Loss: -3.683,Avg.Loss: -3.750,LR: 1.42E-08]Training epoch 100:  66%|██████▌   | 74/112 [00:01<00:00, 53.30it/s, Epoch: 100, Batch: 75,Loss: -3.801,Avg.Loss: -3.750,LR: 1.35E-08]Training epoch 100:  67%|██████▋   | 75/112 [00:01<00:00, 53.30it/s, Epoch: 100, Batch: 76,Loss: -4.030,Avg.Loss: -3.754,LR: 1.27E-08]Training epoch 100:  68%|██████▊   | 76/112 [00:01<00:00, 53.30it/s, Epoch: 100, Batch: 77,Loss: -3.987,Avg.Loss: -3.757,LR: 1.21E-08]Training epoch 100:  69%|██████▉   | 77/112 [00:01<00:00, 53.30it/s, Epoch: 100, Batch: 78,Loss: -3.542,Avg.Loss: -3.754,LR: 1.14E-08]Training epoch 100:  70%|██████▉   | 78/112 [00:01<00:00, 53.30it/s, Epoch: 100, Batch: 79,Loss: -3.522,Avg.Loss: -3.751,LR: 1.07E-08]Training epoch 100:  71%|███████   | 79/112 [00:01<00:00, 53.53it/s, Epoch: 100, Batch: 79,Loss: -3.522,Avg.Loss: -3.751,LR: 1.07E-08]Training epoch 100:  71%|███████   | 79/112 [00:01<00:00, 53.53it/s, Epoch: 100, Batch: 80,Loss: -3.695,Avg.Loss: -3.751,LR: 1.01E-08]Training epoch 100:  71%|███████▏  | 80/112 [00:01<00:00, 53.53it/s, Epoch: 100, Batch: 81,Loss: -3.823,Avg.Loss: -3.751,LR: 9.45E-09]Training epoch 100:  72%|███████▏  | 81/112 [00:01<00:00, 53.53it/s, Epoch: 100, Batch: 82,Loss: -3.804,Avg.Loss: -3.752,LR: 8.85E-09]Training epoch 100:  73%|███████▎  | 82/112 [00:01<00:00, 53.53it/s, Epoch: 100, Batch: 83,Loss: -3.540,Avg.Loss: -3.750,LR: 8.27E-09]Training epoch 100:  74%|███████▍  | 83/112 [00:01<00:00, 53.53it/s, Epoch: 100, Batch: 84,Loss: -3.743,Avg.Loss: -3.749,LR: 7.70E-09]Training epoch 100:  75%|███████▌  | 84/112 [00:01<00:00, 53.53it/s, Epoch: 100, Batch: 85,Loss: -3.637,Avg.Loss: -3.748,LR: 7.17E-09]Training epoch 100:  76%|███████▌  | 85/112 [00:01<00:00, 53.77it/s, Epoch: 100, Batch: 85,Loss: -3.637,Avg.Loss: -3.748,LR: 7.17E-09]Training epoch 100:  76%|███████▌  | 85/112 [00:01<00:00, 53.77it/s, Epoch: 100, Batch: 86,Loss: -3.776,Avg.Loss: -3.748,LR: 6.65E-09]Training epoch 100:  77%|███████▋  | 86/112 [00:01<00:00, 53.77it/s, Epoch: 100, Batch: 87,Loss: -3.772,Avg.Loss: -3.749,LR: 6.14E-09]Training epoch 100:  78%|███████▊  | 87/112 [00:01<00:00, 53.77it/s, Epoch: 100, Batch: 88,Loss: -3.982,Avg.Loss: -3.751,LR: 5.66E-09]Training epoch 100:  79%|███████▊  | 88/112 [00:01<00:00, 53.77it/s, Epoch: 100, Batch: 89,Loss: -3.597,Avg.Loss: -3.750,LR: 5.20E-09]Training epoch 100:  79%|███████▉  | 89/112 [00:01<00:00, 53.77it/s, Epoch: 100, Batch: 90,Loss: -3.774,Avg.Loss: -3.750,LR: 4.75E-09]Training epoch 100:  80%|████████  | 90/112 [00:01<00:00, 53.77it/s, Epoch: 100, Batch: 91,Loss: -3.681,Avg.Loss: -3.749,LR: 4.34E-09]Training epoch 100:  81%|████████▏ | 91/112 [00:01<00:00, 53.80it/s, Epoch: 100, Batch: 91,Loss: -3.681,Avg.Loss: -3.749,LR: 4.34E-09]Training epoch 100:  81%|████████▏ | 91/112 [00:01<00:00, 53.80it/s, Epoch: 100, Batch: 92,Loss: -3.831,Avg.Loss: -3.750,LR: 3.93E-09]Training epoch 100:  82%|████████▏ | 92/112 [00:01<00:00, 53.80it/s, Epoch: 100, Batch: 93,Loss: -4.015,Avg.Loss: -3.753,LR: 3.55E-09]Training epoch 100:  83%|████████▎ | 93/112 [00:01<00:00, 53.80it/s, Epoch: 100, Batch: 94,Loss: -3.969,Avg.Loss: -3.755,LR: 3.19E-09]Training epoch 100:  84%|████████▍ | 94/112 [00:01<00:00, 53.80it/s, Epoch: 100, Batch: 95,Loss: -3.270,Avg.Loss: -3.750,LR: 2.85E-09]Training epoch 100:  85%|████████▍ | 95/112 [00:01<00:00, 53.80it/s, Epoch: 100, Batch: 96,Loss: -3.806,Avg.Loss: -3.751,LR: 2.52E-09]Training epoch 100:  86%|████████▌ | 96/112 [00:01<00:00, 53.80it/s, Epoch: 100, Batch: 97,Loss: -3.751,Avg.Loss: -3.751,LR: 2.21E-09]Training epoch 100:  87%|████████▋ | 97/112 [00:01<00:00, 53.62it/s, Epoch: 100, Batch: 97,Loss: -3.751,Avg.Loss: -3.751,LR: 2.21E-09]Training epoch 100:  87%|████████▋ | 97/112 [00:01<00:00, 53.62it/s, Epoch: 100, Batch: 98,Loss: -3.707,Avg.Loss: -3.750,LR: 1.92E-09]Training epoch 100:  88%|████████▊ | 98/112 [00:01<00:00, 53.62it/s, Epoch: 100, Batch: 99,Loss: -4.069,Avg.Loss: -3.753,LR: 1.67E-09]Training epoch 100:  88%|████████▊ | 99/112 [00:01<00:00, 53.62it/s, Epoch: 100, Batch: 100,Loss: -3.476,Avg.Loss: -3.751,LR: 1.42E-09]Training epoch 100:  89%|████████▉ | 100/112 [00:01<00:00, 53.62it/s, Epoch: 100, Batch: 101,Loss: -3.848,Avg.Loss: -3.752,LR: 1.19E-09]Training epoch 100:  90%|█████████ | 101/112 [00:01<00:00, 53.62it/s, Epoch: 100, Batch: 102,Loss: -3.394,Avg.Loss: -3.748,LR: 9.83E-10]Training epoch 100:  91%|█████████ | 102/112 [00:01<00:00, 53.62it/s, Epoch: 100, Batch: 103,Loss: -3.772,Avg.Loss: -3.748,LR: 7.90E-10]Training epoch 100:  92%|█████████▏| 103/112 [00:01<00:00, 53.59it/s, Epoch: 100, Batch: 103,Loss: -3.772,Avg.Loss: -3.748,LR: 7.90E-10]Training epoch 100:  92%|█████████▏| 103/112 [00:01<00:00, 53.59it/s, Epoch: 100, Batch: 104,Loss: -3.654,Avg.Loss: -3.747,LR: 6.26E-10]Training epoch 100:  93%|█████████▎| 104/112 [00:01<00:00, 53.59it/s, Epoch: 100, Batch: 105,Loss: -4.138,Avg.Loss: -3.751,LR: 4.77E-10]Training epoch 100:  94%|█████████▍| 105/112 [00:01<00:00, 53.59it/s, Epoch: 100, Batch: 106,Loss: -3.504,Avg.Loss: -3.749,LR: 3.58E-10]Training epoch 100:  95%|█████████▍| 106/112 [00:01<00:00, 53.59it/s, Epoch: 100, Batch: 107,Loss: -3.308,Avg.Loss: -3.745,LR: 2.53E-10]Training epoch 100:  96%|█████████▌| 107/112 [00:02<00:00, 53.59it/s, Epoch: 100, Batch: 108,Loss: -3.896,Avg.Loss: -3.746,LR: 1.64E-10]Training epoch 100:  96%|█████████▋| 108/112 [00:02<00:00, 53.59it/s, Epoch: 100, Batch: 109,Loss: -3.688,Avg.Loss: -3.746,LR: 8.94E-11]Training epoch 100:  97%|█████████▋| 109/112 [00:02<00:00, 53.38it/s, Epoch: 100, Batch: 109,Loss: -3.688,Avg.Loss: -3.746,LR: 8.94E-11]Training epoch 100:  97%|█████████▋| 109/112 [00:02<00:00, 53.38it/s, Epoch: 100, Batch: 110,Loss: -3.689,Avg.Loss: -3.745,LR: 4.47E-11]Training epoch 100:  98%|█████████▊| 110/112 [00:02<00:00, 53.38it/s, Epoch: 100, Batch: 111,Loss: -3.938,Avg.Loss: -3.747,LR: 1.49E-11]Training epoch 100:  99%|█████████▉| 111/112 [00:02<00:00, 53.38it/s, Epoch: 100, Batch: 112,Loss: -4.295,Avg.Loss: -3.752,LR: 0.00E+00]Training epoch 100: 100%|██████████| 112/112 [00:02<00:00, 53.51it/s, Epoch: 100, Batch: 112,Loss: -4.295,Avg.Loss: -3.752,LR: 0.00E+00]
Finished training
239.09565258026123Plot results
function [run_morpheus] finished in 1396 ms
function [run_morpheus] finished in 1348 ms
function [run_morpheus] finished in 1341 ms
function [run_morpheus] finished in 1412 ms
function [run_morpheus] finished in 1340 ms
function [run_morpheus] finished in 1376 ms
function [run_morpheus] finished in 1330 ms
function [run_morpheus] finished in 1360 ms
function [run_morpheus] finished in 1333 ms
function [run_morpheus] finished in 1358 ms
function [run_morpheus] finished in 1324 ms
function [run_morpheus] finished in 1433 ms
function [run_morpheus] finished in 1335 ms
function [run_morpheus] finished in 1363 ms
function [run_morpheus] finished in 1359 ms
function [run_morpheus] finished in 1318 ms
function [run_morpheus] finished in 1324 ms
function [run_morpheus] finished in 1362 ms
function [run_morpheus] finished in 1350 ms
function [run_morpheus] finished in 1388 ms
function [run_morpheus] finished in 1325 ms
function [run_morpheus] finished in 1411 ms
function [run_morpheus] finished in 1406 ms
function [run_morpheus] finished in 1364 ms
function [run_morpheus] finished in 1349 ms
function [run_morpheus] finished in 1354 ms
function [run_morpheus] finished in 1327 ms
function [run_morpheus] finished in 1337 ms
function [run_morpheus] finished in 1345 ms
function [run_morpheus] finished in 1323 ms
function [run_morpheus] finished in 1373 ms
function [run_morpheus] finished in 1356 ms
function [run_morpheus] finished in 1356 ms
function [run_morpheus] finished in 1317 ms
function [run_morpheus] finished in 1387 ms
function [run_morpheus] finished in 1357 ms
function [run_morpheus] finished in 1400 ms
function [run_morpheus] finished in 1324 ms
function [run_morpheus] finished in 1351 ms
function [run_morpheus] finished in 1357 ms
function [run_morpheus] finished in 1324 ms
function [run_morpheus] finished in 1376 ms
function [run_morpheus] finished in 1293 ms
function [run_morpheus] finished in 1380 ms
function [run_morpheus] finished in 1329 ms
function [run_morpheus] finished in 1393 ms
function [run_morpheus] finished in 1358 ms
function [run_morpheus] finished in 1354 ms
function [run_morpheus] finished in 1357 ms
function [run_morpheus] finished in 1370 ms
function [run_morpheus] finished in 1379 ms
function [run_morpheus] finished in 1302 ms
function [run_morpheus] finished in 1326 ms
function [run_morpheus] finished in 1366 ms
function [run_morpheus] finished in 1380 ms
function [run_morpheus] finished in 1358 ms
function [run_morpheus] finished in 1300 ms
function [run_morpheus] finished in 1319 ms
function [run_morpheus] finished in 1335 ms
function [run_morpheus] finished in 1337 ms
function [run_morpheus] finished in 1329 ms
function [run_morpheus] finished in 1365 ms
function [run_morpheus] finished in 1345 ms
function [run_morpheus] finished in 1321 ms
function [run_morpheus] finished in 1322 ms
function [run_morpheus] finished in 1379 ms
function [run_morpheus] finished in 1284 ms
function [run_morpheus] finished in 1322 ms
function [run_morpheus] finished in 1361 ms
function [run_morpheus] finished in 1320 ms
function [run_morpheus] finished in 1372 ms
function [run_morpheus] finished in 1405 ms
function [run_morpheus] finished in 1300 ms
function [run_morpheus] finished in 1313 ms
function [run_morpheus] finished in 1355 ms
function [run_morpheus] finished in 1343 ms
function [run_morpheus] finished in 1313 ms
function [run_morpheus] finished in 1371 ms
function [run_morpheus] finished in 1344 ms
function [run_morpheus] finished in 1317 ms
function [run_morpheus] finished in 1367 ms
function [run_morpheus] finished in 1311 ms
function [run_morpheus] finished in 1352 ms
function [run_morpheus] finished in 1319 ms
function [run_morpheus] finished in 1373 ms
function [run_morpheus] finished in 1334 ms
function [run_morpheus] finished in 1339 ms
function [run_morpheus] finished in 1346 ms
function [run_morpheus] finished in 1319 ms
function [run_morpheus] finished in 1432 ms
function [run_morpheus] finished in 1349 ms
function [run_morpheus] finished in 1325 ms
function [run_morpheus] finished in 1377 ms
function [run_morpheus] finished in 1317 ms
function [run_morpheus] finished in 1371 ms
function [run_morpheus] finished in 1369 ms
function [run_morpheus] finished in 1328 ms
function [run_morpheus] finished in 1330 ms
function [run_morpheus] finished in 1393 ms
function [run_morpheus] finished in 1325 ms
