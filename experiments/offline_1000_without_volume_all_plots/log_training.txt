Initialize prior
Initialize generative model
function [run_morpheus] finished in 1360 ms
function [run_morpheus] finished in 1357 ms
Initialize amortizer
Initialize trainer
function [run_morpheus] finished in 1411 ms
function [run_morpheus] finished in 1308 ms
Initialization finished
Start reading data
Finished reading data
Start training
Training epoch 1:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 1:   0%|          | 0/153 [00:05<?, ?it/s, Epoch: 1, Batch: 1,Loss: 2.770,Avg.Loss: 2.770,LR: 5.00E-04]Training epoch 1:   1%|          | 1/153 [00:05<14:53,  5.88s/it, Epoch: 1, Batch: 1,Loss: 2.770,Avg.Loss: 2.770,LR: 5.00E-04]Training epoch 1:   1%|          | 1/153 [00:05<14:53,  5.88s/it, Epoch: 1, Batch: 2,Loss: 3.240,Avg.Loss: 3.005,LR: 5.00E-04]Training epoch 1:   1%|▏         | 2/153 [00:05<14:48,  5.88s/it, Epoch: 1, Batch: 3,Loss: 2.893,Avg.Loss: 2.968,LR: 5.00E-04]Training epoch 1:   2%|▏         | 3/153 [00:05<14:42,  5.88s/it, Epoch: 1, Batch: 4,Loss: 2.818,Avg.Loss: 2.930,LR: 5.00E-04]Training epoch 1:   3%|▎         | 4/153 [00:05<14:36,  5.88s/it, Epoch: 1, Batch: 5,Loss: 2.936,Avg.Loss: 2.932,LR: 5.00E-04]Training epoch 1:   3%|▎         | 5/153 [00:05<14:30,  5.88s/it, Epoch: 1, Batch: 6,Loss: 2.908,Avg.Loss: 2.928,LR: 5.00E-04]Training epoch 1:   4%|▍         | 6/153 [00:05<01:48,  1.35it/s, Epoch: 1, Batch: 6,Loss: 2.908,Avg.Loss: 2.928,LR: 5.00E-04]Training epoch 1:   4%|▍         | 6/153 [00:06<01:48,  1.35it/s, Epoch: 1, Batch: 7,Loss: 2.717,Avg.Loss: 2.897,LR: 5.00E-04]Training epoch 1:   5%|▍         | 7/153 [00:06<01:48,  1.35it/s, Epoch: 1, Batch: 8,Loss: 2.918,Avg.Loss: 2.900,LR: 5.00E-04]Training epoch 1:   5%|▌         | 8/153 [00:06<01:47,  1.35it/s, Epoch: 1, Batch: 9,Loss: 3.013,Avg.Loss: 2.913,LR: 5.00E-04]Training epoch 1:   6%|▌         | 9/153 [00:06<01:46,  1.35it/s, Epoch: 1, Batch: 10,Loss: 2.785,Avg.Loss: 2.900,LR: 5.00E-04]Training epoch 1:   7%|▋         | 10/153 [00:06<01:45,  1.35it/s, Epoch: 1, Batch: 11,Loss: 2.876,Avg.Loss: 2.898,LR: 5.00E-04]Training epoch 1:   7%|▋         | 11/153 [00:06<01:45,  1.35it/s, Epoch: 1, Batch: 12,Loss: 2.912,Avg.Loss: 2.899,LR: 5.00E-04]Training epoch 1:   8%|▊         | 12/153 [00:06<00:43,  3.25it/s, Epoch: 1, Batch: 12,Loss: 2.912,Avg.Loss: 2.899,LR: 5.00E-04]Training epoch 1:   8%|▊         | 12/153 [00:06<00:43,  3.25it/s, Epoch: 1, Batch: 13,Loss: 2.719,Avg.Loss: 2.885,LR: 5.00E-04]Training epoch 1:   8%|▊         | 13/153 [00:06<00:43,  3.25it/s, Epoch: 1, Batch: 14,Loss: 2.607,Avg.Loss: 2.865,LR: 5.00E-04]Training epoch 1:   9%|▉         | 14/153 [00:06<00:42,  3.25it/s, Epoch: 1, Batch: 15,Loss: 2.858,Avg.Loss: 2.865,LR: 5.00E-04]Training epoch 1:  10%|▉         | 15/153 [00:06<00:42,  3.25it/s, Epoch: 1, Batch: 16,Loss: 2.691,Avg.Loss: 2.854,LR: 5.00E-04]Training epoch 1:  10%|█         | 16/153 [00:06<00:42,  3.25it/s, Epoch: 1, Batch: 17,Loss: 2.919,Avg.Loss: 2.858,LR: 5.00E-04]Training epoch 1:  11%|█         | 17/153 [00:06<00:41,  3.25it/s, Epoch: 1, Batch: 18,Loss: 2.861,Avg.Loss: 2.858,LR: 5.00E-04]Training epoch 1:  12%|█▏        | 18/153 [00:06<00:23,  5.74it/s, Epoch: 1, Batch: 18,Loss: 2.861,Avg.Loss: 2.858,LR: 5.00E-04]Training epoch 1:  12%|█▏        | 18/153 [00:06<00:23,  5.74it/s, Epoch: 1, Batch: 19,Loss: 2.674,Avg.Loss: 2.848,LR: 5.00E-04]Training epoch 1:  12%|█▏        | 19/153 [00:06<00:23,  5.74it/s, Epoch: 1, Batch: 20,Loss: 2.642,Avg.Loss: 2.838,LR: 5.00E-04]Training epoch 1:  13%|█▎        | 20/153 [00:06<00:23,  5.74it/s, Epoch: 1, Batch: 21,Loss: 2.577,Avg.Loss: 2.825,LR: 5.00E-04]Training epoch 1:  14%|█▎        | 21/153 [00:06<00:23,  5.74it/s, Epoch: 1, Batch: 22,Loss: 2.601,Avg.Loss: 2.815,LR: 5.00E-04]Training epoch 1:  14%|█▍        | 22/153 [00:06<00:22,  5.74it/s, Epoch: 1, Batch: 23,Loss: 2.625,Avg.Loss: 2.807,LR: 5.00E-04]Training epoch 1:  15%|█▌        | 23/153 [00:06<00:22,  5.74it/s, Epoch: 1, Batch: 24,Loss: 2.473,Avg.Loss: 2.793,LR: 5.00E-04]Training epoch 1:  16%|█▌        | 24/153 [00:06<00:14,  8.89it/s, Epoch: 1, Batch: 24,Loss: 2.473,Avg.Loss: 2.793,LR: 5.00E-04]Training epoch 1:  16%|█▌        | 24/153 [00:06<00:14,  8.89it/s, Epoch: 1, Batch: 25,Loss: 2.520,Avg.Loss: 2.782,LR: 5.00E-04]Training epoch 1:  16%|█▋        | 25/153 [00:06<00:14,  8.89it/s, Epoch: 1, Batch: 26,Loss: 2.509,Avg.Loss: 2.772,LR: 5.00E-04]Training epoch 1:  17%|█▋        | 26/153 [00:06<00:14,  8.89it/s, Epoch: 1, Batch: 27,Loss: 2.351,Avg.Loss: 2.756,LR: 5.00E-04]Training epoch 1:  18%|█▊        | 27/153 [00:06<00:14,  8.89it/s, Epoch: 1, Batch: 28,Loss: 2.406,Avg.Loss: 2.744,LR: 5.00E-04]Training epoch 1:  18%|█▊        | 28/153 [00:06<00:14,  8.89it/s, Epoch: 1, Batch: 29,Loss: 2.321,Avg.Loss: 2.729,LR: 5.00E-04]Training epoch 1:  19%|█▉        | 29/153 [00:06<00:13,  8.89it/s, Epoch: 1, Batch: 30,Loss: 2.161,Avg.Loss: 2.710,LR: 5.00E-04]Training epoch 1:  20%|█▉        | 30/153 [00:06<00:09, 12.70it/s, Epoch: 1, Batch: 30,Loss: 2.161,Avg.Loss: 2.710,LR: 5.00E-04]Training epoch 1:  20%|█▉        | 30/153 [00:06<00:09, 12.70it/s, Epoch: 1, Batch: 31,Loss: 2.225,Avg.Loss: 2.694,LR: 5.00E-04]Training epoch 1:  20%|██        | 31/153 [00:06<00:09, 12.70it/s, Epoch: 1, Batch: 32,Loss: 2.363,Avg.Loss: 2.684,LR: 5.00E-04]Training epoch 1:  21%|██        | 32/153 [00:06<00:09, 12.70it/s, Epoch: 1, Batch: 33,Loss: 2.192,Avg.Loss: 2.669,LR: 5.00E-04]Training epoch 1:  22%|██▏       | 33/153 [00:06<00:09, 12.70it/s, Epoch: 1, Batch: 34,Loss: 2.224,Avg.Loss: 2.656,LR: 5.00E-04]Training epoch 1:  22%|██▏       | 34/153 [00:06<00:09, 12.70it/s, Epoch: 1, Batch: 35,Loss: 2.030,Avg.Loss: 2.638,LR: 5.00E-04]Training epoch 1:  23%|██▎       | 35/153 [00:06<00:07, 15.96it/s, Epoch: 1, Batch: 35,Loss: 2.030,Avg.Loss: 2.638,LR: 5.00E-04]Training epoch 1:  23%|██▎       | 35/153 [00:06<00:07, 15.96it/s, Epoch: 1, Batch: 36,Loss: 2.026,Avg.Loss: 2.621,LR: 5.00E-04]Training epoch 1:  24%|██▎       | 36/153 [00:06<00:07, 15.96it/s, Epoch: 1, Batch: 37,Loss: 2.062,Avg.Loss: 2.606,LR: 5.00E-04]Training epoch 1:  24%|██▍       | 37/153 [00:06<00:07, 15.96it/s, Epoch: 1, Batch: 38,Loss: 1.957,Avg.Loss: 2.589,LR: 5.00E-04]Training epoch 1:  25%|██▍       | 38/153 [00:06<00:07, 15.96it/s, Epoch: 1, Batch: 39,Loss: 2.175,Avg.Loss: 2.578,LR: 5.00E-04]Training epoch 1:  25%|██▌       | 39/153 [00:06<00:07, 15.96it/s, Epoch: 1, Batch: 40,Loss: 2.210,Avg.Loss: 2.569,LR: 5.00E-04]Training epoch 1:  26%|██▌       | 40/153 [00:06<00:07, 15.96it/s, Epoch: 1, Batch: 41,Loss: 2.011,Avg.Loss: 2.555,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 41/153 [00:06<00:05, 20.91it/s, Epoch: 1, Batch: 41,Loss: 2.011,Avg.Loss: 2.555,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 41/153 [00:06<00:05, 20.91it/s, Epoch: 1, Batch: 42,Loss: 1.787,Avg.Loss: 2.537,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 42/153 [00:06<00:05, 20.91it/s, Epoch: 1, Batch: 43,Loss: 2.341,Avg.Loss: 2.533,LR: 5.00E-04]Training epoch 1:  28%|██▊       | 43/153 [00:06<00:05, 20.91it/s, Epoch: 1, Batch: 44,Loss: 2.206,Avg.Loss: 2.525,LR: 5.00E-04]Training epoch 1:  29%|██▉       | 44/153 [00:06<00:05, 20.91it/s, Epoch: 1, Batch: 45,Loss: 1.828,Avg.Loss: 2.510,LR: 5.00E-04]Training epoch 1:  29%|██▉       | 45/153 [00:06<00:05, 20.91it/s, Epoch: 1, Batch: 46,Loss: 1.780,Avg.Loss: 2.494,LR: 5.00E-04]Training epoch 1:  30%|███       | 46/153 [00:06<00:05, 20.91it/s, Epoch: 1, Batch: 47,Loss: 1.892,Avg.Loss: 2.481,LR: 5.00E-04]Training epoch 1:  31%|███       | 47/153 [00:06<00:05, 20.91it/s, Epoch: 1, Batch: 48,Loss: 1.936,Avg.Loss: 2.470,LR: 5.00E-04]Training epoch 1:  31%|███▏      | 48/153 [00:06<00:03, 27.83it/s, Epoch: 1, Batch: 48,Loss: 1.936,Avg.Loss: 2.470,LR: 5.00E-04]Training epoch 1:  31%|███▏      | 48/153 [00:06<00:03, 27.83it/s, Epoch: 1, Batch: 49,Loss: 2.015,Avg.Loss: 2.460,LR: 5.00E-04]Training epoch 1:  32%|███▏      | 49/153 [00:06<00:03, 27.83it/s, Epoch: 1, Batch: 50,Loss: 2.262,Avg.Loss: 2.456,LR: 5.00E-04]Training epoch 1:  33%|███▎      | 50/153 [00:06<00:03, 27.83it/s, Epoch: 1, Batch: 51,Loss: 1.963,Avg.Loss: 2.447,LR: 5.00E-04]Training epoch 1:  33%|███▎      | 51/153 [00:06<00:03, 27.83it/s, Epoch: 1, Batch: 52,Loss: 1.868,Avg.Loss: 2.436,LR: 5.00E-04]Training epoch 1:  34%|███▍      | 52/153 [00:06<00:03, 27.83it/s, Epoch: 1, Batch: 53,Loss: 1.756,Avg.Loss: 2.423,LR: 5.00E-04]Training epoch 1:  35%|███▍      | 53/153 [00:06<00:03, 27.83it/s, Epoch: 1, Batch: 54,Loss: 2.001,Avg.Loss: 2.415,LR: 5.00E-04]Training epoch 1:  35%|███▌      | 54/153 [00:06<00:03, 32.97it/s, Epoch: 1, Batch: 54,Loss: 2.001,Avg.Loss: 2.415,LR: 5.00E-04]Training epoch 1:  35%|███▌      | 54/153 [00:06<00:03, 32.97it/s, Epoch: 1, Batch: 55,Loss: 1.868,Avg.Loss: 2.405,LR: 5.00E-04]Training epoch 1:  36%|███▌      | 55/153 [00:06<00:02, 32.97it/s, Epoch: 1, Batch: 56,Loss: 1.727,Avg.Loss: 2.393,LR: 5.00E-04]Training epoch 1:  37%|███▋      | 56/153 [00:06<00:02, 32.97it/s, Epoch: 1, Batch: 57,Loss: 1.636,Avg.Loss: 2.380,LR: 5.00E-04]Training epoch 1:  37%|███▋      | 57/153 [00:06<00:02, 32.97it/s, Epoch: 1, Batch: 58,Loss: 1.942,Avg.Loss: 2.372,LR: 5.00E-04]Training epoch 1:  38%|███▊      | 58/153 [00:06<00:02, 32.97it/s, Epoch: 1, Batch: 59,Loss: 1.633,Avg.Loss: 2.360,LR: 5.00E-04]Training epoch 1:  39%|███▊      | 59/153 [00:07<00:02, 32.97it/s, Epoch: 1, Batch: 60,Loss: 1.638,Avg.Loss: 2.348,LR: 5.00E-04]Training epoch 1:  39%|███▉      | 60/153 [00:07<00:02, 37.13it/s, Epoch: 1, Batch: 60,Loss: 1.638,Avg.Loss: 2.348,LR: 5.00E-04]Training epoch 1:  39%|███▉      | 60/153 [00:07<00:02, 37.13it/s, Epoch: 1, Batch: 61,Loss: 1.620,Avg.Loss: 2.336,LR: 5.00E-04]Training epoch 1:  40%|███▉      | 61/153 [00:07<00:02, 37.13it/s, Epoch: 1, Batch: 62,Loss: 1.792,Avg.Loss: 2.327,LR: 5.00E-04]Training epoch 1:  41%|████      | 62/153 [00:07<00:02, 37.13it/s, Epoch: 1, Batch: 63,Loss: 1.781,Avg.Loss: 2.318,LR: 5.00E-04]Training epoch 1:  41%|████      | 63/153 [00:07<00:02, 37.13it/s, Epoch: 1, Batch: 64,Loss: 1.637,Avg.Loss: 2.308,LR: 5.00E-04]Training epoch 1:  42%|████▏     | 64/153 [00:07<00:02, 37.13it/s, Epoch: 1, Batch: 65,Loss: 1.714,Avg.Loss: 2.298,LR: 5.00E-04]Training epoch 1:  42%|████▏     | 65/153 [00:07<00:02, 37.13it/s, Epoch: 1, Batch: 66,Loss: 1.578,Avg.Loss: 2.288,LR: 5.00E-04]Training epoch 1:  43%|████▎     | 66/153 [00:07<00:02, 40.82it/s, Epoch: 1, Batch: 66,Loss: 1.578,Avg.Loss: 2.288,LR: 5.00E-04]Training epoch 1:  43%|████▎     | 66/153 [00:07<00:02, 40.82it/s, Epoch: 1, Batch: 67,Loss: 1.351,Avg.Loss: 2.274,LR: 5.00E-04]Training epoch 1:  44%|████▍     | 67/153 [00:07<00:02, 40.82it/s, Epoch: 1, Batch: 68,Loss: 1.473,Avg.Loss: 2.262,LR: 5.00E-04]Training epoch 1:  44%|████▍     | 68/153 [00:07<00:02, 40.82it/s, Epoch: 1, Batch: 69,Loss: 1.686,Avg.Loss: 2.253,LR: 5.00E-04]Training epoch 1:  45%|████▌     | 69/153 [00:07<00:02, 40.82it/s, Epoch: 1, Batch: 70,Loss: 1.341,Avg.Loss: 2.240,LR: 5.00E-04]Training epoch 1:  46%|████▌     | 70/153 [00:07<00:02, 40.82it/s, Epoch: 1, Batch: 71,Loss: 1.632,Avg.Loss: 2.232,LR: 5.00E-04]Training epoch 1:  46%|████▋     | 71/153 [00:07<00:02, 40.82it/s, Epoch: 1, Batch: 72,Loss: 2.153,Avg.Loss: 2.231,LR: 5.00E-04]Training epoch 1:  47%|████▋     | 72/153 [00:07<00:01, 43.98it/s, Epoch: 1, Batch: 72,Loss: 2.153,Avg.Loss: 2.231,LR: 5.00E-04]Training epoch 1:  47%|████▋     | 72/153 [00:07<00:01, 43.98it/s, Epoch: 1, Batch: 73,Loss: 1.920,Avg.Loss: 2.226,LR: 5.00E-04]Training epoch 1:  48%|████▊     | 73/153 [00:07<00:01, 43.98it/s, Epoch: 1, Batch: 74,Loss: 1.625,Avg.Loss: 2.218,LR: 5.00E-04]Training epoch 1:  48%|████▊     | 74/153 [00:07<00:01, 43.98it/s, Epoch: 1, Batch: 75,Loss: 1.476,Avg.Loss: 2.208,LR: 5.00E-04]Training epoch 1:  49%|████▉     | 75/153 [00:07<00:01, 43.98it/s, Epoch: 1, Batch: 76,Loss: 1.498,Avg.Loss: 2.199,LR: 5.00E-04]Training epoch 1:  50%|████▉     | 76/153 [00:07<00:01, 43.98it/s, Epoch: 1, Batch: 77,Loss: 1.439,Avg.Loss: 2.189,LR: 5.00E-04]Training epoch 1:  50%|█████     | 77/153 [00:07<00:01, 43.98it/s, Epoch: 1, Batch: 78,Loss: 1.925,Avg.Loss: 2.186,LR: 5.00E-04]Training epoch 1:  51%|█████     | 78/153 [00:07<00:01, 45.88it/s, Epoch: 1, Batch: 78,Loss: 1.925,Avg.Loss: 2.186,LR: 5.00E-04]Training epoch 1:  51%|█████     | 78/153 [00:07<00:01, 45.88it/s, Epoch: 1, Batch: 79,Loss: 1.966,Avg.Loss: 2.183,LR: 5.00E-04]Training epoch 1:  52%|█████▏    | 79/153 [00:07<00:01, 45.88it/s, Epoch: 1, Batch: 80,Loss: 1.636,Avg.Loss: 2.176,LR: 5.00E-04]Training epoch 1:  52%|█████▏    | 80/153 [00:07<00:01, 45.88it/s, Epoch: 1, Batch: 81,Loss: 1.992,Avg.Loss: 2.174,LR: 5.00E-04]Training epoch 1:  53%|█████▎    | 81/153 [00:07<00:01, 45.88it/s, Epoch: 1, Batch: 82,Loss: 1.315,Avg.Loss: 2.163,LR: 5.00E-04]Training epoch 1:  54%|█████▎    | 82/153 [00:07<00:01, 45.88it/s, Epoch: 1, Batch: 83,Loss: 1.850,Avg.Loss: 2.160,LR: 5.00E-04]Training epoch 1:  54%|█████▍    | 83/153 [00:07<00:01, 45.88it/s, Epoch: 1, Batch: 84,Loss: 1.856,Avg.Loss: 2.156,LR: 5.00E-04]Training epoch 1:  55%|█████▍    | 84/153 [00:07<00:01, 46.06it/s, Epoch: 1, Batch: 84,Loss: 1.856,Avg.Loss: 2.156,LR: 5.00E-04]Training epoch 1:  55%|█████▍    | 84/153 [00:07<00:01, 46.06it/s, Epoch: 1, Batch: 85,Loss: 1.755,Avg.Loss: 2.151,LR: 5.00E-04]Training epoch 1:  56%|█████▌    | 85/153 [00:07<00:01, 46.06it/s, Epoch: 1, Batch: 86,Loss: 1.892,Avg.Loss: 2.148,LR: 5.00E-04]Training epoch 1:  56%|█████▌    | 86/153 [00:07<00:01, 46.06it/s, Epoch: 1, Batch: 87,Loss: 1.978,Avg.Loss: 2.146,LR: 5.00E-04]Training epoch 1:  57%|█████▋    | 87/153 [00:07<00:01, 46.06it/s, Epoch: 1, Batch: 88,Loss: 2.206,Avg.Loss: 2.147,LR: 5.00E-04]Training epoch 1:  58%|█████▊    | 88/153 [00:07<00:01, 46.06it/s, Epoch: 1, Batch: 89,Loss: 1.948,Avg.Loss: 2.145,LR: 5.00E-04]Training epoch 1:  58%|█████▊    | 89/153 [00:07<00:01, 46.06it/s, Epoch: 1, Batch: 90,Loss: 1.480,Avg.Loss: 2.137,LR: 5.00E-04]Training epoch 1:  59%|█████▉    | 90/153 [00:07<00:01, 47.55it/s, Epoch: 1, Batch: 90,Loss: 1.480,Avg.Loss: 2.137,LR: 5.00E-04]Training epoch 1:  59%|█████▉    | 90/153 [00:07<00:01, 47.55it/s, Epoch: 1, Batch: 91,Loss: 1.700,Avg.Loss: 2.133,LR: 5.00E-04]Training epoch 1:  59%|█████▉    | 91/153 [00:07<00:01, 47.55it/s, Epoch: 1, Batch: 92,Loss: 1.553,Avg.Loss: 2.126,LR: 5.00E-04]Training epoch 1:  60%|██████    | 92/153 [00:07<00:01, 47.55it/s, Epoch: 1, Batch: 93,Loss: 1.454,Avg.Loss: 2.119,LR: 5.00E-04]Training epoch 1:  61%|██████    | 93/153 [00:07<00:01, 47.55it/s, Epoch: 1, Batch: 94,Loss: 1.473,Avg.Loss: 2.112,LR: 5.00E-04]Training epoch 1:  61%|██████▏   | 94/153 [00:07<00:01, 47.55it/s, Epoch: 1, Batch: 95,Loss: 1.640,Avg.Loss: 2.107,LR: 5.00E-04]Training epoch 1:  62%|██████▏   | 95/153 [00:07<00:01, 47.55it/s, Epoch: 1, Batch: 96,Loss: 1.567,Avg.Loss: 2.102,LR: 5.00E-04]Training epoch 1:  63%|██████▎   | 96/153 [00:07<00:01, 48.90it/s, Epoch: 1, Batch: 96,Loss: 1.567,Avg.Loss: 2.102,LR: 5.00E-04]Training epoch 1:  63%|██████▎   | 96/153 [00:07<00:01, 48.90it/s, Epoch: 1, Batch: 97,Loss: 1.413,Avg.Loss: 2.095,LR: 5.00E-04]Training epoch 1:  63%|██████▎   | 97/153 [00:07<00:01, 48.90it/s, Epoch: 1, Batch: 98,Loss: 1.467,Avg.Loss: 2.088,LR: 5.00E-04]Training epoch 1:  64%|██████▍   | 98/153 [00:07<00:01, 48.90it/s, Epoch: 1, Batch: 99,Loss: 1.455,Avg.Loss: 2.082,LR: 5.00E-04]Training epoch 1:  65%|██████▍   | 99/153 [00:07<00:01, 48.90it/s, Epoch: 1, Batch: 100,Loss: 1.381,Avg.Loss: 2.075,LR: 5.00E-04]Training epoch 1:  65%|██████▌   | 100/153 [00:07<00:01, 48.90it/s, Epoch: 1, Batch: 101,Loss: 1.490,Avg.Loss: 2.069,LR: 5.00E-04]Training epoch 1:  66%|██████▌   | 101/153 [00:07<00:01, 48.90it/s, Epoch: 1, Batch: 102,Loss: 1.468,Avg.Loss: 2.063,LR: 5.00E-04]Training epoch 1:  67%|██████▋   | 102/153 [00:07<00:01, 49.92it/s, Epoch: 1, Batch: 102,Loss: 1.468,Avg.Loss: 2.063,LR: 5.00E-04]Training epoch 1:  67%|██████▋   | 102/153 [00:07<00:01, 49.92it/s, Epoch: 1, Batch: 103,Loss: 1.409,Avg.Loss: 2.057,LR: 5.00E-04]Training epoch 1:  67%|██████▋   | 103/153 [00:07<00:01, 49.92it/s, Epoch: 1, Batch: 104,Loss: 1.422,Avg.Loss: 2.051,LR: 5.00E-04]Training epoch 1:  68%|██████▊   | 104/153 [00:07<00:00, 49.92it/s, Epoch: 1, Batch: 105,Loss: 1.428,Avg.Loss: 2.045,LR: 5.00E-04]Training epoch 1:  69%|██████▊   | 105/153 [00:07<00:00, 49.92it/s, Epoch: 1, Batch: 106,Loss: 1.485,Avg.Loss: 2.039,LR: 5.00E-04]Training epoch 1:  69%|██████▉   | 106/153 [00:07<00:00, 49.92it/s, Epoch: 1, Batch: 107,Loss: 1.645,Avg.Loss: 2.036,LR: 5.00E-04]Training epoch 1:  70%|██████▉   | 107/153 [00:07<00:00, 49.92it/s, Epoch: 1, Batch: 108,Loss: 1.681,Avg.Loss: 2.032,LR: 5.00E-04]Training epoch 1:  71%|███████   | 108/153 [00:07<00:00, 50.54it/s, Epoch: 1, Batch: 108,Loss: 1.681,Avg.Loss: 2.032,LR: 5.00E-04]Training epoch 1:  71%|███████   | 108/153 [00:07<00:00, 50.54it/s, Epoch: 1, Batch: 109,Loss: 1.415,Avg.Loss: 2.027,LR: 5.00E-04]Training epoch 1:  71%|███████   | 109/153 [00:07<00:00, 50.54it/s, Epoch: 1, Batch: 110,Loss: 1.395,Avg.Loss: 2.021,LR: 5.00E-04]Training epoch 1:  72%|███████▏  | 110/153 [00:08<00:00, 50.54it/s, Epoch: 1, Batch: 111,Loss: 1.369,Avg.Loss: 2.015,LR: 5.00E-04]Training epoch 1:  73%|███████▎  | 111/153 [00:08<00:00, 50.54it/s, Epoch: 1, Batch: 112,Loss: 1.286,Avg.Loss: 2.009,LR: 5.00E-04]Training epoch 1:  73%|███████▎  | 112/153 [00:08<00:00, 50.54it/s, Epoch: 1, Batch: 113,Loss: 1.518,Avg.Loss: 2.004,LR: 5.00E-04]Training epoch 1:  74%|███████▍  | 113/153 [00:08<00:00, 50.54it/s, Epoch: 1, Batch: 114,Loss: 1.296,Avg.Loss: 1.998,LR: 5.00E-04]Training epoch 1:  75%|███████▍  | 114/153 [00:08<00:00, 51.17it/s, Epoch: 1, Batch: 114,Loss: 1.296,Avg.Loss: 1.998,LR: 5.00E-04]Training epoch 1:  75%|███████▍  | 114/153 [00:08<00:00, 51.17it/s, Epoch: 1, Batch: 115,Loss: 1.540,Avg.Loss: 1.994,LR: 5.00E-04]Training epoch 1:  75%|███████▌  | 115/153 [00:08<00:00, 51.17it/s, Epoch: 1, Batch: 116,Loss: 2.589,Avg.Loss: 1.999,LR: 5.00E-04]Training epoch 1:  76%|███████▌  | 116/153 [00:08<00:00, 51.17it/s, Epoch: 1, Batch: 117,Loss: 1.648,Avg.Loss: 1.996,LR: 5.00E-04]Training epoch 1:  76%|███████▋  | 117/153 [00:08<00:00, 51.17it/s, Epoch: 1, Batch: 118,Loss: 1.209,Avg.Loss: 1.990,LR: 5.00E-04]Training epoch 1:  77%|███████▋  | 118/153 [00:08<00:00, 51.17it/s, Epoch: 1, Batch: 119,Loss: 1.514,Avg.Loss: 1.986,LR: 5.00E-04]Training epoch 1:  78%|███████▊  | 119/153 [00:08<00:00, 51.17it/s, Epoch: 1, Batch: 120,Loss: 1.458,Avg.Loss: 1.981,LR: 5.00E-04]Training epoch 1:  78%|███████▊  | 120/153 [00:08<00:00, 51.55it/s, Epoch: 1, Batch: 120,Loss: 1.458,Avg.Loss: 1.981,LR: 5.00E-04]Training epoch 1:  78%|███████▊  | 120/153 [00:08<00:00, 51.55it/s, Epoch: 1, Batch: 121,Loss: 1.536,Avg.Loss: 1.977,LR: 5.00E-04]Training epoch 1:  79%|███████▉  | 121/153 [00:08<00:00, 51.55it/s, Epoch: 1, Batch: 122,Loss: 1.594,Avg.Loss: 1.974,LR: 5.00E-04]Training epoch 1:  80%|███████▉  | 122/153 [00:08<00:00, 51.55it/s, Epoch: 1, Batch: 123,Loss: 1.545,Avg.Loss: 1.971,LR: 5.00E-04]Training epoch 1:  80%|████████  | 123/153 [00:08<00:00, 51.55it/s, Epoch: 1, Batch: 124,Loss: 1.382,Avg.Loss: 1.966,LR: 5.00E-04]Training epoch 1:  81%|████████  | 124/153 [00:08<00:00, 51.55it/s, Epoch: 1, Batch: 125,Loss: 1.054,Avg.Loss: 1.959,LR: 5.00E-04]Training epoch 1:  82%|████████▏ | 125/153 [00:08<00:00, 51.55it/s, Epoch: 1, Batch: 126,Loss: 1.272,Avg.Loss: 1.953,LR: 5.00E-04]Training epoch 1:  82%|████████▏ | 126/153 [00:08<00:00, 52.17it/s, Epoch: 1, Batch: 126,Loss: 1.272,Avg.Loss: 1.953,LR: 5.00E-04]Training epoch 1:  82%|████████▏ | 126/153 [00:08<00:00, 52.17it/s, Epoch: 1, Batch: 127,Loss: 1.171,Avg.Loss: 1.947,LR: 5.00E-04]Training epoch 1:  83%|████████▎ | 127/153 [00:08<00:00, 52.17it/s, Epoch: 1, Batch: 128,Loss: 2.159,Avg.Loss: 1.949,LR: 5.00E-04]Training epoch 1:  84%|████████▎ | 128/153 [00:08<00:00, 52.17it/s, Epoch: 1, Batch: 129,Loss: 1.599,Avg.Loss: 1.946,LR: 5.00E-04]Training epoch 1:  84%|████████▍ | 129/153 [00:08<00:00, 52.17it/s, Epoch: 1, Batch: 130,Loss: 1.284,Avg.Loss: 1.941,LR: 5.00E-04]Training epoch 1:  85%|████████▍ | 130/153 [00:08<00:00, 52.17it/s, Epoch: 1, Batch: 131,Loss: 1.422,Avg.Loss: 1.937,LR: 5.00E-04]Training epoch 1:  86%|████████▌ | 131/153 [00:08<00:00, 52.17it/s, Epoch: 1, Batch: 132,Loss: 1.166,Avg.Loss: 1.931,LR: 5.00E-04]Training epoch 1:  86%|████████▋ | 132/153 [00:08<00:00, 52.71it/s, Epoch: 1, Batch: 132,Loss: 1.166,Avg.Loss: 1.931,LR: 5.00E-04]Training epoch 1:  86%|████████▋ | 132/153 [00:08<00:00, 52.71it/s, Epoch: 1, Batch: 133,Loss: 1.492,Avg.Loss: 1.928,LR: 5.00E-04]Training epoch 1:  87%|████████▋ | 133/153 [00:08<00:00, 52.71it/s, Epoch: 1, Batch: 134,Loss: 1.420,Avg.Loss: 1.924,LR: 5.00E-04]Training epoch 1:  88%|████████▊ | 134/153 [00:08<00:00, 52.71it/s, Epoch: 1, Batch: 135,Loss: 1.300,Avg.Loss: 1.920,LR: 5.00E-04]Training epoch 1:  88%|████████▊ | 135/153 [00:08<00:00, 52.71it/s, Epoch: 1, Batch: 136,Loss: 1.223,Avg.Loss: 1.914,LR: 5.00E-04]Training epoch 1:  89%|████████▉ | 136/153 [00:08<00:00, 52.71it/s, Epoch: 1, Batch: 137,Loss: 1.639,Avg.Loss: 1.912,LR: 5.00E-04]Training epoch 1:  90%|████████▉ | 137/153 [00:08<00:00, 52.71it/s, Epoch: 1, Batch: 138,Loss: 1.338,Avg.Loss: 1.908,LR: 5.00E-04]Training epoch 1:  90%|█████████ | 138/153 [00:08<00:00, 52.62it/s, Epoch: 1, Batch: 138,Loss: 1.338,Avg.Loss: 1.908,LR: 5.00E-04]Training epoch 1:  90%|█████████ | 138/153 [00:08<00:00, 52.62it/s, Epoch: 1, Batch: 139,Loss: 1.266,Avg.Loss: 1.904,LR: 5.00E-04]Training epoch 1:  91%|█████████ | 139/153 [00:08<00:00, 52.62it/s, Epoch: 1, Batch: 140,Loss: 1.152,Avg.Loss: 1.898,LR: 5.00E-04]Training epoch 1:  92%|█████████▏| 140/153 [00:08<00:00, 52.62it/s, Epoch: 1, Batch: 141,Loss: 1.656,Avg.Loss: 1.896,LR: 5.00E-04]Training epoch 1:  92%|█████████▏| 141/153 [00:08<00:00, 52.62it/s, Epoch: 1, Batch: 142,Loss: 1.706,Avg.Loss: 1.895,LR: 5.00E-04]Training epoch 1:  93%|█████████▎| 142/153 [00:08<00:00, 52.62it/s, Epoch: 1, Batch: 143,Loss: 1.217,Avg.Loss: 1.890,LR: 5.00E-04]Training epoch 1:  93%|█████████▎| 143/153 [00:08<00:00, 52.62it/s, Epoch: 1, Batch: 144,Loss: 1.341,Avg.Loss: 1.887,LR: 5.00E-04]Training epoch 1:  94%|█████████▍| 144/153 [00:08<00:00, 52.69it/s, Epoch: 1, Batch: 144,Loss: 1.341,Avg.Loss: 1.887,LR: 5.00E-04]Training epoch 1:  94%|█████████▍| 144/153 [00:08<00:00, 52.69it/s, Epoch: 1, Batch: 145,Loss: 1.582,Avg.Loss: 1.884,LR: 5.00E-04]Training epoch 1:  95%|█████████▍| 145/153 [00:08<00:00, 52.69it/s, Epoch: 1, Batch: 146,Loss: 1.384,Avg.Loss: 1.881,LR: 5.00E-04]Training epoch 1:  95%|█████████▌| 146/153 [00:08<00:00, 52.69it/s, Epoch: 1, Batch: 147,Loss: 1.558,Avg.Loss: 1.879,LR: 5.00E-04]Training epoch 1:  96%|█████████▌| 147/153 [00:08<00:00, 52.69it/s, Epoch: 1, Batch: 148,Loss: 1.168,Avg.Loss: 1.874,LR: 5.00E-04]Training epoch 1:  97%|█████████▋| 148/153 [00:08<00:00, 52.69it/s, Epoch: 1, Batch: 149,Loss: 1.172,Avg.Loss: 1.869,LR: 5.00E-04]Training epoch 1:  97%|█████████▋| 149/153 [00:08<00:00, 52.69it/s, Epoch: 1, Batch: 150,Loss: 1.577,Avg.Loss: 1.867,LR: 5.00E-04]Training epoch 1:  98%|█████████▊| 150/153 [00:08<00:00, 52.75it/s, Epoch: 1, Batch: 150,Loss: 1.577,Avg.Loss: 1.867,LR: 5.00E-04]Training epoch 1:  98%|█████████▊| 150/153 [00:08<00:00, 52.75it/s, Epoch: 1, Batch: 151,Loss: 2.107,Avg.Loss: 1.869,LR: 5.00E-04]Training epoch 1:  99%|█████████▊| 151/153 [00:08<00:00, 52.75it/s, Epoch: 1, Batch: 152,Loss: 1.041,Avg.Loss: 1.864,LR: 5.00E-04]Training epoch 1:  99%|█████████▉| 152/153 [00:13<00:00, 52.75it/s, Epoch: 1, Batch: 153,Loss: 1.265,Avg.Loss: 1.860,LR: 5.00E-04]Training epoch 1: 100%|██████████| 153/153 [00:13<00:00, 11.57it/s, Epoch: 1, Batch: 153,Loss: 1.265,Avg.Loss: 1.860,LR: 5.00E-04]
Training epoch 2:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 2:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 2, Batch: 1,Loss: 1.451,Avg.Loss: 1.451,LR: 5.00E-04]Training epoch 2:   1%|          | 1/153 [00:00<00:06, 23.88it/s, Epoch: 2, Batch: 2,Loss: 1.334,Avg.Loss: 1.392,LR: 5.00E-04]Training epoch 2:   1%|▏         | 2/153 [00:00<00:04, 33.60it/s, Epoch: 2, Batch: 3,Loss: 1.463,Avg.Loss: 1.416,LR: 5.00E-04]Training epoch 2:   2%|▏         | 3/153 [00:00<00:03, 40.52it/s, Epoch: 2, Batch: 4,Loss: 1.641,Avg.Loss: 1.472,LR: 5.00E-04]Training epoch 2:   3%|▎         | 4/153 [00:00<00:03, 45.31it/s, Epoch: 2, Batch: 5,Loss: 1.582,Avg.Loss: 1.494,LR: 5.00E-04]Training epoch 2:   3%|▎         | 5/153 [00:00<00:03, 47.65it/s, Epoch: 2, Batch: 6,Loss: 1.325,Avg.Loss: 1.466,LR: 5.00E-04]Training epoch 2:   4%|▍         | 6/153 [00:00<00:02, 57.09it/s, Epoch: 2, Batch: 6,Loss: 1.325,Avg.Loss: 1.466,LR: 5.00E-04]Training epoch 2:   4%|▍         | 6/153 [00:00<00:02, 57.09it/s, Epoch: 2, Batch: 7,Loss: 1.205,Avg.Loss: 1.429,LR: 5.00E-04]Training epoch 2:   5%|▍         | 7/153 [00:00<00:02, 57.09it/s, Epoch: 2, Batch: 8,Loss: 1.385,Avg.Loss: 1.423,LR: 5.00E-04]Training epoch 2:   5%|▌         | 8/153 [00:00<00:02, 57.09it/s, Epoch: 2, Batch: 9,Loss: 1.612,Avg.Loss: 1.444,LR: 5.00E-04]Training epoch 2:   6%|▌         | 9/153 [00:00<00:02, 57.09it/s, Epoch: 2, Batch: 10,Loss: 1.215,Avg.Loss: 1.421,LR: 5.00E-04]Training epoch 2:   7%|▋         | 10/153 [00:00<00:02, 57.09it/s, Epoch: 2, Batch: 11,Loss: 1.491,Avg.Loss: 1.428,LR: 5.00E-04]Training epoch 2:   7%|▋         | 11/153 [00:00<00:02, 57.09it/s, Epoch: 2, Batch: 12,Loss: 1.381,Avg.Loss: 1.424,LR: 5.00E-04]Training epoch 2:   8%|▊         | 12/153 [00:00<00:02, 57.09it/s, Epoch: 2, Batch: 13,Loss: 1.197,Avg.Loss: 1.406,LR: 5.00E-04]Training epoch 2:   8%|▊         | 13/153 [00:00<00:02, 63.89it/s, Epoch: 2, Batch: 13,Loss: 1.197,Avg.Loss: 1.406,LR: 5.00E-04]Training epoch 2:   8%|▊         | 13/153 [00:00<00:02, 63.89it/s, Epoch: 2, Batch: 14,Loss: 1.486,Avg.Loss: 1.412,LR: 5.00E-04]Training epoch 2:   9%|▉         | 14/153 [00:00<00:02, 63.89it/s, Epoch: 2, Batch: 15,Loss: 1.038,Avg.Loss: 1.387,LR: 5.00E-04]Training epoch 2:  10%|▉         | 15/153 [00:00<00:02, 63.89it/s, Epoch: 2, Batch: 16,Loss: 1.382,Avg.Loss: 1.387,LR: 5.00E-04]Training epoch 2:  10%|█         | 16/153 [00:00<00:02, 63.89it/s, Epoch: 2, Batch: 17,Loss: 1.124,Avg.Loss: 1.371,LR: 5.00E-04]Training epoch 2:  11%|█         | 17/153 [00:00<00:02, 63.89it/s, Epoch: 2, Batch: 18,Loss: 1.447,Avg.Loss: 1.376,LR: 5.00E-04]Training epoch 2:  12%|█▏        | 18/153 [00:00<00:02, 63.89it/s, Epoch: 2, Batch: 19,Loss: 1.709,Avg.Loss: 1.393,LR: 5.00E-04]Training epoch 2:  12%|█▏        | 19/153 [00:00<00:02, 63.89it/s, Epoch: 2, Batch: 20,Loss: 1.171,Avg.Loss: 1.382,LR: 5.00E-04]Training epoch 2:  13%|█▎        | 20/153 [00:00<00:02, 58.04it/s, Epoch: 2, Batch: 20,Loss: 1.171,Avg.Loss: 1.382,LR: 5.00E-04]Training epoch 2:  13%|█▎        | 20/153 [00:00<00:02, 58.04it/s, Epoch: 2, Batch: 21,Loss: 1.232,Avg.Loss: 1.375,LR: 5.00E-04]Training epoch 2:  14%|█▎        | 21/153 [00:00<00:02, 58.04it/s, Epoch: 2, Batch: 22,Loss: 1.262,Avg.Loss: 1.370,LR: 5.00E-04]Training epoch 2:  14%|█▍        | 22/153 [00:00<00:02, 58.04it/s, Epoch: 2, Batch: 23,Loss: 1.215,Avg.Loss: 1.363,LR: 5.00E-04]Training epoch 2:  15%|█▌        | 23/153 [00:00<00:02, 58.04it/s, Epoch: 2, Batch: 24,Loss: 1.174,Avg.Loss: 1.355,LR: 5.00E-04]Training epoch 2:  16%|█▌        | 24/153 [00:00<00:02, 58.04it/s, Epoch: 2, Batch: 25,Loss: 1.490,Avg.Loss: 1.361,LR: 5.00E-04]Training epoch 2:  16%|█▋        | 25/153 [00:00<00:02, 58.04it/s, Epoch: 2, Batch: 26,Loss: 1.432,Avg.Loss: 1.363,LR: 5.00E-04]Training epoch 2:  17%|█▋        | 26/153 [00:00<00:02, 55.71it/s, Epoch: 2, Batch: 26,Loss: 1.432,Avg.Loss: 1.363,LR: 5.00E-04]Training epoch 2:  17%|█▋        | 26/153 [00:00<00:02, 55.71it/s, Epoch: 2, Batch: 27,Loss: 1.162,Avg.Loss: 1.356,LR: 5.00E-04]Training epoch 2:  18%|█▊        | 27/153 [00:00<00:02, 55.71it/s, Epoch: 2, Batch: 28,Loss: 1.725,Avg.Loss: 1.369,LR: 5.00E-04]Training epoch 2:  18%|█▊        | 28/153 [00:00<00:02, 55.71it/s, Epoch: 2, Batch: 29,Loss: 1.095,Avg.Loss: 1.360,LR: 5.00E-04]Training epoch 2:  19%|█▉        | 29/153 [00:00<00:02, 55.71it/s, Epoch: 2, Batch: 30,Loss: 1.160,Avg.Loss: 1.353,LR: 5.00E-04]Training epoch 2:  20%|█▉        | 30/153 [00:00<00:02, 55.71it/s, Epoch: 2, Batch: 31,Loss: 1.235,Avg.Loss: 1.349,LR: 5.00E-04]Training epoch 2:  20%|██        | 31/153 [00:00<00:02, 55.71it/s, Epoch: 2, Batch: 32,Loss: 1.034,Avg.Loss: 1.339,LR: 5.00E-04]Training epoch 2:  21%|██        | 32/153 [00:00<00:02, 54.51it/s, Epoch: 2, Batch: 32,Loss: 1.034,Avg.Loss: 1.339,LR: 5.00E-04]Training epoch 2:  21%|██        | 32/153 [00:00<00:02, 54.51it/s, Epoch: 2, Batch: 33,Loss: 1.217,Avg.Loss: 1.336,LR: 5.00E-04]Training epoch 2:  22%|██▏       | 33/153 [00:00<00:02, 54.51it/s, Epoch: 2, Batch: 34,Loss: 1.005,Avg.Loss: 1.326,LR: 5.00E-04]Training epoch 2:  22%|██▏       | 34/153 [00:00<00:02, 54.51it/s, Epoch: 2, Batch: 35,Loss: 1.200,Avg.Loss: 1.322,LR: 5.00E-04]Training epoch 2:  23%|██▎       | 35/153 [00:00<00:02, 54.51it/s, Epoch: 2, Batch: 36,Loss: 1.281,Avg.Loss: 1.321,LR: 5.00E-04]Training epoch 2:  24%|██▎       | 36/153 [00:00<00:02, 54.51it/s, Epoch: 2, Batch: 37,Loss: 1.418,Avg.Loss: 1.324,LR: 5.00E-04]Training epoch 2:  24%|██▍       | 37/153 [00:00<00:02, 54.51it/s, Epoch: 2, Batch: 38,Loss: 1.340,Avg.Loss: 1.324,LR: 5.00E-04]Training epoch 2:  25%|██▍       | 38/153 [00:00<00:02, 53.81it/s, Epoch: 2, Batch: 38,Loss: 1.340,Avg.Loss: 1.324,LR: 5.00E-04]Training epoch 2:  25%|██▍       | 38/153 [00:00<00:02, 53.81it/s, Epoch: 2, Batch: 39,Loss: 1.280,Avg.Loss: 1.323,LR: 5.00E-04]Training epoch 2:  25%|██▌       | 39/153 [00:00<00:02, 53.81it/s, Epoch: 2, Batch: 40,Loss: 1.169,Avg.Loss: 1.319,LR: 5.00E-04]Training epoch 2:  26%|██▌       | 40/153 [00:00<00:02, 53.81it/s, Epoch: 2, Batch: 41,Loss: 1.187,Avg.Loss: 1.316,LR: 5.00E-04]Training epoch 2:  27%|██▋       | 41/153 [00:00<00:02, 53.81it/s, Epoch: 2, Batch: 42,Loss: 1.635,Avg.Loss: 1.324,LR: 5.00E-04]Training epoch 2:  27%|██▋       | 42/153 [00:00<00:02, 53.81it/s, Epoch: 2, Batch: 43,Loss: 0.825,Avg.Loss: 1.312,LR: 5.00E-04]Training epoch 2:  28%|██▊       | 43/153 [00:00<00:02, 53.81it/s, Epoch: 2, Batch: 44,Loss: 1.223,Avg.Loss: 1.310,LR: 5.00E-04]Training epoch 2:  29%|██▉       | 44/153 [00:00<00:02, 53.90it/s, Epoch: 2, Batch: 44,Loss: 1.223,Avg.Loss: 1.310,LR: 5.00E-04]Training epoch 2:  29%|██▉       | 44/153 [00:00<00:02, 53.90it/s, Epoch: 2, Batch: 45,Loss: 1.256,Avg.Loss: 1.309,LR: 5.00E-04]Training epoch 2:  29%|██▉       | 45/153 [00:00<00:02, 53.90it/s, Epoch: 2, Batch: 46,Loss: 1.409,Avg.Loss: 1.311,LR: 5.00E-04]Training epoch 2:  30%|███       | 46/153 [00:00<00:01, 53.90it/s, Epoch: 2, Batch: 47,Loss: 0.945,Avg.Loss: 1.303,LR: 5.00E-04]Training epoch 2:  31%|███       | 47/153 [00:00<00:01, 53.90it/s, Epoch: 2, Batch: 48,Loss: 1.303,Avg.Loss: 1.303,LR: 5.00E-04]Training epoch 2:  31%|███▏      | 48/153 [00:00<00:01, 53.90it/s, Epoch: 2, Batch: 49,Loss: 1.570,Avg.Loss: 1.309,LR: 5.00E-04]Training epoch 2:  32%|███▏      | 49/153 [00:00<00:01, 53.90it/s, Epoch: 2, Batch: 50,Loss: 1.061,Avg.Loss: 1.304,LR: 5.00E-04]Training epoch 2:  33%|███▎      | 50/153 [00:00<00:01, 53.71it/s, Epoch: 2, Batch: 50,Loss: 1.061,Avg.Loss: 1.304,LR: 5.00E-04]Training epoch 2:  33%|███▎      | 50/153 [00:00<00:01, 53.71it/s, Epoch: 2, Batch: 51,Loss: 1.412,Avg.Loss: 1.306,LR: 5.00E-04]Training epoch 2:  33%|███▎      | 51/153 [00:00<00:01, 53.71it/s, Epoch: 2, Batch: 52,Loss: 1.363,Avg.Loss: 1.307,LR: 5.00E-04]Training epoch 2:  34%|███▍      | 52/153 [00:00<00:01, 53.71it/s, Epoch: 2, Batch: 53,Loss: 1.335,Avg.Loss: 1.307,LR: 5.00E-04]Training epoch 2:  35%|███▍      | 53/153 [00:00<00:01, 53.71it/s, Epoch: 2, Batch: 54,Loss: 1.138,Avg.Loss: 1.304,LR: 5.00E-04]Training epoch 2:  35%|███▌      | 54/153 [00:01<00:01, 53.71it/s, Epoch: 2, Batch: 55,Loss: 1.306,Avg.Loss: 1.304,LR: 5.00E-04]Training epoch 2:  36%|███▌      | 55/153 [00:01<00:01, 53.71it/s, Epoch: 2, Batch: 56,Loss: 1.135,Avg.Loss: 1.301,LR: 5.00E-04]Training epoch 2:  37%|███▋      | 56/153 [00:01<00:01, 53.16it/s, Epoch: 2, Batch: 56,Loss: 1.135,Avg.Loss: 1.301,LR: 5.00E-04]Training epoch 2:  37%|███▋      | 56/153 [00:01<00:01, 53.16it/s, Epoch: 2, Batch: 57,Loss: 0.919,Avg.Loss: 1.295,LR: 5.00E-04]Training epoch 2:  37%|███▋      | 57/153 [00:01<00:01, 53.16it/s, Epoch: 2, Batch: 58,Loss: 1.611,Avg.Loss: 1.300,LR: 5.00E-04]Training epoch 2:  38%|███▊      | 58/153 [00:01<00:01, 53.16it/s, Epoch: 2, Batch: 59,Loss: 0.893,Avg.Loss: 1.293,LR: 5.00E-04]Training epoch 2:  39%|███▊      | 59/153 [00:01<00:01, 53.16it/s, Epoch: 2, Batch: 60,Loss: 1.206,Avg.Loss: 1.292,LR: 5.00E-04]Training epoch 2:  39%|███▉      | 60/153 [00:01<00:01, 53.16it/s, Epoch: 2, Batch: 61,Loss: 1.247,Avg.Loss: 1.291,LR: 5.00E-04]Training epoch 2:  40%|███▉      | 61/153 [00:01<00:01, 53.16it/s, Epoch: 2, Batch: 62,Loss: 1.078,Avg.Loss: 1.287,LR: 5.00E-04]Training epoch 2:  41%|████      | 62/153 [00:01<00:01, 52.82it/s, Epoch: 2, Batch: 62,Loss: 1.078,Avg.Loss: 1.287,LR: 5.00E-04]Training epoch 2:  41%|████      | 62/153 [00:01<00:01, 52.82it/s, Epoch: 2, Batch: 63,Loss: 1.270,Avg.Loss: 1.287,LR: 5.00E-04]Training epoch 2:  41%|████      | 63/153 [00:01<00:01, 52.82it/s, Epoch: 2, Batch: 64,Loss: 1.142,Avg.Loss: 1.285,LR: 5.00E-04]Training epoch 2:  42%|████▏     | 64/153 [00:01<00:01, 52.82it/s, Epoch: 2, Batch: 65,Loss: 0.910,Avg.Loss: 1.279,LR: 5.00E-04]Training epoch 2:  42%|████▏     | 65/153 [00:01<00:01, 52.82it/s, Epoch: 2, Batch: 66,Loss: 1.337,Avg.Loss: 1.280,LR: 5.00E-04]Training epoch 2:  43%|████▎     | 66/153 [00:01<00:01, 52.82it/s, Epoch: 2, Batch: 67,Loss: 1.106,Avg.Loss: 1.277,LR: 5.00E-04]Training epoch 2:  44%|████▍     | 67/153 [00:01<00:01, 52.82it/s, Epoch: 2, Batch: 68,Loss: 1.308,Avg.Loss: 1.278,LR: 5.00E-04]Training epoch 2:  44%|████▍     | 68/153 [00:01<00:01, 52.70it/s, Epoch: 2, Batch: 68,Loss: 1.308,Avg.Loss: 1.278,LR: 5.00E-04]Training epoch 2:  44%|████▍     | 68/153 [00:01<00:01, 52.70it/s, Epoch: 2, Batch: 69,Loss: 1.177,Avg.Loss: 1.276,LR: 5.00E-04]Training epoch 2:  45%|████▌     | 69/153 [00:01<00:01, 52.70it/s, Epoch: 2, Batch: 70,Loss: 1.282,Avg.Loss: 1.277,LR: 5.00E-04]Training epoch 2:  46%|████▌     | 70/153 [00:01<00:01, 52.70it/s, Epoch: 2, Batch: 71,Loss: 1.515,Avg.Loss: 1.280,LR: 5.00E-04]Training epoch 2:  46%|████▋     | 71/153 [00:01<00:01, 52.70it/s, Epoch: 2, Batch: 72,Loss: 1.137,Avg.Loss: 1.278,LR: 5.00E-04]Training epoch 2:  47%|████▋     | 72/153 [00:01<00:01, 52.70it/s, Epoch: 2, Batch: 73,Loss: 1.280,Avg.Loss: 1.278,LR: 5.00E-04]Training epoch 2:  48%|████▊     | 73/153 [00:01<00:01, 52.70it/s, Epoch: 2, Batch: 74,Loss: 1.007,Avg.Loss: 1.274,LR: 5.00E-04]Training epoch 2:  48%|████▊     | 74/153 [00:01<00:01, 51.75it/s, Epoch: 2, Batch: 74,Loss: 1.007,Avg.Loss: 1.274,LR: 5.00E-04]Training epoch 2:  48%|████▊     | 74/153 [00:01<00:01, 51.75it/s, Epoch: 2, Batch: 75,Loss: 1.434,Avg.Loss: 1.276,LR: 5.00E-04]Training epoch 2:  49%|████▉     | 75/153 [00:01<00:01, 51.75it/s, Epoch: 2, Batch: 76,Loss: 1.663,Avg.Loss: 1.281,LR: 5.00E-04]Training epoch 2:  50%|████▉     | 76/153 [00:01<00:01, 51.75it/s, Epoch: 2, Batch: 77,Loss: 1.047,Avg.Loss: 1.278,LR: 5.00E-04]Training epoch 2:  50%|█████     | 77/153 [00:01<00:01, 51.75it/s, Epoch: 2, Batch: 78,Loss: 1.155,Avg.Loss: 1.277,LR: 5.00E-04]Training epoch 2:  51%|█████     | 78/153 [00:01<00:01, 51.75it/s, Epoch: 2, Batch: 79,Loss: 1.326,Avg.Loss: 1.277,LR: 5.00E-04]Training epoch 2:  52%|█████▏    | 79/153 [00:01<00:01, 51.75it/s, Epoch: 2, Batch: 80,Loss: 1.281,Avg.Loss: 1.278,LR: 5.00E-04]Training epoch 2:  52%|█████▏    | 80/153 [00:01<00:01, 51.93it/s, Epoch: 2, Batch: 80,Loss: 1.281,Avg.Loss: 1.278,LR: 5.00E-04]Training epoch 2:  52%|█████▏    | 80/153 [00:01<00:01, 51.93it/s, Epoch: 2, Batch: 81,Loss: 1.305,Avg.Loss: 1.278,LR: 5.00E-04]Training epoch 2:  53%|█████▎    | 81/153 [00:01<00:01, 51.93it/s, Epoch: 2, Batch: 82,Loss: 1.060,Avg.Loss: 1.275,LR: 5.00E-04]Training epoch 2:  54%|█████▎    | 82/153 [00:01<00:01, 51.93it/s, Epoch: 2, Batch: 83,Loss: 1.091,Avg.Loss: 1.273,LR: 5.00E-04]Training epoch 2:  54%|█████▍    | 83/153 [00:01<00:01, 51.93it/s, Epoch: 2, Batch: 84,Loss: 1.124,Avg.Loss: 1.271,LR: 5.00E-04]Training epoch 2:  55%|█████▍    | 84/153 [00:01<00:01, 51.93it/s, Epoch: 2, Batch: 85,Loss: 0.970,Avg.Loss: 1.268,LR: 5.00E-04]Training epoch 2:  56%|█████▌    | 85/153 [00:01<00:01, 51.93it/s, Epoch: 2, Batch: 86,Loss: 1.250,Avg.Loss: 1.267,LR: 5.00E-04]Training epoch 2:  56%|█████▌    | 86/153 [00:01<00:01, 52.29it/s, Epoch: 2, Batch: 86,Loss: 1.250,Avg.Loss: 1.267,LR: 5.00E-04]Training epoch 2:  56%|█████▌    | 86/153 [00:01<00:01, 52.29it/s, Epoch: 2, Batch: 87,Loss: 1.102,Avg.Loss: 1.266,LR: 5.00E-04]Training epoch 2:  57%|█████▋    | 87/153 [00:01<00:01, 52.29it/s, Epoch: 2, Batch: 88,Loss: 1.263,Avg.Loss: 1.266,LR: 5.00E-04]Training epoch 2:  58%|█████▊    | 88/153 [00:01<00:01, 52.29it/s, Epoch: 2, Batch: 89,Loss: 1.460,Avg.Loss: 1.268,LR: 5.00E-04]Training epoch 2:  58%|█████▊    | 89/153 [00:01<00:01, 52.29it/s, Epoch: 2, Batch: 90,Loss: 1.470,Avg.Loss: 1.270,LR: 5.00E-04]Training epoch 2:  59%|█████▉    | 90/153 [00:01<00:01, 52.29it/s, Epoch: 2, Batch: 91,Loss: 1.538,Avg.Loss: 1.273,LR: 5.00E-04]Training epoch 2:  59%|█████▉    | 91/153 [00:01<00:01, 52.29it/s, Epoch: 2, Batch: 92,Loss: 1.299,Avg.Loss: 1.273,LR: 5.00E-04]Training epoch 2:  60%|██████    | 92/153 [00:01<00:01, 52.45it/s, Epoch: 2, Batch: 92,Loss: 1.299,Avg.Loss: 1.273,LR: 5.00E-04]Training epoch 2:  60%|██████    | 92/153 [00:01<00:01, 52.45it/s, Epoch: 2, Batch: 93,Loss: 1.227,Avg.Loss: 1.273,LR: 5.00E-04]Training epoch 2:  61%|██████    | 93/153 [00:01<00:01, 52.45it/s, Epoch: 2, Batch: 94,Loss: 0.998,Avg.Loss: 1.270,LR: 5.00E-04]Training epoch 2:  61%|██████▏   | 94/153 [00:01<00:01, 52.45it/s, Epoch: 2, Batch: 95,Loss: 0.970,Avg.Loss: 1.267,LR: 5.00E-04]Training epoch 2:  62%|██████▏   | 95/153 [00:01<00:01, 52.45it/s, Epoch: 2, Batch: 96,Loss: 1.294,Avg.Loss: 1.267,LR: 5.00E-04]Training epoch 2:  63%|██████▎   | 96/153 [00:01<00:01, 52.45it/s, Epoch: 2, Batch: 97,Loss: 1.141,Avg.Loss: 1.266,LR: 5.00E-04]Training epoch 2:  63%|██████▎   | 97/153 [00:01<00:01, 52.45it/s, Epoch: 2, Batch: 98,Loss: 1.024,Avg.Loss: 1.263,LR: 5.00E-04]Training epoch 2:  64%|██████▍   | 98/153 [00:01<00:01, 52.55it/s, Epoch: 2, Batch: 98,Loss: 1.024,Avg.Loss: 1.263,LR: 5.00E-04]Training epoch 2:  64%|██████▍   | 98/153 [00:01<00:01, 52.55it/s, Epoch: 2, Batch: 99,Loss: 1.025,Avg.Loss: 1.261,LR: 5.00E-04]Training epoch 2:  65%|██████▍   | 99/153 [00:01<00:01, 52.55it/s, Epoch: 2, Batch: 100,Loss: 1.351,Avg.Loss: 1.262,LR: 5.00E-04]Training epoch 2:  65%|██████▌   | 100/153 [00:01<00:01, 52.55it/s, Epoch: 2, Batch: 101,Loss: 1.141,Avg.Loss: 1.260,LR: 5.00E-04]Training epoch 2:  66%|██████▌   | 101/153 [00:01<00:00, 52.55it/s, Epoch: 2, Batch: 102,Loss: 0.968,Avg.Loss: 1.258,LR: 5.00E-04]Training epoch 2:  67%|██████▋   | 102/153 [00:01<00:00, 52.55it/s, Epoch: 2, Batch: 103,Loss: 0.856,Avg.Loss: 1.254,LR: 5.00E-04]Training epoch 2:  67%|██████▋   | 103/153 [00:01<00:00, 52.55it/s, Epoch: 2, Batch: 104,Loss: 1.221,Avg.Loss: 1.253,LR: 5.00E-04]Training epoch 2:  68%|██████▊   | 104/153 [00:01<00:00, 52.70it/s, Epoch: 2, Batch: 104,Loss: 1.221,Avg.Loss: 1.253,LR: 5.00E-04]Training epoch 2:  68%|██████▊   | 104/153 [00:01<00:00, 52.70it/s, Epoch: 2, Batch: 105,Loss: 1.092,Avg.Loss: 1.252,LR: 5.00E-04]Training epoch 2:  69%|██████▊   | 105/153 [00:01<00:00, 52.70it/s, Epoch: 2, Batch: 106,Loss: 1.193,Avg.Loss: 1.251,LR: 5.00E-04]Training epoch 2:  69%|██████▉   | 106/153 [00:01<00:00, 52.70it/s, Epoch: 2, Batch: 107,Loss: 1.163,Avg.Loss: 1.250,LR: 5.00E-04]Training epoch 2:  70%|██████▉   | 107/153 [00:02<00:00, 52.70it/s, Epoch: 2, Batch: 108,Loss: 1.138,Avg.Loss: 1.249,LR: 5.00E-04]Training epoch 2:  71%|███████   | 108/153 [00:02<00:00, 52.70it/s, Epoch: 2, Batch: 109,Loss: 1.395,Avg.Loss: 1.251,LR: 5.00E-04]Training epoch 2:  71%|███████   | 109/153 [00:02<00:00, 52.70it/s, Epoch: 2, Batch: 110,Loss: 1.298,Avg.Loss: 1.251,LR: 5.00E-04]Training epoch 2:  72%|███████▏  | 110/153 [00:02<00:00, 52.77it/s, Epoch: 2, Batch: 110,Loss: 1.298,Avg.Loss: 1.251,LR: 5.00E-04]Training epoch 2:  72%|███████▏  | 110/153 [00:02<00:00, 52.77it/s, Epoch: 2, Batch: 111,Loss: 1.180,Avg.Loss: 1.251,LR: 5.00E-04]Training epoch 2:  73%|███████▎  | 111/153 [00:02<00:00, 52.77it/s, Epoch: 2, Batch: 112,Loss: 1.254,Avg.Loss: 1.251,LR: 5.00E-04]Training epoch 2:  73%|███████▎  | 112/153 [00:02<00:00, 52.77it/s, Epoch: 2, Batch: 113,Loss: 1.044,Avg.Loss: 1.249,LR: 5.00E-04]Training epoch 2:  74%|███████▍  | 113/153 [00:02<00:00, 52.77it/s, Epoch: 2, Batch: 114,Loss: 1.264,Avg.Loss: 1.249,LR: 5.00E-04]Training epoch 2:  75%|███████▍  | 114/153 [00:02<00:00, 52.77it/s, Epoch: 2, Batch: 115,Loss: 1.123,Avg.Loss: 1.248,LR: 5.00E-04]Training epoch 2:  75%|███████▌  | 115/153 [00:02<00:00, 52.77it/s, Epoch: 2, Batch: 116,Loss: 1.250,Avg.Loss: 1.248,LR: 5.00E-04]Training epoch 2:  76%|███████▌  | 116/153 [00:02<00:00, 53.03it/s, Epoch: 2, Batch: 116,Loss: 1.250,Avg.Loss: 1.248,LR: 5.00E-04]Training epoch 2:  76%|███████▌  | 116/153 [00:02<00:00, 53.03it/s, Epoch: 2, Batch: 117,Loss: 1.630,Avg.Loss: 1.251,LR: 5.00E-04]Training epoch 2:  76%|███████▋  | 117/153 [00:02<00:00, 53.03it/s, Epoch: 2, Batch: 118,Loss: 1.076,Avg.Loss: 1.250,LR: 5.00E-04]Training epoch 2:  77%|███████▋  | 118/153 [00:02<00:00, 53.03it/s, Epoch: 2, Batch: 119,Loss: 1.082,Avg.Loss: 1.248,LR: 5.00E-04]Training epoch 2:  78%|███████▊  | 119/153 [00:02<00:00, 53.03it/s, Epoch: 2, Batch: 120,Loss: 1.024,Avg.Loss: 1.246,LR: 5.00E-04]Training epoch 2:  78%|███████▊  | 120/153 [00:02<00:00, 53.03it/s, Epoch: 2, Batch: 121,Loss: 1.459,Avg.Loss: 1.248,LR: 5.00E-04]Training epoch 2:  79%|███████▉  | 121/153 [00:02<00:00, 53.03it/s, Epoch: 2, Batch: 122,Loss: 1.136,Avg.Loss: 1.247,LR: 5.00E-04]Training epoch 2:  80%|███████▉  | 122/153 [00:02<00:00, 53.23it/s, Epoch: 2, Batch: 122,Loss: 1.136,Avg.Loss: 1.247,LR: 5.00E-04]Training epoch 2:  80%|███████▉  | 122/153 [00:02<00:00, 53.23it/s, Epoch: 2, Batch: 123,Loss: 1.674,Avg.Loss: 1.251,LR: 5.00E-04]Training epoch 2:  80%|████████  | 123/153 [00:02<00:00, 53.23it/s, Epoch: 2, Batch: 124,Loss: 0.955,Avg.Loss: 1.248,LR: 5.00E-04]Training epoch 2:  81%|████████  | 124/153 [00:02<00:00, 53.23it/s, Epoch: 2, Batch: 125,Loss: 1.307,Avg.Loss: 1.249,LR: 5.00E-04]Training epoch 2:  82%|████████▏ | 125/153 [00:02<00:00, 53.23it/s, Epoch: 2, Batch: 126,Loss: 0.920,Avg.Loss: 1.246,LR: 5.00E-04]Training epoch 2:  82%|████████▏ | 126/153 [00:02<00:00, 53.23it/s, Epoch: 2, Batch: 127,Loss: 1.292,Avg.Loss: 1.246,LR: 5.00E-04]Training epoch 2:  83%|████████▎ | 127/153 [00:02<00:00, 53.23it/s, Epoch: 2, Batch: 128,Loss: 1.148,Avg.Loss: 1.246,LR: 5.00E-04]Training epoch 2:  84%|████████▎ | 128/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 128,Loss: 1.148,Avg.Loss: 1.246,LR: 5.00E-04]Training epoch 2:  84%|████████▎ | 128/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 129,Loss: 1.432,Avg.Loss: 1.247,LR: 5.00E-04]Training epoch 2:  84%|████████▍ | 129/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 130,Loss: 1.203,Avg.Loss: 1.247,LR: 5.00E-04]Training epoch 2:  85%|████████▍ | 130/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 131,Loss: 0.968,Avg.Loss: 1.245,LR: 5.00E-04]Training epoch 2:  86%|████████▌ | 131/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 132,Loss: 1.145,Avg.Loss: 1.244,LR: 5.00E-04]Training epoch 2:  86%|████████▋ | 132/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 133,Loss: 1.167,Avg.Loss: 1.243,LR: 5.00E-04]Training epoch 2:  87%|████████▋ | 133/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 134,Loss: 1.200,Avg.Loss: 1.243,LR: 5.00E-04]Training epoch 2:  88%|████████▊ | 134/153 [00:02<00:00, 53.41it/s, Epoch: 2, Batch: 134,Loss: 1.200,Avg.Loss: 1.243,LR: 5.00E-04]Training epoch 2:  88%|████████▊ | 134/153 [00:02<00:00, 53.41it/s, Epoch: 2, Batch: 135,Loss: 0.932,Avg.Loss: 1.241,LR: 5.00E-04]Training epoch 2:  88%|████████▊ | 135/153 [00:02<00:00, 53.41it/s, Epoch: 2, Batch: 136,Loss: 1.126,Avg.Loss: 1.240,LR: 5.00E-04]Training epoch 2:  89%|████████▉ | 136/153 [00:02<00:00, 53.41it/s, Epoch: 2, Batch: 137,Loss: 1.066,Avg.Loss: 1.239,LR: 5.00E-04]Training epoch 2:  90%|████████▉ | 137/153 [00:02<00:00, 53.41it/s, Epoch: 2, Batch: 138,Loss: 1.285,Avg.Loss: 1.239,LR: 5.00E-04]Training epoch 2:  90%|█████████ | 138/153 [00:02<00:00, 53.41it/s, Epoch: 2, Batch: 139,Loss: 1.151,Avg.Loss: 1.238,LR: 5.00E-04]Training epoch 2:  91%|█████████ | 139/153 [00:02<00:00, 53.41it/s, Epoch: 2, Batch: 140,Loss: 1.169,Avg.Loss: 1.238,LR: 5.00E-04]Training epoch 2:  92%|█████████▏| 140/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 140,Loss: 1.169,Avg.Loss: 1.238,LR: 5.00E-04]Training epoch 2:  92%|█████████▏| 140/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 141,Loss: 1.212,Avg.Loss: 1.238,LR: 5.00E-04]Training epoch 2:  92%|█████████▏| 141/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 142,Loss: 1.267,Avg.Loss: 1.238,LR: 5.00E-04]Training epoch 2:  93%|█████████▎| 142/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 143,Loss: 1.249,Avg.Loss: 1.238,LR: 5.00E-04]Training epoch 2:  93%|█████████▎| 143/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 144,Loss: 1.366,Avg.Loss: 1.239,LR: 5.00E-04]Training epoch 2:  94%|█████████▍| 144/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 145,Loss: 0.977,Avg.Loss: 1.237,LR: 5.00E-04]Training epoch 2:  95%|█████████▍| 145/153 [00:02<00:00, 53.36it/s, Epoch: 2, Batch: 146,Loss: 0.893,Avg.Loss: 1.235,LR: 5.00E-04]Training epoch 2:  95%|█████████▌| 146/153 [00:02<00:00, 53.28it/s, Epoch: 2, Batch: 146,Loss: 0.893,Avg.Loss: 1.235,LR: 5.00E-04]Training epoch 2:  95%|█████████▌| 146/153 [00:02<00:00, 53.28it/s, Epoch: 2, Batch: 147,Loss: 1.207,Avg.Loss: 1.234,LR: 5.00E-04]Training epoch 2:  96%|█████████▌| 147/153 [00:02<00:00, 53.28it/s, Epoch: 2, Batch: 148,Loss: 1.154,Avg.Loss: 1.234,LR: 5.00E-04]Training epoch 2:  97%|█████████▋| 148/153 [00:02<00:00, 53.28it/s, Epoch: 2, Batch: 149,Loss: 1.469,Avg.Loss: 1.235,LR: 5.00E-04]Training epoch 2:  97%|█████████▋| 149/153 [00:02<00:00, 53.28it/s, Epoch: 2, Batch: 150,Loss: 1.031,Avg.Loss: 1.234,LR: 5.00E-04]Training epoch 2:  98%|█████████▊| 150/153 [00:02<00:00, 53.28it/s, Epoch: 2, Batch: 151,Loss: 1.290,Avg.Loss: 1.234,LR: 5.00E-04]Training epoch 2:  99%|█████████▊| 151/153 [00:02<00:00, 53.28it/s, Epoch: 2, Batch: 152,Loss: 1.146,Avg.Loss: 1.234,LR: 5.00E-04]Training epoch 2:  99%|█████████▉| 152/153 [00:02<00:00, 53.27it/s, Epoch: 2, Batch: 152,Loss: 1.146,Avg.Loss: 1.234,LR: 5.00E-04]Training epoch 2:  99%|█████████▉| 152/153 [00:02<00:00, 53.27it/s, Epoch: 2, Batch: 153,Loss: 0.969,Avg.Loss: 1.232,LR: 5.00E-04]Training epoch 2: 100%|██████████| 153/153 [00:02<00:00, 53.45it/s, Epoch: 2, Batch: 153,Loss: 0.969,Avg.Loss: 1.232,LR: 5.00E-04]
Training epoch 3:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 3:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 3, Batch: 1,Loss: 1.030,Avg.Loss: 1.030,LR: 5.00E-04]Training epoch 3:   1%|          | 1/153 [00:00<00:06, 22.79it/s, Epoch: 3, Batch: 2,Loss: 0.953,Avg.Loss: 0.991,LR: 5.00E-04]Training epoch 3:   1%|▏         | 2/153 [00:00<00:04, 33.67it/s, Epoch: 3, Batch: 3,Loss: 1.212,Avg.Loss: 1.065,LR: 4.99E-04]Training epoch 3:   2%|▏         | 3/153 [00:00<00:03, 39.40it/s, Epoch: 3, Batch: 4,Loss: 0.882,Avg.Loss: 1.019,LR: 4.99E-04]Training epoch 3:   3%|▎         | 4/153 [00:00<00:03, 44.00it/s, Epoch: 3, Batch: 5,Loss: 1.307,Avg.Loss: 1.077,LR: 4.99E-04]Training epoch 3:   3%|▎         | 5/153 [00:00<00:03, 47.11it/s, Epoch: 3, Batch: 6,Loss: 1.146,Avg.Loss: 1.088,LR: 4.99E-04]Training epoch 3:   4%|▍         | 6/153 [00:00<00:02, 56.44it/s, Epoch: 3, Batch: 6,Loss: 1.146,Avg.Loss: 1.088,LR: 4.99E-04]Training epoch 3:   4%|▍         | 6/153 [00:00<00:02, 56.44it/s, Epoch: 3, Batch: 7,Loss: 0.988,Avg.Loss: 1.074,LR: 4.99E-04]Training epoch 3:   5%|▍         | 7/153 [00:00<00:02, 56.44it/s, Epoch: 3, Batch: 8,Loss: 0.989,Avg.Loss: 1.063,LR: 4.99E-04]Training epoch 3:   5%|▌         | 8/153 [00:00<00:02, 56.44it/s, Epoch: 3, Batch: 9,Loss: 1.121,Avg.Loss: 1.070,LR: 4.99E-04]Training epoch 3:   6%|▌         | 9/153 [00:00<00:02, 56.44it/s, Epoch: 3, Batch: 10,Loss: 1.453,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 3:   7%|▋         | 10/153 [00:00<00:02, 56.44it/s, Epoch: 3, Batch: 11,Loss: 1.179,Avg.Loss: 1.115,LR: 4.99E-04]Training epoch 3:   7%|▋         | 11/153 [00:00<00:02, 56.44it/s, Epoch: 3, Batch: 12,Loss: 1.250,Avg.Loss: 1.126,LR: 4.99E-04]Training epoch 3:   8%|▊         | 12/153 [00:00<00:02, 56.44it/s, Epoch: 3, Batch: 13,Loss: 0.992,Avg.Loss: 1.116,LR: 4.99E-04]Training epoch 3:   8%|▊         | 13/153 [00:00<00:02, 58.46it/s, Epoch: 3, Batch: 13,Loss: 0.992,Avg.Loss: 1.116,LR: 4.99E-04]Training epoch 3:   8%|▊         | 13/153 [00:00<00:02, 58.46it/s, Epoch: 3, Batch: 14,Loss: 1.105,Avg.Loss: 1.115,LR: 4.99E-04]Training epoch 3:   9%|▉         | 14/153 [00:00<00:02, 58.46it/s, Epoch: 3, Batch: 15,Loss: 1.068,Avg.Loss: 1.112,LR: 4.99E-04]Training epoch 3:  10%|▉         | 15/153 [00:00<00:02, 58.46it/s, Epoch: 3, Batch: 16,Loss: 1.122,Avg.Loss: 1.112,LR: 4.99E-04]Training epoch 3:  10%|█         | 16/153 [00:00<00:02, 58.46it/s, Epoch: 3, Batch: 17,Loss: 1.237,Avg.Loss: 1.120,LR: 4.99E-04]Training epoch 3:  11%|█         | 17/153 [00:00<00:02, 58.46it/s, Epoch: 3, Batch: 18,Loss: 1.265,Avg.Loss: 1.128,LR: 4.99E-04]Training epoch 3:  12%|█▏        | 18/153 [00:00<00:02, 58.46it/s, Epoch: 3, Batch: 19,Loss: 1.268,Avg.Loss: 1.135,LR: 4.99E-04]Training epoch 3:  12%|█▏        | 19/153 [00:00<00:02, 55.56it/s, Epoch: 3, Batch: 19,Loss: 1.268,Avg.Loss: 1.135,LR: 4.99E-04]Training epoch 3:  12%|█▏        | 19/153 [00:00<00:02, 55.56it/s, Epoch: 3, Batch: 20,Loss: 0.828,Avg.Loss: 1.120,LR: 4.99E-04]Training epoch 3:  13%|█▎        | 20/153 [00:00<00:02, 55.56it/s, Epoch: 3, Batch: 21,Loss: 1.048,Avg.Loss: 1.116,LR: 4.99E-04]Training epoch 3:  14%|█▎        | 21/153 [00:00<00:02, 55.56it/s, Epoch: 3, Batch: 22,Loss: 0.970,Avg.Loss: 1.110,LR: 4.99E-04]Training epoch 3:  14%|█▍        | 22/153 [00:00<00:02, 55.56it/s, Epoch: 3, Batch: 23,Loss: 1.546,Avg.Loss: 1.129,LR: 4.99E-04]Training epoch 3:  15%|█▌        | 23/153 [00:00<00:02, 55.56it/s, Epoch: 3, Batch: 24,Loss: 1.072,Avg.Loss: 1.126,LR: 4.99E-04]Training epoch 3:  16%|█▌        | 24/153 [00:00<00:02, 55.56it/s, Epoch: 3, Batch: 25,Loss: 0.939,Avg.Loss: 1.119,LR: 4.99E-04]Training epoch 3:  16%|█▋        | 25/153 [00:00<00:02, 54.34it/s, Epoch: 3, Batch: 25,Loss: 0.939,Avg.Loss: 1.119,LR: 4.99E-04]Training epoch 3:  16%|█▋        | 25/153 [00:00<00:02, 54.34it/s, Epoch: 3, Batch: 26,Loss: 1.131,Avg.Loss: 1.119,LR: 4.99E-04]Training epoch 3:  17%|█▋        | 26/153 [00:00<00:02, 54.34it/s, Epoch: 3, Batch: 27,Loss: 1.154,Avg.Loss: 1.121,LR: 4.99E-04]Training epoch 3:  18%|█▊        | 27/153 [00:00<00:02, 54.34it/s, Epoch: 3, Batch: 28,Loss: 1.209,Avg.Loss: 1.124,LR: 4.99E-04]Training epoch 3:  18%|█▊        | 28/153 [00:00<00:02, 54.34it/s, Epoch: 3, Batch: 29,Loss: 1.409,Avg.Loss: 1.134,LR: 4.99E-04]Training epoch 3:  19%|█▉        | 29/153 [00:00<00:02, 54.34it/s, Epoch: 3, Batch: 30,Loss: 0.961,Avg.Loss: 1.128,LR: 4.99E-04]Training epoch 3:  20%|█▉        | 30/153 [00:00<00:02, 54.34it/s, Epoch: 3, Batch: 31,Loss: 1.004,Avg.Loss: 1.124,LR: 4.99E-04]Training epoch 3:  20%|██        | 31/153 [00:00<00:02, 53.73it/s, Epoch: 3, Batch: 31,Loss: 1.004,Avg.Loss: 1.124,LR: 4.99E-04]Training epoch 3:  20%|██        | 31/153 [00:00<00:02, 53.73it/s, Epoch: 3, Batch: 32,Loss: 1.387,Avg.Loss: 1.132,LR: 4.99E-04]Training epoch 3:  21%|██        | 32/153 [00:00<00:02, 53.73it/s, Epoch: 3, Batch: 33,Loss: 1.221,Avg.Loss: 1.135,LR: 4.99E-04]Training epoch 3:  22%|██▏       | 33/153 [00:00<00:02, 53.73it/s, Epoch: 3, Batch: 34,Loss: 0.886,Avg.Loss: 1.127,LR: 4.99E-04]Training epoch 3:  22%|██▏       | 34/153 [00:00<00:02, 53.73it/s, Epoch: 3, Batch: 35,Loss: 0.903,Avg.Loss: 1.121,LR: 4.99E-04]Training epoch 3:  23%|██▎       | 35/153 [00:00<00:02, 53.73it/s, Epoch: 3, Batch: 36,Loss: 1.102,Avg.Loss: 1.120,LR: 4.99E-04]Training epoch 3:  24%|██▎       | 36/153 [00:00<00:02, 53.73it/s, Epoch: 3, Batch: 37,Loss: 1.156,Avg.Loss: 1.121,LR: 4.99E-04]Training epoch 3:  24%|██▍       | 37/153 [00:00<00:02, 53.28it/s, Epoch: 3, Batch: 37,Loss: 1.156,Avg.Loss: 1.121,LR: 4.99E-04]Training epoch 3:  24%|██▍       | 37/153 [00:00<00:02, 53.28it/s, Epoch: 3, Batch: 38,Loss: 0.945,Avg.Loss: 1.117,LR: 4.99E-04]Training epoch 3:  25%|██▍       | 38/153 [00:00<00:02, 53.28it/s, Epoch: 3, Batch: 39,Loss: 1.046,Avg.Loss: 1.115,LR: 4.99E-04]Training epoch 3:  25%|██▌       | 39/153 [00:00<00:02, 53.28it/s, Epoch: 3, Batch: 40,Loss: 0.966,Avg.Loss: 1.111,LR: 4.99E-04]Training epoch 3:  26%|██▌       | 40/153 [00:00<00:02, 53.28it/s, Epoch: 3, Batch: 41,Loss: 1.144,Avg.Loss: 1.112,LR: 4.99E-04]Training epoch 3:  27%|██▋       | 41/153 [00:00<00:02, 53.28it/s, Epoch: 3, Batch: 42,Loss: 1.130,Avg.Loss: 1.113,LR: 4.99E-04]Training epoch 3:  27%|██▋       | 42/153 [00:00<00:02, 53.28it/s, Epoch: 3, Batch: 43,Loss: 0.986,Avg.Loss: 1.110,LR: 4.99E-04]Training epoch 3:  28%|██▊       | 43/153 [00:00<00:02, 53.09it/s, Epoch: 3, Batch: 43,Loss: 0.986,Avg.Loss: 1.110,LR: 4.99E-04]Training epoch 3:  28%|██▊       | 43/153 [00:00<00:02, 53.09it/s, Epoch: 3, Batch: 44,Loss: 1.034,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 3:  29%|██▉       | 44/153 [00:00<00:02, 53.09it/s, Epoch: 3, Batch: 45,Loss: 1.004,Avg.Loss: 1.106,LR: 4.99E-04]Training epoch 3:  29%|██▉       | 45/153 [00:00<00:02, 53.09it/s, Epoch: 3, Batch: 46,Loss: 0.974,Avg.Loss: 1.103,LR: 4.99E-04]Training epoch 3:  30%|███       | 46/153 [00:00<00:02, 53.09it/s, Epoch: 3, Batch: 47,Loss: 0.863,Avg.Loss: 1.098,LR: 4.99E-04]Training epoch 3:  31%|███       | 47/153 [00:00<00:01, 53.09it/s, Epoch: 3, Batch: 48,Loss: 1.349,Avg.Loss: 1.103,LR: 4.99E-04]Training epoch 3:  31%|███▏      | 48/153 [00:00<00:01, 53.09it/s, Epoch: 3, Batch: 49,Loss: 1.194,Avg.Loss: 1.105,LR: 4.99E-04]Training epoch 3:  32%|███▏      | 49/153 [00:00<00:01, 53.23it/s, Epoch: 3, Batch: 49,Loss: 1.194,Avg.Loss: 1.105,LR: 4.99E-04]Training epoch 3:  32%|███▏      | 49/153 [00:00<00:01, 53.23it/s, Epoch: 3, Batch: 50,Loss: 1.371,Avg.Loss: 1.110,LR: 4.99E-04]Training epoch 3:  33%|███▎      | 50/153 [00:00<00:01, 53.23it/s, Epoch: 3, Batch: 51,Loss: 1.356,Avg.Loss: 1.115,LR: 4.99E-04]Training epoch 3:  33%|███▎      | 51/153 [00:00<00:01, 53.23it/s, Epoch: 3, Batch: 52,Loss: 0.870,Avg.Loss: 1.110,LR: 4.99E-04]Training epoch 3:  34%|███▍      | 52/153 [00:00<00:01, 53.23it/s, Epoch: 3, Batch: 53,Loss: 1.102,Avg.Loss: 1.110,LR: 4.99E-04]Training epoch 3:  35%|███▍      | 53/153 [00:01<00:01, 53.23it/s, Epoch: 3, Batch: 54,Loss: 1.046,Avg.Loss: 1.109,LR: 4.99E-04]Training epoch 3:  35%|███▌      | 54/153 [00:01<00:01, 53.23it/s, Epoch: 3, Batch: 55,Loss: 1.070,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 3:  36%|███▌      | 55/153 [00:01<00:01, 52.90it/s, Epoch: 3, Batch: 55,Loss: 1.070,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 3:  36%|███▌      | 55/153 [00:01<00:01, 52.90it/s, Epoch: 3, Batch: 56,Loss: 1.153,Avg.Loss: 1.109,LR: 4.99E-04]Training epoch 3:  37%|███▋      | 56/153 [00:01<00:01, 52.90it/s, Epoch: 3, Batch: 57,Loss: 1.395,Avg.Loss: 1.114,LR: 4.99E-04]Training epoch 3:  37%|███▋      | 57/153 [00:01<00:01, 52.90it/s, Epoch: 3, Batch: 58,Loss: 0.803,Avg.Loss: 1.109,LR: 4.99E-04]Training epoch 3:  38%|███▊      | 58/153 [00:01<00:01, 52.90it/s, Epoch: 3, Batch: 59,Loss: 1.363,Avg.Loss: 1.113,LR: 4.99E-04]Training epoch 3:  39%|███▊      | 59/153 [00:01<00:01, 52.90it/s, Epoch: 3, Batch: 60,Loss: 1.108,Avg.Loss: 1.113,LR: 4.99E-04]Training epoch 3:  39%|███▉      | 60/153 [00:01<00:01, 52.90it/s, Epoch: 3, Batch: 61,Loss: 1.252,Avg.Loss: 1.115,LR: 4.99E-04]Training epoch 3:  40%|███▉      | 61/153 [00:01<00:01, 52.86it/s, Epoch: 3, Batch: 61,Loss: 1.252,Avg.Loss: 1.115,LR: 4.99E-04]Training epoch 3:  40%|███▉      | 61/153 [00:01<00:01, 52.86it/s, Epoch: 3, Batch: 62,Loss: 0.939,Avg.Loss: 1.112,LR: 4.99E-04]Training epoch 3:  41%|████      | 62/153 [00:01<00:01, 52.86it/s, Epoch: 3, Batch: 63,Loss: 1.531,Avg.Loss: 1.119,LR: 4.99E-04]Training epoch 3:  41%|████      | 63/153 [00:01<00:01, 52.86it/s, Epoch: 3, Batch: 64,Loss: 1.354,Avg.Loss: 1.123,LR: 4.99E-04]Training epoch 3:  42%|████▏     | 64/153 [00:01<00:01, 52.86it/s, Epoch: 3, Batch: 65,Loss: 1.205,Avg.Loss: 1.124,LR: 4.99E-04]Training epoch 3:  42%|████▏     | 65/153 [00:01<00:01, 52.86it/s, Epoch: 3, Batch: 66,Loss: 1.354,Avg.Loss: 1.127,LR: 4.99E-04]Training epoch 3:  43%|████▎     | 66/153 [00:01<00:01, 52.86it/s, Epoch: 3, Batch: 67,Loss: 1.403,Avg.Loss: 1.131,LR: 4.99E-04]Training epoch 3:  44%|████▍     | 67/153 [00:01<00:01, 52.80it/s, Epoch: 3, Batch: 67,Loss: 1.403,Avg.Loss: 1.131,LR: 4.99E-04]Training epoch 3:  44%|████▍     | 67/153 [00:01<00:01, 52.80it/s, Epoch: 3, Batch: 68,Loss: 1.523,Avg.Loss: 1.137,LR: 4.99E-04]Training epoch 3:  44%|████▍     | 68/153 [00:01<00:01, 52.80it/s, Epoch: 3, Batch: 69,Loss: 1.354,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 3:  45%|████▌     | 69/153 [00:01<00:01, 52.80it/s, Epoch: 3, Batch: 70,Loss: 1.080,Avg.Loss: 1.139,LR: 4.99E-04]Training epoch 3:  46%|████▌     | 70/153 [00:01<00:01, 52.80it/s, Epoch: 3, Batch: 71,Loss: 1.032,Avg.Loss: 1.138,LR: 4.99E-04]Training epoch 3:  46%|████▋     | 71/153 [00:01<00:01, 52.80it/s, Epoch: 3, Batch: 72,Loss: 1.411,Avg.Loss: 1.142,LR: 4.99E-04]Training epoch 3:  47%|████▋     | 72/153 [00:01<00:01, 52.80it/s, Epoch: 3, Batch: 73,Loss: 1.009,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 3:  48%|████▊     | 73/153 [00:01<00:01, 52.94it/s, Epoch: 3, Batch: 73,Loss: 1.009,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 3:  48%|████▊     | 73/153 [00:01<00:01, 52.94it/s, Epoch: 3, Batch: 74,Loss: 1.164,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 3:  48%|████▊     | 74/153 [00:01<00:01, 52.94it/s, Epoch: 3, Batch: 75,Loss: 1.251,Avg.Loss: 1.142,LR: 4.99E-04]Training epoch 3:  49%|████▉     | 75/153 [00:01<00:01, 52.94it/s, Epoch: 3, Batch: 76,Loss: 1.024,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 3:  50%|████▉     | 76/153 [00:01<00:01, 52.94it/s, Epoch: 3, Batch: 77,Loss: 1.220,Avg.Loss: 1.141,LR: 4.99E-04]Training epoch 3:  50%|█████     | 77/153 [00:01<00:01, 52.94it/s, Epoch: 3, Batch: 78,Loss: 1.036,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 3:  51%|█████     | 78/153 [00:01<00:01, 52.94it/s, Epoch: 3, Batch: 79,Loss: 1.169,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 3:  52%|█████▏    | 79/153 [00:01<00:01, 52.91it/s, Epoch: 3, Batch: 79,Loss: 1.169,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 3:  52%|█████▏    | 79/153 [00:01<00:01, 52.91it/s, Epoch: 3, Batch: 80,Loss: 1.216,Avg.Loss: 1.141,LR: 4.99E-04]Training epoch 3:  52%|█████▏    | 80/153 [00:01<00:01, 52.91it/s, Epoch: 3, Batch: 81,Loss: 1.363,Avg.Loss: 1.144,LR: 4.99E-04]Training epoch 3:  53%|█████▎    | 81/153 [00:01<00:01, 52.91it/s, Epoch: 3, Batch: 82,Loss: 1.255,Avg.Loss: 1.145,LR: 4.99E-04]Training epoch 3:  54%|█████▎    | 82/153 [00:01<00:01, 52.91it/s, Epoch: 3, Batch: 83,Loss: 0.845,Avg.Loss: 1.142,LR: 4.99E-04]Training epoch 3:  54%|█████▍    | 83/153 [00:01<00:01, 52.91it/s, Epoch: 3, Batch: 84,Loss: 0.757,Avg.Loss: 1.137,LR: 4.99E-04]Training epoch 3:  55%|█████▍    | 84/153 [00:01<00:01, 52.91it/s, Epoch: 3, Batch: 85,Loss: 0.993,Avg.Loss: 1.135,LR: 4.99E-04]Training epoch 3:  56%|█████▌    | 85/153 [00:01<00:01, 52.61it/s, Epoch: 3, Batch: 85,Loss: 0.993,Avg.Loss: 1.135,LR: 4.99E-04]Training epoch 3:  56%|█████▌    | 85/153 [00:01<00:01, 52.61it/s, Epoch: 3, Batch: 86,Loss: 1.355,Avg.Loss: 1.138,LR: 4.99E-04]Training epoch 3:  56%|█████▌    | 86/153 [00:01<00:01, 52.61it/s, Epoch: 3, Batch: 87,Loss: 1.097,Avg.Loss: 1.137,LR: 4.99E-04]Training epoch 3:  57%|█████▋    | 87/153 [00:01<00:01, 52.61it/s, Epoch: 3, Batch: 88,Loss: 1.110,Avg.Loss: 1.137,LR: 4.99E-04]Training epoch 3:  58%|█████▊    | 88/153 [00:01<00:01, 52.61it/s, Epoch: 3, Batch: 89,Loss: 0.875,Avg.Loss: 1.134,LR: 4.99E-04]Training epoch 3:  58%|█████▊    | 89/153 [00:01<00:01, 52.61it/s, Epoch: 3, Batch: 90,Loss: 1.016,Avg.Loss: 1.133,LR: 4.99E-04]Training epoch 3:  59%|█████▉    | 90/153 [00:01<00:01, 52.61it/s, Epoch: 3, Batch: 91,Loss: 0.585,Avg.Loss: 1.127,LR: 4.99E-04]Training epoch 3:  59%|█████▉    | 91/153 [00:01<00:01, 52.77it/s, Epoch: 3, Batch: 91,Loss: 0.585,Avg.Loss: 1.127,LR: 4.99E-04]Training epoch 3:  59%|█████▉    | 91/153 [00:01<00:01, 52.77it/s, Epoch: 3, Batch: 92,Loss: 0.969,Avg.Loss: 1.125,LR: 4.99E-04]Training epoch 3:  60%|██████    | 92/153 [00:01<00:01, 52.77it/s, Epoch: 3, Batch: 93,Loss: 1.282,Avg.Loss: 1.127,LR: 4.99E-04]Training epoch 3:  61%|██████    | 93/153 [00:01<00:01, 52.77it/s, Epoch: 3, Batch: 94,Loss: 0.915,Avg.Loss: 1.125,LR: 4.99E-04]Training epoch 3:  61%|██████▏   | 94/153 [00:01<00:01, 52.77it/s, Epoch: 3, Batch: 95,Loss: 0.854,Avg.Loss: 1.122,LR: 4.99E-04]Training epoch 3:  62%|██████▏   | 95/153 [00:01<00:01, 52.77it/s, Epoch: 3, Batch: 96,Loss: 1.094,Avg.Loss: 1.121,LR: 4.99E-04]Training epoch 3:  63%|██████▎   | 96/153 [00:01<00:01, 52.77it/s, Epoch: 3, Batch: 97,Loss: 1.149,Avg.Loss: 1.122,LR: 4.99E-04]Training epoch 3:  63%|██████▎   | 97/153 [00:01<00:01, 52.69it/s, Epoch: 3, Batch: 97,Loss: 1.149,Avg.Loss: 1.122,LR: 4.99E-04]Training epoch 3:  63%|██████▎   | 97/153 [00:01<00:01, 52.69it/s, Epoch: 3, Batch: 98,Loss: 1.079,Avg.Loss: 1.121,LR: 4.99E-04]Training epoch 3:  64%|██████▍   | 98/153 [00:01<00:01, 52.69it/s, Epoch: 3, Batch: 99,Loss: 1.107,Avg.Loss: 1.121,LR: 4.99E-04]Training epoch 3:  65%|██████▍   | 99/153 [00:01<00:01, 52.69it/s, Epoch: 3, Batch: 100,Loss: 0.999,Avg.Loss: 1.120,LR: 4.99E-04]Training epoch 3:  65%|██████▌   | 100/153 [00:01<00:01, 52.69it/s, Epoch: 3, Batch: 101,Loss: 1.116,Avg.Loss: 1.120,LR: 4.99E-04]Training epoch 3:  66%|██████▌   | 101/153 [00:01<00:00, 52.69it/s, Epoch: 3, Batch: 102,Loss: 0.996,Avg.Loss: 1.119,LR: 4.99E-04]Training epoch 3:  67%|██████▋   | 102/153 [00:01<00:00, 52.69it/s, Epoch: 3, Batch: 103,Loss: 1.163,Avg.Loss: 1.119,LR: 4.99E-04]Training epoch 3:  67%|██████▋   | 103/153 [00:01<00:00, 52.73it/s, Epoch: 3, Batch: 103,Loss: 1.163,Avg.Loss: 1.119,LR: 4.99E-04]Training epoch 3:  67%|██████▋   | 103/153 [00:01<00:00, 52.73it/s, Epoch: 3, Batch: 104,Loss: 1.191,Avg.Loss: 1.120,LR: 4.99E-04]Training epoch 3:  68%|██████▊   | 104/153 [00:01<00:00, 52.73it/s, Epoch: 3, Batch: 105,Loss: 0.915,Avg.Loss: 1.118,LR: 4.99E-04]Training epoch 3:  69%|██████▊   | 105/153 [00:01<00:00, 52.73it/s, Epoch: 3, Batch: 106,Loss: 0.904,Avg.Loss: 1.116,LR: 4.99E-04]Training epoch 3:  69%|██████▉   | 106/153 [00:02<00:00, 52.73it/s, Epoch: 3, Batch: 107,Loss: 1.232,Avg.Loss: 1.117,LR: 4.99E-04]Training epoch 3:  70%|██████▉   | 107/153 [00:02<00:00, 52.73it/s, Epoch: 3, Batch: 108,Loss: 0.916,Avg.Loss: 1.115,LR: 4.99E-04]Training epoch 3:  71%|███████   | 108/153 [00:02<00:00, 52.73it/s, Epoch: 3, Batch: 109,Loss: 0.905,Avg.Loss: 1.113,LR: 4.99E-04]Training epoch 3:  71%|███████   | 109/153 [00:02<00:00, 52.81it/s, Epoch: 3, Batch: 109,Loss: 0.905,Avg.Loss: 1.113,LR: 4.99E-04]Training epoch 3:  71%|███████   | 109/153 [00:02<00:00, 52.81it/s, Epoch: 3, Batch: 110,Loss: 0.855,Avg.Loss: 1.111,LR: 4.99E-04]Training epoch 3:  72%|███████▏  | 110/153 [00:02<00:00, 52.81it/s, Epoch: 3, Batch: 111,Loss: 0.893,Avg.Loss: 1.109,LR: 4.99E-04]Training epoch 3:  73%|███████▎  | 111/153 [00:02<00:00, 52.81it/s, Epoch: 3, Batch: 112,Loss: 1.005,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 3:  73%|███████▎  | 112/153 [00:02<00:00, 52.81it/s, Epoch: 3, Batch: 113,Loss: 0.849,Avg.Loss: 1.106,LR: 4.99E-04]Training epoch 3:  74%|███████▍  | 113/153 [00:02<00:00, 52.81it/s, Epoch: 3, Batch: 114,Loss: 0.815,Avg.Loss: 1.103,LR: 4.99E-04]Training epoch 3:  75%|███████▍  | 114/153 [00:02<00:00, 52.81it/s, Epoch: 3, Batch: 115,Loss: 1.014,Avg.Loss: 1.102,LR: 4.99E-04]Training epoch 3:  75%|███████▌  | 115/153 [00:02<00:00, 53.07it/s, Epoch: 3, Batch: 115,Loss: 1.014,Avg.Loss: 1.102,LR: 4.99E-04]Training epoch 3:  75%|███████▌  | 115/153 [00:02<00:00, 53.07it/s, Epoch: 3, Batch: 116,Loss: 1.363,Avg.Loss: 1.104,LR: 4.99E-04]Training epoch 3:  76%|███████▌  | 116/153 [00:02<00:00, 53.07it/s, Epoch: 3, Batch: 117,Loss: 0.989,Avg.Loss: 1.103,LR: 4.99E-04]Training epoch 3:  76%|███████▋  | 117/153 [00:02<00:00, 53.07it/s, Epoch: 3, Batch: 118,Loss: 1.148,Avg.Loss: 1.104,LR: 4.99E-04]Training epoch 3:  77%|███████▋  | 118/153 [00:02<00:00, 53.07it/s, Epoch: 3, Batch: 119,Loss: 0.952,Avg.Loss: 1.103,LR: 4.99E-04]Training epoch 3:  78%|███████▊  | 119/153 [00:02<00:00, 53.07it/s, Epoch: 3, Batch: 120,Loss: 1.372,Avg.Loss: 1.105,LR: 4.99E-04]Training epoch 3:  78%|███████▊  | 120/153 [00:02<00:00, 53.07it/s, Epoch: 3, Batch: 121,Loss: 1.486,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 3:  79%|███████▉  | 121/153 [00:02<00:00, 52.80it/s, Epoch: 3, Batch: 121,Loss: 1.486,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 3:  79%|███████▉  | 121/153 [00:02<00:00, 52.80it/s, Epoch: 3, Batch: 122,Loss: 0.874,Avg.Loss: 1.106,LR: 4.99E-04]Training epoch 3:  80%|███████▉  | 122/153 [00:02<00:00, 52.80it/s, Epoch: 3, Batch: 123,Loss: 0.925,Avg.Loss: 1.105,LR: 4.99E-04]Training epoch 3:  80%|████████  | 123/153 [00:02<00:00, 52.80it/s, Epoch: 3, Batch: 124,Loss: 0.873,Avg.Loss: 1.103,LR: 4.99E-04]Training epoch 3:  81%|████████  | 124/153 [00:02<00:00, 52.80it/s, Epoch: 3, Batch: 125,Loss: 1.011,Avg.Loss: 1.102,LR: 4.99E-04]Training epoch 3:  82%|████████▏ | 125/153 [00:02<00:00, 52.80it/s, Epoch: 3, Batch: 126,Loss: 1.658,Avg.Loss: 1.106,LR: 4.99E-04]Training epoch 3:  82%|████████▏ | 126/153 [00:02<00:00, 52.80it/s, Epoch: 3, Batch: 127,Loss: 1.069,Avg.Loss: 1.106,LR: 4.99E-04]Training epoch 3:  83%|████████▎ | 127/153 [00:02<00:00, 53.01it/s, Epoch: 3, Batch: 127,Loss: 1.069,Avg.Loss: 1.106,LR: 4.99E-04]Training epoch 3:  83%|████████▎ | 127/153 [00:02<00:00, 53.01it/s, Epoch: 3, Batch: 128,Loss: 1.350,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 3:  84%|████████▎ | 128/153 [00:02<00:00, 53.01it/s, Epoch: 3, Batch: 129,Loss: 0.742,Avg.Loss: 1.105,LR: 4.99E-04]Training epoch 3:  84%|████████▍ | 129/153 [00:02<00:00, 53.01it/s, Epoch: 3, Batch: 130,Loss: 1.004,Avg.Loss: 1.104,LR: 4.99E-04]Training epoch 3:  85%|████████▍ | 130/153 [00:02<00:00, 53.01it/s, Epoch: 3, Batch: 131,Loss: 1.252,Avg.Loss: 1.106,LR: 4.99E-04]Training epoch 3:  86%|████████▌ | 131/153 [00:02<00:00, 53.01it/s, Epoch: 3, Batch: 132,Loss: 1.000,Avg.Loss: 1.105,LR: 4.99E-04]Training epoch 3:  86%|████████▋ | 132/153 [00:02<00:00, 53.01it/s, Epoch: 3, Batch: 133,Loss: 0.860,Avg.Loss: 1.103,LR: 4.99E-04]Training epoch 3:  87%|████████▋ | 133/153 [00:02<00:00, 53.05it/s, Epoch: 3, Batch: 133,Loss: 0.860,Avg.Loss: 1.103,LR: 4.99E-04]Training epoch 3:  87%|████████▋ | 133/153 [00:02<00:00, 53.05it/s, Epoch: 3, Batch: 134,Loss: 0.807,Avg.Loss: 1.101,LR: 4.99E-04]Training epoch 3:  88%|████████▊ | 134/153 [00:02<00:00, 53.05it/s, Epoch: 3, Batch: 135,Loss: 1.104,Avg.Loss: 1.101,LR: 4.99E-04]Training epoch 3:  88%|████████▊ | 135/153 [00:02<00:00, 53.05it/s, Epoch: 3, Batch: 136,Loss: 0.813,Avg.Loss: 1.099,LR: 4.99E-04]Training epoch 3:  89%|████████▉ | 136/153 [00:02<00:00, 53.05it/s, Epoch: 3, Batch: 137,Loss: 1.344,Avg.Loss: 1.100,LR: 4.99E-04]Training epoch 3:  90%|████████▉ | 137/153 [00:02<00:00, 53.05it/s, Epoch: 3, Batch: 138,Loss: 0.582,Avg.Loss: 1.097,LR: 4.99E-04]Training epoch 3:  90%|█████████ | 138/153 [00:02<00:00, 53.05it/s, Epoch: 3, Batch: 139,Loss: 1.156,Avg.Loss: 1.097,LR: 4.99E-04]Training epoch 3:  91%|█████████ | 139/153 [00:02<00:00, 53.18it/s, Epoch: 3, Batch: 139,Loss: 1.156,Avg.Loss: 1.097,LR: 4.99E-04]Training epoch 3:  91%|█████████ | 139/153 [00:02<00:00, 53.18it/s, Epoch: 3, Batch: 140,Loss: 0.896,Avg.Loss: 1.096,LR: 4.99E-04]Training epoch 3:  92%|█████████▏| 140/153 [00:02<00:00, 53.18it/s, Epoch: 3, Batch: 141,Loss: 1.178,Avg.Loss: 1.096,LR: 4.99E-04]Training epoch 3:  92%|█████████▏| 141/153 [00:02<00:00, 53.18it/s, Epoch: 3, Batch: 142,Loss: 0.805,Avg.Loss: 1.094,LR: 4.99E-04]Training epoch 3:  93%|█████████▎| 142/153 [00:02<00:00, 53.18it/s, Epoch: 3, Batch: 143,Loss: 1.130,Avg.Loss: 1.094,LR: 4.99E-04]Training epoch 3:  93%|█████████▎| 143/153 [00:02<00:00, 53.18it/s, Epoch: 3, Batch: 144,Loss: 0.995,Avg.Loss: 1.094,LR: 4.99E-04]Training epoch 3:  94%|█████████▍| 144/153 [00:02<00:00, 53.18it/s, Epoch: 3, Batch: 145,Loss: 1.038,Avg.Loss: 1.093,LR: 4.99E-04]Training epoch 3:  95%|█████████▍| 145/153 [00:02<00:00, 53.48it/s, Epoch: 3, Batch: 145,Loss: 1.038,Avg.Loss: 1.093,LR: 4.99E-04]Training epoch 3:  95%|█████████▍| 145/153 [00:02<00:00, 53.48it/s, Epoch: 3, Batch: 146,Loss: 1.125,Avg.Loss: 1.094,LR: 4.99E-04]Training epoch 3:  95%|█████████▌| 146/153 [00:02<00:00, 53.48it/s, Epoch: 3, Batch: 147,Loss: 0.750,Avg.Loss: 1.091,LR: 4.99E-04]Training epoch 3:  96%|█████████▌| 147/153 [00:02<00:00, 53.48it/s, Epoch: 3, Batch: 148,Loss: 1.153,Avg.Loss: 1.092,LR: 4.99E-04]Training epoch 3:  97%|█████████▋| 148/153 [00:02<00:00, 53.48it/s, Epoch: 3, Batch: 149,Loss: 1.324,Avg.Loss: 1.093,LR: 4.99E-04]Training epoch 3:  97%|█████████▋| 149/153 [00:02<00:00, 53.48it/s, Epoch: 3, Batch: 150,Loss: 0.950,Avg.Loss: 1.092,LR: 4.99E-04]Training epoch 3:  98%|█████████▊| 150/153 [00:02<00:00, 53.48it/s, Epoch: 3, Batch: 151,Loss: 1.039,Avg.Loss: 1.092,LR: 4.99E-04]Training epoch 3:  99%|█████████▊| 151/153 [00:02<00:00, 53.14it/s, Epoch: 3, Batch: 151,Loss: 1.039,Avg.Loss: 1.092,LR: 4.99E-04]Training epoch 3:  99%|█████████▊| 151/153 [00:02<00:00, 53.14it/s, Epoch: 3, Batch: 152,Loss: 0.849,Avg.Loss: 1.090,LR: 4.99E-04]Training epoch 3:  99%|█████████▉| 152/153 [00:02<00:00, 53.14it/s, Epoch: 3, Batch: 153,Loss: 1.187,Avg.Loss: 1.091,LR: 4.99E-04]Training epoch 3: 100%|██████████| 153/153 [00:02<00:00, 53.20it/s, Epoch: 3, Batch: 153,Loss: 1.187,Avg.Loss: 1.091,LR: 4.99E-04]
Training epoch 4:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 4:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 4, Batch: 1,Loss: 1.158,Avg.Loss: 1.158,LR: 4.99E-04]Training epoch 4:   1%|          | 1/153 [00:00<00:05, 26.21it/s, Epoch: 4, Batch: 2,Loss: 1.224,Avg.Loss: 1.191,LR: 4.99E-04]Training epoch 4:   1%|▏         | 2/153 [00:00<00:04, 37.55it/s, Epoch: 4, Batch: 3,Loss: 1.184,Avg.Loss: 1.189,LR: 4.99E-04]Training epoch 4:   2%|▏         | 3/153 [00:00<00:03, 43.61it/s, Epoch: 4, Batch: 4,Loss: 1.213,Avg.Loss: 1.195,LR: 4.99E-04]Training epoch 4:   3%|▎         | 4/153 [00:00<00:03, 48.45it/s, Epoch: 4, Batch: 5,Loss: 0.880,Avg.Loss: 1.132,LR: 4.99E-04]Training epoch 4:   3%|▎         | 5/153 [00:00<00:02, 51.07it/s, Epoch: 4, Batch: 6,Loss: 1.191,Avg.Loss: 1.142,LR: 4.99E-04]Training epoch 4:   4%|▍         | 6/153 [00:00<00:02, 53.19it/s, Epoch: 4, Batch: 7,Loss: 1.363,Avg.Loss: 1.173,LR: 4.99E-04]Training epoch 4:   5%|▍         | 7/153 [00:00<00:02, 61.96it/s, Epoch: 4, Batch: 7,Loss: 1.363,Avg.Loss: 1.173,LR: 4.99E-04]Training epoch 4:   5%|▍         | 7/153 [00:00<00:02, 61.96it/s, Epoch: 4, Batch: 8,Loss: 0.719,Avg.Loss: 1.116,LR: 4.99E-04]Training epoch 4:   5%|▌         | 8/153 [00:00<00:02, 61.96it/s, Epoch: 4, Batch: 9,Loss: 1.027,Avg.Loss: 1.106,LR: 4.99E-04]Training epoch 4:   6%|▌         | 9/153 [00:00<00:02, 61.96it/s, Epoch: 4, Batch: 10,Loss: 1.197,Avg.Loss: 1.116,LR: 4.99E-04]Training epoch 4:   7%|▋         | 10/153 [00:00<00:02, 61.96it/s, Epoch: 4, Batch: 11,Loss: 1.062,Avg.Loss: 1.111,LR: 4.99E-04]Training epoch 4:   7%|▋         | 11/153 [00:00<00:02, 61.96it/s, Epoch: 4, Batch: 12,Loss: 1.252,Avg.Loss: 1.122,LR: 4.99E-04]Training epoch 4:   8%|▊         | 12/153 [00:00<00:02, 61.96it/s, Epoch: 4, Batch: 13,Loss: 1.321,Avg.Loss: 1.138,LR: 4.99E-04]Training epoch 4:   8%|▊         | 13/153 [00:00<00:02, 61.96it/s, Epoch: 4, Batch: 14,Loss: 1.350,Avg.Loss: 1.153,LR: 4.99E-04]Training epoch 4:   9%|▉         | 14/153 [00:00<00:02, 62.26it/s, Epoch: 4, Batch: 14,Loss: 1.350,Avg.Loss: 1.153,LR: 4.99E-04]Training epoch 4:   9%|▉         | 14/153 [00:00<00:02, 62.26it/s, Epoch: 4, Batch: 15,Loss: 1.250,Avg.Loss: 1.159,LR: 4.99E-04]Training epoch 4:  10%|▉         | 15/153 [00:00<00:02, 62.26it/s, Epoch: 4, Batch: 16,Loss: 1.015,Avg.Loss: 1.150,LR: 4.99E-04]Training epoch 4:  10%|█         | 16/153 [00:00<00:02, 62.26it/s, Epoch: 4, Batch: 17,Loss: 0.795,Avg.Loss: 1.129,LR: 4.99E-04]Training epoch 4:  11%|█         | 17/153 [00:00<00:02, 62.26it/s, Epoch: 4, Batch: 18,Loss: 1.327,Avg.Loss: 1.140,LR: 4.99E-04]Training epoch 4:  12%|█▏        | 18/153 [00:00<00:02, 62.26it/s, Epoch: 4, Batch: 19,Loss: 0.974,Avg.Loss: 1.132,LR: 4.99E-04]Training epoch 4:  12%|█▏        | 19/153 [00:00<00:02, 62.26it/s, Epoch: 4, Batch: 20,Loss: 0.848,Avg.Loss: 1.118,LR: 4.99E-04]Training epoch 4:  13%|█▎        | 20/153 [00:00<00:02, 62.26it/s, Epoch: 4, Batch: 21,Loss: 1.096,Avg.Loss: 1.116,LR: 4.99E-04]Training epoch 4:  14%|█▎        | 21/153 [00:00<00:02, 57.11it/s, Epoch: 4, Batch: 21,Loss: 1.096,Avg.Loss: 1.116,LR: 4.99E-04]Training epoch 4:  14%|█▎        | 21/153 [00:00<00:02, 57.11it/s, Epoch: 4, Batch: 22,Loss: 1.345,Avg.Loss: 1.127,LR: 4.99E-04]Training epoch 4:  14%|█▍        | 22/153 [00:00<00:02, 57.11it/s, Epoch: 4, Batch: 23,Loss: 1.313,Avg.Loss: 1.135,LR: 4.99E-04]Training epoch 4:  15%|█▌        | 23/153 [00:00<00:02, 57.11it/s, Epoch: 4, Batch: 24,Loss: 1.189,Avg.Loss: 1.137,LR: 4.99E-04]Training epoch 4:  16%|█▌        | 24/153 [00:00<00:02, 57.11it/s, Epoch: 4, Batch: 25,Loss: 1.125,Avg.Loss: 1.137,LR: 4.99E-04]Training epoch 4:  16%|█▋        | 25/153 [00:00<00:02, 57.11it/s, Epoch: 4, Batch: 26,Loss: 1.115,Avg.Loss: 1.136,LR: 4.99E-04]Training epoch 4:  17%|█▋        | 26/153 [00:00<00:02, 57.11it/s, Epoch: 4, Batch: 27,Loss: 1.063,Avg.Loss: 1.133,LR: 4.99E-04]Training epoch 4:  18%|█▊        | 27/153 [00:00<00:02, 53.22it/s, Epoch: 4, Batch: 27,Loss: 1.063,Avg.Loss: 1.133,LR: 4.99E-04]Training epoch 4:  18%|█▊        | 27/153 [00:00<00:02, 53.22it/s, Epoch: 4, Batch: 28,Loss: 1.421,Avg.Loss: 1.143,LR: 4.99E-04]Training epoch 4:  18%|█▊        | 28/153 [00:00<00:02, 53.22it/s, Epoch: 4, Batch: 29,Loss: 1.634,Avg.Loss: 1.160,LR: 4.99E-04]Training epoch 4:  19%|█▉        | 29/153 [00:00<00:02, 53.22it/s, Epoch: 4, Batch: 30,Loss: 1.057,Avg.Loss: 1.157,LR: 4.99E-04]Training epoch 4:  20%|█▉        | 30/153 [00:00<00:02, 53.22it/s, Epoch: 4, Batch: 31,Loss: 0.842,Avg.Loss: 1.147,LR: 4.99E-04]Training epoch 4:  20%|██        | 31/153 [00:00<00:02, 53.22it/s, Epoch: 4, Batch: 32,Loss: 0.747,Avg.Loss: 1.134,LR: 4.99E-04]Training epoch 4:  21%|██        | 32/153 [00:00<00:02, 53.22it/s, Epoch: 4, Batch: 33,Loss: 0.994,Avg.Loss: 1.130,LR: 4.99E-04]Training epoch 4:  22%|██▏       | 33/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 33,Loss: 0.994,Avg.Loss: 1.130,LR: 4.99E-04]Training epoch 4:  22%|██▏       | 33/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 34,Loss: 0.898,Avg.Loss: 1.123,LR: 4.99E-04]Training epoch 4:  22%|██▏       | 34/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 35,Loss: 0.851,Avg.Loss: 1.115,LR: 4.99E-04]Training epoch 4:  23%|██▎       | 35/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 36,Loss: 0.878,Avg.Loss: 1.109,LR: 4.99E-04]Training epoch 4:  24%|██▎       | 36/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 37,Loss: 1.089,Avg.Loss: 1.108,LR: 4.99E-04]Training epoch 4:  24%|██▍       | 37/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 38,Loss: 1.053,Avg.Loss: 1.107,LR: 4.99E-04]Training epoch 4:  25%|██▍       | 38/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 39,Loss: 0.995,Avg.Loss: 1.104,LR: 4.99E-04]Training epoch 4:  25%|██▌       | 39/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 39,Loss: 0.995,Avg.Loss: 1.104,LR: 4.99E-04]Training epoch 4:  25%|██▌       | 39/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 40,Loss: 1.024,Avg.Loss: 1.102,LR: 4.99E-04]Training epoch 4:  26%|██▌       | 40/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 41,Loss: 0.829,Avg.Loss: 1.095,LR: 4.99E-04]Training epoch 4:  27%|██▋       | 41/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 42,Loss: 1.192,Avg.Loss: 1.098,LR: 4.99E-04]Training epoch 4:  27%|██▋       | 42/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 43,Loss: 0.976,Avg.Loss: 1.095,LR: 4.99E-04]Training epoch 4:  28%|██▊       | 43/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 44,Loss: 1.006,Avg.Loss: 1.093,LR: 4.99E-04]Training epoch 4:  29%|██▉       | 44/153 [00:00<00:02, 53.13it/s, Epoch: 4, Batch: 45,Loss: 1.176,Avg.Loss: 1.095,LR: 4.99E-04]Training epoch 4:  29%|██▉       | 45/153 [00:00<00:02, 53.04it/s, Epoch: 4, Batch: 45,Loss: 1.176,Avg.Loss: 1.095,LR: 4.99E-04]Training epoch 4:  29%|██▉       | 45/153 [00:00<00:02, 53.04it/s, Epoch: 4, Batch: 46,Loss: 1.031,Avg.Loss: 1.093,LR: 4.99E-04]Training epoch 4:  30%|███       | 46/153 [00:00<00:02, 53.04it/s, Epoch: 4, Batch: 47,Loss: 1.110,Avg.Loss: 1.094,LR: 4.99E-04]Training epoch 4:  31%|███       | 47/153 [00:00<00:01, 53.04it/s, Epoch: 4, Batch: 48,Loss: 0.925,Avg.Loss: 1.090,LR: 4.99E-04]Training epoch 4:  31%|███▏      | 48/153 [00:00<00:01, 53.04it/s, Epoch: 4, Batch: 49,Loss: 1.194,Avg.Loss: 1.092,LR: 4.99E-04]Training epoch 4:  32%|███▏      | 49/153 [00:00<00:01, 53.04it/s, Epoch: 4, Batch: 50,Loss: 0.760,Avg.Loss: 1.086,LR: 4.99E-04]Training epoch 4:  33%|███▎      | 50/153 [00:00<00:01, 53.04it/s, Epoch: 4, Batch: 51,Loss: 0.836,Avg.Loss: 1.081,LR: 4.99E-04]Training epoch 4:  33%|███▎      | 51/153 [00:00<00:01, 53.09it/s, Epoch: 4, Batch: 51,Loss: 0.836,Avg.Loss: 1.081,LR: 4.99E-04]Training epoch 4:  33%|███▎      | 51/153 [00:00<00:01, 53.09it/s, Epoch: 4, Batch: 52,Loss: 1.172,Avg.Loss: 1.082,LR: 4.99E-04]Training epoch 4:  34%|███▍      | 52/153 [00:00<00:01, 53.09it/s, Epoch: 4, Batch: 53,Loss: 0.788,Avg.Loss: 1.077,LR: 4.99E-04]Training epoch 4:  35%|███▍      | 53/153 [00:00<00:01, 53.09it/s, Epoch: 4, Batch: 54,Loss: 0.994,Avg.Loss: 1.075,LR: 4.99E-04]Training epoch 4:  35%|███▌      | 54/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 55,Loss: 0.818,Avg.Loss: 1.071,LR: 4.99E-04]Training epoch 4:  36%|███▌      | 55/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 56,Loss: 1.276,Avg.Loss: 1.074,LR: 4.99E-04]Training epoch 4:  37%|███▋      | 56/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 57,Loss: 0.818,Avg.Loss: 1.070,LR: 4.99E-04]Training epoch 4:  37%|███▋      | 57/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 57,Loss: 0.818,Avg.Loss: 1.070,LR: 4.99E-04]Training epoch 4:  37%|███▋      | 57/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 58,Loss: 0.881,Avg.Loss: 1.067,LR: 4.99E-04]Training epoch 4:  38%|███▊      | 58/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 59,Loss: 1.120,Avg.Loss: 1.067,LR: 4.99E-04]Training epoch 4:  39%|███▊      | 59/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 60,Loss: 1.240,Avg.Loss: 1.070,LR: 4.99E-04]Training epoch 4:  39%|███▉      | 60/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 61,Loss: 0.870,Avg.Loss: 1.067,LR: 4.99E-04]Training epoch 4:  40%|███▉      | 61/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 62,Loss: 0.792,Avg.Loss: 1.063,LR: 4.99E-04]Training epoch 4:  41%|████      | 62/153 [00:01<00:01, 53.09it/s, Epoch: 4, Batch: 63,Loss: 1.141,Avg.Loss: 1.064,LR: 4.99E-04]Training epoch 4:  41%|████      | 63/153 [00:01<00:01, 53.53it/s, Epoch: 4, Batch: 63,Loss: 1.141,Avg.Loss: 1.064,LR: 4.99E-04]Training epoch 4:  41%|████      | 63/153 [00:01<00:01, 53.53it/s, Epoch: 4, Batch: 64,Loss: 1.194,Avg.Loss: 1.066,LR: 4.99E-04]Training epoch 4:  42%|████▏     | 64/153 [00:01<00:01, 53.53it/s, Epoch: 4, Batch: 65,Loss: 1.319,Avg.Loss: 1.070,LR: 4.99E-04]Training epoch 4:  42%|████▏     | 65/153 [00:01<00:01, 53.53it/s, Epoch: 4, Batch: 66,Loss: 1.229,Avg.Loss: 1.072,LR: 4.99E-04]Training epoch 4:  43%|████▎     | 66/153 [00:01<00:01, 53.53it/s, Epoch: 4, Batch: 67,Loss: 0.929,Avg.Loss: 1.070,LR: 4.99E-04]Training epoch 4:  44%|████▍     | 67/153 [00:01<00:01, 53.53it/s, Epoch: 4, Batch: 68,Loss: 0.995,Avg.Loss: 1.069,LR: 4.99E-04]Training epoch 4:  44%|████▍     | 68/153 [00:01<00:01, 53.53it/s, Epoch: 4, Batch: 69,Loss: 0.880,Avg.Loss: 1.066,LR: 4.99E-04]Training epoch 4:  45%|████▌     | 69/153 [00:01<00:01, 53.26it/s, Epoch: 4, Batch: 69,Loss: 0.880,Avg.Loss: 1.066,LR: 4.99E-04]Training epoch 4:  45%|████▌     | 69/153 [00:01<00:01, 53.26it/s, Epoch: 4, Batch: 70,Loss: 0.849,Avg.Loss: 1.063,LR: 4.99E-04]Training epoch 4:  46%|████▌     | 70/153 [00:01<00:01, 53.26it/s, Epoch: 4, Batch: 71,Loss: 1.104,Avg.Loss: 1.064,LR: 4.99E-04]Training epoch 4:  46%|████▋     | 71/153 [00:01<00:01, 53.26it/s, Epoch: 4, Batch: 72,Loss: 0.994,Avg.Loss: 1.063,LR: 4.99E-04]Training epoch 4:  47%|████▋     | 72/153 [00:01<00:01, 53.26it/s, Epoch: 4, Batch: 73,Loss: 0.961,Avg.Loss: 1.061,LR: 4.99E-04]Training epoch 4:  48%|████▊     | 73/153 [00:01<00:01, 53.26it/s, Epoch: 4, Batch: 74,Loss: 1.093,Avg.Loss: 1.062,LR: 4.99E-04]Training epoch 4:  48%|████▊     | 74/153 [00:01<00:01, 53.26it/s, Epoch: 4, Batch: 75,Loss: 1.261,Avg.Loss: 1.064,LR: 4.98E-04]Training epoch 4:  49%|████▉     | 75/153 [00:01<00:01, 52.12it/s, Epoch: 4, Batch: 75,Loss: 1.261,Avg.Loss: 1.064,LR: 4.98E-04]Training epoch 4:  49%|████▉     | 75/153 [00:01<00:01, 52.12it/s, Epoch: 4, Batch: 76,Loss: 0.912,Avg.Loss: 1.062,LR: 4.98E-04]Training epoch 4:  50%|████▉     | 76/153 [00:01<00:01, 52.12it/s, Epoch: 4, Batch: 77,Loss: 1.200,Avg.Loss: 1.064,LR: 4.98E-04]Training epoch 4:  50%|█████     | 77/153 [00:01<00:01, 52.12it/s, Epoch: 4, Batch: 78,Loss: 0.898,Avg.Loss: 1.062,LR: 4.98E-04]Training epoch 4:  51%|█████     | 78/153 [00:01<00:01, 52.12it/s, Epoch: 4, Batch: 79,Loss: 0.786,Avg.Loss: 1.059,LR: 4.98E-04]Training epoch 4:  52%|█████▏    | 79/153 [00:01<00:01, 52.12it/s, Epoch: 4, Batch: 80,Loss: 0.884,Avg.Loss: 1.056,LR: 4.98E-04]Training epoch 4:  52%|█████▏    | 80/153 [00:01<00:01, 52.12it/s, Epoch: 4, Batch: 81,Loss: 0.766,Avg.Loss: 1.053,LR: 4.98E-04]Training epoch 4:  53%|█████▎    | 81/153 [00:01<00:01, 52.27it/s, Epoch: 4, Batch: 81,Loss: 0.766,Avg.Loss: 1.053,LR: 4.98E-04]Training epoch 4:  53%|█████▎    | 81/153 [00:01<00:01, 52.27it/s, Epoch: 4, Batch: 82,Loss: 0.827,Avg.Loss: 1.050,LR: 4.98E-04]Training epoch 4:  54%|█████▎    | 82/153 [00:01<00:01, 52.27it/s, Epoch: 4, Batch: 83,Loss: 0.777,Avg.Loss: 1.047,LR: 4.98E-04]Training epoch 4:  54%|█████▍    | 83/153 [00:01<00:01, 52.27it/s, Epoch: 4, Batch: 84,Loss: 0.997,Avg.Loss: 1.046,LR: 4.98E-04]Training epoch 4:  55%|█████▍    | 84/153 [00:01<00:01, 52.27it/s, Epoch: 4, Batch: 85,Loss: 1.036,Avg.Loss: 1.046,LR: 4.98E-04]Training epoch 4:  56%|█████▌    | 85/153 [00:01<00:01, 52.27it/s, Epoch: 4, Batch: 86,Loss: 1.640,Avg.Loss: 1.053,LR: 4.98E-04]Training epoch 4:  56%|█████▌    | 86/153 [00:01<00:01, 52.27it/s, Epoch: 4, Batch: 87,Loss: 0.770,Avg.Loss: 1.050,LR: 4.98E-04]Training epoch 4:  57%|█████▋    | 87/153 [00:01<00:01, 53.08it/s, Epoch: 4, Batch: 87,Loss: 0.770,Avg.Loss: 1.050,LR: 4.98E-04]Training epoch 4:  57%|█████▋    | 87/153 [00:01<00:01, 53.08it/s, Epoch: 4, Batch: 88,Loss: 0.972,Avg.Loss: 1.049,LR: 4.98E-04]Training epoch 4:  58%|█████▊    | 88/153 [00:01<00:01, 53.08it/s, Epoch: 4, Batch: 89,Loss: 1.360,Avg.Loss: 1.052,LR: 4.98E-04]Training epoch 4:  58%|█████▊    | 89/153 [00:01<00:01, 53.08it/s, Epoch: 4, Batch: 90,Loss: 0.587,Avg.Loss: 1.047,LR: 4.98E-04]Training epoch 4:  59%|█████▉    | 90/153 [00:01<00:01, 53.08it/s, Epoch: 4, Batch: 91,Loss: 1.275,Avg.Loss: 1.050,LR: 4.98E-04]Training epoch 4:  59%|█████▉    | 91/153 [00:01<00:01, 53.08it/s, Epoch: 4, Batch: 92,Loss: 0.838,Avg.Loss: 1.047,LR: 4.98E-04]Training epoch 4:  60%|██████    | 92/153 [00:01<00:01, 53.08it/s, Epoch: 4, Batch: 93,Loss: 0.772,Avg.Loss: 1.044,LR: 4.98E-04]Training epoch 4:  61%|██████    | 93/153 [00:01<00:01, 53.03it/s, Epoch: 4, Batch: 93,Loss: 0.772,Avg.Loss: 1.044,LR: 4.98E-04]Training epoch 4:  61%|██████    | 93/153 [00:01<00:01, 53.03it/s, Epoch: 4, Batch: 94,Loss: 1.148,Avg.Loss: 1.045,LR: 4.98E-04]Training epoch 4:  61%|██████▏   | 94/153 [00:01<00:01, 53.03it/s, Epoch: 4, Batch: 95,Loss: 0.870,Avg.Loss: 1.044,LR: 4.98E-04]Training epoch 4:  62%|██████▏   | 95/153 [00:01<00:01, 53.03it/s, Epoch: 4, Batch: 96,Loss: 0.587,Avg.Loss: 1.039,LR: 4.98E-04]Training epoch 4:  63%|██████▎   | 96/153 [00:01<00:01, 53.03it/s, Epoch: 4, Batch: 97,Loss: 0.970,Avg.Loss: 1.038,LR: 4.98E-04]Training epoch 4:  63%|██████▎   | 97/153 [00:01<00:01, 53.03it/s, Epoch: 4, Batch: 98,Loss: 0.908,Avg.Loss: 1.037,LR: 4.98E-04]Training epoch 4:  64%|██████▍   | 98/153 [00:01<00:01, 53.03it/s, Epoch: 4, Batch: 99,Loss: 0.878,Avg.Loss: 1.035,LR: 4.98E-04]Training epoch 4:  65%|██████▍   | 99/153 [00:01<00:01, 52.96it/s, Epoch: 4, Batch: 99,Loss: 0.878,Avg.Loss: 1.035,LR: 4.98E-04]Training epoch 4:  65%|██████▍   | 99/153 [00:01<00:01, 52.96it/s, Epoch: 4, Batch: 100,Loss: 1.064,Avg.Loss: 1.036,LR: 4.98E-04]Training epoch 4:  65%|██████▌   | 100/153 [00:01<00:01, 52.96it/s, Epoch: 4, Batch: 101,Loss: 0.823,Avg.Loss: 1.033,LR: 4.98E-04]Training epoch 4:  66%|██████▌   | 101/153 [00:01<00:00, 52.96it/s, Epoch: 4, Batch: 102,Loss: 0.925,Avg.Loss: 1.032,LR: 4.98E-04]Training epoch 4:  67%|██████▋   | 102/153 [00:01<00:00, 52.96it/s, Epoch: 4, Batch: 103,Loss: 0.661,Avg.Loss: 1.029,LR: 4.98E-04]Training epoch 4:  67%|██████▋   | 103/153 [00:01<00:00, 52.96it/s, Epoch: 4, Batch: 104,Loss: 0.874,Avg.Loss: 1.027,LR: 4.98E-04]Training epoch 4:  68%|██████▊   | 104/153 [00:01<00:00, 52.96it/s, Epoch: 4, Batch: 105,Loss: 0.939,Avg.Loss: 1.026,LR: 4.98E-04]Training epoch 4:  69%|██████▊   | 105/153 [00:01<00:00, 53.01it/s, Epoch: 4, Batch: 105,Loss: 0.939,Avg.Loss: 1.026,LR: 4.98E-04]Training epoch 4:  69%|██████▊   | 105/153 [00:01<00:00, 53.01it/s, Epoch: 4, Batch: 106,Loss: 0.948,Avg.Loss: 1.026,LR: 4.98E-04]Training epoch 4:  69%|██████▉   | 106/153 [00:01<00:00, 53.01it/s, Epoch: 4, Batch: 107,Loss: 1.357,Avg.Loss: 1.029,LR: 4.98E-04]Training epoch 4:  70%|██████▉   | 107/153 [00:02<00:00, 53.01it/s, Epoch: 4, Batch: 108,Loss: 0.681,Avg.Loss: 1.026,LR: 4.98E-04]Training epoch 4:  71%|███████   | 108/153 [00:02<00:00, 53.01it/s, Epoch: 4, Batch: 109,Loss: 1.365,Avg.Loss: 1.029,LR: 4.98E-04]Training epoch 4:  71%|███████   | 109/153 [00:02<00:00, 53.01it/s, Epoch: 4, Batch: 110,Loss: 1.225,Avg.Loss: 1.030,LR: 4.98E-04]Training epoch 4:  72%|███████▏  | 110/153 [00:02<00:00, 53.01it/s, Epoch: 4, Batch: 111,Loss: 1.226,Avg.Loss: 1.032,LR: 4.98E-04]Training epoch 4:  73%|███████▎  | 111/153 [00:02<00:00, 52.90it/s, Epoch: 4, Batch: 111,Loss: 1.226,Avg.Loss: 1.032,LR: 4.98E-04]Training epoch 4:  73%|███████▎  | 111/153 [00:02<00:00, 52.90it/s, Epoch: 4, Batch: 112,Loss: 0.894,Avg.Loss: 1.031,LR: 4.98E-04]Training epoch 4:  73%|███████▎  | 112/153 [00:02<00:00, 52.90it/s, Epoch: 4, Batch: 113,Loss: 1.100,Avg.Loss: 1.032,LR: 4.98E-04]Training epoch 4:  74%|███████▍  | 113/153 [00:02<00:00, 52.90it/s, Epoch: 4, Batch: 114,Loss: 0.579,Avg.Loss: 1.028,LR: 4.98E-04]Training epoch 4:  75%|███████▍  | 114/153 [00:02<00:00, 52.90it/s, Epoch: 4, Batch: 115,Loss: 1.237,Avg.Loss: 1.029,LR: 4.98E-04]Training epoch 4:  75%|███████▌  | 115/153 [00:02<00:00, 52.90it/s, Epoch: 4, Batch: 116,Loss: 0.740,Avg.Loss: 1.027,LR: 4.98E-04]Training epoch 4:  76%|███████▌  | 116/153 [00:02<00:00, 52.90it/s, Epoch: 4, Batch: 117,Loss: 0.987,Avg.Loss: 1.027,LR: 4.98E-04]Training epoch 4:  76%|███████▋  | 117/153 [00:02<00:00, 52.97it/s, Epoch: 4, Batch: 117,Loss: 0.987,Avg.Loss: 1.027,LR: 4.98E-04]Training epoch 4:  76%|███████▋  | 117/153 [00:02<00:00, 52.97it/s, Epoch: 4, Batch: 118,Loss: 0.941,Avg.Loss: 1.026,LR: 4.98E-04]Training epoch 4:  77%|███████▋  | 118/153 [00:02<00:00, 52.97it/s, Epoch: 4, Batch: 119,Loss: 0.872,Avg.Loss: 1.025,LR: 4.98E-04]Training epoch 4:  78%|███████▊  | 119/153 [00:02<00:00, 52.97it/s, Epoch: 4, Batch: 120,Loss: 0.875,Avg.Loss: 1.023,LR: 4.98E-04]Training epoch 4:  78%|███████▊  | 120/153 [00:02<00:00, 52.97it/s, Epoch: 4, Batch: 121,Loss: 0.961,Avg.Loss: 1.023,LR: 4.98E-04]Training epoch 4:  79%|███████▉  | 121/153 [00:02<00:00, 52.97it/s, Epoch: 4, Batch: 122,Loss: 0.837,Avg.Loss: 1.021,LR: 4.98E-04]Training epoch 4:  80%|███████▉  | 122/153 [00:02<00:00, 52.97it/s, Epoch: 4, Batch: 123,Loss: 0.729,Avg.Loss: 1.019,LR: 4.98E-04]Training epoch 4:  80%|████████  | 123/153 [00:02<00:00, 53.08it/s, Epoch: 4, Batch: 123,Loss: 0.729,Avg.Loss: 1.019,LR: 4.98E-04]Training epoch 4:  80%|████████  | 123/153 [00:02<00:00, 53.08it/s, Epoch: 4, Batch: 124,Loss: 0.761,Avg.Loss: 1.017,LR: 4.98E-04]Training epoch 4:  81%|████████  | 124/153 [00:02<00:00, 53.08it/s, Epoch: 4, Batch: 125,Loss: 1.071,Avg.Loss: 1.017,LR: 4.98E-04]Training epoch 4:  82%|████████▏ | 125/153 [00:02<00:00, 53.08it/s, Epoch: 4, Batch: 126,Loss: 0.902,Avg.Loss: 1.016,LR: 4.98E-04]Training epoch 4:  82%|████████▏ | 126/153 [00:02<00:00, 53.08it/s, Epoch: 4, Batch: 127,Loss: 0.927,Avg.Loss: 1.016,LR: 4.98E-04]Training epoch 4:  83%|████████▎ | 127/153 [00:02<00:00, 53.08it/s, Epoch: 4, Batch: 128,Loss: 1.179,Avg.Loss: 1.017,LR: 4.98E-04]Training epoch 4:  84%|████████▎ | 128/153 [00:02<00:00, 53.08it/s, Epoch: 4, Batch: 129,Loss: 0.873,Avg.Loss: 1.016,LR: 4.98E-04]Training epoch 4:  84%|████████▍ | 129/153 [00:02<00:00, 53.12it/s, Epoch: 4, Batch: 129,Loss: 0.873,Avg.Loss: 1.016,LR: 4.98E-04]Training epoch 4:  84%|████████▍ | 129/153 [00:02<00:00, 53.12it/s, Epoch: 4, Batch: 130,Loss: 0.847,Avg.Loss: 1.015,LR: 4.98E-04]Training epoch 4:  85%|████████▍ | 130/153 [00:02<00:00, 53.12it/s, Epoch: 4, Batch: 131,Loss: 0.894,Avg.Loss: 1.014,LR: 4.98E-04]Training epoch 4:  86%|████████▌ | 131/153 [00:02<00:00, 53.12it/s, Epoch: 4, Batch: 132,Loss: 1.073,Avg.Loss: 1.014,LR: 4.98E-04]Training epoch 4:  86%|████████▋ | 132/153 [00:02<00:00, 53.12it/s, Epoch: 4, Batch: 133,Loss: 0.994,Avg.Loss: 1.014,LR: 4.98E-04]Training epoch 4:  87%|████████▋ | 133/153 [00:02<00:00, 53.12it/s, Epoch: 4, Batch: 134,Loss: 0.952,Avg.Loss: 1.013,LR: 4.98E-04]Training epoch 4:  88%|████████▊ | 134/153 [00:02<00:00, 53.12it/s, Epoch: 4, Batch: 135,Loss: 0.504,Avg.Loss: 1.010,LR: 4.98E-04]Training epoch 4:  88%|████████▊ | 135/153 [00:02<00:00, 53.10it/s, Epoch: 4, Batch: 135,Loss: 0.504,Avg.Loss: 1.010,LR: 4.98E-04]Training epoch 4:  88%|████████▊ | 135/153 [00:02<00:00, 53.10it/s, Epoch: 4, Batch: 136,Loss: 0.876,Avg.Loss: 1.009,LR: 4.98E-04]Training epoch 4:  89%|████████▉ | 136/153 [00:02<00:00, 53.10it/s, Epoch: 4, Batch: 137,Loss: 0.852,Avg.Loss: 1.008,LR: 4.98E-04]Training epoch 4:  90%|████████▉ | 137/153 [00:02<00:00, 53.10it/s, Epoch: 4, Batch: 138,Loss: 1.248,Avg.Loss: 1.009,LR: 4.98E-04]Training epoch 4:  90%|█████████ | 138/153 [00:02<00:00, 53.10it/s, Epoch: 4, Batch: 139,Loss: 0.921,Avg.Loss: 1.009,LR: 4.98E-04]Training epoch 4:  91%|█████████ | 139/153 [00:02<00:00, 53.10it/s, Epoch: 4, Batch: 140,Loss: 0.869,Avg.Loss: 1.008,LR: 4.98E-04]Training epoch 4:  92%|█████████▏| 140/153 [00:02<00:00, 53.10it/s, Epoch: 4, Batch: 141,Loss: 0.770,Avg.Loss: 1.006,LR: 4.98E-04]Training epoch 4:  92%|█████████▏| 141/153 [00:02<00:00, 53.13it/s, Epoch: 4, Batch: 141,Loss: 0.770,Avg.Loss: 1.006,LR: 4.98E-04]Training epoch 4:  92%|█████████▏| 141/153 [00:02<00:00, 53.13it/s, Epoch: 4, Batch: 142,Loss: 1.036,Avg.Loss: 1.006,LR: 4.98E-04]Training epoch 4:  93%|█████████▎| 142/153 [00:02<00:00, 53.13it/s, Epoch: 4, Batch: 143,Loss: 0.897,Avg.Loss: 1.005,LR: 4.98E-04]Training epoch 4:  93%|█████████▎| 143/153 [00:02<00:00, 53.13it/s, Epoch: 4, Batch: 144,Loss: 0.708,Avg.Loss: 1.003,LR: 4.98E-04]Training epoch 4:  94%|█████████▍| 144/153 [00:02<00:00, 53.13it/s, Epoch: 4, Batch: 145,Loss: 0.693,Avg.Loss: 1.001,LR: 4.98E-04]Training epoch 4:  95%|█████████▍| 145/153 [00:02<00:00, 53.13it/s, Epoch: 4, Batch: 146,Loss: 0.906,Avg.Loss: 1.001,LR: 4.98E-04]Training epoch 4:  95%|█████████▌| 146/153 [00:02<00:00, 53.13it/s, Epoch: 4, Batch: 147,Loss: 0.947,Avg.Loss: 1.000,LR: 4.98E-04]Training epoch 4:  96%|█████████▌| 147/153 [00:02<00:00, 53.21it/s, Epoch: 4, Batch: 147,Loss: 0.947,Avg.Loss: 1.000,LR: 4.98E-04]Training epoch 4:  96%|█████████▌| 147/153 [00:02<00:00, 53.21it/s, Epoch: 4, Batch: 148,Loss: 1.077,Avg.Loss: 1.001,LR: 4.98E-04]Training epoch 4:  97%|█████████▋| 148/153 [00:02<00:00, 53.21it/s, Epoch: 4, Batch: 149,Loss: 0.895,Avg.Loss: 1.000,LR: 4.98E-04]Training epoch 4:  97%|█████████▋| 149/153 [00:02<00:00, 53.21it/s, Epoch: 4, Batch: 150,Loss: 1.032,Avg.Loss: 1.000,LR: 4.98E-04]Training epoch 4:  98%|█████████▊| 150/153 [00:02<00:00, 53.21it/s, Epoch: 4, Batch: 151,Loss: 0.763,Avg.Loss: 0.999,LR: 4.98E-04]Training epoch 4:  99%|█████████▊| 151/153 [00:02<00:00, 53.21it/s, Epoch: 4, Batch: 152,Loss: 0.782,Avg.Loss: 0.997,LR: 4.98E-04]Training epoch 4:  99%|█████████▉| 152/153 [00:02<00:00, 53.21it/s, Epoch: 4, Batch: 153,Loss: 0.455,Avg.Loss: 0.994,LR: 4.98E-04]Training epoch 4: 100%|██████████| 153/153 [00:02<00:00, 52.77it/s, Epoch: 4, Batch: 153,Loss: 0.455,Avg.Loss: 0.994,LR: 4.98E-04]Training epoch 4: 100%|██████████| 153/153 [00:02<00:00, 53.37it/s, Epoch: 4, Batch: 153,Loss: 0.455,Avg.Loss: 0.994,LR: 4.98E-04]
Training epoch 5:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 5:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 5, Batch: 1,Loss: 0.759,Avg.Loss: 0.759,LR: 4.98E-04]Training epoch 5:   1%|          | 1/153 [00:00<00:06, 23.16it/s, Epoch: 5, Batch: 2,Loss: 0.660,Avg.Loss: 0.709,LR: 4.98E-04]Training epoch 5:   1%|▏         | 2/153 [00:00<00:04, 33.57it/s, Epoch: 5, Batch: 3,Loss: 0.973,Avg.Loss: 0.797,LR: 4.98E-04]Training epoch 5:   2%|▏         | 3/153 [00:00<00:03, 39.49it/s, Epoch: 5, Batch: 4,Loss: 0.635,Avg.Loss: 0.757,LR: 4.98E-04]Training epoch 5:   3%|▎         | 4/153 [00:00<00:03, 41.98it/s, Epoch: 5, Batch: 5,Loss: 0.851,Avg.Loss: 0.775,LR: 4.98E-04]Training epoch 5:   3%|▎         | 5/153 [00:00<00:03, 44.87it/s, Epoch: 5, Batch: 6,Loss: 0.935,Avg.Loss: 0.802,LR: 4.98E-04]Training epoch 5:   4%|▍         | 6/153 [00:00<00:02, 53.77it/s, Epoch: 5, Batch: 6,Loss: 0.935,Avg.Loss: 0.802,LR: 4.98E-04]Training epoch 5:   4%|▍         | 6/153 [00:00<00:02, 53.77it/s, Epoch: 5, Batch: 7,Loss: 1.139,Avg.Loss: 0.850,LR: 4.98E-04]Training epoch 5:   5%|▍         | 7/153 [00:00<00:02, 53.77it/s, Epoch: 5, Batch: 8,Loss: 1.071,Avg.Loss: 0.878,LR: 4.98E-04]Training epoch 5:   5%|▌         | 8/153 [00:00<00:02, 53.77it/s, Epoch: 5, Batch: 9,Loss: 0.765,Avg.Loss: 0.865,LR: 4.98E-04]Training epoch 5:   6%|▌         | 9/153 [00:00<00:02, 53.77it/s, Epoch: 5, Batch: 10,Loss: 1.005,Avg.Loss: 0.879,LR: 4.98E-04]Training epoch 5:   7%|▋         | 10/153 [00:00<00:02, 53.77it/s, Epoch: 5, Batch: 11,Loss: 0.913,Avg.Loss: 0.882,LR: 4.98E-04]Training epoch 5:   7%|▋         | 11/153 [00:00<00:02, 53.77it/s, Epoch: 5, Batch: 12,Loss: 1.080,Avg.Loss: 0.899,LR: 4.98E-04]Training epoch 5:   8%|▊         | 12/153 [00:00<00:02, 53.77it/s, Epoch: 5, Batch: 13,Loss: 0.958,Avg.Loss: 0.903,LR: 4.98E-04]Training epoch 5:   8%|▊         | 13/153 [00:00<00:02, 60.13it/s, Epoch: 5, Batch: 13,Loss: 0.958,Avg.Loss: 0.903,LR: 4.98E-04]Training epoch 5:   8%|▊         | 13/153 [00:00<00:02, 60.13it/s, Epoch: 5, Batch: 14,Loss: 1.151,Avg.Loss: 0.921,LR: 4.98E-04]Training epoch 5:   9%|▉         | 14/153 [00:00<00:02, 60.13it/s, Epoch: 5, Batch: 15,Loss: 0.687,Avg.Loss: 0.905,LR: 4.98E-04]Training epoch 5:  10%|▉         | 15/153 [00:00<00:02, 60.13it/s, Epoch: 5, Batch: 16,Loss: 1.067,Avg.Loss: 0.916,LR: 4.98E-04]Training epoch 5:  10%|█         | 16/153 [00:00<00:02, 60.13it/s, Epoch: 5, Batch: 17,Loss: 0.625,Avg.Loss: 0.898,LR: 4.98E-04]Training epoch 5:  11%|█         | 17/153 [00:00<00:02, 60.13it/s, Epoch: 5, Batch: 18,Loss: 1.021,Avg.Loss: 0.905,LR: 4.98E-04]Training epoch 5:  12%|█▏        | 18/153 [00:00<00:02, 60.13it/s, Epoch: 5, Batch: 19,Loss: 0.915,Avg.Loss: 0.906,LR: 4.98E-04]Training epoch 5:  12%|█▏        | 19/153 [00:00<00:02, 60.13it/s, Epoch: 5, Batch: 20,Loss: 1.146,Avg.Loss: 0.918,LR: 4.98E-04]Training epoch 5:  13%|█▎        | 20/153 [00:00<00:02, 56.84it/s, Epoch: 5, Batch: 20,Loss: 1.146,Avg.Loss: 0.918,LR: 4.98E-04]Training epoch 5:  13%|█▎        | 20/153 [00:00<00:02, 56.84it/s, Epoch: 5, Batch: 21,Loss: 0.787,Avg.Loss: 0.912,LR: 4.98E-04]Training epoch 5:  14%|█▎        | 21/153 [00:00<00:02, 56.84it/s, Epoch: 5, Batch: 22,Loss: 0.638,Avg.Loss: 0.899,LR: 4.98E-04]Training epoch 5:  14%|█▍        | 22/153 [00:00<00:02, 56.84it/s, Epoch: 5, Batch: 23,Loss: 0.831,Avg.Loss: 0.896,LR: 4.98E-04]Training epoch 5:  15%|█▌        | 23/153 [00:00<00:02, 56.84it/s, Epoch: 5, Batch: 24,Loss: 0.819,Avg.Loss: 0.893,LR: 4.98E-04]Training epoch 5:  16%|█▌        | 24/153 [00:00<00:02, 56.84it/s, Epoch: 5, Batch: 25,Loss: 0.748,Avg.Loss: 0.887,LR: 4.98E-04]Training epoch 5:  16%|█▋        | 25/153 [00:00<00:02, 56.84it/s, Epoch: 5, Batch: 26,Loss: 0.807,Avg.Loss: 0.884,LR: 4.98E-04]Training epoch 5:  17%|█▋        | 26/153 [00:00<00:02, 54.90it/s, Epoch: 5, Batch: 26,Loss: 0.807,Avg.Loss: 0.884,LR: 4.98E-04]Training epoch 5:  17%|█▋        | 26/153 [00:00<00:02, 54.90it/s, Epoch: 5, Batch: 27,Loss: 1.231,Avg.Loss: 0.897,LR: 4.98E-04]Training epoch 5:  18%|█▊        | 27/153 [00:00<00:02, 54.90it/s, Epoch: 5, Batch: 28,Loss: 0.956,Avg.Loss: 0.899,LR: 4.98E-04]Training epoch 5:  18%|█▊        | 28/153 [00:00<00:02, 54.90it/s, Epoch: 5, Batch: 29,Loss: 1.081,Avg.Loss: 0.905,LR: 4.98E-04]Training epoch 5:  19%|█▉        | 29/153 [00:00<00:02, 54.90it/s, Epoch: 5, Batch: 30,Loss: 1.039,Avg.Loss: 0.910,LR: 4.98E-04]Training epoch 5:  20%|█▉        | 30/153 [00:00<00:02, 54.90it/s, Epoch: 5, Batch: 31,Loss: 1.015,Avg.Loss: 0.913,LR: 4.98E-04]Training epoch 5:  20%|██        | 31/153 [00:00<00:02, 54.90it/s, Epoch: 5, Batch: 32,Loss: 0.994,Avg.Loss: 0.916,LR: 4.98E-04]Training epoch 5:  21%|██        | 32/153 [00:00<00:02, 53.45it/s, Epoch: 5, Batch: 32,Loss: 0.994,Avg.Loss: 0.916,LR: 4.98E-04]Training epoch 5:  21%|██        | 32/153 [00:00<00:02, 53.45it/s, Epoch: 5, Batch: 33,Loss: 0.965,Avg.Loss: 0.917,LR: 4.98E-04]Training epoch 5:  22%|██▏       | 33/153 [00:00<00:02, 53.45it/s, Epoch: 5, Batch: 34,Loss: 0.752,Avg.Loss: 0.912,LR: 4.98E-04]Training epoch 5:  22%|██▏       | 34/153 [00:00<00:02, 53.45it/s, Epoch: 5, Batch: 35,Loss: 0.938,Avg.Loss: 0.913,LR: 4.98E-04]Training epoch 5:  23%|██▎       | 35/153 [00:00<00:02, 53.45it/s, Epoch: 5, Batch: 36,Loss: 1.207,Avg.Loss: 0.921,LR: 4.98E-04]Training epoch 5:  24%|██▎       | 36/153 [00:00<00:02, 53.45it/s, Epoch: 5, Batch: 37,Loss: 0.926,Avg.Loss: 0.921,LR: 4.98E-04]Training epoch 5:  24%|██▍       | 37/153 [00:00<00:02, 53.45it/s, Epoch: 5, Batch: 38,Loss: 0.815,Avg.Loss: 0.919,LR: 4.98E-04]Training epoch 5:  25%|██▍       | 38/153 [00:00<00:02, 53.01it/s, Epoch: 5, Batch: 38,Loss: 0.815,Avg.Loss: 0.919,LR: 4.98E-04]Training epoch 5:  25%|██▍       | 38/153 [00:00<00:02, 53.01it/s, Epoch: 5, Batch: 39,Loss: 0.849,Avg.Loss: 0.917,LR: 4.98E-04]Training epoch 5:  25%|██▌       | 39/153 [00:00<00:02, 53.01it/s, Epoch: 5, Batch: 40,Loss: 0.745,Avg.Loss: 0.913,LR: 4.98E-04]Training epoch 5:  26%|██▌       | 40/153 [00:00<00:02, 53.01it/s, Epoch: 5, Batch: 41,Loss: 1.054,Avg.Loss: 0.916,LR: 4.98E-04]Training epoch 5:  27%|██▋       | 41/153 [00:00<00:02, 53.01it/s, Epoch: 5, Batch: 42,Loss: 0.889,Avg.Loss: 0.915,LR: 4.98E-04]Training epoch 5:  27%|██▋       | 42/153 [00:00<00:02, 53.01it/s, Epoch: 5, Batch: 43,Loss: 0.869,Avg.Loss: 0.914,LR: 4.98E-04]Training epoch 5:  28%|██▊       | 43/153 [00:00<00:02, 53.01it/s, Epoch: 5, Batch: 44,Loss: 0.981,Avg.Loss: 0.916,LR: 4.98E-04]Training epoch 5:  29%|██▉       | 44/153 [00:00<00:02, 52.98it/s, Epoch: 5, Batch: 44,Loss: 0.981,Avg.Loss: 0.916,LR: 4.98E-04]Training epoch 5:  29%|██▉       | 44/153 [00:00<00:02, 52.98it/s, Epoch: 5, Batch: 45,Loss: 0.963,Avg.Loss: 0.917,LR: 4.98E-04]Training epoch 5:  29%|██▉       | 45/153 [00:00<00:02, 52.98it/s, Epoch: 5, Batch: 46,Loss: 0.716,Avg.Loss: 0.912,LR: 4.98E-04]Training epoch 5:  30%|███       | 46/153 [00:00<00:02, 52.98it/s, Epoch: 5, Batch: 47,Loss: 0.970,Avg.Loss: 0.914,LR: 4.98E-04]Training epoch 5:  31%|███       | 47/153 [00:00<00:02, 52.98it/s, Epoch: 5, Batch: 48,Loss: 0.825,Avg.Loss: 0.912,LR: 4.98E-04]Training epoch 5:  31%|███▏      | 48/153 [00:00<00:01, 52.98it/s, Epoch: 5, Batch: 49,Loss: 1.080,Avg.Loss: 0.915,LR: 4.98E-04]Training epoch 5:  32%|███▏      | 49/153 [00:00<00:01, 52.98it/s, Epoch: 5, Batch: 50,Loss: 0.694,Avg.Loss: 0.911,LR: 4.98E-04]Training epoch 5:  33%|███▎      | 50/153 [00:00<00:01, 53.01it/s, Epoch: 5, Batch: 50,Loss: 0.694,Avg.Loss: 0.911,LR: 4.98E-04]Training epoch 5:  33%|███▎      | 50/153 [00:00<00:01, 53.01it/s, Epoch: 5, Batch: 51,Loss: 0.763,Avg.Loss: 0.908,LR: 4.98E-04]Training epoch 5:  33%|███▎      | 51/153 [00:00<00:01, 53.01it/s, Epoch: 5, Batch: 52,Loss: 0.642,Avg.Loss: 0.903,LR: 4.98E-04]Training epoch 5:  34%|███▍      | 52/153 [00:00<00:01, 53.01it/s, Epoch: 5, Batch: 53,Loss: 0.757,Avg.Loss: 0.900,LR: 4.98E-04]Training epoch 5:  35%|███▍      | 53/153 [00:01<00:01, 53.01it/s, Epoch: 5, Batch: 54,Loss: 0.911,Avg.Loss: 0.900,LR: 4.98E-04]Training epoch 5:  35%|███▌      | 54/153 [00:01<00:01, 53.01it/s, Epoch: 5, Batch: 55,Loss: 1.126,Avg.Loss: 0.904,LR: 4.98E-04]Training epoch 5:  36%|███▌      | 55/153 [00:01<00:01, 53.01it/s, Epoch: 5, Batch: 56,Loss: 0.714,Avg.Loss: 0.901,LR: 4.98E-04]Training epoch 5:  37%|███▋      | 56/153 [00:01<00:01, 53.05it/s, Epoch: 5, Batch: 56,Loss: 0.714,Avg.Loss: 0.901,LR: 4.98E-04]Training epoch 5:  37%|███▋      | 56/153 [00:01<00:01, 53.05it/s, Epoch: 5, Batch: 57,Loss: 0.929,Avg.Loss: 0.902,LR: 4.98E-04]Training epoch 5:  37%|███▋      | 57/153 [00:01<00:01, 53.05it/s, Epoch: 5, Batch: 58,Loss: 0.558,Avg.Loss: 0.896,LR: 4.98E-04]Training epoch 5:  38%|███▊      | 58/153 [00:01<00:01, 53.05it/s, Epoch: 5, Batch: 59,Loss: 0.727,Avg.Loss: 0.893,LR: 4.98E-04]Training epoch 5:  39%|███▊      | 59/153 [00:01<00:01, 53.05it/s, Epoch: 5, Batch: 60,Loss: 0.869,Avg.Loss: 0.892,LR: 4.98E-04]Training epoch 5:  39%|███▉      | 60/153 [00:01<00:01, 53.05it/s, Epoch: 5, Batch: 61,Loss: 0.765,Avg.Loss: 0.890,LR: 4.98E-04]Training epoch 5:  40%|███▉      | 61/153 [00:01<00:01, 53.05it/s, Epoch: 5, Batch: 62,Loss: 0.636,Avg.Loss: 0.886,LR: 4.98E-04]Training epoch 5:  41%|████      | 62/153 [00:01<00:01, 52.98it/s, Epoch: 5, Batch: 62,Loss: 0.636,Avg.Loss: 0.886,LR: 4.98E-04]Training epoch 5:  41%|████      | 62/153 [00:01<00:01, 52.98it/s, Epoch: 5, Batch: 63,Loss: 0.678,Avg.Loss: 0.883,LR: 4.98E-04]Training epoch 5:  41%|████      | 63/153 [00:01<00:01, 52.98it/s, Epoch: 5, Batch: 64,Loss: 0.367,Avg.Loss: 0.875,LR: 4.98E-04]Training epoch 5:  42%|████▏     | 64/153 [00:01<00:01, 52.98it/s, Epoch: 5, Batch: 65,Loss: 1.017,Avg.Loss: 0.877,LR: 4.98E-04]Training epoch 5:  42%|████▏     | 65/153 [00:01<00:01, 52.98it/s, Epoch: 5, Batch: 66,Loss: 0.706,Avg.Loss: 0.874,LR: 4.98E-04]Training epoch 5:  43%|████▎     | 66/153 [00:01<00:01, 52.98it/s, Epoch: 5, Batch: 67,Loss: 1.130,Avg.Loss: 0.878,LR: 4.98E-04]Training epoch 5:  44%|████▍     | 67/153 [00:01<00:01, 52.98it/s, Epoch: 5, Batch: 68,Loss: 0.476,Avg.Loss: 0.872,LR: 4.98E-04]Training epoch 5:  44%|████▍     | 68/153 [00:01<00:01, 52.96it/s, Epoch: 5, Batch: 68,Loss: 0.476,Avg.Loss: 0.872,LR: 4.98E-04]Training epoch 5:  44%|████▍     | 68/153 [00:01<00:01, 52.96it/s, Epoch: 5, Batch: 69,Loss: 1.155,Avg.Loss: 0.876,LR: 4.98E-04]Training epoch 5:  45%|████▌     | 69/153 [00:01<00:01, 52.96it/s, Epoch: 5, Batch: 70,Loss: 0.630,Avg.Loss: 0.873,LR: 4.98E-04]Training epoch 5:  46%|████▌     | 70/153 [00:01<00:01, 52.96it/s, Epoch: 5, Batch: 71,Loss: 1.234,Avg.Loss: 0.878,LR: 4.98E-04]Training epoch 5:  46%|████▋     | 71/153 [00:01<00:01, 52.96it/s, Epoch: 5, Batch: 72,Loss: 0.970,Avg.Loss: 0.879,LR: 4.98E-04]Training epoch 5:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 5, Batch: 73,Loss: 0.759,Avg.Loss: 0.878,LR: 4.98E-04]Training epoch 5:  48%|████▊     | 73/153 [00:01<00:01, 52.96it/s, Epoch: 5, Batch: 74,Loss: 0.992,Avg.Loss: 0.879,LR: 4.98E-04]Training epoch 5:  48%|████▊     | 74/153 [00:01<00:01, 52.86it/s, Epoch: 5, Batch: 74,Loss: 0.992,Avg.Loss: 0.879,LR: 4.98E-04]Training epoch 5:  48%|████▊     | 74/153 [00:01<00:01, 52.86it/s, Epoch: 5, Batch: 75,Loss: 0.834,Avg.Loss: 0.879,LR: 4.98E-04]Training epoch 5:  49%|████▉     | 75/153 [00:01<00:01, 52.86it/s, Epoch: 5, Batch: 76,Loss: 0.708,Avg.Loss: 0.876,LR: 4.98E-04]Training epoch 5:  50%|████▉     | 76/153 [00:01<00:01, 52.86it/s, Epoch: 5, Batch: 77,Loss: 0.558,Avg.Loss: 0.872,LR: 4.98E-04]Training epoch 5:  50%|█████     | 77/153 [00:01<00:01, 52.86it/s, Epoch: 5, Batch: 78,Loss: 0.839,Avg.Loss: 0.872,LR: 4.97E-04]Training epoch 5:  51%|█████     | 78/153 [00:01<00:01, 52.86it/s, Epoch: 5, Batch: 79,Loss: 0.857,Avg.Loss: 0.872,LR: 4.97E-04]Training epoch 5:  52%|█████▏    | 79/153 [00:01<00:01, 52.86it/s, Epoch: 5, Batch: 80,Loss: 0.486,Avg.Loss: 0.867,LR: 4.97E-04]Training epoch 5:  52%|█████▏    | 80/153 [00:01<00:01, 53.08it/s, Epoch: 5, Batch: 80,Loss: 0.486,Avg.Loss: 0.867,LR: 4.97E-04]Training epoch 5:  52%|█████▏    | 80/153 [00:01<00:01, 53.08it/s, Epoch: 5, Batch: 81,Loss: 0.832,Avg.Loss: 0.866,LR: 4.97E-04]Training epoch 5:  53%|█████▎    | 81/153 [00:01<00:01, 53.08it/s, Epoch: 5, Batch: 82,Loss: 0.796,Avg.Loss: 0.865,LR: 4.97E-04]Training epoch 5:  54%|█████▎    | 82/153 [00:01<00:01, 53.08it/s, Epoch: 5, Batch: 83,Loss: 1.056,Avg.Loss: 0.868,LR: 4.97E-04]Training epoch 5:  54%|█████▍    | 83/153 [00:01<00:01, 53.08it/s, Epoch: 5, Batch: 84,Loss: 0.443,Avg.Loss: 0.863,LR: 4.97E-04]Training epoch 5:  55%|█████▍    | 84/153 [00:01<00:01, 53.08it/s, Epoch: 5, Batch: 85,Loss: 0.683,Avg.Loss: 0.861,LR: 4.97E-04]Training epoch 5:  56%|█████▌    | 85/153 [00:01<00:01, 53.08it/s, Epoch: 5, Batch: 86,Loss: 0.756,Avg.Loss: 0.859,LR: 4.97E-04]Training epoch 5:  56%|█████▌    | 86/153 [00:01<00:01, 53.11it/s, Epoch: 5, Batch: 86,Loss: 0.756,Avg.Loss: 0.859,LR: 4.97E-04]Training epoch 5:  56%|█████▌    | 86/153 [00:01<00:01, 53.11it/s, Epoch: 5, Batch: 87,Loss: 0.703,Avg.Loss: 0.858,LR: 4.97E-04]Training epoch 5:  57%|█████▋    | 87/153 [00:01<00:01, 53.11it/s, Epoch: 5, Batch: 88,Loss: 0.685,Avg.Loss: 0.856,LR: 4.97E-04]Training epoch 5:  58%|█████▊    | 88/153 [00:01<00:01, 53.11it/s, Epoch: 5, Batch: 89,Loss: 0.515,Avg.Loss: 0.852,LR: 4.97E-04]Training epoch 5:  58%|█████▊    | 89/153 [00:01<00:01, 53.11it/s, Epoch: 5, Batch: 90,Loss: 0.951,Avg.Loss: 0.853,LR: 4.97E-04]Training epoch 5:  59%|█████▉    | 90/153 [00:01<00:01, 53.11it/s, Epoch: 5, Batch: 91,Loss: 1.002,Avg.Loss: 0.855,LR: 4.97E-04]Training epoch 5:  59%|█████▉    | 91/153 [00:01<00:01, 53.11it/s, Epoch: 5, Batch: 92,Loss: 0.599,Avg.Loss: 0.852,LR: 4.97E-04]Training epoch 5:  60%|██████    | 92/153 [00:01<00:01, 52.97it/s, Epoch: 5, Batch: 92,Loss: 0.599,Avg.Loss: 0.852,LR: 4.97E-04]Training epoch 5:  60%|██████    | 92/153 [00:01<00:01, 52.97it/s, Epoch: 5, Batch: 93,Loss: 1.136,Avg.Loss: 0.855,LR: 4.97E-04]Training epoch 5:  61%|██████    | 93/153 [00:01<00:01, 52.97it/s, Epoch: 5, Batch: 94,Loss: 0.761,Avg.Loss: 0.854,LR: 4.97E-04]Training epoch 5:  61%|██████▏   | 94/153 [00:01<00:01, 52.97it/s, Epoch: 5, Batch: 95,Loss: 0.753,Avg.Loss: 0.853,LR: 4.97E-04]Training epoch 5:  62%|██████▏   | 95/153 [00:01<00:01, 52.97it/s, Epoch: 5, Batch: 96,Loss: 0.891,Avg.Loss: 0.853,LR: 4.97E-04]Training epoch 5:  63%|██████▎   | 96/153 [00:01<00:01, 52.97it/s, Epoch: 5, Batch: 97,Loss: 0.675,Avg.Loss: 0.851,LR: 4.97E-04]Training epoch 5:  63%|██████▎   | 97/153 [00:01<00:01, 52.97it/s, Epoch: 5, Batch: 98,Loss: 0.587,Avg.Loss: 0.849,LR: 4.97E-04]Training epoch 5:  64%|██████▍   | 98/153 [00:01<00:01, 53.09it/s, Epoch: 5, Batch: 98,Loss: 0.587,Avg.Loss: 0.849,LR: 4.97E-04]Training epoch 5:  64%|██████▍   | 98/153 [00:01<00:01, 53.09it/s, Epoch: 5, Batch: 99,Loss: 0.601,Avg.Loss: 0.846,LR: 4.97E-04]Training epoch 5:  65%|██████▍   | 99/153 [00:01<00:01, 53.09it/s, Epoch: 5, Batch: 100,Loss: 0.635,Avg.Loss: 0.844,LR: 4.97E-04]Training epoch 5:  65%|██████▌   | 100/153 [00:01<00:00, 53.09it/s, Epoch: 5, Batch: 101,Loss: 0.589,Avg.Loss: 0.841,LR: 4.97E-04]Training epoch 5:  66%|██████▌   | 101/153 [00:01<00:00, 53.09it/s, Epoch: 5, Batch: 102,Loss: 0.816,Avg.Loss: 0.841,LR: 4.97E-04]Training epoch 5:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 5, Batch: 103,Loss: 0.276,Avg.Loss: 0.836,LR: 4.97E-04]Training epoch 5:  67%|██████▋   | 103/153 [00:01<00:00, 53.09it/s, Epoch: 5, Batch: 104,Loss: 0.849,Avg.Loss: 0.836,LR: 4.97E-04]Training epoch 5:  68%|██████▊   | 104/153 [00:01<00:00, 53.03it/s, Epoch: 5, Batch: 104,Loss: 0.849,Avg.Loss: 0.836,LR: 4.97E-04]Training epoch 5:  68%|██████▊   | 104/153 [00:01<00:00, 53.03it/s, Epoch: 5, Batch: 105,Loss: 0.922,Avg.Loss: 0.837,LR: 4.97E-04]Training epoch 5:  69%|██████▊   | 105/153 [00:01<00:00, 53.03it/s, Epoch: 5, Batch: 106,Loss: 0.955,Avg.Loss: 0.838,LR: 4.97E-04]Training epoch 5:  69%|██████▉   | 106/153 [00:02<00:00, 53.03it/s, Epoch: 5, Batch: 107,Loss: 0.969,Avg.Loss: 0.839,LR: 4.97E-04]Training epoch 5:  70%|██████▉   | 107/153 [00:02<00:00, 53.03it/s, Epoch: 5, Batch: 108,Loss: 1.185,Avg.Loss: 0.842,LR: 4.97E-04]Training epoch 5:  71%|███████   | 108/153 [00:02<00:00, 53.03it/s, Epoch: 5, Batch: 109,Loss: 0.836,Avg.Loss: 0.842,LR: 4.97E-04]Training epoch 5:  71%|███████   | 109/153 [00:02<00:00, 53.03it/s, Epoch: 5, Batch: 110,Loss: 0.571,Avg.Loss: 0.840,LR: 4.97E-04]Training epoch 5:  72%|███████▏  | 110/153 [00:02<00:00, 52.28it/s, Epoch: 5, Batch: 110,Loss: 0.571,Avg.Loss: 0.840,LR: 4.97E-04]Training epoch 5:  72%|███████▏  | 110/153 [00:02<00:00, 52.28it/s, Epoch: 5, Batch: 111,Loss: 0.722,Avg.Loss: 0.839,LR: 4.97E-04]Training epoch 5:  73%|███████▎  | 111/153 [00:02<00:00, 52.28it/s, Epoch: 5, Batch: 112,Loss: 1.060,Avg.Loss: 0.841,LR: 4.97E-04]Training epoch 5:  73%|███████▎  | 112/153 [00:02<00:00, 52.28it/s, Epoch: 5, Batch: 113,Loss: 0.698,Avg.Loss: 0.839,LR: 4.97E-04]Training epoch 5:  74%|███████▍  | 113/153 [00:02<00:00, 52.28it/s, Epoch: 5, Batch: 114,Loss: 0.709,Avg.Loss: 0.838,LR: 4.97E-04]Training epoch 5:  75%|███████▍  | 114/153 [00:02<00:00, 52.28it/s, Epoch: 5, Batch: 115,Loss: 0.461,Avg.Loss: 0.835,LR: 4.97E-04]Training epoch 5:  75%|███████▌  | 115/153 [00:02<00:00, 52.28it/s, Epoch: 5, Batch: 116,Loss: 0.468,Avg.Loss: 0.832,LR: 4.97E-04]Training epoch 5:  76%|███████▌  | 116/153 [00:02<00:00, 51.44it/s, Epoch: 5, Batch: 116,Loss: 0.468,Avg.Loss: 0.832,LR: 4.97E-04]Training epoch 5:  76%|███████▌  | 116/153 [00:02<00:00, 51.44it/s, Epoch: 5, Batch: 117,Loss: 0.558,Avg.Loss: 0.829,LR: 4.97E-04]Training epoch 5:  76%|███████▋  | 117/153 [00:02<00:00, 51.44it/s, Epoch: 5, Batch: 118,Loss: 0.653,Avg.Loss: 0.828,LR: 4.97E-04]Training epoch 5:  77%|███████▋  | 118/153 [00:02<00:00, 51.44it/s, Epoch: 5, Batch: 119,Loss: 0.840,Avg.Loss: 0.828,LR: 4.97E-04]Training epoch 5:  78%|███████▊  | 119/153 [00:02<00:00, 51.44it/s, Epoch: 5, Batch: 120,Loss: 0.323,Avg.Loss: 0.824,LR: 4.97E-04]Training epoch 5:  78%|███████▊  | 120/153 [00:02<00:00, 51.44it/s, Epoch: 5, Batch: 121,Loss: 0.608,Avg.Loss: 0.822,LR: 4.97E-04]Training epoch 5:  79%|███████▉  | 121/153 [00:02<00:00, 51.44it/s, Epoch: 5, Batch: 122,Loss: 0.891,Avg.Loss: 0.823,LR: 4.97E-04]Training epoch 5:  80%|███████▉  | 122/153 [00:02<00:00, 51.74it/s, Epoch: 5, Batch: 122,Loss: 0.891,Avg.Loss: 0.823,LR: 4.97E-04]Training epoch 5:  80%|███████▉  | 122/153 [00:02<00:00, 51.74it/s, Epoch: 5, Batch: 123,Loss: 0.908,Avg.Loss: 0.823,LR: 4.97E-04]Training epoch 5:  80%|████████  | 123/153 [00:02<00:00, 51.74it/s, Epoch: 5, Batch: 124,Loss: 0.877,Avg.Loss: 0.824,LR: 4.97E-04]Training epoch 5:  81%|████████  | 124/153 [00:02<00:00, 51.74it/s, Epoch: 5, Batch: 125,Loss: 0.622,Avg.Loss: 0.822,LR: 4.97E-04]Training epoch 5:  82%|████████▏ | 125/153 [00:02<00:00, 51.74it/s, Epoch: 5, Batch: 126,Loss: 0.903,Avg.Loss: 0.823,LR: 4.97E-04]Training epoch 5:  82%|████████▏ | 126/153 [00:02<00:00, 51.74it/s, Epoch: 5, Batch: 127,Loss: 1.030,Avg.Loss: 0.824,LR: 4.97E-04]Training epoch 5:  83%|████████▎ | 127/153 [00:02<00:00, 51.74it/s, Epoch: 5, Batch: 128,Loss: 0.541,Avg.Loss: 0.822,LR: 4.97E-04]Training epoch 5:  84%|████████▎ | 128/153 [00:02<00:00, 52.07it/s, Epoch: 5, Batch: 128,Loss: 0.541,Avg.Loss: 0.822,LR: 4.97E-04]Training epoch 5:  84%|████████▎ | 128/153 [00:02<00:00, 52.07it/s, Epoch: 5, Batch: 129,Loss: 0.711,Avg.Loss: 0.821,LR: 4.97E-04]Training epoch 5:  84%|████████▍ | 129/153 [00:02<00:00, 52.07it/s, Epoch: 5, Batch: 130,Loss: 0.621,Avg.Loss: 0.820,LR: 4.97E-04]Training epoch 5:  85%|████████▍ | 130/153 [00:02<00:00, 52.07it/s, Epoch: 5, Batch: 131,Loss: 0.613,Avg.Loss: 0.818,LR: 4.97E-04]Training epoch 5:  86%|████████▌ | 131/153 [00:02<00:00, 52.07it/s, Epoch: 5, Batch: 132,Loss: 0.648,Avg.Loss: 0.817,LR: 4.97E-04]Training epoch 5:  86%|████████▋ | 132/153 [00:02<00:00, 52.07it/s, Epoch: 5, Batch: 133,Loss: 0.533,Avg.Loss: 0.815,LR: 4.97E-04]Training epoch 5:  87%|████████▋ | 133/153 [00:02<00:00, 52.07it/s, Epoch: 5, Batch: 134,Loss: 0.562,Avg.Loss: 0.813,LR: 4.97E-04]Training epoch 5:  88%|████████▊ | 134/153 [00:02<00:00, 52.35it/s, Epoch: 5, Batch: 134,Loss: 0.562,Avg.Loss: 0.813,LR: 4.97E-04]Training epoch 5:  88%|████████▊ | 134/153 [00:02<00:00, 52.35it/s, Epoch: 5, Batch: 135,Loss: 0.608,Avg.Loss: 0.811,LR: 4.97E-04]Training epoch 5:  88%|████████▊ | 135/153 [00:02<00:00, 52.35it/s, Epoch: 5, Batch: 136,Loss: 0.592,Avg.Loss: 0.810,LR: 4.97E-04]Training epoch 5:  89%|████████▉ | 136/153 [00:02<00:00, 52.35it/s, Epoch: 5, Batch: 137,Loss: 0.403,Avg.Loss: 0.807,LR: 4.97E-04]Training epoch 5:  90%|████████▉ | 137/153 [00:02<00:00, 52.35it/s, Epoch: 5, Batch: 138,Loss: 0.291,Avg.Loss: 0.803,LR: 4.97E-04]Training epoch 5:  90%|█████████ | 138/153 [00:02<00:00, 52.35it/s, Epoch: 5, Batch: 139,Loss: 0.451,Avg.Loss: 0.801,LR: 4.97E-04]Training epoch 5:  91%|█████████ | 139/153 [00:02<00:00, 52.35it/s, Epoch: 5, Batch: 140,Loss: 0.398,Avg.Loss: 0.798,LR: 4.97E-04]Training epoch 5:  92%|█████████▏| 140/153 [00:02<00:00, 52.69it/s, Epoch: 5, Batch: 140,Loss: 0.398,Avg.Loss: 0.798,LR: 4.97E-04]Training epoch 5:  92%|█████████▏| 140/153 [00:02<00:00, 52.69it/s, Epoch: 5, Batch: 141,Loss: 0.409,Avg.Loss: 0.795,LR: 4.97E-04]Training epoch 5:  92%|█████████▏| 141/153 [00:02<00:00, 52.69it/s, Epoch: 5, Batch: 142,Loss: 0.671,Avg.Loss: 0.794,LR: 4.97E-04]Training epoch 5:  93%|█████████▎| 142/153 [00:02<00:00, 52.69it/s, Epoch: 5, Batch: 143,Loss: 0.628,Avg.Loss: 0.793,LR: 4.97E-04]Training epoch 5:  93%|█████████▎| 143/153 [00:02<00:00, 52.69it/s, Epoch: 5, Batch: 144,Loss: 1.184,Avg.Loss: 0.796,LR: 4.97E-04]Training epoch 5:  94%|█████████▍| 144/153 [00:02<00:00, 52.69it/s, Epoch: 5, Batch: 145,Loss: 0.299,Avg.Loss: 0.792,LR: 4.97E-04]Training epoch 5:  95%|█████████▍| 145/153 [00:02<00:00, 52.69it/s, Epoch: 5, Batch: 146,Loss: 0.841,Avg.Loss: 0.792,LR: 4.97E-04]Training epoch 5:  95%|█████████▌| 146/153 [00:02<00:00, 52.80it/s, Epoch: 5, Batch: 146,Loss: 0.841,Avg.Loss: 0.792,LR: 4.97E-04]Training epoch 5:  95%|█████████▌| 146/153 [00:02<00:00, 52.80it/s, Epoch: 5, Batch: 147,Loss: 0.581,Avg.Loss: 0.791,LR: 4.97E-04]Training epoch 5:  96%|█████████▌| 147/153 [00:02<00:00, 52.80it/s, Epoch: 5, Batch: 148,Loss: 0.663,Avg.Loss: 0.790,LR: 4.97E-04]Training epoch 5:  97%|█████████▋| 148/153 [00:02<00:00, 52.80it/s, Epoch: 5, Batch: 149,Loss: 0.731,Avg.Loss: 0.790,LR: 4.97E-04]Training epoch 5:  97%|█████████▋| 149/153 [00:02<00:00, 52.80it/s, Epoch: 5, Batch: 150,Loss: 1.112,Avg.Loss: 0.792,LR: 4.97E-04]Training epoch 5:  98%|█████████▊| 150/153 [00:02<00:00, 52.80it/s, Epoch: 5, Batch: 151,Loss: 0.578,Avg.Loss: 0.791,LR: 4.97E-04]Training epoch 5:  99%|█████████▊| 151/153 [00:02<00:00, 52.80it/s, Epoch: 5, Batch: 152,Loss: 0.717,Avg.Loss: 0.790,LR: 4.97E-04]Training epoch 5:  99%|█████████▉| 152/153 [00:02<00:00, 52.94it/s, Epoch: 5, Batch: 152,Loss: 0.717,Avg.Loss: 0.790,LR: 4.97E-04]Training epoch 5:  99%|█████████▉| 152/153 [00:02<00:00, 52.94it/s, Epoch: 5, Batch: 153,Loss: 1.908,Avg.Loss: 0.797,LR: 4.97E-04]Training epoch 5: 100%|██████████| 153/153 [00:02<00:00, 53.02it/s, Epoch: 5, Batch: 153,Loss: 1.908,Avg.Loss: 0.797,LR: 4.97E-04]
Training epoch 6:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 6:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 6, Batch: 1,Loss: 0.359,Avg.Loss: 0.359,LR: 4.97E-04]Training epoch 6:   1%|          | 1/153 [00:00<00:06, 25.19it/s, Epoch: 6, Batch: 2,Loss: 0.803,Avg.Loss: 0.581,LR: 4.97E-04]Training epoch 6:   1%|▏         | 2/153 [00:00<00:04, 34.31it/s, Epoch: 6, Batch: 3,Loss: 1.203,Avg.Loss: 0.789,LR: 4.97E-04]Training epoch 6:   2%|▏         | 3/153 [00:00<00:03, 40.94it/s, Epoch: 6, Batch: 4,Loss: 0.854,Avg.Loss: 0.805,LR: 4.97E-04]Training epoch 6:   3%|▎         | 4/153 [00:00<00:03, 45.40it/s, Epoch: 6, Batch: 5,Loss: 0.829,Avg.Loss: 0.810,LR: 4.97E-04]Training epoch 6:   3%|▎         | 5/153 [00:00<00:03, 47.11it/s, Epoch: 6, Batch: 6,Loss: 0.949,Avg.Loss: 0.833,LR: 4.97E-04]Training epoch 6:   4%|▍         | 6/153 [00:00<00:02, 56.44it/s, Epoch: 6, Batch: 6,Loss: 0.949,Avg.Loss: 0.833,LR: 4.97E-04]Training epoch 6:   4%|▍         | 6/153 [00:00<00:02, 56.44it/s, Epoch: 6, Batch: 7,Loss: 0.420,Avg.Loss: 0.774,LR: 4.97E-04]Training epoch 6:   5%|▍         | 7/153 [00:00<00:02, 56.44it/s, Epoch: 6, Batch: 8,Loss: 0.915,Avg.Loss: 0.791,LR: 4.97E-04]Training epoch 6:   5%|▌         | 8/153 [00:00<00:02, 56.44it/s, Epoch: 6, Batch: 9,Loss: 0.968,Avg.Loss: 0.811,LR: 4.97E-04]Training epoch 6:   6%|▌         | 9/153 [00:00<00:02, 56.44it/s, Epoch: 6, Batch: 10,Loss: 0.506,Avg.Loss: 0.781,LR: 4.97E-04]Training epoch 6:   7%|▋         | 10/153 [00:00<00:02, 56.44it/s, Epoch: 6, Batch: 11,Loss: 0.702,Avg.Loss: 0.773,LR: 4.97E-04]Training epoch 6:   7%|▋         | 11/153 [00:00<00:02, 56.44it/s, Epoch: 6, Batch: 12,Loss: 0.462,Avg.Loss: 0.747,LR: 4.97E-04]Training epoch 6:   8%|▊         | 12/153 [00:00<00:02, 54.02it/s, Epoch: 6, Batch: 12,Loss: 0.462,Avg.Loss: 0.747,LR: 4.97E-04]Training epoch 6:   8%|▊         | 12/153 [00:00<00:02, 54.02it/s, Epoch: 6, Batch: 13,Loss: 0.643,Avg.Loss: 0.739,LR: 4.97E-04]Training epoch 6:   8%|▊         | 13/153 [00:00<00:02, 54.02it/s, Epoch: 6, Batch: 14,Loss: 0.566,Avg.Loss: 0.727,LR: 4.97E-04]Training epoch 6:   9%|▉         | 14/153 [00:00<00:02, 54.02it/s, Epoch: 6, Batch: 15,Loss: 0.604,Avg.Loss: 0.719,LR: 4.97E-04]Training epoch 6:  10%|▉         | 15/153 [00:00<00:02, 54.02it/s, Epoch: 6, Batch: 16,Loss: 0.847,Avg.Loss: 0.727,LR: 4.97E-04]Training epoch 6:  10%|█         | 16/153 [00:00<00:02, 54.02it/s, Epoch: 6, Batch: 17,Loss: 0.568,Avg.Loss: 0.717,LR: 4.97E-04]Training epoch 6:  11%|█         | 17/153 [00:00<00:02, 54.02it/s, Epoch: 6, Batch: 18,Loss: 1.158,Avg.Loss: 0.742,LR: 4.97E-04]Training epoch 6:  12%|█▏        | 18/153 [00:00<00:02, 53.41it/s, Epoch: 6, Batch: 18,Loss: 1.158,Avg.Loss: 0.742,LR: 4.97E-04]Training epoch 6:  12%|█▏        | 18/153 [00:00<00:02, 53.41it/s, Epoch: 6, Batch: 19,Loss: 0.899,Avg.Loss: 0.750,LR: 4.97E-04]Training epoch 6:  12%|█▏        | 19/153 [00:00<00:02, 53.41it/s, Epoch: 6, Batch: 20,Loss: 0.465,Avg.Loss: 0.736,LR: 4.97E-04]Training epoch 6:  13%|█▎        | 20/153 [00:00<00:02, 53.41it/s, Epoch: 6, Batch: 21,Loss: 0.521,Avg.Loss: 0.726,LR: 4.97E-04]Training epoch 6:  14%|█▎        | 21/153 [00:00<00:02, 53.41it/s, Epoch: 6, Batch: 22,Loss: 0.818,Avg.Loss: 0.730,LR: 4.97E-04]Training epoch 6:  14%|█▍        | 22/153 [00:00<00:02, 53.41it/s, Epoch: 6, Batch: 23,Loss: 1.216,Avg.Loss: 0.751,LR: 4.97E-04]Training epoch 6:  15%|█▌        | 23/153 [00:00<00:02, 53.41it/s, Epoch: 6, Batch: 24,Loss: 1.153,Avg.Loss: 0.768,LR: 4.97E-04]Training epoch 6:  16%|█▌        | 24/153 [00:00<00:02, 51.29it/s, Epoch: 6, Batch: 24,Loss: 1.153,Avg.Loss: 0.768,LR: 4.97E-04]Training epoch 6:  16%|█▌        | 24/153 [00:00<00:02, 51.29it/s, Epoch: 6, Batch: 25,Loss: 0.488,Avg.Loss: 0.757,LR: 4.97E-04]Training epoch 6:  16%|█▋        | 25/153 [00:00<00:02, 51.29it/s, Epoch: 6, Batch: 26,Loss: 0.731,Avg.Loss: 0.756,LR: 4.97E-04]Training epoch 6:  17%|█▋        | 26/153 [00:00<00:02, 51.29it/s, Epoch: 6, Batch: 27,Loss: 0.836,Avg.Loss: 0.758,LR: 4.97E-04]Training epoch 6:  18%|█▊        | 27/153 [00:00<00:02, 51.29it/s, Epoch: 6, Batch: 28,Loss: 0.733,Avg.Loss: 0.758,LR: 4.97E-04]Training epoch 6:  18%|█▊        | 28/153 [00:00<00:02, 51.29it/s, Epoch: 6, Batch: 29,Loss: 0.444,Avg.Loss: 0.747,LR: 4.97E-04]Training epoch 6:  19%|█▉        | 29/153 [00:00<00:02, 51.29it/s, Epoch: 6, Batch: 30,Loss: 0.735,Avg.Loss: 0.746,LR: 4.97E-04]Training epoch 6:  20%|█▉        | 30/153 [00:00<00:02, 50.80it/s, Epoch: 6, Batch: 30,Loss: 0.735,Avg.Loss: 0.746,LR: 4.97E-04]Training epoch 6:  20%|█▉        | 30/153 [00:00<00:02, 50.80it/s, Epoch: 6, Batch: 31,Loss: 0.391,Avg.Loss: 0.735,LR: 4.97E-04]Training epoch 6:  20%|██        | 31/153 [00:00<00:02, 50.80it/s, Epoch: 6, Batch: 32,Loss: 0.646,Avg.Loss: 0.732,LR: 4.97E-04]Training epoch 6:  21%|██        | 32/153 [00:00<00:02, 50.80it/s, Epoch: 6, Batch: 33,Loss: 0.308,Avg.Loss: 0.719,LR: 4.97E-04]Training epoch 6:  22%|██▏       | 33/153 [00:00<00:02, 50.80it/s, Epoch: 6, Batch: 34,Loss: 0.493,Avg.Loss: 0.713,LR: 4.97E-04]Training epoch 6:  22%|██▏       | 34/153 [00:00<00:02, 50.80it/s, Epoch: 6, Batch: 35,Loss: 0.941,Avg.Loss: 0.719,LR: 4.97E-04]Training epoch 6:  23%|██▎       | 35/153 [00:00<00:02, 50.80it/s, Epoch: 6, Batch: 36,Loss: 0.668,Avg.Loss: 0.718,LR: 4.97E-04]Training epoch 6:  24%|██▎       | 36/153 [00:00<00:02, 51.18it/s, Epoch: 6, Batch: 36,Loss: 0.668,Avg.Loss: 0.718,LR: 4.97E-04]Training epoch 6:  24%|██▎       | 36/153 [00:00<00:02, 51.18it/s, Epoch: 6, Batch: 37,Loss: 1.004,Avg.Loss: 0.725,LR: 4.97E-04]Training epoch 6:  24%|██▍       | 37/153 [00:00<00:02, 51.18it/s, Epoch: 6, Batch: 38,Loss: 0.417,Avg.Loss: 0.717,LR: 4.97E-04]Training epoch 6:  25%|██▍       | 38/153 [00:00<00:02, 51.18it/s, Epoch: 6, Batch: 39,Loss: 0.737,Avg.Loss: 0.718,LR: 4.97E-04]Training epoch 6:  25%|██▌       | 39/153 [00:00<00:02, 51.18it/s, Epoch: 6, Batch: 40,Loss: 0.715,Avg.Loss: 0.718,LR: 4.97E-04]Training epoch 6:  26%|██▌       | 40/153 [00:00<00:02, 51.18it/s, Epoch: 6, Batch: 41,Loss: 0.656,Avg.Loss: 0.716,LR: 4.97E-04]Training epoch 6:  27%|██▋       | 41/153 [00:00<00:02, 51.18it/s, Epoch: 6, Batch: 42,Loss: 0.425,Avg.Loss: 0.709,LR: 4.97E-04]Training epoch 6:  27%|██▋       | 42/153 [00:00<00:02, 51.83it/s, Epoch: 6, Batch: 42,Loss: 0.425,Avg.Loss: 0.709,LR: 4.97E-04]Training epoch 6:  27%|██▋       | 42/153 [00:00<00:02, 51.83it/s, Epoch: 6, Batch: 43,Loss: 0.506,Avg.Loss: 0.705,LR: 4.97E-04]Training epoch 6:  28%|██▊       | 43/153 [00:00<00:02, 51.83it/s, Epoch: 6, Batch: 44,Loss: 0.644,Avg.Loss: 0.703,LR: 4.97E-04]Training epoch 6:  29%|██▉       | 44/153 [00:00<00:02, 51.83it/s, Epoch: 6, Batch: 45,Loss: 0.253,Avg.Loss: 0.693,LR: 4.97E-04]Training epoch 6:  29%|██▉       | 45/153 [00:00<00:02, 51.83it/s, Epoch: 6, Batch: 46,Loss: 0.546,Avg.Loss: 0.690,LR: 4.97E-04]Training epoch 6:  30%|███       | 46/153 [00:00<00:02, 51.83it/s, Epoch: 6, Batch: 47,Loss: 0.693,Avg.Loss: 0.690,LR: 4.97E-04]Training epoch 6:  31%|███       | 47/153 [00:00<00:02, 51.83it/s, Epoch: 6, Batch: 48,Loss: 0.806,Avg.Loss: 0.693,LR: 4.97E-04]Training epoch 6:  31%|███▏      | 48/153 [00:00<00:02, 52.14it/s, Epoch: 6, Batch: 48,Loss: 0.806,Avg.Loss: 0.693,LR: 4.97E-04]Training epoch 6:  31%|███▏      | 48/153 [00:00<00:02, 52.14it/s, Epoch: 6, Batch: 49,Loss: 0.450,Avg.Loss: 0.688,LR: 4.97E-04]Training epoch 6:  32%|███▏      | 49/153 [00:00<00:01, 52.14it/s, Epoch: 6, Batch: 50,Loss: 0.457,Avg.Loss: 0.683,LR: 4.97E-04]Training epoch 6:  33%|███▎      | 50/153 [00:00<00:01, 52.14it/s, Epoch: 6, Batch: 51,Loss: 0.579,Avg.Loss: 0.681,LR: 4.96E-04]Training epoch 6:  33%|███▎      | 51/153 [00:00<00:01, 52.14it/s, Epoch: 6, Batch: 52,Loss: 0.650,Avg.Loss: 0.680,LR: 4.96E-04]Training epoch 6:  34%|███▍      | 52/153 [00:01<00:01, 52.14it/s, Epoch: 6, Batch: 53,Loss: 0.297,Avg.Loss: 0.673,LR: 4.96E-04]Training epoch 6:  35%|███▍      | 53/153 [00:01<00:01, 52.14it/s, Epoch: 6, Batch: 54,Loss: 1.250,Avg.Loss: 0.684,LR: 4.96E-04]Training epoch 6:  35%|███▌      | 54/153 [00:01<00:01, 52.37it/s, Epoch: 6, Batch: 54,Loss: 1.250,Avg.Loss: 0.684,LR: 4.96E-04]Training epoch 6:  35%|███▌      | 54/153 [00:01<00:01, 52.37it/s, Epoch: 6, Batch: 55,Loss: 1.084,Avg.Loss: 0.691,LR: 4.96E-04]Training epoch 6:  36%|███▌      | 55/153 [00:01<00:01, 52.37it/s, Epoch: 6, Batch: 56,Loss: 0.714,Avg.Loss: 0.691,LR: 4.96E-04]Training epoch 6:  37%|███▋      | 56/153 [00:01<00:01, 52.37it/s, Epoch: 6, Batch: 57,Loss: 0.682,Avg.Loss: 0.691,LR: 4.96E-04]Training epoch 6:  37%|███▋      | 57/153 [00:01<00:01, 52.37it/s, Epoch: 6, Batch: 58,Loss: 1.055,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  38%|███▊      | 58/153 [00:01<00:01, 52.37it/s, Epoch: 6, Batch: 59,Loss: 0.959,Avg.Loss: 0.702,LR: 4.96E-04]Training epoch 6:  39%|███▊      | 59/153 [00:01<00:01, 52.37it/s, Epoch: 6, Batch: 60,Loss: 0.836,Avg.Loss: 0.704,LR: 4.96E-04]Training epoch 6:  39%|███▉      | 60/153 [00:01<00:01, 52.44it/s, Epoch: 6, Batch: 60,Loss: 0.836,Avg.Loss: 0.704,LR: 4.96E-04]Training epoch 6:  39%|███▉      | 60/153 [00:01<00:01, 52.44it/s, Epoch: 6, Batch: 61,Loss: 0.697,Avg.Loss: 0.704,LR: 4.96E-04]Training epoch 6:  40%|███▉      | 61/153 [00:01<00:01, 52.44it/s, Epoch: 6, Batch: 62,Loss: 0.613,Avg.Loss: 0.703,LR: 4.96E-04]Training epoch 6:  41%|████      | 62/153 [00:01<00:01, 52.44it/s, Epoch: 6, Batch: 63,Loss: 0.642,Avg.Loss: 0.702,LR: 4.96E-04]Training epoch 6:  41%|████      | 63/153 [00:01<00:01, 52.44it/s, Epoch: 6, Batch: 64,Loss: 1.009,Avg.Loss: 0.706,LR: 4.96E-04]Training epoch 6:  42%|████▏     | 64/153 [00:01<00:01, 52.44it/s, Epoch: 6, Batch: 65,Loss: 0.297,Avg.Loss: 0.700,LR: 4.96E-04]Training epoch 6:  42%|████▏     | 65/153 [00:01<00:01, 52.44it/s, Epoch: 6, Batch: 66,Loss: 0.456,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  43%|████▎     | 66/153 [00:01<00:01, 52.72it/s, Epoch: 6, Batch: 66,Loss: 0.456,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  43%|████▎     | 66/153 [00:01<00:01, 52.72it/s, Epoch: 6, Batch: 67,Loss: 0.614,Avg.Loss: 0.695,LR: 4.96E-04]Training epoch 6:  44%|████▍     | 67/153 [00:01<00:01, 52.72it/s, Epoch: 6, Batch: 68,Loss: 0.670,Avg.Loss: 0.695,LR: 4.96E-04]Training epoch 6:  44%|████▍     | 68/153 [00:01<00:01, 52.72it/s, Epoch: 6, Batch: 69,Loss: 0.601,Avg.Loss: 0.694,LR: 4.96E-04]Training epoch 6:  45%|████▌     | 69/153 [00:01<00:01, 52.72it/s, Epoch: 6, Batch: 70,Loss: 0.422,Avg.Loss: 0.690,LR: 4.96E-04]Training epoch 6:  46%|████▌     | 70/153 [00:01<00:01, 52.72it/s, Epoch: 6, Batch: 71,Loss: 0.729,Avg.Loss: 0.690,LR: 4.96E-04]Training epoch 6:  46%|████▋     | 71/153 [00:01<00:01, 52.72it/s, Epoch: 6, Batch: 72,Loss: 0.780,Avg.Loss: 0.691,LR: 4.96E-04]Training epoch 6:  47%|████▋     | 72/153 [00:01<00:01, 52.86it/s, Epoch: 6, Batch: 72,Loss: 0.780,Avg.Loss: 0.691,LR: 4.96E-04]Training epoch 6:  47%|████▋     | 72/153 [00:01<00:01, 52.86it/s, Epoch: 6, Batch: 73,Loss: 0.535,Avg.Loss: 0.689,LR: 4.96E-04]Training epoch 6:  48%|████▊     | 73/153 [00:01<00:01, 52.86it/s, Epoch: 6, Batch: 74,Loss: 0.793,Avg.Loss: 0.691,LR: 4.96E-04]Training epoch 6:  48%|████▊     | 74/153 [00:01<00:01, 52.86it/s, Epoch: 6, Batch: 75,Loss: 0.683,Avg.Loss: 0.691,LR: 4.96E-04]Training epoch 6:  49%|████▉     | 75/153 [00:01<00:01, 52.86it/s, Epoch: 6, Batch: 76,Loss: 0.971,Avg.Loss: 0.694,LR: 4.96E-04]Training epoch 6:  50%|████▉     | 76/153 [00:01<00:01, 52.86it/s, Epoch: 6, Batch: 77,Loss: 0.717,Avg.Loss: 0.695,LR: 4.96E-04]Training epoch 6:  50%|█████     | 77/153 [00:01<00:01, 52.86it/s, Epoch: 6, Batch: 78,Loss: 0.617,Avg.Loss: 0.694,LR: 4.96E-04]Training epoch 6:  51%|█████     | 78/153 [00:01<00:01, 52.93it/s, Epoch: 6, Batch: 78,Loss: 0.617,Avg.Loss: 0.694,LR: 4.96E-04]Training epoch 6:  51%|█████     | 78/153 [00:01<00:01, 52.93it/s, Epoch: 6, Batch: 79,Loss: 0.970,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  52%|█████▏    | 79/153 [00:01<00:01, 52.93it/s, Epoch: 6, Batch: 80,Loss: 0.744,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  52%|█████▏    | 80/153 [00:01<00:01, 52.93it/s, Epoch: 6, Batch: 81,Loss: 0.748,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  53%|█████▎    | 81/153 [00:01<00:01, 52.93it/s, Epoch: 6, Batch: 82,Loss: 0.452,Avg.Loss: 0.695,LR: 4.96E-04]Training epoch 6:  54%|█████▎    | 82/153 [00:01<00:01, 52.93it/s, Epoch: 6, Batch: 83,Loss: 0.530,Avg.Loss: 0.693,LR: 4.96E-04]Training epoch 6:  54%|█████▍    | 83/153 [00:01<00:01, 52.93it/s, Epoch: 6, Batch: 84,Loss: 0.603,Avg.Loss: 0.692,LR: 4.96E-04]Training epoch 6:  55%|█████▍    | 84/153 [00:01<00:01, 53.00it/s, Epoch: 6, Batch: 84,Loss: 0.603,Avg.Loss: 0.692,LR: 4.96E-04]Training epoch 6:  55%|█████▍    | 84/153 [00:01<00:01, 53.00it/s, Epoch: 6, Batch: 85,Loss: 0.731,Avg.Loss: 0.693,LR: 4.96E-04]Training epoch 6:  56%|█████▌    | 85/153 [00:01<00:01, 53.00it/s, Epoch: 6, Batch: 86,Loss: 0.613,Avg.Loss: 0.692,LR: 4.96E-04]Training epoch 6:  56%|█████▌    | 86/153 [00:01<00:01, 53.00it/s, Epoch: 6, Batch: 87,Loss: 0.970,Avg.Loss: 0.695,LR: 4.96E-04]Training epoch 6:  57%|█████▋    | 87/153 [00:01<00:01, 53.00it/s, Epoch: 6, Batch: 88,Loss: 1.000,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  58%|█████▊    | 88/153 [00:01<00:01, 53.00it/s, Epoch: 6, Batch: 89,Loss: 1.384,Avg.Loss: 0.706,LR: 4.96E-04]Training epoch 6:  58%|█████▊    | 89/153 [00:01<00:01, 53.00it/s, Epoch: 6, Batch: 90,Loss: 0.953,Avg.Loss: 0.709,LR: 4.96E-04]Training epoch 6:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 6, Batch: 90,Loss: 0.953,Avg.Loss: 0.709,LR: 4.96E-04]Training epoch 6:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 6, Batch: 91,Loss: 0.929,Avg.Loss: 0.711,LR: 4.96E-04]Training epoch 6:  59%|█████▉    | 91/153 [00:01<00:01, 53.06it/s, Epoch: 6, Batch: 92,Loss: 0.800,Avg.Loss: 0.712,LR: 4.96E-04]Training epoch 6:  60%|██████    | 92/153 [00:01<00:01, 53.06it/s, Epoch: 6, Batch: 93,Loss: 0.615,Avg.Loss: 0.711,LR: 4.96E-04]Training epoch 6:  61%|██████    | 93/153 [00:01<00:01, 53.06it/s, Epoch: 6, Batch: 94,Loss: 0.501,Avg.Loss: 0.709,LR: 4.96E-04]Training epoch 6:  61%|██████▏   | 94/153 [00:01<00:01, 53.06it/s, Epoch: 6, Batch: 95,Loss: 0.656,Avg.Loss: 0.708,LR: 4.96E-04]Training epoch 6:  62%|██████▏   | 95/153 [00:01<00:01, 53.06it/s, Epoch: 6, Batch: 96,Loss: 0.833,Avg.Loss: 0.710,LR: 4.96E-04]Training epoch 6:  63%|██████▎   | 96/153 [00:01<00:01, 53.12it/s, Epoch: 6, Batch: 96,Loss: 0.833,Avg.Loss: 0.710,LR: 4.96E-04]Training epoch 6:  63%|██████▎   | 96/153 [00:01<00:01, 53.12it/s, Epoch: 6, Batch: 97,Loss: 0.316,Avg.Loss: 0.706,LR: 4.96E-04]Training epoch 6:  63%|██████▎   | 97/153 [00:01<00:01, 53.12it/s, Epoch: 6, Batch: 98,Loss: 0.749,Avg.Loss: 0.706,LR: 4.96E-04]Training epoch 6:  64%|██████▍   | 98/153 [00:01<00:01, 53.12it/s, Epoch: 6, Batch: 99,Loss: 0.295,Avg.Loss: 0.702,LR: 4.96E-04]Training epoch 6:  65%|██████▍   | 99/153 [00:01<00:01, 53.12it/s, Epoch: 6, Batch: 100,Loss: 0.646,Avg.Loss: 0.701,LR: 4.96E-04]Training epoch 6:  65%|██████▌   | 100/153 [00:01<00:00, 53.12it/s, Epoch: 6, Batch: 101,Loss: 0.392,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  66%|██████▌   | 101/153 [00:01<00:00, 53.12it/s, Epoch: 6, Batch: 102,Loss: 0.489,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  67%|██████▋   | 102/153 [00:01<00:00, 52.75it/s, Epoch: 6, Batch: 102,Loss: 0.489,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  67%|██████▋   | 102/153 [00:01<00:00, 52.75it/s, Epoch: 6, Batch: 103,Loss: 0.690,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  67%|██████▋   | 103/153 [00:01<00:00, 52.75it/s, Epoch: 6, Batch: 104,Loss: 1.044,Avg.Loss: 0.700,LR: 4.96E-04]Training epoch 6:  68%|██████▊   | 104/153 [00:01<00:00, 52.75it/s, Epoch: 6, Batch: 105,Loss: 0.816,Avg.Loss: 0.701,LR: 4.96E-04]Training epoch 6:  69%|██████▊   | 105/153 [00:02<00:00, 52.75it/s, Epoch: 6, Batch: 106,Loss: 0.649,Avg.Loss: 0.700,LR: 4.96E-04]Training epoch 6:  69%|██████▉   | 106/153 [00:02<00:00, 52.75it/s, Epoch: 6, Batch: 107,Loss: 0.728,Avg.Loss: 0.700,LR: 4.96E-04]Training epoch 6:  70%|██████▉   | 107/153 [00:02<00:00, 52.75it/s, Epoch: 6, Batch: 108,Loss: 0.623,Avg.Loss: 0.700,LR: 4.96E-04]Training epoch 6:  71%|███████   | 108/153 [00:02<00:00, 52.88it/s, Epoch: 6, Batch: 108,Loss: 0.623,Avg.Loss: 0.700,LR: 4.96E-04]Training epoch 6:  71%|███████   | 108/153 [00:02<00:00, 52.88it/s, Epoch: 6, Batch: 109,Loss: 0.879,Avg.Loss: 0.701,LR: 4.96E-04]Training epoch 6:  71%|███████   | 109/153 [00:02<00:00, 52.88it/s, Epoch: 6, Batch: 110,Loss: 0.937,Avg.Loss: 0.703,LR: 4.96E-04]Training epoch 6:  72%|███████▏  | 110/153 [00:02<00:00, 52.88it/s, Epoch: 6, Batch: 111,Loss: 0.515,Avg.Loss: 0.702,LR: 4.96E-04]Training epoch 6:  73%|███████▎  | 111/153 [00:02<00:00, 52.88it/s, Epoch: 6, Batch: 112,Loss: 0.471,Avg.Loss: 0.700,LR: 4.96E-04]Training epoch 6:  73%|███████▎  | 112/153 [00:02<00:00, 52.88it/s, Epoch: 6, Batch: 113,Loss: 0.502,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  74%|███████▍  | 113/153 [00:02<00:00, 52.88it/s, Epoch: 6, Batch: 114,Loss: 0.799,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  75%|███████▍  | 114/153 [00:02<00:00, 52.82it/s, Epoch: 6, Batch: 114,Loss: 0.799,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  75%|███████▍  | 114/153 [00:02<00:00, 52.82it/s, Epoch: 6, Batch: 115,Loss: 0.598,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  75%|███████▌  | 115/153 [00:02<00:00, 52.82it/s, Epoch: 6, Batch: 116,Loss: 1.154,Avg.Loss: 0.702,LR: 4.96E-04]Training epoch 6:  76%|███████▌  | 116/153 [00:02<00:00, 52.82it/s, Epoch: 6, Batch: 117,Loss: 0.457,Avg.Loss: 0.700,LR: 4.96E-04]Training epoch 6:  76%|███████▋  | 117/153 [00:02<00:00, 52.82it/s, Epoch: 6, Batch: 118,Loss: 0.462,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  77%|███████▋  | 118/153 [00:02<00:00, 52.82it/s, Epoch: 6, Batch: 119,Loss: 0.613,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  78%|███████▊  | 119/153 [00:02<00:00, 52.82it/s, Epoch: 6, Batch: 120,Loss: 0.706,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  78%|███████▊  | 120/153 [00:02<00:00, 52.80it/s, Epoch: 6, Batch: 120,Loss: 0.706,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  78%|███████▊  | 120/153 [00:02<00:00, 52.80it/s, Epoch: 6, Batch: 121,Loss: 0.751,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  79%|███████▉  | 121/153 [00:02<00:00, 52.80it/s, Epoch: 6, Batch: 122,Loss: 0.822,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  80%|███████▉  | 122/153 [00:02<00:00, 52.80it/s, Epoch: 6, Batch: 123,Loss: 0.735,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  80%|████████  | 123/153 [00:02<00:00, 52.80it/s, Epoch: 6, Batch: 124,Loss: 0.461,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  81%|████████  | 124/153 [00:02<00:00, 52.80it/s, Epoch: 6, Batch: 125,Loss: 0.550,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  82%|████████▏ | 125/153 [00:02<00:00, 52.80it/s, Epoch: 6, Batch: 126,Loss: 0.693,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  82%|████████▏ | 126/153 [00:02<00:00, 52.55it/s, Epoch: 6, Batch: 126,Loss: 0.693,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  82%|████████▏ | 126/153 [00:02<00:00, 52.55it/s, Epoch: 6, Batch: 127,Loss: 0.392,Avg.Loss: 0.693,LR: 4.96E-04]Training epoch 6:  83%|████████▎ | 127/153 [00:02<00:00, 52.55it/s, Epoch: 6, Batch: 128,Loss: 0.744,Avg.Loss: 0.694,LR: 4.96E-04]Training epoch 6:  84%|████████▎ | 128/153 [00:02<00:00, 52.55it/s, Epoch: 6, Batch: 129,Loss: 0.700,Avg.Loss: 0.694,LR: 4.96E-04]Training epoch 6:  84%|████████▍ | 129/153 [00:02<00:00, 52.55it/s, Epoch: 6, Batch: 130,Loss: 1.056,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  85%|████████▍ | 130/153 [00:02<00:00, 52.55it/s, Epoch: 6, Batch: 131,Loss: 0.970,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  86%|████████▌ | 131/153 [00:02<00:00, 52.55it/s, Epoch: 6, Batch: 132,Loss: 0.730,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  86%|████████▋ | 132/153 [00:02<00:00, 52.76it/s, Epoch: 6, Batch: 132,Loss: 0.730,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  86%|████████▋ | 132/153 [00:02<00:00, 52.76it/s, Epoch: 6, Batch: 133,Loss: 0.718,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  87%|████████▋ | 133/153 [00:02<00:00, 52.76it/s, Epoch: 6, Batch: 134,Loss: 0.689,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  88%|████████▊ | 134/153 [00:02<00:00, 52.76it/s, Epoch: 6, Batch: 135,Loss: 0.695,Avg.Loss: 0.699,LR: 4.96E-04]Training epoch 6:  88%|████████▊ | 135/153 [00:02<00:00, 52.76it/s, Epoch: 6, Batch: 136,Loss: 0.549,Avg.Loss: 0.698,LR: 4.96E-04]Training epoch 6:  89%|████████▉ | 136/153 [00:02<00:00, 52.76it/s, Epoch: 6, Batch: 137,Loss: 0.533,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  90%|████████▉ | 137/153 [00:02<00:00, 52.76it/s, Epoch: 6, Batch: 138,Loss: 0.762,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  90%|█████████ | 138/153 [00:02<00:00, 52.69it/s, Epoch: 6, Batch: 138,Loss: 0.762,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  90%|█████████ | 138/153 [00:02<00:00, 52.69it/s, Epoch: 6, Batch: 139,Loss: 0.707,Avg.Loss: 0.697,LR: 4.96E-04]Training epoch 6:  91%|█████████ | 139/153 [00:02<00:00, 52.69it/s, Epoch: 6, Batch: 140,Loss: 0.400,Avg.Loss: 0.695,LR: 4.96E-04]Training epoch 6:  92%|█████████▏| 140/153 [00:02<00:00, 52.69it/s, Epoch: 6, Batch: 141,Loss: 0.822,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  92%|█████████▏| 141/153 [00:02<00:00, 52.69it/s, Epoch: 6, Batch: 142,Loss: 0.687,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  93%|█████████▎| 142/153 [00:02<00:00, 52.69it/s, Epoch: 6, Batch: 143,Loss: 0.754,Avg.Loss: 0.696,LR: 4.96E-04]Training epoch 6:  93%|█████████▎| 143/153 [00:02<00:00, 52.69it/s, Epoch: 6, Batch: 144,Loss: 0.564,Avg.Loss: 0.695,LR: 4.96E-04]Training epoch 6:  94%|█████████▍| 144/153 [00:02<00:00, 52.66it/s, Epoch: 6, Batch: 144,Loss: 0.564,Avg.Loss: 0.695,LR: 4.96E-04]Training epoch 6:  94%|█████████▍| 144/153 [00:02<00:00, 52.66it/s, Epoch: 6, Batch: 145,Loss: 0.409,Avg.Loss: 0.693,LR: 4.96E-04]Training epoch 6:  95%|█████████▍| 145/153 [00:02<00:00, 52.66it/s, Epoch: 6, Batch: 146,Loss: 0.267,Avg.Loss: 0.691,LR: 4.96E-04]Training epoch 6:  95%|█████████▌| 146/153 [00:02<00:00, 52.66it/s, Epoch: 6, Batch: 147,Loss: 0.348,Avg.Loss: 0.688,LR: 4.96E-04]Training epoch 6:  96%|█████████▌| 147/153 [00:02<00:00, 52.66it/s, Epoch: 6, Batch: 148,Loss: 0.621,Avg.Loss: 0.688,LR: 4.96E-04]Training epoch 6:  97%|█████████▋| 148/153 [00:02<00:00, 52.66it/s, Epoch: 6, Batch: 149,Loss: 0.370,Avg.Loss: 0.686,LR: 4.96E-04]Training epoch 6:  97%|█████████▋| 149/153 [00:02<00:00, 52.66it/s, Epoch: 6, Batch: 150,Loss: 0.126,Avg.Loss: 0.682,LR: 4.96E-04]Training epoch 6:  98%|█████████▊| 150/153 [00:02<00:00, 52.64it/s, Epoch: 6, Batch: 150,Loss: 0.126,Avg.Loss: 0.682,LR: 4.96E-04]Training epoch 6:  98%|█████████▊| 150/153 [00:02<00:00, 52.64it/s, Epoch: 6, Batch: 151,Loss: 0.508,Avg.Loss: 0.681,LR: 4.96E-04]Training epoch 6:  99%|█████████▊| 151/153 [00:02<00:00, 52.64it/s, Epoch: 6, Batch: 152,Loss: 0.704,Avg.Loss: 0.681,LR: 4.96E-04]Training epoch 6:  99%|█████████▉| 152/153 [00:02<00:00, 52.64it/s, Epoch: 6, Batch: 153,Loss: 1.029,Avg.Loss: 0.683,LR: 4.96E-04]Training epoch 6: 100%|██████████| 153/153 [00:02<00:00, 52.53it/s, Epoch: 6, Batch: 153,Loss: 1.029,Avg.Loss: 0.683,LR: 4.96E-04]
Training epoch 7:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 7:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 7, Batch: 1,Loss: 0.453,Avg.Loss: 0.453,LR: 4.96E-04]Training epoch 7:   1%|          | 1/153 [00:00<00:06, 24.90it/s, Epoch: 7, Batch: 2,Loss: 1.105,Avg.Loss: 0.779,LR: 4.96E-04]Training epoch 7:   1%|▏         | 2/153 [00:00<00:04, 33.94it/s, Epoch: 7, Batch: 3,Loss: 1.570,Avg.Loss: 1.043,LR: 4.96E-04]Training epoch 7:   2%|▏         | 3/153 [00:00<00:03, 39.46it/s, Epoch: 7, Batch: 4,Loss: 0.982,Avg.Loss: 1.028,LR: 4.96E-04]Training epoch 7:   3%|▎         | 4/153 [00:00<00:03, 42.91it/s, Epoch: 7, Batch: 5,Loss: 0.448,Avg.Loss: 0.912,LR: 4.96E-04]Training epoch 7:   3%|▎         | 5/153 [00:00<00:03, 44.95it/s, Epoch: 7, Batch: 6,Loss: 0.495,Avg.Loss: 0.842,LR: 4.96E-04]Training epoch 7:   4%|▍         | 6/153 [00:00<00:02, 53.84it/s, Epoch: 7, Batch: 6,Loss: 0.495,Avg.Loss: 0.842,LR: 4.96E-04]Training epoch 7:   4%|▍         | 6/153 [00:00<00:02, 53.84it/s, Epoch: 7, Batch: 7,Loss: 0.671,Avg.Loss: 0.818,LR: 4.96E-04]Training epoch 7:   5%|▍         | 7/153 [00:00<00:02, 53.84it/s, Epoch: 7, Batch: 8,Loss: 0.653,Avg.Loss: 0.797,LR: 4.95E-04]Training epoch 7:   5%|▌         | 8/153 [00:00<00:02, 53.84it/s, Epoch: 7, Batch: 9,Loss: 0.647,Avg.Loss: 0.780,LR: 4.95E-04]Training epoch 7:   6%|▌         | 9/153 [00:00<00:02, 53.84it/s, Epoch: 7, Batch: 10,Loss: 0.898,Avg.Loss: 0.792,LR: 4.95E-04]Training epoch 7:   7%|▋         | 10/153 [00:00<00:02, 53.84it/s, Epoch: 7, Batch: 11,Loss: 0.606,Avg.Loss: 0.775,LR: 4.95E-04]Training epoch 7:   7%|▋         | 11/153 [00:00<00:02, 53.84it/s, Epoch: 7, Batch: 12,Loss: 0.699,Avg.Loss: 0.769,LR: 4.95E-04]Training epoch 7:   8%|▊         | 12/153 [00:00<00:02, 53.22it/s, Epoch: 7, Batch: 12,Loss: 0.699,Avg.Loss: 0.769,LR: 4.95E-04]Training epoch 7:   8%|▊         | 12/153 [00:00<00:02, 53.22it/s, Epoch: 7, Batch: 13,Loss: 0.497,Avg.Loss: 0.748,LR: 4.95E-04]Training epoch 7:   8%|▊         | 13/153 [00:00<00:02, 53.22it/s, Epoch: 7, Batch: 14,Loss: 0.373,Avg.Loss: 0.721,LR: 4.95E-04]Training epoch 7:   9%|▉         | 14/153 [00:00<00:02, 53.22it/s, Epoch: 7, Batch: 15,Loss: 0.237,Avg.Loss: 0.689,LR: 4.95E-04]Training epoch 7:  10%|▉         | 15/153 [00:00<00:02, 53.22it/s, Epoch: 7, Batch: 16,Loss: 0.538,Avg.Loss: 0.680,LR: 4.95E-04]Training epoch 7:  10%|█         | 16/153 [00:00<00:02, 53.22it/s, Epoch: 7, Batch: 17,Loss: 0.440,Avg.Loss: 0.665,LR: 4.95E-04]Training epoch 7:  11%|█         | 17/153 [00:00<00:02, 53.22it/s, Epoch: 7, Batch: 18,Loss: 0.491,Avg.Loss: 0.656,LR: 4.95E-04]Training epoch 7:  12%|█▏        | 18/153 [00:00<00:02, 53.02it/s, Epoch: 7, Batch: 18,Loss: 0.491,Avg.Loss: 0.656,LR: 4.95E-04]Training epoch 7:  12%|█▏        | 18/153 [00:00<00:02, 53.02it/s, Epoch: 7, Batch: 19,Loss: 0.467,Avg.Loss: 0.646,LR: 4.95E-04]Training epoch 7:  12%|█▏        | 19/153 [00:00<00:02, 53.02it/s, Epoch: 7, Batch: 20,Loss: 0.384,Avg.Loss: 0.633,LR: 4.95E-04]Training epoch 7:  13%|█▎        | 20/153 [00:00<00:02, 53.02it/s, Epoch: 7, Batch: 21,Loss: 0.612,Avg.Loss: 0.632,LR: 4.95E-04]Training epoch 7:  14%|█▎        | 21/153 [00:00<00:02, 53.02it/s, Epoch: 7, Batch: 22,Loss: 0.637,Avg.Loss: 0.632,LR: 4.95E-04]Training epoch 7:  14%|█▍        | 22/153 [00:00<00:02, 53.02it/s, Epoch: 7, Batch: 23,Loss: 0.751,Avg.Loss: 0.637,LR: 4.95E-04]Training epoch 7:  15%|█▌        | 23/153 [00:00<00:02, 53.02it/s, Epoch: 7, Batch: 24,Loss: 0.431,Avg.Loss: 0.629,LR: 4.95E-04]Training epoch 7:  16%|█▌        | 24/153 [00:00<00:02, 50.81it/s, Epoch: 7, Batch: 24,Loss: 0.431,Avg.Loss: 0.629,LR: 4.95E-04]Training epoch 7:  16%|█▌        | 24/153 [00:00<00:02, 50.81it/s, Epoch: 7, Batch: 25,Loss: 0.526,Avg.Loss: 0.624,LR: 4.95E-04]Training epoch 7:  16%|█▋        | 25/153 [00:00<00:02, 50.81it/s, Epoch: 7, Batch: 26,Loss: 0.870,Avg.Loss: 0.634,LR: 4.95E-04]Training epoch 7:  17%|█▋        | 26/153 [00:00<00:02, 50.81it/s, Epoch: 7, Batch: 27,Loss: 1.171,Avg.Loss: 0.654,LR: 4.95E-04]Training epoch 7:  18%|█▊        | 27/153 [00:00<00:02, 50.81it/s, Epoch: 7, Batch: 28,Loss: 0.975,Avg.Loss: 0.665,LR: 4.95E-04]Training epoch 7:  18%|█▊        | 28/153 [00:00<00:02, 50.81it/s, Epoch: 7, Batch: 29,Loss: 0.698,Avg.Loss: 0.666,LR: 4.95E-04]Training epoch 7:  19%|█▉        | 29/153 [00:00<00:02, 50.81it/s, Epoch: 7, Batch: 30,Loss: 0.448,Avg.Loss: 0.659,LR: 4.95E-04]Training epoch 7:  20%|█▉        | 30/153 [00:00<00:02, 50.94it/s, Epoch: 7, Batch: 30,Loss: 0.448,Avg.Loss: 0.659,LR: 4.95E-04]Training epoch 7:  20%|█▉        | 30/153 [00:00<00:02, 50.94it/s, Epoch: 7, Batch: 31,Loss: 0.477,Avg.Loss: 0.653,LR: 4.95E-04]Training epoch 7:  20%|██        | 31/153 [00:00<00:02, 50.94it/s, Epoch: 7, Batch: 32,Loss: 0.271,Avg.Loss: 0.641,LR: 4.95E-04]Training epoch 7:  21%|██        | 32/153 [00:00<00:02, 50.94it/s, Epoch: 7, Batch: 33,Loss: 0.348,Avg.Loss: 0.632,LR: 4.95E-04]Training epoch 7:  22%|██▏       | 33/153 [00:00<00:02, 50.94it/s, Epoch: 7, Batch: 34,Loss: 0.510,Avg.Loss: 0.629,LR: 4.95E-04]Training epoch 7:  22%|██▏       | 34/153 [00:00<00:02, 50.94it/s, Epoch: 7, Batch: 35,Loss: 0.659,Avg.Loss: 0.630,LR: 4.95E-04]Training epoch 7:  23%|██▎       | 35/153 [00:00<00:02, 50.94it/s, Epoch: 7, Batch: 36,Loss: 0.467,Avg.Loss: 0.625,LR: 4.95E-04]Training epoch 7:  24%|██▎       | 36/153 [00:00<00:02, 51.57it/s, Epoch: 7, Batch: 36,Loss: 0.467,Avg.Loss: 0.625,LR: 4.95E-04]Training epoch 7:  24%|██▎       | 36/153 [00:00<00:02, 51.57it/s, Epoch: 7, Batch: 37,Loss: 0.298,Avg.Loss: 0.616,LR: 4.95E-04]Training epoch 7:  24%|██▍       | 37/153 [00:00<00:02, 51.57it/s, Epoch: 7, Batch: 38,Loss: 0.388,Avg.Loss: 0.610,LR: 4.95E-04]Training epoch 7:  25%|██▍       | 38/153 [00:00<00:02, 51.57it/s, Epoch: 7, Batch: 39,Loss: 0.557,Avg.Loss: 0.609,LR: 4.95E-04]Training epoch 7:  25%|██▌       | 39/153 [00:00<00:02, 51.57it/s, Epoch: 7, Batch: 40,Loss: 0.542,Avg.Loss: 0.607,LR: 4.95E-04]Training epoch 7:  26%|██▌       | 40/153 [00:00<00:02, 51.57it/s, Epoch: 7, Batch: 41,Loss: 0.776,Avg.Loss: 0.611,LR: 4.95E-04]Training epoch 7:  27%|██▋       | 41/153 [00:00<00:02, 51.57it/s, Epoch: 7, Batch: 42,Loss: 0.305,Avg.Loss: 0.604,LR: 4.95E-04]Training epoch 7:  27%|██▋       | 42/153 [00:00<00:02, 51.97it/s, Epoch: 7, Batch: 42,Loss: 0.305,Avg.Loss: 0.604,LR: 4.95E-04]Training epoch 7:  27%|██▋       | 42/153 [00:00<00:02, 51.97it/s, Epoch: 7, Batch: 43,Loss: 0.447,Avg.Loss: 0.600,LR: 4.95E-04]Training epoch 7:  28%|██▊       | 43/153 [00:00<00:02, 51.97it/s, Epoch: 7, Batch: 44,Loss: 0.356,Avg.Loss: 0.595,LR: 4.95E-04]Training epoch 7:  29%|██▉       | 44/153 [00:00<00:02, 51.97it/s, Epoch: 7, Batch: 45,Loss: 0.471,Avg.Loss: 0.592,LR: 4.95E-04]Training epoch 7:  29%|██▉       | 45/153 [00:00<00:02, 51.97it/s, Epoch: 7, Batch: 46,Loss: 0.068,Avg.Loss: 0.581,LR: 4.95E-04]Training epoch 7:  30%|███       | 46/153 [00:00<00:02, 51.97it/s, Epoch: 7, Batch: 47,Loss: 0.727,Avg.Loss: 0.584,LR: 4.95E-04]Training epoch 7:  31%|███       | 47/153 [00:00<00:02, 51.97it/s, Epoch: 7, Batch: 48,Loss: 0.383,Avg.Loss: 0.580,LR: 4.95E-04]Training epoch 7:  31%|███▏      | 48/153 [00:00<00:02, 51.87it/s, Epoch: 7, Batch: 48,Loss: 0.383,Avg.Loss: 0.580,LR: 4.95E-04]Training epoch 7:  31%|███▏      | 48/153 [00:00<00:02, 51.87it/s, Epoch: 7, Batch: 49,Loss: 0.475,Avg.Loss: 0.578,LR: 4.95E-04]Training epoch 7:  32%|███▏      | 49/153 [00:00<00:02, 51.87it/s, Epoch: 7, Batch: 50,Loss: 0.683,Avg.Loss: 0.580,LR: 4.95E-04]Training epoch 7:  33%|███▎      | 50/153 [00:00<00:01, 51.87it/s, Epoch: 7, Batch: 51,Loss: 0.555,Avg.Loss: 0.579,LR: 4.95E-04]Training epoch 7:  33%|███▎      | 51/153 [00:01<00:01, 51.87it/s, Epoch: 7, Batch: 52,Loss: 0.662,Avg.Loss: 0.581,LR: 4.95E-04]Training epoch 7:  34%|███▍      | 52/153 [00:01<00:01, 51.87it/s, Epoch: 7, Batch: 53,Loss: 0.326,Avg.Loss: 0.576,LR: 4.95E-04]Training epoch 7:  35%|███▍      | 53/153 [00:01<00:01, 51.87it/s, Epoch: 7, Batch: 54,Loss: 0.667,Avg.Loss: 0.578,LR: 4.95E-04]Training epoch 7:  35%|███▌      | 54/153 [00:01<00:01, 52.17it/s, Epoch: 7, Batch: 54,Loss: 0.667,Avg.Loss: 0.578,LR: 4.95E-04]Training epoch 7:  35%|███▌      | 54/153 [00:01<00:01, 52.17it/s, Epoch: 7, Batch: 55,Loss: 0.198,Avg.Loss: 0.571,LR: 4.95E-04]Training epoch 7:  36%|███▌      | 55/153 [00:01<00:01, 52.17it/s, Epoch: 7, Batch: 56,Loss: 0.309,Avg.Loss: 0.566,LR: 4.95E-04]Training epoch 7:  37%|███▋      | 56/153 [00:01<00:01, 52.17it/s, Epoch: 7, Batch: 57,Loss: 0.696,Avg.Loss: 0.568,LR: 4.95E-04]Training epoch 7:  37%|███▋      | 57/153 [00:01<00:01, 52.17it/s, Epoch: 7, Batch: 58,Loss: 0.645,Avg.Loss: 0.570,LR: 4.95E-04]Training epoch 7:  38%|███▊      | 58/153 [00:01<00:01, 52.17it/s, Epoch: 7, Batch: 59,Loss: 0.303,Avg.Loss: 0.565,LR: 4.95E-04]Training epoch 7:  39%|███▊      | 59/153 [00:01<00:01, 52.17it/s, Epoch: 7, Batch: 60,Loss: 0.287,Avg.Loss: 0.560,LR: 4.95E-04]Training epoch 7:  39%|███▉      | 60/153 [00:01<00:01, 52.51it/s, Epoch: 7, Batch: 60,Loss: 0.287,Avg.Loss: 0.560,LR: 4.95E-04]Training epoch 7:  39%|███▉      | 60/153 [00:01<00:01, 52.51it/s, Epoch: 7, Batch: 61,Loss: 0.718,Avg.Loss: 0.563,LR: 4.95E-04]Training epoch 7:  40%|███▉      | 61/153 [00:01<00:01, 52.51it/s, Epoch: 7, Batch: 62,Loss: 0.454,Avg.Loss: 0.561,LR: 4.95E-04]Training epoch 7:  41%|████      | 62/153 [00:01<00:01, 52.51it/s, Epoch: 7, Batch: 63,Loss: 0.485,Avg.Loss: 0.560,LR: 4.95E-04]Training epoch 7:  41%|████      | 63/153 [00:01<00:01, 52.51it/s, Epoch: 7, Batch: 64,Loss: 0.719,Avg.Loss: 0.563,LR: 4.95E-04]Training epoch 7:  42%|████▏     | 64/153 [00:01<00:01, 52.51it/s, Epoch: 7, Batch: 65,Loss: 0.922,Avg.Loss: 0.568,LR: 4.95E-04]Training epoch 7:  42%|████▏     | 65/153 [00:01<00:01, 52.51it/s, Epoch: 7, Batch: 66,Loss: 0.726,Avg.Loss: 0.570,LR: 4.95E-04]Training epoch 7:  43%|████▎     | 66/153 [00:01<00:01, 53.02it/s, Epoch: 7, Batch: 66,Loss: 0.726,Avg.Loss: 0.570,LR: 4.95E-04]Training epoch 7:  43%|████▎     | 66/153 [00:01<00:01, 53.02it/s, Epoch: 7, Batch: 67,Loss: 0.535,Avg.Loss: 0.570,LR: 4.95E-04]Training epoch 7:  44%|████▍     | 67/153 [00:01<00:01, 53.02it/s, Epoch: 7, Batch: 68,Loss: 0.555,Avg.Loss: 0.570,LR: 4.95E-04]Training epoch 7:  44%|████▍     | 68/153 [00:01<00:01, 53.02it/s, Epoch: 7, Batch: 69,Loss: 0.446,Avg.Loss: 0.568,LR: 4.95E-04]Training epoch 7:  45%|████▌     | 69/153 [00:01<00:01, 53.02it/s, Epoch: 7, Batch: 70,Loss: 0.233,Avg.Loss: 0.563,LR: 4.95E-04]Training epoch 7:  46%|████▌     | 70/153 [00:01<00:01, 53.02it/s, Epoch: 7, Batch: 71,Loss: 0.540,Avg.Loss: 0.563,LR: 4.95E-04]Training epoch 7:  46%|████▋     | 71/153 [00:01<00:01, 53.02it/s, Epoch: 7, Batch: 72,Loss: 0.437,Avg.Loss: 0.561,LR: 4.95E-04]Training epoch 7:  47%|████▋     | 72/153 [00:01<00:01, 52.77it/s, Epoch: 7, Batch: 72,Loss: 0.437,Avg.Loss: 0.561,LR: 4.95E-04]Training epoch 7:  47%|████▋     | 72/153 [00:01<00:01, 52.77it/s, Epoch: 7, Batch: 73,Loss: 0.693,Avg.Loss: 0.563,LR: 4.95E-04]Training epoch 7:  48%|████▊     | 73/153 [00:01<00:01, 52.77it/s, Epoch: 7, Batch: 74,Loss: 0.445,Avg.Loss: 0.561,LR: 4.95E-04]Training epoch 7:  48%|████▊     | 74/153 [00:01<00:01, 52.77it/s, Epoch: 7, Batch: 75,Loss: 0.405,Avg.Loss: 0.559,LR: 4.95E-04]Training epoch 7:  49%|████▉     | 75/153 [00:01<00:01, 52.77it/s, Epoch: 7, Batch: 76,Loss: 0.815,Avg.Loss: 0.563,LR: 4.95E-04]Training epoch 7:  50%|████▉     | 76/153 [00:01<00:01, 52.77it/s, Epoch: 7, Batch: 77,Loss: 0.258,Avg.Loss: 0.559,LR: 4.95E-04]Training epoch 7:  50%|█████     | 77/153 [00:01<00:01, 52.77it/s, Epoch: 7, Batch: 78,Loss: 0.435,Avg.Loss: 0.557,LR: 4.95E-04]Training epoch 7:  51%|█████     | 78/153 [00:01<00:01, 52.82it/s, Epoch: 7, Batch: 78,Loss: 0.435,Avg.Loss: 0.557,LR: 4.95E-04]Training epoch 7:  51%|█████     | 78/153 [00:01<00:01, 52.82it/s, Epoch: 7, Batch: 79,Loss: 0.495,Avg.Loss: 0.556,LR: 4.95E-04]Training epoch 7:  52%|█████▏    | 79/153 [00:01<00:01, 52.82it/s, Epoch: 7, Batch: 80,Loss: 0.354,Avg.Loss: 0.554,LR: 4.95E-04]Training epoch 7:  52%|█████▏    | 80/153 [00:01<00:01, 52.82it/s, Epoch: 7, Batch: 81,Loss: 0.523,Avg.Loss: 0.553,LR: 4.95E-04]Training epoch 7:  53%|█████▎    | 81/153 [00:01<00:01, 52.82it/s, Epoch: 7, Batch: 82,Loss: 0.240,Avg.Loss: 0.550,LR: 4.95E-04]Training epoch 7:  54%|█████▎    | 82/153 [00:01<00:01, 52.82it/s, Epoch: 7, Batch: 83,Loss: 0.570,Avg.Loss: 0.550,LR: 4.95E-04]Training epoch 7:  54%|█████▍    | 83/153 [00:01<00:01, 52.82it/s, Epoch: 7, Batch: 84,Loss: 0.123,Avg.Loss: 0.545,LR: 4.95E-04]Training epoch 7:  55%|█████▍    | 84/153 [00:01<00:01, 52.78it/s, Epoch: 7, Batch: 84,Loss: 0.123,Avg.Loss: 0.545,LR: 4.95E-04]Training epoch 7:  55%|█████▍    | 84/153 [00:01<00:01, 52.78it/s, Epoch: 7, Batch: 85,Loss: 0.153,Avg.Loss: 0.540,LR: 4.95E-04]Training epoch 7:  56%|█████▌    | 85/153 [00:01<00:01, 52.78it/s, Epoch: 7, Batch: 86,Loss: 0.377,Avg.Loss: 0.538,LR: 4.95E-04]Training epoch 7:  56%|█████▌    | 86/153 [00:01<00:01, 52.78it/s, Epoch: 7, Batch: 87,Loss: 0.337,Avg.Loss: 0.536,LR: 4.95E-04]Training epoch 7:  57%|█████▋    | 87/153 [00:01<00:01, 52.78it/s, Epoch: 7, Batch: 88,Loss: 0.202,Avg.Loss: 0.532,LR: 4.95E-04]Training epoch 7:  58%|█████▊    | 88/153 [00:01<00:01, 52.78it/s, Epoch: 7, Batch: 89,Loss: 0.258,Avg.Loss: 0.529,LR: 4.95E-04]Training epoch 7:  58%|█████▊    | 89/153 [00:01<00:01, 52.78it/s, Epoch: 7, Batch: 90,Loss: 0.163,Avg.Loss: 0.525,LR: 4.95E-04]Training epoch 7:  59%|█████▉    | 90/153 [00:01<00:01, 53.10it/s, Epoch: 7, Batch: 90,Loss: 0.163,Avg.Loss: 0.525,LR: 4.95E-04]Training epoch 7:  59%|█████▉    | 90/153 [00:01<00:01, 53.10it/s, Epoch: 7, Batch: 91,Loss: 0.345,Avg.Loss: 0.523,LR: 4.95E-04]Training epoch 7:  59%|█████▉    | 91/153 [00:01<00:01, 53.10it/s, Epoch: 7, Batch: 92,Loss: 0.178,Avg.Loss: 0.519,LR: 4.95E-04]Training epoch 7:  60%|██████    | 92/153 [00:01<00:01, 53.10it/s, Epoch: 7, Batch: 93,Loss: 0.667,Avg.Loss: 0.521,LR: 4.95E-04]Training epoch 7:  61%|██████    | 93/153 [00:01<00:01, 53.10it/s, Epoch: 7, Batch: 94,Loss: 0.615,Avg.Loss: 0.522,LR: 4.95E-04]Training epoch 7:  61%|██████▏   | 94/153 [00:01<00:01, 53.10it/s, Epoch: 7, Batch: 95,Loss: 0.592,Avg.Loss: 0.523,LR: 4.95E-04]Training epoch 7:  62%|██████▏   | 95/153 [00:01<00:01, 53.10it/s, Epoch: 7, Batch: 96,Loss: 0.315,Avg.Loss: 0.520,LR: 4.95E-04]Training epoch 7:  63%|██████▎   | 96/153 [00:01<00:01, 53.22it/s, Epoch: 7, Batch: 96,Loss: 0.315,Avg.Loss: 0.520,LR: 4.95E-04]Training epoch 7:  63%|██████▎   | 96/153 [00:01<00:01, 53.22it/s, Epoch: 7, Batch: 97,Loss: 0.368,Avg.Loss: 0.519,LR: 4.95E-04]Training epoch 7:  63%|██████▎   | 97/153 [00:01<00:01, 53.22it/s, Epoch: 7, Batch: 98,Loss: 0.613,Avg.Loss: 0.520,LR: 4.95E-04]Training epoch 7:  64%|██████▍   | 98/153 [00:01<00:01, 53.22it/s, Epoch: 7, Batch: 99,Loss: 0.275,Avg.Loss: 0.517,LR: 4.95E-04]Training epoch 7:  65%|██████▍   | 99/153 [00:01<00:01, 53.22it/s, Epoch: 7, Batch: 100,Loss: 0.262,Avg.Loss: 0.515,LR: 4.95E-04]Training epoch 7:  65%|██████▌   | 100/153 [00:01<00:00, 53.22it/s, Epoch: 7, Batch: 101,Loss: 0.188,Avg.Loss: 0.512,LR: 4.95E-04]Training epoch 7:  66%|██████▌   | 101/153 [00:01<00:00, 53.22it/s, Epoch: 7, Batch: 102,Loss: 0.560,Avg.Loss: 0.512,LR: 4.95E-04]Training epoch 7:  67%|██████▋   | 102/153 [00:01<00:00, 53.24it/s, Epoch: 7, Batch: 102,Loss: 0.560,Avg.Loss: 0.512,LR: 4.95E-04]Training epoch 7:  67%|██████▋   | 102/153 [00:01<00:00, 53.24it/s, Epoch: 7, Batch: 103,Loss: 0.687,Avg.Loss: 0.514,LR: 4.95E-04]Training epoch 7:  67%|██████▋   | 103/153 [00:01<00:00, 53.24it/s, Epoch: 7, Batch: 104,Loss: 0.542,Avg.Loss: 0.514,LR: 4.95E-04]Training epoch 7:  68%|██████▊   | 104/153 [00:01<00:00, 53.24it/s, Epoch: 7, Batch: 105,Loss: 0.773,Avg.Loss: 0.516,LR: 4.95E-04]Training epoch 7:  69%|██████▊   | 105/153 [00:02<00:00, 53.24it/s, Epoch: 7, Batch: 106,Loss: 1.035,Avg.Loss: 0.521,LR: 4.94E-04]Training epoch 7:  69%|██████▉   | 106/153 [00:02<00:00, 53.24it/s, Epoch: 7, Batch: 107,Loss: 0.454,Avg.Loss: 0.521,LR: 4.94E-04]Training epoch 7:  70%|██████▉   | 107/153 [00:02<00:00, 53.24it/s, Epoch: 7, Batch: 108,Loss: 0.535,Avg.Loss: 0.521,LR: 4.94E-04]Training epoch 7:  71%|███████   | 108/153 [00:02<00:00, 53.10it/s, Epoch: 7, Batch: 108,Loss: 0.535,Avg.Loss: 0.521,LR: 4.94E-04]Training epoch 7:  71%|███████   | 108/153 [00:02<00:00, 53.10it/s, Epoch: 7, Batch: 109,Loss: 0.991,Avg.Loss: 0.525,LR: 4.94E-04]Training epoch 7:  71%|███████   | 109/153 [00:02<00:00, 53.10it/s, Epoch: 7, Batch: 110,Loss: 1.034,Avg.Loss: 0.530,LR: 4.94E-04]Training epoch 7:  72%|███████▏  | 110/153 [00:02<00:00, 53.10it/s, Epoch: 7, Batch: 111,Loss: 0.450,Avg.Loss: 0.529,LR: 4.94E-04]Training epoch 7:  73%|███████▎  | 111/153 [00:02<00:00, 53.10it/s, Epoch: 7, Batch: 112,Loss: 0.913,Avg.Loss: 0.532,LR: 4.94E-04]Training epoch 7:  73%|███████▎  | 112/153 [00:02<00:00, 53.10it/s, Epoch: 7, Batch: 113,Loss: 2.112,Avg.Loss: 0.546,LR: 4.94E-04]Training epoch 7:  74%|███████▍  | 113/153 [00:02<00:00, 53.10it/s, Epoch: 7, Batch: 114,Loss: 1.503,Avg.Loss: 0.555,LR: 4.94E-04]Training epoch 7:  75%|███████▍  | 114/153 [00:02<00:00, 53.13it/s, Epoch: 7, Batch: 114,Loss: 1.503,Avg.Loss: 0.555,LR: 4.94E-04]Training epoch 7:  75%|███████▍  | 114/153 [00:02<00:00, 53.13it/s, Epoch: 7, Batch: 115,Loss: 0.465,Avg.Loss: 0.554,LR: 4.94E-04]Training epoch 7:  75%|███████▌  | 115/153 [00:02<00:00, 53.13it/s, Epoch: 7, Batch: 116,Loss: 0.412,Avg.Loss: 0.553,LR: 4.94E-04]Training epoch 7:  76%|███████▌  | 116/153 [00:02<00:00, 53.13it/s, Epoch: 7, Batch: 117,Loss: 0.506,Avg.Loss: 0.552,LR: 4.94E-04]Training epoch 7:  76%|███████▋  | 117/153 [00:02<00:00, 53.13it/s, Epoch: 7, Batch: 118,Loss: 0.506,Avg.Loss: 0.552,LR: 4.94E-04]Training epoch 7:  77%|███████▋  | 118/153 [00:02<00:00, 53.13it/s, Epoch: 7, Batch: 119,Loss: 0.082,Avg.Loss: 0.548,LR: 4.94E-04]Training epoch 7:  78%|███████▊  | 119/153 [00:02<00:00, 53.13it/s, Epoch: 7, Batch: 120,Loss: 0.232,Avg.Loss: 0.545,LR: 4.94E-04]Training epoch 7:  78%|███████▊  | 120/153 [00:02<00:00, 53.14it/s, Epoch: 7, Batch: 120,Loss: 0.232,Avg.Loss: 0.545,LR: 4.94E-04]Training epoch 7:  78%|███████▊  | 120/153 [00:02<00:00, 53.14it/s, Epoch: 7, Batch: 121,Loss: 0.464,Avg.Loss: 0.545,LR: 4.94E-04]Training epoch 7:  79%|███████▉  | 121/153 [00:02<00:00, 53.14it/s, Epoch: 7, Batch: 122,Loss: 0.702,Avg.Loss: 0.546,LR: 4.94E-04]Training epoch 7:  80%|███████▉  | 122/153 [00:02<00:00, 53.14it/s, Epoch: 7, Batch: 123,Loss: 1.105,Avg.Loss: 0.551,LR: 4.94E-04]Training epoch 7:  80%|████████  | 123/153 [00:02<00:00, 53.14it/s, Epoch: 7, Batch: 124,Loss: 0.345,Avg.Loss: 0.549,LR: 4.94E-04]Training epoch 7:  81%|████████  | 124/153 [00:02<00:00, 53.14it/s, Epoch: 7, Batch: 125,Loss: 0.511,Avg.Loss: 0.549,LR: 4.94E-04]Training epoch 7:  82%|████████▏ | 125/153 [00:02<00:00, 53.14it/s, Epoch: 7, Batch: 126,Loss: 0.471,Avg.Loss: 0.548,LR: 4.94E-04]Training epoch 7:  82%|████████▏ | 126/153 [00:02<00:00, 53.35it/s, Epoch: 7, Batch: 126,Loss: 0.471,Avg.Loss: 0.548,LR: 4.94E-04]Training epoch 7:  82%|████████▏ | 126/153 [00:02<00:00, 53.35it/s, Epoch: 7, Batch: 127,Loss: 0.208,Avg.Loss: 0.545,LR: 4.94E-04]Training epoch 7:  83%|████████▎ | 127/153 [00:02<00:00, 53.35it/s, Epoch: 7, Batch: 128,Loss: 0.029,Avg.Loss: 0.541,LR: 4.94E-04]Training epoch 7:  84%|████████▎ | 128/153 [00:02<00:00, 53.35it/s, Epoch: 7, Batch: 129,Loss: 0.027,Avg.Loss: 0.537,LR: 4.94E-04]Training epoch 7:  84%|████████▍ | 129/153 [00:02<00:00, 53.35it/s, Epoch: 7, Batch: 130,Loss: 0.035,Avg.Loss: 0.533,LR: 4.94E-04]Training epoch 7:  85%|████████▍ | 130/153 [00:02<00:00, 53.35it/s, Epoch: 7, Batch: 131,Loss: 0.084,Avg.Loss: 0.530,LR: 4.94E-04]Training epoch 7:  86%|████████▌ | 131/153 [00:02<00:00, 53.35it/s, Epoch: 7, Batch: 132,Loss: 0.419,Avg.Loss: 0.529,LR: 4.94E-04]Training epoch 7:  86%|████████▋ | 132/153 [00:02<00:00, 53.36it/s, Epoch: 7, Batch: 132,Loss: 0.419,Avg.Loss: 0.529,LR: 4.94E-04]Training epoch 7:  86%|████████▋ | 132/153 [00:02<00:00, 53.36it/s, Epoch: 7, Batch: 133,Loss: 0.905,Avg.Loss: 0.532,LR: 4.94E-04]Training epoch 7:  87%|████████▋ | 133/153 [00:02<00:00, 53.36it/s, Epoch: 7, Batch: 134,Loss: 0.442,Avg.Loss: 0.531,LR: 4.94E-04]Training epoch 7:  88%|████████▊ | 134/153 [00:02<00:00, 53.36it/s, Epoch: 7, Batch: 135,Loss: 0.597,Avg.Loss: 0.532,LR: 4.94E-04]Training epoch 7:  88%|████████▊ | 135/153 [00:02<00:00, 53.36it/s, Epoch: 7, Batch: 136,Loss: 0.790,Avg.Loss: 0.534,LR: 4.94E-04]Training epoch 7:  89%|████████▉ | 136/153 [00:02<00:00, 53.36it/s, Epoch: 7, Batch: 137,Loss: 0.778,Avg.Loss: 0.536,LR: 4.94E-04]Training epoch 7:  90%|████████▉ | 137/153 [00:02<00:00, 53.36it/s, Epoch: 7, Batch: 138,Loss: -0.116,Avg.Loss: 0.531,LR: 4.94E-04]Training epoch 7:  90%|█████████ | 138/153 [00:02<00:00, 53.54it/s, Epoch: 7, Batch: 138,Loss: -0.116,Avg.Loss: 0.531,LR: 4.94E-04]Training epoch 7:  90%|█████████ | 138/153 [00:02<00:00, 53.54it/s, Epoch: 7, Batch: 139,Loss: 0.130,Avg.Loss: 0.528,LR: 4.94E-04] Training epoch 7:  91%|█████████ | 139/153 [00:02<00:00, 53.54it/s, Epoch: 7, Batch: 140,Loss: 0.084,Avg.Loss: 0.525,LR: 4.94E-04]Training epoch 7:  92%|█████████▏| 140/153 [00:02<00:00, 53.54it/s, Epoch: 7, Batch: 141,Loss: 0.240,Avg.Loss: 0.523,LR: 4.94E-04]Training epoch 7:  92%|█████████▏| 141/153 [00:02<00:00, 53.54it/s, Epoch: 7, Batch: 142,Loss: 0.242,Avg.Loss: 0.521,LR: 4.94E-04]Training epoch 7:  93%|█████████▎| 142/153 [00:02<00:00, 53.54it/s, Epoch: 7, Batch: 143,Loss: -0.080,Avg.Loss: 0.517,LR: 4.94E-04]Training epoch 7:  93%|█████████▎| 143/153 [00:02<00:00, 53.54it/s, Epoch: 7, Batch: 144,Loss: 0.210,Avg.Loss: 0.514,LR: 4.94E-04] Training epoch 7:  94%|█████████▍| 144/153 [00:02<00:00, 53.20it/s, Epoch: 7, Batch: 144,Loss: 0.210,Avg.Loss: 0.514,LR: 4.94E-04]Training epoch 7:  94%|█████████▍| 144/153 [00:02<00:00, 53.20it/s, Epoch: 7, Batch: 145,Loss: 0.179,Avg.Loss: 0.512,LR: 4.94E-04]Training epoch 7:  95%|█████████▍| 145/153 [00:02<00:00, 53.20it/s, Epoch: 7, Batch: 146,Loss: 0.332,Avg.Loss: 0.511,LR: 4.94E-04]Training epoch 7:  95%|█████████▌| 146/153 [00:02<00:00, 53.20it/s, Epoch: 7, Batch: 147,Loss: 0.105,Avg.Loss: 0.508,LR: 4.94E-04]Training epoch 7:  96%|█████████▌| 147/153 [00:02<00:00, 53.20it/s, Epoch: 7, Batch: 148,Loss: 0.850,Avg.Loss: 0.510,LR: 4.94E-04]Training epoch 7:  97%|█████████▋| 148/153 [00:02<00:00, 53.20it/s, Epoch: 7, Batch: 149,Loss: 0.407,Avg.Loss: 0.510,LR: 4.94E-04]Training epoch 7:  97%|█████████▋| 149/153 [00:02<00:00, 53.20it/s, Epoch: 7, Batch: 150,Loss: 0.764,Avg.Loss: 0.511,LR: 4.94E-04]Training epoch 7:  98%|█████████▊| 150/153 [00:02<00:00, 53.39it/s, Epoch: 7, Batch: 150,Loss: 0.764,Avg.Loss: 0.511,LR: 4.94E-04]Training epoch 7:  98%|█████████▊| 150/153 [00:02<00:00, 53.39it/s, Epoch: 7, Batch: 151,Loss: 0.649,Avg.Loss: 0.512,LR: 4.94E-04]Training epoch 7:  99%|█████████▊| 151/153 [00:02<00:00, 53.39it/s, Epoch: 7, Batch: 152,Loss: 0.322,Avg.Loss: 0.511,LR: 4.94E-04]Training epoch 7:  99%|█████████▉| 152/153 [00:02<00:00, 53.39it/s, Epoch: 7, Batch: 153,Loss: 0.590,Avg.Loss: 0.512,LR: 4.94E-04]Training epoch 7: 100%|██████████| 153/153 [00:02<00:00, 52.75it/s, Epoch: 7, Batch: 153,Loss: 0.590,Avg.Loss: 0.512,LR: 4.94E-04]
Training epoch 8:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 8:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 8, Batch: 1,Loss: 1.112,Avg.Loss: 1.112,LR: 4.94E-04]Training epoch 8:   1%|          | 1/153 [00:00<00:06, 25.15it/s, Epoch: 8, Batch: 2,Loss: 0.988,Avg.Loss: 1.050,LR: 4.94E-04]Training epoch 8:   1%|▏         | 2/153 [00:00<00:04, 37.22it/s, Epoch: 8, Batch: 3,Loss: 0.537,Avg.Loss: 0.879,LR: 4.94E-04]Training epoch 8:   2%|▏         | 3/153 [00:00<00:03, 42.55it/s, Epoch: 8, Batch: 4,Loss: 0.180,Avg.Loss: 0.704,LR: 4.94E-04]Training epoch 8:   3%|▎         | 4/153 [00:00<00:03, 46.18it/s, Epoch: 8, Batch: 5,Loss: 0.834,Avg.Loss: 0.730,LR: 4.94E-04]Training epoch 8:   3%|▎         | 5/153 [00:00<00:03, 47.55it/s, Epoch: 8, Batch: 6,Loss: 0.523,Avg.Loss: 0.696,LR: 4.94E-04]Training epoch 8:   4%|▍         | 6/153 [00:00<00:02, 56.95it/s, Epoch: 8, Batch: 6,Loss: 0.523,Avg.Loss: 0.696,LR: 4.94E-04]Training epoch 8:   4%|▍         | 6/153 [00:00<00:02, 56.95it/s, Epoch: 8, Batch: 7,Loss: 0.217,Avg.Loss: 0.627,LR: 4.94E-04]Training epoch 8:   5%|▍         | 7/153 [00:00<00:02, 56.95it/s, Epoch: 8, Batch: 8,Loss: 0.459,Avg.Loss: 0.606,LR: 4.94E-04]Training epoch 8:   5%|▌         | 8/153 [00:00<00:02, 56.95it/s, Epoch: 8, Batch: 9,Loss: 0.166,Avg.Loss: 0.557,LR: 4.94E-04]Training epoch 8:   6%|▌         | 9/153 [00:00<00:02, 56.95it/s, Epoch: 8, Batch: 10,Loss: 0.693,Avg.Loss: 0.571,LR: 4.94E-04]Training epoch 8:   7%|▋         | 10/153 [00:00<00:02, 56.95it/s, Epoch: 8, Batch: 11,Loss: 0.783,Avg.Loss: 0.590,LR: 4.94E-04]Training epoch 8:   7%|▋         | 11/153 [00:00<00:02, 56.95it/s, Epoch: 8, Batch: 12,Loss: 0.195,Avg.Loss: 0.557,LR: 4.94E-04]Training epoch 8:   8%|▊         | 12/153 [00:00<00:02, 53.94it/s, Epoch: 8, Batch: 12,Loss: 0.195,Avg.Loss: 0.557,LR: 4.94E-04]Training epoch 8:   8%|▊         | 12/153 [00:00<00:02, 53.94it/s, Epoch: 8, Batch: 13,Loss: 0.181,Avg.Loss: 0.528,LR: 4.94E-04]Training epoch 8:   8%|▊         | 13/153 [00:00<00:02, 53.94it/s, Epoch: 8, Batch: 14,Loss: 0.145,Avg.Loss: 0.501,LR: 4.94E-04]Training epoch 8:   9%|▉         | 14/153 [00:00<00:02, 53.94it/s, Epoch: 8, Batch: 15,Loss: 0.183,Avg.Loss: 0.480,LR: 4.94E-04]Training epoch 8:  10%|▉         | 15/153 [00:00<00:02, 53.94it/s, Epoch: 8, Batch: 16,Loss: 0.596,Avg.Loss: 0.487,LR: 4.94E-04]Training epoch 8:  10%|█         | 16/153 [00:00<00:02, 53.94it/s, Epoch: 8, Batch: 17,Loss: 0.565,Avg.Loss: 0.492,LR: 4.94E-04]Training epoch 8:  11%|█         | 17/153 [00:00<00:02, 53.94it/s, Epoch: 8, Batch: 18,Loss: 0.509,Avg.Loss: 0.492,LR: 4.94E-04]Training epoch 8:  12%|█▏        | 18/153 [00:00<00:02, 53.52it/s, Epoch: 8, Batch: 18,Loss: 0.509,Avg.Loss: 0.492,LR: 4.94E-04]Training epoch 8:  12%|█▏        | 18/153 [00:00<00:02, 53.52it/s, Epoch: 8, Batch: 19,Loss: 0.385,Avg.Loss: 0.487,LR: 4.94E-04]Training epoch 8:  12%|█▏        | 19/153 [00:00<00:02, 53.52it/s, Epoch: 8, Batch: 20,Loss: 0.566,Avg.Loss: 0.491,LR: 4.94E-04]Training epoch 8:  13%|█▎        | 20/153 [00:00<00:02, 53.52it/s, Epoch: 8, Batch: 21,Loss: 0.488,Avg.Loss: 0.491,LR: 4.94E-04]Training epoch 8:  14%|█▎        | 21/153 [00:00<00:02, 53.52it/s, Epoch: 8, Batch: 22,Loss: 0.677,Avg.Loss: 0.499,LR: 4.94E-04]Training epoch 8:  14%|█▍        | 22/153 [00:00<00:02, 53.52it/s, Epoch: 8, Batch: 23,Loss: 0.646,Avg.Loss: 0.506,LR: 4.94E-04]Training epoch 8:  15%|█▌        | 23/153 [00:00<00:02, 53.52it/s, Epoch: 8, Batch: 24,Loss: 1.318,Avg.Loss: 0.539,LR: 4.94E-04]Training epoch 8:  16%|█▌        | 24/153 [00:00<00:02, 52.92it/s, Epoch: 8, Batch: 24,Loss: 1.318,Avg.Loss: 0.539,LR: 4.94E-04]Training epoch 8:  16%|█▌        | 24/153 [00:00<00:02, 52.92it/s, Epoch: 8, Batch: 25,Loss: 0.850,Avg.Loss: 0.552,LR: 4.94E-04]Training epoch 8:  16%|█▋        | 25/153 [00:00<00:02, 52.92it/s, Epoch: 8, Batch: 26,Loss: 0.256,Avg.Loss: 0.540,LR: 4.94E-04]Training epoch 8:  17%|█▋        | 26/153 [00:00<00:02, 52.92it/s, Epoch: 8, Batch: 27,Loss: 0.548,Avg.Loss: 0.541,LR: 4.94E-04]Training epoch 8:  18%|█▊        | 27/153 [00:00<00:02, 52.92it/s, Epoch: 8, Batch: 28,Loss: 1.036,Avg.Loss: 0.558,LR: 4.94E-04]Training epoch 8:  18%|█▊        | 28/153 [00:00<00:02, 52.92it/s, Epoch: 8, Batch: 29,Loss: 1.064,Avg.Loss: 0.576,LR: 4.94E-04]Training epoch 8:  19%|█▉        | 29/153 [00:00<00:02, 52.92it/s, Epoch: 8, Batch: 30,Loss: 0.258,Avg.Loss: 0.565,LR: 4.94E-04]Training epoch 8:  20%|█▉        | 30/153 [00:00<00:02, 51.88it/s, Epoch: 8, Batch: 30,Loss: 0.258,Avg.Loss: 0.565,LR: 4.94E-04]Training epoch 8:  20%|█▉        | 30/153 [00:00<00:02, 51.88it/s, Epoch: 8, Batch: 31,Loss: 0.578,Avg.Loss: 0.566,LR: 4.94E-04]Training epoch 8:  20%|██        | 31/153 [00:00<00:02, 51.88it/s, Epoch: 8, Batch: 32,Loss: 0.477,Avg.Loss: 0.563,LR: 4.94E-04]Training epoch 8:  21%|██        | 32/153 [00:00<00:02, 51.88it/s, Epoch: 8, Batch: 33,Loss: 0.591,Avg.Loss: 0.564,LR: 4.94E-04]Training epoch 8:  22%|██▏       | 33/153 [00:00<00:02, 51.88it/s, Epoch: 8, Batch: 34,Loss: 0.645,Avg.Loss: 0.566,LR: 4.94E-04]Training epoch 8:  22%|██▏       | 34/153 [00:00<00:02, 51.88it/s, Epoch: 8, Batch: 35,Loss: 0.348,Avg.Loss: 0.560,LR: 4.94E-04]Training epoch 8:  23%|██▎       | 35/153 [00:00<00:02, 51.88it/s, Epoch: 8, Batch: 36,Loss: 0.332,Avg.Loss: 0.554,LR: 4.94E-04]Training epoch 8:  24%|██▎       | 36/153 [00:00<00:02, 52.43it/s, Epoch: 8, Batch: 36,Loss: 0.332,Avg.Loss: 0.554,LR: 4.94E-04]Training epoch 8:  24%|██▎       | 36/153 [00:00<00:02, 52.43it/s, Epoch: 8, Batch: 37,Loss: 0.149,Avg.Loss: 0.543,LR: 4.94E-04]Training epoch 8:  24%|██▍       | 37/153 [00:00<00:02, 52.43it/s, Epoch: 8, Batch: 38,Loss: 0.170,Avg.Loss: 0.533,LR: 4.94E-04]Training epoch 8:  25%|██▍       | 38/153 [00:00<00:02, 52.43it/s, Epoch: 8, Batch: 39,Loss: 0.850,Avg.Loss: 0.541,LR: 4.94E-04]Training epoch 8:  25%|██▌       | 39/153 [00:00<00:02, 52.43it/s, Epoch: 8, Batch: 40,Loss: 0.017,Avg.Loss: 0.528,LR: 4.94E-04]Training epoch 8:  26%|██▌       | 40/153 [00:00<00:02, 52.43it/s, Epoch: 8, Batch: 41,Loss: 0.296,Avg.Loss: 0.522,LR: 4.94E-04]Training epoch 8:  27%|██▋       | 41/153 [00:00<00:02, 52.43it/s, Epoch: 8, Batch: 42,Loss: 0.145,Avg.Loss: 0.513,LR: 4.93E-04]Training epoch 8:  27%|██▋       | 42/153 [00:00<00:02, 52.59it/s, Epoch: 8, Batch: 42,Loss: 0.145,Avg.Loss: 0.513,LR: 4.93E-04]Training epoch 8:  27%|██▋       | 42/153 [00:00<00:02, 52.59it/s, Epoch: 8, Batch: 43,Loss: 0.388,Avg.Loss: 0.510,LR: 4.93E-04]Training epoch 8:  28%|██▊       | 43/153 [00:00<00:02, 52.59it/s, Epoch: 8, Batch: 44,Loss: 0.231,Avg.Loss: 0.504,LR: 4.93E-04]Training epoch 8:  29%|██▉       | 44/153 [00:00<00:02, 52.59it/s, Epoch: 8, Batch: 45,Loss: 0.341,Avg.Loss: 0.500,LR: 4.93E-04]Training epoch 8:  29%|██▉       | 45/153 [00:00<00:02, 52.59it/s, Epoch: 8, Batch: 46,Loss: 0.343,Avg.Loss: 0.497,LR: 4.93E-04]Training epoch 8:  30%|███       | 46/153 [00:00<00:02, 52.59it/s, Epoch: 8, Batch: 47,Loss: 0.209,Avg.Loss: 0.491,LR: 4.93E-04]Training epoch 8:  31%|███       | 47/153 [00:00<00:02, 52.59it/s, Epoch: 8, Batch: 48,Loss: 0.280,Avg.Loss: 0.486,LR: 4.93E-04]Training epoch 8:  31%|███▏      | 48/153 [00:00<00:01, 52.85it/s, Epoch: 8, Batch: 48,Loss: 0.280,Avg.Loss: 0.486,LR: 4.93E-04]Training epoch 8:  31%|███▏      | 48/153 [00:00<00:01, 52.85it/s, Epoch: 8, Batch: 49,Loss: 0.144,Avg.Loss: 0.479,LR: 4.93E-04]Training epoch 8:  32%|███▏      | 49/153 [00:00<00:01, 52.85it/s, Epoch: 8, Batch: 50,Loss: 0.292,Avg.Loss: 0.476,LR: 4.93E-04]Training epoch 8:  33%|███▎      | 50/153 [00:00<00:01, 52.85it/s, Epoch: 8, Batch: 51,Loss: 0.465,Avg.Loss: 0.475,LR: 4.93E-04]Training epoch 8:  33%|███▎      | 51/153 [00:00<00:01, 52.85it/s, Epoch: 8, Batch: 52,Loss: 0.195,Avg.Loss: 0.470,LR: 4.93E-04]Training epoch 8:  34%|███▍      | 52/153 [00:01<00:01, 52.85it/s, Epoch: 8, Batch: 53,Loss: 0.050,Avg.Loss: 0.462,LR: 4.93E-04]Training epoch 8:  35%|███▍      | 53/153 [00:01<00:01, 52.85it/s, Epoch: 8, Batch: 54,Loss: -0.057,Avg.Loss: 0.453,LR: 4.93E-04]Training epoch 8:  35%|███▌      | 54/153 [00:01<00:01, 52.76it/s, Epoch: 8, Batch: 54,Loss: -0.057,Avg.Loss: 0.453,LR: 4.93E-04]Training epoch 8:  35%|███▌      | 54/153 [00:01<00:01, 52.76it/s, Epoch: 8, Batch: 55,Loss: 0.156,Avg.Loss: 0.447,LR: 4.93E-04] Training epoch 8:  36%|███▌      | 55/153 [00:01<00:01, 52.76it/s, Epoch: 8, Batch: 56,Loss: 0.216,Avg.Loss: 0.443,LR: 4.93E-04]Training epoch 8:  37%|███▋      | 56/153 [00:01<00:01, 52.76it/s, Epoch: 8, Batch: 57,Loss: 0.253,Avg.Loss: 0.440,LR: 4.93E-04]Training epoch 8:  37%|███▋      | 57/153 [00:01<00:01, 52.76it/s, Epoch: 8, Batch: 58,Loss: 0.259,Avg.Loss: 0.437,LR: 4.93E-04]Training epoch 8:  38%|███▊      | 58/153 [00:01<00:01, 52.76it/s, Epoch: 8, Batch: 59,Loss: 0.068,Avg.Loss: 0.430,LR: 4.93E-04]Training epoch 8:  39%|███▊      | 59/153 [00:01<00:01, 52.76it/s, Epoch: 8, Batch: 60,Loss: 0.228,Avg.Loss: 0.427,LR: 4.93E-04]Training epoch 8:  39%|███▉      | 60/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 60,Loss: 0.228,Avg.Loss: 0.427,LR: 4.93E-04]Training epoch 8:  39%|███▉      | 60/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 61,Loss: 0.154,Avg.Loss: 0.422,LR: 4.93E-04]Training epoch 8:  40%|███▉      | 61/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 62,Loss: 0.222,Avg.Loss: 0.419,LR: 4.93E-04]Training epoch 8:  41%|████      | 62/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 63,Loss: 0.178,Avg.Loss: 0.415,LR: 4.93E-04]Training epoch 8:  41%|████      | 63/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 64,Loss: 0.150,Avg.Loss: 0.411,LR: 4.93E-04]Training epoch 8:  42%|████▏     | 64/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 65,Loss: 0.156,Avg.Loss: 0.407,LR: 4.93E-04]Training epoch 8:  42%|████▏     | 65/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 66,Loss: 0.282,Avg.Loss: 0.405,LR: 4.93E-04]Training epoch 8:  43%|████▎     | 66/153 [00:01<00:01, 52.74it/s, Epoch: 8, Batch: 66,Loss: 0.282,Avg.Loss: 0.405,LR: 4.93E-04]Training epoch 8:  43%|████▎     | 66/153 [00:01<00:01, 52.74it/s, Epoch: 8, Batch: 67,Loss: 0.119,Avg.Loss: 0.401,LR: 4.93E-04]Training epoch 8:  44%|████▍     | 67/153 [00:01<00:01, 52.74it/s, Epoch: 8, Batch: 68,Loss: 0.246,Avg.Loss: 0.399,LR: 4.93E-04]Training epoch 8:  44%|████▍     | 68/153 [00:01<00:01, 52.74it/s, Epoch: 8, Batch: 69,Loss: 0.488,Avg.Loss: 0.400,LR: 4.93E-04]Training epoch 8:  45%|████▌     | 69/153 [00:01<00:01, 52.74it/s, Epoch: 8, Batch: 70,Loss: 0.182,Avg.Loss: 0.397,LR: 4.93E-04]Training epoch 8:  46%|████▌     | 70/153 [00:01<00:01, 52.74it/s, Epoch: 8, Batch: 71,Loss: 0.186,Avg.Loss: 0.394,LR: 4.93E-04]Training epoch 8:  46%|████▋     | 71/153 [00:01<00:01, 52.74it/s, Epoch: 8, Batch: 72,Loss: 0.238,Avg.Loss: 0.392,LR: 4.93E-04]Training epoch 8:  47%|████▋     | 72/153 [00:01<00:01, 52.95it/s, Epoch: 8, Batch: 72,Loss: 0.238,Avg.Loss: 0.392,LR: 4.93E-04]Training epoch 8:  47%|████▋     | 72/153 [00:01<00:01, 52.95it/s, Epoch: 8, Batch: 73,Loss: -0.093,Avg.Loss: 0.385,LR: 4.93E-04]Training epoch 8:  48%|████▊     | 73/153 [00:01<00:01, 52.95it/s, Epoch: 8, Batch: 74,Loss: 0.045,Avg.Loss: 0.381,LR: 4.93E-04] Training epoch 8:  48%|████▊     | 74/153 [00:01<00:01, 52.95it/s, Epoch: 8, Batch: 75,Loss: -0.082,Avg.Loss: 0.374,LR: 4.93E-04]Training epoch 8:  49%|████▉     | 75/153 [00:01<00:01, 52.95it/s, Epoch: 8, Batch: 76,Loss: 0.388,Avg.Loss: 0.375,LR: 4.93E-04] Training epoch 8:  50%|████▉     | 76/153 [00:01<00:01, 52.95it/s, Epoch: 8, Batch: 77,Loss: 0.249,Avg.Loss: 0.373,LR: 4.93E-04]Training epoch 8:  50%|█████     | 77/153 [00:01<00:01, 52.95it/s, Epoch: 8, Batch: 78,Loss: -0.025,Avg.Loss: 0.368,LR: 4.93E-04]Training epoch 8:  51%|█████     | 78/153 [00:01<00:01, 53.01it/s, Epoch: 8, Batch: 78,Loss: -0.025,Avg.Loss: 0.368,LR: 4.93E-04]Training epoch 8:  51%|█████     | 78/153 [00:01<00:01, 53.01it/s, Epoch: 8, Batch: 79,Loss: -0.053,Avg.Loss: 0.363,LR: 4.93E-04]Training epoch 8:  52%|█████▏    | 79/153 [00:01<00:01, 53.01it/s, Epoch: 8, Batch: 80,Loss: 0.467,Avg.Loss: 0.364,LR: 4.93E-04] Training epoch 8:  52%|█████▏    | 80/153 [00:01<00:01, 53.01it/s, Epoch: 8, Batch: 81,Loss: -0.026,Avg.Loss: 0.359,LR: 4.93E-04]Training epoch 8:  53%|█████▎    | 81/153 [00:01<00:01, 53.01it/s, Epoch: 8, Batch: 82,Loss: 0.572,Avg.Loss: 0.362,LR: 4.93E-04] Training epoch 8:  54%|█████▎    | 82/153 [00:01<00:01, 53.01it/s, Epoch: 8, Batch: 83,Loss: 1.520,Avg.Loss: 0.376,LR: 4.93E-04]Training epoch 8:  54%|█████▍    | 83/153 [00:01<00:01, 53.01it/s, Epoch: 8, Batch: 84,Loss: 0.458,Avg.Loss: 0.377,LR: 4.93E-04]Training epoch 8:  55%|█████▍    | 84/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 84,Loss: 0.458,Avg.Loss: 0.377,LR: 4.93E-04]Training epoch 8:  55%|█████▍    | 84/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 85,Loss: 0.056,Avg.Loss: 0.373,LR: 4.93E-04]Training epoch 8:  56%|█████▌    | 85/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 86,Loss: 1.102,Avg.Loss: 0.381,LR: 4.93E-04]Training epoch 8:  56%|█████▌    | 86/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 87,Loss: 1.904,Avg.Loss: 0.399,LR: 4.93E-04]Training epoch 8:  57%|█████▋    | 87/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 88,Loss: 2.364,Avg.Loss: 0.421,LR: 4.93E-04]Training epoch 8:  58%|█████▊    | 88/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 89,Loss: 0.522,Avg.Loss: 0.422,LR: 4.93E-04]Training epoch 8:  58%|█████▊    | 89/153 [00:01<00:01, 52.72it/s, Epoch: 8, Batch: 90,Loss: -0.069,Avg.Loss: 0.417,LR: 4.93E-04]Training epoch 8:  59%|█████▉    | 90/153 [00:01<00:01, 52.87it/s, Epoch: 8, Batch: 90,Loss: -0.069,Avg.Loss: 0.417,LR: 4.93E-04]Training epoch 8:  59%|█████▉    | 90/153 [00:01<00:01, 52.87it/s, Epoch: 8, Batch: 91,Loss: 1.411,Avg.Loss: 0.428,LR: 4.93E-04] Training epoch 8:  59%|█████▉    | 91/153 [00:01<00:01, 52.87it/s, Epoch: 8, Batch: 92,Loss: 4.595,Avg.Loss: 0.473,LR: 4.93E-04]Training epoch 8:  60%|██████    | 92/153 [00:01<00:01, 52.87it/s, Epoch: 8, Batch: 93,Loss: 5.782,Avg.Loss: 0.530,LR: 4.93E-04]Training epoch 8:  61%|██████    | 93/153 [00:01<00:01, 52.87it/s, Epoch: 8, Batch: 94,Loss: 3.175,Avg.Loss: 0.558,LR: 4.93E-04]Training epoch 8:  61%|██████▏   | 94/153 [00:01<00:01, 52.87it/s, Epoch: 8, Batch: 95,Loss: 1.205,Avg.Loss: 0.565,LR: 4.93E-04]Training epoch 8:  62%|██████▏   | 95/153 [00:01<00:01, 52.87it/s, Epoch: 8, Batch: 96,Loss: -0.098,Avg.Loss: 0.558,LR: 4.93E-04]Training epoch 8:  63%|██████▎   | 96/153 [00:01<00:01, 53.02it/s, Epoch: 8, Batch: 96,Loss: -0.098,Avg.Loss: 0.558,LR: 4.93E-04]Training epoch 8:  63%|██████▎   | 96/153 [00:01<00:01, 53.02it/s, Epoch: 8, Batch: 97,Loss: 0.329,Avg.Loss: 0.556,LR: 4.93E-04] Training epoch 8:  63%|██████▎   | 97/153 [00:01<00:01, 53.02it/s, Epoch: 8, Batch: 98,Loss: 0.815,Avg.Loss: 0.558,LR: 4.93E-04]Training epoch 8:  64%|██████▍   | 98/153 [00:01<00:01, 53.02it/s, Epoch: 8, Batch: 99,Loss: 0.020,Avg.Loss: 0.553,LR: 4.93E-04]Training epoch 8:  65%|██████▍   | 99/153 [00:01<00:01, 53.02it/s, Epoch: 8, Batch: 100,Loss: 0.229,Avg.Loss: 0.550,LR: 4.93E-04]Training epoch 8:  65%|██████▌   | 100/153 [00:01<00:00, 53.02it/s, Epoch: 8, Batch: 101,Loss: 0.653,Avg.Loss: 0.551,LR: 4.93E-04]Training epoch 8:  66%|██████▌   | 101/153 [00:01<00:00, 53.02it/s, Epoch: 8, Batch: 102,Loss: 0.043,Avg.Loss: 0.546,LR: 4.93E-04]Training epoch 8:  67%|██████▋   | 102/153 [00:01<00:00, 53.05it/s, Epoch: 8, Batch: 102,Loss: 0.043,Avg.Loss: 0.546,LR: 4.93E-04]Training epoch 8:  67%|██████▋   | 102/153 [00:01<00:00, 53.05it/s, Epoch: 8, Batch: 103,Loss: 0.179,Avg.Loss: 0.542,LR: 4.93E-04]Training epoch 8:  67%|██████▋   | 103/153 [00:01<00:00, 53.05it/s, Epoch: 8, Batch: 104,Loss: 0.302,Avg.Loss: 0.540,LR: 4.93E-04]Training epoch 8:  68%|██████▊   | 104/153 [00:01<00:00, 53.05it/s, Epoch: 8, Batch: 105,Loss: -0.062,Avg.Loss: 0.534,LR: 4.93E-04]Training epoch 8:  69%|██████▊   | 105/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 106,Loss: 0.285,Avg.Loss: 0.532,LR: 4.93E-04] Training epoch 8:  69%|██████▉   | 106/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 107,Loss: -0.000,Avg.Loss: 0.527,LR: 4.93E-04]Training epoch 8:  70%|██████▉   | 107/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 108,Loss: 0.172,Avg.Loss: 0.524,LR: 4.93E-04] Training epoch 8:  71%|███████   | 108/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 108,Loss: 0.172,Avg.Loss: 0.524,LR: 4.93E-04]Training epoch 8:  71%|███████   | 108/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 109,Loss: 0.077,Avg.Loss: 0.519,LR: 4.93E-04]Training epoch 8:  71%|███████   | 109/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 110,Loss: 0.186,Avg.Loss: 0.516,LR: 4.93E-04]Training epoch 8:  72%|███████▏  | 110/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 111,Loss: 0.218,Avg.Loss: 0.514,LR: 4.93E-04]Training epoch 8:  73%|███████▎  | 111/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 112,Loss: -0.285,Avg.Loss: 0.507,LR: 4.93E-04]Training epoch 8:  73%|███████▎  | 112/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 113,Loss: -0.118,Avg.Loss: 0.501,LR: 4.93E-04]Training epoch 8:  74%|███████▍  | 113/153 [00:02<00:00, 53.05it/s, Epoch: 8, Batch: 114,Loss: 0.255,Avg.Loss: 0.499,LR: 4.93E-04] Training epoch 8:  75%|███████▍  | 114/153 [00:02<00:00, 53.20it/s, Epoch: 8, Batch: 114,Loss: 0.255,Avg.Loss: 0.499,LR: 4.93E-04]Training epoch 8:  75%|███████▍  | 114/153 [00:02<00:00, 53.20it/s, Epoch: 8, Batch: 115,Loss: 0.364,Avg.Loss: 0.498,LR: 4.93E-04]Training epoch 8:  75%|███████▌  | 115/153 [00:02<00:00, 53.20it/s, Epoch: 8, Batch: 116,Loss: 0.043,Avg.Loss: 0.494,LR: 4.93E-04]Training epoch 8:  76%|███████▌  | 116/153 [00:02<00:00, 53.20it/s, Epoch: 8, Batch: 117,Loss: 0.567,Avg.Loss: 0.494,LR: 4.93E-04]Training epoch 8:  76%|███████▋  | 117/153 [00:02<00:00, 53.20it/s, Epoch: 8, Batch: 118,Loss: -0.075,Avg.Loss: 0.490,LR: 4.93E-04]Training epoch 8:  77%|███████▋  | 118/153 [00:02<00:00, 53.20it/s, Epoch: 8, Batch: 119,Loss: 0.330,Avg.Loss: 0.488,LR: 4.93E-04] Training epoch 8:  78%|███████▊  | 119/153 [00:02<00:00, 53.20it/s, Epoch: 8, Batch: 120,Loss: 0.532,Avg.Loss: 0.489,LR: 4.93E-04]Training epoch 8:  78%|███████▊  | 120/153 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 120,Loss: 0.532,Avg.Loss: 0.489,LR: 4.93E-04]Training epoch 8:  78%|███████▊  | 120/153 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 121,Loss: 0.418,Avg.Loss: 0.488,LR: 4.93E-04]Training epoch 8:  79%|███████▉  | 121/153 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 122,Loss: 0.068,Avg.Loss: 0.485,LR: 4.93E-04]Training epoch 8:  80%|███████▉  | 122/153 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 123,Loss: 0.475,Avg.Loss: 0.485,LR: 4.93E-04]Training epoch 8:  80%|████████  | 123/153 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 124,Loss: 1.076,Avg.Loss: 0.489,LR: 4.93E-04]Training epoch 8:  81%|████████  | 124/153 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 125,Loss: 1.431,Avg.Loss: 0.497,LR: 4.92E-04]Training epoch 8:  82%|████████▏ | 125/153 [00:02<00:00, 53.25it/s, Epoch: 8, Batch: 126,Loss: 0.344,Avg.Loss: 0.496,LR: 4.92E-04]Training epoch 8:  82%|████████▏ | 126/153 [00:02<00:00, 53.62it/s, Epoch: 8, Batch: 126,Loss: 0.344,Avg.Loss: 0.496,LR: 4.92E-04]Training epoch 8:  82%|████████▏ | 126/153 [00:02<00:00, 53.62it/s, Epoch: 8, Batch: 127,Loss: 1.336,Avg.Loss: 0.502,LR: 4.92E-04]Training epoch 8:  83%|████████▎ | 127/153 [00:02<00:00, 53.62it/s, Epoch: 8, Batch: 128,Loss: 1.698,Avg.Loss: 0.512,LR: 4.92E-04]Training epoch 8:  84%|████████▎ | 128/153 [00:02<00:00, 53.62it/s, Epoch: 8, Batch: 129,Loss: 1.776,Avg.Loss: 0.521,LR: 4.92E-04]Training epoch 8:  84%|████████▍ | 129/153 [00:02<00:00, 53.62it/s, Epoch: 8, Batch: 130,Loss: 0.382,Avg.Loss: 0.520,LR: 4.92E-04]Training epoch 8:  85%|████████▍ | 130/153 [00:02<00:00, 53.62it/s, Epoch: 8, Batch: 131,Loss: 0.400,Avg.Loss: 0.519,LR: 4.92E-04]Training epoch 8:  86%|████████▌ | 131/153 [00:02<00:00, 53.62it/s, Epoch: 8, Batch: 132,Loss: 0.740,Avg.Loss: 0.521,LR: 4.92E-04]Training epoch 8:  86%|████████▋ | 132/153 [00:02<00:00, 53.56it/s, Epoch: 8, Batch: 132,Loss: 0.740,Avg.Loss: 0.521,LR: 4.92E-04]Training epoch 8:  86%|████████▋ | 132/153 [00:02<00:00, 53.56it/s, Epoch: 8, Batch: 133,Loss: 0.725,Avg.Loss: 0.523,LR: 4.92E-04]Training epoch 8:  87%|████████▋ | 133/153 [00:02<00:00, 53.56it/s, Epoch: 8, Batch: 134,Loss: 0.604,Avg.Loss: 0.523,LR: 4.92E-04]Training epoch 8:  88%|████████▊ | 134/153 [00:02<00:00, 53.56it/s, Epoch: 8, Batch: 135,Loss: 0.668,Avg.Loss: 0.524,LR: 4.92E-04]Training epoch 8:  88%|████████▊ | 135/153 [00:02<00:00, 53.56it/s, Epoch: 8, Batch: 136,Loss: 1.004,Avg.Loss: 0.528,LR: 4.92E-04]Training epoch 8:  89%|████████▉ | 136/153 [00:02<00:00, 53.56it/s, Epoch: 8, Batch: 137,Loss: 1.008,Avg.Loss: 0.531,LR: 4.92E-04]Training epoch 8:  90%|████████▉ | 137/153 [00:02<00:00, 53.56it/s, Epoch: 8, Batch: 138,Loss: -0.077,Avg.Loss: 0.527,LR: 4.92E-04]Training epoch 8:  90%|█████████ | 138/153 [00:02<00:00, 53.61it/s, Epoch: 8, Batch: 138,Loss: -0.077,Avg.Loss: 0.527,LR: 4.92E-04]Training epoch 8:  90%|█████████ | 138/153 [00:02<00:00, 53.61it/s, Epoch: 8, Batch: 139,Loss: 0.362,Avg.Loss: 0.526,LR: 4.92E-04] Training epoch 8:  91%|█████████ | 139/153 [00:02<00:00, 53.61it/s, Epoch: 8, Batch: 140,Loss: 0.529,Avg.Loss: 0.526,LR: 4.92E-04]Training epoch 8:  92%|█████████▏| 140/153 [00:02<00:00, 53.61it/s, Epoch: 8, Batch: 141,Loss: 1.421,Avg.Loss: 0.532,LR: 4.92E-04]Training epoch 8:  92%|█████████▏| 141/153 [00:02<00:00, 53.61it/s, Epoch: 8, Batch: 142,Loss: 0.066,Avg.Loss: 0.529,LR: 4.92E-04]Training epoch 8:  93%|█████████▎| 142/153 [00:02<00:00, 53.61it/s, Epoch: 8, Batch: 143,Loss: 0.405,Avg.Loss: 0.528,LR: 4.92E-04]Training epoch 8:  93%|█████████▎| 143/153 [00:02<00:00, 53.61it/s, Epoch: 8, Batch: 144,Loss: 0.529,Avg.Loss: 0.528,LR: 4.92E-04]Training epoch 8:  94%|█████████▍| 144/153 [00:02<00:00, 53.72it/s, Epoch: 8, Batch: 144,Loss: 0.529,Avg.Loss: 0.528,LR: 4.92E-04]Training epoch 8:  94%|█████████▍| 144/153 [00:02<00:00, 53.72it/s, Epoch: 8, Batch: 145,Loss: 0.774,Avg.Loss: 0.530,LR: 4.92E-04]Training epoch 8:  95%|█████████▍| 145/153 [00:02<00:00, 53.72it/s, Epoch: 8, Batch: 146,Loss: 0.237,Avg.Loss: 0.528,LR: 4.92E-04]Training epoch 8:  95%|█████████▌| 146/153 [00:02<00:00, 53.72it/s, Epoch: 8, Batch: 147,Loss: 0.093,Avg.Loss: 0.525,LR: 4.92E-04]Training epoch 8:  96%|█████████▌| 147/153 [00:02<00:00, 53.72it/s, Epoch: 8, Batch: 148,Loss: 0.328,Avg.Loss: 0.523,LR: 4.92E-04]Training epoch 8:  97%|█████████▋| 148/153 [00:02<00:00, 53.72it/s, Epoch: 8, Batch: 149,Loss: 0.020,Avg.Loss: 0.520,LR: 4.92E-04]Training epoch 8:  97%|█████████▋| 149/153 [00:02<00:00, 53.72it/s, Epoch: 8, Batch: 150,Loss: -0.163,Avg.Loss: 0.515,LR: 4.92E-04]Training epoch 8:  98%|█████████▊| 150/153 [00:02<00:00, 53.21it/s, Epoch: 8, Batch: 150,Loss: -0.163,Avg.Loss: 0.515,LR: 4.92E-04]Training epoch 8:  98%|█████████▊| 150/153 [00:02<00:00, 53.21it/s, Epoch: 8, Batch: 151,Loss: 0.000,Avg.Loss: 0.512,LR: 4.92E-04] Training epoch 8:  99%|█████████▊| 151/153 [00:02<00:00, 53.21it/s, Epoch: 8, Batch: 152,Loss: 0.028,Avg.Loss: 0.509,LR: 4.92E-04]Training epoch 8:  99%|█████████▉| 152/153 [00:02<00:00, 53.21it/s, Epoch: 8, Batch: 153,Loss: -0.235,Avg.Loss: 0.504,LR: 4.92E-04]Training epoch 8: 100%|██████████| 153/153 [00:02<00:00, 53.02it/s, Epoch: 8, Batch: 153,Loss: -0.235,Avg.Loss: 0.504,LR: 4.92E-04]
Training epoch 9:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 9:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 9, Batch: 1,Loss: 0.407,Avg.Loss: 0.407,LR: 4.92E-04]Training epoch 9:   1%|          | 1/153 [00:00<00:05, 27.71it/s, Epoch: 9, Batch: 2,Loss: 0.069,Avg.Loss: 0.238,LR: 4.92E-04]Training epoch 9:   1%|▏         | 2/153 [00:00<00:03, 39.75it/s, Epoch: 9, Batch: 3,Loss: 0.308,Avg.Loss: 0.261,LR: 4.92E-04]Training epoch 9:   2%|▏         | 3/153 [00:00<00:03, 47.02it/s, Epoch: 9, Batch: 4,Loss: 0.033,Avg.Loss: 0.204,LR: 4.92E-04]Training epoch 9:   3%|▎         | 4/153 [00:00<00:02, 51.13it/s, Epoch: 9, Batch: 5,Loss: 0.191,Avg.Loss: 0.202,LR: 4.92E-04]Training epoch 9:   3%|▎         | 5/153 [00:00<00:02, 51.80it/s, Epoch: 9, Batch: 6,Loss: -0.017,Avg.Loss: 0.165,LR: 4.92E-04]Training epoch 9:   4%|▍         | 6/153 [00:00<00:02, 51.96it/s, Epoch: 9, Batch: 7,Loss: 0.212,Avg.Loss: 0.172,LR: 4.92E-04] Training epoch 9:   5%|▍         | 7/153 [00:00<00:02, 60.52it/s, Epoch: 9, Batch: 7,Loss: 0.212,Avg.Loss: 0.172,LR: 4.92E-04]Training epoch 9:   5%|▍         | 7/153 [00:00<00:02, 60.52it/s, Epoch: 9, Batch: 8,Loss: 0.169,Avg.Loss: 0.172,LR: 4.92E-04]Training epoch 9:   5%|▌         | 8/153 [00:00<00:02, 60.52it/s, Epoch: 9, Batch: 9,Loss: 0.556,Avg.Loss: 0.214,LR: 4.92E-04]Training epoch 9:   6%|▌         | 9/153 [00:00<00:02, 60.52it/s, Epoch: 9, Batch: 10,Loss: 0.360,Avg.Loss: 0.229,LR: 4.92E-04]Training epoch 9:   7%|▋         | 10/153 [00:00<00:02, 60.52it/s, Epoch: 9, Batch: 11,Loss: 0.533,Avg.Loss: 0.256,LR: 4.92E-04]Training epoch 9:   7%|▋         | 11/153 [00:00<00:02, 60.52it/s, Epoch: 9, Batch: 12,Loss: 0.305,Avg.Loss: 0.261,LR: 4.92E-04]Training epoch 9:   8%|▊         | 12/153 [00:00<00:02, 60.52it/s, Epoch: 9, Batch: 13,Loss: 0.281,Avg.Loss: 0.262,LR: 4.92E-04]Training epoch 9:   8%|▊         | 13/153 [00:00<00:02, 60.52it/s, Epoch: 9, Batch: 14,Loss: 0.350,Avg.Loss: 0.268,LR: 4.92E-04]Training epoch 9:   9%|▉         | 14/153 [00:00<00:02, 55.70it/s, Epoch: 9, Batch: 14,Loss: 0.350,Avg.Loss: 0.268,LR: 4.92E-04]Training epoch 9:   9%|▉         | 14/153 [00:00<00:02, 55.70it/s, Epoch: 9, Batch: 15,Loss: 0.278,Avg.Loss: 0.269,LR: 4.92E-04]Training epoch 9:  10%|▉         | 15/153 [00:00<00:02, 55.70it/s, Epoch: 9, Batch: 16,Loss: 0.385,Avg.Loss: 0.276,LR: 4.92E-04]Training epoch 9:  10%|█         | 16/153 [00:00<00:02, 55.70it/s, Epoch: 9, Batch: 17,Loss: -0.019,Avg.Loss: 0.259,LR: 4.92E-04]Training epoch 9:  11%|█         | 17/153 [00:00<00:02, 55.70it/s, Epoch: 9, Batch: 18,Loss: -0.024,Avg.Loss: 0.243,LR: 4.92E-04]Training epoch 9:  12%|█▏        | 18/153 [00:00<00:02, 55.70it/s, Epoch: 9, Batch: 19,Loss: 0.534,Avg.Loss: 0.259,LR: 4.92E-04] Training epoch 9:  12%|█▏        | 19/153 [00:00<00:02, 55.70it/s, Epoch: 9, Batch: 20,Loss: 0.115,Avg.Loss: 0.251,LR: 4.92E-04]Training epoch 9:  13%|█▎        | 20/153 [00:00<00:02, 54.51it/s, Epoch: 9, Batch: 20,Loss: 0.115,Avg.Loss: 0.251,LR: 4.92E-04]Training epoch 9:  13%|█▎        | 20/153 [00:00<00:02, 54.51it/s, Epoch: 9, Batch: 21,Loss: 0.351,Avg.Loss: 0.256,LR: 4.92E-04]Training epoch 9:  14%|█▎        | 21/153 [00:00<00:02, 54.51it/s, Epoch: 9, Batch: 22,Loss: 0.330,Avg.Loss: 0.260,LR: 4.92E-04]Training epoch 9:  14%|█▍        | 22/153 [00:00<00:02, 54.51it/s, Epoch: 9, Batch: 23,Loss: 0.633,Avg.Loss: 0.276,LR: 4.92E-04]Training epoch 9:  15%|█▌        | 23/153 [00:00<00:02, 54.51it/s, Epoch: 9, Batch: 24,Loss: 0.098,Avg.Loss: 0.268,LR: 4.92E-04]Training epoch 9:  16%|█▌        | 24/153 [00:00<00:02, 54.51it/s, Epoch: 9, Batch: 25,Loss: 0.042,Avg.Loss: 0.259,LR: 4.92E-04]Training epoch 9:  16%|█▋        | 25/153 [00:00<00:02, 54.51it/s, Epoch: 9, Batch: 26,Loss: -0.085,Avg.Loss: 0.246,LR: 4.92E-04]Training epoch 9:  17%|█▋        | 26/153 [00:00<00:02, 53.47it/s, Epoch: 9, Batch: 26,Loss: -0.085,Avg.Loss: 0.246,LR: 4.92E-04]Training epoch 9:  17%|█▋        | 26/153 [00:00<00:02, 53.47it/s, Epoch: 9, Batch: 27,Loss: 0.061,Avg.Loss: 0.239,LR: 4.92E-04] Training epoch 9:  18%|█▊        | 27/153 [00:00<00:02, 53.47it/s, Epoch: 9, Batch: 28,Loss: -0.220,Avg.Loss: 0.223,LR: 4.92E-04]Training epoch 9:  18%|█▊        | 28/153 [00:00<00:02, 53.47it/s, Epoch: 9, Batch: 29,Loss: -0.046,Avg.Loss: 0.214,LR: 4.92E-04]Training epoch 9:  19%|█▉        | 29/153 [00:00<00:02, 53.47it/s, Epoch: 9, Batch: 30,Loss: -0.210,Avg.Loss: 0.199,LR: 4.92E-04]Training epoch 9:  20%|█▉        | 30/153 [00:00<00:02, 53.47it/s, Epoch: 9, Batch: 31,Loss: -0.038,Avg.Loss: 0.192,LR: 4.92E-04]Training epoch 9:  20%|██        | 31/153 [00:00<00:02, 53.47it/s, Epoch: 9, Batch: 32,Loss: 0.172,Avg.Loss: 0.191,LR: 4.92E-04] Training epoch 9:  21%|██        | 32/153 [00:00<00:02, 53.00it/s, Epoch: 9, Batch: 32,Loss: 0.172,Avg.Loss: 0.191,LR: 4.92E-04]Training epoch 9:  21%|██        | 32/153 [00:00<00:02, 53.00it/s, Epoch: 9, Batch: 33,Loss: -0.170,Avg.Loss: 0.180,LR: 4.92E-04]Training epoch 9:  22%|██▏       | 33/153 [00:00<00:02, 53.00it/s, Epoch: 9, Batch: 34,Loss: 0.565,Avg.Loss: 0.192,LR: 4.92E-04] Training epoch 9:  22%|██▏       | 34/153 [00:00<00:02, 53.00it/s, Epoch: 9, Batch: 35,Loss: 0.525,Avg.Loss: 0.201,LR: 4.92E-04]Training epoch 9:  23%|██▎       | 35/153 [00:00<00:02, 53.00it/s, Epoch: 9, Batch: 36,Loss: 0.081,Avg.Loss: 0.198,LR: 4.92E-04]Training epoch 9:  24%|██▎       | 36/153 [00:00<00:02, 53.00it/s, Epoch: 9, Batch: 37,Loss: 0.613,Avg.Loss: 0.209,LR: 4.92E-04]Training epoch 9:  24%|██▍       | 37/153 [00:00<00:02, 53.00it/s, Epoch: 9, Batch: 38,Loss: -0.148,Avg.Loss: 0.200,LR: 4.92E-04]Training epoch 9:  25%|██▍       | 38/153 [00:00<00:02, 52.99it/s, Epoch: 9, Batch: 38,Loss: -0.148,Avg.Loss: 0.200,LR: 4.92E-04]Training epoch 9:  25%|██▍       | 38/153 [00:00<00:02, 52.99it/s, Epoch: 9, Batch: 39,Loss: 0.113,Avg.Loss: 0.197,LR: 4.92E-04] Training epoch 9:  25%|██▌       | 39/153 [00:00<00:02, 52.99it/s, Epoch: 9, Batch: 40,Loss: -0.180,Avg.Loss: 0.188,LR: 4.92E-04]Training epoch 9:  26%|██▌       | 40/153 [00:00<00:02, 52.99it/s, Epoch: 9, Batch: 41,Loss: -0.061,Avg.Loss: 0.182,LR: 4.92E-04]Training epoch 9:  27%|██▋       | 41/153 [00:00<00:02, 52.99it/s, Epoch: 9, Batch: 42,Loss: 0.610,Avg.Loss: 0.192,LR: 4.92E-04] Training epoch 9:  27%|██▋       | 42/153 [00:00<00:02, 52.99it/s, Epoch: 9, Batch: 43,Loss: -0.011,Avg.Loss: 0.187,LR: 4.92E-04]Training epoch 9:  28%|██▊       | 43/153 [00:00<00:02, 52.99it/s, Epoch: 9, Batch: 44,Loss: 0.162,Avg.Loss: 0.187,LR: 4.92E-04] Training epoch 9:  29%|██▉       | 44/153 [00:00<00:02, 52.91it/s, Epoch: 9, Batch: 44,Loss: 0.162,Avg.Loss: 0.187,LR: 4.92E-04]Training epoch 9:  29%|██▉       | 44/153 [00:00<00:02, 52.91it/s, Epoch: 9, Batch: 45,Loss: 0.174,Avg.Loss: 0.186,LR: 4.92E-04]Training epoch 9:  29%|██▉       | 45/153 [00:00<00:02, 52.91it/s, Epoch: 9, Batch: 46,Loss: -0.178,Avg.Loss: 0.179,LR: 4.92E-04]Training epoch 9:  30%|███       | 46/153 [00:00<00:02, 52.91it/s, Epoch: 9, Batch: 47,Loss: -0.184,Avg.Loss: 0.171,LR: 4.92E-04]Training epoch 9:  31%|███       | 47/153 [00:00<00:02, 52.91it/s, Epoch: 9, Batch: 48,Loss: -0.044,Avg.Loss: 0.166,LR: 4.92E-04]Training epoch 9:  31%|███▏      | 48/153 [00:00<00:01, 52.91it/s, Epoch: 9, Batch: 49,Loss: 0.118,Avg.Loss: 0.165,LR: 4.92E-04] Training epoch 9:  32%|███▏      | 49/153 [00:00<00:01, 52.91it/s, Epoch: 9, Batch: 50,Loss: 0.183,Avg.Loss: 0.166,LR: 4.91E-04]Training epoch 9:  33%|███▎      | 50/153 [00:00<00:01, 52.84it/s, Epoch: 9, Batch: 50,Loss: 0.183,Avg.Loss: 0.166,LR: 4.91E-04]Training epoch 9:  33%|███▎      | 50/153 [00:00<00:01, 52.84it/s, Epoch: 9, Batch: 51,Loss: 0.352,Avg.Loss: 0.169,LR: 4.91E-04]Training epoch 9:  33%|███▎      | 51/153 [00:00<00:01, 52.84it/s, Epoch: 9, Batch: 52,Loss: -0.073,Avg.Loss: 0.165,LR: 4.91E-04]Training epoch 9:  34%|███▍      | 52/153 [00:00<00:01, 52.84it/s, Epoch: 9, Batch: 53,Loss: 0.005,Avg.Loss: 0.162,LR: 4.91E-04] Training epoch 9:  35%|███▍      | 53/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 54,Loss: 0.168,Avg.Loss: 0.162,LR: 4.91E-04]Training epoch 9:  35%|███▌      | 54/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 55,Loss: 0.088,Avg.Loss: 0.160,LR: 4.91E-04]Training epoch 9:  36%|███▌      | 55/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 56,Loss: 0.102,Avg.Loss: 0.159,LR: 4.91E-04]Training epoch 9:  37%|███▋      | 56/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 56,Loss: 0.102,Avg.Loss: 0.159,LR: 4.91E-04]Training epoch 9:  37%|███▋      | 56/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 57,Loss: 0.437,Avg.Loss: 0.164,LR: 4.91E-04]Training epoch 9:  37%|███▋      | 57/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 58,Loss: 0.320,Avg.Loss: 0.167,LR: 4.91E-04]Training epoch 9:  38%|███▊      | 58/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 59,Loss: -0.111,Avg.Loss: 0.162,LR: 4.91E-04]Training epoch 9:  39%|███▊      | 59/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 60,Loss: -0.073,Avg.Loss: 0.158,LR: 4.91E-04]Training epoch 9:  39%|███▉      | 60/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 61,Loss: -0.076,Avg.Loss: 0.155,LR: 4.91E-04]Training epoch 9:  40%|███▉      | 61/153 [00:01<00:01, 52.84it/s, Epoch: 9, Batch: 62,Loss: 0.050,Avg.Loss: 0.153,LR: 4.91E-04] Training epoch 9:  41%|████      | 62/153 [00:01<00:01, 53.04it/s, Epoch: 9, Batch: 62,Loss: 0.050,Avg.Loss: 0.153,LR: 4.91E-04]Training epoch 9:  41%|████      | 62/153 [00:01<00:01, 53.04it/s, Epoch: 9, Batch: 63,Loss: 0.267,Avg.Loss: 0.155,LR: 4.91E-04]Training epoch 9:  41%|████      | 63/153 [00:01<00:01, 53.04it/s, Epoch: 9, Batch: 64,Loss: 0.507,Avg.Loss: 0.160,LR: 4.91E-04]Training epoch 9:  42%|████▏     | 64/153 [00:01<00:01, 53.04it/s, Epoch: 9, Batch: 65,Loss: 0.171,Avg.Loss: 0.160,LR: 4.91E-04]Training epoch 9:  42%|████▏     | 65/153 [00:01<00:01, 53.04it/s, Epoch: 9, Batch: 66,Loss: 0.200,Avg.Loss: 0.161,LR: 4.91E-04]Training epoch 9:  43%|████▎     | 66/153 [00:01<00:01, 53.04it/s, Epoch: 9, Batch: 67,Loss: 0.316,Avg.Loss: 0.163,LR: 4.91E-04]Training epoch 9:  44%|████▍     | 67/153 [00:01<00:01, 53.04it/s, Epoch: 9, Batch: 68,Loss: 0.018,Avg.Loss: 0.161,LR: 4.91E-04]Training epoch 9:  44%|████▍     | 68/153 [00:01<00:01, 53.02it/s, Epoch: 9, Batch: 68,Loss: 0.018,Avg.Loss: 0.161,LR: 4.91E-04]Training epoch 9:  44%|████▍     | 68/153 [00:01<00:01, 53.02it/s, Epoch: 9, Batch: 69,Loss: 0.246,Avg.Loss: 0.162,LR: 4.91E-04]Training epoch 9:  45%|████▌     | 69/153 [00:01<00:01, 53.02it/s, Epoch: 9, Batch: 70,Loss: -0.147,Avg.Loss: 0.158,LR: 4.91E-04]Training epoch 9:  46%|████▌     | 70/153 [00:01<00:01, 53.02it/s, Epoch: 9, Batch: 71,Loss: 0.046,Avg.Loss: 0.156,LR: 4.91E-04] Training epoch 9:  46%|████▋     | 71/153 [00:01<00:01, 53.02it/s, Epoch: 9, Batch: 72,Loss: -0.006,Avg.Loss: 0.154,LR: 4.91E-04]Training epoch 9:  47%|████▋     | 72/153 [00:01<00:01, 53.02it/s, Epoch: 9, Batch: 73,Loss: 0.377,Avg.Loss: 0.157,LR: 4.91E-04] Training epoch 9:  48%|████▊     | 73/153 [00:01<00:01, 53.02it/s, Epoch: 9, Batch: 74,Loss: 1.115,Avg.Loss: 0.170,LR: 4.91E-04]Training epoch 9:  48%|████▊     | 74/153 [00:01<00:01, 53.15it/s, Epoch: 9, Batch: 74,Loss: 1.115,Avg.Loss: 0.170,LR: 4.91E-04]Training epoch 9:  48%|████▊     | 74/153 [00:01<00:01, 53.15it/s, Epoch: 9, Batch: 75,Loss: 1.072,Avg.Loss: 0.182,LR: 4.91E-04]Training epoch 9:  49%|████▉     | 75/153 [00:01<00:01, 53.15it/s, Epoch: 9, Batch: 76,Loss: -0.297,Avg.Loss: 0.176,LR: 4.91E-04]Training epoch 9:  50%|████▉     | 76/153 [00:01<00:01, 53.15it/s, Epoch: 9, Batch: 77,Loss: 0.004,Avg.Loss: 0.174,LR: 4.91E-04] Training epoch 9:  50%|█████     | 77/153 [00:01<00:01, 53.15it/s, Epoch: 9, Batch: 78,Loss: 0.144,Avg.Loss: 0.173,LR: 4.91E-04]Training epoch 9:  51%|█████     | 78/153 [00:01<00:01, 53.15it/s, Epoch: 9, Batch: 79,Loss: 0.255,Avg.Loss: 0.174,LR: 4.91E-04]Training epoch 9:  52%|█████▏    | 79/153 [00:01<00:01, 53.15it/s, Epoch: 9, Batch: 80,Loss: 0.031,Avg.Loss: 0.172,LR: 4.91E-04]Training epoch 9:  52%|█████▏    | 80/153 [00:01<00:01, 53.22it/s, Epoch: 9, Batch: 80,Loss: 0.031,Avg.Loss: 0.172,LR: 4.91E-04]Training epoch 9:  52%|█████▏    | 80/153 [00:01<00:01, 53.22it/s, Epoch: 9, Batch: 81,Loss: -0.061,Avg.Loss: 0.170,LR: 4.91E-04]Training epoch 9:  53%|█████▎    | 81/153 [00:01<00:01, 53.22it/s, Epoch: 9, Batch: 82,Loss: -0.104,Avg.Loss: 0.166,LR: 4.91E-04]Training epoch 9:  54%|█████▎    | 82/153 [00:01<00:01, 53.22it/s, Epoch: 9, Batch: 83,Loss: 0.100,Avg.Loss: 0.165,LR: 4.91E-04] Training epoch 9:  54%|█████▍    | 83/153 [00:01<00:01, 53.22it/s, Epoch: 9, Batch: 84,Loss: 0.003,Avg.Loss: 0.163,LR: 4.91E-04]Training epoch 9:  55%|█████▍    | 84/153 [00:01<00:01, 53.22it/s, Epoch: 9, Batch: 85,Loss: 0.215,Avg.Loss: 0.164,LR: 4.91E-04]Training epoch 9:  56%|█████▌    | 85/153 [00:01<00:01, 53.22it/s, Epoch: 9, Batch: 86,Loss: 0.261,Avg.Loss: 0.165,LR: 4.91E-04]Training epoch 9:  56%|█████▌    | 86/153 [00:01<00:01, 53.29it/s, Epoch: 9, Batch: 86,Loss: 0.261,Avg.Loss: 0.165,LR: 4.91E-04]Training epoch 9:  56%|█████▌    | 86/153 [00:01<00:01, 53.29it/s, Epoch: 9, Batch: 87,Loss: 0.510,Avg.Loss: 0.169,LR: 4.91E-04]Training epoch 9:  57%|█████▋    | 87/153 [00:01<00:01, 53.29it/s, Epoch: 9, Batch: 88,Loss: 1.726,Avg.Loss: 0.187,LR: 4.91E-04]Training epoch 9:  58%|█████▊    | 88/153 [00:01<00:01, 53.29it/s, Epoch: 9, Batch: 89,Loss: 2.314,Avg.Loss: 0.211,LR: 4.91E-04]Training epoch 9:  58%|█████▊    | 89/153 [00:01<00:01, 53.29it/s, Epoch: 9, Batch: 90,Loss: 1.095,Avg.Loss: 0.221,LR: 4.91E-04]Training epoch 9:  59%|█████▉    | 90/153 [00:01<00:01, 53.29it/s, Epoch: 9, Batch: 91,Loss: 0.204,Avg.Loss: 0.220,LR: 4.91E-04]Training epoch 9:  59%|█████▉    | 91/153 [00:01<00:01, 53.29it/s, Epoch: 9, Batch: 92,Loss: 1.183,Avg.Loss: 0.231,LR: 4.91E-04]Training epoch 9:  60%|██████    | 92/153 [00:01<00:01, 53.16it/s, Epoch: 9, Batch: 92,Loss: 1.183,Avg.Loss: 0.231,LR: 4.91E-04]Training epoch 9:  60%|██████    | 92/153 [00:01<00:01, 53.16it/s, Epoch: 9, Batch: 93,Loss: 1.531,Avg.Loss: 0.245,LR: 4.91E-04]Training epoch 9:  61%|██████    | 93/153 [00:01<00:01, 53.16it/s, Epoch: 9, Batch: 94,Loss: 1.545,Avg.Loss: 0.259,LR: 4.91E-04]Training epoch 9:  61%|██████▏   | 94/153 [00:01<00:01, 53.16it/s, Epoch: 9, Batch: 95,Loss: 0.655,Avg.Loss: 0.263,LR: 4.91E-04]Training epoch 9:  62%|██████▏   | 95/153 [00:01<00:01, 53.16it/s, Epoch: 9, Batch: 96,Loss: -0.269,Avg.Loss: 0.257,LR: 4.91E-04]Training epoch 9:  63%|██████▎   | 96/153 [00:01<00:01, 53.16it/s, Epoch: 9, Batch: 97,Loss: 0.369,Avg.Loss: 0.258,LR: 4.91E-04] Training epoch 9:  63%|██████▎   | 97/153 [00:01<00:01, 53.16it/s, Epoch: 9, Batch: 98,Loss: 0.640,Avg.Loss: 0.262,LR: 4.91E-04]Training epoch 9:  64%|██████▍   | 98/153 [00:01<00:01, 53.17it/s, Epoch: 9, Batch: 98,Loss: 0.640,Avg.Loss: 0.262,LR: 4.91E-04]Training epoch 9:  64%|██████▍   | 98/153 [00:01<00:01, 53.17it/s, Epoch: 9, Batch: 99,Loss: -0.072,Avg.Loss: 0.259,LR: 4.91E-04]Training epoch 9:  65%|██████▍   | 99/153 [00:01<00:01, 53.17it/s, Epoch: 9, Batch: 100,Loss: 0.278,Avg.Loss: 0.259,LR: 4.91E-04]Training epoch 9:  65%|██████▌   | 100/153 [00:01<00:00, 53.17it/s, Epoch: 9, Batch: 101,Loss: 1.539,Avg.Loss: 0.272,LR: 4.91E-04]Training epoch 9:  66%|██████▌   | 101/153 [00:01<00:00, 53.17it/s, Epoch: 9, Batch: 102,Loss: 0.992,Avg.Loss: 0.279,LR: 4.91E-04]Training epoch 9:  67%|██████▋   | 102/153 [00:01<00:00, 53.17it/s, Epoch: 9, Batch: 103,Loss: 0.511,Avg.Loss: 0.281,LR: 4.91E-04]Training epoch 9:  67%|██████▋   | 103/153 [00:01<00:00, 53.17it/s, Epoch: 9, Batch: 104,Loss: 0.522,Avg.Loss: 0.283,LR: 4.91E-04]Training epoch 9:  68%|██████▊   | 104/153 [00:01<00:00, 53.14it/s, Epoch: 9, Batch: 104,Loss: 0.522,Avg.Loss: 0.283,LR: 4.91E-04]Training epoch 9:  68%|██████▊   | 104/153 [00:01<00:00, 53.14it/s, Epoch: 9, Batch: 105,Loss: 0.798,Avg.Loss: 0.288,LR: 4.91E-04]Training epoch 9:  69%|██████▊   | 105/153 [00:01<00:00, 53.14it/s, Epoch: 9, Batch: 106,Loss: 0.352,Avg.Loss: 0.289,LR: 4.91E-04]Training epoch 9:  69%|██████▉   | 106/153 [00:02<00:00, 53.14it/s, Epoch: 9, Batch: 107,Loss: 0.114,Avg.Loss: 0.287,LR: 4.91E-04]Training epoch 9:  70%|██████▉   | 107/153 [00:02<00:00, 53.14it/s, Epoch: 9, Batch: 108,Loss: -0.158,Avg.Loss: 0.283,LR: 4.91E-04]Training epoch 9:  71%|███████   | 108/153 [00:02<00:00, 53.14it/s, Epoch: 9, Batch: 109,Loss: 0.015,Avg.Loss: 0.281,LR: 4.91E-04] Training epoch 9:  71%|███████   | 109/153 [00:02<00:00, 53.14it/s, Epoch: 9, Batch: 110,Loss: -0.028,Avg.Loss: 0.278,LR: 4.91E-04]Training epoch 9:  72%|███████▏  | 110/153 [00:02<00:00, 52.78it/s, Epoch: 9, Batch: 110,Loss: -0.028,Avg.Loss: 0.278,LR: 4.91E-04]Training epoch 9:  72%|███████▏  | 110/153 [00:02<00:00, 52.78it/s, Epoch: 9, Batch: 111,Loss: 0.105,Avg.Loss: 0.276,LR: 4.91E-04] Training epoch 9:  73%|███████▎  | 111/153 [00:02<00:00, 52.78it/s, Epoch: 9, Batch: 112,Loss: 0.407,Avg.Loss: 0.278,LR: 4.91E-04]Training epoch 9:  73%|███████▎  | 112/153 [00:02<00:00, 52.78it/s, Epoch: 9, Batch: 113,Loss: 0.423,Avg.Loss: 0.279,LR: 4.91E-04]Training epoch 9:  74%|███████▍  | 113/153 [00:02<00:00, 52.78it/s, Epoch: 9, Batch: 114,Loss: 0.265,Avg.Loss: 0.279,LR: 4.91E-04]Training epoch 9:  75%|███████▍  | 114/153 [00:02<00:00, 52.78it/s, Epoch: 9, Batch: 115,Loss: 0.246,Avg.Loss: 0.278,LR: 4.91E-04]Training epoch 9:  75%|███████▌  | 115/153 [00:02<00:00, 52.78it/s, Epoch: 9, Batch: 116,Loss: 0.945,Avg.Loss: 0.284,LR: 4.91E-04]Training epoch 9:  76%|███████▌  | 116/153 [00:02<00:00, 52.75it/s, Epoch: 9, Batch: 116,Loss: 0.945,Avg.Loss: 0.284,LR: 4.91E-04]Training epoch 9:  76%|███████▌  | 116/153 [00:02<00:00, 52.75it/s, Epoch: 9, Batch: 117,Loss: 0.263,Avg.Loss: 0.284,LR: 4.91E-04]Training epoch 9:  76%|███████▋  | 117/153 [00:02<00:00, 52.75it/s, Epoch: 9, Batch: 118,Loss: 0.094,Avg.Loss: 0.282,LR: 4.91E-04]Training epoch 9:  77%|███████▋  | 118/153 [00:02<00:00, 52.75it/s, Epoch: 9, Batch: 119,Loss: 0.225,Avg.Loss: 0.282,LR: 4.91E-04]Training epoch 9:  78%|███████▊  | 119/153 [00:02<00:00, 52.75it/s, Epoch: 9, Batch: 120,Loss: 0.025,Avg.Loss: 0.280,LR: 4.91E-04]Training epoch 9:  78%|███████▊  | 120/153 [00:02<00:00, 52.75it/s, Epoch: 9, Batch: 121,Loss: 0.059,Avg.Loss: 0.278,LR: 4.91E-04]Training epoch 9:  79%|███████▉  | 121/153 [00:02<00:00, 52.75it/s, Epoch: 9, Batch: 122,Loss: 0.498,Avg.Loss: 0.280,LR: 4.91E-04]Training epoch 9:  80%|███████▉  | 122/153 [00:02<00:00, 52.80it/s, Epoch: 9, Batch: 122,Loss: 0.498,Avg.Loss: 0.280,LR: 4.91E-04]Training epoch 9:  80%|███████▉  | 122/153 [00:02<00:00, 52.80it/s, Epoch: 9, Batch: 123,Loss: 0.011,Avg.Loss: 0.278,LR: 4.90E-04]Training epoch 9:  80%|████████  | 123/153 [00:02<00:00, 52.80it/s, Epoch: 9, Batch: 124,Loss: 0.091,Avg.Loss: 0.276,LR: 4.90E-04]Training epoch 9:  81%|████████  | 124/153 [00:02<00:00, 52.80it/s, Epoch: 9, Batch: 125,Loss: 0.391,Avg.Loss: 0.277,LR: 4.90E-04]Training epoch 9:  82%|████████▏ | 125/153 [00:02<00:00, 52.80it/s, Epoch: 9, Batch: 126,Loss: 0.663,Avg.Loss: 0.280,LR: 4.90E-04]Training epoch 9:  82%|████████▏ | 126/153 [00:02<00:00, 52.80it/s, Epoch: 9, Batch: 127,Loss: 0.755,Avg.Loss: 0.284,LR: 4.90E-04]Training epoch 9:  83%|████████▎ | 127/153 [00:02<00:00, 52.80it/s, Epoch: 9, Batch: 128,Loss: 0.536,Avg.Loss: 0.286,LR: 4.90E-04]Training epoch 9:  84%|████████▎ | 128/153 [00:02<00:00, 53.01it/s, Epoch: 9, Batch: 128,Loss: 0.536,Avg.Loss: 0.286,LR: 4.90E-04]Training epoch 9:  84%|████████▎ | 128/153 [00:02<00:00, 53.01it/s, Epoch: 9, Batch: 129,Loss: 0.721,Avg.Loss: 0.289,LR: 4.90E-04]Training epoch 9:  84%|████████▍ | 129/153 [00:02<00:00, 53.01it/s, Epoch: 9, Batch: 130,Loss: 0.596,Avg.Loss: 0.292,LR: 4.90E-04]Training epoch 9:  85%|████████▍ | 130/153 [00:02<00:00, 53.01it/s, Epoch: 9, Batch: 131,Loss: -0.051,Avg.Loss: 0.289,LR: 4.90E-04]Training epoch 9:  86%|████████▌ | 131/153 [00:02<00:00, 53.01it/s, Epoch: 9, Batch: 132,Loss: 0.755,Avg.Loss: 0.292,LR: 4.90E-04] Training epoch 9:  86%|████████▋ | 132/153 [00:02<00:00, 53.01it/s, Epoch: 9, Batch: 133,Loss: 1.100,Avg.Loss: 0.298,LR: 4.90E-04]Training epoch 9:  87%|████████▋ | 133/153 [00:02<00:00, 53.01it/s, Epoch: 9, Batch: 134,Loss: 1.781,Avg.Loss: 0.310,LR: 4.90E-04]Training epoch 9:  88%|████████▊ | 134/153 [00:02<00:00, 53.17it/s, Epoch: 9, Batch: 134,Loss: 1.781,Avg.Loss: 0.310,LR: 4.90E-04]Training epoch 9:  88%|████████▊ | 134/153 [00:02<00:00, 53.17it/s, Epoch: 9, Batch: 135,Loss: 1.039,Avg.Loss: 0.315,LR: 4.90E-04]Training epoch 9:  88%|████████▊ | 135/153 [00:02<00:00, 53.17it/s, Epoch: 9, Batch: 136,Loss: 0.075,Avg.Loss: 0.313,LR: 4.90E-04]Training epoch 9:  89%|████████▉ | 136/153 [00:02<00:00, 53.17it/s, Epoch: 9, Batch: 137,Loss: 0.092,Avg.Loss: 0.312,LR: 4.90E-04]Training epoch 9:  90%|████████▉ | 137/153 [00:02<00:00, 53.17it/s, Epoch: 9, Batch: 138,Loss: -0.131,Avg.Loss: 0.308,LR: 4.90E-04]Training epoch 9:  90%|█████████ | 138/153 [00:02<00:00, 53.17it/s, Epoch: 9, Batch: 139,Loss: 0.273,Avg.Loss: 0.308,LR: 4.90E-04] Training epoch 9:  91%|█████████ | 139/153 [00:02<00:00, 53.17it/s, Epoch: 9, Batch: 140,Loss: 0.040,Avg.Loss: 0.306,LR: 4.90E-04]Training epoch 9:  92%|█████████▏| 140/153 [00:02<00:00, 53.23it/s, Epoch: 9, Batch: 140,Loss: 0.040,Avg.Loss: 0.306,LR: 4.90E-04]Training epoch 9:  92%|█████████▏| 140/153 [00:02<00:00, 53.23it/s, Epoch: 9, Batch: 141,Loss: 0.035,Avg.Loss: 0.304,LR: 4.90E-04]Training epoch 9:  92%|█████████▏| 141/153 [00:02<00:00, 53.23it/s, Epoch: 9, Batch: 142,Loss: 0.036,Avg.Loss: 0.302,LR: 4.90E-04]Training epoch 9:  93%|█████████▎| 142/153 [00:02<00:00, 53.23it/s, Epoch: 9, Batch: 143,Loss: 0.104,Avg.Loss: 0.301,LR: 4.90E-04]Training epoch 9:  93%|█████████▎| 143/153 [00:02<00:00, 53.23it/s, Epoch: 9, Batch: 144,Loss: -0.226,Avg.Loss: 0.297,LR: 4.90E-04]Training epoch 9:  94%|█████████▍| 144/153 [00:02<00:00, 53.23it/s, Epoch: 9, Batch: 145,Loss: 0.202,Avg.Loss: 0.297,LR: 4.90E-04] Training epoch 9:  95%|█████████▍| 145/153 [00:02<00:00, 53.23it/s, Epoch: 9, Batch: 146,Loss: -0.023,Avg.Loss: 0.294,LR: 4.90E-04]Training epoch 9:  95%|█████████▌| 146/153 [00:02<00:00, 53.26it/s, Epoch: 9, Batch: 146,Loss: -0.023,Avg.Loss: 0.294,LR: 4.90E-04]Training epoch 9:  95%|█████████▌| 146/153 [00:02<00:00, 53.26it/s, Epoch: 9, Batch: 147,Loss: -0.198,Avg.Loss: 0.291,LR: 4.90E-04]Training epoch 9:  96%|█████████▌| 147/153 [00:02<00:00, 53.26it/s, Epoch: 9, Batch: 148,Loss: 0.089,Avg.Loss: 0.290,LR: 4.90E-04] Training epoch 9:  97%|█████████▋| 148/153 [00:02<00:00, 53.26it/s, Epoch: 9, Batch: 149,Loss: -0.105,Avg.Loss: 0.287,LR: 4.90E-04]Training epoch 9:  97%|█████████▋| 149/153 [00:02<00:00, 53.26it/s, Epoch: 9, Batch: 150,Loss: 0.138,Avg.Loss: 0.286,LR: 4.90E-04] Training epoch 9:  98%|█████████▊| 150/153 [00:02<00:00, 53.26it/s, Epoch: 9, Batch: 151,Loss: -0.001,Avg.Loss: 0.284,LR: 4.90E-04]Training epoch 9:  99%|█████████▊| 151/153 [00:02<00:00, 53.26it/s, Epoch: 9, Batch: 152,Loss: 0.106,Avg.Loss: 0.283,LR: 4.90E-04] Training epoch 9:  99%|█████████▉| 152/153 [00:02<00:00, 53.44it/s, Epoch: 9, Batch: 152,Loss: 0.106,Avg.Loss: 0.283,LR: 4.90E-04]Training epoch 9:  99%|█████████▉| 152/153 [00:02<00:00, 53.44it/s, Epoch: 9, Batch: 153,Loss: 0.026,Avg.Loss: 0.281,LR: 4.90E-04]Training epoch 9: 100%|██████████| 153/153 [00:02<00:00, 53.24it/s, Epoch: 9, Batch: 153,Loss: 0.026,Avg.Loss: 0.281,LR: 4.90E-04]
Training epoch 10:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 10:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 10, Batch: 1,Loss: 0.072,Avg.Loss: 0.072,LR: 4.90E-04]Training epoch 10:   1%|          | 1/153 [00:00<00:06, 24.71it/s, Epoch: 10, Batch: 2,Loss: 0.130,Avg.Loss: 0.101,LR: 4.90E-04]Training epoch 10:   1%|▏         | 2/153 [00:00<00:04, 33.98it/s, Epoch: 10, Batch: 3,Loss: 0.279,Avg.Loss: 0.160,LR: 4.90E-04]Training epoch 10:   2%|▏         | 3/153 [00:00<00:03, 40.22it/s, Epoch: 10, Batch: 4,Loss: 0.267,Avg.Loss: 0.187,LR: 4.90E-04]Training epoch 10:   3%|▎         | 4/153 [00:00<00:03, 43.48it/s, Epoch: 10, Batch: 5,Loss: 0.050,Avg.Loss: 0.160,LR: 4.90E-04]Training epoch 10:   3%|▎         | 5/153 [00:00<00:03, 45.07it/s, Epoch: 10, Batch: 6,Loss: 0.238,Avg.Loss: 0.173,LR: 4.90E-04]Training epoch 10:   4%|▍         | 6/153 [00:00<00:02, 54.00it/s, Epoch: 10, Batch: 6,Loss: 0.238,Avg.Loss: 0.173,LR: 4.90E-04]Training epoch 10:   4%|▍         | 6/153 [00:00<00:02, 54.00it/s, Epoch: 10, Batch: 7,Loss: -0.169,Avg.Loss: 0.124,LR: 4.90E-04]Training epoch 10:   5%|▍         | 7/153 [00:00<00:02, 54.00it/s, Epoch: 10, Batch: 8,Loss: -0.157,Avg.Loss: 0.089,LR: 4.90E-04]Training epoch 10:   5%|▌         | 8/153 [00:00<00:02, 54.00it/s, Epoch: 10, Batch: 9,Loss: 0.092,Avg.Loss: 0.089,LR: 4.90E-04] Training epoch 10:   6%|▌         | 9/153 [00:00<00:02, 54.00it/s, Epoch: 10, Batch: 10,Loss: 0.127,Avg.Loss: 0.093,LR: 4.90E-04]Training epoch 10:   7%|▋         | 10/153 [00:00<00:02, 54.00it/s, Epoch: 10, Batch: 11,Loss: 0.333,Avg.Loss: 0.115,LR: 4.90E-04]Training epoch 10:   7%|▋         | 11/153 [00:00<00:02, 54.00it/s, Epoch: 10, Batch: 12,Loss: -0.098,Avg.Loss: 0.097,LR: 4.90E-04]Training epoch 10:   8%|▊         | 12/153 [00:00<00:02, 53.22it/s, Epoch: 10, Batch: 12,Loss: -0.098,Avg.Loss: 0.097,LR: 4.90E-04]Training epoch 10:   8%|▊         | 12/153 [00:00<00:02, 53.22it/s, Epoch: 10, Batch: 13,Loss: -0.325,Avg.Loss: 0.064,LR: 4.90E-04]Training epoch 10:   8%|▊         | 13/153 [00:00<00:02, 53.22it/s, Epoch: 10, Batch: 14,Loss: 0.438,Avg.Loss: 0.091,LR: 4.90E-04] Training epoch 10:   9%|▉         | 14/153 [00:00<00:02, 53.22it/s, Epoch: 10, Batch: 15,Loss: 0.508,Avg.Loss: 0.119,LR: 4.90E-04]Training epoch 10:  10%|▉         | 15/153 [00:00<00:02, 53.22it/s, Epoch: 10, Batch: 16,Loss: 0.282,Avg.Loss: 0.129,LR: 4.90E-04]Training epoch 10:  10%|█         | 16/153 [00:00<00:02, 53.22it/s, Epoch: 10, Batch: 17,Loss: 0.121,Avg.Loss: 0.129,LR: 4.90E-04]Training epoch 10:  11%|█         | 17/153 [00:00<00:02, 53.22it/s, Epoch: 10, Batch: 18,Loss: -0.344,Avg.Loss: 0.102,LR: 4.90E-04]Training epoch 10:  12%|█▏        | 18/153 [00:00<00:02, 53.52it/s, Epoch: 10, Batch: 18,Loss: -0.344,Avg.Loss: 0.102,LR: 4.90E-04]Training epoch 10:  12%|█▏        | 18/153 [00:00<00:02, 53.52it/s, Epoch: 10, Batch: 19,Loss: 0.216,Avg.Loss: 0.108,LR: 4.90E-04] Training epoch 10:  12%|█▏        | 19/153 [00:00<00:02, 53.52it/s, Epoch: 10, Batch: 20,Loss: -0.213,Avg.Loss: 0.092,LR: 4.90E-04]Training epoch 10:  13%|█▎        | 20/153 [00:00<00:02, 53.52it/s, Epoch: 10, Batch: 21,Loss: 0.188,Avg.Loss: 0.097,LR: 4.90E-04] Training epoch 10:  14%|█▎        | 21/153 [00:00<00:02, 53.52it/s, Epoch: 10, Batch: 22,Loss: -0.189,Avg.Loss: 0.084,LR: 4.90E-04]Training epoch 10:  14%|█▍        | 22/153 [00:00<00:02, 53.52it/s, Epoch: 10, Batch: 23,Loss: -0.057,Avg.Loss: 0.078,LR: 4.90E-04]Training epoch 10:  15%|█▌        | 23/153 [00:00<00:02, 53.52it/s, Epoch: 10, Batch: 24,Loss: 0.018,Avg.Loss: 0.075,LR: 4.90E-04] Training epoch 10:  16%|█▌        | 24/153 [00:00<00:02, 51.51it/s, Epoch: 10, Batch: 24,Loss: 0.018,Avg.Loss: 0.075,LR: 4.90E-04]Training epoch 10:  16%|█▌        | 24/153 [00:00<00:02, 51.51it/s, Epoch: 10, Batch: 25,Loss: 0.488,Avg.Loss: 0.092,LR: 4.90E-04]Training epoch 10:  16%|█▋        | 25/153 [00:00<00:02, 51.51it/s, Epoch: 10, Batch: 26,Loss: 0.066,Avg.Loss: 0.091,LR: 4.90E-04]Training epoch 10:  17%|█▋        | 26/153 [00:00<00:02, 51.51it/s, Epoch: 10, Batch: 27,Loss: 0.269,Avg.Loss: 0.097,LR: 4.90E-04]Training epoch 10:  18%|█▊        | 27/153 [00:00<00:02, 51.51it/s, Epoch: 10, Batch: 28,Loss: -0.080,Avg.Loss: 0.091,LR: 4.90E-04]Training epoch 10:  18%|█▊        | 28/153 [00:00<00:02, 51.51it/s, Epoch: 10, Batch: 29,Loss: -0.299,Avg.Loss: 0.078,LR: 4.90E-04]Training epoch 10:  19%|█▉        | 29/153 [00:00<00:02, 51.51it/s, Epoch: 10, Batch: 30,Loss: 0.654,Avg.Loss: 0.097,LR: 4.90E-04] Training epoch 10:  20%|█▉        | 30/153 [00:00<00:02, 51.40it/s, Epoch: 10, Batch: 30,Loss: 0.654,Avg.Loss: 0.097,LR: 4.90E-04]Training epoch 10:  20%|█▉        | 30/153 [00:00<00:02, 51.40it/s, Epoch: 10, Batch: 31,Loss: 0.807,Avg.Loss: 0.120,LR: 4.90E-04]Training epoch 10:  20%|██        | 31/153 [00:00<00:02, 51.40it/s, Epoch: 10, Batch: 32,Loss: 0.250,Avg.Loss: 0.124,LR: 4.90E-04]Training epoch 10:  21%|██        | 32/153 [00:00<00:02, 51.40it/s, Epoch: 10, Batch: 33,Loss: 0.076,Avg.Loss: 0.122,LR: 4.90E-04]Training epoch 10:  22%|██▏       | 33/153 [00:00<00:02, 51.40it/s, Epoch: 10, Batch: 34,Loss: -0.189,Avg.Loss: 0.113,LR: 4.90E-04]Training epoch 10:  22%|██▏       | 34/153 [00:00<00:02, 51.40it/s, Epoch: 10, Batch: 35,Loss: -0.027,Avg.Loss: 0.109,LR: 4.90E-04]Training epoch 10:  23%|██▎       | 35/153 [00:00<00:02, 51.40it/s, Epoch: 10, Batch: 36,Loss: -0.183,Avg.Loss: 0.101,LR: 4.90E-04]Training epoch 10:  24%|██▎       | 36/153 [00:00<00:02, 50.67it/s, Epoch: 10, Batch: 36,Loss: -0.183,Avg.Loss: 0.101,LR: 4.90E-04]Training epoch 10:  24%|██▎       | 36/153 [00:00<00:02, 50.67it/s, Epoch: 10, Batch: 37,Loss: 0.181,Avg.Loss: 0.103,LR: 4.90E-04] Training epoch 10:  24%|██▍       | 37/153 [00:00<00:02, 50.67it/s, Epoch: 10, Batch: 38,Loss: 0.069,Avg.Loss: 0.102,LR: 4.90E-04]Training epoch 10:  25%|██▍       | 38/153 [00:00<00:02, 50.67it/s, Epoch: 10, Batch: 39,Loss: -0.215,Avg.Loss: 0.094,LR: 4.90E-04]Training epoch 10:  25%|██▌       | 39/153 [00:00<00:02, 50.67it/s, Epoch: 10, Batch: 40,Loss: 0.087,Avg.Loss: 0.094,LR: 4.89E-04] Training epoch 10:  26%|██▌       | 40/153 [00:00<00:02, 50.67it/s, Epoch: 10, Batch: 41,Loss: -0.428,Avg.Loss: 0.081,LR: 4.89E-04]Training epoch 10:  27%|██▋       | 41/153 [00:00<00:02, 50.67it/s, Epoch: 10, Batch: 42,Loss: -0.205,Avg.Loss: 0.074,LR: 4.89E-04]Training epoch 10:  27%|██▋       | 42/153 [00:00<00:02, 51.27it/s, Epoch: 10, Batch: 42,Loss: -0.205,Avg.Loss: 0.074,LR: 4.89E-04]Training epoch 10:  27%|██▋       | 42/153 [00:00<00:02, 51.27it/s, Epoch: 10, Batch: 43,Loss: -0.084,Avg.Loss: 0.071,LR: 4.89E-04]Training epoch 10:  28%|██▊       | 43/153 [00:00<00:02, 51.27it/s, Epoch: 10, Batch: 44,Loss: -0.010,Avg.Loss: 0.069,LR: 4.89E-04]Training epoch 10:  29%|██▉       | 44/153 [00:00<00:02, 51.27it/s, Epoch: 10, Batch: 45,Loss: 0.045,Avg.Loss: 0.068,LR: 4.89E-04] Training epoch 10:  29%|██▉       | 45/153 [00:00<00:02, 51.27it/s, Epoch: 10, Batch: 46,Loss: -0.245,Avg.Loss: 0.062,LR: 4.89E-04]Training epoch 10:  30%|███       | 46/153 [00:00<00:02, 51.27it/s, Epoch: 10, Batch: 47,Loss: -0.012,Avg.Loss: 0.060,LR: 4.89E-04]Training epoch 10:  31%|███       | 47/153 [00:00<00:02, 51.27it/s, Epoch: 10, Batch: 48,Loss: -0.378,Avg.Loss: 0.051,LR: 4.89E-04]Training epoch 10:  31%|███▏      | 48/153 [00:00<00:02, 51.95it/s, Epoch: 10, Batch: 48,Loss: -0.378,Avg.Loss: 0.051,LR: 4.89E-04]Training epoch 10:  31%|███▏      | 48/153 [00:00<00:02, 51.95it/s, Epoch: 10, Batch: 49,Loss: -0.130,Avg.Loss: 0.047,LR: 4.89E-04]Training epoch 10:  32%|███▏      | 49/153 [00:00<00:02, 51.95it/s, Epoch: 10, Batch: 50,Loss: 0.172,Avg.Loss: 0.050,LR: 4.89E-04] Training epoch 10:  33%|███▎      | 50/153 [00:00<00:01, 51.95it/s, Epoch: 10, Batch: 51,Loss: 0.073,Avg.Loss: 0.050,LR: 4.89E-04]Training epoch 10:  33%|███▎      | 51/153 [00:00<00:01, 51.95it/s, Epoch: 10, Batch: 52,Loss: 0.175,Avg.Loss: 0.053,LR: 4.89E-04]Training epoch 10:  34%|███▍      | 52/153 [00:01<00:01, 51.95it/s, Epoch: 10, Batch: 53,Loss: 0.164,Avg.Loss: 0.055,LR: 4.89E-04]Training epoch 10:  35%|███▍      | 53/153 [00:01<00:01, 51.95it/s, Epoch: 10, Batch: 54,Loss: -0.499,Avg.Loss: 0.044,LR: 4.89E-04]Training epoch 10:  35%|███▌      | 54/153 [00:01<00:01, 52.46it/s, Epoch: 10, Batch: 54,Loss: -0.499,Avg.Loss: 0.044,LR: 4.89E-04]Training epoch 10:  35%|███▌      | 54/153 [00:01<00:01, 52.46it/s, Epoch: 10, Batch: 55,Loss: 0.259,Avg.Loss: 0.048,LR: 4.89E-04] Training epoch 10:  36%|███▌      | 55/153 [00:01<00:01, 52.46it/s, Epoch: 10, Batch: 56,Loss: 0.412,Avg.Loss: 0.055,LR: 4.89E-04]Training epoch 10:  37%|███▋      | 56/153 [00:01<00:01, 52.46it/s, Epoch: 10, Batch: 57,Loss: 0.261,Avg.Loss: 0.058,LR: 4.89E-04]Training epoch 10:  37%|███▋      | 57/153 [00:01<00:01, 52.46it/s, Epoch: 10, Batch: 58,Loss: 0.000,Avg.Loss: 0.057,LR: 4.89E-04]Training epoch 10:  38%|███▊      | 58/153 [00:01<00:01, 52.46it/s, Epoch: 10, Batch: 59,Loss: 0.231,Avg.Loss: 0.060,LR: 4.89E-04]Training epoch 10:  39%|███▊      | 59/153 [00:01<00:01, 52.46it/s, Epoch: 10, Batch: 60,Loss: -0.001,Avg.Loss: 0.059,LR: 4.89E-04]Training epoch 10:  39%|███▉      | 60/153 [00:01<00:01, 52.35it/s, Epoch: 10, Batch: 60,Loss: -0.001,Avg.Loss: 0.059,LR: 4.89E-04]Training epoch 10:  39%|███▉      | 60/153 [00:01<00:01, 52.35it/s, Epoch: 10, Batch: 61,Loss: 0.005,Avg.Loss: 0.058,LR: 4.89E-04] Training epoch 10:  40%|███▉      | 61/153 [00:01<00:01, 52.35it/s, Epoch: 10, Batch: 62,Loss: 0.349,Avg.Loss: 0.063,LR: 4.89E-04]Training epoch 10:  41%|████      | 62/153 [00:01<00:01, 52.35it/s, Epoch: 10, Batch: 63,Loss: 0.125,Avg.Loss: 0.064,LR: 4.89E-04]Training epoch 10:  41%|████      | 63/153 [00:01<00:01, 52.35it/s, Epoch: 10, Batch: 64,Loss: -0.099,Avg.Loss: 0.062,LR: 4.89E-04]Training epoch 10:  42%|████▏     | 64/153 [00:01<00:01, 52.35it/s, Epoch: 10, Batch: 65,Loss: 0.028,Avg.Loss: 0.061,LR: 4.89E-04] Training epoch 10:  42%|████▏     | 65/153 [00:01<00:01, 52.35it/s, Epoch: 10, Batch: 66,Loss: -0.339,Avg.Loss: 0.055,LR: 4.89E-04]Training epoch 10:  43%|████▎     | 66/153 [00:01<00:01, 52.16it/s, Epoch: 10, Batch: 66,Loss: -0.339,Avg.Loss: 0.055,LR: 4.89E-04]Training epoch 10:  43%|████▎     | 66/153 [00:01<00:01, 52.16it/s, Epoch: 10, Batch: 67,Loss: 0.103,Avg.Loss: 0.056,LR: 4.89E-04] Training epoch 10:  44%|████▍     | 67/153 [00:01<00:01, 52.16it/s, Epoch: 10, Batch: 68,Loss: 0.198,Avg.Loss: 0.058,LR: 4.89E-04]Training epoch 10:  44%|████▍     | 68/153 [00:01<00:01, 52.16it/s, Epoch: 10, Batch: 69,Loss: -0.175,Avg.Loss: 0.054,LR: 4.89E-04]Training epoch 10:  45%|████▌     | 69/153 [00:01<00:01, 52.16it/s, Epoch: 10, Batch: 70,Loss: 0.058,Avg.Loss: 0.055,LR: 4.89E-04] Training epoch 10:  46%|████▌     | 70/153 [00:01<00:01, 52.16it/s, Epoch: 10, Batch: 71,Loss: 0.182,Avg.Loss: 0.056,LR: 4.89E-04]Training epoch 10:  46%|████▋     | 71/153 [00:01<00:01, 52.16it/s, Epoch: 10, Batch: 72,Loss: 0.825,Avg.Loss: 0.067,LR: 4.89E-04]Training epoch 10:  47%|████▋     | 72/153 [00:01<00:01, 51.94it/s, Epoch: 10, Batch: 72,Loss: 0.825,Avg.Loss: 0.067,LR: 4.89E-04]Training epoch 10:  47%|████▋     | 72/153 [00:01<00:01, 51.94it/s, Epoch: 10, Batch: 73,Loss: 0.774,Avg.Loss: 0.077,LR: 4.89E-04]Training epoch 10:  48%|████▊     | 73/153 [00:01<00:01, 51.94it/s, Epoch: 10, Batch: 74,Loss: 0.555,Avg.Loss: 0.083,LR: 4.89E-04]Training epoch 10:  48%|████▊     | 74/153 [00:01<00:01, 51.94it/s, Epoch: 10, Batch: 75,Loss: 0.861,Avg.Loss: 0.093,LR: 4.89E-04]Training epoch 10:  49%|████▉     | 75/153 [00:01<00:01, 51.94it/s, Epoch: 10, Batch: 76,Loss: 0.214,Avg.Loss: 0.095,LR: 4.89E-04]Training epoch 10:  50%|████▉     | 76/153 [00:01<00:01, 51.94it/s, Epoch: 10, Batch: 77,Loss: 0.318,Avg.Loss: 0.098,LR: 4.89E-04]Training epoch 10:  50%|█████     | 77/153 [00:01<00:01, 51.94it/s, Epoch: 10, Batch: 78,Loss: 0.108,Avg.Loss: 0.098,LR: 4.89E-04]Training epoch 10:  51%|█████     | 78/153 [00:01<00:01, 52.36it/s, Epoch: 10, Batch: 78,Loss: 0.108,Avg.Loss: 0.098,LR: 4.89E-04]Training epoch 10:  51%|█████     | 78/153 [00:01<00:01, 52.36it/s, Epoch: 10, Batch: 79,Loss: 0.056,Avg.Loss: 0.098,LR: 4.89E-04]Training epoch 10:  52%|█████▏    | 79/153 [00:01<00:01, 52.36it/s, Epoch: 10, Batch: 80,Loss: 0.439,Avg.Loss: 0.102,LR: 4.89E-04]Training epoch 10:  52%|█████▏    | 80/153 [00:01<00:01, 52.36it/s, Epoch: 10, Batch: 81,Loss: 0.674,Avg.Loss: 0.109,LR: 4.89E-04]Training epoch 10:  53%|█████▎    | 81/153 [00:01<00:01, 52.36it/s, Epoch: 10, Batch: 82,Loss: 0.033,Avg.Loss: 0.108,LR: 4.89E-04]Training epoch 10:  54%|█████▎    | 82/153 [00:01<00:01, 52.36it/s, Epoch: 10, Batch: 83,Loss: -0.106,Avg.Loss: 0.105,LR: 4.89E-04]Training epoch 10:  54%|█████▍    | 83/153 [00:01<00:01, 52.36it/s, Epoch: 10, Batch: 84,Loss: 0.229,Avg.Loss: 0.107,LR: 4.89E-04] Training epoch 10:  55%|█████▍    | 84/153 [00:01<00:01, 52.21it/s, Epoch: 10, Batch: 84,Loss: 0.229,Avg.Loss: 0.107,LR: 4.89E-04]Training epoch 10:  55%|█████▍    | 84/153 [00:01<00:01, 52.21it/s, Epoch: 10, Batch: 85,Loss: -0.062,Avg.Loss: 0.105,LR: 4.89E-04]Training epoch 10:  56%|█████▌    | 85/153 [00:01<00:01, 52.21it/s, Epoch: 10, Batch: 86,Loss: -0.352,Avg.Loss: 0.100,LR: 4.89E-04]Training epoch 10:  56%|█████▌    | 86/153 [00:01<00:01, 52.21it/s, Epoch: 10, Batch: 87,Loss: -0.100,Avg.Loss: 0.097,LR: 4.89E-04]Training epoch 10:  57%|█████▋    | 87/153 [00:01<00:01, 52.21it/s, Epoch: 10, Batch: 88,Loss: 0.281,Avg.Loss: 0.099,LR: 4.89E-04] Training epoch 10:  58%|█████▊    | 88/153 [00:01<00:01, 52.21it/s, Epoch: 10, Batch: 89,Loss: 0.378,Avg.Loss: 0.102,LR: 4.89E-04]Training epoch 10:  58%|█████▊    | 89/153 [00:01<00:01, 52.21it/s, Epoch: 10, Batch: 90,Loss: -0.109,Avg.Loss: 0.100,LR: 4.89E-04]Training epoch 10:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 10, Batch: 90,Loss: -0.109,Avg.Loss: 0.100,LR: 4.89E-04]Training epoch 10:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 10, Batch: 91,Loss: 0.178,Avg.Loss: 0.101,LR: 4.89E-04] Training epoch 10:  59%|█████▉    | 91/153 [00:01<00:01, 52.91it/s, Epoch: 10, Batch: 92,Loss: 0.198,Avg.Loss: 0.102,LR: 4.89E-04]Training epoch 10:  60%|██████    | 92/153 [00:01<00:01, 52.91it/s, Epoch: 10, Batch: 93,Loss: 0.120,Avg.Loss: 0.102,LR: 4.89E-04]Training epoch 10:  61%|██████    | 93/153 [00:01<00:01, 52.91it/s, Epoch: 10, Batch: 94,Loss: -0.099,Avg.Loss: 0.100,LR: 4.89E-04]Training epoch 10:  61%|██████▏   | 94/153 [00:01<00:01, 52.91it/s, Epoch: 10, Batch: 95,Loss: -0.114,Avg.Loss: 0.098,LR: 4.89E-04]Training epoch 10:  62%|██████▏   | 95/153 [00:01<00:01, 52.91it/s, Epoch: 10, Batch: 96,Loss: -0.327,Avg.Loss: 0.093,LR: 4.89E-04]Training epoch 10:  63%|██████▎   | 96/153 [00:01<00:01, 52.44it/s, Epoch: 10, Batch: 96,Loss: -0.327,Avg.Loss: 0.093,LR: 4.89E-04]Training epoch 10:  63%|██████▎   | 96/153 [00:01<00:01, 52.44it/s, Epoch: 10, Batch: 97,Loss: -0.265,Avg.Loss: 0.090,LR: 4.89E-04]Training epoch 10:  63%|██████▎   | 97/153 [00:01<00:01, 52.44it/s, Epoch: 10, Batch: 98,Loss: -0.298,Avg.Loss: 0.086,LR: 4.89E-04]Training epoch 10:  64%|██████▍   | 98/153 [00:01<00:01, 52.44it/s, Epoch: 10, Batch: 99,Loss: 0.113,Avg.Loss: 0.086,LR: 4.89E-04] Training epoch 10:  65%|██████▍   | 99/153 [00:01<00:01, 52.44it/s, Epoch: 10, Batch: 100,Loss: -0.162,Avg.Loss: 0.084,LR: 4.89E-04]Training epoch 10:  65%|██████▌   | 100/153 [00:01<00:01, 52.44it/s, Epoch: 10, Batch: 101,Loss: 0.005,Avg.Loss: 0.083,LR: 4.89E-04]Training epoch 10:  66%|██████▌   | 101/153 [00:01<00:00, 52.44it/s, Epoch: 10, Batch: 102,Loss: -0.011,Avg.Loss: 0.082,LR: 4.89E-04]Training epoch 10:  67%|██████▋   | 102/153 [00:01<00:00, 52.58it/s, Epoch: 10, Batch: 102,Loss: -0.011,Avg.Loss: 0.082,LR: 4.89E-04]Training epoch 10:  67%|██████▋   | 102/153 [00:01<00:00, 52.58it/s, Epoch: 10, Batch: 103,Loss: -0.006,Avg.Loss: 0.081,LR: 4.89E-04]Training epoch 10:  67%|██████▋   | 103/153 [00:01<00:00, 52.58it/s, Epoch: 10, Batch: 104,Loss: -0.081,Avg.Loss: 0.079,LR: 4.89E-04]Training epoch 10:  68%|██████▊   | 104/153 [00:02<00:00, 52.58it/s, Epoch: 10, Batch: 105,Loss: -0.300,Avg.Loss: 0.076,LR: 4.89E-04]Training epoch 10:  69%|██████▊   | 105/153 [00:02<00:00, 52.58it/s, Epoch: 10, Batch: 106,Loss: -0.337,Avg.Loss: 0.072,LR: 4.88E-04]Training epoch 10:  69%|██████▉   | 106/153 [00:02<00:00, 52.58it/s, Epoch: 10, Batch: 107,Loss: -0.332,Avg.Loss: 0.068,LR: 4.88E-04]Training epoch 10:  70%|██████▉   | 107/153 [00:02<00:00, 52.58it/s, Epoch: 10, Batch: 108,Loss: -0.001,Avg.Loss: 0.068,LR: 4.88E-04]Training epoch 10:  71%|███████   | 108/153 [00:02<00:00, 52.82it/s, Epoch: 10, Batch: 108,Loss: -0.001,Avg.Loss: 0.068,LR: 4.88E-04]Training epoch 10:  71%|███████   | 108/153 [00:02<00:00, 52.82it/s, Epoch: 10, Batch: 109,Loss: -0.308,Avg.Loss: 0.064,LR: 4.88E-04]Training epoch 10:  71%|███████   | 109/153 [00:02<00:00, 52.82it/s, Epoch: 10, Batch: 110,Loss: -0.180,Avg.Loss: 0.062,LR: 4.88E-04]Training epoch 10:  72%|███████▏  | 110/153 [00:02<00:00, 52.82it/s, Epoch: 10, Batch: 111,Loss: 0.016,Avg.Loss: 0.061,LR: 4.88E-04] Training epoch 10:  73%|███████▎  | 111/153 [00:02<00:00, 52.82it/s, Epoch: 10, Batch: 112,Loss: -0.010,Avg.Loss: 0.061,LR: 4.88E-04]Training epoch 10:  73%|███████▎  | 112/153 [00:02<00:00, 52.82it/s, Epoch: 10, Batch: 113,Loss: -0.129,Avg.Loss: 0.059,LR: 4.88E-04]Training epoch 10:  74%|███████▍  | 113/153 [00:02<00:00, 52.82it/s, Epoch: 10, Batch: 114,Loss: 0.014,Avg.Loss: 0.059,LR: 4.88E-04] Training epoch 10:  75%|███████▍  | 114/153 [00:02<00:00, 52.83it/s, Epoch: 10, Batch: 114,Loss: 0.014,Avg.Loss: 0.059,LR: 4.88E-04]Training epoch 10:  75%|███████▍  | 114/153 [00:02<00:00, 52.83it/s, Epoch: 10, Batch: 115,Loss: -0.502,Avg.Loss: 0.054,LR: 4.88E-04]Training epoch 10:  75%|███████▌  | 115/153 [00:02<00:00, 52.83it/s, Epoch: 10, Batch: 116,Loss: 0.502,Avg.Loss: 0.058,LR: 4.88E-04] Training epoch 10:  76%|███████▌  | 116/153 [00:02<00:00, 52.83it/s, Epoch: 10, Batch: 117,Loss: 0.518,Avg.Loss: 0.062,LR: 4.88E-04]Training epoch 10:  76%|███████▋  | 117/153 [00:02<00:00, 52.83it/s, Epoch: 10, Batch: 118,Loss: 0.502,Avg.Loss: 0.065,LR: 4.88E-04]Training epoch 10:  77%|███████▋  | 118/153 [00:02<00:00, 52.83it/s, Epoch: 10, Batch: 119,Loss: -0.098,Avg.Loss: 0.064,LR: 4.88E-04]Training epoch 10:  78%|███████▊  | 119/153 [00:02<00:00, 52.83it/s, Epoch: 10, Batch: 120,Loss: 0.114,Avg.Loss: 0.064,LR: 4.88E-04] Training epoch 10:  78%|███████▊  | 120/153 [00:02<00:00, 53.04it/s, Epoch: 10, Batch: 120,Loss: 0.114,Avg.Loss: 0.064,LR: 4.88E-04]Training epoch 10:  78%|███████▊  | 120/153 [00:02<00:00, 53.04it/s, Epoch: 10, Batch: 121,Loss: -0.147,Avg.Loss: 0.063,LR: 4.88E-04]Training epoch 10:  79%|███████▉  | 121/153 [00:02<00:00, 53.04it/s, Epoch: 10, Batch: 122,Loss: 0.184,Avg.Loss: 0.064,LR: 4.88E-04] Training epoch 10:  80%|███████▉  | 122/153 [00:02<00:00, 53.04it/s, Epoch: 10, Batch: 123,Loss: 0.002,Avg.Loss: 0.063,LR: 4.88E-04]Training epoch 10:  80%|████████  | 123/153 [00:02<00:00, 53.04it/s, Epoch: 10, Batch: 124,Loss: -0.313,Avg.Loss: 0.060,LR: 4.88E-04]Training epoch 10:  81%|████████  | 124/153 [00:02<00:00, 53.04it/s, Epoch: 10, Batch: 125,Loss: 0.018,Avg.Loss: 0.060,LR: 4.88E-04] Training epoch 10:  82%|████████▏ | 125/153 [00:02<00:00, 53.04it/s, Epoch: 10, Batch: 126,Loss: 0.243,Avg.Loss: 0.061,LR: 4.88E-04]Training epoch 10:  82%|████████▏ | 126/153 [00:02<00:00, 53.27it/s, Epoch: 10, Batch: 126,Loss: 0.243,Avg.Loss: 0.061,LR: 4.88E-04]Training epoch 10:  82%|████████▏ | 126/153 [00:02<00:00, 53.27it/s, Epoch: 10, Batch: 127,Loss: 0.981,Avg.Loss: 0.069,LR: 4.88E-04]Training epoch 10:  83%|████████▎ | 127/153 [00:02<00:00, 53.27it/s, Epoch: 10, Batch: 128,Loss: -0.317,Avg.Loss: 0.065,LR: 4.88E-04]Training epoch 10:  84%|████████▎ | 128/153 [00:02<00:00, 53.27it/s, Epoch: 10, Batch: 129,Loss: -0.002,Avg.Loss: 0.065,LR: 4.88E-04]Training epoch 10:  84%|████████▍ | 129/153 [00:02<00:00, 53.27it/s, Epoch: 10, Batch: 130,Loss: 0.020,Avg.Loss: 0.065,LR: 4.88E-04] Training epoch 10:  85%|████████▍ | 130/153 [00:02<00:00, 53.27it/s, Epoch: 10, Batch: 131,Loss: 0.633,Avg.Loss: 0.069,LR: 4.88E-04]Training epoch 10:  86%|████████▌ | 131/153 [00:02<00:00, 53.27it/s, Epoch: 10, Batch: 132,Loss: 0.137,Avg.Loss: 0.069,LR: 4.88E-04]Training epoch 10:  86%|████████▋ | 132/153 [00:02<00:00, 53.26it/s, Epoch: 10, Batch: 132,Loss: 0.137,Avg.Loss: 0.069,LR: 4.88E-04]Training epoch 10:  86%|████████▋ | 132/153 [00:02<00:00, 53.26it/s, Epoch: 10, Batch: 133,Loss: -0.354,Avg.Loss: 0.066,LR: 4.88E-04]Training epoch 10:  87%|████████▋ | 133/153 [00:02<00:00, 53.26it/s, Epoch: 10, Batch: 134,Loss: 0.100,Avg.Loss: 0.067,LR: 4.88E-04] Training epoch 10:  88%|████████▊ | 134/153 [00:02<00:00, 53.26it/s, Epoch: 10, Batch: 135,Loss: -0.079,Avg.Loss: 0.065,LR: 4.88E-04]Training epoch 10:  88%|████████▊ | 135/153 [00:02<00:00, 53.26it/s, Epoch: 10, Batch: 136,Loss: -0.381,Avg.Loss: 0.062,LR: 4.88E-04]Training epoch 10:  89%|████████▉ | 136/153 [00:02<00:00, 53.26it/s, Epoch: 10, Batch: 137,Loss: -0.373,Avg.Loss: 0.059,LR: 4.88E-04]Training epoch 10:  90%|████████▉ | 137/153 [00:02<00:00, 53.26it/s, Epoch: 10, Batch: 138,Loss: 0.049,Avg.Loss: 0.059,LR: 4.88E-04] Training epoch 10:  90%|█████████ | 138/153 [00:02<00:00, 53.39it/s, Epoch: 10, Batch: 138,Loss: 0.049,Avg.Loss: 0.059,LR: 4.88E-04]Training epoch 10:  90%|█████████ | 138/153 [00:02<00:00, 53.39it/s, Epoch: 10, Batch: 139,Loss: 0.043,Avg.Loss: 0.059,LR: 4.88E-04]Training epoch 10:  91%|█████████ | 139/153 [00:02<00:00, 53.39it/s, Epoch: 10, Batch: 140,Loss: -0.047,Avg.Loss: 0.058,LR: 4.88E-04]Training epoch 10:  92%|█████████▏| 140/153 [00:02<00:00, 53.39it/s, Epoch: 10, Batch: 141,Loss: 0.115,Avg.Loss: 0.058,LR: 4.88E-04] Training epoch 10:  92%|█████████▏| 141/153 [00:02<00:00, 53.39it/s, Epoch: 10, Batch: 142,Loss: 0.034,Avg.Loss: 0.058,LR: 4.88E-04]Training epoch 10:  93%|█████████▎| 142/153 [00:02<00:00, 53.39it/s, Epoch: 10, Batch: 143,Loss: -0.274,Avg.Loss: 0.056,LR: 4.88E-04]Training epoch 10:  93%|█████████▎| 143/153 [00:02<00:00, 53.39it/s, Epoch: 10, Batch: 144,Loss: -0.299,Avg.Loss: 0.054,LR: 4.88E-04]Training epoch 10:  94%|█████████▍| 144/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 144,Loss: -0.299,Avg.Loss: 0.054,LR: 4.88E-04]Training epoch 10:  94%|█████████▍| 144/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 145,Loss: -0.343,Avg.Loss: 0.051,LR: 4.88E-04]Training epoch 10:  95%|█████████▍| 145/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 146,Loss: 0.265,Avg.Loss: 0.052,LR: 4.88E-04] Training epoch 10:  95%|█████████▌| 146/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 147,Loss: 0.659,Avg.Loss: 0.056,LR: 4.88E-04]Training epoch 10:  96%|█████████▌| 147/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 148,Loss: 0.495,Avg.Loss: 0.059,LR: 4.88E-04]Training epoch 10:  97%|█████████▋| 148/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 149,Loss: -0.287,Avg.Loss: 0.057,LR: 4.88E-04]Training epoch 10:  97%|█████████▋| 149/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 150,Loss: 0.273,Avg.Loss: 0.058,LR: 4.88E-04] Training epoch 10:  98%|█████████▊| 150/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 150,Loss: 0.273,Avg.Loss: 0.058,LR: 4.88E-04]Training epoch 10:  98%|█████████▊| 150/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 151,Loss: 1.029,Avg.Loss: 0.065,LR: 4.88E-04]Training epoch 10:  99%|█████████▊| 151/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 152,Loss: 0.674,Avg.Loss: 0.069,LR: 4.88E-04]Training epoch 10:  99%|█████████▉| 152/153 [00:02<00:00, 53.31it/s, Epoch: 10, Batch: 153,Loss: 0.372,Avg.Loss: 0.071,LR: 4.88E-04]Training epoch 10: 100%|██████████| 153/153 [00:02<00:00, 52.55it/s, Epoch: 10, Batch: 153,Loss: 0.372,Avg.Loss: 0.071,LR: 4.88E-04]
Training epoch 11:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 11:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 11, Batch: 1,Loss: 0.110,Avg.Loss: 0.110,LR: 4.88E-04]Training epoch 11:   1%|          | 1/153 [00:00<00:05, 26.28it/s, Epoch: 11, Batch: 2,Loss: 0.238,Avg.Loss: 0.174,LR: 4.88E-04]Training epoch 11:   1%|▏         | 2/153 [00:00<00:04, 34.92it/s, Epoch: 11, Batch: 3,Loss: -0.098,Avg.Loss: 0.083,LR: 4.88E-04]Training epoch 11:   2%|▏         | 3/153 [00:00<00:03, 42.67it/s, Epoch: 11, Batch: 4,Loss: 0.003,Avg.Loss: 0.063,LR: 4.88E-04] Training epoch 11:   3%|▎         | 4/153 [00:00<00:03, 46.49it/s, Epoch: 11, Batch: 5,Loss: 0.781,Avg.Loss: 0.207,LR: 4.88E-04]Training epoch 11:   3%|▎         | 5/153 [00:00<00:03, 47.53it/s, Epoch: 11, Batch: 6,Loss: 0.843,Avg.Loss: 0.313,LR: 4.88E-04]Training epoch 11:   4%|▍         | 6/153 [00:00<00:02, 56.94it/s, Epoch: 11, Batch: 6,Loss: 0.843,Avg.Loss: 0.313,LR: 4.88E-04]Training epoch 11:   4%|▍         | 6/153 [00:00<00:02, 56.94it/s, Epoch: 11, Batch: 7,Loss: -0.171,Avg.Loss: 0.244,LR: 4.88E-04]Training epoch 11:   5%|▍         | 7/153 [00:00<00:02, 56.94it/s, Epoch: 11, Batch: 8,Loss: -0.192,Avg.Loss: 0.189,LR: 4.88E-04]Training epoch 11:   5%|▌         | 8/153 [00:00<00:02, 56.94it/s, Epoch: 11, Batch: 9,Loss: 0.044,Avg.Loss: 0.173,LR: 4.88E-04] Training epoch 11:   6%|▌         | 9/153 [00:00<00:02, 56.94it/s, Epoch: 11, Batch: 10,Loss: 0.047,Avg.Loss: 0.160,LR: 4.88E-04]Training epoch 11:   7%|▋         | 10/153 [00:00<00:02, 56.94it/s, Epoch: 11, Batch: 11,Loss: -0.054,Avg.Loss: 0.141,LR: 4.88E-04]Training epoch 11:   7%|▋         | 11/153 [00:00<00:02, 56.94it/s, Epoch: 11, Batch: 12,Loss: 0.095,Avg.Loss: 0.137,LR: 4.88E-04] Training epoch 11:   8%|▊         | 12/153 [00:00<00:02, 54.41it/s, Epoch: 11, Batch: 12,Loss: 0.095,Avg.Loss: 0.137,LR: 4.88E-04]Training epoch 11:   8%|▊         | 12/153 [00:00<00:02, 54.41it/s, Epoch: 11, Batch: 13,Loss: 0.216,Avg.Loss: 0.143,LR: 4.88E-04]Training epoch 11:   8%|▊         | 13/153 [00:00<00:02, 54.41it/s, Epoch: 11, Batch: 14,Loss: 0.167,Avg.Loss: 0.145,LR: 4.88E-04]Training epoch 11:   9%|▉         | 14/153 [00:00<00:02, 54.41it/s, Epoch: 11, Batch: 15,Loss: -0.529,Avg.Loss: 0.100,LR: 4.88E-04]Training epoch 11:  10%|▉         | 15/153 [00:00<00:02, 54.41it/s, Epoch: 11, Batch: 16,Loss: 0.512,Avg.Loss: 0.126,LR: 4.88E-04] Training epoch 11:  10%|█         | 16/153 [00:00<00:02, 54.41it/s, Epoch: 11, Batch: 17,Loss: 1.500,Avg.Loss: 0.207,LR: 4.87E-04]Training epoch 11:  11%|█         | 17/153 [00:00<00:02, 54.41it/s, Epoch: 11, Batch: 18,Loss: 2.150,Avg.Loss: 0.315,LR: 4.87E-04]Training epoch 11:  12%|█▏        | 18/153 [00:00<00:02, 53.95it/s, Epoch: 11, Batch: 18,Loss: 2.150,Avg.Loss: 0.315,LR: 4.87E-04]Training epoch 11:  12%|█▏        | 18/153 [00:00<00:02, 53.95it/s, Epoch: 11, Batch: 19,Loss: 0.997,Avg.Loss: 0.351,LR: 4.87E-04]Training epoch 11:  12%|█▏        | 19/153 [00:00<00:02, 53.95it/s, Epoch: 11, Batch: 20,Loss: 1.408,Avg.Loss: 0.403,LR: 4.87E-04]Training epoch 11:  13%|█▎        | 20/153 [00:00<00:02, 53.95it/s, Epoch: 11, Batch: 21,Loss: 1.447,Avg.Loss: 0.453,LR: 4.87E-04]Training epoch 11:  14%|█▎        | 21/153 [00:00<00:02, 53.95it/s, Epoch: 11, Batch: 22,Loss: 1.163,Avg.Loss: 0.485,LR: 4.87E-04]Training epoch 11:  14%|█▍        | 22/153 [00:00<00:02, 53.95it/s, Epoch: 11, Batch: 23,Loss: 0.268,Avg.Loss: 0.476,LR: 4.87E-04]Training epoch 11:  15%|█▌        | 23/153 [00:00<00:02, 53.95it/s, Epoch: 11, Batch: 24,Loss: 0.079,Avg.Loss: 0.459,LR: 4.87E-04]Training epoch 11:  16%|█▌        | 24/153 [00:00<00:02, 52.98it/s, Epoch: 11, Batch: 24,Loss: 0.079,Avg.Loss: 0.459,LR: 4.87E-04]Training epoch 11:  16%|█▌        | 24/153 [00:00<00:02, 52.98it/s, Epoch: 11, Batch: 25,Loss: 0.126,Avg.Loss: 0.446,LR: 4.87E-04]Training epoch 11:  16%|█▋        | 25/153 [00:00<00:02, 52.98it/s, Epoch: 11, Batch: 26,Loss: 0.380,Avg.Loss: 0.443,LR: 4.87E-04]Training epoch 11:  17%|█▋        | 26/153 [00:00<00:02, 52.98it/s, Epoch: 11, Batch: 27,Loss: 0.048,Avg.Loss: 0.429,LR: 4.87E-04]Training epoch 11:  18%|█▊        | 27/153 [00:00<00:02, 52.98it/s, Epoch: 11, Batch: 28,Loss: 0.139,Avg.Loss: 0.418,LR: 4.87E-04]Training epoch 11:  18%|█▊        | 28/153 [00:00<00:02, 52.98it/s, Epoch: 11, Batch: 29,Loss: 0.545,Avg.Loss: 0.423,LR: 4.87E-04]Training epoch 11:  19%|█▉        | 29/153 [00:00<00:02, 52.98it/s, Epoch: 11, Batch: 30,Loss: 0.099,Avg.Loss: 0.412,LR: 4.87E-04]Training epoch 11:  20%|█▉        | 30/153 [00:00<00:02, 52.34it/s, Epoch: 11, Batch: 30,Loss: 0.099,Avg.Loss: 0.412,LR: 4.87E-04]Training epoch 11:  20%|█▉        | 30/153 [00:00<00:02, 52.34it/s, Epoch: 11, Batch: 31,Loss: 0.455,Avg.Loss: 0.413,LR: 4.87E-04]Training epoch 11:  20%|██        | 31/153 [00:00<00:02, 52.34it/s, Epoch: 11, Batch: 32,Loss: 0.236,Avg.Loss: 0.408,LR: 4.87E-04]Training epoch 11:  21%|██        | 32/153 [00:00<00:02, 52.34it/s, Epoch: 11, Batch: 33,Loss: 0.179,Avg.Loss: 0.401,LR: 4.87E-04]Training epoch 11:  22%|██▏       | 33/153 [00:00<00:02, 52.34it/s, Epoch: 11, Batch: 34,Loss: -0.519,Avg.Loss: 0.374,LR: 4.87E-04]Training epoch 11:  22%|██▏       | 34/153 [00:00<00:02, 52.34it/s, Epoch: 11, Batch: 35,Loss: -0.199,Avg.Loss: 0.358,LR: 4.87E-04]Training epoch 11:  23%|██▎       | 35/153 [00:00<00:02, 52.34it/s, Epoch: 11, Batch: 36,Loss: -0.208,Avg.Loss: 0.342,LR: 4.87E-04]Training epoch 11:  24%|██▎       | 36/153 [00:00<00:02, 52.50it/s, Epoch: 11, Batch: 36,Loss: -0.208,Avg.Loss: 0.342,LR: 4.87E-04]Training epoch 11:  24%|██▎       | 36/153 [00:00<00:02, 52.50it/s, Epoch: 11, Batch: 37,Loss: -0.235,Avg.Loss: 0.326,LR: 4.87E-04]Training epoch 11:  24%|██▍       | 37/153 [00:00<00:02, 52.50it/s, Epoch: 11, Batch: 38,Loss: 0.079,Avg.Loss: 0.320,LR: 4.87E-04] Training epoch 11:  25%|██▍       | 38/153 [00:00<00:02, 52.50it/s, Epoch: 11, Batch: 39,Loss: -0.069,Avg.Loss: 0.310,LR: 4.87E-04]Training epoch 11:  25%|██▌       | 39/153 [00:00<00:02, 52.50it/s, Epoch: 11, Batch: 40,Loss: -0.478,Avg.Loss: 0.290,LR: 4.87E-04]Training epoch 11:  26%|██▌       | 40/153 [00:00<00:02, 52.50it/s, Epoch: 11, Batch: 41,Loss: -0.318,Avg.Loss: 0.275,LR: 4.87E-04]Training epoch 11:  27%|██▋       | 41/153 [00:00<00:02, 52.50it/s, Epoch: 11, Batch: 42,Loss: 0.002,Avg.Loss: 0.269,LR: 4.87E-04] Training epoch 11:  27%|██▋       | 42/153 [00:00<00:02, 52.73it/s, Epoch: 11, Batch: 42,Loss: 0.002,Avg.Loss: 0.269,LR: 4.87E-04]Training epoch 11:  27%|██▋       | 42/153 [00:00<00:02, 52.73it/s, Epoch: 11, Batch: 43,Loss: -0.164,Avg.Loss: 0.259,LR: 4.87E-04]Training epoch 11:  28%|██▊       | 43/153 [00:00<00:02, 52.73it/s, Epoch: 11, Batch: 44,Loss: -0.189,Avg.Loss: 0.248,LR: 4.87E-04]Training epoch 11:  29%|██▉       | 44/153 [00:00<00:02, 52.73it/s, Epoch: 11, Batch: 45,Loss: -0.346,Avg.Loss: 0.235,LR: 4.87E-04]Training epoch 11:  29%|██▉       | 45/153 [00:00<00:02, 52.73it/s, Epoch: 11, Batch: 46,Loss: -0.510,Avg.Loss: 0.219,LR: 4.87E-04]Training epoch 11:  30%|███       | 46/153 [00:00<00:02, 52.73it/s, Epoch: 11, Batch: 47,Loss: 0.218,Avg.Loss: 0.219,LR: 4.87E-04] Training epoch 11:  31%|███       | 47/153 [00:00<00:02, 52.73it/s, Epoch: 11, Batch: 48,Loss: 0.261,Avg.Loss: 0.220,LR: 4.87E-04]Training epoch 11:  31%|███▏      | 48/153 [00:00<00:01, 52.98it/s, Epoch: 11, Batch: 48,Loss: 0.261,Avg.Loss: 0.220,LR: 4.87E-04]Training epoch 11:  31%|███▏      | 48/153 [00:00<00:01, 52.98it/s, Epoch: 11, Batch: 49,Loss: 0.184,Avg.Loss: 0.219,LR: 4.87E-04]Training epoch 11:  32%|███▏      | 49/153 [00:00<00:01, 52.98it/s, Epoch: 11, Batch: 50,Loss: -0.371,Avg.Loss: 0.207,LR: 4.87E-04]Training epoch 11:  33%|███▎      | 50/153 [00:00<00:01, 52.98it/s, Epoch: 11, Batch: 51,Loss: 0.605,Avg.Loss: 0.215,LR: 4.87E-04] Training epoch 11:  33%|███▎      | 51/153 [00:00<00:01, 52.98it/s, Epoch: 11, Batch: 52,Loss: 1.464,Avg.Loss: 0.239,LR: 4.87E-04]Training epoch 11:  34%|███▍      | 52/153 [00:00<00:01, 52.98it/s, Epoch: 11, Batch: 53,Loss: 3.117,Avg.Loss: 0.293,LR: 4.87E-04]Training epoch 11:  35%|███▍      | 53/153 [00:01<00:01, 52.98it/s, Epoch: 11, Batch: 54,Loss: 0.762,Avg.Loss: 0.302,LR: 4.87E-04]Training epoch 11:  35%|███▌      | 54/153 [00:01<00:01, 53.25it/s, Epoch: 11, Batch: 54,Loss: 0.762,Avg.Loss: 0.302,LR: 4.87E-04]Training epoch 11:  35%|███▌      | 54/153 [00:01<00:01, 53.25it/s, Epoch: 11, Batch: 55,Loss: 0.060,Avg.Loss: 0.298,LR: 4.87E-04]Training epoch 11:  36%|███▌      | 55/153 [00:01<00:01, 53.25it/s, Epoch: 11, Batch: 56,Loss: -0.189,Avg.Loss: 0.289,LR: 4.87E-04]Training epoch 11:  37%|███▋      | 56/153 [00:01<00:01, 53.25it/s, Epoch: 11, Batch: 57,Loss: 1.030,Avg.Loss: 0.302,LR: 4.87E-04] Training epoch 11:  37%|███▋      | 57/153 [00:01<00:01, 53.25it/s, Epoch: 11, Batch: 58,Loss: 0.862,Avg.Loss: 0.312,LR: 4.87E-04]Training epoch 11:  38%|███▊      | 58/153 [00:01<00:01, 53.25it/s, Epoch: 11, Batch: 59,Loss: 0.265,Avg.Loss: 0.311,LR: 4.87E-04]Training epoch 11:  39%|███▊      | 59/153 [00:01<00:01, 53.25it/s, Epoch: 11, Batch: 60,Loss: 0.144,Avg.Loss: 0.308,LR: 4.87E-04]Training epoch 11:  39%|███▉      | 60/153 [00:01<00:01, 53.33it/s, Epoch: 11, Batch: 60,Loss: 0.144,Avg.Loss: 0.308,LR: 4.87E-04]Training epoch 11:  39%|███▉      | 60/153 [00:01<00:01, 53.33it/s, Epoch: 11, Batch: 61,Loss: -0.002,Avg.Loss: 0.303,LR: 4.87E-04]Training epoch 11:  40%|███▉      | 61/153 [00:01<00:01, 53.33it/s, Epoch: 11, Batch: 62,Loss: 0.474,Avg.Loss: 0.306,LR: 4.87E-04] Training epoch 11:  41%|████      | 62/153 [00:01<00:01, 53.33it/s, Epoch: 11, Batch: 63,Loss: 0.721,Avg.Loss: 0.312,LR: 4.87E-04]Training epoch 11:  41%|████      | 63/153 [00:01<00:01, 53.33it/s, Epoch: 11, Batch: 64,Loss: 0.033,Avg.Loss: 0.308,LR: 4.87E-04]Training epoch 11:  42%|████▏     | 64/153 [00:01<00:01, 53.33it/s, Epoch: 11, Batch: 65,Loss: -0.368,Avg.Loss: 0.298,LR: 4.87E-04]Training epoch 11:  42%|████▏     | 65/153 [00:01<00:01, 53.33it/s, Epoch: 11, Batch: 66,Loss: 0.030,Avg.Loss: 0.294,LR: 4.87E-04] Training epoch 11:  43%|████▎     | 66/153 [00:01<00:01, 53.24it/s, Epoch: 11, Batch: 66,Loss: 0.030,Avg.Loss: 0.294,LR: 4.87E-04]Training epoch 11:  43%|████▎     | 66/153 [00:01<00:01, 53.24it/s, Epoch: 11, Batch: 67,Loss: 0.037,Avg.Loss: 0.290,LR: 4.87E-04]Training epoch 11:  44%|████▍     | 67/153 [00:01<00:01, 53.24it/s, Epoch: 11, Batch: 68,Loss: 0.122,Avg.Loss: 0.287,LR: 4.87E-04]Training epoch 11:  44%|████▍     | 68/153 [00:01<00:01, 53.24it/s, Epoch: 11, Batch: 69,Loss: -0.231,Avg.Loss: 0.280,LR: 4.87E-04]Training epoch 11:  45%|████▌     | 69/153 [00:01<00:01, 53.24it/s, Epoch: 11, Batch: 70,Loss: 0.071,Avg.Loss: 0.277,LR: 4.87E-04] Training epoch 11:  46%|████▌     | 70/153 [00:01<00:01, 53.24it/s, Epoch: 11, Batch: 71,Loss: 0.172,Avg.Loss: 0.275,LR: 4.87E-04]Training epoch 11:  46%|████▋     | 71/153 [00:01<00:01, 53.24it/s, Epoch: 11, Batch: 72,Loss: -0.480,Avg.Loss: 0.265,LR: 4.87E-04]Training epoch 11:  47%|████▋     | 72/153 [00:01<00:01, 53.28it/s, Epoch: 11, Batch: 72,Loss: -0.480,Avg.Loss: 0.265,LR: 4.87E-04]Training epoch 11:  47%|████▋     | 72/153 [00:01<00:01, 53.28it/s, Epoch: 11, Batch: 73,Loss: -0.290,Avg.Loss: 0.257,LR: 4.87E-04]Training epoch 11:  48%|████▊     | 73/153 [00:01<00:01, 53.28it/s, Epoch: 11, Batch: 74,Loss: -0.531,Avg.Loss: 0.247,LR: 4.87E-04]Training epoch 11:  48%|████▊     | 74/153 [00:01<00:01, 53.28it/s, Epoch: 11, Batch: 75,Loss: -0.314,Avg.Loss: 0.239,LR: 4.87E-04]Training epoch 11:  49%|████▉     | 75/153 [00:01<00:01, 53.28it/s, Epoch: 11, Batch: 76,Loss: -0.181,Avg.Loss: 0.234,LR: 4.87E-04]Training epoch 11:  50%|████▉     | 76/153 [00:01<00:01, 53.28it/s, Epoch: 11, Batch: 77,Loss: -0.393,Avg.Loss: 0.225,LR: 4.87E-04]Training epoch 11:  50%|█████     | 77/153 [00:01<00:01, 53.28it/s, Epoch: 11, Batch: 78,Loss: -0.581,Avg.Loss: 0.215,LR: 4.86E-04]Training epoch 11:  51%|█████     | 78/153 [00:01<00:01, 53.13it/s, Epoch: 11, Batch: 78,Loss: -0.581,Avg.Loss: 0.215,LR: 4.86E-04]Training epoch 11:  51%|█████     | 78/153 [00:01<00:01, 53.13it/s, Epoch: 11, Batch: 79,Loss: 0.141,Avg.Loss: 0.214,LR: 4.86E-04] Training epoch 11:  52%|█████▏    | 79/153 [00:01<00:01, 53.13it/s, Epoch: 11, Batch: 80,Loss: 0.442,Avg.Loss: 0.217,LR: 4.86E-04]Training epoch 11:  52%|█████▏    | 80/153 [00:01<00:01, 53.13it/s, Epoch: 11, Batch: 81,Loss: -0.148,Avg.Loss: 0.212,LR: 4.86E-04]Training epoch 11:  53%|█████▎    | 81/153 [00:01<00:01, 53.13it/s, Epoch: 11, Batch: 82,Loss: -0.264,Avg.Loss: 0.207,LR: 4.86E-04]Training epoch 11:  54%|█████▎    | 82/153 [00:01<00:01, 53.13it/s, Epoch: 11, Batch: 83,Loss: 0.263,Avg.Loss: 0.207,LR: 4.86E-04] Training epoch 11:  54%|█████▍    | 83/153 [00:01<00:01, 53.13it/s, Epoch: 11, Batch: 84,Loss: 0.597,Avg.Loss: 0.212,LR: 4.86E-04]Training epoch 11:  55%|█████▍    | 84/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 84,Loss: 0.597,Avg.Loss: 0.212,LR: 4.86E-04]Training epoch 11:  55%|█████▍    | 84/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 85,Loss: -0.268,Avg.Loss: 0.206,LR: 4.86E-04]Training epoch 11:  56%|█████▌    | 85/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 86,Loss: -0.117,Avg.Loss: 0.203,LR: 4.86E-04]Training epoch 11:  56%|█████▌    | 86/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 87,Loss: 0.814,Avg.Loss: 0.210,LR: 4.86E-04] Training epoch 11:  57%|█████▋    | 87/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 88,Loss: 0.426,Avg.Loss: 0.212,LR: 4.86E-04]Training epoch 11:  58%|█████▊    | 88/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 89,Loss: -0.434,Avg.Loss: 0.205,LR: 4.86E-04]Training epoch 11:  58%|█████▊    | 89/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 90,Loss: -0.087,Avg.Loss: 0.202,LR: 4.86E-04]Training epoch 11:  59%|█████▉    | 90/153 [00:01<00:01, 52.89it/s, Epoch: 11, Batch: 90,Loss: -0.087,Avg.Loss: 0.202,LR: 4.86E-04]Training epoch 11:  59%|█████▉    | 90/153 [00:01<00:01, 52.89it/s, Epoch: 11, Batch: 91,Loss: 0.638,Avg.Loss: 0.206,LR: 4.86E-04] Training epoch 11:  59%|█████▉    | 91/153 [00:01<00:01, 52.89it/s, Epoch: 11, Batch: 92,Loss: 0.069,Avg.Loss: 0.205,LR: 4.86E-04]Training epoch 11:  60%|██████    | 92/153 [00:01<00:01, 52.89it/s, Epoch: 11, Batch: 93,Loss: -0.540,Avg.Loss: 0.197,LR: 4.86E-04]Training epoch 11:  61%|██████    | 93/153 [00:01<00:01, 52.89it/s, Epoch: 11, Batch: 94,Loss: -0.183,Avg.Loss: 0.193,LR: 4.86E-04]Training epoch 11:  61%|██████▏   | 94/153 [00:01<00:01, 52.89it/s, Epoch: 11, Batch: 95,Loss: 0.408,Avg.Loss: 0.195,LR: 4.86E-04] Training epoch 11:  62%|██████▏   | 95/153 [00:01<00:01, 52.89it/s, Epoch: 11, Batch: 96,Loss: -0.412,Avg.Loss: 0.189,LR: 4.86E-04]Training epoch 11:  63%|██████▎   | 96/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 96,Loss: -0.412,Avg.Loss: 0.189,LR: 4.86E-04]Training epoch 11:  63%|██████▎   | 96/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 97,Loss: -0.526,Avg.Loss: 0.181,LR: 4.86E-04]Training epoch 11:  63%|██████▎   | 97/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 98,Loss: 0.285,Avg.Loss: 0.182,LR: 4.86E-04] Training epoch 11:  64%|██████▍   | 98/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 99,Loss: 0.154,Avg.Loss: 0.182,LR: 4.86E-04]Training epoch 11:  65%|██████▍   | 99/153 [00:01<00:01, 53.11it/s, Epoch: 11, Batch: 100,Loss: 0.180,Avg.Loss: 0.182,LR: 4.86E-04]Training epoch 11:  65%|██████▌   | 100/153 [00:01<00:00, 53.11it/s, Epoch: 11, Batch: 101,Loss: -0.542,Avg.Loss: 0.175,LR: 4.86E-04]Training epoch 11:  66%|██████▌   | 101/153 [00:01<00:00, 53.11it/s, Epoch: 11, Batch: 102,Loss: -0.105,Avg.Loss: 0.172,LR: 4.86E-04]Training epoch 11:  67%|██████▋   | 102/153 [00:01<00:00, 53.14it/s, Epoch: 11, Batch: 102,Loss: -0.105,Avg.Loss: 0.172,LR: 4.86E-04]Training epoch 11:  67%|██████▋   | 102/153 [00:01<00:00, 53.14it/s, Epoch: 11, Batch: 103,Loss: 0.031,Avg.Loss: 0.171,LR: 4.86E-04] Training epoch 11:  67%|██████▋   | 103/153 [00:01<00:00, 53.14it/s, Epoch: 11, Batch: 104,Loss: 0.087,Avg.Loss: 0.170,LR: 4.86E-04]Training epoch 11:  68%|██████▊   | 104/153 [00:01<00:00, 53.14it/s, Epoch: 11, Batch: 105,Loss: -0.633,Avg.Loss: 0.162,LR: 4.86E-04]Training epoch 11:  69%|██████▊   | 105/153 [00:01<00:00, 53.14it/s, Epoch: 11, Batch: 106,Loss: -0.336,Avg.Loss: 0.158,LR: 4.86E-04]Training epoch 11:  69%|██████▉   | 106/153 [00:02<00:00, 53.14it/s, Epoch: 11, Batch: 107,Loss: -0.150,Avg.Loss: 0.155,LR: 4.86E-04]Training epoch 11:  70%|██████▉   | 107/153 [00:02<00:00, 53.14it/s, Epoch: 11, Batch: 108,Loss: -0.441,Avg.Loss: 0.149,LR: 4.86E-04]Training epoch 11:  71%|███████   | 108/153 [00:02<00:00, 53.41it/s, Epoch: 11, Batch: 108,Loss: -0.441,Avg.Loss: 0.149,LR: 4.86E-04]Training epoch 11:  71%|███████   | 108/153 [00:02<00:00, 53.41it/s, Epoch: 11, Batch: 109,Loss: -0.284,Avg.Loss: 0.145,LR: 4.86E-04]Training epoch 11:  71%|███████   | 109/153 [00:02<00:00, 53.41it/s, Epoch: 11, Batch: 110,Loss: -0.279,Avg.Loss: 0.141,LR: 4.86E-04]Training epoch 11:  72%|███████▏  | 110/153 [00:02<00:00, 53.41it/s, Epoch: 11, Batch: 111,Loss: -0.024,Avg.Loss: 0.140,LR: 4.86E-04]Training epoch 11:  73%|███████▎  | 111/153 [00:02<00:00, 53.41it/s, Epoch: 11, Batch: 112,Loss: -0.356,Avg.Loss: 0.136,LR: 4.86E-04]Training epoch 11:  73%|███████▎  | 112/153 [00:02<00:00, 53.41it/s, Epoch: 11, Batch: 113,Loss: -0.453,Avg.Loss: 0.130,LR: 4.86E-04]Training epoch 11:  74%|███████▍  | 113/153 [00:02<00:00, 53.41it/s, Epoch: 11, Batch: 114,Loss: 0.211,Avg.Loss: 0.131,LR: 4.86E-04] Training epoch 11:  75%|███████▍  | 114/153 [00:02<00:00, 53.34it/s, Epoch: 11, Batch: 114,Loss: 0.211,Avg.Loss: 0.131,LR: 4.86E-04]Training epoch 11:  75%|███████▍  | 114/153 [00:02<00:00, 53.34it/s, Epoch: 11, Batch: 115,Loss: -0.040,Avg.Loss: 0.130,LR: 4.86E-04]Training epoch 11:  75%|███████▌  | 115/153 [00:02<00:00, 53.34it/s, Epoch: 11, Batch: 116,Loss: -0.438,Avg.Loss: 0.125,LR: 4.86E-04]Training epoch 11:  76%|███████▌  | 116/153 [00:02<00:00, 53.34it/s, Epoch: 11, Batch: 117,Loss: -0.220,Avg.Loss: 0.122,LR: 4.86E-04]Training epoch 11:  76%|███████▋  | 117/153 [00:02<00:00, 53.34it/s, Epoch: 11, Batch: 118,Loss: -0.556,Avg.Loss: 0.116,LR: 4.86E-04]Training epoch 11:  77%|███████▋  | 118/153 [00:02<00:00, 53.34it/s, Epoch: 11, Batch: 119,Loss: -0.438,Avg.Loss: 0.111,LR: 4.86E-04]Training epoch 11:  78%|███████▊  | 119/153 [00:02<00:00, 53.34it/s, Epoch: 11, Batch: 120,Loss: -0.082,Avg.Loss: 0.110,LR: 4.86E-04]Training epoch 11:  78%|███████▊  | 120/153 [00:02<00:00, 53.20it/s, Epoch: 11, Batch: 120,Loss: -0.082,Avg.Loss: 0.110,LR: 4.86E-04]Training epoch 11:  78%|███████▊  | 120/153 [00:02<00:00, 53.20it/s, Epoch: 11, Batch: 121,Loss: -0.535,Avg.Loss: 0.104,LR: 4.86E-04]Training epoch 11:  79%|███████▉  | 121/153 [00:02<00:00, 53.20it/s, Epoch: 11, Batch: 122,Loss: -0.675,Avg.Loss: 0.098,LR: 4.86E-04]Training epoch 11:  80%|███████▉  | 122/153 [00:02<00:00, 53.20it/s, Epoch: 11, Batch: 123,Loss: -0.673,Avg.Loss: 0.092,LR: 4.86E-04]Training epoch 11:  80%|████████  | 123/153 [00:02<00:00, 53.20it/s, Epoch: 11, Batch: 124,Loss: -0.536,Avg.Loss: 0.087,LR: 4.86E-04]Training epoch 11:  81%|████████  | 124/153 [00:02<00:00, 53.20it/s, Epoch: 11, Batch: 125,Loss: -0.366,Avg.Loss: 0.083,LR: 4.86E-04]Training epoch 11:  82%|████████▏ | 125/153 [00:02<00:00, 53.20it/s, Epoch: 11, Batch: 126,Loss: -0.506,Avg.Loss: 0.078,LR: 4.86E-04]Training epoch 11:  82%|████████▏ | 126/153 [00:02<00:00, 53.19it/s, Epoch: 11, Batch: 126,Loss: -0.506,Avg.Loss: 0.078,LR: 4.86E-04]Training epoch 11:  82%|████████▏ | 126/153 [00:02<00:00, 53.19it/s, Epoch: 11, Batch: 127,Loss: -0.490,Avg.Loss: 0.074,LR: 4.86E-04]Training epoch 11:  83%|████████▎ | 127/153 [00:02<00:00, 53.19it/s, Epoch: 11, Batch: 128,Loss: -0.328,Avg.Loss: 0.071,LR: 4.86E-04]Training epoch 11:  84%|████████▎ | 128/153 [00:02<00:00, 53.19it/s, Epoch: 11, Batch: 129,Loss: -0.614,Avg.Loss: 0.065,LR: 4.86E-04]Training epoch 11:  84%|████████▍ | 129/153 [00:02<00:00, 53.19it/s, Epoch: 11, Batch: 130,Loss: -0.770,Avg.Loss: 0.059,LR: 4.86E-04]Training epoch 11:  85%|████████▍ | 130/153 [00:02<00:00, 53.19it/s, Epoch: 11, Batch: 131,Loss: -0.558,Avg.Loss: 0.054,LR: 4.86E-04]Training epoch 11:  86%|████████▌ | 131/153 [00:02<00:00, 53.19it/s, Epoch: 11, Batch: 132,Loss: -0.551,Avg.Loss: 0.050,LR: 4.86E-04]Training epoch 11:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 11, Batch: 132,Loss: -0.551,Avg.Loss: 0.050,LR: 4.86E-04]Training epoch 11:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 11, Batch: 133,Loss: -0.366,Avg.Loss: 0.047,LR: 4.86E-04]Training epoch 11:  87%|████████▋ | 133/153 [00:02<00:00, 53.28it/s, Epoch: 11, Batch: 134,Loss: -0.467,Avg.Loss: 0.043,LR: 4.86E-04]Training epoch 11:  88%|████████▊ | 134/153 [00:02<00:00, 53.28it/s, Epoch: 11, Batch: 135,Loss: -0.009,Avg.Loss: 0.042,LR: 4.86E-04]Training epoch 11:  88%|████████▊ | 135/153 [00:02<00:00, 53.28it/s, Epoch: 11, Batch: 136,Loss: -0.729,Avg.Loss: 0.037,LR: 4.86E-04]Training epoch 11:  89%|████████▉ | 136/153 [00:02<00:00, 53.28it/s, Epoch: 11, Batch: 137,Loss: -0.355,Avg.Loss: 0.034,LR: 4.85E-04]Training epoch 11:  90%|████████▉ | 137/153 [00:02<00:00, 53.28it/s, Epoch: 11, Batch: 138,Loss: -0.272,Avg.Loss: 0.032,LR: 4.85E-04]Training epoch 11:  90%|█████████ | 138/153 [00:02<00:00, 53.40it/s, Epoch: 11, Batch: 138,Loss: -0.272,Avg.Loss: 0.032,LR: 4.85E-04]Training epoch 11:  90%|█████████ | 138/153 [00:02<00:00, 53.40it/s, Epoch: 11, Batch: 139,Loss: -0.127,Avg.Loss: 0.030,LR: 4.85E-04]Training epoch 11:  91%|█████████ | 139/153 [00:02<00:00, 53.40it/s, Epoch: 11, Batch: 140,Loss: -0.881,Avg.Loss: 0.024,LR: 4.85E-04]Training epoch 11:  92%|█████████▏| 140/153 [00:02<00:00, 53.40it/s, Epoch: 11, Batch: 141,Loss: -0.293,Avg.Loss: 0.022,LR: 4.85E-04]Training epoch 11:  92%|█████████▏| 141/153 [00:02<00:00, 53.40it/s, Epoch: 11, Batch: 142,Loss: -0.230,Avg.Loss: 0.020,LR: 4.85E-04]Training epoch 11:  93%|█████████▎| 142/153 [00:02<00:00, 53.40it/s, Epoch: 11, Batch: 143,Loss: -0.234,Avg.Loss: 0.018,LR: 4.85E-04]Training epoch 11:  93%|█████████▎| 143/153 [00:02<00:00, 53.40it/s, Epoch: 11, Batch: 144,Loss: -0.114,Avg.Loss: 0.017,LR: 4.85E-04]Training epoch 11:  94%|█████████▍| 144/153 [00:02<00:00, 53.39it/s, Epoch: 11, Batch: 144,Loss: -0.114,Avg.Loss: 0.017,LR: 4.85E-04]Training epoch 11:  94%|█████████▍| 144/153 [00:02<00:00, 53.39it/s, Epoch: 11, Batch: 145,Loss: 0.913,Avg.Loss: 0.023,LR: 4.85E-04] Training epoch 11:  95%|█████████▍| 145/153 [00:02<00:00, 53.39it/s, Epoch: 11, Batch: 146,Loss: 0.261,Avg.Loss: 0.025,LR: 4.85E-04]Training epoch 11:  95%|█████████▌| 146/153 [00:02<00:00, 53.39it/s, Epoch: 11, Batch: 147,Loss: -0.435,Avg.Loss: 0.022,LR: 4.85E-04]Training epoch 11:  96%|█████████▌| 147/153 [00:02<00:00, 53.39it/s, Epoch: 11, Batch: 148,Loss: -0.363,Avg.Loss: 0.019,LR: 4.85E-04]Training epoch 11:  97%|█████████▋| 148/153 [00:02<00:00, 53.39it/s, Epoch: 11, Batch: 149,Loss: -0.347,Avg.Loss: 0.017,LR: 4.85E-04]Training epoch 11:  97%|█████████▋| 149/153 [00:02<00:00, 53.39it/s, Epoch: 11, Batch: 150,Loss: -0.241,Avg.Loss: 0.015,LR: 4.85E-04]Training epoch 11:  98%|█████████▊| 150/153 [00:02<00:00, 53.58it/s, Epoch: 11, Batch: 150,Loss: -0.241,Avg.Loss: 0.015,LR: 4.85E-04]Training epoch 11:  98%|█████████▊| 150/153 [00:02<00:00, 53.58it/s, Epoch: 11, Batch: 151,Loss: -0.282,Avg.Loss: 0.013,LR: 4.85E-04]Training epoch 11:  99%|█████████▊| 151/153 [00:02<00:00, 53.58it/s, Epoch: 11, Batch: 152,Loss: -0.678,Avg.Loss: 0.009,LR: 4.85E-04]Training epoch 11:  99%|█████████▉| 152/153 [00:02<00:00, 53.58it/s, Epoch: 11, Batch: 153,Loss: 0.598,Avg.Loss: 0.012,LR: 4.85E-04] Training epoch 11: 100%|██████████| 153/153 [00:02<00:00, 53.19it/s, Epoch: 11, Batch: 153,Loss: 0.598,Avg.Loss: 0.012,LR: 4.85E-04]
Training epoch 12:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 12:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 12, Batch: 1,Loss: -0.283,Avg.Loss: -0.283,LR: 4.85E-04]Training epoch 12:   1%|          | 1/153 [00:00<00:05, 27.76it/s, Epoch: 12, Batch: 2,Loss: -0.726,Avg.Loss: -0.505,LR: 4.85E-04]Training epoch 12:   1%|▏         | 2/153 [00:00<00:04, 36.65it/s, Epoch: 12, Batch: 3,Loss: 0.068,Avg.Loss: -0.314,LR: 4.85E-04] Training epoch 12:   2%|▏         | 3/153 [00:00<00:03, 42.14it/s, Epoch: 12, Batch: 4,Loss: 0.492,Avg.Loss: -0.112,LR: 4.85E-04]Training epoch 12:   3%|▎         | 4/153 [00:00<00:03, 45.38it/s, Epoch: 12, Batch: 5,Loss: 0.387,Avg.Loss: -0.012,LR: 4.85E-04]Training epoch 12:   3%|▎         | 5/153 [00:00<00:03, 46.60it/s, Epoch: 12, Batch: 6,Loss: -0.100,Avg.Loss: -0.027,LR: 4.85E-04]Training epoch 12:   4%|▍         | 6/153 [00:00<00:02, 55.83it/s, Epoch: 12, Batch: 6,Loss: -0.100,Avg.Loss: -0.027,LR: 4.85E-04]Training epoch 12:   4%|▍         | 6/153 [00:00<00:02, 55.83it/s, Epoch: 12, Batch: 7,Loss: -0.138,Avg.Loss: -0.043,LR: 4.85E-04]Training epoch 12:   5%|▍         | 7/153 [00:00<00:02, 55.83it/s, Epoch: 12, Batch: 8,Loss: 0.093,Avg.Loss: -0.026,LR: 4.85E-04] Training epoch 12:   5%|▌         | 8/153 [00:00<00:02, 55.83it/s, Epoch: 12, Batch: 9,Loss: -0.091,Avg.Loss: -0.033,LR: 4.85E-04]Training epoch 12:   6%|▌         | 9/153 [00:00<00:02, 55.83it/s, Epoch: 12, Batch: 10,Loss: -0.509,Avg.Loss: -0.081,LR: 4.85E-04]Training epoch 12:   7%|▋         | 10/153 [00:00<00:02, 55.83it/s, Epoch: 12, Batch: 11,Loss: -0.438,Avg.Loss: -0.113,LR: 4.85E-04]Training epoch 12:   7%|▋         | 11/153 [00:00<00:02, 55.83it/s, Epoch: 12, Batch: 12,Loss: 0.229,Avg.Loss: -0.085,LR: 4.85E-04] Training epoch 12:   8%|▊         | 12/153 [00:00<00:02, 54.08it/s, Epoch: 12, Batch: 12,Loss: 0.229,Avg.Loss: -0.085,LR: 4.85E-04]Training epoch 12:   8%|▊         | 12/153 [00:00<00:02, 54.08it/s, Epoch: 12, Batch: 13,Loss: -0.627,Avg.Loss: -0.126,LR: 4.85E-04]Training epoch 12:   8%|▊         | 13/153 [00:00<00:02, 54.08it/s, Epoch: 12, Batch: 14,Loss: -0.563,Avg.Loss: -0.158,LR: 4.85E-04]Training epoch 12:   9%|▉         | 14/153 [00:00<00:02, 54.08it/s, Epoch: 12, Batch: 15,Loss: -0.513,Avg.Loss: -0.181,LR: 4.85E-04]Training epoch 12:  10%|▉         | 15/153 [00:00<00:02, 54.08it/s, Epoch: 12, Batch: 16,Loss: -0.635,Avg.Loss: -0.210,LR: 4.85E-04]Training epoch 12:  10%|█         | 16/153 [00:00<00:02, 54.08it/s, Epoch: 12, Batch: 17,Loss: -0.397,Avg.Loss: -0.221,LR: 4.85E-04]Training epoch 12:  11%|█         | 17/153 [00:00<00:02, 54.08it/s, Epoch: 12, Batch: 18,Loss: -0.570,Avg.Loss: -0.240,LR: 4.85E-04]Training epoch 12:  12%|█▏        | 18/153 [00:00<00:02, 53.79it/s, Epoch: 12, Batch: 18,Loss: -0.570,Avg.Loss: -0.240,LR: 4.85E-04]Training epoch 12:  12%|█▏        | 18/153 [00:00<00:02, 53.79it/s, Epoch: 12, Batch: 19,Loss: -0.571,Avg.Loss: -0.257,LR: 4.85E-04]Training epoch 12:  12%|█▏        | 19/153 [00:00<00:02, 53.79it/s, Epoch: 12, Batch: 20,Loss: -0.287,Avg.Loss: -0.259,LR: 4.85E-04]Training epoch 12:  13%|█▎        | 20/153 [00:00<00:02, 53.79it/s, Epoch: 12, Batch: 21,Loss: -0.405,Avg.Loss: -0.266,LR: 4.85E-04]Training epoch 12:  14%|█▎        | 21/153 [00:00<00:02, 53.79it/s, Epoch: 12, Batch: 22,Loss: -0.523,Avg.Loss: -0.278,LR: 4.85E-04]Training epoch 12:  14%|█▍        | 22/153 [00:00<00:02, 53.79it/s, Epoch: 12, Batch: 23,Loss: -0.358,Avg.Loss: -0.281,LR: 4.85E-04]Training epoch 12:  15%|█▌        | 23/153 [00:00<00:02, 53.79it/s, Epoch: 12, Batch: 24,Loss: -0.683,Avg.Loss: -0.298,LR: 4.85E-04]Training epoch 12:  16%|█▌        | 24/153 [00:00<00:02, 53.44it/s, Epoch: 12, Batch: 24,Loss: -0.683,Avg.Loss: -0.298,LR: 4.85E-04]Training epoch 12:  16%|█▌        | 24/153 [00:00<00:02, 53.44it/s, Epoch: 12, Batch: 25,Loss: -0.727,Avg.Loss: -0.315,LR: 4.85E-04]Training epoch 12:  16%|█▋        | 25/153 [00:00<00:02, 53.44it/s, Epoch: 12, Batch: 26,Loss: -0.567,Avg.Loss: -0.325,LR: 4.85E-04]Training epoch 12:  17%|█▋        | 26/153 [00:00<00:02, 53.44it/s, Epoch: 12, Batch: 27,Loss: -0.236,Avg.Loss: -0.321,LR: 4.85E-04]Training epoch 12:  18%|█▊        | 27/153 [00:00<00:02, 53.44it/s, Epoch: 12, Batch: 28,Loss: -0.387,Avg.Loss: -0.324,LR: 4.85E-04]Training epoch 12:  18%|█▊        | 28/153 [00:00<00:02, 53.44it/s, Epoch: 12, Batch: 29,Loss: -0.541,Avg.Loss: -0.331,LR: 4.85E-04]Training epoch 12:  19%|█▉        | 29/153 [00:00<00:02, 53.44it/s, Epoch: 12, Batch: 30,Loss: -0.649,Avg.Loss: -0.342,LR: 4.85E-04]Training epoch 12:  20%|█▉        | 30/153 [00:00<00:02, 52.98it/s, Epoch: 12, Batch: 30,Loss: -0.649,Avg.Loss: -0.342,LR: 4.85E-04]Training epoch 12:  20%|█▉        | 30/153 [00:00<00:02, 52.98it/s, Epoch: 12, Batch: 31,Loss: -0.378,Avg.Loss: -0.343,LR: 4.85E-04]Training epoch 12:  20%|██        | 31/153 [00:00<00:02, 52.98it/s, Epoch: 12, Batch: 32,Loss: -0.881,Avg.Loss: -0.360,LR: 4.85E-04]Training epoch 12:  21%|██        | 32/153 [00:00<00:02, 52.98it/s, Epoch: 12, Batch: 33,Loss: -0.526,Avg.Loss: -0.365,LR: 4.85E-04]Training epoch 12:  22%|██▏       | 33/153 [00:00<00:02, 52.98it/s, Epoch: 12, Batch: 34,Loss: -0.464,Avg.Loss: -0.368,LR: 4.85E-04]Training epoch 12:  22%|██▏       | 34/153 [00:00<00:02, 52.98it/s, Epoch: 12, Batch: 35,Loss: -0.290,Avg.Loss: -0.366,LR: 4.85E-04]Training epoch 12:  23%|██▎       | 35/153 [00:00<00:02, 52.98it/s, Epoch: 12, Batch: 36,Loss: -0.471,Avg.Loss: -0.368,LR: 4.85E-04]Training epoch 12:  24%|██▎       | 36/153 [00:00<00:02, 52.67it/s, Epoch: 12, Batch: 36,Loss: -0.471,Avg.Loss: -0.368,LR: 4.85E-04]Training epoch 12:  24%|██▎       | 36/153 [00:00<00:02, 52.67it/s, Epoch: 12, Batch: 37,Loss: -0.615,Avg.Loss: -0.375,LR: 4.85E-04]Training epoch 12:  24%|██▍       | 37/153 [00:00<00:02, 52.67it/s, Epoch: 12, Batch: 38,Loss: 0.029,Avg.Loss: -0.365,LR: 4.85E-04] Training epoch 12:  25%|██▍       | 38/153 [00:00<00:02, 52.67it/s, Epoch: 12, Batch: 39,Loss: -0.748,Avg.Loss: -0.374,LR: 4.85E-04]Training epoch 12:  25%|██▌       | 39/153 [00:00<00:02, 52.67it/s, Epoch: 12, Batch: 40,Loss: -0.659,Avg.Loss: -0.381,LR: 4.85E-04]Training epoch 12:  26%|██▌       | 40/153 [00:00<00:02, 52.67it/s, Epoch: 12, Batch: 41,Loss: -0.676,Avg.Loss: -0.389,LR: 4.84E-04]Training epoch 12:  27%|██▋       | 41/153 [00:00<00:02, 52.67it/s, Epoch: 12, Batch: 42,Loss: -0.687,Avg.Loss: -0.396,LR: 4.84E-04]Training epoch 12:  27%|██▋       | 42/153 [00:00<00:02, 52.52it/s, Epoch: 12, Batch: 42,Loss: -0.687,Avg.Loss: -0.396,LR: 4.84E-04]Training epoch 12:  27%|██▋       | 42/153 [00:00<00:02, 52.52it/s, Epoch: 12, Batch: 43,Loss: -0.510,Avg.Loss: -0.398,LR: 4.84E-04]Training epoch 12:  28%|██▊       | 43/153 [00:00<00:02, 52.52it/s, Epoch: 12, Batch: 44,Loss: -0.506,Avg.Loss: -0.401,LR: 4.84E-04]Training epoch 12:  29%|██▉       | 44/153 [00:00<00:02, 52.52it/s, Epoch: 12, Batch: 45,Loss: -0.580,Avg.Loss: -0.405,LR: 4.84E-04]Training epoch 12:  29%|██▉       | 45/153 [00:00<00:02, 52.52it/s, Epoch: 12, Batch: 46,Loss: -0.267,Avg.Loss: -0.402,LR: 4.84E-04]Training epoch 12:  30%|███       | 46/153 [00:00<00:02, 52.52it/s, Epoch: 12, Batch: 47,Loss: 0.011,Avg.Loss: -0.393,LR: 4.84E-04] Training epoch 12:  31%|███       | 47/153 [00:00<00:02, 52.52it/s, Epoch: 12, Batch: 48,Loss: 1.024,Avg.Loss: -0.364,LR: 4.84E-04]Training epoch 12:  31%|███▏      | 48/153 [00:00<00:01, 52.74it/s, Epoch: 12, Batch: 48,Loss: 1.024,Avg.Loss: -0.364,LR: 4.84E-04]Training epoch 12:  31%|███▏      | 48/153 [00:00<00:01, 52.74it/s, Epoch: 12, Batch: 49,Loss: 0.222,Avg.Loss: -0.352,LR: 4.84E-04]Training epoch 12:  32%|███▏      | 49/153 [00:00<00:01, 52.74it/s, Epoch: 12, Batch: 50,Loss: -0.492,Avg.Loss: -0.354,LR: 4.84E-04]Training epoch 12:  33%|███▎      | 50/153 [00:00<00:01, 52.74it/s, Epoch: 12, Batch: 51,Loss: 0.283,Avg.Loss: -0.342,LR: 4.84E-04] Training epoch 12:  33%|███▎      | 51/153 [00:00<00:01, 52.74it/s, Epoch: 12, Batch: 52,Loss: 0.717,Avg.Loss: -0.322,LR: 4.84E-04]Training epoch 12:  34%|███▍      | 52/153 [00:00<00:01, 52.74it/s, Epoch: 12, Batch: 53,Loss: 0.397,Avg.Loss: -0.308,LR: 4.84E-04]Training epoch 12:  35%|███▍      | 53/153 [00:01<00:01, 52.74it/s, Epoch: 12, Batch: 54,Loss: 0.253,Avg.Loss: -0.298,LR: 4.84E-04]Training epoch 12:  35%|███▌      | 54/153 [00:01<00:01, 52.86it/s, Epoch: 12, Batch: 54,Loss: 0.253,Avg.Loss: -0.298,LR: 4.84E-04]Training epoch 12:  35%|███▌      | 54/153 [00:01<00:01, 52.86it/s, Epoch: 12, Batch: 55,Loss: -0.489,Avg.Loss: -0.301,LR: 4.84E-04]Training epoch 12:  36%|███▌      | 55/153 [00:01<00:01, 52.86it/s, Epoch: 12, Batch: 56,Loss: -0.445,Avg.Loss: -0.304,LR: 4.84E-04]Training epoch 12:  37%|███▋      | 56/153 [00:01<00:01, 52.86it/s, Epoch: 12, Batch: 57,Loss: 0.682,Avg.Loss: -0.286,LR: 4.84E-04] Training epoch 12:  37%|███▋      | 57/153 [00:01<00:01, 52.86it/s, Epoch: 12, Batch: 58,Loss: 0.267,Avg.Loss: -0.277,LR: 4.84E-04]Training epoch 12:  38%|███▊      | 58/153 [00:01<00:01, 52.86it/s, Epoch: 12, Batch: 59,Loss: -0.122,Avg.Loss: -0.274,LR: 4.84E-04]Training epoch 12:  39%|███▊      | 59/153 [00:01<00:01, 52.86it/s, Epoch: 12, Batch: 60,Loss: -0.570,Avg.Loss: -0.279,LR: 4.84E-04]Training epoch 12:  39%|███▉      | 60/153 [00:01<00:01, 52.64it/s, Epoch: 12, Batch: 60,Loss: -0.570,Avg.Loss: -0.279,LR: 4.84E-04]Training epoch 12:  39%|███▉      | 60/153 [00:01<00:01, 52.64it/s, Epoch: 12, Batch: 61,Loss: -0.348,Avg.Loss: -0.280,LR: 4.84E-04]Training epoch 12:  40%|███▉      | 61/153 [00:01<00:01, 52.64it/s, Epoch: 12, Batch: 62,Loss: -0.303,Avg.Loss: -0.281,LR: 4.84E-04]Training epoch 12:  41%|████      | 62/153 [00:01<00:01, 52.64it/s, Epoch: 12, Batch: 63,Loss: -0.260,Avg.Loss: -0.280,LR: 4.84E-04]Training epoch 12:  41%|████      | 63/153 [00:01<00:01, 52.64it/s, Epoch: 12, Batch: 64,Loss: -0.594,Avg.Loss: -0.285,LR: 4.84E-04]Training epoch 12:  42%|████▏     | 64/153 [00:01<00:01, 52.64it/s, Epoch: 12, Batch: 65,Loss: -0.573,Avg.Loss: -0.290,LR: 4.84E-04]Training epoch 12:  42%|████▏     | 65/153 [00:01<00:01, 52.64it/s, Epoch: 12, Batch: 66,Loss: -0.636,Avg.Loss: -0.295,LR: 4.84E-04]Training epoch 12:  43%|████▎     | 66/153 [00:01<00:01, 52.87it/s, Epoch: 12, Batch: 66,Loss: -0.636,Avg.Loss: -0.295,LR: 4.84E-04]Training epoch 12:  43%|████▎     | 66/153 [00:01<00:01, 52.87it/s, Epoch: 12, Batch: 67,Loss: -0.675,Avg.Loss: -0.301,LR: 4.84E-04]Training epoch 12:  44%|████▍     | 67/153 [00:01<00:01, 52.87it/s, Epoch: 12, Batch: 68,Loss: -0.675,Avg.Loss: -0.306,LR: 4.84E-04]Training epoch 12:  44%|████▍     | 68/153 [00:01<00:01, 52.87it/s, Epoch: 12, Batch: 69,Loss: -0.693,Avg.Loss: -0.312,LR: 4.84E-04]Training epoch 12:  45%|████▌     | 69/153 [00:01<00:01, 52.87it/s, Epoch: 12, Batch: 70,Loss: -0.553,Avg.Loss: -0.315,LR: 4.84E-04]Training epoch 12:  46%|████▌     | 70/153 [00:01<00:01, 52.87it/s, Epoch: 12, Batch: 71,Loss: -0.691,Avg.Loss: -0.320,LR: 4.84E-04]Training epoch 12:  46%|████▋     | 71/153 [00:01<00:01, 52.87it/s, Epoch: 12, Batch: 72,Loss: -0.823,Avg.Loss: -0.327,LR: 4.84E-04]Training epoch 12:  47%|████▋     | 72/153 [00:01<00:01, 52.99it/s, Epoch: 12, Batch: 72,Loss: -0.823,Avg.Loss: -0.327,LR: 4.84E-04]Training epoch 12:  47%|████▋     | 72/153 [00:01<00:01, 52.99it/s, Epoch: 12, Batch: 73,Loss: -0.659,Avg.Loss: -0.332,LR: 4.84E-04]Training epoch 12:  48%|████▊     | 73/153 [00:01<00:01, 52.99it/s, Epoch: 12, Batch: 74,Loss: -0.215,Avg.Loss: -0.330,LR: 4.84E-04]Training epoch 12:  48%|████▊     | 74/153 [00:01<00:01, 52.99it/s, Epoch: 12, Batch: 75,Loss: 0.334,Avg.Loss: -0.321,LR: 4.84E-04] Training epoch 12:  49%|████▉     | 75/153 [00:01<00:01, 52.99it/s, Epoch: 12, Batch: 76,Loss: -0.231,Avg.Loss: -0.320,LR: 4.84E-04]Training epoch 12:  50%|████▉     | 76/153 [00:01<00:01, 52.99it/s, Epoch: 12, Batch: 77,Loss: -0.769,Avg.Loss: -0.326,LR: 4.84E-04]Training epoch 12:  50%|█████     | 77/153 [00:01<00:01, 52.99it/s, Epoch: 12, Batch: 78,Loss: -0.601,Avg.Loss: -0.330,LR: 4.84E-04]Training epoch 12:  51%|█████     | 78/153 [00:01<00:01, 52.95it/s, Epoch: 12, Batch: 78,Loss: -0.601,Avg.Loss: -0.330,LR: 4.84E-04]Training epoch 12:  51%|█████     | 78/153 [00:01<00:01, 52.95it/s, Epoch: 12, Batch: 79,Loss: -0.678,Avg.Loss: -0.334,LR: 4.84E-04]Training epoch 12:  52%|█████▏    | 79/153 [00:01<00:01, 52.95it/s, Epoch: 12, Batch: 80,Loss: -0.713,Avg.Loss: -0.339,LR: 4.84E-04]Training epoch 12:  52%|█████▏    | 80/153 [00:01<00:01, 52.95it/s, Epoch: 12, Batch: 81,Loss: -0.632,Avg.Loss: -0.342,LR: 4.84E-04]Training epoch 12:  53%|█████▎    | 81/153 [00:01<00:01, 52.95it/s, Epoch: 12, Batch: 82,Loss: -0.903,Avg.Loss: -0.349,LR: 4.84E-04]Training epoch 12:  54%|█████▎    | 82/153 [00:01<00:01, 52.95it/s, Epoch: 12, Batch: 83,Loss: -0.702,Avg.Loss: -0.353,LR: 4.84E-04]Training epoch 12:  54%|█████▍    | 83/153 [00:01<00:01, 52.95it/s, Epoch: 12, Batch: 84,Loss: -0.781,Avg.Loss: -0.359,LR: 4.84E-04]Training epoch 12:  55%|█████▍    | 84/153 [00:01<00:01, 53.01it/s, Epoch: 12, Batch: 84,Loss: -0.781,Avg.Loss: -0.359,LR: 4.84E-04]Training epoch 12:  55%|█████▍    | 84/153 [00:01<00:01, 53.01it/s, Epoch: 12, Batch: 85,Loss: -0.753,Avg.Loss: -0.363,LR: 4.84E-04]Training epoch 12:  56%|█████▌    | 85/153 [00:01<00:01, 53.01it/s, Epoch: 12, Batch: 86,Loss: -0.818,Avg.Loss: -0.369,LR: 4.84E-04]Training epoch 12:  56%|█████▌    | 86/153 [00:01<00:01, 53.01it/s, Epoch: 12, Batch: 87,Loss: -0.605,Avg.Loss: -0.371,LR: 4.84E-04]Training epoch 12:  57%|█████▋    | 87/153 [00:01<00:01, 53.01it/s, Epoch: 12, Batch: 88,Loss: -0.837,Avg.Loss: -0.377,LR: 4.84E-04]Training epoch 12:  58%|█████▊    | 88/153 [00:01<00:01, 53.01it/s, Epoch: 12, Batch: 89,Loss: -1.003,Avg.Loss: -0.384,LR: 4.84E-04]Training epoch 12:  58%|█████▊    | 89/153 [00:01<00:01, 53.01it/s, Epoch: 12, Batch: 90,Loss: -0.685,Avg.Loss: -0.387,LR: 4.84E-04]Training epoch 12:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 12, Batch: 90,Loss: -0.685,Avg.Loss: -0.387,LR: 4.84E-04]Training epoch 12:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 12, Batch: 91,Loss: -0.871,Avg.Loss: -0.392,LR: 4.84E-04]Training epoch 12:  59%|█████▉    | 91/153 [00:01<00:01, 53.06it/s, Epoch: 12, Batch: 92,Loss: -1.108,Avg.Loss: -0.400,LR: 4.84E-04]Training epoch 12:  60%|██████    | 92/153 [00:01<00:01, 53.06it/s, Epoch: 12, Batch: 93,Loss: -0.671,Avg.Loss: -0.403,LR: 4.84E-04]Training epoch 12:  61%|██████    | 93/153 [00:01<00:01, 53.06it/s, Epoch: 12, Batch: 94,Loss: -0.549,Avg.Loss: -0.404,LR: 4.84E-04]Training epoch 12:  61%|██████▏   | 94/153 [00:01<00:01, 53.06it/s, Epoch: 12, Batch: 95,Loss: -0.920,Avg.Loss: -0.410,LR: 4.84E-04]Training epoch 12:  62%|██████▏   | 95/153 [00:01<00:01, 53.06it/s, Epoch: 12, Batch: 96,Loss: -0.817,Avg.Loss: -0.414,LR: 4.84E-04]Training epoch 12:  63%|██████▎   | 96/153 [00:01<00:01, 53.16it/s, Epoch: 12, Batch: 96,Loss: -0.817,Avg.Loss: -0.414,LR: 4.84E-04]Training epoch 12:  63%|██████▎   | 96/153 [00:01<00:01, 53.16it/s, Epoch: 12, Batch: 97,Loss: -1.015,Avg.Loss: -0.420,LR: 4.83E-04]Training epoch 12:  63%|██████▎   | 97/153 [00:01<00:01, 53.16it/s, Epoch: 12, Batch: 98,Loss: -1.009,Avg.Loss: -0.426,LR: 4.83E-04]Training epoch 12:  64%|██████▍   | 98/153 [00:01<00:01, 53.16it/s, Epoch: 12, Batch: 99,Loss: -0.878,Avg.Loss: -0.431,LR: 4.83E-04]Training epoch 12:  65%|██████▍   | 99/153 [00:01<00:01, 53.16it/s, Epoch: 12, Batch: 100,Loss: -1.194,Avg.Loss: -0.439,LR: 4.83E-04]Training epoch 12:  65%|██████▌   | 100/153 [00:01<00:00, 53.16it/s, Epoch: 12, Batch: 101,Loss: -0.881,Avg.Loss: -0.443,LR: 4.83E-04]Training epoch 12:  66%|██████▌   | 101/153 [00:01<00:00, 53.16it/s, Epoch: 12, Batch: 102,Loss: -0.292,Avg.Loss: -0.441,LR: 4.83E-04]Training epoch 12:  67%|██████▋   | 102/153 [00:01<00:00, 52.94it/s, Epoch: 12, Batch: 102,Loss: -0.292,Avg.Loss: -0.441,LR: 4.83E-04]Training epoch 12:  67%|██████▋   | 102/153 [00:01<00:00, 52.94it/s, Epoch: 12, Batch: 103,Loss: -0.830,Avg.Loss: -0.445,LR: 4.83E-04]Training epoch 12:  67%|██████▋   | 103/153 [00:01<00:00, 52.94it/s, Epoch: 12, Batch: 104,Loss: -1.014,Avg.Loss: -0.451,LR: 4.83E-04]Training epoch 12:  68%|██████▊   | 104/153 [00:01<00:00, 52.94it/s, Epoch: 12, Batch: 105,Loss: -0.888,Avg.Loss: -0.455,LR: 4.83E-04]Training epoch 12:  69%|██████▊   | 105/153 [00:01<00:00, 52.94it/s, Epoch: 12, Batch: 106,Loss: -0.801,Avg.Loss: -0.458,LR: 4.83E-04]Training epoch 12:  69%|██████▉   | 106/153 [00:02<00:00, 52.94it/s, Epoch: 12, Batch: 107,Loss: -0.810,Avg.Loss: -0.461,LR: 4.83E-04]Training epoch 12:  70%|██████▉   | 107/153 [00:02<00:00, 52.94it/s, Epoch: 12, Batch: 108,Loss: -0.777,Avg.Loss: -0.464,LR: 4.83E-04]Training epoch 12:  71%|███████   | 108/153 [00:02<00:00, 53.13it/s, Epoch: 12, Batch: 108,Loss: -0.777,Avg.Loss: -0.464,LR: 4.83E-04]Training epoch 12:  71%|███████   | 108/153 [00:02<00:00, 53.13it/s, Epoch: 12, Batch: 109,Loss: -0.724,Avg.Loss: -0.467,LR: 4.83E-04]Training epoch 12:  71%|███████   | 109/153 [00:02<00:00, 53.13it/s, Epoch: 12, Batch: 110,Loss: -0.745,Avg.Loss: -0.469,LR: 4.83E-04]Training epoch 12:  72%|███████▏  | 110/153 [00:02<00:00, 53.13it/s, Epoch: 12, Batch: 111,Loss: -0.828,Avg.Loss: -0.472,LR: 4.83E-04]Training epoch 12:  73%|███████▎  | 111/153 [00:02<00:00, 53.13it/s, Epoch: 12, Batch: 112,Loss: -0.822,Avg.Loss: -0.476,LR: 4.83E-04]Training epoch 12:  73%|███████▎  | 112/153 [00:02<00:00, 53.13it/s, Epoch: 12, Batch: 113,Loss: -1.140,Avg.Loss: -0.481,LR: 4.83E-04]Training epoch 12:  74%|███████▍  | 113/153 [00:02<00:00, 53.13it/s, Epoch: 12, Batch: 114,Loss: -0.985,Avg.Loss: -0.486,LR: 4.83E-04]Training epoch 12:  75%|███████▍  | 114/153 [00:02<00:00, 53.28it/s, Epoch: 12, Batch: 114,Loss: -0.985,Avg.Loss: -0.486,LR: 4.83E-04]Training epoch 12:  75%|███████▍  | 114/153 [00:02<00:00, 53.28it/s, Epoch: 12, Batch: 115,Loss: -0.979,Avg.Loss: -0.490,LR: 4.83E-04]Training epoch 12:  75%|███████▌  | 115/153 [00:02<00:00, 53.28it/s, Epoch: 12, Batch: 116,Loss: -0.589,Avg.Loss: -0.491,LR: 4.83E-04]Training epoch 12:  76%|███████▌  | 116/153 [00:02<00:00, 53.28it/s, Epoch: 12, Batch: 117,Loss: -1.067,Avg.Loss: -0.496,LR: 4.83E-04]Training epoch 12:  76%|███████▋  | 117/153 [00:02<00:00, 53.28it/s, Epoch: 12, Batch: 118,Loss: -1.164,Avg.Loss: -0.502,LR: 4.83E-04]Training epoch 12:  77%|███████▋  | 118/153 [00:02<00:00, 53.28it/s, Epoch: 12, Batch: 119,Loss: -1.077,Avg.Loss: -0.506,LR: 4.83E-04]Training epoch 12:  78%|███████▊  | 119/153 [00:02<00:00, 53.28it/s, Epoch: 12, Batch: 120,Loss: -1.305,Avg.Loss: -0.513,LR: 4.83E-04]Training epoch 12:  78%|███████▊  | 120/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 120,Loss: -1.305,Avg.Loss: -0.513,LR: 4.83E-04]Training epoch 12:  78%|███████▊  | 120/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 121,Loss: -1.177,Avg.Loss: -0.519,LR: 4.83E-04]Training epoch 12:  79%|███████▉  | 121/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 122,Loss: -0.607,Avg.Loss: -0.519,LR: 4.83E-04]Training epoch 12:  80%|███████▉  | 122/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 123,Loss: -1.131,Avg.Loss: -0.524,LR: 4.83E-04]Training epoch 12:  80%|████████  | 123/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 124,Loss: 0.058,Avg.Loss: -0.520,LR: 4.83E-04] Training epoch 12:  81%|████████  | 124/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 125,Loss: -0.588,Avg.Loss: -0.520,LR: 4.83E-04]Training epoch 12:  82%|████████▏ | 125/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 126,Loss: -0.508,Avg.Loss: -0.520,LR: 4.83E-04]Training epoch 12:  82%|████████▏ | 126/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 126,Loss: -0.508,Avg.Loss: -0.520,LR: 4.83E-04]Training epoch 12:  82%|████████▏ | 126/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 127,Loss: -0.937,Avg.Loss: -0.523,LR: 4.83E-04]Training epoch 12:  83%|████████▎ | 127/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 128,Loss: -0.862,Avg.Loss: -0.526,LR: 4.83E-04]Training epoch 12:  84%|████████▎ | 128/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 129,Loss: -1.004,Avg.Loss: -0.530,LR: 4.83E-04]Training epoch 12:  84%|████████▍ | 129/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 130,Loss: -0.777,Avg.Loss: -0.532,LR: 4.83E-04]Training epoch 12:  85%|████████▍ | 130/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 131,Loss: -0.749,Avg.Loss: -0.533,LR: 4.83E-04]Training epoch 12:  86%|████████▌ | 131/153 [00:02<00:00, 53.39it/s, Epoch: 12, Batch: 132,Loss: -0.998,Avg.Loss: -0.537,LR: 4.83E-04]Training epoch 12:  86%|████████▋ | 132/153 [00:02<00:00, 53.31it/s, Epoch: 12, Batch: 132,Loss: -0.998,Avg.Loss: -0.537,LR: 4.83E-04]Training epoch 12:  86%|████████▋ | 132/153 [00:02<00:00, 53.31it/s, Epoch: 12, Batch: 133,Loss: -0.245,Avg.Loss: -0.535,LR: 4.83E-04]Training epoch 12:  87%|████████▋ | 133/153 [00:02<00:00, 53.31it/s, Epoch: 12, Batch: 134,Loss: -1.082,Avg.Loss: -0.539,LR: 4.83E-04]Training epoch 12:  88%|████████▊ | 134/153 [00:02<00:00, 53.31it/s, Epoch: 12, Batch: 135,Loss: -1.051,Avg.Loss: -0.542,LR: 4.83E-04]Training epoch 12:  88%|████████▊ | 135/153 [00:02<00:00, 53.31it/s, Epoch: 12, Batch: 136,Loss: -0.895,Avg.Loss: -0.545,LR: 4.83E-04]Training epoch 12:  89%|████████▉ | 136/153 [00:02<00:00, 53.31it/s, Epoch: 12, Batch: 137,Loss: -1.305,Avg.Loss: -0.551,LR: 4.83E-04]Training epoch 12:  90%|████████▉ | 137/153 [00:02<00:00, 53.31it/s, Epoch: 12, Batch: 138,Loss: -1.103,Avg.Loss: -0.555,LR: 4.83E-04]Training epoch 12:  90%|█████████ | 138/153 [00:02<00:00, 53.57it/s, Epoch: 12, Batch: 138,Loss: -1.103,Avg.Loss: -0.555,LR: 4.83E-04]Training epoch 12:  90%|█████████ | 138/153 [00:02<00:00, 53.57it/s, Epoch: 12, Batch: 139,Loss: -0.701,Avg.Loss: -0.556,LR: 4.83E-04]Training epoch 12:  91%|█████████ | 139/153 [00:02<00:00, 53.57it/s, Epoch: 12, Batch: 140,Loss: -0.695,Avg.Loss: -0.557,LR: 4.83E-04]Training epoch 12:  92%|█████████▏| 140/153 [00:02<00:00, 53.57it/s, Epoch: 12, Batch: 141,Loss: -0.444,Avg.Loss: -0.556,LR: 4.83E-04]Training epoch 12:  92%|█████████▏| 141/153 [00:02<00:00, 53.57it/s, Epoch: 12, Batch: 142,Loss: -0.856,Avg.Loss: -0.558,LR: 4.83E-04]Training epoch 12:  93%|█████████▎| 142/153 [00:02<00:00, 53.57it/s, Epoch: 12, Batch: 143,Loss: -1.212,Avg.Loss: -0.563,LR: 4.83E-04]Training epoch 12:  93%|█████████▎| 143/153 [00:02<00:00, 53.57it/s, Epoch: 12, Batch: 144,Loss: -0.911,Avg.Loss: -0.565,LR: 4.83E-04]Training epoch 12:  94%|█████████▍| 144/153 [00:02<00:00, 53.62it/s, Epoch: 12, Batch: 144,Loss: -0.911,Avg.Loss: -0.565,LR: 4.83E-04]Training epoch 12:  94%|█████████▍| 144/153 [00:02<00:00, 53.62it/s, Epoch: 12, Batch: 145,Loss: -0.817,Avg.Loss: -0.567,LR: 4.83E-04]Training epoch 12:  95%|█████████▍| 145/153 [00:02<00:00, 53.62it/s, Epoch: 12, Batch: 146,Loss: -1.065,Avg.Loss: -0.570,LR: 4.83E-04]Training epoch 12:  95%|█████████▌| 146/153 [00:02<00:00, 53.62it/s, Epoch: 12, Batch: 147,Loss: -0.703,Avg.Loss: -0.571,LR: 4.83E-04]Training epoch 12:  96%|█████████▌| 147/153 [00:02<00:00, 53.62it/s, Epoch: 12, Batch: 148,Loss: -1.141,Avg.Loss: -0.575,LR: 4.83E-04]Training epoch 12:  97%|█████████▋| 148/153 [00:02<00:00, 53.62it/s, Epoch: 12, Batch: 149,Loss: -1.210,Avg.Loss: -0.579,LR: 4.83E-04]Training epoch 12:  97%|█████████▋| 149/153 [00:02<00:00, 53.62it/s, Epoch: 12, Batch: 150,Loss: -0.946,Avg.Loss: -0.582,LR: 4.83E-04]Training epoch 12:  98%|█████████▊| 150/153 [00:02<00:00, 53.49it/s, Epoch: 12, Batch: 150,Loss: -0.946,Avg.Loss: -0.582,LR: 4.83E-04]Training epoch 12:  98%|█████████▊| 150/153 [00:02<00:00, 53.49it/s, Epoch: 12, Batch: 151,Loss: -0.464,Avg.Loss: -0.581,LR: 4.82E-04]Training epoch 12:  99%|█████████▊| 151/153 [00:02<00:00, 53.49it/s, Epoch: 12, Batch: 152,Loss: -0.927,Avg.Loss: -0.583,LR: 4.82E-04]Training epoch 12:  99%|█████████▉| 152/153 [00:02<00:00, 53.49it/s, Epoch: 12, Batch: 153,Loss: -0.919,Avg.Loss: -0.585,LR: 4.82E-04]Training epoch 12: 100%|██████████| 153/153 [00:02<00:00, 53.15it/s, Epoch: 12, Batch: 153,Loss: -0.919,Avg.Loss: -0.585,LR: 4.82E-04]
Training epoch 13:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 13:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 13, Batch: 1,Loss: -0.992,Avg.Loss: -0.992,LR: 4.82E-04]Training epoch 13:   1%|          | 1/153 [00:00<00:04, 30.43it/s, Epoch: 13, Batch: 2,Loss: -0.964,Avg.Loss: -0.978,LR: 4.82E-04]Training epoch 13:   1%|▏         | 2/153 [00:00<00:03, 42.37it/s, Epoch: 13, Batch: 3,Loss: -0.729,Avg.Loss: -0.895,LR: 4.82E-04]Training epoch 13:   2%|▏         | 3/153 [00:00<00:03, 46.96it/s, Epoch: 13, Batch: 4,Loss: -0.498,Avg.Loss: -0.796,LR: 4.82E-04]Training epoch 13:   3%|▎         | 4/153 [00:00<00:03, 48.86it/s, Epoch: 13, Batch: 5,Loss: -0.185,Avg.Loss: -0.674,LR: 4.82E-04]Training epoch 13:   3%|▎         | 5/153 [00:00<00:02, 49.48it/s, Epoch: 13, Batch: 6,Loss: -0.099,Avg.Loss: -0.578,LR: 4.82E-04]Training epoch 13:   4%|▍         | 6/153 [00:00<00:02, 59.26it/s, Epoch: 13, Batch: 6,Loss: -0.099,Avg.Loss: -0.578,LR: 4.82E-04]Training epoch 13:   4%|▍         | 6/153 [00:00<00:02, 59.26it/s, Epoch: 13, Batch: 7,Loss: -0.892,Avg.Loss: -0.623,LR: 4.82E-04]Training epoch 13:   5%|▍         | 7/153 [00:00<00:02, 59.26it/s, Epoch: 13, Batch: 8,Loss: -0.805,Avg.Loss: -0.646,LR: 4.82E-04]Training epoch 13:   5%|▌         | 8/153 [00:00<00:02, 59.26it/s, Epoch: 13, Batch: 9,Loss: -0.648,Avg.Loss: -0.646,LR: 4.82E-04]Training epoch 13:   6%|▌         | 9/153 [00:00<00:02, 59.26it/s, Epoch: 13, Batch: 10,Loss: -0.866,Avg.Loss: -0.668,LR: 4.82E-04]Training epoch 13:   7%|▋         | 10/153 [00:00<00:02, 59.26it/s, Epoch: 13, Batch: 11,Loss: -1.183,Avg.Loss: -0.715,LR: 4.82E-04]Training epoch 13:   7%|▋         | 11/153 [00:00<00:02, 59.26it/s, Epoch: 13, Batch: 12,Loss: -0.486,Avg.Loss: -0.696,LR: 4.82E-04]Training epoch 13:   8%|▊         | 12/153 [00:00<00:02, 55.63it/s, Epoch: 13, Batch: 12,Loss: -0.486,Avg.Loss: -0.696,LR: 4.82E-04]Training epoch 13:   8%|▊         | 12/153 [00:00<00:02, 55.63it/s, Epoch: 13, Batch: 13,Loss: -0.974,Avg.Loss: -0.717,LR: 4.82E-04]Training epoch 13:   8%|▊         | 13/153 [00:00<00:02, 55.63it/s, Epoch: 13, Batch: 14,Loss: -0.437,Avg.Loss: -0.697,LR: 4.82E-04]Training epoch 13:   9%|▉         | 14/153 [00:00<00:02, 55.63it/s, Epoch: 13, Batch: 15,Loss: 0.122,Avg.Loss: -0.642,LR: 4.82E-04] Training epoch 13:  10%|▉         | 15/153 [00:00<00:02, 55.63it/s, Epoch: 13, Batch: 16,Loss: -0.890,Avg.Loss: -0.658,LR: 4.82E-04]Training epoch 13:  10%|█         | 16/153 [00:00<00:02, 55.63it/s, Epoch: 13, Batch: 17,Loss: -1.180,Avg.Loss: -0.689,LR: 4.82E-04]Training epoch 13:  11%|█         | 17/153 [00:00<00:02, 55.63it/s, Epoch: 13, Batch: 18,Loss: -0.897,Avg.Loss: -0.700,LR: 4.82E-04]Training epoch 13:  12%|█▏        | 18/153 [00:00<00:02, 54.27it/s, Epoch: 13, Batch: 18,Loss: -0.897,Avg.Loss: -0.700,LR: 4.82E-04]Training epoch 13:  12%|█▏        | 18/153 [00:00<00:02, 54.27it/s, Epoch: 13, Batch: 19,Loss: -1.075,Avg.Loss: -0.720,LR: 4.82E-04]Training epoch 13:  12%|█▏        | 19/153 [00:00<00:02, 54.27it/s, Epoch: 13, Batch: 20,Loss: -1.127,Avg.Loss: -0.740,LR: 4.82E-04]Training epoch 13:  13%|█▎        | 20/153 [00:00<00:02, 54.27it/s, Epoch: 13, Batch: 21,Loss: -0.770,Avg.Loss: -0.742,LR: 4.82E-04]Training epoch 13:  14%|█▎        | 21/153 [00:00<00:02, 54.27it/s, Epoch: 13, Batch: 22,Loss: -0.780,Avg.Loss: -0.743,LR: 4.82E-04]Training epoch 13:  14%|█▍        | 22/153 [00:00<00:02, 54.27it/s, Epoch: 13, Batch: 23,Loss: -1.058,Avg.Loss: -0.757,LR: 4.82E-04]Training epoch 13:  15%|█▌        | 23/153 [00:00<00:02, 54.27it/s, Epoch: 13, Batch: 24,Loss: -0.893,Avg.Loss: -0.763,LR: 4.82E-04]Training epoch 13:  16%|█▌        | 24/153 [00:00<00:02, 53.47it/s, Epoch: 13, Batch: 24,Loss: -0.893,Avg.Loss: -0.763,LR: 4.82E-04]Training epoch 13:  16%|█▌        | 24/153 [00:00<00:02, 53.47it/s, Epoch: 13, Batch: 25,Loss: -1.304,Avg.Loss: -0.784,LR: 4.82E-04]Training epoch 13:  16%|█▋        | 25/153 [00:00<00:02, 53.47it/s, Epoch: 13, Batch: 26,Loss: -0.978,Avg.Loss: -0.792,LR: 4.82E-04]Training epoch 13:  17%|█▋        | 26/153 [00:00<00:02, 53.47it/s, Epoch: 13, Batch: 27,Loss: -1.026,Avg.Loss: -0.801,LR: 4.82E-04]Training epoch 13:  18%|█▊        | 27/153 [00:00<00:02, 53.47it/s, Epoch: 13, Batch: 28,Loss: -0.819,Avg.Loss: -0.801,LR: 4.82E-04]Training epoch 13:  18%|█▊        | 28/153 [00:00<00:02, 53.47it/s, Epoch: 13, Batch: 29,Loss: -0.983,Avg.Loss: -0.808,LR: 4.82E-04]Training epoch 13:  19%|█▉        | 29/153 [00:00<00:02, 53.47it/s, Epoch: 13, Batch: 30,Loss: -1.273,Avg.Loss: -0.823,LR: 4.82E-04]Training epoch 13:  20%|█▉        | 30/153 [00:00<00:02, 52.93it/s, Epoch: 13, Batch: 30,Loss: -1.273,Avg.Loss: -0.823,LR: 4.82E-04]Training epoch 13:  20%|█▉        | 30/153 [00:00<00:02, 52.93it/s, Epoch: 13, Batch: 31,Loss: -0.486,Avg.Loss: -0.812,LR: 4.82E-04]Training epoch 13:  20%|██        | 31/153 [00:00<00:02, 52.93it/s, Epoch: 13, Batch: 32,Loss: -1.038,Avg.Loss: -0.819,LR: 4.82E-04]Training epoch 13:  21%|██        | 32/153 [00:00<00:02, 52.93it/s, Epoch: 13, Batch: 33,Loss: -1.051,Avg.Loss: -0.826,LR: 4.82E-04]Training epoch 13:  22%|██▏       | 33/153 [00:00<00:02, 52.93it/s, Epoch: 13, Batch: 34,Loss: -0.660,Avg.Loss: -0.821,LR: 4.82E-04]Training epoch 13:  22%|██▏       | 34/153 [00:00<00:02, 52.93it/s, Epoch: 13, Batch: 35,Loss: -0.274,Avg.Loss: -0.806,LR: 4.82E-04]Training epoch 13:  23%|██▎       | 35/153 [00:00<00:02, 52.93it/s, Epoch: 13, Batch: 36,Loss: 0.589,Avg.Loss: -0.767,LR: 4.82E-04] Training epoch 13:  24%|██▎       | 36/153 [00:00<00:02, 52.83it/s, Epoch: 13, Batch: 36,Loss: 0.589,Avg.Loss: -0.767,LR: 4.82E-04]Training epoch 13:  24%|██▎       | 36/153 [00:00<00:02, 52.83it/s, Epoch: 13, Batch: 37,Loss: 0.214,Avg.Loss: -0.740,LR: 4.82E-04]Training epoch 13:  24%|██▍       | 37/153 [00:00<00:02, 52.83it/s, Epoch: 13, Batch: 38,Loss: -0.142,Avg.Loss: -0.725,LR: 4.82E-04]Training epoch 13:  25%|██▍       | 38/153 [00:00<00:02, 52.83it/s, Epoch: 13, Batch: 39,Loss: -0.408,Avg.Loss: -0.717,LR: 4.82E-04]Training epoch 13:  25%|██▌       | 39/153 [00:00<00:02, 52.83it/s, Epoch: 13, Batch: 40,Loss: 0.017,Avg.Loss: -0.698,LR: 4.82E-04] Training epoch 13:  26%|██▌       | 40/153 [00:00<00:02, 52.83it/s, Epoch: 13, Batch: 41,Loss: -0.464,Avg.Loss: -0.693,LR: 4.82E-04]Training epoch 13:  27%|██▋       | 41/153 [00:00<00:02, 52.83it/s, Epoch: 13, Batch: 42,Loss: -0.533,Avg.Loss: -0.689,LR: 4.82E-04]Training epoch 13:  27%|██▋       | 42/153 [00:00<00:02, 52.90it/s, Epoch: 13, Batch: 42,Loss: -0.533,Avg.Loss: -0.689,LR: 4.82E-04]Training epoch 13:  27%|██▋       | 42/153 [00:00<00:02, 52.90it/s, Epoch: 13, Batch: 43,Loss: -0.717,Avg.Loss: -0.689,LR: 4.82E-04]Training epoch 13:  28%|██▊       | 43/153 [00:00<00:02, 52.90it/s, Epoch: 13, Batch: 44,Loss: -1.227,Avg.Loss: -0.702,LR: 4.82E-04]Training epoch 13:  29%|██▉       | 44/153 [00:00<00:02, 52.90it/s, Epoch: 13, Batch: 45,Loss: -0.190,Avg.Loss: -0.690,LR: 4.82E-04]Training epoch 13:  29%|██▉       | 45/153 [00:00<00:02, 52.90it/s, Epoch: 13, Batch: 46,Loss: -0.364,Avg.Loss: -0.683,LR: 4.82E-04]Training epoch 13:  30%|███       | 46/153 [00:00<00:02, 52.90it/s, Epoch: 13, Batch: 47,Loss: -0.654,Avg.Loss: -0.683,LR: 4.82E-04]Training epoch 13:  31%|███       | 47/153 [00:00<00:02, 52.90it/s, Epoch: 13, Batch: 48,Loss: -0.682,Avg.Loss: -0.683,LR: 4.82E-04]Training epoch 13:  31%|███▏      | 48/153 [00:00<00:01, 52.90it/s, Epoch: 13, Batch: 48,Loss: -0.682,Avg.Loss: -0.683,LR: 4.82E-04]Training epoch 13:  31%|███▏      | 48/153 [00:00<00:01, 52.90it/s, Epoch: 13, Batch: 49,Loss: -0.729,Avg.Loss: -0.684,LR: 4.82E-04]Training epoch 13:  32%|███▏      | 49/153 [00:00<00:01, 52.90it/s, Epoch: 13, Batch: 50,Loss: -1.113,Avg.Loss: -0.692,LR: 4.81E-04]Training epoch 13:  33%|███▎      | 50/153 [00:00<00:01, 52.90it/s, Epoch: 13, Batch: 51,Loss: -0.753,Avg.Loss: -0.693,LR: 4.81E-04]Training epoch 13:  33%|███▎      | 51/153 [00:00<00:01, 52.90it/s, Epoch: 13, Batch: 52,Loss: -0.865,Avg.Loss: -0.697,LR: 4.81E-04]Training epoch 13:  34%|███▍      | 52/153 [00:00<00:01, 52.90it/s, Epoch: 13, Batch: 53,Loss: -1.292,Avg.Loss: -0.708,LR: 4.81E-04]Training epoch 13:  35%|███▍      | 53/153 [00:01<00:01, 52.90it/s, Epoch: 13, Batch: 54,Loss: -1.073,Avg.Loss: -0.715,LR: 4.81E-04]Training epoch 13:  35%|███▌      | 54/153 [00:01<00:01, 52.95it/s, Epoch: 13, Batch: 54,Loss: -1.073,Avg.Loss: -0.715,LR: 4.81E-04]Training epoch 13:  35%|███▌      | 54/153 [00:01<00:01, 52.95it/s, Epoch: 13, Batch: 55,Loss: -0.742,Avg.Loss: -0.715,LR: 4.81E-04]Training epoch 13:  36%|███▌      | 55/153 [00:01<00:01, 52.95it/s, Epoch: 13, Batch: 56,Loss: -1.013,Avg.Loss: -0.720,LR: 4.81E-04]Training epoch 13:  37%|███▋      | 56/153 [00:01<00:01, 52.95it/s, Epoch: 13, Batch: 57,Loss: -1.143,Avg.Loss: -0.728,LR: 4.81E-04]Training epoch 13:  37%|███▋      | 57/153 [00:01<00:01, 52.95it/s, Epoch: 13, Batch: 58,Loss: -0.556,Avg.Loss: -0.725,LR: 4.81E-04]Training epoch 13:  38%|███▊      | 58/153 [00:01<00:01, 52.95it/s, Epoch: 13, Batch: 59,Loss: -1.207,Avg.Loss: -0.733,LR: 4.81E-04]Training epoch 13:  39%|███▊      | 59/153 [00:01<00:01, 52.95it/s, Epoch: 13, Batch: 60,Loss: -1.235,Avg.Loss: -0.741,LR: 4.81E-04]Training epoch 13:  39%|███▉      | 60/153 [00:01<00:01, 52.84it/s, Epoch: 13, Batch: 60,Loss: -1.235,Avg.Loss: -0.741,LR: 4.81E-04]Training epoch 13:  39%|███▉      | 60/153 [00:01<00:01, 52.84it/s, Epoch: 13, Batch: 61,Loss: -1.057,Avg.Loss: -0.747,LR: 4.81E-04]Training epoch 13:  40%|███▉      | 61/153 [00:01<00:01, 52.84it/s, Epoch: 13, Batch: 62,Loss: -1.345,Avg.Loss: -0.756,LR: 4.81E-04]Training epoch 13:  41%|████      | 62/153 [00:01<00:01, 52.84it/s, Epoch: 13, Batch: 63,Loss: -1.070,Avg.Loss: -0.761,LR: 4.81E-04]Training epoch 13:  41%|████      | 63/153 [00:01<00:01, 52.84it/s, Epoch: 13, Batch: 64,Loss: -1.192,Avg.Loss: -0.768,LR: 4.81E-04]Training epoch 13:  42%|████▏     | 64/153 [00:01<00:01, 52.84it/s, Epoch: 13, Batch: 65,Loss: -1.210,Avg.Loss: -0.775,LR: 4.81E-04]Training epoch 13:  42%|████▏     | 65/153 [00:01<00:01, 52.84it/s, Epoch: 13, Batch: 66,Loss: -1.300,Avg.Loss: -0.783,LR: 4.81E-04]Training epoch 13:  43%|████▎     | 66/153 [00:01<00:01, 52.80it/s, Epoch: 13, Batch: 66,Loss: -1.300,Avg.Loss: -0.783,LR: 4.81E-04]Training epoch 13:  43%|████▎     | 66/153 [00:01<00:01, 52.80it/s, Epoch: 13, Batch: 67,Loss: -1.102,Avg.Loss: -0.787,LR: 4.81E-04]Training epoch 13:  44%|████▍     | 67/153 [00:01<00:01, 52.80it/s, Epoch: 13, Batch: 68,Loss: -0.942,Avg.Loss: -0.790,LR: 4.81E-04]Training epoch 13:  44%|████▍     | 68/153 [00:01<00:01, 52.80it/s, Epoch: 13, Batch: 69,Loss: -1.207,Avg.Loss: -0.796,LR: 4.81E-04]Training epoch 13:  45%|████▌     | 69/153 [00:01<00:01, 52.80it/s, Epoch: 13, Batch: 70,Loss: -0.811,Avg.Loss: -0.796,LR: 4.81E-04]Training epoch 13:  46%|████▌     | 70/153 [00:01<00:01, 52.80it/s, Epoch: 13, Batch: 71,Loss: -0.669,Avg.Loss: -0.794,LR: 4.81E-04]Training epoch 13:  46%|████▋     | 71/153 [00:01<00:01, 52.80it/s, Epoch: 13, Batch: 72,Loss: -0.818,Avg.Loss: -0.795,LR: 4.81E-04]Training epoch 13:  47%|████▋     | 72/153 [00:01<00:01, 52.87it/s, Epoch: 13, Batch: 72,Loss: -0.818,Avg.Loss: -0.795,LR: 4.81E-04]Training epoch 13:  47%|████▋     | 72/153 [00:01<00:01, 52.87it/s, Epoch: 13, Batch: 73,Loss: -0.969,Avg.Loss: -0.797,LR: 4.81E-04]Training epoch 13:  48%|████▊     | 73/153 [00:01<00:01, 52.87it/s, Epoch: 13, Batch: 74,Loss: -0.906,Avg.Loss: -0.798,LR: 4.81E-04]Training epoch 13:  48%|████▊     | 74/153 [00:01<00:01, 52.87it/s, Epoch: 13, Batch: 75,Loss: -1.069,Avg.Loss: -0.802,LR: 4.81E-04]Training epoch 13:  49%|████▉     | 75/153 [00:01<00:01, 52.87it/s, Epoch: 13, Batch: 76,Loss: -0.855,Avg.Loss: -0.803,LR: 4.81E-04]Training epoch 13:  50%|████▉     | 76/153 [00:01<00:01, 52.87it/s, Epoch: 13, Batch: 77,Loss: -1.112,Avg.Loss: -0.807,LR: 4.81E-04]Training epoch 13:  50%|█████     | 77/153 [00:01<00:01, 52.87it/s, Epoch: 13, Batch: 78,Loss: -1.144,Avg.Loss: -0.811,LR: 4.81E-04]Training epoch 13:  51%|█████     | 78/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 78,Loss: -1.144,Avg.Loss: -0.811,LR: 4.81E-04]Training epoch 13:  51%|█████     | 78/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 79,Loss: -1.096,Avg.Loss: -0.815,LR: 4.81E-04]Training epoch 13:  52%|█████▏    | 79/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 80,Loss: -1.127,Avg.Loss: -0.819,LR: 4.81E-04]Training epoch 13:  52%|█████▏    | 80/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 81,Loss: -0.967,Avg.Loss: -0.820,LR: 4.81E-04]Training epoch 13:  53%|█████▎    | 81/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 82,Loss: -0.250,Avg.Loss: -0.813,LR: 4.81E-04]Training epoch 13:  54%|█████▎    | 82/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 83,Loss: -0.731,Avg.Loss: -0.812,LR: 4.81E-04]Training epoch 13:  54%|█████▍    | 83/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 84,Loss: -1.202,Avg.Loss: -0.817,LR: 4.81E-04]Training epoch 13:  55%|█████▍    | 84/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 84,Loss: -1.202,Avg.Loss: -0.817,LR: 4.81E-04]Training epoch 13:  55%|█████▍    | 84/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 85,Loss: -1.369,Avg.Loss: -0.824,LR: 4.81E-04]Training epoch 13:  56%|█████▌    | 85/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 86,Loss: -1.478,Avg.Loss: -0.831,LR: 4.81E-04]Training epoch 13:  56%|█████▌    | 86/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 87,Loss: -1.257,Avg.Loss: -0.836,LR: 4.81E-04]Training epoch 13:  57%|█████▋    | 87/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 88,Loss: -1.134,Avg.Loss: -0.839,LR: 4.81E-04]Training epoch 13:  58%|█████▊    | 88/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 89,Loss: -0.933,Avg.Loss: -0.841,LR: 4.81E-04]Training epoch 13:  58%|█████▊    | 89/153 [00:01<00:01, 53.00it/s, Epoch: 13, Batch: 90,Loss: -0.778,Avg.Loss: -0.840,LR: 4.81E-04]Training epoch 13:  59%|█████▉    | 90/153 [00:01<00:01, 53.10it/s, Epoch: 13, Batch: 90,Loss: -0.778,Avg.Loss: -0.840,LR: 4.81E-04]Training epoch 13:  59%|█████▉    | 90/153 [00:01<00:01, 53.10it/s, Epoch: 13, Batch: 91,Loss: -0.914,Avg.Loss: -0.841,LR: 4.81E-04]Training epoch 13:  59%|█████▉    | 91/153 [00:01<00:01, 53.10it/s, Epoch: 13, Batch: 92,Loss: -1.144,Avg.Loss: -0.844,LR: 4.81E-04]Training epoch 13:  60%|██████    | 92/153 [00:01<00:01, 53.10it/s, Epoch: 13, Batch: 93,Loss: -1.457,Avg.Loss: -0.851,LR: 4.81E-04]Training epoch 13:  61%|██████    | 93/153 [00:01<00:01, 53.10it/s, Epoch: 13, Batch: 94,Loss: -1.141,Avg.Loss: -0.854,LR: 4.81E-04]Training epoch 13:  61%|██████▏   | 94/153 [00:01<00:01, 53.10it/s, Epoch: 13, Batch: 95,Loss: -1.374,Avg.Loss: -0.859,LR: 4.81E-04]Training epoch 13:  62%|██████▏   | 95/153 [00:01<00:01, 53.10it/s, Epoch: 13, Batch: 96,Loss: -0.912,Avg.Loss: -0.860,LR: 4.81E-04]Training epoch 13:  63%|██████▎   | 96/153 [00:01<00:01, 53.02it/s, Epoch: 13, Batch: 96,Loss: -0.912,Avg.Loss: -0.860,LR: 4.81E-04]Training epoch 13:  63%|██████▎   | 96/153 [00:01<00:01, 53.02it/s, Epoch: 13, Batch: 97,Loss: -0.539,Avg.Loss: -0.856,LR: 4.81E-04]Training epoch 13:  63%|██████▎   | 97/153 [00:01<00:01, 53.02it/s, Epoch: 13, Batch: 98,Loss: -0.115,Avg.Loss: -0.849,LR: 4.81E-04]Training epoch 13:  64%|██████▍   | 98/153 [00:01<00:01, 53.02it/s, Epoch: 13, Batch: 99,Loss: -0.388,Avg.Loss: -0.844,LR: 4.81E-04]Training epoch 13:  65%|██████▍   | 99/153 [00:01<00:01, 53.02it/s, Epoch: 13, Batch: 100,Loss: -1.282,Avg.Loss: -0.849,LR: 4.81E-04]Training epoch 13:  65%|██████▌   | 100/153 [00:01<00:00, 53.02it/s, Epoch: 13, Batch: 101,Loss: -0.483,Avg.Loss: -0.845,LR: 4.80E-04]Training epoch 13:  66%|██████▌   | 101/153 [00:01<00:00, 53.02it/s, Epoch: 13, Batch: 102,Loss: 0.575,Avg.Loss: -0.831,LR: 4.80E-04] Training epoch 13:  67%|██████▋   | 102/153 [00:01<00:00, 52.68it/s, Epoch: 13, Batch: 102,Loss: 0.575,Avg.Loss: -0.831,LR: 4.80E-04]Training epoch 13:  67%|██████▋   | 102/153 [00:01<00:00, 52.68it/s, Epoch: 13, Batch: 103,Loss: 0.597,Avg.Loss: -0.817,LR: 4.80E-04]Training epoch 13:  67%|██████▋   | 103/153 [00:01<00:00, 52.68it/s, Epoch: 13, Batch: 104,Loss: -0.300,Avg.Loss: -0.812,LR: 4.80E-04]Training epoch 13:  68%|██████▊   | 104/153 [00:01<00:00, 52.68it/s, Epoch: 13, Batch: 105,Loss: -0.981,Avg.Loss: -0.814,LR: 4.80E-04]Training epoch 13:  69%|██████▊   | 105/153 [00:01<00:00, 52.68it/s, Epoch: 13, Batch: 106,Loss: -0.866,Avg.Loss: -0.814,LR: 4.80E-04]Training epoch 13:  69%|██████▉   | 106/153 [00:02<00:00, 52.68it/s, Epoch: 13, Batch: 107,Loss: -0.112,Avg.Loss: -0.808,LR: 4.80E-04]Training epoch 13:  70%|██████▉   | 107/153 [00:02<00:00, 52.68it/s, Epoch: 13, Batch: 108,Loss: -0.441,Avg.Loss: -0.804,LR: 4.80E-04]Training epoch 13:  71%|███████   | 108/153 [00:02<00:00, 53.01it/s, Epoch: 13, Batch: 108,Loss: -0.441,Avg.Loss: -0.804,LR: 4.80E-04]Training epoch 13:  71%|███████   | 108/153 [00:02<00:00, 53.01it/s, Epoch: 13, Batch: 109,Loss: -0.728,Avg.Loss: -0.804,LR: 4.80E-04]Training epoch 13:  71%|███████   | 109/153 [00:02<00:00, 53.01it/s, Epoch: 13, Batch: 110,Loss: -0.322,Avg.Loss: -0.799,LR: 4.80E-04]Training epoch 13:  72%|███████▏  | 110/153 [00:02<00:00, 53.01it/s, Epoch: 13, Batch: 111,Loss: 0.470,Avg.Loss: -0.788,LR: 4.80E-04] Training epoch 13:  73%|███████▎  | 111/153 [00:02<00:00, 53.01it/s, Epoch: 13, Batch: 112,Loss: 0.913,Avg.Loss: -0.773,LR: 4.80E-04]Training epoch 13:  73%|███████▎  | 112/153 [00:02<00:00, 53.01it/s, Epoch: 13, Batch: 113,Loss: -0.157,Avg.Loss: -0.767,LR: 4.80E-04]Training epoch 13:  74%|███████▍  | 113/153 [00:02<00:00, 53.01it/s, Epoch: 13, Batch: 114,Loss: -1.260,Avg.Loss: -0.771,LR: 4.80E-04]Training epoch 13:  75%|███████▍  | 114/153 [00:02<00:00, 52.71it/s, Epoch: 13, Batch: 114,Loss: -1.260,Avg.Loss: -0.771,LR: 4.80E-04]Training epoch 13:  75%|███████▍  | 114/153 [00:02<00:00, 52.71it/s, Epoch: 13, Batch: 115,Loss: -0.729,Avg.Loss: -0.771,LR: 4.80E-04]Training epoch 13:  75%|███████▌  | 115/153 [00:02<00:00, 52.71it/s, Epoch: 13, Batch: 116,Loss: 0.478,Avg.Loss: -0.760,LR: 4.80E-04] Training epoch 13:  76%|███████▌  | 116/153 [00:02<00:00, 52.71it/s, Epoch: 13, Batch: 117,Loss: 0.700,Avg.Loss: -0.748,LR: 4.80E-04]Training epoch 13:  76%|███████▋  | 117/153 [00:02<00:00, 52.71it/s, Epoch: 13, Batch: 118,Loss: -0.252,Avg.Loss: -0.744,LR: 4.80E-04]Training epoch 13:  77%|███████▋  | 118/153 [00:02<00:00, 52.71it/s, Epoch: 13, Batch: 119,Loss: -1.264,Avg.Loss: -0.748,LR: 4.80E-04]Training epoch 13:  78%|███████▊  | 119/153 [00:02<00:00, 52.71it/s, Epoch: 13, Batch: 120,Loss: -0.897,Avg.Loss: -0.749,LR: 4.80E-04]Training epoch 13:  78%|███████▊  | 120/153 [00:02<00:00, 53.05it/s, Epoch: 13, Batch: 120,Loss: -0.897,Avg.Loss: -0.749,LR: 4.80E-04]Training epoch 13:  78%|███████▊  | 120/153 [00:02<00:00, 53.05it/s, Epoch: 13, Batch: 121,Loss: -0.337,Avg.Loss: -0.746,LR: 4.80E-04]Training epoch 13:  79%|███████▉  | 121/153 [00:02<00:00, 53.05it/s, Epoch: 13, Batch: 122,Loss: 0.202,Avg.Loss: -0.738,LR: 4.80E-04] Training epoch 13:  80%|███████▉  | 122/153 [00:02<00:00, 53.05it/s, Epoch: 13, Batch: 123,Loss: -0.235,Avg.Loss: -0.734,LR: 4.80E-04]Training epoch 13:  80%|████████  | 123/153 [00:02<00:00, 53.05it/s, Epoch: 13, Batch: 124,Loss: -1.199,Avg.Loss: -0.738,LR: 4.80E-04]Training epoch 13:  81%|████████  | 124/153 [00:02<00:00, 53.05it/s, Epoch: 13, Batch: 125,Loss: -0.397,Avg.Loss: -0.735,LR: 4.80E-04]Training epoch 13:  82%|████████▏ | 125/153 [00:02<00:00, 53.05it/s, Epoch: 13, Batch: 126,Loss: 0.611,Avg.Loss: -0.724,LR: 4.80E-04] Training epoch 13:  82%|████████▏ | 126/153 [00:02<00:00, 53.39it/s, Epoch: 13, Batch: 126,Loss: 0.611,Avg.Loss: -0.724,LR: 4.80E-04]Training epoch 13:  82%|████████▏ | 126/153 [00:02<00:00, 53.39it/s, Epoch: 13, Batch: 127,Loss: 0.102,Avg.Loss: -0.718,LR: 4.80E-04]Training epoch 13:  83%|████████▎ | 127/153 [00:02<00:00, 53.39it/s, Epoch: 13, Batch: 128,Loss: -0.537,Avg.Loss: -0.716,LR: 4.80E-04]Training epoch 13:  84%|████████▎ | 128/153 [00:02<00:00, 53.39it/s, Epoch: 13, Batch: 129,Loss: -0.988,Avg.Loss: -0.719,LR: 4.80E-04]Training epoch 13:  84%|████████▍ | 129/153 [00:02<00:00, 53.39it/s, Epoch: 13, Batch: 130,Loss: -0.822,Avg.Loss: -0.719,LR: 4.80E-04]Training epoch 13:  85%|████████▍ | 130/153 [00:02<00:00, 53.39it/s, Epoch: 13, Batch: 131,Loss: -0.104,Avg.Loss: -0.715,LR: 4.80E-04]Training epoch 13:  86%|████████▌ | 131/153 [00:02<00:00, 53.39it/s, Epoch: 13, Batch: 132,Loss: 0.064,Avg.Loss: -0.709,LR: 4.80E-04] Training epoch 13:  86%|████████▋ | 132/153 [00:02<00:00, 53.66it/s, Epoch: 13, Batch: 132,Loss: 0.064,Avg.Loss: -0.709,LR: 4.80E-04]Training epoch 13:  86%|████████▋ | 132/153 [00:02<00:00, 53.66it/s, Epoch: 13, Batch: 133,Loss: -0.447,Avg.Loss: -0.707,LR: 4.80E-04]Training epoch 13:  87%|████████▋ | 133/153 [00:02<00:00, 53.66it/s, Epoch: 13, Batch: 134,Loss: -1.231,Avg.Loss: -0.711,LR: 4.80E-04]Training epoch 13:  88%|████████▊ | 134/153 [00:02<00:00, 53.66it/s, Epoch: 13, Batch: 135,Loss: -0.992,Avg.Loss: -0.713,LR: 4.80E-04]Training epoch 13:  88%|████████▊ | 135/153 [00:02<00:00, 53.66it/s, Epoch: 13, Batch: 136,Loss: -0.177,Avg.Loss: -0.709,LR: 4.80E-04]Training epoch 13:  89%|████████▉ | 136/153 [00:02<00:00, 53.66it/s, Epoch: 13, Batch: 137,Loss: -0.560,Avg.Loss: -0.708,LR: 4.80E-04]Training epoch 13:  90%|████████▉ | 137/153 [00:02<00:00, 53.66it/s, Epoch: 13, Batch: 138,Loss: -0.649,Avg.Loss: -0.707,LR: 4.80E-04]Training epoch 13:  90%|█████████ | 138/153 [00:02<00:00, 53.65it/s, Epoch: 13, Batch: 138,Loss: -0.649,Avg.Loss: -0.707,LR: 4.80E-04]Training epoch 13:  90%|█████████ | 138/153 [00:02<00:00, 53.65it/s, Epoch: 13, Batch: 139,Loss: -1.152,Avg.Loss: -0.711,LR: 4.80E-04]Training epoch 13:  91%|█████████ | 139/153 [00:02<00:00, 53.65it/s, Epoch: 13, Batch: 140,Loss: -0.867,Avg.Loss: -0.712,LR: 4.80E-04]Training epoch 13:  92%|█████████▏| 140/153 [00:02<00:00, 53.65it/s, Epoch: 13, Batch: 141,Loss: -0.241,Avg.Loss: -0.708,LR: 4.80E-04]Training epoch 13:  92%|█████████▏| 141/153 [00:02<00:00, 53.65it/s, Epoch: 13, Batch: 142,Loss: -0.374,Avg.Loss: -0.706,LR: 4.80E-04]Training epoch 13:  93%|█████████▎| 142/153 [00:02<00:00, 53.65it/s, Epoch: 13, Batch: 143,Loss: -0.551,Avg.Loss: -0.705,LR: 4.80E-04]Training epoch 13:  93%|█████████▎| 143/153 [00:02<00:00, 53.65it/s, Epoch: 13, Batch: 144,Loss: -1.137,Avg.Loss: -0.708,LR: 4.80E-04]Training epoch 13:  94%|█████████▍| 144/153 [00:02<00:00, 53.33it/s, Epoch: 13, Batch: 144,Loss: -1.137,Avg.Loss: -0.708,LR: 4.80E-04]Training epoch 13:  94%|█████████▍| 144/153 [00:02<00:00, 53.33it/s, Epoch: 13, Batch: 145,Loss: -1.015,Avg.Loss: -0.710,LR: 4.80E-04]Training epoch 13:  95%|█████████▍| 145/153 [00:02<00:00, 53.33it/s, Epoch: 13, Batch: 146,Loss: -0.861,Avg.Loss: -0.711,LR: 4.80E-04]Training epoch 13:  95%|█████████▌| 146/153 [00:02<00:00, 53.33it/s, Epoch: 13, Batch: 147,Loss: -0.807,Avg.Loss: -0.712,LR: 4.80E-04]Training epoch 13:  96%|█████████▌| 147/153 [00:02<00:00, 53.33it/s, Epoch: 13, Batch: 148,Loss: -1.384,Avg.Loss: -0.716,LR: 4.80E-04]Training epoch 13:  97%|█████████▋| 148/153 [00:02<00:00, 53.33it/s, Epoch: 13, Batch: 149,Loss: -1.000,Avg.Loss: -0.718,LR: 4.80E-04]Training epoch 13:  97%|█████████▋| 149/153 [00:02<00:00, 53.33it/s, Epoch: 13, Batch: 150,Loss: -0.604,Avg.Loss: -0.717,LR: 4.79E-04]Training epoch 13:  98%|█████████▊| 150/153 [00:02<00:00, 53.44it/s, Epoch: 13, Batch: 150,Loss: -0.604,Avg.Loss: -0.717,LR: 4.79E-04]Training epoch 13:  98%|█████████▊| 150/153 [00:02<00:00, 53.44it/s, Epoch: 13, Batch: 151,Loss: -0.752,Avg.Loss: -0.718,LR: 4.79E-04]Training epoch 13:  99%|█████████▊| 151/153 [00:02<00:00, 53.44it/s, Epoch: 13, Batch: 152,Loss: -1.244,Avg.Loss: -0.721,LR: 4.79E-04]Training epoch 13:  99%|█████████▉| 152/153 [00:02<00:00, 53.44it/s, Epoch: 13, Batch: 153,Loss: -1.032,Avg.Loss: -0.723,LR: 4.79E-04]Training epoch 13: 100%|██████████| 153/153 [00:02<00:00, 53.16it/s, Epoch: 13, Batch: 153,Loss: -1.032,Avg.Loss: -0.723,LR: 4.79E-04]
Training epoch 14:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 14:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 14, Batch: 1,Loss: -0.865,Avg.Loss: -0.865,LR: 4.79E-04]Training epoch 14:   1%|          | 1/153 [00:00<00:05, 27.47it/s, Epoch: 14, Batch: 2,Loss: -1.295,Avg.Loss: -1.080,LR: 4.79E-04]Training epoch 14:   1%|▏         | 2/153 [00:00<00:04, 37.38it/s, Epoch: 14, Batch: 3,Loss: -1.252,Avg.Loss: -1.137,LR: 4.79E-04]Training epoch 14:   2%|▏         | 3/153 [00:00<00:03, 42.40it/s, Epoch: 14, Batch: 4,Loss: -1.215,Avg.Loss: -1.157,LR: 4.79E-04]Training epoch 14:   3%|▎         | 4/153 [00:00<00:03, 45.44it/s, Epoch: 14, Batch: 5,Loss: -1.098,Avg.Loss: -1.145,LR: 4.79E-04]Training epoch 14:   3%|▎         | 5/153 [00:00<00:03, 47.74it/s, Epoch: 14, Batch: 6,Loss: -1.283,Avg.Loss: -1.168,LR: 4.79E-04]Training epoch 14:   4%|▍         | 6/153 [00:00<00:02, 57.20it/s, Epoch: 14, Batch: 6,Loss: -1.283,Avg.Loss: -1.168,LR: 4.79E-04]Training epoch 14:   4%|▍         | 6/153 [00:00<00:02, 57.20it/s, Epoch: 14, Batch: 7,Loss: -1.323,Avg.Loss: -1.190,LR: 4.79E-04]Training epoch 14:   5%|▍         | 7/153 [00:00<00:02, 57.20it/s, Epoch: 14, Batch: 8,Loss: -0.193,Avg.Loss: -1.066,LR: 4.79E-04]Training epoch 14:   5%|▌         | 8/153 [00:00<00:02, 57.20it/s, Epoch: 14, Batch: 9,Loss: -0.872,Avg.Loss: -1.044,LR: 4.79E-04]Training epoch 14:   6%|▌         | 9/153 [00:00<00:02, 57.20it/s, Epoch: 14, Batch: 10,Loss: -1.425,Avg.Loss: -1.082,LR: 4.79E-04]Training epoch 14:   7%|▋         | 10/153 [00:00<00:02, 57.20it/s, Epoch: 14, Batch: 11,Loss: -1.448,Avg.Loss: -1.115,LR: 4.79E-04]Training epoch 14:   7%|▋         | 11/153 [00:00<00:02, 57.20it/s, Epoch: 14, Batch: 12,Loss: -1.438,Avg.Loss: -1.142,LR: 4.79E-04]Training epoch 14:   8%|▊         | 12/153 [00:00<00:02, 55.16it/s, Epoch: 14, Batch: 12,Loss: -1.438,Avg.Loss: -1.142,LR: 4.79E-04]Training epoch 14:   8%|▊         | 12/153 [00:00<00:02, 55.16it/s, Epoch: 14, Batch: 13,Loss: -1.024,Avg.Loss: -1.133,LR: 4.79E-04]Training epoch 14:   8%|▊         | 13/153 [00:00<00:02, 55.16it/s, Epoch: 14, Batch: 14,Loss: -1.222,Avg.Loss: -1.140,LR: 4.79E-04]Training epoch 14:   9%|▉         | 14/153 [00:00<00:02, 55.16it/s, Epoch: 14, Batch: 15,Loss: -1.159,Avg.Loss: -1.141,LR: 4.79E-04]Training epoch 14:  10%|▉         | 15/153 [00:00<00:02, 55.16it/s, Epoch: 14, Batch: 16,Loss: -1.284,Avg.Loss: -1.150,LR: 4.79E-04]Training epoch 14:  10%|█         | 16/153 [00:00<00:02, 55.16it/s, Epoch: 14, Batch: 17,Loss: -1.381,Avg.Loss: -1.163,LR: 4.79E-04]Training epoch 14:  11%|█         | 17/153 [00:00<00:02, 55.16it/s, Epoch: 14, Batch: 18,Loss: -1.301,Avg.Loss: -1.171,LR: 4.79E-04]Training epoch 14:  12%|█▏        | 18/153 [00:00<00:02, 54.20it/s, Epoch: 14, Batch: 18,Loss: -1.301,Avg.Loss: -1.171,LR: 4.79E-04]Training epoch 14:  12%|█▏        | 18/153 [00:00<00:02, 54.20it/s, Epoch: 14, Batch: 19,Loss: -0.670,Avg.Loss: -1.145,LR: 4.79E-04]Training epoch 14:  12%|█▏        | 19/153 [00:00<00:02, 54.20it/s, Epoch: 14, Batch: 20,Loss: -0.493,Avg.Loss: -1.112,LR: 4.79E-04]Training epoch 14:  13%|█▎        | 20/153 [00:00<00:02, 54.20it/s, Epoch: 14, Batch: 21,Loss: 0.238,Avg.Loss: -1.048,LR: 4.79E-04] Training epoch 14:  14%|█▎        | 21/153 [00:00<00:02, 54.20it/s, Epoch: 14, Batch: 22,Loss: -0.997,Avg.Loss: -1.046,LR: 4.79E-04]Training epoch 14:  14%|█▍        | 22/153 [00:00<00:02, 54.20it/s, Epoch: 14, Batch: 23,Loss: -1.333,Avg.Loss: -1.058,LR: 4.79E-04]Training epoch 14:  15%|█▌        | 23/153 [00:00<00:02, 54.20it/s, Epoch: 14, Batch: 24,Loss: -0.840,Avg.Loss: -1.049,LR: 4.79E-04]Training epoch 14:  16%|█▌        | 24/153 [00:00<00:02, 53.33it/s, Epoch: 14, Batch: 24,Loss: -0.840,Avg.Loss: -1.049,LR: 4.79E-04]Training epoch 14:  16%|█▌        | 24/153 [00:00<00:02, 53.33it/s, Epoch: 14, Batch: 25,Loss: -0.174,Avg.Loss: -1.014,LR: 4.79E-04]Training epoch 14:  16%|█▋        | 25/153 [00:00<00:02, 53.33it/s, Epoch: 14, Batch: 26,Loss: -0.702,Avg.Loss: -1.002,LR: 4.79E-04]Training epoch 14:  17%|█▋        | 26/153 [00:00<00:02, 53.33it/s, Epoch: 14, Batch: 27,Loss: -1.129,Avg.Loss: -1.007,LR: 4.79E-04]Training epoch 14:  18%|█▊        | 27/153 [00:00<00:02, 53.33it/s, Epoch: 14, Batch: 28,Loss: -1.026,Avg.Loss: -1.007,LR: 4.79E-04]Training epoch 14:  18%|█▊        | 28/153 [00:00<00:02, 53.33it/s, Epoch: 14, Batch: 29,Loss: -1.379,Avg.Loss: -1.020,LR: 4.79E-04]Training epoch 14:  19%|█▉        | 29/153 [00:00<00:02, 53.33it/s, Epoch: 14, Batch: 30,Loss: -1.224,Avg.Loss: -1.027,LR: 4.79E-04]Training epoch 14:  20%|█▉        | 30/153 [00:00<00:02, 52.53it/s, Epoch: 14, Batch: 30,Loss: -1.224,Avg.Loss: -1.027,LR: 4.79E-04]Training epoch 14:  20%|█▉        | 30/153 [00:00<00:02, 52.53it/s, Epoch: 14, Batch: 31,Loss: -0.587,Avg.Loss: -1.013,LR: 4.79E-04]Training epoch 14:  20%|██        | 31/153 [00:00<00:02, 52.53it/s, Epoch: 14, Batch: 32,Loss: -0.986,Avg.Loss: -1.012,LR: 4.79E-04]Training epoch 14:  21%|██        | 32/153 [00:00<00:02, 52.53it/s, Epoch: 14, Batch: 33,Loss: -1.106,Avg.Loss: -1.015,LR: 4.79E-04]Training epoch 14:  22%|██▏       | 33/153 [00:00<00:02, 52.53it/s, Epoch: 14, Batch: 34,Loss: -1.139,Avg.Loss: -1.018,LR: 4.79E-04]Training epoch 14:  22%|██▏       | 34/153 [00:00<00:02, 52.53it/s, Epoch: 14, Batch: 35,Loss: -1.161,Avg.Loss: -1.023,LR: 4.79E-04]Training epoch 14:  23%|██▎       | 35/153 [00:00<00:02, 52.53it/s, Epoch: 14, Batch: 36,Loss: -1.553,Avg.Loss: -1.037,LR: 4.79E-04]Training epoch 14:  24%|██▎       | 36/153 [00:00<00:02, 52.85it/s, Epoch: 14, Batch: 36,Loss: -1.553,Avg.Loss: -1.037,LR: 4.79E-04]Training epoch 14:  24%|██▎       | 36/153 [00:00<00:02, 52.85it/s, Epoch: 14, Batch: 37,Loss: -1.359,Avg.Loss: -1.046,LR: 4.79E-04]Training epoch 14:  24%|██▍       | 37/153 [00:00<00:02, 52.85it/s, Epoch: 14, Batch: 38,Loss: -1.340,Avg.Loss: -1.054,LR: 4.79E-04]Training epoch 14:  25%|██▍       | 38/153 [00:00<00:02, 52.85it/s, Epoch: 14, Batch: 39,Loss: -1.416,Avg.Loss: -1.063,LR: 4.79E-04]Training epoch 14:  25%|██▌       | 39/153 [00:00<00:02, 52.85it/s, Epoch: 14, Batch: 40,Loss: -0.892,Avg.Loss: -1.059,LR: 4.79E-04]Training epoch 14:  26%|██▌       | 40/153 [00:00<00:02, 52.85it/s, Epoch: 14, Batch: 41,Loss: -1.475,Avg.Loss: -1.069,LR: 4.79E-04]Training epoch 14:  27%|██▋       | 41/153 [00:00<00:02, 52.85it/s, Epoch: 14, Batch: 42,Loss: -1.058,Avg.Loss: -1.069,LR: 4.79E-04]Training epoch 14:  27%|██▋       | 42/153 [00:00<00:02, 53.21it/s, Epoch: 14, Batch: 42,Loss: -1.058,Avg.Loss: -1.069,LR: 4.79E-04]Training epoch 14:  27%|██▋       | 42/153 [00:00<00:02, 53.21it/s, Epoch: 14, Batch: 43,Loss: -1.151,Avg.Loss: -1.070,LR: 4.79E-04]Training epoch 14:  28%|██▊       | 43/153 [00:00<00:02, 53.21it/s, Epoch: 14, Batch: 44,Loss: -1.187,Avg.Loss: -1.073,LR: 4.79E-04]Training epoch 14:  29%|██▉       | 44/153 [00:00<00:02, 53.21it/s, Epoch: 14, Batch: 45,Loss: -1.272,Avg.Loss: -1.078,LR: 4.79E-04]Training epoch 14:  29%|██▉       | 45/153 [00:00<00:02, 53.21it/s, Epoch: 14, Batch: 46,Loss: -1.214,Avg.Loss: -1.081,LR: 4.78E-04]Training epoch 14:  30%|███       | 46/153 [00:00<00:02, 53.21it/s, Epoch: 14, Batch: 47,Loss: -1.588,Avg.Loss: -1.091,LR: 4.78E-04]Training epoch 14:  31%|███       | 47/153 [00:00<00:01, 53.21it/s, Epoch: 14, Batch: 48,Loss: -1.540,Avg.Loss: -1.101,LR: 4.78E-04]Training epoch 14:  31%|███▏      | 48/153 [00:00<00:01, 53.17it/s, Epoch: 14, Batch: 48,Loss: -1.540,Avg.Loss: -1.101,LR: 4.78E-04]Training epoch 14:  31%|███▏      | 48/153 [00:00<00:01, 53.17it/s, Epoch: 14, Batch: 49,Loss: -1.070,Avg.Loss: -1.100,LR: 4.78E-04]Training epoch 14:  32%|███▏      | 49/153 [00:00<00:01, 53.17it/s, Epoch: 14, Batch: 50,Loss: -0.474,Avg.Loss: -1.088,LR: 4.78E-04]Training epoch 14:  33%|███▎      | 50/153 [00:00<00:01, 53.17it/s, Epoch: 14, Batch: 51,Loss: -0.710,Avg.Loss: -1.080,LR: 4.78E-04]Training epoch 14:  33%|███▎      | 51/153 [00:00<00:01, 53.17it/s, Epoch: 14, Batch: 52,Loss: -0.993,Avg.Loss: -1.078,LR: 4.78E-04]Training epoch 14:  34%|███▍      | 52/153 [00:00<00:01, 53.17it/s, Epoch: 14, Batch: 53,Loss: -1.272,Avg.Loss: -1.082,LR: 4.78E-04]Training epoch 14:  35%|███▍      | 53/153 [00:01<00:01, 53.17it/s, Epoch: 14, Batch: 54,Loss: -1.203,Avg.Loss: -1.084,LR: 4.78E-04]Training epoch 14:  35%|███▌      | 54/153 [00:01<00:01, 53.11it/s, Epoch: 14, Batch: 54,Loss: -1.203,Avg.Loss: -1.084,LR: 4.78E-04]Training epoch 14:  35%|███▌      | 54/153 [00:01<00:01, 53.11it/s, Epoch: 14, Batch: 55,Loss: -0.813,Avg.Loss: -1.079,LR: 4.78E-04]Training epoch 14:  36%|███▌      | 55/153 [00:01<00:01, 53.11it/s, Epoch: 14, Batch: 56,Loss: -0.197,Avg.Loss: -1.064,LR: 4.78E-04]Training epoch 14:  37%|███▋      | 56/153 [00:01<00:01, 53.11it/s, Epoch: 14, Batch: 57,Loss: -1.006,Avg.Loss: -1.063,LR: 4.78E-04]Training epoch 14:  37%|███▋      | 57/153 [00:01<00:01, 53.11it/s, Epoch: 14, Batch: 58,Loss: -0.601,Avg.Loss: -1.055,LR: 4.78E-04]Training epoch 14:  38%|███▊      | 58/153 [00:01<00:01, 53.11it/s, Epoch: 14, Batch: 59,Loss: -0.144,Avg.Loss: -1.039,LR: 4.78E-04]Training epoch 14:  39%|███▊      | 59/153 [00:01<00:01, 53.11it/s, Epoch: 14, Batch: 60,Loss: -0.970,Avg.Loss: -1.038,LR: 4.78E-04]Training epoch 14:  39%|███▉      | 60/153 [00:01<00:01, 53.32it/s, Epoch: 14, Batch: 60,Loss: -0.970,Avg.Loss: -1.038,LR: 4.78E-04]Training epoch 14:  39%|███▉      | 60/153 [00:01<00:01, 53.32it/s, Epoch: 14, Batch: 61,Loss: -0.726,Avg.Loss: -1.033,LR: 4.78E-04]Training epoch 14:  40%|███▉      | 61/153 [00:01<00:01, 53.32it/s, Epoch: 14, Batch: 62,Loss: -0.829,Avg.Loss: -1.030,LR: 4.78E-04]Training epoch 14:  41%|████      | 62/153 [00:01<00:01, 53.32it/s, Epoch: 14, Batch: 63,Loss: -0.238,Avg.Loss: -1.017,LR: 4.78E-04]Training epoch 14:  41%|████      | 63/153 [00:01<00:01, 53.32it/s, Epoch: 14, Batch: 64,Loss: -0.581,Avg.Loss: -1.010,LR: 4.78E-04]Training epoch 14:  42%|████▏     | 64/153 [00:01<00:01, 53.32it/s, Epoch: 14, Batch: 65,Loss: -0.774,Avg.Loss: -1.007,LR: 4.78E-04]Training epoch 14:  42%|████▏     | 65/153 [00:01<00:01, 53.32it/s, Epoch: 14, Batch: 66,Loss: -0.752,Avg.Loss: -1.003,LR: 4.78E-04]Training epoch 14:  43%|████▎     | 66/153 [00:01<00:01, 53.42it/s, Epoch: 14, Batch: 66,Loss: -0.752,Avg.Loss: -1.003,LR: 4.78E-04]Training epoch 14:  43%|████▎     | 66/153 [00:01<00:01, 53.42it/s, Epoch: 14, Batch: 67,Loss: -0.947,Avg.Loss: -1.002,LR: 4.78E-04]Training epoch 14:  44%|████▍     | 67/153 [00:01<00:01, 53.42it/s, Epoch: 14, Batch: 68,Loss: -0.885,Avg.Loss: -1.000,LR: 4.78E-04]Training epoch 14:  44%|████▍     | 68/153 [00:01<00:01, 53.42it/s, Epoch: 14, Batch: 69,Loss: -1.186,Avg.Loss: -1.003,LR: 4.78E-04]Training epoch 14:  45%|████▌     | 69/153 [00:01<00:01, 53.42it/s, Epoch: 14, Batch: 70,Loss: -1.396,Avg.Loss: -1.009,LR: 4.78E-04]Training epoch 14:  46%|████▌     | 70/153 [00:01<00:01, 53.42it/s, Epoch: 14, Batch: 71,Loss: -1.102,Avg.Loss: -1.010,LR: 4.78E-04]Training epoch 14:  46%|████▋     | 71/153 [00:01<00:01, 53.42it/s, Epoch: 14, Batch: 72,Loss: -0.993,Avg.Loss: -1.010,LR: 4.78E-04]Training epoch 14:  47%|████▋     | 72/153 [00:01<00:01, 53.21it/s, Epoch: 14, Batch: 72,Loss: -0.993,Avg.Loss: -1.010,LR: 4.78E-04]Training epoch 14:  47%|████▋     | 72/153 [00:01<00:01, 53.21it/s, Epoch: 14, Batch: 73,Loss: -1.586,Avg.Loss: -1.018,LR: 4.78E-04]Training epoch 14:  48%|████▊     | 73/153 [00:01<00:01, 53.21it/s, Epoch: 14, Batch: 74,Loss: -1.188,Avg.Loss: -1.020,LR: 4.78E-04]Training epoch 14:  48%|████▊     | 74/153 [00:01<00:01, 53.21it/s, Epoch: 14, Batch: 75,Loss: -0.883,Avg.Loss: -1.018,LR: 4.78E-04]Training epoch 14:  49%|████▉     | 75/153 [00:01<00:01, 53.21it/s, Epoch: 14, Batch: 76,Loss: -1.482,Avg.Loss: -1.024,LR: 4.78E-04]Training epoch 14:  50%|████▉     | 76/153 [00:01<00:01, 53.21it/s, Epoch: 14, Batch: 77,Loss: -1.063,Avg.Loss: -1.025,LR: 4.78E-04]Training epoch 14:  50%|█████     | 77/153 [00:01<00:01, 53.21it/s, Epoch: 14, Batch: 78,Loss: -1.112,Avg.Loss: -1.026,LR: 4.78E-04]Training epoch 14:  51%|█████     | 78/153 [00:01<00:01, 53.38it/s, Epoch: 14, Batch: 78,Loss: -1.112,Avg.Loss: -1.026,LR: 4.78E-04]Training epoch 14:  51%|█████     | 78/153 [00:01<00:01, 53.38it/s, Epoch: 14, Batch: 79,Loss: -0.618,Avg.Loss: -1.021,LR: 4.78E-04]Training epoch 14:  52%|█████▏    | 79/153 [00:01<00:01, 53.38it/s, Epoch: 14, Batch: 80,Loss: -1.033,Avg.Loss: -1.021,LR: 4.78E-04]Training epoch 14:  52%|█████▏    | 80/153 [00:01<00:01, 53.38it/s, Epoch: 14, Batch: 81,Loss: -1.165,Avg.Loss: -1.023,LR: 4.78E-04]Training epoch 14:  53%|█████▎    | 81/153 [00:01<00:01, 53.38it/s, Epoch: 14, Batch: 82,Loss: -1.291,Avg.Loss: -1.026,LR: 4.78E-04]Training epoch 14:  54%|█████▎    | 82/153 [00:01<00:01, 53.38it/s, Epoch: 14, Batch: 83,Loss: -0.629,Avg.Loss: -1.021,LR: 4.78E-04]Training epoch 14:  54%|█████▍    | 83/153 [00:01<00:01, 53.38it/s, Epoch: 14, Batch: 84,Loss: -0.733,Avg.Loss: -1.018,LR: 4.78E-04]Training epoch 14:  55%|█████▍    | 84/153 [00:01<00:01, 53.43it/s, Epoch: 14, Batch: 84,Loss: -0.733,Avg.Loss: -1.018,LR: 4.78E-04]Training epoch 14:  55%|█████▍    | 84/153 [00:01<00:01, 53.43it/s, Epoch: 14, Batch: 85,Loss: -1.450,Avg.Loss: -1.023,LR: 4.78E-04]Training epoch 14:  56%|█████▌    | 85/153 [00:01<00:01, 53.43it/s, Epoch: 14, Batch: 86,Loss: -1.365,Avg.Loss: -1.027,LR: 4.78E-04]Training epoch 14:  56%|█████▌    | 86/153 [00:01<00:01, 53.43it/s, Epoch: 14, Batch: 87,Loss: -0.759,Avg.Loss: -1.024,LR: 4.78E-04]Training epoch 14:  57%|█████▋    | 87/153 [00:01<00:01, 53.43it/s, Epoch: 14, Batch: 88,Loss: -0.851,Avg.Loss: -1.022,LR: 4.78E-04]Training epoch 14:  58%|█████▊    | 88/153 [00:01<00:01, 53.43it/s, Epoch: 14, Batch: 89,Loss: -1.121,Avg.Loss: -1.023,LR: 4.78E-04]Training epoch 14:  58%|█████▊    | 89/153 [00:01<00:01, 53.43it/s, Epoch: 14, Batch: 90,Loss: -1.441,Avg.Loss: -1.027,LR: 4.78E-04]Training epoch 14:  59%|█████▉    | 90/153 [00:01<00:01, 53.25it/s, Epoch: 14, Batch: 90,Loss: -1.441,Avg.Loss: -1.027,LR: 4.78E-04]Training epoch 14:  59%|█████▉    | 90/153 [00:01<00:01, 53.25it/s, Epoch: 14, Batch: 91,Loss: -0.699,Avg.Loss: -1.024,LR: 4.78E-04]Training epoch 14:  59%|█████▉    | 91/153 [00:01<00:01, 53.25it/s, Epoch: 14, Batch: 92,Loss: -1.158,Avg.Loss: -1.025,LR: 4.78E-04]Training epoch 14:  60%|██████    | 92/153 [00:01<00:01, 53.25it/s, Epoch: 14, Batch: 93,Loss: -1.071,Avg.Loss: -1.026,LR: 4.78E-04]Training epoch 14:  61%|██████    | 93/153 [00:01<00:01, 53.25it/s, Epoch: 14, Batch: 94,Loss: -1.508,Avg.Loss: -1.031,LR: 4.77E-04]Training epoch 14:  61%|██████▏   | 94/153 [00:01<00:01, 53.25it/s, Epoch: 14, Batch: 95,Loss: -1.531,Avg.Loss: -1.036,LR: 4.77E-04]Training epoch 14:  62%|██████▏   | 95/153 [00:01<00:01, 53.25it/s, Epoch: 14, Batch: 96,Loss: -0.938,Avg.Loss: -1.035,LR: 4.77E-04]Training epoch 14:  63%|██████▎   | 96/153 [00:01<00:01, 53.16it/s, Epoch: 14, Batch: 96,Loss: -0.938,Avg.Loss: -1.035,LR: 4.77E-04]Training epoch 14:  63%|██████▎   | 96/153 [00:01<00:01, 53.16it/s, Epoch: 14, Batch: 97,Loss: -1.197,Avg.Loss: -1.037,LR: 4.77E-04]Training epoch 14:  63%|██████▎   | 97/153 [00:01<00:01, 53.16it/s, Epoch: 14, Batch: 98,Loss: -1.533,Avg.Loss: -1.042,LR: 4.77E-04]Training epoch 14:  64%|██████▍   | 98/153 [00:01<00:01, 53.16it/s, Epoch: 14, Batch: 99,Loss: -0.937,Avg.Loss: -1.041,LR: 4.77E-04]Training epoch 14:  65%|██████▍   | 99/153 [00:01<00:01, 53.16it/s, Epoch: 14, Batch: 100,Loss: -1.459,Avg.Loss: -1.045,LR: 4.77E-04]Training epoch 14:  65%|██████▌   | 100/153 [00:01<00:00, 53.16it/s, Epoch: 14, Batch: 101,Loss: -1.298,Avg.Loss: -1.047,LR: 4.77E-04]Training epoch 14:  66%|██████▌   | 101/153 [00:01<00:00, 53.16it/s, Epoch: 14, Batch: 102,Loss: -0.969,Avg.Loss: -1.047,LR: 4.77E-04]Training epoch 14:  67%|██████▋   | 102/153 [00:01<00:00, 53.32it/s, Epoch: 14, Batch: 102,Loss: -0.969,Avg.Loss: -1.047,LR: 4.77E-04]Training epoch 14:  67%|██████▋   | 102/153 [00:01<00:00, 53.32it/s, Epoch: 14, Batch: 103,Loss: -1.303,Avg.Loss: -1.049,LR: 4.77E-04]Training epoch 14:  67%|██████▋   | 103/153 [00:01<00:00, 53.32it/s, Epoch: 14, Batch: 104,Loss: -0.728,Avg.Loss: -1.046,LR: 4.77E-04]Training epoch 14:  68%|██████▊   | 104/153 [00:01<00:00, 53.32it/s, Epoch: 14, Batch: 105,Loss: 0.199,Avg.Loss: -1.034,LR: 4.77E-04] Training epoch 14:  69%|██████▊   | 105/153 [00:01<00:00, 53.32it/s, Epoch: 14, Batch: 106,Loss: -0.298,Avg.Loss: -1.027,LR: 4.77E-04]Training epoch 14:  69%|██████▉   | 106/153 [00:02<00:00, 53.32it/s, Epoch: 14, Batch: 107,Loss: -0.495,Avg.Loss: -1.022,LR: 4.77E-04]Training epoch 14:  70%|██████▉   | 107/153 [00:02<00:00, 53.32it/s, Epoch: 14, Batch: 108,Loss: -0.424,Avg.Loss: -1.017,LR: 4.77E-04]Training epoch 14:  71%|███████   | 108/153 [00:02<00:00, 53.40it/s, Epoch: 14, Batch: 108,Loss: -0.424,Avg.Loss: -1.017,LR: 4.77E-04]Training epoch 14:  71%|███████   | 108/153 [00:02<00:00, 53.40it/s, Epoch: 14, Batch: 109,Loss: 0.006,Avg.Loss: -1.007,LR: 4.77E-04] Training epoch 14:  71%|███████   | 109/153 [00:02<00:00, 53.40it/s, Epoch: 14, Batch: 110,Loss: -0.538,Avg.Loss: -1.003,LR: 4.77E-04]Training epoch 14:  72%|███████▏  | 110/153 [00:02<00:00, 53.40it/s, Epoch: 14, Batch: 111,Loss: -1.005,Avg.Loss: -1.003,LR: 4.77E-04]Training epoch 14:  73%|███████▎  | 111/153 [00:02<00:00, 53.40it/s, Epoch: 14, Batch: 112,Loss: -0.942,Avg.Loss: -1.003,LR: 4.77E-04]Training epoch 14:  73%|███████▎  | 112/153 [00:02<00:00, 53.40it/s, Epoch: 14, Batch: 113,Loss: -0.044,Avg.Loss: -0.994,LR: 4.77E-04]Training epoch 14:  74%|███████▍  | 113/153 [00:02<00:00, 53.40it/s, Epoch: 14, Batch: 114,Loss: -0.312,Avg.Loss: -0.988,LR: 4.77E-04]Training epoch 14:  75%|███████▍  | 114/153 [00:02<00:00, 53.45it/s, Epoch: 14, Batch: 114,Loss: -0.312,Avg.Loss: -0.988,LR: 4.77E-04]Training epoch 14:  75%|███████▍  | 114/153 [00:02<00:00, 53.45it/s, Epoch: 14, Batch: 115,Loss: -0.748,Avg.Loss: -0.986,LR: 4.77E-04]Training epoch 14:  75%|███████▌  | 115/153 [00:02<00:00, 53.45it/s, Epoch: 14, Batch: 116,Loss: -0.344,Avg.Loss: -0.980,LR: 4.77E-04]Training epoch 14:  76%|███████▌  | 116/153 [00:02<00:00, 53.45it/s, Epoch: 14, Batch: 117,Loss: -0.326,Avg.Loss: -0.975,LR: 4.77E-04]Training epoch 14:  76%|███████▋  | 117/153 [00:02<00:00, 53.45it/s, Epoch: 14, Batch: 118,Loss: -0.861,Avg.Loss: -0.974,LR: 4.77E-04]Training epoch 14:  77%|███████▋  | 118/153 [00:02<00:00, 53.45it/s, Epoch: 14, Batch: 119,Loss: -1.278,Avg.Loss: -0.976,LR: 4.77E-04]Training epoch 14:  78%|███████▊  | 119/153 [00:02<00:00, 53.45it/s, Epoch: 14, Batch: 120,Loss: -0.801,Avg.Loss: -0.975,LR: 4.77E-04]Training epoch 14:  78%|███████▊  | 120/153 [00:02<00:00, 53.62it/s, Epoch: 14, Batch: 120,Loss: -0.801,Avg.Loss: -0.975,LR: 4.77E-04]Training epoch 14:  78%|███████▊  | 120/153 [00:02<00:00, 53.62it/s, Epoch: 14, Batch: 121,Loss: 0.409,Avg.Loss: -0.964,LR: 4.77E-04] Training epoch 14:  79%|███████▉  | 121/153 [00:02<00:00, 53.62it/s, Epoch: 14, Batch: 122,Loss: -0.435,Avg.Loss: -0.959,LR: 4.77E-04]Training epoch 14:  80%|███████▉  | 122/153 [00:02<00:00, 53.62it/s, Epoch: 14, Batch: 123,Loss: -0.701,Avg.Loss: -0.957,LR: 4.77E-04]Training epoch 14:  80%|████████  | 123/153 [00:02<00:00, 53.62it/s, Epoch: 14, Batch: 124,Loss: -0.508,Avg.Loss: -0.954,LR: 4.77E-04]Training epoch 14:  81%|████████  | 124/153 [00:02<00:00, 53.62it/s, Epoch: 14, Batch: 125,Loss: 0.416,Avg.Loss: -0.943,LR: 4.77E-04] Training epoch 14:  82%|████████▏ | 125/153 [00:02<00:00, 53.62it/s, Epoch: 14, Batch: 126,Loss: 0.154,Avg.Loss: -0.934,LR: 4.77E-04]Training epoch 14:  82%|████████▏ | 126/153 [00:02<00:00, 53.52it/s, Epoch: 14, Batch: 126,Loss: 0.154,Avg.Loss: -0.934,LR: 4.77E-04]Training epoch 14:  82%|████████▏ | 126/153 [00:02<00:00, 53.52it/s, Epoch: 14, Batch: 127,Loss: -0.861,Avg.Loss: -0.933,LR: 4.77E-04]Training epoch 14:  83%|████████▎ | 127/153 [00:02<00:00, 53.52it/s, Epoch: 14, Batch: 128,Loss: -1.030,Avg.Loss: -0.934,LR: 4.77E-04]Training epoch 14:  84%|████████▎ | 128/153 [00:02<00:00, 53.52it/s, Epoch: 14, Batch: 129,Loss: -1.270,Avg.Loss: -0.937,LR: 4.77E-04]Training epoch 14:  84%|████████▍ | 129/153 [00:02<00:00, 53.52it/s, Epoch: 14, Batch: 130,Loss: -1.261,Avg.Loss: -0.939,LR: 4.77E-04]Training epoch 14:  85%|████████▍ | 130/153 [00:02<00:00, 53.52it/s, Epoch: 14, Batch: 131,Loss: -1.563,Avg.Loss: -0.944,LR: 4.77E-04]Training epoch 14:  86%|████████▌ | 131/153 [00:02<00:00, 53.52it/s, Epoch: 14, Batch: 132,Loss: -1.468,Avg.Loss: -0.948,LR: 4.77E-04]Training epoch 14:  86%|████████▋ | 132/153 [00:02<00:00, 53.49it/s, Epoch: 14, Batch: 132,Loss: -1.468,Avg.Loss: -0.948,LR: 4.77E-04]Training epoch 14:  86%|████████▋ | 132/153 [00:02<00:00, 53.49it/s, Epoch: 14, Batch: 133,Loss: -1.162,Avg.Loss: -0.949,LR: 4.77E-04]Training epoch 14:  87%|████████▋ | 133/153 [00:02<00:00, 53.49it/s, Epoch: 14, Batch: 134,Loss: -1.379,Avg.Loss: -0.953,LR: 4.77E-04]Training epoch 14:  88%|████████▊ | 134/153 [00:02<00:00, 53.49it/s, Epoch: 14, Batch: 135,Loss: -1.355,Avg.Loss: -0.956,LR: 4.77E-04]Training epoch 14:  88%|████████▊ | 135/153 [00:02<00:00, 53.49it/s, Epoch: 14, Batch: 136,Loss: -1.237,Avg.Loss: -0.958,LR: 4.77E-04]Training epoch 14:  89%|████████▉ | 136/153 [00:02<00:00, 53.49it/s, Epoch: 14, Batch: 137,Loss: -1.732,Avg.Loss: -0.963,LR: 4.77E-04]Training epoch 14:  90%|████████▉ | 137/153 [00:02<00:00, 53.49it/s, Epoch: 14, Batch: 138,Loss: -1.351,Avg.Loss: -0.966,LR: 4.77E-04]Training epoch 14:  90%|█████████ | 138/153 [00:02<00:00, 53.50it/s, Epoch: 14, Batch: 138,Loss: -1.351,Avg.Loss: -0.966,LR: 4.77E-04]Training epoch 14:  90%|█████████ | 138/153 [00:02<00:00, 53.50it/s, Epoch: 14, Batch: 139,Loss: -1.125,Avg.Loss: -0.967,LR: 4.77E-04]Training epoch 14:  91%|█████████ | 139/153 [00:02<00:00, 53.50it/s, Epoch: 14, Batch: 140,Loss: -1.488,Avg.Loss: -0.971,LR: 4.76E-04]Training epoch 14:  92%|█████████▏| 140/153 [00:02<00:00, 53.50it/s, Epoch: 14, Batch: 141,Loss: -1.287,Avg.Loss: -0.973,LR: 4.76E-04]Training epoch 14:  92%|█████████▏| 141/153 [00:02<00:00, 53.50it/s, Epoch: 14, Batch: 142,Loss: -1.306,Avg.Loss: -0.976,LR: 4.76E-04]Training epoch 14:  93%|█████████▎| 142/153 [00:02<00:00, 53.50it/s, Epoch: 14, Batch: 143,Loss: -1.474,Avg.Loss: -0.979,LR: 4.76E-04]Training epoch 14:  93%|█████████▎| 143/153 [00:02<00:00, 53.50it/s, Epoch: 14, Batch: 144,Loss: -1.110,Avg.Loss: -0.980,LR: 4.76E-04]Training epoch 14:  94%|█████████▍| 144/153 [00:02<00:00, 53.37it/s, Epoch: 14, Batch: 144,Loss: -1.110,Avg.Loss: -0.980,LR: 4.76E-04]Training epoch 14:  94%|█████████▍| 144/153 [00:02<00:00, 53.37it/s, Epoch: 14, Batch: 145,Loss: -1.095,Avg.Loss: -0.981,LR: 4.76E-04]Training epoch 14:  95%|█████████▍| 145/153 [00:02<00:00, 53.37it/s, Epoch: 14, Batch: 146,Loss: -1.442,Avg.Loss: -0.984,LR: 4.76E-04]Training epoch 14:  95%|█████████▌| 146/153 [00:02<00:00, 53.37it/s, Epoch: 14, Batch: 147,Loss: -0.623,Avg.Loss: -0.982,LR: 4.76E-04]Training epoch 14:  96%|█████████▌| 147/153 [00:02<00:00, 53.37it/s, Epoch: 14, Batch: 148,Loss: -0.672,Avg.Loss: -0.979,LR: 4.76E-04]Training epoch 14:  97%|█████████▋| 148/153 [00:02<00:00, 53.37it/s, Epoch: 14, Batch: 149,Loss: -1.381,Avg.Loss: -0.982,LR: 4.76E-04]Training epoch 14:  97%|█████████▋| 149/153 [00:02<00:00, 53.37it/s, Epoch: 14, Batch: 150,Loss: -1.108,Avg.Loss: -0.983,LR: 4.76E-04]Training epoch 14:  98%|█████████▊| 150/153 [00:02<00:00, 53.34it/s, Epoch: 14, Batch: 150,Loss: -1.108,Avg.Loss: -0.983,LR: 4.76E-04]Training epoch 14:  98%|█████████▊| 150/153 [00:02<00:00, 53.34it/s, Epoch: 14, Batch: 151,Loss: -1.548,Avg.Loss: -0.987,LR: 4.76E-04]Training epoch 14:  99%|█████████▊| 151/153 [00:02<00:00, 53.34it/s, Epoch: 14, Batch: 152,Loss: -1.370,Avg.Loss: -0.989,LR: 4.76E-04]Training epoch 14:  99%|█████████▉| 152/153 [00:02<00:00, 53.34it/s, Epoch: 14, Batch: 153,Loss: -1.588,Avg.Loss: -0.993,LR: 4.76E-04]Training epoch 14: 100%|██████████| 153/153 [00:02<00:00, 53.35it/s, Epoch: 14, Batch: 153,Loss: -1.588,Avg.Loss: -0.993,LR: 4.76E-04]
Training epoch 15:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 15:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 15, Batch: 1,Loss: -1.580,Avg.Loss: -1.580,LR: 4.76E-04]Training epoch 15:   1%|          | 1/153 [00:00<00:06, 24.95it/s, Epoch: 15, Batch: 2,Loss: -1.291,Avg.Loss: -1.436,LR: 4.76E-04]Training epoch 15:   1%|▏         | 2/153 [00:00<00:04, 37.65it/s, Epoch: 15, Batch: 3,Loss: -1.311,Avg.Loss: -1.394,LR: 4.76E-04]Training epoch 15:   2%|▏         | 3/153 [00:00<00:03, 43.73it/s, Epoch: 15, Batch: 4,Loss: -1.619,Avg.Loss: -1.450,LR: 4.76E-04]Training epoch 15:   3%|▎         | 4/153 [00:00<00:03, 45.96it/s, Epoch: 15, Batch: 5,Loss: -0.789,Avg.Loss: -1.318,LR: 4.76E-04]Training epoch 15:   3%|▎         | 5/153 [00:00<00:03, 47.19it/s, Epoch: 15, Batch: 6,Loss: -0.708,Avg.Loss: -1.216,LR: 4.76E-04]Training epoch 15:   4%|▍         | 6/153 [00:00<00:02, 56.53it/s, Epoch: 15, Batch: 6,Loss: -0.708,Avg.Loss: -1.216,LR: 4.76E-04]Training epoch 15:   4%|▍         | 6/153 [00:00<00:02, 56.53it/s, Epoch: 15, Batch: 7,Loss: -1.327,Avg.Loss: -1.232,LR: 4.76E-04]Training epoch 15:   5%|▍         | 7/153 [00:00<00:02, 56.53it/s, Epoch: 15, Batch: 8,Loss: -0.902,Avg.Loss: -1.191,LR: 4.76E-04]Training epoch 15:   5%|▌         | 8/153 [00:00<00:02, 56.53it/s, Epoch: 15, Batch: 9,Loss: -1.753,Avg.Loss: -1.253,LR: 4.76E-04]Training epoch 15:   6%|▌         | 9/153 [00:00<00:02, 56.53it/s, Epoch: 15, Batch: 10,Loss: -1.757,Avg.Loss: -1.304,LR: 4.76E-04]Training epoch 15:   7%|▋         | 10/153 [00:00<00:02, 56.53it/s, Epoch: 15, Batch: 11,Loss: -1.558,Avg.Loss: -1.327,LR: 4.76E-04]Training epoch 15:   7%|▋         | 11/153 [00:00<00:02, 56.53it/s, Epoch: 15, Batch: 12,Loss: -1.497,Avg.Loss: -1.341,LR: 4.76E-04]Training epoch 15:   8%|▊         | 12/153 [00:00<00:02, 54.31it/s, Epoch: 15, Batch: 12,Loss: -1.497,Avg.Loss: -1.341,LR: 4.76E-04]Training epoch 15:   8%|▊         | 12/153 [00:00<00:02, 54.31it/s, Epoch: 15, Batch: 13,Loss: -1.562,Avg.Loss: -1.358,LR: 4.76E-04]Training epoch 15:   8%|▊         | 13/153 [00:00<00:02, 54.31it/s, Epoch: 15, Batch: 14,Loss: -1.445,Avg.Loss: -1.364,LR: 4.76E-04]Training epoch 15:   9%|▉         | 14/153 [00:00<00:02, 54.31it/s, Epoch: 15, Batch: 15,Loss: -1.413,Avg.Loss: -1.367,LR: 4.76E-04]Training epoch 15:  10%|▉         | 15/153 [00:00<00:02, 54.31it/s, Epoch: 15, Batch: 16,Loss: -1.164,Avg.Loss: -1.355,LR: 4.76E-04]Training epoch 15:  10%|█         | 16/153 [00:00<00:02, 54.31it/s, Epoch: 15, Batch: 17,Loss: -1.564,Avg.Loss: -1.367,LR: 4.76E-04]Training epoch 15:  11%|█         | 17/153 [00:00<00:02, 54.31it/s, Epoch: 15, Batch: 18,Loss: -1.346,Avg.Loss: -1.366,LR: 4.76E-04]Training epoch 15:  12%|█▏        | 18/153 [00:00<00:02, 53.72it/s, Epoch: 15, Batch: 18,Loss: -1.346,Avg.Loss: -1.366,LR: 4.76E-04]Training epoch 15:  12%|█▏        | 18/153 [00:00<00:02, 53.72it/s, Epoch: 15, Batch: 19,Loss: -1.192,Avg.Loss: -1.357,LR: 4.76E-04]Training epoch 15:  12%|█▏        | 19/153 [00:00<00:02, 53.72it/s, Epoch: 15, Batch: 20,Loss: -1.348,Avg.Loss: -1.356,LR: 4.76E-04]Training epoch 15:  13%|█▎        | 20/153 [00:00<00:02, 53.72it/s, Epoch: 15, Batch: 21,Loss: -1.219,Avg.Loss: -1.350,LR: 4.76E-04]Training epoch 15:  14%|█▎        | 21/153 [00:00<00:02, 53.72it/s, Epoch: 15, Batch: 22,Loss: -1.441,Avg.Loss: -1.354,LR: 4.76E-04]Training epoch 15:  14%|█▍        | 22/153 [00:00<00:02, 53.72it/s, Epoch: 15, Batch: 23,Loss: -1.022,Avg.Loss: -1.339,LR: 4.76E-04]Training epoch 15:  15%|█▌        | 23/153 [00:00<00:02, 53.72it/s, Epoch: 15, Batch: 24,Loss: -1.435,Avg.Loss: -1.343,LR: 4.76E-04]Training epoch 15:  16%|█▌        | 24/153 [00:00<00:02, 52.66it/s, Epoch: 15, Batch: 24,Loss: -1.435,Avg.Loss: -1.343,LR: 4.76E-04]Training epoch 15:  16%|█▌        | 24/153 [00:00<00:02, 52.66it/s, Epoch: 15, Batch: 25,Loss: -1.606,Avg.Loss: -1.354,LR: 4.76E-04]Training epoch 15:  16%|█▋        | 25/153 [00:00<00:02, 52.66it/s, Epoch: 15, Batch: 26,Loss: -1.291,Avg.Loss: -1.352,LR: 4.76E-04]Training epoch 15:  17%|█▋        | 26/153 [00:00<00:02, 52.66it/s, Epoch: 15, Batch: 27,Loss: -1.631,Avg.Loss: -1.362,LR: 4.76E-04]Training epoch 15:  18%|█▊        | 27/153 [00:00<00:02, 52.66it/s, Epoch: 15, Batch: 28,Loss: -1.546,Avg.Loss: -1.368,LR: 4.76E-04]Training epoch 15:  18%|█▊        | 28/153 [00:00<00:02, 52.66it/s, Epoch: 15, Batch: 29,Loss: -1.493,Avg.Loss: -1.373,LR: 4.76E-04]Training epoch 15:  19%|█▉        | 29/153 [00:00<00:02, 52.66it/s, Epoch: 15, Batch: 30,Loss: -1.687,Avg.Loss: -1.383,LR: 4.76E-04]Training epoch 15:  20%|█▉        | 30/153 [00:00<00:02, 52.31it/s, Epoch: 15, Batch: 30,Loss: -1.687,Avg.Loss: -1.383,LR: 4.76E-04]Training epoch 15:  20%|█▉        | 30/153 [00:00<00:02, 52.31it/s, Epoch: 15, Batch: 31,Loss: -1.505,Avg.Loss: -1.387,LR: 4.76E-04]Training epoch 15:  20%|██        | 31/153 [00:00<00:02, 52.31it/s, Epoch: 15, Batch: 32,Loss: -1.290,Avg.Loss: -1.384,LR: 4.76E-04]Training epoch 15:  21%|██        | 32/153 [00:00<00:02, 52.31it/s, Epoch: 15, Batch: 33,Loss: -1.557,Avg.Loss: -1.389,LR: 4.75E-04]Training epoch 15:  22%|██▏       | 33/153 [00:00<00:02, 52.31it/s, Epoch: 15, Batch: 34,Loss: -1.808,Avg.Loss: -1.402,LR: 4.75E-04]Training epoch 15:  22%|██▏       | 34/153 [00:00<00:02, 52.31it/s, Epoch: 15, Batch: 35,Loss: -1.396,Avg.Loss: -1.402,LR: 4.75E-04]Training epoch 15:  23%|██▎       | 35/153 [00:00<00:02, 52.31it/s, Epoch: 15, Batch: 36,Loss: -1.456,Avg.Loss: -1.403,LR: 4.75E-04]Training epoch 15:  24%|██▎       | 36/153 [00:00<00:02, 52.64it/s, Epoch: 15, Batch: 36,Loss: -1.456,Avg.Loss: -1.403,LR: 4.75E-04]Training epoch 15:  24%|██▎       | 36/153 [00:00<00:02, 52.64it/s, Epoch: 15, Batch: 37,Loss: -1.655,Avg.Loss: -1.410,LR: 4.75E-04]Training epoch 15:  24%|██▍       | 37/153 [00:00<00:02, 52.64it/s, Epoch: 15, Batch: 38,Loss: -0.815,Avg.Loss: -1.394,LR: 4.75E-04]Training epoch 15:  25%|██▍       | 38/153 [00:00<00:02, 52.64it/s, Epoch: 15, Batch: 39,Loss: -1.062,Avg.Loss: -1.386,LR: 4.75E-04]Training epoch 15:  25%|██▌       | 39/153 [00:00<00:02, 52.64it/s, Epoch: 15, Batch: 40,Loss: -1.431,Avg.Loss: -1.387,LR: 4.75E-04]Training epoch 15:  26%|██▌       | 40/153 [00:00<00:02, 52.64it/s, Epoch: 15, Batch: 41,Loss: -1.553,Avg.Loss: -1.391,LR: 4.75E-04]Training epoch 15:  27%|██▋       | 41/153 [00:00<00:02, 52.64it/s, Epoch: 15, Batch: 42,Loss: -0.898,Avg.Loss: -1.379,LR: 4.75E-04]Training epoch 15:  27%|██▋       | 42/153 [00:00<00:02, 52.86it/s, Epoch: 15, Batch: 42,Loss: -0.898,Avg.Loss: -1.379,LR: 4.75E-04]Training epoch 15:  27%|██▋       | 42/153 [00:00<00:02, 52.86it/s, Epoch: 15, Batch: 43,Loss: -1.350,Avg.Loss: -1.378,LR: 4.75E-04]Training epoch 15:  28%|██▊       | 43/153 [00:00<00:02, 52.86it/s, Epoch: 15, Batch: 44,Loss: -0.928,Avg.Loss: -1.368,LR: 4.75E-04]Training epoch 15:  29%|██▉       | 44/153 [00:00<00:02, 52.86it/s, Epoch: 15, Batch: 45,Loss: -1.054,Avg.Loss: -1.361,LR: 4.75E-04]Training epoch 15:  29%|██▉       | 45/153 [00:00<00:02, 52.86it/s, Epoch: 15, Batch: 46,Loss: -1.088,Avg.Loss: -1.355,LR: 4.75E-04]Training epoch 15:  30%|███       | 46/153 [00:00<00:02, 52.86it/s, Epoch: 15, Batch: 47,Loss: -1.574,Avg.Loss: -1.360,LR: 4.75E-04]Training epoch 15:  31%|███       | 47/153 [00:00<00:02, 52.86it/s, Epoch: 15, Batch: 48,Loss: -1.295,Avg.Loss: -1.359,LR: 4.75E-04]Training epoch 15:  31%|███▏      | 48/153 [00:00<00:01, 52.95it/s, Epoch: 15, Batch: 48,Loss: -1.295,Avg.Loss: -1.359,LR: 4.75E-04]Training epoch 15:  31%|███▏      | 48/153 [00:00<00:01, 52.95it/s, Epoch: 15, Batch: 49,Loss: -1.418,Avg.Loss: -1.360,LR: 4.75E-04]Training epoch 15:  32%|███▏      | 49/153 [00:00<00:01, 52.95it/s, Epoch: 15, Batch: 50,Loss: -0.607,Avg.Loss: -1.345,LR: 4.75E-04]Training epoch 15:  33%|███▎      | 50/153 [00:00<00:01, 52.95it/s, Epoch: 15, Batch: 51,Loss: -1.104,Avg.Loss: -1.340,LR: 4.75E-04]Training epoch 15:  33%|███▎      | 51/153 [00:00<00:01, 52.95it/s, Epoch: 15, Batch: 52,Loss: -1.550,Avg.Loss: -1.344,LR: 4.75E-04]Training epoch 15:  34%|███▍      | 52/153 [00:00<00:01, 52.95it/s, Epoch: 15, Batch: 53,Loss: -0.862,Avg.Loss: -1.335,LR: 4.75E-04]Training epoch 15:  35%|███▍      | 53/153 [00:01<00:01, 52.95it/s, Epoch: 15, Batch: 54,Loss: 0.180,Avg.Loss: -1.307,LR: 4.75E-04] Training epoch 15:  35%|███▌      | 54/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 54,Loss: 0.180,Avg.Loss: -1.307,LR: 4.75E-04]Training epoch 15:  35%|███▌      | 54/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 55,Loss: -0.458,Avg.Loss: -1.291,LR: 4.75E-04]Training epoch 15:  36%|███▌      | 55/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 56,Loss: -0.099,Avg.Loss: -1.270,LR: 4.75E-04]Training epoch 15:  37%|███▋      | 56/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 57,Loss: -1.011,Avg.Loss: -1.266,LR: 4.75E-04]Training epoch 15:  37%|███▋      | 57/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 58,Loss: -1.440,Avg.Loss: -1.269,LR: 4.75E-04]Training epoch 15:  38%|███▊      | 58/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 59,Loss: -1.124,Avg.Loss: -1.266,LR: 4.75E-04]Training epoch 15:  39%|███▊      | 59/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 60,Loss: -1.529,Avg.Loss: -1.271,LR: 4.75E-04]Training epoch 15:  39%|███▉      | 60/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 60,Loss: -1.529,Avg.Loss: -1.271,LR: 4.75E-04]Training epoch 15:  39%|███▉      | 60/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 61,Loss: -0.866,Avg.Loss: -1.264,LR: 4.75E-04]Training epoch 15:  40%|███▉      | 61/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 62,Loss: -1.108,Avg.Loss: -1.261,LR: 4.75E-04]Training epoch 15:  41%|████      | 62/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 63,Loss: -1.644,Avg.Loss: -1.267,LR: 4.75E-04]Training epoch 15:  41%|████      | 63/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 64,Loss: -1.347,Avg.Loss: -1.269,LR: 4.75E-04]Training epoch 15:  42%|████▏     | 64/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 65,Loss: -1.528,Avg.Loss: -1.273,LR: 4.75E-04]Training epoch 15:  42%|████▏     | 65/153 [00:01<00:01, 52.85it/s, Epoch: 15, Batch: 66,Loss: -1.339,Avg.Loss: -1.274,LR: 4.75E-04]Training epoch 15:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 15, Batch: 66,Loss: -1.339,Avg.Loss: -1.274,LR: 4.75E-04]Training epoch 15:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 15, Batch: 67,Loss: -1.312,Avg.Loss: -1.274,LR: 4.75E-04]Training epoch 15:  44%|████▍     | 67/153 [00:01<00:01, 52.84it/s, Epoch: 15, Batch: 68,Loss: -1.114,Avg.Loss: -1.272,LR: 4.75E-04]Training epoch 15:  44%|████▍     | 68/153 [00:01<00:01, 52.84it/s, Epoch: 15, Batch: 69,Loss: -1.468,Avg.Loss: -1.275,LR: 4.75E-04]Training epoch 15:  45%|████▌     | 69/153 [00:01<00:01, 52.84it/s, Epoch: 15, Batch: 70,Loss: -1.716,Avg.Loss: -1.281,LR: 4.75E-04]Training epoch 15:  46%|████▌     | 70/153 [00:01<00:01, 52.84it/s, Epoch: 15, Batch: 71,Loss: -1.531,Avg.Loss: -1.285,LR: 4.75E-04]Training epoch 15:  46%|████▋     | 71/153 [00:01<00:01, 52.84it/s, Epoch: 15, Batch: 72,Loss: -1.669,Avg.Loss: -1.290,LR: 4.75E-04]Training epoch 15:  47%|████▋     | 72/153 [00:01<00:01, 52.97it/s, Epoch: 15, Batch: 72,Loss: -1.669,Avg.Loss: -1.290,LR: 4.75E-04]Training epoch 15:  47%|████▋     | 72/153 [00:01<00:01, 52.97it/s, Epoch: 15, Batch: 73,Loss: -1.414,Avg.Loss: -1.292,LR: 4.75E-04]Training epoch 15:  48%|████▊     | 73/153 [00:01<00:01, 52.97it/s, Epoch: 15, Batch: 74,Loss: -1.129,Avg.Loss: -1.289,LR: 4.75E-04]Training epoch 15:  48%|████▊     | 74/153 [00:01<00:01, 52.97it/s, Epoch: 15, Batch: 75,Loss: -0.829,Avg.Loss: -1.283,LR: 4.75E-04]Training epoch 15:  49%|████▉     | 75/153 [00:01<00:01, 52.97it/s, Epoch: 15, Batch: 76,Loss: -0.725,Avg.Loss: -1.276,LR: 4.75E-04]Training epoch 15:  50%|████▉     | 76/153 [00:01<00:01, 52.97it/s, Epoch: 15, Batch: 77,Loss: -1.281,Avg.Loss: -1.276,LR: 4.74E-04]Training epoch 15:  50%|█████     | 77/153 [00:01<00:01, 52.97it/s, Epoch: 15, Batch: 78,Loss: -0.920,Avg.Loss: -1.271,LR: 4.74E-04]Training epoch 15:  51%|█████     | 78/153 [00:01<00:01, 53.04it/s, Epoch: 15, Batch: 78,Loss: -0.920,Avg.Loss: -1.271,LR: 4.74E-04]Training epoch 15:  51%|█████     | 78/153 [00:01<00:01, 53.04it/s, Epoch: 15, Batch: 79,Loss: -1.614,Avg.Loss: -1.276,LR: 4.74E-04]Training epoch 15:  52%|█████▏    | 79/153 [00:01<00:01, 53.04it/s, Epoch: 15, Batch: 80,Loss: -1.422,Avg.Loss: -1.278,LR: 4.74E-04]Training epoch 15:  52%|█████▏    | 80/153 [00:01<00:01, 53.04it/s, Epoch: 15, Batch: 81,Loss: -1.402,Avg.Loss: -1.279,LR: 4.74E-04]Training epoch 15:  53%|█████▎    | 81/153 [00:01<00:01, 53.04it/s, Epoch: 15, Batch: 82,Loss: -1.235,Avg.Loss: -1.279,LR: 4.74E-04]Training epoch 15:  54%|█████▎    | 82/153 [00:01<00:01, 53.04it/s, Epoch: 15, Batch: 83,Loss: -0.952,Avg.Loss: -1.275,LR: 4.74E-04]Training epoch 15:  54%|█████▍    | 83/153 [00:01<00:01, 53.04it/s, Epoch: 15, Batch: 84,Loss: -1.176,Avg.Loss: -1.273,LR: 4.74E-04]Training epoch 15:  55%|█████▍    | 84/153 [00:01<00:01, 51.68it/s, Epoch: 15, Batch: 84,Loss: -1.176,Avg.Loss: -1.273,LR: 4.74E-04]Training epoch 15:  55%|█████▍    | 84/153 [00:01<00:01, 51.68it/s, Epoch: 15, Batch: 85,Loss: -1.302,Avg.Loss: -1.274,LR: 4.74E-04]Training epoch 15:  56%|█████▌    | 85/153 [00:01<00:01, 51.68it/s, Epoch: 15, Batch: 86,Loss: -0.789,Avg.Loss: -1.268,LR: 4.74E-04]Training epoch 15:  56%|█████▌    | 86/153 [00:01<00:01, 51.68it/s, Epoch: 15, Batch: 87,Loss: -0.616,Avg.Loss: -1.261,LR: 4.74E-04]Training epoch 15:  57%|█████▋    | 87/153 [00:01<00:01, 51.68it/s, Epoch: 15, Batch: 88,Loss: -1.040,Avg.Loss: -1.258,LR: 4.74E-04]Training epoch 15:  58%|█████▊    | 88/153 [00:01<00:01, 51.68it/s, Epoch: 15, Batch: 89,Loss: -1.182,Avg.Loss: -1.257,LR: 4.74E-04]Training epoch 15:  58%|█████▊    | 89/153 [00:01<00:01, 51.68it/s, Epoch: 15, Batch: 90,Loss: -1.736,Avg.Loss: -1.263,LR: 4.74E-04]Training epoch 15:  59%|█████▉    | 90/153 [00:01<00:01, 51.91it/s, Epoch: 15, Batch: 90,Loss: -1.736,Avg.Loss: -1.263,LR: 4.74E-04]Training epoch 15:  59%|█████▉    | 90/153 [00:01<00:01, 51.91it/s, Epoch: 15, Batch: 91,Loss: -1.418,Avg.Loss: -1.264,LR: 4.74E-04]Training epoch 15:  59%|█████▉    | 91/153 [00:01<00:01, 51.91it/s, Epoch: 15, Batch: 92,Loss: -1.468,Avg.Loss: -1.267,LR: 4.74E-04]Training epoch 15:  60%|██████    | 92/153 [00:01<00:01, 51.91it/s, Epoch: 15, Batch: 93,Loss: -1.501,Avg.Loss: -1.269,LR: 4.74E-04]Training epoch 15:  61%|██████    | 93/153 [00:01<00:01, 51.91it/s, Epoch: 15, Batch: 94,Loss: -1.761,Avg.Loss: -1.274,LR: 4.74E-04]Training epoch 15:  61%|██████▏   | 94/153 [00:01<00:01, 51.91it/s, Epoch: 15, Batch: 95,Loss: -1.243,Avg.Loss: -1.274,LR: 4.74E-04]Training epoch 15:  62%|██████▏   | 95/153 [00:01<00:01, 51.91it/s, Epoch: 15, Batch: 96,Loss: -1.956,Avg.Loss: -1.281,LR: 4.74E-04]Training epoch 15:  63%|██████▎   | 96/153 [00:01<00:01, 52.10it/s, Epoch: 15, Batch: 96,Loss: -1.956,Avg.Loss: -1.281,LR: 4.74E-04]Training epoch 15:  63%|██████▎   | 96/153 [00:01<00:01, 52.10it/s, Epoch: 15, Batch: 97,Loss: -1.826,Avg.Loss: -1.287,LR: 4.74E-04]Training epoch 15:  63%|██████▎   | 97/153 [00:01<00:01, 52.10it/s, Epoch: 15, Batch: 98,Loss: -1.569,Avg.Loss: -1.290,LR: 4.74E-04]Training epoch 15:  64%|██████▍   | 98/153 [00:01<00:01, 52.10it/s, Epoch: 15, Batch: 99,Loss: -1.603,Avg.Loss: -1.293,LR: 4.74E-04]Training epoch 15:  65%|██████▍   | 99/153 [00:01<00:01, 52.10it/s, Epoch: 15, Batch: 100,Loss: -1.274,Avg.Loss: -1.293,LR: 4.74E-04]Training epoch 15:  65%|██████▌   | 100/153 [00:01<00:01, 52.10it/s, Epoch: 15, Batch: 101,Loss: -1.814,Avg.Loss: -1.298,LR: 4.74E-04]Training epoch 15:  66%|██████▌   | 101/153 [00:01<00:00, 52.10it/s, Epoch: 15, Batch: 102,Loss: -1.125,Avg.Loss: -1.296,LR: 4.74E-04]Training epoch 15:  67%|██████▋   | 102/153 [00:01<00:00, 52.34it/s, Epoch: 15, Batch: 102,Loss: -1.125,Avg.Loss: -1.296,LR: 4.74E-04]Training epoch 15:  67%|██████▋   | 102/153 [00:01<00:00, 52.34it/s, Epoch: 15, Batch: 103,Loss: -0.763,Avg.Loss: -1.291,LR: 4.74E-04]Training epoch 15:  67%|██████▋   | 103/153 [00:01<00:00, 52.34it/s, Epoch: 15, Batch: 104,Loss: 0.284,Avg.Loss: -1.276,LR: 4.74E-04] Training epoch 15:  68%|██████▊   | 104/153 [00:01<00:00, 52.34it/s, Epoch: 15, Batch: 105,Loss: -0.274,Avg.Loss: -1.266,LR: 4.74E-04]Training epoch 15:  69%|██████▊   | 105/153 [00:02<00:00, 52.34it/s, Epoch: 15, Batch: 106,Loss: -1.233,Avg.Loss: -1.266,LR: 4.74E-04]Training epoch 15:  69%|██████▉   | 106/153 [00:02<00:00, 52.34it/s, Epoch: 15, Batch: 107,Loss: -1.706,Avg.Loss: -1.270,LR: 4.74E-04]Training epoch 15:  70%|██████▉   | 107/153 [00:02<00:00, 52.34it/s, Epoch: 15, Batch: 108,Loss: -0.806,Avg.Loss: -1.266,LR: 4.74E-04]Training epoch 15:  71%|███████   | 108/153 [00:02<00:00, 52.45it/s, Epoch: 15, Batch: 108,Loss: -0.806,Avg.Loss: -1.266,LR: 4.74E-04]Training epoch 15:  71%|███████   | 108/153 [00:02<00:00, 52.45it/s, Epoch: 15, Batch: 109,Loss: -1.384,Avg.Loss: -1.267,LR: 4.74E-04]Training epoch 15:  71%|███████   | 109/153 [00:02<00:00, 52.45it/s, Epoch: 15, Batch: 110,Loss: -0.578,Avg.Loss: -1.260,LR: 4.74E-04]Training epoch 15:  72%|███████▏  | 110/153 [00:02<00:00, 52.45it/s, Epoch: 15, Batch: 111,Loss: -1.131,Avg.Loss: -1.259,LR: 4.74E-04]Training epoch 15:  73%|███████▎  | 111/153 [00:02<00:00, 52.45it/s, Epoch: 15, Batch: 112,Loss: -1.406,Avg.Loss: -1.261,LR: 4.74E-04]Training epoch 15:  73%|███████▎  | 112/153 [00:02<00:00, 52.45it/s, Epoch: 15, Batch: 113,Loss: -1.439,Avg.Loss: -1.262,LR: 4.74E-04]Training epoch 15:  74%|███████▍  | 113/153 [00:02<00:00, 52.45it/s, Epoch: 15, Batch: 114,Loss: -1.323,Avg.Loss: -1.263,LR: 4.74E-04]Training epoch 15:  75%|███████▍  | 114/153 [00:02<00:00, 52.63it/s, Epoch: 15, Batch: 114,Loss: -1.323,Avg.Loss: -1.263,LR: 4.74E-04]Training epoch 15:  75%|███████▍  | 114/153 [00:02<00:00, 52.63it/s, Epoch: 15, Batch: 115,Loss: -1.078,Avg.Loss: -1.261,LR: 4.74E-04]Training epoch 15:  75%|███████▌  | 115/153 [00:02<00:00, 52.63it/s, Epoch: 15, Batch: 116,Loss: -1.147,Avg.Loss: -1.260,LR: 4.74E-04]Training epoch 15:  76%|███████▌  | 116/153 [00:02<00:00, 52.63it/s, Epoch: 15, Batch: 117,Loss: -1.290,Avg.Loss: -1.260,LR: 4.74E-04]Training epoch 15:  76%|███████▋  | 117/153 [00:02<00:00, 52.63it/s, Epoch: 15, Batch: 118,Loss: -0.760,Avg.Loss: -1.256,LR: 4.74E-04]Training epoch 15:  77%|███████▋  | 118/153 [00:02<00:00, 52.63it/s, Epoch: 15, Batch: 119,Loss: -1.026,Avg.Loss: -1.254,LR: 4.74E-04]Training epoch 15:  78%|███████▊  | 119/153 [00:02<00:00, 52.63it/s, Epoch: 15, Batch: 120,Loss: -1.188,Avg.Loss: -1.254,LR: 4.74E-04]Training epoch 15:  78%|███████▊  | 120/153 [00:02<00:00, 52.76it/s, Epoch: 15, Batch: 120,Loss: -1.188,Avg.Loss: -1.254,LR: 4.74E-04]Training epoch 15:  78%|███████▊  | 120/153 [00:02<00:00, 52.76it/s, Epoch: 15, Batch: 121,Loss: -0.611,Avg.Loss: -1.248,LR: 4.73E-04]Training epoch 15:  79%|███████▉  | 121/153 [00:02<00:00, 52.76it/s, Epoch: 15, Batch: 122,Loss: -0.931,Avg.Loss: -1.246,LR: 4.73E-04]Training epoch 15:  80%|███████▉  | 122/153 [00:02<00:00, 52.76it/s, Epoch: 15, Batch: 123,Loss: -1.234,Avg.Loss: -1.246,LR: 4.73E-04]Training epoch 15:  80%|████████  | 123/153 [00:02<00:00, 52.76it/s, Epoch: 15, Batch: 124,Loss: -1.084,Avg.Loss: -1.244,LR: 4.73E-04]Training epoch 15:  81%|████████  | 124/153 [00:02<00:00, 52.76it/s, Epoch: 15, Batch: 125,Loss: -0.327,Avg.Loss: -1.237,LR: 4.73E-04]Training epoch 15:  82%|████████▏ | 125/153 [00:02<00:00, 52.76it/s, Epoch: 15, Batch: 126,Loss: -0.021,Avg.Loss: -1.227,LR: 4.73E-04]Training epoch 15:  82%|████████▏ | 126/153 [00:02<00:00, 52.95it/s, Epoch: 15, Batch: 126,Loss: -0.021,Avg.Loss: -1.227,LR: 4.73E-04]Training epoch 15:  82%|████████▏ | 126/153 [00:02<00:00, 52.95it/s, Epoch: 15, Batch: 127,Loss: -1.195,Avg.Loss: -1.227,LR: 4.73E-04]Training epoch 15:  83%|████████▎ | 127/153 [00:02<00:00, 52.95it/s, Epoch: 15, Batch: 128,Loss: -1.255,Avg.Loss: -1.227,LR: 4.73E-04]Training epoch 15:  84%|████████▎ | 128/153 [00:02<00:00, 52.95it/s, Epoch: 15, Batch: 129,Loss: -1.232,Avg.Loss: -1.227,LR: 4.73E-04]Training epoch 15:  84%|████████▍ | 129/153 [00:02<00:00, 52.95it/s, Epoch: 15, Batch: 130,Loss: -1.148,Avg.Loss: -1.227,LR: 4.73E-04]Training epoch 15:  85%|████████▍ | 130/153 [00:02<00:00, 52.95it/s, Epoch: 15, Batch: 131,Loss: -0.752,Avg.Loss: -1.223,LR: 4.73E-04]Training epoch 15:  86%|████████▌ | 131/153 [00:02<00:00, 52.95it/s, Epoch: 15, Batch: 132,Loss: -1.346,Avg.Loss: -1.224,LR: 4.73E-04]Training epoch 15:  86%|████████▋ | 132/153 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 132,Loss: -1.346,Avg.Loss: -1.224,LR: 4.73E-04]Training epoch 15:  86%|████████▋ | 132/153 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 133,Loss: -1.475,Avg.Loss: -1.226,LR: 4.73E-04]Training epoch 15:  87%|████████▋ | 133/153 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 134,Loss: -1.369,Avg.Loss: -1.227,LR: 4.73E-04]Training epoch 15:  88%|████████▊ | 134/153 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 135,Loss: -1.262,Avg.Loss: -1.227,LR: 4.73E-04]Training epoch 15:  88%|████████▊ | 135/153 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 136,Loss: -0.894,Avg.Loss: -1.225,LR: 4.73E-04]Training epoch 15:  89%|████████▉ | 136/153 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 137,Loss: -0.814,Avg.Loss: -1.222,LR: 4.73E-04]Training epoch 15:  90%|████████▉ | 137/153 [00:02<00:00, 53.16it/s, Epoch: 15, Batch: 138,Loss: -0.795,Avg.Loss: -1.219,LR: 4.73E-04]Training epoch 15:  90%|█████████ | 138/153 [00:02<00:00, 53.10it/s, Epoch: 15, Batch: 138,Loss: -0.795,Avg.Loss: -1.219,LR: 4.73E-04]Training epoch 15:  90%|█████████ | 138/153 [00:02<00:00, 53.10it/s, Epoch: 15, Batch: 139,Loss: -1.410,Avg.Loss: -1.220,LR: 4.73E-04]Training epoch 15:  91%|█████████ | 139/153 [00:02<00:00, 53.10it/s, Epoch: 15, Batch: 140,Loss: -1.681,Avg.Loss: -1.223,LR: 4.73E-04]Training epoch 15:  92%|█████████▏| 140/153 [00:02<00:00, 53.10it/s, Epoch: 15, Batch: 141,Loss: -1.414,Avg.Loss: -1.225,LR: 4.73E-04]Training epoch 15:  92%|█████████▏| 141/153 [00:02<00:00, 53.10it/s, Epoch: 15, Batch: 142,Loss: -0.498,Avg.Loss: -1.220,LR: 4.73E-04]Training epoch 15:  93%|█████████▎| 142/153 [00:02<00:00, 53.10it/s, Epoch: 15, Batch: 143,Loss: -0.888,Avg.Loss: -1.217,LR: 4.73E-04]Training epoch 15:  93%|█████████▎| 143/153 [00:02<00:00, 53.10it/s, Epoch: 15, Batch: 144,Loss: -0.785,Avg.Loss: -1.214,LR: 4.73E-04]Training epoch 15:  94%|█████████▍| 144/153 [00:02<00:00, 53.20it/s, Epoch: 15, Batch: 144,Loss: -0.785,Avg.Loss: -1.214,LR: 4.73E-04]Training epoch 15:  94%|█████████▍| 144/153 [00:02<00:00, 53.20it/s, Epoch: 15, Batch: 145,Loss: -1.069,Avg.Loss: -1.213,LR: 4.73E-04]Training epoch 15:  95%|█████████▍| 145/153 [00:02<00:00, 53.20it/s, Epoch: 15, Batch: 146,Loss: -1.452,Avg.Loss: -1.215,LR: 4.73E-04]Training epoch 15:  95%|█████████▌| 146/153 [00:02<00:00, 53.20it/s, Epoch: 15, Batch: 147,Loss: -1.113,Avg.Loss: -1.214,LR: 4.73E-04]Training epoch 15:  96%|█████████▌| 147/153 [00:02<00:00, 53.20it/s, Epoch: 15, Batch: 148,Loss: -1.211,Avg.Loss: -1.214,LR: 4.73E-04]Training epoch 15:  97%|█████████▋| 148/153 [00:02<00:00, 53.20it/s, Epoch: 15, Batch: 149,Loss: -1.350,Avg.Loss: -1.215,LR: 4.73E-04]Training epoch 15:  97%|█████████▋| 149/153 [00:02<00:00, 53.20it/s, Epoch: 15, Batch: 150,Loss: -1.698,Avg.Loss: -1.218,LR: 4.73E-04]Training epoch 15:  98%|█████████▊| 150/153 [00:02<00:00, 53.27it/s, Epoch: 15, Batch: 150,Loss: -1.698,Avg.Loss: -1.218,LR: 4.73E-04]Training epoch 15:  98%|█████████▊| 150/153 [00:02<00:00, 53.27it/s, Epoch: 15, Batch: 151,Loss: -1.002,Avg.Loss: -1.217,LR: 4.73E-04]Training epoch 15:  99%|█████████▊| 151/153 [00:02<00:00, 53.27it/s, Epoch: 15, Batch: 152,Loss: -1.465,Avg.Loss: -1.219,LR: 4.73E-04]Training epoch 15:  99%|█████████▉| 152/153 [00:02<00:00, 53.27it/s, Epoch: 15, Batch: 153,Loss: -1.291,Avg.Loss: -1.219,LR: 4.73E-04]Training epoch 15: 100%|██████████| 153/153 [00:02<00:00, 52.79it/s, Epoch: 15, Batch: 153,Loss: -1.291,Avg.Loss: -1.219,LR: 4.73E-04]
Training epoch 16:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 16:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 16, Batch: 1,Loss: -1.057,Avg.Loss: -1.057,LR: 4.73E-04]Training epoch 16:   1%|          | 1/153 [00:00<00:05, 27.05it/s, Epoch: 16, Batch: 2,Loss: -1.213,Avg.Loss: -1.135,LR: 4.73E-04]Training epoch 16:   1%|▏         | 2/153 [00:00<00:03, 40.12it/s, Epoch: 16, Batch: 3,Loss: -0.414,Avg.Loss: -0.894,LR: 4.73E-04]Training epoch 16:   2%|▏         | 3/153 [00:00<00:03, 44.84it/s, Epoch: 16, Batch: 4,Loss: -0.598,Avg.Loss: -0.820,LR: 4.73E-04]Training epoch 16:   3%|▎         | 4/153 [00:00<00:03, 47.92it/s, Epoch: 16, Batch: 5,Loss: -1.510,Avg.Loss: -0.958,LR: 4.73E-04]Training epoch 16:   3%|▎         | 5/153 [00:00<00:02, 49.76it/s, Epoch: 16, Batch: 6,Loss: -1.202,Avg.Loss: -0.999,LR: 4.73E-04]Training epoch 16:   4%|▍         | 6/153 [00:00<00:02, 59.62it/s, Epoch: 16, Batch: 6,Loss: -1.202,Avg.Loss: -0.999,LR: 4.73E-04]Training epoch 16:   4%|▍         | 6/153 [00:00<00:02, 59.62it/s, Epoch: 16, Batch: 7,Loss: -1.348,Avg.Loss: -1.049,LR: 4.73E-04]Training epoch 16:   5%|▍         | 7/153 [00:00<00:02, 59.62it/s, Epoch: 16, Batch: 8,Loss: -1.060,Avg.Loss: -1.050,LR: 4.73E-04]Training epoch 16:   5%|▌         | 8/153 [00:00<00:02, 59.62it/s, Epoch: 16, Batch: 9,Loss: -1.100,Avg.Loss: -1.056,LR: 4.73E-04]Training epoch 16:   6%|▌         | 9/153 [00:00<00:02, 59.62it/s, Epoch: 16, Batch: 10,Loss: -1.475,Avg.Loss: -1.098,LR: 4.73E-04]Training epoch 16:   7%|▋         | 10/153 [00:00<00:02, 59.62it/s, Epoch: 16, Batch: 11,Loss: -1.355,Avg.Loss: -1.121,LR: 4.72E-04]Training epoch 16:   7%|▋         | 11/153 [00:00<00:02, 59.62it/s, Epoch: 16, Batch: 12,Loss: -1.793,Avg.Loss: -1.177,LR: 4.72E-04]Training epoch 16:   8%|▊         | 12/153 [00:00<00:02, 55.48it/s, Epoch: 16, Batch: 12,Loss: -1.793,Avg.Loss: -1.177,LR: 4.72E-04]Training epoch 16:   8%|▊         | 12/153 [00:00<00:02, 55.48it/s, Epoch: 16, Batch: 13,Loss: -1.681,Avg.Loss: -1.216,LR: 4.72E-04]Training epoch 16:   8%|▊         | 13/153 [00:00<00:02, 55.48it/s, Epoch: 16, Batch: 14,Loss: -1.764,Avg.Loss: -1.255,LR: 4.72E-04]Training epoch 16:   9%|▉         | 14/153 [00:00<00:02, 55.48it/s, Epoch: 16, Batch: 15,Loss: -1.525,Avg.Loss: -1.273,LR: 4.72E-04]Training epoch 16:  10%|▉         | 15/153 [00:00<00:02, 55.48it/s, Epoch: 16, Batch: 16,Loss: -1.088,Avg.Loss: -1.261,LR: 4.72E-04]Training epoch 16:  10%|█         | 16/153 [00:00<00:02, 55.48it/s, Epoch: 16, Batch: 17,Loss: -1.541,Avg.Loss: -1.278,LR: 4.72E-04]Training epoch 16:  11%|█         | 17/153 [00:00<00:02, 55.48it/s, Epoch: 16, Batch: 18,Loss: -1.808,Avg.Loss: -1.307,LR: 4.72E-04]Training epoch 16:  12%|█▏        | 18/153 [00:00<00:02, 54.32it/s, Epoch: 16, Batch: 18,Loss: -1.808,Avg.Loss: -1.307,LR: 4.72E-04]Training epoch 16:  12%|█▏        | 18/153 [00:00<00:02, 54.32it/s, Epoch: 16, Batch: 19,Loss: -1.575,Avg.Loss: -1.321,LR: 4.72E-04]Training epoch 16:  12%|█▏        | 19/153 [00:00<00:02, 54.32it/s, Epoch: 16, Batch: 20,Loss: -1.441,Avg.Loss: -1.327,LR: 4.72E-04]Training epoch 16:  13%|█▎        | 20/153 [00:00<00:02, 54.32it/s, Epoch: 16, Batch: 21,Loss: -1.580,Avg.Loss: -1.339,LR: 4.72E-04]Training epoch 16:  14%|█▎        | 21/153 [00:00<00:02, 54.32it/s, Epoch: 16, Batch: 22,Loss: -1.695,Avg.Loss: -1.355,LR: 4.72E-04]Training epoch 16:  14%|█▍        | 22/153 [00:00<00:02, 54.32it/s, Epoch: 16, Batch: 23,Loss: -2.045,Avg.Loss: -1.385,LR: 4.72E-04]Training epoch 16:  15%|█▌        | 23/153 [00:00<00:02, 54.32it/s, Epoch: 16, Batch: 24,Loss: -1.700,Avg.Loss: -1.399,LR: 4.72E-04]Training epoch 16:  16%|█▌        | 24/153 [00:00<00:02, 53.79it/s, Epoch: 16, Batch: 24,Loss: -1.700,Avg.Loss: -1.399,LR: 4.72E-04]Training epoch 16:  16%|█▌        | 24/153 [00:00<00:02, 53.79it/s, Epoch: 16, Batch: 25,Loss: -1.731,Avg.Loss: -1.412,LR: 4.72E-04]Training epoch 16:  16%|█▋        | 25/153 [00:00<00:02, 53.79it/s, Epoch: 16, Batch: 26,Loss: -1.573,Avg.Loss: -1.418,LR: 4.72E-04]Training epoch 16:  17%|█▋        | 26/153 [00:00<00:02, 53.79it/s, Epoch: 16, Batch: 27,Loss: -1.510,Avg.Loss: -1.421,LR: 4.72E-04]Training epoch 16:  18%|█▊        | 27/153 [00:00<00:02, 53.79it/s, Epoch: 16, Batch: 28,Loss: -0.905,Avg.Loss: -1.403,LR: 4.72E-04]Training epoch 16:  18%|█▊        | 28/153 [00:00<00:02, 53.79it/s, Epoch: 16, Batch: 29,Loss: -1.145,Avg.Loss: -1.394,LR: 4.72E-04]Training epoch 16:  19%|█▉        | 29/153 [00:00<00:02, 53.79it/s, Epoch: 16, Batch: 30,Loss: -0.669,Avg.Loss: -1.370,LR: 4.72E-04]Training epoch 16:  20%|█▉        | 30/153 [00:00<00:02, 53.13it/s, Epoch: 16, Batch: 30,Loss: -0.669,Avg.Loss: -1.370,LR: 4.72E-04]Training epoch 16:  20%|█▉        | 30/153 [00:00<00:02, 53.13it/s, Epoch: 16, Batch: 31,Loss: -1.395,Avg.Loss: -1.371,LR: 4.72E-04]Training epoch 16:  20%|██        | 31/153 [00:00<00:02, 53.13it/s, Epoch: 16, Batch: 32,Loss: -1.220,Avg.Loss: -1.366,LR: 4.72E-04]Training epoch 16:  21%|██        | 32/153 [00:00<00:02, 53.13it/s, Epoch: 16, Batch: 33,Loss: -1.237,Avg.Loss: -1.362,LR: 4.72E-04]Training epoch 16:  22%|██▏       | 33/153 [00:00<00:02, 53.13it/s, Epoch: 16, Batch: 34,Loss: -1.845,Avg.Loss: -1.376,LR: 4.72E-04]Training epoch 16:  22%|██▏       | 34/153 [00:00<00:02, 53.13it/s, Epoch: 16, Batch: 35,Loss: -1.341,Avg.Loss: -1.375,LR: 4.72E-04]Training epoch 16:  23%|██▎       | 35/153 [00:00<00:02, 53.13it/s, Epoch: 16, Batch: 36,Loss: -1.658,Avg.Loss: -1.383,LR: 4.72E-04]Training epoch 16:  24%|██▎       | 36/153 [00:00<00:02, 52.93it/s, Epoch: 16, Batch: 36,Loss: -1.658,Avg.Loss: -1.383,LR: 4.72E-04]Training epoch 16:  24%|██▎       | 36/153 [00:00<00:02, 52.93it/s, Epoch: 16, Batch: 37,Loss: -1.272,Avg.Loss: -1.380,LR: 4.72E-04]Training epoch 16:  24%|██▍       | 37/153 [00:00<00:02, 52.93it/s, Epoch: 16, Batch: 38,Loss: -1.949,Avg.Loss: -1.395,LR: 4.72E-04]Training epoch 16:  25%|██▍       | 38/153 [00:00<00:02, 52.93it/s, Epoch: 16, Batch: 39,Loss: -1.317,Avg.Loss: -1.393,LR: 4.72E-04]Training epoch 16:  25%|██▌       | 39/153 [00:00<00:02, 52.93it/s, Epoch: 16, Batch: 40,Loss: -0.700,Avg.Loss: -1.376,LR: 4.72E-04]Training epoch 16:  26%|██▌       | 40/153 [00:00<00:02, 52.93it/s, Epoch: 16, Batch: 41,Loss: -0.950,Avg.Loss: -1.365,LR: 4.72E-04]Training epoch 16:  27%|██▋       | 41/153 [00:00<00:02, 52.93it/s, Epoch: 16, Batch: 42,Loss: -1.581,Avg.Loss: -1.371,LR: 4.72E-04]Training epoch 16:  27%|██▋       | 42/153 [00:00<00:02, 53.18it/s, Epoch: 16, Batch: 42,Loss: -1.581,Avg.Loss: -1.371,LR: 4.72E-04]Training epoch 16:  27%|██▋       | 42/153 [00:00<00:02, 53.18it/s, Epoch: 16, Batch: 43,Loss: -1.205,Avg.Loss: -1.367,LR: 4.72E-04]Training epoch 16:  28%|██▊       | 43/153 [00:00<00:02, 53.18it/s, Epoch: 16, Batch: 44,Loss: -0.876,Avg.Loss: -1.356,LR: 4.72E-04]Training epoch 16:  29%|██▉       | 44/153 [00:00<00:02, 53.18it/s, Epoch: 16, Batch: 45,Loss: -0.182,Avg.Loss: -1.330,LR: 4.72E-04]Training epoch 16:  29%|██▉       | 45/153 [00:00<00:02, 53.18it/s, Epoch: 16, Batch: 46,Loss: -0.332,Avg.Loss: -1.308,LR: 4.72E-04]Training epoch 16:  30%|███       | 46/153 [00:00<00:02, 53.18it/s, Epoch: 16, Batch: 47,Loss: 0.350,Avg.Loss: -1.273,LR: 4.72E-04] Training epoch 16:  31%|███       | 47/153 [00:00<00:01, 53.18it/s, Epoch: 16, Batch: 48,Loss: -0.809,Avg.Loss: -1.263,LR: 4.72E-04]Training epoch 16:  31%|███▏      | 48/153 [00:00<00:01, 53.26it/s, Epoch: 16, Batch: 48,Loss: -0.809,Avg.Loss: -1.263,LR: 4.72E-04]Training epoch 16:  31%|███▏      | 48/153 [00:00<00:01, 53.26it/s, Epoch: 16, Batch: 49,Loss: -1.255,Avg.Loss: -1.263,LR: 4.72E-04]Training epoch 16:  32%|███▏      | 49/153 [00:00<00:01, 53.26it/s, Epoch: 16, Batch: 50,Loss: -1.647,Avg.Loss: -1.270,LR: 4.72E-04]Training epoch 16:  33%|███▎      | 50/153 [00:00<00:01, 53.26it/s, Epoch: 16, Batch: 51,Loss: -1.572,Avg.Loss: -1.276,LR: 4.72E-04]Training epoch 16:  33%|███▎      | 51/153 [00:00<00:01, 53.26it/s, Epoch: 16, Batch: 52,Loss: -1.420,Avg.Loss: -1.279,LR: 4.72E-04]Training epoch 16:  34%|███▍      | 52/153 [00:00<00:01, 53.26it/s, Epoch: 16, Batch: 53,Loss: -1.592,Avg.Loss: -1.285,LR: 4.72E-04]Training epoch 16:  35%|███▍      | 53/153 [00:01<00:01, 53.26it/s, Epoch: 16, Batch: 54,Loss: -1.891,Avg.Loss: -1.296,LR: 4.71E-04]Training epoch 16:  35%|███▌      | 54/153 [00:01<00:01, 53.02it/s, Epoch: 16, Batch: 54,Loss: -1.891,Avg.Loss: -1.296,LR: 4.71E-04]Training epoch 16:  35%|███▌      | 54/153 [00:01<00:01, 53.02it/s, Epoch: 16, Batch: 55,Loss: -1.539,Avg.Loss: -1.301,LR: 4.71E-04]Training epoch 16:  36%|███▌      | 55/153 [00:01<00:01, 53.02it/s, Epoch: 16, Batch: 56,Loss: -1.698,Avg.Loss: -1.308,LR: 4.71E-04]Training epoch 16:  37%|███▋      | 56/153 [00:01<00:01, 53.02it/s, Epoch: 16, Batch: 57,Loss: -1.589,Avg.Loss: -1.313,LR: 4.71E-04]Training epoch 16:  37%|███▋      | 57/153 [00:01<00:01, 53.02it/s, Epoch: 16, Batch: 58,Loss: -1.725,Avg.Loss: -1.320,LR: 4.71E-04]Training epoch 16:  38%|███▊      | 58/153 [00:01<00:01, 53.02it/s, Epoch: 16, Batch: 59,Loss: -1.856,Avg.Loss: -1.329,LR: 4.71E-04]Training epoch 16:  39%|███▊      | 59/153 [00:01<00:01, 53.02it/s, Epoch: 16, Batch: 60,Loss: -1.465,Avg.Loss: -1.331,LR: 4.71E-04]Training epoch 16:  39%|███▉      | 60/153 [00:01<00:01, 53.14it/s, Epoch: 16, Batch: 60,Loss: -1.465,Avg.Loss: -1.331,LR: 4.71E-04]Training epoch 16:  39%|███▉      | 60/153 [00:01<00:01, 53.14it/s, Epoch: 16, Batch: 61,Loss: -1.716,Avg.Loss: -1.337,LR: 4.71E-04]Training epoch 16:  40%|███▉      | 61/153 [00:01<00:01, 53.14it/s, Epoch: 16, Batch: 62,Loss: -1.556,Avg.Loss: -1.341,LR: 4.71E-04]Training epoch 16:  41%|████      | 62/153 [00:01<00:01, 53.14it/s, Epoch: 16, Batch: 63,Loss: -1.118,Avg.Loss: -1.337,LR: 4.71E-04]Training epoch 16:  41%|████      | 63/153 [00:01<00:01, 53.14it/s, Epoch: 16, Batch: 64,Loss: -1.489,Avg.Loss: -1.340,LR: 4.71E-04]Training epoch 16:  42%|████▏     | 64/153 [00:01<00:01, 53.14it/s, Epoch: 16, Batch: 65,Loss: -1.165,Avg.Loss: -1.337,LR: 4.71E-04]Training epoch 16:  42%|████▏     | 65/153 [00:01<00:01, 53.14it/s, Epoch: 16, Batch: 66,Loss: -1.034,Avg.Loss: -1.333,LR: 4.71E-04]Training epoch 16:  43%|████▎     | 66/153 [00:01<00:01, 53.08it/s, Epoch: 16, Batch: 66,Loss: -1.034,Avg.Loss: -1.333,LR: 4.71E-04]Training epoch 16:  43%|████▎     | 66/153 [00:01<00:01, 53.08it/s, Epoch: 16, Batch: 67,Loss: -1.250,Avg.Loss: -1.331,LR: 4.71E-04]Training epoch 16:  44%|████▍     | 67/153 [00:01<00:01, 53.08it/s, Epoch: 16, Batch: 68,Loss: -1.477,Avg.Loss: -1.333,LR: 4.71E-04]Training epoch 16:  44%|████▍     | 68/153 [00:01<00:01, 53.08it/s, Epoch: 16, Batch: 69,Loss: -1.482,Avg.Loss: -1.336,LR: 4.71E-04]Training epoch 16:  45%|████▌     | 69/153 [00:01<00:01, 53.08it/s, Epoch: 16, Batch: 70,Loss: -1.653,Avg.Loss: -1.340,LR: 4.71E-04]Training epoch 16:  46%|████▌     | 70/153 [00:01<00:01, 53.08it/s, Epoch: 16, Batch: 71,Loss: -1.956,Avg.Loss: -1.349,LR: 4.71E-04]Training epoch 16:  46%|████▋     | 71/153 [00:01<00:01, 53.08it/s, Epoch: 16, Batch: 72,Loss: -1.520,Avg.Loss: -1.351,LR: 4.71E-04]Training epoch 16:  47%|████▋     | 72/153 [00:01<00:01, 53.17it/s, Epoch: 16, Batch: 72,Loss: -1.520,Avg.Loss: -1.351,LR: 4.71E-04]Training epoch 16:  47%|████▋     | 72/153 [00:01<00:01, 53.17it/s, Epoch: 16, Batch: 73,Loss: -1.297,Avg.Loss: -1.350,LR: 4.71E-04]Training epoch 16:  48%|████▊     | 73/153 [00:01<00:01, 53.17it/s, Epoch: 16, Batch: 74,Loss: -1.418,Avg.Loss: -1.351,LR: 4.71E-04]Training epoch 16:  48%|████▊     | 74/153 [00:01<00:01, 53.17it/s, Epoch: 16, Batch: 75,Loss: -1.939,Avg.Loss: -1.359,LR: 4.71E-04]Training epoch 16:  49%|████▉     | 75/153 [00:01<00:01, 53.17it/s, Epoch: 16, Batch: 76,Loss: -0.985,Avg.Loss: -1.354,LR: 4.71E-04]Training epoch 16:  50%|████▉     | 76/153 [00:01<00:01, 53.17it/s, Epoch: 16, Batch: 77,Loss: -0.928,Avg.Loss: -1.349,LR: 4.71E-04]Training epoch 16:  50%|█████     | 77/153 [00:01<00:01, 53.17it/s, Epoch: 16, Batch: 78,Loss: -1.376,Avg.Loss: -1.349,LR: 4.71E-04]Training epoch 16:  51%|█████     | 78/153 [00:01<00:01, 53.18it/s, Epoch: 16, Batch: 78,Loss: -1.376,Avg.Loss: -1.349,LR: 4.71E-04]Training epoch 16:  51%|█████     | 78/153 [00:01<00:01, 53.18it/s, Epoch: 16, Batch: 79,Loss: -1.331,Avg.Loss: -1.349,LR: 4.71E-04]Training epoch 16:  52%|█████▏    | 79/153 [00:01<00:01, 53.18it/s, Epoch: 16, Batch: 80,Loss: -1.539,Avg.Loss: -1.351,LR: 4.71E-04]Training epoch 16:  52%|█████▏    | 80/153 [00:01<00:01, 53.18it/s, Epoch: 16, Batch: 81,Loss: -1.154,Avg.Loss: -1.349,LR: 4.71E-04]Training epoch 16:  53%|█████▎    | 81/153 [00:01<00:01, 53.18it/s, Epoch: 16, Batch: 82,Loss: -1.382,Avg.Loss: -1.349,LR: 4.71E-04]Training epoch 16:  54%|█████▎    | 82/153 [00:01<00:01, 53.18it/s, Epoch: 16, Batch: 83,Loss: -1.832,Avg.Loss: -1.355,LR: 4.71E-04]Training epoch 16:  54%|█████▍    | 83/153 [00:01<00:01, 53.18it/s, Epoch: 16, Batch: 84,Loss: -1.441,Avg.Loss: -1.356,LR: 4.71E-04]Training epoch 16:  55%|█████▍    | 84/153 [00:01<00:01, 53.38it/s, Epoch: 16, Batch: 84,Loss: -1.441,Avg.Loss: -1.356,LR: 4.71E-04]Training epoch 16:  55%|█████▍    | 84/153 [00:01<00:01, 53.38it/s, Epoch: 16, Batch: 85,Loss: -0.942,Avg.Loss: -1.351,LR: 4.71E-04]Training epoch 16:  56%|█████▌    | 85/153 [00:01<00:01, 53.38it/s, Epoch: 16, Batch: 86,Loss: -1.563,Avg.Loss: -1.354,LR: 4.71E-04]Training epoch 16:  56%|█████▌    | 86/153 [00:01<00:01, 53.38it/s, Epoch: 16, Batch: 87,Loss: -1.559,Avg.Loss: -1.356,LR: 4.71E-04]Training epoch 16:  57%|█████▋    | 87/153 [00:01<00:01, 53.38it/s, Epoch: 16, Batch: 88,Loss: -1.476,Avg.Loss: -1.357,LR: 4.71E-04]Training epoch 16:  58%|█████▊    | 88/153 [00:01<00:01, 53.38it/s, Epoch: 16, Batch: 89,Loss: -1.669,Avg.Loss: -1.361,LR: 4.71E-04]Training epoch 16:  58%|█████▊    | 89/153 [00:01<00:01, 53.38it/s, Epoch: 16, Batch: 90,Loss: -1.707,Avg.Loss: -1.365,LR: 4.71E-04]Training epoch 16:  59%|█████▉    | 90/153 [00:01<00:01, 53.28it/s, Epoch: 16, Batch: 90,Loss: -1.707,Avg.Loss: -1.365,LR: 4.71E-04]Training epoch 16:  59%|█████▉    | 90/153 [00:01<00:01, 53.28it/s, Epoch: 16, Batch: 91,Loss: -1.578,Avg.Loss: -1.367,LR: 4.71E-04]Training epoch 16:  59%|█████▉    | 91/153 [00:01<00:01, 53.28it/s, Epoch: 16, Batch: 92,Loss: -1.852,Avg.Loss: -1.372,LR: 4.71E-04]Training epoch 16:  60%|██████    | 92/153 [00:01<00:01, 53.28it/s, Epoch: 16, Batch: 93,Loss: -1.772,Avg.Loss: -1.377,LR: 4.71E-04]Training epoch 16:  61%|██████    | 93/153 [00:01<00:01, 53.28it/s, Epoch: 16, Batch: 94,Loss: -1.314,Avg.Loss: -1.376,LR: 4.71E-04]Training epoch 16:  61%|██████▏   | 94/153 [00:01<00:01, 53.28it/s, Epoch: 16, Batch: 95,Loss: -1.621,Avg.Loss: -1.378,LR: 4.70E-04]Training epoch 16:  62%|██████▏   | 95/153 [00:01<00:01, 53.28it/s, Epoch: 16, Batch: 96,Loss: -1.557,Avg.Loss: -1.380,LR: 4.70E-04]Training epoch 16:  63%|██████▎   | 96/153 [00:01<00:01, 53.23it/s, Epoch: 16, Batch: 96,Loss: -1.557,Avg.Loss: -1.380,LR: 4.70E-04]Training epoch 16:  63%|██████▎   | 96/153 [00:01<00:01, 53.23it/s, Epoch: 16, Batch: 97,Loss: -1.413,Avg.Loss: -1.381,LR: 4.70E-04]Training epoch 16:  63%|██████▎   | 97/153 [00:01<00:01, 53.23it/s, Epoch: 16, Batch: 98,Loss: -1.971,Avg.Loss: -1.387,LR: 4.70E-04]Training epoch 16:  64%|██████▍   | 98/153 [00:01<00:01, 53.23it/s, Epoch: 16, Batch: 99,Loss: -1.656,Avg.Loss: -1.389,LR: 4.70E-04]Training epoch 16:  65%|██████▍   | 99/153 [00:01<00:01, 53.23it/s, Epoch: 16, Batch: 100,Loss: -1.429,Avg.Loss: -1.390,LR: 4.70E-04]Training epoch 16:  65%|██████▌   | 100/153 [00:01<00:00, 53.23it/s, Epoch: 16, Batch: 101,Loss: -1.644,Avg.Loss: -1.392,LR: 4.70E-04]Training epoch 16:  66%|██████▌   | 101/153 [00:01<00:00, 53.23it/s, Epoch: 16, Batch: 102,Loss: -1.467,Avg.Loss: -1.393,LR: 4.70E-04]Training epoch 16:  67%|██████▋   | 102/153 [00:01<00:00, 53.25it/s, Epoch: 16, Batch: 102,Loss: -1.467,Avg.Loss: -1.393,LR: 4.70E-04]Training epoch 16:  67%|██████▋   | 102/153 [00:01<00:00, 53.25it/s, Epoch: 16, Batch: 103,Loss: -1.341,Avg.Loss: -1.393,LR: 4.70E-04]Training epoch 16:  67%|██████▋   | 103/153 [00:01<00:00, 53.25it/s, Epoch: 16, Batch: 104,Loss: -1.558,Avg.Loss: -1.394,LR: 4.70E-04]Training epoch 16:  68%|██████▊   | 104/153 [00:01<00:00, 53.25it/s, Epoch: 16, Batch: 105,Loss: -1.781,Avg.Loss: -1.398,LR: 4.70E-04]Training epoch 16:  69%|██████▊   | 105/153 [00:01<00:00, 53.25it/s, Epoch: 16, Batch: 106,Loss: -1.189,Avg.Loss: -1.396,LR: 4.70E-04]Training epoch 16:  69%|██████▉   | 106/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 107,Loss: -1.567,Avg.Loss: -1.397,LR: 4.70E-04]Training epoch 16:  70%|██████▉   | 107/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 108,Loss: -1.789,Avg.Loss: -1.401,LR: 4.70E-04]Training epoch 16:  71%|███████   | 108/153 [00:02<00:00, 53.16it/s, Epoch: 16, Batch: 108,Loss: -1.789,Avg.Loss: -1.401,LR: 4.70E-04]Training epoch 16:  71%|███████   | 108/153 [00:02<00:00, 53.16it/s, Epoch: 16, Batch: 109,Loss: -1.975,Avg.Loss: -1.406,LR: 4.70E-04]Training epoch 16:  71%|███████   | 109/153 [00:02<00:00, 53.16it/s, Epoch: 16, Batch: 110,Loss: -1.824,Avg.Loss: -1.410,LR: 4.70E-04]Training epoch 16:  72%|███████▏  | 110/153 [00:02<00:00, 53.16it/s, Epoch: 16, Batch: 111,Loss: -1.521,Avg.Loss: -1.411,LR: 4.70E-04]Training epoch 16:  73%|███████▎  | 111/153 [00:02<00:00, 53.16it/s, Epoch: 16, Batch: 112,Loss: -1.587,Avg.Loss: -1.413,LR: 4.70E-04]Training epoch 16:  73%|███████▎  | 112/153 [00:02<00:00, 53.16it/s, Epoch: 16, Batch: 113,Loss: -1.785,Avg.Loss: -1.416,LR: 4.70E-04]Training epoch 16:  74%|███████▍  | 113/153 [00:02<00:00, 53.16it/s, Epoch: 16, Batch: 114,Loss: -1.633,Avg.Loss: -1.418,LR: 4.70E-04]Training epoch 16:  75%|███████▍  | 114/153 [00:02<00:00, 53.27it/s, Epoch: 16, Batch: 114,Loss: -1.633,Avg.Loss: -1.418,LR: 4.70E-04]Training epoch 16:  75%|███████▍  | 114/153 [00:02<00:00, 53.27it/s, Epoch: 16, Batch: 115,Loss: -2.259,Avg.Loss: -1.425,LR: 4.70E-04]Training epoch 16:  75%|███████▌  | 115/153 [00:02<00:00, 53.27it/s, Epoch: 16, Batch: 116,Loss: -1.616,Avg.Loss: -1.427,LR: 4.70E-04]Training epoch 16:  76%|███████▌  | 116/153 [00:02<00:00, 53.27it/s, Epoch: 16, Batch: 117,Loss: -1.380,Avg.Loss: -1.426,LR: 4.70E-04]Training epoch 16:  76%|███████▋  | 117/153 [00:02<00:00, 53.27it/s, Epoch: 16, Batch: 118,Loss: -1.580,Avg.Loss: -1.428,LR: 4.70E-04]Training epoch 16:  77%|███████▋  | 118/153 [00:02<00:00, 53.27it/s, Epoch: 16, Batch: 119,Loss: -1.755,Avg.Loss: -1.431,LR: 4.70E-04]Training epoch 16:  78%|███████▊  | 119/153 [00:02<00:00, 53.27it/s, Epoch: 16, Batch: 120,Loss: -1.629,Avg.Loss: -1.432,LR: 4.70E-04]Training epoch 16:  78%|███████▊  | 120/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 120,Loss: -1.629,Avg.Loss: -1.432,LR: 4.70E-04]Training epoch 16:  78%|███████▊  | 120/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 121,Loss: -1.360,Avg.Loss: -1.432,LR: 4.70E-04]Training epoch 16:  79%|███████▉  | 121/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 122,Loss: -2.025,Avg.Loss: -1.436,LR: 4.70E-04]Training epoch 16:  80%|███████▉  | 122/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 123,Loss: -1.847,Avg.Loss: -1.440,LR: 4.70E-04]Training epoch 16:  80%|████████  | 123/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 124,Loss: -1.303,Avg.Loss: -1.439,LR: 4.70E-04]Training epoch 16:  81%|████████  | 124/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 125,Loss: -1.660,Avg.Loss: -1.440,LR: 4.70E-04]Training epoch 16:  82%|████████▏ | 125/153 [00:02<00:00, 53.25it/s, Epoch: 16, Batch: 126,Loss: -2.124,Avg.Loss: -1.446,LR: 4.70E-04]Training epoch 16:  82%|████████▏ | 126/153 [00:02<00:00, 53.41it/s, Epoch: 16, Batch: 126,Loss: -2.124,Avg.Loss: -1.446,LR: 4.70E-04]Training epoch 16:  82%|████████▏ | 126/153 [00:02<00:00, 53.41it/s, Epoch: 16, Batch: 127,Loss: -1.963,Avg.Loss: -1.450,LR: 4.70E-04]Training epoch 16:  83%|████████▎ | 127/153 [00:02<00:00, 53.41it/s, Epoch: 16, Batch: 128,Loss: -1.427,Avg.Loss: -1.450,LR: 4.70E-04]Training epoch 16:  84%|████████▎ | 128/153 [00:02<00:00, 53.41it/s, Epoch: 16, Batch: 129,Loss: -1.645,Avg.Loss: -1.451,LR: 4.70E-04]Training epoch 16:  84%|████████▍ | 129/153 [00:02<00:00, 53.41it/s, Epoch: 16, Batch: 130,Loss: -1.831,Avg.Loss: -1.454,LR: 4.70E-04]Training epoch 16:  85%|████████▍ | 130/153 [00:02<00:00, 53.41it/s, Epoch: 16, Batch: 131,Loss: -1.792,Avg.Loss: -1.457,LR: 4.70E-04]Training epoch 16:  86%|████████▌ | 131/153 [00:02<00:00, 53.41it/s, Epoch: 16, Batch: 132,Loss: -1.385,Avg.Loss: -1.456,LR: 4.70E-04]Training epoch 16:  86%|████████▋ | 132/153 [00:02<00:00, 53.35it/s, Epoch: 16, Batch: 132,Loss: -1.385,Avg.Loss: -1.456,LR: 4.70E-04]Training epoch 16:  86%|████████▋ | 132/153 [00:02<00:00, 53.35it/s, Epoch: 16, Batch: 133,Loss: -1.210,Avg.Loss: -1.454,LR: 4.70E-04]Training epoch 16:  87%|████████▋ | 133/153 [00:02<00:00, 53.35it/s, Epoch: 16, Batch: 134,Loss: -1.693,Avg.Loss: -1.456,LR: 4.70E-04]Training epoch 16:  88%|████████▊ | 134/153 [00:02<00:00, 53.35it/s, Epoch: 16, Batch: 135,Loss: -1.783,Avg.Loss: -1.459,LR: 4.70E-04]Training epoch 16:  88%|████████▊ | 135/153 [00:02<00:00, 53.35it/s, Epoch: 16, Batch: 136,Loss: -2.119,Avg.Loss: -1.463,LR: 4.69E-04]Training epoch 16:  89%|████████▉ | 136/153 [00:02<00:00, 53.35it/s, Epoch: 16, Batch: 137,Loss: -2.160,Avg.Loss: -1.469,LR: 4.69E-04]Training epoch 16:  90%|████████▉ | 137/153 [00:02<00:00, 53.35it/s, Epoch: 16, Batch: 138,Loss: -1.603,Avg.Loss: -1.469,LR: 4.69E-04]Training epoch 16:  90%|█████████ | 138/153 [00:02<00:00, 53.37it/s, Epoch: 16, Batch: 138,Loss: -1.603,Avg.Loss: -1.469,LR: 4.69E-04]Training epoch 16:  90%|█████████ | 138/153 [00:02<00:00, 53.37it/s, Epoch: 16, Batch: 139,Loss: -1.379,Avg.Loss: -1.469,LR: 4.69E-04]Training epoch 16:  91%|█████████ | 139/153 [00:02<00:00, 53.37it/s, Epoch: 16, Batch: 140,Loss: -0.844,Avg.Loss: -1.464,LR: 4.69E-04]Training epoch 16:  92%|█████████▏| 140/153 [00:02<00:00, 53.37it/s, Epoch: 16, Batch: 141,Loss: -1.692,Avg.Loss: -1.466,LR: 4.69E-04]Training epoch 16:  92%|█████████▏| 141/153 [00:02<00:00, 53.37it/s, Epoch: 16, Batch: 142,Loss: -1.295,Avg.Loss: -1.465,LR: 4.69E-04]Training epoch 16:  93%|█████████▎| 142/153 [00:02<00:00, 53.37it/s, Epoch: 16, Batch: 143,Loss: -1.291,Avg.Loss: -1.464,LR: 4.69E-04]Training epoch 16:  93%|█████████▎| 143/153 [00:02<00:00, 53.37it/s, Epoch: 16, Batch: 144,Loss: -1.731,Avg.Loss: -1.465,LR: 4.69E-04]Training epoch 16:  94%|█████████▍| 144/153 [00:02<00:00, 53.49it/s, Epoch: 16, Batch: 144,Loss: -1.731,Avg.Loss: -1.465,LR: 4.69E-04]Training epoch 16:  94%|█████████▍| 144/153 [00:02<00:00, 53.49it/s, Epoch: 16, Batch: 145,Loss: -1.131,Avg.Loss: -1.463,LR: 4.69E-04]Training epoch 16:  95%|█████████▍| 145/153 [00:02<00:00, 53.49it/s, Epoch: 16, Batch: 146,Loss: -1.634,Avg.Loss: -1.464,LR: 4.69E-04]Training epoch 16:  95%|█████████▌| 146/153 [00:02<00:00, 53.49it/s, Epoch: 16, Batch: 147,Loss: -1.853,Avg.Loss: -1.467,LR: 4.69E-04]Training epoch 16:  96%|█████████▌| 147/153 [00:02<00:00, 53.49it/s, Epoch: 16, Batch: 148,Loss: -1.746,Avg.Loss: -1.469,LR: 4.69E-04]Training epoch 16:  97%|█████████▋| 148/153 [00:02<00:00, 53.49it/s, Epoch: 16, Batch: 149,Loss: -2.002,Avg.Loss: -1.472,LR: 4.69E-04]Training epoch 16:  97%|█████████▋| 149/153 [00:02<00:00, 53.49it/s, Epoch: 16, Batch: 150,Loss: -1.753,Avg.Loss: -1.474,LR: 4.69E-04]Training epoch 16:  98%|█████████▊| 150/153 [00:02<00:00, 53.33it/s, Epoch: 16, Batch: 150,Loss: -1.753,Avg.Loss: -1.474,LR: 4.69E-04]Training epoch 16:  98%|█████████▊| 150/153 [00:02<00:00, 53.33it/s, Epoch: 16, Batch: 151,Loss: -1.784,Avg.Loss: -1.476,LR: 4.69E-04]Training epoch 16:  99%|█████████▊| 151/153 [00:02<00:00, 53.33it/s, Epoch: 16, Batch: 152,Loss: -1.453,Avg.Loss: -1.476,LR: 4.69E-04]Training epoch 16:  99%|█████████▉| 152/153 [00:02<00:00, 53.33it/s, Epoch: 16, Batch: 153,Loss: -1.461,Avg.Loss: -1.476,LR: 4.69E-04]Training epoch 16: 100%|██████████| 153/153 [00:02<00:00, 53.34it/s, Epoch: 16, Batch: 153,Loss: -1.461,Avg.Loss: -1.476,LR: 4.69E-04]
Training epoch 17:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 17:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 17, Batch: 1,Loss: -1.813,Avg.Loss: -1.813,LR: 4.69E-04]Training epoch 17:   1%|          | 1/153 [00:00<00:06, 25.08it/s, Epoch: 17, Batch: 2,Loss: -1.997,Avg.Loss: -1.905,LR: 4.69E-04]Training epoch 17:   1%|▏         | 2/153 [00:00<00:04, 35.43it/s, Epoch: 17, Batch: 3,Loss: -1.906,Avg.Loss: -1.905,LR: 4.69E-04]Training epoch 17:   2%|▏         | 3/153 [00:00<00:03, 40.84it/s, Epoch: 17, Batch: 4,Loss: -2.071,Avg.Loss: -1.947,LR: 4.69E-04]Training epoch 17:   3%|▎         | 4/153 [00:00<00:03, 44.39it/s, Epoch: 17, Batch: 5,Loss: -1.543,Avg.Loss: -1.866,LR: 4.69E-04]Training epoch 17:   3%|▎         | 5/153 [00:00<00:03, 46.52it/s, Epoch: 17, Batch: 6,Loss: -1.553,Avg.Loss: -1.814,LR: 4.69E-04]Training epoch 17:   4%|▍         | 6/153 [00:00<00:02, 55.73it/s, Epoch: 17, Batch: 6,Loss: -1.553,Avg.Loss: -1.814,LR: 4.69E-04]Training epoch 17:   4%|▍         | 6/153 [00:00<00:02, 55.73it/s, Epoch: 17, Batch: 7,Loss: -1.835,Avg.Loss: -1.817,LR: 4.69E-04]Training epoch 17:   5%|▍         | 7/153 [00:00<00:02, 55.73it/s, Epoch: 17, Batch: 8,Loss: -1.502,Avg.Loss: -1.778,LR: 4.69E-04]Training epoch 17:   5%|▌         | 8/153 [00:00<00:02, 55.73it/s, Epoch: 17, Batch: 9,Loss: -1.644,Avg.Loss: -1.763,LR: 4.69E-04]Training epoch 17:   6%|▌         | 9/153 [00:00<00:02, 55.73it/s, Epoch: 17, Batch: 10,Loss: -0.897,Avg.Loss: -1.676,LR: 4.69E-04]Training epoch 17:   7%|▋         | 10/153 [00:00<00:02, 55.73it/s, Epoch: 17, Batch: 11,Loss: -0.689,Avg.Loss: -1.586,LR: 4.69E-04]Training epoch 17:   7%|▋         | 11/153 [00:00<00:02, 55.73it/s, Epoch: 17, Batch: 12,Loss: -0.675,Avg.Loss: -1.510,LR: 4.69E-04]Training epoch 17:   8%|▊         | 12/153 [00:00<00:02, 53.59it/s, Epoch: 17, Batch: 12,Loss: -0.675,Avg.Loss: -1.510,LR: 4.69E-04]Training epoch 17:   8%|▊         | 12/153 [00:00<00:02, 53.59it/s, Epoch: 17, Batch: 13,Loss: -1.877,Avg.Loss: -1.539,LR: 4.69E-04]Training epoch 17:   8%|▊         | 13/153 [00:00<00:02, 53.59it/s, Epoch: 17, Batch: 14,Loss: -1.700,Avg.Loss: -1.550,LR: 4.69E-04]Training epoch 17:   9%|▉         | 14/153 [00:00<00:02, 53.59it/s, Epoch: 17, Batch: 15,Loss: -2.015,Avg.Loss: -1.581,LR: 4.69E-04]Training epoch 17:  10%|▉         | 15/153 [00:00<00:02, 53.59it/s, Epoch: 17, Batch: 16,Loss: -1.830,Avg.Loss: -1.597,LR: 4.69E-04]Training epoch 17:  10%|█         | 16/153 [00:00<00:02, 53.59it/s, Epoch: 17, Batch: 17,Loss: -1.535,Avg.Loss: -1.593,LR: 4.69E-04]Training epoch 17:  11%|█         | 17/153 [00:00<00:02, 53.59it/s, Epoch: 17, Batch: 18,Loss: -2.081,Avg.Loss: -1.620,LR: 4.69E-04]Training epoch 17:  12%|█▏        | 18/153 [00:00<00:02, 53.02it/s, Epoch: 17, Batch: 18,Loss: -2.081,Avg.Loss: -1.620,LR: 4.69E-04]Training epoch 17:  12%|█▏        | 18/153 [00:00<00:02, 53.02it/s, Epoch: 17, Batch: 19,Loss: -0.748,Avg.Loss: -1.574,LR: 4.69E-04]Training epoch 17:  12%|█▏        | 19/153 [00:00<00:02, 53.02it/s, Epoch: 17, Batch: 20,Loss: -0.059,Avg.Loss: -1.499,LR: 4.69E-04]Training epoch 17:  13%|█▎        | 20/153 [00:00<00:02, 53.02it/s, Epoch: 17, Batch: 21,Loss: -1.547,Avg.Loss: -1.501,LR: 4.69E-04]Training epoch 17:  14%|█▎        | 21/153 [00:00<00:02, 53.02it/s, Epoch: 17, Batch: 22,Loss: -1.888,Avg.Loss: -1.518,LR: 4.69E-04]Training epoch 17:  14%|█▍        | 22/153 [00:00<00:02, 53.02it/s, Epoch: 17, Batch: 23,Loss: -0.410,Avg.Loss: -1.470,LR: 4.69E-04]Training epoch 17:  15%|█▌        | 23/153 [00:00<00:02, 53.02it/s, Epoch: 17, Batch: 24,Loss: 1.617,Avg.Loss: -1.342,LR: 4.68E-04] Training epoch 17:  16%|█▌        | 24/153 [00:00<00:02, 52.44it/s, Epoch: 17, Batch: 24,Loss: 1.617,Avg.Loss: -1.342,LR: 4.68E-04]Training epoch 17:  16%|█▌        | 24/153 [00:00<00:02, 52.44it/s, Epoch: 17, Batch: 25,Loss: 1.861,Avg.Loss: -1.213,LR: 4.68E-04]Training epoch 17:  16%|█▋        | 25/153 [00:00<00:02, 52.44it/s, Epoch: 17, Batch: 26,Loss: -0.819,Avg.Loss: -1.198,LR: 4.68E-04]Training epoch 17:  17%|█▋        | 26/153 [00:00<00:02, 52.44it/s, Epoch: 17, Batch: 27,Loss: -1.216,Avg.Loss: -1.199,LR: 4.68E-04]Training epoch 17:  18%|█▊        | 27/153 [00:00<00:02, 52.44it/s, Epoch: 17, Batch: 28,Loss: -1.133,Avg.Loss: -1.197,LR: 4.68E-04]Training epoch 17:  18%|█▊        | 28/153 [00:00<00:02, 52.44it/s, Epoch: 17, Batch: 29,Loss: -1.327,Avg.Loss: -1.201,LR: 4.68E-04]Training epoch 17:  19%|█▉        | 29/153 [00:00<00:02, 52.44it/s, Epoch: 17, Batch: 30,Loss: -1.404,Avg.Loss: -1.208,LR: 4.68E-04]Training epoch 17:  20%|█▉        | 30/153 [00:00<00:02, 51.53it/s, Epoch: 17, Batch: 30,Loss: -1.404,Avg.Loss: -1.208,LR: 4.68E-04]Training epoch 17:  20%|█▉        | 30/153 [00:00<00:02, 51.53it/s, Epoch: 17, Batch: 31,Loss: -1.268,Avg.Loss: -1.210,LR: 4.68E-04]Training epoch 17:  20%|██        | 31/153 [00:00<00:02, 51.53it/s, Epoch: 17, Batch: 32,Loss: -1.162,Avg.Loss: -1.208,LR: 4.68E-04]Training epoch 17:  21%|██        | 32/153 [00:00<00:02, 51.53it/s, Epoch: 17, Batch: 33,Loss: -1.669,Avg.Loss: -1.222,LR: 4.68E-04]Training epoch 17:  22%|██▏       | 33/153 [00:00<00:02, 51.53it/s, Epoch: 17, Batch: 34,Loss: -1.582,Avg.Loss: -1.233,LR: 4.68E-04]Training epoch 17:  22%|██▏       | 34/153 [00:00<00:02, 51.53it/s, Epoch: 17, Batch: 35,Loss: -0.953,Avg.Loss: -1.225,LR: 4.68E-04]Training epoch 17:  23%|██▎       | 35/153 [00:00<00:02, 51.53it/s, Epoch: 17, Batch: 36,Loss: -1.458,Avg.Loss: -1.231,LR: 4.68E-04]Training epoch 17:  24%|██▎       | 36/153 [00:00<00:02, 52.03it/s, Epoch: 17, Batch: 36,Loss: -1.458,Avg.Loss: -1.231,LR: 4.68E-04]Training epoch 17:  24%|██▎       | 36/153 [00:00<00:02, 52.03it/s, Epoch: 17, Batch: 37,Loss: -1.616,Avg.Loss: -1.242,LR: 4.68E-04]Training epoch 17:  24%|██▍       | 37/153 [00:00<00:02, 52.03it/s, Epoch: 17, Batch: 38,Loss: -1.167,Avg.Loss: -1.240,LR: 4.68E-04]Training epoch 17:  25%|██▍       | 38/153 [00:00<00:02, 52.03it/s, Epoch: 17, Batch: 39,Loss: -1.702,Avg.Loss: -1.252,LR: 4.68E-04]Training epoch 17:  25%|██▌       | 39/153 [00:00<00:02, 52.03it/s, Epoch: 17, Batch: 40,Loss: -1.850,Avg.Loss: -1.267,LR: 4.68E-04]Training epoch 17:  26%|██▌       | 40/153 [00:00<00:02, 52.03it/s, Epoch: 17, Batch: 41,Loss: -1.665,Avg.Loss: -1.276,LR: 4.68E-04]Training epoch 17:  27%|██▋       | 41/153 [00:00<00:02, 52.03it/s, Epoch: 17, Batch: 42,Loss: -1.233,Avg.Loss: -1.275,LR: 4.68E-04]Training epoch 17:  27%|██▋       | 42/153 [00:00<00:02, 52.50it/s, Epoch: 17, Batch: 42,Loss: -1.233,Avg.Loss: -1.275,LR: 4.68E-04]Training epoch 17:  27%|██▋       | 42/153 [00:00<00:02, 52.50it/s, Epoch: 17, Batch: 43,Loss: -0.985,Avg.Loss: -1.269,LR: 4.68E-04]Training epoch 17:  28%|██▊       | 43/153 [00:00<00:02, 52.50it/s, Epoch: 17, Batch: 44,Loss: -1.246,Avg.Loss: -1.268,LR: 4.68E-04]Training epoch 17:  29%|██▉       | 44/153 [00:00<00:02, 52.50it/s, Epoch: 17, Batch: 45,Loss: -1.465,Avg.Loss: -1.272,LR: 4.68E-04]Training epoch 17:  29%|██▉       | 45/153 [00:00<00:02, 52.50it/s, Epoch: 17, Batch: 46,Loss: -1.228,Avg.Loss: -1.271,LR: 4.68E-04]Training epoch 17:  30%|███       | 46/153 [00:00<00:02, 52.50it/s, Epoch: 17, Batch: 47,Loss: -1.648,Avg.Loss: -1.279,LR: 4.68E-04]Training epoch 17:  31%|███       | 47/153 [00:00<00:02, 52.50it/s, Epoch: 17, Batch: 48,Loss: -2.071,Avg.Loss: -1.296,LR: 4.68E-04]Training epoch 17:  31%|███▏      | 48/153 [00:00<00:01, 52.70it/s, Epoch: 17, Batch: 48,Loss: -2.071,Avg.Loss: -1.296,LR: 4.68E-04]Training epoch 17:  31%|███▏      | 48/153 [00:00<00:01, 52.70it/s, Epoch: 17, Batch: 49,Loss: -1.618,Avg.Loss: -1.303,LR: 4.68E-04]Training epoch 17:  32%|███▏      | 49/153 [00:00<00:01, 52.70it/s, Epoch: 17, Batch: 50,Loss: -1.199,Avg.Loss: -1.300,LR: 4.68E-04]Training epoch 17:  33%|███▎      | 50/153 [00:00<00:01, 52.70it/s, Epoch: 17, Batch: 51,Loss: -1.565,Avg.Loss: -1.306,LR: 4.68E-04]Training epoch 17:  33%|███▎      | 51/153 [00:00<00:01, 52.70it/s, Epoch: 17, Batch: 52,Loss: -1.473,Avg.Loss: -1.309,LR: 4.68E-04]Training epoch 17:  34%|███▍      | 52/153 [00:01<00:01, 52.70it/s, Epoch: 17, Batch: 53,Loss: -1.318,Avg.Loss: -1.309,LR: 4.68E-04]Training epoch 17:  35%|███▍      | 53/153 [00:01<00:01, 52.70it/s, Epoch: 17, Batch: 54,Loss: -1.735,Avg.Loss: -1.317,LR: 4.68E-04]Training epoch 17:  35%|███▌      | 54/153 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 54,Loss: -1.735,Avg.Loss: -1.317,LR: 4.68E-04]Training epoch 17:  35%|███▌      | 54/153 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 55,Loss: -1.706,Avg.Loss: -1.324,LR: 4.68E-04]Training epoch 17:  36%|███▌      | 55/153 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 56,Loss: -1.172,Avg.Loss: -1.321,LR: 4.68E-04]Training epoch 17:  37%|███▋      | 56/153 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 57,Loss: -1.755,Avg.Loss: -1.329,LR: 4.68E-04]Training epoch 17:  37%|███▋      | 57/153 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 58,Loss: -1.424,Avg.Loss: -1.331,LR: 4.68E-04]Training epoch 17:  38%|███▊      | 58/153 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 59,Loss: -1.109,Avg.Loss: -1.327,LR: 4.68E-04]Training epoch 17:  39%|███▊      | 59/153 [00:01<00:01, 53.01it/s, Epoch: 17, Batch: 60,Loss: -1.664,Avg.Loss: -1.332,LR: 4.68E-04]Training epoch 17:  39%|███▉      | 60/153 [00:01<00:01, 52.97it/s, Epoch: 17, Batch: 60,Loss: -1.664,Avg.Loss: -1.332,LR: 4.68E-04]Training epoch 17:  39%|███▉      | 60/153 [00:01<00:01, 52.97it/s, Epoch: 17, Batch: 61,Loss: -1.813,Avg.Loss: -1.340,LR: 4.68E-04]Training epoch 17:  40%|███▉      | 61/153 [00:01<00:01, 52.97it/s, Epoch: 17, Batch: 62,Loss: -1.571,Avg.Loss: -1.344,LR: 4.68E-04]Training epoch 17:  41%|████      | 62/153 [00:01<00:01, 52.97it/s, Epoch: 17, Batch: 63,Loss: -1.193,Avg.Loss: -1.342,LR: 4.68E-04]Training epoch 17:  41%|████      | 63/153 [00:01<00:01, 52.97it/s, Epoch: 17, Batch: 64,Loss: -1.463,Avg.Loss: -1.343,LR: 4.67E-04]Training epoch 17:  42%|████▏     | 64/153 [00:01<00:01, 52.97it/s, Epoch: 17, Batch: 65,Loss: -2.036,Avg.Loss: -1.354,LR: 4.67E-04]Training epoch 17:  42%|████▏     | 65/153 [00:01<00:01, 52.97it/s, Epoch: 17, Batch: 66,Loss: -1.523,Avg.Loss: -1.357,LR: 4.67E-04]Training epoch 17:  43%|████▎     | 66/153 [00:01<00:01, 52.90it/s, Epoch: 17, Batch: 66,Loss: -1.523,Avg.Loss: -1.357,LR: 4.67E-04]Training epoch 17:  43%|████▎     | 66/153 [00:01<00:01, 52.90it/s, Epoch: 17, Batch: 67,Loss: -1.463,Avg.Loss: -1.358,LR: 4.67E-04]Training epoch 17:  44%|████▍     | 67/153 [00:01<00:01, 52.90it/s, Epoch: 17, Batch: 68,Loss: -1.958,Avg.Loss: -1.367,LR: 4.67E-04]Training epoch 17:  44%|████▍     | 68/153 [00:01<00:01, 52.90it/s, Epoch: 17, Batch: 69,Loss: -1.558,Avg.Loss: -1.370,LR: 4.67E-04]Training epoch 17:  45%|████▌     | 69/153 [00:01<00:01, 52.90it/s, Epoch: 17, Batch: 70,Loss: -0.602,Avg.Loss: -1.359,LR: 4.67E-04]Training epoch 17:  46%|████▌     | 70/153 [00:01<00:01, 52.90it/s, Epoch: 17, Batch: 71,Loss: -1.112,Avg.Loss: -1.355,LR: 4.67E-04]Training epoch 17:  46%|████▋     | 71/153 [00:01<00:01, 52.90it/s, Epoch: 17, Batch: 72,Loss: -1.358,Avg.Loss: -1.355,LR: 4.67E-04]Training epoch 17:  47%|████▋     | 72/153 [00:01<00:01, 53.02it/s, Epoch: 17, Batch: 72,Loss: -1.358,Avg.Loss: -1.355,LR: 4.67E-04]Training epoch 17:  47%|████▋     | 72/153 [00:01<00:01, 53.02it/s, Epoch: 17, Batch: 73,Loss: -1.862,Avg.Loss: -1.362,LR: 4.67E-04]Training epoch 17:  48%|████▊     | 73/153 [00:01<00:01, 53.02it/s, Epoch: 17, Batch: 74,Loss: -1.355,Avg.Loss: -1.362,LR: 4.67E-04]Training epoch 17:  48%|████▊     | 74/153 [00:01<00:01, 53.02it/s, Epoch: 17, Batch: 75,Loss: -0.908,Avg.Loss: -1.356,LR: 4.67E-04]Training epoch 17:  49%|████▉     | 75/153 [00:01<00:01, 53.02it/s, Epoch: 17, Batch: 76,Loss: -1.537,Avg.Loss: -1.359,LR: 4.67E-04]Training epoch 17:  50%|████▉     | 76/153 [00:01<00:01, 53.02it/s, Epoch: 17, Batch: 77,Loss: -1.499,Avg.Loss: -1.360,LR: 4.67E-04]Training epoch 17:  50%|█████     | 77/153 [00:01<00:01, 53.02it/s, Epoch: 17, Batch: 78,Loss: -1.867,Avg.Loss: -1.367,LR: 4.67E-04]Training epoch 17:  51%|█████     | 78/153 [00:01<00:01, 53.07it/s, Epoch: 17, Batch: 78,Loss: -1.867,Avg.Loss: -1.367,LR: 4.67E-04]Training epoch 17:  51%|█████     | 78/153 [00:01<00:01, 53.07it/s, Epoch: 17, Batch: 79,Loss: -1.380,Avg.Loss: -1.367,LR: 4.67E-04]Training epoch 17:  52%|█████▏    | 79/153 [00:01<00:01, 53.07it/s, Epoch: 17, Batch: 80,Loss: -1.622,Avg.Loss: -1.370,LR: 4.67E-04]Training epoch 17:  52%|█████▏    | 80/153 [00:01<00:01, 53.07it/s, Epoch: 17, Batch: 81,Loss: -1.834,Avg.Loss: -1.376,LR: 4.67E-04]Training epoch 17:  53%|█████▎    | 81/153 [00:01<00:01, 53.07it/s, Epoch: 17, Batch: 82,Loss: -2.143,Avg.Loss: -1.385,LR: 4.67E-04]Training epoch 17:  54%|█████▎    | 82/153 [00:01<00:01, 53.07it/s, Epoch: 17, Batch: 83,Loss: -1.324,Avg.Loss: -1.385,LR: 4.67E-04]Training epoch 17:  54%|█████▍    | 83/153 [00:01<00:01, 53.07it/s, Epoch: 17, Batch: 84,Loss: -1.660,Avg.Loss: -1.388,LR: 4.67E-04]Training epoch 17:  55%|█████▍    | 84/153 [00:01<00:01, 52.91it/s, Epoch: 17, Batch: 84,Loss: -1.660,Avg.Loss: -1.388,LR: 4.67E-04]Training epoch 17:  55%|█████▍    | 84/153 [00:01<00:01, 52.91it/s, Epoch: 17, Batch: 85,Loss: -1.856,Avg.Loss: -1.393,LR: 4.67E-04]Training epoch 17:  56%|█████▌    | 85/153 [00:01<00:01, 52.91it/s, Epoch: 17, Batch: 86,Loss: -1.912,Avg.Loss: -1.399,LR: 4.67E-04]Training epoch 17:  56%|█████▌    | 86/153 [00:01<00:01, 52.91it/s, Epoch: 17, Batch: 87,Loss: -1.419,Avg.Loss: -1.400,LR: 4.67E-04]Training epoch 17:  57%|█████▋    | 87/153 [00:01<00:01, 52.91it/s, Epoch: 17, Batch: 88,Loss: -1.402,Avg.Loss: -1.400,LR: 4.67E-04]Training epoch 17:  58%|█████▊    | 88/153 [00:01<00:01, 52.91it/s, Epoch: 17, Batch: 89,Loss: -1.333,Avg.Loss: -1.399,LR: 4.67E-04]Training epoch 17:  58%|█████▊    | 89/153 [00:01<00:01, 52.91it/s, Epoch: 17, Batch: 90,Loss: -1.424,Avg.Loss: -1.399,LR: 4.67E-04]Training epoch 17:  59%|█████▉    | 90/153 [00:01<00:01, 52.94it/s, Epoch: 17, Batch: 90,Loss: -1.424,Avg.Loss: -1.399,LR: 4.67E-04]Training epoch 17:  59%|█████▉    | 90/153 [00:01<00:01, 52.94it/s, Epoch: 17, Batch: 91,Loss: -0.481,Avg.Loss: -1.389,LR: 4.67E-04]Training epoch 17:  59%|█████▉    | 91/153 [00:01<00:01, 52.94it/s, Epoch: 17, Batch: 92,Loss: -1.117,Avg.Loss: -1.386,LR: 4.67E-04]Training epoch 17:  60%|██████    | 92/153 [00:01<00:01, 52.94it/s, Epoch: 17, Batch: 93,Loss: -1.271,Avg.Loss: -1.385,LR: 4.67E-04]Training epoch 17:  61%|██████    | 93/153 [00:01<00:01, 52.94it/s, Epoch: 17, Batch: 94,Loss: -1.003,Avg.Loss: -1.381,LR: 4.67E-04]Training epoch 17:  61%|██████▏   | 94/153 [00:01<00:01, 52.94it/s, Epoch: 17, Batch: 95,Loss: -1.377,Avg.Loss: -1.381,LR: 4.67E-04]Training epoch 17:  62%|██████▏   | 95/153 [00:01<00:01, 52.94it/s, Epoch: 17, Batch: 96,Loss: -1.617,Avg.Loss: -1.383,LR: 4.67E-04]Training epoch 17:  63%|██████▎   | 96/153 [00:01<00:01, 53.05it/s, Epoch: 17, Batch: 96,Loss: -1.617,Avg.Loss: -1.383,LR: 4.67E-04]Training epoch 17:  63%|██████▎   | 96/153 [00:01<00:01, 53.05it/s, Epoch: 17, Batch: 97,Loss: -1.378,Avg.Loss: -1.383,LR: 4.67E-04]Training epoch 17:  63%|██████▎   | 97/153 [00:01<00:01, 53.05it/s, Epoch: 17, Batch: 98,Loss: -1.757,Avg.Loss: -1.387,LR: 4.67E-04]Training epoch 17:  64%|██████▍   | 98/153 [00:01<00:01, 53.05it/s, Epoch: 17, Batch: 99,Loss: -1.557,Avg.Loss: -1.389,LR: 4.67E-04]Training epoch 17:  65%|██████▍   | 99/153 [00:01<00:01, 53.05it/s, Epoch: 17, Batch: 100,Loss: -1.286,Avg.Loss: -1.388,LR: 4.67E-04]Training epoch 17:  65%|██████▌   | 100/153 [00:01<00:00, 53.05it/s, Epoch: 17, Batch: 101,Loss: -1.403,Avg.Loss: -1.388,LR: 4.67E-04]Training epoch 17:  66%|██████▌   | 101/153 [00:01<00:00, 53.05it/s, Epoch: 17, Batch: 102,Loss: -1.552,Avg.Loss: -1.389,LR: 4.67E-04]Training epoch 17:  67%|██████▋   | 102/153 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 102,Loss: -1.552,Avg.Loss: -1.389,LR: 4.67E-04]Training epoch 17:  67%|██████▋   | 102/153 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 103,Loss: -0.783,Avg.Loss: -1.384,LR: 4.66E-04]Training epoch 17:  67%|██████▋   | 103/153 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 104,Loss: -0.781,Avg.Loss: -1.378,LR: 4.66E-04]Training epoch 17:  68%|██████▊   | 104/153 [00:01<00:00, 53.08it/s, Epoch: 17, Batch: 105,Loss: -1.384,Avg.Loss: -1.378,LR: 4.66E-04]Training epoch 17:  69%|██████▊   | 105/153 [00:02<00:00, 53.08it/s, Epoch: 17, Batch: 106,Loss: -1.958,Avg.Loss: -1.383,LR: 4.66E-04]Training epoch 17:  69%|██████▉   | 106/153 [00:02<00:00, 53.08it/s, Epoch: 17, Batch: 107,Loss: -1.647,Avg.Loss: -1.386,LR: 4.66E-04]Training epoch 17:  70%|██████▉   | 107/153 [00:02<00:00, 53.08it/s, Epoch: 17, Batch: 108,Loss: -1.527,Avg.Loss: -1.387,LR: 4.66E-04]Training epoch 17:  71%|███████   | 108/153 [00:02<00:00, 53.21it/s, Epoch: 17, Batch: 108,Loss: -1.527,Avg.Loss: -1.387,LR: 4.66E-04]Training epoch 17:  71%|███████   | 108/153 [00:02<00:00, 53.21it/s, Epoch: 17, Batch: 109,Loss: -1.158,Avg.Loss: -1.385,LR: 4.66E-04]Training epoch 17:  71%|███████   | 109/153 [00:02<00:00, 53.21it/s, Epoch: 17, Batch: 110,Loss: -0.790,Avg.Loss: -1.380,LR: 4.66E-04]Training epoch 17:  72%|███████▏  | 110/153 [00:02<00:00, 53.21it/s, Epoch: 17, Batch: 111,Loss: -1.253,Avg.Loss: -1.378,LR: 4.66E-04]Training epoch 17:  73%|███████▎  | 111/153 [00:02<00:00, 53.21it/s, Epoch: 17, Batch: 112,Loss: -1.434,Avg.Loss: -1.379,LR: 4.66E-04]Training epoch 17:  73%|███████▎  | 112/153 [00:02<00:00, 53.21it/s, Epoch: 17, Batch: 113,Loss: -1.850,Avg.Loss: -1.383,LR: 4.66E-04]Training epoch 17:  74%|███████▍  | 113/153 [00:02<00:00, 53.21it/s, Epoch: 17, Batch: 114,Loss: -0.853,Avg.Loss: -1.378,LR: 4.66E-04]Training epoch 17:  75%|███████▍  | 114/153 [00:02<00:00, 53.49it/s, Epoch: 17, Batch: 114,Loss: -0.853,Avg.Loss: -1.378,LR: 4.66E-04]Training epoch 17:  75%|███████▍  | 114/153 [00:02<00:00, 53.49it/s, Epoch: 17, Batch: 115,Loss: -1.052,Avg.Loss: -1.376,LR: 4.66E-04]Training epoch 17:  75%|███████▌  | 115/153 [00:02<00:00, 53.49it/s, Epoch: 17, Batch: 116,Loss: -1.572,Avg.Loss: -1.377,LR: 4.66E-04]Training epoch 17:  76%|███████▌  | 116/153 [00:02<00:00, 53.49it/s, Epoch: 17, Batch: 117,Loss: -1.812,Avg.Loss: -1.381,LR: 4.66E-04]Training epoch 17:  76%|███████▋  | 117/153 [00:02<00:00, 53.49it/s, Epoch: 17, Batch: 118,Loss: -2.046,Avg.Loss: -1.387,LR: 4.66E-04]Training epoch 17:  77%|███████▋  | 118/153 [00:02<00:00, 53.49it/s, Epoch: 17, Batch: 119,Loss: -1.799,Avg.Loss: -1.390,LR: 4.66E-04]Training epoch 17:  78%|███████▊  | 119/153 [00:02<00:00, 53.49it/s, Epoch: 17, Batch: 120,Loss: -1.661,Avg.Loss: -1.392,LR: 4.66E-04]Training epoch 17:  78%|███████▊  | 120/153 [00:02<00:00, 53.61it/s, Epoch: 17, Batch: 120,Loss: -1.661,Avg.Loss: -1.392,LR: 4.66E-04]Training epoch 17:  78%|███████▊  | 120/153 [00:02<00:00, 53.61it/s, Epoch: 17, Batch: 121,Loss: -1.674,Avg.Loss: -1.395,LR: 4.66E-04]Training epoch 17:  79%|███████▉  | 121/153 [00:02<00:00, 53.61it/s, Epoch: 17, Batch: 122,Loss: -1.337,Avg.Loss: -1.394,LR: 4.66E-04]Training epoch 17:  80%|███████▉  | 122/153 [00:02<00:00, 53.61it/s, Epoch: 17, Batch: 123,Loss: -1.910,Avg.Loss: -1.398,LR: 4.66E-04]Training epoch 17:  80%|████████  | 123/153 [00:02<00:00, 53.61it/s, Epoch: 17, Batch: 124,Loss: -1.475,Avg.Loss: -1.399,LR: 4.66E-04]Training epoch 17:  81%|████████  | 124/153 [00:02<00:00, 53.61it/s, Epoch: 17, Batch: 125,Loss: -1.911,Avg.Loss: -1.403,LR: 4.66E-04]Training epoch 17:  82%|████████▏ | 125/153 [00:02<00:00, 53.61it/s, Epoch: 17, Batch: 126,Loss: -2.037,Avg.Loss: -1.408,LR: 4.66E-04]Training epoch 17:  82%|████████▏ | 126/153 [00:02<00:00, 53.82it/s, Epoch: 17, Batch: 126,Loss: -2.037,Avg.Loss: -1.408,LR: 4.66E-04]Training epoch 17:  82%|████████▏ | 126/153 [00:02<00:00, 53.82it/s, Epoch: 17, Batch: 127,Loss: -1.972,Avg.Loss: -1.413,LR: 4.66E-04]Training epoch 17:  83%|████████▎ | 127/153 [00:02<00:00, 53.82it/s, Epoch: 17, Batch: 128,Loss: -1.821,Avg.Loss: -1.416,LR: 4.66E-04]Training epoch 17:  84%|████████▎ | 128/153 [00:02<00:00, 53.82it/s, Epoch: 17, Batch: 129,Loss: -1.945,Avg.Loss: -1.420,LR: 4.66E-04]Training epoch 17:  84%|████████▍ | 129/153 [00:02<00:00, 53.82it/s, Epoch: 17, Batch: 130,Loss: -1.759,Avg.Loss: -1.423,LR: 4.66E-04]Training epoch 17:  85%|████████▍ | 130/153 [00:02<00:00, 53.82it/s, Epoch: 17, Batch: 131,Loss: -1.901,Avg.Loss: -1.426,LR: 4.66E-04]Training epoch 17:  86%|████████▌ | 131/153 [00:02<00:00, 53.82it/s, Epoch: 17, Batch: 132,Loss: -1.592,Avg.Loss: -1.427,LR: 4.66E-04]Training epoch 17:  86%|████████▋ | 132/153 [00:02<00:00, 53.63it/s, Epoch: 17, Batch: 132,Loss: -1.592,Avg.Loss: -1.427,LR: 4.66E-04]Training epoch 17:  86%|████████▋ | 132/153 [00:02<00:00, 53.63it/s, Epoch: 17, Batch: 133,Loss: -1.962,Avg.Loss: -1.431,LR: 4.66E-04]Training epoch 17:  87%|████████▋ | 133/153 [00:02<00:00, 53.63it/s, Epoch: 17, Batch: 134,Loss: -1.507,Avg.Loss: -1.432,LR: 4.66E-04]Training epoch 17:  88%|████████▊ | 134/153 [00:02<00:00, 53.63it/s, Epoch: 17, Batch: 135,Loss: -2.003,Avg.Loss: -1.436,LR: 4.66E-04]Training epoch 17:  88%|████████▊ | 135/153 [00:02<00:00, 53.63it/s, Epoch: 17, Batch: 136,Loss: -1.978,Avg.Loss: -1.440,LR: 4.66E-04]Training epoch 17:  89%|████████▉ | 136/153 [00:02<00:00, 53.63it/s, Epoch: 17, Batch: 137,Loss: -1.064,Avg.Loss: -1.437,LR: 4.66E-04]Training epoch 17:  90%|████████▉ | 137/153 [00:02<00:00, 53.63it/s, Epoch: 17, Batch: 138,Loss: -2.206,Avg.Loss: -1.443,LR: 4.66E-04]Training epoch 17:  90%|█████████ | 138/153 [00:02<00:00, 53.33it/s, Epoch: 17, Batch: 138,Loss: -2.206,Avg.Loss: -1.443,LR: 4.66E-04]Training epoch 17:  90%|█████████ | 138/153 [00:02<00:00, 53.33it/s, Epoch: 17, Batch: 139,Loss: -1.086,Avg.Loss: -1.440,LR: 4.66E-04]Training epoch 17:  91%|█████████ | 139/153 [00:02<00:00, 53.33it/s, Epoch: 17, Batch: 140,Loss: -0.951,Avg.Loss: -1.437,LR: 4.66E-04]Training epoch 17:  92%|█████████▏| 140/153 [00:02<00:00, 53.33it/s, Epoch: 17, Batch: 141,Loss: -1.727,Avg.Loss: -1.439,LR: 4.65E-04]Training epoch 17:  92%|█████████▏| 141/153 [00:02<00:00, 53.33it/s, Epoch: 17, Batch: 142,Loss: -1.132,Avg.Loss: -1.437,LR: 4.65E-04]Training epoch 17:  93%|█████████▎| 142/153 [00:02<00:00, 53.33it/s, Epoch: 17, Batch: 143,Loss: -0.910,Avg.Loss: -1.433,LR: 4.65E-04]Training epoch 17:  93%|█████████▎| 143/153 [00:02<00:00, 53.33it/s, Epoch: 17, Batch: 144,Loss: -1.147,Avg.Loss: -1.431,LR: 4.65E-04]Training epoch 17:  94%|█████████▍| 144/153 [00:02<00:00, 53.35it/s, Epoch: 17, Batch: 144,Loss: -1.147,Avg.Loss: -1.431,LR: 4.65E-04]Training epoch 17:  94%|█████████▍| 144/153 [00:02<00:00, 53.35it/s, Epoch: 17, Batch: 145,Loss: -1.892,Avg.Loss: -1.434,LR: 4.65E-04]Training epoch 17:  95%|█████████▍| 145/153 [00:02<00:00, 53.35it/s, Epoch: 17, Batch: 146,Loss: -1.224,Avg.Loss: -1.433,LR: 4.65E-04]Training epoch 17:  95%|█████████▌| 146/153 [00:02<00:00, 53.35it/s, Epoch: 17, Batch: 147,Loss: -0.976,Avg.Loss: -1.430,LR: 4.65E-04]Training epoch 17:  96%|█████████▌| 147/153 [00:02<00:00, 53.35it/s, Epoch: 17, Batch: 148,Loss: -1.163,Avg.Loss: -1.428,LR: 4.65E-04]Training epoch 17:  97%|█████████▋| 148/153 [00:02<00:00, 53.35it/s, Epoch: 17, Batch: 149,Loss: -1.431,Avg.Loss: -1.428,LR: 4.65E-04]Training epoch 17:  97%|█████████▋| 149/153 [00:02<00:00, 53.35it/s, Epoch: 17, Batch: 150,Loss: -0.791,Avg.Loss: -1.424,LR: 4.65E-04]Training epoch 17:  98%|█████████▊| 150/153 [00:02<00:00, 53.46it/s, Epoch: 17, Batch: 150,Loss: -0.791,Avg.Loss: -1.424,LR: 4.65E-04]Training epoch 17:  98%|█████████▊| 150/153 [00:02<00:00, 53.46it/s, Epoch: 17, Batch: 151,Loss: -0.791,Avg.Loss: -1.420,LR: 4.65E-04]Training epoch 17:  99%|█████████▊| 151/153 [00:02<00:00, 53.46it/s, Epoch: 17, Batch: 152,Loss: -1.963,Avg.Loss: -1.423,LR: 4.65E-04]Training epoch 17:  99%|█████████▉| 152/153 [00:02<00:00, 53.46it/s, Epoch: 17, Batch: 153,Loss: -1.535,Avg.Loss: -1.424,LR: 4.65E-04]Training epoch 17: 100%|██████████| 153/153 [00:02<00:00, 53.04it/s, Epoch: 17, Batch: 153,Loss: -1.535,Avg.Loss: -1.424,LR: 4.65E-04]
Training epoch 18:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 18:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 18, Batch: 1,Loss: -1.413,Avg.Loss: -1.413,LR: 4.65E-04]Training epoch 18:   1%|          | 1/153 [00:00<00:05, 25.73it/s, Epoch: 18, Batch: 2,Loss: -1.752,Avg.Loss: -1.582,LR: 4.65E-04]Training epoch 18:   1%|▏         | 2/153 [00:00<00:04, 37.47it/s, Epoch: 18, Batch: 3,Loss: -1.914,Avg.Loss: -1.693,LR: 4.65E-04]Training epoch 18:   2%|▏         | 3/153 [00:00<00:03, 42.41it/s, Epoch: 18, Batch: 4,Loss: -1.061,Avg.Loss: -1.535,LR: 4.65E-04]Training epoch 18:   3%|▎         | 4/153 [00:00<00:03, 45.33it/s, Epoch: 18, Batch: 5,Loss: -1.289,Avg.Loss: -1.486,LR: 4.65E-04]Training epoch 18:   3%|▎         | 5/153 [00:00<00:03, 46.82it/s, Epoch: 18, Batch: 6,Loss: -1.129,Avg.Loss: -1.426,LR: 4.65E-04]Training epoch 18:   4%|▍         | 6/153 [00:00<00:02, 56.08it/s, Epoch: 18, Batch: 6,Loss: -1.129,Avg.Loss: -1.426,LR: 4.65E-04]Training epoch 18:   4%|▍         | 6/153 [00:00<00:02, 56.08it/s, Epoch: 18, Batch: 7,Loss: -1.595,Avg.Loss: -1.450,LR: 4.65E-04]Training epoch 18:   5%|▍         | 7/153 [00:00<00:02, 56.08it/s, Epoch: 18, Batch: 8,Loss: -1.708,Avg.Loss: -1.483,LR: 4.65E-04]Training epoch 18:   5%|▌         | 8/153 [00:00<00:02, 56.08it/s, Epoch: 18, Batch: 9,Loss: -0.694,Avg.Loss: -1.395,LR: 4.65E-04]Training epoch 18:   6%|▌         | 9/153 [00:00<00:02, 56.08it/s, Epoch: 18, Batch: 10,Loss: -0.271,Avg.Loss: -1.283,LR: 4.65E-04]Training epoch 18:   7%|▋         | 10/153 [00:00<00:02, 56.08it/s, Epoch: 18, Batch: 11,Loss: -1.056,Avg.Loss: -1.262,LR: 4.65E-04]Training epoch 18:   7%|▋         | 11/153 [00:00<00:02, 56.08it/s, Epoch: 18, Batch: 12,Loss: -1.257,Avg.Loss: -1.261,LR: 4.65E-04]Training epoch 18:   8%|▊         | 12/153 [00:00<00:02, 53.87it/s, Epoch: 18, Batch: 12,Loss: -1.257,Avg.Loss: -1.261,LR: 4.65E-04]Training epoch 18:   8%|▊         | 12/153 [00:00<00:02, 53.87it/s, Epoch: 18, Batch: 13,Loss: -1.602,Avg.Loss: -1.288,LR: 4.65E-04]Training epoch 18:   8%|▊         | 13/153 [00:00<00:02, 53.87it/s, Epoch: 18, Batch: 14,Loss: -0.842,Avg.Loss: -1.256,LR: 4.65E-04]Training epoch 18:   9%|▉         | 14/153 [00:00<00:02, 53.87it/s, Epoch: 18, Batch: 15,Loss: -0.723,Avg.Loss: -1.220,LR: 4.65E-04]Training epoch 18:  10%|▉         | 15/153 [00:00<00:02, 53.87it/s, Epoch: 18, Batch: 16,Loss: -0.407,Avg.Loss: -1.170,LR: 4.65E-04]Training epoch 18:  10%|█         | 16/153 [00:00<00:02, 53.87it/s, Epoch: 18, Batch: 17,Loss: -1.538,Avg.Loss: -1.191,LR: 4.65E-04]Training epoch 18:  11%|█         | 17/153 [00:00<00:02, 53.87it/s, Epoch: 18, Batch: 18,Loss: -1.882,Avg.Loss: -1.230,LR: 4.65E-04]Training epoch 18:  12%|█▏        | 18/153 [00:00<00:02, 53.30it/s, Epoch: 18, Batch: 18,Loss: -1.882,Avg.Loss: -1.230,LR: 4.65E-04]Training epoch 18:  12%|█▏        | 18/153 [00:00<00:02, 53.30it/s, Epoch: 18, Batch: 19,Loss: -1.331,Avg.Loss: -1.235,LR: 4.65E-04]Training epoch 18:  12%|█▏        | 19/153 [00:00<00:02, 53.30it/s, Epoch: 18, Batch: 20,Loss: -1.356,Avg.Loss: -1.241,LR: 4.65E-04]Training epoch 18:  13%|█▎        | 20/153 [00:00<00:02, 53.30it/s, Epoch: 18, Batch: 21,Loss: -1.532,Avg.Loss: -1.255,LR: 4.65E-04]Training epoch 18:  14%|█▎        | 21/153 [00:00<00:02, 53.30it/s, Epoch: 18, Batch: 22,Loss: -1.621,Avg.Loss: -1.271,LR: 4.65E-04]Training epoch 18:  14%|█▍        | 22/153 [00:00<00:02, 53.30it/s, Epoch: 18, Batch: 23,Loss: -1.855,Avg.Loss: -1.297,LR: 4.65E-04]Training epoch 18:  15%|█▌        | 23/153 [00:00<00:02, 53.30it/s, Epoch: 18, Batch: 24,Loss: -2.054,Avg.Loss: -1.328,LR: 4.65E-04]Training epoch 18:  16%|█▌        | 24/153 [00:00<00:02, 51.11it/s, Epoch: 18, Batch: 24,Loss: -2.054,Avg.Loss: -1.328,LR: 4.65E-04]Training epoch 18:  16%|█▌        | 24/153 [00:00<00:02, 51.11it/s, Epoch: 18, Batch: 25,Loss: -1.870,Avg.Loss: -1.350,LR: 4.65E-04]Training epoch 18:  16%|█▋        | 25/153 [00:00<00:02, 51.11it/s, Epoch: 18, Batch: 26,Loss: -1.676,Avg.Loss: -1.363,LR: 4.65E-04]Training epoch 18:  17%|█▋        | 26/153 [00:00<00:02, 51.11it/s, Epoch: 18, Batch: 27,Loss: -1.947,Avg.Loss: -1.384,LR: 4.64E-04]Training epoch 18:  18%|█▊        | 27/153 [00:00<00:02, 51.11it/s, Epoch: 18, Batch: 28,Loss: -1.902,Avg.Loss: -1.403,LR: 4.64E-04]Training epoch 18:  18%|█▊        | 28/153 [00:00<00:02, 51.11it/s, Epoch: 18, Batch: 29,Loss: -2.008,Avg.Loss: -1.424,LR: 4.64E-04]Training epoch 18:  19%|█▉        | 29/153 [00:00<00:02, 51.11it/s, Epoch: 18, Batch: 30,Loss: -1.592,Avg.Loss: -1.429,LR: 4.64E-04]Training epoch 18:  20%|█▉        | 30/153 [00:00<00:02, 51.90it/s, Epoch: 18, Batch: 30,Loss: -1.592,Avg.Loss: -1.429,LR: 4.64E-04]Training epoch 18:  20%|█▉        | 30/153 [00:00<00:02, 51.90it/s, Epoch: 18, Batch: 31,Loss: -1.661,Avg.Loss: -1.437,LR: 4.64E-04]Training epoch 18:  20%|██        | 31/153 [00:00<00:02, 51.90it/s, Epoch: 18, Batch: 32,Loss: -2.170,Avg.Loss: -1.460,LR: 4.64E-04]Training epoch 18:  21%|██        | 32/153 [00:00<00:02, 51.90it/s, Epoch: 18, Batch: 33,Loss: -1.498,Avg.Loss: -1.461,LR: 4.64E-04]Training epoch 18:  22%|██▏       | 33/153 [00:00<00:02, 51.90it/s, Epoch: 18, Batch: 34,Loss: -1.041,Avg.Loss: -1.448,LR: 4.64E-04]Training epoch 18:  22%|██▏       | 34/153 [00:00<00:02, 51.90it/s, Epoch: 18, Batch: 35,Loss: -2.049,Avg.Loss: -1.466,LR: 4.64E-04]Training epoch 18:  23%|██▎       | 35/153 [00:00<00:02, 51.90it/s, Epoch: 18, Batch: 36,Loss: -1.474,Avg.Loss: -1.466,LR: 4.64E-04]Training epoch 18:  24%|██▎       | 36/153 [00:00<00:02, 52.22it/s, Epoch: 18, Batch: 36,Loss: -1.474,Avg.Loss: -1.466,LR: 4.64E-04]Training epoch 18:  24%|██▎       | 36/153 [00:00<00:02, 52.22it/s, Epoch: 18, Batch: 37,Loss: -1.008,Avg.Loss: -1.453,LR: 4.64E-04]Training epoch 18:  24%|██▍       | 37/153 [00:00<00:02, 52.22it/s, Epoch: 18, Batch: 38,Loss: -1.828,Avg.Loss: -1.463,LR: 4.64E-04]Training epoch 18:  25%|██▍       | 38/153 [00:00<00:02, 52.22it/s, Epoch: 18, Batch: 39,Loss: -1.481,Avg.Loss: -1.464,LR: 4.64E-04]Training epoch 18:  25%|██▌       | 39/153 [00:00<00:02, 52.22it/s, Epoch: 18, Batch: 40,Loss: -1.287,Avg.Loss: -1.459,LR: 4.64E-04]Training epoch 18:  26%|██▌       | 40/153 [00:00<00:02, 52.22it/s, Epoch: 18, Batch: 41,Loss: -2.119,Avg.Loss: -1.475,LR: 4.64E-04]Training epoch 18:  27%|██▋       | 41/153 [00:00<00:02, 52.22it/s, Epoch: 18, Batch: 42,Loss: -1.596,Avg.Loss: -1.478,LR: 4.64E-04]Training epoch 18:  27%|██▋       | 42/153 [00:00<00:02, 52.41it/s, Epoch: 18, Batch: 42,Loss: -1.596,Avg.Loss: -1.478,LR: 4.64E-04]Training epoch 18:  27%|██▋       | 42/153 [00:00<00:02, 52.41it/s, Epoch: 18, Batch: 43,Loss: -1.196,Avg.Loss: -1.472,LR: 4.64E-04]Training epoch 18:  28%|██▊       | 43/153 [00:00<00:02, 52.41it/s, Epoch: 18, Batch: 44,Loss: -1.464,Avg.Loss: -1.472,LR: 4.64E-04]Training epoch 18:  29%|██▉       | 44/153 [00:00<00:02, 52.41it/s, Epoch: 18, Batch: 45,Loss: -1.777,Avg.Loss: -1.478,LR: 4.64E-04]Training epoch 18:  29%|██▉       | 45/153 [00:00<00:02, 52.41it/s, Epoch: 18, Batch: 46,Loss: -1.537,Avg.Loss: -1.480,LR: 4.64E-04]Training epoch 18:  30%|███       | 46/153 [00:00<00:02, 52.41it/s, Epoch: 18, Batch: 47,Loss: -1.799,Avg.Loss: -1.486,LR: 4.64E-04]Training epoch 18:  31%|███       | 47/153 [00:00<00:02, 52.41it/s, Epoch: 18, Batch: 48,Loss: -1.643,Avg.Loss: -1.490,LR: 4.64E-04]Training epoch 18:  31%|███▏      | 48/153 [00:00<00:01, 52.59it/s, Epoch: 18, Batch: 48,Loss: -1.643,Avg.Loss: -1.490,LR: 4.64E-04]Training epoch 18:  31%|███▏      | 48/153 [00:00<00:01, 52.59it/s, Epoch: 18, Batch: 49,Loss: -1.316,Avg.Loss: -1.486,LR: 4.64E-04]Training epoch 18:  32%|███▏      | 49/153 [00:00<00:01, 52.59it/s, Epoch: 18, Batch: 50,Loss: -1.989,Avg.Loss: -1.496,LR: 4.64E-04]Training epoch 18:  33%|███▎      | 50/153 [00:00<00:01, 52.59it/s, Epoch: 18, Batch: 51,Loss: -1.544,Avg.Loss: -1.497,LR: 4.64E-04]Training epoch 18:  33%|███▎      | 51/153 [00:00<00:01, 52.59it/s, Epoch: 18, Batch: 52,Loss: -1.300,Avg.Loss: -1.493,LR: 4.64E-04]Training epoch 18:  34%|███▍      | 52/153 [00:01<00:01, 52.59it/s, Epoch: 18, Batch: 53,Loss: -1.693,Avg.Loss: -1.497,LR: 4.64E-04]Training epoch 18:  35%|███▍      | 53/153 [00:01<00:01, 52.59it/s, Epoch: 18, Batch: 54,Loss: -1.611,Avg.Loss: -1.499,LR: 4.64E-04]Training epoch 18:  35%|███▌      | 54/153 [00:01<00:01, 52.67it/s, Epoch: 18, Batch: 54,Loss: -1.611,Avg.Loss: -1.499,LR: 4.64E-04]Training epoch 18:  35%|███▌      | 54/153 [00:01<00:01, 52.67it/s, Epoch: 18, Batch: 55,Loss: -1.391,Avg.Loss: -1.497,LR: 4.64E-04]Training epoch 18:  36%|███▌      | 55/153 [00:01<00:01, 52.67it/s, Epoch: 18, Batch: 56,Loss: -2.038,Avg.Loss: -1.507,LR: 4.64E-04]Training epoch 18:  37%|███▋      | 56/153 [00:01<00:01, 52.67it/s, Epoch: 18, Batch: 57,Loss: -1.227,Avg.Loss: -1.502,LR: 4.64E-04]Training epoch 18:  37%|███▋      | 57/153 [00:01<00:01, 52.67it/s, Epoch: 18, Batch: 58,Loss: -1.772,Avg.Loss: -1.507,LR: 4.64E-04]Training epoch 18:  38%|███▊      | 58/153 [00:01<00:01, 52.67it/s, Epoch: 18, Batch: 59,Loss: -2.517,Avg.Loss: -1.524,LR: 4.64E-04]Training epoch 18:  39%|███▊      | 59/153 [00:01<00:01, 52.67it/s, Epoch: 18, Batch: 60,Loss: -2.213,Avg.Loss: -1.535,LR: 4.64E-04]Training epoch 18:  39%|███▉      | 60/153 [00:01<00:01, 52.79it/s, Epoch: 18, Batch: 60,Loss: -2.213,Avg.Loss: -1.535,LR: 4.64E-04]Training epoch 18:  39%|███▉      | 60/153 [00:01<00:01, 52.79it/s, Epoch: 18, Batch: 61,Loss: -1.813,Avg.Loss: -1.540,LR: 4.64E-04]Training epoch 18:  40%|███▉      | 61/153 [00:01<00:01, 52.79it/s, Epoch: 18, Batch: 62,Loss: -1.929,Avg.Loss: -1.546,LR: 4.64E-04]Training epoch 18:  41%|████      | 62/153 [00:01<00:01, 52.79it/s, Epoch: 18, Batch: 63,Loss: -1.873,Avg.Loss: -1.551,LR: 4.64E-04]Training epoch 18:  41%|████      | 63/153 [00:01<00:01, 52.79it/s, Epoch: 18, Batch: 64,Loss: -1.453,Avg.Loss: -1.550,LR: 4.63E-04]Training epoch 18:  42%|████▏     | 64/153 [00:01<00:01, 52.79it/s, Epoch: 18, Batch: 65,Loss: -0.959,Avg.Loss: -1.541,LR: 4.63E-04]Training epoch 18:  42%|████▏     | 65/153 [00:01<00:01, 52.79it/s, Epoch: 18, Batch: 66,Loss: -1.483,Avg.Loss: -1.540,LR: 4.63E-04]Training epoch 18:  43%|████▎     | 66/153 [00:01<00:01, 52.89it/s, Epoch: 18, Batch: 66,Loss: -1.483,Avg.Loss: -1.540,LR: 4.63E-04]Training epoch 18:  43%|████▎     | 66/153 [00:01<00:01, 52.89it/s, Epoch: 18, Batch: 67,Loss: -1.567,Avg.Loss: -1.540,LR: 4.63E-04]Training epoch 18:  44%|████▍     | 67/153 [00:01<00:01, 52.89it/s, Epoch: 18, Batch: 68,Loss: -0.868,Avg.Loss: -1.530,LR: 4.63E-04]Training epoch 18:  44%|████▍     | 68/153 [00:01<00:01, 52.89it/s, Epoch: 18, Batch: 69,Loss: -1.034,Avg.Loss: -1.523,LR: 4.63E-04]Training epoch 18:  45%|████▌     | 69/153 [00:01<00:01, 52.89it/s, Epoch: 18, Batch: 70,Loss: -2.038,Avg.Loss: -1.530,LR: 4.63E-04]Training epoch 18:  46%|████▌     | 70/153 [00:01<00:01, 52.89it/s, Epoch: 18, Batch: 71,Loss: -1.817,Avg.Loss: -1.534,LR: 4.63E-04]Training epoch 18:  46%|████▋     | 71/153 [00:01<00:01, 52.89it/s, Epoch: 18, Batch: 72,Loss: -1.522,Avg.Loss: -1.534,LR: 4.63E-04]Training epoch 18:  47%|████▋     | 72/153 [00:01<00:01, 53.07it/s, Epoch: 18, Batch: 72,Loss: -1.522,Avg.Loss: -1.534,LR: 4.63E-04]Training epoch 18:  47%|████▋     | 72/153 [00:01<00:01, 53.07it/s, Epoch: 18, Batch: 73,Loss: -1.698,Avg.Loss: -1.537,LR: 4.63E-04]Training epoch 18:  48%|████▊     | 73/153 [00:01<00:01, 53.07it/s, Epoch: 18, Batch: 74,Loss: -1.633,Avg.Loss: -1.538,LR: 4.63E-04]Training epoch 18:  48%|████▊     | 74/153 [00:01<00:01, 53.07it/s, Epoch: 18, Batch: 75,Loss: -0.930,Avg.Loss: -1.530,LR: 4.63E-04]Training epoch 18:  49%|████▉     | 75/153 [00:01<00:01, 53.07it/s, Epoch: 18, Batch: 76,Loss: -0.950,Avg.Loss: -1.522,LR: 4.63E-04]Training epoch 18:  50%|████▉     | 76/153 [00:01<00:01, 53.07it/s, Epoch: 18, Batch: 77,Loss: -0.962,Avg.Loss: -1.515,LR: 4.63E-04]Training epoch 18:  50%|█████     | 77/153 [00:01<00:01, 53.07it/s, Epoch: 18, Batch: 78,Loss: -1.776,Avg.Loss: -1.518,LR: 4.63E-04]Training epoch 18:  51%|█████     | 78/153 [00:01<00:01, 53.10it/s, Epoch: 18, Batch: 78,Loss: -1.776,Avg.Loss: -1.518,LR: 4.63E-04]Training epoch 18:  51%|█████     | 78/153 [00:01<00:01, 53.10it/s, Epoch: 18, Batch: 79,Loss: -1.787,Avg.Loss: -1.522,LR: 4.63E-04]Training epoch 18:  52%|█████▏    | 79/153 [00:01<00:01, 53.10it/s, Epoch: 18, Batch: 80,Loss: -0.598,Avg.Loss: -1.510,LR: 4.63E-04]Training epoch 18:  52%|█████▏    | 80/153 [00:01<00:01, 53.10it/s, Epoch: 18, Batch: 81,Loss: -1.019,Avg.Loss: -1.504,LR: 4.63E-04]Training epoch 18:  53%|█████▎    | 81/153 [00:01<00:01, 53.10it/s, Epoch: 18, Batch: 82,Loss: -0.505,Avg.Loss: -1.492,LR: 4.63E-04]Training epoch 18:  54%|█████▎    | 82/153 [00:01<00:01, 53.10it/s, Epoch: 18, Batch: 83,Loss: -1.241,Avg.Loss: -1.489,LR: 4.63E-04]Training epoch 18:  54%|█████▍    | 83/153 [00:01<00:01, 53.10it/s, Epoch: 18, Batch: 84,Loss: -1.588,Avg.Loss: -1.490,LR: 4.63E-04]Training epoch 18:  55%|█████▍    | 84/153 [00:01<00:01, 53.32it/s, Epoch: 18, Batch: 84,Loss: -1.588,Avg.Loss: -1.490,LR: 4.63E-04]Training epoch 18:  55%|█████▍    | 84/153 [00:01<00:01, 53.32it/s, Epoch: 18, Batch: 85,Loss: -1.721,Avg.Loss: -1.493,LR: 4.63E-04]Training epoch 18:  56%|█████▌    | 85/153 [00:01<00:01, 53.32it/s, Epoch: 18, Batch: 86,Loss: -1.407,Avg.Loss: -1.492,LR: 4.63E-04]Training epoch 18:  56%|█████▌    | 86/153 [00:01<00:01, 53.32it/s, Epoch: 18, Batch: 87,Loss: -1.794,Avg.Loss: -1.495,LR: 4.63E-04]Training epoch 18:  57%|█████▋    | 87/153 [00:01<00:01, 53.32it/s, Epoch: 18, Batch: 88,Loss: -1.569,Avg.Loss: -1.496,LR: 4.63E-04]Training epoch 18:  58%|█████▊    | 88/153 [00:01<00:01, 53.32it/s, Epoch: 18, Batch: 89,Loss: -1.469,Avg.Loss: -1.496,LR: 4.63E-04]Training epoch 18:  58%|█████▊    | 89/153 [00:01<00:01, 53.32it/s, Epoch: 18, Batch: 90,Loss: -0.720,Avg.Loss: -1.487,LR: 4.63E-04]Training epoch 18:  59%|█████▉    | 90/153 [00:01<00:01, 53.02it/s, Epoch: 18, Batch: 90,Loss: -0.720,Avg.Loss: -1.487,LR: 4.63E-04]Training epoch 18:  59%|█████▉    | 90/153 [00:01<00:01, 53.02it/s, Epoch: 18, Batch: 91,Loss: -1.399,Avg.Loss: -1.486,LR: 4.63E-04]Training epoch 18:  59%|█████▉    | 91/153 [00:01<00:01, 53.02it/s, Epoch: 18, Batch: 92,Loss: -0.959,Avg.Loss: -1.480,LR: 4.63E-04]Training epoch 18:  60%|██████    | 92/153 [00:01<00:01, 53.02it/s, Epoch: 18, Batch: 93,Loss: -1.519,Avg.Loss: -1.481,LR: 4.63E-04]Training epoch 18:  61%|██████    | 93/153 [00:01<00:01, 53.02it/s, Epoch: 18, Batch: 94,Loss: -1.380,Avg.Loss: -1.480,LR: 4.63E-04]Training epoch 18:  61%|██████▏   | 94/153 [00:01<00:01, 53.02it/s, Epoch: 18, Batch: 95,Loss: -1.137,Avg.Loss: -1.476,LR: 4.63E-04]Training epoch 18:  62%|██████▏   | 95/153 [00:01<00:01, 53.02it/s, Epoch: 18, Batch: 96,Loss: -0.819,Avg.Loss: -1.469,LR: 4.63E-04]Training epoch 18:  63%|██████▎   | 96/153 [00:01<00:01, 52.93it/s, Epoch: 18, Batch: 96,Loss: -0.819,Avg.Loss: -1.469,LR: 4.63E-04]Training epoch 18:  63%|██████▎   | 96/153 [00:01<00:01, 52.93it/s, Epoch: 18, Batch: 97,Loss: -1.521,Avg.Loss: -1.470,LR: 4.63E-04]Training epoch 18:  63%|██████▎   | 97/153 [00:01<00:01, 52.93it/s, Epoch: 18, Batch: 98,Loss: -1.538,Avg.Loss: -1.470,LR: 4.63E-04]Training epoch 18:  64%|██████▍   | 98/153 [00:01<00:01, 52.93it/s, Epoch: 18, Batch: 99,Loss: -0.464,Avg.Loss: -1.460,LR: 4.63E-04]Training epoch 18:  65%|██████▍   | 99/153 [00:01<00:01, 52.93it/s, Epoch: 18, Batch: 100,Loss: -1.016,Avg.Loss: -1.456,LR: 4.63E-04]Training epoch 18:  65%|██████▌   | 100/153 [00:01<00:01, 52.93it/s, Epoch: 18, Batch: 101,Loss: -1.695,Avg.Loss: -1.458,LR: 4.63E-04]Training epoch 18:  66%|██████▌   | 101/153 [00:01<00:00, 52.93it/s, Epoch: 18, Batch: 102,Loss: -1.703,Avg.Loss: -1.461,LR: 4.62E-04]Training epoch 18:  67%|██████▋   | 102/153 [00:01<00:00, 52.85it/s, Epoch: 18, Batch: 102,Loss: -1.703,Avg.Loss: -1.461,LR: 4.62E-04]Training epoch 18:  67%|██████▋   | 102/153 [00:01<00:00, 52.85it/s, Epoch: 18, Batch: 103,Loss: -1.765,Avg.Loss: -1.464,LR: 4.62E-04]Training epoch 18:  67%|██████▋   | 103/153 [00:01<00:00, 52.85it/s, Epoch: 18, Batch: 104,Loss: -1.814,Avg.Loss: -1.467,LR: 4.62E-04]Training epoch 18:  68%|██████▊   | 104/153 [00:01<00:00, 52.85it/s, Epoch: 18, Batch: 105,Loss: -1.972,Avg.Loss: -1.472,LR: 4.62E-04]Training epoch 18:  69%|██████▊   | 105/153 [00:02<00:00, 52.85it/s, Epoch: 18, Batch: 106,Loss: -1.656,Avg.Loss: -1.474,LR: 4.62E-04]Training epoch 18:  69%|██████▉   | 106/153 [00:02<00:00, 52.85it/s, Epoch: 18, Batch: 107,Loss: -1.939,Avg.Loss: -1.478,LR: 4.62E-04]Training epoch 18:  70%|██████▉   | 107/153 [00:02<00:00, 52.85it/s, Epoch: 18, Batch: 108,Loss: -1.676,Avg.Loss: -1.480,LR: 4.62E-04]Training epoch 18:  71%|███████   | 108/153 [00:02<00:00, 53.01it/s, Epoch: 18, Batch: 108,Loss: -1.676,Avg.Loss: -1.480,LR: 4.62E-04]Training epoch 18:  71%|███████   | 108/153 [00:02<00:00, 53.01it/s, Epoch: 18, Batch: 109,Loss: -1.772,Avg.Loss: -1.482,LR: 4.62E-04]Training epoch 18:  71%|███████   | 109/153 [00:02<00:00, 53.01it/s, Epoch: 18, Batch: 110,Loss: -1.869,Avg.Loss: -1.486,LR: 4.62E-04]Training epoch 18:  72%|███████▏  | 110/153 [00:02<00:00, 53.01it/s, Epoch: 18, Batch: 111,Loss: -1.739,Avg.Loss: -1.488,LR: 4.62E-04]Training epoch 18:  73%|███████▎  | 111/153 [00:02<00:00, 53.01it/s, Epoch: 18, Batch: 112,Loss: -1.747,Avg.Loss: -1.491,LR: 4.62E-04]Training epoch 18:  73%|███████▎  | 112/153 [00:02<00:00, 53.01it/s, Epoch: 18, Batch: 113,Loss: -1.654,Avg.Loss: -1.492,LR: 4.62E-04]Training epoch 18:  74%|███████▍  | 113/153 [00:02<00:00, 53.01it/s, Epoch: 18, Batch: 114,Loss: -1.926,Avg.Loss: -1.496,LR: 4.62E-04]Training epoch 18:  75%|███████▍  | 114/153 [00:02<00:00, 52.97it/s, Epoch: 18, Batch: 114,Loss: -1.926,Avg.Loss: -1.496,LR: 4.62E-04]Training epoch 18:  75%|███████▍  | 114/153 [00:02<00:00, 52.97it/s, Epoch: 18, Batch: 115,Loss: -2.022,Avg.Loss: -1.500,LR: 4.62E-04]Training epoch 18:  75%|███████▌  | 115/153 [00:02<00:00, 52.97it/s, Epoch: 18, Batch: 116,Loss: -2.016,Avg.Loss: -1.505,LR: 4.62E-04]Training epoch 18:  76%|███████▌  | 116/153 [00:02<00:00, 52.97it/s, Epoch: 18, Batch: 117,Loss: -1.833,Avg.Loss: -1.508,LR: 4.62E-04]Training epoch 18:  76%|███████▋  | 117/153 [00:02<00:00, 52.97it/s, Epoch: 18, Batch: 118,Loss: -1.886,Avg.Loss: -1.511,LR: 4.62E-04]Training epoch 18:  77%|███████▋  | 118/153 [00:02<00:00, 52.97it/s, Epoch: 18, Batch: 119,Loss: -1.842,Avg.Loss: -1.514,LR: 4.62E-04]Training epoch 18:  78%|███████▊  | 119/153 [00:02<00:00, 52.97it/s, Epoch: 18, Batch: 120,Loss: -1.869,Avg.Loss: -1.517,LR: 4.62E-04]Training epoch 18:  78%|███████▊  | 120/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 120,Loss: -1.869,Avg.Loss: -1.517,LR: 4.62E-04]Training epoch 18:  78%|███████▊  | 120/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 121,Loss: -2.169,Avg.Loss: -1.522,LR: 4.62E-04]Training epoch 18:  79%|███████▉  | 121/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 122,Loss: -1.933,Avg.Loss: -1.525,LR: 4.62E-04]Training epoch 18:  80%|███████▉  | 122/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 123,Loss: -1.594,Avg.Loss: -1.526,LR: 4.62E-04]Training epoch 18:  80%|████████  | 123/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 124,Loss: -2.229,Avg.Loss: -1.532,LR: 4.62E-04]Training epoch 18:  81%|████████  | 124/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 125,Loss: -1.661,Avg.Loss: -1.533,LR: 4.62E-04]Training epoch 18:  82%|████████▏ | 125/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 126,Loss: -1.868,Avg.Loss: -1.535,LR: 4.62E-04]Training epoch 18:  82%|████████▏ | 126/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 126,Loss: -1.868,Avg.Loss: -1.535,LR: 4.62E-04]Training epoch 18:  82%|████████▏ | 126/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 127,Loss: -1.113,Avg.Loss: -1.532,LR: 4.62E-04]Training epoch 18:  83%|████████▎ | 127/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 128,Loss: -1.850,Avg.Loss: -1.534,LR: 4.62E-04]Training epoch 18:  84%|████████▎ | 128/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 129,Loss: -1.422,Avg.Loss: -1.534,LR: 4.62E-04]Training epoch 18:  84%|████████▍ | 129/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 130,Loss: -1.160,Avg.Loss: -1.531,LR: 4.62E-04]Training epoch 18:  85%|████████▍ | 130/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 131,Loss: -1.795,Avg.Loss: -1.533,LR: 4.62E-04]Training epoch 18:  86%|████████▌ | 131/153 [00:02<00:00, 53.20it/s, Epoch: 18, Batch: 132,Loss: -1.104,Avg.Loss: -1.529,LR: 4.62E-04]Training epoch 18:  86%|████████▋ | 132/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 132,Loss: -1.104,Avg.Loss: -1.529,LR: 4.62E-04]Training epoch 18:  86%|████████▋ | 132/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 133,Loss: -1.845,Avg.Loss: -1.532,LR: 4.62E-04]Training epoch 18:  87%|████████▋ | 133/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 134,Loss: -0.899,Avg.Loss: -1.527,LR: 4.62E-04]Training epoch 18:  88%|████████▊ | 134/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 135,Loss: -0.269,Avg.Loss: -1.518,LR: 4.62E-04]Training epoch 18:  88%|████████▊ | 135/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 136,Loss: -0.507,Avg.Loss: -1.510,LR: 4.62E-04]Training epoch 18:  89%|████████▉ | 136/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 137,Loss: -1.025,Avg.Loss: -1.507,LR: 4.62E-04]Training epoch 18:  90%|████████▉ | 137/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 138,Loss: -1.486,Avg.Loss: -1.507,LR: 4.61E-04]Training epoch 18:  90%|█████████ | 138/153 [00:02<00:00, 53.35it/s, Epoch: 18, Batch: 138,Loss: -1.486,Avg.Loss: -1.507,LR: 4.61E-04]Training epoch 18:  90%|█████████ | 138/153 [00:02<00:00, 53.35it/s, Epoch: 18, Batch: 139,Loss: -2.154,Avg.Loss: -1.511,LR: 4.61E-04]Training epoch 18:  91%|█████████ | 139/153 [00:02<00:00, 53.35it/s, Epoch: 18, Batch: 140,Loss: -1.293,Avg.Loss: -1.510,LR: 4.61E-04]Training epoch 18:  92%|█████████▏| 140/153 [00:02<00:00, 53.35it/s, Epoch: 18, Batch: 141,Loss: -1.503,Avg.Loss: -1.510,LR: 4.61E-04]Training epoch 18:  92%|█████████▏| 141/153 [00:02<00:00, 53.35it/s, Epoch: 18, Batch: 142,Loss: -1.307,Avg.Loss: -1.508,LR: 4.61E-04]Training epoch 18:  93%|█████████▎| 142/153 [00:02<00:00, 53.35it/s, Epoch: 18, Batch: 143,Loss: -1.277,Avg.Loss: -1.507,LR: 4.61E-04]Training epoch 18:  93%|█████████▎| 143/153 [00:02<00:00, 53.35it/s, Epoch: 18, Batch: 144,Loss: -0.933,Avg.Loss: -1.503,LR: 4.61E-04]Training epoch 18:  94%|█████████▍| 144/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 144,Loss: -0.933,Avg.Loss: -1.503,LR: 4.61E-04]Training epoch 18:  94%|█████████▍| 144/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 145,Loss: -1.579,Avg.Loss: -1.503,LR: 4.61E-04]Training epoch 18:  95%|█████████▍| 145/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 146,Loss: -1.168,Avg.Loss: -1.501,LR: 4.61E-04]Training epoch 18:  95%|█████████▌| 146/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 147,Loss: -1.356,Avg.Loss: -1.500,LR: 4.61E-04]Training epoch 18:  96%|█████████▌| 147/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 148,Loss: -1.734,Avg.Loss: -1.501,LR: 4.61E-04]Training epoch 18:  97%|█████████▋| 148/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 149,Loss: -2.003,Avg.Loss: -1.505,LR: 4.61E-04]Training epoch 18:  97%|█████████▋| 149/153 [00:02<00:00, 53.07it/s, Epoch: 18, Batch: 150,Loss: -1.661,Avg.Loss: -1.506,LR: 4.61E-04]Training epoch 18:  98%|█████████▊| 150/153 [00:02<00:00, 53.19it/s, Epoch: 18, Batch: 150,Loss: -1.661,Avg.Loss: -1.506,LR: 4.61E-04]Training epoch 18:  98%|█████████▊| 150/153 [00:02<00:00, 53.19it/s, Epoch: 18, Batch: 151,Loss: -2.215,Avg.Loss: -1.511,LR: 4.61E-04]Training epoch 18:  99%|█████████▊| 151/153 [00:02<00:00, 53.19it/s, Epoch: 18, Batch: 152,Loss: -2.003,Avg.Loss: -1.514,LR: 4.61E-04]Training epoch 18:  99%|█████████▉| 152/153 [00:02<00:00, 53.19it/s, Epoch: 18, Batch: 153,Loss: -1.860,Avg.Loss: -1.516,LR: 4.61E-04]Training epoch 18: 100%|██████████| 153/153 [00:02<00:00, 52.88it/s, Epoch: 18, Batch: 153,Loss: -1.860,Avg.Loss: -1.516,LR: 4.61E-04]
Training epoch 19:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 19:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 19, Batch: 1,Loss: -2.126,Avg.Loss: -2.126,LR: 4.61E-04]Training epoch 19:   1%|          | 1/153 [00:00<00:05, 26.58it/s, Epoch: 19, Batch: 2,Loss: -1.367,Avg.Loss: -1.747,LR: 4.61E-04]Training epoch 19:   1%|▏         | 2/153 [00:00<00:04, 36.45it/s, Epoch: 19, Batch: 3,Loss: -1.034,Avg.Loss: -1.509,LR: 4.61E-04]Training epoch 19:   2%|▏         | 3/153 [00:00<00:03, 41.37it/s, Epoch: 19, Batch: 4,Loss: -1.889,Avg.Loss: -1.604,LR: 4.61E-04]Training epoch 19:   3%|▎         | 4/153 [00:00<00:03, 44.08it/s, Epoch: 19, Batch: 5,Loss: -1.746,Avg.Loss: -1.632,LR: 4.61E-04]Training epoch 19:   3%|▎         | 5/153 [00:00<00:03, 45.55it/s, Epoch: 19, Batch: 6,Loss: -1.198,Avg.Loss: -1.560,LR: 4.61E-04]Training epoch 19:   4%|▍         | 6/153 [00:00<00:02, 54.56it/s, Epoch: 19, Batch: 6,Loss: -1.198,Avg.Loss: -1.560,LR: 4.61E-04]Training epoch 19:   4%|▍         | 6/153 [00:00<00:02, 54.56it/s, Epoch: 19, Batch: 7,Loss: -1.372,Avg.Loss: -1.533,LR: 4.61E-04]Training epoch 19:   5%|▍         | 7/153 [00:00<00:02, 54.56it/s, Epoch: 19, Batch: 8,Loss: -1.676,Avg.Loss: -1.551,LR: 4.61E-04]Training epoch 19:   5%|▌         | 8/153 [00:00<00:02, 54.56it/s, Epoch: 19, Batch: 9,Loss: -1.899,Avg.Loss: -1.590,LR: 4.61E-04]Training epoch 19:   6%|▌         | 9/153 [00:00<00:02, 54.56it/s, Epoch: 19, Batch: 10,Loss: -1.901,Avg.Loss: -1.621,LR: 4.61E-04]Training epoch 19:   7%|▋         | 10/153 [00:00<00:02, 54.56it/s, Epoch: 19, Batch: 11,Loss: -1.574,Avg.Loss: -1.617,LR: 4.61E-04]Training epoch 19:   7%|▋         | 11/153 [00:00<00:02, 54.56it/s, Epoch: 19, Batch: 12,Loss: -0.589,Avg.Loss: -1.531,LR: 4.61E-04]Training epoch 19:   8%|▊         | 12/153 [00:00<00:02, 53.37it/s, Epoch: 19, Batch: 12,Loss: -0.589,Avg.Loss: -1.531,LR: 4.61E-04]Training epoch 19:   8%|▊         | 12/153 [00:00<00:02, 53.37it/s, Epoch: 19, Batch: 13,Loss: -1.913,Avg.Loss: -1.560,LR: 4.61E-04]Training epoch 19:   8%|▊         | 13/153 [00:00<00:02, 53.37it/s, Epoch: 19, Batch: 14,Loss: -1.432,Avg.Loss: -1.551,LR: 4.61E-04]Training epoch 19:   9%|▉         | 14/153 [00:00<00:02, 53.37it/s, Epoch: 19, Batch: 15,Loss: -1.497,Avg.Loss: -1.548,LR: 4.61E-04]Training epoch 19:  10%|▉         | 15/153 [00:00<00:02, 53.37it/s, Epoch: 19, Batch: 16,Loss: -1.706,Avg.Loss: -1.558,LR: 4.61E-04]Training epoch 19:  10%|█         | 16/153 [00:00<00:02, 53.37it/s, Epoch: 19, Batch: 17,Loss: -1.749,Avg.Loss: -1.569,LR: 4.61E-04]Training epoch 19:  11%|█         | 17/153 [00:00<00:02, 53.37it/s, Epoch: 19, Batch: 18,Loss: -1.513,Avg.Loss: -1.566,LR: 4.61E-04]Training epoch 19:  12%|█▏        | 18/153 [00:00<00:02, 53.09it/s, Epoch: 19, Batch: 18,Loss: -1.513,Avg.Loss: -1.566,LR: 4.61E-04]Training epoch 19:  12%|█▏        | 18/153 [00:00<00:02, 53.09it/s, Epoch: 19, Batch: 19,Loss: -2.132,Avg.Loss: -1.596,LR: 4.61E-04]Training epoch 19:  12%|█▏        | 19/153 [00:00<00:02, 53.09it/s, Epoch: 19, Batch: 20,Loss: -1.186,Avg.Loss: -1.575,LR: 4.61E-04]Training epoch 19:  13%|█▎        | 20/153 [00:00<00:02, 53.09it/s, Epoch: 19, Batch: 21,Loss: -0.974,Avg.Loss: -1.546,LR: 4.61E-04]Training epoch 19:  14%|█▎        | 21/153 [00:00<00:02, 53.09it/s, Epoch: 19, Batch: 22,Loss: -1.433,Avg.Loss: -1.541,LR: 4.60E-04]Training epoch 19:  14%|█▍        | 22/153 [00:00<00:02, 53.09it/s, Epoch: 19, Batch: 23,Loss: -2.067,Avg.Loss: -1.564,LR: 4.60E-04]Training epoch 19:  15%|█▌        | 23/153 [00:00<00:02, 53.09it/s, Epoch: 19, Batch: 24,Loss: -2.004,Avg.Loss: -1.582,LR: 4.60E-04]Training epoch 19:  16%|█▌        | 24/153 [00:00<00:02, 51.91it/s, Epoch: 19, Batch: 24,Loss: -2.004,Avg.Loss: -1.582,LR: 4.60E-04]Training epoch 19:  16%|█▌        | 24/153 [00:00<00:02, 51.91it/s, Epoch: 19, Batch: 25,Loss: -2.000,Avg.Loss: -1.599,LR: 4.60E-04]Training epoch 19:  16%|█▋        | 25/153 [00:00<00:02, 51.91it/s, Epoch: 19, Batch: 26,Loss: -1.309,Avg.Loss: -1.588,LR: 4.60E-04]Training epoch 19:  17%|█▋        | 26/153 [00:00<00:02, 51.91it/s, Epoch: 19, Batch: 27,Loss: -1.472,Avg.Loss: -1.584,LR: 4.60E-04]Training epoch 19:  18%|█▊        | 27/153 [00:00<00:02, 51.91it/s, Epoch: 19, Batch: 28,Loss: -1.838,Avg.Loss: -1.593,LR: 4.60E-04]Training epoch 19:  18%|█▊        | 28/153 [00:00<00:02, 51.91it/s, Epoch: 19, Batch: 29,Loss: -2.179,Avg.Loss: -1.613,LR: 4.60E-04]Training epoch 19:  19%|█▉        | 29/153 [00:00<00:02, 51.91it/s, Epoch: 19, Batch: 30,Loss: -1.912,Avg.Loss: -1.623,LR: 4.60E-04]Training epoch 19:  20%|█▉        | 30/153 [00:00<00:02, 51.18it/s, Epoch: 19, Batch: 30,Loss: -1.912,Avg.Loss: -1.623,LR: 4.60E-04]Training epoch 19:  20%|█▉        | 30/153 [00:00<00:02, 51.18it/s, Epoch: 19, Batch: 31,Loss: -1.913,Avg.Loss: -1.632,LR: 4.60E-04]Training epoch 19:  20%|██        | 31/153 [00:00<00:02, 51.18it/s, Epoch: 19, Batch: 32,Loss: -1.616,Avg.Loss: -1.632,LR: 4.60E-04]Training epoch 19:  21%|██        | 32/153 [00:00<00:02, 51.18it/s, Epoch: 19, Batch: 33,Loss: -1.470,Avg.Loss: -1.627,LR: 4.60E-04]Training epoch 19:  22%|██▏       | 33/153 [00:00<00:02, 51.18it/s, Epoch: 19, Batch: 34,Loss: -1.034,Avg.Loss: -1.610,LR: 4.60E-04]Training epoch 19:  22%|██▏       | 34/153 [00:00<00:02, 51.18it/s, Epoch: 19, Batch: 35,Loss: -1.829,Avg.Loss: -1.616,LR: 4.60E-04]Training epoch 19:  23%|██▎       | 35/153 [00:00<00:02, 51.18it/s, Epoch: 19, Batch: 36,Loss: -0.653,Avg.Loss: -1.589,LR: 4.60E-04]Training epoch 19:  24%|██▎       | 36/153 [00:00<00:02, 51.83it/s, Epoch: 19, Batch: 36,Loss: -0.653,Avg.Loss: -1.589,LR: 4.60E-04]Training epoch 19:  24%|██▎       | 36/153 [00:00<00:02, 51.83it/s, Epoch: 19, Batch: 37,Loss: 0.168,Avg.Loss: -1.542,LR: 4.60E-04] Training epoch 19:  24%|██▍       | 37/153 [00:00<00:02, 51.83it/s, Epoch: 19, Batch: 38,Loss: -0.801,Avg.Loss: -1.522,LR: 4.60E-04]Training epoch 19:  25%|██▍       | 38/153 [00:00<00:02, 51.83it/s, Epoch: 19, Batch: 39,Loss: -1.458,Avg.Loss: -1.520,LR: 4.60E-04]Training epoch 19:  25%|██▌       | 39/153 [00:00<00:02, 51.83it/s, Epoch: 19, Batch: 40,Loss: -1.193,Avg.Loss: -1.512,LR: 4.60E-04]Training epoch 19:  26%|██▌       | 40/153 [00:00<00:02, 51.83it/s, Epoch: 19, Batch: 41,Loss: 1.051,Avg.Loss: -1.450,LR: 4.60E-04] Training epoch 19:  27%|██▋       | 41/153 [00:00<00:02, 51.83it/s, Epoch: 19, Batch: 42,Loss: -0.630,Avg.Loss: -1.430,LR: 4.60E-04]Training epoch 19:  27%|██▋       | 42/153 [00:00<00:02, 52.32it/s, Epoch: 19, Batch: 42,Loss: -0.630,Avg.Loss: -1.430,LR: 4.60E-04]Training epoch 19:  27%|██▋       | 42/153 [00:00<00:02, 52.32it/s, Epoch: 19, Batch: 43,Loss: -1.203,Avg.Loss: -1.425,LR: 4.60E-04]Training epoch 19:  28%|██▊       | 43/153 [00:00<00:02, 52.32it/s, Epoch: 19, Batch: 44,Loss: -1.563,Avg.Loss: -1.428,LR: 4.60E-04]Training epoch 19:  29%|██▉       | 44/153 [00:00<00:02, 52.32it/s, Epoch: 19, Batch: 45,Loss: -0.755,Avg.Loss: -1.413,LR: 4.60E-04]Training epoch 19:  29%|██▉       | 45/153 [00:00<00:02, 52.32it/s, Epoch: 19, Batch: 46,Loss: -1.577,Avg.Loss: -1.417,LR: 4.60E-04]Training epoch 19:  30%|███       | 46/153 [00:00<00:02, 52.32it/s, Epoch: 19, Batch: 47,Loss: -1.771,Avg.Loss: -1.424,LR: 4.60E-04]Training epoch 19:  31%|███       | 47/153 [00:00<00:02, 52.32it/s, Epoch: 19, Batch: 48,Loss: -1.299,Avg.Loss: -1.422,LR: 4.60E-04]Training epoch 19:  31%|███▏      | 48/153 [00:00<00:02, 52.39it/s, Epoch: 19, Batch: 48,Loss: -1.299,Avg.Loss: -1.422,LR: 4.60E-04]Training epoch 19:  31%|███▏      | 48/153 [00:00<00:02, 52.39it/s, Epoch: 19, Batch: 49,Loss: -0.837,Avg.Loss: -1.410,LR: 4.60E-04]Training epoch 19:  32%|███▏      | 49/153 [00:00<00:01, 52.39it/s, Epoch: 19, Batch: 50,Loss: -1.629,Avg.Loss: -1.414,LR: 4.60E-04]Training epoch 19:  33%|███▎      | 50/153 [00:00<00:01, 52.39it/s, Epoch: 19, Batch: 51,Loss: -1.184,Avg.Loss: -1.410,LR: 4.60E-04]Training epoch 19:  33%|███▎      | 51/153 [00:00<00:01, 52.39it/s, Epoch: 19, Batch: 52,Loss: -0.271,Avg.Loss: -1.388,LR: 4.60E-04]Training epoch 19:  34%|███▍      | 52/153 [00:01<00:01, 52.39it/s, Epoch: 19, Batch: 53,Loss: -1.791,Avg.Loss: -1.395,LR: 4.60E-04]Training epoch 19:  35%|███▍      | 53/153 [00:01<00:01, 52.39it/s, Epoch: 19, Batch: 54,Loss: -1.959,Avg.Loss: -1.406,LR: 4.60E-04]Training epoch 19:  35%|███▌      | 54/153 [00:01<00:01, 52.76it/s, Epoch: 19, Batch: 54,Loss: -1.959,Avg.Loss: -1.406,LR: 4.60E-04]Training epoch 19:  35%|███▌      | 54/153 [00:01<00:01, 52.76it/s, Epoch: 19, Batch: 55,Loss: -1.827,Avg.Loss: -1.413,LR: 4.60E-04]Training epoch 19:  36%|███▌      | 55/153 [00:01<00:01, 52.76it/s, Epoch: 19, Batch: 56,Loss: -2.019,Avg.Loss: -1.424,LR: 4.60E-04]Training epoch 19:  37%|███▋      | 56/153 [00:01<00:01, 52.76it/s, Epoch: 19, Batch: 57,Loss: -2.099,Avg.Loss: -1.436,LR: 4.59E-04]Training epoch 19:  37%|███▋      | 57/153 [00:01<00:01, 52.76it/s, Epoch: 19, Batch: 58,Loss: -1.937,Avg.Loss: -1.445,LR: 4.59E-04]Training epoch 19:  38%|███▊      | 58/153 [00:01<00:01, 52.76it/s, Epoch: 19, Batch: 59,Loss: -1.853,Avg.Loss: -1.452,LR: 4.59E-04]Training epoch 19:  39%|███▊      | 59/153 [00:01<00:01, 52.76it/s, Epoch: 19, Batch: 60,Loss: -1.847,Avg.Loss: -1.458,LR: 4.59E-04]Training epoch 19:  39%|███▉      | 60/153 [00:01<00:01, 52.80it/s, Epoch: 19, Batch: 60,Loss: -1.847,Avg.Loss: -1.458,LR: 4.59E-04]Training epoch 19:  39%|███▉      | 60/153 [00:01<00:01, 52.80it/s, Epoch: 19, Batch: 61,Loss: -1.669,Avg.Loss: -1.462,LR: 4.59E-04]Training epoch 19:  40%|███▉      | 61/153 [00:01<00:01, 52.80it/s, Epoch: 19, Batch: 62,Loss: -1.669,Avg.Loss: -1.465,LR: 4.59E-04]Training epoch 19:  41%|████      | 62/153 [00:01<00:01, 52.80it/s, Epoch: 19, Batch: 63,Loss: -1.911,Avg.Loss: -1.472,LR: 4.59E-04]Training epoch 19:  41%|████      | 63/153 [00:01<00:01, 52.80it/s, Epoch: 19, Batch: 64,Loss: -2.024,Avg.Loss: -1.481,LR: 4.59E-04]Training epoch 19:  42%|████▏     | 64/153 [00:01<00:01, 52.80it/s, Epoch: 19, Batch: 65,Loss: -1.856,Avg.Loss: -1.486,LR: 4.59E-04]Training epoch 19:  42%|████▏     | 65/153 [00:01<00:01, 52.80it/s, Epoch: 19, Batch: 66,Loss: -1.075,Avg.Loss: -1.480,LR: 4.59E-04]Training epoch 19:  43%|████▎     | 66/153 [00:01<00:01, 53.02it/s, Epoch: 19, Batch: 66,Loss: -1.075,Avg.Loss: -1.480,LR: 4.59E-04]Training epoch 19:  43%|████▎     | 66/153 [00:01<00:01, 53.02it/s, Epoch: 19, Batch: 67,Loss: -1.936,Avg.Loss: -1.487,LR: 4.59E-04]Training epoch 19:  44%|████▍     | 67/153 [00:01<00:01, 53.02it/s, Epoch: 19, Batch: 68,Loss: -2.080,Avg.Loss: -1.496,LR: 4.59E-04]Training epoch 19:  44%|████▍     | 68/153 [00:01<00:01, 53.02it/s, Epoch: 19, Batch: 69,Loss: -1.416,Avg.Loss: -1.495,LR: 4.59E-04]Training epoch 19:  45%|████▌     | 69/153 [00:01<00:01, 53.02it/s, Epoch: 19, Batch: 70,Loss: -1.885,Avg.Loss: -1.500,LR: 4.59E-04]Training epoch 19:  46%|████▌     | 70/153 [00:01<00:01, 53.02it/s, Epoch: 19, Batch: 71,Loss: -2.036,Avg.Loss: -1.508,LR: 4.59E-04]Training epoch 19:  46%|████▋     | 71/153 [00:01<00:01, 53.02it/s, Epoch: 19, Batch: 72,Loss: -1.533,Avg.Loss: -1.508,LR: 4.59E-04]Training epoch 19:  47%|████▋     | 72/153 [00:01<00:01, 52.86it/s, Epoch: 19, Batch: 72,Loss: -1.533,Avg.Loss: -1.508,LR: 4.59E-04]Training epoch 19:  47%|████▋     | 72/153 [00:01<00:01, 52.86it/s, Epoch: 19, Batch: 73,Loss: -1.281,Avg.Loss: -1.505,LR: 4.59E-04]Training epoch 19:  48%|████▊     | 73/153 [00:01<00:01, 52.86it/s, Epoch: 19, Batch: 74,Loss: -0.931,Avg.Loss: -1.497,LR: 4.59E-04]Training epoch 19:  48%|████▊     | 74/153 [00:01<00:01, 52.86it/s, Epoch: 19, Batch: 75,Loss: -0.653,Avg.Loss: -1.486,LR: 4.59E-04]Training epoch 19:  49%|████▉     | 75/153 [00:01<00:01, 52.86it/s, Epoch: 19, Batch: 76,Loss: -0.882,Avg.Loss: -1.478,LR: 4.59E-04]Training epoch 19:  50%|████▉     | 76/153 [00:01<00:01, 52.86it/s, Epoch: 19, Batch: 77,Loss: -1.408,Avg.Loss: -1.477,LR: 4.59E-04]Training epoch 19:  50%|█████     | 77/153 [00:01<00:01, 52.86it/s, Epoch: 19, Batch: 78,Loss: -1.271,Avg.Loss: -1.474,LR: 4.59E-04]Training epoch 19:  51%|█████     | 78/153 [00:01<00:01, 52.73it/s, Epoch: 19, Batch: 78,Loss: -1.271,Avg.Loss: -1.474,LR: 4.59E-04]Training epoch 19:  51%|█████     | 78/153 [00:01<00:01, 52.73it/s, Epoch: 19, Batch: 79,Loss: -0.302,Avg.Loss: -1.460,LR: 4.59E-04]Training epoch 19:  52%|█████▏    | 79/153 [00:01<00:01, 52.73it/s, Epoch: 19, Batch: 80,Loss: -0.682,Avg.Loss: -1.450,LR: 4.59E-04]Training epoch 19:  52%|█████▏    | 80/153 [00:01<00:01, 52.73it/s, Epoch: 19, Batch: 81,Loss: -1.377,Avg.Loss: -1.449,LR: 4.59E-04]Training epoch 19:  53%|█████▎    | 81/153 [00:01<00:01, 52.73it/s, Epoch: 19, Batch: 82,Loss: -1.286,Avg.Loss: -1.447,LR: 4.59E-04]Training epoch 19:  54%|█████▎    | 82/153 [00:01<00:01, 52.73it/s, Epoch: 19, Batch: 83,Loss: -1.895,Avg.Loss: -1.452,LR: 4.59E-04]Training epoch 19:  54%|█████▍    | 83/153 [00:01<00:01, 52.73it/s, Epoch: 19, Batch: 84,Loss: -1.484,Avg.Loss: -1.453,LR: 4.59E-04]Training epoch 19:  55%|█████▍    | 84/153 [00:01<00:01, 53.12it/s, Epoch: 19, Batch: 84,Loss: -1.484,Avg.Loss: -1.453,LR: 4.59E-04]Training epoch 19:  55%|█████▍    | 84/153 [00:01<00:01, 53.12it/s, Epoch: 19, Batch: 85,Loss: -1.029,Avg.Loss: -1.448,LR: 4.59E-04]Training epoch 19:  56%|█████▌    | 85/153 [00:01<00:01, 53.12it/s, Epoch: 19, Batch: 86,Loss: -1.923,Avg.Loss: -1.453,LR: 4.59E-04]Training epoch 19:  56%|█████▌    | 86/153 [00:01<00:01, 53.12it/s, Epoch: 19, Batch: 87,Loss: -1.963,Avg.Loss: -1.459,LR: 4.59E-04]Training epoch 19:  57%|█████▋    | 87/153 [00:01<00:01, 53.12it/s, Epoch: 19, Batch: 88,Loss: -1.925,Avg.Loss: -1.464,LR: 4.59E-04]Training epoch 19:  58%|█████▊    | 88/153 [00:01<00:01, 53.12it/s, Epoch: 19, Batch: 89,Loss: -1.855,Avg.Loss: -1.469,LR: 4.59E-04]Training epoch 19:  58%|█████▊    | 89/153 [00:01<00:01, 53.12it/s, Epoch: 19, Batch: 90,Loss: -1.754,Avg.Loss: -1.472,LR: 4.59E-04]Training epoch 19:  59%|█████▉    | 90/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 90,Loss: -1.754,Avg.Loss: -1.472,LR: 4.59E-04]Training epoch 19:  59%|█████▉    | 90/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 91,Loss: -2.055,Avg.Loss: -1.478,LR: 4.59E-04]Training epoch 19:  59%|█████▉    | 91/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 92,Loss: -1.702,Avg.Loss: -1.481,LR: 4.59E-04]Training epoch 19:  60%|██████    | 92/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 93,Loss: -0.444,Avg.Loss: -1.470,LR: 4.58E-04]Training epoch 19:  61%|██████    | 93/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 94,Loss: -0.544,Avg.Loss: -1.460,LR: 4.58E-04]Training epoch 19:  61%|██████▏   | 94/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 95,Loss: -1.383,Avg.Loss: -1.459,LR: 4.58E-04]Training epoch 19:  62%|██████▏   | 95/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 96,Loss: -1.331,Avg.Loss: -1.458,LR: 4.58E-04]Training epoch 19:  63%|██████▎   | 96/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 96,Loss: -1.331,Avg.Loss: -1.458,LR: 4.58E-04]Training epoch 19:  63%|██████▎   | 96/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 97,Loss: -1.619,Avg.Loss: -1.459,LR: 4.58E-04]Training epoch 19:  63%|██████▎   | 97/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 98,Loss: -1.908,Avg.Loss: -1.464,LR: 4.58E-04]Training epoch 19:  64%|██████▍   | 98/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 99,Loss: -1.044,Avg.Loss: -1.460,LR: 4.58E-04]Training epoch 19:  65%|██████▍   | 99/153 [00:01<00:01, 53.28it/s, Epoch: 19, Batch: 100,Loss: -1.714,Avg.Loss: -1.462,LR: 4.58E-04]Training epoch 19:  65%|██████▌   | 100/153 [00:01<00:00, 53.28it/s, Epoch: 19, Batch: 101,Loss: -1.448,Avg.Loss: -1.462,LR: 4.58E-04]Training epoch 19:  66%|██████▌   | 101/153 [00:01<00:00, 53.28it/s, Epoch: 19, Batch: 102,Loss: -1.905,Avg.Loss: -1.466,LR: 4.58E-04]Training epoch 19:  67%|██████▋   | 102/153 [00:01<00:00, 53.22it/s, Epoch: 19, Batch: 102,Loss: -1.905,Avg.Loss: -1.466,LR: 4.58E-04]Training epoch 19:  67%|██████▋   | 102/153 [00:01<00:00, 53.22it/s, Epoch: 19, Batch: 103,Loss: -1.942,Avg.Loss: -1.471,LR: 4.58E-04]Training epoch 19:  67%|██████▋   | 103/153 [00:01<00:00, 53.22it/s, Epoch: 19, Batch: 104,Loss: -1.915,Avg.Loss: -1.475,LR: 4.58E-04]Training epoch 19:  68%|██████▊   | 104/153 [00:01<00:00, 53.22it/s, Epoch: 19, Batch: 105,Loss: -1.868,Avg.Loss: -1.479,LR: 4.58E-04]Training epoch 19:  69%|██████▊   | 105/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 106,Loss: -2.005,Avg.Loss: -1.484,LR: 4.58E-04]Training epoch 19:  69%|██████▉   | 106/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 107,Loss: -1.501,Avg.Loss: -1.484,LR: 4.58E-04]Training epoch 19:  70%|██████▉   | 107/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 108,Loss: -1.017,Avg.Loss: -1.480,LR: 4.58E-04]Training epoch 19:  71%|███████   | 108/153 [00:02<00:00, 53.13it/s, Epoch: 19, Batch: 108,Loss: -1.017,Avg.Loss: -1.480,LR: 4.58E-04]Training epoch 19:  71%|███████   | 108/153 [00:02<00:00, 53.13it/s, Epoch: 19, Batch: 109,Loss: -1.278,Avg.Loss: -1.478,LR: 4.58E-04]Training epoch 19:  71%|███████   | 109/153 [00:02<00:00, 53.13it/s, Epoch: 19, Batch: 110,Loss: -1.922,Avg.Loss: -1.482,LR: 4.58E-04]Training epoch 19:  72%|███████▏  | 110/153 [00:02<00:00, 53.13it/s, Epoch: 19, Batch: 111,Loss: -1.661,Avg.Loss: -1.484,LR: 4.58E-04]Training epoch 19:  73%|███████▎  | 111/153 [00:02<00:00, 53.13it/s, Epoch: 19, Batch: 112,Loss: -1.486,Avg.Loss: -1.484,LR: 4.58E-04]Training epoch 19:  73%|███████▎  | 112/153 [00:02<00:00, 53.13it/s, Epoch: 19, Batch: 113,Loss: -1.504,Avg.Loss: -1.484,LR: 4.58E-04]Training epoch 19:  74%|███████▍  | 113/153 [00:02<00:00, 53.13it/s, Epoch: 19, Batch: 114,Loss: -1.907,Avg.Loss: -1.488,LR: 4.58E-04]Training epoch 19:  75%|███████▍  | 114/153 [00:02<00:00, 53.04it/s, Epoch: 19, Batch: 114,Loss: -1.907,Avg.Loss: -1.488,LR: 4.58E-04]Training epoch 19:  75%|███████▍  | 114/153 [00:02<00:00, 53.04it/s, Epoch: 19, Batch: 115,Loss: -1.442,Avg.Loss: -1.487,LR: 4.58E-04]Training epoch 19:  75%|███████▌  | 115/153 [00:02<00:00, 53.04it/s, Epoch: 19, Batch: 116,Loss: -1.159,Avg.Loss: -1.484,LR: 4.58E-04]Training epoch 19:  76%|███████▌  | 116/153 [00:02<00:00, 53.04it/s, Epoch: 19, Batch: 117,Loss: -2.107,Avg.Loss: -1.490,LR: 4.58E-04]Training epoch 19:  76%|███████▋  | 117/153 [00:02<00:00, 53.04it/s, Epoch: 19, Batch: 118,Loss: -1.313,Avg.Loss: -1.488,LR: 4.58E-04]Training epoch 19:  77%|███████▋  | 118/153 [00:02<00:00, 53.04it/s, Epoch: 19, Batch: 119,Loss: -0.758,Avg.Loss: -1.482,LR: 4.58E-04]Training epoch 19:  78%|███████▊  | 119/153 [00:02<00:00, 53.04it/s, Epoch: 19, Batch: 120,Loss: -1.514,Avg.Loss: -1.482,LR: 4.58E-04]Training epoch 19:  78%|███████▊  | 120/153 [00:02<00:00, 53.12it/s, Epoch: 19, Batch: 120,Loss: -1.514,Avg.Loss: -1.482,LR: 4.58E-04]Training epoch 19:  78%|███████▊  | 120/153 [00:02<00:00, 53.12it/s, Epoch: 19, Batch: 121,Loss: -1.264,Avg.Loss: -1.480,LR: 4.58E-04]Training epoch 19:  79%|███████▉  | 121/153 [00:02<00:00, 53.12it/s, Epoch: 19, Batch: 122,Loss: -1.706,Avg.Loss: -1.482,LR: 4.58E-04]Training epoch 19:  80%|███████▉  | 122/153 [00:02<00:00, 53.12it/s, Epoch: 19, Batch: 123,Loss: -1.559,Avg.Loss: -1.483,LR: 4.58E-04]Training epoch 19:  80%|████████  | 123/153 [00:02<00:00, 53.12it/s, Epoch: 19, Batch: 124,Loss: -1.478,Avg.Loss: -1.483,LR: 4.58E-04]Training epoch 19:  81%|████████  | 124/153 [00:02<00:00, 53.12it/s, Epoch: 19, Batch: 125,Loss: -1.754,Avg.Loss: -1.485,LR: 4.58E-04]Training epoch 19:  82%|████████▏ | 125/153 [00:02<00:00, 53.12it/s, Epoch: 19, Batch: 126,Loss: -1.476,Avg.Loss: -1.485,LR: 4.58E-04]Training epoch 19:  82%|████████▏ | 126/153 [00:02<00:00, 53.29it/s, Epoch: 19, Batch: 126,Loss: -1.476,Avg.Loss: -1.485,LR: 4.58E-04]Training epoch 19:  82%|████████▏ | 126/153 [00:02<00:00, 53.29it/s, Epoch: 19, Batch: 127,Loss: -1.903,Avg.Loss: -1.488,LR: 4.58E-04]Training epoch 19:  83%|████████▎ | 127/153 [00:02<00:00, 53.29it/s, Epoch: 19, Batch: 128,Loss: -1.045,Avg.Loss: -1.485,LR: 4.57E-04]Training epoch 19:  84%|████████▎ | 128/153 [00:02<00:00, 53.29it/s, Epoch: 19, Batch: 129,Loss: -1.893,Avg.Loss: -1.488,LR: 4.57E-04]Training epoch 19:  84%|████████▍ | 129/153 [00:02<00:00, 53.29it/s, Epoch: 19, Batch: 130,Loss: -1.728,Avg.Loss: -1.490,LR: 4.57E-04]Training epoch 19:  85%|████████▍ | 130/153 [00:02<00:00, 53.29it/s, Epoch: 19, Batch: 131,Loss: -2.029,Avg.Loss: -1.494,LR: 4.57E-04]Training epoch 19:  86%|████████▌ | 131/153 [00:02<00:00, 53.29it/s, Epoch: 19, Batch: 132,Loss: -2.614,Avg.Loss: -1.502,LR: 4.57E-04]Training epoch 19:  86%|████████▋ | 132/153 [00:02<00:00, 53.19it/s, Epoch: 19, Batch: 132,Loss: -2.614,Avg.Loss: -1.502,LR: 4.57E-04]Training epoch 19:  86%|████████▋ | 132/153 [00:02<00:00, 53.19it/s, Epoch: 19, Batch: 133,Loss: -1.124,Avg.Loss: -1.500,LR: 4.57E-04]Training epoch 19:  87%|████████▋ | 133/153 [00:02<00:00, 53.19it/s, Epoch: 19, Batch: 134,Loss: -0.986,Avg.Loss: -1.496,LR: 4.57E-04]Training epoch 19:  88%|████████▊ | 134/153 [00:02<00:00, 53.19it/s, Epoch: 19, Batch: 135,Loss: -1.293,Avg.Loss: -1.494,LR: 4.57E-04]Training epoch 19:  88%|████████▊ | 135/153 [00:02<00:00, 53.19it/s, Epoch: 19, Batch: 136,Loss: -1.870,Avg.Loss: -1.497,LR: 4.57E-04]Training epoch 19:  89%|████████▉ | 136/153 [00:02<00:00, 53.19it/s, Epoch: 19, Batch: 137,Loss: -2.094,Avg.Loss: -1.501,LR: 4.57E-04]Training epoch 19:  90%|████████▉ | 137/153 [00:02<00:00, 53.19it/s, Epoch: 19, Batch: 138,Loss: -2.279,Avg.Loss: -1.507,LR: 4.57E-04]Training epoch 19:  90%|█████████ | 138/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 138,Loss: -2.279,Avg.Loss: -1.507,LR: 4.57E-04]Training epoch 19:  90%|█████████ | 138/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 139,Loss: -1.007,Avg.Loss: -1.503,LR: 4.57E-04]Training epoch 19:  91%|█████████ | 139/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 140,Loss: -1.458,Avg.Loss: -1.503,LR: 4.57E-04]Training epoch 19:  92%|█████████▏| 140/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 141,Loss: -1.488,Avg.Loss: -1.503,LR: 4.57E-04]Training epoch 19:  92%|█████████▏| 141/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 142,Loss: -1.564,Avg.Loss: -1.503,LR: 4.57E-04]Training epoch 19:  93%|█████████▎| 142/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 143,Loss: -2.143,Avg.Loss: -1.508,LR: 4.57E-04]Training epoch 19:  93%|█████████▎| 143/153 [00:02<00:00, 53.22it/s, Epoch: 19, Batch: 144,Loss: -1.832,Avg.Loss: -1.510,LR: 4.57E-04]Training epoch 19:  94%|█████████▍| 144/153 [00:02<00:00, 53.24it/s, Epoch: 19, Batch: 144,Loss: -1.832,Avg.Loss: -1.510,LR: 4.57E-04]Training epoch 19:  94%|█████████▍| 144/153 [00:02<00:00, 53.24it/s, Epoch: 19, Batch: 145,Loss: -1.674,Avg.Loss: -1.511,LR: 4.57E-04]Training epoch 19:  95%|█████████▍| 145/153 [00:02<00:00, 53.24it/s, Epoch: 19, Batch: 146,Loss: -1.748,Avg.Loss: -1.513,LR: 4.57E-04]Training epoch 19:  95%|█████████▌| 146/153 [00:02<00:00, 53.24it/s, Epoch: 19, Batch: 147,Loss: -2.120,Avg.Loss: -1.517,LR: 4.57E-04]Training epoch 19:  96%|█████████▌| 147/153 [00:02<00:00, 53.24it/s, Epoch: 19, Batch: 148,Loss: -1.455,Avg.Loss: -1.517,LR: 4.57E-04]Training epoch 19:  97%|█████████▋| 148/153 [00:02<00:00, 53.24it/s, Epoch: 19, Batch: 149,Loss: -0.551,Avg.Loss: -1.510,LR: 4.57E-04]Training epoch 19:  97%|█████████▋| 149/153 [00:02<00:00, 53.24it/s, Epoch: 19, Batch: 150,Loss: -1.160,Avg.Loss: -1.508,LR: 4.57E-04]Training epoch 19:  98%|█████████▊| 150/153 [00:02<00:00, 53.31it/s, Epoch: 19, Batch: 150,Loss: -1.160,Avg.Loss: -1.508,LR: 4.57E-04]Training epoch 19:  98%|█████████▊| 150/153 [00:02<00:00, 53.31it/s, Epoch: 19, Batch: 151,Loss: -1.479,Avg.Loss: -1.508,LR: 4.57E-04]Training epoch 19:  99%|█████████▊| 151/153 [00:02<00:00, 53.31it/s, Epoch: 19, Batch: 152,Loss: -1.770,Avg.Loss: -1.509,LR: 4.57E-04]Training epoch 19:  99%|█████████▉| 152/153 [00:02<00:00, 53.31it/s, Epoch: 19, Batch: 153,Loss: -2.006,Avg.Loss: -1.513,LR: 4.57E-04]Training epoch 19: 100%|██████████| 153/153 [00:02<00:00, 52.87it/s, Epoch: 19, Batch: 153,Loss: -2.006,Avg.Loss: -1.513,LR: 4.57E-04]
Training epoch 20:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 20:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 20, Batch: 1,Loss: -1.723,Avg.Loss: -1.723,LR: 4.57E-04]Training epoch 20:   1%|          | 1/153 [00:00<00:06, 23.36it/s, Epoch: 20, Batch: 2,Loss: -1.135,Avg.Loss: -1.429,LR: 4.57E-04]Training epoch 20:   1%|▏         | 2/153 [00:00<00:04, 33.61it/s, Epoch: 20, Batch: 3,Loss: -0.954,Avg.Loss: -1.271,LR: 4.57E-04]Training epoch 20:   2%|▏         | 3/153 [00:00<00:03, 39.41it/s, Epoch: 20, Batch: 4,Loss: -0.765,Avg.Loss: -1.145,LR: 4.57E-04]Training epoch 20:   3%|▎         | 4/153 [00:00<00:03, 42.30it/s, Epoch: 20, Batch: 5,Loss: -1.454,Avg.Loss: -1.207,LR: 4.57E-04]Training epoch 20:   3%|▎         | 5/153 [00:00<00:03, 44.23it/s, Epoch: 20, Batch: 6,Loss: -1.821,Avg.Loss: -1.309,LR: 4.57E-04]Training epoch 20:   4%|▍         | 6/153 [00:00<00:02, 52.99it/s, Epoch: 20, Batch: 6,Loss: -1.821,Avg.Loss: -1.309,LR: 4.57E-04]Training epoch 20:   4%|▍         | 6/153 [00:00<00:02, 52.99it/s, Epoch: 20, Batch: 7,Loss: -1.628,Avg.Loss: -1.354,LR: 4.57E-04]Training epoch 20:   5%|▍         | 7/153 [00:00<00:02, 52.99it/s, Epoch: 20, Batch: 8,Loss: -1.003,Avg.Loss: -1.311,LR: 4.57E-04]Training epoch 20:   5%|▌         | 8/153 [00:00<00:02, 52.99it/s, Epoch: 20, Batch: 9,Loss: -1.664,Avg.Loss: -1.350,LR: 4.57E-04]Training epoch 20:   6%|▌         | 9/153 [00:00<00:02, 52.99it/s, Epoch: 20, Batch: 10,Loss: -1.292,Avg.Loss: -1.344,LR: 4.56E-04]Training epoch 20:   7%|▋         | 10/153 [00:00<00:02, 52.99it/s, Epoch: 20, Batch: 11,Loss: -1.261,Avg.Loss: -1.336,LR: 4.56E-04]Training epoch 20:   7%|▋         | 11/153 [00:00<00:02, 52.99it/s, Epoch: 20, Batch: 12,Loss: -1.492,Avg.Loss: -1.349,LR: 4.56E-04]Training epoch 20:   8%|▊         | 12/153 [00:00<00:02, 53.40it/s, Epoch: 20, Batch: 12,Loss: -1.492,Avg.Loss: -1.349,LR: 4.56E-04]Training epoch 20:   8%|▊         | 12/153 [00:00<00:02, 53.40it/s, Epoch: 20, Batch: 13,Loss: -1.896,Avg.Loss: -1.391,LR: 4.56E-04]Training epoch 20:   8%|▊         | 13/153 [00:00<00:02, 53.40it/s, Epoch: 20, Batch: 14,Loss: -1.386,Avg.Loss: -1.391,LR: 4.56E-04]Training epoch 20:   9%|▉         | 14/153 [00:00<00:02, 53.40it/s, Epoch: 20, Batch: 15,Loss: -1.564,Avg.Loss: -1.403,LR: 4.56E-04]Training epoch 20:  10%|▉         | 15/153 [00:00<00:02, 53.40it/s, Epoch: 20, Batch: 16,Loss: -1.813,Avg.Loss: -1.428,LR: 4.56E-04]Training epoch 20:  10%|█         | 16/153 [00:00<00:02, 53.40it/s, Epoch: 20, Batch: 17,Loss: -1.738,Avg.Loss: -1.446,LR: 4.56E-04]Training epoch 20:  11%|█         | 17/153 [00:00<00:02, 53.40it/s, Epoch: 20, Batch: 18,Loss: -2.002,Avg.Loss: -1.477,LR: 4.56E-04]Training epoch 20:  12%|█▏        | 18/153 [00:00<00:02, 53.59it/s, Epoch: 20, Batch: 18,Loss: -2.002,Avg.Loss: -1.477,LR: 4.56E-04]Training epoch 20:  12%|█▏        | 18/153 [00:00<00:02, 53.59it/s, Epoch: 20, Batch: 19,Loss: -1.748,Avg.Loss: -1.492,LR: 4.56E-04]Training epoch 20:  12%|█▏        | 19/153 [00:00<00:02, 53.59it/s, Epoch: 20, Batch: 20,Loss: -1.656,Avg.Loss: -1.500,LR: 4.56E-04]Training epoch 20:  13%|█▎        | 20/153 [00:00<00:02, 53.59it/s, Epoch: 20, Batch: 21,Loss: -1.404,Avg.Loss: -1.495,LR: 4.56E-04]Training epoch 20:  14%|█▎        | 21/153 [00:00<00:02, 53.59it/s, Epoch: 20, Batch: 22,Loss: -2.066,Avg.Loss: -1.521,LR: 4.56E-04]Training epoch 20:  14%|█▍        | 22/153 [00:00<00:02, 53.59it/s, Epoch: 20, Batch: 23,Loss: -1.535,Avg.Loss: -1.522,LR: 4.56E-04]Training epoch 20:  15%|█▌        | 23/153 [00:00<00:02, 53.59it/s, Epoch: 20, Batch: 24,Loss: -1.417,Avg.Loss: -1.517,LR: 4.56E-04]Training epoch 20:  16%|█▌        | 24/153 [00:00<00:02, 52.90it/s, Epoch: 20, Batch: 24,Loss: -1.417,Avg.Loss: -1.517,LR: 4.56E-04]Training epoch 20:  16%|█▌        | 24/153 [00:00<00:02, 52.90it/s, Epoch: 20, Batch: 25,Loss: -1.448,Avg.Loss: -1.515,LR: 4.56E-04]Training epoch 20:  16%|█▋        | 25/153 [00:00<00:02, 52.90it/s, Epoch: 20, Batch: 26,Loss: -1.849,Avg.Loss: -1.528,LR: 4.56E-04]Training epoch 20:  17%|█▋        | 26/153 [00:00<00:02, 52.90it/s, Epoch: 20, Batch: 27,Loss: -1.446,Avg.Loss: -1.524,LR: 4.56E-04]Training epoch 20:  18%|█▊        | 27/153 [00:00<00:02, 52.90it/s, Epoch: 20, Batch: 28,Loss: -2.153,Avg.Loss: -1.547,LR: 4.56E-04]Training epoch 20:  18%|█▊        | 28/153 [00:00<00:02, 52.90it/s, Epoch: 20, Batch: 29,Loss: -1.855,Avg.Loss: -1.558,LR: 4.56E-04]Training epoch 20:  19%|█▉        | 29/153 [00:00<00:02, 52.90it/s, Epoch: 20, Batch: 30,Loss: -1.807,Avg.Loss: -1.566,LR: 4.56E-04]Training epoch 20:  20%|█▉        | 30/153 [00:00<00:02, 52.31it/s, Epoch: 20, Batch: 30,Loss: -1.807,Avg.Loss: -1.566,LR: 4.56E-04]Training epoch 20:  20%|█▉        | 30/153 [00:00<00:02, 52.31it/s, Epoch: 20, Batch: 31,Loss: -2.083,Avg.Loss: -1.582,LR: 4.56E-04]Training epoch 20:  20%|██        | 31/153 [00:00<00:02, 52.31it/s, Epoch: 20, Batch: 32,Loss: -1.857,Avg.Loss: -1.591,LR: 4.56E-04]Training epoch 20:  21%|██        | 32/153 [00:00<00:02, 52.31it/s, Epoch: 20, Batch: 33,Loss: -2.114,Avg.Loss: -1.607,LR: 4.56E-04]Training epoch 20:  22%|██▏       | 33/153 [00:00<00:02, 52.31it/s, Epoch: 20, Batch: 34,Loss: -2.220,Avg.Loss: -1.625,LR: 4.56E-04]Training epoch 20:  22%|██▏       | 34/153 [00:00<00:02, 52.31it/s, Epoch: 20, Batch: 35,Loss: -2.009,Avg.Loss: -1.636,LR: 4.56E-04]Training epoch 20:  23%|██▎       | 35/153 [00:00<00:02, 52.31it/s, Epoch: 20, Batch: 36,Loss: -2.031,Avg.Loss: -1.647,LR: 4.56E-04]Training epoch 20:  24%|██▎       | 36/153 [00:00<00:02, 52.72it/s, Epoch: 20, Batch: 36,Loss: -2.031,Avg.Loss: -1.647,LR: 4.56E-04]Training epoch 20:  24%|██▎       | 36/153 [00:00<00:02, 52.72it/s, Epoch: 20, Batch: 37,Loss: -2.105,Avg.Loss: -1.659,LR: 4.56E-04]Training epoch 20:  24%|██▍       | 37/153 [00:00<00:02, 52.72it/s, Epoch: 20, Batch: 38,Loss: -1.928,Avg.Loss: -1.666,LR: 4.56E-04]Training epoch 20:  25%|██▍       | 38/153 [00:00<00:02, 52.72it/s, Epoch: 20, Batch: 39,Loss: -1.894,Avg.Loss: -1.672,LR: 4.56E-04]Training epoch 20:  25%|██▌       | 39/153 [00:00<00:02, 52.72it/s, Epoch: 20, Batch: 40,Loss: -2.354,Avg.Loss: -1.689,LR: 4.56E-04]Training epoch 20:  26%|██▌       | 40/153 [00:00<00:02, 52.72it/s, Epoch: 20, Batch: 41,Loss: -1.856,Avg.Loss: -1.693,LR: 4.56E-04]Training epoch 20:  27%|██▋       | 41/153 [00:00<00:02, 52.72it/s, Epoch: 20, Batch: 42,Loss: -1.921,Avg.Loss: -1.699,LR: 4.56E-04]Training epoch 20:  27%|██▋       | 42/153 [00:00<00:02, 52.83it/s, Epoch: 20, Batch: 42,Loss: -1.921,Avg.Loss: -1.699,LR: 4.56E-04]Training epoch 20:  27%|██▋       | 42/153 [00:00<00:02, 52.83it/s, Epoch: 20, Batch: 43,Loss: -2.000,Avg.Loss: -1.706,LR: 4.56E-04]Training epoch 20:  28%|██▊       | 43/153 [00:00<00:02, 52.83it/s, Epoch: 20, Batch: 44,Loss: -2.058,Avg.Loss: -1.714,LR: 4.55E-04]Training epoch 20:  29%|██▉       | 44/153 [00:00<00:02, 52.83it/s, Epoch: 20, Batch: 45,Loss: -1.960,Avg.Loss: -1.719,LR: 4.55E-04]Training epoch 20:  29%|██▉       | 45/153 [00:00<00:02, 52.83it/s, Epoch: 20, Batch: 46,Loss: -1.658,Avg.Loss: -1.718,LR: 4.55E-04]Training epoch 20:  30%|███       | 46/153 [00:00<00:02, 52.83it/s, Epoch: 20, Batch: 47,Loss: -1.655,Avg.Loss: -1.717,LR: 4.55E-04]Training epoch 20:  31%|███       | 47/153 [00:00<00:02, 52.83it/s, Epoch: 20, Batch: 48,Loss: -1.982,Avg.Loss: -1.722,LR: 4.55E-04]Training epoch 20:  31%|███▏      | 48/153 [00:00<00:01, 52.97it/s, Epoch: 20, Batch: 48,Loss: -1.982,Avg.Loss: -1.722,LR: 4.55E-04]Training epoch 20:  31%|███▏      | 48/153 [00:00<00:01, 52.97it/s, Epoch: 20, Batch: 49,Loss: -1.410,Avg.Loss: -1.716,LR: 4.55E-04]Training epoch 20:  32%|███▏      | 49/153 [00:00<00:01, 52.97it/s, Epoch: 20, Batch: 50,Loss: -1.573,Avg.Loss: -1.713,LR: 4.55E-04]Training epoch 20:  33%|███▎      | 50/153 [00:00<00:01, 52.97it/s, Epoch: 20, Batch: 51,Loss: -1.691,Avg.Loss: -1.712,LR: 4.55E-04]Training epoch 20:  33%|███▎      | 51/153 [00:00<00:01, 52.97it/s, Epoch: 20, Batch: 52,Loss: -1.734,Avg.Loss: -1.713,LR: 4.55E-04]Training epoch 20:  34%|███▍      | 52/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 53,Loss: -1.921,Avg.Loss: -1.717,LR: 4.55E-04]Training epoch 20:  35%|███▍      | 53/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 54,Loss: -2.122,Avg.Loss: -1.724,LR: 4.55E-04]Training epoch 20:  35%|███▌      | 54/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 54,Loss: -2.122,Avg.Loss: -1.724,LR: 4.55E-04]Training epoch 20:  35%|███▌      | 54/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 55,Loss: -2.287,Avg.Loss: -1.734,LR: 4.55E-04]Training epoch 20:  36%|███▌      | 55/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 56,Loss: -1.582,Avg.Loss: -1.732,LR: 4.55E-04]Training epoch 20:  37%|███▋      | 56/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 57,Loss: -0.664,Avg.Loss: -1.713,LR: 4.55E-04]Training epoch 20:  37%|███▋      | 57/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 58,Loss: -0.560,Avg.Loss: -1.693,LR: 4.55E-04]Training epoch 20:  38%|███▊      | 58/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 59,Loss: 0.035,Avg.Loss: -1.664,LR: 4.55E-04] Training epoch 20:  39%|███▊      | 59/153 [00:01<00:01, 52.97it/s, Epoch: 20, Batch: 60,Loss: 0.202,Avg.Loss: -1.633,LR: 4.55E-04]Training epoch 20:  39%|███▉      | 60/153 [00:01<00:01, 53.13it/s, Epoch: 20, Batch: 60,Loss: 0.202,Avg.Loss: -1.633,LR: 4.55E-04]Training epoch 20:  39%|███▉      | 60/153 [00:01<00:01, 53.13it/s, Epoch: 20, Batch: 61,Loss: -1.017,Avg.Loss: -1.623,LR: 4.55E-04]Training epoch 20:  40%|███▉      | 61/153 [00:01<00:01, 53.13it/s, Epoch: 20, Batch: 62,Loss: -1.672,Avg.Loss: -1.623,LR: 4.55E-04]Training epoch 20:  41%|████      | 62/153 [00:01<00:01, 53.13it/s, Epoch: 20, Batch: 63,Loss: -1.196,Avg.Loss: -1.617,LR: 4.55E-04]Training epoch 20:  41%|████      | 63/153 [00:01<00:01, 53.13it/s, Epoch: 20, Batch: 64,Loss: -1.005,Avg.Loss: -1.607,LR: 4.55E-04]Training epoch 20:  42%|████▏     | 64/153 [00:01<00:01, 53.13it/s, Epoch: 20, Batch: 65,Loss: -1.506,Avg.Loss: -1.606,LR: 4.55E-04]Training epoch 20:  42%|████▏     | 65/153 [00:01<00:01, 53.13it/s, Epoch: 20, Batch: 66,Loss: -1.241,Avg.Loss: -1.600,LR: 4.55E-04]Training epoch 20:  43%|████▎     | 66/153 [00:01<00:01, 53.06it/s, Epoch: 20, Batch: 66,Loss: -1.241,Avg.Loss: -1.600,LR: 4.55E-04]Training epoch 20:  43%|████▎     | 66/153 [00:01<00:01, 53.06it/s, Epoch: 20, Batch: 67,Loss: -0.799,Avg.Loss: -1.588,LR: 4.55E-04]Training epoch 20:  44%|████▍     | 67/153 [00:01<00:01, 53.06it/s, Epoch: 20, Batch: 68,Loss: -1.578,Avg.Loss: -1.588,LR: 4.55E-04]Training epoch 20:  44%|████▍     | 68/153 [00:01<00:01, 53.06it/s, Epoch: 20, Batch: 69,Loss: -2.078,Avg.Loss: -1.595,LR: 4.55E-04]Training epoch 20:  45%|████▌     | 69/153 [00:01<00:01, 53.06it/s, Epoch: 20, Batch: 70,Loss: -2.144,Avg.Loss: -1.603,LR: 4.55E-04]Training epoch 20:  46%|████▌     | 70/153 [00:01<00:01, 53.06it/s, Epoch: 20, Batch: 71,Loss: -2.155,Avg.Loss: -1.611,LR: 4.55E-04]Training epoch 20:  46%|████▋     | 71/153 [00:01<00:01, 53.06it/s, Epoch: 20, Batch: 72,Loss: -2.091,Avg.Loss: -1.617,LR: 4.55E-04]Training epoch 20:  47%|████▋     | 72/153 [00:01<00:01, 53.07it/s, Epoch: 20, Batch: 72,Loss: -2.091,Avg.Loss: -1.617,LR: 4.55E-04]Training epoch 20:  47%|████▋     | 72/153 [00:01<00:01, 53.07it/s, Epoch: 20, Batch: 73,Loss: -2.184,Avg.Loss: -1.625,LR: 4.55E-04]Training epoch 20:  48%|████▊     | 73/153 [00:01<00:01, 53.07it/s, Epoch: 20, Batch: 74,Loss: -1.842,Avg.Loss: -1.628,LR: 4.55E-04]Training epoch 20:  48%|████▊     | 74/153 [00:01<00:01, 53.07it/s, Epoch: 20, Batch: 75,Loss: -1.508,Avg.Loss: -1.626,LR: 4.55E-04]Training epoch 20:  49%|████▉     | 75/153 [00:01<00:01, 53.07it/s, Epoch: 20, Batch: 76,Loss: -1.568,Avg.Loss: -1.626,LR: 4.55E-04]Training epoch 20:  50%|████▉     | 76/153 [00:01<00:01, 53.07it/s, Epoch: 20, Batch: 77,Loss: -1.625,Avg.Loss: -1.626,LR: 4.55E-04]Training epoch 20:  50%|█████     | 77/153 [00:01<00:01, 53.07it/s, Epoch: 20, Batch: 78,Loss: -2.222,Avg.Loss: -1.633,LR: 4.54E-04]Training epoch 20:  51%|█████     | 78/153 [00:01<00:01, 52.85it/s, Epoch: 20, Batch: 78,Loss: -2.222,Avg.Loss: -1.633,LR: 4.54E-04]Training epoch 20:  51%|█████     | 78/153 [00:01<00:01, 52.85it/s, Epoch: 20, Batch: 79,Loss: -0.535,Avg.Loss: -1.619,LR: 4.54E-04]Training epoch 20:  52%|█████▏    | 79/153 [00:01<00:01, 52.85it/s, Epoch: 20, Batch: 80,Loss: 0.244,Avg.Loss: -1.596,LR: 4.54E-04] Training epoch 20:  52%|█████▏    | 80/153 [00:01<00:01, 52.85it/s, Epoch: 20, Batch: 81,Loss: -0.618,Avg.Loss: -1.584,LR: 4.54E-04]Training epoch 20:  53%|█████▎    | 81/153 [00:01<00:01, 52.85it/s, Epoch: 20, Batch: 82,Loss: -1.617,Avg.Loss: -1.584,LR: 4.54E-04]Training epoch 20:  54%|█████▎    | 82/153 [00:01<00:01, 52.85it/s, Epoch: 20, Batch: 83,Loss: -1.423,Avg.Loss: -1.582,LR: 4.54E-04]Training epoch 20:  54%|█████▍    | 83/153 [00:01<00:01, 52.85it/s, Epoch: 20, Batch: 84,Loss: -0.128,Avg.Loss: -1.565,LR: 4.54E-04]Training epoch 20:  55%|█████▍    | 84/153 [00:01<00:01, 52.98it/s, Epoch: 20, Batch: 84,Loss: -0.128,Avg.Loss: -1.565,LR: 4.54E-04]Training epoch 20:  55%|█████▍    | 84/153 [00:01<00:01, 52.98it/s, Epoch: 20, Batch: 85,Loss: -0.299,Avg.Loss: -1.550,LR: 4.54E-04]Training epoch 20:  56%|█████▌    | 85/153 [00:01<00:01, 52.98it/s, Epoch: 20, Batch: 86,Loss: -1.186,Avg.Loss: -1.546,LR: 4.54E-04]Training epoch 20:  56%|█████▌    | 86/153 [00:01<00:01, 52.98it/s, Epoch: 20, Batch: 87,Loss: -0.968,Avg.Loss: -1.539,LR: 4.54E-04]Training epoch 20:  57%|█████▋    | 87/153 [00:01<00:01, 52.98it/s, Epoch: 20, Batch: 88,Loss: -1.606,Avg.Loss: -1.540,LR: 4.54E-04]Training epoch 20:  58%|█████▊    | 88/153 [00:01<00:01, 52.98it/s, Epoch: 20, Batch: 89,Loss: -2.109,Avg.Loss: -1.547,LR: 4.54E-04]Training epoch 20:  58%|█████▊    | 89/153 [00:01<00:01, 52.98it/s, Epoch: 20, Batch: 90,Loss: -1.846,Avg.Loss: -1.550,LR: 4.54E-04]Training epoch 20:  59%|█████▉    | 90/153 [00:01<00:01, 52.88it/s, Epoch: 20, Batch: 90,Loss: -1.846,Avg.Loss: -1.550,LR: 4.54E-04]Training epoch 20:  59%|█████▉    | 90/153 [00:01<00:01, 52.88it/s, Epoch: 20, Batch: 91,Loss: -1.868,Avg.Loss: -1.553,LR: 4.54E-04]Training epoch 20:  59%|█████▉    | 91/153 [00:01<00:01, 52.88it/s, Epoch: 20, Batch: 92,Loss: -1.931,Avg.Loss: -1.557,LR: 4.54E-04]Training epoch 20:  60%|██████    | 92/153 [00:01<00:01, 52.88it/s, Epoch: 20, Batch: 93,Loss: -1.597,Avg.Loss: -1.558,LR: 4.54E-04]Training epoch 20:  61%|██████    | 93/153 [00:01<00:01, 52.88it/s, Epoch: 20, Batch: 94,Loss: -1.734,Avg.Loss: -1.560,LR: 4.54E-04]Training epoch 20:  61%|██████▏   | 94/153 [00:01<00:01, 52.88it/s, Epoch: 20, Batch: 95,Loss: -1.851,Avg.Loss: -1.563,LR: 4.54E-04]Training epoch 20:  62%|██████▏   | 95/153 [00:01<00:01, 52.88it/s, Epoch: 20, Batch: 96,Loss: -0.445,Avg.Loss: -1.551,LR: 4.54E-04]Training epoch 20:  63%|██████▎   | 96/153 [00:01<00:01, 52.64it/s, Epoch: 20, Batch: 96,Loss: -0.445,Avg.Loss: -1.551,LR: 4.54E-04]Training epoch 20:  63%|██████▎   | 96/153 [00:01<00:01, 52.64it/s, Epoch: 20, Batch: 97,Loss: -0.194,Avg.Loss: -1.537,LR: 4.54E-04]Training epoch 20:  63%|██████▎   | 97/153 [00:01<00:01, 52.64it/s, Epoch: 20, Batch: 98,Loss: -1.314,Avg.Loss: -1.535,LR: 4.54E-04]Training epoch 20:  64%|██████▍   | 98/153 [00:01<00:01, 52.64it/s, Epoch: 20, Batch: 99,Loss: -1.617,Avg.Loss: -1.536,LR: 4.54E-04]Training epoch 20:  65%|██████▍   | 99/153 [00:01<00:01, 52.64it/s, Epoch: 20, Batch: 100,Loss: -0.937,Avg.Loss: -1.530,LR: 4.54E-04]Training epoch 20:  65%|██████▌   | 100/153 [00:01<00:01, 52.64it/s, Epoch: 20, Batch: 101,Loss: 0.332,Avg.Loss: -1.511,LR: 4.54E-04]Training epoch 20:  66%|██████▌   | 101/153 [00:01<00:00, 52.64it/s, Epoch: 20, Batch: 102,Loss: -0.242,Avg.Loss: -1.499,LR: 4.54E-04]Training epoch 20:  67%|██████▋   | 102/153 [00:01<00:00, 52.57it/s, Epoch: 20, Batch: 102,Loss: -0.242,Avg.Loss: -1.499,LR: 4.54E-04]Training epoch 20:  67%|██████▋   | 102/153 [00:01<00:00, 52.57it/s, Epoch: 20, Batch: 103,Loss: -1.742,Avg.Loss: -1.501,LR: 4.54E-04]Training epoch 20:  67%|██████▋   | 103/153 [00:01<00:00, 52.57it/s, Epoch: 20, Batch: 104,Loss: -1.846,Avg.Loss: -1.505,LR: 4.54E-04]Training epoch 20:  68%|██████▊   | 104/153 [00:01<00:00, 52.57it/s, Epoch: 20, Batch: 105,Loss: -0.631,Avg.Loss: -1.496,LR: 4.54E-04]Training epoch 20:  69%|██████▊   | 105/153 [00:02<00:00, 52.57it/s, Epoch: 20, Batch: 106,Loss: -1.189,Avg.Loss: -1.493,LR: 4.54E-04]Training epoch 20:  69%|██████▉   | 106/153 [00:02<00:00, 52.57it/s, Epoch: 20, Batch: 107,Loss: -1.874,Avg.Loss: -1.497,LR: 4.54E-04]Training epoch 20:  70%|██████▉   | 107/153 [00:02<00:00, 52.57it/s, Epoch: 20, Batch: 108,Loss: -1.763,Avg.Loss: -1.499,LR: 4.54E-04]Training epoch 20:  71%|███████   | 108/153 [00:02<00:00, 52.60it/s, Epoch: 20, Batch: 108,Loss: -1.763,Avg.Loss: -1.499,LR: 4.54E-04]Training epoch 20:  71%|███████   | 108/153 [00:02<00:00, 52.60it/s, Epoch: 20, Batch: 109,Loss: -1.765,Avg.Loss: -1.502,LR: 4.54E-04]Training epoch 20:  71%|███████   | 109/153 [00:02<00:00, 52.60it/s, Epoch: 20, Batch: 110,Loss: -2.206,Avg.Loss: -1.508,LR: 4.54E-04]Training epoch 20:  72%|███████▏  | 110/153 [00:02<00:00, 52.60it/s, Epoch: 20, Batch: 111,Loss: -1.389,Avg.Loss: -1.507,LR: 4.54E-04]Training epoch 20:  73%|███████▎  | 111/153 [00:02<00:00, 52.60it/s, Epoch: 20, Batch: 112,Loss: -1.416,Avg.Loss: -1.506,LR: 4.53E-04]Training epoch 20:  73%|███████▎  | 112/153 [00:02<00:00, 52.60it/s, Epoch: 20, Batch: 113,Loss: -1.059,Avg.Loss: -1.502,LR: 4.53E-04]Training epoch 20:  74%|███████▍  | 113/153 [00:02<00:00, 52.60it/s, Epoch: 20, Batch: 114,Loss: -1.473,Avg.Loss: -1.502,LR: 4.53E-04]Training epoch 20:  75%|███████▍  | 114/153 [00:02<00:00, 52.69it/s, Epoch: 20, Batch: 114,Loss: -1.473,Avg.Loss: -1.502,LR: 4.53E-04]Training epoch 20:  75%|███████▍  | 114/153 [00:02<00:00, 52.69it/s, Epoch: 20, Batch: 115,Loss: -0.827,Avg.Loss: -1.496,LR: 4.53E-04]Training epoch 20:  75%|███████▌  | 115/153 [00:02<00:00, 52.69it/s, Epoch: 20, Batch: 116,Loss: -1.302,Avg.Loss: -1.495,LR: 4.53E-04]Training epoch 20:  76%|███████▌  | 116/153 [00:02<00:00, 52.69it/s, Epoch: 20, Batch: 117,Loss: -1.120,Avg.Loss: -1.491,LR: 4.53E-04]Training epoch 20:  76%|███████▋  | 117/153 [00:02<00:00, 52.69it/s, Epoch: 20, Batch: 118,Loss: -2.140,Avg.Loss: -1.497,LR: 4.53E-04]Training epoch 20:  77%|███████▋  | 118/153 [00:02<00:00, 52.69it/s, Epoch: 20, Batch: 119,Loss: -1.958,Avg.Loss: -1.501,LR: 4.53E-04]Training epoch 20:  78%|███████▊  | 119/153 [00:02<00:00, 52.69it/s, Epoch: 20, Batch: 120,Loss: -1.628,Avg.Loss: -1.502,LR: 4.53E-04]Training epoch 20:  78%|███████▊  | 120/153 [00:02<00:00, 52.81it/s, Epoch: 20, Batch: 120,Loss: -1.628,Avg.Loss: -1.502,LR: 4.53E-04]Training epoch 20:  78%|███████▊  | 120/153 [00:02<00:00, 52.81it/s, Epoch: 20, Batch: 121,Loss: -1.194,Avg.Loss: -1.499,LR: 4.53E-04]Training epoch 20:  79%|███████▉  | 121/153 [00:02<00:00, 52.81it/s, Epoch: 20, Batch: 122,Loss: -1.923,Avg.Loss: -1.503,LR: 4.53E-04]Training epoch 20:  80%|███████▉  | 122/153 [00:02<00:00, 52.81it/s, Epoch: 20, Batch: 123,Loss: -2.388,Avg.Loss: -1.510,LR: 4.53E-04]Training epoch 20:  80%|████████  | 123/153 [00:02<00:00, 52.81it/s, Epoch: 20, Batch: 124,Loss: -1.063,Avg.Loss: -1.506,LR: 4.53E-04]Training epoch 20:  81%|████████  | 124/153 [00:02<00:00, 52.81it/s, Epoch: 20, Batch: 125,Loss: 0.106,Avg.Loss: -1.493,LR: 4.53E-04] Training epoch 20:  82%|████████▏ | 125/153 [00:02<00:00, 52.81it/s, Epoch: 20, Batch: 126,Loss: -0.709,Avg.Loss: -1.487,LR: 4.53E-04]Training epoch 20:  82%|████████▏ | 126/153 [00:02<00:00, 52.66it/s, Epoch: 20, Batch: 126,Loss: -0.709,Avg.Loss: -1.487,LR: 4.53E-04]Training epoch 20:  82%|████████▏ | 126/153 [00:02<00:00, 52.66it/s, Epoch: 20, Batch: 127,Loss: -1.362,Avg.Loss: -1.486,LR: 4.53E-04]Training epoch 20:  83%|████████▎ | 127/153 [00:02<00:00, 52.66it/s, Epoch: 20, Batch: 128,Loss: -1.643,Avg.Loss: -1.487,LR: 4.53E-04]Training epoch 20:  84%|████████▎ | 128/153 [00:02<00:00, 52.66it/s, Epoch: 20, Batch: 129,Loss: -1.531,Avg.Loss: -1.488,LR: 4.53E-04]Training epoch 20:  84%|████████▍ | 129/153 [00:02<00:00, 52.66it/s, Epoch: 20, Batch: 130,Loss: -1.988,Avg.Loss: -1.492,LR: 4.53E-04]Training epoch 20:  85%|████████▍ | 130/153 [00:02<00:00, 52.66it/s, Epoch: 20, Batch: 131,Loss: -1.490,Avg.Loss: -1.492,LR: 4.53E-04]Training epoch 20:  86%|████████▌ | 131/153 [00:02<00:00, 52.66it/s, Epoch: 20, Batch: 132,Loss: -1.524,Avg.Loss: -1.492,LR: 4.53E-04]Training epoch 20:  86%|████████▋ | 132/153 [00:02<00:00, 52.87it/s, Epoch: 20, Batch: 132,Loss: -1.524,Avg.Loss: -1.492,LR: 4.53E-04]Training epoch 20:  86%|████████▋ | 132/153 [00:02<00:00, 52.87it/s, Epoch: 20, Batch: 133,Loss: -1.885,Avg.Loss: -1.495,LR: 4.53E-04]Training epoch 20:  87%|████████▋ | 133/153 [00:02<00:00, 52.87it/s, Epoch: 20, Batch: 134,Loss: -1.690,Avg.Loss: -1.496,LR: 4.53E-04]Training epoch 20:  88%|████████▊ | 134/153 [00:02<00:00, 52.87it/s, Epoch: 20, Batch: 135,Loss: -1.738,Avg.Loss: -1.498,LR: 4.53E-04]Training epoch 20:  88%|████████▊ | 135/153 [00:02<00:00, 52.87it/s, Epoch: 20, Batch: 136,Loss: -1.601,Avg.Loss: -1.499,LR: 4.53E-04]Training epoch 20:  89%|████████▉ | 136/153 [00:02<00:00, 52.87it/s, Epoch: 20, Batch: 137,Loss: -1.775,Avg.Loss: -1.501,LR: 4.53E-04]Training epoch 20:  90%|████████▉ | 137/153 [00:02<00:00, 52.87it/s, Epoch: 20, Batch: 138,Loss: -1.114,Avg.Loss: -1.498,LR: 4.53E-04]Training epoch 20:  90%|█████████ | 138/153 [00:02<00:00, 53.12it/s, Epoch: 20, Batch: 138,Loss: -1.114,Avg.Loss: -1.498,LR: 4.53E-04]Training epoch 20:  90%|█████████ | 138/153 [00:02<00:00, 53.12it/s, Epoch: 20, Batch: 139,Loss: -1.610,Avg.Loss: -1.499,LR: 4.53E-04]Training epoch 20:  91%|█████████ | 139/153 [00:02<00:00, 53.12it/s, Epoch: 20, Batch: 140,Loss: -1.983,Avg.Loss: -1.502,LR: 4.53E-04]Training epoch 20:  92%|█████████▏| 140/153 [00:02<00:00, 53.12it/s, Epoch: 20, Batch: 141,Loss: -1.635,Avg.Loss: -1.503,LR: 4.53E-04]Training epoch 20:  92%|█████████▏| 141/153 [00:02<00:00, 53.12it/s, Epoch: 20, Batch: 142,Loss: -1.618,Avg.Loss: -1.504,LR: 4.53E-04]Training epoch 20:  93%|█████████▎| 142/153 [00:02<00:00, 53.12it/s, Epoch: 20, Batch: 143,Loss: -1.707,Avg.Loss: -1.505,LR: 4.53E-04]Training epoch 20:  93%|█████████▎| 143/153 [00:02<00:00, 53.12it/s, Epoch: 20, Batch: 144,Loss: -1.696,Avg.Loss: -1.507,LR: 4.53E-04]Training epoch 20:  94%|█████████▍| 144/153 [00:02<00:00, 53.31it/s, Epoch: 20, Batch: 144,Loss: -1.696,Avg.Loss: -1.507,LR: 4.53E-04]Training epoch 20:  94%|█████████▍| 144/153 [00:02<00:00, 53.31it/s, Epoch: 20, Batch: 145,Loss: -1.674,Avg.Loss: -1.508,LR: 4.52E-04]Training epoch 20:  95%|█████████▍| 145/153 [00:02<00:00, 53.31it/s, Epoch: 20, Batch: 146,Loss: -1.863,Avg.Loss: -1.510,LR: 4.52E-04]Training epoch 20:  95%|█████████▌| 146/153 [00:02<00:00, 53.31it/s, Epoch: 20, Batch: 147,Loss: -1.823,Avg.Loss: -1.513,LR: 4.52E-04]Training epoch 20:  96%|█████████▌| 147/153 [00:02<00:00, 53.31it/s, Epoch: 20, Batch: 148,Loss: -1.310,Avg.Loss: -1.511,LR: 4.52E-04]Training epoch 20:  97%|█████████▋| 148/153 [00:02<00:00, 53.31it/s, Epoch: 20, Batch: 149,Loss: -1.636,Avg.Loss: -1.512,LR: 4.52E-04]Training epoch 20:  97%|█████████▋| 149/153 [00:02<00:00, 53.31it/s, Epoch: 20, Batch: 150,Loss: -2.044,Avg.Loss: -1.516,LR: 4.52E-04]Training epoch 20:  98%|█████████▊| 150/153 [00:02<00:00, 53.39it/s, Epoch: 20, Batch: 150,Loss: -2.044,Avg.Loss: -1.516,LR: 4.52E-04]Training epoch 20:  98%|█████████▊| 150/153 [00:02<00:00, 53.39it/s, Epoch: 20, Batch: 151,Loss: -1.313,Avg.Loss: -1.514,LR: 4.52E-04]Training epoch 20:  99%|█████████▊| 151/153 [00:02<00:00, 53.39it/s, Epoch: 20, Batch: 152,Loss: -0.746,Avg.Loss: -1.509,LR: 4.52E-04]Training epoch 20:  99%|█████████▉| 152/153 [00:02<00:00, 53.39it/s, Epoch: 20, Batch: 153,Loss: -1.623,Avg.Loss: -1.510,LR: 4.52E-04]Training epoch 20: 100%|██████████| 153/153 [00:02<00:00, 52.90it/s, Epoch: 20, Batch: 153,Loss: -1.623,Avg.Loss: -1.510,LR: 4.52E-04]
Training epoch 21:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 21:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 21, Batch: 1,Loss: -2.131,Avg.Loss: -2.131,LR: 4.52E-04]Training epoch 21:   1%|          | 1/153 [00:00<00:06, 23.56it/s, Epoch: 21, Batch: 2,Loss: -1.941,Avg.Loss: -2.036,LR: 4.52E-04]Training epoch 21:   1%|▏         | 2/153 [00:00<00:04, 33.46it/s, Epoch: 21, Batch: 3,Loss: -2.082,Avg.Loss: -2.051,LR: 4.52E-04]Training epoch 21:   2%|▏         | 3/153 [00:00<00:03, 38.57it/s, Epoch: 21, Batch: 4,Loss: -1.520,Avg.Loss: -1.918,LR: 4.52E-04]Training epoch 21:   3%|▎         | 4/153 [00:00<00:03, 41.27it/s, Epoch: 21, Batch: 5,Loss: -1.585,Avg.Loss: -1.852,LR: 4.52E-04]Training epoch 21:   3%|▎         | 5/153 [00:00<00:03, 43.12it/s, Epoch: 21, Batch: 6,Loss: -1.980,Avg.Loss: -1.873,LR: 4.52E-04]Training epoch 21:   4%|▍         | 6/153 [00:00<00:02, 51.66it/s, Epoch: 21, Batch: 6,Loss: -1.980,Avg.Loss: -1.873,LR: 4.52E-04]Training epoch 21:   4%|▍         | 6/153 [00:00<00:02, 51.66it/s, Epoch: 21, Batch: 7,Loss: -1.733,Avg.Loss: -1.853,LR: 4.52E-04]Training epoch 21:   5%|▍         | 7/153 [00:00<00:02, 51.66it/s, Epoch: 21, Batch: 8,Loss: -2.095,Avg.Loss: -1.883,LR: 4.52E-04]Training epoch 21:   5%|▌         | 8/153 [00:00<00:02, 51.66it/s, Epoch: 21, Batch: 9,Loss: -1.374,Avg.Loss: -1.827,LR: 4.52E-04]Training epoch 21:   6%|▌         | 9/153 [00:00<00:02, 51.66it/s, Epoch: 21, Batch: 10,Loss: -2.110,Avg.Loss: -1.855,LR: 4.52E-04]Training epoch 21:   7%|▋         | 10/153 [00:00<00:02, 51.66it/s, Epoch: 21, Batch: 11,Loss: -2.169,Avg.Loss: -1.884,LR: 4.52E-04]Training epoch 21:   7%|▋         | 11/153 [00:00<00:02, 51.66it/s, Epoch: 21, Batch: 12,Loss: -1.417,Avg.Loss: -1.845,LR: 4.52E-04]Training epoch 21:   8%|▊         | 12/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 12,Loss: -1.417,Avg.Loss: -1.845,LR: 4.52E-04]Training epoch 21:   8%|▊         | 12/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 13,Loss: -1.909,Avg.Loss: -1.850,LR: 4.52E-04]Training epoch 21:   8%|▊         | 13/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 14,Loss: -2.514,Avg.Loss: -1.897,LR: 4.52E-04]Training epoch 21:   9%|▉         | 14/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 15,Loss: -1.784,Avg.Loss: -1.890,LR: 4.52E-04]Training epoch 21:  10%|▉         | 15/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 16,Loss: -2.046,Avg.Loss: -1.899,LR: 4.52E-04]Training epoch 21:  10%|█         | 16/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 17,Loss: -1.601,Avg.Loss: -1.882,LR: 4.52E-04]Training epoch 21:  11%|█         | 17/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 18,Loss: -1.340,Avg.Loss: -1.852,LR: 4.52E-04]Training epoch 21:  12%|█▏        | 18/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 18,Loss: -1.340,Avg.Loss: -1.852,LR: 4.52E-04]Training epoch 21:  12%|█▏        | 18/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 19,Loss: -2.093,Avg.Loss: -1.864,LR: 4.52E-04]Training epoch 21:  12%|█▏        | 19/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 20,Loss: -2.066,Avg.Loss: -1.874,LR: 4.52E-04]Training epoch 21:  13%|█▎        | 20/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 21,Loss: -2.112,Avg.Loss: -1.886,LR: 4.52E-04]Training epoch 21:  14%|█▎        | 21/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 22,Loss: -1.807,Avg.Loss: -1.882,LR: 4.52E-04]Training epoch 21:  14%|█▍        | 22/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 23,Loss: -2.046,Avg.Loss: -1.889,LR: 4.52E-04]Training epoch 21:  15%|█▌        | 23/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 24,Loss: -1.836,Avg.Loss: -1.887,LR: 4.52E-04]Training epoch 21:  16%|█▌        | 24/153 [00:00<00:02, 52.49it/s, Epoch: 21, Batch: 24,Loss: -1.836,Avg.Loss: -1.887,LR: 4.52E-04]Training epoch 21:  16%|█▌        | 24/153 [00:00<00:02, 52.49it/s, Epoch: 21, Batch: 25,Loss: -1.772,Avg.Loss: -1.882,LR: 4.51E-04]Training epoch 21:  16%|█▋        | 25/153 [00:00<00:02, 52.49it/s, Epoch: 21, Batch: 26,Loss: -1.874,Avg.Loss: -1.882,LR: 4.51E-04]Training epoch 21:  17%|█▋        | 26/153 [00:00<00:02, 52.49it/s, Epoch: 21, Batch: 27,Loss: -2.076,Avg.Loss: -1.889,LR: 4.51E-04]Training epoch 21:  18%|█▊        | 27/153 [00:00<00:02, 52.49it/s, Epoch: 21, Batch: 28,Loss: -2.401,Avg.Loss: -1.908,LR: 4.51E-04]Training epoch 21:  18%|█▊        | 28/153 [00:00<00:02, 52.49it/s, Epoch: 21, Batch: 29,Loss: -2.225,Avg.Loss: -1.919,LR: 4.51E-04]Training epoch 21:  19%|█▉        | 29/153 [00:00<00:02, 52.49it/s, Epoch: 21, Batch: 30,Loss: -1.927,Avg.Loss: -1.919,LR: 4.51E-04]Training epoch 21:  20%|█▉        | 30/153 [00:00<00:02, 52.33it/s, Epoch: 21, Batch: 30,Loss: -1.927,Avg.Loss: -1.919,LR: 4.51E-04]Training epoch 21:  20%|█▉        | 30/153 [00:00<00:02, 52.33it/s, Epoch: 21, Batch: 31,Loss: -2.111,Avg.Loss: -1.925,LR: 4.51E-04]Training epoch 21:  20%|██        | 31/153 [00:00<00:02, 52.33it/s, Epoch: 21, Batch: 32,Loss: -2.378,Avg.Loss: -1.939,LR: 4.51E-04]Training epoch 21:  21%|██        | 32/153 [00:00<00:02, 52.33it/s, Epoch: 21, Batch: 33,Loss: -1.682,Avg.Loss: -1.931,LR: 4.51E-04]Training epoch 21:  22%|██▏       | 33/153 [00:00<00:02, 52.33it/s, Epoch: 21, Batch: 34,Loss: -1.947,Avg.Loss: -1.932,LR: 4.51E-04]Training epoch 21:  22%|██▏       | 34/153 [00:00<00:02, 52.33it/s, Epoch: 21, Batch: 35,Loss: -1.696,Avg.Loss: -1.925,LR: 4.51E-04]Training epoch 21:  23%|██▎       | 35/153 [00:00<00:02, 52.33it/s, Epoch: 21, Batch: 36,Loss: -0.910,Avg.Loss: -1.897,LR: 4.51E-04]Training epoch 21:  24%|██▎       | 36/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 36,Loss: -0.910,Avg.Loss: -1.897,LR: 4.51E-04]Training epoch 21:  24%|██▎       | 36/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 37,Loss: 0.107,Avg.Loss: -1.843,LR: 4.51E-04] Training epoch 21:  24%|██▍       | 37/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 38,Loss: 0.019,Avg.Loss: -1.794,LR: 4.51E-04]Training epoch 21:  25%|██▍       | 38/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 39,Loss: -1.827,Avg.Loss: -1.795,LR: 4.51E-04]Training epoch 21:  25%|██▌       | 39/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 40,Loss: -1.502,Avg.Loss: -1.787,LR: 4.51E-04]Training epoch 21:  26%|██▌       | 40/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 41,Loss: -0.428,Avg.Loss: -1.754,LR: 4.51E-04]Training epoch 21:  27%|██▋       | 41/153 [00:00<00:02, 52.57it/s, Epoch: 21, Batch: 42,Loss: -0.069,Avg.Loss: -1.714,LR: 4.51E-04]Training epoch 21:  27%|██▋       | 42/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 42,Loss: -0.069,Avg.Loss: -1.714,LR: 4.51E-04]Training epoch 21:  27%|██▋       | 42/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 43,Loss: -1.730,Avg.Loss: -1.714,LR: 4.51E-04]Training epoch 21:  28%|██▊       | 43/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 44,Loss: -1.600,Avg.Loss: -1.712,LR: 4.51E-04]Training epoch 21:  29%|██▉       | 44/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 45,Loss: -1.292,Avg.Loss: -1.702,LR: 4.51E-04]Training epoch 21:  29%|██▉       | 45/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 46,Loss: -1.851,Avg.Loss: -1.706,LR: 4.51E-04]Training epoch 21:  30%|███       | 46/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 47,Loss: -2.239,Avg.Loss: -1.717,LR: 4.51E-04]Training epoch 21:  31%|███       | 47/153 [00:00<00:02, 52.68it/s, Epoch: 21, Batch: 48,Loss: -1.541,Avg.Loss: -1.713,LR: 4.51E-04]Training epoch 21:  31%|███▏      | 48/153 [00:00<00:01, 52.83it/s, Epoch: 21, Batch: 48,Loss: -1.541,Avg.Loss: -1.713,LR: 4.51E-04]Training epoch 21:  31%|███▏      | 48/153 [00:00<00:01, 52.83it/s, Epoch: 21, Batch: 49,Loss: 0.755,Avg.Loss: -1.663,LR: 4.51E-04] Training epoch 21:  32%|███▏      | 49/153 [00:00<00:01, 52.83it/s, Epoch: 21, Batch: 50,Loss: -0.921,Avg.Loss: -1.648,LR: 4.51E-04]Training epoch 21:  33%|███▎      | 50/153 [00:00<00:01, 52.83it/s, Epoch: 21, Batch: 51,Loss: -1.986,Avg.Loss: -1.655,LR: 4.51E-04]Training epoch 21:  33%|███▎      | 51/153 [00:00<00:01, 52.83it/s, Epoch: 21, Batch: 52,Loss: -1.302,Avg.Loss: -1.648,LR: 4.51E-04]Training epoch 21:  34%|███▍      | 52/153 [00:01<00:01, 52.83it/s, Epoch: 21, Batch: 53,Loss: 0.463,Avg.Loss: -1.608,LR: 4.51E-04] Training epoch 21:  35%|███▍      | 53/153 [00:01<00:01, 52.83it/s, Epoch: 21, Batch: 54,Loss: -0.232,Avg.Loss: -1.583,LR: 4.51E-04]Training epoch 21:  35%|███▌      | 54/153 [00:01<00:01, 52.95it/s, Epoch: 21, Batch: 54,Loss: -0.232,Avg.Loss: -1.583,LR: 4.51E-04]Training epoch 21:  35%|███▌      | 54/153 [00:01<00:01, 52.95it/s, Epoch: 21, Batch: 55,Loss: -1.740,Avg.Loss: -1.586,LR: 4.51E-04]Training epoch 21:  36%|███▌      | 55/153 [00:01<00:01, 52.95it/s, Epoch: 21, Batch: 56,Loss: -2.007,Avg.Loss: -1.593,LR: 4.51E-04]Training epoch 21:  37%|███▋      | 56/153 [00:01<00:01, 52.95it/s, Epoch: 21, Batch: 57,Loss: -0.811,Avg.Loss: -1.579,LR: 4.51E-04]Training epoch 21:  37%|███▋      | 57/153 [00:01<00:01, 52.95it/s, Epoch: 21, Batch: 58,Loss: -0.885,Avg.Loss: -1.567,LR: 4.50E-04]Training epoch 21:  38%|███▊      | 58/153 [00:01<00:01, 52.95it/s, Epoch: 21, Batch: 59,Loss: -1.939,Avg.Loss: -1.574,LR: 4.50E-04]Training epoch 21:  39%|███▊      | 59/153 [00:01<00:01, 52.95it/s, Epoch: 21, Batch: 60,Loss: -1.353,Avg.Loss: -1.570,LR: 4.50E-04]Training epoch 21:  39%|███▉      | 60/153 [00:01<00:01, 52.96it/s, Epoch: 21, Batch: 60,Loss: -1.353,Avg.Loss: -1.570,LR: 4.50E-04]Training epoch 21:  39%|███▉      | 60/153 [00:01<00:01, 52.96it/s, Epoch: 21, Batch: 61,Loss: -0.118,Avg.Loss: -1.546,LR: 4.50E-04]Training epoch 21:  40%|███▉      | 61/153 [00:01<00:01, 52.96it/s, Epoch: 21, Batch: 62,Loss: -0.307,Avg.Loss: -1.526,LR: 4.50E-04]Training epoch 21:  41%|████      | 62/153 [00:01<00:01, 52.96it/s, Epoch: 21, Batch: 63,Loss: -1.839,Avg.Loss: -1.531,LR: 4.50E-04]Training epoch 21:  41%|████      | 63/153 [00:01<00:01, 52.96it/s, Epoch: 21, Batch: 64,Loss: -2.051,Avg.Loss: -1.539,LR: 4.50E-04]Training epoch 21:  42%|████▏     | 64/153 [00:01<00:01, 52.96it/s, Epoch: 21, Batch: 65,Loss: -1.486,Avg.Loss: -1.538,LR: 4.50E-04]Training epoch 21:  42%|████▏     | 65/153 [00:01<00:01, 52.96it/s, Epoch: 21, Batch: 66,Loss: -1.535,Avg.Loss: -1.538,LR: 4.50E-04]Training epoch 21:  43%|████▎     | 66/153 [00:01<00:01, 52.99it/s, Epoch: 21, Batch: 66,Loss: -1.535,Avg.Loss: -1.538,LR: 4.50E-04]Training epoch 21:  43%|████▎     | 66/153 [00:01<00:01, 52.99it/s, Epoch: 21, Batch: 67,Loss: -1.525,Avg.Loss: -1.538,LR: 4.50E-04]Training epoch 21:  44%|████▍     | 67/153 [00:01<00:01, 52.99it/s, Epoch: 21, Batch: 68,Loss: -1.208,Avg.Loss: -1.533,LR: 4.50E-04]Training epoch 21:  44%|████▍     | 68/153 [00:01<00:01, 52.99it/s, Epoch: 21, Batch: 69,Loss: -0.075,Avg.Loss: -1.512,LR: 4.50E-04]Training epoch 21:  45%|████▌     | 69/153 [00:01<00:01, 52.99it/s, Epoch: 21, Batch: 70,Loss: -0.614,Avg.Loss: -1.499,LR: 4.50E-04]Training epoch 21:  46%|████▌     | 70/153 [00:01<00:01, 52.99it/s, Epoch: 21, Batch: 71,Loss: -1.640,Avg.Loss: -1.501,LR: 4.50E-04]Training epoch 21:  46%|████▋     | 71/153 [00:01<00:01, 52.99it/s, Epoch: 21, Batch: 72,Loss: -1.758,Avg.Loss: -1.505,LR: 4.50E-04]Training epoch 21:  47%|████▋     | 72/153 [00:01<00:01, 52.97it/s, Epoch: 21, Batch: 72,Loss: -1.758,Avg.Loss: -1.505,LR: 4.50E-04]Training epoch 21:  47%|████▋     | 72/153 [00:01<00:01, 52.97it/s, Epoch: 21, Batch: 73,Loss: -0.339,Avg.Loss: -1.489,LR: 4.50E-04]Training epoch 21:  48%|████▊     | 73/153 [00:01<00:01, 52.97it/s, Epoch: 21, Batch: 74,Loss: -1.381,Avg.Loss: -1.488,LR: 4.50E-04]Training epoch 21:  48%|████▊     | 74/153 [00:01<00:01, 52.97it/s, Epoch: 21, Batch: 75,Loss: -2.191,Avg.Loss: -1.497,LR: 4.50E-04]Training epoch 21:  49%|████▉     | 75/153 [00:01<00:01, 52.97it/s, Epoch: 21, Batch: 76,Loss: -1.380,Avg.Loss: -1.495,LR: 4.50E-04]Training epoch 21:  50%|████▉     | 76/153 [00:01<00:01, 52.97it/s, Epoch: 21, Batch: 77,Loss: -0.668,Avg.Loss: -1.485,LR: 4.50E-04]Training epoch 21:  50%|█████     | 77/153 [00:01<00:01, 52.97it/s, Epoch: 21, Batch: 78,Loss: -0.668,Avg.Loss: -1.474,LR: 4.50E-04]Training epoch 21:  51%|█████     | 78/153 [00:01<00:01, 52.59it/s, Epoch: 21, Batch: 78,Loss: -0.668,Avg.Loss: -1.474,LR: 4.50E-04]Training epoch 21:  51%|█████     | 78/153 [00:01<00:01, 52.59it/s, Epoch: 21, Batch: 79,Loss: -1.501,Avg.Loss: -1.474,LR: 4.50E-04]Training epoch 21:  52%|█████▏    | 79/153 [00:01<00:01, 52.59it/s, Epoch: 21, Batch: 80,Loss: -1.551,Avg.Loss: -1.475,LR: 4.50E-04]Training epoch 21:  52%|█████▏    | 80/153 [00:01<00:01, 52.59it/s, Epoch: 21, Batch: 81,Loss: -0.529,Avg.Loss: -1.464,LR: 4.50E-04]Training epoch 21:  53%|█████▎    | 81/153 [00:01<00:01, 52.59it/s, Epoch: 21, Batch: 82,Loss: -1.039,Avg.Loss: -1.459,LR: 4.50E-04]Training epoch 21:  54%|█████▎    | 82/153 [00:01<00:01, 52.59it/s, Epoch: 21, Batch: 83,Loss: -1.853,Avg.Loss: -1.463,LR: 4.50E-04]Training epoch 21:  54%|█████▍    | 83/153 [00:01<00:01, 52.59it/s, Epoch: 21, Batch: 84,Loss: -1.738,Avg.Loss: -1.467,LR: 4.50E-04]Training epoch 21:  55%|█████▍    | 84/153 [00:01<00:01, 53.62it/s, Epoch: 21, Batch: 84,Loss: -1.738,Avg.Loss: -1.467,LR: 4.50E-04]Training epoch 21:  55%|█████▍    | 84/153 [00:01<00:01, 53.62it/s, Epoch: 21, Batch: 85,Loss: -0.862,Avg.Loss: -1.459,LR: 4.50E-04]Training epoch 21:  56%|█████▌    | 85/153 [00:01<00:01, 53.62it/s, Epoch: 21, Batch: 86,Loss: -0.982,Avg.Loss: -1.454,LR: 4.50E-04]Training epoch 21:  56%|█████▌    | 86/153 [00:01<00:01, 53.62it/s, Epoch: 21, Batch: 87,Loss: -1.775,Avg.Loss: -1.458,LR: 4.50E-04]Training epoch 21:  57%|█████▋    | 87/153 [00:01<00:01, 53.62it/s, Epoch: 21, Batch: 88,Loss: -1.474,Avg.Loss: -1.458,LR: 4.50E-04]Training epoch 21:  58%|█████▊    | 88/153 [00:01<00:01, 53.62it/s, Epoch: 21, Batch: 89,Loss: -0.595,Avg.Loss: -1.448,LR: 4.50E-04]Training epoch 21:  58%|█████▊    | 89/153 [00:01<00:01, 53.62it/s, Epoch: 21, Batch: 90,Loss: -1.058,Avg.Loss: -1.444,LR: 4.50E-04]Training epoch 21:  59%|█████▉    | 90/153 [00:01<00:01, 53.46it/s, Epoch: 21, Batch: 90,Loss: -1.058,Avg.Loss: -1.444,LR: 4.50E-04]Training epoch 21:  59%|█████▉    | 90/153 [00:01<00:01, 53.46it/s, Epoch: 21, Batch: 91,Loss: -2.025,Avg.Loss: -1.450,LR: 4.49E-04]Training epoch 21:  59%|█████▉    | 91/153 [00:01<00:01, 53.46it/s, Epoch: 21, Batch: 92,Loss: -1.515,Avg.Loss: -1.451,LR: 4.49E-04]Training epoch 21:  60%|██████    | 92/153 [00:01<00:01, 53.46it/s, Epoch: 21, Batch: 93,Loss: -0.967,Avg.Loss: -1.446,LR: 4.49E-04]Training epoch 21:  61%|██████    | 93/153 [00:01<00:01, 53.46it/s, Epoch: 21, Batch: 94,Loss: -1.033,Avg.Loss: -1.441,LR: 4.49E-04]Training epoch 21:  61%|██████▏   | 94/153 [00:01<00:01, 53.46it/s, Epoch: 21, Batch: 95,Loss: -2.064,Avg.Loss: -1.448,LR: 4.49E-04]Training epoch 21:  62%|██████▏   | 95/153 [00:01<00:01, 53.46it/s, Epoch: 21, Batch: 96,Loss: -1.879,Avg.Loss: -1.452,LR: 4.49E-04]Training epoch 21:  63%|██████▎   | 96/153 [00:01<00:01, 53.21it/s, Epoch: 21, Batch: 96,Loss: -1.879,Avg.Loss: -1.452,LR: 4.49E-04]Training epoch 21:  63%|██████▎   | 96/153 [00:01<00:01, 53.21it/s, Epoch: 21, Batch: 97,Loss: -0.775,Avg.Loss: -1.445,LR: 4.49E-04]Training epoch 21:  63%|██████▎   | 97/153 [00:01<00:01, 53.21it/s, Epoch: 21, Batch: 98,Loss: -0.489,Avg.Loss: -1.436,LR: 4.49E-04]Training epoch 21:  64%|██████▍   | 98/153 [00:01<00:01, 53.21it/s, Epoch: 21, Batch: 99,Loss: -1.515,Avg.Loss: -1.436,LR: 4.49E-04]Training epoch 21:  65%|██████▍   | 99/153 [00:01<00:01, 53.21it/s, Epoch: 21, Batch: 100,Loss: -1.687,Avg.Loss: -1.439,LR: 4.49E-04]Training epoch 21:  65%|██████▌   | 100/153 [00:01<00:00, 53.21it/s, Epoch: 21, Batch: 101,Loss: -1.597,Avg.Loss: -1.440,LR: 4.49E-04]Training epoch 21:  66%|██████▌   | 101/153 [00:01<00:00, 53.21it/s, Epoch: 21, Batch: 102,Loss: -1.312,Avg.Loss: -1.439,LR: 4.49E-04]Training epoch 21:  67%|██████▋   | 102/153 [00:01<00:00, 53.25it/s, Epoch: 21, Batch: 102,Loss: -1.312,Avg.Loss: -1.439,LR: 4.49E-04]Training epoch 21:  67%|██████▋   | 102/153 [00:01<00:00, 53.25it/s, Epoch: 21, Batch: 103,Loss: -1.977,Avg.Loss: -1.444,LR: 4.49E-04]Training epoch 21:  67%|██████▋   | 103/153 [00:01<00:00, 53.25it/s, Epoch: 21, Batch: 104,Loss: -2.029,Avg.Loss: -1.450,LR: 4.49E-04]Training epoch 21:  68%|██████▊   | 104/153 [00:01<00:00, 53.25it/s, Epoch: 21, Batch: 105,Loss: -1.590,Avg.Loss: -1.451,LR: 4.49E-04]Training epoch 21:  69%|██████▊   | 105/153 [00:02<00:00, 53.25it/s, Epoch: 21, Batch: 106,Loss: -1.701,Avg.Loss: -1.454,LR: 4.49E-04]Training epoch 21:  69%|██████▉   | 106/153 [00:02<00:00, 53.25it/s, Epoch: 21, Batch: 107,Loss: -2.024,Avg.Loss: -1.459,LR: 4.49E-04]Training epoch 21:  70%|██████▉   | 107/153 [00:02<00:00, 53.25it/s, Epoch: 21, Batch: 108,Loss: -1.085,Avg.Loss: -1.456,LR: 4.49E-04]Training epoch 21:  71%|███████   | 108/153 [00:02<00:00, 53.23it/s, Epoch: 21, Batch: 108,Loss: -1.085,Avg.Loss: -1.456,LR: 4.49E-04]Training epoch 21:  71%|███████   | 108/153 [00:02<00:00, 53.23it/s, Epoch: 21, Batch: 109,Loss: -1.182,Avg.Loss: -1.453,LR: 4.49E-04]Training epoch 21:  71%|███████   | 109/153 [00:02<00:00, 53.23it/s, Epoch: 21, Batch: 110,Loss: -1.798,Avg.Loss: -1.456,LR: 4.49E-04]Training epoch 21:  72%|███████▏  | 110/153 [00:02<00:00, 53.23it/s, Epoch: 21, Batch: 111,Loss: -1.734,Avg.Loss: -1.459,LR: 4.49E-04]Training epoch 21:  73%|███████▎  | 111/153 [00:02<00:00, 53.23it/s, Epoch: 21, Batch: 112,Loss: -1.690,Avg.Loss: -1.461,LR: 4.49E-04]Training epoch 21:  73%|███████▎  | 112/153 [00:02<00:00, 53.23it/s, Epoch: 21, Batch: 113,Loss: -1.898,Avg.Loss: -1.465,LR: 4.49E-04]Training epoch 21:  74%|███████▍  | 113/153 [00:02<00:00, 53.23it/s, Epoch: 21, Batch: 114,Loss: -1.646,Avg.Loss: -1.466,LR: 4.49E-04]Training epoch 21:  75%|███████▍  | 114/153 [00:02<00:00, 53.30it/s, Epoch: 21, Batch: 114,Loss: -1.646,Avg.Loss: -1.466,LR: 4.49E-04]Training epoch 21:  75%|███████▍  | 114/153 [00:02<00:00, 53.30it/s, Epoch: 21, Batch: 115,Loss: -1.397,Avg.Loss: -1.466,LR: 4.49E-04]Training epoch 21:  75%|███████▌  | 115/153 [00:02<00:00, 53.30it/s, Epoch: 21, Batch: 116,Loss: -1.785,Avg.Loss: -1.468,LR: 4.49E-04]Training epoch 21:  76%|███████▌  | 116/153 [00:02<00:00, 53.30it/s, Epoch: 21, Batch: 117,Loss: -1.920,Avg.Loss: -1.472,LR: 4.49E-04]Training epoch 21:  76%|███████▋  | 117/153 [00:02<00:00, 53.30it/s, Epoch: 21, Batch: 118,Loss: -1.941,Avg.Loss: -1.476,LR: 4.49E-04]Training epoch 21:  77%|███████▋  | 118/153 [00:02<00:00, 53.30it/s, Epoch: 21, Batch: 119,Loss: -2.388,Avg.Loss: -1.484,LR: 4.49E-04]Training epoch 21:  78%|███████▊  | 119/153 [00:02<00:00, 53.30it/s, Epoch: 21, Batch: 120,Loss: -1.829,Avg.Loss: -1.487,LR: 4.49E-04]Training epoch 21:  78%|███████▊  | 120/153 [00:02<00:00, 53.47it/s, Epoch: 21, Batch: 120,Loss: -1.829,Avg.Loss: -1.487,LR: 4.49E-04]Training epoch 21:  78%|███████▊  | 120/153 [00:02<00:00, 53.47it/s, Epoch: 21, Batch: 121,Loss: -1.102,Avg.Loss: -1.484,LR: 4.49E-04]Training epoch 21:  79%|███████▉  | 121/153 [00:02<00:00, 53.47it/s, Epoch: 21, Batch: 122,Loss: -1.864,Avg.Loss: -1.487,LR: 4.49E-04]Training epoch 21:  80%|███████▉  | 122/153 [00:02<00:00, 53.47it/s, Epoch: 21, Batch: 123,Loss: -2.112,Avg.Loss: -1.492,LR: 4.48E-04]Training epoch 21:  80%|████████  | 123/153 [00:02<00:00, 53.47it/s, Epoch: 21, Batch: 124,Loss: -1.301,Avg.Loss: -1.490,LR: 4.48E-04]Training epoch 21:  81%|████████  | 124/153 [00:02<00:00, 53.47it/s, Epoch: 21, Batch: 125,Loss: -1.752,Avg.Loss: -1.492,LR: 4.48E-04]Training epoch 21:  82%|████████▏ | 125/153 [00:02<00:00, 53.47it/s, Epoch: 21, Batch: 126,Loss: -1.225,Avg.Loss: -1.490,LR: 4.48E-04]Training epoch 21:  82%|████████▏ | 126/153 [00:02<00:00, 53.46it/s, Epoch: 21, Batch: 126,Loss: -1.225,Avg.Loss: -1.490,LR: 4.48E-04]Training epoch 21:  82%|████████▏ | 126/153 [00:02<00:00, 53.46it/s, Epoch: 21, Batch: 127,Loss: -1.475,Avg.Loss: -1.490,LR: 4.48E-04]Training epoch 21:  83%|████████▎ | 127/153 [00:02<00:00, 53.46it/s, Epoch: 21, Batch: 128,Loss: -1.804,Avg.Loss: -1.493,LR: 4.48E-04]Training epoch 21:  84%|████████▎ | 128/153 [00:02<00:00, 53.46it/s, Epoch: 21, Batch: 129,Loss: -1.997,Avg.Loss: -1.496,LR: 4.48E-04]Training epoch 21:  84%|████████▍ | 129/153 [00:02<00:00, 53.46it/s, Epoch: 21, Batch: 130,Loss: -1.610,Avg.Loss: -1.497,LR: 4.48E-04]Training epoch 21:  85%|████████▍ | 130/153 [00:02<00:00, 53.46it/s, Epoch: 21, Batch: 131,Loss: -2.047,Avg.Loss: -1.502,LR: 4.48E-04]Training epoch 21:  86%|████████▌ | 131/153 [00:02<00:00, 53.46it/s, Epoch: 21, Batch: 132,Loss: -1.257,Avg.Loss: -1.500,LR: 4.48E-04]Training epoch 21:  86%|████████▋ | 132/153 [00:02<00:00, 53.45it/s, Epoch: 21, Batch: 132,Loss: -1.257,Avg.Loss: -1.500,LR: 4.48E-04]Training epoch 21:  86%|████████▋ | 132/153 [00:02<00:00, 53.45it/s, Epoch: 21, Batch: 133,Loss: -1.155,Avg.Loss: -1.497,LR: 4.48E-04]Training epoch 21:  87%|████████▋ | 133/153 [00:02<00:00, 53.45it/s, Epoch: 21, Batch: 134,Loss: -1.773,Avg.Loss: -1.499,LR: 4.48E-04]Training epoch 21:  88%|████████▊ | 134/153 [00:02<00:00, 53.45it/s, Epoch: 21, Batch: 135,Loss: -2.107,Avg.Loss: -1.504,LR: 4.48E-04]Training epoch 21:  88%|████████▊ | 135/153 [00:02<00:00, 53.45it/s, Epoch: 21, Batch: 136,Loss: -1.793,Avg.Loss: -1.506,LR: 4.48E-04]Training epoch 21:  89%|████████▉ | 136/153 [00:02<00:00, 53.45it/s, Epoch: 21, Batch: 137,Loss: -2.109,Avg.Loss: -1.510,LR: 4.48E-04]Training epoch 21:  90%|████████▉ | 137/153 [00:02<00:00, 53.45it/s, Epoch: 21, Batch: 138,Loss: -1.714,Avg.Loss: -1.512,LR: 4.48E-04]Training epoch 21:  90%|█████████ | 138/153 [00:02<00:00, 53.49it/s, Epoch: 21, Batch: 138,Loss: -1.714,Avg.Loss: -1.512,LR: 4.48E-04]Training epoch 21:  90%|█████████ | 138/153 [00:02<00:00, 53.49it/s, Epoch: 21, Batch: 139,Loss: -1.999,Avg.Loss: -1.515,LR: 4.48E-04]Training epoch 21:  91%|█████████ | 139/153 [00:02<00:00, 53.49it/s, Epoch: 21, Batch: 140,Loss: -2.040,Avg.Loss: -1.519,LR: 4.48E-04]Training epoch 21:  92%|█████████▏| 140/153 [00:02<00:00, 53.49it/s, Epoch: 21, Batch: 141,Loss: -2.414,Avg.Loss: -1.525,LR: 4.48E-04]Training epoch 21:  92%|█████████▏| 141/153 [00:02<00:00, 53.49it/s, Epoch: 21, Batch: 142,Loss: -1.407,Avg.Loss: -1.524,LR: 4.48E-04]Training epoch 21:  93%|█████████▎| 142/153 [00:02<00:00, 53.49it/s, Epoch: 21, Batch: 143,Loss: -1.548,Avg.Loss: -1.525,LR: 4.48E-04]Training epoch 21:  93%|█████████▎| 143/153 [00:02<00:00, 53.49it/s, Epoch: 21, Batch: 144,Loss: -1.638,Avg.Loss: -1.525,LR: 4.48E-04]Training epoch 21:  94%|█████████▍| 144/153 [00:02<00:00, 53.54it/s, Epoch: 21, Batch: 144,Loss: -1.638,Avg.Loss: -1.525,LR: 4.48E-04]Training epoch 21:  94%|█████████▍| 144/153 [00:02<00:00, 53.54it/s, Epoch: 21, Batch: 145,Loss: -1.888,Avg.Loss: -1.528,LR: 4.48E-04]Training epoch 21:  95%|█████████▍| 145/153 [00:02<00:00, 53.54it/s, Epoch: 21, Batch: 146,Loss: -1.950,Avg.Loss: -1.531,LR: 4.48E-04]Training epoch 21:  95%|█████████▌| 146/153 [00:02<00:00, 53.54it/s, Epoch: 21, Batch: 147,Loss: -1.962,Avg.Loss: -1.534,LR: 4.48E-04]Training epoch 21:  96%|█████████▌| 147/153 [00:02<00:00, 53.54it/s, Epoch: 21, Batch: 148,Loss: -1.869,Avg.Loss: -1.536,LR: 4.48E-04]Training epoch 21:  97%|█████████▋| 148/153 [00:02<00:00, 53.54it/s, Epoch: 21, Batch: 149,Loss: -1.790,Avg.Loss: -1.538,LR: 4.48E-04]Training epoch 21:  97%|█████████▋| 149/153 [00:02<00:00, 53.54it/s, Epoch: 21, Batch: 150,Loss: -1.612,Avg.Loss: -1.538,LR: 4.48E-04]Training epoch 21:  98%|█████████▊| 150/153 [00:02<00:00, 53.52it/s, Epoch: 21, Batch: 150,Loss: -1.612,Avg.Loss: -1.538,LR: 4.48E-04]Training epoch 21:  98%|█████████▊| 150/153 [00:02<00:00, 53.52it/s, Epoch: 21, Batch: 151,Loss: -1.996,Avg.Loss: -1.541,LR: 4.48E-04]Training epoch 21:  99%|█████████▊| 151/153 [00:02<00:00, 53.52it/s, Epoch: 21, Batch: 152,Loss: -1.751,Avg.Loss: -1.543,LR: 4.48E-04]Training epoch 21:  99%|█████████▉| 152/153 [00:02<00:00, 53.52it/s, Epoch: 21, Batch: 153,Loss: -1.228,Avg.Loss: -1.541,LR: 4.48E-04]Training epoch 21: 100%|██████████| 153/153 [00:02<00:00, 53.05it/s, Epoch: 21, Batch: 153,Loss: -1.228,Avg.Loss: -1.541,LR: 4.48E-04]
Training epoch 22:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 22:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 22, Batch: 1,Loss: -1.736,Avg.Loss: -1.736,LR: 4.48E-04]Training epoch 22:   1%|          | 1/153 [00:00<00:06, 23.43it/s, Epoch: 22, Batch: 2,Loss: -1.979,Avg.Loss: -1.857,LR: 4.47E-04]Training epoch 22:   1%|▏         | 2/153 [00:00<00:04, 32.85it/s, Epoch: 22, Batch: 3,Loss: -1.949,Avg.Loss: -1.888,LR: 4.47E-04]Training epoch 22:   2%|▏         | 3/153 [00:00<00:03, 38.37it/s, Epoch: 22, Batch: 4,Loss: -1.742,Avg.Loss: -1.851,LR: 4.47E-04]Training epoch 22:   3%|▎         | 4/153 [00:00<00:03, 41.38it/s, Epoch: 22, Batch: 5,Loss: -1.933,Avg.Loss: -1.868,LR: 4.47E-04]Training epoch 22:   3%|▎         | 5/153 [00:00<00:03, 43.40it/s, Epoch: 22, Batch: 6,Loss: -2.007,Avg.Loss: -1.891,LR: 4.47E-04]Training epoch 22:   4%|▍         | 6/153 [00:00<00:02, 51.99it/s, Epoch: 22, Batch: 6,Loss: -2.007,Avg.Loss: -1.891,LR: 4.47E-04]Training epoch 22:   4%|▍         | 6/153 [00:00<00:02, 51.99it/s, Epoch: 22, Batch: 7,Loss: -0.833,Avg.Loss: -1.740,LR: 4.47E-04]Training epoch 22:   5%|▍         | 7/153 [00:00<00:02, 51.99it/s, Epoch: 22, Batch: 8,Loss: -0.860,Avg.Loss: -1.630,LR: 4.47E-04]Training epoch 22:   5%|▌         | 8/153 [00:00<00:02, 51.99it/s, Epoch: 22, Batch: 9,Loss: -0.976,Avg.Loss: -1.557,LR: 4.47E-04]Training epoch 22:   6%|▌         | 9/153 [00:00<00:02, 51.99it/s, Epoch: 22, Batch: 10,Loss: -0.333,Avg.Loss: -1.435,LR: 4.47E-04]Training epoch 22:   7%|▋         | 10/153 [00:00<00:02, 51.99it/s, Epoch: 22, Batch: 11,Loss: 0.158,Avg.Loss: -1.290,LR: 4.47E-04]Training epoch 22:   7%|▋         | 11/153 [00:00<00:02, 51.99it/s, Epoch: 22, Batch: 12,Loss: -0.922,Avg.Loss: -1.259,LR: 4.47E-04]Training epoch 22:   8%|▊         | 12/153 [00:00<00:02, 52.74it/s, Epoch: 22, Batch: 12,Loss: -0.922,Avg.Loss: -1.259,LR: 4.47E-04]Training epoch 22:   8%|▊         | 12/153 [00:00<00:02, 52.74it/s, Epoch: 22, Batch: 13,Loss: -1.395,Avg.Loss: -1.270,LR: 4.47E-04]Training epoch 22:   8%|▊         | 13/153 [00:00<00:02, 52.74it/s, Epoch: 22, Batch: 14,Loss: -1.626,Avg.Loss: -1.295,LR: 4.47E-04]Training epoch 22:   9%|▉         | 14/153 [00:00<00:02, 52.74it/s, Epoch: 22, Batch: 15,Loss: -1.033,Avg.Loss: -1.278,LR: 4.47E-04]Training epoch 22:  10%|▉         | 15/153 [00:00<00:02, 52.74it/s, Epoch: 22, Batch: 16,Loss: -1.176,Avg.Loss: -1.271,LR: 4.47E-04]Training epoch 22:  10%|█         | 16/153 [00:00<00:02, 52.74it/s, Epoch: 22, Batch: 17,Loss: -1.172,Avg.Loss: -1.266,LR: 4.47E-04]Training epoch 22:  11%|█         | 17/153 [00:00<00:02, 52.74it/s, Epoch: 22, Batch: 18,Loss: -1.199,Avg.Loss: -1.262,LR: 4.47E-04]Training epoch 22:  12%|█▏        | 18/153 [00:00<00:02, 52.49it/s, Epoch: 22, Batch: 18,Loss: -1.199,Avg.Loss: -1.262,LR: 4.47E-04]Training epoch 22:  12%|█▏        | 18/153 [00:00<00:02, 52.49it/s, Epoch: 22, Batch: 19,Loss: -1.239,Avg.Loss: -1.261,LR: 4.47E-04]Training epoch 22:  12%|█▏        | 19/153 [00:00<00:02, 52.49it/s, Epoch: 22, Batch: 20,Loss: -1.383,Avg.Loss: -1.267,LR: 4.47E-04]Training epoch 22:  13%|█▎        | 20/153 [00:00<00:02, 52.49it/s, Epoch: 22, Batch: 21,Loss: -1.709,Avg.Loss: -1.288,LR: 4.47E-04]Training epoch 22:  14%|█▎        | 21/153 [00:00<00:02, 52.49it/s, Epoch: 22, Batch: 22,Loss: -0.832,Avg.Loss: -1.267,LR: 4.47E-04]Training epoch 22:  14%|█▍        | 22/153 [00:00<00:02, 52.49it/s, Epoch: 22, Batch: 23,Loss: -0.041,Avg.Loss: -1.214,LR: 4.47E-04]Training epoch 22:  15%|█▌        | 23/153 [00:00<00:02, 52.49it/s, Epoch: 22, Batch: 24,Loss: 0.226,Avg.Loss: -1.154,LR: 4.47E-04] Training epoch 22:  16%|█▌        | 24/153 [00:00<00:02, 51.68it/s, Epoch: 22, Batch: 24,Loss: 0.226,Avg.Loss: -1.154,LR: 4.47E-04]Training epoch 22:  16%|█▌        | 24/153 [00:00<00:02, 51.68it/s, Epoch: 22, Batch: 25,Loss: -0.939,Avg.Loss: -1.145,LR: 4.47E-04]Training epoch 22:  16%|█▋        | 25/153 [00:00<00:02, 51.68it/s, Epoch: 22, Batch: 26,Loss: -0.619,Avg.Loss: -1.125,LR: 4.47E-04]Training epoch 22:  17%|█▋        | 26/153 [00:00<00:02, 51.68it/s, Epoch: 22, Batch: 27,Loss: 0.173,Avg.Loss: -1.077,LR: 4.47E-04] Training epoch 22:  18%|█▊        | 27/153 [00:00<00:02, 51.68it/s, Epoch: 22, Batch: 28,Loss: -0.380,Avg.Loss: -1.052,LR: 4.47E-04]Training epoch 22:  18%|█▊        | 28/153 [00:00<00:02, 51.68it/s, Epoch: 22, Batch: 29,Loss: -1.353,Avg.Loss: -1.062,LR: 4.47E-04]Training epoch 22:  19%|█▉        | 29/153 [00:00<00:02, 51.68it/s, Epoch: 22, Batch: 30,Loss: -1.166,Avg.Loss: -1.066,LR: 4.47E-04]Training epoch 22:  20%|█▉        | 30/153 [00:00<00:02, 51.76it/s, Epoch: 22, Batch: 30,Loss: -1.166,Avg.Loss: -1.066,LR: 4.47E-04]Training epoch 22:  20%|█▉        | 30/153 [00:00<00:02, 51.76it/s, Epoch: 22, Batch: 31,Loss: -1.312,Avg.Loss: -1.074,LR: 4.47E-04]Training epoch 22:  20%|██        | 31/153 [00:00<00:02, 51.76it/s, Epoch: 22, Batch: 32,Loss: -1.644,Avg.Loss: -1.092,LR: 4.47E-04]Training epoch 22:  21%|██        | 32/153 [00:00<00:02, 51.76it/s, Epoch: 22, Batch: 33,Loss: -2.324,Avg.Loss: -1.129,LR: 4.46E-04]Training epoch 22:  22%|██▏       | 33/153 [00:00<00:02, 51.76it/s, Epoch: 22, Batch: 34,Loss: -1.413,Avg.Loss: -1.137,LR: 4.46E-04]Training epoch 22:  22%|██▏       | 34/153 [00:00<00:02, 51.76it/s, Epoch: 22, Batch: 35,Loss: -0.186,Avg.Loss: -1.110,LR: 4.46E-04]Training epoch 22:  23%|██▎       | 35/153 [00:00<00:02, 51.76it/s, Epoch: 22, Batch: 36,Loss: 0.121,Avg.Loss: -1.076,LR: 4.46E-04] Training epoch 22:  24%|██▎       | 36/153 [00:00<00:02, 52.01it/s, Epoch: 22, Batch: 36,Loss: 0.121,Avg.Loss: -1.076,LR: 4.46E-04]Training epoch 22:  24%|██▎       | 36/153 [00:00<00:02, 52.01it/s, Epoch: 22, Batch: 37,Loss: -0.909,Avg.Loss: -1.071,LR: 4.46E-04]Training epoch 22:  24%|██▍       | 37/153 [00:00<00:02, 52.01it/s, Epoch: 22, Batch: 38,Loss: -1.416,Avg.Loss: -1.080,LR: 4.46E-04]Training epoch 22:  25%|██▍       | 38/153 [00:00<00:02, 52.01it/s, Epoch: 22, Batch: 39,Loss: -0.890,Avg.Loss: -1.076,LR: 4.46E-04]Training epoch 22:  25%|██▌       | 39/153 [00:00<00:02, 52.01it/s, Epoch: 22, Batch: 40,Loss: -0.533,Avg.Loss: -1.062,LR: 4.46E-04]Training epoch 22:  26%|██▌       | 40/153 [00:00<00:02, 52.01it/s, Epoch: 22, Batch: 41,Loss: -0.405,Avg.Loss: -1.046,LR: 4.46E-04]Training epoch 22:  27%|██▋       | 41/153 [00:00<00:02, 52.01it/s, Epoch: 22, Batch: 42,Loss: -1.757,Avg.Loss: -1.063,LR: 4.46E-04]Training epoch 22:  27%|██▋       | 42/153 [00:00<00:02, 52.33it/s, Epoch: 22, Batch: 42,Loss: -1.757,Avg.Loss: -1.063,LR: 4.46E-04]Training epoch 22:  27%|██▋       | 42/153 [00:00<00:02, 52.33it/s, Epoch: 22, Batch: 43,Loss: -1.573,Avg.Loss: -1.075,LR: 4.46E-04]Training epoch 22:  28%|██▊       | 43/153 [00:00<00:02, 52.33it/s, Epoch: 22, Batch: 44,Loss: -1.628,Avg.Loss: -1.087,LR: 4.46E-04]Training epoch 22:  29%|██▉       | 44/153 [00:00<00:02, 52.33it/s, Epoch: 22, Batch: 45,Loss: -1.377,Avg.Loss: -1.094,LR: 4.46E-04]Training epoch 22:  29%|██▉       | 45/153 [00:00<00:02, 52.33it/s, Epoch: 22, Batch: 46,Loss: -1.728,Avg.Loss: -1.108,LR: 4.46E-04]Training epoch 22:  30%|███       | 46/153 [00:00<00:02, 52.33it/s, Epoch: 22, Batch: 47,Loss: -1.393,Avg.Loss: -1.114,LR: 4.46E-04]Training epoch 22:  31%|███       | 47/153 [00:00<00:02, 52.33it/s, Epoch: 22, Batch: 48,Loss: -0.881,Avg.Loss: -1.109,LR: 4.46E-04]Training epoch 22:  31%|███▏      | 48/153 [00:00<00:02, 51.49it/s, Epoch: 22, Batch: 48,Loss: -0.881,Avg.Loss: -1.109,LR: 4.46E-04]Training epoch 22:  31%|███▏      | 48/153 [00:00<00:02, 51.49it/s, Epoch: 22, Batch: 49,Loss: -0.649,Avg.Loss: -1.099,LR: 4.46E-04]Training epoch 22:  32%|███▏      | 49/153 [00:00<00:02, 51.49it/s, Epoch: 22, Batch: 50,Loss: -0.672,Avg.Loss: -1.091,LR: 4.46E-04]Training epoch 22:  33%|███▎      | 50/153 [00:00<00:02, 51.49it/s, Epoch: 22, Batch: 51,Loss: -1.626,Avg.Loss: -1.101,LR: 4.46E-04]Training epoch 22:  33%|███▎      | 51/153 [00:01<00:01, 51.49it/s, Epoch: 22, Batch: 52,Loss: -1.450,Avg.Loss: -1.108,LR: 4.46E-04]Training epoch 22:  34%|███▍      | 52/153 [00:01<00:01, 51.49it/s, Epoch: 22, Batch: 53,Loss: -1.810,Avg.Loss: -1.121,LR: 4.46E-04]Training epoch 22:  35%|███▍      | 53/153 [00:01<00:01, 51.49it/s, Epoch: 22, Batch: 54,Loss: -1.420,Avg.Loss: -1.127,LR: 4.46E-04]Training epoch 22:  35%|███▌      | 54/153 [00:01<00:01, 51.63it/s, Epoch: 22, Batch: 54,Loss: -1.420,Avg.Loss: -1.127,LR: 4.46E-04]Training epoch 22:  35%|███▌      | 54/153 [00:01<00:01, 51.63it/s, Epoch: 22, Batch: 55,Loss: -1.777,Avg.Loss: -1.139,LR: 4.46E-04]Training epoch 22:  36%|███▌      | 55/153 [00:01<00:01, 51.63it/s, Epoch: 22, Batch: 56,Loss: -1.865,Avg.Loss: -1.152,LR: 4.46E-04]Training epoch 22:  37%|███▋      | 56/153 [00:01<00:01, 51.63it/s, Epoch: 22, Batch: 57,Loss: -0.691,Avg.Loss: -1.144,LR: 4.46E-04]Training epoch 22:  37%|███▋      | 57/153 [00:01<00:01, 51.63it/s, Epoch: 22, Batch: 58,Loss: 0.376,Avg.Loss: -1.117,LR: 4.46E-04] Training epoch 22:  38%|███▊      | 58/153 [00:01<00:01, 51.63it/s, Epoch: 22, Batch: 59,Loss: -0.277,Avg.Loss: -1.103,LR: 4.46E-04]Training epoch 22:  39%|███▊      | 59/153 [00:01<00:01, 51.63it/s, Epoch: 22, Batch: 60,Loss: -0.903,Avg.Loss: -1.100,LR: 4.46E-04]Training epoch 22:  39%|███▉      | 60/153 [00:01<00:01, 52.08it/s, Epoch: 22, Batch: 60,Loss: -0.903,Avg.Loss: -1.100,LR: 4.46E-04]Training epoch 22:  39%|███▉      | 60/153 [00:01<00:01, 52.08it/s, Epoch: 22, Batch: 61,Loss: -1.059,Avg.Loss: -1.099,LR: 4.46E-04]Training epoch 22:  40%|███▉      | 61/153 [00:01<00:01, 52.08it/s, Epoch: 22, Batch: 62,Loss: -0.161,Avg.Loss: -1.084,LR: 4.46E-04]Training epoch 22:  41%|████      | 62/153 [00:01<00:01, 52.08it/s, Epoch: 22, Batch: 63,Loss: -0.646,Avg.Loss: -1.077,LR: 4.46E-04]Training epoch 22:  41%|████      | 63/153 [00:01<00:01, 52.08it/s, Epoch: 22, Batch: 64,Loss: -1.057,Avg.Loss: -1.077,LR: 4.46E-04]Training epoch 22:  42%|████▏     | 64/153 [00:01<00:01, 52.08it/s, Epoch: 22, Batch: 65,Loss: -1.621,Avg.Loss: -1.085,LR: 4.45E-04]Training epoch 22:  42%|████▏     | 65/153 [00:01<00:01, 52.08it/s, Epoch: 22, Batch: 66,Loss: -1.254,Avg.Loss: -1.088,LR: 4.45E-04]Training epoch 22:  43%|████▎     | 66/153 [00:01<00:01, 52.38it/s, Epoch: 22, Batch: 66,Loss: -1.254,Avg.Loss: -1.088,LR: 4.45E-04]Training epoch 22:  43%|████▎     | 66/153 [00:01<00:01, 52.38it/s, Epoch: 22, Batch: 67,Loss: -1.582,Avg.Loss: -1.095,LR: 4.45E-04]Training epoch 22:  44%|████▍     | 67/153 [00:01<00:01, 52.38it/s, Epoch: 22, Batch: 68,Loss: -1.732,Avg.Loss: -1.104,LR: 4.45E-04]Training epoch 22:  44%|████▍     | 68/153 [00:01<00:01, 52.38it/s, Epoch: 22, Batch: 69,Loss: -2.079,Avg.Loss: -1.119,LR: 4.45E-04]Training epoch 22:  45%|████▌     | 69/153 [00:01<00:01, 52.38it/s, Epoch: 22, Batch: 70,Loss: -1.787,Avg.Loss: -1.128,LR: 4.45E-04]Training epoch 22:  46%|████▌     | 70/153 [00:01<00:01, 52.38it/s, Epoch: 22, Batch: 71,Loss: -1.931,Avg.Loss: -1.139,LR: 4.45E-04]Training epoch 22:  46%|████▋     | 71/153 [00:01<00:01, 52.38it/s, Epoch: 22, Batch: 72,Loss: -2.140,Avg.Loss: -1.153,LR: 4.45E-04]Training epoch 22:  47%|████▋     | 72/153 [00:01<00:01, 52.41it/s, Epoch: 22, Batch: 72,Loss: -2.140,Avg.Loss: -1.153,LR: 4.45E-04]Training epoch 22:  47%|████▋     | 72/153 [00:01<00:01, 52.41it/s, Epoch: 22, Batch: 73,Loss: -2.003,Avg.Loss: -1.165,LR: 4.45E-04]Training epoch 22:  48%|████▊     | 73/153 [00:01<00:01, 52.41it/s, Epoch: 22, Batch: 74,Loss: -1.914,Avg.Loss: -1.175,LR: 4.45E-04]Training epoch 22:  48%|████▊     | 74/153 [00:01<00:01, 52.41it/s, Epoch: 22, Batch: 75,Loss: -2.193,Avg.Loss: -1.189,LR: 4.45E-04]Training epoch 22:  49%|████▉     | 75/153 [00:01<00:01, 52.41it/s, Epoch: 22, Batch: 76,Loss: -1.740,Avg.Loss: -1.196,LR: 4.45E-04]Training epoch 22:  50%|████▉     | 76/153 [00:01<00:01, 52.41it/s, Epoch: 22, Batch: 77,Loss: -1.685,Avg.Loss: -1.202,LR: 4.45E-04]Training epoch 22:  50%|█████     | 77/153 [00:01<00:01, 52.41it/s, Epoch: 22, Batch: 78,Loss: -1.754,Avg.Loss: -1.209,LR: 4.45E-04]Training epoch 22:  51%|█████     | 78/153 [00:01<00:01, 52.59it/s, Epoch: 22, Batch: 78,Loss: -1.754,Avg.Loss: -1.209,LR: 4.45E-04]Training epoch 22:  51%|█████     | 78/153 [00:01<00:01, 52.59it/s, Epoch: 22, Batch: 79,Loss: -1.805,Avg.Loss: -1.217,LR: 4.45E-04]Training epoch 22:  52%|█████▏    | 79/153 [00:01<00:01, 52.59it/s, Epoch: 22, Batch: 80,Loss: -1.432,Avg.Loss: -1.220,LR: 4.45E-04]Training epoch 22:  52%|█████▏    | 80/153 [00:01<00:01, 52.59it/s, Epoch: 22, Batch: 81,Loss: -1.513,Avg.Loss: -1.223,LR: 4.45E-04]Training epoch 22:  53%|█████▎    | 81/153 [00:01<00:01, 52.59it/s, Epoch: 22, Batch: 82,Loss: -1.750,Avg.Loss: -1.230,LR: 4.45E-04]Training epoch 22:  54%|█████▎    | 82/153 [00:01<00:01, 52.59it/s, Epoch: 22, Batch: 83,Loss: -1.833,Avg.Loss: -1.237,LR: 4.45E-04]Training epoch 22:  54%|█████▍    | 83/153 [00:01<00:01, 52.59it/s, Epoch: 22, Batch: 84,Loss: -0.912,Avg.Loss: -1.233,LR: 4.45E-04]Training epoch 22:  55%|█████▍    | 84/153 [00:01<00:01, 52.71it/s, Epoch: 22, Batch: 84,Loss: -0.912,Avg.Loss: -1.233,LR: 4.45E-04]Training epoch 22:  55%|█████▍    | 84/153 [00:01<00:01, 52.71it/s, Epoch: 22, Batch: 85,Loss: -1.303,Avg.Loss: -1.234,LR: 4.45E-04]Training epoch 22:  56%|█████▌    | 85/153 [00:01<00:01, 52.71it/s, Epoch: 22, Batch: 86,Loss: -1.889,Avg.Loss: -1.241,LR: 4.45E-04]Training epoch 22:  56%|█████▌    | 86/153 [00:01<00:01, 52.71it/s, Epoch: 22, Batch: 87,Loss: -1.869,Avg.Loss: -1.249,LR: 4.45E-04]Training epoch 22:  57%|█████▋    | 87/153 [00:01<00:01, 52.71it/s, Epoch: 22, Batch: 88,Loss: -1.820,Avg.Loss: -1.255,LR: 4.45E-04]Training epoch 22:  58%|█████▊    | 88/153 [00:01<00:01, 52.71it/s, Epoch: 22, Batch: 89,Loss: -1.932,Avg.Loss: -1.263,LR: 4.45E-04]Training epoch 22:  58%|█████▊    | 89/153 [00:01<00:01, 52.71it/s, Epoch: 22, Batch: 90,Loss: -1.791,Avg.Loss: -1.269,LR: 4.45E-04]Training epoch 22:  59%|█████▉    | 90/153 [00:01<00:01, 52.78it/s, Epoch: 22, Batch: 90,Loss: -1.791,Avg.Loss: -1.269,LR: 4.45E-04]Training epoch 22:  59%|█████▉    | 90/153 [00:01<00:01, 52.78it/s, Epoch: 22, Batch: 91,Loss: -2.100,Avg.Loss: -1.278,LR: 4.45E-04]Training epoch 22:  59%|█████▉    | 91/153 [00:01<00:01, 52.78it/s, Epoch: 22, Batch: 92,Loss: -1.722,Avg.Loss: -1.283,LR: 4.45E-04]Training epoch 22:  60%|██████    | 92/153 [00:01<00:01, 52.78it/s, Epoch: 22, Batch: 93,Loss: -1.940,Avg.Loss: -1.290,LR: 4.45E-04]Training epoch 22:  61%|██████    | 93/153 [00:01<00:01, 52.78it/s, Epoch: 22, Batch: 94,Loss: -1.607,Avg.Loss: -1.293,LR: 4.45E-04]Training epoch 22:  61%|██████▏   | 94/153 [00:01<00:01, 52.78it/s, Epoch: 22, Batch: 95,Loss: -1.442,Avg.Loss: -1.295,LR: 4.45E-04]Training epoch 22:  62%|██████▏   | 95/153 [00:01<00:01, 52.78it/s, Epoch: 22, Batch: 96,Loss: -1.954,Avg.Loss: -1.301,LR: 4.44E-04]Training epoch 22:  63%|██████▎   | 96/153 [00:01<00:01, 53.00it/s, Epoch: 22, Batch: 96,Loss: -1.954,Avg.Loss: -1.301,LR: 4.44E-04]Training epoch 22:  63%|██████▎   | 96/153 [00:01<00:01, 53.00it/s, Epoch: 22, Batch: 97,Loss: -2.186,Avg.Loss: -1.311,LR: 4.44E-04]Training epoch 22:  63%|██████▎   | 97/153 [00:01<00:01, 53.00it/s, Epoch: 22, Batch: 98,Loss: -2.094,Avg.Loss: -1.319,LR: 4.44E-04]Training epoch 22:  64%|██████▍   | 98/153 [00:01<00:01, 53.00it/s, Epoch: 22, Batch: 99,Loss: -1.520,Avg.Loss: -1.321,LR: 4.44E-04]Training epoch 22:  65%|██████▍   | 99/153 [00:01<00:01, 53.00it/s, Epoch: 22, Batch: 100,Loss: -1.801,Avg.Loss: -1.325,LR: 4.44E-04]Training epoch 22:  65%|██████▌   | 100/153 [00:01<00:01, 53.00it/s, Epoch: 22, Batch: 101,Loss: -1.664,Avg.Loss: -1.329,LR: 4.44E-04]Training epoch 22:  66%|██████▌   | 101/153 [00:01<00:00, 53.00it/s, Epoch: 22, Batch: 102,Loss: -1.310,Avg.Loss: -1.329,LR: 4.44E-04]Training epoch 22:  67%|██████▋   | 102/153 [00:01<00:00, 53.00it/s, Epoch: 22, Batch: 102,Loss: -1.310,Avg.Loss: -1.329,LR: 4.44E-04]Training epoch 22:  67%|██████▋   | 102/153 [00:01<00:00, 53.00it/s, Epoch: 22, Batch: 103,Loss: -1.667,Avg.Loss: -1.332,LR: 4.44E-04]Training epoch 22:  67%|██████▋   | 103/153 [00:01<00:00, 53.00it/s, Epoch: 22, Batch: 104,Loss: -1.786,Avg.Loss: -1.336,LR: 4.44E-04]Training epoch 22:  68%|██████▊   | 104/153 [00:02<00:00, 53.00it/s, Epoch: 22, Batch: 105,Loss: -1.943,Avg.Loss: -1.342,LR: 4.44E-04]Training epoch 22:  69%|██████▊   | 105/153 [00:02<00:00, 53.00it/s, Epoch: 22, Batch: 106,Loss: -2.257,Avg.Loss: -1.351,LR: 4.44E-04]Training epoch 22:  69%|██████▉   | 106/153 [00:02<00:00, 53.00it/s, Epoch: 22, Batch: 107,Loss: -1.840,Avg.Loss: -1.355,LR: 4.44E-04]Training epoch 22:  70%|██████▉   | 107/153 [00:02<00:00, 53.00it/s, Epoch: 22, Batch: 108,Loss: -2.198,Avg.Loss: -1.363,LR: 4.44E-04]Training epoch 22:  71%|███████   | 108/153 [00:02<00:00, 53.06it/s, Epoch: 22, Batch: 108,Loss: -2.198,Avg.Loss: -1.363,LR: 4.44E-04]Training epoch 22:  71%|███████   | 108/153 [00:02<00:00, 53.06it/s, Epoch: 22, Batch: 109,Loss: -1.814,Avg.Loss: -1.367,LR: 4.44E-04]Training epoch 22:  71%|███████   | 109/153 [00:02<00:00, 53.06it/s, Epoch: 22, Batch: 110,Loss: -1.613,Avg.Loss: -1.369,LR: 4.44E-04]Training epoch 22:  72%|███████▏  | 110/153 [00:02<00:00, 53.06it/s, Epoch: 22, Batch: 111,Loss: -2.025,Avg.Loss: -1.375,LR: 4.44E-04]Training epoch 22:  73%|███████▎  | 111/153 [00:02<00:00, 53.06it/s, Epoch: 22, Batch: 112,Loss: -1.498,Avg.Loss: -1.376,LR: 4.44E-04]Training epoch 22:  73%|███████▎  | 112/153 [00:02<00:00, 53.06it/s, Epoch: 22, Batch: 113,Loss: -1.467,Avg.Loss: -1.377,LR: 4.44E-04]Training epoch 22:  74%|███████▍  | 113/153 [00:02<00:00, 53.06it/s, Epoch: 22, Batch: 114,Loss: -1.817,Avg.Loss: -1.381,LR: 4.44E-04]Training epoch 22:  75%|███████▍  | 114/153 [00:02<00:00, 52.98it/s, Epoch: 22, Batch: 114,Loss: -1.817,Avg.Loss: -1.381,LR: 4.44E-04]Training epoch 22:  75%|███████▍  | 114/153 [00:02<00:00, 52.98it/s, Epoch: 22, Batch: 115,Loss: -1.628,Avg.Loss: -1.383,LR: 4.44E-04]Training epoch 22:  75%|███████▌  | 115/153 [00:02<00:00, 52.98it/s, Epoch: 22, Batch: 116,Loss: -1.440,Avg.Loss: -1.384,LR: 4.44E-04]Training epoch 22:  76%|███████▌  | 116/153 [00:02<00:00, 52.98it/s, Epoch: 22, Batch: 117,Loss: -1.012,Avg.Loss: -1.381,LR: 4.44E-04]Training epoch 22:  76%|███████▋  | 117/153 [00:02<00:00, 52.98it/s, Epoch: 22, Batch: 118,Loss: -1.764,Avg.Loss: -1.384,LR: 4.44E-04]Training epoch 22:  77%|███████▋  | 118/153 [00:02<00:00, 52.98it/s, Epoch: 22, Batch: 119,Loss: -1.316,Avg.Loss: -1.383,LR: 4.44E-04]Training epoch 22:  78%|███████▊  | 119/153 [00:02<00:00, 52.98it/s, Epoch: 22, Batch: 120,Loss: -0.310,Avg.Loss: -1.374,LR: 4.44E-04]Training epoch 22:  78%|███████▊  | 120/153 [00:02<00:00, 53.08it/s, Epoch: 22, Batch: 120,Loss: -0.310,Avg.Loss: -1.374,LR: 4.44E-04]Training epoch 22:  78%|███████▊  | 120/153 [00:02<00:00, 53.08it/s, Epoch: 22, Batch: 121,Loss: -0.401,Avg.Loss: -1.366,LR: 4.44E-04]Training epoch 22:  79%|███████▉  | 121/153 [00:02<00:00, 53.08it/s, Epoch: 22, Batch: 122,Loss: -1.525,Avg.Loss: -1.368,LR: 4.44E-04]Training epoch 22:  80%|███████▉  | 122/153 [00:02<00:00, 53.08it/s, Epoch: 22, Batch: 123,Loss: -0.830,Avg.Loss: -1.363,LR: 4.44E-04]Training epoch 22:  80%|████████  | 123/153 [00:02<00:00, 53.08it/s, Epoch: 22, Batch: 124,Loss: -0.625,Avg.Loss: -1.357,LR: 4.44E-04]Training epoch 22:  81%|████████  | 124/153 [00:02<00:00, 53.08it/s, Epoch: 22, Batch: 125,Loss: -1.206,Avg.Loss: -1.356,LR: 4.44E-04]Training epoch 22:  82%|████████▏ | 125/153 [00:02<00:00, 53.08it/s, Epoch: 22, Batch: 126,Loss: -1.708,Avg.Loss: -1.359,LR: 4.44E-04]Training epoch 22:  82%|████████▏ | 126/153 [00:02<00:00, 53.18it/s, Epoch: 22, Batch: 126,Loss: -1.708,Avg.Loss: -1.359,LR: 4.44E-04]Training epoch 22:  82%|████████▏ | 126/153 [00:02<00:00, 53.18it/s, Epoch: 22, Batch: 127,Loss: -1.522,Avg.Loss: -1.360,LR: 4.43E-04]Training epoch 22:  83%|████████▎ | 127/153 [00:02<00:00, 53.18it/s, Epoch: 22, Batch: 128,Loss: -1.073,Avg.Loss: -1.358,LR: 4.43E-04]Training epoch 22:  84%|████████▎ | 128/153 [00:02<00:00, 53.18it/s, Epoch: 22, Batch: 129,Loss: -1.272,Avg.Loss: -1.357,LR: 4.43E-04]Training epoch 22:  84%|████████▍ | 129/153 [00:02<00:00, 53.18it/s, Epoch: 22, Batch: 130,Loss: -1.815,Avg.Loss: -1.361,LR: 4.43E-04]Training epoch 22:  85%|████████▍ | 130/153 [00:02<00:00, 53.18it/s, Epoch: 22, Batch: 131,Loss: -1.495,Avg.Loss: -1.362,LR: 4.43E-04]Training epoch 22:  86%|████████▌ | 131/153 [00:02<00:00, 53.18it/s, Epoch: 22, Batch: 132,Loss: -0.748,Avg.Loss: -1.357,LR: 4.43E-04]Training epoch 22:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 22, Batch: 132,Loss: -0.748,Avg.Loss: -1.357,LR: 4.43E-04]Training epoch 22:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 22, Batch: 133,Loss: -0.121,Avg.Loss: -1.348,LR: 4.43E-04]Training epoch 22:  87%|████████▋ | 133/153 [00:02<00:00, 53.28it/s, Epoch: 22, Batch: 134,Loss: -1.031,Avg.Loss: -1.345,LR: 4.43E-04]Training epoch 22:  88%|████████▊ | 134/153 [00:02<00:00, 53.28it/s, Epoch: 22, Batch: 135,Loss: -1.396,Avg.Loss: -1.346,LR: 4.43E-04]Training epoch 22:  88%|████████▊ | 135/153 [00:02<00:00, 53.28it/s, Epoch: 22, Batch: 136,Loss: -1.716,Avg.Loss: -1.348,LR: 4.43E-04]Training epoch 22:  89%|████████▉ | 136/153 [00:02<00:00, 53.28it/s, Epoch: 22, Batch: 137,Loss: -1.455,Avg.Loss: -1.349,LR: 4.43E-04]Training epoch 22:  90%|████████▉ | 137/153 [00:02<00:00, 53.28it/s, Epoch: 22, Batch: 138,Loss: -1.516,Avg.Loss: -1.350,LR: 4.43E-04]Training epoch 22:  90%|█████████ | 138/153 [00:02<00:00, 51.39it/s, Epoch: 22, Batch: 138,Loss: -1.516,Avg.Loss: -1.350,LR: 4.43E-04]Training epoch 22:  90%|█████████ | 138/153 [00:02<00:00, 51.39it/s, Epoch: 22, Batch: 139,Loss: -1.744,Avg.Loss: -1.353,LR: 4.43E-04]Training epoch 22:  91%|█████████ | 139/153 [00:02<00:00, 51.39it/s, Epoch: 22, Batch: 140,Loss: -2.054,Avg.Loss: -1.358,LR: 4.43E-04]Training epoch 22:  92%|█████████▏| 140/153 [00:02<00:00, 51.39it/s, Epoch: 22, Batch: 141,Loss: -1.535,Avg.Loss: -1.360,LR: 4.43E-04]Training epoch 22:  92%|█████████▏| 141/153 [00:02<00:00, 51.39it/s, Epoch: 22, Batch: 142,Loss: -1.306,Avg.Loss: -1.359,LR: 4.43E-04]Training epoch 22:  93%|█████████▎| 142/153 [00:02<00:00, 51.39it/s, Epoch: 22, Batch: 143,Loss: -2.155,Avg.Loss: -1.365,LR: 4.43E-04]Training epoch 22:  93%|█████████▎| 143/153 [00:02<00:00, 51.39it/s, Epoch: 22, Batch: 144,Loss: -2.023,Avg.Loss: -1.369,LR: 4.43E-04]Training epoch 22:  94%|█████████▍| 144/153 [00:02<00:00, 51.83it/s, Epoch: 22, Batch: 144,Loss: -2.023,Avg.Loss: -1.369,LR: 4.43E-04]Training epoch 22:  94%|█████████▍| 144/153 [00:02<00:00, 51.83it/s, Epoch: 22, Batch: 145,Loss: -1.318,Avg.Loss: -1.369,LR: 4.43E-04]Training epoch 22:  95%|█████████▍| 145/153 [00:02<00:00, 51.83it/s, Epoch: 22, Batch: 146,Loss: -1.462,Avg.Loss: -1.370,LR: 4.43E-04]Training epoch 22:  95%|█████████▌| 146/153 [00:02<00:00, 51.83it/s, Epoch: 22, Batch: 147,Loss: -0.965,Avg.Loss: -1.367,LR: 4.43E-04]Training epoch 22:  96%|█████████▌| 147/153 [00:02<00:00, 51.83it/s, Epoch: 22, Batch: 148,Loss: -0.945,Avg.Loss: -1.364,LR: 4.43E-04]Training epoch 22:  97%|█████████▋| 148/153 [00:02<00:00, 51.83it/s, Epoch: 22, Batch: 149,Loss: -1.605,Avg.Loss: -1.366,LR: 4.43E-04]Training epoch 22:  97%|█████████▋| 149/153 [00:02<00:00, 51.83it/s, Epoch: 22, Batch: 150,Loss: -1.629,Avg.Loss: -1.367,LR: 4.43E-04]Training epoch 22:  98%|█████████▊| 150/153 [00:02<00:00, 52.28it/s, Epoch: 22, Batch: 150,Loss: -1.629,Avg.Loss: -1.367,LR: 4.43E-04]Training epoch 22:  98%|█████████▊| 150/153 [00:02<00:00, 52.28it/s, Epoch: 22, Batch: 151,Loss: -1.395,Avg.Loss: -1.368,LR: 4.43E-04]Training epoch 22:  99%|█████████▊| 151/153 [00:02<00:00, 52.28it/s, Epoch: 22, Batch: 152,Loss: -1.848,Avg.Loss: -1.371,LR: 4.43E-04]Training epoch 22:  99%|█████████▉| 152/153 [00:02<00:00, 52.28it/s, Epoch: 22, Batch: 153,Loss: -2.130,Avg.Loss: -1.376,LR: 4.43E-04]Training epoch 22: 100%|██████████| 153/153 [00:02<00:00, 52.35it/s, Epoch: 22, Batch: 153,Loss: -2.130,Avg.Loss: -1.376,LR: 4.43E-04]
Training epoch 23:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 23:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 23, Batch: 1,Loss: -1.432,Avg.Loss: -1.432,LR: 4.43E-04]Training epoch 23:   1%|          | 1/153 [00:00<00:05, 29.04it/s, Epoch: 23, Batch: 2,Loss: -1.875,Avg.Loss: -1.654,LR: 4.43E-04]Training epoch 23:   1%|▏         | 2/153 [00:00<00:03, 38.59it/s, Epoch: 23, Batch: 3,Loss: -1.649,Avg.Loss: -1.652,LR: 4.43E-04]Training epoch 23:   2%|▏         | 3/153 [00:00<00:03, 43.77it/s, Epoch: 23, Batch: 4,Loss: -1.864,Avg.Loss: -1.705,LR: 4.42E-04]Training epoch 23:   3%|▎         | 4/153 [00:00<00:03, 46.19it/s, Epoch: 23, Batch: 5,Loss: -1.667,Avg.Loss: -1.698,LR: 4.42E-04]Training epoch 23:   3%|▎         | 5/153 [00:00<00:03, 47.32it/s, Epoch: 23, Batch: 6,Loss: -1.504,Avg.Loss: -1.665,LR: 4.42E-04]Training epoch 23:   4%|▍         | 6/153 [00:00<00:02, 56.68it/s, Epoch: 23, Batch: 6,Loss: -1.504,Avg.Loss: -1.665,LR: 4.42E-04]Training epoch 23:   4%|▍         | 6/153 [00:00<00:02, 56.68it/s, Epoch: 23, Batch: 7,Loss: -1.916,Avg.Loss: -1.701,LR: 4.42E-04]Training epoch 23:   5%|▍         | 7/153 [00:00<00:02, 56.68it/s, Epoch: 23, Batch: 8,Loss: -1.720,Avg.Loss: -1.703,LR: 4.42E-04]Training epoch 23:   5%|▌         | 8/153 [00:00<00:02, 56.68it/s, Epoch: 23, Batch: 9,Loss: -1.739,Avg.Loss: -1.707,LR: 4.42E-04]Training epoch 23:   6%|▌         | 9/153 [00:00<00:02, 56.68it/s, Epoch: 23, Batch: 10,Loss: -2.093,Avg.Loss: -1.746,LR: 4.42E-04]Training epoch 23:   7%|▋         | 10/153 [00:00<00:02, 56.68it/s, Epoch: 23, Batch: 11,Loss: -2.159,Avg.Loss: -1.783,LR: 4.42E-04]Training epoch 23:   7%|▋         | 11/153 [00:00<00:02, 56.68it/s, Epoch: 23, Batch: 12,Loss: -1.909,Avg.Loss: -1.794,LR: 4.42E-04]Training epoch 23:   8%|▊         | 12/153 [00:00<00:02, 54.26it/s, Epoch: 23, Batch: 12,Loss: -1.909,Avg.Loss: -1.794,LR: 4.42E-04]Training epoch 23:   8%|▊         | 12/153 [00:00<00:02, 54.26it/s, Epoch: 23, Batch: 13,Loss: -1.886,Avg.Loss: -1.801,LR: 4.42E-04]Training epoch 23:   8%|▊         | 13/153 [00:00<00:02, 54.26it/s, Epoch: 23, Batch: 14,Loss: -1.914,Avg.Loss: -1.809,LR: 4.42E-04]Training epoch 23:   9%|▉         | 14/153 [00:00<00:02, 54.26it/s, Epoch: 23, Batch: 15,Loss: -1.691,Avg.Loss: -1.801,LR: 4.42E-04]Training epoch 23:  10%|▉         | 15/153 [00:00<00:02, 54.26it/s, Epoch: 23, Batch: 16,Loss: -1.391,Avg.Loss: -1.776,LR: 4.42E-04]Training epoch 23:  10%|█         | 16/153 [00:00<00:02, 54.26it/s, Epoch: 23, Batch: 17,Loss: -2.028,Avg.Loss: -1.791,LR: 4.42E-04]Training epoch 23:  11%|█         | 17/153 [00:00<00:02, 54.26it/s, Epoch: 23, Batch: 18,Loss: -1.467,Avg.Loss: -1.773,LR: 4.42E-04]Training epoch 23:  12%|█▏        | 18/153 [00:00<00:02, 53.60it/s, Epoch: 23, Batch: 18,Loss: -1.467,Avg.Loss: -1.773,LR: 4.42E-04]Training epoch 23:  12%|█▏        | 18/153 [00:00<00:02, 53.60it/s, Epoch: 23, Batch: 19,Loss: -1.639,Avg.Loss: -1.765,LR: 4.42E-04]Training epoch 23:  12%|█▏        | 19/153 [00:00<00:02, 53.60it/s, Epoch: 23, Batch: 20,Loss: -1.832,Avg.Loss: -1.769,LR: 4.42E-04]Training epoch 23:  13%|█▎        | 20/153 [00:00<00:02, 53.60it/s, Epoch: 23, Batch: 21,Loss: -1.585,Avg.Loss: -1.760,LR: 4.42E-04]Training epoch 23:  14%|█▎        | 21/153 [00:00<00:02, 53.60it/s, Epoch: 23, Batch: 22,Loss: -1.539,Avg.Loss: -1.750,LR: 4.42E-04]Training epoch 23:  14%|█▍        | 22/153 [00:00<00:02, 53.60it/s, Epoch: 23, Batch: 23,Loss: -1.866,Avg.Loss: -1.755,LR: 4.42E-04]Training epoch 23:  15%|█▌        | 23/153 [00:00<00:02, 53.60it/s, Epoch: 23, Batch: 24,Loss: -1.548,Avg.Loss: -1.746,LR: 4.42E-04]Training epoch 23:  16%|█▌        | 24/153 [00:00<00:02, 52.47it/s, Epoch: 23, Batch: 24,Loss: -1.548,Avg.Loss: -1.746,LR: 4.42E-04]Training epoch 23:  16%|█▌        | 24/153 [00:00<00:02, 52.47it/s, Epoch: 23, Batch: 25,Loss: -1.220,Avg.Loss: -1.725,LR: 4.42E-04]Training epoch 23:  16%|█▋        | 25/153 [00:00<00:02, 52.47it/s, Epoch: 23, Batch: 26,Loss: -1.342,Avg.Loss: -1.711,LR: 4.42E-04]Training epoch 23:  17%|█▋        | 26/153 [00:00<00:02, 52.47it/s, Epoch: 23, Batch: 27,Loss: -2.200,Avg.Loss: -1.729,LR: 4.42E-04]Training epoch 23:  18%|█▊        | 27/153 [00:00<00:02, 52.47it/s, Epoch: 23, Batch: 28,Loss: -1.519,Avg.Loss: -1.721,LR: 4.42E-04]Training epoch 23:  18%|█▊        | 28/153 [00:00<00:02, 52.47it/s, Epoch: 23, Batch: 29,Loss: -1.139,Avg.Loss: -1.701,LR: 4.42E-04]Training epoch 23:  19%|█▉        | 29/153 [00:00<00:02, 52.47it/s, Epoch: 23, Batch: 30,Loss: -1.669,Avg.Loss: -1.700,LR: 4.42E-04]Training epoch 23:  20%|█▉        | 30/153 [00:00<00:02, 52.19it/s, Epoch: 23, Batch: 30,Loss: -1.669,Avg.Loss: -1.700,LR: 4.42E-04]Training epoch 23:  20%|█▉        | 30/153 [00:00<00:02, 52.19it/s, Epoch: 23, Batch: 31,Loss: -1.819,Avg.Loss: -1.704,LR: 4.42E-04]Training epoch 23:  20%|██        | 31/153 [00:00<00:02, 52.19it/s, Epoch: 23, Batch: 32,Loss: -1.438,Avg.Loss: -1.696,LR: 4.42E-04]Training epoch 23:  21%|██        | 32/153 [00:00<00:02, 52.19it/s, Epoch: 23, Batch: 33,Loss: -1.344,Avg.Loss: -1.685,LR: 4.42E-04]Training epoch 23:  22%|██▏       | 33/153 [00:00<00:02, 52.19it/s, Epoch: 23, Batch: 34,Loss: -1.816,Avg.Loss: -1.689,LR: 4.42E-04]Training epoch 23:  22%|██▏       | 34/153 [00:00<00:02, 52.19it/s, Epoch: 23, Batch: 35,Loss: -2.023,Avg.Loss: -1.698,LR: 4.41E-04]Training epoch 23:  23%|██▎       | 35/153 [00:00<00:02, 52.19it/s, Epoch: 23, Batch: 36,Loss: -1.820,Avg.Loss: -1.702,LR: 4.41E-04]Training epoch 23:  24%|██▎       | 36/153 [00:00<00:02, 52.44it/s, Epoch: 23, Batch: 36,Loss: -1.820,Avg.Loss: -1.702,LR: 4.41E-04]Training epoch 23:  24%|██▎       | 36/153 [00:00<00:02, 52.44it/s, Epoch: 23, Batch: 37,Loss: -1.778,Avg.Loss: -1.704,LR: 4.41E-04]Training epoch 23:  24%|██▍       | 37/153 [00:00<00:02, 52.44it/s, Epoch: 23, Batch: 38,Loss: -1.849,Avg.Loss: -1.708,LR: 4.41E-04]Training epoch 23:  25%|██▍       | 38/153 [00:00<00:02, 52.44it/s, Epoch: 23, Batch: 39,Loss: -1.649,Avg.Loss: -1.706,LR: 4.41E-04]Training epoch 23:  25%|██▌       | 39/153 [00:00<00:02, 52.44it/s, Epoch: 23, Batch: 40,Loss: -1.550,Avg.Loss: -1.702,LR: 4.41E-04]Training epoch 23:  26%|██▌       | 40/153 [00:00<00:02, 52.44it/s, Epoch: 23, Batch: 41,Loss: -1.077,Avg.Loss: -1.687,LR: 4.41E-04]Training epoch 23:  27%|██▋       | 41/153 [00:00<00:02, 52.44it/s, Epoch: 23, Batch: 42,Loss: -1.564,Avg.Loss: -1.684,LR: 4.41E-04]Training epoch 23:  27%|██▋       | 42/153 [00:00<00:02, 52.69it/s, Epoch: 23, Batch: 42,Loss: -1.564,Avg.Loss: -1.684,LR: 4.41E-04]Training epoch 23:  27%|██▋       | 42/153 [00:00<00:02, 52.69it/s, Epoch: 23, Batch: 43,Loss: -1.245,Avg.Loss: -1.674,LR: 4.41E-04]Training epoch 23:  28%|██▊       | 43/153 [00:00<00:02, 52.69it/s, Epoch: 23, Batch: 44,Loss: -1.585,Avg.Loss: -1.672,LR: 4.41E-04]Training epoch 23:  29%|██▉       | 44/153 [00:00<00:02, 52.69it/s, Epoch: 23, Batch: 45,Loss: -1.699,Avg.Loss: -1.672,LR: 4.41E-04]Training epoch 23:  29%|██▉       | 45/153 [00:00<00:02, 52.69it/s, Epoch: 23, Batch: 46,Loss: -0.901,Avg.Loss: -1.656,LR: 4.41E-04]Training epoch 23:  30%|███       | 46/153 [00:00<00:02, 52.69it/s, Epoch: 23, Batch: 47,Loss: -1.394,Avg.Loss: -1.650,LR: 4.41E-04]Training epoch 23:  31%|███       | 47/153 [00:00<00:02, 52.69it/s, Epoch: 23, Batch: 48,Loss: -1.832,Avg.Loss: -1.654,LR: 4.41E-04]Training epoch 23:  31%|███▏      | 48/153 [00:00<00:01, 52.85it/s, Epoch: 23, Batch: 48,Loss: -1.832,Avg.Loss: -1.654,LR: 4.41E-04]Training epoch 23:  31%|███▏      | 48/153 [00:00<00:01, 52.85it/s, Epoch: 23, Batch: 49,Loss: -1.393,Avg.Loss: -1.649,LR: 4.41E-04]Training epoch 23:  32%|███▏      | 49/153 [00:00<00:01, 52.85it/s, Epoch: 23, Batch: 50,Loss: -1.968,Avg.Loss: -1.655,LR: 4.41E-04]Training epoch 23:  33%|███▎      | 50/153 [00:00<00:01, 52.85it/s, Epoch: 23, Batch: 51,Loss: -2.076,Avg.Loss: -1.663,LR: 4.41E-04]Training epoch 23:  33%|███▎      | 51/153 [00:00<00:01, 52.85it/s, Epoch: 23, Batch: 52,Loss: -1.955,Avg.Loss: -1.669,LR: 4.41E-04]Training epoch 23:  34%|███▍      | 52/153 [00:01<00:01, 52.85it/s, Epoch: 23, Batch: 53,Loss: -1.795,Avg.Loss: -1.671,LR: 4.41E-04]Training epoch 23:  35%|███▍      | 53/153 [00:01<00:01, 52.85it/s, Epoch: 23, Batch: 54,Loss: -1.996,Avg.Loss: -1.677,LR: 4.41E-04]Training epoch 23:  35%|███▌      | 54/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 54,Loss: -1.996,Avg.Loss: -1.677,LR: 4.41E-04]Training epoch 23:  35%|███▌      | 54/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 55,Loss: -1.961,Avg.Loss: -1.682,LR: 4.41E-04]Training epoch 23:  36%|███▌      | 55/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 56,Loss: -2.141,Avg.Loss: -1.691,LR: 4.41E-04]Training epoch 23:  37%|███▋      | 56/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 57,Loss: -1.828,Avg.Loss: -1.693,LR: 4.41E-04]Training epoch 23:  37%|███▋      | 57/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 58,Loss: -1.781,Avg.Loss: -1.695,LR: 4.41E-04]Training epoch 23:  38%|███▊      | 58/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 59,Loss: -1.802,Avg.Loss: -1.696,LR: 4.41E-04]Training epoch 23:  39%|███▊      | 59/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 60,Loss: -2.143,Avg.Loss: -1.704,LR: 4.41E-04]Training epoch 23:  39%|███▉      | 60/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 60,Loss: -2.143,Avg.Loss: -1.704,LR: 4.41E-04]Training epoch 23:  39%|███▉      | 60/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 61,Loss: -1.367,Avg.Loss: -1.698,LR: 4.41E-04]Training epoch 23:  40%|███▉      | 61/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 62,Loss: -2.116,Avg.Loss: -1.705,LR: 4.41E-04]Training epoch 23:  41%|████      | 62/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 63,Loss: -2.087,Avg.Loss: -1.711,LR: 4.41E-04]Training epoch 23:  41%|████      | 63/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 64,Loss: -1.889,Avg.Loss: -1.714,LR: 4.41E-04]Training epoch 23:  42%|████▏     | 64/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 65,Loss: -2.033,Avg.Loss: -1.719,LR: 4.40E-04]Training epoch 23:  42%|████▏     | 65/153 [00:01<00:01, 52.97it/s, Epoch: 23, Batch: 66,Loss: -1.502,Avg.Loss: -1.715,LR: 4.40E-04]Training epoch 23:  43%|████▎     | 66/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 66,Loss: -1.502,Avg.Loss: -1.715,LR: 4.40E-04]Training epoch 23:  43%|████▎     | 66/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 67,Loss: -0.875,Avg.Loss: -1.703,LR: 4.40E-04]Training epoch 23:  44%|████▍     | 67/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 68,Loss: -1.204,Avg.Loss: -1.696,LR: 4.40E-04]Training epoch 23:  44%|████▍     | 68/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 69,Loss: -0.822,Avg.Loss: -1.683,LR: 4.40E-04]Training epoch 23:  45%|████▌     | 69/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 70,Loss: -0.573,Avg.Loss: -1.667,LR: 4.40E-04]Training epoch 23:  46%|████▌     | 70/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 71,Loss: -1.323,Avg.Loss: -1.662,LR: 4.40E-04]Training epoch 23:  46%|████▋     | 71/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 72,Loss: -1.659,Avg.Loss: -1.662,LR: 4.40E-04]Training epoch 23:  47%|████▋     | 72/153 [00:01<00:01, 53.03it/s, Epoch: 23, Batch: 72,Loss: -1.659,Avg.Loss: -1.662,LR: 4.40E-04]Training epoch 23:  47%|████▋     | 72/153 [00:01<00:01, 53.03it/s, Epoch: 23, Batch: 73,Loss: -2.197,Avg.Loss: -1.669,LR: 4.40E-04]Training epoch 23:  48%|████▊     | 73/153 [00:01<00:01, 53.03it/s, Epoch: 23, Batch: 74,Loss: -2.189,Avg.Loss: -1.676,LR: 4.40E-04]Training epoch 23:  48%|████▊     | 74/153 [00:01<00:01, 53.03it/s, Epoch: 23, Batch: 75,Loss: -1.716,Avg.Loss: -1.677,LR: 4.40E-04]Training epoch 23:  49%|████▉     | 75/153 [00:01<00:01, 53.03it/s, Epoch: 23, Batch: 76,Loss: -0.410,Avg.Loss: -1.660,LR: 4.40E-04]Training epoch 23:  50%|████▉     | 76/153 [00:01<00:01, 53.03it/s, Epoch: 23, Batch: 77,Loss: -1.782,Avg.Loss: -1.662,LR: 4.40E-04]Training epoch 23:  50%|█████     | 77/153 [00:01<00:01, 53.03it/s, Epoch: 23, Batch: 78,Loss: -2.187,Avg.Loss: -1.669,LR: 4.40E-04]Training epoch 23:  51%|█████     | 78/153 [00:01<00:01, 52.92it/s, Epoch: 23, Batch: 78,Loss: -2.187,Avg.Loss: -1.669,LR: 4.40E-04]Training epoch 23:  51%|█████     | 78/153 [00:01<00:01, 52.92it/s, Epoch: 23, Batch: 79,Loss: -1.919,Avg.Loss: -1.672,LR: 4.40E-04]Training epoch 23:  52%|█████▏    | 79/153 [00:01<00:01, 52.92it/s, Epoch: 23, Batch: 80,Loss: -2.266,Avg.Loss: -1.679,LR: 4.40E-04]Training epoch 23:  52%|█████▏    | 80/153 [00:01<00:01, 52.92it/s, Epoch: 23, Batch: 81,Loss: -1.947,Avg.Loss: -1.683,LR: 4.40E-04]Training epoch 23:  53%|█████▎    | 81/153 [00:01<00:01, 52.92it/s, Epoch: 23, Batch: 82,Loss: -1.904,Avg.Loss: -1.685,LR: 4.40E-04]Training epoch 23:  54%|█████▎    | 82/153 [00:01<00:01, 52.92it/s, Epoch: 23, Batch: 83,Loss: -1.775,Avg.Loss: -1.686,LR: 4.40E-04]Training epoch 23:  54%|█████▍    | 83/153 [00:01<00:01, 52.92it/s, Epoch: 23, Batch: 84,Loss: -1.411,Avg.Loss: -1.683,LR: 4.40E-04]Training epoch 23:  55%|█████▍    | 84/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 84,Loss: -1.411,Avg.Loss: -1.683,LR: 4.40E-04]Training epoch 23:  55%|█████▍    | 84/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 85,Loss: -1.572,Avg.Loss: -1.682,LR: 4.40E-04]Training epoch 23:  56%|█████▌    | 85/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 86,Loss: -2.038,Avg.Loss: -1.686,LR: 4.40E-04]Training epoch 23:  56%|█████▌    | 86/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 87,Loss: -1.807,Avg.Loss: -1.687,LR: 4.40E-04]Training epoch 23:  57%|█████▋    | 87/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 88,Loss: -1.663,Avg.Loss: -1.687,LR: 4.40E-04]Training epoch 23:  58%|█████▊    | 88/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 89,Loss: -2.140,Avg.Loss: -1.692,LR: 4.40E-04]Training epoch 23:  58%|█████▊    | 89/153 [00:01<00:01, 53.01it/s, Epoch: 23, Batch: 90,Loss: -1.632,Avg.Loss: -1.691,LR: 4.40E-04]Training epoch 23:  59%|█████▉    | 90/153 [00:01<00:01, 52.94it/s, Epoch: 23, Batch: 90,Loss: -1.632,Avg.Loss: -1.691,LR: 4.40E-04]Training epoch 23:  59%|█████▉    | 90/153 [00:01<00:01, 52.94it/s, Epoch: 23, Batch: 91,Loss: -1.533,Avg.Loss: -1.690,LR: 4.40E-04]Training epoch 23:  59%|█████▉    | 91/153 [00:01<00:01, 52.94it/s, Epoch: 23, Batch: 92,Loss: -1.948,Avg.Loss: -1.692,LR: 4.40E-04]Training epoch 23:  60%|██████    | 92/153 [00:01<00:01, 52.94it/s, Epoch: 23, Batch: 93,Loss: -1.936,Avg.Loss: -1.695,LR: 4.40E-04]Training epoch 23:  61%|██████    | 93/153 [00:01<00:01, 52.94it/s, Epoch: 23, Batch: 94,Loss: -2.026,Avg.Loss: -1.699,LR: 4.40E-04]Training epoch 23:  61%|██████▏   | 94/153 [00:01<00:01, 52.94it/s, Epoch: 23, Batch: 95,Loss: -2.210,Avg.Loss: -1.704,LR: 4.39E-04]Training epoch 23:  62%|██████▏   | 95/153 [00:01<00:01, 52.94it/s, Epoch: 23, Batch: 96,Loss: -2.430,Avg.Loss: -1.712,LR: 4.39E-04]Training epoch 23:  63%|██████▎   | 96/153 [00:01<00:01, 53.15it/s, Epoch: 23, Batch: 96,Loss: -2.430,Avg.Loss: -1.712,LR: 4.39E-04]Training epoch 23:  63%|██████▎   | 96/153 [00:01<00:01, 53.15it/s, Epoch: 23, Batch: 97,Loss: -1.729,Avg.Loss: -1.712,LR: 4.39E-04]Training epoch 23:  63%|██████▎   | 97/153 [00:01<00:01, 53.15it/s, Epoch: 23, Batch: 98,Loss: -2.314,Avg.Loss: -1.718,LR: 4.39E-04]Training epoch 23:  64%|██████▍   | 98/153 [00:01<00:01, 53.15it/s, Epoch: 23, Batch: 99,Loss: -1.430,Avg.Loss: -1.715,LR: 4.39E-04]Training epoch 23:  65%|██████▍   | 99/153 [00:01<00:01, 53.15it/s, Epoch: 23, Batch: 100,Loss: -1.703,Avg.Loss: -1.715,LR: 4.39E-04]Training epoch 23:  65%|██████▌   | 100/153 [00:01<00:00, 53.15it/s, Epoch: 23, Batch: 101,Loss: -1.936,Avg.Loss: -1.717,LR: 4.39E-04]Training epoch 23:  66%|██████▌   | 101/153 [00:01<00:00, 53.15it/s, Epoch: 23, Batch: 102,Loss: -1.807,Avg.Loss: -1.718,LR: 4.39E-04]Training epoch 23:  67%|██████▋   | 102/153 [00:01<00:00, 53.11it/s, Epoch: 23, Batch: 102,Loss: -1.807,Avg.Loss: -1.718,LR: 4.39E-04]Training epoch 23:  67%|██████▋   | 102/153 [00:01<00:00, 53.11it/s, Epoch: 23, Batch: 103,Loss: -1.047,Avg.Loss: -1.711,LR: 4.39E-04]Training epoch 23:  67%|██████▋   | 103/153 [00:01<00:00, 53.11it/s, Epoch: 23, Batch: 104,Loss: -1.834,Avg.Loss: -1.713,LR: 4.39E-04]Training epoch 23:  68%|██████▊   | 104/153 [00:01<00:00, 53.11it/s, Epoch: 23, Batch: 105,Loss: -2.344,Avg.Loss: -1.719,LR: 4.39E-04]Training epoch 23:  69%|██████▊   | 105/153 [00:01<00:00, 53.11it/s, Epoch: 23, Batch: 106,Loss: -1.986,Avg.Loss: -1.721,LR: 4.39E-04]Training epoch 23:  69%|██████▉   | 106/153 [00:02<00:00, 53.11it/s, Epoch: 23, Batch: 107,Loss: -2.001,Avg.Loss: -1.724,LR: 4.39E-04]Training epoch 23:  70%|██████▉   | 107/153 [00:02<00:00, 53.11it/s, Epoch: 23, Batch: 108,Loss: -1.928,Avg.Loss: -1.726,LR: 4.39E-04]Training epoch 23:  71%|███████   | 108/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 108,Loss: -1.928,Avg.Loss: -1.726,LR: 4.39E-04]Training epoch 23:  71%|███████   | 108/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 109,Loss: -1.747,Avg.Loss: -1.726,LR: 4.39E-04]Training epoch 23:  71%|███████   | 109/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 110,Loss: -1.900,Avg.Loss: -1.727,LR: 4.39E-04]Training epoch 23:  72%|███████▏  | 110/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 111,Loss: -2.125,Avg.Loss: -1.731,LR: 4.39E-04]Training epoch 23:  73%|███████▎  | 111/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 112,Loss: -1.625,Avg.Loss: -1.730,LR: 4.39E-04]Training epoch 23:  73%|███████▎  | 112/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 113,Loss: -2.105,Avg.Loss: -1.733,LR: 4.39E-04]Training epoch 23:  74%|███████▍  | 113/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 114,Loss: -1.538,Avg.Loss: -1.732,LR: 4.39E-04]Training epoch 23:  75%|███████▍  | 114/153 [00:02<00:00, 52.60it/s, Epoch: 23, Batch: 114,Loss: -1.538,Avg.Loss: -1.732,LR: 4.39E-04]Training epoch 23:  75%|███████▍  | 114/153 [00:02<00:00, 52.60it/s, Epoch: 23, Batch: 115,Loss: -1.214,Avg.Loss: -1.727,LR: 4.39E-04]Training epoch 23:  75%|███████▌  | 115/153 [00:02<00:00, 52.60it/s, Epoch: 23, Batch: 116,Loss: -2.001,Avg.Loss: -1.730,LR: 4.39E-04]Training epoch 23:  76%|███████▌  | 116/153 [00:02<00:00, 52.60it/s, Epoch: 23, Batch: 117,Loss: -2.159,Avg.Loss: -1.733,LR: 4.39E-04]Training epoch 23:  76%|███████▋  | 117/153 [00:02<00:00, 52.60it/s, Epoch: 23, Batch: 118,Loss: -1.844,Avg.Loss: -1.734,LR: 4.39E-04]Training epoch 23:  77%|███████▋  | 118/153 [00:02<00:00, 52.60it/s, Epoch: 23, Batch: 119,Loss: -1.760,Avg.Loss: -1.734,LR: 4.39E-04]Training epoch 23:  78%|███████▊  | 119/153 [00:02<00:00, 52.60it/s, Epoch: 23, Batch: 120,Loss: -2.302,Avg.Loss: -1.739,LR: 4.39E-04]Training epoch 23:  78%|███████▊  | 120/153 [00:02<00:00, 52.40it/s, Epoch: 23, Batch: 120,Loss: -2.302,Avg.Loss: -1.739,LR: 4.39E-04]Training epoch 23:  78%|███████▊  | 120/153 [00:02<00:00, 52.40it/s, Epoch: 23, Batch: 121,Loss: -1.618,Avg.Loss: -1.738,LR: 4.39E-04]Training epoch 23:  79%|███████▉  | 121/153 [00:02<00:00, 52.40it/s, Epoch: 23, Batch: 122,Loss: -1.488,Avg.Loss: -1.736,LR: 4.39E-04]Training epoch 23:  80%|███████▉  | 122/153 [00:02<00:00, 52.40it/s, Epoch: 23, Batch: 123,Loss: -1.771,Avg.Loss: -1.736,LR: 4.39E-04]Training epoch 23:  80%|████████  | 123/153 [00:02<00:00, 52.40it/s, Epoch: 23, Batch: 124,Loss: -1.665,Avg.Loss: -1.736,LR: 4.39E-04]Training epoch 23:  81%|████████  | 124/153 [00:02<00:00, 52.40it/s, Epoch: 23, Batch: 125,Loss: -1.837,Avg.Loss: -1.737,LR: 4.38E-04]Training epoch 23:  82%|████████▏ | 125/153 [00:02<00:00, 52.40it/s, Epoch: 23, Batch: 126,Loss: -1.982,Avg.Loss: -1.739,LR: 4.38E-04]Training epoch 23:  82%|████████▏ | 126/153 [00:02<00:00, 52.71it/s, Epoch: 23, Batch: 126,Loss: -1.982,Avg.Loss: -1.739,LR: 4.38E-04]Training epoch 23:  82%|████████▏ | 126/153 [00:02<00:00, 52.71it/s, Epoch: 23, Batch: 127,Loss: -1.827,Avg.Loss: -1.739,LR: 4.38E-04]Training epoch 23:  83%|████████▎ | 127/153 [00:02<00:00, 52.71it/s, Epoch: 23, Batch: 128,Loss: -2.083,Avg.Loss: -1.742,LR: 4.38E-04]Training epoch 23:  84%|████████▎ | 128/153 [00:02<00:00, 52.71it/s, Epoch: 23, Batch: 129,Loss: -1.636,Avg.Loss: -1.741,LR: 4.38E-04]Training epoch 23:  84%|████████▍ | 129/153 [00:02<00:00, 52.71it/s, Epoch: 23, Batch: 130,Loss: -0.717,Avg.Loss: -1.733,LR: 4.38E-04]Training epoch 23:  85%|████████▍ | 130/153 [00:02<00:00, 52.71it/s, Epoch: 23, Batch: 131,Loss: -1.273,Avg.Loss: -1.730,LR: 4.38E-04]Training epoch 23:  86%|████████▌ | 131/153 [00:02<00:00, 52.71it/s, Epoch: 23, Batch: 132,Loss: -1.758,Avg.Loss: -1.730,LR: 4.38E-04]Training epoch 23:  86%|████████▋ | 132/153 [00:02<00:00, 52.94it/s, Epoch: 23, Batch: 132,Loss: -1.758,Avg.Loss: -1.730,LR: 4.38E-04]Training epoch 23:  86%|████████▋ | 132/153 [00:02<00:00, 52.94it/s, Epoch: 23, Batch: 133,Loss: -0.863,Avg.Loss: -1.723,LR: 4.38E-04]Training epoch 23:  87%|████████▋ | 133/153 [00:02<00:00, 52.94it/s, Epoch: 23, Batch: 134,Loss: -1.781,Avg.Loss: -1.724,LR: 4.38E-04]Training epoch 23:  88%|████████▊ | 134/153 [00:02<00:00, 52.94it/s, Epoch: 23, Batch: 135,Loss: -1.750,Avg.Loss: -1.724,LR: 4.38E-04]Training epoch 23:  88%|████████▊ | 135/153 [00:02<00:00, 52.94it/s, Epoch: 23, Batch: 136,Loss: -1.346,Avg.Loss: -1.721,LR: 4.38E-04]Training epoch 23:  89%|████████▉ | 136/153 [00:02<00:00, 52.94it/s, Epoch: 23, Batch: 137,Loss: -0.271,Avg.Loss: -1.711,LR: 4.38E-04]Training epoch 23:  90%|████████▉ | 137/153 [00:02<00:00, 52.94it/s, Epoch: 23, Batch: 138,Loss: 0.256,Avg.Loss: -1.696,LR: 4.38E-04] Training epoch 23:  90%|█████████ | 138/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 138,Loss: 0.256,Avg.Loss: -1.696,LR: 4.38E-04]Training epoch 23:  90%|█████████ | 138/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 139,Loss: -1.241,Avg.Loss: -1.693,LR: 4.38E-04]Training epoch 23:  91%|█████████ | 139/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 140,Loss: -1.169,Avg.Loss: -1.689,LR: 4.38E-04]Training epoch 23:  92%|█████████▏| 140/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 141,Loss: -0.360,Avg.Loss: -1.680,LR: 4.38E-04]Training epoch 23:  92%|█████████▏| 141/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 142,Loss: -0.733,Avg.Loss: -1.673,LR: 4.38E-04]Training epoch 23:  93%|█████████▎| 142/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 143,Loss: -2.074,Avg.Loss: -1.676,LR: 4.38E-04]Training epoch 23:  93%|█████████▎| 143/153 [00:02<00:00, 53.12it/s, Epoch: 23, Batch: 144,Loss: -1.834,Avg.Loss: -1.677,LR: 4.38E-04]Training epoch 23:  94%|█████████▍| 144/153 [00:02<00:00, 53.17it/s, Epoch: 23, Batch: 144,Loss: -1.834,Avg.Loss: -1.677,LR: 4.38E-04]Training epoch 23:  94%|█████████▍| 144/153 [00:02<00:00, 53.17it/s, Epoch: 23, Batch: 145,Loss: -1.063,Avg.Loss: -1.673,LR: 4.38E-04]Training epoch 23:  95%|█████████▍| 145/153 [00:02<00:00, 53.17it/s, Epoch: 23, Batch: 146,Loss: -1.248,Avg.Loss: -1.670,LR: 4.38E-04]Training epoch 23:  95%|█████████▌| 146/153 [00:02<00:00, 53.17it/s, Epoch: 23, Batch: 147,Loss: -1.924,Avg.Loss: -1.672,LR: 4.38E-04]Training epoch 23:  96%|█████████▌| 147/153 [00:02<00:00, 53.17it/s, Epoch: 23, Batch: 148,Loss: -1.950,Avg.Loss: -1.674,LR: 4.38E-04]Training epoch 23:  97%|█████████▋| 148/153 [00:02<00:00, 53.17it/s, Epoch: 23, Batch: 149,Loss: -1.223,Avg.Loss: -1.671,LR: 4.38E-04]Training epoch 23:  97%|█████████▋| 149/153 [00:02<00:00, 53.17it/s, Epoch: 23, Batch: 150,Loss: -1.636,Avg.Loss: -1.670,LR: 4.38E-04]Training epoch 23:  98%|█████████▊| 150/153 [00:02<00:00, 53.28it/s, Epoch: 23, Batch: 150,Loss: -1.636,Avg.Loss: -1.670,LR: 4.38E-04]Training epoch 23:  98%|█████████▊| 150/153 [00:02<00:00, 53.28it/s, Epoch: 23, Batch: 151,Loss: -1.934,Avg.Loss: -1.672,LR: 4.38E-04]Training epoch 23:  99%|█████████▊| 151/153 [00:02<00:00, 53.28it/s, Epoch: 23, Batch: 152,Loss: -2.070,Avg.Loss: -1.675,LR: 4.38E-04]Training epoch 23:  99%|█████████▉| 152/153 [00:02<00:00, 53.28it/s, Epoch: 23, Batch: 153,Loss: -1.994,Avg.Loss: -1.677,LR: 4.38E-04]Training epoch 23: 100%|██████████| 153/153 [00:02<00:00, 52.95it/s, Epoch: 23, Batch: 153,Loss: -1.994,Avg.Loss: -1.677,LR: 4.38E-04]
Training epoch 24:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 24:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 24, Batch: 1,Loss: -2.024,Avg.Loss: -2.024,LR: 4.37E-04]Training epoch 24:   1%|          | 1/153 [00:00<00:04, 30.45it/s, Epoch: 24, Batch: 2,Loss: -2.209,Avg.Loss: -2.116,LR: 4.37E-04]Training epoch 24:   1%|▏         | 2/153 [00:00<00:03, 39.51it/s, Epoch: 24, Batch: 3,Loss: -1.756,Avg.Loss: -1.996,LR: 4.37E-04]Training epoch 24:   2%|▏         | 3/153 [00:00<00:03, 46.53it/s, Epoch: 24, Batch: 4,Loss: -2.000,Avg.Loss: -1.997,LR: 4.37E-04]Training epoch 24:   3%|▎         | 4/153 [00:00<00:03, 48.40it/s, Epoch: 24, Batch: 5,Loss: -1.996,Avg.Loss: -1.997,LR: 4.37E-04]Training epoch 24:   3%|▎         | 5/153 [00:00<00:02, 49.95it/s, Epoch: 24, Batch: 6,Loss: -1.997,Avg.Loss: -1.997,LR: 4.37E-04]Training epoch 24:   4%|▍         | 6/153 [00:00<00:02, 59.86it/s, Epoch: 24, Batch: 6,Loss: -1.997,Avg.Loss: -1.997,LR: 4.37E-04]Training epoch 24:   4%|▍         | 6/153 [00:00<00:02, 59.86it/s, Epoch: 24, Batch: 7,Loss: -2.043,Avg.Loss: -2.004,LR: 4.37E-04]Training epoch 24:   5%|▍         | 7/153 [00:00<00:02, 59.86it/s, Epoch: 24, Batch: 8,Loss: -1.655,Avg.Loss: -1.960,LR: 4.37E-04]Training epoch 24:   5%|▌         | 8/153 [00:00<00:02, 59.86it/s, Epoch: 24, Batch: 9,Loss: -1.625,Avg.Loss: -1.923,LR: 4.37E-04]Training epoch 24:   6%|▌         | 9/153 [00:00<00:02, 59.86it/s, Epoch: 24, Batch: 10,Loss: -2.155,Avg.Loss: -1.946,LR: 4.37E-04]Training epoch 24:   7%|▋         | 10/153 [00:00<00:02, 59.86it/s, Epoch: 24, Batch: 11,Loss: -1.812,Avg.Loss: -1.934,LR: 4.37E-04]Training epoch 24:   7%|▋         | 11/153 [00:00<00:02, 59.86it/s, Epoch: 24, Batch: 12,Loss: -1.916,Avg.Loss: -1.932,LR: 4.37E-04]Training epoch 24:   8%|▊         | 12/153 [00:00<00:02, 55.74it/s, Epoch: 24, Batch: 12,Loss: -1.916,Avg.Loss: -1.932,LR: 4.37E-04]Training epoch 24:   8%|▊         | 12/153 [00:00<00:02, 55.74it/s, Epoch: 24, Batch: 13,Loss: -2.244,Avg.Loss: -1.956,LR: 4.37E-04]Training epoch 24:   8%|▊         | 13/153 [00:00<00:02, 55.74it/s, Epoch: 24, Batch: 14,Loss: -1.464,Avg.Loss: -1.921,LR: 4.37E-04]Training epoch 24:   9%|▉         | 14/153 [00:00<00:02, 55.74it/s, Epoch: 24, Batch: 15,Loss: -1.958,Avg.Loss: -1.924,LR: 4.37E-04]Training epoch 24:  10%|▉         | 15/153 [00:00<00:02, 55.74it/s, Epoch: 24, Batch: 16,Loss: -1.653,Avg.Loss: -1.907,LR: 4.37E-04]Training epoch 24:  10%|█         | 16/153 [00:00<00:02, 55.74it/s, Epoch: 24, Batch: 17,Loss: -1.800,Avg.Loss: -1.900,LR: 4.37E-04]Training epoch 24:  11%|█         | 17/153 [00:00<00:02, 55.74it/s, Epoch: 24, Batch: 18,Loss: -1.795,Avg.Loss: -1.895,LR: 4.37E-04]Training epoch 24:  12%|█▏        | 18/153 [00:00<00:02, 53.57it/s, Epoch: 24, Batch: 18,Loss: -1.795,Avg.Loss: -1.895,LR: 4.37E-04]Training epoch 24:  12%|█▏        | 18/153 [00:00<00:02, 53.57it/s, Epoch: 24, Batch: 19,Loss: -1.298,Avg.Loss: -1.863,LR: 4.37E-04]Training epoch 24:  12%|█▏        | 19/153 [00:00<00:02, 53.57it/s, Epoch: 24, Batch: 20,Loss: -1.887,Avg.Loss: -1.864,LR: 4.37E-04]Training epoch 24:  13%|█▎        | 20/153 [00:00<00:02, 53.57it/s, Epoch: 24, Batch: 21,Loss: -2.001,Avg.Loss: -1.871,LR: 4.37E-04]Training epoch 24:  14%|█▎        | 21/153 [00:00<00:02, 53.57it/s, Epoch: 24, Batch: 22,Loss: -2.236,Avg.Loss: -1.887,LR: 4.37E-04]Training epoch 24:  14%|█▍        | 22/153 [00:00<00:02, 53.57it/s, Epoch: 24, Batch: 23,Loss: -0.582,Avg.Loss: -1.831,LR: 4.37E-04]Training epoch 24:  15%|█▌        | 23/153 [00:00<00:02, 53.57it/s, Epoch: 24, Batch: 24,Loss: 1.557,Avg.Loss: -1.690,LR: 4.37E-04] Training epoch 24:  16%|█▌        | 24/153 [00:00<00:02, 51.85it/s, Epoch: 24, Batch: 24,Loss: 1.557,Avg.Loss: -1.690,LR: 4.37E-04]Training epoch 24:  16%|█▌        | 24/153 [00:00<00:02, 51.85it/s, Epoch: 24, Batch: 25,Loss: 0.084,Avg.Loss: -1.619,LR: 4.37E-04]Training epoch 24:  16%|█▋        | 25/153 [00:00<00:02, 51.85it/s, Epoch: 24, Batch: 26,Loss: -1.013,Avg.Loss: -1.595,LR: 4.37E-04]Training epoch 24:  17%|█▋        | 26/153 [00:00<00:02, 51.85it/s, Epoch: 24, Batch: 27,Loss: -0.567,Avg.Loss: -1.557,LR: 4.37E-04]Training epoch 24:  18%|█▊        | 27/153 [00:00<00:02, 51.85it/s, Epoch: 24, Batch: 28,Loss: 0.332,Avg.Loss: -1.490,LR: 4.37E-04] Training epoch 24:  18%|█▊        | 28/153 [00:00<00:02, 51.85it/s, Epoch: 24, Batch: 29,Loss: -0.493,Avg.Loss: -1.455,LR: 4.37E-04]Training epoch 24:  19%|█▉        | 29/153 [00:00<00:02, 51.85it/s, Epoch: 24, Batch: 30,Loss: -1.352,Avg.Loss: -1.452,LR: 4.37E-04]Training epoch 24:  20%|█▉        | 30/153 [00:00<00:02, 52.02it/s, Epoch: 24, Batch: 30,Loss: -1.352,Avg.Loss: -1.452,LR: 4.37E-04]Training epoch 24:  20%|█▉        | 30/153 [00:00<00:02, 52.02it/s, Epoch: 24, Batch: 31,Loss: -1.818,Avg.Loss: -1.464,LR: 4.36E-04]Training epoch 24:  20%|██        | 31/153 [00:00<00:02, 52.02it/s, Epoch: 24, Batch: 32,Loss: -1.076,Avg.Loss: -1.452,LR: 4.36E-04]Training epoch 24:  21%|██        | 32/153 [00:00<00:02, 52.02it/s, Epoch: 24, Batch: 33,Loss: -1.214,Avg.Loss: -1.444,LR: 4.36E-04]Training epoch 24:  22%|██▏       | 33/153 [00:00<00:02, 52.02it/s, Epoch: 24, Batch: 34,Loss: -1.787,Avg.Loss: -1.454,LR: 4.36E-04]Training epoch 24:  22%|██▏       | 34/153 [00:00<00:02, 52.02it/s, Epoch: 24, Batch: 35,Loss: -1.451,Avg.Loss: -1.454,LR: 4.36E-04]Training epoch 24:  23%|██▎       | 35/153 [00:00<00:02, 52.02it/s, Epoch: 24, Batch: 36,Loss: -0.774,Avg.Loss: -1.435,LR: 4.36E-04]Training epoch 24:  24%|██▎       | 36/153 [00:00<00:02, 52.55it/s, Epoch: 24, Batch: 36,Loss: -0.774,Avg.Loss: -1.435,LR: 4.36E-04]Training epoch 24:  24%|██▎       | 36/153 [00:00<00:02, 52.55it/s, Epoch: 24, Batch: 37,Loss: -0.248,Avg.Loss: -1.403,LR: 4.36E-04]Training epoch 24:  24%|██▍       | 37/153 [00:00<00:02, 52.55it/s, Epoch: 24, Batch: 38,Loss: -0.892,Avg.Loss: -1.390,LR: 4.36E-04]Training epoch 24:  25%|██▍       | 38/153 [00:00<00:02, 52.55it/s, Epoch: 24, Batch: 39,Loss: -1.166,Avg.Loss: -1.384,LR: 4.36E-04]Training epoch 24:  25%|██▌       | 39/153 [00:00<00:02, 52.55it/s, Epoch: 24, Batch: 40,Loss: -1.647,Avg.Loss: -1.391,LR: 4.36E-04]Training epoch 24:  26%|██▌       | 40/153 [00:00<00:02, 52.55it/s, Epoch: 24, Batch: 41,Loss: -1.776,Avg.Loss: -1.400,LR: 4.36E-04]Training epoch 24:  27%|██▋       | 41/153 [00:00<00:02, 52.55it/s, Epoch: 24, Batch: 42,Loss: -1.945,Avg.Loss: -1.413,LR: 4.36E-04]Training epoch 24:  27%|██▋       | 42/153 [00:00<00:02, 52.59it/s, Epoch: 24, Batch: 42,Loss: -1.945,Avg.Loss: -1.413,LR: 4.36E-04]Training epoch 24:  27%|██▋       | 42/153 [00:00<00:02, 52.59it/s, Epoch: 24, Batch: 43,Loss: -2.277,Avg.Loss: -1.433,LR: 4.36E-04]Training epoch 24:  28%|██▊       | 43/153 [00:00<00:02, 52.59it/s, Epoch: 24, Batch: 44,Loss: -2.206,Avg.Loss: -1.451,LR: 4.36E-04]Training epoch 24:  29%|██▉       | 44/153 [00:00<00:02, 52.59it/s, Epoch: 24, Batch: 45,Loss: -2.215,Avg.Loss: -1.468,LR: 4.36E-04]Training epoch 24:  29%|██▉       | 45/153 [00:00<00:02, 52.59it/s, Epoch: 24, Batch: 46,Loss: -1.654,Avg.Loss: -1.472,LR: 4.36E-04]Training epoch 24:  30%|███       | 46/153 [00:00<00:02, 52.59it/s, Epoch: 24, Batch: 47,Loss: -1.567,Avg.Loss: -1.474,LR: 4.36E-04]Training epoch 24:  31%|███       | 47/153 [00:00<00:02, 52.59it/s, Epoch: 24, Batch: 48,Loss: -1.947,Avg.Loss: -1.484,LR: 4.36E-04]Training epoch 24:  31%|███▏      | 48/153 [00:00<00:01, 52.77it/s, Epoch: 24, Batch: 48,Loss: -1.947,Avg.Loss: -1.484,LR: 4.36E-04]Training epoch 24:  31%|███▏      | 48/153 [00:00<00:01, 52.77it/s, Epoch: 24, Batch: 49,Loss: -1.949,Avg.Loss: -1.493,LR: 4.36E-04]Training epoch 24:  32%|███▏      | 49/153 [00:00<00:01, 52.77it/s, Epoch: 24, Batch: 50,Loss: -1.901,Avg.Loss: -1.501,LR: 4.36E-04]Training epoch 24:  33%|███▎      | 50/153 [00:00<00:01, 52.77it/s, Epoch: 24, Batch: 51,Loss: -2.126,Avg.Loss: -1.514,LR: 4.36E-04]Training epoch 24:  33%|███▎      | 51/153 [00:00<00:01, 52.77it/s, Epoch: 24, Batch: 52,Loss: -1.443,Avg.Loss: -1.512,LR: 4.36E-04]Training epoch 24:  34%|███▍      | 52/153 [00:00<00:01, 52.77it/s, Epoch: 24, Batch: 53,Loss: -1.911,Avg.Loss: -1.520,LR: 4.36E-04]Training epoch 24:  35%|███▍      | 53/153 [00:01<00:01, 52.77it/s, Epoch: 24, Batch: 54,Loss: -1.686,Avg.Loss: -1.523,LR: 4.36E-04]Training epoch 24:  35%|███▌      | 54/153 [00:01<00:01, 52.87it/s, Epoch: 24, Batch: 54,Loss: -1.686,Avg.Loss: -1.523,LR: 4.36E-04]Training epoch 24:  35%|███▌      | 54/153 [00:01<00:01, 52.87it/s, Epoch: 24, Batch: 55,Loss: -1.056,Avg.Loss: -1.514,LR: 4.36E-04]Training epoch 24:  36%|███▌      | 55/153 [00:01<00:01, 52.87it/s, Epoch: 24, Batch: 56,Loss: -0.801,Avg.Loss: -1.502,LR: 4.36E-04]Training epoch 24:  37%|███▋      | 56/153 [00:01<00:01, 52.87it/s, Epoch: 24, Batch: 57,Loss: -1.456,Avg.Loss: -1.501,LR: 4.36E-04]Training epoch 24:  37%|███▋      | 57/153 [00:01<00:01, 52.87it/s, Epoch: 24, Batch: 58,Loss: -1.633,Avg.Loss: -1.503,LR: 4.36E-04]Training epoch 24:  38%|███▊      | 58/153 [00:01<00:01, 52.87it/s, Epoch: 24, Batch: 59,Loss: -1.145,Avg.Loss: -1.497,LR: 4.36E-04]Training epoch 24:  39%|███▊      | 59/153 [00:01<00:01, 52.87it/s, Epoch: 24, Batch: 60,Loss: -1.702,Avg.Loss: -1.500,LR: 4.35E-04]Training epoch 24:  39%|███▉      | 60/153 [00:01<00:01, 53.03it/s, Epoch: 24, Batch: 60,Loss: -1.702,Avg.Loss: -1.500,LR: 4.35E-04]Training epoch 24:  39%|███▉      | 60/153 [00:01<00:01, 53.03it/s, Epoch: 24, Batch: 61,Loss: -1.888,Avg.Loss: -1.507,LR: 4.35E-04]Training epoch 24:  40%|███▉      | 61/153 [00:01<00:01, 53.03it/s, Epoch: 24, Batch: 62,Loss: -2.069,Avg.Loss: -1.516,LR: 4.35E-04]Training epoch 24:  41%|████      | 62/153 [00:01<00:01, 53.03it/s, Epoch: 24, Batch: 63,Loss: -2.288,Avg.Loss: -1.528,LR: 4.35E-04]Training epoch 24:  41%|████      | 63/153 [00:01<00:01, 53.03it/s, Epoch: 24, Batch: 64,Loss: -2.120,Avg.Loss: -1.537,LR: 4.35E-04]Training epoch 24:  42%|████▏     | 64/153 [00:01<00:01, 53.03it/s, Epoch: 24, Batch: 65,Loss: -1.912,Avg.Loss: -1.543,LR: 4.35E-04]Training epoch 24:  42%|████▏     | 65/153 [00:01<00:01, 53.03it/s, Epoch: 24, Batch: 66,Loss: -2.412,Avg.Loss: -1.556,LR: 4.35E-04]Training epoch 24:  43%|████▎     | 66/153 [00:01<00:01, 53.17it/s, Epoch: 24, Batch: 66,Loss: -2.412,Avg.Loss: -1.556,LR: 4.35E-04]Training epoch 24:  43%|████▎     | 66/153 [00:01<00:01, 53.17it/s, Epoch: 24, Batch: 67,Loss: -1.721,Avg.Loss: -1.559,LR: 4.35E-04]Training epoch 24:  44%|████▍     | 67/153 [00:01<00:01, 53.17it/s, Epoch: 24, Batch: 68,Loss: -1.597,Avg.Loss: -1.559,LR: 4.35E-04]Training epoch 24:  44%|████▍     | 68/153 [00:01<00:01, 53.17it/s, Epoch: 24, Batch: 69,Loss: -2.193,Avg.Loss: -1.568,LR: 4.35E-04]Training epoch 24:  45%|████▌     | 69/153 [00:01<00:01, 53.17it/s, Epoch: 24, Batch: 70,Loss: -1.262,Avg.Loss: -1.564,LR: 4.35E-04]Training epoch 24:  46%|████▌     | 70/153 [00:01<00:01, 53.17it/s, Epoch: 24, Batch: 71,Loss: 0.193,Avg.Loss: -1.539,LR: 4.35E-04] Training epoch 24:  46%|████▋     | 71/153 [00:01<00:01, 53.17it/s, Epoch: 24, Batch: 72,Loss: -0.297,Avg.Loss: -1.522,LR: 4.35E-04]Training epoch 24:  47%|████▋     | 72/153 [00:01<00:01, 52.83it/s, Epoch: 24, Batch: 72,Loss: -0.297,Avg.Loss: -1.522,LR: 4.35E-04]Training epoch 24:  47%|████▋     | 72/153 [00:01<00:01, 52.83it/s, Epoch: 24, Batch: 73,Loss: -1.922,Avg.Loss: -1.528,LR: 4.35E-04]Training epoch 24:  48%|████▊     | 73/153 [00:01<00:01, 52.83it/s, Epoch: 24, Batch: 74,Loss: -1.157,Avg.Loss: -1.523,LR: 4.35E-04]Training epoch 24:  48%|████▊     | 74/153 [00:01<00:01, 52.83it/s, Epoch: 24, Batch: 75,Loss: -1.082,Avg.Loss: -1.517,LR: 4.35E-04]Training epoch 24:  49%|████▉     | 75/153 [00:01<00:01, 52.83it/s, Epoch: 24, Batch: 76,Loss: 0.710,Avg.Loss: -1.487,LR: 4.35E-04] Training epoch 24:  50%|████▉     | 76/153 [00:01<00:01, 52.83it/s, Epoch: 24, Batch: 77,Loss: -1.160,Avg.Loss: -1.483,LR: 4.35E-04]Training epoch 24:  50%|█████     | 77/153 [00:01<00:01, 52.83it/s, Epoch: 24, Batch: 78,Loss: -1.161,Avg.Loss: -1.479,LR: 4.35E-04]Training epoch 24:  51%|█████     | 78/153 [00:01<00:01, 52.98it/s, Epoch: 24, Batch: 78,Loss: -1.161,Avg.Loss: -1.479,LR: 4.35E-04]Training epoch 24:  51%|█████     | 78/153 [00:01<00:01, 52.98it/s, Epoch: 24, Batch: 79,Loss: -1.443,Avg.Loss: -1.479,LR: 4.35E-04]Training epoch 24:  52%|█████▏    | 79/153 [00:01<00:01, 52.98it/s, Epoch: 24, Batch: 80,Loss: -2.293,Avg.Loss: -1.489,LR: 4.35E-04]Training epoch 24:  52%|█████▏    | 80/153 [00:01<00:01, 52.98it/s, Epoch: 24, Batch: 81,Loss: -1.633,Avg.Loss: -1.491,LR: 4.35E-04]Training epoch 24:  53%|█████▎    | 81/153 [00:01<00:01, 52.98it/s, Epoch: 24, Batch: 82,Loss: -0.626,Avg.Loss: -1.480,LR: 4.35E-04]Training epoch 24:  54%|█████▎    | 82/153 [00:01<00:01, 52.98it/s, Epoch: 24, Batch: 83,Loss: -0.624,Avg.Loss: -1.470,LR: 4.35E-04]Training epoch 24:  54%|█████▍    | 83/153 [00:01<00:01, 52.98it/s, Epoch: 24, Batch: 84,Loss: -1.446,Avg.Loss: -1.469,LR: 4.35E-04]Training epoch 24:  55%|█████▍    | 84/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 84,Loss: -1.446,Avg.Loss: -1.469,LR: 4.35E-04]Training epoch 24:  55%|█████▍    | 84/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 85,Loss: -1.680,Avg.Loss: -1.472,LR: 4.35E-04]Training epoch 24:  56%|█████▌    | 85/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 86,Loss: -2.210,Avg.Loss: -1.480,LR: 4.35E-04]Training epoch 24:  56%|█████▌    | 86/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 87,Loss: -1.864,Avg.Loss: -1.485,LR: 4.35E-04]Training epoch 24:  57%|█████▋    | 87/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 88,Loss: -1.796,Avg.Loss: -1.488,LR: 4.35E-04]Training epoch 24:  58%|█████▊    | 88/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 89,Loss: -1.684,Avg.Loss: -1.491,LR: 4.34E-04]Training epoch 24:  58%|█████▊    | 89/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 90,Loss: -1.628,Avg.Loss: -1.492,LR: 4.34E-04]Training epoch 24:  59%|█████▉    | 90/153 [00:01<00:01, 52.84it/s, Epoch: 24, Batch: 90,Loss: -1.628,Avg.Loss: -1.492,LR: 4.34E-04]Training epoch 24:  59%|█████▉    | 90/153 [00:01<00:01, 52.84it/s, Epoch: 24, Batch: 91,Loss: -1.402,Avg.Loss: -1.491,LR: 4.34E-04]Training epoch 24:  59%|█████▉    | 91/153 [00:01<00:01, 52.84it/s, Epoch: 24, Batch: 92,Loss: -1.939,Avg.Loss: -1.496,LR: 4.34E-04]Training epoch 24:  60%|██████    | 92/153 [00:01<00:01, 52.84it/s, Epoch: 24, Batch: 93,Loss: -2.109,Avg.Loss: -1.503,LR: 4.34E-04]Training epoch 24:  61%|██████    | 93/153 [00:01<00:01, 52.84it/s, Epoch: 24, Batch: 94,Loss: -1.698,Avg.Loss: -1.505,LR: 4.34E-04]Training epoch 24:  61%|██████▏   | 94/153 [00:01<00:01, 52.84it/s, Epoch: 24, Batch: 95,Loss: -1.824,Avg.Loss: -1.508,LR: 4.34E-04]Training epoch 24:  62%|██████▏   | 95/153 [00:01<00:01, 52.84it/s, Epoch: 24, Batch: 96,Loss: -1.466,Avg.Loss: -1.508,LR: 4.34E-04]Training epoch 24:  63%|██████▎   | 96/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 96,Loss: -1.466,Avg.Loss: -1.508,LR: 4.34E-04]Training epoch 24:  63%|██████▎   | 96/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 97,Loss: -1.329,Avg.Loss: -1.506,LR: 4.34E-04]Training epoch 24:  63%|██████▎   | 97/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 98,Loss: -1.717,Avg.Loss: -1.508,LR: 4.34E-04]Training epoch 24:  64%|██████▍   | 98/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 99,Loss: -2.146,Avg.Loss: -1.514,LR: 4.34E-04]Training epoch 24:  65%|██████▍   | 99/153 [00:01<00:01, 53.04it/s, Epoch: 24, Batch: 100,Loss: -2.080,Avg.Loss: -1.520,LR: 4.34E-04]Training epoch 24:  65%|██████▌   | 100/153 [00:01<00:00, 53.04it/s, Epoch: 24, Batch: 101,Loss: -1.872,Avg.Loss: -1.523,LR: 4.34E-04]Training epoch 24:  66%|██████▌   | 101/153 [00:01<00:00, 53.04it/s, Epoch: 24, Batch: 102,Loss: -1.972,Avg.Loss: -1.528,LR: 4.34E-04]Training epoch 24:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 24, Batch: 102,Loss: -1.972,Avg.Loss: -1.528,LR: 4.34E-04]Training epoch 24:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 24, Batch: 103,Loss: -1.909,Avg.Loss: -1.532,LR: 4.34E-04]Training epoch 24:  67%|██████▋   | 103/153 [00:01<00:00, 53.09it/s, Epoch: 24, Batch: 104,Loss: -2.045,Avg.Loss: -1.537,LR: 4.34E-04]Training epoch 24:  68%|██████▊   | 104/153 [00:01<00:00, 53.09it/s, Epoch: 24, Batch: 105,Loss: -2.221,Avg.Loss: -1.543,LR: 4.34E-04]Training epoch 24:  69%|██████▊   | 105/153 [00:01<00:00, 53.09it/s, Epoch: 24, Batch: 106,Loss: -2.188,Avg.Loss: -1.549,LR: 4.34E-04]Training epoch 24:  69%|██████▉   | 106/153 [00:02<00:00, 53.09it/s, Epoch: 24, Batch: 107,Loss: -2.172,Avg.Loss: -1.555,LR: 4.34E-04]Training epoch 24:  70%|██████▉   | 107/153 [00:02<00:00, 53.09it/s, Epoch: 24, Batch: 108,Loss: -1.727,Avg.Loss: -1.557,LR: 4.34E-04]Training epoch 24:  71%|███████   | 108/153 [00:02<00:00, 52.96it/s, Epoch: 24, Batch: 108,Loss: -1.727,Avg.Loss: -1.557,LR: 4.34E-04]Training epoch 24:  71%|███████   | 108/153 [00:02<00:00, 52.96it/s, Epoch: 24, Batch: 109,Loss: -1.951,Avg.Loss: -1.560,LR: 4.34E-04]Training epoch 24:  71%|███████   | 109/153 [00:02<00:00, 52.96it/s, Epoch: 24, Batch: 110,Loss: -2.094,Avg.Loss: -1.565,LR: 4.34E-04]Training epoch 24:  72%|███████▏  | 110/153 [00:02<00:00, 52.96it/s, Epoch: 24, Batch: 111,Loss: -2.195,Avg.Loss: -1.571,LR: 4.34E-04]Training epoch 24:  73%|███████▎  | 111/153 [00:02<00:00, 52.96it/s, Epoch: 24, Batch: 112,Loss: -1.547,Avg.Loss: -1.570,LR: 4.34E-04]Training epoch 24:  73%|███████▎  | 112/153 [00:02<00:00, 52.96it/s, Epoch: 24, Batch: 113,Loss: -2.134,Avg.Loss: -1.575,LR: 4.34E-04]Training epoch 24:  74%|███████▍  | 113/153 [00:02<00:00, 52.96it/s, Epoch: 24, Batch: 114,Loss: -1.952,Avg.Loss: -1.579,LR: 4.34E-04]Training epoch 24:  75%|███████▍  | 114/153 [00:02<00:00, 52.92it/s, Epoch: 24, Batch: 114,Loss: -1.952,Avg.Loss: -1.579,LR: 4.34E-04]Training epoch 24:  75%|███████▍  | 114/153 [00:02<00:00, 52.92it/s, Epoch: 24, Batch: 115,Loss: -2.079,Avg.Loss: -1.583,LR: 4.34E-04]Training epoch 24:  75%|███████▌  | 115/153 [00:02<00:00, 52.92it/s, Epoch: 24, Batch: 116,Loss: -2.050,Avg.Loss: -1.587,LR: 4.34E-04]Training epoch 24:  76%|███████▌  | 116/153 [00:02<00:00, 52.92it/s, Epoch: 24, Batch: 117,Loss: -2.226,Avg.Loss: -1.593,LR: 4.34E-04]Training epoch 24:  76%|███████▋  | 117/153 [00:02<00:00, 52.92it/s, Epoch: 24, Batch: 118,Loss: -1.847,Avg.Loss: -1.595,LR: 4.33E-04]Training epoch 24:  77%|███████▋  | 118/153 [00:02<00:00, 52.92it/s, Epoch: 24, Batch: 119,Loss: -1.896,Avg.Loss: -1.597,LR: 4.33E-04]Training epoch 24:  78%|███████▊  | 119/153 [00:02<00:00, 52.92it/s, Epoch: 24, Batch: 120,Loss: -2.088,Avg.Loss: -1.601,LR: 4.33E-04]Training epoch 24:  78%|███████▊  | 120/153 [00:02<00:00, 52.90it/s, Epoch: 24, Batch: 120,Loss: -2.088,Avg.Loss: -1.601,LR: 4.33E-04]Training epoch 24:  78%|███████▊  | 120/153 [00:02<00:00, 52.90it/s, Epoch: 24, Batch: 121,Loss: -1.837,Avg.Loss: -1.603,LR: 4.33E-04]Training epoch 24:  79%|███████▉  | 121/153 [00:02<00:00, 52.90it/s, Epoch: 24, Batch: 122,Loss: -1.907,Avg.Loss: -1.606,LR: 4.33E-04]Training epoch 24:  80%|███████▉  | 122/153 [00:02<00:00, 52.90it/s, Epoch: 24, Batch: 123,Loss: -1.645,Avg.Loss: -1.606,LR: 4.33E-04]Training epoch 24:  80%|████████  | 123/153 [00:02<00:00, 52.90it/s, Epoch: 24, Batch: 124,Loss: -1.520,Avg.Loss: -1.605,LR: 4.33E-04]Training epoch 24:  81%|████████  | 124/153 [00:02<00:00, 52.90it/s, Epoch: 24, Batch: 125,Loss: -2.048,Avg.Loss: -1.609,LR: 4.33E-04]Training epoch 24:  82%|████████▏ | 125/153 [00:02<00:00, 52.90it/s, Epoch: 24, Batch: 126,Loss: -1.830,Avg.Loss: -1.611,LR: 4.33E-04]Training epoch 24:  82%|████████▏ | 126/153 [00:02<00:00, 53.02it/s, Epoch: 24, Batch: 126,Loss: -1.830,Avg.Loss: -1.611,LR: 4.33E-04]Training epoch 24:  82%|████████▏ | 126/153 [00:02<00:00, 53.02it/s, Epoch: 24, Batch: 127,Loss: -0.805,Avg.Loss: -1.604,LR: 4.33E-04]Training epoch 24:  83%|████████▎ | 127/153 [00:02<00:00, 53.02it/s, Epoch: 24, Batch: 128,Loss: -1.609,Avg.Loss: -1.604,LR: 4.33E-04]Training epoch 24:  84%|████████▎ | 128/153 [00:02<00:00, 53.02it/s, Epoch: 24, Batch: 129,Loss: -1.854,Avg.Loss: -1.606,LR: 4.33E-04]Training epoch 24:  84%|████████▍ | 129/153 [00:02<00:00, 53.02it/s, Epoch: 24, Batch: 130,Loss: -1.310,Avg.Loss: -1.604,LR: 4.33E-04]Training epoch 24:  85%|████████▍ | 130/153 [00:02<00:00, 53.02it/s, Epoch: 24, Batch: 131,Loss: -2.337,Avg.Loss: -1.610,LR: 4.33E-04]Training epoch 24:  86%|████████▌ | 131/153 [00:02<00:00, 53.02it/s, Epoch: 24, Batch: 132,Loss: -0.907,Avg.Loss: -1.604,LR: 4.33E-04]Training epoch 24:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 24, Batch: 132,Loss: -0.907,Avg.Loss: -1.604,LR: 4.33E-04]Training epoch 24:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 24, Batch: 133,Loss: -0.696,Avg.Loss: -1.597,LR: 4.33E-04]Training epoch 24:  87%|████████▋ | 133/153 [00:02<00:00, 53.28it/s, Epoch: 24, Batch: 134,Loss: -1.368,Avg.Loss: -1.596,LR: 4.33E-04]Training epoch 24:  88%|████████▊ | 134/153 [00:02<00:00, 53.28it/s, Epoch: 24, Batch: 135,Loss: -2.109,Avg.Loss: -1.600,LR: 4.33E-04]Training epoch 24:  88%|████████▊ | 135/153 [00:02<00:00, 53.28it/s, Epoch: 24, Batch: 136,Loss: -1.836,Avg.Loss: -1.601,LR: 4.33E-04]Training epoch 24:  89%|████████▉ | 136/153 [00:02<00:00, 53.28it/s, Epoch: 24, Batch: 137,Loss: -1.718,Avg.Loss: -1.602,LR: 4.33E-04]Training epoch 24:  90%|████████▉ | 137/153 [00:02<00:00, 53.28it/s, Epoch: 24, Batch: 138,Loss: -2.180,Avg.Loss: -1.606,LR: 4.33E-04]Training epoch 24:  90%|█████████ | 138/153 [00:02<00:00, 53.14it/s, Epoch: 24, Batch: 138,Loss: -2.180,Avg.Loss: -1.606,LR: 4.33E-04]Training epoch 24:  90%|█████████ | 138/153 [00:02<00:00, 53.14it/s, Epoch: 24, Batch: 139,Loss: -1.051,Avg.Loss: -1.602,LR: 4.33E-04]Training epoch 24:  91%|█████████ | 139/153 [00:02<00:00, 53.14it/s, Epoch: 24, Batch: 140,Loss: -0.706,Avg.Loss: -1.596,LR: 4.33E-04]Training epoch 24:  92%|█████████▏| 140/153 [00:02<00:00, 53.14it/s, Epoch: 24, Batch: 141,Loss: -1.486,Avg.Loss: -1.595,LR: 4.33E-04]Training epoch 24:  92%|█████████▏| 141/153 [00:02<00:00, 53.14it/s, Epoch: 24, Batch: 142,Loss: -2.464,Avg.Loss: -1.601,LR: 4.33E-04]Training epoch 24:  93%|█████████▎| 142/153 [00:02<00:00, 53.14it/s, Epoch: 24, Batch: 143,Loss: -2.110,Avg.Loss: -1.605,LR: 4.33E-04]Training epoch 24:  93%|█████████▎| 143/153 [00:02<00:00, 53.14it/s, Epoch: 24, Batch: 144,Loss: -1.466,Avg.Loss: -1.604,LR: 4.33E-04]Training epoch 24:  94%|█████████▍| 144/153 [00:02<00:00, 53.26it/s, Epoch: 24, Batch: 144,Loss: -1.466,Avg.Loss: -1.604,LR: 4.33E-04]Training epoch 24:  94%|█████████▍| 144/153 [00:02<00:00, 53.26it/s, Epoch: 24, Batch: 145,Loss: -1.750,Avg.Loss: -1.605,LR: 4.33E-04]Training epoch 24:  95%|█████████▍| 145/153 [00:02<00:00, 53.26it/s, Epoch: 24, Batch: 146,Loss: -1.732,Avg.Loss: -1.606,LR: 4.32E-04]Training epoch 24:  95%|█████████▌| 146/153 [00:02<00:00, 53.26it/s, Epoch: 24, Batch: 147,Loss: -2.117,Avg.Loss: -1.609,LR: 4.32E-04]Training epoch 24:  96%|█████████▌| 147/153 [00:02<00:00, 53.26it/s, Epoch: 24, Batch: 148,Loss: -1.783,Avg.Loss: -1.610,LR: 4.32E-04]Training epoch 24:  97%|█████████▋| 148/153 [00:02<00:00, 53.26it/s, Epoch: 24, Batch: 149,Loss: -0.926,Avg.Loss: -1.606,LR: 4.32E-04]Training epoch 24:  97%|█████████▋| 149/153 [00:02<00:00, 53.26it/s, Epoch: 24, Batch: 150,Loss: -1.632,Avg.Loss: -1.606,LR: 4.32E-04]Training epoch 24:  98%|█████████▊| 150/153 [00:02<00:00, 53.23it/s, Epoch: 24, Batch: 150,Loss: -1.632,Avg.Loss: -1.606,LR: 4.32E-04]Training epoch 24:  98%|█████████▊| 150/153 [00:02<00:00, 53.23it/s, Epoch: 24, Batch: 151,Loss: -1.389,Avg.Loss: -1.605,LR: 4.32E-04]Training epoch 24:  99%|█████████▊| 151/153 [00:02<00:00, 53.23it/s, Epoch: 24, Batch: 152,Loss: -1.973,Avg.Loss: -1.607,LR: 4.32E-04]Training epoch 24:  99%|█████████▉| 152/153 [00:02<00:00, 53.23it/s, Epoch: 24, Batch: 153,Loss: -2.010,Avg.Loss: -1.610,LR: 4.32E-04]Training epoch 24: 100%|██████████| 153/153 [00:02<00:00, 53.01it/s, Epoch: 24, Batch: 153,Loss: -2.010,Avg.Loss: -1.610,LR: 4.32E-04]
Training epoch 25:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 25:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 25, Batch: 1,Loss: -1.653,Avg.Loss: -1.653,LR: 4.32E-04]Training epoch 25:   1%|          | 1/153 [00:00<00:06, 24.39it/s, Epoch: 25, Batch: 2,Loss: -2.276,Avg.Loss: -1.964,LR: 4.32E-04]Training epoch 25:   1%|▏         | 2/153 [00:00<00:04, 36.96it/s, Epoch: 25, Batch: 3,Loss: -1.655,Avg.Loss: -1.861,LR: 4.32E-04]Training epoch 25:   2%|▏         | 3/153 [00:00<00:03, 44.08it/s, Epoch: 25, Batch: 4,Loss: -1.792,Avg.Loss: -1.844,LR: 4.32E-04]Training epoch 25:   3%|▎         | 4/153 [00:00<00:03, 47.09it/s, Epoch: 25, Batch: 5,Loss: -1.996,Avg.Loss: -1.875,LR: 4.32E-04]Training epoch 25:   3%|▎         | 5/153 [00:00<00:03, 48.80it/s, Epoch: 25, Batch: 6,Loss: -2.015,Avg.Loss: -1.898,LR: 4.32E-04]Training epoch 25:   4%|▍         | 6/153 [00:00<00:02, 58.45it/s, Epoch: 25, Batch: 6,Loss: -2.015,Avg.Loss: -1.898,LR: 4.32E-04]Training epoch 25:   4%|▍         | 6/153 [00:00<00:02, 58.45it/s, Epoch: 25, Batch: 7,Loss: -0.948,Avg.Loss: -1.762,LR: 4.32E-04]Training epoch 25:   5%|▍         | 7/153 [00:00<00:02, 58.45it/s, Epoch: 25, Batch: 8,Loss: -1.065,Avg.Loss: -1.675,LR: 4.32E-04]Training epoch 25:   5%|▌         | 8/153 [00:00<00:02, 58.45it/s, Epoch: 25, Batch: 9,Loss: -1.494,Avg.Loss: -1.655,LR: 4.32E-04]Training epoch 25:   6%|▌         | 9/153 [00:00<00:02, 58.45it/s, Epoch: 25, Batch: 10,Loss: -1.415,Avg.Loss: -1.631,LR: 4.32E-04]Training epoch 25:   7%|▋         | 10/153 [00:00<00:02, 58.45it/s, Epoch: 25, Batch: 11,Loss: -1.320,Avg.Loss: -1.603,LR: 4.32E-04]Training epoch 25:   7%|▋         | 11/153 [00:00<00:02, 58.45it/s, Epoch: 25, Batch: 12,Loss: -0.653,Avg.Loss: -1.524,LR: 4.32E-04]Training epoch 25:   8%|▊         | 12/153 [00:00<00:02, 55.24it/s, Epoch: 25, Batch: 12,Loss: -0.653,Avg.Loss: -1.524,LR: 4.32E-04]Training epoch 25:   8%|▊         | 12/153 [00:00<00:02, 55.24it/s, Epoch: 25, Batch: 13,Loss: -0.634,Avg.Loss: -1.455,LR: 4.32E-04]Training epoch 25:   8%|▊         | 13/153 [00:00<00:02, 55.24it/s, Epoch: 25, Batch: 14,Loss: -1.563,Avg.Loss: -1.463,LR: 4.32E-04]Training epoch 25:   9%|▉         | 14/153 [00:00<00:02, 55.24it/s, Epoch: 25, Batch: 15,Loss: -1.891,Avg.Loss: -1.491,LR: 4.32E-04]Training epoch 25:  10%|▉         | 15/153 [00:00<00:02, 55.24it/s, Epoch: 25, Batch: 16,Loss: -1.684,Avg.Loss: -1.504,LR: 4.32E-04]Training epoch 25:  10%|█         | 16/153 [00:00<00:02, 55.24it/s, Epoch: 25, Batch: 17,Loss: -1.419,Avg.Loss: -1.499,LR: 4.32E-04]Training epoch 25:  11%|█         | 17/153 [00:00<00:02, 55.24it/s, Epoch: 25, Batch: 18,Loss: -1.676,Avg.Loss: -1.508,LR: 4.32E-04]Training epoch 25:  12%|█▏        | 18/153 [00:00<00:02, 54.02it/s, Epoch: 25, Batch: 18,Loss: -1.676,Avg.Loss: -1.508,LR: 4.32E-04]Training epoch 25:  12%|█▏        | 18/153 [00:00<00:02, 54.02it/s, Epoch: 25, Batch: 19,Loss: -1.946,Avg.Loss: -1.531,LR: 4.32E-04]Training epoch 25:  12%|█▏        | 19/153 [00:00<00:02, 54.02it/s, Epoch: 25, Batch: 20,Loss: -1.552,Avg.Loss: -1.532,LR: 4.32E-04]Training epoch 25:  13%|█▎        | 20/153 [00:00<00:02, 54.02it/s, Epoch: 25, Batch: 21,Loss: -1.214,Avg.Loss: -1.517,LR: 4.32E-04]Training epoch 25:  14%|█▎        | 21/153 [00:00<00:02, 54.02it/s, Epoch: 25, Batch: 22,Loss: -1.480,Avg.Loss: -1.516,LR: 4.31E-04]Training epoch 25:  14%|█▍        | 22/153 [00:00<00:02, 54.02it/s, Epoch: 25, Batch: 23,Loss: -1.837,Avg.Loss: -1.530,LR: 4.31E-04]Training epoch 25:  15%|█▌        | 23/153 [00:00<00:02, 54.02it/s, Epoch: 25, Batch: 24,Loss: -2.076,Avg.Loss: -1.552,LR: 4.31E-04]Training epoch 25:  16%|█▌        | 24/153 [00:00<00:02, 53.50it/s, Epoch: 25, Batch: 24,Loss: -2.076,Avg.Loss: -1.552,LR: 4.31E-04]Training epoch 25:  16%|█▌        | 24/153 [00:00<00:02, 53.50it/s, Epoch: 25, Batch: 25,Loss: -2.267,Avg.Loss: -1.581,LR: 4.31E-04]Training epoch 25:  16%|█▋        | 25/153 [00:00<00:02, 53.50it/s, Epoch: 25, Batch: 26,Loss: -2.553,Avg.Loss: -1.618,LR: 4.31E-04]Training epoch 25:  17%|█▋        | 26/153 [00:00<00:02, 53.50it/s, Epoch: 25, Batch: 27,Loss: -2.047,Avg.Loss: -1.634,LR: 4.31E-04]Training epoch 25:  18%|█▊        | 27/153 [00:00<00:02, 53.50it/s, Epoch: 25, Batch: 28,Loss: -1.724,Avg.Loss: -1.637,LR: 4.31E-04]Training epoch 25:  18%|█▊        | 28/153 [00:00<00:02, 53.50it/s, Epoch: 25, Batch: 29,Loss: -1.860,Avg.Loss: -1.645,LR: 4.31E-04]Training epoch 25:  19%|█▉        | 29/153 [00:00<00:02, 53.50it/s, Epoch: 25, Batch: 30,Loss: -1.801,Avg.Loss: -1.650,LR: 4.31E-04]Training epoch 25:  20%|█▉        | 30/153 [00:00<00:02, 52.79it/s, Epoch: 25, Batch: 30,Loss: -1.801,Avg.Loss: -1.650,LR: 4.31E-04]Training epoch 25:  20%|█▉        | 30/153 [00:00<00:02, 52.79it/s, Epoch: 25, Batch: 31,Loss: -1.890,Avg.Loss: -1.658,LR: 4.31E-04]Training epoch 25:  20%|██        | 31/153 [00:00<00:02, 52.79it/s, Epoch: 25, Batch: 32,Loss: -2.117,Avg.Loss: -1.672,LR: 4.31E-04]Training epoch 25:  21%|██        | 32/153 [00:00<00:02, 52.79it/s, Epoch: 25, Batch: 33,Loss: -1.637,Avg.Loss: -1.671,LR: 4.31E-04]Training epoch 25:  22%|██▏       | 33/153 [00:00<00:02, 52.79it/s, Epoch: 25, Batch: 34,Loss: -1.616,Avg.Loss: -1.670,LR: 4.31E-04]Training epoch 25:  22%|██▏       | 34/153 [00:00<00:02, 52.79it/s, Epoch: 25, Batch: 35,Loss: -1.966,Avg.Loss: -1.678,LR: 4.31E-04]Training epoch 25:  23%|██▎       | 35/153 [00:00<00:02, 52.79it/s, Epoch: 25, Batch: 36,Loss: -1.595,Avg.Loss: -1.676,LR: 4.31E-04]Training epoch 25:  24%|██▎       | 36/153 [00:00<00:02, 52.73it/s, Epoch: 25, Batch: 36,Loss: -1.595,Avg.Loss: -1.676,LR: 4.31E-04]Training epoch 25:  24%|██▎       | 36/153 [00:00<00:02, 52.73it/s, Epoch: 25, Batch: 37,Loss: -1.907,Avg.Loss: -1.682,LR: 4.31E-04]Training epoch 25:  24%|██▍       | 37/153 [00:00<00:02, 52.73it/s, Epoch: 25, Batch: 38,Loss: -1.978,Avg.Loss: -1.690,LR: 4.31E-04]Training epoch 25:  25%|██▍       | 38/153 [00:00<00:02, 52.73it/s, Epoch: 25, Batch: 39,Loss: -1.318,Avg.Loss: -1.680,LR: 4.31E-04]Training epoch 25:  25%|██▌       | 39/153 [00:00<00:02, 52.73it/s, Epoch: 25, Batch: 40,Loss: -1.825,Avg.Loss: -1.684,LR: 4.31E-04]Training epoch 25:  26%|██▌       | 40/153 [00:00<00:02, 52.73it/s, Epoch: 25, Batch: 41,Loss: -1.784,Avg.Loss: -1.686,LR: 4.31E-04]Training epoch 25:  27%|██▋       | 41/153 [00:00<00:02, 52.73it/s, Epoch: 25, Batch: 42,Loss: -1.654,Avg.Loss: -1.686,LR: 4.31E-04]Training epoch 25:  27%|██▋       | 42/153 [00:00<00:02, 52.72it/s, Epoch: 25, Batch: 42,Loss: -1.654,Avg.Loss: -1.686,LR: 4.31E-04]Training epoch 25:  27%|██▋       | 42/153 [00:00<00:02, 52.72it/s, Epoch: 25, Batch: 43,Loss: -1.279,Avg.Loss: -1.676,LR: 4.31E-04]Training epoch 25:  28%|██▊       | 43/153 [00:00<00:02, 52.72it/s, Epoch: 25, Batch: 44,Loss: -1.258,Avg.Loss: -1.667,LR: 4.31E-04]Training epoch 25:  29%|██▉       | 44/153 [00:00<00:02, 52.72it/s, Epoch: 25, Batch: 45,Loss: -1.965,Avg.Loss: -1.673,LR: 4.31E-04]Training epoch 25:  29%|██▉       | 45/153 [00:00<00:02, 52.72it/s, Epoch: 25, Batch: 46,Loss: -1.424,Avg.Loss: -1.668,LR: 4.31E-04]Training epoch 25:  30%|███       | 46/153 [00:00<00:02, 52.72it/s, Epoch: 25, Batch: 47,Loss: -0.947,Avg.Loss: -1.652,LR: 4.31E-04]Training epoch 25:  31%|███       | 47/153 [00:00<00:02, 52.72it/s, Epoch: 25, Batch: 48,Loss: -1.107,Avg.Loss: -1.641,LR: 4.31E-04]Training epoch 25:  31%|███▏      | 48/153 [00:00<00:01, 52.66it/s, Epoch: 25, Batch: 48,Loss: -1.107,Avg.Loss: -1.641,LR: 4.31E-04]Training epoch 25:  31%|███▏      | 48/153 [00:00<00:01, 52.66it/s, Epoch: 25, Batch: 49,Loss: -1.248,Avg.Loss: -1.633,LR: 4.31E-04]Training epoch 25:  32%|███▏      | 49/153 [00:00<00:01, 52.66it/s, Epoch: 25, Batch: 50,Loss: -1.011,Avg.Loss: -1.621,LR: 4.30E-04]Training epoch 25:  33%|███▎      | 50/153 [00:00<00:01, 52.66it/s, Epoch: 25, Batch: 51,Loss: -1.721,Avg.Loss: -1.623,LR: 4.30E-04]Training epoch 25:  33%|███▎      | 51/153 [00:00<00:01, 52.66it/s, Epoch: 25, Batch: 52,Loss: -1.929,Avg.Loss: -1.629,LR: 4.30E-04]Training epoch 25:  34%|███▍      | 52/153 [00:00<00:01, 52.66it/s, Epoch: 25, Batch: 53,Loss: -1.552,Avg.Loss: -1.627,LR: 4.30E-04]Training epoch 25:  35%|███▍      | 53/153 [00:01<00:01, 52.66it/s, Epoch: 25, Batch: 54,Loss: -2.081,Avg.Loss: -1.635,LR: 4.30E-04]Training epoch 25:  35%|███▌      | 54/153 [00:01<00:01, 52.88it/s, Epoch: 25, Batch: 54,Loss: -2.081,Avg.Loss: -1.635,LR: 4.30E-04]Training epoch 25:  35%|███▌      | 54/153 [00:01<00:01, 52.88it/s, Epoch: 25, Batch: 55,Loss: -1.852,Avg.Loss: -1.639,LR: 4.30E-04]Training epoch 25:  36%|███▌      | 55/153 [00:01<00:01, 52.88it/s, Epoch: 25, Batch: 56,Loss: -1.730,Avg.Loss: -1.641,LR: 4.30E-04]Training epoch 25:  37%|███▋      | 56/153 [00:01<00:01, 52.88it/s, Epoch: 25, Batch: 57,Loss: -2.103,Avg.Loss: -1.649,LR: 4.30E-04]Training epoch 25:  37%|███▋      | 57/153 [00:01<00:01, 52.88it/s, Epoch: 25, Batch: 58,Loss: -1.545,Avg.Loss: -1.647,LR: 4.30E-04]Training epoch 25:  38%|███▊      | 58/153 [00:01<00:01, 52.88it/s, Epoch: 25, Batch: 59,Loss: -1.073,Avg.Loss: -1.638,LR: 4.30E-04]Training epoch 25:  39%|███▊      | 59/153 [00:01<00:01, 52.88it/s, Epoch: 25, Batch: 60,Loss: -1.395,Avg.Loss: -1.634,LR: 4.30E-04]Training epoch 25:  39%|███▉      | 60/153 [00:01<00:01, 52.37it/s, Epoch: 25, Batch: 60,Loss: -1.395,Avg.Loss: -1.634,LR: 4.30E-04]Training epoch 25:  39%|███▉      | 60/153 [00:01<00:01, 52.37it/s, Epoch: 25, Batch: 61,Loss: -2.152,Avg.Loss: -1.642,LR: 4.30E-04]Training epoch 25:  40%|███▉      | 61/153 [00:01<00:01, 52.37it/s, Epoch: 25, Batch: 62,Loss: -0.773,Avg.Loss: -1.628,LR: 4.30E-04]Training epoch 25:  41%|████      | 62/153 [00:01<00:01, 52.37it/s, Epoch: 25, Batch: 63,Loss: 0.219,Avg.Loss: -1.599,LR: 4.30E-04] Training epoch 25:  41%|████      | 63/153 [00:01<00:01, 52.37it/s, Epoch: 25, Batch: 64,Loss: -0.543,Avg.Loss: -1.582,LR: 4.30E-04]Training epoch 25:  42%|████▏     | 64/153 [00:01<00:01, 52.37it/s, Epoch: 25, Batch: 65,Loss: -1.190,Avg.Loss: -1.576,LR: 4.30E-04]Training epoch 25:  42%|████▏     | 65/153 [00:01<00:01, 52.37it/s, Epoch: 25, Batch: 66,Loss: -1.204,Avg.Loss: -1.571,LR: 4.30E-04]Training epoch 25:  43%|████▎     | 66/153 [00:01<00:01, 52.46it/s, Epoch: 25, Batch: 66,Loss: -1.204,Avg.Loss: -1.571,LR: 4.30E-04]Training epoch 25:  43%|████▎     | 66/153 [00:01<00:01, 52.46it/s, Epoch: 25, Batch: 67,Loss: -1.535,Avg.Loss: -1.570,LR: 4.30E-04]Training epoch 25:  44%|████▍     | 67/153 [00:01<00:01, 52.46it/s, Epoch: 25, Batch: 68,Loss: -1.390,Avg.Loss: -1.567,LR: 4.30E-04]Training epoch 25:  44%|████▍     | 68/153 [00:01<00:01, 52.46it/s, Epoch: 25, Batch: 69,Loss: -1.299,Avg.Loss: -1.564,LR: 4.30E-04]Training epoch 25:  45%|████▌     | 69/153 [00:01<00:01, 52.46it/s, Epoch: 25, Batch: 70,Loss: -1.460,Avg.Loss: -1.562,LR: 4.30E-04]Training epoch 25:  46%|████▌     | 70/153 [00:01<00:01, 52.46it/s, Epoch: 25, Batch: 71,Loss: -1.856,Avg.Loss: -1.566,LR: 4.30E-04]Training epoch 25:  46%|████▋     | 71/153 [00:01<00:01, 52.46it/s, Epoch: 25, Batch: 72,Loss: -1.839,Avg.Loss: -1.570,LR: 4.30E-04]Training epoch 25:  47%|████▋     | 72/153 [00:01<00:01, 52.58it/s, Epoch: 25, Batch: 72,Loss: -1.839,Avg.Loss: -1.570,LR: 4.30E-04]Training epoch 25:  47%|████▋     | 72/153 [00:01<00:01, 52.58it/s, Epoch: 25, Batch: 73,Loss: -1.434,Avg.Loss: -1.568,LR: 4.30E-04]Training epoch 25:  48%|████▊     | 73/153 [00:01<00:01, 52.58it/s, Epoch: 25, Batch: 74,Loss: -1.688,Avg.Loss: -1.570,LR: 4.30E-04]Training epoch 25:  48%|████▊     | 74/153 [00:01<00:01, 52.58it/s, Epoch: 25, Batch: 75,Loss: -2.188,Avg.Loss: -1.578,LR: 4.30E-04]Training epoch 25:  49%|████▉     | 75/153 [00:01<00:01, 52.58it/s, Epoch: 25, Batch: 76,Loss: -1.060,Avg.Loss: -1.571,LR: 4.30E-04]Training epoch 25:  50%|████▉     | 76/153 [00:01<00:01, 52.58it/s, Epoch: 25, Batch: 77,Loss: -1.008,Avg.Loss: -1.564,LR: 4.30E-04]Training epoch 25:  50%|█████     | 77/153 [00:01<00:01, 52.58it/s, Epoch: 25, Batch: 78,Loss: -1.440,Avg.Loss: -1.562,LR: 4.29E-04]Training epoch 25:  51%|█████     | 78/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 78,Loss: -1.440,Avg.Loss: -1.562,LR: 4.29E-04]Training epoch 25:  51%|█████     | 78/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 79,Loss: -1.966,Avg.Loss: -1.567,LR: 4.29E-04]Training epoch 25:  52%|█████▏    | 79/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 80,Loss: -1.938,Avg.Loss: -1.572,LR: 4.29E-04]Training epoch 25:  52%|█████▏    | 80/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 81,Loss: -0.598,Avg.Loss: -1.560,LR: 4.29E-04]Training epoch 25:  53%|█████▎    | 81/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 82,Loss: -0.326,Avg.Loss: -1.545,LR: 4.29E-04]Training epoch 25:  54%|█████▎    | 82/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 83,Loss: -0.036,Avg.Loss: -1.527,LR: 4.29E-04]Training epoch 25:  54%|█████▍    | 83/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 84,Loss: -0.804,Avg.Loss: -1.518,LR: 4.29E-04]Training epoch 25:  55%|█████▍    | 84/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 84,Loss: -0.804,Avg.Loss: -1.518,LR: 4.29E-04]Training epoch 25:  55%|█████▍    | 84/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 85,Loss: -1.153,Avg.Loss: -1.514,LR: 4.29E-04]Training epoch 25:  56%|█████▌    | 85/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 86,Loss: -1.987,Avg.Loss: -1.519,LR: 4.29E-04]Training epoch 25:  56%|█████▌    | 86/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 87,Loss: -1.709,Avg.Loss: -1.522,LR: 4.29E-04]Training epoch 25:  57%|█████▋    | 87/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 88,Loss: -1.048,Avg.Loss: -1.516,LR: 4.29E-04]Training epoch 25:  58%|█████▊    | 88/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 89,Loss: -1.560,Avg.Loss: -1.517,LR: 4.29E-04]Training epoch 25:  58%|█████▊    | 89/153 [00:01<00:01, 52.92it/s, Epoch: 25, Batch: 90,Loss: -1.231,Avg.Loss: -1.513,LR: 4.29E-04]Training epoch 25:  59%|█████▉    | 90/153 [00:01<00:01, 53.10it/s, Epoch: 25, Batch: 90,Loss: -1.231,Avg.Loss: -1.513,LR: 4.29E-04]Training epoch 25:  59%|█████▉    | 90/153 [00:01<00:01, 53.10it/s, Epoch: 25, Batch: 91,Loss: -1.258,Avg.Loss: -1.511,LR: 4.29E-04]Training epoch 25:  59%|█████▉    | 91/153 [00:01<00:01, 53.10it/s, Epoch: 25, Batch: 92,Loss: -1.871,Avg.Loss: -1.515,LR: 4.29E-04]Training epoch 25:  60%|██████    | 92/153 [00:01<00:01, 53.10it/s, Epoch: 25, Batch: 93,Loss: -1.516,Avg.Loss: -1.515,LR: 4.29E-04]Training epoch 25:  61%|██████    | 93/153 [00:01<00:01, 53.10it/s, Epoch: 25, Batch: 94,Loss: -1.294,Avg.Loss: -1.512,LR: 4.29E-04]Training epoch 25:  61%|██████▏   | 94/153 [00:01<00:01, 53.10it/s, Epoch: 25, Batch: 95,Loss: -1.931,Avg.Loss: -1.517,LR: 4.29E-04]Training epoch 25:  62%|██████▏   | 95/153 [00:01<00:01, 53.10it/s, Epoch: 25, Batch: 96,Loss: -1.500,Avg.Loss: -1.516,LR: 4.29E-04]Training epoch 25:  63%|██████▎   | 96/153 [00:01<00:01, 53.04it/s, Epoch: 25, Batch: 96,Loss: -1.500,Avg.Loss: -1.516,LR: 4.29E-04]Training epoch 25:  63%|██████▎   | 96/153 [00:01<00:01, 53.04it/s, Epoch: 25, Batch: 97,Loss: -1.164,Avg.Loss: -1.513,LR: 4.29E-04]Training epoch 25:  63%|██████▎   | 97/153 [00:01<00:01, 53.04it/s, Epoch: 25, Batch: 98,Loss: -1.608,Avg.Loss: -1.514,LR: 4.29E-04]Training epoch 25:  64%|██████▍   | 98/153 [00:01<00:01, 53.04it/s, Epoch: 25, Batch: 99,Loss: -1.730,Avg.Loss: -1.516,LR: 4.29E-04]Training epoch 25:  65%|██████▍   | 99/153 [00:01<00:01, 53.04it/s, Epoch: 25, Batch: 100,Loss: -1.471,Avg.Loss: -1.516,LR: 4.29E-04]Training epoch 25:  65%|██████▌   | 100/153 [00:01<00:00, 53.04it/s, Epoch: 25, Batch: 101,Loss: -1.877,Avg.Loss: -1.519,LR: 4.29E-04]Training epoch 25:  66%|██████▌   | 101/153 [00:01<00:00, 53.04it/s, Epoch: 25, Batch: 102,Loss: -2.104,Avg.Loss: -1.525,LR: 4.29E-04]Training epoch 25:  67%|██████▋   | 102/153 [00:01<00:00, 52.99it/s, Epoch: 25, Batch: 102,Loss: -2.104,Avg.Loss: -1.525,LR: 4.29E-04]Training epoch 25:  67%|██████▋   | 102/153 [00:01<00:00, 52.99it/s, Epoch: 25, Batch: 103,Loss: -1.436,Avg.Loss: -1.524,LR: 4.29E-04]Training epoch 25:  67%|██████▋   | 103/153 [00:01<00:00, 52.99it/s, Epoch: 25, Batch: 104,Loss: -1.731,Avg.Loss: -1.526,LR: 4.29E-04]Training epoch 25:  68%|██████▊   | 104/153 [00:01<00:00, 52.99it/s, Epoch: 25, Batch: 105,Loss: -1.642,Avg.Loss: -1.527,LR: 4.29E-04]Training epoch 25:  69%|██████▊   | 105/153 [00:01<00:00, 52.99it/s, Epoch: 25, Batch: 106,Loss: -1.338,Avg.Loss: -1.525,LR: 4.28E-04]Training epoch 25:  69%|██████▉   | 106/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 107,Loss: -1.604,Avg.Loss: -1.526,LR: 4.28E-04]Training epoch 25:  70%|██████▉   | 107/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 108,Loss: -1.866,Avg.Loss: -1.529,LR: 4.28E-04]Training epoch 25:  71%|███████   | 108/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 108,Loss: -1.866,Avg.Loss: -1.529,LR: 4.28E-04]Training epoch 25:  71%|███████   | 108/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 109,Loss: -1.649,Avg.Loss: -1.530,LR: 4.28E-04]Training epoch 25:  71%|███████   | 109/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 110,Loss: -2.047,Avg.Loss: -1.535,LR: 4.28E-04]Training epoch 25:  72%|███████▏  | 110/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 111,Loss: -2.033,Avg.Loss: -1.539,LR: 4.28E-04]Training epoch 25:  73%|███████▎  | 111/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 112,Loss: -1.900,Avg.Loss: -1.543,LR: 4.28E-04]Training epoch 25:  73%|███████▎  | 112/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 113,Loss: -1.934,Avg.Loss: -1.546,LR: 4.28E-04]Training epoch 25:  74%|███████▍  | 113/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 114,Loss: -1.989,Avg.Loss: -1.550,LR: 4.28E-04]Training epoch 25:  75%|███████▍  | 114/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 114,Loss: -1.989,Avg.Loss: -1.550,LR: 4.28E-04]Training epoch 25:  75%|███████▍  | 114/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 115,Loss: -1.390,Avg.Loss: -1.549,LR: 4.28E-04]Training epoch 25:  75%|███████▌  | 115/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 116,Loss: -1.963,Avg.Loss: -1.552,LR: 4.28E-04]Training epoch 25:  76%|███████▌  | 116/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 117,Loss: -1.802,Avg.Loss: -1.554,LR: 4.28E-04]Training epoch 25:  76%|███████▋  | 117/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 118,Loss: -1.350,Avg.Loss: -1.553,LR: 4.28E-04]Training epoch 25:  77%|███████▋  | 118/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 119,Loss: -1.847,Avg.Loss: -1.555,LR: 4.28E-04]Training epoch 25:  78%|███████▊  | 119/153 [00:02<00:00, 52.99it/s, Epoch: 25, Batch: 120,Loss: -1.877,Avg.Loss: -1.558,LR: 4.28E-04]Training epoch 25:  78%|███████▊  | 120/153 [00:02<00:00, 53.16it/s, Epoch: 25, Batch: 120,Loss: -1.877,Avg.Loss: -1.558,LR: 4.28E-04]Training epoch 25:  78%|███████▊  | 120/153 [00:02<00:00, 53.16it/s, Epoch: 25, Batch: 121,Loss: -1.937,Avg.Loss: -1.561,LR: 4.28E-04]Training epoch 25:  79%|███████▉  | 121/153 [00:02<00:00, 53.16it/s, Epoch: 25, Batch: 122,Loss: -2.225,Avg.Loss: -1.566,LR: 4.28E-04]Training epoch 25:  80%|███████▉  | 122/153 [00:02<00:00, 53.16it/s, Epoch: 25, Batch: 123,Loss: -1.961,Avg.Loss: -1.570,LR: 4.28E-04]Training epoch 25:  80%|████████  | 123/153 [00:02<00:00, 53.16it/s, Epoch: 25, Batch: 124,Loss: -1.570,Avg.Loss: -1.570,LR: 4.28E-04]Training epoch 25:  81%|████████  | 124/153 [00:02<00:00, 53.16it/s, Epoch: 25, Batch: 125,Loss: -2.086,Avg.Loss: -1.574,LR: 4.28E-04]Training epoch 25:  82%|████████▏ | 125/153 [00:02<00:00, 53.16it/s, Epoch: 25, Batch: 126,Loss: -1.791,Avg.Loss: -1.575,LR: 4.28E-04]Training epoch 25:  82%|████████▏ | 126/153 [00:02<00:00, 53.19it/s, Epoch: 25, Batch: 126,Loss: -1.791,Avg.Loss: -1.575,LR: 4.28E-04]Training epoch 25:  82%|████████▏ | 126/153 [00:02<00:00, 53.19it/s, Epoch: 25, Batch: 127,Loss: -1.601,Avg.Loss: -1.576,LR: 4.28E-04]Training epoch 25:  83%|████████▎ | 127/153 [00:02<00:00, 53.19it/s, Epoch: 25, Batch: 128,Loss: -2.177,Avg.Loss: -1.580,LR: 4.28E-04]Training epoch 25:  84%|████████▎ | 128/153 [00:02<00:00, 53.19it/s, Epoch: 25, Batch: 129,Loss: -2.128,Avg.Loss: -1.585,LR: 4.28E-04]Training epoch 25:  84%|████████▍ | 129/153 [00:02<00:00, 53.19it/s, Epoch: 25, Batch: 130,Loss: -1.552,Avg.Loss: -1.584,LR: 4.28E-04]Training epoch 25:  85%|████████▍ | 130/153 [00:02<00:00, 53.19it/s, Epoch: 25, Batch: 131,Loss: -2.222,Avg.Loss: -1.589,LR: 4.28E-04]Training epoch 25:  86%|████████▌ | 131/153 [00:02<00:00, 53.19it/s, Epoch: 25, Batch: 132,Loss: -1.970,Avg.Loss: -1.592,LR: 4.28E-04]Training epoch 25:  86%|████████▋ | 132/153 [00:02<00:00, 53.36it/s, Epoch: 25, Batch: 132,Loss: -1.970,Avg.Loss: -1.592,LR: 4.28E-04]Training epoch 25:  86%|████████▋ | 132/153 [00:02<00:00, 53.36it/s, Epoch: 25, Batch: 133,Loss: -1.553,Avg.Loss: -1.592,LR: 4.28E-04]Training epoch 25:  87%|████████▋ | 133/153 [00:02<00:00, 53.36it/s, Epoch: 25, Batch: 134,Loss: -2.292,Avg.Loss: -1.597,LR: 4.27E-04]Training epoch 25:  88%|████████▊ | 134/153 [00:02<00:00, 53.36it/s, Epoch: 25, Batch: 135,Loss: -1.899,Avg.Loss: -1.599,LR: 4.27E-04]Training epoch 25:  88%|████████▊ | 135/153 [00:02<00:00, 53.36it/s, Epoch: 25, Batch: 136,Loss: -1.810,Avg.Loss: -1.601,LR: 4.27E-04]Training epoch 25:  89%|████████▉ | 136/153 [00:02<00:00, 53.36it/s, Epoch: 25, Batch: 137,Loss: -2.512,Avg.Loss: -1.607,LR: 4.27E-04]Training epoch 25:  90%|████████▉ | 137/153 [00:02<00:00, 53.36it/s, Epoch: 25, Batch: 138,Loss: -2.028,Avg.Loss: -1.610,LR: 4.27E-04]Training epoch 25:  90%|█████████ | 138/153 [00:02<00:00, 53.44it/s, Epoch: 25, Batch: 138,Loss: -2.028,Avg.Loss: -1.610,LR: 4.27E-04]Training epoch 25:  90%|█████████ | 138/153 [00:02<00:00, 53.44it/s, Epoch: 25, Batch: 139,Loss: -1.450,Avg.Loss: -1.609,LR: 4.27E-04]Training epoch 25:  91%|█████████ | 139/153 [00:02<00:00, 53.44it/s, Epoch: 25, Batch: 140,Loss: -1.966,Avg.Loss: -1.612,LR: 4.27E-04]Training epoch 25:  92%|█████████▏| 140/153 [00:02<00:00, 53.44it/s, Epoch: 25, Batch: 141,Loss: -2.130,Avg.Loss: -1.616,LR: 4.27E-04]Training epoch 25:  92%|█████████▏| 141/153 [00:02<00:00, 53.44it/s, Epoch: 25, Batch: 142,Loss: -1.624,Avg.Loss: -1.616,LR: 4.27E-04]Training epoch 25:  93%|█████████▎| 142/153 [00:02<00:00, 53.44it/s, Epoch: 25, Batch: 143,Loss: -2.247,Avg.Loss: -1.620,LR: 4.27E-04]Training epoch 25:  93%|█████████▎| 143/153 [00:02<00:00, 53.44it/s, Epoch: 25, Batch: 144,Loss: -2.397,Avg.Loss: -1.625,LR: 4.27E-04]Training epoch 25:  94%|█████████▍| 144/153 [00:02<00:00, 53.51it/s, Epoch: 25, Batch: 144,Loss: -2.397,Avg.Loss: -1.625,LR: 4.27E-04]Training epoch 25:  94%|█████████▍| 144/153 [00:02<00:00, 53.51it/s, Epoch: 25, Batch: 145,Loss: -1.657,Avg.Loss: -1.626,LR: 4.27E-04]Training epoch 25:  95%|█████████▍| 145/153 [00:02<00:00, 53.51it/s, Epoch: 25, Batch: 146,Loss: -1.838,Avg.Loss: -1.627,LR: 4.27E-04]Training epoch 25:  95%|█████████▌| 146/153 [00:02<00:00, 53.51it/s, Epoch: 25, Batch: 147,Loss: -1.502,Avg.Loss: -1.626,LR: 4.27E-04]Training epoch 25:  96%|█████████▌| 147/153 [00:02<00:00, 53.51it/s, Epoch: 25, Batch: 148,Loss: -1.970,Avg.Loss: -1.629,LR: 4.27E-04]Training epoch 25:  97%|█████████▋| 148/153 [00:02<00:00, 53.51it/s, Epoch: 25, Batch: 149,Loss: -2.260,Avg.Loss: -1.633,LR: 4.27E-04]Training epoch 25:  97%|█████████▋| 149/153 [00:02<00:00, 53.51it/s, Epoch: 25, Batch: 150,Loss: -1.937,Avg.Loss: -1.635,LR: 4.27E-04]Training epoch 25:  98%|█████████▊| 150/153 [00:02<00:00, 53.02it/s, Epoch: 25, Batch: 150,Loss: -1.937,Avg.Loss: -1.635,LR: 4.27E-04]Training epoch 25:  98%|█████████▊| 150/153 [00:02<00:00, 53.02it/s, Epoch: 25, Batch: 151,Loss: -1.597,Avg.Loss: -1.635,LR: 4.27E-04]Training epoch 25:  99%|█████████▊| 151/153 [00:02<00:00, 53.02it/s, Epoch: 25, Batch: 152,Loss: -1.918,Avg.Loss: -1.636,LR: 4.27E-04]Training epoch 25:  99%|█████████▉| 152/153 [00:02<00:00, 53.02it/s, Epoch: 25, Batch: 153,Loss: -2.011,Avg.Loss: -1.639,LR: 4.27E-04]Training epoch 25: 100%|██████████| 153/153 [00:02<00:00, 53.04it/s, Epoch: 25, Batch: 153,Loss: -2.011,Avg.Loss: -1.639,LR: 4.27E-04]
Training epoch 26:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 26:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 26, Batch: 1,Loss: -1.998,Avg.Loss: -1.998,LR: 4.27E-04]Training epoch 26:   1%|          | 1/153 [00:00<00:05, 26.16it/s, Epoch: 26, Batch: 2,Loss: -2.344,Avg.Loss: -2.171,LR: 4.27E-04]Training epoch 26:   1%|▏         | 2/153 [00:00<00:04, 35.98it/s, Epoch: 26, Batch: 3,Loss: -1.908,Avg.Loss: -2.083,LR: 4.27E-04]Training epoch 26:   2%|▏         | 3/153 [00:00<00:03, 41.03it/s, Epoch: 26, Batch: 4,Loss: -1.648,Avg.Loss: -1.974,LR: 4.27E-04]Training epoch 26:   3%|▎         | 4/153 [00:00<00:03, 44.15it/s, Epoch: 26, Batch: 5,Loss: -2.383,Avg.Loss: -2.056,LR: 4.27E-04]Training epoch 26:   3%|▎         | 5/153 [00:00<00:03, 46.21it/s, Epoch: 26, Batch: 6,Loss: -2.084,Avg.Loss: -2.061,LR: 4.27E-04]Training epoch 26:   4%|▍         | 6/153 [00:00<00:02, 55.36it/s, Epoch: 26, Batch: 6,Loss: -2.084,Avg.Loss: -2.061,LR: 4.27E-04]Training epoch 26:   4%|▍         | 6/153 [00:00<00:02, 55.36it/s, Epoch: 26, Batch: 7,Loss: -1.965,Avg.Loss: -2.047,LR: 4.27E-04]Training epoch 26:   5%|▍         | 7/153 [00:00<00:02, 55.36it/s, Epoch: 26, Batch: 8,Loss: -1.852,Avg.Loss: -2.023,LR: 4.26E-04]Training epoch 26:   5%|▌         | 8/153 [00:00<00:02, 55.36it/s, Epoch: 26, Batch: 9,Loss: -1.951,Avg.Loss: -2.015,LR: 4.26E-04]Training epoch 26:   6%|▌         | 9/153 [00:00<00:02, 55.36it/s, Epoch: 26, Batch: 10,Loss: -1.714,Avg.Loss: -1.985,LR: 4.26E-04]Training epoch 26:   7%|▋         | 10/153 [00:00<00:02, 55.36it/s, Epoch: 26, Batch: 11,Loss: -2.048,Avg.Loss: -1.990,LR: 4.26E-04]Training epoch 26:   7%|▋         | 11/153 [00:00<00:02, 55.36it/s, Epoch: 26, Batch: 12,Loss: -1.784,Avg.Loss: -1.973,LR: 4.26E-04]Training epoch 26:   8%|▊         | 12/153 [00:00<00:02, 53.91it/s, Epoch: 26, Batch: 12,Loss: -1.784,Avg.Loss: -1.973,LR: 4.26E-04]Training epoch 26:   8%|▊         | 12/153 [00:00<00:02, 53.91it/s, Epoch: 26, Batch: 13,Loss: -1.844,Avg.Loss: -1.963,LR: 4.26E-04]Training epoch 26:   8%|▊         | 13/153 [00:00<00:02, 53.91it/s, Epoch: 26, Batch: 14,Loss: -2.229,Avg.Loss: -1.982,LR: 4.26E-04]Training epoch 26:   9%|▉         | 14/153 [00:00<00:02, 53.91it/s, Epoch: 26, Batch: 15,Loss: -2.016,Avg.Loss: -1.985,LR: 4.26E-04]Training epoch 26:  10%|▉         | 15/153 [00:00<00:02, 53.91it/s, Epoch: 26, Batch: 16,Loss: -1.687,Avg.Loss: -1.966,LR: 4.26E-04]Training epoch 26:  10%|█         | 16/153 [00:00<00:02, 53.91it/s, Epoch: 26, Batch: 17,Loss: -2.227,Avg.Loss: -1.981,LR: 4.26E-04]Training epoch 26:  11%|█         | 17/153 [00:00<00:02, 53.91it/s, Epoch: 26, Batch: 18,Loss: -1.973,Avg.Loss: -1.981,LR: 4.26E-04]Training epoch 26:  12%|█▏        | 18/153 [00:00<00:02, 53.23it/s, Epoch: 26, Batch: 18,Loss: -1.973,Avg.Loss: -1.981,LR: 4.26E-04]Training epoch 26:  12%|█▏        | 18/153 [00:00<00:02, 53.23it/s, Epoch: 26, Batch: 19,Loss: -1.709,Avg.Loss: -1.967,LR: 4.26E-04]Training epoch 26:  12%|█▏        | 19/153 [00:00<00:02, 53.23it/s, Epoch: 26, Batch: 20,Loss: -2.085,Avg.Loss: -1.972,LR: 4.26E-04]Training epoch 26:  13%|█▎        | 20/153 [00:00<00:02, 53.23it/s, Epoch: 26, Batch: 21,Loss: -2.079,Avg.Loss: -1.978,LR: 4.26E-04]Training epoch 26:  14%|█▎        | 21/153 [00:00<00:02, 53.23it/s, Epoch: 26, Batch: 22,Loss: -1.767,Avg.Loss: -1.968,LR: 4.26E-04]Training epoch 26:  14%|█▍        | 22/153 [00:00<00:02, 53.23it/s, Epoch: 26, Batch: 23,Loss: -2.350,Avg.Loss: -1.985,LR: 4.26E-04]Training epoch 26:  15%|█▌        | 23/153 [00:00<00:02, 53.23it/s, Epoch: 26, Batch: 24,Loss: -2.321,Avg.Loss: -1.999,LR: 4.26E-04]Training epoch 26:  16%|█▌        | 24/153 [00:00<00:02, 52.97it/s, Epoch: 26, Batch: 24,Loss: -2.321,Avg.Loss: -1.999,LR: 4.26E-04]Training epoch 26:  16%|█▌        | 24/153 [00:00<00:02, 52.97it/s, Epoch: 26, Batch: 25,Loss: -2.144,Avg.Loss: -2.004,LR: 4.26E-04]Training epoch 26:  16%|█▋        | 25/153 [00:00<00:02, 52.97it/s, Epoch: 26, Batch: 26,Loss: -1.492,Avg.Loss: -1.985,LR: 4.26E-04]Training epoch 26:  17%|█▋        | 26/153 [00:00<00:02, 52.97it/s, Epoch: 26, Batch: 27,Loss: -1.652,Avg.Loss: -1.972,LR: 4.26E-04]Training epoch 26:  18%|█▊        | 27/153 [00:00<00:02, 52.97it/s, Epoch: 26, Batch: 28,Loss: -0.581,Avg.Loss: -1.923,LR: 4.26E-04]Training epoch 26:  18%|█▊        | 28/153 [00:00<00:02, 52.97it/s, Epoch: 26, Batch: 29,Loss: -0.657,Avg.Loss: -1.879,LR: 4.26E-04]Training epoch 26:  19%|█▉        | 29/153 [00:00<00:02, 52.97it/s, Epoch: 26, Batch: 30,Loss: -1.776,Avg.Loss: -1.876,LR: 4.26E-04]Training epoch 26:  20%|█▉        | 30/153 [00:00<00:02, 52.64it/s, Epoch: 26, Batch: 30,Loss: -1.776,Avg.Loss: -1.876,LR: 4.26E-04]Training epoch 26:  20%|█▉        | 30/153 [00:00<00:02, 52.64it/s, Epoch: 26, Batch: 31,Loss: -1.707,Avg.Loss: -1.870,LR: 4.26E-04]Training epoch 26:  20%|██        | 31/153 [00:00<00:02, 52.64it/s, Epoch: 26, Batch: 32,Loss: -1.699,Avg.Loss: -1.865,LR: 4.26E-04]Training epoch 26:  21%|██        | 32/153 [00:00<00:02, 52.64it/s, Epoch: 26, Batch: 33,Loss: -1.193,Avg.Loss: -1.844,LR: 4.26E-04]Training epoch 26:  22%|██▏       | 33/153 [00:00<00:02, 52.64it/s, Epoch: 26, Batch: 34,Loss: -1.241,Avg.Loss: -1.827,LR: 4.26E-04]Training epoch 26:  22%|██▏       | 34/153 [00:00<00:02, 52.64it/s, Epoch: 26, Batch: 35,Loss: -1.996,Avg.Loss: -1.832,LR: 4.26E-04]Training epoch 26:  23%|██▎       | 35/153 [00:00<00:02, 52.64it/s, Epoch: 26, Batch: 36,Loss: -1.797,Avg.Loss: -1.831,LR: 4.25E-04]Training epoch 26:  24%|██▎       | 36/153 [00:00<00:02, 52.67it/s, Epoch: 26, Batch: 36,Loss: -1.797,Avg.Loss: -1.831,LR: 4.25E-04]Training epoch 26:  24%|██▎       | 36/153 [00:00<00:02, 52.67it/s, Epoch: 26, Batch: 37,Loss: -1.477,Avg.Loss: -1.821,LR: 4.25E-04]Training epoch 26:  24%|██▍       | 37/153 [00:00<00:02, 52.67it/s, Epoch: 26, Batch: 38,Loss: -1.862,Avg.Loss: -1.822,LR: 4.25E-04]Training epoch 26:  25%|██▍       | 38/153 [00:00<00:02, 52.67it/s, Epoch: 26, Batch: 39,Loss: -1.592,Avg.Loss: -1.816,LR: 4.25E-04]Training epoch 26:  25%|██▌       | 39/153 [00:00<00:02, 52.67it/s, Epoch: 26, Batch: 40,Loss: -1.042,Avg.Loss: -1.797,LR: 4.25E-04]Training epoch 26:  26%|██▌       | 40/153 [00:00<00:02, 52.67it/s, Epoch: 26, Batch: 41,Loss: -1.498,Avg.Loss: -1.790,LR: 4.25E-04]Training epoch 26:  27%|██▋       | 41/153 [00:00<00:02, 52.67it/s, Epoch: 26, Batch: 42,Loss: -1.244,Avg.Loss: -1.777,LR: 4.25E-04]Training epoch 26:  27%|██▋       | 42/153 [00:00<00:02, 52.84it/s, Epoch: 26, Batch: 42,Loss: -1.244,Avg.Loss: -1.777,LR: 4.25E-04]Training epoch 26:  27%|██▋       | 42/153 [00:00<00:02, 52.84it/s, Epoch: 26, Batch: 43,Loss: -1.720,Avg.Loss: -1.775,LR: 4.25E-04]Training epoch 26:  28%|██▊       | 43/153 [00:00<00:02, 52.84it/s, Epoch: 26, Batch: 44,Loss: -2.198,Avg.Loss: -1.785,LR: 4.25E-04]Training epoch 26:  29%|██▉       | 44/153 [00:00<00:02, 52.84it/s, Epoch: 26, Batch: 45,Loss: -1.831,Avg.Loss: -1.786,LR: 4.25E-04]Training epoch 26:  29%|██▉       | 45/153 [00:00<00:02, 52.84it/s, Epoch: 26, Batch: 46,Loss: -1.902,Avg.Loss: -1.788,LR: 4.25E-04]Training epoch 26:  30%|███       | 46/153 [00:00<00:02, 52.84it/s, Epoch: 26, Batch: 47,Loss: -1.410,Avg.Loss: -1.780,LR: 4.25E-04]Training epoch 26:  31%|███       | 47/153 [00:00<00:02, 52.84it/s, Epoch: 26, Batch: 48,Loss: -1.426,Avg.Loss: -1.773,LR: 4.25E-04]Training epoch 26:  31%|███▏      | 48/153 [00:00<00:01, 52.87it/s, Epoch: 26, Batch: 48,Loss: -1.426,Avg.Loss: -1.773,LR: 4.25E-04]Training epoch 26:  31%|███▏      | 48/153 [00:00<00:01, 52.87it/s, Epoch: 26, Batch: 49,Loss: -1.511,Avg.Loss: -1.768,LR: 4.25E-04]Training epoch 26:  32%|███▏      | 49/153 [00:00<00:01, 52.87it/s, Epoch: 26, Batch: 50,Loss: -1.227,Avg.Loss: -1.757,LR: 4.25E-04]Training epoch 26:  33%|███▎      | 50/153 [00:00<00:01, 52.87it/s, Epoch: 26, Batch: 51,Loss: -1.264,Avg.Loss: -1.747,LR: 4.25E-04]Training epoch 26:  33%|███▎      | 51/153 [00:00<00:01, 52.87it/s, Epoch: 26, Batch: 52,Loss: -2.012,Avg.Loss: -1.752,LR: 4.25E-04]Training epoch 26:  34%|███▍      | 52/153 [00:01<00:01, 52.87it/s, Epoch: 26, Batch: 53,Loss: -2.096,Avg.Loss: -1.759,LR: 4.25E-04]Training epoch 26:  35%|███▍      | 53/153 [00:01<00:01, 52.87it/s, Epoch: 26, Batch: 54,Loss: -2.064,Avg.Loss: -1.764,LR: 4.25E-04]Training epoch 26:  35%|███▌      | 54/153 [00:01<00:01, 52.60it/s, Epoch: 26, Batch: 54,Loss: -2.064,Avg.Loss: -1.764,LR: 4.25E-04]Training epoch 26:  35%|███▌      | 54/153 [00:01<00:01, 52.60it/s, Epoch: 26, Batch: 55,Loss: -1.083,Avg.Loss: -1.752,LR: 4.25E-04]Training epoch 26:  36%|███▌      | 55/153 [00:01<00:01, 52.60it/s, Epoch: 26, Batch: 56,Loss: -1.253,Avg.Loss: -1.743,LR: 4.25E-04]Training epoch 26:  37%|███▋      | 56/153 [00:01<00:01, 52.60it/s, Epoch: 26, Batch: 57,Loss: -1.552,Avg.Loss: -1.740,LR: 4.25E-04]Training epoch 26:  37%|███▋      | 57/153 [00:01<00:01, 52.60it/s, Epoch: 26, Batch: 58,Loss: -0.637,Avg.Loss: -1.721,LR: 4.25E-04]Training epoch 26:  38%|███▊      | 58/153 [00:01<00:01, 52.60it/s, Epoch: 26, Batch: 59,Loss: -1.032,Avg.Loss: -1.709,LR: 4.25E-04]Training epoch 26:  39%|███▊      | 59/153 [00:01<00:01, 52.60it/s, Epoch: 26, Batch: 60,Loss: -1.496,Avg.Loss: -1.706,LR: 4.25E-04]Training epoch 26:  39%|███▉      | 60/153 [00:01<00:01, 52.76it/s, Epoch: 26, Batch: 60,Loss: -1.496,Avg.Loss: -1.706,LR: 4.25E-04]Training epoch 26:  39%|███▉      | 60/153 [00:01<00:01, 52.76it/s, Epoch: 26, Batch: 61,Loss: -1.551,Avg.Loss: -1.703,LR: 4.25E-04]Training epoch 26:  40%|███▉      | 61/153 [00:01<00:01, 52.76it/s, Epoch: 26, Batch: 62,Loss: -1.178,Avg.Loss: -1.695,LR: 4.25E-04]Training epoch 26:  41%|████      | 62/153 [00:01<00:01, 52.76it/s, Epoch: 26, Batch: 63,Loss: -1.941,Avg.Loss: -1.698,LR: 4.24E-04]Training epoch 26:  41%|████      | 63/153 [00:01<00:01, 52.76it/s, Epoch: 26, Batch: 64,Loss: -1.511,Avg.Loss: -1.695,LR: 4.24E-04]Training epoch 26:  42%|████▏     | 64/153 [00:01<00:01, 52.76it/s, Epoch: 26, Batch: 65,Loss: -1.828,Avg.Loss: -1.698,LR: 4.24E-04]Training epoch 26:  42%|████▏     | 65/153 [00:01<00:01, 52.76it/s, Epoch: 26, Batch: 66,Loss: -1.993,Avg.Loss: -1.702,LR: 4.24E-04]Training epoch 26:  43%|████▎     | 66/153 [00:01<00:01, 52.75it/s, Epoch: 26, Batch: 66,Loss: -1.993,Avg.Loss: -1.702,LR: 4.24E-04]Training epoch 26:  43%|████▎     | 66/153 [00:01<00:01, 52.75it/s, Epoch: 26, Batch: 67,Loss: -2.264,Avg.Loss: -1.710,LR: 4.24E-04]Training epoch 26:  44%|████▍     | 67/153 [00:01<00:01, 52.75it/s, Epoch: 26, Batch: 68,Loss: -1.805,Avg.Loss: -1.712,LR: 4.24E-04]Training epoch 26:  44%|████▍     | 68/153 [00:01<00:01, 52.75it/s, Epoch: 26, Batch: 69,Loss: -2.463,Avg.Loss: -1.723,LR: 4.24E-04]Training epoch 26:  45%|████▌     | 69/153 [00:01<00:01, 52.75it/s, Epoch: 26, Batch: 70,Loss: -2.300,Avg.Loss: -1.731,LR: 4.24E-04]Training epoch 26:  46%|████▌     | 70/153 [00:01<00:01, 52.75it/s, Epoch: 26, Batch: 71,Loss: -2.250,Avg.Loss: -1.738,LR: 4.24E-04]Training epoch 26:  46%|████▋     | 71/153 [00:01<00:01, 52.75it/s, Epoch: 26, Batch: 72,Loss: -1.965,Avg.Loss: -1.741,LR: 4.24E-04]Training epoch 26:  47%|████▋     | 72/153 [00:01<00:01, 53.12it/s, Epoch: 26, Batch: 72,Loss: -1.965,Avg.Loss: -1.741,LR: 4.24E-04]Training epoch 26:  47%|████▋     | 72/153 [00:01<00:01, 53.12it/s, Epoch: 26, Batch: 73,Loss: -1.314,Avg.Loss: -1.736,LR: 4.24E-04]Training epoch 26:  48%|████▊     | 73/153 [00:01<00:01, 53.12it/s, Epoch: 26, Batch: 74,Loss: -1.992,Avg.Loss: -1.739,LR: 4.24E-04]Training epoch 26:  48%|████▊     | 74/153 [00:01<00:01, 53.12it/s, Epoch: 26, Batch: 75,Loss: -1.794,Avg.Loss: -1.740,LR: 4.24E-04]Training epoch 26:  49%|████▉     | 75/153 [00:01<00:01, 53.12it/s, Epoch: 26, Batch: 76,Loss: -1.251,Avg.Loss: -1.733,LR: 4.24E-04]Training epoch 26:  50%|████▉     | 76/153 [00:01<00:01, 53.12it/s, Epoch: 26, Batch: 77,Loss: -1.545,Avg.Loss: -1.731,LR: 4.24E-04]Training epoch 26:  50%|█████     | 77/153 [00:01<00:01, 53.12it/s, Epoch: 26, Batch: 78,Loss: -1.929,Avg.Loss: -1.733,LR: 4.24E-04]Training epoch 26:  51%|█████     | 78/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 78,Loss: -1.929,Avg.Loss: -1.733,LR: 4.24E-04]Training epoch 26:  51%|█████     | 78/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 79,Loss: -1.933,Avg.Loss: -1.736,LR: 4.24E-04]Training epoch 26:  52%|█████▏    | 79/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 80,Loss: -2.105,Avg.Loss: -1.741,LR: 4.24E-04]Training epoch 26:  52%|█████▏    | 80/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 81,Loss: -1.894,Avg.Loss: -1.742,LR: 4.24E-04]Training epoch 26:  53%|█████▎    | 81/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 82,Loss: -1.888,Avg.Loss: -1.744,LR: 4.24E-04]Training epoch 26:  54%|█████▎    | 82/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 83,Loss: -1.840,Avg.Loss: -1.745,LR: 4.24E-04]Training epoch 26:  54%|█████▍    | 83/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 84,Loss: -1.517,Avg.Loss: -1.743,LR: 4.24E-04]Training epoch 26:  55%|█████▍    | 84/153 [00:01<00:01, 52.96it/s, Epoch: 26, Batch: 84,Loss: -1.517,Avg.Loss: -1.743,LR: 4.24E-04]Training epoch 26:  55%|█████▍    | 84/153 [00:01<00:01, 52.96it/s, Epoch: 26, Batch: 85,Loss: -1.773,Avg.Loss: -1.743,LR: 4.24E-04]Training epoch 26:  56%|█████▌    | 85/153 [00:01<00:01, 52.96it/s, Epoch: 26, Batch: 86,Loss: -1.020,Avg.Loss: -1.735,LR: 4.24E-04]Training epoch 26:  56%|█████▌    | 86/153 [00:01<00:01, 52.96it/s, Epoch: 26, Batch: 87,Loss: -1.522,Avg.Loss: -1.732,LR: 4.24E-04]Training epoch 26:  57%|█████▋    | 87/153 [00:01<00:01, 52.96it/s, Epoch: 26, Batch: 88,Loss: -1.609,Avg.Loss: -1.731,LR: 4.24E-04]Training epoch 26:  58%|█████▊    | 88/153 [00:01<00:01, 52.96it/s, Epoch: 26, Batch: 89,Loss: -2.186,Avg.Loss: -1.736,LR: 4.24E-04]Training epoch 26:  58%|█████▊    | 89/153 [00:01<00:01, 52.96it/s, Epoch: 26, Batch: 90,Loss: -1.819,Avg.Loss: -1.737,LR: 4.23E-04]Training epoch 26:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 26, Batch: 90,Loss: -1.819,Avg.Loss: -1.737,LR: 4.23E-04]Training epoch 26:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 26, Batch: 91,Loss: -0.874,Avg.Loss: -1.727,LR: 4.23E-04]Training epoch 26:  59%|█████▉    | 91/153 [00:01<00:01, 53.06it/s, Epoch: 26, Batch: 92,Loss: -1.331,Avg.Loss: -1.723,LR: 4.23E-04]Training epoch 26:  60%|██████    | 92/153 [00:01<00:01, 53.06it/s, Epoch: 26, Batch: 93,Loss: -1.674,Avg.Loss: -1.722,LR: 4.23E-04]Training epoch 26:  61%|██████    | 93/153 [00:01<00:01, 53.06it/s, Epoch: 26, Batch: 94,Loss: -1.187,Avg.Loss: -1.717,LR: 4.23E-04]Training epoch 26:  61%|██████▏   | 94/153 [00:01<00:01, 53.06it/s, Epoch: 26, Batch: 95,Loss: -2.064,Avg.Loss: -1.720,LR: 4.23E-04]Training epoch 26:  62%|██████▏   | 95/153 [00:01<00:01, 53.06it/s, Epoch: 26, Batch: 96,Loss: -2.067,Avg.Loss: -1.724,LR: 4.23E-04]Training epoch 26:  63%|██████▎   | 96/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 96,Loss: -2.067,Avg.Loss: -1.724,LR: 4.23E-04]Training epoch 26:  63%|██████▎   | 96/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 97,Loss: -2.065,Avg.Loss: -1.728,LR: 4.23E-04]Training epoch 26:  63%|██████▎   | 97/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 98,Loss: -1.981,Avg.Loss: -1.730,LR: 4.23E-04]Training epoch 26:  64%|██████▍   | 98/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 99,Loss: -1.162,Avg.Loss: -1.724,LR: 4.23E-04]Training epoch 26:  65%|██████▍   | 99/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 100,Loss: -1.527,Avg.Loss: -1.722,LR: 4.23E-04]Training epoch 26:  65%|██████▌   | 100/153 [00:01<00:01, 52.97it/s, Epoch: 26, Batch: 101,Loss: -2.137,Avg.Loss: -1.727,LR: 4.23E-04]Training epoch 26:  66%|██████▌   | 101/153 [00:01<00:00, 52.97it/s, Epoch: 26, Batch: 102,Loss: -1.139,Avg.Loss: -1.721,LR: 4.23E-04]Training epoch 26:  67%|██████▋   | 102/153 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 102,Loss: -1.139,Avg.Loss: -1.721,LR: 4.23E-04]Training epoch 26:  67%|██████▋   | 102/153 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 103,Loss: -0.917,Avg.Loss: -1.713,LR: 4.23E-04]Training epoch 26:  67%|██████▋   | 103/153 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 104,Loss: -1.620,Avg.Loss: -1.712,LR: 4.23E-04]Training epoch 26:  68%|██████▊   | 104/153 [00:01<00:00, 53.21it/s, Epoch: 26, Batch: 105,Loss: -2.276,Avg.Loss: -1.717,LR: 4.23E-04]Training epoch 26:  69%|██████▊   | 105/153 [00:02<00:00, 53.21it/s, Epoch: 26, Batch: 106,Loss: -1.842,Avg.Loss: -1.719,LR: 4.23E-04]Training epoch 26:  69%|██████▉   | 106/153 [00:02<00:00, 53.21it/s, Epoch: 26, Batch: 107,Loss: -1.851,Avg.Loss: -1.720,LR: 4.23E-04]Training epoch 26:  70%|██████▉   | 107/153 [00:02<00:00, 53.21it/s, Epoch: 26, Batch: 108,Loss: -2.041,Avg.Loss: -1.723,LR: 4.23E-04]Training epoch 26:  71%|███████   | 108/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 108,Loss: -2.041,Avg.Loss: -1.723,LR: 4.23E-04]Training epoch 26:  71%|███████   | 108/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 109,Loss: -1.437,Avg.Loss: -1.720,LR: 4.23E-04]Training epoch 26:  71%|███████   | 109/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 110,Loss: -2.036,Avg.Loss: -1.723,LR: 4.23E-04]Training epoch 26:  72%|███████▏  | 110/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 111,Loss: -1.995,Avg.Loss: -1.726,LR: 4.23E-04]Training epoch 26:  73%|███████▎  | 111/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 112,Loss: -2.098,Avg.Loss: -1.729,LR: 4.23E-04]Training epoch 26:  73%|███████▎  | 112/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 113,Loss: -2.063,Avg.Loss: -1.732,LR: 4.23E-04]Training epoch 26:  74%|███████▍  | 113/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 114,Loss: -2.117,Avg.Loss: -1.735,LR: 4.23E-04]Training epoch 26:  75%|███████▍  | 114/153 [00:02<00:00, 52.88it/s, Epoch: 26, Batch: 114,Loss: -2.117,Avg.Loss: -1.735,LR: 4.23E-04]Training epoch 26:  75%|███████▍  | 114/153 [00:02<00:00, 52.88it/s, Epoch: 26, Batch: 115,Loss: -1.324,Avg.Loss: -1.732,LR: 4.23E-04]Training epoch 26:  75%|███████▌  | 115/153 [00:02<00:00, 52.88it/s, Epoch: 26, Batch: 116,Loss: -2.144,Avg.Loss: -1.735,LR: 4.23E-04]Training epoch 26:  76%|███████▌  | 116/153 [00:02<00:00, 52.88it/s, Epoch: 26, Batch: 117,Loss: -1.741,Avg.Loss: -1.735,LR: 4.22E-04]Training epoch 26:  76%|███████▋  | 117/153 [00:02<00:00, 52.88it/s, Epoch: 26, Batch: 118,Loss: -1.726,Avg.Loss: -1.735,LR: 4.22E-04]Training epoch 26:  77%|███████▋  | 118/153 [00:02<00:00, 52.88it/s, Epoch: 26, Batch: 119,Loss: -1.968,Avg.Loss: -1.737,LR: 4.22E-04]Training epoch 26:  78%|███████▊  | 119/153 [00:02<00:00, 52.88it/s, Epoch: 26, Batch: 120,Loss: -1.602,Avg.Loss: -1.736,LR: 4.22E-04]Training epoch 26:  78%|███████▊  | 120/153 [00:02<00:00, 53.04it/s, Epoch: 26, Batch: 120,Loss: -1.602,Avg.Loss: -1.736,LR: 4.22E-04]Training epoch 26:  78%|███████▊  | 120/153 [00:02<00:00, 53.04it/s, Epoch: 26, Batch: 121,Loss: -1.728,Avg.Loss: -1.736,LR: 4.22E-04]Training epoch 26:  79%|███████▉  | 121/153 [00:02<00:00, 53.04it/s, Epoch: 26, Batch: 122,Loss: -2.289,Avg.Loss: -1.740,LR: 4.22E-04]Training epoch 26:  80%|███████▉  | 122/153 [00:02<00:00, 53.04it/s, Epoch: 26, Batch: 123,Loss: -2.210,Avg.Loss: -1.744,LR: 4.22E-04]Training epoch 26:  80%|████████  | 123/153 [00:02<00:00, 53.04it/s, Epoch: 26, Batch: 124,Loss: -1.670,Avg.Loss: -1.744,LR: 4.22E-04]Training epoch 26:  81%|████████  | 124/153 [00:02<00:00, 53.04it/s, Epoch: 26, Batch: 125,Loss: -2.232,Avg.Loss: -1.748,LR: 4.22E-04]Training epoch 26:  82%|████████▏ | 125/153 [00:02<00:00, 53.04it/s, Epoch: 26, Batch: 126,Loss: -2.124,Avg.Loss: -1.751,LR: 4.22E-04]Training epoch 26:  82%|████████▏ | 126/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 126,Loss: -2.124,Avg.Loss: -1.751,LR: 4.22E-04]Training epoch 26:  82%|████████▏ | 126/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 127,Loss: -2.118,Avg.Loss: -1.753,LR: 4.22E-04]Training epoch 26:  83%|████████▎ | 127/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 128,Loss: -2.072,Avg.Loss: -1.756,LR: 4.22E-04]Training epoch 26:  84%|████████▎ | 128/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 129,Loss: -1.779,Avg.Loss: -1.756,LR: 4.22E-04]Training epoch 26:  84%|████████▍ | 129/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 130,Loss: -2.558,Avg.Loss: -1.762,LR: 4.22E-04]Training epoch 26:  85%|████████▍ | 130/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 131,Loss: -2.131,Avg.Loss: -1.765,LR: 4.22E-04]Training epoch 26:  86%|████████▌ | 131/153 [00:02<00:00, 52.90it/s, Epoch: 26, Batch: 132,Loss: -2.282,Avg.Loss: -1.769,LR: 4.22E-04]Training epoch 26:  86%|████████▋ | 132/153 [00:02<00:00, 53.15it/s, Epoch: 26, Batch: 132,Loss: -2.282,Avg.Loss: -1.769,LR: 4.22E-04]Training epoch 26:  86%|████████▋ | 132/153 [00:02<00:00, 53.15it/s, Epoch: 26, Batch: 133,Loss: -2.433,Avg.Loss: -1.774,LR: 4.22E-04]Training epoch 26:  87%|████████▋ | 133/153 [00:02<00:00, 53.15it/s, Epoch: 26, Batch: 134,Loss: -2.221,Avg.Loss: -1.777,LR: 4.22E-04]Training epoch 26:  88%|████████▊ | 134/153 [00:02<00:00, 53.15it/s, Epoch: 26, Batch: 135,Loss: -2.153,Avg.Loss: -1.780,LR: 4.22E-04]Training epoch 26:  88%|████████▊ | 135/153 [00:02<00:00, 53.15it/s, Epoch: 26, Batch: 136,Loss: -1.500,Avg.Loss: -1.778,LR: 4.22E-04]Training epoch 26:  89%|████████▉ | 136/153 [00:02<00:00, 53.15it/s, Epoch: 26, Batch: 137,Loss: -1.826,Avg.Loss: -1.778,LR: 4.22E-04]Training epoch 26:  90%|████████▉ | 137/153 [00:02<00:00, 53.15it/s, Epoch: 26, Batch: 138,Loss: -2.323,Avg.Loss: -1.782,LR: 4.22E-04]Training epoch 26:  90%|█████████ | 138/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 138,Loss: -2.323,Avg.Loss: -1.782,LR: 4.22E-04]Training epoch 26:  90%|█████████ | 138/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 139,Loss: -1.876,Avg.Loss: -1.783,LR: 4.22E-04]Training epoch 26:  91%|█████████ | 139/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 140,Loss: -2.057,Avg.Loss: -1.785,LR: 4.22E-04]Training epoch 26:  92%|█████████▏| 140/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 141,Loss: -1.624,Avg.Loss: -1.784,LR: 4.22E-04]Training epoch 26:  92%|█████████▏| 141/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 142,Loss: -2.034,Avg.Loss: -1.786,LR: 4.22E-04]Training epoch 26:  93%|█████████▎| 142/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 143,Loss: -2.265,Avg.Loss: -1.789,LR: 4.22E-04]Training epoch 26:  93%|█████████▎| 143/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 144,Loss: -2.089,Avg.Loss: -1.791,LR: 4.21E-04]Training epoch 26:  94%|█████████▍| 144/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 144,Loss: -2.089,Avg.Loss: -1.791,LR: 4.21E-04]Training epoch 26:  94%|█████████▍| 144/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 145,Loss: -1.840,Avg.Loss: -1.791,LR: 4.21E-04]Training epoch 26:  95%|█████████▍| 145/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 146,Loss: -2.358,Avg.Loss: -1.795,LR: 4.21E-04]Training epoch 26:  95%|█████████▌| 146/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 147,Loss: -1.357,Avg.Loss: -1.792,LR: 4.21E-04]Training epoch 26:  96%|█████████▌| 147/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 148,Loss: -1.502,Avg.Loss: -1.790,LR: 4.21E-04]Training epoch 26:  97%|█████████▋| 148/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 149,Loss: -2.055,Avg.Loss: -1.792,LR: 4.21E-04]Training epoch 26:  97%|█████████▋| 149/153 [00:02<00:00, 53.24it/s, Epoch: 26, Batch: 150,Loss: -1.479,Avg.Loss: -1.790,LR: 4.21E-04]Training epoch 26:  98%|█████████▊| 150/153 [00:02<00:00, 53.11it/s, Epoch: 26, Batch: 150,Loss: -1.479,Avg.Loss: -1.790,LR: 4.21E-04]Training epoch 26:  98%|█████████▊| 150/153 [00:02<00:00, 53.11it/s, Epoch: 26, Batch: 151,Loss: -1.496,Avg.Loss: -1.788,LR: 4.21E-04]Training epoch 26:  99%|█████████▊| 151/153 [00:02<00:00, 53.11it/s, Epoch: 26, Batch: 152,Loss: -2.142,Avg.Loss: -1.790,LR: 4.21E-04]Training epoch 26:  99%|█████████▉| 152/153 [00:02<00:00, 53.11it/s, Epoch: 26, Batch: 153,Loss: -1.013,Avg.Loss: -1.785,LR: 4.21E-04]Training epoch 26: 100%|██████████| 153/153 [00:02<00:00, 52.94it/s, Epoch: 26, Batch: 153,Loss: -1.013,Avg.Loss: -1.785,LR: 4.21E-04]
Training epoch 27:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 27:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 27, Batch: 1,Loss: -1.166,Avg.Loss: -1.166,LR: 4.21E-04]Training epoch 27:   1%|          | 1/153 [00:00<00:04, 31.19it/s, Epoch: 27, Batch: 2,Loss: -1.722,Avg.Loss: -1.444,LR: 4.21E-04]Training epoch 27:   1%|▏         | 2/153 [00:00<00:03, 40.78it/s, Epoch: 27, Batch: 3,Loss: -1.272,Avg.Loss: -1.387,LR: 4.21E-04]Training epoch 27:   2%|▏         | 3/153 [00:00<00:03, 44.68it/s, Epoch: 27, Batch: 4,Loss: -1.494,Avg.Loss: -1.414,LR: 4.21E-04]Training epoch 27:   3%|▎         | 4/153 [00:00<00:03, 47.04it/s, Epoch: 27, Batch: 5,Loss: -1.929,Avg.Loss: -1.517,LR: 4.21E-04]Training epoch 27:   3%|▎         | 5/153 [00:00<00:03, 47.96it/s, Epoch: 27, Batch: 6,Loss: -2.147,Avg.Loss: -1.622,LR: 4.21E-04]Training epoch 27:   4%|▍         | 6/153 [00:00<00:02, 57.44it/s, Epoch: 27, Batch: 6,Loss: -2.147,Avg.Loss: -1.622,LR: 4.21E-04]Training epoch 27:   4%|▍         | 6/153 [00:00<00:02, 57.44it/s, Epoch: 27, Batch: 7,Loss: -1.693,Avg.Loss: -1.632,LR: 4.21E-04]Training epoch 27:   5%|▍         | 7/153 [00:00<00:02, 57.44it/s, Epoch: 27, Batch: 8,Loss: -1.849,Avg.Loss: -1.659,LR: 4.21E-04]Training epoch 27:   5%|▌         | 8/153 [00:00<00:02, 57.44it/s, Epoch: 27, Batch: 9,Loss: -2.296,Avg.Loss: -1.730,LR: 4.21E-04]Training epoch 27:   6%|▌         | 9/153 [00:00<00:02, 57.44it/s, Epoch: 27, Batch: 10,Loss: -1.536,Avg.Loss: -1.710,LR: 4.21E-04]Training epoch 27:   7%|▋         | 10/153 [00:00<00:02, 57.44it/s, Epoch: 27, Batch: 11,Loss: -2.181,Avg.Loss: -1.753,LR: 4.21E-04]Training epoch 27:   7%|▋         | 11/153 [00:00<00:02, 57.44it/s, Epoch: 27, Batch: 12,Loss: -1.686,Avg.Loss: -1.748,LR: 4.21E-04]Training epoch 27:   8%|▊         | 12/153 [00:00<00:02, 54.62it/s, Epoch: 27, Batch: 12,Loss: -1.686,Avg.Loss: -1.748,LR: 4.21E-04]Training epoch 27:   8%|▊         | 12/153 [00:00<00:02, 54.62it/s, Epoch: 27, Batch: 13,Loss: -2.099,Avg.Loss: -1.775,LR: 4.21E-04]Training epoch 27:   8%|▊         | 13/153 [00:00<00:02, 54.62it/s, Epoch: 27, Batch: 14,Loss: -2.094,Avg.Loss: -1.797,LR: 4.21E-04]Training epoch 27:   9%|▉         | 14/153 [00:00<00:02, 54.62it/s, Epoch: 27, Batch: 15,Loss: -2.021,Avg.Loss: -1.812,LR: 4.21E-04]Training epoch 27:  10%|▉         | 15/153 [00:00<00:02, 54.62it/s, Epoch: 27, Batch: 16,Loss: -1.984,Avg.Loss: -1.823,LR: 4.21E-04]Training epoch 27:  10%|█         | 16/153 [00:00<00:02, 54.62it/s, Epoch: 27, Batch: 17,Loss: -0.595,Avg.Loss: -1.751,LR: 4.20E-04]Training epoch 27:  11%|█         | 17/153 [00:00<00:02, 54.62it/s, Epoch: 27, Batch: 18,Loss: -0.289,Avg.Loss: -1.670,LR: 4.20E-04]Training epoch 27:  12%|█▏        | 18/153 [00:00<00:02, 54.18it/s, Epoch: 27, Batch: 18,Loss: -0.289,Avg.Loss: -1.670,LR: 4.20E-04]Training epoch 27:  12%|█▏        | 18/153 [00:00<00:02, 54.18it/s, Epoch: 27, Batch: 19,Loss: -0.657,Avg.Loss: -1.616,LR: 4.20E-04]Training epoch 27:  12%|█▏        | 19/153 [00:00<00:02, 54.18it/s, Epoch: 27, Batch: 20,Loss: -1.966,Avg.Loss: -1.634,LR: 4.20E-04]Training epoch 27:  13%|█▎        | 20/153 [00:00<00:02, 54.18it/s, Epoch: 27, Batch: 21,Loss: -1.232,Avg.Loss: -1.615,LR: 4.20E-04]Training epoch 27:  14%|█▎        | 21/153 [00:00<00:02, 54.18it/s, Epoch: 27, Batch: 22,Loss: 0.850,Avg.Loss: -1.503,LR: 4.20E-04] Training epoch 27:  14%|█▍        | 22/153 [00:00<00:02, 54.18it/s, Epoch: 27, Batch: 23,Loss: 1.511,Avg.Loss: -1.372,LR: 4.20E-04]Training epoch 27:  15%|█▌        | 23/153 [00:00<00:02, 54.18it/s, Epoch: 27, Batch: 24,Loss: -0.943,Avg.Loss: -1.354,LR: 4.20E-04]Training epoch 27:  16%|█▌        | 24/153 [00:00<00:02, 53.44it/s, Epoch: 27, Batch: 24,Loss: -0.943,Avg.Loss: -1.354,LR: 4.20E-04]Training epoch 27:  16%|█▌        | 24/153 [00:00<00:02, 53.44it/s, Epoch: 27, Batch: 25,Loss: -1.739,Avg.Loss: -1.369,LR: 4.20E-04]Training epoch 27:  16%|█▋        | 25/153 [00:00<00:02, 53.44it/s, Epoch: 27, Batch: 26,Loss: -1.689,Avg.Loss: -1.382,LR: 4.20E-04]Training epoch 27:  17%|█▋        | 26/153 [00:00<00:02, 53.44it/s, Epoch: 27, Batch: 27,Loss: -1.693,Avg.Loss: -1.393,LR: 4.20E-04]Training epoch 27:  18%|█▊        | 27/153 [00:00<00:02, 53.44it/s, Epoch: 27, Batch: 28,Loss: -2.334,Avg.Loss: -1.427,LR: 4.20E-04]Training epoch 27:  18%|█▊        | 28/153 [00:00<00:02, 53.44it/s, Epoch: 27, Batch: 29,Loss: -1.972,Avg.Loss: -1.445,LR: 4.20E-04]Training epoch 27:  19%|█▉        | 29/153 [00:00<00:02, 53.44it/s, Epoch: 27, Batch: 30,Loss: -1.718,Avg.Loss: -1.455,LR: 4.20E-04]Training epoch 27:  20%|█▉        | 30/153 [00:00<00:02, 53.03it/s, Epoch: 27, Batch: 30,Loss: -1.718,Avg.Loss: -1.455,LR: 4.20E-04]Training epoch 27:  20%|█▉        | 30/153 [00:00<00:02, 53.03it/s, Epoch: 27, Batch: 31,Loss: -2.142,Avg.Loss: -1.477,LR: 4.20E-04]Training epoch 27:  20%|██        | 31/153 [00:00<00:02, 53.03it/s, Epoch: 27, Batch: 32,Loss: -2.181,Avg.Loss: -1.499,LR: 4.20E-04]Training epoch 27:  21%|██        | 32/153 [00:00<00:02, 53.03it/s, Epoch: 27, Batch: 33,Loss: -2.043,Avg.Loss: -1.515,LR: 4.20E-04]Training epoch 27:  22%|██▏       | 33/153 [00:00<00:02, 53.03it/s, Epoch: 27, Batch: 34,Loss: -2.234,Avg.Loss: -1.536,LR: 4.20E-04]Training epoch 27:  22%|██▏       | 34/153 [00:00<00:02, 53.03it/s, Epoch: 27, Batch: 35,Loss: -1.750,Avg.Loss: -1.542,LR: 4.20E-04]Training epoch 27:  23%|██▎       | 35/153 [00:00<00:02, 53.03it/s, Epoch: 27, Batch: 36,Loss: -0.755,Avg.Loss: -1.521,LR: 4.20E-04]Training epoch 27:  24%|██▎       | 36/153 [00:00<00:02, 52.87it/s, Epoch: 27, Batch: 36,Loss: -0.755,Avg.Loss: -1.521,LR: 4.20E-04]Training epoch 27:  24%|██▎       | 36/153 [00:00<00:02, 52.87it/s, Epoch: 27, Batch: 37,Loss: -1.232,Avg.Loss: -1.513,LR: 4.20E-04]Training epoch 27:  24%|██▍       | 37/153 [00:00<00:02, 52.87it/s, Epoch: 27, Batch: 38,Loss: -1.774,Avg.Loss: -1.520,LR: 4.20E-04]Training epoch 27:  25%|██▍       | 38/153 [00:00<00:02, 52.87it/s, Epoch: 27, Batch: 39,Loss: -1.142,Avg.Loss: -1.510,LR: 4.20E-04]Training epoch 27:  25%|██▌       | 39/153 [00:00<00:02, 52.87it/s, Epoch: 27, Batch: 40,Loss: 0.313,Avg.Loss: -1.464,LR: 4.20E-04] Training epoch 27:  26%|██▌       | 40/153 [00:00<00:02, 52.87it/s, Epoch: 27, Batch: 41,Loss: -0.148,Avg.Loss: -1.432,LR: 4.20E-04]Training epoch 27:  27%|██▋       | 41/153 [00:00<00:02, 52.87it/s, Epoch: 27, Batch: 42,Loss: -1.066,Avg.Loss: -1.424,LR: 4.20E-04]Training epoch 27:  27%|██▋       | 42/153 [00:00<00:02, 52.82it/s, Epoch: 27, Batch: 42,Loss: -1.066,Avg.Loss: -1.424,LR: 4.20E-04]Training epoch 27:  27%|██▋       | 42/153 [00:00<00:02, 52.82it/s, Epoch: 27, Batch: 43,Loss: -1.190,Avg.Loss: -1.418,LR: 4.20E-04]Training epoch 27:  28%|██▊       | 43/153 [00:00<00:02, 52.82it/s, Epoch: 27, Batch: 44,Loss: -1.404,Avg.Loss: -1.418,LR: 4.19E-04]Training epoch 27:  29%|██▉       | 44/153 [00:00<00:02, 52.82it/s, Epoch: 27, Batch: 45,Loss: -1.651,Avg.Loss: -1.423,LR: 4.19E-04]Training epoch 27:  29%|██▉       | 45/153 [00:00<00:02, 52.82it/s, Epoch: 27, Batch: 46,Loss: -1.930,Avg.Loss: -1.434,LR: 4.19E-04]Training epoch 27:  30%|███       | 46/153 [00:00<00:02, 52.82it/s, Epoch: 27, Batch: 47,Loss: -1.932,Avg.Loss: -1.445,LR: 4.19E-04]Training epoch 27:  31%|███       | 47/153 [00:00<00:02, 52.82it/s, Epoch: 27, Batch: 48,Loss: -2.413,Avg.Loss: -1.465,LR: 4.19E-04]Training epoch 27:  31%|███▏      | 48/153 [00:00<00:01, 52.77it/s, Epoch: 27, Batch: 48,Loss: -2.413,Avg.Loss: -1.465,LR: 4.19E-04]Training epoch 27:  31%|███▏      | 48/153 [00:00<00:01, 52.77it/s, Epoch: 27, Batch: 49,Loss: -2.577,Avg.Loss: -1.488,LR: 4.19E-04]Training epoch 27:  32%|███▏      | 49/153 [00:00<00:01, 52.77it/s, Epoch: 27, Batch: 50,Loss: -2.026,Avg.Loss: -1.498,LR: 4.19E-04]Training epoch 27:  33%|███▎      | 50/153 [00:00<00:01, 52.77it/s, Epoch: 27, Batch: 51,Loss: -2.285,Avg.Loss: -1.514,LR: 4.19E-04]Training epoch 27:  33%|███▎      | 51/153 [00:00<00:01, 52.77it/s, Epoch: 27, Batch: 52,Loss: -1.708,Avg.Loss: -1.517,LR: 4.19E-04]Training epoch 27:  34%|███▍      | 52/153 [00:00<00:01, 52.77it/s, Epoch: 27, Batch: 53,Loss: -2.247,Avg.Loss: -1.531,LR: 4.19E-04]Training epoch 27:  35%|███▍      | 53/153 [00:01<00:01, 52.77it/s, Epoch: 27, Batch: 54,Loss: -1.661,Avg.Loss: -1.534,LR: 4.19E-04]Training epoch 27:  35%|███▌      | 54/153 [00:01<00:01, 52.68it/s, Epoch: 27, Batch: 54,Loss: -1.661,Avg.Loss: -1.534,LR: 4.19E-04]Training epoch 27:  35%|███▌      | 54/153 [00:01<00:01, 52.68it/s, Epoch: 27, Batch: 55,Loss: -1.555,Avg.Loss: -1.534,LR: 4.19E-04]Training epoch 27:  36%|███▌      | 55/153 [00:01<00:01, 52.68it/s, Epoch: 27, Batch: 56,Loss: -2.386,Avg.Loss: -1.549,LR: 4.19E-04]Training epoch 27:  37%|███▋      | 56/153 [00:01<00:01, 52.68it/s, Epoch: 27, Batch: 57,Loss: -2.369,Avg.Loss: -1.564,LR: 4.19E-04]Training epoch 27:  37%|███▋      | 57/153 [00:01<00:01, 52.68it/s, Epoch: 27, Batch: 58,Loss: -1.889,Avg.Loss: -1.569,LR: 4.19E-04]Training epoch 27:  38%|███▊      | 58/153 [00:01<00:01, 52.68it/s, Epoch: 27, Batch: 59,Loss: -2.163,Avg.Loss: -1.579,LR: 4.19E-04]Training epoch 27:  39%|███▊      | 59/153 [00:01<00:01, 52.68it/s, Epoch: 27, Batch: 60,Loss: -1.669,Avg.Loss: -1.581,LR: 4.19E-04]Training epoch 27:  39%|███▉      | 60/153 [00:01<00:01, 52.72it/s, Epoch: 27, Batch: 60,Loss: -1.669,Avg.Loss: -1.581,LR: 4.19E-04]Training epoch 27:  39%|███▉      | 60/153 [00:01<00:01, 52.72it/s, Epoch: 27, Batch: 61,Loss: -1.519,Avg.Loss: -1.580,LR: 4.19E-04]Training epoch 27:  40%|███▉      | 61/153 [00:01<00:01, 52.72it/s, Epoch: 27, Batch: 62,Loss: -1.427,Avg.Loss: -1.577,LR: 4.19E-04]Training epoch 27:  41%|████      | 62/153 [00:01<00:01, 52.72it/s, Epoch: 27, Batch: 63,Loss: -1.288,Avg.Loss: -1.573,LR: 4.19E-04]Training epoch 27:  41%|████      | 63/153 [00:01<00:01, 52.72it/s, Epoch: 27, Batch: 64,Loss: -1.433,Avg.Loss: -1.571,LR: 4.19E-04]Training epoch 27:  42%|████▏     | 64/153 [00:01<00:01, 52.72it/s, Epoch: 27, Batch: 65,Loss: -2.000,Avg.Loss: -1.577,LR: 4.19E-04]Training epoch 27:  42%|████▏     | 65/153 [00:01<00:01, 52.72it/s, Epoch: 27, Batch: 66,Loss: -1.184,Avg.Loss: -1.571,LR: 4.19E-04]Training epoch 27:  43%|████▎     | 66/153 [00:01<00:01, 52.50it/s, Epoch: 27, Batch: 66,Loss: -1.184,Avg.Loss: -1.571,LR: 4.19E-04]Training epoch 27:  43%|████▎     | 66/153 [00:01<00:01, 52.50it/s, Epoch: 27, Batch: 67,Loss: -1.457,Avg.Loss: -1.569,LR: 4.19E-04]Training epoch 27:  44%|████▍     | 67/153 [00:01<00:01, 52.50it/s, Epoch: 27, Batch: 68,Loss: -1.160,Avg.Loss: -1.563,LR: 4.19E-04]Training epoch 27:  44%|████▍     | 68/153 [00:01<00:01, 52.50it/s, Epoch: 27, Batch: 69,Loss: -1.656,Avg.Loss: -1.565,LR: 4.19E-04]Training epoch 27:  45%|████▌     | 69/153 [00:01<00:01, 52.50it/s, Epoch: 27, Batch: 70,Loss: -2.098,Avg.Loss: -1.572,LR: 4.18E-04]Training epoch 27:  46%|████▌     | 70/153 [00:01<00:01, 52.50it/s, Epoch: 27, Batch: 71,Loss: -1.626,Avg.Loss: -1.573,LR: 4.18E-04]Training epoch 27:  46%|████▋     | 71/153 [00:01<00:01, 52.50it/s, Epoch: 27, Batch: 72,Loss: -2.225,Avg.Loss: -1.582,LR: 4.18E-04]Training epoch 27:  47%|████▋     | 72/153 [00:01<00:01, 52.83it/s, Epoch: 27, Batch: 72,Loss: -2.225,Avg.Loss: -1.582,LR: 4.18E-04]Training epoch 27:  47%|████▋     | 72/153 [00:01<00:01, 52.83it/s, Epoch: 27, Batch: 73,Loss: -1.563,Avg.Loss: -1.582,LR: 4.18E-04]Training epoch 27:  48%|████▊     | 73/153 [00:01<00:01, 52.83it/s, Epoch: 27, Batch: 74,Loss: -2.055,Avg.Loss: -1.588,LR: 4.18E-04]Training epoch 27:  48%|████▊     | 74/153 [00:01<00:01, 52.83it/s, Epoch: 27, Batch: 75,Loss: -1.934,Avg.Loss: -1.593,LR: 4.18E-04]Training epoch 27:  49%|████▉     | 75/153 [00:01<00:01, 52.83it/s, Epoch: 27, Batch: 76,Loss: -1.690,Avg.Loss: -1.594,LR: 4.18E-04]Training epoch 27:  50%|████▉     | 76/153 [00:01<00:01, 52.83it/s, Epoch: 27, Batch: 77,Loss: -1.501,Avg.Loss: -1.593,LR: 4.18E-04]Training epoch 27:  50%|█████     | 77/153 [00:01<00:01, 52.83it/s, Epoch: 27, Batch: 78,Loss: -2.065,Avg.Loss: -1.599,LR: 4.18E-04]Training epoch 27:  51%|█████     | 78/153 [00:01<00:01, 52.60it/s, Epoch: 27, Batch: 78,Loss: -2.065,Avg.Loss: -1.599,LR: 4.18E-04]Training epoch 27:  51%|█████     | 78/153 [00:01<00:01, 52.60it/s, Epoch: 27, Batch: 79,Loss: -2.334,Avg.Loss: -1.608,LR: 4.18E-04]Training epoch 27:  52%|█████▏    | 79/153 [00:01<00:01, 52.60it/s, Epoch: 27, Batch: 80,Loss: -2.047,Avg.Loss: -1.614,LR: 4.18E-04]Training epoch 27:  52%|█████▏    | 80/153 [00:01<00:01, 52.60it/s, Epoch: 27, Batch: 81,Loss: -1.916,Avg.Loss: -1.618,LR: 4.18E-04]Training epoch 27:  53%|█████▎    | 81/153 [00:01<00:01, 52.60it/s, Epoch: 27, Batch: 82,Loss: -0.431,Avg.Loss: -1.603,LR: 4.18E-04]Training epoch 27:  54%|█████▎    | 82/153 [00:01<00:01, 52.60it/s, Epoch: 27, Batch: 83,Loss: -2.025,Avg.Loss: -1.608,LR: 4.18E-04]Training epoch 27:  54%|█████▍    | 83/153 [00:01<00:01, 52.60it/s, Epoch: 27, Batch: 84,Loss: -1.906,Avg.Loss: -1.612,LR: 4.18E-04]Training epoch 27:  55%|█████▍    | 84/153 [00:01<00:01, 52.75it/s, Epoch: 27, Batch: 84,Loss: -1.906,Avg.Loss: -1.612,LR: 4.18E-04]Training epoch 27:  55%|█████▍    | 84/153 [00:01<00:01, 52.75it/s, Epoch: 27, Batch: 85,Loss: -1.563,Avg.Loss: -1.611,LR: 4.18E-04]Training epoch 27:  56%|█████▌    | 85/153 [00:01<00:01, 52.75it/s, Epoch: 27, Batch: 86,Loss: -1.675,Avg.Loss: -1.612,LR: 4.18E-04]Training epoch 27:  56%|█████▌    | 86/153 [00:01<00:01, 52.75it/s, Epoch: 27, Batch: 87,Loss: -2.647,Avg.Loss: -1.624,LR: 4.18E-04]Training epoch 27:  57%|█████▋    | 87/153 [00:01<00:01, 52.75it/s, Epoch: 27, Batch: 88,Loss: -1.636,Avg.Loss: -1.624,LR: 4.18E-04]Training epoch 27:  58%|█████▊    | 88/153 [00:01<00:01, 52.75it/s, Epoch: 27, Batch: 89,Loss: -0.909,Avg.Loss: -1.616,LR: 4.18E-04]Training epoch 27:  58%|█████▊    | 89/153 [00:01<00:01, 52.75it/s, Epoch: 27, Batch: 90,Loss: -1.494,Avg.Loss: -1.615,LR: 4.18E-04]Training epoch 27:  59%|█████▉    | 90/153 [00:01<00:01, 52.69it/s, Epoch: 27, Batch: 90,Loss: -1.494,Avg.Loss: -1.615,LR: 4.18E-04]Training epoch 27:  59%|█████▉    | 90/153 [00:01<00:01, 52.69it/s, Epoch: 27, Batch: 91,Loss: -0.588,Avg.Loss: -1.603,LR: 4.18E-04]Training epoch 27:  59%|█████▉    | 91/153 [00:01<00:01, 52.69it/s, Epoch: 27, Batch: 92,Loss: -0.724,Avg.Loss: -1.594,LR: 4.18E-04]Training epoch 27:  60%|██████    | 92/153 [00:01<00:01, 52.69it/s, Epoch: 27, Batch: 93,Loss: -0.257,Avg.Loss: -1.579,LR: 4.18E-04]Training epoch 27:  61%|██████    | 93/153 [00:01<00:01, 52.69it/s, Epoch: 27, Batch: 94,Loss: -1.449,Avg.Loss: -1.578,LR: 4.18E-04]Training epoch 27:  61%|██████▏   | 94/153 [00:01<00:01, 52.69it/s, Epoch: 27, Batch: 95,Loss: -0.525,Avg.Loss: -1.567,LR: 4.18E-04]Training epoch 27:  62%|██████▏   | 95/153 [00:01<00:01, 52.69it/s, Epoch: 27, Batch: 96,Loss: -0.707,Avg.Loss: -1.558,LR: 4.18E-04]Training epoch 27:  63%|██████▎   | 96/153 [00:01<00:01, 52.88it/s, Epoch: 27, Batch: 96,Loss: -0.707,Avg.Loss: -1.558,LR: 4.18E-04]Training epoch 27:  63%|██████▎   | 96/153 [00:01<00:01, 52.88it/s, Epoch: 27, Batch: 97,Loss: 0.771,Avg.Loss: -1.534,LR: 4.17E-04] Training epoch 27:  63%|██████▎   | 97/153 [00:01<00:01, 52.88it/s, Epoch: 27, Batch: 98,Loss: -2.218,Avg.Loss: -1.541,LR: 4.17E-04]Training epoch 27:  64%|██████▍   | 98/153 [00:01<00:01, 52.88it/s, Epoch: 27, Batch: 99,Loss: -2.047,Avg.Loss: -1.546,LR: 4.17E-04]Training epoch 27:  65%|██████▍   | 99/153 [00:01<00:01, 52.88it/s, Epoch: 27, Batch: 100,Loss: -1.681,Avg.Loss: -1.547,LR: 4.17E-04]Training epoch 27:  65%|██████▌   | 100/153 [00:01<00:01, 52.88it/s, Epoch: 27, Batch: 101,Loss: -2.204,Avg.Loss: -1.554,LR: 4.17E-04]Training epoch 27:  66%|██████▌   | 101/153 [00:01<00:00, 52.88it/s, Epoch: 27, Batch: 102,Loss: -1.582,Avg.Loss: -1.554,LR: 4.17E-04]Training epoch 27:  67%|██████▋   | 102/153 [00:01<00:00, 52.96it/s, Epoch: 27, Batch: 102,Loss: -1.582,Avg.Loss: -1.554,LR: 4.17E-04]Training epoch 27:  67%|██████▋   | 102/153 [00:01<00:00, 52.96it/s, Epoch: 27, Batch: 103,Loss: -1.746,Avg.Loss: -1.556,LR: 4.17E-04]Training epoch 27:  67%|██████▋   | 103/153 [00:01<00:00, 52.96it/s, Epoch: 27, Batch: 104,Loss: -2.076,Avg.Loss: -1.561,LR: 4.17E-04]Training epoch 27:  68%|██████▊   | 104/153 [00:01<00:00, 52.96it/s, Epoch: 27, Batch: 105,Loss: -2.258,Avg.Loss: -1.568,LR: 4.17E-04]Training epoch 27:  69%|██████▊   | 105/153 [00:01<00:00, 52.96it/s, Epoch: 27, Batch: 106,Loss: -1.421,Avg.Loss: -1.566,LR: 4.17E-04]Training epoch 27:  69%|██████▉   | 106/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 107,Loss: -1.812,Avg.Loss: -1.569,LR: 4.17E-04]Training epoch 27:  70%|██████▉   | 107/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 108,Loss: -1.871,Avg.Loss: -1.571,LR: 4.17E-04]Training epoch 27:  71%|███████   | 108/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 108,Loss: -1.871,Avg.Loss: -1.571,LR: 4.17E-04]Training epoch 27:  71%|███████   | 108/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 109,Loss: -1.540,Avg.Loss: -1.571,LR: 4.17E-04]Training epoch 27:  71%|███████   | 109/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 110,Loss: -2.166,Avg.Loss: -1.577,LR: 4.17E-04]Training epoch 27:  72%|███████▏  | 110/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 111,Loss: -2.386,Avg.Loss: -1.584,LR: 4.17E-04]Training epoch 27:  73%|███████▎  | 111/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 112,Loss: -1.990,Avg.Loss: -1.587,LR: 4.17E-04]Training epoch 27:  73%|███████▎  | 112/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 113,Loss: -2.534,Avg.Loss: -1.596,LR: 4.17E-04]Training epoch 27:  74%|███████▍  | 113/153 [00:02<00:00, 52.96it/s, Epoch: 27, Batch: 114,Loss: -2.148,Avg.Loss: -1.601,LR: 4.17E-04]Training epoch 27:  75%|███████▍  | 114/153 [00:02<00:00, 52.94it/s, Epoch: 27, Batch: 114,Loss: -2.148,Avg.Loss: -1.601,LR: 4.17E-04]Training epoch 27:  75%|███████▍  | 114/153 [00:02<00:00, 52.94it/s, Epoch: 27, Batch: 115,Loss: -2.450,Avg.Loss: -1.608,LR: 4.17E-04]Training epoch 27:  75%|███████▌  | 115/153 [00:02<00:00, 52.94it/s, Epoch: 27, Batch: 116,Loss: -1.720,Avg.Loss: -1.609,LR: 4.17E-04]Training epoch 27:  76%|███████▌  | 116/153 [00:02<00:00, 52.94it/s, Epoch: 27, Batch: 117,Loss: -2.006,Avg.Loss: -1.612,LR: 4.17E-04]Training epoch 27:  76%|███████▋  | 117/153 [00:02<00:00, 52.94it/s, Epoch: 27, Batch: 118,Loss: -2.173,Avg.Loss: -1.617,LR: 4.17E-04]Training epoch 27:  77%|███████▋  | 118/153 [00:02<00:00, 52.94it/s, Epoch: 27, Batch: 119,Loss: -2.244,Avg.Loss: -1.622,LR: 4.17E-04]Training epoch 27:  78%|███████▊  | 119/153 [00:02<00:00, 52.94it/s, Epoch: 27, Batch: 120,Loss: -1.943,Avg.Loss: -1.625,LR: 4.17E-04]Training epoch 27:  78%|███████▊  | 120/153 [00:02<00:00, 53.15it/s, Epoch: 27, Batch: 120,Loss: -1.943,Avg.Loss: -1.625,LR: 4.17E-04]Training epoch 27:  78%|███████▊  | 120/153 [00:02<00:00, 53.15it/s, Epoch: 27, Batch: 121,Loss: -2.084,Avg.Loss: -1.629,LR: 4.17E-04]Training epoch 27:  79%|███████▉  | 121/153 [00:02<00:00, 53.15it/s, Epoch: 27, Batch: 122,Loss: -2.024,Avg.Loss: -1.632,LR: 4.17E-04]Training epoch 27:  80%|███████▉  | 122/153 [00:02<00:00, 53.15it/s, Epoch: 27, Batch: 123,Loss: -1.721,Avg.Loss: -1.633,LR: 4.16E-04]Training epoch 27:  80%|████████  | 123/153 [00:02<00:00, 53.15it/s, Epoch: 27, Batch: 124,Loss: -1.778,Avg.Loss: -1.634,LR: 4.16E-04]Training epoch 27:  81%|████████  | 124/153 [00:02<00:00, 53.15it/s, Epoch: 27, Batch: 125,Loss: -0.725,Avg.Loss: -1.627,LR: 4.16E-04]Training epoch 27:  82%|████████▏ | 125/153 [00:02<00:00, 53.15it/s, Epoch: 27, Batch: 126,Loss: -0.424,Avg.Loss: -1.617,LR: 4.16E-04]Training epoch 27:  82%|████████▏ | 126/153 [00:02<00:00, 53.30it/s, Epoch: 27, Batch: 126,Loss: -0.424,Avg.Loss: -1.617,LR: 4.16E-04]Training epoch 27:  82%|████████▏ | 126/153 [00:02<00:00, 53.30it/s, Epoch: 27, Batch: 127,Loss: -0.926,Avg.Loss: -1.612,LR: 4.16E-04]Training epoch 27:  83%|████████▎ | 127/153 [00:02<00:00, 53.30it/s, Epoch: 27, Batch: 128,Loss: -1.802,Avg.Loss: -1.613,LR: 4.16E-04]Training epoch 27:  84%|████████▎ | 128/153 [00:02<00:00, 53.30it/s, Epoch: 27, Batch: 129,Loss: -1.877,Avg.Loss: -1.615,LR: 4.16E-04]Training epoch 27:  84%|████████▍ | 129/153 [00:02<00:00, 53.30it/s, Epoch: 27, Batch: 130,Loss: -0.760,Avg.Loss: -1.609,LR: 4.16E-04]Training epoch 27:  85%|████████▍ | 130/153 [00:02<00:00, 53.30it/s, Epoch: 27, Batch: 131,Loss: -0.444,Avg.Loss: -1.600,LR: 4.16E-04]Training epoch 27:  86%|████████▌ | 131/153 [00:02<00:00, 53.30it/s, Epoch: 27, Batch: 132,Loss: -0.378,Avg.Loss: -1.591,LR: 4.16E-04]Training epoch 27:  86%|████████▋ | 132/153 [00:02<00:00, 53.34it/s, Epoch: 27, Batch: 132,Loss: -0.378,Avg.Loss: -1.591,LR: 4.16E-04]Training epoch 27:  86%|████████▋ | 132/153 [00:02<00:00, 53.34it/s, Epoch: 27, Batch: 133,Loss: -1.727,Avg.Loss: -1.592,LR: 4.16E-04]Training epoch 27:  87%|████████▋ | 133/153 [00:02<00:00, 53.34it/s, Epoch: 27, Batch: 134,Loss: -1.047,Avg.Loss: -1.588,LR: 4.16E-04]Training epoch 27:  88%|████████▊ | 134/153 [00:02<00:00, 53.34it/s, Epoch: 27, Batch: 135,Loss: 0.007,Avg.Loss: -1.576,LR: 4.16E-04] Training epoch 27:  88%|████████▊ | 135/153 [00:02<00:00, 53.34it/s, Epoch: 27, Batch: 136,Loss: 1.581,Avg.Loss: -1.552,LR: 4.16E-04]Training epoch 27:  89%|████████▉ | 136/153 [00:02<00:00, 53.34it/s, Epoch: 27, Batch: 137,Loss: 0.834,Avg.Loss: -1.535,LR: 4.16E-04]Training epoch 27:  90%|████████▉ | 137/153 [00:02<00:00, 53.34it/s, Epoch: 27, Batch: 138,Loss: 1.541,Avg.Loss: -1.513,LR: 4.16E-04]Training epoch 27:  90%|█████████ | 138/153 [00:02<00:00, 53.42it/s, Epoch: 27, Batch: 138,Loss: 1.541,Avg.Loss: -1.513,LR: 4.16E-04]Training epoch 27:  90%|█████████ | 138/153 [00:02<00:00, 53.42it/s, Epoch: 27, Batch: 139,Loss: -0.210,Avg.Loss: -1.503,LR: 4.16E-04]Training epoch 27:  91%|█████████ | 139/153 [00:02<00:00, 53.42it/s, Epoch: 27, Batch: 140,Loss: -1.522,Avg.Loss: -1.504,LR: 4.16E-04]Training epoch 27:  92%|█████████▏| 140/153 [00:02<00:00, 53.42it/s, Epoch: 27, Batch: 141,Loss: -1.335,Avg.Loss: -1.502,LR: 4.16E-04]Training epoch 27:  92%|█████████▏| 141/153 [00:02<00:00, 53.42it/s, Epoch: 27, Batch: 142,Loss: -1.405,Avg.Loss: -1.502,LR: 4.16E-04]Training epoch 27:  93%|█████████▎| 142/153 [00:02<00:00, 53.42it/s, Epoch: 27, Batch: 143,Loss: -0.787,Avg.Loss: -1.497,LR: 4.16E-04]Training epoch 27:  93%|█████████▎| 143/153 [00:02<00:00, 53.42it/s, Epoch: 27, Batch: 144,Loss: -0.318,Avg.Loss: -1.488,LR: 4.16E-04]Training epoch 27:  94%|█████████▍| 144/153 [00:02<00:00, 53.22it/s, Epoch: 27, Batch: 144,Loss: -0.318,Avg.Loss: -1.488,LR: 4.16E-04]Training epoch 27:  94%|█████████▍| 144/153 [00:02<00:00, 53.22it/s, Epoch: 27, Batch: 145,Loss: -1.123,Avg.Loss: -1.486,LR: 4.16E-04]Training epoch 27:  95%|█████████▍| 145/153 [00:02<00:00, 53.22it/s, Epoch: 27, Batch: 146,Loss: -1.648,Avg.Loss: -1.487,LR: 4.16E-04]Training epoch 27:  95%|█████████▌| 146/153 [00:02<00:00, 53.22it/s, Epoch: 27, Batch: 147,Loss: -1.474,Avg.Loss: -1.487,LR: 4.16E-04]Training epoch 27:  96%|█████████▌| 147/153 [00:02<00:00, 53.22it/s, Epoch: 27, Batch: 148,Loss: -1.272,Avg.Loss: -1.486,LR: 4.16E-04]Training epoch 27:  97%|█████████▋| 148/153 [00:02<00:00, 53.22it/s, Epoch: 27, Batch: 149,Loss: -0.552,Avg.Loss: -1.479,LR: 4.15E-04]Training epoch 27:  97%|█████████▋| 149/153 [00:02<00:00, 53.22it/s, Epoch: 27, Batch: 150,Loss: 0.076,Avg.Loss: -1.469,LR: 4.15E-04] Training epoch 27:  98%|█████████▊| 150/153 [00:02<00:00, 53.26it/s, Epoch: 27, Batch: 150,Loss: 0.076,Avg.Loss: -1.469,LR: 4.15E-04]Training epoch 27:  98%|█████████▊| 150/153 [00:02<00:00, 53.26it/s, Epoch: 27, Batch: 151,Loss: -0.655,Avg.Loss: -1.464,LR: 4.15E-04]Training epoch 27:  99%|█████████▊| 151/153 [00:02<00:00, 53.26it/s, Epoch: 27, Batch: 152,Loss: -1.144,Avg.Loss: -1.461,LR: 4.15E-04]Training epoch 27:  99%|█████████▉| 152/153 [00:02<00:00, 53.26it/s, Epoch: 27, Batch: 153,Loss: -0.999,Avg.Loss: -1.458,LR: 4.15E-04]Training epoch 27: 100%|██████████| 153/153 [00:02<00:00, 53.06it/s, Epoch: 27, Batch: 153,Loss: -0.999,Avg.Loss: -1.458,LR: 4.15E-04]
Training epoch 28:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 28:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 28, Batch: 1,Loss: -2.003,Avg.Loss: -2.003,LR: 4.15E-04]Training epoch 28:   1%|          | 1/153 [00:00<00:06, 23.07it/s, Epoch: 28, Batch: 2,Loss: -1.087,Avg.Loss: -1.545,LR: 4.15E-04]Training epoch 28:   1%|▏         | 2/153 [00:00<00:04, 31.98it/s, Epoch: 28, Batch: 3,Loss: -0.825,Avg.Loss: -1.305,LR: 4.15E-04]Training epoch 28:   2%|▏         | 3/153 [00:00<00:03, 38.55it/s, Epoch: 28, Batch: 4,Loss: -0.680,Avg.Loss: -1.149,LR: 4.15E-04]Training epoch 28:   3%|▎         | 4/153 [00:00<00:03, 41.10it/s, Epoch: 28, Batch: 5,Loss: -0.635,Avg.Loss: -1.046,LR: 4.15E-04]Training epoch 28:   3%|▎         | 5/153 [00:00<00:03, 42.85it/s, Epoch: 28, Batch: 6,Loss: -0.580,Avg.Loss: -0.968,LR: 4.15E-04]Training epoch 28:   4%|▍         | 6/153 [00:00<00:02, 51.34it/s, Epoch: 28, Batch: 6,Loss: -0.580,Avg.Loss: -0.968,LR: 4.15E-04]Training epoch 28:   4%|▍         | 6/153 [00:00<00:02, 51.34it/s, Epoch: 28, Batch: 7,Loss: -0.305,Avg.Loss: -0.874,LR: 4.15E-04]Training epoch 28:   5%|▍         | 7/153 [00:00<00:02, 51.34it/s, Epoch: 28, Batch: 8,Loss: -1.682,Avg.Loss: -0.975,LR: 4.15E-04]Training epoch 28:   5%|▌         | 8/153 [00:00<00:02, 51.34it/s, Epoch: 28, Batch: 9,Loss: -1.876,Avg.Loss: -1.075,LR: 4.15E-04]Training epoch 28:   6%|▌         | 9/153 [00:00<00:02, 51.34it/s, Epoch: 28, Batch: 10,Loss: -1.675,Avg.Loss: -1.135,LR: 4.15E-04]Training epoch 28:   7%|▋         | 10/153 [00:00<00:02, 51.34it/s, Epoch: 28, Batch: 11,Loss: -1.506,Avg.Loss: -1.169,LR: 4.15E-04]Training epoch 28:   7%|▋         | 11/153 [00:00<00:02, 51.34it/s, Epoch: 28, Batch: 12,Loss: -1.399,Avg.Loss: -1.188,LR: 4.15E-04]Training epoch 28:   8%|▊         | 12/153 [00:00<00:02, 51.95it/s, Epoch: 28, Batch: 12,Loss: -1.399,Avg.Loss: -1.188,LR: 4.15E-04]Training epoch 28:   8%|▊         | 12/153 [00:00<00:02, 51.95it/s, Epoch: 28, Batch: 13,Loss: -1.408,Avg.Loss: -1.205,LR: 4.15E-04]Training epoch 28:   8%|▊         | 13/153 [00:00<00:02, 51.95it/s, Epoch: 28, Batch: 14,Loss: -0.727,Avg.Loss: -1.171,LR: 4.15E-04]Training epoch 28:   9%|▉         | 14/153 [00:00<00:02, 51.95it/s, Epoch: 28, Batch: 15,Loss: -1.042,Avg.Loss: -1.162,LR: 4.15E-04]Training epoch 28:  10%|▉         | 15/153 [00:00<00:02, 51.95it/s, Epoch: 28, Batch: 16,Loss: -1.689,Avg.Loss: -1.195,LR: 4.15E-04]Training epoch 28:  10%|█         | 16/153 [00:00<00:02, 51.95it/s, Epoch: 28, Batch: 17,Loss: -1.863,Avg.Loss: -1.234,LR: 4.15E-04]Training epoch 28:  11%|█         | 17/153 [00:00<00:02, 51.95it/s, Epoch: 28, Batch: 18,Loss: -1.302,Avg.Loss: -1.238,LR: 4.15E-04]Training epoch 28:  12%|█▏        | 18/153 [00:00<00:02, 52.20it/s, Epoch: 28, Batch: 18,Loss: -1.302,Avg.Loss: -1.238,LR: 4.15E-04]Training epoch 28:  12%|█▏        | 18/153 [00:00<00:02, 52.20it/s, Epoch: 28, Batch: 19,Loss: -1.207,Avg.Loss: -1.236,LR: 4.15E-04]Training epoch 28:  12%|█▏        | 19/153 [00:00<00:02, 52.20it/s, Epoch: 28, Batch: 20,Loss: -1.490,Avg.Loss: -1.249,LR: 4.15E-04]Training epoch 28:  13%|█▎        | 20/153 [00:00<00:02, 52.20it/s, Epoch: 28, Batch: 21,Loss: -1.704,Avg.Loss: -1.271,LR: 4.15E-04]Training epoch 28:  14%|█▎        | 21/153 [00:00<00:02, 52.20it/s, Epoch: 28, Batch: 22,Loss: -1.748,Avg.Loss: -1.292,LR: 4.14E-04]Training epoch 28:  14%|█▍        | 22/153 [00:00<00:02, 52.20it/s, Epoch: 28, Batch: 23,Loss: -1.882,Avg.Loss: -1.318,LR: 4.14E-04]Training epoch 28:  15%|█▌        | 23/153 [00:00<00:02, 52.20it/s, Epoch: 28, Batch: 24,Loss: -1.790,Avg.Loss: -1.338,LR: 4.14E-04]Training epoch 28:  16%|█▌        | 24/153 [00:00<00:02, 51.90it/s, Epoch: 28, Batch: 24,Loss: -1.790,Avg.Loss: -1.338,LR: 4.14E-04]Training epoch 28:  16%|█▌        | 24/153 [00:00<00:02, 51.90it/s, Epoch: 28, Batch: 25,Loss: -1.959,Avg.Loss: -1.363,LR: 4.14E-04]Training epoch 28:  16%|█▋        | 25/153 [00:00<00:02, 51.90it/s, Epoch: 28, Batch: 26,Loss: -1.455,Avg.Loss: -1.366,LR: 4.14E-04]Training epoch 28:  17%|█▋        | 26/153 [00:00<00:02, 51.90it/s, Epoch: 28, Batch: 27,Loss: -1.391,Avg.Loss: -1.367,LR: 4.14E-04]Training epoch 28:  18%|█▊        | 27/153 [00:00<00:02, 51.90it/s, Epoch: 28, Batch: 28,Loss: -1.730,Avg.Loss: -1.380,LR: 4.14E-04]Training epoch 28:  18%|█▊        | 28/153 [00:00<00:02, 51.90it/s, Epoch: 28, Batch: 29,Loss: -1.999,Avg.Loss: -1.401,LR: 4.14E-04]Training epoch 28:  19%|█▉        | 29/153 [00:00<00:02, 51.90it/s, Epoch: 28, Batch: 30,Loss: -1.499,Avg.Loss: -1.405,LR: 4.14E-04]Training epoch 28:  20%|█▉        | 30/153 [00:00<00:02, 51.54it/s, Epoch: 28, Batch: 30,Loss: -1.499,Avg.Loss: -1.405,LR: 4.14E-04]Training epoch 28:  20%|█▉        | 30/153 [00:00<00:02, 51.54it/s, Epoch: 28, Batch: 31,Loss: -2.126,Avg.Loss: -1.428,LR: 4.14E-04]Training epoch 28:  20%|██        | 31/153 [00:00<00:02, 51.54it/s, Epoch: 28, Batch: 32,Loss: -1.784,Avg.Loss: -1.439,LR: 4.14E-04]Training epoch 28:  21%|██        | 32/153 [00:00<00:02, 51.54it/s, Epoch: 28, Batch: 33,Loss: -1.345,Avg.Loss: -1.436,LR: 4.14E-04]Training epoch 28:  22%|██▏       | 33/153 [00:00<00:02, 51.54it/s, Epoch: 28, Batch: 34,Loss: -1.788,Avg.Loss: -1.447,LR: 4.14E-04]Training epoch 28:  22%|██▏       | 34/153 [00:00<00:02, 51.54it/s, Epoch: 28, Batch: 35,Loss: -2.250,Avg.Loss: -1.469,LR: 4.14E-04]Training epoch 28:  23%|██▎       | 35/153 [00:00<00:02, 51.54it/s, Epoch: 28, Batch: 36,Loss: -1.849,Avg.Loss: -1.480,LR: 4.14E-04]Training epoch 28:  24%|██▎       | 36/153 [00:00<00:02, 52.01it/s, Epoch: 28, Batch: 36,Loss: -1.849,Avg.Loss: -1.480,LR: 4.14E-04]Training epoch 28:  24%|██▎       | 36/153 [00:00<00:02, 52.01it/s, Epoch: 28, Batch: 37,Loss: -1.862,Avg.Loss: -1.490,LR: 4.14E-04]Training epoch 28:  24%|██▍       | 37/153 [00:00<00:02, 52.01it/s, Epoch: 28, Batch: 38,Loss: -1.538,Avg.Loss: -1.492,LR: 4.14E-04]Training epoch 28:  25%|██▍       | 38/153 [00:00<00:02, 52.01it/s, Epoch: 28, Batch: 39,Loss: -1.598,Avg.Loss: -1.494,LR: 4.14E-04]Training epoch 28:  25%|██▌       | 39/153 [00:00<00:02, 52.01it/s, Epoch: 28, Batch: 40,Loss: -1.580,Avg.Loss: -1.497,LR: 4.14E-04]Training epoch 28:  26%|██▌       | 40/153 [00:00<00:02, 52.01it/s, Epoch: 28, Batch: 41,Loss: -1.955,Avg.Loss: -1.508,LR: 4.14E-04]Training epoch 28:  27%|██▋       | 41/153 [00:00<00:02, 52.01it/s, Epoch: 28, Batch: 42,Loss: -2.290,Avg.Loss: -1.526,LR: 4.14E-04]Training epoch 28:  27%|██▋       | 42/153 [00:00<00:02, 52.51it/s, Epoch: 28, Batch: 42,Loss: -2.290,Avg.Loss: -1.526,LR: 4.14E-04]Training epoch 28:  27%|██▋       | 42/153 [00:00<00:02, 52.51it/s, Epoch: 28, Batch: 43,Loss: -2.023,Avg.Loss: -1.538,LR: 4.14E-04]Training epoch 28:  28%|██▊       | 43/153 [00:00<00:02, 52.51it/s, Epoch: 28, Batch: 44,Loss: -1.707,Avg.Loss: -1.542,LR: 4.14E-04]Training epoch 28:  29%|██▉       | 44/153 [00:00<00:02, 52.51it/s, Epoch: 28, Batch: 45,Loss: -1.447,Avg.Loss: -1.540,LR: 4.14E-04]Training epoch 28:  29%|██▉       | 45/153 [00:00<00:02, 52.51it/s, Epoch: 28, Batch: 46,Loss: -1.855,Avg.Loss: -1.546,LR: 4.14E-04]Training epoch 28:  30%|███       | 46/153 [00:00<00:02, 52.51it/s, Epoch: 28, Batch: 47,Loss: -2.511,Avg.Loss: -1.567,LR: 4.14E-04]Training epoch 28:  31%|███       | 47/153 [00:00<00:02, 52.51it/s, Epoch: 28, Batch: 48,Loss: -1.404,Avg.Loss: -1.564,LR: 4.13E-04]Training epoch 28:  31%|███▏      | 48/153 [00:00<00:01, 52.90it/s, Epoch: 28, Batch: 48,Loss: -1.404,Avg.Loss: -1.564,LR: 4.13E-04]Training epoch 28:  31%|███▏      | 48/153 [00:00<00:01, 52.90it/s, Epoch: 28, Batch: 49,Loss: -2.210,Avg.Loss: -1.577,LR: 4.13E-04]Training epoch 28:  32%|███▏      | 49/153 [00:00<00:01, 52.90it/s, Epoch: 28, Batch: 50,Loss: -2.111,Avg.Loss: -1.587,LR: 4.13E-04]Training epoch 28:  33%|███▎      | 50/153 [00:00<00:01, 52.90it/s, Epoch: 28, Batch: 51,Loss: -1.681,Avg.Loss: -1.589,LR: 4.13E-04]Training epoch 28:  33%|███▎      | 51/153 [00:00<00:01, 52.90it/s, Epoch: 28, Batch: 52,Loss: -2.109,Avg.Loss: -1.599,LR: 4.13E-04]Training epoch 28:  34%|███▍      | 52/153 [00:01<00:01, 52.90it/s, Epoch: 28, Batch: 53,Loss: -2.127,Avg.Loss: -1.609,LR: 4.13E-04]Training epoch 28:  35%|███▍      | 53/153 [00:01<00:01, 52.90it/s, Epoch: 28, Batch: 54,Loss: -1.941,Avg.Loss: -1.615,LR: 4.13E-04]Training epoch 28:  35%|███▌      | 54/153 [00:01<00:01, 53.06it/s, Epoch: 28, Batch: 54,Loss: -1.941,Avg.Loss: -1.615,LR: 4.13E-04]Training epoch 28:  35%|███▌      | 54/153 [00:01<00:01, 53.06it/s, Epoch: 28, Batch: 55,Loss: -2.033,Avg.Loss: -1.623,LR: 4.13E-04]Training epoch 28:  36%|███▌      | 55/153 [00:01<00:01, 53.06it/s, Epoch: 28, Batch: 56,Loss: -1.504,Avg.Loss: -1.621,LR: 4.13E-04]Training epoch 28:  37%|███▋      | 56/153 [00:01<00:01, 53.06it/s, Epoch: 28, Batch: 57,Loss: -0.950,Avg.Loss: -1.609,LR: 4.13E-04]Training epoch 28:  37%|███▋      | 57/153 [00:01<00:01, 53.06it/s, Epoch: 28, Batch: 58,Loss: -1.557,Avg.Loss: -1.608,LR: 4.13E-04]Training epoch 28:  38%|███▊      | 58/153 [00:01<00:01, 53.06it/s, Epoch: 28, Batch: 59,Loss: -2.121,Avg.Loss: -1.617,LR: 4.13E-04]Training epoch 28:  39%|███▊      | 59/153 [00:01<00:01, 53.06it/s, Epoch: 28, Batch: 60,Loss: -2.370,Avg.Loss: -1.629,LR: 4.13E-04]Training epoch 28:  39%|███▉      | 60/153 [00:01<00:01, 53.34it/s, Epoch: 28, Batch: 60,Loss: -2.370,Avg.Loss: -1.629,LR: 4.13E-04]Training epoch 28:  39%|███▉      | 60/153 [00:01<00:01, 53.34it/s, Epoch: 28, Batch: 61,Loss: -1.741,Avg.Loss: -1.631,LR: 4.13E-04]Training epoch 28:  40%|███▉      | 61/153 [00:01<00:01, 53.34it/s, Epoch: 28, Batch: 62,Loss: -1.802,Avg.Loss: -1.634,LR: 4.13E-04]Training epoch 28:  41%|████      | 62/153 [00:01<00:01, 53.34it/s, Epoch: 28, Batch: 63,Loss: -1.940,Avg.Loss: -1.639,LR: 4.13E-04]Training epoch 28:  41%|████      | 63/153 [00:01<00:01, 53.34it/s, Epoch: 28, Batch: 64,Loss: -2.326,Avg.Loss: -1.650,LR: 4.13E-04]Training epoch 28:  42%|████▏     | 64/153 [00:01<00:01, 53.34it/s, Epoch: 28, Batch: 65,Loss: -2.331,Avg.Loss: -1.660,LR: 4.13E-04]Training epoch 28:  42%|████▏     | 65/153 [00:01<00:01, 53.34it/s, Epoch: 28, Batch: 66,Loss: -1.897,Avg.Loss: -1.664,LR: 4.13E-04]Training epoch 28:  43%|████▎     | 66/153 [00:01<00:01, 53.41it/s, Epoch: 28, Batch: 66,Loss: -1.897,Avg.Loss: -1.664,LR: 4.13E-04]Training epoch 28:  43%|████▎     | 66/153 [00:01<00:01, 53.41it/s, Epoch: 28, Batch: 67,Loss: -2.259,Avg.Loss: -1.673,LR: 4.13E-04]Training epoch 28:  44%|████▍     | 67/153 [00:01<00:01, 53.41it/s, Epoch: 28, Batch: 68,Loss: -2.315,Avg.Loss: -1.682,LR: 4.13E-04]Training epoch 28:  44%|████▍     | 68/153 [00:01<00:01, 53.41it/s, Epoch: 28, Batch: 69,Loss: -1.780,Avg.Loss: -1.683,LR: 4.13E-04]Training epoch 28:  45%|████▌     | 69/153 [00:01<00:01, 53.41it/s, Epoch: 28, Batch: 70,Loss: -2.168,Avg.Loss: -1.690,LR: 4.13E-04]Training epoch 28:  46%|████▌     | 70/153 [00:01<00:01, 53.41it/s, Epoch: 28, Batch: 71,Loss: -2.152,Avg.Loss: -1.697,LR: 4.13E-04]Training epoch 28:  46%|████▋     | 71/153 [00:01<00:01, 53.41it/s, Epoch: 28, Batch: 72,Loss: -1.950,Avg.Loss: -1.700,LR: 4.13E-04]Training epoch 28:  47%|████▋     | 72/153 [00:01<00:01, 53.47it/s, Epoch: 28, Batch: 72,Loss: -1.950,Avg.Loss: -1.700,LR: 4.13E-04]Training epoch 28:  47%|████▋     | 72/153 [00:01<00:01, 53.47it/s, Epoch: 28, Batch: 73,Loss: -2.471,Avg.Loss: -1.711,LR: 4.12E-04]Training epoch 28:  48%|████▊     | 73/153 [00:01<00:01, 53.47it/s, Epoch: 28, Batch: 74,Loss: -1.749,Avg.Loss: -1.711,LR: 4.12E-04]Training epoch 28:  48%|████▊     | 74/153 [00:01<00:01, 53.47it/s, Epoch: 28, Batch: 75,Loss: -1.622,Avg.Loss: -1.710,LR: 4.12E-04]Training epoch 28:  49%|████▉     | 75/153 [00:01<00:01, 53.47it/s, Epoch: 28, Batch: 76,Loss: -1.786,Avg.Loss: -1.711,LR: 4.12E-04]Training epoch 28:  50%|████▉     | 76/153 [00:01<00:01, 53.47it/s, Epoch: 28, Batch: 77,Loss: -1.796,Avg.Loss: -1.712,LR: 4.12E-04]Training epoch 28:  50%|█████     | 77/153 [00:01<00:01, 53.47it/s, Epoch: 28, Batch: 78,Loss: -1.853,Avg.Loss: -1.714,LR: 4.12E-04]Training epoch 28:  51%|█████     | 78/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 78,Loss: -1.853,Avg.Loss: -1.714,LR: 4.12E-04]Training epoch 28:  51%|█████     | 78/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 79,Loss: -1.787,Avg.Loss: -1.715,LR: 4.12E-04]Training epoch 28:  52%|█████▏    | 79/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 80,Loss: -2.195,Avg.Loss: -1.721,LR: 4.12E-04]Training epoch 28:  52%|█████▏    | 80/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 81,Loss: -2.452,Avg.Loss: -1.730,LR: 4.12E-04]Training epoch 28:  53%|█████▎    | 81/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 82,Loss: -2.163,Avg.Loss: -1.735,LR: 4.12E-04]Training epoch 28:  54%|█████▎    | 82/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 83,Loss: -1.626,Avg.Loss: -1.734,LR: 4.12E-04]Training epoch 28:  54%|█████▍    | 83/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 84,Loss: -1.519,Avg.Loss: -1.732,LR: 4.12E-04]Training epoch 28:  55%|█████▍    | 84/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 84,Loss: -1.519,Avg.Loss: -1.732,LR: 4.12E-04]Training epoch 28:  55%|█████▍    | 84/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 85,Loss: -2.019,Avg.Loss: -1.735,LR: 4.12E-04]Training epoch 28:  56%|█████▌    | 85/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 86,Loss: -1.916,Avg.Loss: -1.737,LR: 4.12E-04]Training epoch 28:  56%|█████▌    | 86/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 87,Loss: -1.653,Avg.Loss: -1.736,LR: 4.12E-04]Training epoch 28:  57%|█████▋    | 87/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 88,Loss: -1.510,Avg.Loss: -1.733,LR: 4.12E-04]Training epoch 28:  58%|█████▊    | 88/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 89,Loss: -2.103,Avg.Loss: -1.738,LR: 4.12E-04]Training epoch 28:  58%|█████▊    | 89/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 90,Loss: -1.615,Avg.Loss: -1.736,LR: 4.12E-04]Training epoch 28:  59%|█████▉    | 90/153 [00:01<00:01, 53.49it/s, Epoch: 28, Batch: 90,Loss: -1.615,Avg.Loss: -1.736,LR: 4.12E-04]Training epoch 28:  59%|█████▉    | 90/153 [00:01<00:01, 53.49it/s, Epoch: 28, Batch: 91,Loss: -2.198,Avg.Loss: -1.741,LR: 4.12E-04]Training epoch 28:  59%|█████▉    | 91/153 [00:01<00:01, 53.49it/s, Epoch: 28, Batch: 92,Loss: -2.049,Avg.Loss: -1.745,LR: 4.12E-04]Training epoch 28:  60%|██████    | 92/153 [00:01<00:01, 53.49it/s, Epoch: 28, Batch: 93,Loss: -1.791,Avg.Loss: -1.745,LR: 4.12E-04]Training epoch 28:  61%|██████    | 93/153 [00:01<00:01, 53.49it/s, Epoch: 28, Batch: 94,Loss: -2.079,Avg.Loss: -1.749,LR: 4.12E-04]Training epoch 28:  61%|██████▏   | 94/153 [00:01<00:01, 53.49it/s, Epoch: 28, Batch: 95,Loss: -1.811,Avg.Loss: -1.749,LR: 4.12E-04]Training epoch 28:  62%|██████▏   | 95/153 [00:01<00:01, 53.49it/s, Epoch: 28, Batch: 96,Loss: -1.283,Avg.Loss: -1.745,LR: 4.12E-04]Training epoch 28:  63%|██████▎   | 96/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 96,Loss: -1.283,Avg.Loss: -1.745,LR: 4.12E-04]Training epoch 28:  63%|██████▎   | 96/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 97,Loss: -2.056,Avg.Loss: -1.748,LR: 4.12E-04]Training epoch 28:  63%|██████▎   | 97/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 98,Loss: -1.301,Avg.Loss: -1.743,LR: 4.12E-04]Training epoch 28:  64%|██████▍   | 98/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 99,Loss: -1.201,Avg.Loss: -1.738,LR: 4.11E-04]Training epoch 28:  65%|██████▍   | 99/153 [00:01<00:01, 53.50it/s, Epoch: 28, Batch: 100,Loss: -1.261,Avg.Loss: -1.733,LR: 4.11E-04]Training epoch 28:  65%|██████▌   | 100/153 [00:01<00:00, 53.50it/s, Epoch: 28, Batch: 101,Loss: -0.970,Avg.Loss: -1.725,LR: 4.11E-04]Training epoch 28:  66%|██████▌   | 101/153 [00:01<00:00, 53.50it/s, Epoch: 28, Batch: 102,Loss: -1.439,Avg.Loss: -1.723,LR: 4.11E-04]Training epoch 28:  67%|██████▋   | 102/153 [00:01<00:00, 53.41it/s, Epoch: 28, Batch: 102,Loss: -1.439,Avg.Loss: -1.723,LR: 4.11E-04]Training epoch 28:  67%|██████▋   | 102/153 [00:01<00:00, 53.41it/s, Epoch: 28, Batch: 103,Loss: -1.795,Avg.Loss: -1.723,LR: 4.11E-04]Training epoch 28:  67%|██████▋   | 103/153 [00:01<00:00, 53.41it/s, Epoch: 28, Batch: 104,Loss: -1.581,Avg.Loss: -1.722,LR: 4.11E-04]Training epoch 28:  68%|██████▊   | 104/153 [00:01<00:00, 53.41it/s, Epoch: 28, Batch: 105,Loss: -1.790,Avg.Loss: -1.723,LR: 4.11E-04]Training epoch 28:  69%|██████▊   | 105/153 [00:01<00:00, 53.41it/s, Epoch: 28, Batch: 106,Loss: -2.012,Avg.Loss: -1.725,LR: 4.11E-04]Training epoch 28:  69%|██████▉   | 106/153 [00:02<00:00, 53.41it/s, Epoch: 28, Batch: 107,Loss: -1.385,Avg.Loss: -1.722,LR: 4.11E-04]Training epoch 28:  70%|██████▉   | 107/153 [00:02<00:00, 53.41it/s, Epoch: 28, Batch: 108,Loss: -0.852,Avg.Loss: -1.714,LR: 4.11E-04]Training epoch 28:  71%|███████   | 108/153 [00:02<00:00, 54.22it/s, Epoch: 28, Batch: 108,Loss: -0.852,Avg.Loss: -1.714,LR: 4.11E-04]Training epoch 28:  71%|███████   | 108/153 [00:02<00:00, 54.22it/s, Epoch: 28, Batch: 109,Loss: -1.509,Avg.Loss: -1.712,LR: 4.11E-04]Training epoch 28:  71%|███████   | 109/153 [00:02<00:00, 54.22it/s, Epoch: 28, Batch: 110,Loss: -2.474,Avg.Loss: -1.719,LR: 4.11E-04]Training epoch 28:  72%|███████▏  | 110/153 [00:02<00:00, 54.22it/s, Epoch: 28, Batch: 111,Loss: -2.158,Avg.Loss: -1.723,LR: 4.11E-04]Training epoch 28:  73%|███████▎  | 111/153 [00:02<00:00, 54.22it/s, Epoch: 28, Batch: 112,Loss: -2.294,Avg.Loss: -1.728,LR: 4.11E-04]Training epoch 28:  73%|███████▎  | 112/153 [00:02<00:00, 54.22it/s, Epoch: 28, Batch: 113,Loss: -2.102,Avg.Loss: -1.731,LR: 4.11E-04]Training epoch 28:  74%|███████▍  | 113/153 [00:02<00:00, 54.22it/s, Epoch: 28, Batch: 114,Loss: -2.085,Avg.Loss: -1.735,LR: 4.11E-04]Training epoch 28:  75%|███████▍  | 114/153 [00:02<00:00, 54.20it/s, Epoch: 28, Batch: 114,Loss: -2.085,Avg.Loss: -1.735,LR: 4.11E-04]Training epoch 28:  75%|███████▍  | 114/153 [00:02<00:00, 54.20it/s, Epoch: 28, Batch: 115,Loss: -1.978,Avg.Loss: -1.737,LR: 4.11E-04]Training epoch 28:  75%|███████▌  | 115/153 [00:02<00:00, 54.20it/s, Epoch: 28, Batch: 116,Loss: -2.137,Avg.Loss: -1.740,LR: 4.11E-04]Training epoch 28:  76%|███████▌  | 116/153 [00:02<00:00, 54.20it/s, Epoch: 28, Batch: 117,Loss: -2.144,Avg.Loss: -1.744,LR: 4.11E-04]Training epoch 28:  76%|███████▋  | 117/153 [00:02<00:00, 54.20it/s, Epoch: 28, Batch: 118,Loss: -1.631,Avg.Loss: -1.743,LR: 4.11E-04]Training epoch 28:  77%|███████▋  | 118/153 [00:02<00:00, 54.20it/s, Epoch: 28, Batch: 119,Loss: -1.833,Avg.Loss: -1.743,LR: 4.11E-04]Training epoch 28:  78%|███████▊  | 119/153 [00:02<00:00, 54.20it/s, Epoch: 28, Batch: 120,Loss: -1.126,Avg.Loss: -1.738,LR: 4.11E-04]Training epoch 28:  78%|███████▊  | 120/153 [00:02<00:00, 54.40it/s, Epoch: 28, Batch: 120,Loss: -1.126,Avg.Loss: -1.738,LR: 4.11E-04]Training epoch 28:  78%|███████▊  | 120/153 [00:02<00:00, 54.40it/s, Epoch: 28, Batch: 121,Loss: -1.955,Avg.Loss: -1.740,LR: 4.11E-04]Training epoch 28:  79%|███████▉  | 121/153 [00:02<00:00, 54.40it/s, Epoch: 28, Batch: 122,Loss: -2.217,Avg.Loss: -1.744,LR: 4.11E-04]Training epoch 28:  80%|███████▉  | 122/153 [00:02<00:00, 54.40it/s, Epoch: 28, Batch: 123,Loss: -1.853,Avg.Loss: -1.745,LR: 4.11E-04]Training epoch 28:  80%|████████  | 123/153 [00:02<00:00, 54.40it/s, Epoch: 28, Batch: 124,Loss: -1.571,Avg.Loss: -1.743,LR: 4.11E-04]Training epoch 28:  81%|████████  | 124/153 [00:02<00:00, 54.40it/s, Epoch: 28, Batch: 125,Loss: -1.795,Avg.Loss: -1.744,LR: 4.10E-04]Training epoch 28:  82%|████████▏ | 125/153 [00:02<00:00, 54.40it/s, Epoch: 28, Batch: 126,Loss: -2.054,Avg.Loss: -1.746,LR: 4.10E-04]Training epoch 28:  82%|████████▏ | 126/153 [00:02<00:00, 54.08it/s, Epoch: 28, Batch: 126,Loss: -2.054,Avg.Loss: -1.746,LR: 4.10E-04]Training epoch 28:  82%|████████▏ | 126/153 [00:02<00:00, 54.08it/s, Epoch: 28, Batch: 127,Loss: -1.843,Avg.Loss: -1.747,LR: 4.10E-04]Training epoch 28:  83%|████████▎ | 127/153 [00:02<00:00, 54.08it/s, Epoch: 28, Batch: 128,Loss: -1.952,Avg.Loss: -1.749,LR: 4.10E-04]Training epoch 28:  84%|████████▎ | 128/153 [00:02<00:00, 54.08it/s, Epoch: 28, Batch: 129,Loss: -1.961,Avg.Loss: -1.750,LR: 4.10E-04]Training epoch 28:  84%|████████▍ | 129/153 [00:02<00:00, 54.08it/s, Epoch: 28, Batch: 130,Loss: -2.124,Avg.Loss: -1.753,LR: 4.10E-04]Training epoch 28:  85%|████████▍ | 130/153 [00:02<00:00, 54.08it/s, Epoch: 28, Batch: 131,Loss: -1.543,Avg.Loss: -1.752,LR: 4.10E-04]Training epoch 28:  86%|████████▌ | 131/153 [00:02<00:00, 54.08it/s, Epoch: 28, Batch: 132,Loss: -1.720,Avg.Loss: -1.751,LR: 4.10E-04]Training epoch 28:  86%|████████▋ | 132/153 [00:02<00:00, 53.87it/s, Epoch: 28, Batch: 132,Loss: -1.720,Avg.Loss: -1.751,LR: 4.10E-04]Training epoch 28:  86%|████████▋ | 132/153 [00:02<00:00, 53.87it/s, Epoch: 28, Batch: 133,Loss: -2.274,Avg.Loss: -1.755,LR: 4.10E-04]Training epoch 28:  87%|████████▋ | 133/153 [00:02<00:00, 53.87it/s, Epoch: 28, Batch: 134,Loss: -2.098,Avg.Loss: -1.758,LR: 4.10E-04]Training epoch 28:  88%|████████▊ | 134/153 [00:02<00:00, 53.87it/s, Epoch: 28, Batch: 135,Loss: -2.348,Avg.Loss: -1.762,LR: 4.10E-04]Training epoch 28:  88%|████████▊ | 135/153 [00:02<00:00, 53.87it/s, Epoch: 28, Batch: 136,Loss: -1.810,Avg.Loss: -1.763,LR: 4.10E-04]Training epoch 28:  89%|████████▉ | 136/153 [00:02<00:00, 53.87it/s, Epoch: 28, Batch: 137,Loss: -1.742,Avg.Loss: -1.762,LR: 4.10E-04]Training epoch 28:  90%|████████▉ | 137/153 [00:02<00:00, 53.87it/s, Epoch: 28, Batch: 138,Loss: -1.539,Avg.Loss: -1.761,LR: 4.10E-04]Training epoch 28:  90%|█████████ | 138/153 [00:02<00:00, 53.83it/s, Epoch: 28, Batch: 138,Loss: -1.539,Avg.Loss: -1.761,LR: 4.10E-04]Training epoch 28:  90%|█████████ | 138/153 [00:02<00:00, 53.83it/s, Epoch: 28, Batch: 139,Loss: -2.043,Avg.Loss: -1.763,LR: 4.10E-04]Training epoch 28:  91%|█████████ | 139/153 [00:02<00:00, 53.83it/s, Epoch: 28, Batch: 140,Loss: -1.600,Avg.Loss: -1.762,LR: 4.10E-04]Training epoch 28:  92%|█████████▏| 140/153 [00:02<00:00, 53.83it/s, Epoch: 28, Batch: 141,Loss: -2.480,Avg.Loss: -1.767,LR: 4.10E-04]Training epoch 28:  92%|█████████▏| 141/153 [00:02<00:00, 53.83it/s, Epoch: 28, Batch: 142,Loss: -1.730,Avg.Loss: -1.766,LR: 4.10E-04]Training epoch 28:  93%|█████████▎| 142/153 [00:02<00:00, 53.83it/s, Epoch: 28, Batch: 143,Loss: -2.134,Avg.Loss: -1.769,LR: 4.10E-04]Training epoch 28:  93%|█████████▎| 143/153 [00:02<00:00, 53.83it/s, Epoch: 28, Batch: 144,Loss: -1.630,Avg.Loss: -1.768,LR: 4.10E-04]Training epoch 28:  94%|█████████▍| 144/153 [00:02<00:00, 53.65it/s, Epoch: 28, Batch: 144,Loss: -1.630,Avg.Loss: -1.768,LR: 4.10E-04]Training epoch 28:  94%|█████████▍| 144/153 [00:02<00:00, 53.65it/s, Epoch: 28, Batch: 145,Loss: -1.846,Avg.Loss: -1.769,LR: 4.10E-04]Training epoch 28:  95%|█████████▍| 145/153 [00:02<00:00, 53.65it/s, Epoch: 28, Batch: 146,Loss: -2.099,Avg.Loss: -1.771,LR: 4.10E-04]Training epoch 28:  95%|█████████▌| 146/153 [00:02<00:00, 53.65it/s, Epoch: 28, Batch: 147,Loss: -2.415,Avg.Loss: -1.775,LR: 4.10E-04]Training epoch 28:  96%|█████████▌| 147/153 [00:02<00:00, 53.65it/s, Epoch: 28, Batch: 148,Loss: -2.300,Avg.Loss: -1.779,LR: 4.10E-04]Training epoch 28:  97%|█████████▋| 148/153 [00:02<00:00, 53.65it/s, Epoch: 28, Batch: 149,Loss: -2.076,Avg.Loss: -1.781,LR: 4.10E-04]Training epoch 28:  97%|█████████▋| 149/153 [00:02<00:00, 53.65it/s, Epoch: 28, Batch: 150,Loss: -2.293,Avg.Loss: -1.784,LR: 4.09E-04]Training epoch 28:  98%|█████████▊| 150/153 [00:02<00:00, 53.47it/s, Epoch: 28, Batch: 150,Loss: -2.293,Avg.Loss: -1.784,LR: 4.09E-04]Training epoch 28:  98%|█████████▊| 150/153 [00:02<00:00, 53.47it/s, Epoch: 28, Batch: 151,Loss: -1.041,Avg.Loss: -1.779,LR: 4.09E-04]Training epoch 28:  99%|█████████▊| 151/153 [00:02<00:00, 53.47it/s, Epoch: 28, Batch: 152,Loss: -0.855,Avg.Loss: -1.773,LR: 4.09E-04]Training epoch 28:  99%|█████████▉| 152/153 [00:02<00:00, 53.47it/s, Epoch: 28, Batch: 153,Loss: -0.116,Avg.Loss: -1.762,LR: 4.09E-04]Training epoch 28: 100%|██████████| 153/153 [00:02<00:00, 53.23it/s, Epoch: 28, Batch: 153,Loss: -0.116,Avg.Loss: -1.762,LR: 4.09E-04]
Training epoch 29:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 29:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 29, Batch: 1,Loss: -1.445,Avg.Loss: -1.445,LR: 4.09E-04]Training epoch 29:   1%|          | 1/153 [00:00<00:06, 24.98it/s, Epoch: 29, Batch: 2,Loss: -1.217,Avg.Loss: -1.331,LR: 4.09E-04]Training epoch 29:   1%|▏         | 2/153 [00:00<00:04, 35.04it/s, Epoch: 29, Batch: 3,Loss: -1.152,Avg.Loss: -1.271,LR: 4.09E-04]Training epoch 29:   2%|▏         | 3/153 [00:00<00:03, 42.60it/s, Epoch: 29, Batch: 4,Loss: -1.423,Avg.Loss: -1.309,LR: 4.09E-04]Training epoch 29:   3%|▎         | 4/153 [00:00<00:03, 45.48it/s, Epoch: 29, Batch: 5,Loss: -1.050,Avg.Loss: -1.257,LR: 4.09E-04]Training epoch 29:   3%|▎         | 5/153 [00:00<00:03, 48.58it/s, Epoch: 29, Batch: 6,Loss: -1.090,Avg.Loss: -1.230,LR: 4.09E-04]Training epoch 29:   4%|▍         | 6/153 [00:00<00:02, 58.19it/s, Epoch: 29, Batch: 6,Loss: -1.090,Avg.Loss: -1.230,LR: 4.09E-04]Training epoch 29:   4%|▍         | 6/153 [00:00<00:02, 58.19it/s, Epoch: 29, Batch: 7,Loss: -1.255,Avg.Loss: -1.233,LR: 4.09E-04]Training epoch 29:   5%|▍         | 7/153 [00:00<00:02, 58.19it/s, Epoch: 29, Batch: 8,Loss: -1.666,Avg.Loss: -1.287,LR: 4.09E-04]Training epoch 29:   5%|▌         | 8/153 [00:00<00:02, 58.19it/s, Epoch: 29, Batch: 9,Loss: -1.113,Avg.Loss: -1.268,LR: 4.09E-04]Training epoch 29:   6%|▌         | 9/153 [00:00<00:02, 58.19it/s, Epoch: 29, Batch: 10,Loss: -1.847,Avg.Loss: -1.326,LR: 4.09E-04]Training epoch 29:   7%|▋         | 10/153 [00:00<00:02, 58.19it/s, Epoch: 29, Batch: 11,Loss: -1.312,Avg.Loss: -1.325,LR: 4.09E-04]Training epoch 29:   7%|▋         | 11/153 [00:00<00:02, 58.19it/s, Epoch: 29, Batch: 12,Loss: -0.384,Avg.Loss: -1.246,LR: 4.09E-04]Training epoch 29:   8%|▊         | 12/153 [00:00<00:02, 55.47it/s, Epoch: 29, Batch: 12,Loss: -0.384,Avg.Loss: -1.246,LR: 4.09E-04]Training epoch 29:   8%|▊         | 12/153 [00:00<00:02, 55.47it/s, Epoch: 29, Batch: 13,Loss: -0.422,Avg.Loss: -1.183,LR: 4.09E-04]Training epoch 29:   8%|▊         | 13/153 [00:00<00:02, 55.47it/s, Epoch: 29, Batch: 14,Loss: -1.744,Avg.Loss: -1.223,LR: 4.09E-04]Training epoch 29:   9%|▉         | 14/153 [00:00<00:02, 55.47it/s, Epoch: 29, Batch: 15,Loss: -1.555,Avg.Loss: -1.245,LR: 4.09E-04]Training epoch 29:  10%|▉         | 15/153 [00:00<00:02, 55.47it/s, Epoch: 29, Batch: 16,Loss: -1.984,Avg.Loss: -1.291,LR: 4.09E-04]Training epoch 29:  10%|█         | 16/153 [00:00<00:02, 55.47it/s, Epoch: 29, Batch: 17,Loss: -1.747,Avg.Loss: -1.318,LR: 4.09E-04]Training epoch 29:  11%|█         | 17/153 [00:00<00:02, 55.47it/s, Epoch: 29, Batch: 18,Loss: -1.671,Avg.Loss: -1.338,LR: 4.09E-04]Training epoch 29:  12%|█▏        | 18/153 [00:00<00:02, 54.70it/s, Epoch: 29, Batch: 18,Loss: -1.671,Avg.Loss: -1.338,LR: 4.09E-04]Training epoch 29:  12%|█▏        | 18/153 [00:00<00:02, 54.70it/s, Epoch: 29, Batch: 19,Loss: -1.366,Avg.Loss: -1.339,LR: 4.09E-04]Training epoch 29:  12%|█▏        | 19/153 [00:00<00:02, 54.70it/s, Epoch: 29, Batch: 20,Loss: -1.170,Avg.Loss: -1.331,LR: 4.09E-04]Training epoch 29:  13%|█▎        | 20/153 [00:00<00:02, 54.70it/s, Epoch: 29, Batch: 21,Loss: -1.787,Avg.Loss: -1.352,LR: 4.09E-04]Training epoch 29:  14%|█▎        | 21/153 [00:00<00:02, 54.70it/s, Epoch: 29, Batch: 22,Loss: -1.993,Avg.Loss: -1.382,LR: 4.08E-04]Training epoch 29:  14%|█▍        | 22/153 [00:00<00:02, 54.70it/s, Epoch: 29, Batch: 23,Loss: -0.395,Avg.Loss: -1.339,LR: 4.08E-04]Training epoch 29:  15%|█▌        | 23/153 [00:00<00:02, 54.70it/s, Epoch: 29, Batch: 24,Loss: -0.425,Avg.Loss: -1.301,LR: 4.08E-04]Training epoch 29:  16%|█▌        | 24/153 [00:00<00:02, 53.68it/s, Epoch: 29, Batch: 24,Loss: -0.425,Avg.Loss: -1.301,LR: 4.08E-04]Training epoch 29:  16%|█▌        | 24/153 [00:00<00:02, 53.68it/s, Epoch: 29, Batch: 25,Loss: -0.430,Avg.Loss: -1.266,LR: 4.08E-04]Training epoch 29:  16%|█▋        | 25/153 [00:00<00:02, 53.68it/s, Epoch: 29, Batch: 26,Loss: -1.253,Avg.Loss: -1.265,LR: 4.08E-04]Training epoch 29:  17%|█▋        | 26/153 [00:00<00:02, 53.68it/s, Epoch: 29, Batch: 27,Loss: -1.848,Avg.Loss: -1.287,LR: 4.08E-04]Training epoch 29:  18%|█▊        | 27/153 [00:00<00:02, 53.68it/s, Epoch: 29, Batch: 28,Loss: -1.680,Avg.Loss: -1.301,LR: 4.08E-04]Training epoch 29:  18%|█▊        | 28/153 [00:00<00:02, 53.68it/s, Epoch: 29, Batch: 29,Loss: -1.295,Avg.Loss: -1.301,LR: 4.08E-04]Training epoch 29:  19%|█▉        | 29/153 [00:00<00:02, 53.68it/s, Epoch: 29, Batch: 30,Loss: -0.406,Avg.Loss: -1.271,LR: 4.08E-04]Training epoch 29:  20%|█▉        | 30/153 [00:00<00:02, 52.89it/s, Epoch: 29, Batch: 30,Loss: -0.406,Avg.Loss: -1.271,LR: 4.08E-04]Training epoch 29:  20%|█▉        | 30/153 [00:00<00:02, 52.89it/s, Epoch: 29, Batch: 31,Loss: -0.587,Avg.Loss: -1.249,LR: 4.08E-04]Training epoch 29:  20%|██        | 31/153 [00:00<00:02, 52.89it/s, Epoch: 29, Batch: 32,Loss: 0.591,Avg.Loss: -1.191,LR: 4.08E-04] Training epoch 29:  21%|██        | 32/153 [00:00<00:02, 52.89it/s, Epoch: 29, Batch: 33,Loss: 2.460,Avg.Loss: -1.081,LR: 4.08E-04]Training epoch 29:  22%|██▏       | 33/153 [00:00<00:02, 52.89it/s, Epoch: 29, Batch: 34,Loss: 0.630,Avg.Loss: -1.030,LR: 4.08E-04]Training epoch 29:  22%|██▏       | 34/153 [00:00<00:02, 52.89it/s, Epoch: 29, Batch: 35,Loss: -0.218,Avg.Loss: -1.007,LR: 4.08E-04]Training epoch 29:  23%|██▎       | 35/153 [00:00<00:02, 52.89it/s, Epoch: 29, Batch: 36,Loss: -0.489,Avg.Loss: -0.993,LR: 4.08E-04]Training epoch 29:  24%|██▎       | 36/153 [00:00<00:02, 52.63it/s, Epoch: 29, Batch: 36,Loss: -0.489,Avg.Loss: -0.993,LR: 4.08E-04]Training epoch 29:  24%|██▎       | 36/153 [00:00<00:02, 52.63it/s, Epoch: 29, Batch: 37,Loss: 0.667,Avg.Loss: -0.948,LR: 4.08E-04] Training epoch 29:  24%|██▍       | 37/153 [00:00<00:02, 52.63it/s, Epoch: 29, Batch: 38,Loss: 0.353,Avg.Loss: -0.914,LR: 4.08E-04]Training epoch 29:  25%|██▍       | 38/153 [00:00<00:02, 52.63it/s, Epoch: 29, Batch: 39,Loss: -1.648,Avg.Loss: -0.932,LR: 4.08E-04]Training epoch 29:  25%|██▌       | 39/153 [00:00<00:02, 52.63it/s, Epoch: 29, Batch: 40,Loss: -0.526,Avg.Loss: -0.922,LR: 4.08E-04]Training epoch 29:  26%|██▌       | 40/153 [00:00<00:02, 52.63it/s, Epoch: 29, Batch: 41,Loss: 0.915,Avg.Loss: -0.877,LR: 4.08E-04] Training epoch 29:  27%|██▋       | 41/153 [00:00<00:02, 52.63it/s, Epoch: 29, Batch: 42,Loss: 1.548,Avg.Loss: -0.820,LR: 4.08E-04]Training epoch 29:  27%|██▋       | 42/153 [00:00<00:02, 53.15it/s, Epoch: 29, Batch: 42,Loss: 1.548,Avg.Loss: -0.820,LR: 4.08E-04]Training epoch 29:  27%|██▋       | 42/153 [00:00<00:02, 53.15it/s, Epoch: 29, Batch: 43,Loss: -0.672,Avg.Loss: -0.816,LR: 4.08E-04]Training epoch 29:  28%|██▊       | 43/153 [00:00<00:02, 53.15it/s, Epoch: 29, Batch: 44,Loss: -1.043,Avg.Loss: -0.821,LR: 4.08E-04]Training epoch 29:  29%|██▉       | 44/153 [00:00<00:02, 53.15it/s, Epoch: 29, Batch: 45,Loss: -1.242,Avg.Loss: -0.831,LR: 4.08E-04]Training epoch 29:  29%|██▉       | 45/153 [00:00<00:02, 53.15it/s, Epoch: 29, Batch: 46,Loss: -0.943,Avg.Loss: -0.833,LR: 4.08E-04]Training epoch 29:  30%|███       | 46/153 [00:00<00:02, 53.15it/s, Epoch: 29, Batch: 47,Loss: -1.662,Avg.Loss: -0.851,LR: 4.07E-04]Training epoch 29:  31%|███       | 47/153 [00:00<00:01, 53.15it/s, Epoch: 29, Batch: 48,Loss: -1.723,Avg.Loss: -0.869,LR: 4.07E-04]Training epoch 29:  31%|███▏      | 48/153 [00:00<00:01, 53.38it/s, Epoch: 29, Batch: 48,Loss: -1.723,Avg.Loss: -0.869,LR: 4.07E-04]Training epoch 29:  31%|███▏      | 48/153 [00:00<00:01, 53.38it/s, Epoch: 29, Batch: 49,Loss: -2.045,Avg.Loss: -0.893,LR: 4.07E-04]Training epoch 29:  32%|███▏      | 49/153 [00:00<00:01, 53.38it/s, Epoch: 29, Batch: 50,Loss: -1.595,Avg.Loss: -0.907,LR: 4.07E-04]Training epoch 29:  33%|███▎      | 50/153 [00:00<00:01, 53.38it/s, Epoch: 29, Batch: 51,Loss: -1.320,Avg.Loss: -0.915,LR: 4.07E-04]Training epoch 29:  33%|███▎      | 51/153 [00:00<00:01, 53.38it/s, Epoch: 29, Batch: 52,Loss: -2.017,Avg.Loss: -0.936,LR: 4.07E-04]Training epoch 29:  34%|███▍      | 52/153 [00:00<00:01, 53.38it/s, Epoch: 29, Batch: 53,Loss: -1.840,Avg.Loss: -0.953,LR: 4.07E-04]Training epoch 29:  35%|███▍      | 53/153 [00:01<00:01, 53.38it/s, Epoch: 29, Batch: 54,Loss: -1.542,Avg.Loss: -0.964,LR: 4.07E-04]Training epoch 29:  35%|███▌      | 54/153 [00:01<00:01, 53.66it/s, Epoch: 29, Batch: 54,Loss: -1.542,Avg.Loss: -0.964,LR: 4.07E-04]Training epoch 29:  35%|███▌      | 54/153 [00:01<00:01, 53.66it/s, Epoch: 29, Batch: 55,Loss: -1.332,Avg.Loss: -0.971,LR: 4.07E-04]Training epoch 29:  36%|███▌      | 55/153 [00:01<00:01, 53.66it/s, Epoch: 29, Batch: 56,Loss: -1.209,Avg.Loss: -0.975,LR: 4.07E-04]Training epoch 29:  37%|███▋      | 56/153 [00:01<00:01, 53.66it/s, Epoch: 29, Batch: 57,Loss: -1.032,Avg.Loss: -0.976,LR: 4.07E-04]Training epoch 29:  37%|███▋      | 57/153 [00:01<00:01, 53.66it/s, Epoch: 29, Batch: 58,Loss: -1.244,Avg.Loss: -0.981,LR: 4.07E-04]Training epoch 29:  38%|███▊      | 58/153 [00:01<00:01, 53.66it/s, Epoch: 29, Batch: 59,Loss: -1.958,Avg.Loss: -0.997,LR: 4.07E-04]Training epoch 29:  39%|███▊      | 59/153 [00:01<00:01, 53.66it/s, Epoch: 29, Batch: 60,Loss: -2.026,Avg.Loss: -1.015,LR: 4.07E-04]Training epoch 29:  39%|███▉      | 60/153 [00:01<00:01, 53.79it/s, Epoch: 29, Batch: 60,Loss: -2.026,Avg.Loss: -1.015,LR: 4.07E-04]Training epoch 29:  39%|███▉      | 60/153 [00:01<00:01, 53.79it/s, Epoch: 29, Batch: 61,Loss: -1.814,Avg.Loss: -1.028,LR: 4.07E-04]Training epoch 29:  40%|███▉      | 61/153 [00:01<00:01, 53.79it/s, Epoch: 29, Batch: 62,Loss: -1.989,Avg.Loss: -1.043,LR: 4.07E-04]Training epoch 29:  41%|████      | 62/153 [00:01<00:01, 53.79it/s, Epoch: 29, Batch: 63,Loss: -1.683,Avg.Loss: -1.053,LR: 4.07E-04]Training epoch 29:  41%|████      | 63/153 [00:01<00:01, 53.79it/s, Epoch: 29, Batch: 64,Loss: -1.419,Avg.Loss: -1.059,LR: 4.07E-04]Training epoch 29:  42%|████▏     | 64/153 [00:01<00:01, 53.79it/s, Epoch: 29, Batch: 65,Loss: -1.454,Avg.Loss: -1.065,LR: 4.07E-04]Training epoch 29:  42%|████▏     | 65/153 [00:01<00:01, 53.79it/s, Epoch: 29, Batch: 66,Loss: -1.479,Avg.Loss: -1.071,LR: 4.07E-04]Training epoch 29:  43%|████▎     | 66/153 [00:01<00:01, 53.73it/s, Epoch: 29, Batch: 66,Loss: -1.479,Avg.Loss: -1.071,LR: 4.07E-04]Training epoch 29:  43%|████▎     | 66/153 [00:01<00:01, 53.73it/s, Epoch: 29, Batch: 67,Loss: -2.074,Avg.Loss: -1.086,LR: 4.07E-04]Training epoch 29:  44%|████▍     | 67/153 [00:01<00:01, 53.73it/s, Epoch: 29, Batch: 68,Loss: -2.156,Avg.Loss: -1.102,LR: 4.07E-04]Training epoch 29:  44%|████▍     | 68/153 [00:01<00:01, 53.73it/s, Epoch: 29, Batch: 69,Loss: -1.503,Avg.Loss: -1.108,LR: 4.07E-04]Training epoch 29:  45%|████▌     | 69/153 [00:01<00:01, 53.73it/s, Epoch: 29, Batch: 70,Loss: -1.749,Avg.Loss: -1.117,LR: 4.07E-04]Training epoch 29:  46%|████▌     | 70/153 [00:01<00:01, 53.73it/s, Epoch: 29, Batch: 71,Loss: -1.556,Avg.Loss: -1.123,LR: 4.07E-04]Training epoch 29:  46%|████▋     | 71/153 [00:01<00:01, 53.73it/s, Epoch: 29, Batch: 72,Loss: -1.527,Avg.Loss: -1.129,LR: 4.06E-04]Training epoch 29:  47%|████▋     | 72/153 [00:01<00:01, 53.67it/s, Epoch: 29, Batch: 72,Loss: -1.527,Avg.Loss: -1.129,LR: 4.06E-04]Training epoch 29:  47%|████▋     | 72/153 [00:01<00:01, 53.67it/s, Epoch: 29, Batch: 73,Loss: -1.392,Avg.Loss: -1.132,LR: 4.06E-04]Training epoch 29:  48%|████▊     | 73/153 [00:01<00:01, 53.67it/s, Epoch: 29, Batch: 74,Loss: -1.654,Avg.Loss: -1.140,LR: 4.06E-04]Training epoch 29:  48%|████▊     | 74/153 [00:01<00:01, 53.67it/s, Epoch: 29, Batch: 75,Loss: -1.574,Avg.Loss: -1.145,LR: 4.06E-04]Training epoch 29:  49%|████▉     | 75/153 [00:01<00:01, 53.67it/s, Epoch: 29, Batch: 76,Loss: -1.931,Avg.Loss: -1.156,LR: 4.06E-04]Training epoch 29:  50%|████▉     | 76/153 [00:01<00:01, 53.67it/s, Epoch: 29, Batch: 77,Loss: -2.011,Avg.Loss: -1.167,LR: 4.06E-04]Training epoch 29:  50%|█████     | 77/153 [00:01<00:01, 53.67it/s, Epoch: 29, Batch: 78,Loss: -2.275,Avg.Loss: -1.181,LR: 4.06E-04]Training epoch 29:  51%|█████     | 78/153 [00:01<00:01, 53.64it/s, Epoch: 29, Batch: 78,Loss: -2.275,Avg.Loss: -1.181,LR: 4.06E-04]Training epoch 29:  51%|█████     | 78/153 [00:01<00:01, 53.64it/s, Epoch: 29, Batch: 79,Loss: -1.579,Avg.Loss: -1.186,LR: 4.06E-04]Training epoch 29:  52%|█████▏    | 79/153 [00:01<00:01, 53.64it/s, Epoch: 29, Batch: 80,Loss: -1.892,Avg.Loss: -1.195,LR: 4.06E-04]Training epoch 29:  52%|█████▏    | 80/153 [00:01<00:01, 53.64it/s, Epoch: 29, Batch: 81,Loss: -1.901,Avg.Loss: -1.204,LR: 4.06E-04]Training epoch 29:  53%|█████▎    | 81/153 [00:01<00:01, 53.64it/s, Epoch: 29, Batch: 82,Loss: -1.967,Avg.Loss: -1.213,LR: 4.06E-04]Training epoch 29:  54%|█████▎    | 82/153 [00:01<00:01, 53.64it/s, Epoch: 29, Batch: 83,Loss: -1.570,Avg.Loss: -1.217,LR: 4.06E-04]Training epoch 29:  54%|█████▍    | 83/153 [00:01<00:01, 53.64it/s, Epoch: 29, Batch: 84,Loss: -1.765,Avg.Loss: -1.224,LR: 4.06E-04]Training epoch 29:  55%|█████▍    | 84/153 [00:01<00:01, 53.57it/s, Epoch: 29, Batch: 84,Loss: -1.765,Avg.Loss: -1.224,LR: 4.06E-04]Training epoch 29:  55%|█████▍    | 84/153 [00:01<00:01, 53.57it/s, Epoch: 29, Batch: 85,Loss: -1.430,Avg.Loss: -1.226,LR: 4.06E-04]Training epoch 29:  56%|█████▌    | 85/153 [00:01<00:01, 53.57it/s, Epoch: 29, Batch: 86,Loss: -1.428,Avg.Loss: -1.228,LR: 4.06E-04]Training epoch 29:  56%|█████▌    | 86/153 [00:01<00:01, 53.57it/s, Epoch: 29, Batch: 87,Loss: -2.254,Avg.Loss: -1.240,LR: 4.06E-04]Training epoch 29:  57%|█████▋    | 87/153 [00:01<00:01, 53.57it/s, Epoch: 29, Batch: 88,Loss: -1.937,Avg.Loss: -1.248,LR: 4.06E-04]Training epoch 29:  58%|█████▊    | 88/153 [00:01<00:01, 53.57it/s, Epoch: 29, Batch: 89,Loss: -1.004,Avg.Loss: -1.245,LR: 4.06E-04]Training epoch 29:  58%|█████▊    | 89/153 [00:01<00:01, 53.57it/s, Epoch: 29, Batch: 90,Loss: -1.268,Avg.Loss: -1.246,LR: 4.06E-04]Training epoch 29:  59%|█████▉    | 90/153 [00:01<00:01, 53.75it/s, Epoch: 29, Batch: 90,Loss: -1.268,Avg.Loss: -1.246,LR: 4.06E-04]Training epoch 29:  59%|█████▉    | 90/153 [00:01<00:01, 53.75it/s, Epoch: 29, Batch: 91,Loss: -1.616,Avg.Loss: -1.250,LR: 4.06E-04]Training epoch 29:  59%|█████▉    | 91/153 [00:01<00:01, 53.75it/s, Epoch: 29, Batch: 92,Loss: -1.703,Avg.Loss: -1.255,LR: 4.06E-04]Training epoch 29:  60%|██████    | 92/153 [00:01<00:01, 53.75it/s, Epoch: 29, Batch: 93,Loss: -1.889,Avg.Loss: -1.261,LR: 4.06E-04]Training epoch 29:  61%|██████    | 93/153 [00:01<00:01, 53.75it/s, Epoch: 29, Batch: 94,Loss: -1.847,Avg.Loss: -1.268,LR: 4.06E-04]Training epoch 29:  61%|██████▏   | 94/153 [00:01<00:01, 53.75it/s, Epoch: 29, Batch: 95,Loss: -1.350,Avg.Loss: -1.269,LR: 4.06E-04]Training epoch 29:  62%|██████▏   | 95/153 [00:01<00:01, 53.75it/s, Epoch: 29, Batch: 96,Loss: -1.077,Avg.Loss: -1.267,LR: 4.06E-04]Training epoch 29:  63%|██████▎   | 96/153 [00:01<00:01, 53.76it/s, Epoch: 29, Batch: 96,Loss: -1.077,Avg.Loss: -1.267,LR: 4.06E-04]Training epoch 29:  63%|██████▎   | 96/153 [00:01<00:01, 53.76it/s, Epoch: 29, Batch: 97,Loss: -1.038,Avg.Loss: -1.264,LR: 4.05E-04]Training epoch 29:  63%|██████▎   | 97/153 [00:01<00:01, 53.76it/s, Epoch: 29, Batch: 98,Loss: -2.164,Avg.Loss: -1.273,LR: 4.05E-04]Training epoch 29:  64%|██████▍   | 98/153 [00:01<00:01, 53.76it/s, Epoch: 29, Batch: 99,Loss: -1.690,Avg.Loss: -1.278,LR: 4.05E-04]Training epoch 29:  65%|██████▍   | 99/153 [00:01<00:01, 53.76it/s, Epoch: 29, Batch: 100,Loss: -1.484,Avg.Loss: -1.280,LR: 4.05E-04]Training epoch 29:  65%|██████▌   | 100/153 [00:01<00:00, 53.76it/s, Epoch: 29, Batch: 101,Loss: -0.933,Avg.Loss: -1.276,LR: 4.05E-04]Training epoch 29:  66%|██████▌   | 101/153 [00:01<00:00, 53.76it/s, Epoch: 29, Batch: 102,Loss: -1.006,Avg.Loss: -1.274,LR: 4.05E-04]Training epoch 29:  67%|██████▋   | 102/153 [00:01<00:00, 53.48it/s, Epoch: 29, Batch: 102,Loss: -1.006,Avg.Loss: -1.274,LR: 4.05E-04]Training epoch 29:  67%|██████▋   | 102/153 [00:01<00:00, 53.48it/s, Epoch: 29, Batch: 103,Loss: -0.010,Avg.Loss: -1.261,LR: 4.05E-04]Training epoch 29:  67%|██████▋   | 103/153 [00:01<00:00, 53.48it/s, Epoch: 29, Batch: 104,Loss: 0.026,Avg.Loss: -1.249,LR: 4.05E-04] Training epoch 29:  68%|██████▊   | 104/153 [00:01<00:00, 53.48it/s, Epoch: 29, Batch: 105,Loss: -0.542,Avg.Loss: -1.242,LR: 4.05E-04]Training epoch 29:  69%|██████▊   | 105/153 [00:01<00:00, 53.48it/s, Epoch: 29, Batch: 106,Loss: -0.546,Avg.Loss: -1.236,LR: 4.05E-04]Training epoch 29:  69%|██████▉   | 106/153 [00:01<00:00, 53.48it/s, Epoch: 29, Batch: 107,Loss: -1.090,Avg.Loss: -1.234,LR: 4.05E-04]Training epoch 29:  70%|██████▉   | 107/153 [00:02<00:00, 53.48it/s, Epoch: 29, Batch: 108,Loss: -1.127,Avg.Loss: -1.233,LR: 4.05E-04]Training epoch 29:  71%|███████   | 108/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 108,Loss: -1.127,Avg.Loss: -1.233,LR: 4.05E-04]Training epoch 29:  71%|███████   | 108/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 109,Loss: -0.782,Avg.Loss: -1.229,LR: 4.05E-04]Training epoch 29:  71%|███████   | 109/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 110,Loss: -1.035,Avg.Loss: -1.227,LR: 4.05E-04]Training epoch 29:  72%|███████▏  | 110/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 111,Loss: -1.493,Avg.Loss: -1.230,LR: 4.05E-04]Training epoch 29:  73%|███████▎  | 111/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 112,Loss: -1.675,Avg.Loss: -1.234,LR: 4.05E-04]Training epoch 29:  73%|███████▎  | 112/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 113,Loss: -1.985,Avg.Loss: -1.240,LR: 4.05E-04]Training epoch 29:  74%|███████▍  | 113/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 114,Loss: -2.046,Avg.Loss: -1.247,LR: 4.05E-04]Training epoch 29:  75%|███████▍  | 114/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 114,Loss: -2.046,Avg.Loss: -1.247,LR: 4.05E-04]Training epoch 29:  75%|███████▍  | 114/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 115,Loss: -1.892,Avg.Loss: -1.253,LR: 4.05E-04]Training epoch 29:  75%|███████▌  | 115/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 116,Loss: -1.988,Avg.Loss: -1.259,LR: 4.05E-04]Training epoch 29:  76%|███████▌  | 116/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 117,Loss: -1.205,Avg.Loss: -1.259,LR: 4.05E-04]Training epoch 29:  76%|███████▋  | 117/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 118,Loss: -1.822,Avg.Loss: -1.264,LR: 4.05E-04]Training epoch 29:  77%|███████▋  | 118/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 119,Loss: -1.537,Avg.Loss: -1.266,LR: 4.05E-04]Training epoch 29:  78%|███████▊  | 119/153 [00:02<00:00, 53.40it/s, Epoch: 29, Batch: 120,Loss: -1.256,Avg.Loss: -1.266,LR: 4.05E-04]Training epoch 29:  78%|███████▊  | 120/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 120,Loss: -1.256,Avg.Loss: -1.266,LR: 4.05E-04]Training epoch 29:  78%|███████▊  | 120/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 121,Loss: -0.144,Avg.Loss: -1.257,LR: 4.05E-04]Training epoch 29:  79%|███████▉  | 121/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 122,Loss: -0.951,Avg.Loss: -1.254,LR: 4.04E-04]Training epoch 29:  80%|███████▉  | 122/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 123,Loss: -1.296,Avg.Loss: -1.255,LR: 4.04E-04]Training epoch 29:  80%|████████  | 123/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 124,Loss: -1.245,Avg.Loss: -1.254,LR: 4.04E-04]Training epoch 29:  81%|████████  | 124/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 125,Loss: -1.597,Avg.Loss: -1.257,LR: 4.04E-04]Training epoch 29:  82%|████████▏ | 125/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 126,Loss: -1.074,Avg.Loss: -1.256,LR: 4.04E-04]Training epoch 29:  82%|████████▏ | 126/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 126,Loss: -1.074,Avg.Loss: -1.256,LR: 4.04E-04]Training epoch 29:  82%|████████▏ | 126/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 127,Loss: -0.520,Avg.Loss: -1.250,LR: 4.04E-04]Training epoch 29:  83%|████████▎ | 127/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 128,Loss: -1.633,Avg.Loss: -1.253,LR: 4.04E-04]Training epoch 29:  84%|████████▎ | 128/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 129,Loss: -1.698,Avg.Loss: -1.256,LR: 4.04E-04]Training epoch 29:  84%|████████▍ | 129/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 130,Loss: -1.778,Avg.Loss: -1.260,LR: 4.04E-04]Training epoch 29:  85%|████████▍ | 130/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 131,Loss: -1.304,Avg.Loss: -1.261,LR: 4.04E-04]Training epoch 29:  86%|████████▌ | 131/153 [00:02<00:00, 53.47it/s, Epoch: 29, Batch: 132,Loss: -1.543,Avg.Loss: -1.263,LR: 4.04E-04]Training epoch 29:  86%|████████▋ | 132/153 [00:02<00:00, 53.60it/s, Epoch: 29, Batch: 132,Loss: -1.543,Avg.Loss: -1.263,LR: 4.04E-04]Training epoch 29:  86%|████████▋ | 132/153 [00:02<00:00, 53.60it/s, Epoch: 29, Batch: 133,Loss: -1.684,Avg.Loss: -1.266,LR: 4.04E-04]Training epoch 29:  87%|████████▋ | 133/153 [00:02<00:00, 53.60it/s, Epoch: 29, Batch: 134,Loss: -1.590,Avg.Loss: -1.268,LR: 4.04E-04]Training epoch 29:  88%|████████▊ | 134/153 [00:02<00:00, 53.60it/s, Epoch: 29, Batch: 135,Loss: -2.017,Avg.Loss: -1.274,LR: 4.04E-04]Training epoch 29:  88%|████████▊ | 135/153 [00:02<00:00, 53.60it/s, Epoch: 29, Batch: 136,Loss: -1.678,Avg.Loss: -1.277,LR: 4.04E-04]Training epoch 29:  89%|████████▉ | 136/153 [00:02<00:00, 53.60it/s, Epoch: 29, Batch: 137,Loss: -1.665,Avg.Loss: -1.280,LR: 4.04E-04]Training epoch 29:  90%|████████▉ | 137/153 [00:02<00:00, 53.60it/s, Epoch: 29, Batch: 138,Loss: -1.432,Avg.Loss: -1.281,LR: 4.04E-04]Training epoch 29:  90%|█████████ | 138/153 [00:02<00:00, 53.50it/s, Epoch: 29, Batch: 138,Loss: -1.432,Avg.Loss: -1.281,LR: 4.04E-04]Training epoch 29:  90%|█████████ | 138/153 [00:02<00:00, 53.50it/s, Epoch: 29, Batch: 139,Loss: -1.116,Avg.Loss: -1.280,LR: 4.04E-04]Training epoch 29:  91%|█████████ | 139/153 [00:02<00:00, 53.50it/s, Epoch: 29, Batch: 140,Loss: -1.727,Avg.Loss: -1.283,LR: 4.04E-04]Training epoch 29:  92%|█████████▏| 140/153 [00:02<00:00, 53.50it/s, Epoch: 29, Batch: 141,Loss: -1.494,Avg.Loss: -1.284,LR: 4.04E-04]Training epoch 29:  92%|█████████▏| 141/153 [00:02<00:00, 53.50it/s, Epoch: 29, Batch: 142,Loss: -0.516,Avg.Loss: -1.279,LR: 4.04E-04]Training epoch 29:  93%|█████████▎| 142/153 [00:02<00:00, 53.50it/s, Epoch: 29, Batch: 143,Loss: -1.088,Avg.Loss: -1.278,LR: 4.04E-04]Training epoch 29:  93%|█████████▎| 143/153 [00:02<00:00, 53.50it/s, Epoch: 29, Batch: 144,Loss: -2.019,Avg.Loss: -1.283,LR: 4.04E-04]Training epoch 29:  94%|█████████▍| 144/153 [00:02<00:00, 53.48it/s, Epoch: 29, Batch: 144,Loss: -2.019,Avg.Loss: -1.283,LR: 4.04E-04]Training epoch 29:  94%|█████████▍| 144/153 [00:02<00:00, 53.48it/s, Epoch: 29, Batch: 145,Loss: -0.278,Avg.Loss: -1.276,LR: 4.04E-04]Training epoch 29:  95%|█████████▍| 145/153 [00:02<00:00, 53.48it/s, Epoch: 29, Batch: 146,Loss: 1.411,Avg.Loss: -1.257,LR: 4.04E-04] Training epoch 29:  95%|█████████▌| 146/153 [00:02<00:00, 53.48it/s, Epoch: 29, Batch: 147,Loss: 1.859,Avg.Loss: -1.236,LR: 4.03E-04]Training epoch 29:  96%|█████████▌| 147/153 [00:02<00:00, 53.48it/s, Epoch: 29, Batch: 148,Loss: -0.612,Avg.Loss: -1.232,LR: 4.03E-04]Training epoch 29:  97%|█████████▋| 148/153 [00:02<00:00, 53.48it/s, Epoch: 29, Batch: 149,Loss: -1.411,Avg.Loss: -1.233,LR: 4.03E-04]Training epoch 29:  97%|█████████▋| 149/153 [00:02<00:00, 53.48it/s, Epoch: 29, Batch: 150,Loss: -1.570,Avg.Loss: -1.235,LR: 4.03E-04]Training epoch 29:  98%|█████████▊| 150/153 [00:02<00:00, 53.55it/s, Epoch: 29, Batch: 150,Loss: -1.570,Avg.Loss: -1.235,LR: 4.03E-04]Training epoch 29:  98%|█████████▊| 150/153 [00:02<00:00, 53.55it/s, Epoch: 29, Batch: 151,Loss: -1.525,Avg.Loss: -1.237,LR: 4.03E-04]Training epoch 29:  99%|█████████▊| 151/153 [00:02<00:00, 53.55it/s, Epoch: 29, Batch: 152,Loss: -2.050,Avg.Loss: -1.243,LR: 4.03E-04]Training epoch 29:  99%|█████████▉| 152/153 [00:02<00:00, 53.55it/s, Epoch: 29, Batch: 153,Loss: -2.596,Avg.Loss: -1.252,LR: 4.03E-04]Training epoch 29: 100%|██████████| 153/153 [00:02<00:00, 53.58it/s, Epoch: 29, Batch: 153,Loss: -2.596,Avg.Loss: -1.252,LR: 4.03E-04]
Training epoch 30:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 30:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 30, Batch: 1,Loss: -1.912,Avg.Loss: -1.912,LR: 4.03E-04]Training epoch 30:   1%|          | 1/153 [00:00<00:07, 21.41it/s, Epoch: 30, Batch: 2,Loss: -2.191,Avg.Loss: -2.052,LR: 4.03E-04]Training epoch 30:   1%|▏         | 2/153 [00:00<00:04, 31.71it/s, Epoch: 30, Batch: 3,Loss: -1.903,Avg.Loss: -2.002,LR: 4.03E-04]Training epoch 30:   2%|▏         | 3/153 [00:00<00:04, 37.12it/s, Epoch: 30, Batch: 4,Loss: -1.590,Avg.Loss: -1.899,LR: 4.03E-04]Training epoch 30:   3%|▎         | 4/153 [00:00<00:03, 40.04it/s, Epoch: 30, Batch: 5,Loss: -1.756,Avg.Loss: -1.871,LR: 4.03E-04]Training epoch 30:   3%|▎         | 5/153 [00:00<00:02, 49.95it/s, Epoch: 30, Batch: 5,Loss: -1.756,Avg.Loss: -1.871,LR: 4.03E-04]Training epoch 30:   3%|▎         | 5/153 [00:00<00:02, 49.95it/s, Epoch: 30, Batch: 6,Loss: -2.112,Avg.Loss: -1.911,LR: 4.03E-04]Training epoch 30:   4%|▍         | 6/153 [00:00<00:02, 49.95it/s, Epoch: 30, Batch: 7,Loss: -1.877,Avg.Loss: -1.906,LR: 4.03E-04]Training epoch 30:   5%|▍         | 7/153 [00:00<00:02, 49.95it/s, Epoch: 30, Batch: 8,Loss: -1.450,Avg.Loss: -1.849,LR: 4.03E-04]Training epoch 30:   5%|▌         | 8/153 [00:00<00:02, 49.95it/s, Epoch: 30, Batch: 9,Loss: -1.868,Avg.Loss: -1.851,LR: 4.03E-04]Training epoch 30:   6%|▌         | 9/153 [00:00<00:02, 49.95it/s, Epoch: 30, Batch: 10,Loss: -1.503,Avg.Loss: -1.816,LR: 4.03E-04]Training epoch 30:   7%|▋         | 10/153 [00:00<00:02, 49.95it/s, Epoch: 30, Batch: 11,Loss: -1.179,Avg.Loss: -1.758,LR: 4.03E-04]Training epoch 30:   7%|▋         | 11/153 [00:00<00:02, 52.17it/s, Epoch: 30, Batch: 11,Loss: -1.179,Avg.Loss: -1.758,LR: 4.03E-04]Training epoch 30:   7%|▋         | 11/153 [00:00<00:02, 52.17it/s, Epoch: 30, Batch: 12,Loss: -1.772,Avg.Loss: -1.759,LR: 4.03E-04]Training epoch 30:   8%|▊         | 12/153 [00:00<00:02, 52.17it/s, Epoch: 30, Batch: 13,Loss: -0.433,Avg.Loss: -1.657,LR: 4.03E-04]Training epoch 30:   8%|▊         | 13/153 [00:00<00:02, 52.17it/s, Epoch: 30, Batch: 14,Loss: -2.074,Avg.Loss: -1.687,LR: 4.03E-04]Training epoch 30:   9%|▉         | 14/153 [00:00<00:02, 52.17it/s, Epoch: 30, Batch: 15,Loss: -1.863,Avg.Loss: -1.699,LR: 4.03E-04]Training epoch 30:  10%|▉         | 15/153 [00:00<00:02, 52.17it/s, Epoch: 30, Batch: 16,Loss: -1.940,Avg.Loss: -1.714,LR: 4.03E-04]Training epoch 30:  10%|█         | 16/153 [00:00<00:02, 52.17it/s, Epoch: 30, Batch: 17,Loss: -1.543,Avg.Loss: -1.704,LR: 4.03E-04]Training epoch 30:  11%|█         | 17/153 [00:00<00:02, 53.04it/s, Epoch: 30, Batch: 17,Loss: -1.543,Avg.Loss: -1.704,LR: 4.03E-04]Training epoch 30:  11%|█         | 17/153 [00:00<00:02, 53.04it/s, Epoch: 30, Batch: 18,Loss: -1.703,Avg.Loss: -1.704,LR: 4.02E-04]Training epoch 30:  12%|█▏        | 18/153 [00:00<00:02, 53.04it/s, Epoch: 30, Batch: 19,Loss: -1.995,Avg.Loss: -1.719,LR: 4.02E-04]Training epoch 30:  12%|█▏        | 19/153 [00:00<00:02, 53.04it/s, Epoch: 30, Batch: 20,Loss: -2.016,Avg.Loss: -1.734,LR: 4.02E-04]Training epoch 30:  13%|█▎        | 20/153 [00:00<00:02, 53.04it/s, Epoch: 30, Batch: 21,Loss: -1.879,Avg.Loss: -1.741,LR: 4.02E-04]Training epoch 30:  14%|█▎        | 21/153 [00:00<00:02, 53.04it/s, Epoch: 30, Batch: 22,Loss: -2.039,Avg.Loss: -1.754,LR: 4.02E-04]Training epoch 30:  14%|█▍        | 22/153 [00:00<00:02, 53.04it/s, Epoch: 30, Batch: 23,Loss: -1.432,Avg.Loss: -1.740,LR: 4.02E-04]Training epoch 30:  15%|█▌        | 23/153 [00:00<00:02, 52.81it/s, Epoch: 30, Batch: 23,Loss: -1.432,Avg.Loss: -1.740,LR: 4.02E-04]Training epoch 30:  15%|█▌        | 23/153 [00:00<00:02, 52.81it/s, Epoch: 30, Batch: 24,Loss: -2.171,Avg.Loss: -1.758,LR: 4.02E-04]Training epoch 30:  16%|█▌        | 24/153 [00:00<00:02, 52.81it/s, Epoch: 30, Batch: 25,Loss: -2.350,Avg.Loss: -1.782,LR: 4.02E-04]Training epoch 30:  16%|█▋        | 25/153 [00:00<00:02, 52.81it/s, Epoch: 30, Batch: 26,Loss: -1.789,Avg.Loss: -1.782,LR: 4.02E-04]Training epoch 30:  17%|█▋        | 26/153 [00:00<00:02, 52.81it/s, Epoch: 30, Batch: 27,Loss: -2.022,Avg.Loss: -1.791,LR: 4.02E-04]Training epoch 30:  18%|█▊        | 27/153 [00:00<00:02, 52.81it/s, Epoch: 30, Batch: 28,Loss: -2.392,Avg.Loss: -1.813,LR: 4.02E-04]Training epoch 30:  18%|█▊        | 28/153 [00:00<00:02, 52.81it/s, Epoch: 30, Batch: 29,Loss: -2.059,Avg.Loss: -1.821,LR: 4.02E-04]Training epoch 30:  19%|█▉        | 29/153 [00:00<00:02, 52.22it/s, Epoch: 30, Batch: 29,Loss: -2.059,Avg.Loss: -1.821,LR: 4.02E-04]Training epoch 30:  19%|█▉        | 29/153 [00:00<00:02, 52.22it/s, Epoch: 30, Batch: 30,Loss: -1.875,Avg.Loss: -1.823,LR: 4.02E-04]Training epoch 30:  20%|█▉        | 30/153 [00:00<00:02, 52.22it/s, Epoch: 30, Batch: 31,Loss: -2.518,Avg.Loss: -1.845,LR: 4.02E-04]Training epoch 30:  20%|██        | 31/153 [00:00<00:02, 52.22it/s, Epoch: 30, Batch: 32,Loss: -1.715,Avg.Loss: -1.841,LR: 4.02E-04]Training epoch 30:  21%|██        | 32/153 [00:00<00:02, 52.22it/s, Epoch: 30, Batch: 33,Loss: -1.934,Avg.Loss: -1.844,LR: 4.02E-04]Training epoch 30:  22%|██▏       | 33/153 [00:00<00:02, 52.22it/s, Epoch: 30, Batch: 34,Loss: -1.309,Avg.Loss: -1.828,LR: 4.02E-04]Training epoch 30:  22%|██▏       | 34/153 [00:00<00:02, 52.22it/s, Epoch: 30, Batch: 35,Loss: -1.437,Avg.Loss: -1.817,LR: 4.02E-04]Training epoch 30:  23%|██▎       | 35/153 [00:00<00:02, 52.04it/s, Epoch: 30, Batch: 35,Loss: -1.437,Avg.Loss: -1.817,LR: 4.02E-04]Training epoch 30:  23%|██▎       | 35/153 [00:00<00:02, 52.04it/s, Epoch: 30, Batch: 36,Loss: -1.426,Avg.Loss: -1.806,LR: 4.02E-04]Training epoch 30:  24%|██▎       | 36/153 [00:00<00:02, 52.04it/s, Epoch: 30, Batch: 37,Loss: -1.486,Avg.Loss: -1.798,LR: 4.02E-04]Training epoch 30:  24%|██▍       | 37/153 [00:00<00:02, 52.04it/s, Epoch: 30, Batch: 38,Loss: -1.197,Avg.Loss: -1.782,LR: 4.02E-04]Training epoch 30:  25%|██▍       | 38/153 [00:00<00:02, 52.04it/s, Epoch: 30, Batch: 39,Loss: -2.102,Avg.Loss: -1.790,LR: 4.02E-04]Training epoch 30:  25%|██▌       | 39/153 [00:00<00:02, 52.04it/s, Epoch: 30, Batch: 40,Loss: -1.665,Avg.Loss: -1.787,LR: 4.02E-04]Training epoch 30:  26%|██▌       | 40/153 [00:00<00:02, 52.04it/s, Epoch: 30, Batch: 41,Loss: -0.507,Avg.Loss: -1.756,LR: 4.02E-04]Training epoch 30:  27%|██▋       | 41/153 [00:00<00:02, 52.59it/s, Epoch: 30, Batch: 41,Loss: -0.507,Avg.Loss: -1.756,LR: 4.02E-04]Training epoch 30:  27%|██▋       | 41/153 [00:00<00:02, 52.59it/s, Epoch: 30, Batch: 42,Loss: -0.932,Avg.Loss: -1.736,LR: 4.02E-04]Training epoch 30:  27%|██▋       | 42/153 [00:00<00:02, 52.59it/s, Epoch: 30, Batch: 43,Loss: -2.101,Avg.Loss: -1.745,LR: 4.01E-04]Training epoch 30:  28%|██▊       | 43/153 [00:00<00:02, 52.59it/s, Epoch: 30, Batch: 44,Loss: -1.477,Avg.Loss: -1.738,LR: 4.01E-04]Training epoch 30:  29%|██▉       | 44/153 [00:00<00:02, 52.59it/s, Epoch: 30, Batch: 45,Loss: -0.103,Avg.Loss: -1.702,LR: 4.01E-04]Training epoch 30:  29%|██▉       | 45/153 [00:00<00:02, 52.59it/s, Epoch: 30, Batch: 46,Loss: 0.776,Avg.Loss: -1.648,LR: 4.01E-04] Training epoch 30:  30%|███       | 46/153 [00:00<00:02, 52.59it/s, Epoch: 30, Batch: 47,Loss: -1.268,Avg.Loss: -1.640,LR: 4.01E-04]Training epoch 30:  31%|███       | 47/153 [00:00<00:02, 52.67it/s, Epoch: 30, Batch: 47,Loss: -1.268,Avg.Loss: -1.640,LR: 4.01E-04]Training epoch 30:  31%|███       | 47/153 [00:00<00:02, 52.67it/s, Epoch: 30, Batch: 48,Loss: -0.893,Avg.Loss: -1.625,LR: 4.01E-04]Training epoch 30:  31%|███▏      | 48/153 [00:00<00:01, 52.67it/s, Epoch: 30, Batch: 49,Loss: -2.322,Avg.Loss: -1.639,LR: 4.01E-04]Training epoch 30:  32%|███▏      | 49/153 [00:00<00:01, 52.67it/s, Epoch: 30, Batch: 50,Loss: -2.129,Avg.Loss: -1.649,LR: 4.01E-04]Training epoch 30:  33%|███▎      | 50/153 [00:00<00:01, 52.67it/s, Epoch: 30, Batch: 51,Loss: -1.955,Avg.Loss: -1.655,LR: 4.01E-04]Training epoch 30:  33%|███▎      | 51/153 [00:00<00:01, 52.67it/s, Epoch: 30, Batch: 52,Loss: -1.688,Avg.Loss: -1.655,LR: 4.01E-04]Training epoch 30:  34%|███▍      | 52/153 [00:01<00:01, 52.67it/s, Epoch: 30, Batch: 53,Loss: -1.280,Avg.Loss: -1.648,LR: 4.01E-04]Training epoch 30:  35%|███▍      | 53/153 [00:01<00:01, 52.79it/s, Epoch: 30, Batch: 53,Loss: -1.280,Avg.Loss: -1.648,LR: 4.01E-04]Training epoch 30:  35%|███▍      | 53/153 [00:01<00:01, 52.79it/s, Epoch: 30, Batch: 54,Loss: -1.776,Avg.Loss: -1.651,LR: 4.01E-04]Training epoch 30:  35%|███▌      | 54/153 [00:01<00:01, 52.79it/s, Epoch: 30, Batch: 55,Loss: -2.264,Avg.Loss: -1.662,LR: 4.01E-04]Training epoch 30:  36%|███▌      | 55/153 [00:01<00:01, 52.79it/s, Epoch: 30, Batch: 56,Loss: -1.601,Avg.Loss: -1.661,LR: 4.01E-04]Training epoch 30:  37%|███▋      | 56/153 [00:01<00:01, 52.79it/s, Epoch: 30, Batch: 57,Loss: -1.072,Avg.Loss: -1.650,LR: 4.01E-04]Training epoch 30:  37%|███▋      | 57/153 [00:01<00:01, 52.79it/s, Epoch: 30, Batch: 58,Loss: -2.276,Avg.Loss: -1.661,LR: 4.01E-04]Training epoch 30:  38%|███▊      | 58/153 [00:01<00:01, 52.79it/s, Epoch: 30, Batch: 59,Loss: -1.545,Avg.Loss: -1.659,LR: 4.01E-04]Training epoch 30:  39%|███▊      | 59/153 [00:01<00:01, 52.69it/s, Epoch: 30, Batch: 59,Loss: -1.545,Avg.Loss: -1.659,LR: 4.01E-04]Training epoch 30:  39%|███▊      | 59/153 [00:01<00:01, 52.69it/s, Epoch: 30, Batch: 60,Loss: -1.596,Avg.Loss: -1.658,LR: 4.01E-04]Training epoch 30:  39%|███▉      | 60/153 [00:01<00:01, 52.69it/s, Epoch: 30, Batch: 61,Loss: -1.743,Avg.Loss: -1.659,LR: 4.01E-04]Training epoch 30:  40%|███▉      | 61/153 [00:01<00:01, 52.69it/s, Epoch: 30, Batch: 62,Loss: -1.939,Avg.Loss: -1.664,LR: 4.01E-04]Training epoch 30:  41%|████      | 62/153 [00:01<00:01, 52.69it/s, Epoch: 30, Batch: 63,Loss: -2.055,Avg.Loss: -1.670,LR: 4.01E-04]Training epoch 30:  41%|████      | 63/153 [00:01<00:01, 52.69it/s, Epoch: 30, Batch: 64,Loss: -2.471,Avg.Loss: -1.683,LR: 4.01E-04]Training epoch 30:  42%|████▏     | 64/153 [00:01<00:01, 52.69it/s, Epoch: 30, Batch: 65,Loss: -2.303,Avg.Loss: -1.692,LR: 4.01E-04]Training epoch 30:  42%|████▏     | 65/153 [00:01<00:01, 53.02it/s, Epoch: 30, Batch: 65,Loss: -2.303,Avg.Loss: -1.692,LR: 4.01E-04]Training epoch 30:  42%|████▏     | 65/153 [00:01<00:01, 53.02it/s, Epoch: 30, Batch: 66,Loss: -2.020,Avg.Loss: -1.697,LR: 4.01E-04]Training epoch 30:  43%|████▎     | 66/153 [00:01<00:01, 53.02it/s, Epoch: 30, Batch: 67,Loss: -1.408,Avg.Loss: -1.693,LR: 4.00E-04]Training epoch 30:  44%|████▍     | 67/153 [00:01<00:01, 53.02it/s, Epoch: 30, Batch: 68,Loss: -1.856,Avg.Loss: -1.695,LR: 4.00E-04]Training epoch 30:  44%|████▍     | 68/153 [00:01<00:01, 53.02it/s, Epoch: 30, Batch: 69,Loss: -2.026,Avg.Loss: -1.700,LR: 4.00E-04]Training epoch 30:  45%|████▌     | 69/153 [00:01<00:01, 53.02it/s, Epoch: 30, Batch: 70,Loss: -2.083,Avg.Loss: -1.706,LR: 4.00E-04]Training epoch 30:  46%|████▌     | 70/153 [00:01<00:01, 53.02it/s, Epoch: 30, Batch: 71,Loss: -1.962,Avg.Loss: -1.709,LR: 4.00E-04]Training epoch 30:  46%|████▋     | 71/153 [00:01<00:01, 53.18it/s, Epoch: 30, Batch: 71,Loss: -1.962,Avg.Loss: -1.709,LR: 4.00E-04]Training epoch 30:  46%|████▋     | 71/153 [00:01<00:01, 53.18it/s, Epoch: 30, Batch: 72,Loss: -1.880,Avg.Loss: -1.712,LR: 4.00E-04]Training epoch 30:  47%|████▋     | 72/153 [00:01<00:01, 53.18it/s, Epoch: 30, Batch: 73,Loss: -1.674,Avg.Loss: -1.711,LR: 4.00E-04]Training epoch 30:  48%|████▊     | 73/153 [00:01<00:01, 53.18it/s, Epoch: 30, Batch: 74,Loss: -1.527,Avg.Loss: -1.709,LR: 4.00E-04]Training epoch 30:  48%|████▊     | 74/153 [00:01<00:01, 53.18it/s, Epoch: 30, Batch: 75,Loss: -1.664,Avg.Loss: -1.708,LR: 4.00E-04]Training epoch 30:  49%|████▉     | 75/153 [00:01<00:01, 53.18it/s, Epoch: 30, Batch: 76,Loss: -2.431,Avg.Loss: -1.717,LR: 4.00E-04]Training epoch 30:  50%|████▉     | 76/153 [00:01<00:01, 53.18it/s, Epoch: 30, Batch: 77,Loss: -2.095,Avg.Loss: -1.722,LR: 4.00E-04]Training epoch 30:  50%|█████     | 77/153 [00:01<00:01, 53.15it/s, Epoch: 30, Batch: 77,Loss: -2.095,Avg.Loss: -1.722,LR: 4.00E-04]Training epoch 30:  50%|█████     | 77/153 [00:01<00:01, 53.15it/s, Epoch: 30, Batch: 78,Loss: -2.309,Avg.Loss: -1.730,LR: 4.00E-04]Training epoch 30:  51%|█████     | 78/153 [00:01<00:01, 53.15it/s, Epoch: 30, Batch: 79,Loss: -2.204,Avg.Loss: -1.736,LR: 4.00E-04]Training epoch 30:  52%|█████▏    | 79/153 [00:01<00:01, 53.15it/s, Epoch: 30, Batch: 80,Loss: -2.100,Avg.Loss: -1.740,LR: 4.00E-04]Training epoch 30:  52%|█████▏    | 80/153 [00:01<00:01, 53.15it/s, Epoch: 30, Batch: 81,Loss: -1.036,Avg.Loss: -1.732,LR: 4.00E-04]Training epoch 30:  53%|█████▎    | 81/153 [00:01<00:01, 53.15it/s, Epoch: 30, Batch: 82,Loss: -1.388,Avg.Loss: -1.728,LR: 4.00E-04]Training epoch 30:  54%|█████▎    | 82/153 [00:01<00:01, 53.15it/s, Epoch: 30, Batch: 83,Loss: -1.986,Avg.Loss: -1.731,LR: 4.00E-04]Training epoch 30:  54%|█████▍    | 83/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 83,Loss: -1.986,Avg.Loss: -1.731,LR: 4.00E-04]Training epoch 30:  54%|█████▍    | 83/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 84,Loss: -2.107,Avg.Loss: -1.735,LR: 4.00E-04]Training epoch 30:  55%|█████▍    | 84/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 85,Loss: -2.046,Avg.Loss: -1.739,LR: 4.00E-04]Training epoch 30:  56%|█████▌    | 85/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 86,Loss: -2.016,Avg.Loss: -1.742,LR: 4.00E-04]Training epoch 30:  56%|█████▌    | 86/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 87,Loss: -2.377,Avg.Loss: -1.749,LR: 4.00E-04]Training epoch 30:  57%|█████▋    | 87/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 88,Loss: -2.220,Avg.Loss: -1.755,LR: 4.00E-04]Training epoch 30:  58%|█████▊    | 88/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 89,Loss: -2.296,Avg.Loss: -1.761,LR: 4.00E-04]Training epoch 30:  58%|█████▊    | 89/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 89,Loss: -2.296,Avg.Loss: -1.761,LR: 4.00E-04]Training epoch 30:  58%|█████▊    | 89/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 90,Loss: -2.337,Avg.Loss: -1.767,LR: 4.00E-04]Training epoch 30:  59%|█████▉    | 90/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 91,Loss: -1.765,Avg.Loss: -1.767,LR: 4.00E-04]Training epoch 30:  59%|█████▉    | 91/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 92,Loss: -2.415,Avg.Loss: -1.774,LR: 3.99E-04]Training epoch 30:  60%|██████    | 92/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 93,Loss: -2.415,Avg.Loss: -1.781,LR: 3.99E-04]Training epoch 30:  61%|██████    | 93/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 94,Loss: -2.243,Avg.Loss: -1.786,LR: 3.99E-04]Training epoch 30:  61%|██████▏   | 94/153 [00:01<00:01, 53.42it/s, Epoch: 30, Batch: 95,Loss: -1.798,Avg.Loss: -1.786,LR: 3.99E-04]Training epoch 30:  62%|██████▏   | 95/153 [00:01<00:01, 53.49it/s, Epoch: 30, Batch: 95,Loss: -1.798,Avg.Loss: -1.786,LR: 3.99E-04]Training epoch 30:  62%|██████▏   | 95/153 [00:01<00:01, 53.49it/s, Epoch: 30, Batch: 96,Loss: -2.451,Avg.Loss: -1.793,LR: 3.99E-04]Training epoch 30:  63%|██████▎   | 96/153 [00:01<00:01, 53.49it/s, Epoch: 30, Batch: 97,Loss: -2.055,Avg.Loss: -1.796,LR: 3.99E-04]Training epoch 30:  63%|██████▎   | 97/153 [00:01<00:01, 53.49it/s, Epoch: 30, Batch: 98,Loss: -1.429,Avg.Loss: -1.792,LR: 3.99E-04]Training epoch 30:  64%|██████▍   | 98/153 [00:01<00:01, 53.49it/s, Epoch: 30, Batch: 99,Loss: -1.942,Avg.Loss: -1.793,LR: 3.99E-04]Training epoch 30:  65%|██████▍   | 99/153 [00:01<00:01, 53.49it/s, Epoch: 30, Batch: 100,Loss: -2.360,Avg.Loss: -1.799,LR: 3.99E-04]Training epoch 30:  65%|██████▌   | 100/153 [00:01<00:00, 53.49it/s, Epoch: 30, Batch: 101,Loss: -2.284,Avg.Loss: -1.804,LR: 3.99E-04]Training epoch 30:  66%|██████▌   | 101/153 [00:01<00:00, 53.65it/s, Epoch: 30, Batch: 101,Loss: -2.284,Avg.Loss: -1.804,LR: 3.99E-04]Training epoch 30:  66%|██████▌   | 101/153 [00:01<00:00, 53.65it/s, Epoch: 30, Batch: 102,Loss: -2.153,Avg.Loss: -1.807,LR: 3.99E-04]Training epoch 30:  67%|██████▋   | 102/153 [00:01<00:00, 53.65it/s, Epoch: 30, Batch: 103,Loss: -1.592,Avg.Loss: -1.805,LR: 3.99E-04]Training epoch 30:  67%|██████▋   | 103/153 [00:01<00:00, 53.65it/s, Epoch: 30, Batch: 104,Loss: -2.520,Avg.Loss: -1.812,LR: 3.99E-04]Training epoch 30:  68%|██████▊   | 104/153 [00:01<00:00, 53.65it/s, Epoch: 30, Batch: 105,Loss: -2.088,Avg.Loss: -1.815,LR: 3.99E-04]Training epoch 30:  69%|██████▊   | 105/153 [00:02<00:00, 53.65it/s, Epoch: 30, Batch: 106,Loss: -1.599,Avg.Loss: -1.813,LR: 3.99E-04]Training epoch 30:  69%|██████▉   | 106/153 [00:02<00:00, 53.65it/s, Epoch: 30, Batch: 107,Loss: -1.368,Avg.Loss: -1.809,LR: 3.99E-04]Training epoch 30:  70%|██████▉   | 107/153 [00:02<00:00, 53.32it/s, Epoch: 30, Batch: 107,Loss: -1.368,Avg.Loss: -1.809,LR: 3.99E-04]Training epoch 30:  70%|██████▉   | 107/153 [00:02<00:00, 53.32it/s, Epoch: 30, Batch: 108,Loss: -1.672,Avg.Loss: -1.807,LR: 3.99E-04]Training epoch 30:  71%|███████   | 108/153 [00:02<00:00, 53.32it/s, Epoch: 30, Batch: 109,Loss: -2.462,Avg.Loss: -1.813,LR: 3.99E-04]Training epoch 30:  71%|███████   | 109/153 [00:02<00:00, 53.32it/s, Epoch: 30, Batch: 110,Loss: -2.101,Avg.Loss: -1.816,LR: 3.99E-04]Training epoch 30:  72%|███████▏  | 110/153 [00:02<00:00, 53.32it/s, Epoch: 30, Batch: 111,Loss: -1.308,Avg.Loss: -1.811,LR: 3.99E-04]Training epoch 30:  73%|███████▎  | 111/153 [00:02<00:00, 53.32it/s, Epoch: 30, Batch: 112,Loss: -1.889,Avg.Loss: -1.812,LR: 3.99E-04]Training epoch 30:  73%|███████▎  | 112/153 [00:02<00:00, 53.32it/s, Epoch: 30, Batch: 113,Loss: -1.695,Avg.Loss: -1.811,LR: 3.99E-04]Training epoch 30:  74%|███████▍  | 113/153 [00:02<00:00, 53.26it/s, Epoch: 30, Batch: 113,Loss: -1.695,Avg.Loss: -1.811,LR: 3.99E-04]Training epoch 30:  74%|███████▍  | 113/153 [00:02<00:00, 53.26it/s, Epoch: 30, Batch: 114,Loss: -1.507,Avg.Loss: -1.808,LR: 3.99E-04]Training epoch 30:  75%|███████▍  | 114/153 [00:02<00:00, 53.26it/s, Epoch: 30, Batch: 115,Loss: -2.226,Avg.Loss: -1.812,LR: 3.99E-04]Training epoch 30:  75%|███████▌  | 115/153 [00:02<00:00, 53.26it/s, Epoch: 30, Batch: 116,Loss: -1.547,Avg.Loss: -1.810,LR: 3.98E-04]Training epoch 30:  76%|███████▌  | 116/153 [00:02<00:00, 53.26it/s, Epoch: 30, Batch: 117,Loss: -0.789,Avg.Loss: -1.801,LR: 3.98E-04]Training epoch 30:  76%|███████▋  | 117/153 [00:02<00:00, 53.26it/s, Epoch: 30, Batch: 118,Loss: -1.789,Avg.Loss: -1.801,LR: 3.98E-04]Training epoch 30:  77%|███████▋  | 118/153 [00:02<00:00, 53.26it/s, Epoch: 30, Batch: 119,Loss: -2.350,Avg.Loss: -1.806,LR: 3.98E-04]Training epoch 30:  78%|███████▊  | 119/153 [00:02<00:00, 53.30it/s, Epoch: 30, Batch: 119,Loss: -2.350,Avg.Loss: -1.806,LR: 3.98E-04]Training epoch 30:  78%|███████▊  | 119/153 [00:02<00:00, 53.30it/s, Epoch: 30, Batch: 120,Loss: -2.038,Avg.Loss: -1.807,LR: 3.98E-04]Training epoch 30:  78%|███████▊  | 120/153 [00:02<00:00, 53.30it/s, Epoch: 30, Batch: 121,Loss: -2.459,Avg.Loss: -1.813,LR: 3.98E-04]Training epoch 30:  79%|███████▉  | 121/153 [00:02<00:00, 53.30it/s, Epoch: 30, Batch: 122,Loss: -2.563,Avg.Loss: -1.819,LR: 3.98E-04]Training epoch 30:  80%|███████▉  | 122/153 [00:02<00:00, 53.30it/s, Epoch: 30, Batch: 123,Loss: -2.066,Avg.Loss: -1.821,LR: 3.98E-04]Training epoch 30:  80%|████████  | 123/153 [00:02<00:00, 53.30it/s, Epoch: 30, Batch: 124,Loss: -2.508,Avg.Loss: -1.827,LR: 3.98E-04]Training epoch 30:  81%|████████  | 124/153 [00:02<00:00, 53.30it/s, Epoch: 30, Batch: 125,Loss: -1.885,Avg.Loss: -1.827,LR: 3.98E-04]Training epoch 30:  82%|████████▏ | 125/153 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 125,Loss: -1.885,Avg.Loss: -1.827,LR: 3.98E-04]Training epoch 30:  82%|████████▏ | 125/153 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 126,Loss: -2.060,Avg.Loss: -1.829,LR: 3.98E-04]Training epoch 30:  82%|████████▏ | 126/153 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 127,Loss: -1.762,Avg.Loss: -1.828,LR: 3.98E-04]Training epoch 30:  83%|████████▎ | 127/153 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 128,Loss: -1.881,Avg.Loss: -1.829,LR: 3.98E-04]Training epoch 30:  84%|████████▎ | 128/153 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 129,Loss: -2.564,Avg.Loss: -1.834,LR: 3.98E-04]Training epoch 30:  84%|████████▍ | 129/153 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 130,Loss: -2.634,Avg.Loss: -1.841,LR: 3.98E-04]Training epoch 30:  85%|████████▍ | 130/153 [00:02<00:00, 53.33it/s, Epoch: 30, Batch: 131,Loss: -2.552,Avg.Loss: -1.846,LR: 3.98E-04]Training epoch 30:  86%|████████▌ | 131/153 [00:02<00:00, 53.54it/s, Epoch: 30, Batch: 131,Loss: -2.552,Avg.Loss: -1.846,LR: 3.98E-04]Training epoch 30:  86%|████████▌ | 131/153 [00:02<00:00, 53.54it/s, Epoch: 30, Batch: 132,Loss: -2.132,Avg.Loss: -1.848,LR: 3.98E-04]Training epoch 30:  86%|████████▋ | 132/153 [00:02<00:00, 53.54it/s, Epoch: 30, Batch: 133,Loss: -2.549,Avg.Loss: -1.853,LR: 3.98E-04]Training epoch 30:  87%|████████▋ | 133/153 [00:02<00:00, 53.54it/s, Epoch: 30, Batch: 134,Loss: -2.224,Avg.Loss: -1.856,LR: 3.98E-04]Training epoch 30:  88%|████████▊ | 134/153 [00:02<00:00, 53.54it/s, Epoch: 30, Batch: 135,Loss: -1.949,Avg.Loss: -1.857,LR: 3.98E-04]Training epoch 30:  88%|████████▊ | 135/153 [00:02<00:00, 53.54it/s, Epoch: 30, Batch: 136,Loss: -1.516,Avg.Loss: -1.854,LR: 3.98E-04]Training epoch 30:  89%|████████▉ | 136/153 [00:02<00:00, 53.54it/s, Epoch: 30, Batch: 137,Loss: -2.334,Avg.Loss: -1.858,LR: 3.98E-04]Training epoch 30:  90%|████████▉ | 137/153 [00:02<00:00, 53.57it/s, Epoch: 30, Batch: 137,Loss: -2.334,Avg.Loss: -1.858,LR: 3.98E-04]Training epoch 30:  90%|████████▉ | 137/153 [00:02<00:00, 53.57it/s, Epoch: 30, Batch: 138,Loss: -2.251,Avg.Loss: -1.861,LR: 3.98E-04]Training epoch 30:  90%|█████████ | 138/153 [00:02<00:00, 53.57it/s, Epoch: 30, Batch: 139,Loss: -2.249,Avg.Loss: -1.864,LR: 3.98E-04]Training epoch 30:  91%|█████████ | 139/153 [00:02<00:00, 53.57it/s, Epoch: 30, Batch: 140,Loss: -2.399,Avg.Loss: -1.867,LR: 3.97E-04]Training epoch 30:  92%|█████████▏| 140/153 [00:02<00:00, 53.57it/s, Epoch: 30, Batch: 141,Loss: -2.291,Avg.Loss: -1.870,LR: 3.97E-04]Training epoch 30:  92%|█████████▏| 141/153 [00:02<00:00, 53.57it/s, Epoch: 30, Batch: 142,Loss: -1.879,Avg.Loss: -1.870,LR: 3.97E-04]Training epoch 30:  93%|█████████▎| 142/153 [00:02<00:00, 53.57it/s, Epoch: 30, Batch: 143,Loss: -1.750,Avg.Loss: -1.870,LR: 3.97E-04]Training epoch 30:  93%|█████████▎| 143/153 [00:02<00:00, 53.40it/s, Epoch: 30, Batch: 143,Loss: -1.750,Avg.Loss: -1.870,LR: 3.97E-04]Training epoch 30:  93%|█████████▎| 143/153 [00:02<00:00, 53.40it/s, Epoch: 30, Batch: 144,Loss: -1.760,Avg.Loss: -1.869,LR: 3.97E-04]Training epoch 30:  94%|█████████▍| 144/153 [00:02<00:00, 53.40it/s, Epoch: 30, Batch: 145,Loss: -1.775,Avg.Loss: -1.868,LR: 3.97E-04]Training epoch 30:  95%|█████████▍| 145/153 [00:02<00:00, 53.40it/s, Epoch: 30, Batch: 146,Loss: -2.391,Avg.Loss: -1.872,LR: 3.97E-04]Training epoch 30:  95%|█████████▌| 146/153 [00:02<00:00, 53.40it/s, Epoch: 30, Batch: 147,Loss: -1.628,Avg.Loss: -1.870,LR: 3.97E-04]Training epoch 30:  96%|█████████▌| 147/153 [00:02<00:00, 53.40it/s, Epoch: 30, Batch: 148,Loss: -1.103,Avg.Loss: -1.865,LR: 3.97E-04]Training epoch 30:  97%|█████████▋| 148/153 [00:02<00:00, 53.40it/s, Epoch: 30, Batch: 149,Loss: -1.560,Avg.Loss: -1.863,LR: 3.97E-04]Training epoch 30:  97%|█████████▋| 149/153 [00:02<00:00, 53.24it/s, Epoch: 30, Batch: 149,Loss: -1.560,Avg.Loss: -1.863,LR: 3.97E-04]Training epoch 30:  97%|█████████▋| 149/153 [00:02<00:00, 53.24it/s, Epoch: 30, Batch: 150,Loss: -2.142,Avg.Loss: -1.865,LR: 3.97E-04]Training epoch 30:  98%|█████████▊| 150/153 [00:02<00:00, 53.24it/s, Epoch: 30, Batch: 151,Loss: -2.458,Avg.Loss: -1.869,LR: 3.97E-04]Training epoch 30:  99%|█████████▊| 151/153 [00:02<00:00, 53.24it/s, Epoch: 30, Batch: 152,Loss: -2.160,Avg.Loss: -1.871,LR: 3.97E-04]Training epoch 30:  99%|█████████▉| 152/153 [00:02<00:00, 53.24it/s, Epoch: 30, Batch: 153,Loss: -1.599,Avg.Loss: -1.869,LR: 3.97E-04]Training epoch 30: 100%|██████████| 153/153 [00:02<00:00, 53.00it/s, Epoch: 30, Batch: 153,Loss: -1.599,Avg.Loss: -1.869,LR: 3.97E-04]
Training epoch 31:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 31:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 31, Batch: 1,Loss: -1.648,Avg.Loss: -1.648,LR: 3.97E-04]Training epoch 31:   1%|          | 1/153 [00:00<00:06, 25.32it/s, Epoch: 31, Batch: 2,Loss: -1.747,Avg.Loss: -1.697,LR: 3.97E-04]Training epoch 31:   1%|▏         | 2/153 [00:00<00:04, 34.67it/s, Epoch: 31, Batch: 3,Loss: -2.000,Avg.Loss: -1.798,LR: 3.97E-04]Training epoch 31:   2%|▏         | 3/153 [00:00<00:03, 40.67it/s, Epoch: 31, Batch: 4,Loss: -1.797,Avg.Loss: -1.798,LR: 3.97E-04]Training epoch 31:   3%|▎         | 4/153 [00:00<00:03, 43.93it/s, Epoch: 31, Batch: 5,Loss: -2.262,Avg.Loss: -1.891,LR: 3.97E-04]Training epoch 31:   3%|▎         | 5/153 [00:00<00:03, 45.74it/s, Epoch: 31, Batch: 6,Loss: -2.370,Avg.Loss: -1.971,LR: 3.97E-04]Training epoch 31:   4%|▍         | 6/153 [00:00<00:02, 54.79it/s, Epoch: 31, Batch: 6,Loss: -2.370,Avg.Loss: -1.971,LR: 3.97E-04]Training epoch 31:   4%|▍         | 6/153 [00:00<00:02, 54.79it/s, Epoch: 31, Batch: 7,Loss: -1.933,Avg.Loss: -1.965,LR: 3.97E-04]Training epoch 31:   5%|▍         | 7/153 [00:00<00:02, 54.79it/s, Epoch: 31, Batch: 8,Loss: -2.428,Avg.Loss: -2.023,LR: 3.97E-04]Training epoch 31:   5%|▌         | 8/153 [00:00<00:02, 54.79it/s, Epoch: 31, Batch: 9,Loss: -2.357,Avg.Loss: -2.060,LR: 3.97E-04]Training epoch 31:   6%|▌         | 9/153 [00:00<00:02, 54.79it/s, Epoch: 31, Batch: 10,Loss: -2.527,Avg.Loss: -2.107,LR: 3.97E-04]Training epoch 31:   7%|▋         | 10/153 [00:00<00:02, 54.79it/s, Epoch: 31, Batch: 11,Loss: -2.481,Avg.Loss: -2.141,LR: 3.96E-04]Training epoch 31:   7%|▋         | 11/153 [00:00<00:02, 54.79it/s, Epoch: 31, Batch: 12,Loss: -2.265,Avg.Loss: -2.151,LR: 3.96E-04]Training epoch 31:   8%|▊         | 12/153 [00:00<00:02, 53.78it/s, Epoch: 31, Batch: 12,Loss: -2.265,Avg.Loss: -2.151,LR: 3.96E-04]Training epoch 31:   8%|▊         | 12/153 [00:00<00:02, 53.78it/s, Epoch: 31, Batch: 13,Loss: -1.601,Avg.Loss: -2.109,LR: 3.96E-04]Training epoch 31:   8%|▊         | 13/153 [00:00<00:02, 53.78it/s, Epoch: 31, Batch: 14,Loss: -1.695,Avg.Loss: -2.079,LR: 3.96E-04]Training epoch 31:   9%|▉         | 14/153 [00:00<00:02, 53.78it/s, Epoch: 31, Batch: 15,Loss: -1.942,Avg.Loss: -2.070,LR: 3.96E-04]Training epoch 31:  10%|▉         | 15/153 [00:00<00:02, 53.78it/s, Epoch: 31, Batch: 16,Loss: -2.328,Avg.Loss: -2.086,LR: 3.96E-04]Training epoch 31:  10%|█         | 16/153 [00:00<00:02, 53.78it/s, Epoch: 31, Batch: 17,Loss: -2.042,Avg.Loss: -2.084,LR: 3.96E-04]Training epoch 31:  11%|█         | 17/153 [00:00<00:02, 53.78it/s, Epoch: 31, Batch: 18,Loss: -1.772,Avg.Loss: -2.066,LR: 3.96E-04]Training epoch 31:  12%|█▏        | 18/153 [00:00<00:02, 53.13it/s, Epoch: 31, Batch: 18,Loss: -1.772,Avg.Loss: -2.066,LR: 3.96E-04]Training epoch 31:  12%|█▏        | 18/153 [00:00<00:02, 53.13it/s, Epoch: 31, Batch: 19,Loss: -1.467,Avg.Loss: -2.035,LR: 3.96E-04]Training epoch 31:  12%|█▏        | 19/153 [00:00<00:02, 53.13it/s, Epoch: 31, Batch: 20,Loss: -1.606,Avg.Loss: -2.013,LR: 3.96E-04]Training epoch 31:  13%|█▎        | 20/153 [00:00<00:02, 53.13it/s, Epoch: 31, Batch: 21,Loss: -0.869,Avg.Loss: -1.959,LR: 3.96E-04]Training epoch 31:  14%|█▎        | 21/153 [00:00<00:02, 53.13it/s, Epoch: 31, Batch: 22,Loss: -1.279,Avg.Loss: -1.928,LR: 3.96E-04]Training epoch 31:  14%|█▍        | 22/153 [00:00<00:02, 53.13it/s, Epoch: 31, Batch: 23,Loss: -0.714,Avg.Loss: -1.875,LR: 3.96E-04]Training epoch 31:  15%|█▌        | 23/153 [00:00<00:02, 53.13it/s, Epoch: 31, Batch: 24,Loss: -1.840,Avg.Loss: -1.874,LR: 3.96E-04]Training epoch 31:  16%|█▌        | 24/153 [00:00<00:02, 53.04it/s, Epoch: 31, Batch: 24,Loss: -1.840,Avg.Loss: -1.874,LR: 3.96E-04]Training epoch 31:  16%|█▌        | 24/153 [00:00<00:02, 53.04it/s, Epoch: 31, Batch: 25,Loss: -1.767,Avg.Loss: -1.869,LR: 3.96E-04]Training epoch 31:  16%|█▋        | 25/153 [00:00<00:02, 53.04it/s, Epoch: 31, Batch: 26,Loss: -2.648,Avg.Loss: -1.899,LR: 3.96E-04]Training epoch 31:  17%|█▋        | 26/153 [00:00<00:02, 53.04it/s, Epoch: 31, Batch: 27,Loss: -1.440,Avg.Loss: -1.882,LR: 3.96E-04]Training epoch 31:  18%|█▊        | 27/153 [00:00<00:02, 53.04it/s, Epoch: 31, Batch: 28,Loss: -1.417,Avg.Loss: -1.866,LR: 3.96E-04]Training epoch 31:  18%|█▊        | 28/153 [00:00<00:02, 53.04it/s, Epoch: 31, Batch: 29,Loss: -0.818,Avg.Loss: -1.830,LR: 3.96E-04]Training epoch 31:  19%|█▉        | 29/153 [00:00<00:02, 53.04it/s, Epoch: 31, Batch: 30,Loss: -0.726,Avg.Loss: -1.793,LR: 3.96E-04]Training epoch 31:  20%|█▉        | 30/153 [00:00<00:02, 52.44it/s, Epoch: 31, Batch: 30,Loss: -0.726,Avg.Loss: -1.793,LR: 3.96E-04]Training epoch 31:  20%|█▉        | 30/153 [00:00<00:02, 52.44it/s, Epoch: 31, Batch: 31,Loss: -0.903,Avg.Loss: -1.764,LR: 3.96E-04]Training epoch 31:  20%|██        | 31/153 [00:00<00:02, 52.44it/s, Epoch: 31, Batch: 32,Loss: -2.538,Avg.Loss: -1.788,LR: 3.96E-04]Training epoch 31:  21%|██        | 32/153 [00:00<00:02, 52.44it/s, Epoch: 31, Batch: 33,Loss: -2.002,Avg.Loss: -1.795,LR: 3.96E-04]Training epoch 31:  22%|██▏       | 33/153 [00:00<00:02, 52.44it/s, Epoch: 31, Batch: 34,Loss: -1.372,Avg.Loss: -1.782,LR: 3.96E-04]Training epoch 31:  22%|██▏       | 34/153 [00:00<00:02, 52.44it/s, Epoch: 31, Batch: 35,Loss: -0.767,Avg.Loss: -1.753,LR: 3.95E-04]Training epoch 31:  23%|██▎       | 35/153 [00:00<00:02, 52.44it/s, Epoch: 31, Batch: 36,Loss: -2.328,Avg.Loss: -1.769,LR: 3.95E-04]Training epoch 31:  24%|██▎       | 36/153 [00:00<00:02, 52.43it/s, Epoch: 31, Batch: 36,Loss: -2.328,Avg.Loss: -1.769,LR: 3.95E-04]Training epoch 31:  24%|██▎       | 36/153 [00:00<00:02, 52.43it/s, Epoch: 31, Batch: 37,Loss: -2.514,Avg.Loss: -1.789,LR: 3.95E-04]Training epoch 31:  24%|██▍       | 37/153 [00:00<00:02, 52.43it/s, Epoch: 31, Batch: 38,Loss: -1.551,Avg.Loss: -1.783,LR: 3.95E-04]Training epoch 31:  25%|██▍       | 38/153 [00:00<00:02, 52.43it/s, Epoch: 31, Batch: 39,Loss: -0.635,Avg.Loss: -1.754,LR: 3.95E-04]Training epoch 31:  25%|██▌       | 39/153 [00:00<00:02, 52.43it/s, Epoch: 31, Batch: 40,Loss: -0.909,Avg.Loss: -1.733,LR: 3.95E-04]Training epoch 31:  26%|██▌       | 40/153 [00:00<00:02, 52.43it/s, Epoch: 31, Batch: 41,Loss: -0.757,Avg.Loss: -1.709,LR: 3.95E-04]Training epoch 31:  27%|██▋       | 41/153 [00:00<00:02, 52.43it/s, Epoch: 31, Batch: 42,Loss: -2.486,Avg.Loss: -1.727,LR: 3.95E-04]Training epoch 31:  27%|██▋       | 42/153 [00:00<00:02, 52.76it/s, Epoch: 31, Batch: 42,Loss: -2.486,Avg.Loss: -1.727,LR: 3.95E-04]Training epoch 31:  27%|██▋       | 42/153 [00:00<00:02, 52.76it/s, Epoch: 31, Batch: 43,Loss: -2.244,Avg.Loss: -1.739,LR: 3.95E-04]Training epoch 31:  28%|██▊       | 43/153 [00:00<00:02, 52.76it/s, Epoch: 31, Batch: 44,Loss: -1.841,Avg.Loss: -1.742,LR: 3.95E-04]Training epoch 31:  29%|██▉       | 44/153 [00:00<00:02, 52.76it/s, Epoch: 31, Batch: 45,Loss: -1.898,Avg.Loss: -1.745,LR: 3.95E-04]Training epoch 31:  29%|██▉       | 45/153 [00:00<00:02, 52.76it/s, Epoch: 31, Batch: 46,Loss: -1.585,Avg.Loss: -1.742,LR: 3.95E-04]Training epoch 31:  30%|███       | 46/153 [00:00<00:02, 52.76it/s, Epoch: 31, Batch: 47,Loss: -2.374,Avg.Loss: -1.755,LR: 3.95E-04]Training epoch 31:  31%|███       | 47/153 [00:00<00:02, 52.76it/s, Epoch: 31, Batch: 48,Loss: -1.675,Avg.Loss: -1.753,LR: 3.95E-04]Training epoch 31:  31%|███▏      | 48/153 [00:00<00:01, 53.11it/s, Epoch: 31, Batch: 48,Loss: -1.675,Avg.Loss: -1.753,LR: 3.95E-04]Training epoch 31:  31%|███▏      | 48/153 [00:00<00:01, 53.11it/s, Epoch: 31, Batch: 49,Loss: -1.641,Avg.Loss: -1.751,LR: 3.95E-04]Training epoch 31:  32%|███▏      | 49/153 [00:00<00:01, 53.11it/s, Epoch: 31, Batch: 50,Loss: -1.705,Avg.Loss: -1.750,LR: 3.95E-04]Training epoch 31:  33%|███▎      | 50/153 [00:00<00:01, 53.11it/s, Epoch: 31, Batch: 51,Loss: -1.830,Avg.Loss: -1.752,LR: 3.95E-04]Training epoch 31:  33%|███▎      | 51/153 [00:00<00:01, 53.11it/s, Epoch: 31, Batch: 52,Loss: -2.019,Avg.Loss: -1.757,LR: 3.95E-04]Training epoch 31:  34%|███▍      | 52/153 [00:00<00:01, 53.11it/s, Epoch: 31, Batch: 53,Loss: -1.357,Avg.Loss: -1.749,LR: 3.95E-04]Training epoch 31:  35%|███▍      | 53/153 [00:01<00:01, 53.11it/s, Epoch: 31, Batch: 54,Loss: -2.230,Avg.Loss: -1.758,LR: 3.95E-04]Training epoch 31:  35%|███▌      | 54/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 54,Loss: -2.230,Avg.Loss: -1.758,LR: 3.95E-04]Training epoch 31:  35%|███▌      | 54/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 55,Loss: -2.204,Avg.Loss: -1.766,LR: 3.95E-04]Training epoch 31:  36%|███▌      | 55/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 56,Loss: -1.934,Avg.Loss: -1.769,LR: 3.95E-04]Training epoch 31:  37%|███▋      | 56/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 57,Loss: -2.368,Avg.Loss: -1.780,LR: 3.95E-04]Training epoch 31:  37%|███▋      | 57/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 58,Loss: -2.513,Avg.Loss: -1.793,LR: 3.95E-04]Training epoch 31:  38%|███▊      | 58/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 59,Loss: -2.349,Avg.Loss: -1.802,LR: 3.94E-04]Training epoch 31:  39%|███▊      | 59/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 60,Loss: -2.103,Avg.Loss: -1.807,LR: 3.94E-04]Training epoch 31:  39%|███▉      | 60/153 [00:01<00:01, 53.67it/s, Epoch: 31, Batch: 60,Loss: -2.103,Avg.Loss: -1.807,LR: 3.94E-04]Training epoch 31:  39%|███▉      | 60/153 [00:01<00:01, 53.67it/s, Epoch: 31, Batch: 61,Loss: -2.203,Avg.Loss: -1.813,LR: 3.94E-04]Training epoch 31:  40%|███▉      | 61/153 [00:01<00:01, 53.67it/s, Epoch: 31, Batch: 62,Loss: -1.844,Avg.Loss: -1.814,LR: 3.94E-04]Training epoch 31:  41%|████      | 62/153 [00:01<00:01, 53.67it/s, Epoch: 31, Batch: 63,Loss: -2.340,Avg.Loss: -1.822,LR: 3.94E-04]Training epoch 31:  41%|████      | 63/153 [00:01<00:01, 53.67it/s, Epoch: 31, Batch: 64,Loss: -2.515,Avg.Loss: -1.833,LR: 3.94E-04]Training epoch 31:  42%|████▏     | 64/153 [00:01<00:01, 53.67it/s, Epoch: 31, Batch: 65,Loss: -2.388,Avg.Loss: -1.842,LR: 3.94E-04]Training epoch 31:  42%|████▏     | 65/153 [00:01<00:01, 53.67it/s, Epoch: 31, Batch: 66,Loss: -2.377,Avg.Loss: -1.850,LR: 3.94E-04]Training epoch 31:  43%|████▎     | 66/153 [00:01<00:01, 53.92it/s, Epoch: 31, Batch: 66,Loss: -2.377,Avg.Loss: -1.850,LR: 3.94E-04]Training epoch 31:  43%|████▎     | 66/153 [00:01<00:01, 53.92it/s, Epoch: 31, Batch: 67,Loss: -2.011,Avg.Loss: -1.852,LR: 3.94E-04]Training epoch 31:  44%|████▍     | 67/153 [00:01<00:01, 53.92it/s, Epoch: 31, Batch: 68,Loss: -2.204,Avg.Loss: -1.857,LR: 3.94E-04]Training epoch 31:  44%|████▍     | 68/153 [00:01<00:01, 53.92it/s, Epoch: 31, Batch: 69,Loss: -2.246,Avg.Loss: -1.863,LR: 3.94E-04]Training epoch 31:  45%|████▌     | 69/153 [00:01<00:01, 53.92it/s, Epoch: 31, Batch: 70,Loss: -2.388,Avg.Loss: -1.871,LR: 3.94E-04]Training epoch 31:  46%|████▌     | 70/153 [00:01<00:01, 53.92it/s, Epoch: 31, Batch: 71,Loss: -2.169,Avg.Loss: -1.875,LR: 3.94E-04]Training epoch 31:  46%|████▋     | 71/153 [00:01<00:01, 53.92it/s, Epoch: 31, Batch: 72,Loss: -2.372,Avg.Loss: -1.882,LR: 3.94E-04]Training epoch 31:  47%|████▋     | 72/153 [00:01<00:01, 53.69it/s, Epoch: 31, Batch: 72,Loss: -2.372,Avg.Loss: -1.882,LR: 3.94E-04]Training epoch 31:  47%|████▋     | 72/153 [00:01<00:01, 53.69it/s, Epoch: 31, Batch: 73,Loss: -2.404,Avg.Loss: -1.889,LR: 3.94E-04]Training epoch 31:  48%|████▊     | 73/153 [00:01<00:01, 53.69it/s, Epoch: 31, Batch: 74,Loss: -2.724,Avg.Loss: -1.900,LR: 3.94E-04]Training epoch 31:  48%|████▊     | 74/153 [00:01<00:01, 53.69it/s, Epoch: 31, Batch: 75,Loss: -2.223,Avg.Loss: -1.904,LR: 3.94E-04]Training epoch 31:  49%|████▉     | 75/153 [00:01<00:01, 53.69it/s, Epoch: 31, Batch: 76,Loss: -2.275,Avg.Loss: -1.909,LR: 3.94E-04]Training epoch 31:  50%|████▉     | 76/153 [00:01<00:01, 53.69it/s, Epoch: 31, Batch: 77,Loss: -2.235,Avg.Loss: -1.913,LR: 3.94E-04]Training epoch 31:  50%|█████     | 77/153 [00:01<00:01, 53.69it/s, Epoch: 31, Batch: 78,Loss: -1.913,Avg.Loss: -1.913,LR: 3.94E-04]Training epoch 31:  51%|█████     | 78/153 [00:01<00:01, 53.41it/s, Epoch: 31, Batch: 78,Loss: -1.913,Avg.Loss: -1.913,LR: 3.94E-04]Training epoch 31:  51%|█████     | 78/153 [00:01<00:01, 53.41it/s, Epoch: 31, Batch: 79,Loss: -2.191,Avg.Loss: -1.917,LR: 3.94E-04]Training epoch 31:  52%|█████▏    | 79/153 [00:01<00:01, 53.41it/s, Epoch: 31, Batch: 80,Loss: -2.291,Avg.Loss: -1.922,LR: 3.94E-04]Training epoch 31:  52%|█████▏    | 80/153 [00:01<00:01, 53.41it/s, Epoch: 31, Batch: 81,Loss: -1.863,Avg.Loss: -1.921,LR: 3.94E-04]Training epoch 31:  53%|█████▎    | 81/153 [00:01<00:01, 53.41it/s, Epoch: 31, Batch: 82,Loss: -1.846,Avg.Loss: -1.920,LR: 3.94E-04]Training epoch 31:  54%|█████▎    | 82/153 [00:01<00:01, 53.41it/s, Epoch: 31, Batch: 83,Loss: -2.305,Avg.Loss: -1.925,LR: 3.93E-04]Training epoch 31:  54%|█████▍    | 83/153 [00:01<00:01, 53.41it/s, Epoch: 31, Batch: 84,Loss: -2.029,Avg.Loss: -1.926,LR: 3.93E-04]Training epoch 31:  55%|█████▍    | 84/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 84,Loss: -2.029,Avg.Loss: -1.926,LR: 3.93E-04]Training epoch 31:  55%|█████▍    | 84/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 85,Loss: -2.122,Avg.Loss: -1.928,LR: 3.93E-04]Training epoch 31:  56%|█████▌    | 85/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 86,Loss: -2.663,Avg.Loss: -1.937,LR: 3.93E-04]Training epoch 31:  56%|█████▌    | 86/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 87,Loss: -2.051,Avg.Loss: -1.938,LR: 3.93E-04]Training epoch 31:  57%|█████▋    | 87/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 88,Loss: -2.364,Avg.Loss: -1.943,LR: 3.93E-04]Training epoch 31:  58%|█████▊    | 88/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 89,Loss: -2.465,Avg.Loss: -1.949,LR: 3.93E-04]Training epoch 31:  58%|█████▊    | 89/153 [00:01<00:01, 53.30it/s, Epoch: 31, Batch: 90,Loss: -2.150,Avg.Loss: -1.951,LR: 3.93E-04]Training epoch 31:  59%|█████▉    | 90/153 [00:01<00:01, 53.55it/s, Epoch: 31, Batch: 90,Loss: -2.150,Avg.Loss: -1.951,LR: 3.93E-04]Training epoch 31:  59%|█████▉    | 90/153 [00:01<00:01, 53.55it/s, Epoch: 31, Batch: 91,Loss: -2.505,Avg.Loss: -1.957,LR: 3.93E-04]Training epoch 31:  59%|█████▉    | 91/153 [00:01<00:01, 53.55it/s, Epoch: 31, Batch: 92,Loss: -2.467,Avg.Loss: -1.963,LR: 3.93E-04]Training epoch 31:  60%|██████    | 92/153 [00:01<00:01, 53.55it/s, Epoch: 31, Batch: 93,Loss: -2.822,Avg.Loss: -1.972,LR: 3.93E-04]Training epoch 31:  61%|██████    | 93/153 [00:01<00:01, 53.55it/s, Epoch: 31, Batch: 94,Loss: -2.676,Avg.Loss: -1.979,LR: 3.93E-04]Training epoch 31:  61%|██████▏   | 94/153 [00:01<00:01, 53.55it/s, Epoch: 31, Batch: 95,Loss: -2.297,Avg.Loss: -1.983,LR: 3.93E-04]Training epoch 31:  62%|██████▏   | 95/153 [00:01<00:01, 53.55it/s, Epoch: 31, Batch: 96,Loss: -2.293,Avg.Loss: -1.986,LR: 3.93E-04]Training epoch 31:  63%|██████▎   | 96/153 [00:01<00:01, 53.50it/s, Epoch: 31, Batch: 96,Loss: -2.293,Avg.Loss: -1.986,LR: 3.93E-04]Training epoch 31:  63%|██████▎   | 96/153 [00:01<00:01, 53.50it/s, Epoch: 31, Batch: 97,Loss: -1.899,Avg.Loss: -1.985,LR: 3.93E-04]Training epoch 31:  63%|██████▎   | 97/153 [00:01<00:01, 53.50it/s, Epoch: 31, Batch: 98,Loss: -1.304,Avg.Loss: -1.978,LR: 3.93E-04]Training epoch 31:  64%|██████▍   | 98/153 [00:01<00:01, 53.50it/s, Epoch: 31, Batch: 99,Loss: -2.003,Avg.Loss: -1.978,LR: 3.93E-04]Training epoch 31:  65%|██████▍   | 99/153 [00:01<00:01, 53.50it/s, Epoch: 31, Batch: 100,Loss: -2.435,Avg.Loss: -1.983,LR: 3.93E-04]Training epoch 31:  65%|██████▌   | 100/153 [00:01<00:00, 53.50it/s, Epoch: 31, Batch: 101,Loss: -2.035,Avg.Loss: -1.983,LR: 3.93E-04]Training epoch 31:  66%|██████▌   | 101/153 [00:01<00:00, 53.50it/s, Epoch: 31, Batch: 102,Loss: -1.266,Avg.Loss: -1.976,LR: 3.93E-04]Training epoch 31:  67%|██████▋   | 102/153 [00:01<00:00, 53.54it/s, Epoch: 31, Batch: 102,Loss: -1.266,Avg.Loss: -1.976,LR: 3.93E-04]Training epoch 31:  67%|██████▋   | 102/153 [00:01<00:00, 53.54it/s, Epoch: 31, Batch: 103,Loss: -1.534,Avg.Loss: -1.972,LR: 3.93E-04]Training epoch 31:  67%|██████▋   | 103/153 [00:01<00:00, 53.54it/s, Epoch: 31, Batch: 104,Loss: -1.920,Avg.Loss: -1.972,LR: 3.93E-04]Training epoch 31:  68%|██████▊   | 104/153 [00:01<00:00, 53.54it/s, Epoch: 31, Batch: 105,Loss: -1.499,Avg.Loss: -1.967,LR: 3.93E-04]Training epoch 31:  69%|██████▊   | 105/153 [00:01<00:00, 53.54it/s, Epoch: 31, Batch: 106,Loss: -2.142,Avg.Loss: -1.969,LR: 3.93E-04]Training epoch 31:  69%|██████▉   | 106/153 [00:02<00:00, 53.54it/s, Epoch: 31, Batch: 107,Loss: -2.993,Avg.Loss: -1.978,LR: 3.92E-04]Training epoch 31:  70%|██████▉   | 107/153 [00:02<00:00, 53.54it/s, Epoch: 31, Batch: 108,Loss: -1.323,Avg.Loss: -1.972,LR: 3.92E-04]Training epoch 31:  71%|███████   | 108/153 [00:02<00:00, 53.53it/s, Epoch: 31, Batch: 108,Loss: -1.323,Avg.Loss: -1.972,LR: 3.92E-04]Training epoch 31:  71%|███████   | 108/153 [00:02<00:00, 53.53it/s, Epoch: 31, Batch: 109,Loss: -1.253,Avg.Loss: -1.966,LR: 3.92E-04]Training epoch 31:  71%|███████   | 109/153 [00:02<00:00, 53.53it/s, Epoch: 31, Batch: 110,Loss: -1.660,Avg.Loss: -1.963,LR: 3.92E-04]Training epoch 31:  72%|███████▏  | 110/153 [00:02<00:00, 53.53it/s, Epoch: 31, Batch: 111,Loss: -2.602,Avg.Loss: -1.969,LR: 3.92E-04]Training epoch 31:  73%|███████▎  | 111/153 [00:02<00:00, 53.53it/s, Epoch: 31, Batch: 112,Loss: -1.761,Avg.Loss: -1.967,LR: 3.92E-04]Training epoch 31:  73%|███████▎  | 112/153 [00:02<00:00, 53.53it/s, Epoch: 31, Batch: 113,Loss: -2.236,Avg.Loss: -1.969,LR: 3.92E-04]Training epoch 31:  74%|███████▍  | 113/153 [00:02<00:00, 53.53it/s, Epoch: 31, Batch: 114,Loss: -2.439,Avg.Loss: -1.973,LR: 3.92E-04]Training epoch 31:  75%|███████▍  | 114/153 [00:02<00:00, 53.67it/s, Epoch: 31, Batch: 114,Loss: -2.439,Avg.Loss: -1.973,LR: 3.92E-04]Training epoch 31:  75%|███████▍  | 114/153 [00:02<00:00, 53.67it/s, Epoch: 31, Batch: 115,Loss: -2.162,Avg.Loss: -1.975,LR: 3.92E-04]Training epoch 31:  75%|███████▌  | 115/153 [00:02<00:00, 53.67it/s, Epoch: 31, Batch: 116,Loss: -2.825,Avg.Loss: -1.982,LR: 3.92E-04]Training epoch 31:  76%|███████▌  | 116/153 [00:02<00:00, 53.67it/s, Epoch: 31, Batch: 117,Loss: -2.252,Avg.Loss: -1.985,LR: 3.92E-04]Training epoch 31:  76%|███████▋  | 117/153 [00:02<00:00, 53.67it/s, Epoch: 31, Batch: 118,Loss: -2.121,Avg.Loss: -1.986,LR: 3.92E-04]Training epoch 31:  77%|███████▋  | 118/153 [00:02<00:00, 53.67it/s, Epoch: 31, Batch: 119,Loss: -1.169,Avg.Loss: -1.979,LR: 3.92E-04]Training epoch 31:  78%|███████▊  | 119/153 [00:02<00:00, 53.67it/s, Epoch: 31, Batch: 120,Loss: -2.325,Avg.Loss: -1.982,LR: 3.92E-04]Training epoch 31:  78%|███████▊  | 120/153 [00:02<00:00, 53.44it/s, Epoch: 31, Batch: 120,Loss: -2.325,Avg.Loss: -1.982,LR: 3.92E-04]Training epoch 31:  78%|███████▊  | 120/153 [00:02<00:00, 53.44it/s, Epoch: 31, Batch: 121,Loss: -1.687,Avg.Loss: -1.979,LR: 3.92E-04]Training epoch 31:  79%|███████▉  | 121/153 [00:02<00:00, 53.44it/s, Epoch: 31, Batch: 122,Loss: -2.097,Avg.Loss: -1.980,LR: 3.92E-04]Training epoch 31:  80%|███████▉  | 122/153 [00:02<00:00, 53.44it/s, Epoch: 31, Batch: 123,Loss: -1.807,Avg.Loss: -1.979,LR: 3.92E-04]Training epoch 31:  80%|████████  | 123/153 [00:02<00:00, 53.44it/s, Epoch: 31, Batch: 124,Loss: -2.416,Avg.Loss: -1.982,LR: 3.92E-04]Training epoch 31:  81%|████████  | 124/153 [00:02<00:00, 53.44it/s, Epoch: 31, Batch: 125,Loss: -2.528,Avg.Loss: -1.987,LR: 3.92E-04]Training epoch 31:  82%|████████▏ | 125/153 [00:02<00:00, 53.44it/s, Epoch: 31, Batch: 126,Loss: -2.105,Avg.Loss: -1.988,LR: 3.92E-04]Training epoch 31:  82%|████████▏ | 126/153 [00:02<00:00, 53.39it/s, Epoch: 31, Batch: 126,Loss: -2.105,Avg.Loss: -1.988,LR: 3.92E-04]Training epoch 31:  82%|████████▏ | 126/153 [00:02<00:00, 53.39it/s, Epoch: 31, Batch: 127,Loss: -2.160,Avg.Loss: -1.989,LR: 3.92E-04]Training epoch 31:  83%|████████▎ | 127/153 [00:02<00:00, 53.39it/s, Epoch: 31, Batch: 128,Loss: -2.233,Avg.Loss: -1.991,LR: 3.92E-04]Training epoch 31:  84%|████████▎ | 128/153 [00:02<00:00, 53.39it/s, Epoch: 31, Batch: 129,Loss: -2.193,Avg.Loss: -1.992,LR: 3.92E-04]Training epoch 31:  84%|████████▍ | 129/153 [00:02<00:00, 53.39it/s, Epoch: 31, Batch: 130,Loss: -1.875,Avg.Loss: -1.992,LR: 3.91E-04]Training epoch 31:  85%|████████▍ | 130/153 [00:02<00:00, 53.39it/s, Epoch: 31, Batch: 131,Loss: -2.284,Avg.Loss: -1.994,LR: 3.91E-04]Training epoch 31:  86%|████████▌ | 131/153 [00:02<00:00, 53.39it/s, Epoch: 31, Batch: 132,Loss: -1.980,Avg.Loss: -1.994,LR: 3.91E-04]Training epoch 31:  86%|████████▋ | 132/153 [00:02<00:00, 53.59it/s, Epoch: 31, Batch: 132,Loss: -1.980,Avg.Loss: -1.994,LR: 3.91E-04]Training epoch 31:  86%|████████▋ | 132/153 [00:02<00:00, 53.59it/s, Epoch: 31, Batch: 133,Loss: -2.337,Avg.Loss: -1.996,LR: 3.91E-04]Training epoch 31:  87%|████████▋ | 133/153 [00:02<00:00, 53.59it/s, Epoch: 31, Batch: 134,Loss: 0.299,Avg.Loss: -1.979,LR: 3.91E-04] Training epoch 31:  88%|████████▊ | 134/153 [00:02<00:00, 53.59it/s, Epoch: 31, Batch: 135,Loss: 0.425,Avg.Loss: -1.961,LR: 3.91E-04]Training epoch 31:  88%|████████▊ | 135/153 [00:02<00:00, 53.59it/s, Epoch: 31, Batch: 136,Loss: -0.421,Avg.Loss: -1.950,LR: 3.91E-04]Training epoch 31:  89%|████████▉ | 136/153 [00:02<00:00, 53.59it/s, Epoch: 31, Batch: 137,Loss: -1.019,Avg.Loss: -1.943,LR: 3.91E-04]Training epoch 31:  90%|████████▉ | 137/153 [00:02<00:00, 53.59it/s, Epoch: 31, Batch: 138,Loss: -1.541,Avg.Loss: -1.940,LR: 3.91E-04]Training epoch 31:  90%|█████████ | 138/153 [00:02<00:00, 53.48it/s, Epoch: 31, Batch: 138,Loss: -1.541,Avg.Loss: -1.940,LR: 3.91E-04]Training epoch 31:  90%|█████████ | 138/153 [00:02<00:00, 53.48it/s, Epoch: 31, Batch: 139,Loss: -0.142,Avg.Loss: -1.927,LR: 3.91E-04]Training epoch 31:  91%|█████████ | 139/153 [00:02<00:00, 53.48it/s, Epoch: 31, Batch: 140,Loss: -0.834,Avg.Loss: -1.920,LR: 3.91E-04]Training epoch 31:  92%|█████████▏| 140/153 [00:02<00:00, 53.48it/s, Epoch: 31, Batch: 141,Loss: -2.215,Avg.Loss: -1.922,LR: 3.91E-04]Training epoch 31:  92%|█████████▏| 141/153 [00:02<00:00, 53.48it/s, Epoch: 31, Batch: 142,Loss: -1.276,Avg.Loss: -1.917,LR: 3.91E-04]Training epoch 31:  93%|█████████▎| 142/153 [00:02<00:00, 53.48it/s, Epoch: 31, Batch: 143,Loss: -0.154,Avg.Loss: -1.905,LR: 3.91E-04]Training epoch 31:  93%|█████████▎| 143/153 [00:02<00:00, 53.48it/s, Epoch: 31, Batch: 144,Loss: -0.394,Avg.Loss: -1.894,LR: 3.91E-04]Training epoch 31:  94%|█████████▍| 144/153 [00:02<00:00, 53.47it/s, Epoch: 31, Batch: 144,Loss: -0.394,Avg.Loss: -1.894,LR: 3.91E-04]Training epoch 31:  94%|█████████▍| 144/153 [00:02<00:00, 53.47it/s, Epoch: 31, Batch: 145,Loss: -2.142,Avg.Loss: -1.896,LR: 3.91E-04]Training epoch 31:  95%|█████████▍| 145/153 [00:02<00:00, 53.47it/s, Epoch: 31, Batch: 146,Loss: -1.271,Avg.Loss: -1.892,LR: 3.91E-04]Training epoch 31:  95%|█████████▌| 146/153 [00:02<00:00, 53.47it/s, Epoch: 31, Batch: 147,Loss: 0.508,Avg.Loss: -1.875,LR: 3.91E-04] Training epoch 31:  96%|█████████▌| 147/153 [00:02<00:00, 53.47it/s, Epoch: 31, Batch: 148,Loss: 0.188,Avg.Loss: -1.861,LR: 3.91E-04]Training epoch 31:  97%|█████████▋| 148/153 [00:02<00:00, 53.47it/s, Epoch: 31, Batch: 149,Loss: -1.773,Avg.Loss: -1.861,LR: 3.91E-04]Training epoch 31:  97%|█████████▋| 149/153 [00:02<00:00, 53.47it/s, Epoch: 31, Batch: 150,Loss: -1.975,Avg.Loss: -1.862,LR: 3.91E-04]Training epoch 31:  98%|█████████▊| 150/153 [00:02<00:00, 53.57it/s, Epoch: 31, Batch: 150,Loss: -1.975,Avg.Loss: -1.862,LR: 3.91E-04]Training epoch 31:  98%|█████████▊| 150/153 [00:02<00:00, 53.57it/s, Epoch: 31, Batch: 151,Loss: -0.731,Avg.Loss: -1.854,LR: 3.91E-04]Training epoch 31:  99%|█████████▊| 151/153 [00:02<00:00, 53.57it/s, Epoch: 31, Batch: 152,Loss: -1.006,Avg.Loss: -1.849,LR: 3.91E-04]Training epoch 31:  99%|█████████▉| 152/153 [00:02<00:00, 53.57it/s, Epoch: 31, Batch: 153,Loss: -2.491,Avg.Loss: -1.853,LR: 3.91E-04]Training epoch 31: 100%|██████████| 153/153 [00:02<00:00, 53.31it/s, Epoch: 31, Batch: 153,Loss: -2.491,Avg.Loss: -1.853,LR: 3.91E-04]
Training epoch 32:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 32:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 32, Batch: 1,Loss: -1.233,Avg.Loss: -1.233,LR: 3.90E-04]Training epoch 32:   1%|          | 1/153 [00:00<00:06, 23.56it/s, Epoch: 32, Batch: 2,Loss: -0.819,Avg.Loss: -1.026,LR: 3.90E-04]Training epoch 32:   1%|▏         | 2/153 [00:00<00:04, 33.32it/s, Epoch: 32, Batch: 3,Loss: -0.712,Avg.Loss: -0.921,LR: 3.90E-04]Training epoch 32:   2%|▏         | 3/153 [00:00<00:03, 38.97it/s, Epoch: 32, Batch: 4,Loss: -2.474,Avg.Loss: -1.309,LR: 3.90E-04]Training epoch 32:   3%|▎         | 4/153 [00:00<00:03, 42.18it/s, Epoch: 32, Batch: 5,Loss: -1.882,Avg.Loss: -1.424,LR: 3.90E-04]Training epoch 32:   3%|▎         | 5/153 [00:00<00:03, 44.13it/s, Epoch: 32, Batch: 6,Loss: -0.836,Avg.Loss: -1.326,LR: 3.90E-04]Training epoch 32:   4%|▍         | 6/153 [00:00<00:02, 52.87it/s, Epoch: 32, Batch: 6,Loss: -0.836,Avg.Loss: -1.326,LR: 3.90E-04]Training epoch 32:   4%|▍         | 6/153 [00:00<00:02, 52.87it/s, Epoch: 32, Batch: 7,Loss: -1.217,Avg.Loss: -1.310,LR: 3.90E-04]Training epoch 32:   5%|▍         | 7/153 [00:00<00:02, 52.87it/s, Epoch: 32, Batch: 8,Loss: -2.488,Avg.Loss: -1.457,LR: 3.90E-04]Training epoch 32:   5%|▌         | 8/153 [00:00<00:02, 52.87it/s, Epoch: 32, Batch: 9,Loss: -0.749,Avg.Loss: -1.379,LR: 3.90E-04]Training epoch 32:   6%|▌         | 9/153 [00:00<00:02, 52.87it/s, Epoch: 32, Batch: 10,Loss: 1.337,Avg.Loss: -1.107,LR: 3.90E-04]Training epoch 32:   7%|▋         | 10/153 [00:00<00:02, 52.87it/s, Epoch: 32, Batch: 11,Loss: 0.203,Avg.Loss: -0.988,LR: 3.90E-04]Training epoch 32:   7%|▋         | 11/153 [00:00<00:02, 52.87it/s, Epoch: 32, Batch: 12,Loss: -1.415,Avg.Loss: -1.024,LR: 3.90E-04]Training epoch 32:   8%|▊         | 12/153 [00:00<00:02, 52.73it/s, Epoch: 32, Batch: 12,Loss: -1.415,Avg.Loss: -1.024,LR: 3.90E-04]Training epoch 32:   8%|▊         | 12/153 [00:00<00:02, 52.73it/s, Epoch: 32, Batch: 13,Loss: -2.639,Avg.Loss: -1.148,LR: 3.90E-04]Training epoch 32:   8%|▊         | 13/153 [00:00<00:02, 52.73it/s, Epoch: 32, Batch: 14,Loss: -1.924,Avg.Loss: -1.203,LR: 3.90E-04]Training epoch 32:   9%|▉         | 14/153 [00:00<00:02, 52.73it/s, Epoch: 32, Batch: 15,Loss: -1.725,Avg.Loss: -1.238,LR: 3.90E-04]Training epoch 32:  10%|▉         | 15/153 [00:00<00:02, 52.73it/s, Epoch: 32, Batch: 16,Loss: -2.290,Avg.Loss: -1.304,LR: 3.90E-04]Training epoch 32:  10%|█         | 16/153 [00:00<00:02, 52.73it/s, Epoch: 32, Batch: 17,Loss: -1.712,Avg.Loss: -1.328,LR: 3.90E-04]Training epoch 32:  11%|█         | 17/153 [00:00<00:02, 52.73it/s, Epoch: 32, Batch: 18,Loss: -1.255,Avg.Loss: -1.324,LR: 3.90E-04]Training epoch 32:  12%|█▏        | 18/153 [00:00<00:02, 53.24it/s, Epoch: 32, Batch: 18,Loss: -1.255,Avg.Loss: -1.324,LR: 3.90E-04]Training epoch 32:  12%|█▏        | 18/153 [00:00<00:02, 53.24it/s, Epoch: 32, Batch: 19,Loss: -0.773,Avg.Loss: -1.295,LR: 3.90E-04]Training epoch 32:  12%|█▏        | 19/153 [00:00<00:02, 53.24it/s, Epoch: 32, Batch: 20,Loss: -1.000,Avg.Loss: -1.280,LR: 3.90E-04]Training epoch 32:  13%|█▎        | 20/153 [00:00<00:02, 53.24it/s, Epoch: 32, Batch: 21,Loss: -0.395,Avg.Loss: -1.238,LR: 3.90E-04]Training epoch 32:  14%|█▎        | 21/153 [00:00<00:02, 53.24it/s, Epoch: 32, Batch: 22,Loss: -1.005,Avg.Loss: -1.227,LR: 3.90E-04]Training epoch 32:  14%|█▍        | 22/153 [00:00<00:02, 53.24it/s, Epoch: 32, Batch: 23,Loss: -1.790,Avg.Loss: -1.252,LR: 3.90E-04]Training epoch 32:  15%|█▌        | 23/153 [00:00<00:02, 53.24it/s, Epoch: 32, Batch: 24,Loss: -1.438,Avg.Loss: -1.260,LR: 3.90E-04]Training epoch 32:  16%|█▌        | 24/153 [00:00<00:02, 52.85it/s, Epoch: 32, Batch: 24,Loss: -1.438,Avg.Loss: -1.260,LR: 3.90E-04]Training epoch 32:  16%|█▌        | 24/153 [00:00<00:02, 52.85it/s, Epoch: 32, Batch: 25,Loss: -1.872,Avg.Loss: -1.284,LR: 3.89E-04]Training epoch 32:  16%|█▋        | 25/153 [00:00<00:02, 52.85it/s, Epoch: 32, Batch: 26,Loss: -0.813,Avg.Loss: -1.266,LR: 3.89E-04]Training epoch 32:  17%|█▋        | 26/153 [00:00<00:02, 52.85it/s, Epoch: 32, Batch: 27,Loss: -1.793,Avg.Loss: -1.286,LR: 3.89E-04]Training epoch 32:  18%|█▊        | 27/153 [00:00<00:02, 52.85it/s, Epoch: 32, Batch: 28,Loss: -1.818,Avg.Loss: -1.305,LR: 3.89E-04]Training epoch 32:  18%|█▊        | 28/153 [00:00<00:02, 52.85it/s, Epoch: 32, Batch: 29,Loss: -0.952,Avg.Loss: -1.292,LR: 3.89E-04]Training epoch 32:  19%|█▉        | 29/153 [00:00<00:02, 52.85it/s, Epoch: 32, Batch: 30,Loss: -1.424,Avg.Loss: -1.297,LR: 3.89E-04]Training epoch 32:  20%|█▉        | 30/153 [00:00<00:02, 52.18it/s, Epoch: 32, Batch: 30,Loss: -1.424,Avg.Loss: -1.297,LR: 3.89E-04]Training epoch 32:  20%|█▉        | 30/153 [00:00<00:02, 52.18it/s, Epoch: 32, Batch: 31,Loss: -1.964,Avg.Loss: -1.318,LR: 3.89E-04]Training epoch 32:  20%|██        | 31/153 [00:00<00:02, 52.18it/s, Epoch: 32, Batch: 32,Loss: -2.321,Avg.Loss: -1.350,LR: 3.89E-04]Training epoch 32:  21%|██        | 32/153 [00:00<00:02, 52.18it/s, Epoch: 32, Batch: 33,Loss: -0.952,Avg.Loss: -1.338,LR: 3.89E-04]Training epoch 32:  22%|██▏       | 33/153 [00:00<00:02, 52.18it/s, Epoch: 32, Batch: 34,Loss: -0.166,Avg.Loss: -1.303,LR: 3.89E-04]Training epoch 32:  22%|██▏       | 34/153 [00:00<00:02, 52.18it/s, Epoch: 32, Batch: 35,Loss: -0.992,Avg.Loss: -1.294,LR: 3.89E-04]Training epoch 32:  23%|██▎       | 35/153 [00:00<00:02, 52.18it/s, Epoch: 32, Batch: 36,Loss: -1.511,Avg.Loss: -1.300,LR: 3.89E-04]Training epoch 32:  24%|██▎       | 36/153 [00:00<00:02, 52.38it/s, Epoch: 32, Batch: 36,Loss: -1.511,Avg.Loss: -1.300,LR: 3.89E-04]Training epoch 32:  24%|██▎       | 36/153 [00:00<00:02, 52.38it/s, Epoch: 32, Batch: 37,Loss: -0.092,Avg.Loss: -1.268,LR: 3.89E-04]Training epoch 32:  24%|██▍       | 37/153 [00:00<00:02, 52.38it/s, Epoch: 32, Batch: 38,Loss: 1.016,Avg.Loss: -1.207,LR: 3.89E-04] Training epoch 32:  25%|██▍       | 38/153 [00:00<00:02, 52.38it/s, Epoch: 32, Batch: 39,Loss: -0.018,Avg.Loss: -1.177,LR: 3.89E-04]Training epoch 32:  25%|██▌       | 39/153 [00:00<00:02, 52.38it/s, Epoch: 32, Batch: 40,Loss: -1.601,Avg.Loss: -1.188,LR: 3.89E-04]Training epoch 32:  26%|██▌       | 40/153 [00:00<00:02, 52.38it/s, Epoch: 32, Batch: 41,Loss: -0.417,Avg.Loss: -1.169,LR: 3.89E-04]Training epoch 32:  27%|██▋       | 41/153 [00:00<00:02, 52.38it/s, Epoch: 32, Batch: 42,Loss: 2.975,Avg.Loss: -1.070,LR: 3.89E-04] Training epoch 32:  27%|██▋       | 42/153 [00:00<00:02, 52.67it/s, Epoch: 32, Batch: 42,Loss: 2.975,Avg.Loss: -1.070,LR: 3.89E-04]Training epoch 32:  27%|██▋       | 42/153 [00:00<00:02, 52.67it/s, Epoch: 32, Batch: 43,Loss: 1.234,Avg.Loss: -1.017,LR: 3.89E-04]Training epoch 32:  28%|██▊       | 43/153 [00:00<00:02, 52.67it/s, Epoch: 32, Batch: 44,Loss: -0.010,Avg.Loss: -0.994,LR: 3.89E-04]Training epoch 32:  29%|██▉       | 44/153 [00:00<00:02, 52.67it/s, Epoch: 32, Batch: 45,Loss: -1.649,Avg.Loss: -1.008,LR: 3.89E-04]Training epoch 32:  29%|██▉       | 45/153 [00:00<00:02, 52.67it/s, Epoch: 32, Batch: 46,Loss: 1.180,Avg.Loss: -0.961,LR: 3.89E-04] Training epoch 32:  30%|███       | 46/153 [00:00<00:02, 52.67it/s, Epoch: 32, Batch: 47,Loss: 2.304,Avg.Loss: -0.891,LR: 3.89E-04]Training epoch 32:  31%|███       | 47/153 [00:00<00:02, 52.67it/s, Epoch: 32, Batch: 48,Loss: 5.237,Avg.Loss: -0.764,LR: 3.88E-04]Training epoch 32:  31%|███▏      | 48/153 [00:00<00:01, 52.72it/s, Epoch: 32, Batch: 48,Loss: 5.237,Avg.Loss: -0.764,LR: 3.88E-04]Training epoch 32:  31%|███▏      | 48/153 [00:00<00:01, 52.72it/s, Epoch: 32, Batch: 49,Loss: 2.815,Avg.Loss: -0.691,LR: 3.88E-04]Training epoch 32:  32%|███▏      | 49/153 [00:00<00:01, 52.72it/s, Epoch: 32, Batch: 50,Loss: -0.535,Avg.Loss: -0.687,LR: 3.88E-04]Training epoch 32:  33%|███▎      | 50/153 [00:00<00:01, 52.72it/s, Epoch: 32, Batch: 51,Loss: -0.592,Avg.Loss: -0.686,LR: 3.88E-04]Training epoch 32:  33%|███▎      | 51/153 [00:00<00:01, 52.72it/s, Epoch: 32, Batch: 52,Loss: 1.691,Avg.Loss: -0.640,LR: 3.88E-04] Training epoch 32:  34%|███▍      | 52/153 [00:01<00:01, 52.72it/s, Epoch: 32, Batch: 53,Loss: 1.640,Avg.Loss: -0.597,LR: 3.88E-04]Training epoch 32:  35%|███▍      | 53/153 [00:01<00:01, 52.72it/s, Epoch: 32, Batch: 54,Loss: -0.248,Avg.Loss: -0.590,LR: 3.88E-04]Training epoch 32:  35%|███▌      | 54/153 [00:01<00:01, 52.90it/s, Epoch: 32, Batch: 54,Loss: -0.248,Avg.Loss: -0.590,LR: 3.88E-04]Training epoch 32:  35%|███▌      | 54/153 [00:01<00:01, 52.90it/s, Epoch: 32, Batch: 55,Loss: -1.026,Avg.Loss: -0.598,LR: 3.88E-04]Training epoch 32:  36%|███▌      | 55/153 [00:01<00:01, 52.90it/s, Epoch: 32, Batch: 56,Loss: -1.109,Avg.Loss: -0.607,LR: 3.88E-04]Training epoch 32:  37%|███▋      | 56/153 [00:01<00:01, 52.90it/s, Epoch: 32, Batch: 57,Loss: -0.141,Avg.Loss: -0.599,LR: 3.88E-04]Training epoch 32:  37%|███▋      | 57/153 [00:01<00:01, 52.90it/s, Epoch: 32, Batch: 58,Loss: -0.491,Avg.Loss: -0.597,LR: 3.88E-04]Training epoch 32:  38%|███▊      | 58/153 [00:01<00:01, 52.90it/s, Epoch: 32, Batch: 59,Loss: -1.416,Avg.Loss: -0.611,LR: 3.88E-04]Training epoch 32:  39%|███▊      | 59/153 [00:01<00:01, 52.90it/s, Epoch: 32, Batch: 60,Loss: -1.547,Avg.Loss: -0.627,LR: 3.88E-04]Training epoch 32:  39%|███▉      | 60/153 [00:01<00:01, 52.95it/s, Epoch: 32, Batch: 60,Loss: -1.547,Avg.Loss: -0.627,LR: 3.88E-04]Training epoch 32:  39%|███▉      | 60/153 [00:01<00:01, 52.95it/s, Epoch: 32, Batch: 61,Loss: -1.371,Avg.Loss: -0.639,LR: 3.88E-04]Training epoch 32:  40%|███▉      | 61/153 [00:01<00:01, 52.95it/s, Epoch: 32, Batch: 62,Loss: -1.546,Avg.Loss: -0.654,LR: 3.88E-04]Training epoch 32:  41%|████      | 62/153 [00:01<00:01, 52.95it/s, Epoch: 32, Batch: 63,Loss: -2.034,Avg.Loss: -0.676,LR: 3.88E-04]Training epoch 32:  41%|████      | 63/153 [00:01<00:01, 52.95it/s, Epoch: 32, Batch: 64,Loss: -1.354,Avg.Loss: -0.686,LR: 3.88E-04]Training epoch 32:  42%|████▏     | 64/153 [00:01<00:01, 52.95it/s, Epoch: 32, Batch: 65,Loss: -0.189,Avg.Loss: -0.678,LR: 3.88E-04]Training epoch 32:  42%|████▏     | 65/153 [00:01<00:01, 52.95it/s, Epoch: 32, Batch: 66,Loss: -0.250,Avg.Loss: -0.672,LR: 3.88E-04]Training epoch 32:  43%|████▎     | 66/153 [00:01<00:01, 52.91it/s, Epoch: 32, Batch: 66,Loss: -0.250,Avg.Loss: -0.672,LR: 3.88E-04]Training epoch 32:  43%|████▎     | 66/153 [00:01<00:01, 52.91it/s, Epoch: 32, Batch: 67,Loss: -1.578,Avg.Loss: -0.686,LR: 3.88E-04]Training epoch 32:  44%|████▍     | 67/153 [00:01<00:01, 52.91it/s, Epoch: 32, Batch: 68,Loss: -1.758,Avg.Loss: -0.701,LR: 3.88E-04]Training epoch 32:  44%|████▍     | 68/153 [00:01<00:01, 52.91it/s, Epoch: 32, Batch: 69,Loss: 0.234,Avg.Loss: -0.688,LR: 3.88E-04] Training epoch 32:  45%|████▌     | 69/153 [00:01<00:01, 52.91it/s, Epoch: 32, Batch: 70,Loss: -1.154,Avg.Loss: -0.694,LR: 3.88E-04]Training epoch 32:  46%|████▌     | 70/153 [00:01<00:01, 52.91it/s, Epoch: 32, Batch: 71,Loss: -1.349,Avg.Loss: -0.704,LR: 3.87E-04]Training epoch 32:  46%|████▋     | 71/153 [00:01<00:01, 52.91it/s, Epoch: 32, Batch: 72,Loss: -2.094,Avg.Loss: -0.723,LR: 3.87E-04]Training epoch 32:  47%|████▋     | 72/153 [00:01<00:01, 53.04it/s, Epoch: 32, Batch: 72,Loss: -2.094,Avg.Loss: -0.723,LR: 3.87E-04]Training epoch 32:  47%|████▋     | 72/153 [00:01<00:01, 53.04it/s, Epoch: 32, Batch: 73,Loss: -2.314,Avg.Loss: -0.745,LR: 3.87E-04]Training epoch 32:  48%|████▊     | 73/153 [00:01<00:01, 53.04it/s, Epoch: 32, Batch: 74,Loss: -2.212,Avg.Loss: -0.765,LR: 3.87E-04]Training epoch 32:  48%|████▊     | 74/153 [00:01<00:01, 53.04it/s, Epoch: 32, Batch: 75,Loss: -1.827,Avg.Loss: -0.779,LR: 3.87E-04]Training epoch 32:  49%|████▉     | 75/153 [00:01<00:01, 53.04it/s, Epoch: 32, Batch: 76,Loss: -1.815,Avg.Loss: -0.792,LR: 3.87E-04]Training epoch 32:  50%|████▉     | 76/153 [00:01<00:01, 53.04it/s, Epoch: 32, Batch: 77,Loss: -2.443,Avg.Loss: -0.814,LR: 3.87E-04]Training epoch 32:  50%|█████     | 77/153 [00:01<00:01, 53.04it/s, Epoch: 32, Batch: 78,Loss: -1.503,Avg.Loss: -0.823,LR: 3.87E-04]Training epoch 32:  51%|█████     | 78/153 [00:01<00:01, 52.97it/s, Epoch: 32, Batch: 78,Loss: -1.503,Avg.Loss: -0.823,LR: 3.87E-04]Training epoch 32:  51%|█████     | 78/153 [00:01<00:01, 52.97it/s, Epoch: 32, Batch: 79,Loss: -1.044,Avg.Loss: -0.825,LR: 3.87E-04]Training epoch 32:  52%|█████▏    | 79/153 [00:01<00:01, 52.97it/s, Epoch: 32, Batch: 80,Loss: -1.652,Avg.Loss: -0.836,LR: 3.87E-04]Training epoch 32:  52%|█████▏    | 80/153 [00:01<00:01, 52.97it/s, Epoch: 32, Batch: 81,Loss: -2.088,Avg.Loss: -0.851,LR: 3.87E-04]Training epoch 32:  53%|█████▎    | 81/153 [00:01<00:01, 52.97it/s, Epoch: 32, Batch: 82,Loss: -2.290,Avg.Loss: -0.869,LR: 3.87E-04]Training epoch 32:  54%|█████▎    | 82/153 [00:01<00:01, 52.97it/s, Epoch: 32, Batch: 83,Loss: -2.241,Avg.Loss: -0.885,LR: 3.87E-04]Training epoch 32:  54%|█████▍    | 83/153 [00:01<00:01, 52.97it/s, Epoch: 32, Batch: 84,Loss: -2.095,Avg.Loss: -0.900,LR: 3.87E-04]Training epoch 32:  55%|█████▍    | 84/153 [00:01<00:01, 52.85it/s, Epoch: 32, Batch: 84,Loss: -2.095,Avg.Loss: -0.900,LR: 3.87E-04]Training epoch 32:  55%|█████▍    | 84/153 [00:01<00:01, 52.85it/s, Epoch: 32, Batch: 85,Loss: -2.103,Avg.Loss: -0.914,LR: 3.87E-04]Training epoch 32:  56%|█████▌    | 85/153 [00:01<00:01, 52.85it/s, Epoch: 32, Batch: 86,Loss: -2.528,Avg.Loss: -0.933,LR: 3.87E-04]Training epoch 32:  56%|█████▌    | 86/153 [00:01<00:01, 52.85it/s, Epoch: 32, Batch: 87,Loss: -1.443,Avg.Loss: -0.939,LR: 3.87E-04]Training epoch 32:  57%|█████▋    | 87/153 [00:01<00:01, 52.85it/s, Epoch: 32, Batch: 88,Loss: -1.303,Avg.Loss: -0.943,LR: 3.87E-04]Training epoch 32:  58%|█████▊    | 88/153 [00:01<00:01, 52.85it/s, Epoch: 32, Batch: 89,Loss: -1.937,Avg.Loss: -0.954,LR: 3.87E-04]Training epoch 32:  58%|█████▊    | 89/153 [00:01<00:01, 52.85it/s, Epoch: 32, Batch: 90,Loss: -2.302,Avg.Loss: -0.969,LR: 3.87E-04]Training epoch 32:  59%|█████▉    | 90/153 [00:01<00:01, 52.75it/s, Epoch: 32, Batch: 90,Loss: -2.302,Avg.Loss: -0.969,LR: 3.87E-04]Training epoch 32:  59%|█████▉    | 90/153 [00:01<00:01, 52.75it/s, Epoch: 32, Batch: 91,Loss: -2.003,Avg.Loss: -0.980,LR: 3.87E-04]Training epoch 32:  59%|█████▉    | 91/153 [00:01<00:01, 52.75it/s, Epoch: 32, Batch: 92,Loss: -2.143,Avg.Loss: -0.993,LR: 3.87E-04]Training epoch 32:  60%|██████    | 92/153 [00:01<00:01, 52.75it/s, Epoch: 32, Batch: 93,Loss: -2.021,Avg.Loss: -1.004,LR: 3.87E-04]Training epoch 32:  61%|██████    | 93/153 [00:01<00:01, 52.75it/s, Epoch: 32, Batch: 94,Loss: -1.617,Avg.Loss: -1.010,LR: 3.87E-04]Training epoch 32:  61%|██████▏   | 94/153 [00:01<00:01, 52.75it/s, Epoch: 32, Batch: 95,Loss: -2.246,Avg.Loss: -1.023,LR: 3.86E-04]Training epoch 32:  62%|██████▏   | 95/153 [00:01<00:01, 52.75it/s, Epoch: 32, Batch: 96,Loss: -2.331,Avg.Loss: -1.037,LR: 3.86E-04]Training epoch 32:  63%|██████▎   | 96/153 [00:01<00:01, 53.19it/s, Epoch: 32, Batch: 96,Loss: -2.331,Avg.Loss: -1.037,LR: 3.86E-04]Training epoch 32:  63%|██████▎   | 96/153 [00:01<00:01, 53.19it/s, Epoch: 32, Batch: 97,Loss: -2.409,Avg.Loss: -1.051,LR: 3.86E-04]Training epoch 32:  63%|██████▎   | 97/153 [00:01<00:01, 53.19it/s, Epoch: 32, Batch: 98,Loss: -2.056,Avg.Loss: -1.061,LR: 3.86E-04]Training epoch 32:  64%|██████▍   | 98/153 [00:01<00:01, 53.19it/s, Epoch: 32, Batch: 99,Loss: -2.116,Avg.Loss: -1.072,LR: 3.86E-04]Training epoch 32:  65%|██████▍   | 99/153 [00:01<00:01, 53.19it/s, Epoch: 32, Batch: 100,Loss: -1.963,Avg.Loss: -1.081,LR: 3.86E-04]Training epoch 32:  65%|██████▌   | 100/153 [00:01<00:00, 53.19it/s, Epoch: 32, Batch: 101,Loss: -1.859,Avg.Loss: -1.089,LR: 3.86E-04]Training epoch 32:  66%|██████▌   | 101/153 [00:01<00:00, 53.19it/s, Epoch: 32, Batch: 102,Loss: -2.487,Avg.Loss: -1.102,LR: 3.86E-04]Training epoch 32:  67%|██████▋   | 102/153 [00:01<00:00, 54.58it/s, Epoch: 32, Batch: 102,Loss: -2.487,Avg.Loss: -1.102,LR: 3.86E-04]Training epoch 32:  67%|██████▋   | 102/153 [00:01<00:00, 54.58it/s, Epoch: 32, Batch: 103,Loss: -2.218,Avg.Loss: -1.113,LR: 3.86E-04]Training epoch 32:  67%|██████▋   | 103/153 [00:01<00:00, 54.58it/s, Epoch: 32, Batch: 104,Loss: -2.478,Avg.Loss: -1.126,LR: 3.86E-04]Training epoch 32:  68%|██████▊   | 104/153 [00:01<00:00, 54.58it/s, Epoch: 32, Batch: 105,Loss: -2.189,Avg.Loss: -1.136,LR: 3.86E-04]Training epoch 32:  69%|██████▊   | 105/153 [00:01<00:00, 54.58it/s, Epoch: 32, Batch: 106,Loss: -2.187,Avg.Loss: -1.146,LR: 3.86E-04]Training epoch 32:  69%|██████▉   | 106/153 [00:02<00:00, 54.58it/s, Epoch: 32, Batch: 107,Loss: -2.493,Avg.Loss: -1.159,LR: 3.86E-04]Training epoch 32:  70%|██████▉   | 107/153 [00:02<00:00, 54.58it/s, Epoch: 32, Batch: 108,Loss: -2.128,Avg.Loss: -1.168,LR: 3.86E-04]Training epoch 32:  71%|███████   | 108/153 [00:02<00:00, 53.66it/s, Epoch: 32, Batch: 108,Loss: -2.128,Avg.Loss: -1.168,LR: 3.86E-04]Training epoch 32:  71%|███████   | 108/153 [00:02<00:00, 53.66it/s, Epoch: 32, Batch: 109,Loss: -2.155,Avg.Loss: -1.177,LR: 3.86E-04]Training epoch 32:  71%|███████   | 109/153 [00:02<00:00, 53.66it/s, Epoch: 32, Batch: 110,Loss: -1.393,Avg.Loss: -1.179,LR: 3.86E-04]Training epoch 32:  72%|███████▏  | 110/153 [00:02<00:00, 53.66it/s, Epoch: 32, Batch: 111,Loss: -2.212,Avg.Loss: -1.188,LR: 3.86E-04]Training epoch 32:  73%|███████▎  | 111/153 [00:02<00:00, 53.66it/s, Epoch: 32, Batch: 112,Loss: -2.410,Avg.Loss: -1.199,LR: 3.86E-04]Training epoch 32:  73%|███████▎  | 112/153 [00:02<00:00, 53.66it/s, Epoch: 32, Batch: 113,Loss: -2.100,Avg.Loss: -1.207,LR: 3.86E-04]Training epoch 32:  74%|███████▍  | 113/153 [00:02<00:00, 53.66it/s, Epoch: 32, Batch: 114,Loss: -2.177,Avg.Loss: -1.216,LR: 3.86E-04]Training epoch 32:  75%|███████▍  | 114/153 [00:02<00:00, 53.41it/s, Epoch: 32, Batch: 114,Loss: -2.177,Avg.Loss: -1.216,LR: 3.86E-04]Training epoch 32:  75%|███████▍  | 114/153 [00:02<00:00, 53.41it/s, Epoch: 32, Batch: 115,Loss: -2.258,Avg.Loss: -1.225,LR: 3.86E-04]Training epoch 32:  75%|███████▌  | 115/153 [00:02<00:00, 53.41it/s, Epoch: 32, Batch: 116,Loss: -2.482,Avg.Loss: -1.236,LR: 3.86E-04]Training epoch 32:  76%|███████▌  | 116/153 [00:02<00:00, 53.41it/s, Epoch: 32, Batch: 117,Loss: -1.978,Avg.Loss: -1.242,LR: 3.86E-04]Training epoch 32:  76%|███████▋  | 117/153 [00:02<00:00, 53.41it/s, Epoch: 32, Batch: 118,Loss: -2.226,Avg.Loss: -1.250,LR: 3.85E-04]Training epoch 32:  77%|███████▋  | 118/153 [00:02<00:00, 53.41it/s, Epoch: 32, Batch: 119,Loss: -2.155,Avg.Loss: -1.258,LR: 3.85E-04]Training epoch 32:  78%|███████▊  | 119/153 [00:02<00:00, 53.41it/s, Epoch: 32, Batch: 120,Loss: -2.366,Avg.Loss: -1.267,LR: 3.85E-04]Training epoch 32:  78%|███████▊  | 120/153 [00:02<00:00, 53.09it/s, Epoch: 32, Batch: 120,Loss: -2.366,Avg.Loss: -1.267,LR: 3.85E-04]Training epoch 32:  78%|███████▊  | 120/153 [00:02<00:00, 53.09it/s, Epoch: 32, Batch: 121,Loss: -2.414,Avg.Loss: -1.277,LR: 3.85E-04]Training epoch 32:  79%|███████▉  | 121/153 [00:02<00:00, 53.09it/s, Epoch: 32, Batch: 122,Loss: -1.641,Avg.Loss: -1.280,LR: 3.85E-04]Training epoch 32:  80%|███████▉  | 122/153 [00:02<00:00, 53.09it/s, Epoch: 32, Batch: 123,Loss: -1.826,Avg.Loss: -1.284,LR: 3.85E-04]Training epoch 32:  80%|████████  | 123/153 [00:02<00:00, 53.09it/s, Epoch: 32, Batch: 124,Loss: -2.160,Avg.Loss: -1.291,LR: 3.85E-04]Training epoch 32:  81%|████████  | 124/153 [00:02<00:00, 53.09it/s, Epoch: 32, Batch: 125,Loss: -1.823,Avg.Loss: -1.295,LR: 3.85E-04]Training epoch 32:  82%|████████▏ | 125/153 [00:02<00:00, 53.09it/s, Epoch: 32, Batch: 126,Loss: -1.285,Avg.Loss: -1.295,LR: 3.85E-04]Training epoch 32:  82%|████████▏ | 126/153 [00:02<00:00, 53.29it/s, Epoch: 32, Batch: 126,Loss: -1.285,Avg.Loss: -1.295,LR: 3.85E-04]Training epoch 32:  82%|████████▏ | 126/153 [00:02<00:00, 53.29it/s, Epoch: 32, Batch: 127,Loss: -1.981,Avg.Loss: -1.301,LR: 3.85E-04]Training epoch 32:  83%|████████▎ | 127/153 [00:02<00:00, 53.29it/s, Epoch: 32, Batch: 128,Loss: -2.550,Avg.Loss: -1.310,LR: 3.85E-04]Training epoch 32:  84%|████████▎ | 128/153 [00:02<00:00, 53.29it/s, Epoch: 32, Batch: 129,Loss: -0.998,Avg.Loss: -1.308,LR: 3.85E-04]Training epoch 32:  84%|████████▍ | 129/153 [00:02<00:00, 53.29it/s, Epoch: 32, Batch: 130,Loss: -0.004,Avg.Loss: -1.298,LR: 3.85E-04]Training epoch 32:  85%|████████▍ | 130/153 [00:02<00:00, 53.29it/s, Epoch: 32, Batch: 131,Loss: -0.841,Avg.Loss: -1.294,LR: 3.85E-04]Training epoch 32:  86%|████████▌ | 131/153 [00:02<00:00, 53.29it/s, Epoch: 32, Batch: 132,Loss: -1.661,Avg.Loss: -1.297,LR: 3.85E-04]Training epoch 32:  86%|████████▋ | 132/153 [00:02<00:00, 53.30it/s, Epoch: 32, Batch: 132,Loss: -1.661,Avg.Loss: -1.297,LR: 3.85E-04]Training epoch 32:  86%|████████▋ | 132/153 [00:02<00:00, 53.30it/s, Epoch: 32, Batch: 133,Loss: -0.885,Avg.Loss: -1.294,LR: 3.85E-04]Training epoch 32:  87%|████████▋ | 133/153 [00:02<00:00, 53.30it/s, Epoch: 32, Batch: 134,Loss: 1.303,Avg.Loss: -1.275,LR: 3.85E-04] Training epoch 32:  88%|████████▊ | 134/153 [00:02<00:00, 53.30it/s, Epoch: 32, Batch: 135,Loss: 1.775,Avg.Loss: -1.252,LR: 3.85E-04]Training epoch 32:  88%|████████▊ | 135/153 [00:02<00:00, 53.30it/s, Epoch: 32, Batch: 136,Loss: -0.705,Avg.Loss: -1.248,LR: 3.85E-04]Training epoch 32:  89%|████████▉ | 136/153 [00:02<00:00, 53.30it/s, Epoch: 32, Batch: 137,Loss: -1.303,Avg.Loss: -1.249,LR: 3.85E-04]Training epoch 32:  90%|████████▉ | 137/153 [00:02<00:00, 53.30it/s, Epoch: 32, Batch: 138,Loss: 0.638,Avg.Loss: -1.235,LR: 3.85E-04] Training epoch 32:  90%|█████████ | 138/153 [00:02<00:00, 53.46it/s, Epoch: 32, Batch: 138,Loss: 0.638,Avg.Loss: -1.235,LR: 3.85E-04]Training epoch 32:  90%|█████████ | 138/153 [00:02<00:00, 53.46it/s, Epoch: 32, Batch: 139,Loss: 1.800,Avg.Loss: -1.213,LR: 3.85E-04]Training epoch 32:  91%|█████████ | 139/153 [00:02<00:00, 53.46it/s, Epoch: 32, Batch: 140,Loss: 2.596,Avg.Loss: -1.186,LR: 3.85E-04]Training epoch 32:  92%|█████████▏| 140/153 [00:02<00:00, 53.46it/s, Epoch: 32, Batch: 141,Loss: 0.021,Avg.Loss: -1.177,LR: 3.84E-04]Training epoch 32:  92%|█████████▏| 141/153 [00:02<00:00, 53.46it/s, Epoch: 32, Batch: 142,Loss: -2.026,Avg.Loss: -1.183,LR: 3.84E-04]Training epoch 32:  93%|█████████▎| 142/153 [00:02<00:00, 53.46it/s, Epoch: 32, Batch: 143,Loss: -0.295,Avg.Loss: -1.177,LR: 3.84E-04]Training epoch 32:  93%|█████████▎| 143/153 [00:02<00:00, 53.46it/s, Epoch: 32, Batch: 144,Loss: 2.444,Avg.Loss: -1.152,LR: 3.84E-04] Training epoch 32:  94%|█████████▍| 144/153 [00:02<00:00, 53.54it/s, Epoch: 32, Batch: 144,Loss: 2.444,Avg.Loss: -1.152,LR: 3.84E-04]Training epoch 32:  94%|█████████▍| 144/153 [00:02<00:00, 53.54it/s, Epoch: 32, Batch: 145,Loss: 1.335,Avg.Loss: -1.135,LR: 3.84E-04]Training epoch 32:  95%|█████████▍| 145/153 [00:02<00:00, 53.54it/s, Epoch: 32, Batch: 146,Loss: 1.394,Avg.Loss: -1.117,LR: 3.84E-04]Training epoch 32:  95%|█████████▌| 146/153 [00:02<00:00, 53.54it/s, Epoch: 32, Batch: 147,Loss: -1.724,Avg.Loss: -1.122,LR: 3.84E-04]Training epoch 32:  96%|█████████▌| 147/153 [00:02<00:00, 53.54it/s, Epoch: 32, Batch: 148,Loss: -1.636,Avg.Loss: -1.125,LR: 3.84E-04]Training epoch 32:  97%|█████████▋| 148/153 [00:02<00:00, 53.54it/s, Epoch: 32, Batch: 149,Loss: -1.243,Avg.Loss: -1.126,LR: 3.84E-04]Training epoch 32:  97%|█████████▋| 149/153 [00:02<00:00, 53.54it/s, Epoch: 32, Batch: 150,Loss: -0.818,Avg.Loss: -1.124,LR: 3.84E-04]Training epoch 32:  98%|█████████▊| 150/153 [00:02<00:00, 53.40it/s, Epoch: 32, Batch: 150,Loss: -0.818,Avg.Loss: -1.124,LR: 3.84E-04]Training epoch 32:  98%|█████████▊| 150/153 [00:02<00:00, 53.40it/s, Epoch: 32, Batch: 151,Loss: -1.975,Avg.Loss: -1.129,LR: 3.84E-04]Training epoch 32:  99%|█████████▊| 151/153 [00:02<00:00, 53.40it/s, Epoch: 32, Batch: 152,Loss: -2.239,Avg.Loss: -1.137,LR: 3.84E-04]Training epoch 32:  99%|█████████▉| 152/153 [00:02<00:00, 53.40it/s, Epoch: 32, Batch: 153,Loss: -1.599,Avg.Loss: -1.140,LR: 3.84E-04]Training epoch 32: 100%|██████████| 153/153 [00:02<00:00, 53.07it/s, Epoch: 32, Batch: 153,Loss: -1.599,Avg.Loss: -1.140,LR: 3.84E-04]
Training epoch 33:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 33:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 33, Batch: 1,Loss: -1.567,Avg.Loss: -1.567,LR: 3.84E-04]Training epoch 33:   1%|          | 1/153 [00:00<00:05, 26.76it/s, Epoch: 33, Batch: 2,Loss: -1.689,Avg.Loss: -1.628,LR: 3.84E-04]Training epoch 33:   1%|▏         | 2/153 [00:00<00:03, 38.68it/s, Epoch: 33, Batch: 3,Loss: -2.144,Avg.Loss: -1.800,LR: 3.84E-04]Training epoch 33:   2%|▏         | 3/153 [00:00<00:03, 43.29it/s, Epoch: 33, Batch: 4,Loss: -2.445,Avg.Loss: -1.961,LR: 3.84E-04]Training epoch 33:   3%|▎         | 4/153 [00:00<00:03, 45.28it/s, Epoch: 33, Batch: 5,Loss: -1.899,Avg.Loss: -1.949,LR: 3.84E-04]Training epoch 33:   3%|▎         | 5/153 [00:00<00:03, 47.31it/s, Epoch: 33, Batch: 6,Loss: -2.274,Avg.Loss: -2.003,LR: 3.84E-04]Training epoch 33:   4%|▍         | 6/153 [00:00<00:02, 56.67it/s, Epoch: 33, Batch: 6,Loss: -2.274,Avg.Loss: -2.003,LR: 3.84E-04]Training epoch 33:   4%|▍         | 6/153 [00:00<00:02, 56.67it/s, Epoch: 33, Batch: 7,Loss: -1.845,Avg.Loss: -1.981,LR: 3.84E-04]Training epoch 33:   5%|▍         | 7/153 [00:00<00:02, 56.67it/s, Epoch: 33, Batch: 8,Loss: -1.754,Avg.Loss: -1.952,LR: 3.84E-04]Training epoch 33:   5%|▌         | 8/153 [00:00<00:02, 56.67it/s, Epoch: 33, Batch: 9,Loss: -1.663,Avg.Loss: -1.920,LR: 3.84E-04]Training epoch 33:   6%|▌         | 9/153 [00:00<00:02, 56.67it/s, Epoch: 33, Batch: 10,Loss: -2.044,Avg.Loss: -1.933,LR: 3.84E-04]Training epoch 33:   7%|▋         | 10/153 [00:00<00:02, 56.67it/s, Epoch: 33, Batch: 11,Loss: -2.302,Avg.Loss: -1.966,LR: 3.83E-04]Training epoch 33:   7%|▋         | 11/153 [00:00<00:02, 56.67it/s, Epoch: 33, Batch: 12,Loss: -2.204,Avg.Loss: -1.986,LR: 3.83E-04]Training epoch 33:   8%|▊         | 12/153 [00:00<00:02, 54.26it/s, Epoch: 33, Batch: 12,Loss: -2.204,Avg.Loss: -1.986,LR: 3.83E-04]Training epoch 33:   8%|▊         | 12/153 [00:00<00:02, 54.26it/s, Epoch: 33, Batch: 13,Loss: -2.217,Avg.Loss: -2.004,LR: 3.83E-04]Training epoch 33:   8%|▊         | 13/153 [00:00<00:02, 54.26it/s, Epoch: 33, Batch: 14,Loss: -1.640,Avg.Loss: -1.978,LR: 3.83E-04]Training epoch 33:   9%|▉         | 14/153 [00:00<00:02, 54.26it/s, Epoch: 33, Batch: 15,Loss: -1.771,Avg.Loss: -1.964,LR: 3.83E-04]Training epoch 33:  10%|▉         | 15/153 [00:00<00:02, 54.26it/s, Epoch: 33, Batch: 16,Loss: -1.773,Avg.Loss: -1.952,LR: 3.83E-04]Training epoch 33:  10%|█         | 16/153 [00:00<00:02, 54.26it/s, Epoch: 33, Batch: 17,Loss: -2.024,Avg.Loss: -1.956,LR: 3.83E-04]Training epoch 33:  11%|█         | 17/153 [00:00<00:02, 54.26it/s, Epoch: 33, Batch: 18,Loss: -1.979,Avg.Loss: -1.957,LR: 3.83E-04]Training epoch 33:  12%|█▏        | 18/153 [00:00<00:02, 53.46it/s, Epoch: 33, Batch: 18,Loss: -1.979,Avg.Loss: -1.957,LR: 3.83E-04]Training epoch 33:  12%|█▏        | 18/153 [00:00<00:02, 53.46it/s, Epoch: 33, Batch: 19,Loss: -1.951,Avg.Loss: -1.957,LR: 3.83E-04]Training epoch 33:  12%|█▏        | 19/153 [00:00<00:02, 53.46it/s, Epoch: 33, Batch: 20,Loss: -2.015,Avg.Loss: -1.960,LR: 3.83E-04]Training epoch 33:  13%|█▎        | 20/153 [00:00<00:02, 53.46it/s, Epoch: 33, Batch: 21,Loss: -2.124,Avg.Loss: -1.968,LR: 3.83E-04]Training epoch 33:  14%|█▎        | 21/153 [00:00<00:02, 53.46it/s, Epoch: 33, Batch: 22,Loss: -2.015,Avg.Loss: -1.970,LR: 3.83E-04]Training epoch 33:  14%|█▍        | 22/153 [00:00<00:02, 53.46it/s, Epoch: 33, Batch: 23,Loss: -2.201,Avg.Loss: -1.980,LR: 3.83E-04]Training epoch 33:  15%|█▌        | 23/153 [00:00<00:02, 53.46it/s, Epoch: 33, Batch: 24,Loss: -1.454,Avg.Loss: -1.958,LR: 3.83E-04]Training epoch 33:  16%|█▌        | 24/153 [00:00<00:02, 52.01it/s, Epoch: 33, Batch: 24,Loss: -1.454,Avg.Loss: -1.958,LR: 3.83E-04]Training epoch 33:  16%|█▌        | 24/153 [00:00<00:02, 52.01it/s, Epoch: 33, Batch: 25,Loss: -1.917,Avg.Loss: -1.956,LR: 3.83E-04]Training epoch 33:  16%|█▋        | 25/153 [00:00<00:02, 52.01it/s, Epoch: 33, Batch: 26,Loss: -2.474,Avg.Loss: -1.976,LR: 3.83E-04]Training epoch 33:  17%|█▋        | 26/153 [00:00<00:02, 52.01it/s, Epoch: 33, Batch: 27,Loss: -1.684,Avg.Loss: -1.966,LR: 3.83E-04]Training epoch 33:  18%|█▊        | 27/153 [00:00<00:02, 52.01it/s, Epoch: 33, Batch: 28,Loss: -2.378,Avg.Loss: -1.980,LR: 3.83E-04]Training epoch 33:  18%|█▊        | 28/153 [00:00<00:02, 52.01it/s, Epoch: 33, Batch: 29,Loss: -1.779,Avg.Loss: -1.973,LR: 3.83E-04]Training epoch 33:  19%|█▉        | 29/153 [00:00<00:02, 52.01it/s, Epoch: 33, Batch: 30,Loss: -2.002,Avg.Loss: -1.974,LR: 3.83E-04]Training epoch 33:  20%|█▉        | 30/153 [00:00<00:02, 51.57it/s, Epoch: 33, Batch: 30,Loss: -2.002,Avg.Loss: -1.974,LR: 3.83E-04]Training epoch 33:  20%|█▉        | 30/153 [00:00<00:02, 51.57it/s, Epoch: 33, Batch: 31,Loss: -2.225,Avg.Loss: -1.982,LR: 3.83E-04]Training epoch 33:  20%|██        | 31/153 [00:00<00:02, 51.57it/s, Epoch: 33, Batch: 32,Loss: -1.582,Avg.Loss: -1.970,LR: 3.83E-04]Training epoch 33:  21%|██        | 32/153 [00:00<00:02, 51.57it/s, Epoch: 33, Batch: 33,Loss: -1.616,Avg.Loss: -1.959,LR: 3.83E-04]Training epoch 33:  22%|██▏       | 33/153 [00:00<00:02, 51.57it/s, Epoch: 33, Batch: 34,Loss: -1.989,Avg.Loss: -1.960,LR: 3.82E-04]Training epoch 33:  22%|██▏       | 34/153 [00:00<00:02, 51.57it/s, Epoch: 33, Batch: 35,Loss: -2.400,Avg.Loss: -1.973,LR: 3.82E-04]Training epoch 33:  23%|██▎       | 35/153 [00:00<00:02, 51.57it/s, Epoch: 33, Batch: 36,Loss: -1.745,Avg.Loss: -1.966,LR: 3.82E-04]Training epoch 33:  24%|██▎       | 36/153 [00:00<00:02, 51.99it/s, Epoch: 33, Batch: 36,Loss: -1.745,Avg.Loss: -1.966,LR: 3.82E-04]Training epoch 33:  24%|██▎       | 36/153 [00:00<00:02, 51.99it/s, Epoch: 33, Batch: 37,Loss: -1.766,Avg.Loss: -1.961,LR: 3.82E-04]Training epoch 33:  24%|██▍       | 37/153 [00:00<00:02, 51.99it/s, Epoch: 33, Batch: 38,Loss: -2.140,Avg.Loss: -1.966,LR: 3.82E-04]Training epoch 33:  25%|██▍       | 38/153 [00:00<00:02, 51.99it/s, Epoch: 33, Batch: 39,Loss: -1.814,Avg.Loss: -1.962,LR: 3.82E-04]Training epoch 33:  25%|██▌       | 39/153 [00:00<00:02, 51.99it/s, Epoch: 33, Batch: 40,Loss: -2.301,Avg.Loss: -1.970,LR: 3.82E-04]Training epoch 33:  26%|██▌       | 40/153 [00:00<00:02, 51.99it/s, Epoch: 33, Batch: 41,Loss: -2.090,Avg.Loss: -1.973,LR: 3.82E-04]Training epoch 33:  27%|██▋       | 41/153 [00:00<00:02, 51.99it/s, Epoch: 33, Batch: 42,Loss: -2.324,Avg.Loss: -1.981,LR: 3.82E-04]Training epoch 33:  27%|██▋       | 42/153 [00:00<00:02, 52.27it/s, Epoch: 33, Batch: 42,Loss: -2.324,Avg.Loss: -1.981,LR: 3.82E-04]Training epoch 33:  27%|██▋       | 42/153 [00:00<00:02, 52.27it/s, Epoch: 33, Batch: 43,Loss: -2.162,Avg.Loss: -1.986,LR: 3.82E-04]Training epoch 33:  28%|██▊       | 43/153 [00:00<00:02, 52.27it/s, Epoch: 33, Batch: 44,Loss: -2.208,Avg.Loss: -1.991,LR: 3.82E-04]Training epoch 33:  29%|██▉       | 44/153 [00:00<00:02, 52.27it/s, Epoch: 33, Batch: 45,Loss: -1.931,Avg.Loss: -1.989,LR: 3.82E-04]Training epoch 33:  29%|██▉       | 45/153 [00:00<00:02, 52.27it/s, Epoch: 33, Batch: 46,Loss: -2.172,Avg.Loss: -1.993,LR: 3.82E-04]Training epoch 33:  30%|███       | 46/153 [00:00<00:02, 52.27it/s, Epoch: 33, Batch: 47,Loss: -2.567,Avg.Loss: -2.006,LR: 3.82E-04]Training epoch 33:  31%|███       | 47/153 [00:00<00:02, 52.27it/s, Epoch: 33, Batch: 48,Loss: -2.126,Avg.Loss: -2.008,LR: 3.82E-04]Training epoch 33:  31%|███▏      | 48/153 [00:00<00:02, 52.45it/s, Epoch: 33, Batch: 48,Loss: -2.126,Avg.Loss: -2.008,LR: 3.82E-04]Training epoch 33:  31%|███▏      | 48/153 [00:00<00:02, 52.45it/s, Epoch: 33, Batch: 49,Loss: -2.174,Avg.Loss: -2.011,LR: 3.82E-04]Training epoch 33:  32%|███▏      | 49/153 [00:00<00:01, 52.45it/s, Epoch: 33, Batch: 50,Loss: -2.159,Avg.Loss: -2.014,LR: 3.82E-04]Training epoch 33:  33%|███▎      | 50/153 [00:00<00:01, 52.45it/s, Epoch: 33, Batch: 51,Loss: -1.830,Avg.Loss: -2.011,LR: 3.82E-04]Training epoch 33:  33%|███▎      | 51/153 [00:00<00:01, 52.45it/s, Epoch: 33, Batch: 52,Loss: -2.165,Avg.Loss: -2.014,LR: 3.82E-04]Training epoch 33:  34%|███▍      | 52/153 [00:01<00:01, 52.45it/s, Epoch: 33, Batch: 53,Loss: -2.222,Avg.Loss: -2.018,LR: 3.82E-04]Training epoch 33:  35%|███▍      | 53/153 [00:01<00:01, 52.45it/s, Epoch: 33, Batch: 54,Loss: -1.390,Avg.Loss: -2.006,LR: 3.82E-04]Training epoch 33:  35%|███▌      | 54/153 [00:01<00:01, 52.64it/s, Epoch: 33, Batch: 54,Loss: -1.390,Avg.Loss: -2.006,LR: 3.82E-04]Training epoch 33:  35%|███▌      | 54/153 [00:01<00:01, 52.64it/s, Epoch: 33, Batch: 55,Loss: -2.348,Avg.Loss: -2.012,LR: 3.82E-04]Training epoch 33:  36%|███▌      | 55/153 [00:01<00:01, 52.64it/s, Epoch: 33, Batch: 56,Loss: -2.099,Avg.Loss: -2.014,LR: 3.82E-04]Training epoch 33:  37%|███▋      | 56/153 [00:01<00:01, 52.64it/s, Epoch: 33, Batch: 57,Loss: -2.128,Avg.Loss: -2.016,LR: 3.81E-04]Training epoch 33:  37%|███▋      | 57/153 [00:01<00:01, 52.64it/s, Epoch: 33, Batch: 58,Loss: -2.422,Avg.Loss: -2.023,LR: 3.81E-04]Training epoch 33:  38%|███▊      | 58/153 [00:01<00:01, 52.64it/s, Epoch: 33, Batch: 59,Loss: -1.886,Avg.Loss: -2.021,LR: 3.81E-04]Training epoch 33:  39%|███▊      | 59/153 [00:01<00:01, 52.64it/s, Epoch: 33, Batch: 60,Loss: -2.013,Avg.Loss: -2.020,LR: 3.81E-04]Training epoch 33:  39%|███▉      | 60/153 [00:01<00:01, 53.11it/s, Epoch: 33, Batch: 60,Loss: -2.013,Avg.Loss: -2.020,LR: 3.81E-04]Training epoch 33:  39%|███▉      | 60/153 [00:01<00:01, 53.11it/s, Epoch: 33, Batch: 61,Loss: -2.241,Avg.Loss: -2.024,LR: 3.81E-04]Training epoch 33:  40%|███▉      | 61/153 [00:01<00:01, 53.11it/s, Epoch: 33, Batch: 62,Loss: -1.997,Avg.Loss: -2.024,LR: 3.81E-04]Training epoch 33:  41%|████      | 62/153 [00:01<00:01, 53.11it/s, Epoch: 33, Batch: 63,Loss: -1.475,Avg.Loss: -2.015,LR: 3.81E-04]Training epoch 33:  41%|████      | 63/153 [00:01<00:01, 53.11it/s, Epoch: 33, Batch: 64,Loss: -1.979,Avg.Loss: -2.014,LR: 3.81E-04]Training epoch 33:  42%|████▏     | 64/153 [00:01<00:01, 53.11it/s, Epoch: 33, Batch: 65,Loss: -2.402,Avg.Loss: -2.020,LR: 3.81E-04]Training epoch 33:  42%|████▏     | 65/153 [00:01<00:01, 53.11it/s, Epoch: 33, Batch: 66,Loss: -2.127,Avg.Loss: -2.022,LR: 3.81E-04]Training epoch 33:  43%|████▎     | 66/153 [00:01<00:01, 52.83it/s, Epoch: 33, Batch: 66,Loss: -2.127,Avg.Loss: -2.022,LR: 3.81E-04]Training epoch 33:  43%|████▎     | 66/153 [00:01<00:01, 52.83it/s, Epoch: 33, Batch: 67,Loss: -2.868,Avg.Loss: -2.035,LR: 3.81E-04]Training epoch 33:  44%|████▍     | 67/153 [00:01<00:01, 52.83it/s, Epoch: 33, Batch: 68,Loss: -2.192,Avg.Loss: -2.037,LR: 3.81E-04]Training epoch 33:  44%|████▍     | 68/153 [00:01<00:01, 52.83it/s, Epoch: 33, Batch: 69,Loss: -1.759,Avg.Loss: -2.033,LR: 3.81E-04]Training epoch 33:  45%|████▌     | 69/153 [00:01<00:01, 52.83it/s, Epoch: 33, Batch: 70,Loss: -1.236,Avg.Loss: -2.021,LR: 3.81E-04]Training epoch 33:  46%|████▌     | 70/153 [00:01<00:01, 52.83it/s, Epoch: 33, Batch: 71,Loss: -2.357,Avg.Loss: -2.026,LR: 3.81E-04]Training epoch 33:  46%|████▋     | 71/153 [00:01<00:01, 52.83it/s, Epoch: 33, Batch: 72,Loss: -1.933,Avg.Loss: -2.025,LR: 3.81E-04]Training epoch 33:  47%|████▋     | 72/153 [00:01<00:01, 52.87it/s, Epoch: 33, Batch: 72,Loss: -1.933,Avg.Loss: -2.025,LR: 3.81E-04]Training epoch 33:  47%|████▋     | 72/153 [00:01<00:01, 52.87it/s, Epoch: 33, Batch: 73,Loss: -2.462,Avg.Loss: -2.031,LR: 3.81E-04]Training epoch 33:  48%|████▊     | 73/153 [00:01<00:01, 52.87it/s, Epoch: 33, Batch: 74,Loss: -2.269,Avg.Loss: -2.034,LR: 3.81E-04]Training epoch 33:  48%|████▊     | 74/153 [00:01<00:01, 52.87it/s, Epoch: 33, Batch: 75,Loss: -1.866,Avg.Loss: -2.032,LR: 3.81E-04]Training epoch 33:  49%|████▉     | 75/153 [00:01<00:01, 52.87it/s, Epoch: 33, Batch: 76,Loss: -2.284,Avg.Loss: -2.035,LR: 3.81E-04]Training epoch 33:  50%|████▉     | 76/153 [00:01<00:01, 52.87it/s, Epoch: 33, Batch: 77,Loss: -2.074,Avg.Loss: -2.036,LR: 3.81E-04]Training epoch 33:  50%|█████     | 77/153 [00:01<00:01, 52.87it/s, Epoch: 33, Batch: 78,Loss: -1.991,Avg.Loss: -2.035,LR: 3.81E-04]Training epoch 33:  51%|█████     | 78/153 [00:01<00:01, 52.46it/s, Epoch: 33, Batch: 78,Loss: -1.991,Avg.Loss: -2.035,LR: 3.81E-04]Training epoch 33:  51%|█████     | 78/153 [00:01<00:01, 52.46it/s, Epoch: 33, Batch: 79,Loss: -2.348,Avg.Loss: -2.039,LR: 3.81E-04]Training epoch 33:  52%|█████▏    | 79/153 [00:01<00:01, 52.46it/s, Epoch: 33, Batch: 80,Loss: -1.999,Avg.Loss: -2.039,LR: 3.80E-04]Training epoch 33:  52%|█████▏    | 80/153 [00:01<00:01, 52.46it/s, Epoch: 33, Batch: 81,Loss: -1.436,Avg.Loss: -2.031,LR: 3.80E-04]Training epoch 33:  53%|█████▎    | 81/153 [00:01<00:01, 52.46it/s, Epoch: 33, Batch: 82,Loss: -2.045,Avg.Loss: -2.031,LR: 3.80E-04]Training epoch 33:  54%|█████▎    | 82/153 [00:01<00:01, 52.46it/s, Epoch: 33, Batch: 83,Loss: -2.385,Avg.Loss: -2.036,LR: 3.80E-04]Training epoch 33:  54%|█████▍    | 83/153 [00:01<00:01, 52.46it/s, Epoch: 33, Batch: 84,Loss: -2.152,Avg.Loss: -2.037,LR: 3.80E-04]Training epoch 33:  55%|█████▍    | 84/153 [00:01<00:01, 52.33it/s, Epoch: 33, Batch: 84,Loss: -2.152,Avg.Loss: -2.037,LR: 3.80E-04]Training epoch 33:  55%|█████▍    | 84/153 [00:01<00:01, 52.33it/s, Epoch: 33, Batch: 85,Loss: -1.776,Avg.Loss: -2.034,LR: 3.80E-04]Training epoch 33:  56%|█████▌    | 85/153 [00:01<00:01, 52.33it/s, Epoch: 33, Batch: 86,Loss: -1.879,Avg.Loss: -2.032,LR: 3.80E-04]Training epoch 33:  56%|█████▌    | 86/153 [00:01<00:01, 52.33it/s, Epoch: 33, Batch: 87,Loss: -2.027,Avg.Loss: -2.032,LR: 3.80E-04]Training epoch 33:  57%|█████▋    | 87/153 [00:01<00:01, 52.33it/s, Epoch: 33, Batch: 88,Loss: -2.113,Avg.Loss: -2.033,LR: 3.80E-04]Training epoch 33:  58%|█████▊    | 88/153 [00:01<00:01, 52.33it/s, Epoch: 33, Batch: 89,Loss: -1.857,Avg.Loss: -2.031,LR: 3.80E-04]Training epoch 33:  58%|█████▊    | 89/153 [00:01<00:01, 52.33it/s, Epoch: 33, Batch: 90,Loss: -2.039,Avg.Loss: -2.031,LR: 3.80E-04]Training epoch 33:  59%|█████▉    | 90/153 [00:01<00:01, 52.57it/s, Epoch: 33, Batch: 90,Loss: -2.039,Avg.Loss: -2.031,LR: 3.80E-04]Training epoch 33:  59%|█████▉    | 90/153 [00:01<00:01, 52.57it/s, Epoch: 33, Batch: 91,Loss: -1.807,Avg.Loss: -2.029,LR: 3.80E-04]Training epoch 33:  59%|█████▉    | 91/153 [00:01<00:01, 52.57it/s, Epoch: 33, Batch: 92,Loss: -2.506,Avg.Loss: -2.034,LR: 3.80E-04]Training epoch 33:  60%|██████    | 92/153 [00:01<00:01, 52.57it/s, Epoch: 33, Batch: 93,Loss: -2.506,Avg.Loss: -2.039,LR: 3.80E-04]Training epoch 33:  61%|██████    | 93/153 [00:01<00:01, 52.57it/s, Epoch: 33, Batch: 94,Loss: -2.480,Avg.Loss: -2.044,LR: 3.80E-04]Training epoch 33:  61%|██████▏   | 94/153 [00:01<00:01, 52.57it/s, Epoch: 33, Batch: 95,Loss: -1.688,Avg.Loss: -2.040,LR: 3.80E-04]Training epoch 33:  62%|██████▏   | 95/153 [00:01<00:01, 52.57it/s, Epoch: 33, Batch: 96,Loss: -1.585,Avg.Loss: -2.035,LR: 3.80E-04]Training epoch 33:  63%|██████▎   | 96/153 [00:01<00:01, 52.53it/s, Epoch: 33, Batch: 96,Loss: -1.585,Avg.Loss: -2.035,LR: 3.80E-04]Training epoch 33:  63%|██████▎   | 96/153 [00:01<00:01, 52.53it/s, Epoch: 33, Batch: 97,Loss: -2.065,Avg.Loss: -2.035,LR: 3.80E-04]Training epoch 33:  63%|██████▎   | 97/153 [00:01<00:01, 52.53it/s, Epoch: 33, Batch: 98,Loss: -2.377,Avg.Loss: -2.039,LR: 3.80E-04]Training epoch 33:  64%|██████▍   | 98/153 [00:01<00:01, 52.53it/s, Epoch: 33, Batch: 99,Loss: -2.351,Avg.Loss: -2.042,LR: 3.80E-04]Training epoch 33:  65%|██████▍   | 99/153 [00:01<00:01, 52.53it/s, Epoch: 33, Batch: 100,Loss: -2.373,Avg.Loss: -2.045,LR: 3.80E-04]Training epoch 33:  65%|██████▌   | 100/153 [00:01<00:01, 52.53it/s, Epoch: 33, Batch: 101,Loss: -2.414,Avg.Loss: -2.049,LR: 3.80E-04]Training epoch 33:  66%|██████▌   | 101/153 [00:01<00:00, 52.53it/s, Epoch: 33, Batch: 102,Loss: -1.689,Avg.Loss: -2.045,LR: 3.80E-04]Training epoch 33:  67%|██████▋   | 102/153 [00:01<00:00, 52.59it/s, Epoch: 33, Batch: 102,Loss: -1.689,Avg.Loss: -2.045,LR: 3.80E-04]Training epoch 33:  67%|██████▋   | 102/153 [00:01<00:00, 52.59it/s, Epoch: 33, Batch: 103,Loss: -2.090,Avg.Loss: -2.046,LR: 3.79E-04]Training epoch 33:  67%|██████▋   | 103/153 [00:01<00:00, 52.59it/s, Epoch: 33, Batch: 104,Loss: -2.808,Avg.Loss: -2.053,LR: 3.79E-04]Training epoch 33:  68%|██████▊   | 104/153 [00:01<00:00, 52.59it/s, Epoch: 33, Batch: 105,Loss: -2.241,Avg.Loss: -2.055,LR: 3.79E-04]Training epoch 33:  69%|██████▊   | 105/153 [00:02<00:00, 52.59it/s, Epoch: 33, Batch: 106,Loss: -2.437,Avg.Loss: -2.059,LR: 3.79E-04]Training epoch 33:  69%|██████▉   | 106/153 [00:02<00:00, 52.59it/s, Epoch: 33, Batch: 107,Loss: -1.716,Avg.Loss: -2.055,LR: 3.79E-04]Training epoch 33:  70%|██████▉   | 107/153 [00:02<00:00, 52.59it/s, Epoch: 33, Batch: 108,Loss: -1.874,Avg.Loss: -2.054,LR: 3.79E-04]Training epoch 33:  71%|███████   | 108/153 [00:02<00:00, 52.70it/s, Epoch: 33, Batch: 108,Loss: -1.874,Avg.Loss: -2.054,LR: 3.79E-04]Training epoch 33:  71%|███████   | 108/153 [00:02<00:00, 52.70it/s, Epoch: 33, Batch: 109,Loss: -2.078,Avg.Loss: -2.054,LR: 3.79E-04]Training epoch 33:  71%|███████   | 109/153 [00:02<00:00, 52.70it/s, Epoch: 33, Batch: 110,Loss: -2.315,Avg.Loss: -2.056,LR: 3.79E-04]Training epoch 33:  72%|███████▏  | 110/153 [00:02<00:00, 52.70it/s, Epoch: 33, Batch: 111,Loss: -1.648,Avg.Loss: -2.053,LR: 3.79E-04]Training epoch 33:  73%|███████▎  | 111/153 [00:02<00:00, 52.70it/s, Epoch: 33, Batch: 112,Loss: -2.194,Avg.Loss: -2.054,LR: 3.79E-04]Training epoch 33:  73%|███████▎  | 112/153 [00:02<00:00, 52.70it/s, Epoch: 33, Batch: 113,Loss: -2.447,Avg.Loss: -2.057,LR: 3.79E-04]Training epoch 33:  74%|███████▍  | 113/153 [00:02<00:00, 52.70it/s, Epoch: 33, Batch: 114,Loss: -2.075,Avg.Loss: -2.058,LR: 3.79E-04]Training epoch 33:  75%|███████▍  | 114/153 [00:02<00:00, 52.95it/s, Epoch: 33, Batch: 114,Loss: -2.075,Avg.Loss: -2.058,LR: 3.79E-04]Training epoch 33:  75%|███████▍  | 114/153 [00:02<00:00, 52.95it/s, Epoch: 33, Batch: 115,Loss: -2.452,Avg.Loss: -2.061,LR: 3.79E-04]Training epoch 33:  75%|███████▌  | 115/153 [00:02<00:00, 52.95it/s, Epoch: 33, Batch: 116,Loss: -1.831,Avg.Loss: -2.059,LR: 3.79E-04]Training epoch 33:  76%|███████▌  | 116/153 [00:02<00:00, 52.95it/s, Epoch: 33, Batch: 117,Loss: -1.717,Avg.Loss: -2.056,LR: 3.79E-04]Training epoch 33:  76%|███████▋  | 117/153 [00:02<00:00, 52.95it/s, Epoch: 33, Batch: 118,Loss: -2.033,Avg.Loss: -2.056,LR: 3.79E-04]Training epoch 33:  77%|███████▋  | 118/153 [00:02<00:00, 52.95it/s, Epoch: 33, Batch: 119,Loss: -2.283,Avg.Loss: -2.058,LR: 3.79E-04]Training epoch 33:  78%|███████▊  | 119/153 [00:02<00:00, 52.95it/s, Epoch: 33, Batch: 120,Loss: -1.928,Avg.Loss: -2.057,LR: 3.79E-04]Training epoch 33:  78%|███████▊  | 120/153 [00:02<00:00, 52.80it/s, Epoch: 33, Batch: 120,Loss: -1.928,Avg.Loss: -2.057,LR: 3.79E-04]Training epoch 33:  78%|███████▊  | 120/153 [00:02<00:00, 52.80it/s, Epoch: 33, Batch: 121,Loss: -2.475,Avg.Loss: -2.060,LR: 3.79E-04]Training epoch 33:  79%|███████▉  | 121/153 [00:02<00:00, 52.80it/s, Epoch: 33, Batch: 122,Loss: -1.500,Avg.Loss: -2.056,LR: 3.79E-04]Training epoch 33:  80%|███████▉  | 122/153 [00:02<00:00, 52.80it/s, Epoch: 33, Batch: 123,Loss: -1.724,Avg.Loss: -2.053,LR: 3.79E-04]Training epoch 33:  80%|████████  | 123/153 [00:02<00:00, 52.80it/s, Epoch: 33, Batch: 124,Loss: -2.097,Avg.Loss: -2.053,LR: 3.79E-04]Training epoch 33:  81%|████████  | 124/153 [00:02<00:00, 52.80it/s, Epoch: 33, Batch: 125,Loss: -2.078,Avg.Loss: -2.053,LR: 3.78E-04]Training epoch 33:  82%|████████▏ | 125/153 [00:02<00:00, 52.80it/s, Epoch: 33, Batch: 126,Loss: -2.207,Avg.Loss: -2.055,LR: 3.78E-04]Training epoch 33:  82%|████████▏ | 126/153 [00:02<00:00, 52.91it/s, Epoch: 33, Batch: 126,Loss: -2.207,Avg.Loss: -2.055,LR: 3.78E-04]Training epoch 33:  82%|████████▏ | 126/153 [00:02<00:00, 52.91it/s, Epoch: 33, Batch: 127,Loss: -2.093,Avg.Loss: -2.055,LR: 3.78E-04]Training epoch 33:  83%|████████▎ | 127/153 [00:02<00:00, 52.91it/s, Epoch: 33, Batch: 128,Loss: -2.144,Avg.Loss: -2.056,LR: 3.78E-04]Training epoch 33:  84%|████████▎ | 128/153 [00:02<00:00, 52.91it/s, Epoch: 33, Batch: 129,Loss: -1.718,Avg.Loss: -2.053,LR: 3.78E-04]Training epoch 33:  84%|████████▍ | 129/153 [00:02<00:00, 52.91it/s, Epoch: 33, Batch: 130,Loss: -2.085,Avg.Loss: -2.053,LR: 3.78E-04]Training epoch 33:  85%|████████▍ | 130/153 [00:02<00:00, 52.91it/s, Epoch: 33, Batch: 131,Loss: -2.528,Avg.Loss: -2.057,LR: 3.78E-04]Training epoch 33:  86%|████████▌ | 131/153 [00:02<00:00, 52.91it/s, Epoch: 33, Batch: 132,Loss: -2.478,Avg.Loss: -2.060,LR: 3.78E-04]Training epoch 33:  86%|████████▋ | 132/153 [00:02<00:00, 53.02it/s, Epoch: 33, Batch: 132,Loss: -2.478,Avg.Loss: -2.060,LR: 3.78E-04]Training epoch 33:  86%|████████▋ | 132/153 [00:02<00:00, 53.02it/s, Epoch: 33, Batch: 133,Loss: -2.606,Avg.Loss: -2.064,LR: 3.78E-04]Training epoch 33:  87%|████████▋ | 133/153 [00:02<00:00, 53.02it/s, Epoch: 33, Batch: 134,Loss: -1.725,Avg.Loss: -2.062,LR: 3.78E-04]Training epoch 33:  88%|████████▊ | 134/153 [00:02<00:00, 53.02it/s, Epoch: 33, Batch: 135,Loss: -1.220,Avg.Loss: -2.055,LR: 3.78E-04]Training epoch 33:  88%|████████▊ | 135/153 [00:02<00:00, 53.02it/s, Epoch: 33, Batch: 136,Loss: -1.652,Avg.Loss: -2.052,LR: 3.78E-04]Training epoch 33:  89%|████████▉ | 136/153 [00:02<00:00, 53.02it/s, Epoch: 33, Batch: 137,Loss: -1.984,Avg.Loss: -2.052,LR: 3.78E-04]Training epoch 33:  90%|████████▉ | 137/153 [00:02<00:00, 53.02it/s, Epoch: 33, Batch: 138,Loss: -2.181,Avg.Loss: -2.053,LR: 3.78E-04]Training epoch 33:  90%|█████████ | 138/153 [00:02<00:00, 53.09it/s, Epoch: 33, Batch: 138,Loss: -2.181,Avg.Loss: -2.053,LR: 3.78E-04]Training epoch 33:  90%|█████████ | 138/153 [00:02<00:00, 53.09it/s, Epoch: 33, Batch: 139,Loss: -2.346,Avg.Loss: -2.055,LR: 3.78E-04]Training epoch 33:  91%|█████████ | 139/153 [00:02<00:00, 53.09it/s, Epoch: 33, Batch: 140,Loss: -2.154,Avg.Loss: -2.056,LR: 3.78E-04]Training epoch 33:  92%|█████████▏| 140/153 [00:02<00:00, 53.09it/s, Epoch: 33, Batch: 141,Loss: -2.205,Avg.Loss: -2.057,LR: 3.78E-04]Training epoch 33:  92%|█████████▏| 141/153 [00:02<00:00, 53.09it/s, Epoch: 33, Batch: 142,Loss: -2.514,Avg.Loss: -2.060,LR: 3.78E-04]Training epoch 33:  93%|█████████▎| 142/153 [00:02<00:00, 53.09it/s, Epoch: 33, Batch: 143,Loss: -2.228,Avg.Loss: -2.061,LR: 3.78E-04]Training epoch 33:  93%|█████████▎| 143/153 [00:02<00:00, 53.09it/s, Epoch: 33, Batch: 144,Loss: -1.896,Avg.Loss: -2.060,LR: 3.78E-04]Training epoch 33:  94%|█████████▍| 144/153 [00:02<00:00, 53.05it/s, Epoch: 33, Batch: 144,Loss: -1.896,Avg.Loss: -2.060,LR: 3.78E-04]Training epoch 33:  94%|█████████▍| 144/153 [00:02<00:00, 53.05it/s, Epoch: 33, Batch: 145,Loss: -2.147,Avg.Loss: -2.061,LR: 3.78E-04]Training epoch 33:  95%|█████████▍| 145/153 [00:02<00:00, 53.05it/s, Epoch: 33, Batch: 146,Loss: -2.234,Avg.Loss: -2.062,LR: 3.78E-04]Training epoch 33:  95%|█████████▌| 146/153 [00:02<00:00, 53.05it/s, Epoch: 33, Batch: 147,Loss: -1.721,Avg.Loss: -2.059,LR: 3.78E-04]Training epoch 33:  96%|█████████▌| 147/153 [00:02<00:00, 53.05it/s, Epoch: 33, Batch: 148,Loss: -2.313,Avg.Loss: -2.061,LR: 3.77E-04]Training epoch 33:  97%|█████████▋| 148/153 [00:02<00:00, 53.05it/s, Epoch: 33, Batch: 149,Loss: -2.541,Avg.Loss: -2.064,LR: 3.77E-04]Training epoch 33:  97%|█████████▋| 149/153 [00:02<00:00, 53.05it/s, Epoch: 33, Batch: 150,Loss: -2.404,Avg.Loss: -2.067,LR: 3.77E-04]Training epoch 33:  98%|█████████▊| 150/153 [00:02<00:00, 53.03it/s, Epoch: 33, Batch: 150,Loss: -2.404,Avg.Loss: -2.067,LR: 3.77E-04]Training epoch 33:  98%|█████████▊| 150/153 [00:02<00:00, 53.03it/s, Epoch: 33, Batch: 151,Loss: -2.248,Avg.Loss: -2.068,LR: 3.77E-04]Training epoch 33:  99%|█████████▊| 151/153 [00:02<00:00, 53.03it/s, Epoch: 33, Batch: 152,Loss: -2.168,Avg.Loss: -2.069,LR: 3.77E-04]Training epoch 33:  99%|█████████▉| 152/153 [00:02<00:00, 53.03it/s, Epoch: 33, Batch: 153,Loss: -1.236,Avg.Loss: -2.063,LR: 3.77E-04]Training epoch 33: 100%|██████████| 153/153 [00:02<00:00, 52.71it/s, Epoch: 33, Batch: 153,Loss: -1.236,Avg.Loss: -2.063,LR: 3.77E-04]
Training epoch 34:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 34:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 34, Batch: 1,Loss: -2.135,Avg.Loss: -2.135,LR: 3.77E-04]Training epoch 34:   1%|          | 1/153 [00:00<00:05, 29.97it/s, Epoch: 34, Batch: 2,Loss: -2.052,Avg.Loss: -2.093,LR: 3.77E-04]Training epoch 34:   1%|▏         | 2/153 [00:00<00:03, 43.01it/s, Epoch: 34, Batch: 3,Loss: -2.215,Avg.Loss: -2.134,LR: 3.77E-04]Training epoch 34:   2%|▏         | 3/153 [00:00<00:03, 49.27it/s, Epoch: 34, Batch: 4,Loss: -2.658,Avg.Loss: -2.265,LR: 3.77E-04]Training epoch 34:   3%|▎         | 4/153 [00:00<00:02, 51.73it/s, Epoch: 34, Batch: 5,Loss: -2.225,Avg.Loss: -2.257,LR: 3.77E-04]Training epoch 34:   3%|▎         | 5/153 [00:00<00:02, 52.28it/s, Epoch: 34, Batch: 6,Loss: -2.089,Avg.Loss: -2.229,LR: 3.77E-04]Training epoch 34:   4%|▍         | 6/153 [00:00<00:02, 52.30it/s, Epoch: 34, Batch: 7,Loss: -2.507,Avg.Loss: -2.269,LR: 3.77E-04]Training epoch 34:   5%|▍         | 7/153 [00:00<00:02, 60.92it/s, Epoch: 34, Batch: 7,Loss: -2.507,Avg.Loss: -2.269,LR: 3.77E-04]Training epoch 34:   5%|▍         | 7/153 [00:00<00:02, 60.92it/s, Epoch: 34, Batch: 8,Loss: -2.416,Avg.Loss: -2.287,LR: 3.77E-04]Training epoch 34:   5%|▌         | 8/153 [00:00<00:02, 60.92it/s, Epoch: 34, Batch: 9,Loss: -1.902,Avg.Loss: -2.244,LR: 3.77E-04]Training epoch 34:   6%|▌         | 9/153 [00:00<00:02, 60.92it/s, Epoch: 34, Batch: 10,Loss: -2.180,Avg.Loss: -2.238,LR: 3.77E-04]Training epoch 34:   7%|▋         | 10/153 [00:00<00:02, 60.92it/s, Epoch: 34, Batch: 11,Loss: -2.301,Avg.Loss: -2.244,LR: 3.77E-04]Training epoch 34:   7%|▋         | 11/153 [00:00<00:02, 60.92it/s, Epoch: 34, Batch: 12,Loss: -2.258,Avg.Loss: -2.245,LR: 3.77E-04]Training epoch 34:   8%|▊         | 12/153 [00:00<00:02, 60.92it/s, Epoch: 34, Batch: 13,Loss: -1.938,Avg.Loss: -2.221,LR: 3.77E-04]Training epoch 34:   8%|▊         | 13/153 [00:00<00:02, 60.92it/s, Epoch: 34, Batch: 14,Loss: -2.341,Avg.Loss: -2.230,LR: 3.77E-04]Training epoch 34:   9%|▉         | 14/153 [00:00<00:02, 55.65it/s, Epoch: 34, Batch: 14,Loss: -2.341,Avg.Loss: -2.230,LR: 3.77E-04]Training epoch 34:   9%|▉         | 14/153 [00:00<00:02, 55.65it/s, Epoch: 34, Batch: 15,Loss: -1.804,Avg.Loss: -2.201,LR: 3.77E-04]Training epoch 34:  10%|▉         | 15/153 [00:00<00:02, 55.65it/s, Epoch: 34, Batch: 16,Loss: -2.046,Avg.Loss: -2.192,LR: 3.77E-04]Training epoch 34:  10%|█         | 16/153 [00:00<00:02, 55.65it/s, Epoch: 34, Batch: 17,Loss: -2.383,Avg.Loss: -2.203,LR: 3.77E-04]Training epoch 34:  11%|█         | 17/153 [00:00<00:02, 55.65it/s, Epoch: 34, Batch: 18,Loss: -1.719,Avg.Loss: -2.176,LR: 3.76E-04]Training epoch 34:  12%|█▏        | 18/153 [00:00<00:02, 55.65it/s, Epoch: 34, Batch: 19,Loss: -2.033,Avg.Loss: -2.169,LR: 3.76E-04]Training epoch 34:  12%|█▏        | 19/153 [00:00<00:02, 55.65it/s, Epoch: 34, Batch: 20,Loss: -2.396,Avg.Loss: -2.180,LR: 3.76E-04]Training epoch 34:  13%|█▎        | 20/153 [00:00<00:02, 54.27it/s, Epoch: 34, Batch: 20,Loss: -2.396,Avg.Loss: -2.180,LR: 3.76E-04]Training epoch 34:  13%|█▎        | 20/153 [00:00<00:02, 54.27it/s, Epoch: 34, Batch: 21,Loss: -1.998,Avg.Loss: -2.171,LR: 3.76E-04]Training epoch 34:  14%|█▎        | 21/153 [00:00<00:02, 54.27it/s, Epoch: 34, Batch: 22,Loss: -2.216,Avg.Loss: -2.173,LR: 3.76E-04]Training epoch 34:  14%|█▍        | 22/153 [00:00<00:02, 54.27it/s, Epoch: 34, Batch: 23,Loss: -2.116,Avg.Loss: -2.171,LR: 3.76E-04]Training epoch 34:  15%|█▌        | 23/153 [00:00<00:02, 54.27it/s, Epoch: 34, Batch: 24,Loss: -1.732,Avg.Loss: -2.153,LR: 3.76E-04]Training epoch 34:  16%|█▌        | 24/153 [00:00<00:02, 54.27it/s, Epoch: 34, Batch: 25,Loss: -2.528,Avg.Loss: -2.168,LR: 3.76E-04]Training epoch 34:  16%|█▋        | 25/153 [00:00<00:02, 54.27it/s, Epoch: 34, Batch: 26,Loss: -2.261,Avg.Loss: -2.171,LR: 3.76E-04]Training epoch 34:  17%|█▋        | 26/153 [00:00<00:02, 52.99it/s, Epoch: 34, Batch: 26,Loss: -2.261,Avg.Loss: -2.171,LR: 3.76E-04]Training epoch 34:  17%|█▋        | 26/153 [00:00<00:02, 52.99it/s, Epoch: 34, Batch: 27,Loss: -2.159,Avg.Loss: -2.171,LR: 3.76E-04]Training epoch 34:  18%|█▊        | 27/153 [00:00<00:02, 52.99it/s, Epoch: 34, Batch: 28,Loss: -2.255,Avg.Loss: -2.174,LR: 3.76E-04]Training epoch 34:  18%|█▊        | 28/153 [00:00<00:02, 52.99it/s, Epoch: 34, Batch: 29,Loss: -2.196,Avg.Loss: -2.174,LR: 3.76E-04]Training epoch 34:  19%|█▉        | 29/153 [00:00<00:02, 52.99it/s, Epoch: 34, Batch: 30,Loss: -1.987,Avg.Loss: -2.168,LR: 3.76E-04]Training epoch 34:  20%|█▉        | 30/153 [00:00<00:02, 52.99it/s, Epoch: 34, Batch: 31,Loss: -2.198,Avg.Loss: -2.169,LR: 3.76E-04]Training epoch 34:  20%|██        | 31/153 [00:00<00:02, 52.99it/s, Epoch: 34, Batch: 32,Loss: -2.215,Avg.Loss: -2.171,LR: 3.76E-04]Training epoch 34:  21%|██        | 32/153 [00:00<00:02, 52.68it/s, Epoch: 34, Batch: 32,Loss: -2.215,Avg.Loss: -2.171,LR: 3.76E-04]Training epoch 34:  21%|██        | 32/153 [00:00<00:02, 52.68it/s, Epoch: 34, Batch: 33,Loss: -1.158,Avg.Loss: -2.140,LR: 3.76E-04]Training epoch 34:  22%|██▏       | 33/153 [00:00<00:02, 52.68it/s, Epoch: 34, Batch: 34,Loss: -1.853,Avg.Loss: -2.132,LR: 3.76E-04]Training epoch 34:  22%|██▏       | 34/153 [00:00<00:02, 52.68it/s, Epoch: 34, Batch: 35,Loss: -1.542,Avg.Loss: -2.115,LR: 3.76E-04]Training epoch 34:  23%|██▎       | 35/153 [00:00<00:02, 52.68it/s, Epoch: 34, Batch: 36,Loss: -1.872,Avg.Loss: -2.108,LR: 3.76E-04]Training epoch 34:  24%|██▎       | 36/153 [00:00<00:02, 52.68it/s, Epoch: 34, Batch: 37,Loss: -2.451,Avg.Loss: -2.117,LR: 3.76E-04]Training epoch 34:  24%|██▍       | 37/153 [00:00<00:02, 52.68it/s, Epoch: 34, Batch: 38,Loss: -1.785,Avg.Loss: -2.108,LR: 3.76E-04]Training epoch 34:  25%|██▍       | 38/153 [00:00<00:02, 52.61it/s, Epoch: 34, Batch: 38,Loss: -1.785,Avg.Loss: -2.108,LR: 3.76E-04]Training epoch 34:  25%|██▍       | 38/153 [00:00<00:02, 52.61it/s, Epoch: 34, Batch: 39,Loss: -1.124,Avg.Loss: -2.083,LR: 3.76E-04]Training epoch 34:  25%|██▌       | 39/153 [00:00<00:02, 52.61it/s, Epoch: 34, Batch: 40,Loss: -1.720,Avg.Loss: -2.074,LR: 3.75E-04]Training epoch 34:  26%|██▌       | 40/153 [00:00<00:02, 52.61it/s, Epoch: 34, Batch: 41,Loss: -2.063,Avg.Loss: -2.074,LR: 3.75E-04]Training epoch 34:  27%|██▋       | 41/153 [00:00<00:02, 52.61it/s, Epoch: 34, Batch: 42,Loss: -1.929,Avg.Loss: -2.070,LR: 3.75E-04]Training epoch 34:  27%|██▋       | 42/153 [00:00<00:02, 52.61it/s, Epoch: 34, Batch: 43,Loss: -2.004,Avg.Loss: -2.069,LR: 3.75E-04]Training epoch 34:  28%|██▊       | 43/153 [00:00<00:02, 52.61it/s, Epoch: 34, Batch: 44,Loss: -2.091,Avg.Loss: -2.069,LR: 3.75E-04]Training epoch 34:  29%|██▉       | 44/153 [00:00<00:02, 52.69it/s, Epoch: 34, Batch: 44,Loss: -2.091,Avg.Loss: -2.069,LR: 3.75E-04]Training epoch 34:  29%|██▉       | 44/153 [00:00<00:02, 52.69it/s, Epoch: 34, Batch: 45,Loss: -1.524,Avg.Loss: -2.057,LR: 3.75E-04]Training epoch 34:  29%|██▉       | 45/153 [00:00<00:02, 52.69it/s, Epoch: 34, Batch: 46,Loss: -2.213,Avg.Loss: -2.061,LR: 3.75E-04]Training epoch 34:  30%|███       | 46/153 [00:00<00:02, 52.69it/s, Epoch: 34, Batch: 47,Loss: -2.296,Avg.Loss: -2.066,LR: 3.75E-04]Training epoch 34:  31%|███       | 47/153 [00:00<00:02, 52.69it/s, Epoch: 34, Batch: 48,Loss: -1.989,Avg.Loss: -2.064,LR: 3.75E-04]Training epoch 34:  31%|███▏      | 48/153 [00:00<00:01, 52.69it/s, Epoch: 34, Batch: 49,Loss: -1.853,Avg.Loss: -2.060,LR: 3.75E-04]Training epoch 34:  32%|███▏      | 49/153 [00:00<00:01, 52.69it/s, Epoch: 34, Batch: 50,Loss: -2.098,Avg.Loss: -2.060,LR: 3.75E-04]Training epoch 34:  33%|███▎      | 50/153 [00:00<00:01, 52.95it/s, Epoch: 34, Batch: 50,Loss: -2.098,Avg.Loss: -2.060,LR: 3.75E-04]Training epoch 34:  33%|███▎      | 50/153 [00:00<00:01, 52.95it/s, Epoch: 34, Batch: 51,Loss: -2.094,Avg.Loss: -2.061,LR: 3.75E-04]Training epoch 34:  33%|███▎      | 51/153 [00:00<00:01, 52.95it/s, Epoch: 34, Batch: 52,Loss: -2.143,Avg.Loss: -2.063,LR: 3.75E-04]Training epoch 34:  34%|███▍      | 52/153 [00:00<00:01, 52.95it/s, Epoch: 34, Batch: 53,Loss: -1.996,Avg.Loss: -2.061,LR: 3.75E-04]Training epoch 34:  35%|███▍      | 53/153 [00:01<00:01, 52.95it/s, Epoch: 34, Batch: 54,Loss: -2.094,Avg.Loss: -2.062,LR: 3.75E-04]Training epoch 34:  35%|███▌      | 54/153 [00:01<00:01, 52.95it/s, Epoch: 34, Batch: 55,Loss: -2.338,Avg.Loss: -2.067,LR: 3.75E-04]Training epoch 34:  36%|███▌      | 55/153 [00:01<00:01, 52.95it/s, Epoch: 34, Batch: 56,Loss: -2.265,Avg.Loss: -2.071,LR: 3.75E-04]Training epoch 34:  37%|███▋      | 56/153 [00:01<00:01, 53.04it/s, Epoch: 34, Batch: 56,Loss: -2.265,Avg.Loss: -2.071,LR: 3.75E-04]Training epoch 34:  37%|███▋      | 56/153 [00:01<00:01, 53.04it/s, Epoch: 34, Batch: 57,Loss: -2.595,Avg.Loss: -2.080,LR: 3.75E-04]Training epoch 34:  37%|███▋      | 57/153 [00:01<00:01, 53.04it/s, Epoch: 34, Batch: 58,Loss: -2.085,Avg.Loss: -2.080,LR: 3.75E-04]Training epoch 34:  38%|███▊      | 58/153 [00:01<00:01, 53.04it/s, Epoch: 34, Batch: 59,Loss: -2.012,Avg.Loss: -2.079,LR: 3.75E-04]Training epoch 34:  39%|███▊      | 59/153 [00:01<00:01, 53.04it/s, Epoch: 34, Batch: 60,Loss: -1.783,Avg.Loss: -2.074,LR: 3.75E-04]Training epoch 34:  39%|███▉      | 60/153 [00:01<00:01, 53.04it/s, Epoch: 34, Batch: 61,Loss: -2.408,Avg.Loss: -2.079,LR: 3.75E-04]Training epoch 34:  40%|███▉      | 61/153 [00:01<00:01, 53.04it/s, Epoch: 34, Batch: 62,Loss: -2.612,Avg.Loss: -2.088,LR: 3.75E-04]Training epoch 34:  41%|████      | 62/153 [00:01<00:01, 52.60it/s, Epoch: 34, Batch: 62,Loss: -2.612,Avg.Loss: -2.088,LR: 3.75E-04]Training epoch 34:  41%|████      | 62/153 [00:01<00:01, 52.60it/s, Epoch: 34, Batch: 63,Loss: -2.116,Avg.Loss: -2.088,LR: 3.74E-04]Training epoch 34:  41%|████      | 63/153 [00:01<00:01, 52.60it/s, Epoch: 34, Batch: 64,Loss: -2.384,Avg.Loss: -2.093,LR: 3.74E-04]Training epoch 34:  42%|████▏     | 64/153 [00:01<00:01, 52.60it/s, Epoch: 34, Batch: 65,Loss: -2.606,Avg.Loss: -2.101,LR: 3.74E-04]Training epoch 34:  42%|████▏     | 65/153 [00:01<00:01, 52.60it/s, Epoch: 34, Batch: 66,Loss: -1.987,Avg.Loss: -2.099,LR: 3.74E-04]Training epoch 34:  43%|████▎     | 66/153 [00:01<00:01, 52.60it/s, Epoch: 34, Batch: 67,Loss: -2.310,Avg.Loss: -2.102,LR: 3.74E-04]Training epoch 34:  44%|████▍     | 67/153 [00:01<00:01, 52.60it/s, Epoch: 34, Batch: 68,Loss: -1.440,Avg.Loss: -2.093,LR: 3.74E-04]Training epoch 34:  44%|████▍     | 68/153 [00:01<00:01, 52.66it/s, Epoch: 34, Batch: 68,Loss: -1.440,Avg.Loss: -2.093,LR: 3.74E-04]Training epoch 34:  44%|████▍     | 68/153 [00:01<00:01, 52.66it/s, Epoch: 34, Batch: 69,Loss: -1.620,Avg.Loss: -2.086,LR: 3.74E-04]Training epoch 34:  45%|████▌     | 69/153 [00:01<00:01, 52.66it/s, Epoch: 34, Batch: 70,Loss: -1.891,Avg.Loss: -2.083,LR: 3.74E-04]Training epoch 34:  46%|████▌     | 70/153 [00:01<00:01, 52.66it/s, Epoch: 34, Batch: 71,Loss: -2.523,Avg.Loss: -2.089,LR: 3.74E-04]Training epoch 34:  46%|████▋     | 71/153 [00:01<00:01, 52.66it/s, Epoch: 34, Batch: 72,Loss: -2.167,Avg.Loss: -2.090,LR: 3.74E-04]Training epoch 34:  47%|████▋     | 72/153 [00:01<00:01, 52.66it/s, Epoch: 34, Batch: 73,Loss: -2.103,Avg.Loss: -2.090,LR: 3.74E-04]Training epoch 34:  48%|████▊     | 73/153 [00:01<00:01, 52.66it/s, Epoch: 34, Batch: 74,Loss: -1.869,Avg.Loss: -2.087,LR: 3.74E-04]Training epoch 34:  48%|████▊     | 74/153 [00:01<00:01, 52.92it/s, Epoch: 34, Batch: 74,Loss: -1.869,Avg.Loss: -2.087,LR: 3.74E-04]Training epoch 34:  48%|████▊     | 74/153 [00:01<00:01, 52.92it/s, Epoch: 34, Batch: 75,Loss: -1.904,Avg.Loss: -2.085,LR: 3.74E-04]Training epoch 34:  49%|████▉     | 75/153 [00:01<00:01, 52.92it/s, Epoch: 34, Batch: 76,Loss: -2.216,Avg.Loss: -2.087,LR: 3.74E-04]Training epoch 34:  50%|████▉     | 76/153 [00:01<00:01, 52.92it/s, Epoch: 34, Batch: 77,Loss: -2.394,Avg.Loss: -2.091,LR: 3.74E-04]Training epoch 34:  50%|█████     | 77/153 [00:01<00:01, 52.92it/s, Epoch: 34, Batch: 78,Loss: -1.485,Avg.Loss: -2.083,LR: 3.74E-04]Training epoch 34:  51%|█████     | 78/153 [00:01<00:01, 52.92it/s, Epoch: 34, Batch: 79,Loss: -2.245,Avg.Loss: -2.085,LR: 3.74E-04]Training epoch 34:  52%|█████▏    | 79/153 [00:01<00:01, 52.92it/s, Epoch: 34, Batch: 80,Loss: -2.063,Avg.Loss: -2.085,LR: 3.74E-04]Training epoch 34:  52%|█████▏    | 80/153 [00:01<00:01, 53.16it/s, Epoch: 34, Batch: 80,Loss: -2.063,Avg.Loss: -2.085,LR: 3.74E-04]Training epoch 34:  52%|█████▏    | 80/153 [00:01<00:01, 53.16it/s, Epoch: 34, Batch: 81,Loss: -2.181,Avg.Loss: -2.086,LR: 3.74E-04]Training epoch 34:  53%|█████▎    | 81/153 [00:01<00:01, 53.16it/s, Epoch: 34, Batch: 82,Loss: -2.453,Avg.Loss: -2.090,LR: 3.74E-04]Training epoch 34:  54%|█████▎    | 82/153 [00:01<00:01, 53.16it/s, Epoch: 34, Batch: 83,Loss: -1.966,Avg.Loss: -2.089,LR: 3.74E-04]Training epoch 34:  54%|█████▍    | 83/153 [00:01<00:01, 53.16it/s, Epoch: 34, Batch: 84,Loss: -0.663,Avg.Loss: -2.072,LR: 3.74E-04]Training epoch 34:  55%|█████▍    | 84/153 [00:01<00:01, 53.16it/s, Epoch: 34, Batch: 85,Loss: -1.403,Avg.Loss: -2.064,LR: 3.73E-04]Training epoch 34:  56%|█████▌    | 85/153 [00:01<00:01, 53.16it/s, Epoch: 34, Batch: 86,Loss: -1.112,Avg.Loss: -2.053,LR: 3.73E-04]Training epoch 34:  56%|█████▌    | 86/153 [00:01<00:01, 53.17it/s, Epoch: 34, Batch: 86,Loss: -1.112,Avg.Loss: -2.053,LR: 3.73E-04]Training epoch 34:  56%|█████▌    | 86/153 [00:01<00:01, 53.17it/s, Epoch: 34, Batch: 87,Loss: -2.570,Avg.Loss: -2.059,LR: 3.73E-04]Training epoch 34:  57%|█████▋    | 87/153 [00:01<00:01, 53.17it/s, Epoch: 34, Batch: 88,Loss: -2.168,Avg.Loss: -2.060,LR: 3.73E-04]Training epoch 34:  58%|█████▊    | 88/153 [00:01<00:01, 53.17it/s, Epoch: 34, Batch: 89,Loss: -2.187,Avg.Loss: -2.062,LR: 3.73E-04]Training epoch 34:  58%|█████▊    | 89/153 [00:01<00:01, 53.17it/s, Epoch: 34, Batch: 90,Loss: -2.088,Avg.Loss: -2.062,LR: 3.73E-04]Training epoch 34:  59%|█████▉    | 90/153 [00:01<00:01, 53.17it/s, Epoch: 34, Batch: 91,Loss: -2.584,Avg.Loss: -2.068,LR: 3.73E-04]Training epoch 34:  59%|█████▉    | 91/153 [00:01<00:01, 53.17it/s, Epoch: 34, Batch: 92,Loss: -2.269,Avg.Loss: -2.070,LR: 3.73E-04]Training epoch 34:  60%|██████    | 92/153 [00:01<00:01, 53.22it/s, Epoch: 34, Batch: 92,Loss: -2.269,Avg.Loss: -2.070,LR: 3.73E-04]Training epoch 34:  60%|██████    | 92/153 [00:01<00:01, 53.22it/s, Epoch: 34, Batch: 93,Loss: -2.612,Avg.Loss: -2.076,LR: 3.73E-04]Training epoch 34:  61%|██████    | 93/153 [00:01<00:01, 53.22it/s, Epoch: 34, Batch: 94,Loss: -2.373,Avg.Loss: -2.079,LR: 3.73E-04]Training epoch 34:  61%|██████▏   | 94/153 [00:01<00:01, 53.22it/s, Epoch: 34, Batch: 95,Loss: -1.920,Avg.Loss: -2.077,LR: 3.73E-04]Training epoch 34:  62%|██████▏   | 95/153 [00:01<00:01, 53.22it/s, Epoch: 34, Batch: 96,Loss: -2.221,Avg.Loss: -2.079,LR: 3.73E-04]Training epoch 34:  63%|██████▎   | 96/153 [00:01<00:01, 53.22it/s, Epoch: 34, Batch: 97,Loss: -2.262,Avg.Loss: -2.080,LR: 3.73E-04]Training epoch 34:  63%|██████▎   | 97/153 [00:01<00:01, 53.22it/s, Epoch: 34, Batch: 98,Loss: -2.545,Avg.Loss: -2.085,LR: 3.73E-04]Training epoch 34:  64%|██████▍   | 98/153 [00:01<00:01, 53.26it/s, Epoch: 34, Batch: 98,Loss: -2.545,Avg.Loss: -2.085,LR: 3.73E-04]Training epoch 34:  64%|██████▍   | 98/153 [00:01<00:01, 53.26it/s, Epoch: 34, Batch: 99,Loss: -2.310,Avg.Loss: -2.087,LR: 3.73E-04]Training epoch 34:  65%|██████▍   | 99/153 [00:01<00:01, 53.26it/s, Epoch: 34, Batch: 100,Loss: -1.994,Avg.Loss: -2.087,LR: 3.73E-04]Training epoch 34:  65%|██████▌   | 100/153 [00:01<00:00, 53.26it/s, Epoch: 34, Batch: 101,Loss: -2.460,Avg.Loss: -2.090,LR: 3.73E-04]Training epoch 34:  66%|██████▌   | 101/153 [00:01<00:00, 53.26it/s, Epoch: 34, Batch: 102,Loss: -2.370,Avg.Loss: -2.093,LR: 3.73E-04]Training epoch 34:  67%|██████▋   | 102/153 [00:01<00:00, 53.26it/s, Epoch: 34, Batch: 103,Loss: -2.249,Avg.Loss: -2.095,LR: 3.73E-04]Training epoch 34:  67%|██████▋   | 103/153 [00:01<00:00, 53.26it/s, Epoch: 34, Batch: 104,Loss: -2.369,Avg.Loss: -2.097,LR: 3.73E-04]Training epoch 34:  68%|██████▊   | 104/153 [00:01<00:00, 53.25it/s, Epoch: 34, Batch: 104,Loss: -2.369,Avg.Loss: -2.097,LR: 3.73E-04]Training epoch 34:  68%|██████▊   | 104/153 [00:01<00:00, 53.25it/s, Epoch: 34, Batch: 105,Loss: -1.968,Avg.Loss: -2.096,LR: 3.73E-04]Training epoch 34:  69%|██████▊   | 105/153 [00:01<00:00, 53.25it/s, Epoch: 34, Batch: 106,Loss: -2.335,Avg.Loss: -2.098,LR: 3.73E-04]Training epoch 34:  69%|██████▉   | 106/153 [00:02<00:00, 53.25it/s, Epoch: 34, Batch: 107,Loss: -2.075,Avg.Loss: -2.098,LR: 3.73E-04]Training epoch 34:  70%|██████▉   | 107/153 [00:02<00:00, 53.25it/s, Epoch: 34, Batch: 108,Loss: -2.370,Avg.Loss: -2.100,LR: 3.72E-04]Training epoch 34:  71%|███████   | 108/153 [00:02<00:00, 53.25it/s, Epoch: 34, Batch: 109,Loss: -2.047,Avg.Loss: -2.100,LR: 3.72E-04]Training epoch 34:  71%|███████   | 109/153 [00:02<00:00, 53.25it/s, Epoch: 34, Batch: 110,Loss: -2.484,Avg.Loss: -2.103,LR: 3.72E-04]Training epoch 34:  72%|███████▏  | 110/153 [00:02<00:00, 53.35it/s, Epoch: 34, Batch: 110,Loss: -2.484,Avg.Loss: -2.103,LR: 3.72E-04]Training epoch 34:  72%|███████▏  | 110/153 [00:02<00:00, 53.35it/s, Epoch: 34, Batch: 111,Loss: -2.339,Avg.Loss: -2.106,LR: 3.72E-04]Training epoch 34:  73%|███████▎  | 111/153 [00:02<00:00, 53.35it/s, Epoch: 34, Batch: 112,Loss: -2.802,Avg.Loss: -2.112,LR: 3.72E-04]Training epoch 34:  73%|███████▎  | 112/153 [00:02<00:00, 53.35it/s, Epoch: 34, Batch: 113,Loss: -2.805,Avg.Loss: -2.118,LR: 3.72E-04]Training epoch 34:  74%|███████▍  | 113/153 [00:02<00:00, 53.35it/s, Epoch: 34, Batch: 114,Loss: -2.533,Avg.Loss: -2.122,LR: 3.72E-04]Training epoch 34:  75%|███████▍  | 114/153 [00:02<00:00, 53.35it/s, Epoch: 34, Batch: 115,Loss: -2.245,Avg.Loss: -2.123,LR: 3.72E-04]Training epoch 34:  75%|███████▌  | 115/153 [00:02<00:00, 53.35it/s, Epoch: 34, Batch: 116,Loss: -2.186,Avg.Loss: -2.123,LR: 3.72E-04]Training epoch 34:  76%|███████▌  | 116/153 [00:02<00:00, 53.29it/s, Epoch: 34, Batch: 116,Loss: -2.186,Avg.Loss: -2.123,LR: 3.72E-04]Training epoch 34:  76%|███████▌  | 116/153 [00:02<00:00, 53.29it/s, Epoch: 34, Batch: 117,Loss: -1.928,Avg.Loss: -2.122,LR: 3.72E-04]Training epoch 34:  76%|███████▋  | 117/153 [00:02<00:00, 53.29it/s, Epoch: 34, Batch: 118,Loss: -2.845,Avg.Loss: -2.128,LR: 3.72E-04]Training epoch 34:  77%|███████▋  | 118/153 [00:02<00:00, 53.29it/s, Epoch: 34, Batch: 119,Loss: -1.971,Avg.Loss: -2.126,LR: 3.72E-04]Training epoch 34:  78%|███████▊  | 119/153 [00:02<00:00, 53.29it/s, Epoch: 34, Batch: 120,Loss: -2.656,Avg.Loss: -2.131,LR: 3.72E-04]Training epoch 34:  78%|███████▊  | 120/153 [00:02<00:00, 53.29it/s, Epoch: 34, Batch: 121,Loss: -1.998,Avg.Loss: -2.130,LR: 3.72E-04]Training epoch 34:  79%|███████▉  | 121/153 [00:02<00:00, 53.29it/s, Epoch: 34, Batch: 122,Loss: -2.532,Avg.Loss: -2.133,LR: 3.72E-04]Training epoch 34:  80%|███████▉  | 122/153 [00:02<00:00, 53.39it/s, Epoch: 34, Batch: 122,Loss: -2.532,Avg.Loss: -2.133,LR: 3.72E-04]Training epoch 34:  80%|███████▉  | 122/153 [00:02<00:00, 53.39it/s, Epoch: 34, Batch: 123,Loss: -2.364,Avg.Loss: -2.135,LR: 3.72E-04]Training epoch 34:  80%|████████  | 123/153 [00:02<00:00, 53.39it/s, Epoch: 34, Batch: 124,Loss: -2.471,Avg.Loss: -2.138,LR: 3.72E-04]Training epoch 34:  81%|████████  | 124/153 [00:02<00:00, 53.39it/s, Epoch: 34, Batch: 125,Loss: -2.062,Avg.Loss: -2.137,LR: 3.72E-04]Training epoch 34:  82%|████████▏ | 125/153 [00:02<00:00, 53.39it/s, Epoch: 34, Batch: 126,Loss: -2.115,Avg.Loss: -2.137,LR: 3.72E-04]Training epoch 34:  82%|████████▏ | 126/153 [00:02<00:00, 53.39it/s, Epoch: 34, Batch: 127,Loss: -2.077,Avg.Loss: -2.136,LR: 3.72E-04]Training epoch 34:  83%|████████▎ | 127/153 [00:02<00:00, 53.39it/s, Epoch: 34, Batch: 128,Loss: -0.974,Avg.Loss: -2.127,LR: 3.72E-04]Training epoch 34:  84%|████████▎ | 128/153 [00:02<00:00, 53.21it/s, Epoch: 34, Batch: 128,Loss: -0.974,Avg.Loss: -2.127,LR: 3.72E-04]Training epoch 34:  84%|████████▎ | 128/153 [00:02<00:00, 53.21it/s, Epoch: 34, Batch: 129,Loss: -0.628,Avg.Loss: -2.116,LR: 3.72E-04]Training epoch 34:  84%|████████▍ | 129/153 [00:02<00:00, 53.21it/s, Epoch: 34, Batch: 130,Loss: -1.796,Avg.Loss: -2.113,LR: 3.71E-04]Training epoch 34:  85%|████████▍ | 130/153 [00:02<00:00, 53.21it/s, Epoch: 34, Batch: 131,Loss: -0.864,Avg.Loss: -2.104,LR: 3.71E-04]Training epoch 34:  86%|████████▌ | 131/153 [00:02<00:00, 53.21it/s, Epoch: 34, Batch: 132,Loss: -0.257,Avg.Loss: -2.090,LR: 3.71E-04]Training epoch 34:  86%|████████▋ | 132/153 [00:02<00:00, 53.21it/s, Epoch: 34, Batch: 133,Loss: -0.325,Avg.Loss: -2.076,LR: 3.71E-04]Training epoch 34:  87%|████████▋ | 133/153 [00:02<00:00, 53.21it/s, Epoch: 34, Batch: 134,Loss: -1.746,Avg.Loss: -2.074,LR: 3.71E-04]Training epoch 34:  88%|████████▊ | 134/153 [00:02<00:00, 53.23it/s, Epoch: 34, Batch: 134,Loss: -1.746,Avg.Loss: -2.074,LR: 3.71E-04]Training epoch 34:  88%|████████▊ | 134/153 [00:02<00:00, 53.23it/s, Epoch: 34, Batch: 135,Loss: -1.378,Avg.Loss: -2.069,LR: 3.71E-04]Training epoch 34:  88%|████████▊ | 135/153 [00:02<00:00, 53.23it/s, Epoch: 34, Batch: 136,Loss: 0.240,Avg.Loss: -2.052,LR: 3.71E-04] Training epoch 34:  89%|████████▉ | 136/153 [00:02<00:00, 53.23it/s, Epoch: 34, Batch: 137,Loss: 0.036,Avg.Loss: -2.037,LR: 3.71E-04]Training epoch 34:  90%|████████▉ | 137/153 [00:02<00:00, 53.23it/s, Epoch: 34, Batch: 138,Loss: -1.724,Avg.Loss: -2.034,LR: 3.71E-04]Training epoch 34:  90%|█████████ | 138/153 [00:02<00:00, 53.23it/s, Epoch: 34, Batch: 139,Loss: -1.750,Avg.Loss: -2.032,LR: 3.71E-04]Training epoch 34:  91%|█████████ | 139/153 [00:02<00:00, 53.23it/s, Epoch: 34, Batch: 140,Loss: -0.897,Avg.Loss: -2.024,LR: 3.71E-04]Training epoch 34:  92%|█████████▏| 140/153 [00:02<00:00, 53.09it/s, Epoch: 34, Batch: 140,Loss: -0.897,Avg.Loss: -2.024,LR: 3.71E-04]Training epoch 34:  92%|█████████▏| 140/153 [00:02<00:00, 53.09it/s, Epoch: 34, Batch: 141,Loss: -1.918,Avg.Loss: -2.023,LR: 3.71E-04]Training epoch 34:  92%|█████████▏| 141/153 [00:02<00:00, 53.09it/s, Epoch: 34, Batch: 142,Loss: -2.432,Avg.Loss: -2.026,LR: 3.71E-04]Training epoch 34:  93%|█████████▎| 142/153 [00:02<00:00, 53.09it/s, Epoch: 34, Batch: 143,Loss: -1.282,Avg.Loss: -2.021,LR: 3.71E-04]Training epoch 34:  93%|█████████▎| 143/153 [00:02<00:00, 53.09it/s, Epoch: 34, Batch: 144,Loss: -0.767,Avg.Loss: -2.012,LR: 3.71E-04]Training epoch 34:  94%|█████████▍| 144/153 [00:02<00:00, 53.09it/s, Epoch: 34, Batch: 145,Loss: -0.417,Avg.Loss: -2.001,LR: 3.71E-04]Training epoch 34:  95%|█████████▍| 145/153 [00:02<00:00, 53.09it/s, Epoch: 34, Batch: 146,Loss: -1.625,Avg.Loss: -1.999,LR: 3.71E-04]Training epoch 34:  95%|█████████▌| 146/153 [00:02<00:00, 53.15it/s, Epoch: 34, Batch: 146,Loss: -1.625,Avg.Loss: -1.999,LR: 3.71E-04]Training epoch 34:  95%|█████████▌| 146/153 [00:02<00:00, 53.15it/s, Epoch: 34, Batch: 147,Loss: -2.407,Avg.Loss: -2.002,LR: 3.71E-04]Training epoch 34:  96%|█████████▌| 147/153 [00:02<00:00, 53.15it/s, Epoch: 34, Batch: 148,Loss: -1.550,Avg.Loss: -1.998,LR: 3.71E-04]Training epoch 34:  97%|█████████▋| 148/153 [00:02<00:00, 53.15it/s, Epoch: 34, Batch: 149,Loss: -0.858,Avg.Loss: -1.991,LR: 3.71E-04]Training epoch 34:  97%|█████████▋| 149/153 [00:02<00:00, 53.15it/s, Epoch: 34, Batch: 150,Loss: -1.190,Avg.Loss: -1.985,LR: 3.71E-04]Training epoch 34:  98%|█████████▊| 150/153 [00:02<00:00, 53.15it/s, Epoch: 34, Batch: 151,Loss: -1.507,Avg.Loss: -1.982,LR: 3.71E-04]Training epoch 34:  99%|█████████▊| 151/153 [00:02<00:00, 53.15it/s, Epoch: 34, Batch: 152,Loss: -1.565,Avg.Loss: -1.980,LR: 3.70E-04]Training epoch 34:  99%|█████████▉| 152/153 [00:02<00:00, 53.08it/s, Epoch: 34, Batch: 152,Loss: -1.565,Avg.Loss: -1.980,LR: 3.70E-04]Training epoch 34:  99%|█████████▉| 152/153 [00:02<00:00, 53.08it/s, Epoch: 34, Batch: 153,Loss: -1.221,Avg.Loss: -1.975,LR: 3.70E-04]Training epoch 34: 100%|██████████| 153/153 [00:02<00:00, 53.17it/s, Epoch: 34, Batch: 153,Loss: -1.221,Avg.Loss: -1.975,LR: 3.70E-04]
Training epoch 35:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 35:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 35, Batch: 1,Loss: -1.074,Avg.Loss: -1.074,LR: 3.70E-04]Training epoch 35:   1%|          | 1/153 [00:00<00:06, 23.58it/s, Epoch: 35, Batch: 2,Loss: -0.829,Avg.Loss: -0.952,LR: 3.70E-04]Training epoch 35:   1%|▏         | 2/153 [00:00<00:04, 33.64it/s, Epoch: 35, Batch: 3,Loss: -1.889,Avg.Loss: -1.264,LR: 3.70E-04]Training epoch 35:   2%|▏         | 3/153 [00:00<00:03, 40.77it/s, Epoch: 35, Batch: 4,Loss: -2.101,Avg.Loss: -1.473,LR: 3.70E-04]Training epoch 35:   3%|▎         | 4/153 [00:00<00:03, 43.83it/s, Epoch: 35, Batch: 5,Loss: -2.611,Avg.Loss: -1.701,LR: 3.70E-04]Training epoch 35:   3%|▎         | 5/153 [00:00<00:03, 45.78it/s, Epoch: 35, Batch: 6,Loss: -1.841,Avg.Loss: -1.724,LR: 3.70E-04]Training epoch 35:   4%|▍         | 6/153 [00:00<00:02, 54.85it/s, Epoch: 35, Batch: 6,Loss: -1.841,Avg.Loss: -1.724,LR: 3.70E-04]Training epoch 35:   4%|▍         | 6/153 [00:00<00:02, 54.85it/s, Epoch: 35, Batch: 7,Loss: -0.601,Avg.Loss: -1.564,LR: 3.70E-04]Training epoch 35:   5%|▍         | 7/153 [00:00<00:02, 54.85it/s, Epoch: 35, Batch: 8,Loss: -1.551,Avg.Loss: -1.562,LR: 3.70E-04]Training epoch 35:   5%|▌         | 8/153 [00:00<00:02, 54.85it/s, Epoch: 35, Batch: 9,Loss: -1.920,Avg.Loss: -1.602,LR: 3.70E-04]Training epoch 35:   6%|▌         | 9/153 [00:00<00:02, 54.85it/s, Epoch: 35, Batch: 10,Loss: -2.362,Avg.Loss: -1.678,LR: 3.70E-04]Training epoch 35:   7%|▋         | 10/153 [00:00<00:02, 54.85it/s, Epoch: 35, Batch: 11,Loss: -1.831,Avg.Loss: -1.692,LR: 3.70E-04]Training epoch 35:   7%|▋         | 11/153 [00:00<00:02, 54.85it/s, Epoch: 35, Batch: 12,Loss: -1.743,Avg.Loss: -1.696,LR: 3.70E-04]Training epoch 35:   8%|▊         | 12/153 [00:00<00:02, 53.73it/s, Epoch: 35, Batch: 12,Loss: -1.743,Avg.Loss: -1.696,LR: 3.70E-04]Training epoch 35:   8%|▊         | 12/153 [00:00<00:02, 53.73it/s, Epoch: 35, Batch: 13,Loss: -1.153,Avg.Loss: -1.654,LR: 3.70E-04]Training epoch 35:   8%|▊         | 13/153 [00:00<00:02, 53.73it/s, Epoch: 35, Batch: 14,Loss: -1.683,Avg.Loss: -1.656,LR: 3.70E-04]Training epoch 35:   9%|▉         | 14/153 [00:00<00:02, 53.73it/s, Epoch: 35, Batch: 15,Loss: -2.149,Avg.Loss: -1.689,LR: 3.70E-04]Training epoch 35:  10%|▉         | 15/153 [00:00<00:02, 53.73it/s, Epoch: 35, Batch: 16,Loss: -1.364,Avg.Loss: -1.669,LR: 3.70E-04]Training epoch 35:  10%|█         | 16/153 [00:00<00:02, 53.73it/s, Epoch: 35, Batch: 17,Loss: -1.132,Avg.Loss: -1.637,LR: 3.70E-04]Training epoch 35:  11%|█         | 17/153 [00:00<00:02, 53.73it/s, Epoch: 35, Batch: 18,Loss: -1.481,Avg.Loss: -1.629,LR: 3.70E-04]Training epoch 35:  12%|█▏        | 18/153 [00:00<00:02, 53.26it/s, Epoch: 35, Batch: 18,Loss: -1.481,Avg.Loss: -1.629,LR: 3.70E-04]Training epoch 35:  12%|█▏        | 18/153 [00:00<00:02, 53.26it/s, Epoch: 35, Batch: 19,Loss: -1.724,Avg.Loss: -1.634,LR: 3.70E-04]Training epoch 35:  12%|█▏        | 19/153 [00:00<00:02, 53.26it/s, Epoch: 35, Batch: 20,Loss: -2.013,Avg.Loss: -1.653,LR: 3.70E-04]Training epoch 35:  13%|█▎        | 20/153 [00:00<00:02, 53.26it/s, Epoch: 35, Batch: 21,Loss: -2.065,Avg.Loss: -1.672,LR: 3.69E-04]Training epoch 35:  14%|█▎        | 21/153 [00:00<00:02, 53.26it/s, Epoch: 35, Batch: 22,Loss: -1.434,Avg.Loss: -1.661,LR: 3.69E-04]Training epoch 35:  14%|█▍        | 22/153 [00:00<00:02, 53.26it/s, Epoch: 35, Batch: 23,Loss: -1.392,Avg.Loss: -1.650,LR: 3.69E-04]Training epoch 35:  15%|█▌        | 23/153 [00:00<00:02, 53.26it/s, Epoch: 35, Batch: 24,Loss: -1.767,Avg.Loss: -1.655,LR: 3.69E-04]Training epoch 35:  16%|█▌        | 24/153 [00:00<00:02, 52.44it/s, Epoch: 35, Batch: 24,Loss: -1.767,Avg.Loss: -1.655,LR: 3.69E-04]Training epoch 35:  16%|█▌        | 24/153 [00:00<00:02, 52.44it/s, Epoch: 35, Batch: 25,Loss: -2.291,Avg.Loss: -1.680,LR: 3.69E-04]Training epoch 35:  16%|█▋        | 25/153 [00:00<00:02, 52.44it/s, Epoch: 35, Batch: 26,Loss: -1.946,Avg.Loss: -1.690,LR: 3.69E-04]Training epoch 35:  17%|█▋        | 26/153 [00:00<00:02, 52.44it/s, Epoch: 35, Batch: 27,Loss: -2.385,Avg.Loss: -1.716,LR: 3.69E-04]Training epoch 35:  18%|█▊        | 27/153 [00:00<00:02, 52.44it/s, Epoch: 35, Batch: 28,Loss: -2.008,Avg.Loss: -1.726,LR: 3.69E-04]Training epoch 35:  18%|█▊        | 28/153 [00:00<00:02, 52.44it/s, Epoch: 35, Batch: 29,Loss: -2.059,Avg.Loss: -1.738,LR: 3.69E-04]Training epoch 35:  19%|█▉        | 29/153 [00:00<00:02, 52.44it/s, Epoch: 35, Batch: 30,Loss: -1.670,Avg.Loss: -1.736,LR: 3.69E-04]Training epoch 35:  20%|█▉        | 30/153 [00:00<00:02, 52.30it/s, Epoch: 35, Batch: 30,Loss: -1.670,Avg.Loss: -1.736,LR: 3.69E-04]Training epoch 35:  20%|█▉        | 30/153 [00:00<00:02, 52.30it/s, Epoch: 35, Batch: 31,Loss: -2.143,Avg.Loss: -1.749,LR: 3.69E-04]Training epoch 35:  20%|██        | 31/153 [00:00<00:02, 52.30it/s, Epoch: 35, Batch: 32,Loss: -1.998,Avg.Loss: -1.757,LR: 3.69E-04]Training epoch 35:  21%|██        | 32/153 [00:00<00:02, 52.30it/s, Epoch: 35, Batch: 33,Loss: -2.198,Avg.Loss: -1.770,LR: 3.69E-04]Training epoch 35:  22%|██▏       | 33/153 [00:00<00:02, 52.30it/s, Epoch: 35, Batch: 34,Loss: -2.312,Avg.Loss: -1.786,LR: 3.69E-04]Training epoch 35:  22%|██▏       | 34/153 [00:00<00:02, 52.30it/s, Epoch: 35, Batch: 35,Loss: -1.440,Avg.Loss: -1.776,LR: 3.69E-04]Training epoch 35:  23%|██▎       | 35/153 [00:00<00:02, 52.30it/s, Epoch: 35, Batch: 36,Loss: -2.473,Avg.Loss: -1.795,LR: 3.69E-04]Training epoch 35:  24%|██▎       | 36/153 [00:00<00:02, 51.19it/s, Epoch: 35, Batch: 36,Loss: -2.473,Avg.Loss: -1.795,LR: 3.69E-04]Training epoch 35:  24%|██▎       | 36/153 [00:00<00:02, 51.19it/s, Epoch: 35, Batch: 37,Loss: -1.560,Avg.Loss: -1.789,LR: 3.69E-04]Training epoch 35:  24%|██▍       | 37/153 [00:00<00:02, 51.19it/s, Epoch: 35, Batch: 38,Loss: -1.578,Avg.Loss: -1.783,LR: 3.69E-04]Training epoch 35:  25%|██▍       | 38/153 [00:00<00:02, 51.19it/s, Epoch: 35, Batch: 39,Loss: -2.402,Avg.Loss: -1.799,LR: 3.69E-04]Training epoch 35:  25%|██▌       | 39/153 [00:00<00:02, 51.19it/s, Epoch: 35, Batch: 40,Loss: -2.430,Avg.Loss: -1.815,LR: 3.69E-04]Training epoch 35:  26%|██▌       | 40/153 [00:00<00:02, 51.19it/s, Epoch: 35, Batch: 41,Loss: -1.810,Avg.Loss: -1.815,LR: 3.69E-04]Training epoch 35:  27%|██▋       | 41/153 [00:00<00:02, 51.19it/s, Epoch: 35, Batch: 42,Loss: -2.641,Avg.Loss: -1.835,LR: 3.69E-04]Training epoch 35:  27%|██▋       | 42/153 [00:00<00:02, 51.58it/s, Epoch: 35, Batch: 42,Loss: -2.641,Avg.Loss: -1.835,LR: 3.69E-04]Training epoch 35:  27%|██▋       | 42/153 [00:00<00:02, 51.58it/s, Epoch: 35, Batch: 43,Loss: -1.954,Avg.Loss: -1.837,LR: 3.68E-04]Training epoch 35:  28%|██▊       | 43/153 [00:00<00:02, 51.58it/s, Epoch: 35, Batch: 44,Loss: -1.270,Avg.Loss: -1.825,LR: 3.68E-04]Training epoch 35:  29%|██▉       | 44/153 [00:00<00:02, 51.58it/s, Epoch: 35, Batch: 45,Loss: -1.341,Avg.Loss: -1.814,LR: 3.68E-04]Training epoch 35:  29%|██▉       | 45/153 [00:00<00:02, 51.58it/s, Epoch: 35, Batch: 46,Loss: -1.664,Avg.Loss: -1.811,LR: 3.68E-04]Training epoch 35:  30%|███       | 46/153 [00:00<00:02, 51.58it/s, Epoch: 35, Batch: 47,Loss: -1.722,Avg.Loss: -1.809,LR: 3.68E-04]Training epoch 35:  31%|███       | 47/153 [00:00<00:02, 51.58it/s, Epoch: 35, Batch: 48,Loss: -1.838,Avg.Loss: -1.809,LR: 3.68E-04]Training epoch 35:  31%|███▏      | 48/153 [00:00<00:02, 51.92it/s, Epoch: 35, Batch: 48,Loss: -1.838,Avg.Loss: -1.809,LR: 3.68E-04]Training epoch 35:  31%|███▏      | 48/153 [00:00<00:02, 51.92it/s, Epoch: 35, Batch: 49,Loss: -2.153,Avg.Loss: -1.816,LR: 3.68E-04]Training epoch 35:  32%|███▏      | 49/153 [00:00<00:02, 51.92it/s, Epoch: 35, Batch: 50,Loss: -2.042,Avg.Loss: -1.821,LR: 3.68E-04]Training epoch 35:  33%|███▎      | 50/153 [00:00<00:01, 51.92it/s, Epoch: 35, Batch: 51,Loss: -2.357,Avg.Loss: -1.831,LR: 3.68E-04]Training epoch 35:  33%|███▎      | 51/153 [00:00<00:01, 51.92it/s, Epoch: 35, Batch: 52,Loss: -2.302,Avg.Loss: -1.840,LR: 3.68E-04]Training epoch 35:  34%|███▍      | 52/153 [00:01<00:01, 51.92it/s, Epoch: 35, Batch: 53,Loss: -2.007,Avg.Loss: -1.843,LR: 3.68E-04]Training epoch 35:  35%|███▍      | 53/153 [00:01<00:01, 51.92it/s, Epoch: 35, Batch: 54,Loss: -2.298,Avg.Loss: -1.852,LR: 3.68E-04]Training epoch 35:  35%|███▌      | 54/153 [00:01<00:01, 52.19it/s, Epoch: 35, Batch: 54,Loss: -2.298,Avg.Loss: -1.852,LR: 3.68E-04]Training epoch 35:  35%|███▌      | 54/153 [00:01<00:01, 52.19it/s, Epoch: 35, Batch: 55,Loss: -2.453,Avg.Loss: -1.863,LR: 3.68E-04]Training epoch 35:  36%|███▌      | 55/153 [00:01<00:01, 52.19it/s, Epoch: 35, Batch: 56,Loss: -2.416,Avg.Loss: -1.873,LR: 3.68E-04]Training epoch 35:  37%|███▋      | 56/153 [00:01<00:01, 52.19it/s, Epoch: 35, Batch: 57,Loss: -2.222,Avg.Loss: -1.879,LR: 3.68E-04]Training epoch 35:  37%|███▋      | 57/153 [00:01<00:01, 52.19it/s, Epoch: 35, Batch: 58,Loss: -2.143,Avg.Loss: -1.883,LR: 3.68E-04]Training epoch 35:  38%|███▊      | 58/153 [00:01<00:01, 52.19it/s, Epoch: 35, Batch: 59,Loss: -2.454,Avg.Loss: -1.893,LR: 3.68E-04]Training epoch 35:  39%|███▊      | 59/153 [00:01<00:01, 52.19it/s, Epoch: 35, Batch: 60,Loss: -2.877,Avg.Loss: -1.909,LR: 3.68E-04]Training epoch 35:  39%|███▉      | 60/153 [00:01<00:01, 52.32it/s, Epoch: 35, Batch: 60,Loss: -2.877,Avg.Loss: -1.909,LR: 3.68E-04]Training epoch 35:  39%|███▉      | 60/153 [00:01<00:01, 52.32it/s, Epoch: 35, Batch: 61,Loss: -1.998,Avg.Loss: -1.911,LR: 3.68E-04]Training epoch 35:  40%|███▉      | 61/153 [00:01<00:01, 52.32it/s, Epoch: 35, Batch: 62,Loss: -2.060,Avg.Loss: -1.913,LR: 3.68E-04]Training epoch 35:  41%|████      | 62/153 [00:01<00:01, 52.32it/s, Epoch: 35, Batch: 63,Loss: -2.286,Avg.Loss: -1.919,LR: 3.68E-04]Training epoch 35:  41%|████      | 63/153 [00:01<00:01, 52.32it/s, Epoch: 35, Batch: 64,Loss: -2.270,Avg.Loss: -1.925,LR: 3.68E-04]Training epoch 35:  42%|████▏     | 64/153 [00:01<00:01, 52.32it/s, Epoch: 35, Batch: 65,Loss: -2.188,Avg.Loss: -1.929,LR: 3.68E-04]Training epoch 35:  42%|████▏     | 65/153 [00:01<00:01, 52.32it/s, Epoch: 35, Batch: 66,Loss: -2.263,Avg.Loss: -1.934,LR: 3.67E-04]Training epoch 35:  43%|████▎     | 66/153 [00:01<00:01, 52.47it/s, Epoch: 35, Batch: 66,Loss: -2.263,Avg.Loss: -1.934,LR: 3.67E-04]Training epoch 35:  43%|████▎     | 66/153 [00:01<00:01, 52.47it/s, Epoch: 35, Batch: 67,Loss: -2.661,Avg.Loss: -1.945,LR: 3.67E-04]Training epoch 35:  44%|████▍     | 67/153 [00:01<00:01, 52.47it/s, Epoch: 35, Batch: 68,Loss: -2.478,Avg.Loss: -1.953,LR: 3.67E-04]Training epoch 35:  44%|████▍     | 68/153 [00:01<00:01, 52.47it/s, Epoch: 35, Batch: 69,Loss: -2.248,Avg.Loss: -1.957,LR: 3.67E-04]Training epoch 35:  45%|████▌     | 69/153 [00:01<00:01, 52.47it/s, Epoch: 35, Batch: 70,Loss: -2.389,Avg.Loss: -1.963,LR: 3.67E-04]Training epoch 35:  46%|████▌     | 70/153 [00:01<00:01, 52.47it/s, Epoch: 35, Batch: 71,Loss: -1.841,Avg.Loss: -1.961,LR: 3.67E-04]Training epoch 35:  46%|████▋     | 71/153 [00:01<00:01, 52.47it/s, Epoch: 35, Batch: 72,Loss: -2.141,Avg.Loss: -1.964,LR: 3.67E-04]Training epoch 35:  47%|████▋     | 72/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 72,Loss: -2.141,Avg.Loss: -1.964,LR: 3.67E-04]Training epoch 35:  47%|████▋     | 72/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 73,Loss: -1.875,Avg.Loss: -1.963,LR: 3.67E-04]Training epoch 35:  48%|████▊     | 73/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 74,Loss: -2.202,Avg.Loss: -1.966,LR: 3.67E-04]Training epoch 35:  48%|████▊     | 74/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 75,Loss: -2.299,Avg.Loss: -1.970,LR: 3.67E-04]Training epoch 35:  49%|████▉     | 75/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 76,Loss: -1.866,Avg.Loss: -1.969,LR: 3.67E-04]Training epoch 35:  50%|████▉     | 76/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 77,Loss: -1.632,Avg.Loss: -1.964,LR: 3.67E-04]Training epoch 35:  50%|█████     | 77/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 78,Loss: -1.408,Avg.Loss: -1.957,LR: 3.67E-04]Training epoch 35:  51%|█████     | 78/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 78,Loss: -1.408,Avg.Loss: -1.957,LR: 3.67E-04]Training epoch 35:  51%|█████     | 78/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 79,Loss: -1.076,Avg.Loss: -1.946,LR: 3.67E-04]Training epoch 35:  52%|█████▏    | 79/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 80,Loss: -0.226,Avg.Loss: -1.925,LR: 3.67E-04]Training epoch 35:  52%|█████▏    | 80/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 81,Loss: -1.195,Avg.Loss: -1.916,LR: 3.67E-04]Training epoch 35:  53%|█████▎    | 81/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 82,Loss: -2.063,Avg.Loss: -1.917,LR: 3.67E-04]Training epoch 35:  54%|█████▎    | 82/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 83,Loss: -1.855,Avg.Loss: -1.917,LR: 3.67E-04]Training epoch 35:  54%|█████▍    | 83/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 84,Loss: -1.841,Avg.Loss: -1.916,LR: 3.67E-04]Training epoch 35:  55%|█████▍    | 84/153 [00:01<00:01, 52.82it/s, Epoch: 35, Batch: 84,Loss: -1.841,Avg.Loss: -1.916,LR: 3.67E-04]Training epoch 35:  55%|█████▍    | 84/153 [00:01<00:01, 52.82it/s, Epoch: 35, Batch: 85,Loss: -2.100,Avg.Loss: -1.918,LR: 3.67E-04]Training epoch 35:  56%|█████▌    | 85/153 [00:01<00:01, 52.82it/s, Epoch: 35, Batch: 86,Loss: -2.114,Avg.Loss: -1.920,LR: 3.67E-04]Training epoch 35:  56%|█████▌    | 86/153 [00:01<00:01, 52.82it/s, Epoch: 35, Batch: 87,Loss: -1.882,Avg.Loss: -1.920,LR: 3.67E-04]Training epoch 35:  57%|█████▋    | 87/153 [00:01<00:01, 52.82it/s, Epoch: 35, Batch: 88,Loss: -1.887,Avg.Loss: -1.919,LR: 3.66E-04]Training epoch 35:  58%|█████▊    | 88/153 [00:01<00:01, 52.82it/s, Epoch: 35, Batch: 89,Loss: -2.176,Avg.Loss: -1.922,LR: 3.66E-04]Training epoch 35:  58%|█████▊    | 89/153 [00:01<00:01, 52.82it/s, Epoch: 35, Batch: 90,Loss: -2.420,Avg.Loss: -1.928,LR: 3.66E-04]Training epoch 35:  59%|█████▉    | 90/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 90,Loss: -2.420,Avg.Loss: -1.928,LR: 3.66E-04]Training epoch 35:  59%|█████▉    | 90/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 91,Loss: -1.940,Avg.Loss: -1.928,LR: 3.66E-04]Training epoch 35:  59%|█████▉    | 91/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 92,Loss: -1.718,Avg.Loss: -1.926,LR: 3.66E-04]Training epoch 35:  60%|██████    | 92/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 93,Loss: -1.990,Avg.Loss: -1.926,LR: 3.66E-04]Training epoch 35:  61%|██████    | 93/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 94,Loss: -2.052,Avg.Loss: -1.928,LR: 3.66E-04]Training epoch 35:  61%|██████▏   | 94/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 95,Loss: -2.487,Avg.Loss: -1.934,LR: 3.66E-04]Training epoch 35:  62%|██████▏   | 95/153 [00:01<00:01, 52.65it/s, Epoch: 35, Batch: 96,Loss: -2.285,Avg.Loss: -1.937,LR: 3.66E-04]Training epoch 35:  63%|██████▎   | 96/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 96,Loss: -2.285,Avg.Loss: -1.937,LR: 3.66E-04]Training epoch 35:  63%|██████▎   | 96/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 97,Loss: -2.378,Avg.Loss: -1.942,LR: 3.66E-04]Training epoch 35:  63%|██████▎   | 97/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 98,Loss: -2.696,Avg.Loss: -1.950,LR: 3.66E-04]Training epoch 35:  64%|██████▍   | 98/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 99,Loss: -2.285,Avg.Loss: -1.953,LR: 3.66E-04]Training epoch 35:  65%|██████▍   | 99/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 100,Loss: -2.592,Avg.Loss: -1.959,LR: 3.66E-04]Training epoch 35:  65%|██████▌   | 100/153 [00:01<00:01, 52.74it/s, Epoch: 35, Batch: 101,Loss: -2.170,Avg.Loss: -1.961,LR: 3.66E-04]Training epoch 35:  66%|██████▌   | 101/153 [00:01<00:00, 52.74it/s, Epoch: 35, Batch: 102,Loss: -2.200,Avg.Loss: -1.964,LR: 3.66E-04]Training epoch 35:  67%|██████▋   | 102/153 [00:01<00:00, 52.95it/s, Epoch: 35, Batch: 102,Loss: -2.200,Avg.Loss: -1.964,LR: 3.66E-04]Training epoch 35:  67%|██████▋   | 102/153 [00:01<00:00, 52.95it/s, Epoch: 35, Batch: 103,Loss: -1.713,Avg.Loss: -1.961,LR: 3.66E-04]Training epoch 35:  67%|██████▋   | 103/153 [00:01<00:00, 52.95it/s, Epoch: 35, Batch: 104,Loss: -2.172,Avg.Loss: -1.963,LR: 3.66E-04]Training epoch 35:  68%|██████▊   | 104/153 [00:01<00:00, 52.95it/s, Epoch: 35, Batch: 105,Loss: -1.854,Avg.Loss: -1.962,LR: 3.66E-04]Training epoch 35:  69%|██████▊   | 105/153 [00:02<00:00, 52.95it/s, Epoch: 35, Batch: 106,Loss: -2.040,Avg.Loss: -1.963,LR: 3.66E-04]Training epoch 35:  69%|██████▉   | 106/153 [00:02<00:00, 52.95it/s, Epoch: 35, Batch: 107,Loss: -2.352,Avg.Loss: -1.967,LR: 3.66E-04]Training epoch 35:  70%|██████▉   | 107/153 [00:02<00:00, 52.95it/s, Epoch: 35, Batch: 108,Loss: -2.235,Avg.Loss: -1.969,LR: 3.66E-04]Training epoch 35:  71%|███████   | 108/153 [00:02<00:00, 52.92it/s, Epoch: 35, Batch: 108,Loss: -2.235,Avg.Loss: -1.969,LR: 3.66E-04]Training epoch 35:  71%|███████   | 108/153 [00:02<00:00, 52.92it/s, Epoch: 35, Batch: 109,Loss: -1.695,Avg.Loss: -1.967,LR: 3.66E-04]Training epoch 35:  71%|███████   | 109/153 [00:02<00:00, 52.92it/s, Epoch: 35, Batch: 110,Loss: -2.012,Avg.Loss: -1.967,LR: 3.65E-04]Training epoch 35:  72%|███████▏  | 110/153 [00:02<00:00, 52.92it/s, Epoch: 35, Batch: 111,Loss: -1.930,Avg.Loss: -1.967,LR: 3.65E-04]Training epoch 35:  73%|███████▎  | 111/153 [00:02<00:00, 52.92it/s, Epoch: 35, Batch: 112,Loss: -1.263,Avg.Loss: -1.960,LR: 3.65E-04]Training epoch 35:  73%|███████▎  | 112/153 [00:02<00:00, 52.92it/s, Epoch: 35, Batch: 113,Loss: -2.304,Avg.Loss: -1.963,LR: 3.65E-04]Training epoch 35:  74%|███████▍  | 113/153 [00:02<00:00, 52.92it/s, Epoch: 35, Batch: 114,Loss: -1.552,Avg.Loss: -1.960,LR: 3.65E-04]Training epoch 35:  75%|███████▍  | 114/153 [00:02<00:00, 52.80it/s, Epoch: 35, Batch: 114,Loss: -1.552,Avg.Loss: -1.960,LR: 3.65E-04]Training epoch 35:  75%|███████▍  | 114/153 [00:02<00:00, 52.80it/s, Epoch: 35, Batch: 115,Loss: -1.120,Avg.Loss: -1.953,LR: 3.65E-04]Training epoch 35:  75%|███████▌  | 115/153 [00:02<00:00, 52.80it/s, Epoch: 35, Batch: 116,Loss: -1.330,Avg.Loss: -1.947,LR: 3.65E-04]Training epoch 35:  76%|███████▌  | 116/153 [00:02<00:00, 52.80it/s, Epoch: 35, Batch: 117,Loss: -2.193,Avg.Loss: -1.949,LR: 3.65E-04]Training epoch 35:  76%|███████▋  | 117/153 [00:02<00:00, 52.80it/s, Epoch: 35, Batch: 118,Loss: -2.018,Avg.Loss: -1.950,LR: 3.65E-04]Training epoch 35:  77%|███████▋  | 118/153 [00:02<00:00, 52.80it/s, Epoch: 35, Batch: 119,Loss: -2.844,Avg.Loss: -1.957,LR: 3.65E-04]Training epoch 35:  78%|███████▊  | 119/153 [00:02<00:00, 52.80it/s, Epoch: 35, Batch: 120,Loss: -1.760,Avg.Loss: -1.956,LR: 3.65E-04]Training epoch 35:  78%|███████▊  | 120/153 [00:02<00:00, 52.89it/s, Epoch: 35, Batch: 120,Loss: -1.760,Avg.Loss: -1.956,LR: 3.65E-04]Training epoch 35:  78%|███████▊  | 120/153 [00:02<00:00, 52.89it/s, Epoch: 35, Batch: 121,Loss: -1.543,Avg.Loss: -1.952,LR: 3.65E-04]Training epoch 35:  79%|███████▉  | 121/153 [00:02<00:00, 52.89it/s, Epoch: 35, Batch: 122,Loss: -1.935,Avg.Loss: -1.952,LR: 3.65E-04]Training epoch 35:  80%|███████▉  | 122/153 [00:02<00:00, 52.89it/s, Epoch: 35, Batch: 123,Loss: -2.391,Avg.Loss: -1.956,LR: 3.65E-04]Training epoch 35:  80%|████████  | 123/153 [00:02<00:00, 52.89it/s, Epoch: 35, Batch: 124,Loss: -2.142,Avg.Loss: -1.957,LR: 3.65E-04]Training epoch 35:  81%|████████  | 124/153 [00:02<00:00, 52.89it/s, Epoch: 35, Batch: 125,Loss: -2.475,Avg.Loss: -1.961,LR: 3.65E-04]Training epoch 35:  82%|████████▏ | 125/153 [00:02<00:00, 52.89it/s, Epoch: 35, Batch: 126,Loss: -1.201,Avg.Loss: -1.955,LR: 3.65E-04]Training epoch 35:  82%|████████▏ | 126/153 [00:02<00:00, 53.00it/s, Epoch: 35, Batch: 126,Loss: -1.201,Avg.Loss: -1.955,LR: 3.65E-04]Training epoch 35:  82%|████████▏ | 126/153 [00:02<00:00, 53.00it/s, Epoch: 35, Batch: 127,Loss: -1.341,Avg.Loss: -1.951,LR: 3.65E-04]Training epoch 35:  83%|████████▎ | 127/153 [00:02<00:00, 53.00it/s, Epoch: 35, Batch: 128,Loss: -2.182,Avg.Loss: -1.952,LR: 3.65E-04]Training epoch 35:  84%|████████▎ | 128/153 [00:02<00:00, 53.00it/s, Epoch: 35, Batch: 129,Loss: -2.016,Avg.Loss: -1.953,LR: 3.65E-04]Training epoch 35:  84%|████████▍ | 129/153 [00:02<00:00, 53.00it/s, Epoch: 35, Batch: 130,Loss: 0.779,Avg.Loss: -1.932,LR: 3.65E-04] Training epoch 35:  85%|████████▍ | 130/153 [00:02<00:00, 53.00it/s, Epoch: 35, Batch: 131,Loss: 4.052,Avg.Loss: -1.886,LR: 3.65E-04]Training epoch 35:  86%|████████▌ | 131/153 [00:02<00:00, 53.00it/s, Epoch: 35, Batch: 132,Loss: 3.725,Avg.Loss: -1.844,LR: 3.64E-04]Training epoch 35:  86%|████████▋ | 132/153 [00:02<00:00, 52.99it/s, Epoch: 35, Batch: 132,Loss: 3.725,Avg.Loss: -1.844,LR: 3.64E-04]Training epoch 35:  86%|████████▋ | 132/153 [00:02<00:00, 52.99it/s, Epoch: 35, Batch: 133,Loss: 1.990,Avg.Loss: -1.815,LR: 3.64E-04]Training epoch 35:  87%|████████▋ | 133/153 [00:02<00:00, 52.99it/s, Epoch: 35, Batch: 134,Loss: -0.871,Avg.Loss: -1.808,LR: 3.64E-04]Training epoch 35:  88%|████████▊ | 134/153 [00:02<00:00, 52.99it/s, Epoch: 35, Batch: 135,Loss: -1.072,Avg.Loss: -1.802,LR: 3.64E-04]Training epoch 35:  88%|████████▊ | 135/153 [00:02<00:00, 52.99it/s, Epoch: 35, Batch: 136,Loss: -1.463,Avg.Loss: -1.800,LR: 3.64E-04]Training epoch 35:  89%|████████▉ | 136/153 [00:02<00:00, 52.99it/s, Epoch: 35, Batch: 137,Loss: -2.457,Avg.Loss: -1.805,LR: 3.64E-04]Training epoch 35:  90%|████████▉ | 137/153 [00:02<00:00, 52.99it/s, Epoch: 35, Batch: 138,Loss: -1.524,Avg.Loss: -1.803,LR: 3.64E-04]Training epoch 35:  90%|█████████ | 138/153 [00:02<00:00, 53.10it/s, Epoch: 35, Batch: 138,Loss: -1.524,Avg.Loss: -1.803,LR: 3.64E-04]Training epoch 35:  90%|█████████ | 138/153 [00:02<00:00, 53.10it/s, Epoch: 35, Batch: 139,Loss: -0.115,Avg.Loss: -1.790,LR: 3.64E-04]Training epoch 35:  91%|█████████ | 139/153 [00:02<00:00, 53.10it/s, Epoch: 35, Batch: 140,Loss: -0.259,Avg.Loss: -1.779,LR: 3.64E-04]Training epoch 35:  92%|█████████▏| 140/153 [00:02<00:00, 53.10it/s, Epoch: 35, Batch: 141,Loss: -1.206,Avg.Loss: -1.775,LR: 3.64E-04]Training epoch 35:  92%|█████████▏| 141/153 [00:02<00:00, 53.10it/s, Epoch: 35, Batch: 142,Loss: -0.871,Avg.Loss: -1.769,LR: 3.64E-04]Training epoch 35:  93%|█████████▎| 142/153 [00:02<00:00, 53.10it/s, Epoch: 35, Batch: 143,Loss: 0.266,Avg.Loss: -1.755,LR: 3.64E-04] Training epoch 35:  93%|█████████▎| 143/153 [00:02<00:00, 53.10it/s, Epoch: 35, Batch: 144,Loss: -0.162,Avg.Loss: -1.744,LR: 3.64E-04]Training epoch 35:  94%|█████████▍| 144/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 144,Loss: -0.162,Avg.Loss: -1.744,LR: 3.64E-04]Training epoch 35:  94%|█████████▍| 144/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 145,Loss: -2.030,Avg.Loss: -1.746,LR: 3.64E-04]Training epoch 35:  95%|█████████▍| 145/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 146,Loss: -1.248,Avg.Loss: -1.742,LR: 3.64E-04]Training epoch 35:  95%|█████████▌| 146/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 147,Loss: -0.441,Avg.Loss: -1.733,LR: 3.64E-04]Training epoch 35:  96%|█████████▌| 147/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 148,Loss: -0.681,Avg.Loss: -1.726,LR: 3.64E-04]Training epoch 35:  97%|█████████▋| 148/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 149,Loss: -1.710,Avg.Loss: -1.726,LR: 3.64E-04]Training epoch 35:  97%|█████████▋| 149/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 150,Loss: -1.661,Avg.Loss: -1.726,LR: 3.64E-04]Training epoch 35:  98%|█████████▊| 150/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 150,Loss: -1.661,Avg.Loss: -1.726,LR: 3.64E-04]Training epoch 35:  98%|█████████▊| 150/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 151,Loss: -0.696,Avg.Loss: -1.719,LR: 3.64E-04]Training epoch 35:  99%|█████████▊| 151/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 152,Loss: -1.427,Avg.Loss: -1.717,LR: 3.64E-04]Training epoch 35:  99%|█████████▉| 152/153 [00:02<00:00, 53.20it/s, Epoch: 35, Batch: 153,Loss: -1.394,Avg.Loss: -1.715,LR: 3.63E-04]Training epoch 35: 100%|██████████| 153/153 [00:02<00:00, 52.68it/s, Epoch: 35, Batch: 153,Loss: -1.394,Avg.Loss: -1.715,LR: 3.63E-04]
Training epoch 36:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 36:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 36, Batch: 1,Loss: -0.721,Avg.Loss: -0.721,LR: 3.63E-04]Training epoch 36:   1%|          | 1/153 [00:00<00:05, 26.69it/s, Epoch: 36, Batch: 2,Loss: -1.073,Avg.Loss: -0.897,LR: 3.63E-04]Training epoch 36:   1%|▏         | 2/153 [00:00<00:03, 39.20it/s, Epoch: 36, Batch: 3,Loss: -1.609,Avg.Loss: -1.134,LR: 3.63E-04]Training epoch 36:   2%|▏         | 3/153 [00:00<00:03, 43.12it/s, Epoch: 36, Batch: 4,Loss: -2.409,Avg.Loss: -1.453,LR: 3.63E-04]Training epoch 36:   3%|▎         | 4/153 [00:00<00:03, 45.34it/s, Epoch: 36, Batch: 5,Loss: -0.763,Avg.Loss: -1.315,LR: 3.63E-04]Training epoch 36:   3%|▎         | 5/153 [00:00<00:03, 46.61it/s, Epoch: 36, Batch: 6,Loss: 1.627,Avg.Loss: -0.825,LR: 3.63E-04] Training epoch 36:   4%|▍         | 6/153 [00:00<00:02, 55.84it/s, Epoch: 36, Batch: 6,Loss: 1.627,Avg.Loss: -0.825,LR: 3.63E-04]Training epoch 36:   4%|▍         | 6/153 [00:00<00:02, 55.84it/s, Epoch: 36, Batch: 7,Loss: 0.502,Avg.Loss: -0.635,LR: 3.63E-04]Training epoch 36:   5%|▍         | 7/153 [00:00<00:02, 55.84it/s, Epoch: 36, Batch: 8,Loss: -0.789,Avg.Loss: -0.654,LR: 3.63E-04]Training epoch 36:   5%|▌         | 8/153 [00:00<00:02, 55.84it/s, Epoch: 36, Batch: 9,Loss: -1.951,Avg.Loss: -0.798,LR: 3.63E-04]Training epoch 36:   6%|▌         | 9/153 [00:00<00:02, 55.84it/s, Epoch: 36, Batch: 10,Loss: -1.809,Avg.Loss: -0.899,LR: 3.63E-04]Training epoch 36:   7%|▋         | 10/153 [00:00<00:02, 55.84it/s, Epoch: 36, Batch: 11,Loss: -1.675,Avg.Loss: -0.970,LR: 3.63E-04]Training epoch 36:   7%|▋         | 11/153 [00:00<00:02, 55.84it/s, Epoch: 36, Batch: 12,Loss: -1.689,Avg.Loss: -1.030,LR: 3.63E-04]Training epoch 36:   8%|▊         | 12/153 [00:00<00:02, 54.02it/s, Epoch: 36, Batch: 12,Loss: -1.689,Avg.Loss: -1.030,LR: 3.63E-04]Training epoch 36:   8%|▊         | 12/153 [00:00<00:02, 54.02it/s, Epoch: 36, Batch: 13,Loss: -1.521,Avg.Loss: -1.068,LR: 3.63E-04]Training epoch 36:   8%|▊         | 13/153 [00:00<00:02, 54.02it/s, Epoch: 36, Batch: 14,Loss: -1.187,Avg.Loss: -1.076,LR: 3.63E-04]Training epoch 36:   9%|▉         | 14/153 [00:00<00:02, 54.02it/s, Epoch: 36, Batch: 15,Loss: -1.428,Avg.Loss: -1.100,LR: 3.63E-04]Training epoch 36:  10%|▉         | 15/153 [00:00<00:02, 54.02it/s, Epoch: 36, Batch: 16,Loss: -2.247,Avg.Loss: -1.171,LR: 3.63E-04]Training epoch 36:  10%|█         | 16/153 [00:00<00:02, 54.02it/s, Epoch: 36, Batch: 17,Loss: -1.660,Avg.Loss: -1.200,LR: 3.63E-04]Training epoch 36:  11%|█         | 17/153 [00:00<00:02, 54.02it/s, Epoch: 36, Batch: 18,Loss: -1.471,Avg.Loss: -1.215,LR: 3.63E-04]Training epoch 36:  12%|█▏        | 18/153 [00:00<00:02, 52.65it/s, Epoch: 36, Batch: 18,Loss: -1.471,Avg.Loss: -1.215,LR: 3.63E-04]Training epoch 36:  12%|█▏        | 18/153 [00:00<00:02, 52.65it/s, Epoch: 36, Batch: 19,Loss: -1.475,Avg.Loss: -1.229,LR: 3.63E-04]Training epoch 36:  12%|█▏        | 19/153 [00:00<00:02, 52.65it/s, Epoch: 36, Batch: 20,Loss: -1.203,Avg.Loss: -1.228,LR: 3.63E-04]Training epoch 36:  13%|█▎        | 20/153 [00:00<00:02, 52.65it/s, Epoch: 36, Batch: 21,Loss: -0.851,Avg.Loss: -1.210,LR: 3.63E-04]Training epoch 36:  14%|█▎        | 21/153 [00:00<00:02, 52.65it/s, Epoch: 36, Batch: 22,Loss: -2.010,Avg.Loss: -1.246,LR: 3.62E-04]Training epoch 36:  14%|█▍        | 22/153 [00:00<00:02, 52.65it/s, Epoch: 36, Batch: 23,Loss: -2.090,Avg.Loss: -1.283,LR: 3.62E-04]Training epoch 36:  15%|█▌        | 23/153 [00:00<00:02, 52.65it/s, Epoch: 36, Batch: 24,Loss: -1.604,Avg.Loss: -1.296,LR: 3.62E-04]Training epoch 36:  16%|█▌        | 24/153 [00:00<00:02, 51.66it/s, Epoch: 36, Batch: 24,Loss: -1.604,Avg.Loss: -1.296,LR: 3.62E-04]Training epoch 36:  16%|█▌        | 24/153 [00:00<00:02, 51.66it/s, Epoch: 36, Batch: 25,Loss: -1.918,Avg.Loss: -1.321,LR: 3.62E-04]Training epoch 36:  16%|█▋        | 25/153 [00:00<00:02, 51.66it/s, Epoch: 36, Batch: 26,Loss: -1.889,Avg.Loss: -1.343,LR: 3.62E-04]Training epoch 36:  17%|█▋        | 26/153 [00:00<00:02, 51.66it/s, Epoch: 36, Batch: 27,Loss: -1.594,Avg.Loss: -1.352,LR: 3.62E-04]Training epoch 36:  18%|█▊        | 27/153 [00:00<00:02, 51.66it/s, Epoch: 36, Batch: 28,Loss: -1.696,Avg.Loss: -1.364,LR: 3.62E-04]Training epoch 36:  18%|█▊        | 28/153 [00:00<00:02, 51.66it/s, Epoch: 36, Batch: 29,Loss: -2.034,Avg.Loss: -1.387,LR: 3.62E-04]Training epoch 36:  19%|█▉        | 29/153 [00:00<00:02, 51.66it/s, Epoch: 36, Batch: 30,Loss: -1.694,Avg.Loss: -1.398,LR: 3.62E-04]Training epoch 36:  20%|█▉        | 30/153 [00:00<00:02, 51.76it/s, Epoch: 36, Batch: 30,Loss: -1.694,Avg.Loss: -1.398,LR: 3.62E-04]Training epoch 36:  20%|█▉        | 30/153 [00:00<00:02, 51.76it/s, Epoch: 36, Batch: 31,Loss: -2.102,Avg.Loss: -1.420,LR: 3.62E-04]Training epoch 36:  20%|██        | 31/153 [00:00<00:02, 51.76it/s, Epoch: 36, Batch: 32,Loss: -1.510,Avg.Loss: -1.423,LR: 3.62E-04]Training epoch 36:  21%|██        | 32/153 [00:00<00:02, 51.76it/s, Epoch: 36, Batch: 33,Loss: -1.247,Avg.Loss: -1.418,LR: 3.62E-04]Training epoch 36:  22%|██▏       | 33/153 [00:00<00:02, 51.76it/s, Epoch: 36, Batch: 34,Loss: -1.859,Avg.Loss: -1.431,LR: 3.62E-04]Training epoch 36:  22%|██▏       | 34/153 [00:00<00:02, 51.76it/s, Epoch: 36, Batch: 35,Loss: -1.832,Avg.Loss: -1.442,LR: 3.62E-04]Training epoch 36:  23%|██▎       | 35/153 [00:00<00:02, 51.76it/s, Epoch: 36, Batch: 36,Loss: -1.427,Avg.Loss: -1.442,LR: 3.62E-04]Training epoch 36:  24%|██▎       | 36/153 [00:00<00:02, 52.14it/s, Epoch: 36, Batch: 36,Loss: -1.427,Avg.Loss: -1.442,LR: 3.62E-04]Training epoch 36:  24%|██▎       | 36/153 [00:00<00:02, 52.14it/s, Epoch: 36, Batch: 37,Loss: -1.957,Avg.Loss: -1.456,LR: 3.62E-04]Training epoch 36:  24%|██▍       | 37/153 [00:00<00:02, 52.14it/s, Epoch: 36, Batch: 38,Loss: -2.332,Avg.Loss: -1.479,LR: 3.62E-04]Training epoch 36:  25%|██▍       | 38/153 [00:00<00:02, 52.14it/s, Epoch: 36, Batch: 39,Loss: -2.276,Avg.Loss: -1.499,LR: 3.62E-04]Training epoch 36:  25%|██▌       | 39/153 [00:00<00:02, 52.14it/s, Epoch: 36, Batch: 40,Loss: -2.313,Avg.Loss: -1.520,LR: 3.62E-04]Training epoch 36:  26%|██▌       | 40/153 [00:00<00:02, 52.14it/s, Epoch: 36, Batch: 41,Loss: -2.316,Avg.Loss: -1.539,LR: 3.62E-04]Training epoch 36:  27%|██▋       | 41/153 [00:00<00:02, 52.14it/s, Epoch: 36, Batch: 42,Loss: -2.362,Avg.Loss: -1.559,LR: 3.62E-04]Training epoch 36:  27%|██▋       | 42/153 [00:00<00:02, 52.23it/s, Epoch: 36, Batch: 42,Loss: -2.362,Avg.Loss: -1.559,LR: 3.62E-04]Training epoch 36:  27%|██▋       | 42/153 [00:00<00:02, 52.23it/s, Epoch: 36, Batch: 43,Loss: -2.396,Avg.Loss: -1.578,LR: 3.62E-04]Training epoch 36:  28%|██▊       | 43/153 [00:00<00:02, 52.23it/s, Epoch: 36, Batch: 44,Loss: -2.156,Avg.Loss: -1.591,LR: 3.61E-04]Training epoch 36:  29%|██▉       | 44/153 [00:00<00:02, 52.23it/s, Epoch: 36, Batch: 45,Loss: -2.459,Avg.Loss: -1.611,LR: 3.61E-04]Training epoch 36:  29%|██▉       | 45/153 [00:00<00:02, 52.23it/s, Epoch: 36, Batch: 46,Loss: -2.115,Avg.Loss: -1.621,LR: 3.61E-04]Training epoch 36:  30%|███       | 46/153 [00:00<00:02, 52.23it/s, Epoch: 36, Batch: 47,Loss: -2.189,Avg.Loss: -1.634,LR: 3.61E-04]Training epoch 36:  31%|███       | 47/153 [00:00<00:02, 52.23it/s, Epoch: 36, Batch: 48,Loss: -1.986,Avg.Loss: -1.641,LR: 3.61E-04]Training epoch 36:  31%|███▏      | 48/153 [00:00<00:01, 52.56it/s, Epoch: 36, Batch: 48,Loss: -1.986,Avg.Loss: -1.641,LR: 3.61E-04]Training epoch 36:  31%|███▏      | 48/153 [00:00<00:01, 52.56it/s, Epoch: 36, Batch: 49,Loss: -1.857,Avg.Loss: -1.645,LR: 3.61E-04]Training epoch 36:  32%|███▏      | 49/153 [00:00<00:01, 52.56it/s, Epoch: 36, Batch: 50,Loss: -2.115,Avg.Loss: -1.655,LR: 3.61E-04]Training epoch 36:  33%|███▎      | 50/153 [00:00<00:01, 52.56it/s, Epoch: 36, Batch: 51,Loss: -2.132,Avg.Loss: -1.664,LR: 3.61E-04]Training epoch 36:  33%|███▎      | 51/153 [00:00<00:01, 52.56it/s, Epoch: 36, Batch: 52,Loss: -2.163,Avg.Loss: -1.674,LR: 3.61E-04]Training epoch 36:  34%|███▍      | 52/153 [00:01<00:01, 52.56it/s, Epoch: 36, Batch: 53,Loss: -2.361,Avg.Loss: -1.687,LR: 3.61E-04]Training epoch 36:  35%|███▍      | 53/153 [00:01<00:01, 52.56it/s, Epoch: 36, Batch: 54,Loss: -2.010,Avg.Loss: -1.693,LR: 3.61E-04]Training epoch 36:  35%|███▌      | 54/153 [00:01<00:01, 52.55it/s, Epoch: 36, Batch: 54,Loss: -2.010,Avg.Loss: -1.693,LR: 3.61E-04]Training epoch 36:  35%|███▌      | 54/153 [00:01<00:01, 52.55it/s, Epoch: 36, Batch: 55,Loss: -2.256,Avg.Loss: -1.703,LR: 3.61E-04]Training epoch 36:  36%|███▌      | 55/153 [00:01<00:01, 52.55it/s, Epoch: 36, Batch: 56,Loss: -2.344,Avg.Loss: -1.714,LR: 3.61E-04]Training epoch 36:  37%|███▋      | 56/153 [00:01<00:01, 52.55it/s, Epoch: 36, Batch: 57,Loss: -1.832,Avg.Loss: -1.716,LR: 3.61E-04]Training epoch 36:  37%|███▋      | 57/153 [00:01<00:01, 52.55it/s, Epoch: 36, Batch: 58,Loss: -2.300,Avg.Loss: -1.726,LR: 3.61E-04]Training epoch 36:  38%|███▊      | 58/153 [00:01<00:01, 52.55it/s, Epoch: 36, Batch: 59,Loss: -2.178,Avg.Loss: -1.734,LR: 3.61E-04]Training epoch 36:  39%|███▊      | 59/153 [00:01<00:01, 52.55it/s, Epoch: 36, Batch: 60,Loss: -2.652,Avg.Loss: -1.749,LR: 3.61E-04]Training epoch 36:  39%|███▉      | 60/153 [00:01<00:01, 52.63it/s, Epoch: 36, Batch: 60,Loss: -2.652,Avg.Loss: -1.749,LR: 3.61E-04]Training epoch 36:  39%|███▉      | 60/153 [00:01<00:01, 52.63it/s, Epoch: 36, Batch: 61,Loss: -2.185,Avg.Loss: -1.757,LR: 3.61E-04]Training epoch 36:  40%|███▉      | 61/153 [00:01<00:01, 52.63it/s, Epoch: 36, Batch: 62,Loss: -1.705,Avg.Loss: -1.756,LR: 3.61E-04]Training epoch 36:  41%|████      | 62/153 [00:01<00:01, 52.63it/s, Epoch: 36, Batch: 63,Loss: -2.726,Avg.Loss: -1.771,LR: 3.61E-04]Training epoch 36:  41%|████      | 63/153 [00:01<00:01, 52.63it/s, Epoch: 36, Batch: 64,Loss: -1.925,Avg.Loss: -1.774,LR: 3.61E-04]Training epoch 36:  42%|████▏     | 64/153 [00:01<00:01, 52.63it/s, Epoch: 36, Batch: 65,Loss: -1.534,Avg.Loss: -1.770,LR: 3.61E-04]Training epoch 36:  42%|████▏     | 65/153 [00:01<00:01, 52.63it/s, Epoch: 36, Batch: 66,Loss: -1.571,Avg.Loss: -1.767,LR: 3.60E-04]Training epoch 36:  43%|████▎     | 66/153 [00:01<00:01, 52.77it/s, Epoch: 36, Batch: 66,Loss: -1.571,Avg.Loss: -1.767,LR: 3.60E-04]Training epoch 36:  43%|████▎     | 66/153 [00:01<00:01, 52.77it/s, Epoch: 36, Batch: 67,Loss: -1.366,Avg.Loss: -1.761,LR: 3.60E-04]Training epoch 36:  44%|████▍     | 67/153 [00:01<00:01, 52.77it/s, Epoch: 36, Batch: 68,Loss: -0.912,Avg.Loss: -1.748,LR: 3.60E-04]Training epoch 36:  44%|████▍     | 68/153 [00:01<00:01, 52.77it/s, Epoch: 36, Batch: 69,Loss: -1.963,Avg.Loss: -1.751,LR: 3.60E-04]Training epoch 36:  45%|████▌     | 69/153 [00:01<00:01, 52.77it/s, Epoch: 36, Batch: 70,Loss: -0.964,Avg.Loss: -1.740,LR: 3.60E-04]Training epoch 36:  46%|████▌     | 70/153 [00:01<00:01, 52.77it/s, Epoch: 36, Batch: 71,Loss: 0.220,Avg.Loss: -1.713,LR: 3.60E-04] Training epoch 36:  46%|████▋     | 71/153 [00:01<00:01, 52.77it/s, Epoch: 36, Batch: 72,Loss: -1.345,Avg.Loss: -1.707,LR: 3.60E-04]Training epoch 36:  47%|████▋     | 72/153 [00:01<00:01, 52.70it/s, Epoch: 36, Batch: 72,Loss: -1.345,Avg.Loss: -1.707,LR: 3.60E-04]Training epoch 36:  47%|████▋     | 72/153 [00:01<00:01, 52.70it/s, Epoch: 36, Batch: 73,Loss: -1.565,Avg.Loss: -1.706,LR: 3.60E-04]Training epoch 36:  48%|████▊     | 73/153 [00:01<00:01, 52.70it/s, Epoch: 36, Batch: 74,Loss: -1.250,Avg.Loss: -1.699,LR: 3.60E-04]Training epoch 36:  48%|████▊     | 74/153 [00:01<00:01, 52.70it/s, Epoch: 36, Batch: 75,Loss: 0.364,Avg.Loss: -1.672,LR: 3.60E-04] Training epoch 36:  49%|████▉     | 75/153 [00:01<00:01, 52.70it/s, Epoch: 36, Batch: 76,Loss: -0.729,Avg.Loss: -1.659,LR: 3.60E-04]Training epoch 36:  50%|████▉     | 76/153 [00:01<00:01, 52.70it/s, Epoch: 36, Batch: 77,Loss: -1.690,Avg.Loss: -1.660,LR: 3.60E-04]Training epoch 36:  50%|█████     | 77/153 [00:01<00:01, 52.70it/s, Epoch: 36, Batch: 78,Loss: -1.988,Avg.Loss: -1.664,LR: 3.60E-04]Training epoch 36:  51%|█████     | 78/153 [00:01<00:01, 52.64it/s, Epoch: 36, Batch: 78,Loss: -1.988,Avg.Loss: -1.664,LR: 3.60E-04]Training epoch 36:  51%|█████     | 78/153 [00:01<00:01, 52.64it/s, Epoch: 36, Batch: 79,Loss: -0.910,Avg.Loss: -1.655,LR: 3.60E-04]Training epoch 36:  52%|█████▏    | 79/153 [00:01<00:01, 52.64it/s, Epoch: 36, Batch: 80,Loss: -1.442,Avg.Loss: -1.652,LR: 3.60E-04]Training epoch 36:  52%|█████▏    | 80/153 [00:01<00:01, 52.64it/s, Epoch: 36, Batch: 81,Loss: -2.146,Avg.Loss: -1.658,LR: 3.60E-04]Training epoch 36:  53%|█████▎    | 81/153 [00:01<00:01, 52.64it/s, Epoch: 36, Batch: 82,Loss: -1.780,Avg.Loss: -1.659,LR: 3.60E-04]Training epoch 36:  54%|█████▎    | 82/153 [00:01<00:01, 52.64it/s, Epoch: 36, Batch: 83,Loss: 0.141,Avg.Loss: -1.638,LR: 3.60E-04] Training epoch 36:  54%|█████▍    | 83/153 [00:01<00:01, 52.64it/s, Epoch: 36, Batch: 84,Loss: -0.916,Avg.Loss: -1.629,LR: 3.60E-04]Training epoch 36:  55%|█████▍    | 84/153 [00:01<00:01, 52.78it/s, Epoch: 36, Batch: 84,Loss: -0.916,Avg.Loss: -1.629,LR: 3.60E-04]Training epoch 36:  55%|█████▍    | 84/153 [00:01<00:01, 52.78it/s, Epoch: 36, Batch: 85,Loss: -2.172,Avg.Loss: -1.636,LR: 3.60E-04]Training epoch 36:  56%|█████▌    | 85/153 [00:01<00:01, 52.78it/s, Epoch: 36, Batch: 86,Loss: -1.815,Avg.Loss: -1.638,LR: 3.60E-04]Training epoch 36:  56%|█████▌    | 86/153 [00:01<00:01, 52.78it/s, Epoch: 36, Batch: 87,Loss: -1.208,Avg.Loss: -1.633,LR: 3.60E-04]Training epoch 36:  57%|█████▋    | 87/153 [00:01<00:01, 52.78it/s, Epoch: 36, Batch: 88,Loss: -1.253,Avg.Loss: -1.628,LR: 3.59E-04]Training epoch 36:  58%|█████▊    | 88/153 [00:01<00:01, 52.78it/s, Epoch: 36, Batch: 89,Loss: -1.946,Avg.Loss: -1.632,LR: 3.59E-04]Training epoch 36:  58%|█████▊    | 89/153 [00:01<00:01, 52.78it/s, Epoch: 36, Batch: 90,Loss: -1.603,Avg.Loss: -1.632,LR: 3.59E-04]Training epoch 36:  59%|█████▉    | 90/153 [00:01<00:01, 52.11it/s, Epoch: 36, Batch: 90,Loss: -1.603,Avg.Loss: -1.632,LR: 3.59E-04]Training epoch 36:  59%|█████▉    | 90/153 [00:01<00:01, 52.11it/s, Epoch: 36, Batch: 91,Loss: -1.072,Avg.Loss: -1.625,LR: 3.59E-04]Training epoch 36:  59%|█████▉    | 91/153 [00:01<00:01, 52.11it/s, Epoch: 36, Batch: 92,Loss: -1.301,Avg.Loss: -1.622,LR: 3.59E-04]Training epoch 36:  60%|██████    | 92/153 [00:01<00:01, 52.11it/s, Epoch: 36, Batch: 93,Loss: -2.220,Avg.Loss: -1.628,LR: 3.59E-04]Training epoch 36:  61%|██████    | 93/153 [00:01<00:01, 52.11it/s, Epoch: 36, Batch: 94,Loss: -2.043,Avg.Loss: -1.633,LR: 3.59E-04]Training epoch 36:  61%|██████▏   | 94/153 [00:01<00:01, 52.11it/s, Epoch: 36, Batch: 95,Loss: -0.846,Avg.Loss: -1.625,LR: 3.59E-04]Training epoch 36:  62%|██████▏   | 95/153 [00:01<00:01, 52.11it/s, Epoch: 36, Batch: 96,Loss: -1.414,Avg.Loss: -1.622,LR: 3.59E-04]Training epoch 36:  63%|██████▎   | 96/153 [00:01<00:01, 52.22it/s, Epoch: 36, Batch: 96,Loss: -1.414,Avg.Loss: -1.622,LR: 3.59E-04]Training epoch 36:  63%|██████▎   | 96/153 [00:01<00:01, 52.22it/s, Epoch: 36, Batch: 97,Loss: -2.448,Avg.Loss: -1.631,LR: 3.59E-04]Training epoch 36:  63%|██████▎   | 97/153 [00:01<00:01, 52.22it/s, Epoch: 36, Batch: 98,Loss: -1.508,Avg.Loss: -1.630,LR: 3.59E-04]Training epoch 36:  64%|██████▍   | 98/153 [00:01<00:01, 52.22it/s, Epoch: 36, Batch: 99,Loss: -1.097,Avg.Loss: -1.624,LR: 3.59E-04]Training epoch 36:  65%|██████▍   | 99/153 [00:01<00:01, 52.22it/s, Epoch: 36, Batch: 100,Loss: -1.662,Avg.Loss: -1.625,LR: 3.59E-04]Training epoch 36:  65%|██████▌   | 100/153 [00:01<00:01, 52.22it/s, Epoch: 36, Batch: 101,Loss: -2.169,Avg.Loss: -1.630,LR: 3.59E-04]Training epoch 36:  66%|██████▌   | 101/153 [00:01<00:00, 52.22it/s, Epoch: 36, Batch: 102,Loss: -1.356,Avg.Loss: -1.627,LR: 3.59E-04]Training epoch 36:  67%|██████▋   | 102/153 [00:01<00:00, 52.33it/s, Epoch: 36, Batch: 102,Loss: -1.356,Avg.Loss: -1.627,LR: 3.59E-04]Training epoch 36:  67%|██████▋   | 102/153 [00:01<00:00, 52.33it/s, Epoch: 36, Batch: 103,Loss: -0.847,Avg.Loss: -1.620,LR: 3.59E-04]Training epoch 36:  67%|██████▋   | 103/153 [00:01<00:00, 52.33it/s, Epoch: 36, Batch: 104,Loss: -1.349,Avg.Loss: -1.617,LR: 3.59E-04]Training epoch 36:  68%|██████▊   | 104/153 [00:01<00:00, 52.33it/s, Epoch: 36, Batch: 105,Loss: -2.301,Avg.Loss: -1.624,LR: 3.59E-04]Training epoch 36:  69%|██████▊   | 105/153 [00:02<00:00, 52.33it/s, Epoch: 36, Batch: 106,Loss: -2.079,Avg.Loss: -1.628,LR: 3.59E-04]Training epoch 36:  69%|██████▉   | 106/153 [00:02<00:00, 52.33it/s, Epoch: 36, Batch: 107,Loss: -0.880,Avg.Loss: -1.621,LR: 3.59E-04]Training epoch 36:  70%|██████▉   | 107/153 [00:02<00:00, 52.33it/s, Epoch: 36, Batch: 108,Loss: -1.165,Avg.Loss: -1.617,LR: 3.59E-04]Training epoch 36:  71%|███████   | 108/153 [00:02<00:00, 52.48it/s, Epoch: 36, Batch: 108,Loss: -1.165,Avg.Loss: -1.617,LR: 3.59E-04]Training epoch 36:  71%|███████   | 108/153 [00:02<00:00, 52.48it/s, Epoch: 36, Batch: 109,Loss: -2.420,Avg.Loss: -1.624,LR: 3.58E-04]Training epoch 36:  71%|███████   | 109/153 [00:02<00:00, 52.48it/s, Epoch: 36, Batch: 110,Loss: -2.299,Avg.Loss: -1.630,LR: 3.58E-04]Training epoch 36:  72%|███████▏  | 110/153 [00:02<00:00, 52.48it/s, Epoch: 36, Batch: 111,Loss: -0.940,Avg.Loss: -1.624,LR: 3.58E-04]Training epoch 36:  73%|███████▎  | 111/153 [00:02<00:00, 52.48it/s, Epoch: 36, Batch: 112,Loss: -1.873,Avg.Loss: -1.626,LR: 3.58E-04]Training epoch 36:  73%|███████▎  | 112/153 [00:02<00:00, 52.48it/s, Epoch: 36, Batch: 113,Loss: -2.203,Avg.Loss: -1.631,LR: 3.58E-04]Training epoch 36:  74%|███████▍  | 113/153 [00:02<00:00, 52.48it/s, Epoch: 36, Batch: 114,Loss: -1.847,Avg.Loss: -1.633,LR: 3.58E-04]Training epoch 36:  75%|███████▍  | 114/153 [00:02<00:00, 52.76it/s, Epoch: 36, Batch: 114,Loss: -1.847,Avg.Loss: -1.633,LR: 3.58E-04]Training epoch 36:  75%|███████▍  | 114/153 [00:02<00:00, 52.76it/s, Epoch: 36, Batch: 115,Loss: -1.196,Avg.Loss: -1.629,LR: 3.58E-04]Training epoch 36:  75%|███████▌  | 115/153 [00:02<00:00, 52.76it/s, Epoch: 36, Batch: 116,Loss: -0.812,Avg.Loss: -1.622,LR: 3.58E-04]Training epoch 36:  76%|███████▌  | 116/153 [00:02<00:00, 52.76it/s, Epoch: 36, Batch: 117,Loss: -1.916,Avg.Loss: -1.625,LR: 3.58E-04]Training epoch 36:  76%|███████▋  | 117/153 [00:02<00:00, 52.76it/s, Epoch: 36, Batch: 118,Loss: -2.315,Avg.Loss: -1.631,LR: 3.58E-04]Training epoch 36:  77%|███████▋  | 118/153 [00:02<00:00, 52.76it/s, Epoch: 36, Batch: 119,Loss: -1.656,Avg.Loss: -1.631,LR: 3.58E-04]Training epoch 36:  78%|███████▊  | 119/153 [00:02<00:00, 52.76it/s, Epoch: 36, Batch: 120,Loss: -1.754,Avg.Loss: -1.632,LR: 3.58E-04]Training epoch 36:  78%|███████▊  | 120/153 [00:02<00:00, 52.83it/s, Epoch: 36, Batch: 120,Loss: -1.754,Avg.Loss: -1.632,LR: 3.58E-04]Training epoch 36:  78%|███████▊  | 120/153 [00:02<00:00, 52.83it/s, Epoch: 36, Batch: 121,Loss: -2.482,Avg.Loss: -1.639,LR: 3.58E-04]Training epoch 36:  79%|███████▉  | 121/153 [00:02<00:00, 52.83it/s, Epoch: 36, Batch: 122,Loss: -1.645,Avg.Loss: -1.639,LR: 3.58E-04]Training epoch 36:  80%|███████▉  | 122/153 [00:02<00:00, 52.83it/s, Epoch: 36, Batch: 123,Loss: -1.003,Avg.Loss: -1.634,LR: 3.58E-04]Training epoch 36:  80%|████████  | 123/153 [00:02<00:00, 52.83it/s, Epoch: 36, Batch: 124,Loss: -1.000,Avg.Loss: -1.629,LR: 3.58E-04]Training epoch 36:  81%|████████  | 124/153 [00:02<00:00, 52.83it/s, Epoch: 36, Batch: 125,Loss: -1.939,Avg.Loss: -1.631,LR: 3.58E-04]Training epoch 36:  82%|████████▏ | 125/153 [00:02<00:00, 52.83it/s, Epoch: 36, Batch: 126,Loss: -1.898,Avg.Loss: -1.633,LR: 3.58E-04]Training epoch 36:  82%|████████▏ | 126/153 [00:02<00:00, 52.96it/s, Epoch: 36, Batch: 126,Loss: -1.898,Avg.Loss: -1.633,LR: 3.58E-04]Training epoch 36:  82%|████████▏ | 126/153 [00:02<00:00, 52.96it/s, Epoch: 36, Batch: 127,Loss: -1.870,Avg.Loss: -1.635,LR: 3.58E-04]Training epoch 36:  83%|████████▎ | 127/153 [00:02<00:00, 52.96it/s, Epoch: 36, Batch: 128,Loss: -1.681,Avg.Loss: -1.636,LR: 3.58E-04]Training epoch 36:  84%|████████▎ | 128/153 [00:02<00:00, 52.96it/s, Epoch: 36, Batch: 129,Loss: -2.578,Avg.Loss: -1.643,LR: 3.58E-04]Training epoch 36:  84%|████████▍ | 129/153 [00:02<00:00, 52.96it/s, Epoch: 36, Batch: 130,Loss: -1.826,Avg.Loss: -1.644,LR: 3.58E-04]Training epoch 36:  85%|████████▍ | 130/153 [00:02<00:00, 52.96it/s, Epoch: 36, Batch: 131,Loss: -1.479,Avg.Loss: -1.643,LR: 3.57E-04]Training epoch 36:  86%|████████▌ | 131/153 [00:02<00:00, 52.96it/s, Epoch: 36, Batch: 132,Loss: -1.273,Avg.Loss: -1.640,LR: 3.57E-04]Training epoch 36:  86%|████████▋ | 132/153 [00:02<00:00, 53.21it/s, Epoch: 36, Batch: 132,Loss: -1.273,Avg.Loss: -1.640,LR: 3.57E-04]Training epoch 36:  86%|████████▋ | 132/153 [00:02<00:00, 53.21it/s, Epoch: 36, Batch: 133,Loss: -2.059,Avg.Loss: -1.643,LR: 3.57E-04]Training epoch 36:  87%|████████▋ | 133/153 [00:02<00:00, 53.21it/s, Epoch: 36, Batch: 134,Loss: -1.812,Avg.Loss: -1.645,LR: 3.57E-04]Training epoch 36:  88%|████████▊ | 134/153 [00:02<00:00, 53.21it/s, Epoch: 36, Batch: 135,Loss: -1.653,Avg.Loss: -1.645,LR: 3.57E-04]Training epoch 36:  88%|████████▊ | 135/153 [00:02<00:00, 53.21it/s, Epoch: 36, Batch: 136,Loss: -1.530,Avg.Loss: -1.644,LR: 3.57E-04]Training epoch 36:  89%|████████▉ | 136/153 [00:02<00:00, 53.21it/s, Epoch: 36, Batch: 137,Loss: -1.581,Avg.Loss: -1.643,LR: 3.57E-04]Training epoch 36:  90%|████████▉ | 137/153 [00:02<00:00, 53.21it/s, Epoch: 36, Batch: 138,Loss: -2.097,Avg.Loss: -1.647,LR: 3.57E-04]Training epoch 36:  90%|█████████ | 138/153 [00:02<00:00, 52.61it/s, Epoch: 36, Batch: 138,Loss: -2.097,Avg.Loss: -1.647,LR: 3.57E-04]Training epoch 36:  90%|█████████ | 138/153 [00:02<00:00, 52.61it/s, Epoch: 36, Batch: 139,Loss: -2.720,Avg.Loss: -1.654,LR: 3.57E-04]Training epoch 36:  91%|█████████ | 139/153 [00:02<00:00, 52.61it/s, Epoch: 36, Batch: 140,Loss: -1.447,Avg.Loss: -1.653,LR: 3.57E-04]Training epoch 36:  92%|█████████▏| 140/153 [00:02<00:00, 52.61it/s, Epoch: 36, Batch: 141,Loss: -0.845,Avg.Loss: -1.647,LR: 3.57E-04]Training epoch 36:  92%|█████████▏| 141/153 [00:02<00:00, 52.61it/s, Epoch: 36, Batch: 142,Loss: -1.599,Avg.Loss: -1.647,LR: 3.57E-04]Training epoch 36:  93%|█████████▎| 142/153 [00:02<00:00, 52.61it/s, Epoch: 36, Batch: 143,Loss: -2.312,Avg.Loss: -1.652,LR: 3.57E-04]Training epoch 36:  93%|█████████▎| 143/153 [00:02<00:00, 52.61it/s, Epoch: 36, Batch: 144,Loss: -1.971,Avg.Loss: -1.654,LR: 3.57E-04]Training epoch 36:  94%|█████████▍| 144/153 [00:02<00:00, 52.73it/s, Epoch: 36, Batch: 144,Loss: -1.971,Avg.Loss: -1.654,LR: 3.57E-04]Training epoch 36:  94%|█████████▍| 144/153 [00:02<00:00, 52.73it/s, Epoch: 36, Batch: 145,Loss: -1.468,Avg.Loss: -1.652,LR: 3.57E-04]Training epoch 36:  95%|█████████▍| 145/153 [00:02<00:00, 52.73it/s, Epoch: 36, Batch: 146,Loss: -1.647,Avg.Loss: -1.652,LR: 3.57E-04]Training epoch 36:  95%|█████████▌| 146/153 [00:02<00:00, 52.73it/s, Epoch: 36, Batch: 147,Loss: -1.393,Avg.Loss: -1.651,LR: 3.57E-04]Training epoch 36:  96%|█████████▌| 147/153 [00:02<00:00, 52.73it/s, Epoch: 36, Batch: 148,Loss: -1.725,Avg.Loss: -1.651,LR: 3.57E-04]Training epoch 36:  97%|█████████▋| 148/153 [00:02<00:00, 52.73it/s, Epoch: 36, Batch: 149,Loss: -2.021,Avg.Loss: -1.654,LR: 3.57E-04]Training epoch 36:  97%|█████████▋| 149/153 [00:02<00:00, 52.73it/s, Epoch: 36, Batch: 150,Loss: -1.213,Avg.Loss: -1.651,LR: 3.57E-04]Training epoch 36:  98%|█████████▊| 150/153 [00:02<00:00, 52.94it/s, Epoch: 36, Batch: 150,Loss: -1.213,Avg.Loss: -1.651,LR: 3.57E-04]Training epoch 36:  98%|█████████▊| 150/153 [00:02<00:00, 52.94it/s, Epoch: 36, Batch: 151,Loss: -0.738,Avg.Loss: -1.645,LR: 3.57E-04]Training epoch 36:  99%|█████████▊| 151/153 [00:02<00:00, 52.94it/s, Epoch: 36, Batch: 152,Loss: -2.368,Avg.Loss: -1.649,LR: 3.56E-04]Training epoch 36:  99%|█████████▉| 152/153 [00:02<00:00, 52.94it/s, Epoch: 36, Batch: 153,Loss: -1.538,Avg.Loss: -1.649,LR: 3.56E-04]Training epoch 36: 100%|██████████| 153/153 [00:02<00:00, 52.59it/s, Epoch: 36, Batch: 153,Loss: -1.538,Avg.Loss: -1.649,LR: 3.56E-04]
Training epoch 37:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 37:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 37, Batch: 1,Loss: -1.246,Avg.Loss: -1.246,LR: 3.56E-04]Training epoch 37:   1%|          | 1/153 [00:00<00:05, 26.43it/s, Epoch: 37, Batch: 2,Loss: -1.626,Avg.Loss: -1.436,LR: 3.56E-04]Training epoch 37:   1%|▏         | 2/153 [00:00<00:04, 35.26it/s, Epoch: 37, Batch: 3,Loss: -2.306,Avg.Loss: -1.726,LR: 3.56E-04]Training epoch 37:   2%|▏         | 3/153 [00:00<00:03, 40.81it/s, Epoch: 37, Batch: 4,Loss: -1.586,Avg.Loss: -1.691,LR: 3.56E-04]Training epoch 37:   3%|▎         | 4/153 [00:00<00:03, 43.95it/s, Epoch: 37, Batch: 5,Loss: -2.033,Avg.Loss: -1.760,LR: 3.56E-04]Training epoch 37:   3%|▎         | 5/153 [00:00<00:03, 45.88it/s, Epoch: 37, Batch: 6,Loss: -1.724,Avg.Loss: -1.754,LR: 3.56E-04]Training epoch 37:   4%|▍         | 6/153 [00:00<00:02, 54.98it/s, Epoch: 37, Batch: 6,Loss: -1.724,Avg.Loss: -1.754,LR: 3.56E-04]Training epoch 37:   4%|▍         | 6/153 [00:00<00:02, 54.98it/s, Epoch: 37, Batch: 7,Loss: -1.739,Avg.Loss: -1.752,LR: 3.56E-04]Training epoch 37:   5%|▍         | 7/153 [00:00<00:02, 54.98it/s, Epoch: 37, Batch: 8,Loss: -2.081,Avg.Loss: -1.793,LR: 3.56E-04]Training epoch 37:   5%|▌         | 8/153 [00:00<00:02, 54.98it/s, Epoch: 37, Batch: 9,Loss: -1.770,Avg.Loss: -1.790,LR: 3.56E-04]Training epoch 37:   6%|▌         | 9/153 [00:00<00:02, 54.98it/s, Epoch: 37, Batch: 10,Loss: -0.888,Avg.Loss: -1.700,LR: 3.56E-04]Training epoch 37:   7%|▋         | 10/153 [00:00<00:02, 54.98it/s, Epoch: 37, Batch: 11,Loss: -1.496,Avg.Loss: -1.681,LR: 3.56E-04]Training epoch 37:   7%|▋         | 11/153 [00:00<00:02, 54.98it/s, Epoch: 37, Batch: 12,Loss: -1.982,Avg.Loss: -1.707,LR: 3.56E-04]Training epoch 37:   8%|▊         | 12/153 [00:00<00:02, 53.87it/s, Epoch: 37, Batch: 12,Loss: -1.982,Avg.Loss: -1.707,LR: 3.56E-04]Training epoch 37:   8%|▊         | 12/153 [00:00<00:02, 53.87it/s, Epoch: 37, Batch: 13,Loss: -0.582,Avg.Loss: -1.620,LR: 3.56E-04]Training epoch 37:   8%|▊         | 13/153 [00:00<00:02, 53.87it/s, Epoch: 37, Batch: 14,Loss: 1.781,Avg.Loss: -1.377,LR: 3.56E-04] Training epoch 37:   9%|▉         | 14/153 [00:00<00:02, 53.87it/s, Epoch: 37, Batch: 15,Loss: 1.726,Avg.Loss: -1.170,LR: 3.56E-04]Training epoch 37:  10%|▉         | 15/153 [00:00<00:02, 53.87it/s, Epoch: 37, Batch: 16,Loss: -0.955,Avg.Loss: -1.157,LR: 3.56E-04]Training epoch 37:  10%|█         | 16/153 [00:00<00:02, 53.87it/s, Epoch: 37, Batch: 17,Loss: -1.972,Avg.Loss: -1.205,LR: 3.56E-04]Training epoch 37:  11%|█         | 17/153 [00:00<00:02, 53.87it/s, Epoch: 37, Batch: 18,Loss: -0.620,Avg.Loss: -1.172,LR: 3.56E-04]Training epoch 37:  12%|█▏        | 18/153 [00:00<00:02, 53.51it/s, Epoch: 37, Batch: 18,Loss: -0.620,Avg.Loss: -1.172,LR: 3.56E-04]Training epoch 37:  12%|█▏        | 18/153 [00:00<00:02, 53.51it/s, Epoch: 37, Batch: 19,Loss: 1.107,Avg.Loss: -1.052,LR: 3.56E-04] Training epoch 37:  12%|█▏        | 19/153 [00:00<00:02, 53.51it/s, Epoch: 37, Batch: 20,Loss: 1.854,Avg.Loss: -0.907,LR: 3.56E-04]Training epoch 37:  13%|█▎        | 20/153 [00:00<00:02, 53.51it/s, Epoch: 37, Batch: 21,Loss: 0.411,Avg.Loss: -0.844,LR: 3.55E-04]Training epoch 37:  14%|█▎        | 21/153 [00:00<00:02, 53.51it/s, Epoch: 37, Batch: 22,Loss: -1.552,Avg.Loss: -0.876,LR: 3.55E-04]Training epoch 37:  14%|█▍        | 22/153 [00:00<00:02, 53.51it/s, Epoch: 37, Batch: 23,Loss: -1.453,Avg.Loss: -0.901,LR: 3.55E-04]Training epoch 37:  15%|█▌        | 23/153 [00:00<00:02, 53.51it/s, Epoch: 37, Batch: 24,Loss: -0.265,Avg.Loss: -0.875,LR: 3.55E-04]Training epoch 37:  16%|█▌        | 24/153 [00:00<00:02, 50.00it/s, Epoch: 37, Batch: 24,Loss: -0.265,Avg.Loss: -0.875,LR: 3.55E-04]Training epoch 37:  16%|█▌        | 24/153 [00:00<00:02, 50.00it/s, Epoch: 37, Batch: 25,Loss: 0.927,Avg.Loss: -0.803,LR: 3.55E-04] Training epoch 37:  16%|█▋        | 25/153 [00:00<00:02, 50.00it/s, Epoch: 37, Batch: 26,Loss: -0.910,Avg.Loss: -0.807,LR: 3.55E-04]Training epoch 37:  17%|█▋        | 26/153 [00:00<00:02, 50.00it/s, Epoch: 37, Batch: 27,Loss: -2.202,Avg.Loss: -0.859,LR: 3.55E-04]Training epoch 37:  18%|█▊        | 27/153 [00:00<00:02, 50.00it/s, Epoch: 37, Batch: 28,Loss: -0.790,Avg.Loss: -0.856,LR: 3.55E-04]Training epoch 37:  18%|█▊        | 28/153 [00:00<00:02, 50.00it/s, Epoch: 37, Batch: 29,Loss: 0.938,Avg.Loss: -0.794,LR: 3.55E-04] Training epoch 37:  19%|█▉        | 29/153 [00:00<00:02, 50.00it/s, Epoch: 37, Batch: 30,Loss: 0.081,Avg.Loss: -0.765,LR: 3.55E-04]Training epoch 37:  20%|█▉        | 30/153 [00:00<00:02, 50.46it/s, Epoch: 37, Batch: 30,Loss: 0.081,Avg.Loss: -0.765,LR: 3.55E-04]Training epoch 37:  20%|█▉        | 30/153 [00:00<00:02, 50.46it/s, Epoch: 37, Batch: 31,Loss: -1.098,Avg.Loss: -0.776,LR: 3.55E-04]Training epoch 37:  20%|██        | 31/153 [00:00<00:02, 50.46it/s, Epoch: 37, Batch: 32,Loss: -1.632,Avg.Loss: -0.803,LR: 3.55E-04]Training epoch 37:  21%|██        | 32/153 [00:00<00:02, 50.46it/s, Epoch: 37, Batch: 33,Loss: -1.208,Avg.Loss: -0.815,LR: 3.55E-04]Training epoch 37:  22%|██▏       | 33/153 [00:00<00:02, 50.46it/s, Epoch: 37, Batch: 34,Loss: -0.938,Avg.Loss: -0.819,LR: 3.55E-04]Training epoch 37:  22%|██▏       | 34/153 [00:00<00:02, 50.46it/s, Epoch: 37, Batch: 35,Loss: -1.534,Avg.Loss: -0.839,LR: 3.55E-04]Training epoch 37:  23%|██▎       | 35/153 [00:00<00:02, 50.46it/s, Epoch: 37, Batch: 36,Loss: -2.365,Avg.Loss: -0.881,LR: 3.55E-04]Training epoch 37:  24%|██▎       | 36/153 [00:00<00:02, 51.67it/s, Epoch: 37, Batch: 36,Loss: -2.365,Avg.Loss: -0.881,LR: 3.55E-04]Training epoch 37:  24%|██▎       | 36/153 [00:00<00:02, 51.67it/s, Epoch: 37, Batch: 37,Loss: -1.330,Avg.Loss: -0.894,LR: 3.55E-04]Training epoch 37:  24%|██▍       | 37/153 [00:00<00:02, 51.67it/s, Epoch: 37, Batch: 38,Loss: -0.659,Avg.Loss: -0.887,LR: 3.55E-04]Training epoch 37:  25%|██▍       | 38/153 [00:00<00:02, 51.67it/s, Epoch: 37, Batch: 39,Loss: -1.051,Avg.Loss: -0.892,LR: 3.55E-04]Training epoch 37:  25%|██▌       | 39/153 [00:00<00:02, 51.67it/s, Epoch: 37, Batch: 40,Loss: -1.865,Avg.Loss: -0.916,LR: 3.55E-04]Training epoch 37:  26%|██▌       | 40/153 [00:00<00:02, 51.67it/s, Epoch: 37, Batch: 41,Loss: -2.274,Avg.Loss: -0.949,LR: 3.55E-04]Training epoch 37:  27%|██▋       | 41/153 [00:00<00:02, 51.67it/s, Epoch: 37, Batch: 42,Loss: -1.393,Avg.Loss: -0.960,LR: 3.54E-04]Training epoch 37:  27%|██▋       | 42/153 [00:00<00:02, 52.40it/s, Epoch: 37, Batch: 42,Loss: -1.393,Avg.Loss: -0.960,LR: 3.54E-04]Training epoch 37:  27%|██▋       | 42/153 [00:00<00:02, 52.40it/s, Epoch: 37, Batch: 43,Loss: -1.617,Avg.Loss: -0.975,LR: 3.54E-04]Training epoch 37:  28%|██▊       | 43/153 [00:00<00:02, 52.40it/s, Epoch: 37, Batch: 44,Loss: -2.258,Avg.Loss: -1.004,LR: 3.54E-04]Training epoch 37:  29%|██▉       | 44/153 [00:00<00:02, 52.40it/s, Epoch: 37, Batch: 45,Loss: -1.638,Avg.Loss: -1.018,LR: 3.54E-04]Training epoch 37:  29%|██▉       | 45/153 [00:00<00:02, 52.40it/s, Epoch: 37, Batch: 46,Loss: -1.241,Avg.Loss: -1.023,LR: 3.54E-04]Training epoch 37:  30%|███       | 46/153 [00:00<00:02, 52.40it/s, Epoch: 37, Batch: 47,Loss: -1.761,Avg.Loss: -1.039,LR: 3.54E-04]Training epoch 37:  31%|███       | 47/153 [00:00<00:02, 52.40it/s, Epoch: 37, Batch: 48,Loss: -2.192,Avg.Loss: -1.063,LR: 3.54E-04]Training epoch 37:  31%|███▏      | 48/153 [00:00<00:01, 52.67it/s, Epoch: 37, Batch: 48,Loss: -2.192,Avg.Loss: -1.063,LR: 3.54E-04]Training epoch 37:  31%|███▏      | 48/153 [00:00<00:01, 52.67it/s, Epoch: 37, Batch: 49,Loss: -2.230,Avg.Loss: -1.087,LR: 3.54E-04]Training epoch 37:  32%|███▏      | 49/153 [00:00<00:01, 52.67it/s, Epoch: 37, Batch: 50,Loss: -1.719,Avg.Loss: -1.099,LR: 3.54E-04]Training epoch 37:  33%|███▎      | 50/153 [00:00<00:01, 52.67it/s, Epoch: 37, Batch: 51,Loss: -1.597,Avg.Loss: -1.109,LR: 3.54E-04]Training epoch 37:  33%|███▎      | 51/153 [00:00<00:01, 52.67it/s, Epoch: 37, Batch: 52,Loss: -2.265,Avg.Loss: -1.131,LR: 3.54E-04]Training epoch 37:  34%|███▍      | 52/153 [00:01<00:01, 52.67it/s, Epoch: 37, Batch: 53,Loss: -2.391,Avg.Loss: -1.155,LR: 3.54E-04]Training epoch 37:  35%|███▍      | 53/153 [00:01<00:01, 52.67it/s, Epoch: 37, Batch: 54,Loss: -1.445,Avg.Loss: -1.160,LR: 3.54E-04]Training epoch 37:  35%|███▌      | 54/153 [00:01<00:01, 52.80it/s, Epoch: 37, Batch: 54,Loss: -1.445,Avg.Loss: -1.160,LR: 3.54E-04]Training epoch 37:  35%|███▌      | 54/153 [00:01<00:01, 52.80it/s, Epoch: 37, Batch: 55,Loss: -2.142,Avg.Loss: -1.178,LR: 3.54E-04]Training epoch 37:  36%|███▌      | 55/153 [00:01<00:01, 52.80it/s, Epoch: 37, Batch: 56,Loss: -1.840,Avg.Loss: -1.190,LR: 3.54E-04]Training epoch 37:  37%|███▋      | 56/153 [00:01<00:01, 52.80it/s, Epoch: 37, Batch: 57,Loss: -2.383,Avg.Loss: -1.211,LR: 3.54E-04]Training epoch 37:  37%|███▋      | 57/153 [00:01<00:01, 52.80it/s, Epoch: 37, Batch: 58,Loss: -2.429,Avg.Loss: -1.232,LR: 3.54E-04]Training epoch 37:  38%|███▊      | 58/153 [00:01<00:01, 52.80it/s, Epoch: 37, Batch: 59,Loss: -2.662,Avg.Loss: -1.256,LR: 3.54E-04]Training epoch 37:  39%|███▊      | 59/153 [00:01<00:01, 52.80it/s, Epoch: 37, Batch: 60,Loss: -2.088,Avg.Loss: -1.270,LR: 3.54E-04]Training epoch 37:  39%|███▉      | 60/153 [00:01<00:01, 53.02it/s, Epoch: 37, Batch: 60,Loss: -2.088,Avg.Loss: -1.270,LR: 3.54E-04]Training epoch 37:  39%|███▉      | 60/153 [00:01<00:01, 53.02it/s, Epoch: 37, Batch: 61,Loss: -2.528,Avg.Loss: -1.291,LR: 3.54E-04]Training epoch 37:  40%|███▉      | 61/153 [00:01<00:01, 53.02it/s, Epoch: 37, Batch: 62,Loss: -1.599,Avg.Loss: -1.296,LR: 3.54E-04]Training epoch 37:  41%|████      | 62/153 [00:01<00:01, 53.02it/s, Epoch: 37, Batch: 63,Loss: -1.059,Avg.Loss: -1.292,LR: 3.54E-04]Training epoch 37:  41%|████      | 63/153 [00:01<00:01, 53.02it/s, Epoch: 37, Batch: 64,Loss: -1.195,Avg.Loss: -1.290,LR: 3.53E-04]Training epoch 37:  42%|████▏     | 64/153 [00:01<00:01, 53.02it/s, Epoch: 37, Batch: 65,Loss: -2.224,Avg.Loss: -1.305,LR: 3.53E-04]Training epoch 37:  42%|████▏     | 65/153 [00:01<00:01, 53.02it/s, Epoch: 37, Batch: 66,Loss: -1.799,Avg.Loss: -1.312,LR: 3.53E-04]Training epoch 37:  43%|████▎     | 66/153 [00:01<00:01, 53.01it/s, Epoch: 37, Batch: 66,Loss: -1.799,Avg.Loss: -1.312,LR: 3.53E-04]Training epoch 37:  43%|████▎     | 66/153 [00:01<00:01, 53.01it/s, Epoch: 37, Batch: 67,Loss: -0.086,Avg.Loss: -1.294,LR: 3.53E-04]Training epoch 37:  44%|████▍     | 67/153 [00:01<00:01, 53.01it/s, Epoch: 37, Batch: 68,Loss: -0.635,Avg.Loss: -1.284,LR: 3.53E-04]Training epoch 37:  44%|████▍     | 68/153 [00:01<00:01, 53.01it/s, Epoch: 37, Batch: 69,Loss: -1.469,Avg.Loss: -1.287,LR: 3.53E-04]Training epoch 37:  45%|████▌     | 69/153 [00:01<00:01, 53.01it/s, Epoch: 37, Batch: 70,Loss: -2.353,Avg.Loss: -1.302,LR: 3.53E-04]Training epoch 37:  46%|████▌     | 70/153 [00:01<00:01, 53.01it/s, Epoch: 37, Batch: 71,Loss: -1.590,Avg.Loss: -1.306,LR: 3.53E-04]Training epoch 37:  46%|████▋     | 71/153 [00:01<00:01, 53.01it/s, Epoch: 37, Batch: 72,Loss: -1.938,Avg.Loss: -1.315,LR: 3.53E-04]Training epoch 37:  47%|████▋     | 72/153 [00:01<00:01, 52.92it/s, Epoch: 37, Batch: 72,Loss: -1.938,Avg.Loss: -1.315,LR: 3.53E-04]Training epoch 37:  47%|████▋     | 72/153 [00:01<00:01, 52.92it/s, Epoch: 37, Batch: 73,Loss: -2.315,Avg.Loss: -1.329,LR: 3.53E-04]Training epoch 37:  48%|████▊     | 73/153 [00:01<00:01, 52.92it/s, Epoch: 37, Batch: 74,Loss: -2.280,Avg.Loss: -1.341,LR: 3.53E-04]Training epoch 37:  48%|████▊     | 74/153 [00:01<00:01, 52.92it/s, Epoch: 37, Batch: 75,Loss: -2.417,Avg.Loss: -1.356,LR: 3.53E-04]Training epoch 37:  49%|████▉     | 75/153 [00:01<00:01, 52.92it/s, Epoch: 37, Batch: 76,Loss: -2.417,Avg.Loss: -1.370,LR: 3.53E-04]Training epoch 37:  50%|████▉     | 76/153 [00:01<00:01, 52.92it/s, Epoch: 37, Batch: 77,Loss: -2.317,Avg.Loss: -1.382,LR: 3.53E-04]Training epoch 37:  50%|█████     | 77/153 [00:01<00:01, 52.92it/s, Epoch: 37, Batch: 78,Loss: -2.054,Avg.Loss: -1.391,LR: 3.53E-04]Training epoch 37:  51%|█████     | 78/153 [00:01<00:01, 52.89it/s, Epoch: 37, Batch: 78,Loss: -2.054,Avg.Loss: -1.391,LR: 3.53E-04]Training epoch 37:  51%|█████     | 78/153 [00:01<00:01, 52.89it/s, Epoch: 37, Batch: 79,Loss: -2.147,Avg.Loss: -1.400,LR: 3.53E-04]Training epoch 37:  52%|█████▏    | 79/153 [00:01<00:01, 52.89it/s, Epoch: 37, Batch: 80,Loss: -2.237,Avg.Loss: -1.411,LR: 3.53E-04]Training epoch 37:  52%|█████▏    | 80/153 [00:01<00:01, 52.89it/s, Epoch: 37, Batch: 81,Loss: -1.308,Avg.Loss: -1.409,LR: 3.53E-04]Training epoch 37:  53%|█████▎    | 81/153 [00:01<00:01, 52.89it/s, Epoch: 37, Batch: 82,Loss: -0.645,Avg.Loss: -1.400,LR: 3.53E-04]Training epoch 37:  54%|█████▎    | 82/153 [00:01<00:01, 52.89it/s, Epoch: 37, Batch: 83,Loss: -2.092,Avg.Loss: -1.408,LR: 3.53E-04]Training epoch 37:  54%|█████▍    | 83/153 [00:01<00:01, 52.89it/s, Epoch: 37, Batch: 84,Loss: -2.078,Avg.Loss: -1.416,LR: 3.53E-04]Training epoch 37:  55%|█████▍    | 84/153 [00:01<00:01, 53.03it/s, Epoch: 37, Batch: 84,Loss: -2.078,Avg.Loss: -1.416,LR: 3.53E-04]Training epoch 37:  55%|█████▍    | 84/153 [00:01<00:01, 53.03it/s, Epoch: 37, Batch: 85,Loss: -1.863,Avg.Loss: -1.422,LR: 3.52E-04]Training epoch 37:  56%|█████▌    | 85/153 [00:01<00:01, 53.03it/s, Epoch: 37, Batch: 86,Loss: -1.296,Avg.Loss: -1.420,LR: 3.52E-04]Training epoch 37:  56%|█████▌    | 86/153 [00:01<00:01, 53.03it/s, Epoch: 37, Batch: 87,Loss: -1.858,Avg.Loss: -1.425,LR: 3.52E-04]Training epoch 37:  57%|█████▋    | 87/153 [00:01<00:01, 53.03it/s, Epoch: 37, Batch: 88,Loss: -2.099,Avg.Loss: -1.433,LR: 3.52E-04]Training epoch 37:  58%|█████▊    | 88/153 [00:01<00:01, 53.03it/s, Epoch: 37, Batch: 89,Loss: -2.132,Avg.Loss: -1.441,LR: 3.52E-04]Training epoch 37:  58%|█████▊    | 89/153 [00:01<00:01, 53.03it/s, Epoch: 37, Batch: 90,Loss: -1.757,Avg.Loss: -1.444,LR: 3.52E-04]Training epoch 37:  59%|█████▉    | 90/153 [00:01<00:01, 53.10it/s, Epoch: 37, Batch: 90,Loss: -1.757,Avg.Loss: -1.444,LR: 3.52E-04]Training epoch 37:  59%|█████▉    | 90/153 [00:01<00:01, 53.10it/s, Epoch: 37, Batch: 91,Loss: -1.331,Avg.Loss: -1.443,LR: 3.52E-04]Training epoch 37:  59%|█████▉    | 91/153 [00:01<00:01, 53.10it/s, Epoch: 37, Batch: 92,Loss: -1.736,Avg.Loss: -1.446,LR: 3.52E-04]Training epoch 37:  60%|██████    | 92/153 [00:01<00:01, 53.10it/s, Epoch: 37, Batch: 93,Loss: -1.476,Avg.Loss: -1.447,LR: 3.52E-04]Training epoch 37:  61%|██████    | 93/153 [00:01<00:01, 53.10it/s, Epoch: 37, Batch: 94,Loss: -2.395,Avg.Loss: -1.457,LR: 3.52E-04]Training epoch 37:  61%|██████▏   | 94/153 [00:01<00:01, 53.10it/s, Epoch: 37, Batch: 95,Loss: -2.011,Avg.Loss: -1.463,LR: 3.52E-04]Training epoch 37:  62%|██████▏   | 95/153 [00:01<00:01, 53.10it/s, Epoch: 37, Batch: 96,Loss: -1.796,Avg.Loss: -1.466,LR: 3.52E-04]Training epoch 37:  63%|██████▎   | 96/153 [00:01<00:01, 53.11it/s, Epoch: 37, Batch: 96,Loss: -1.796,Avg.Loss: -1.466,LR: 3.52E-04]Training epoch 37:  63%|██████▎   | 96/153 [00:01<00:01, 53.11it/s, Epoch: 37, Batch: 97,Loss: -1.917,Avg.Loss: -1.471,LR: 3.52E-04]Training epoch 37:  63%|██████▎   | 97/153 [00:01<00:01, 53.11it/s, Epoch: 37, Batch: 98,Loss: -2.006,Avg.Loss: -1.476,LR: 3.52E-04]Training epoch 37:  64%|██████▍   | 98/153 [00:01<00:01, 53.11it/s, Epoch: 37, Batch: 99,Loss: -1.861,Avg.Loss: -1.480,LR: 3.52E-04]Training epoch 37:  65%|██████▍   | 99/153 [00:01<00:01, 53.11it/s, Epoch: 37, Batch: 100,Loss: -2.202,Avg.Loss: -1.487,LR: 3.52E-04]Training epoch 37:  65%|██████▌   | 100/153 [00:01<00:00, 53.11it/s, Epoch: 37, Batch: 101,Loss: -1.678,Avg.Loss: -1.489,LR: 3.52E-04]Training epoch 37:  66%|██████▌   | 101/153 [00:01<00:00, 53.11it/s, Epoch: 37, Batch: 102,Loss: -2.489,Avg.Loss: -1.499,LR: 3.52E-04]Training epoch 37:  67%|██████▋   | 102/153 [00:01<00:00, 53.21it/s, Epoch: 37, Batch: 102,Loss: -2.489,Avg.Loss: -1.499,LR: 3.52E-04]Training epoch 37:  67%|██████▋   | 102/153 [00:01<00:00, 53.21it/s, Epoch: 37, Batch: 103,Loss: -1.998,Avg.Loss: -1.504,LR: 3.52E-04]Training epoch 37:  67%|██████▋   | 103/153 [00:01<00:00, 53.21it/s, Epoch: 37, Batch: 104,Loss: -2.229,Avg.Loss: -1.511,LR: 3.52E-04]Training epoch 37:  68%|██████▊   | 104/153 [00:01<00:00, 53.21it/s, Epoch: 37, Batch: 105,Loss: -1.921,Avg.Loss: -1.515,LR: 3.52E-04]Training epoch 37:  69%|██████▊   | 105/153 [00:02<00:00, 53.21it/s, Epoch: 37, Batch: 106,Loss: -2.459,Avg.Loss: -1.524,LR: 3.51E-04]Training epoch 37:  69%|██████▉   | 106/153 [00:02<00:00, 53.21it/s, Epoch: 37, Batch: 107,Loss: -1.806,Avg.Loss: -1.526,LR: 3.51E-04]Training epoch 37:  70%|██████▉   | 107/153 [00:02<00:00, 53.21it/s, Epoch: 37, Batch: 108,Loss: -2.250,Avg.Loss: -1.533,LR: 3.51E-04]Training epoch 37:  71%|███████   | 108/153 [00:02<00:00, 53.18it/s, Epoch: 37, Batch: 108,Loss: -2.250,Avg.Loss: -1.533,LR: 3.51E-04]Training epoch 37:  71%|███████   | 108/153 [00:02<00:00, 53.18it/s, Epoch: 37, Batch: 109,Loss: -2.056,Avg.Loss: -1.538,LR: 3.51E-04]Training epoch 37:  71%|███████   | 109/153 [00:02<00:00, 53.18it/s, Epoch: 37, Batch: 110,Loss: -2.332,Avg.Loss: -1.545,LR: 3.51E-04]Training epoch 37:  72%|███████▏  | 110/153 [00:02<00:00, 53.18it/s, Epoch: 37, Batch: 111,Loss: -2.433,Avg.Loss: -1.553,LR: 3.51E-04]Training epoch 37:  73%|███████▎  | 111/153 [00:02<00:00, 53.18it/s, Epoch: 37, Batch: 112,Loss: -2.259,Avg.Loss: -1.559,LR: 3.51E-04]Training epoch 37:  73%|███████▎  | 112/153 [00:02<00:00, 53.18it/s, Epoch: 37, Batch: 113,Loss: -1.790,Avg.Loss: -1.561,LR: 3.51E-04]Training epoch 37:  74%|███████▍  | 113/153 [00:02<00:00, 53.18it/s, Epoch: 37, Batch: 114,Loss: -1.640,Avg.Loss: -1.562,LR: 3.51E-04]Training epoch 37:  75%|███████▍  | 114/153 [00:02<00:00, 53.00it/s, Epoch: 37, Batch: 114,Loss: -1.640,Avg.Loss: -1.562,LR: 3.51E-04]Training epoch 37:  75%|███████▍  | 114/153 [00:02<00:00, 53.00it/s, Epoch: 37, Batch: 115,Loss: -1.844,Avg.Loss: -1.564,LR: 3.51E-04]Training epoch 37:  75%|███████▌  | 115/153 [00:02<00:00, 53.00it/s, Epoch: 37, Batch: 116,Loss: -1.440,Avg.Loss: -1.563,LR: 3.51E-04]Training epoch 37:  76%|███████▌  | 116/153 [00:02<00:00, 53.00it/s, Epoch: 37, Batch: 117,Loss: -1.234,Avg.Loss: -1.561,LR: 3.51E-04]Training epoch 37:  76%|███████▋  | 117/153 [00:02<00:00, 53.00it/s, Epoch: 37, Batch: 118,Loss: -1.550,Avg.Loss: -1.560,LR: 3.51E-04]Training epoch 37:  77%|███████▋  | 118/153 [00:02<00:00, 53.00it/s, Epoch: 37, Batch: 119,Loss: -2.031,Avg.Loss: -1.564,LR: 3.51E-04]Training epoch 37:  78%|███████▊  | 119/153 [00:02<00:00, 53.00it/s, Epoch: 37, Batch: 120,Loss: -2.047,Avg.Loss: -1.568,LR: 3.51E-04]Training epoch 37:  78%|███████▊  | 120/153 [00:02<00:00, 52.18it/s, Epoch: 37, Batch: 120,Loss: -2.047,Avg.Loss: -1.568,LR: 3.51E-04]Training epoch 37:  78%|███████▊  | 120/153 [00:02<00:00, 52.18it/s, Epoch: 37, Batch: 121,Loss: -2.091,Avg.Loss: -1.573,LR: 3.51E-04]Training epoch 37:  79%|███████▉  | 121/153 [00:02<00:00, 52.18it/s, Epoch: 37, Batch: 122,Loss: -1.997,Avg.Loss: -1.576,LR: 3.51E-04]Training epoch 37:  80%|███████▉  | 122/153 [00:02<00:00, 52.18it/s, Epoch: 37, Batch: 123,Loss: -1.695,Avg.Loss: -1.577,LR: 3.51E-04]Training epoch 37:  80%|████████  | 123/153 [00:02<00:00, 52.18it/s, Epoch: 37, Batch: 124,Loss: -2.340,Avg.Loss: -1.583,LR: 3.51E-04]Training epoch 37:  81%|████████  | 124/153 [00:02<00:00, 52.18it/s, Epoch: 37, Batch: 125,Loss: -2.321,Avg.Loss: -1.589,LR: 3.51E-04]Training epoch 37:  82%|████████▏ | 125/153 [00:02<00:00, 52.18it/s, Epoch: 37, Batch: 126,Loss: -1.455,Avg.Loss: -1.588,LR: 3.51E-04]Training epoch 37:  82%|████████▏ | 126/153 [00:02<00:00, 52.44it/s, Epoch: 37, Batch: 126,Loss: -1.455,Avg.Loss: -1.588,LR: 3.51E-04]Training epoch 37:  82%|████████▏ | 126/153 [00:02<00:00, 52.44it/s, Epoch: 37, Batch: 127,Loss: -2.438,Avg.Loss: -1.595,LR: 3.51E-04]Training epoch 37:  83%|████████▎ | 127/153 [00:02<00:00, 52.44it/s, Epoch: 37, Batch: 128,Loss: -2.289,Avg.Loss: -1.600,LR: 3.50E-04]Training epoch 37:  84%|████████▎ | 128/153 [00:02<00:00, 52.44it/s, Epoch: 37, Batch: 129,Loss: -1.745,Avg.Loss: -1.601,LR: 3.50E-04]Training epoch 37:  84%|████████▍ | 129/153 [00:02<00:00, 52.44it/s, Epoch: 37, Batch: 130,Loss: -1.868,Avg.Loss: -1.603,LR: 3.50E-04]Training epoch 37:  85%|████████▍ | 130/153 [00:02<00:00, 52.44it/s, Epoch: 37, Batch: 131,Loss: -2.254,Avg.Loss: -1.608,LR: 3.50E-04]Training epoch 37:  86%|████████▌ | 131/153 [00:02<00:00, 52.44it/s, Epoch: 37, Batch: 132,Loss: -1.896,Avg.Loss: -1.611,LR: 3.50E-04]Training epoch 37:  86%|████████▋ | 132/153 [00:02<00:00, 52.52it/s, Epoch: 37, Batch: 132,Loss: -1.896,Avg.Loss: -1.611,LR: 3.50E-04]Training epoch 37:  86%|████████▋ | 132/153 [00:02<00:00, 52.52it/s, Epoch: 37, Batch: 133,Loss: -2.064,Avg.Loss: -1.614,LR: 3.50E-04]Training epoch 37:  87%|████████▋ | 133/153 [00:02<00:00, 52.52it/s, Epoch: 37, Batch: 134,Loss: -1.658,Avg.Loss: -1.614,LR: 3.50E-04]Training epoch 37:  88%|████████▊ | 134/153 [00:02<00:00, 52.52it/s, Epoch: 37, Batch: 135,Loss: -2.136,Avg.Loss: -1.618,LR: 3.50E-04]Training epoch 37:  88%|████████▊ | 135/153 [00:02<00:00, 52.52it/s, Epoch: 37, Batch: 136,Loss: -2.565,Avg.Loss: -1.625,LR: 3.50E-04]Training epoch 37:  89%|████████▉ | 136/153 [00:02<00:00, 52.52it/s, Epoch: 37, Batch: 137,Loss: -2.080,Avg.Loss: -1.628,LR: 3.50E-04]Training epoch 37:  90%|████████▉ | 137/153 [00:02<00:00, 52.52it/s, Epoch: 37, Batch: 138,Loss: -2.067,Avg.Loss: -1.632,LR: 3.50E-04]Training epoch 37:  90%|█████████ | 138/153 [00:02<00:00, 52.69it/s, Epoch: 37, Batch: 138,Loss: -2.067,Avg.Loss: -1.632,LR: 3.50E-04]Training epoch 37:  90%|█████████ | 138/153 [00:02<00:00, 52.69it/s, Epoch: 37, Batch: 139,Loss: -2.598,Avg.Loss: -1.639,LR: 3.50E-04]Training epoch 37:  91%|█████████ | 139/153 [00:02<00:00, 52.69it/s, Epoch: 37, Batch: 140,Loss: -2.377,Avg.Loss: -1.644,LR: 3.50E-04]Training epoch 37:  92%|█████████▏| 140/153 [00:02<00:00, 52.69it/s, Epoch: 37, Batch: 141,Loss: -2.290,Avg.Loss: -1.648,LR: 3.50E-04]Training epoch 37:  92%|█████████▏| 141/153 [00:02<00:00, 52.69it/s, Epoch: 37, Batch: 142,Loss: -2.451,Avg.Loss: -1.654,LR: 3.50E-04]Training epoch 37:  93%|█████████▎| 142/153 [00:02<00:00, 52.69it/s, Epoch: 37, Batch: 143,Loss: -2.574,Avg.Loss: -1.661,LR: 3.50E-04]Training epoch 37:  93%|█████████▎| 143/153 [00:02<00:00, 52.69it/s, Epoch: 37, Batch: 144,Loss: -2.423,Avg.Loss: -1.666,LR: 3.50E-04]Training epoch 37:  94%|█████████▍| 144/153 [00:02<00:00, 52.88it/s, Epoch: 37, Batch: 144,Loss: -2.423,Avg.Loss: -1.666,LR: 3.50E-04]Training epoch 37:  94%|█████████▍| 144/153 [00:02<00:00, 52.88it/s, Epoch: 37, Batch: 145,Loss: -2.215,Avg.Loss: -1.670,LR: 3.50E-04]Training epoch 37:  95%|█████████▍| 145/153 [00:02<00:00, 52.88it/s, Epoch: 37, Batch: 146,Loss: -1.973,Avg.Loss: -1.672,LR: 3.50E-04]Training epoch 37:  95%|█████████▌| 146/153 [00:02<00:00, 52.88it/s, Epoch: 37, Batch: 147,Loss: -2.584,Avg.Loss: -1.678,LR: 3.50E-04]Training epoch 37:  96%|█████████▌| 147/153 [00:02<00:00, 52.88it/s, Epoch: 37, Batch: 148,Loss: -2.519,Avg.Loss: -1.684,LR: 3.50E-04]Training epoch 37:  97%|█████████▋| 148/153 [00:02<00:00, 52.88it/s, Epoch: 37, Batch: 149,Loss: -2.485,Avg.Loss: -1.689,LR: 3.49E-04]Training epoch 37:  97%|█████████▋| 149/153 [00:02<00:00, 52.88it/s, Epoch: 37, Batch: 150,Loss: -2.447,Avg.Loss: -1.694,LR: 3.49E-04]Training epoch 37:  98%|█████████▊| 150/153 [00:02<00:00, 53.40it/s, Epoch: 37, Batch: 150,Loss: -2.447,Avg.Loss: -1.694,LR: 3.49E-04]Training epoch 37:  98%|█████████▊| 150/153 [00:02<00:00, 53.40it/s, Epoch: 37, Batch: 151,Loss: -2.405,Avg.Loss: -1.699,LR: 3.49E-04]Training epoch 37:  99%|█████████▊| 151/153 [00:02<00:00, 53.40it/s, Epoch: 37, Batch: 152,Loss: -2.786,Avg.Loss: -1.706,LR: 3.49E-04]Training epoch 37:  99%|█████████▉| 152/153 [00:02<00:00, 53.40it/s, Epoch: 37, Batch: 153,Loss: -2.612,Avg.Loss: -1.712,LR: 3.49E-04]Training epoch 37: 100%|██████████| 153/153 [00:02<00:00, 52.71it/s, Epoch: 37, Batch: 153,Loss: -2.612,Avg.Loss: -1.712,LR: 3.49E-04]
Training epoch 38:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 38:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 38, Batch: 1,Loss: -2.054,Avg.Loss: -2.054,LR: 3.49E-04]Training epoch 38:   1%|          | 1/153 [00:00<00:05, 27.96it/s, Epoch: 38, Batch: 2,Loss: -2.359,Avg.Loss: -2.206,LR: 3.49E-04]Training epoch 38:   1%|▏         | 2/153 [00:00<00:04, 36.37it/s, Epoch: 38, Batch: 3,Loss: -1.707,Avg.Loss: -2.040,LR: 3.49E-04]Training epoch 38:   2%|▏         | 3/153 [00:00<00:03, 41.12it/s, Epoch: 38, Batch: 4,Loss: -2.428,Avg.Loss: -2.137,LR: 3.49E-04]Training epoch 38:   3%|▎         | 4/153 [00:00<00:03, 44.14it/s, Epoch: 38, Batch: 5,Loss: -2.731,Avg.Loss: -2.256,LR: 3.49E-04]Training epoch 38:   3%|▎         | 5/153 [00:00<00:03, 45.61it/s, Epoch: 38, Batch: 6,Loss: -2.562,Avg.Loss: -2.307,LR: 3.49E-04]Training epoch 38:   4%|▍         | 6/153 [00:00<00:02, 54.64it/s, Epoch: 38, Batch: 6,Loss: -2.562,Avg.Loss: -2.307,LR: 3.49E-04]Training epoch 38:   4%|▍         | 6/153 [00:00<00:02, 54.64it/s, Epoch: 38, Batch: 7,Loss: -2.443,Avg.Loss: -2.326,LR: 3.49E-04]Training epoch 38:   5%|▍         | 7/153 [00:00<00:02, 54.64it/s, Epoch: 38, Batch: 8,Loss: -2.235,Avg.Loss: -2.315,LR: 3.49E-04]Training epoch 38:   5%|▌         | 8/153 [00:00<00:02, 54.64it/s, Epoch: 38, Batch: 9,Loss: -2.565,Avg.Loss: -2.342,LR: 3.49E-04]Training epoch 38:   6%|▌         | 9/153 [00:00<00:02, 54.64it/s, Epoch: 38, Batch: 10,Loss: -1.469,Avg.Loss: -2.255,LR: 3.49E-04]Training epoch 38:   7%|▋         | 10/153 [00:00<00:02, 54.64it/s, Epoch: 38, Batch: 11,Loss: -2.146,Avg.Loss: -2.245,LR: 3.49E-04]Training epoch 38:   7%|▋         | 11/153 [00:00<00:02, 54.64it/s, Epoch: 38, Batch: 12,Loss: -2.427,Avg.Loss: -2.260,LR: 3.49E-04]Training epoch 38:   8%|▊         | 12/153 [00:00<00:02, 53.39it/s, Epoch: 38, Batch: 12,Loss: -2.427,Avg.Loss: -2.260,LR: 3.49E-04]Training epoch 38:   8%|▊         | 12/153 [00:00<00:02, 53.39it/s, Epoch: 38, Batch: 13,Loss: -2.319,Avg.Loss: -2.265,LR: 3.49E-04]Training epoch 38:   8%|▊         | 13/153 [00:00<00:02, 53.39it/s, Epoch: 38, Batch: 14,Loss: -2.499,Avg.Loss: -2.282,LR: 3.49E-04]Training epoch 38:   9%|▉         | 14/153 [00:00<00:02, 53.39it/s, Epoch: 38, Batch: 15,Loss: -2.066,Avg.Loss: -2.267,LR: 3.49E-04]Training epoch 38:  10%|▉         | 15/153 [00:00<00:02, 53.39it/s, Epoch: 38, Batch: 16,Loss: -2.585,Avg.Loss: -2.287,LR: 3.49E-04]Training epoch 38:  10%|█         | 16/153 [00:00<00:02, 53.39it/s, Epoch: 38, Batch: 17,Loss: -2.179,Avg.Loss: -2.281,LR: 3.48E-04]Training epoch 38:  11%|█         | 17/153 [00:00<00:02, 53.39it/s, Epoch: 38, Batch: 18,Loss: -2.617,Avg.Loss: -2.299,LR: 3.48E-04]Training epoch 38:  12%|█▏        | 18/153 [00:00<00:02, 53.20it/s, Epoch: 38, Batch: 18,Loss: -2.617,Avg.Loss: -2.299,LR: 3.48E-04]Training epoch 38:  12%|█▏        | 18/153 [00:00<00:02, 53.20it/s, Epoch: 38, Batch: 19,Loss: -2.590,Avg.Loss: -2.315,LR: 3.48E-04]Training epoch 38:  12%|█▏        | 19/153 [00:00<00:02, 53.20it/s, Epoch: 38, Batch: 20,Loss: -1.893,Avg.Loss: -2.294,LR: 3.48E-04]Training epoch 38:  13%|█▎        | 20/153 [00:00<00:02, 53.20it/s, Epoch: 38, Batch: 21,Loss: -1.965,Avg.Loss: -2.278,LR: 3.48E-04]Training epoch 38:  14%|█▎        | 21/153 [00:00<00:02, 53.20it/s, Epoch: 38, Batch: 22,Loss: -1.336,Avg.Loss: -2.235,LR: 3.48E-04]Training epoch 38:  14%|█▍        | 22/153 [00:00<00:02, 53.20it/s, Epoch: 38, Batch: 23,Loss: -1.857,Avg.Loss: -2.219,LR: 3.48E-04]Training epoch 38:  15%|█▌        | 23/153 [00:00<00:02, 53.20it/s, Epoch: 38, Batch: 24,Loss: -2.345,Avg.Loss: -2.224,LR: 3.48E-04]Training epoch 38:  16%|█▌        | 24/153 [00:00<00:02, 52.52it/s, Epoch: 38, Batch: 24,Loss: -2.345,Avg.Loss: -2.224,LR: 3.48E-04]Training epoch 38:  16%|█▌        | 24/153 [00:00<00:02, 52.52it/s, Epoch: 38, Batch: 25,Loss: -2.150,Avg.Loss: -2.221,LR: 3.48E-04]Training epoch 38:  16%|█▋        | 25/153 [00:00<00:02, 52.52it/s, Epoch: 38, Batch: 26,Loss: -1.804,Avg.Loss: -2.205,LR: 3.48E-04]Training epoch 38:  17%|█▋        | 26/153 [00:00<00:02, 52.52it/s, Epoch: 38, Batch: 27,Loss: -2.192,Avg.Loss: -2.205,LR: 3.48E-04]Training epoch 38:  18%|█▊        | 27/153 [00:00<00:02, 52.52it/s, Epoch: 38, Batch: 28,Loss: -1.853,Avg.Loss: -2.192,LR: 3.48E-04]Training epoch 38:  18%|█▊        | 28/153 [00:00<00:02, 52.52it/s, Epoch: 38, Batch: 29,Loss: -2.330,Avg.Loss: -2.197,LR: 3.48E-04]Training epoch 38:  19%|█▉        | 29/153 [00:00<00:02, 52.52it/s, Epoch: 38, Batch: 30,Loss: -2.729,Avg.Loss: -2.214,LR: 3.48E-04]Training epoch 38:  20%|█▉        | 30/153 [00:00<00:02, 52.19it/s, Epoch: 38, Batch: 30,Loss: -2.729,Avg.Loss: -2.214,LR: 3.48E-04]Training epoch 38:  20%|█▉        | 30/153 [00:00<00:02, 52.19it/s, Epoch: 38, Batch: 31,Loss: -2.056,Avg.Loss: -2.209,LR: 3.48E-04]Training epoch 38:  20%|██        | 31/153 [00:00<00:02, 52.19it/s, Epoch: 38, Batch: 32,Loss: -1.439,Avg.Loss: -2.185,LR: 3.48E-04]Training epoch 38:  21%|██        | 32/153 [00:00<00:02, 52.19it/s, Epoch: 38, Batch: 33,Loss: -1.859,Avg.Loss: -2.175,LR: 3.48E-04]Training epoch 38:  22%|██▏       | 33/153 [00:00<00:02, 52.19it/s, Epoch: 38, Batch: 34,Loss: -2.280,Avg.Loss: -2.178,LR: 3.48E-04]Training epoch 38:  22%|██▏       | 34/153 [00:00<00:02, 52.19it/s, Epoch: 38, Batch: 35,Loss: -2.464,Avg.Loss: -2.187,LR: 3.48E-04]Training epoch 38:  23%|██▎       | 35/153 [00:00<00:02, 52.19it/s, Epoch: 38, Batch: 36,Loss: -2.328,Avg.Loss: -2.191,LR: 3.48E-04]Training epoch 38:  24%|██▎       | 36/153 [00:00<00:02, 52.55it/s, Epoch: 38, Batch: 36,Loss: -2.328,Avg.Loss: -2.191,LR: 3.48E-04]Training epoch 38:  24%|██▎       | 36/153 [00:00<00:02, 52.55it/s, Epoch: 38, Batch: 37,Loss: -2.016,Avg.Loss: -2.186,LR: 3.48E-04]Training epoch 38:  24%|██▍       | 37/153 [00:00<00:02, 52.55it/s, Epoch: 38, Batch: 38,Loss: -2.550,Avg.Loss: -2.195,LR: 3.47E-04]Training epoch 38:  25%|██▍       | 38/153 [00:00<00:02, 52.55it/s, Epoch: 38, Batch: 39,Loss: -2.501,Avg.Loss: -2.203,LR: 3.47E-04]Training epoch 38:  25%|██▌       | 39/153 [00:00<00:02, 52.55it/s, Epoch: 38, Batch: 40,Loss: -2.436,Avg.Loss: -2.209,LR: 3.47E-04]Training epoch 38:  26%|██▌       | 40/153 [00:00<00:02, 52.55it/s, Epoch: 38, Batch: 41,Loss: -1.929,Avg.Loss: -2.202,LR: 3.47E-04]Training epoch 38:  27%|██▋       | 41/153 [00:00<00:02, 52.55it/s, Epoch: 38, Batch: 42,Loss: -2.196,Avg.Loss: -2.202,LR: 3.47E-04]Training epoch 38:  27%|██▋       | 42/153 [00:00<00:02, 52.77it/s, Epoch: 38, Batch: 42,Loss: -2.196,Avg.Loss: -2.202,LR: 3.47E-04]Training epoch 38:  27%|██▋       | 42/153 [00:00<00:02, 52.77it/s, Epoch: 38, Batch: 43,Loss: -2.127,Avg.Loss: -2.200,LR: 3.47E-04]Training epoch 38:  28%|██▊       | 43/153 [00:00<00:02, 52.77it/s, Epoch: 38, Batch: 44,Loss: -2.671,Avg.Loss: -2.211,LR: 3.47E-04]Training epoch 38:  29%|██▉       | 44/153 [00:00<00:02, 52.77it/s, Epoch: 38, Batch: 45,Loss: -2.391,Avg.Loss: -2.215,LR: 3.47E-04]Training epoch 38:  29%|██▉       | 45/153 [00:00<00:02, 52.77it/s, Epoch: 38, Batch: 46,Loss: -2.551,Avg.Loss: -2.222,LR: 3.47E-04]Training epoch 38:  30%|███       | 46/153 [00:00<00:02, 52.77it/s, Epoch: 38, Batch: 47,Loss: -2.269,Avg.Loss: -2.223,LR: 3.47E-04]Training epoch 38:  31%|███       | 47/153 [00:00<00:02, 52.77it/s, Epoch: 38, Batch: 48,Loss: -1.321,Avg.Loss: -2.205,LR: 3.47E-04]Training epoch 38:  31%|███▏      | 48/153 [00:00<00:01, 52.89it/s, Epoch: 38, Batch: 48,Loss: -1.321,Avg.Loss: -2.205,LR: 3.47E-04]Training epoch 38:  31%|███▏      | 48/153 [00:00<00:01, 52.89it/s, Epoch: 38, Batch: 49,Loss: -1.896,Avg.Loss: -2.198,LR: 3.47E-04]Training epoch 38:  32%|███▏      | 49/153 [00:00<00:01, 52.89it/s, Epoch: 38, Batch: 50,Loss: -1.579,Avg.Loss: -2.186,LR: 3.47E-04]Training epoch 38:  33%|███▎      | 50/153 [00:00<00:01, 52.89it/s, Epoch: 38, Batch: 51,Loss: -2.515,Avg.Loss: -2.192,LR: 3.47E-04]Training epoch 38:  33%|███▎      | 51/153 [00:00<00:01, 52.89it/s, Epoch: 38, Batch: 52,Loss: -1.835,Avg.Loss: -2.185,LR: 3.47E-04]Training epoch 38:  34%|███▍      | 52/153 [00:01<00:01, 52.89it/s, Epoch: 38, Batch: 53,Loss: -0.890,Avg.Loss: -2.161,LR: 3.47E-04]Training epoch 38:  35%|███▍      | 53/153 [00:01<00:01, 52.89it/s, Epoch: 38, Batch: 54,Loss: 0.104,Avg.Loss: -2.119,LR: 3.47E-04] Training epoch 38:  35%|███▌      | 54/153 [00:01<00:01, 53.01it/s, Epoch: 38, Batch: 54,Loss: 0.104,Avg.Loss: -2.119,LR: 3.47E-04]Training epoch 38:  35%|███▌      | 54/153 [00:01<00:01, 53.01it/s, Epoch: 38, Batch: 55,Loss: 0.106,Avg.Loss: -2.079,LR: 3.47E-04]Training epoch 38:  36%|███▌      | 55/153 [00:01<00:01, 53.01it/s, Epoch: 38, Batch: 56,Loss: -1.558,Avg.Loss: -2.069,LR: 3.47E-04]Training epoch 38:  37%|███▋      | 56/153 [00:01<00:01, 53.01it/s, Epoch: 38, Batch: 57,Loss: -1.496,Avg.Loss: -2.059,LR: 3.47E-04]Training epoch 38:  37%|███▋      | 57/153 [00:01<00:01, 53.01it/s, Epoch: 38, Batch: 58,Loss: 0.577,Avg.Loss: -2.014,LR: 3.47E-04] Training epoch 38:  38%|███▊      | 58/153 [00:01<00:01, 53.01it/s, Epoch: 38, Batch: 59,Loss: -0.353,Avg.Loss: -1.986,LR: 3.47E-04]Training epoch 38:  39%|███▊      | 59/153 [00:01<00:01, 53.01it/s, Epoch: 38, Batch: 60,Loss: -0.942,Avg.Loss: -1.968,LR: 3.46E-04]Training epoch 38:  39%|███▉      | 60/153 [00:01<00:01, 53.05it/s, Epoch: 38, Batch: 60,Loss: -0.942,Avg.Loss: -1.968,LR: 3.46E-04]Training epoch 38:  39%|███▉      | 60/153 [00:01<00:01, 53.05it/s, Epoch: 38, Batch: 61,Loss: -2.262,Avg.Loss: -1.973,LR: 3.46E-04]Training epoch 38:  40%|███▉      | 61/153 [00:01<00:01, 53.05it/s, Epoch: 38, Batch: 62,Loss: -1.597,Avg.Loss: -1.967,LR: 3.46E-04]Training epoch 38:  41%|████      | 62/153 [00:01<00:01, 53.05it/s, Epoch: 38, Batch: 63,Loss: -1.726,Avg.Loss: -1.963,LR: 3.46E-04]Training epoch 38:  41%|████      | 63/153 [00:01<00:01, 53.05it/s, Epoch: 38, Batch: 64,Loss: -2.222,Avg.Loss: -1.967,LR: 3.46E-04]Training epoch 38:  42%|████▏     | 64/153 [00:01<00:01, 53.05it/s, Epoch: 38, Batch: 65,Loss: -2.491,Avg.Loss: -1.975,LR: 3.46E-04]Training epoch 38:  42%|████▏     | 65/153 [00:01<00:01, 53.05it/s, Epoch: 38, Batch: 66,Loss: -2.102,Avg.Loss: -1.977,LR: 3.46E-04]Training epoch 38:  43%|████▎     | 66/153 [00:01<00:01, 53.22it/s, Epoch: 38, Batch: 66,Loss: -2.102,Avg.Loss: -1.977,LR: 3.46E-04]Training epoch 38:  43%|████▎     | 66/153 [00:01<00:01, 53.22it/s, Epoch: 38, Batch: 67,Loss: -1.971,Avg.Loss: -1.977,LR: 3.46E-04]Training epoch 38:  44%|████▍     | 67/153 [00:01<00:01, 53.22it/s, Epoch: 38, Batch: 68,Loss: -1.894,Avg.Loss: -1.976,LR: 3.46E-04]Training epoch 38:  44%|████▍     | 68/153 [00:01<00:01, 53.22it/s, Epoch: 38, Batch: 69,Loss: -2.001,Avg.Loss: -1.976,LR: 3.46E-04]Training epoch 38:  45%|████▌     | 69/153 [00:01<00:01, 53.22it/s, Epoch: 38, Batch: 70,Loss: -1.979,Avg.Loss: -1.976,LR: 3.46E-04]Training epoch 38:  46%|████▌     | 70/153 [00:01<00:01, 53.22it/s, Epoch: 38, Batch: 71,Loss: -2.215,Avg.Loss: -1.980,LR: 3.46E-04]Training epoch 38:  46%|████▋     | 71/153 [00:01<00:01, 53.22it/s, Epoch: 38, Batch: 72,Loss: -2.081,Avg.Loss: -1.981,LR: 3.46E-04]Training epoch 38:  47%|████▋     | 72/153 [00:01<00:01, 53.26it/s, Epoch: 38, Batch: 72,Loss: -2.081,Avg.Loss: -1.981,LR: 3.46E-04]Training epoch 38:  47%|████▋     | 72/153 [00:01<00:01, 53.26it/s, Epoch: 38, Batch: 73,Loss: -2.309,Avg.Loss: -1.985,LR: 3.46E-04]Training epoch 38:  48%|████▊     | 73/153 [00:01<00:01, 53.26it/s, Epoch: 38, Batch: 74,Loss: -2.063,Avg.Loss: -1.987,LR: 3.46E-04]Training epoch 38:  48%|████▊     | 74/153 [00:01<00:01, 53.26it/s, Epoch: 38, Batch: 75,Loss: -1.103,Avg.Loss: -1.975,LR: 3.46E-04]Training epoch 38:  49%|████▉     | 75/153 [00:01<00:01, 53.26it/s, Epoch: 38, Batch: 76,Loss: -2.158,Avg.Loss: -1.977,LR: 3.46E-04]Training epoch 38:  50%|████▉     | 76/153 [00:01<00:01, 53.26it/s, Epoch: 38, Batch: 77,Loss: -1.536,Avg.Loss: -1.971,LR: 3.46E-04]Training epoch 38:  50%|█████     | 77/153 [00:01<00:01, 53.26it/s, Epoch: 38, Batch: 78,Loss: -1.629,Avg.Loss: -1.967,LR: 3.46E-04]Training epoch 38:  51%|█████     | 78/153 [00:01<00:01, 52.73it/s, Epoch: 38, Batch: 78,Loss: -1.629,Avg.Loss: -1.967,LR: 3.46E-04]Training epoch 38:  51%|█████     | 78/153 [00:01<00:01, 52.73it/s, Epoch: 38, Batch: 79,Loss: -1.517,Avg.Loss: -1.961,LR: 3.46E-04]Training epoch 38:  52%|█████▏    | 79/153 [00:01<00:01, 52.73it/s, Epoch: 38, Batch: 80,Loss: -1.674,Avg.Loss: -1.958,LR: 3.46E-04]Training epoch 38:  52%|█████▏    | 80/153 [00:01<00:01, 52.73it/s, Epoch: 38, Batch: 81,Loss: -1.764,Avg.Loss: -1.955,LR: 3.45E-04]Training epoch 38:  53%|█████▎    | 81/153 [00:01<00:01, 52.73it/s, Epoch: 38, Batch: 82,Loss: -1.978,Avg.Loss: -1.956,LR: 3.45E-04]Training epoch 38:  54%|█████▎    | 82/153 [00:01<00:01, 52.73it/s, Epoch: 38, Batch: 83,Loss: -2.480,Avg.Loss: -1.962,LR: 3.45E-04]Training epoch 38:  54%|█████▍    | 83/153 [00:01<00:01, 52.73it/s, Epoch: 38, Batch: 84,Loss: -1.319,Avg.Loss: -1.954,LR: 3.45E-04]Training epoch 38:  55%|█████▍    | 84/153 [00:01<00:01, 52.75it/s, Epoch: 38, Batch: 84,Loss: -1.319,Avg.Loss: -1.954,LR: 3.45E-04]Training epoch 38:  55%|█████▍    | 84/153 [00:01<00:01, 52.75it/s, Epoch: 38, Batch: 85,Loss: -2.328,Avg.Loss: -1.959,LR: 3.45E-04]Training epoch 38:  56%|█████▌    | 85/153 [00:01<00:01, 52.75it/s, Epoch: 38, Batch: 86,Loss: -2.092,Avg.Loss: -1.960,LR: 3.45E-04]Training epoch 38:  56%|█████▌    | 86/153 [00:01<00:01, 52.75it/s, Epoch: 38, Batch: 87,Loss: -2.101,Avg.Loss: -1.962,LR: 3.45E-04]Training epoch 38:  57%|█████▋    | 87/153 [00:01<00:01, 52.75it/s, Epoch: 38, Batch: 88,Loss: -2.664,Avg.Loss: -1.970,LR: 3.45E-04]Training epoch 38:  58%|█████▊    | 88/153 [00:01<00:01, 52.75it/s, Epoch: 38, Batch: 89,Loss: -1.999,Avg.Loss: -1.970,LR: 3.45E-04]Training epoch 38:  58%|█████▊    | 89/153 [00:01<00:01, 52.75it/s, Epoch: 38, Batch: 90,Loss: -1.405,Avg.Loss: -1.964,LR: 3.45E-04]Training epoch 38:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 38, Batch: 90,Loss: -1.405,Avg.Loss: -1.964,LR: 3.45E-04]Training epoch 38:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 38, Batch: 91,Loss: -1.375,Avg.Loss: -1.957,LR: 3.45E-04]Training epoch 38:  59%|█████▉    | 91/153 [00:01<00:01, 52.91it/s, Epoch: 38, Batch: 92,Loss: -2.311,Avg.Loss: -1.961,LR: 3.45E-04]Training epoch 38:  60%|██████    | 92/153 [00:01<00:01, 52.91it/s, Epoch: 38, Batch: 93,Loss: -1.982,Avg.Loss: -1.962,LR: 3.45E-04]Training epoch 38:  61%|██████    | 93/153 [00:01<00:01, 52.91it/s, Epoch: 38, Batch: 94,Loss: -2.560,Avg.Loss: -1.968,LR: 3.45E-04]Training epoch 38:  61%|██████▏   | 94/153 [00:01<00:01, 52.91it/s, Epoch: 38, Batch: 95,Loss: -2.077,Avg.Loss: -1.969,LR: 3.45E-04]Training epoch 38:  62%|██████▏   | 95/153 [00:01<00:01, 52.91it/s, Epoch: 38, Batch: 96,Loss: -1.551,Avg.Loss: -1.965,LR: 3.45E-04]Training epoch 38:  63%|██████▎   | 96/153 [00:01<00:01, 52.85it/s, Epoch: 38, Batch: 96,Loss: -1.551,Avg.Loss: -1.965,LR: 3.45E-04]Training epoch 38:  63%|██████▎   | 96/153 [00:01<00:01, 52.85it/s, Epoch: 38, Batch: 97,Loss: -1.543,Avg.Loss: -1.960,LR: 3.45E-04]Training epoch 38:  63%|██████▎   | 97/153 [00:01<00:01, 52.85it/s, Epoch: 38, Batch: 98,Loss: -2.435,Avg.Loss: -1.965,LR: 3.45E-04]Training epoch 38:  64%|██████▍   | 98/153 [00:01<00:01, 52.85it/s, Epoch: 38, Batch: 99,Loss: -2.021,Avg.Loss: -1.966,LR: 3.45E-04]Training epoch 38:  65%|██████▍   | 99/153 [00:01<00:01, 52.85it/s, Epoch: 38, Batch: 100,Loss: -2.662,Avg.Loss: -1.973,LR: 3.45E-04]Training epoch 38:  65%|██████▌   | 100/153 [00:01<00:01, 52.85it/s, Epoch: 38, Batch: 101,Loss: -2.137,Avg.Loss: -1.974,LR: 3.45E-04]Training epoch 38:  66%|██████▌   | 101/153 [00:01<00:00, 52.85it/s, Epoch: 38, Batch: 102,Loss: -1.571,Avg.Loss: -1.970,LR: 3.44E-04]Training epoch 38:  67%|██████▋   | 102/153 [00:01<00:00, 52.72it/s, Epoch: 38, Batch: 102,Loss: -1.571,Avg.Loss: -1.970,LR: 3.44E-04]Training epoch 38:  67%|██████▋   | 102/153 [00:01<00:00, 52.72it/s, Epoch: 38, Batch: 103,Loss: -2.192,Avg.Loss: -1.973,LR: 3.44E-04]Training epoch 38:  67%|██████▋   | 103/153 [00:01<00:00, 52.72it/s, Epoch: 38, Batch: 104,Loss: -1.998,Avg.Loss: -1.973,LR: 3.44E-04]Training epoch 38:  68%|██████▊   | 104/153 [00:01<00:00, 52.72it/s, Epoch: 38, Batch: 105,Loss: -2.046,Avg.Loss: -1.973,LR: 3.44E-04]Training epoch 38:  69%|██████▊   | 105/153 [00:02<00:00, 52.72it/s, Epoch: 38, Batch: 106,Loss: -2.722,Avg.Loss: -1.981,LR: 3.44E-04]Training epoch 38:  69%|██████▉   | 106/153 [00:02<00:00, 52.72it/s, Epoch: 38, Batch: 107,Loss: -1.849,Avg.Loss: -1.979,LR: 3.44E-04]Training epoch 38:  70%|██████▉   | 107/153 [00:02<00:00, 52.72it/s, Epoch: 38, Batch: 108,Loss: -1.740,Avg.Loss: -1.977,LR: 3.44E-04]Training epoch 38:  71%|███████   | 108/153 [00:02<00:00, 52.75it/s, Epoch: 38, Batch: 108,Loss: -1.740,Avg.Loss: -1.977,LR: 3.44E-04]Training epoch 38:  71%|███████   | 108/153 [00:02<00:00, 52.75it/s, Epoch: 38, Batch: 109,Loss: -2.099,Avg.Loss: -1.978,LR: 3.44E-04]Training epoch 38:  71%|███████   | 109/153 [00:02<00:00, 52.75it/s, Epoch: 38, Batch: 110,Loss: -2.039,Avg.Loss: -1.979,LR: 3.44E-04]Training epoch 38:  72%|███████▏  | 110/153 [00:02<00:00, 52.75it/s, Epoch: 38, Batch: 111,Loss: -2.057,Avg.Loss: -1.979,LR: 3.44E-04]Training epoch 38:  73%|███████▎  | 111/153 [00:02<00:00, 52.75it/s, Epoch: 38, Batch: 112,Loss: -2.542,Avg.Loss: -1.984,LR: 3.44E-04]Training epoch 38:  73%|███████▎  | 112/153 [00:02<00:00, 52.75it/s, Epoch: 38, Batch: 113,Loss: -2.247,Avg.Loss: -1.987,LR: 3.44E-04]Training epoch 38:  74%|███████▍  | 113/153 [00:02<00:00, 52.75it/s, Epoch: 38, Batch: 114,Loss: -2.084,Avg.Loss: -1.988,LR: 3.44E-04]Training epoch 38:  75%|███████▍  | 114/153 [00:02<00:00, 52.79it/s, Epoch: 38, Batch: 114,Loss: -2.084,Avg.Loss: -1.988,LR: 3.44E-04]Training epoch 38:  75%|███████▍  | 114/153 [00:02<00:00, 52.79it/s, Epoch: 38, Batch: 115,Loss: -2.494,Avg.Loss: -1.992,LR: 3.44E-04]Training epoch 38:  75%|███████▌  | 115/153 [00:02<00:00, 52.79it/s, Epoch: 38, Batch: 116,Loss: -2.735,Avg.Loss: -1.998,LR: 3.44E-04]Training epoch 38:  76%|███████▌  | 116/153 [00:02<00:00, 52.79it/s, Epoch: 38, Batch: 117,Loss: -2.698,Avg.Loss: -2.004,LR: 3.44E-04]Training epoch 38:  76%|███████▋  | 117/153 [00:02<00:00, 52.79it/s, Epoch: 38, Batch: 118,Loss: -2.352,Avg.Loss: -2.007,LR: 3.44E-04]Training epoch 38:  77%|███████▋  | 118/153 [00:02<00:00, 52.79it/s, Epoch: 38, Batch: 119,Loss: -1.374,Avg.Loss: -2.002,LR: 3.44E-04]Training epoch 38:  78%|███████▊  | 119/153 [00:02<00:00, 52.79it/s, Epoch: 38, Batch: 120,Loss: -2.725,Avg.Loss: -2.008,LR: 3.44E-04]Training epoch 38:  78%|███████▊  | 120/153 [00:02<00:00, 52.83it/s, Epoch: 38, Batch: 120,Loss: -2.725,Avg.Loss: -2.008,LR: 3.44E-04]Training epoch 38:  78%|███████▊  | 120/153 [00:02<00:00, 52.83it/s, Epoch: 38, Batch: 121,Loss: -2.101,Avg.Loss: -2.009,LR: 3.44E-04]Training epoch 38:  79%|███████▉  | 121/153 [00:02<00:00, 52.83it/s, Epoch: 38, Batch: 122,Loss: -2.356,Avg.Loss: -2.012,LR: 3.44E-04]Training epoch 38:  80%|███████▉  | 122/153 [00:02<00:00, 52.83it/s, Epoch: 38, Batch: 123,Loss: -2.291,Avg.Loss: -2.014,LR: 3.43E-04]Training epoch 38:  80%|████████  | 123/153 [00:02<00:00, 52.83it/s, Epoch: 38, Batch: 124,Loss: -2.182,Avg.Loss: -2.015,LR: 3.43E-04]Training epoch 38:  81%|████████  | 124/153 [00:02<00:00, 52.83it/s, Epoch: 38, Batch: 125,Loss: -1.558,Avg.Loss: -2.012,LR: 3.43E-04]Training epoch 38:  82%|████████▏ | 125/153 [00:02<00:00, 52.83it/s, Epoch: 38, Batch: 126,Loss: -0.864,Avg.Loss: -2.003,LR: 3.43E-04]Training epoch 38:  82%|████████▏ | 126/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 126,Loss: -0.864,Avg.Loss: -2.003,LR: 3.43E-04]Training epoch 38:  82%|████████▏ | 126/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 127,Loss: -0.796,Avg.Loss: -1.993,LR: 3.43E-04]Training epoch 38:  83%|████████▎ | 127/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 128,Loss: -2.206,Avg.Loss: -1.995,LR: 3.43E-04]Training epoch 38:  84%|████████▎ | 128/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 129,Loss: -2.155,Avg.Loss: -1.996,LR: 3.43E-04]Training epoch 38:  84%|████████▍ | 129/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 130,Loss: -2.229,Avg.Loss: -1.998,LR: 3.43E-04]Training epoch 38:  85%|████████▍ | 130/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 131,Loss: -1.178,Avg.Loss: -1.991,LR: 3.43E-04]Training epoch 38:  86%|████████▌ | 131/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 132,Loss: -1.630,Avg.Loss: -1.989,LR: 3.43E-04]Training epoch 38:  86%|████████▋ | 132/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 132,Loss: -1.630,Avg.Loss: -1.989,LR: 3.43E-04]Training epoch 38:  86%|████████▋ | 132/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 133,Loss: -1.877,Avg.Loss: -1.988,LR: 3.43E-04]Training epoch 38:  87%|████████▋ | 133/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 134,Loss: -2.364,Avg.Loss: -1.991,LR: 3.43E-04]Training epoch 38:  88%|████████▊ | 134/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 135,Loss: -1.811,Avg.Loss: -1.989,LR: 3.43E-04]Training epoch 38:  88%|████████▊ | 135/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 136,Loss: -1.013,Avg.Loss: -1.982,LR: 3.43E-04]Training epoch 38:  89%|████████▉ | 136/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 137,Loss: -1.557,Avg.Loss: -1.979,LR: 3.43E-04]Training epoch 38:  90%|████████▉ | 137/153 [00:02<00:00, 53.06it/s, Epoch: 38, Batch: 138,Loss: -2.345,Avg.Loss: -1.982,LR: 3.43E-04]Training epoch 38:  90%|█████████ | 138/153 [00:02<00:00, 53.10it/s, Epoch: 38, Batch: 138,Loss: -2.345,Avg.Loss: -1.982,LR: 3.43E-04]Training epoch 38:  90%|█████████ | 138/153 [00:02<00:00, 53.10it/s, Epoch: 38, Batch: 139,Loss: -2.244,Avg.Loss: -1.984,LR: 3.43E-04]Training epoch 38:  91%|█████████ | 139/153 [00:02<00:00, 53.10it/s, Epoch: 38, Batch: 140,Loss: -1.555,Avg.Loss: -1.981,LR: 3.43E-04]Training epoch 38:  92%|█████████▏| 140/153 [00:02<00:00, 53.10it/s, Epoch: 38, Batch: 141,Loss: -1.083,Avg.Loss: -1.974,LR: 3.43E-04]Training epoch 38:  92%|█████████▏| 141/153 [00:02<00:00, 53.10it/s, Epoch: 38, Batch: 142,Loss: -1.216,Avg.Loss: -1.969,LR: 3.43E-04]Training epoch 38:  93%|█████████▎| 142/153 [00:02<00:00, 53.10it/s, Epoch: 38, Batch: 143,Loss: -2.315,Avg.Loss: -1.971,LR: 3.43E-04]Training epoch 38:  93%|█████████▎| 143/153 [00:02<00:00, 53.10it/s, Epoch: 38, Batch: 144,Loss: -2.133,Avg.Loss: -1.972,LR: 3.42E-04]Training epoch 38:  94%|█████████▍| 144/153 [00:02<00:00, 52.94it/s, Epoch: 38, Batch: 144,Loss: -2.133,Avg.Loss: -1.972,LR: 3.42E-04]Training epoch 38:  94%|█████████▍| 144/153 [00:02<00:00, 52.94it/s, Epoch: 38, Batch: 145,Loss: -1.931,Avg.Loss: -1.972,LR: 3.42E-04]Training epoch 38:  95%|█████████▍| 145/153 [00:02<00:00, 52.94it/s, Epoch: 38, Batch: 146,Loss: -1.455,Avg.Loss: -1.969,LR: 3.42E-04]Training epoch 38:  95%|█████████▌| 146/153 [00:02<00:00, 52.94it/s, Epoch: 38, Batch: 147,Loss: -1.488,Avg.Loss: -1.965,LR: 3.42E-04]Training epoch 38:  96%|█████████▌| 147/153 [00:02<00:00, 52.94it/s, Epoch: 38, Batch: 148,Loss: -1.816,Avg.Loss: -1.964,LR: 3.42E-04]Training epoch 38:  97%|█████████▋| 148/153 [00:02<00:00, 52.94it/s, Epoch: 38, Batch: 149,Loss: -2.230,Avg.Loss: -1.966,LR: 3.42E-04]Training epoch 38:  97%|█████████▋| 149/153 [00:02<00:00, 52.94it/s, Epoch: 38, Batch: 150,Loss: -2.496,Avg.Loss: -1.970,LR: 3.42E-04]Training epoch 38:  98%|█████████▊| 150/153 [00:02<00:00, 53.00it/s, Epoch: 38, Batch: 150,Loss: -2.496,Avg.Loss: -1.970,LR: 3.42E-04]Training epoch 38:  98%|█████████▊| 150/153 [00:02<00:00, 53.00it/s, Epoch: 38, Batch: 151,Loss: -1.745,Avg.Loss: -1.968,LR: 3.42E-04]Training epoch 38:  99%|█████████▊| 151/153 [00:02<00:00, 53.00it/s, Epoch: 38, Batch: 152,Loss: -1.900,Avg.Loss: -1.968,LR: 3.42E-04]Training epoch 38:  99%|█████████▉| 152/153 [00:02<00:00, 53.00it/s, Epoch: 38, Batch: 153,Loss: -1.830,Avg.Loss: -1.967,LR: 3.42E-04]Training epoch 38: 100%|██████████| 153/153 [00:02<00:00, 52.86it/s, Epoch: 38, Batch: 153,Loss: -1.830,Avg.Loss: -1.967,LR: 3.42E-04]
Training epoch 39:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 39:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 39, Batch: 1,Loss: -2.329,Avg.Loss: -2.329,LR: 3.42E-04]Training epoch 39:   1%|          | 1/153 [00:00<00:06, 25.25it/s, Epoch: 39, Batch: 2,Loss: -1.895,Avg.Loss: -2.112,LR: 3.42E-04]Training epoch 39:   1%|▏         | 2/153 [00:00<00:04, 34.62it/s, Epoch: 39, Batch: 3,Loss: -1.786,Avg.Loss: -2.003,LR: 3.42E-04]Training epoch 39:   2%|▏         | 3/153 [00:00<00:03, 40.27it/s, Epoch: 39, Batch: 4,Loss: -1.737,Avg.Loss: -1.937,LR: 3.42E-04]Training epoch 39:   3%|▎         | 4/153 [00:00<00:03, 42.85it/s, Epoch: 39, Batch: 5,Loss: -1.261,Avg.Loss: -1.802,LR: 3.42E-04]Training epoch 39:   3%|▎         | 5/153 [00:00<00:03, 44.44it/s, Epoch: 39, Batch: 6,Loss: -0.973,Avg.Loss: -1.663,LR: 3.42E-04]Training epoch 39:   4%|▍         | 6/153 [00:00<00:02, 53.24it/s, Epoch: 39, Batch: 6,Loss: -0.973,Avg.Loss: -1.663,LR: 3.42E-04]Training epoch 39:   4%|▍         | 6/153 [00:00<00:02, 53.24it/s, Epoch: 39, Batch: 7,Loss: -1.757,Avg.Loss: -1.677,LR: 3.42E-04]Training epoch 39:   5%|▍         | 7/153 [00:00<00:02, 53.24it/s, Epoch: 39, Batch: 8,Loss: -1.503,Avg.Loss: -1.655,LR: 3.42E-04]Training epoch 39:   5%|▌         | 8/153 [00:00<00:02, 53.24it/s, Epoch: 39, Batch: 9,Loss: -0.436,Avg.Loss: -1.520,LR: 3.42E-04]Training epoch 39:   6%|▌         | 9/153 [00:00<00:02, 53.24it/s, Epoch: 39, Batch: 10,Loss: -0.731,Avg.Loss: -1.441,LR: 3.42E-04]Training epoch 39:   7%|▋         | 10/153 [00:00<00:02, 53.24it/s, Epoch: 39, Batch: 11,Loss: -2.244,Avg.Loss: -1.514,LR: 3.42E-04]Training epoch 39:   7%|▋         | 11/153 [00:00<00:02, 53.24it/s, Epoch: 39, Batch: 12,Loss: -2.305,Avg.Loss: -1.580,LR: 3.41E-04]Training epoch 39:   8%|▊         | 12/153 [00:00<00:02, 53.37it/s, Epoch: 39, Batch: 12,Loss: -2.305,Avg.Loss: -1.580,LR: 3.41E-04]Training epoch 39:   8%|▊         | 12/153 [00:00<00:02, 53.37it/s, Epoch: 39, Batch: 13,Loss: -1.304,Avg.Loss: -1.559,LR: 3.41E-04]Training epoch 39:   8%|▊         | 13/153 [00:00<00:02, 53.37it/s, Epoch: 39, Batch: 14,Loss: -1.963,Avg.Loss: -1.587,LR: 3.41E-04]Training epoch 39:   9%|▉         | 14/153 [00:00<00:02, 53.37it/s, Epoch: 39, Batch: 15,Loss: -2.405,Avg.Loss: -1.642,LR: 3.41E-04]Training epoch 39:  10%|▉         | 15/153 [00:00<00:02, 53.37it/s, Epoch: 39, Batch: 16,Loss: -2.135,Avg.Loss: -1.673,LR: 3.41E-04]Training epoch 39:  10%|█         | 16/153 [00:00<00:02, 53.37it/s, Epoch: 39, Batch: 17,Loss: -2.478,Avg.Loss: -1.720,LR: 3.41E-04]Training epoch 39:  11%|█         | 17/153 [00:00<00:02, 53.37it/s, Epoch: 39, Batch: 18,Loss: -2.057,Avg.Loss: -1.739,LR: 3.41E-04]Training epoch 39:  12%|█▏        | 18/153 [00:00<00:02, 53.53it/s, Epoch: 39, Batch: 18,Loss: -2.057,Avg.Loss: -1.739,LR: 3.41E-04]Training epoch 39:  12%|█▏        | 18/153 [00:00<00:02, 53.53it/s, Epoch: 39, Batch: 19,Loss: -2.659,Avg.Loss: -1.787,LR: 3.41E-04]Training epoch 39:  12%|█▏        | 19/153 [00:00<00:02, 53.53it/s, Epoch: 39, Batch: 20,Loss: -1.508,Avg.Loss: -1.773,LR: 3.41E-04]Training epoch 39:  13%|█▎        | 20/153 [00:00<00:02, 53.53it/s, Epoch: 39, Batch: 21,Loss: -2.302,Avg.Loss: -1.798,LR: 3.41E-04]Training epoch 39:  14%|█▎        | 21/153 [00:00<00:02, 53.53it/s, Epoch: 39, Batch: 22,Loss: -1.751,Avg.Loss: -1.796,LR: 3.41E-04]Training epoch 39:  14%|█▍        | 22/153 [00:00<00:02, 53.53it/s, Epoch: 39, Batch: 23,Loss: -0.780,Avg.Loss: -1.752,LR: 3.41E-04]Training epoch 39:  15%|█▌        | 23/153 [00:00<00:02, 53.53it/s, Epoch: 39, Batch: 24,Loss: -1.517,Avg.Loss: -1.742,LR: 3.41E-04]Training epoch 39:  16%|█▌        | 24/153 [00:00<00:02, 53.12it/s, Epoch: 39, Batch: 24,Loss: -1.517,Avg.Loss: -1.742,LR: 3.41E-04]Training epoch 39:  16%|█▌        | 24/153 [00:00<00:02, 53.12it/s, Epoch: 39, Batch: 25,Loss: -2.584,Avg.Loss: -1.776,LR: 3.41E-04]Training epoch 39:  16%|█▋        | 25/153 [00:00<00:02, 53.12it/s, Epoch: 39, Batch: 26,Loss: -0.639,Avg.Loss: -1.732,LR: 3.41E-04]Training epoch 39:  17%|█▋        | 26/153 [00:00<00:02, 53.12it/s, Epoch: 39, Batch: 27,Loss: -0.272,Avg.Loss: -1.678,LR: 3.41E-04]Training epoch 39:  18%|█▊        | 27/153 [00:00<00:02, 53.12it/s, Epoch: 39, Batch: 28,Loss: 0.103,Avg.Loss: -1.615,LR: 3.41E-04] Training epoch 39:  18%|█▊        | 28/153 [00:00<00:02, 53.12it/s, Epoch: 39, Batch: 29,Loss: -1.261,Avg.Loss: -1.602,LR: 3.41E-04]Training epoch 39:  19%|█▉        | 29/153 [00:00<00:02, 53.12it/s, Epoch: 39, Batch: 30,Loss: -2.405,Avg.Loss: -1.629,LR: 3.41E-04]Training epoch 39:  20%|█▉        | 30/153 [00:00<00:02, 52.49it/s, Epoch: 39, Batch: 30,Loss: -2.405,Avg.Loss: -1.629,LR: 3.41E-04]Training epoch 39:  20%|█▉        | 30/153 [00:00<00:02, 52.49it/s, Epoch: 39, Batch: 31,Loss: -1.839,Avg.Loss: -1.636,LR: 3.41E-04]Training epoch 39:  20%|██        | 31/153 [00:00<00:02, 52.49it/s, Epoch: 39, Batch: 32,Loss: -2.239,Avg.Loss: -1.655,LR: 3.41E-04]Training epoch 39:  21%|██        | 32/153 [00:00<00:02, 52.49it/s, Epoch: 39, Batch: 33,Loss: -2.484,Avg.Loss: -1.680,LR: 3.40E-04]Training epoch 39:  22%|██▏       | 33/153 [00:00<00:02, 52.49it/s, Epoch: 39, Batch: 34,Loss: -1.136,Avg.Loss: -1.664,LR: 3.40E-04]Training epoch 39:  22%|██▏       | 34/153 [00:00<00:02, 52.49it/s, Epoch: 39, Batch: 35,Loss: 0.029,Avg.Loss: -1.615,LR: 3.40E-04] Training epoch 39:  23%|██▎       | 35/153 [00:00<00:02, 52.49it/s, Epoch: 39, Batch: 36,Loss: -0.224,Avg.Loss: -1.577,LR: 3.40E-04]Training epoch 39:  24%|██▎       | 36/153 [00:00<00:02, 52.74it/s, Epoch: 39, Batch: 36,Loss: -0.224,Avg.Loss: -1.577,LR: 3.40E-04]Training epoch 39:  24%|██▎       | 36/153 [00:00<00:02, 52.74it/s, Epoch: 39, Batch: 37,Loss: -1.413,Avg.Loss: -1.572,LR: 3.40E-04]Training epoch 39:  24%|██▍       | 37/153 [00:00<00:02, 52.74it/s, Epoch: 39, Batch: 38,Loss: -2.182,Avg.Loss: -1.588,LR: 3.40E-04]Training epoch 39:  25%|██▍       | 38/153 [00:00<00:02, 52.74it/s, Epoch: 39, Batch: 39,Loss: -1.290,Avg.Loss: -1.581,LR: 3.40E-04]Training epoch 39:  25%|██▌       | 39/153 [00:00<00:02, 52.74it/s, Epoch: 39, Batch: 40,Loss: -2.014,Avg.Loss: -1.592,LR: 3.40E-04]Training epoch 39:  26%|██▌       | 40/153 [00:00<00:02, 52.74it/s, Epoch: 39, Batch: 41,Loss: -2.408,Avg.Loss: -1.612,LR: 3.40E-04]Training epoch 39:  27%|██▋       | 41/153 [00:00<00:02, 52.74it/s, Epoch: 39, Batch: 42,Loss: -1.775,Avg.Loss: -1.615,LR: 3.40E-04]Training epoch 39:  27%|██▋       | 42/153 [00:00<00:02, 53.10it/s, Epoch: 39, Batch: 42,Loss: -1.775,Avg.Loss: -1.615,LR: 3.40E-04]Training epoch 39:  27%|██▋       | 42/153 [00:00<00:02, 53.10it/s, Epoch: 39, Batch: 43,Loss: -1.521,Avg.Loss: -1.613,LR: 3.40E-04]Training epoch 39:  28%|██▊       | 43/153 [00:00<00:02, 53.10it/s, Epoch: 39, Batch: 44,Loss: -1.255,Avg.Loss: -1.605,LR: 3.40E-04]Training epoch 39:  29%|██▉       | 44/153 [00:00<00:02, 53.10it/s, Epoch: 39, Batch: 45,Loss: -2.498,Avg.Loss: -1.625,LR: 3.40E-04]Training epoch 39:  29%|██▉       | 45/153 [00:00<00:02, 53.10it/s, Epoch: 39, Batch: 46,Loss: -1.841,Avg.Loss: -1.630,LR: 3.40E-04]Training epoch 39:  30%|███       | 46/153 [00:00<00:02, 53.10it/s, Epoch: 39, Batch: 47,Loss: -0.094,Avg.Loss: -1.597,LR: 3.40E-04]Training epoch 39:  31%|███       | 47/153 [00:00<00:01, 53.10it/s, Epoch: 39, Batch: 48,Loss: 0.138,Avg.Loss: -1.561,LR: 3.40E-04] Training epoch 39:  31%|███▏      | 48/153 [00:00<00:01, 53.12it/s, Epoch: 39, Batch: 48,Loss: 0.138,Avg.Loss: -1.561,LR: 3.40E-04]Training epoch 39:  31%|███▏      | 48/153 [00:00<00:01, 53.12it/s, Epoch: 39, Batch: 49,Loss: -1.589,Avg.Loss: -1.561,LR: 3.40E-04]Training epoch 39:  32%|███▏      | 49/153 [00:00<00:01, 53.12it/s, Epoch: 39, Batch: 50,Loss: -2.244,Avg.Loss: -1.575,LR: 3.40E-04]Training epoch 39:  33%|███▎      | 50/153 [00:00<00:01, 53.12it/s, Epoch: 39, Batch: 51,Loss: -2.096,Avg.Loss: -1.585,LR: 3.40E-04]Training epoch 39:  33%|███▎      | 51/153 [00:00<00:01, 53.12it/s, Epoch: 39, Batch: 52,Loss: -2.091,Avg.Loss: -1.595,LR: 3.40E-04]Training epoch 39:  34%|███▍      | 52/153 [00:00<00:01, 53.12it/s, Epoch: 39, Batch: 53,Loss: -1.735,Avg.Loss: -1.598,LR: 3.39E-04]Training epoch 39:  35%|███▍      | 53/153 [00:01<00:01, 53.12it/s, Epoch: 39, Batch: 54,Loss: -2.325,Avg.Loss: -1.611,LR: 3.39E-04]Training epoch 39:  35%|███▌      | 54/153 [00:01<00:01, 53.28it/s, Epoch: 39, Batch: 54,Loss: -2.325,Avg.Loss: -1.611,LR: 3.39E-04]Training epoch 39:  35%|███▌      | 54/153 [00:01<00:01, 53.28it/s, Epoch: 39, Batch: 55,Loss: -2.585,Avg.Loss: -1.629,LR: 3.39E-04]Training epoch 39:  36%|███▌      | 55/153 [00:01<00:01, 53.28it/s, Epoch: 39, Batch: 56,Loss: -2.691,Avg.Loss: -1.648,LR: 3.39E-04]Training epoch 39:  37%|███▋      | 56/153 [00:01<00:01, 53.28it/s, Epoch: 39, Batch: 57,Loss: -2.520,Avg.Loss: -1.663,LR: 3.39E-04]Training epoch 39:  37%|███▋      | 57/153 [00:01<00:01, 53.28it/s, Epoch: 39, Batch: 58,Loss: -2.200,Avg.Loss: -1.672,LR: 3.39E-04]Training epoch 39:  38%|███▊      | 58/153 [00:01<00:01, 53.28it/s, Epoch: 39, Batch: 59,Loss: -2.023,Avg.Loss: -1.678,LR: 3.39E-04]Training epoch 39:  39%|███▊      | 59/153 [00:01<00:01, 53.28it/s, Epoch: 39, Batch: 60,Loss: -1.601,Avg.Loss: -1.677,LR: 3.39E-04]Training epoch 39:  39%|███▉      | 60/153 [00:01<00:01, 53.04it/s, Epoch: 39, Batch: 60,Loss: -1.601,Avg.Loss: -1.677,LR: 3.39E-04]Training epoch 39:  39%|███▉      | 60/153 [00:01<00:01, 53.04it/s, Epoch: 39, Batch: 61,Loss: -2.534,Avg.Loss: -1.691,LR: 3.39E-04]Training epoch 39:  40%|███▉      | 61/153 [00:01<00:01, 53.04it/s, Epoch: 39, Batch: 62,Loss: -2.784,Avg.Loss: -1.709,LR: 3.39E-04]Training epoch 39:  41%|████      | 62/153 [00:01<00:01, 53.04it/s, Epoch: 39, Batch: 63,Loss: -2.395,Avg.Loss: -1.720,LR: 3.39E-04]Training epoch 39:  41%|████      | 63/153 [00:01<00:01, 53.04it/s, Epoch: 39, Batch: 64,Loss: -2.124,Avg.Loss: -1.726,LR: 3.39E-04]Training epoch 39:  42%|████▏     | 64/153 [00:01<00:01, 53.04it/s, Epoch: 39, Batch: 65,Loss: -2.273,Avg.Loss: -1.734,LR: 3.39E-04]Training epoch 39:  42%|████▏     | 65/153 [00:01<00:01, 53.04it/s, Epoch: 39, Batch: 66,Loss: -2.174,Avg.Loss: -1.741,LR: 3.39E-04]Training epoch 39:  43%|████▎     | 66/153 [00:01<00:01, 53.08it/s, Epoch: 39, Batch: 66,Loss: -2.174,Avg.Loss: -1.741,LR: 3.39E-04]Training epoch 39:  43%|████▎     | 66/153 [00:01<00:01, 53.08it/s, Epoch: 39, Batch: 67,Loss: -2.283,Avg.Loss: -1.749,LR: 3.39E-04]Training epoch 39:  44%|████▍     | 67/153 [00:01<00:01, 53.08it/s, Epoch: 39, Batch: 68,Loss: -2.404,Avg.Loss: -1.759,LR: 3.39E-04]Training epoch 39:  44%|████▍     | 68/153 [00:01<00:01, 53.08it/s, Epoch: 39, Batch: 69,Loss: -2.058,Avg.Loss: -1.763,LR: 3.39E-04]Training epoch 39:  45%|████▌     | 69/153 [00:01<00:01, 53.08it/s, Epoch: 39, Batch: 70,Loss: -2.332,Avg.Loss: -1.771,LR: 3.39E-04]Training epoch 39:  46%|████▌     | 70/153 [00:01<00:01, 53.08it/s, Epoch: 39, Batch: 71,Loss: -2.009,Avg.Loss: -1.775,LR: 3.39E-04]Training epoch 39:  46%|████▋     | 71/153 [00:01<00:01, 53.08it/s, Epoch: 39, Batch: 72,Loss: -2.446,Avg.Loss: -1.784,LR: 3.39E-04]Training epoch 39:  47%|████▋     | 72/153 [00:01<00:01, 53.10it/s, Epoch: 39, Batch: 72,Loss: -2.446,Avg.Loss: -1.784,LR: 3.39E-04]Training epoch 39:  47%|████▋     | 72/153 [00:01<00:01, 53.10it/s, Epoch: 39, Batch: 73,Loss: -2.339,Avg.Loss: -1.791,LR: 3.39E-04]Training epoch 39:  48%|████▊     | 73/153 [00:01<00:01, 53.10it/s, Epoch: 39, Batch: 74,Loss: -2.200,Avg.Loss: -1.797,LR: 3.38E-04]Training epoch 39:  48%|████▊     | 74/153 [00:01<00:01, 53.10it/s, Epoch: 39, Batch: 75,Loss: -1.812,Avg.Loss: -1.797,LR: 3.38E-04]Training epoch 39:  49%|████▉     | 75/153 [00:01<00:01, 53.10it/s, Epoch: 39, Batch: 76,Loss: -2.029,Avg.Loss: -1.800,LR: 3.38E-04]Training epoch 39:  50%|████▉     | 76/153 [00:01<00:01, 53.10it/s, Epoch: 39, Batch: 77,Loss: -2.148,Avg.Loss: -1.805,LR: 3.38E-04]Training epoch 39:  50%|█████     | 77/153 [00:01<00:01, 53.10it/s, Epoch: 39, Batch: 78,Loss: -2.194,Avg.Loss: -1.810,LR: 3.38E-04]Training epoch 39:  51%|█████     | 78/153 [00:01<00:01, 52.65it/s, Epoch: 39, Batch: 78,Loss: -2.194,Avg.Loss: -1.810,LR: 3.38E-04]Training epoch 39:  51%|█████     | 78/153 [00:01<00:01, 52.65it/s, Epoch: 39, Batch: 79,Loss: -1.482,Avg.Loss: -1.806,LR: 3.38E-04]Training epoch 39:  52%|█████▏    | 79/153 [00:01<00:01, 52.65it/s, Epoch: 39, Batch: 80,Loss: -1.758,Avg.Loss: -1.805,LR: 3.38E-04]Training epoch 39:  52%|█████▏    | 80/153 [00:01<00:01, 52.65it/s, Epoch: 39, Batch: 81,Loss: -2.483,Avg.Loss: -1.813,LR: 3.38E-04]Training epoch 39:  53%|█████▎    | 81/153 [00:01<00:01, 52.65it/s, Epoch: 39, Batch: 82,Loss: -1.885,Avg.Loss: -1.814,LR: 3.38E-04]Training epoch 39:  54%|█████▎    | 82/153 [00:01<00:01, 52.65it/s, Epoch: 39, Batch: 83,Loss: -1.216,Avg.Loss: -1.807,LR: 3.38E-04]Training epoch 39:  54%|█████▍    | 83/153 [00:01<00:01, 52.65it/s, Epoch: 39, Batch: 84,Loss: -0.980,Avg.Loss: -1.797,LR: 3.38E-04]Training epoch 39:  55%|█████▍    | 84/153 [00:01<00:01, 52.44it/s, Epoch: 39, Batch: 84,Loss: -0.980,Avg.Loss: -1.797,LR: 3.38E-04]Training epoch 39:  55%|█████▍    | 84/153 [00:01<00:01, 52.44it/s, Epoch: 39, Batch: 85,Loss: -1.014,Avg.Loss: -1.788,LR: 3.38E-04]Training epoch 39:  56%|█████▌    | 85/153 [00:01<00:01, 52.44it/s, Epoch: 39, Batch: 86,Loss: -1.913,Avg.Loss: -1.789,LR: 3.38E-04]Training epoch 39:  56%|█████▌    | 86/153 [00:01<00:01, 52.44it/s, Epoch: 39, Batch: 87,Loss: -2.344,Avg.Loss: -1.796,LR: 3.38E-04]Training epoch 39:  57%|█████▋    | 87/153 [00:01<00:01, 52.44it/s, Epoch: 39, Batch: 88,Loss: -2.258,Avg.Loss: -1.801,LR: 3.38E-04]Training epoch 39:  58%|█████▊    | 88/153 [00:01<00:01, 52.44it/s, Epoch: 39, Batch: 89,Loss: -1.943,Avg.Loss: -1.803,LR: 3.38E-04]Training epoch 39:  58%|█████▊    | 89/153 [00:01<00:01, 52.44it/s, Epoch: 39, Batch: 90,Loss: -1.376,Avg.Loss: -1.798,LR: 3.38E-04]Training epoch 39:  59%|█████▉    | 90/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 90,Loss: -1.376,Avg.Loss: -1.798,LR: 3.38E-04]Training epoch 39:  59%|█████▉    | 90/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 91,Loss: -1.855,Avg.Loss: -1.798,LR: 3.38E-04]Training epoch 39:  59%|█████▉    | 91/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 92,Loss: -2.046,Avg.Loss: -1.801,LR: 3.38E-04]Training epoch 39:  60%|██████    | 92/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 93,Loss: -1.784,Avg.Loss: -1.801,LR: 3.38E-04]Training epoch 39:  61%|██████    | 93/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 94,Loss: -1.966,Avg.Loss: -1.803,LR: 3.38E-04]Training epoch 39:  61%|██████▏   | 94/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 95,Loss: -1.873,Avg.Loss: -1.803,LR: 3.37E-04]Training epoch 39:  62%|██████▏   | 95/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 96,Loss: -2.403,Avg.Loss: -1.810,LR: 3.37E-04]Training epoch 39:  63%|██████▎   | 96/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 96,Loss: -2.403,Avg.Loss: -1.810,LR: 3.37E-04]Training epoch 39:  63%|██████▎   | 96/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 97,Loss: -1.524,Avg.Loss: -1.807,LR: 3.37E-04]Training epoch 39:  63%|██████▎   | 97/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 98,Loss: -1.684,Avg.Loss: -1.806,LR: 3.37E-04]Training epoch 39:  64%|██████▍   | 98/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 99,Loss: -2.015,Avg.Loss: -1.808,LR: 3.37E-04]Training epoch 39:  65%|██████▍   | 99/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 100,Loss: -1.945,Avg.Loss: -1.809,LR: 3.37E-04]Training epoch 39:  65%|██████▌   | 100/153 [00:01<00:01, 52.50it/s, Epoch: 39, Batch: 101,Loss: -2.098,Avg.Loss: -1.812,LR: 3.37E-04]Training epoch 39:  66%|██████▌   | 101/153 [00:01<00:00, 52.50it/s, Epoch: 39, Batch: 102,Loss: -2.355,Avg.Loss: -1.817,LR: 3.37E-04]Training epoch 39:  67%|██████▋   | 102/153 [00:01<00:00, 52.57it/s, Epoch: 39, Batch: 102,Loss: -2.355,Avg.Loss: -1.817,LR: 3.37E-04]Training epoch 39:  67%|██████▋   | 102/153 [00:01<00:00, 52.57it/s, Epoch: 39, Batch: 103,Loss: -1.894,Avg.Loss: -1.818,LR: 3.37E-04]Training epoch 39:  67%|██████▋   | 103/153 [00:01<00:00, 52.57it/s, Epoch: 39, Batch: 104,Loss: -1.628,Avg.Loss: -1.816,LR: 3.37E-04]Training epoch 39:  68%|██████▊   | 104/153 [00:01<00:00, 52.57it/s, Epoch: 39, Batch: 105,Loss: -2.451,Avg.Loss: -1.822,LR: 3.37E-04]Training epoch 39:  69%|██████▊   | 105/153 [00:02<00:00, 52.57it/s, Epoch: 39, Batch: 106,Loss: -2.274,Avg.Loss: -1.826,LR: 3.37E-04]Training epoch 39:  69%|██████▉   | 106/153 [00:02<00:00, 52.57it/s, Epoch: 39, Batch: 107,Loss: -1.938,Avg.Loss: -1.827,LR: 3.37E-04]Training epoch 39:  70%|██████▉   | 107/153 [00:02<00:00, 52.57it/s, Epoch: 39, Batch: 108,Loss: -2.420,Avg.Loss: -1.833,LR: 3.37E-04]Training epoch 39:  71%|███████   | 108/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 108,Loss: -2.420,Avg.Loss: -1.833,LR: 3.37E-04]Training epoch 39:  71%|███████   | 108/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 109,Loss: -2.402,Avg.Loss: -1.838,LR: 3.37E-04]Training epoch 39:  71%|███████   | 109/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 110,Loss: -1.570,Avg.Loss: -1.836,LR: 3.37E-04]Training epoch 39:  72%|███████▏  | 110/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 111,Loss: -1.904,Avg.Loss: -1.836,LR: 3.37E-04]Training epoch 39:  73%|███████▎  | 111/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 112,Loss: -2.077,Avg.Loss: -1.839,LR: 3.37E-04]Training epoch 39:  73%|███████▎  | 112/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 113,Loss: -2.127,Avg.Loss: -1.841,LR: 3.37E-04]Training epoch 39:  74%|███████▍  | 113/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 114,Loss: -2.563,Avg.Loss: -1.847,LR: 3.37E-04]Training epoch 39:  75%|███████▍  | 114/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 114,Loss: -2.563,Avg.Loss: -1.847,LR: 3.37E-04]Training epoch 39:  75%|███████▍  | 114/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 115,Loss: -2.332,Avg.Loss: -1.852,LR: 3.37E-04]Training epoch 39:  75%|███████▌  | 115/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 116,Loss: -2.250,Avg.Loss: -1.855,LR: 3.36E-04]Training epoch 39:  76%|███████▌  | 116/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 117,Loss: -2.217,Avg.Loss: -1.858,LR: 3.36E-04]Training epoch 39:  76%|███████▋  | 117/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 118,Loss: -2.389,Avg.Loss: -1.863,LR: 3.36E-04]Training epoch 39:  77%|███████▋  | 118/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 119,Loss: -2.235,Avg.Loss: -1.866,LR: 3.36E-04]Training epoch 39:  78%|███████▊  | 119/153 [00:02<00:00, 52.61it/s, Epoch: 39, Batch: 120,Loss: -2.158,Avg.Loss: -1.868,LR: 3.36E-04]Training epoch 39:  78%|███████▊  | 120/153 [00:02<00:00, 52.64it/s, Epoch: 39, Batch: 120,Loss: -2.158,Avg.Loss: -1.868,LR: 3.36E-04]Training epoch 39:  78%|███████▊  | 120/153 [00:02<00:00, 52.64it/s, Epoch: 39, Batch: 121,Loss: -2.277,Avg.Loss: -1.872,LR: 3.36E-04]Training epoch 39:  79%|███████▉  | 121/153 [00:02<00:00, 52.64it/s, Epoch: 39, Batch: 122,Loss: -2.178,Avg.Loss: -1.874,LR: 3.36E-04]Training epoch 39:  80%|███████▉  | 122/153 [00:02<00:00, 52.64it/s, Epoch: 39, Batch: 123,Loss: -2.457,Avg.Loss: -1.879,LR: 3.36E-04]Training epoch 39:  80%|████████  | 123/153 [00:02<00:00, 52.64it/s, Epoch: 39, Batch: 124,Loss: -2.661,Avg.Loss: -1.885,LR: 3.36E-04]Training epoch 39:  81%|████████  | 124/153 [00:02<00:00, 52.64it/s, Epoch: 39, Batch: 125,Loss: -1.554,Avg.Loss: -1.882,LR: 3.36E-04]Training epoch 39:  82%|████████▏ | 125/153 [00:02<00:00, 52.64it/s, Epoch: 39, Batch: 126,Loss: -2.082,Avg.Loss: -1.884,LR: 3.36E-04]Training epoch 39:  82%|████████▏ | 126/153 [00:02<00:00, 52.79it/s, Epoch: 39, Batch: 126,Loss: -2.082,Avg.Loss: -1.884,LR: 3.36E-04]Training epoch 39:  82%|████████▏ | 126/153 [00:02<00:00, 52.79it/s, Epoch: 39, Batch: 127,Loss: -2.472,Avg.Loss: -1.889,LR: 3.36E-04]Training epoch 39:  83%|████████▎ | 127/153 [00:02<00:00, 52.79it/s, Epoch: 39, Batch: 128,Loss: -1.953,Avg.Loss: -1.889,LR: 3.36E-04]Training epoch 39:  84%|████████▎ | 128/153 [00:02<00:00, 52.79it/s, Epoch: 39, Batch: 129,Loss: -2.972,Avg.Loss: -1.898,LR: 3.36E-04]Training epoch 39:  84%|████████▍ | 129/153 [00:02<00:00, 52.79it/s, Epoch: 39, Batch: 130,Loss: -1.702,Avg.Loss: -1.896,LR: 3.36E-04]Training epoch 39:  85%|████████▍ | 130/153 [00:02<00:00, 52.79it/s, Epoch: 39, Batch: 131,Loss: -1.881,Avg.Loss: -1.896,LR: 3.36E-04]Training epoch 39:  86%|████████▌ | 131/153 [00:02<00:00, 52.79it/s, Epoch: 39, Batch: 132,Loss: -2.291,Avg.Loss: -1.899,LR: 3.36E-04]Training epoch 39:  86%|████████▋ | 132/153 [00:02<00:00, 52.84it/s, Epoch: 39, Batch: 132,Loss: -2.291,Avg.Loss: -1.899,LR: 3.36E-04]Training epoch 39:  86%|████████▋ | 132/153 [00:02<00:00, 52.84it/s, Epoch: 39, Batch: 133,Loss: -2.670,Avg.Loss: -1.905,LR: 3.36E-04]Training epoch 39:  87%|████████▋ | 133/153 [00:02<00:00, 52.84it/s, Epoch: 39, Batch: 134,Loss: -2.542,Avg.Loss: -1.910,LR: 3.36E-04]Training epoch 39:  88%|████████▊ | 134/153 [00:02<00:00, 52.84it/s, Epoch: 39, Batch: 135,Loss: -2.673,Avg.Loss: -1.915,LR: 3.36E-04]Training epoch 39:  88%|████████▊ | 135/153 [00:02<00:00, 52.84it/s, Epoch: 39, Batch: 136,Loss: -2.082,Avg.Loss: -1.916,LR: 3.36E-04]Training epoch 39:  89%|████████▉ | 136/153 [00:02<00:00, 52.84it/s, Epoch: 39, Batch: 137,Loss: -1.920,Avg.Loss: -1.916,LR: 3.35E-04]Training epoch 39:  90%|████████▉ | 137/153 [00:02<00:00, 52.84it/s, Epoch: 39, Batch: 138,Loss: -2.289,Avg.Loss: -1.919,LR: 3.35E-04]Training epoch 39:  90%|█████████ | 138/153 [00:02<00:00, 52.87it/s, Epoch: 39, Batch: 138,Loss: -2.289,Avg.Loss: -1.919,LR: 3.35E-04]Training epoch 39:  90%|█████████ | 138/153 [00:02<00:00, 52.87it/s, Epoch: 39, Batch: 139,Loss: -2.306,Avg.Loss: -1.922,LR: 3.35E-04]Training epoch 39:  91%|█████████ | 139/153 [00:02<00:00, 52.87it/s, Epoch: 39, Batch: 140,Loss: -2.121,Avg.Loss: -1.923,LR: 3.35E-04]Training epoch 39:  92%|█████████▏| 140/153 [00:02<00:00, 52.87it/s, Epoch: 39, Batch: 141,Loss: -2.157,Avg.Loss: -1.925,LR: 3.35E-04]Training epoch 39:  92%|█████████▏| 141/153 [00:02<00:00, 52.87it/s, Epoch: 39, Batch: 142,Loss: -2.375,Avg.Loss: -1.928,LR: 3.35E-04]Training epoch 39:  93%|█████████▎| 142/153 [00:02<00:00, 52.87it/s, Epoch: 39, Batch: 143,Loss: -1.712,Avg.Loss: -1.927,LR: 3.35E-04]Training epoch 39:  93%|█████████▎| 143/153 [00:02<00:00, 52.87it/s, Epoch: 39, Batch: 144,Loss: -2.249,Avg.Loss: -1.929,LR: 3.35E-04]Training epoch 39:  94%|█████████▍| 144/153 [00:02<00:00, 52.97it/s, Epoch: 39, Batch: 144,Loss: -2.249,Avg.Loss: -1.929,LR: 3.35E-04]Training epoch 39:  94%|█████████▍| 144/153 [00:02<00:00, 52.97it/s, Epoch: 39, Batch: 145,Loss: -2.321,Avg.Loss: -1.932,LR: 3.35E-04]Training epoch 39:  95%|█████████▍| 145/153 [00:02<00:00, 52.97it/s, Epoch: 39, Batch: 146,Loss: -2.264,Avg.Loss: -1.934,LR: 3.35E-04]Training epoch 39:  95%|█████████▌| 146/153 [00:02<00:00, 52.97it/s, Epoch: 39, Batch: 147,Loss: -2.330,Avg.Loss: -1.937,LR: 3.35E-04]Training epoch 39:  96%|█████████▌| 147/153 [00:02<00:00, 52.97it/s, Epoch: 39, Batch: 148,Loss: -2.165,Avg.Loss: -1.938,LR: 3.35E-04]Training epoch 39:  97%|█████████▋| 148/153 [00:02<00:00, 52.97it/s, Epoch: 39, Batch: 149,Loss: -2.453,Avg.Loss: -1.942,LR: 3.35E-04]Training epoch 39:  97%|█████████▋| 149/153 [00:02<00:00, 52.97it/s, Epoch: 39, Batch: 150,Loss: -2.531,Avg.Loss: -1.945,LR: 3.35E-04]Training epoch 39:  98%|█████████▊| 150/153 [00:02<00:00, 52.90it/s, Epoch: 39, Batch: 150,Loss: -2.531,Avg.Loss: -1.945,LR: 3.35E-04]Training epoch 39:  98%|█████████▊| 150/153 [00:02<00:00, 52.90it/s, Epoch: 39, Batch: 151,Loss: -2.557,Avg.Loss: -1.950,LR: 3.35E-04]Training epoch 39:  99%|█████████▊| 151/153 [00:02<00:00, 52.90it/s, Epoch: 39, Batch: 152,Loss: -1.576,Avg.Loss: -1.947,LR: 3.35E-04]Training epoch 39:  99%|█████████▉| 152/153 [00:02<00:00, 52.90it/s, Epoch: 39, Batch: 153,Loss: -2.442,Avg.Loss: -1.950,LR: 3.35E-04]Training epoch 39: 100%|██████████| 153/153 [00:02<00:00, 52.79it/s, Epoch: 39, Batch: 153,Loss: -2.442,Avg.Loss: -1.950,LR: 3.35E-04]
Training epoch 40:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 40:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 40, Batch: 1,Loss: -2.313,Avg.Loss: -2.313,LR: 3.35E-04]Training epoch 40:   1%|          | 1/153 [00:00<00:06, 24.14it/s, Epoch: 40, Batch: 2,Loss: -2.591,Avg.Loss: -2.452,LR: 3.35E-04]Training epoch 40:   1%|▏         | 2/153 [00:00<00:04, 33.83it/s, Epoch: 40, Batch: 3,Loss: -2.746,Avg.Loss: -2.550,LR: 3.35E-04]Training epoch 40:   2%|▏         | 3/153 [00:00<00:03, 39.28it/s, Epoch: 40, Batch: 4,Loss: -2.522,Avg.Loss: -2.543,LR: 3.34E-04]Training epoch 40:   3%|▎         | 4/153 [00:00<00:03, 42.29it/s, Epoch: 40, Batch: 5,Loss: -2.231,Avg.Loss: -2.481,LR: 3.34E-04]Training epoch 40:   3%|▎         | 5/153 [00:00<00:03, 44.62it/s, Epoch: 40, Batch: 6,Loss: -2.318,Avg.Loss: -2.454,LR: 3.34E-04]Training epoch 40:   4%|▍         | 6/153 [00:00<00:02, 53.45it/s, Epoch: 40, Batch: 6,Loss: -2.318,Avg.Loss: -2.454,LR: 3.34E-04]Training epoch 40:   4%|▍         | 6/153 [00:00<00:02, 53.45it/s, Epoch: 40, Batch: 7,Loss: -2.306,Avg.Loss: -2.432,LR: 3.34E-04]Training epoch 40:   5%|▍         | 7/153 [00:00<00:02, 53.45it/s, Epoch: 40, Batch: 8,Loss: -1.157,Avg.Loss: -2.273,LR: 3.34E-04]Training epoch 40:   5%|▌         | 8/153 [00:00<00:02, 53.45it/s, Epoch: 40, Batch: 9,Loss: -1.960,Avg.Loss: -2.238,LR: 3.34E-04]Training epoch 40:   6%|▌         | 9/153 [00:00<00:02, 53.45it/s, Epoch: 40, Batch: 10,Loss: -2.328,Avg.Loss: -2.247,LR: 3.34E-04]Training epoch 40:   7%|▋         | 10/153 [00:00<00:02, 53.45it/s, Epoch: 40, Batch: 11,Loss: -1.972,Avg.Loss: -2.222,LR: 3.34E-04]Training epoch 40:   7%|▋         | 11/153 [00:00<00:02, 53.45it/s, Epoch: 40, Batch: 12,Loss: -2.539,Avg.Loss: -2.249,LR: 3.34E-04]Training epoch 40:   8%|▊         | 12/153 [00:00<00:02, 52.41it/s, Epoch: 40, Batch: 12,Loss: -2.539,Avg.Loss: -2.249,LR: 3.34E-04]Training epoch 40:   8%|▊         | 12/153 [00:00<00:02, 52.41it/s, Epoch: 40, Batch: 13,Loss: -2.156,Avg.Loss: -2.241,LR: 3.34E-04]Training epoch 40:   8%|▊         | 13/153 [00:00<00:02, 52.41it/s, Epoch: 40, Batch: 14,Loss: -0.925,Avg.Loss: -2.147,LR: 3.34E-04]Training epoch 40:   9%|▉         | 14/153 [00:00<00:02, 52.41it/s, Epoch: 40, Batch: 15,Loss: -2.212,Avg.Loss: -2.152,LR: 3.34E-04]Training epoch 40:  10%|▉         | 15/153 [00:00<00:02, 52.41it/s, Epoch: 40, Batch: 16,Loss: -2.007,Avg.Loss: -2.143,LR: 3.34E-04]Training epoch 40:  10%|█         | 16/153 [00:00<00:02, 52.41it/s, Epoch: 40, Batch: 17,Loss: -1.808,Avg.Loss: -2.123,LR: 3.34E-04]Training epoch 40:  11%|█         | 17/153 [00:00<00:02, 52.41it/s, Epoch: 40, Batch: 18,Loss: -2.635,Avg.Loss: -2.151,LR: 3.34E-04]Training epoch 40:  12%|█▏        | 18/153 [00:00<00:02, 52.48it/s, Epoch: 40, Batch: 18,Loss: -2.635,Avg.Loss: -2.151,LR: 3.34E-04]Training epoch 40:  12%|█▏        | 18/153 [00:00<00:02, 52.48it/s, Epoch: 40, Batch: 19,Loss: -1.843,Avg.Loss: -2.135,LR: 3.34E-04]Training epoch 40:  12%|█▏        | 19/153 [00:00<00:02, 52.48it/s, Epoch: 40, Batch: 20,Loss: -2.052,Avg.Loss: -2.131,LR: 3.34E-04]Training epoch 40:  13%|█▎        | 20/153 [00:00<00:02, 52.48it/s, Epoch: 40, Batch: 21,Loss: -2.392,Avg.Loss: -2.144,LR: 3.34E-04]Training epoch 40:  14%|█▎        | 21/153 [00:00<00:02, 52.48it/s, Epoch: 40, Batch: 22,Loss: -2.154,Avg.Loss: -2.144,LR: 3.34E-04]Training epoch 40:  14%|█▍        | 22/153 [00:00<00:02, 52.48it/s, Epoch: 40, Batch: 23,Loss: -1.771,Avg.Loss: -2.128,LR: 3.34E-04]Training epoch 40:  15%|█▌        | 23/153 [00:00<00:02, 52.48it/s, Epoch: 40, Batch: 24,Loss: -0.734,Avg.Loss: -2.070,LR: 3.34E-04]Training epoch 40:  16%|█▌        | 24/153 [00:00<00:02, 51.90it/s, Epoch: 40, Batch: 24,Loss: -0.734,Avg.Loss: -2.070,LR: 3.34E-04]Training epoch 40:  16%|█▌        | 24/153 [00:00<00:02, 51.90it/s, Epoch: 40, Batch: 25,Loss: -0.991,Avg.Loss: -2.027,LR: 3.33E-04]Training epoch 40:  16%|█▋        | 25/153 [00:00<00:02, 51.90it/s, Epoch: 40, Batch: 26,Loss: -0.860,Avg.Loss: -1.982,LR: 3.33E-04]Training epoch 40:  17%|█▋        | 26/153 [00:00<00:02, 51.90it/s, Epoch: 40, Batch: 27,Loss: -1.044,Avg.Loss: -1.947,LR: 3.33E-04]Training epoch 40:  18%|█▊        | 27/153 [00:00<00:02, 51.90it/s, Epoch: 40, Batch: 28,Loss: -1.282,Avg.Loss: -1.923,LR: 3.33E-04]Training epoch 40:  18%|█▊        | 28/153 [00:00<00:02, 51.90it/s, Epoch: 40, Batch: 29,Loss: -2.181,Avg.Loss: -1.932,LR: 3.33E-04]Training epoch 40:  19%|█▉        | 29/153 [00:00<00:02, 51.90it/s, Epoch: 40, Batch: 30,Loss: -1.873,Avg.Loss: -1.930,LR: 3.33E-04]Training epoch 40:  20%|█▉        | 30/153 [00:00<00:02, 51.77it/s, Epoch: 40, Batch: 30,Loss: -1.873,Avg.Loss: -1.930,LR: 3.33E-04]Training epoch 40:  20%|█▉        | 30/153 [00:00<00:02, 51.77it/s, Epoch: 40, Batch: 31,Loss: -2.637,Avg.Loss: -1.953,LR: 3.33E-04]Training epoch 40:  20%|██        | 31/153 [00:00<00:02, 51.77it/s, Epoch: 40, Batch: 32,Loss: -2.047,Avg.Loss: -1.956,LR: 3.33E-04]Training epoch 40:  21%|██        | 32/153 [00:00<00:02, 51.77it/s, Epoch: 40, Batch: 33,Loss: -1.328,Avg.Loss: -1.937,LR: 3.33E-04]Training epoch 40:  22%|██▏       | 33/153 [00:00<00:02, 51.77it/s, Epoch: 40, Batch: 34,Loss: -1.551,Avg.Loss: -1.925,LR: 3.33E-04]Training epoch 40:  22%|██▏       | 34/153 [00:00<00:02, 51.77it/s, Epoch: 40, Batch: 35,Loss: -1.667,Avg.Loss: -1.918,LR: 3.33E-04]Training epoch 40:  23%|██▎       | 35/153 [00:00<00:02, 51.77it/s, Epoch: 40, Batch: 36,Loss: -2.414,Avg.Loss: -1.932,LR: 3.33E-04]Training epoch 40:  24%|██▎       | 36/153 [00:00<00:02, 51.87it/s, Epoch: 40, Batch: 36,Loss: -2.414,Avg.Loss: -1.932,LR: 3.33E-04]Training epoch 40:  24%|██▎       | 36/153 [00:00<00:02, 51.87it/s, Epoch: 40, Batch: 37,Loss: -1.928,Avg.Loss: -1.932,LR: 3.33E-04]Training epoch 40:  24%|██▍       | 37/153 [00:00<00:02, 51.87it/s, Epoch: 40, Batch: 38,Loss: -1.261,Avg.Loss: -1.914,LR: 3.33E-04]Training epoch 40:  25%|██▍       | 38/153 [00:00<00:02, 51.87it/s, Epoch: 40, Batch: 39,Loss: -1.669,Avg.Loss: -1.908,LR: 3.33E-04]Training epoch 40:  25%|██▌       | 39/153 [00:00<00:02, 51.87it/s, Epoch: 40, Batch: 40,Loss: -2.493,Avg.Loss: -1.922,LR: 3.33E-04]Training epoch 40:  26%|██▌       | 40/153 [00:00<00:02, 51.87it/s, Epoch: 40, Batch: 41,Loss: -2.206,Avg.Loss: -1.929,LR: 3.33E-04]Training epoch 40:  27%|██▋       | 41/153 [00:00<00:02, 51.87it/s, Epoch: 40, Batch: 42,Loss: -2.262,Avg.Loss: -1.937,LR: 3.33E-04]Training epoch 40:  27%|██▋       | 42/153 [00:00<00:02, 52.02it/s, Epoch: 40, Batch: 42,Loss: -2.262,Avg.Loss: -1.937,LR: 3.33E-04]Training epoch 40:  27%|██▋       | 42/153 [00:00<00:02, 52.02it/s, Epoch: 40, Batch: 43,Loss: -2.549,Avg.Loss: -1.952,LR: 3.33E-04]Training epoch 40:  28%|██▊       | 43/153 [00:00<00:02, 52.02it/s, Epoch: 40, Batch: 44,Loss: -2.637,Avg.Loss: -1.967,LR: 3.33E-04]Training epoch 40:  29%|██▉       | 44/153 [00:00<00:02, 52.02it/s, Epoch: 40, Batch: 45,Loss: -1.734,Avg.Loss: -1.962,LR: 3.33E-04]Training epoch 40:  29%|██▉       | 45/153 [00:00<00:02, 52.02it/s, Epoch: 40, Batch: 46,Loss: -1.508,Avg.Loss: -1.952,LR: 3.32E-04]Training epoch 40:  30%|███       | 46/153 [00:00<00:02, 52.02it/s, Epoch: 40, Batch: 47,Loss: -2.306,Avg.Loss: -1.960,LR: 3.32E-04]Training epoch 40:  31%|███       | 47/153 [00:00<00:02, 52.02it/s, Epoch: 40, Batch: 48,Loss: -1.101,Avg.Loss: -1.942,LR: 3.32E-04]Training epoch 40:  31%|███▏      | 48/153 [00:00<00:02, 52.50it/s, Epoch: 40, Batch: 48,Loss: -1.101,Avg.Loss: -1.942,LR: 3.32E-04]Training epoch 40:  31%|███▏      | 48/153 [00:00<00:02, 52.50it/s, Epoch: 40, Batch: 49,Loss: -1.993,Avg.Loss: -1.943,LR: 3.32E-04]Training epoch 40:  32%|███▏      | 49/153 [00:00<00:01, 52.50it/s, Epoch: 40, Batch: 50,Loss: -1.983,Avg.Loss: -1.944,LR: 3.32E-04]Training epoch 40:  33%|███▎      | 50/153 [00:00<00:01, 52.50it/s, Epoch: 40, Batch: 51,Loss: -2.316,Avg.Loss: -1.951,LR: 3.32E-04]Training epoch 40:  33%|███▎      | 51/153 [00:00<00:01, 52.50it/s, Epoch: 40, Batch: 52,Loss: -2.154,Avg.Loss: -1.955,LR: 3.32E-04]Training epoch 40:  34%|███▍      | 52/153 [00:01<00:01, 52.50it/s, Epoch: 40, Batch: 53,Loss: -2.570,Avg.Loss: -1.966,LR: 3.32E-04]Training epoch 40:  35%|███▍      | 53/153 [00:01<00:01, 52.50it/s, Epoch: 40, Batch: 54,Loss: -1.950,Avg.Loss: -1.966,LR: 3.32E-04]Training epoch 40:  35%|███▌      | 54/153 [00:01<00:01, 52.75it/s, Epoch: 40, Batch: 54,Loss: -1.950,Avg.Loss: -1.966,LR: 3.32E-04]Training epoch 40:  35%|███▌      | 54/153 [00:01<00:01, 52.75it/s, Epoch: 40, Batch: 55,Loss: -1.983,Avg.Loss: -1.966,LR: 3.32E-04]Training epoch 40:  36%|███▌      | 55/153 [00:01<00:01, 52.75it/s, Epoch: 40, Batch: 56,Loss: -2.305,Avg.Loss: -1.972,LR: 3.32E-04]Training epoch 40:  37%|███▋      | 56/153 [00:01<00:01, 52.75it/s, Epoch: 40, Batch: 57,Loss: -1.666,Avg.Loss: -1.967,LR: 3.32E-04]Training epoch 40:  37%|███▋      | 57/153 [00:01<00:01, 52.75it/s, Epoch: 40, Batch: 58,Loss: -1.491,Avg.Loss: -1.959,LR: 3.32E-04]Training epoch 40:  38%|███▊      | 58/153 [00:01<00:01, 52.75it/s, Epoch: 40, Batch: 59,Loss: -2.184,Avg.Loss: -1.963,LR: 3.32E-04]Training epoch 40:  39%|███▊      | 59/153 [00:01<00:01, 52.75it/s, Epoch: 40, Batch: 60,Loss: -2.373,Avg.Loss: -1.969,LR: 3.32E-04]Training epoch 40:  39%|███▉      | 60/153 [00:01<00:01, 52.97it/s, Epoch: 40, Batch: 60,Loss: -2.373,Avg.Loss: -1.969,LR: 3.32E-04]Training epoch 40:  39%|███▉      | 60/153 [00:01<00:01, 52.97it/s, Epoch: 40, Batch: 61,Loss: -2.100,Avg.Loss: -1.972,LR: 3.32E-04]Training epoch 40:  40%|███▉      | 61/153 [00:01<00:01, 52.97it/s, Epoch: 40, Batch: 62,Loss: -1.796,Avg.Loss: -1.969,LR: 3.32E-04]Training epoch 40:  41%|████      | 62/153 [00:01<00:01, 52.97it/s, Epoch: 40, Batch: 63,Loss: -2.109,Avg.Loss: -1.971,LR: 3.32E-04]Training epoch 40:  41%|████      | 63/153 [00:01<00:01, 52.97it/s, Epoch: 40, Batch: 64,Loss: -2.197,Avg.Loss: -1.975,LR: 3.32E-04]Training epoch 40:  42%|████▏     | 64/153 [00:01<00:01, 52.97it/s, Epoch: 40, Batch: 65,Loss: -2.367,Avg.Loss: -1.981,LR: 3.32E-04]Training epoch 40:  42%|████▏     | 65/153 [00:01<00:01, 52.97it/s, Epoch: 40, Batch: 66,Loss: -2.214,Avg.Loss: -1.984,LR: 3.31E-04]Training epoch 40:  43%|████▎     | 66/153 [00:01<00:01, 53.05it/s, Epoch: 40, Batch: 66,Loss: -2.214,Avg.Loss: -1.984,LR: 3.31E-04]Training epoch 40:  43%|████▎     | 66/153 [00:01<00:01, 53.05it/s, Epoch: 40, Batch: 67,Loss: -1.844,Avg.Loss: -1.982,LR: 3.31E-04]Training epoch 40:  44%|████▍     | 67/153 [00:01<00:01, 53.05it/s, Epoch: 40, Batch: 68,Loss: -2.324,Avg.Loss: -1.987,LR: 3.31E-04]Training epoch 40:  44%|████▍     | 68/153 [00:01<00:01, 53.05it/s, Epoch: 40, Batch: 69,Loss: -2.242,Avg.Loss: -1.991,LR: 3.31E-04]Training epoch 40:  45%|████▌     | 69/153 [00:01<00:01, 53.05it/s, Epoch: 40, Batch: 70,Loss: -2.506,Avg.Loss: -1.998,LR: 3.31E-04]Training epoch 40:  46%|████▌     | 70/153 [00:01<00:01, 53.05it/s, Epoch: 40, Batch: 71,Loss: -1.982,Avg.Loss: -1.998,LR: 3.31E-04]Training epoch 40:  46%|████▋     | 71/153 [00:01<00:01, 53.05it/s, Epoch: 40, Batch: 72,Loss: -2.131,Avg.Loss: -2.000,LR: 3.31E-04]Training epoch 40:  47%|████▋     | 72/153 [00:01<00:01, 53.16it/s, Epoch: 40, Batch: 72,Loss: -2.131,Avg.Loss: -2.000,LR: 3.31E-04]Training epoch 40:  47%|████▋     | 72/153 [00:01<00:01, 53.16it/s, Epoch: 40, Batch: 73,Loss: -2.142,Avg.Loss: -2.002,LR: 3.31E-04]Training epoch 40:  48%|████▊     | 73/153 [00:01<00:01, 53.16it/s, Epoch: 40, Batch: 74,Loss: -2.169,Avg.Loss: -2.004,LR: 3.31E-04]Training epoch 40:  48%|████▊     | 74/153 [00:01<00:01, 53.16it/s, Epoch: 40, Batch: 75,Loss: -2.246,Avg.Loss: -2.007,LR: 3.31E-04]Training epoch 40:  49%|████▉     | 75/153 [00:01<00:01, 53.16it/s, Epoch: 40, Batch: 76,Loss: -1.498,Avg.Loss: -2.000,LR: 3.31E-04]Training epoch 40:  50%|████▉     | 76/153 [00:01<00:01, 53.16it/s, Epoch: 40, Batch: 77,Loss: -1.289,Avg.Loss: -1.991,LR: 3.31E-04]Training epoch 40:  50%|█████     | 77/153 [00:01<00:01, 53.16it/s, Epoch: 40, Batch: 78,Loss: -1.888,Avg.Loss: -1.990,LR: 3.31E-04]Training epoch 40:  51%|█████     | 78/153 [00:01<00:01, 53.27it/s, Epoch: 40, Batch: 78,Loss: -1.888,Avg.Loss: -1.990,LR: 3.31E-04]Training epoch 40:  51%|█████     | 78/153 [00:01<00:01, 53.27it/s, Epoch: 40, Batch: 79,Loss: -2.058,Avg.Loss: -1.991,LR: 3.31E-04]Training epoch 40:  52%|█████▏    | 79/153 [00:01<00:01, 53.27it/s, Epoch: 40, Batch: 80,Loss: -1.867,Avg.Loss: -1.989,LR: 3.31E-04]Training epoch 40:  52%|█████▏    | 80/153 [00:01<00:01, 53.27it/s, Epoch: 40, Batch: 81,Loss: -2.338,Avg.Loss: -1.994,LR: 3.31E-04]Training epoch 40:  53%|█████▎    | 81/153 [00:01<00:01, 53.27it/s, Epoch: 40, Batch: 82,Loss: -2.097,Avg.Loss: -1.995,LR: 3.31E-04]Training epoch 40:  54%|█████▎    | 82/153 [00:01<00:01, 53.27it/s, Epoch: 40, Batch: 83,Loss: -2.420,Avg.Loss: -2.000,LR: 3.31E-04]Training epoch 40:  54%|█████▍    | 83/153 [00:01<00:01, 53.27it/s, Epoch: 40, Batch: 84,Loss: -1.974,Avg.Loss: -2.000,LR: 3.31E-04]Training epoch 40:  55%|█████▍    | 84/153 [00:01<00:01, 53.17it/s, Epoch: 40, Batch: 84,Loss: -1.974,Avg.Loss: -2.000,LR: 3.31E-04]Training epoch 40:  55%|█████▍    | 84/153 [00:01<00:01, 53.17it/s, Epoch: 40, Batch: 85,Loss: -2.451,Avg.Loss: -2.005,LR: 3.31E-04]Training epoch 40:  56%|█████▌    | 85/153 [00:01<00:01, 53.17it/s, Epoch: 40, Batch: 86,Loss: -2.301,Avg.Loss: -2.008,LR: 3.31E-04]Training epoch 40:  56%|█████▌    | 86/153 [00:01<00:01, 53.17it/s, Epoch: 40, Batch: 87,Loss: -1.984,Avg.Loss: -2.008,LR: 3.30E-04]Training epoch 40:  57%|█████▋    | 87/153 [00:01<00:01, 53.17it/s, Epoch: 40, Batch: 88,Loss: -2.403,Avg.Loss: -2.013,LR: 3.30E-04]Training epoch 40:  58%|█████▊    | 88/153 [00:01<00:01, 53.17it/s, Epoch: 40, Batch: 89,Loss: -1.764,Avg.Loss: -2.010,LR: 3.30E-04]Training epoch 40:  58%|█████▊    | 89/153 [00:01<00:01, 53.17it/s, Epoch: 40, Batch: 90,Loss: -0.812,Avg.Loss: -1.996,LR: 3.30E-04]Training epoch 40:  59%|█████▉    | 90/153 [00:01<00:01, 53.22it/s, Epoch: 40, Batch: 90,Loss: -0.812,Avg.Loss: -1.996,LR: 3.30E-04]Training epoch 40:  59%|█████▉    | 90/153 [00:01<00:01, 53.22it/s, Epoch: 40, Batch: 91,Loss: -1.236,Avg.Loss: -1.988,LR: 3.30E-04]Training epoch 40:  59%|█████▉    | 91/153 [00:01<00:01, 53.22it/s, Epoch: 40, Batch: 92,Loss: -1.653,Avg.Loss: -1.984,LR: 3.30E-04]Training epoch 40:  60%|██████    | 92/153 [00:01<00:01, 53.22it/s, Epoch: 40, Batch: 93,Loss: -1.669,Avg.Loss: -1.981,LR: 3.30E-04]Training epoch 40:  61%|██████    | 93/153 [00:01<00:01, 53.22it/s, Epoch: 40, Batch: 94,Loss: -2.024,Avg.Loss: -1.982,LR: 3.30E-04]Training epoch 40:  61%|██████▏   | 94/153 [00:01<00:01, 53.22it/s, Epoch: 40, Batch: 95,Loss: -0.965,Avg.Loss: -1.971,LR: 3.30E-04]Training epoch 40:  62%|██████▏   | 95/153 [00:01<00:01, 53.22it/s, Epoch: 40, Batch: 96,Loss: -0.526,Avg.Loss: -1.956,LR: 3.30E-04]Training epoch 40:  63%|██████▎   | 96/153 [00:01<00:01, 53.02it/s, Epoch: 40, Batch: 96,Loss: -0.526,Avg.Loss: -1.956,LR: 3.30E-04]Training epoch 40:  63%|██████▎   | 96/153 [00:01<00:01, 53.02it/s, Epoch: 40, Batch: 97,Loss: -1.266,Avg.Loss: -1.949,LR: 3.30E-04]Training epoch 40:  63%|██████▎   | 97/153 [00:01<00:01, 53.02it/s, Epoch: 40, Batch: 98,Loss: -1.090,Avg.Loss: -1.940,LR: 3.30E-04]Training epoch 40:  64%|██████▍   | 98/153 [00:01<00:01, 53.02it/s, Epoch: 40, Batch: 99,Loss: -0.959,Avg.Loss: -1.930,LR: 3.30E-04]Training epoch 40:  65%|██████▍   | 99/153 [00:01<00:01, 53.02it/s, Epoch: 40, Batch: 100,Loss: -2.466,Avg.Loss: -1.935,LR: 3.30E-04]Training epoch 40:  65%|██████▌   | 100/153 [00:01<00:00, 53.02it/s, Epoch: 40, Batch: 101,Loss: -2.437,Avg.Loss: -1.940,LR: 3.30E-04]Training epoch 40:  66%|██████▌   | 101/153 [00:01<00:00, 53.02it/s, Epoch: 40, Batch: 102,Loss: -2.101,Avg.Loss: -1.942,LR: 3.30E-04]Training epoch 40:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 40, Batch: 102,Loss: -2.101,Avg.Loss: -1.942,LR: 3.30E-04]Training epoch 40:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 40, Batch: 103,Loss: -1.881,Avg.Loss: -1.941,LR: 3.30E-04]Training epoch 40:  67%|██████▋   | 103/153 [00:01<00:00, 53.09it/s, Epoch: 40, Batch: 104,Loss: -1.554,Avg.Loss: -1.938,LR: 3.30E-04]Training epoch 40:  68%|██████▊   | 104/153 [00:01<00:00, 53.09it/s, Epoch: 40, Batch: 105,Loss: -1.397,Avg.Loss: -1.932,LR: 3.30E-04]Training epoch 40:  69%|██████▊   | 105/153 [00:02<00:00, 53.09it/s, Epoch: 40, Batch: 106,Loss: -1.864,Avg.Loss: -1.932,LR: 3.30E-04]Training epoch 40:  69%|██████▉   | 106/153 [00:02<00:00, 53.09it/s, Epoch: 40, Batch: 107,Loss: -1.968,Avg.Loss: -1.932,LR: 3.29E-04]Training epoch 40:  70%|██████▉   | 107/153 [00:02<00:00, 53.09it/s, Epoch: 40, Batch: 108,Loss: -1.424,Avg.Loss: -1.927,LR: 3.29E-04]Training epoch 40:  71%|███████   | 108/153 [00:02<00:00, 52.94it/s, Epoch: 40, Batch: 108,Loss: -1.424,Avg.Loss: -1.927,LR: 3.29E-04]Training epoch 40:  71%|███████   | 108/153 [00:02<00:00, 52.94it/s, Epoch: 40, Batch: 109,Loss: -1.987,Avg.Loss: -1.928,LR: 3.29E-04]Training epoch 40:  71%|███████   | 109/153 [00:02<00:00, 52.94it/s, Epoch: 40, Batch: 110,Loss: -1.702,Avg.Loss: -1.926,LR: 3.29E-04]Training epoch 40:  72%|███████▏  | 110/153 [00:02<00:00, 52.94it/s, Epoch: 40, Batch: 111,Loss: -1.545,Avg.Loss: -1.922,LR: 3.29E-04]Training epoch 40:  73%|███████▎  | 111/153 [00:02<00:00, 52.94it/s, Epoch: 40, Batch: 112,Loss: -2.062,Avg.Loss: -1.924,LR: 3.29E-04]Training epoch 40:  73%|███████▎  | 112/153 [00:02<00:00, 52.94it/s, Epoch: 40, Batch: 113,Loss: -2.216,Avg.Loss: -1.926,LR: 3.29E-04]Training epoch 40:  74%|███████▍  | 113/153 [00:02<00:00, 52.94it/s, Epoch: 40, Batch: 114,Loss: -2.147,Avg.Loss: -1.928,LR: 3.29E-04]Training epoch 40:  75%|███████▍  | 114/153 [00:02<00:00, 52.27it/s, Epoch: 40, Batch: 114,Loss: -2.147,Avg.Loss: -1.928,LR: 3.29E-04]Training epoch 40:  75%|███████▍  | 114/153 [00:02<00:00, 52.27it/s, Epoch: 40, Batch: 115,Loss: -2.957,Avg.Loss: -1.937,LR: 3.29E-04]Training epoch 40:  75%|███████▌  | 115/153 [00:02<00:00, 52.27it/s, Epoch: 40, Batch: 116,Loss: -1.962,Avg.Loss: -1.937,LR: 3.29E-04]Training epoch 40:  76%|███████▌  | 116/153 [00:02<00:00, 52.27it/s, Epoch: 40, Batch: 117,Loss: -1.113,Avg.Loss: -1.930,LR: 3.29E-04]Training epoch 40:  76%|███████▋  | 117/153 [00:02<00:00, 52.27it/s, Epoch: 40, Batch: 118,Loss: -1.541,Avg.Loss: -1.927,LR: 3.29E-04]Training epoch 40:  77%|███████▋  | 118/153 [00:02<00:00, 52.27it/s, Epoch: 40, Batch: 119,Loss: -2.443,Avg.Loss: -1.931,LR: 3.29E-04]Training epoch 40:  78%|███████▊  | 119/153 [00:02<00:00, 52.27it/s, Epoch: 40, Batch: 120,Loss: -2.181,Avg.Loss: -1.933,LR: 3.29E-04]Training epoch 40:  78%|███████▊  | 120/153 [00:02<00:00, 51.63it/s, Epoch: 40, Batch: 120,Loss: -2.181,Avg.Loss: -1.933,LR: 3.29E-04]Training epoch 40:  78%|███████▊  | 120/153 [00:02<00:00, 51.63it/s, Epoch: 40, Batch: 121,Loss: -2.164,Avg.Loss: -1.935,LR: 3.29E-04]Training epoch 40:  79%|███████▉  | 121/153 [00:02<00:00, 51.63it/s, Epoch: 40, Batch: 122,Loss: -2.312,Avg.Loss: -1.938,LR: 3.29E-04]Training epoch 40:  80%|███████▉  | 122/153 [00:02<00:00, 51.63it/s, Epoch: 40, Batch: 123,Loss: -1.760,Avg.Loss: -1.937,LR: 3.29E-04]Training epoch 40:  80%|████████  | 123/153 [00:02<00:00, 51.63it/s, Epoch: 40, Batch: 124,Loss: -2.394,Avg.Loss: -1.941,LR: 3.29E-04]Training epoch 40:  81%|████████  | 124/153 [00:02<00:00, 51.63it/s, Epoch: 40, Batch: 125,Loss: -2.004,Avg.Loss: -1.941,LR: 3.29E-04]Training epoch 40:  82%|████████▏ | 125/153 [00:02<00:00, 51.63it/s, Epoch: 40, Batch: 126,Loss: -1.889,Avg.Loss: -1.941,LR: 3.29E-04]Training epoch 40:  82%|████████▏ | 126/153 [00:02<00:00, 52.00it/s, Epoch: 40, Batch: 126,Loss: -1.889,Avg.Loss: -1.941,LR: 3.29E-04]Training epoch 40:  82%|████████▏ | 126/153 [00:02<00:00, 52.00it/s, Epoch: 40, Batch: 127,Loss: -2.588,Avg.Loss: -1.946,LR: 3.29E-04]Training epoch 40:  83%|████████▎ | 127/153 [00:02<00:00, 52.00it/s, Epoch: 40, Batch: 128,Loss: -2.377,Avg.Loss: -1.949,LR: 3.28E-04]Training epoch 40:  84%|████████▎ | 128/153 [00:02<00:00, 52.00it/s, Epoch: 40, Batch: 129,Loss: -1.977,Avg.Loss: -1.949,LR: 3.28E-04]Training epoch 40:  84%|████████▍ | 129/153 [00:02<00:00, 52.00it/s, Epoch: 40, Batch: 130,Loss: -1.902,Avg.Loss: -1.949,LR: 3.28E-04]Training epoch 40:  85%|████████▍ | 130/153 [00:02<00:00, 52.00it/s, Epoch: 40, Batch: 131,Loss: -2.330,Avg.Loss: -1.952,LR: 3.28E-04]Training epoch 40:  86%|████████▌ | 131/153 [00:02<00:00, 52.00it/s, Epoch: 40, Batch: 132,Loss: -1.729,Avg.Loss: -1.950,LR: 3.28E-04]Training epoch 40:  86%|████████▋ | 132/153 [00:02<00:00, 52.24it/s, Epoch: 40, Batch: 132,Loss: -1.729,Avg.Loss: -1.950,LR: 3.28E-04]Training epoch 40:  86%|████████▋ | 132/153 [00:02<00:00, 52.24it/s, Epoch: 40, Batch: 133,Loss: -1.955,Avg.Loss: -1.950,LR: 3.28E-04]Training epoch 40:  87%|████████▋ | 133/153 [00:02<00:00, 52.24it/s, Epoch: 40, Batch: 134,Loss: -1.967,Avg.Loss: -1.950,LR: 3.28E-04]Training epoch 40:  88%|████████▊ | 134/153 [00:02<00:00, 52.24it/s, Epoch: 40, Batch: 135,Loss: -2.255,Avg.Loss: -1.953,LR: 3.28E-04]Training epoch 40:  88%|████████▊ | 135/153 [00:02<00:00, 52.24it/s, Epoch: 40, Batch: 136,Loss: -2.336,Avg.Loss: -1.956,LR: 3.28E-04]Training epoch 40:  89%|████████▉ | 136/153 [00:02<00:00, 52.24it/s, Epoch: 40, Batch: 137,Loss: -1.919,Avg.Loss: -1.955,LR: 3.28E-04]Training epoch 40:  90%|████████▉ | 137/153 [00:02<00:00, 52.24it/s, Epoch: 40, Batch: 138,Loss: -1.374,Avg.Loss: -1.951,LR: 3.28E-04]Training epoch 40:  90%|█████████ | 138/153 [00:02<00:00, 52.47it/s, Epoch: 40, Batch: 138,Loss: -1.374,Avg.Loss: -1.951,LR: 3.28E-04]Training epoch 40:  90%|█████████ | 138/153 [00:02<00:00, 52.47it/s, Epoch: 40, Batch: 139,Loss: -1.706,Avg.Loss: -1.949,LR: 3.28E-04]Training epoch 40:  91%|█████████ | 139/153 [00:02<00:00, 52.47it/s, Epoch: 40, Batch: 140,Loss: -2.584,Avg.Loss: -1.954,LR: 3.28E-04]Training epoch 40:  92%|█████████▏| 140/153 [00:02<00:00, 52.47it/s, Epoch: 40, Batch: 141,Loss: -1.958,Avg.Loss: -1.954,LR: 3.28E-04]Training epoch 40:  92%|█████████▏| 141/153 [00:02<00:00, 52.47it/s, Epoch: 40, Batch: 142,Loss: -1.129,Avg.Loss: -1.948,LR: 3.28E-04]Training epoch 40:  93%|█████████▎| 142/153 [00:02<00:00, 52.47it/s, Epoch: 40, Batch: 143,Loss: -0.879,Avg.Loss: -1.941,LR: 3.28E-04]Training epoch 40:  93%|█████████▎| 143/153 [00:02<00:00, 52.47it/s, Epoch: 40, Batch: 144,Loss: -1.687,Avg.Loss: -1.939,LR: 3.28E-04]Training epoch 40:  94%|█████████▍| 144/153 [00:02<00:00, 52.68it/s, Epoch: 40, Batch: 144,Loss: -1.687,Avg.Loss: -1.939,LR: 3.28E-04]Training epoch 40:  94%|█████████▍| 144/153 [00:02<00:00, 52.68it/s, Epoch: 40, Batch: 145,Loss: -1.813,Avg.Loss: -1.938,LR: 3.28E-04]Training epoch 40:  95%|█████████▍| 145/153 [00:02<00:00, 52.68it/s, Epoch: 40, Batch: 146,Loss: -1.807,Avg.Loss: -1.937,LR: 3.28E-04]Training epoch 40:  95%|█████████▌| 146/153 [00:02<00:00, 52.68it/s, Epoch: 40, Batch: 147,Loss: -2.400,Avg.Loss: -1.940,LR: 3.28E-04]Training epoch 40:  96%|█████████▌| 147/153 [00:02<00:00, 52.68it/s, Epoch: 40, Batch: 148,Loss: -1.986,Avg.Loss: -1.941,LR: 3.27E-04]Training epoch 40:  97%|█████████▋| 148/153 [00:02<00:00, 52.68it/s, Epoch: 40, Batch: 149,Loss: -2.344,Avg.Loss: -1.943,LR: 3.27E-04]Training epoch 40:  97%|█████████▋| 149/153 [00:02<00:00, 52.68it/s, Epoch: 40, Batch: 150,Loss: -2.394,Avg.Loss: -1.946,LR: 3.27E-04]Training epoch 40:  98%|█████████▊| 150/153 [00:02<00:00, 52.67it/s, Epoch: 40, Batch: 150,Loss: -2.394,Avg.Loss: -1.946,LR: 3.27E-04]Training epoch 40:  98%|█████████▊| 150/153 [00:02<00:00, 52.67it/s, Epoch: 40, Batch: 151,Loss: -2.248,Avg.Loss: -1.948,LR: 3.27E-04]Training epoch 40:  99%|█████████▊| 151/153 [00:02<00:00, 52.67it/s, Epoch: 40, Batch: 152,Loss: -2.201,Avg.Loss: -1.950,LR: 3.27E-04]Training epoch 40:  99%|█████████▉| 152/153 [00:02<00:00, 52.67it/s, Epoch: 40, Batch: 153,Loss: -2.125,Avg.Loss: -1.951,LR: 3.27E-04]Training epoch 40: 100%|██████████| 153/153 [00:02<00:00, 52.55it/s, Epoch: 40, Batch: 153,Loss: -2.125,Avg.Loss: -1.951,LR: 3.27E-04]
Training epoch 41:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 41:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 41, Batch: 1,Loss: -0.746,Avg.Loss: -0.746,LR: 3.27E-04]Training epoch 41:   1%|          | 1/153 [00:00<00:05, 26.08it/s, Epoch: 41, Batch: 2,Loss: -1.840,Avg.Loss: -1.293,LR: 3.27E-04]Training epoch 41:   1%|▏         | 2/153 [00:00<00:04, 35.62it/s, Epoch: 41, Batch: 3,Loss: -2.102,Avg.Loss: -1.562,LR: 3.27E-04]Training epoch 41:   2%|▏         | 3/153 [00:00<00:03, 40.80it/s, Epoch: 41, Batch: 4,Loss: -2.186,Avg.Loss: -1.718,LR: 3.27E-04]Training epoch 41:   3%|▎         | 4/153 [00:00<00:03, 43.40it/s, Epoch: 41, Batch: 5,Loss: -1.885,Avg.Loss: -1.752,LR: 3.27E-04]Training epoch 41:   3%|▎         | 5/153 [00:00<00:03, 44.98it/s, Epoch: 41, Batch: 6,Loss: -1.788,Avg.Loss: -1.758,LR: 3.27E-04]Training epoch 41:   4%|▍         | 6/153 [00:00<00:02, 53.89it/s, Epoch: 41, Batch: 6,Loss: -1.788,Avg.Loss: -1.758,LR: 3.27E-04]Training epoch 41:   4%|▍         | 6/153 [00:00<00:02, 53.89it/s, Epoch: 41, Batch: 7,Loss: -2.517,Avg.Loss: -1.866,LR: 3.27E-04]Training epoch 41:   5%|▍         | 7/153 [00:00<00:02, 53.89it/s, Epoch: 41, Batch: 8,Loss: -2.574,Avg.Loss: -1.955,LR: 3.27E-04]Training epoch 41:   5%|▌         | 8/153 [00:00<00:02, 53.89it/s, Epoch: 41, Batch: 9,Loss: -2.277,Avg.Loss: -1.990,LR: 3.27E-04]Training epoch 41:   6%|▌         | 9/153 [00:00<00:02, 53.89it/s, Epoch: 41, Batch: 10,Loss: -2.499,Avg.Loss: -2.041,LR: 3.27E-04]Training epoch 41:   7%|▋         | 10/153 [00:00<00:02, 53.89it/s, Epoch: 41, Batch: 11,Loss: -2.141,Avg.Loss: -2.050,LR: 3.27E-04]Training epoch 41:   7%|▋         | 11/153 [00:00<00:02, 53.89it/s, Epoch: 41, Batch: 12,Loss: -2.265,Avg.Loss: -2.068,LR: 3.27E-04]Training epoch 41:   8%|▊         | 12/153 [00:00<00:02, 53.62it/s, Epoch: 41, Batch: 12,Loss: -2.265,Avg.Loss: -2.068,LR: 3.27E-04]Training epoch 41:   8%|▊         | 12/153 [00:00<00:02, 53.62it/s, Epoch: 41, Batch: 13,Loss: -2.375,Avg.Loss: -2.092,LR: 3.27E-04]Training epoch 41:   8%|▊         | 13/153 [00:00<00:02, 53.62it/s, Epoch: 41, Batch: 14,Loss: -2.156,Avg.Loss: -2.096,LR: 3.27E-04]Training epoch 41:   9%|▉         | 14/153 [00:00<00:02, 53.62it/s, Epoch: 41, Batch: 15,Loss: -2.673,Avg.Loss: -2.135,LR: 3.27E-04]Training epoch 41:  10%|▉         | 15/153 [00:00<00:02, 53.62it/s, Epoch: 41, Batch: 16,Loss: -1.732,Avg.Loss: -2.110,LR: 3.26E-04]Training epoch 41:  10%|█         | 16/153 [00:00<00:02, 53.62it/s, Epoch: 41, Batch: 17,Loss: -2.017,Avg.Loss: -2.104,LR: 3.26E-04]Training epoch 41:  11%|█         | 17/153 [00:00<00:02, 53.62it/s, Epoch: 41, Batch: 18,Loss: -2.644,Avg.Loss: -2.134,LR: 3.26E-04]Training epoch 41:  12%|█▏        | 18/153 [00:00<00:02, 53.34it/s, Epoch: 41, Batch: 18,Loss: -2.644,Avg.Loss: -2.134,LR: 3.26E-04]Training epoch 41:  12%|█▏        | 18/153 [00:00<00:02, 53.34it/s, Epoch: 41, Batch: 19,Loss: -2.601,Avg.Loss: -2.159,LR: 3.26E-04]Training epoch 41:  12%|█▏        | 19/153 [00:00<00:02, 53.34it/s, Epoch: 41, Batch: 20,Loss: -1.529,Avg.Loss: -2.127,LR: 3.26E-04]Training epoch 41:  13%|█▎        | 20/153 [00:00<00:02, 53.34it/s, Epoch: 41, Batch: 21,Loss: -1.592,Avg.Loss: -2.102,LR: 3.26E-04]Training epoch 41:  14%|█▎        | 21/153 [00:00<00:02, 53.34it/s, Epoch: 41, Batch: 22,Loss: -0.925,Avg.Loss: -2.048,LR: 3.26E-04]Training epoch 41:  14%|█▍        | 22/153 [00:00<00:02, 53.34it/s, Epoch: 41, Batch: 23,Loss: -2.498,Avg.Loss: -2.068,LR: 3.26E-04]Training epoch 41:  15%|█▌        | 23/153 [00:00<00:02, 53.34it/s, Epoch: 41, Batch: 24,Loss: -1.744,Avg.Loss: -2.054,LR: 3.26E-04]Training epoch 41:  16%|█▌        | 24/153 [00:00<00:02, 52.41it/s, Epoch: 41, Batch: 24,Loss: -1.744,Avg.Loss: -2.054,LR: 3.26E-04]Training epoch 41:  16%|█▌        | 24/153 [00:00<00:02, 52.41it/s, Epoch: 41, Batch: 25,Loss: -0.828,Avg.Loss: -2.005,LR: 3.26E-04]Training epoch 41:  16%|█▋        | 25/153 [00:00<00:02, 52.41it/s, Epoch: 41, Batch: 26,Loss: -1.416,Avg.Loss: -1.983,LR: 3.26E-04]Training epoch 41:  17%|█▋        | 26/153 [00:00<00:02, 52.41it/s, Epoch: 41, Batch: 27,Loss: -1.519,Avg.Loss: -1.966,LR: 3.26E-04]Training epoch 41:  18%|█▊        | 27/153 [00:00<00:02, 52.41it/s, Epoch: 41, Batch: 28,Loss: -1.732,Avg.Loss: -1.957,LR: 3.26E-04]Training epoch 41:  18%|█▊        | 28/153 [00:00<00:02, 52.41it/s, Epoch: 41, Batch: 29,Loss: -1.701,Avg.Loss: -1.948,LR: 3.26E-04]Training epoch 41:  19%|█▉        | 29/153 [00:00<00:02, 52.41it/s, Epoch: 41, Batch: 30,Loss: -2.152,Avg.Loss: -1.955,LR: 3.26E-04]Training epoch 41:  20%|█▉        | 30/153 [00:00<00:02, 52.01it/s, Epoch: 41, Batch: 30,Loss: -2.152,Avg.Loss: -1.955,LR: 3.26E-04]Training epoch 41:  20%|█▉        | 30/153 [00:00<00:02, 52.01it/s, Epoch: 41, Batch: 31,Loss: -1.706,Avg.Loss: -1.947,LR: 3.26E-04]Training epoch 41:  20%|██        | 31/153 [00:00<00:02, 52.01it/s, Epoch: 41, Batch: 32,Loss: -0.797,Avg.Loss: -1.911,LR: 3.26E-04]Training epoch 41:  21%|██        | 32/153 [00:00<00:02, 52.01it/s, Epoch: 41, Batch: 33,Loss: -0.801,Avg.Loss: -1.877,LR: 3.26E-04]Training epoch 41:  22%|██▏       | 33/153 [00:00<00:02, 52.01it/s, Epoch: 41, Batch: 34,Loss: -1.988,Avg.Loss: -1.881,LR: 3.26E-04]Training epoch 41:  22%|██▏       | 34/153 [00:00<00:02, 52.01it/s, Epoch: 41, Batch: 35,Loss: -0.685,Avg.Loss: -1.847,LR: 3.26E-04]Training epoch 41:  23%|██▎       | 35/153 [00:00<00:02, 52.01it/s, Epoch: 41, Batch: 36,Loss: 0.157,Avg.Loss: -1.791,LR: 3.25E-04] Training epoch 41:  24%|██▎       | 36/153 [00:00<00:02, 51.87it/s, Epoch: 41, Batch: 36,Loss: 0.157,Avg.Loss: -1.791,LR: 3.25E-04]Training epoch 41:  24%|██▎       | 36/153 [00:00<00:02, 51.87it/s, Epoch: 41, Batch: 37,Loss: 0.546,Avg.Loss: -1.728,LR: 3.25E-04]Training epoch 41:  24%|██▍       | 37/153 [00:00<00:02, 51.87it/s, Epoch: 41, Batch: 38,Loss: -1.059,Avg.Loss: -1.710,LR: 3.25E-04]Training epoch 41:  25%|██▍       | 38/153 [00:00<00:02, 51.87it/s, Epoch: 41, Batch: 39,Loss: -1.978,Avg.Loss: -1.717,LR: 3.25E-04]Training epoch 41:  25%|██▌       | 39/153 [00:00<00:02, 51.87it/s, Epoch: 41, Batch: 40,Loss: -1.559,Avg.Loss: -1.713,LR: 3.25E-04]Training epoch 41:  26%|██▌       | 40/153 [00:00<00:02, 51.87it/s, Epoch: 41, Batch: 41,Loss: -2.230,Avg.Loss: -1.726,LR: 3.25E-04]Training epoch 41:  27%|██▋       | 41/153 [00:00<00:02, 51.87it/s, Epoch: 41, Batch: 42,Loss: -2.296,Avg.Loss: -1.739,LR: 3.25E-04]Training epoch 41:  27%|██▋       | 42/153 [00:00<00:02, 52.04it/s, Epoch: 41, Batch: 42,Loss: -2.296,Avg.Loss: -1.739,LR: 3.25E-04]Training epoch 41:  27%|██▋       | 42/153 [00:00<00:02, 52.04it/s, Epoch: 41, Batch: 43,Loss: -2.792,Avg.Loss: -1.764,LR: 3.25E-04]Training epoch 41:  28%|██▊       | 43/153 [00:00<00:02, 52.04it/s, Epoch: 41, Batch: 44,Loss: -1.960,Avg.Loss: -1.768,LR: 3.25E-04]Training epoch 41:  29%|██▉       | 44/153 [00:00<00:02, 52.04it/s, Epoch: 41, Batch: 45,Loss: -1.841,Avg.Loss: -1.770,LR: 3.25E-04]Training epoch 41:  29%|██▉       | 45/153 [00:00<00:02, 52.04it/s, Epoch: 41, Batch: 46,Loss: -1.668,Avg.Loss: -1.768,LR: 3.25E-04]Training epoch 41:  30%|███       | 46/153 [00:00<00:02, 52.04it/s, Epoch: 41, Batch: 47,Loss: -1.886,Avg.Loss: -1.770,LR: 3.25E-04]Training epoch 41:  31%|███       | 47/153 [00:00<00:02, 52.04it/s, Epoch: 41, Batch: 48,Loss: -2.414,Avg.Loss: -1.784,LR: 3.25E-04]Training epoch 41:  31%|███▏      | 48/153 [00:00<00:02, 52.25it/s, Epoch: 41, Batch: 48,Loss: -2.414,Avg.Loss: -1.784,LR: 3.25E-04]Training epoch 41:  31%|███▏      | 48/153 [00:00<00:02, 52.25it/s, Epoch: 41, Batch: 49,Loss: -1.949,Avg.Loss: -1.787,LR: 3.25E-04]Training epoch 41:  32%|███▏      | 49/153 [00:00<00:01, 52.25it/s, Epoch: 41, Batch: 50,Loss: -1.256,Avg.Loss: -1.776,LR: 3.25E-04]Training epoch 41:  33%|███▎      | 50/153 [00:00<00:01, 52.25it/s, Epoch: 41, Batch: 51,Loss: -1.926,Avg.Loss: -1.779,LR: 3.25E-04]Training epoch 41:  33%|███▎      | 51/153 [00:00<00:01, 52.25it/s, Epoch: 41, Batch: 52,Loss: -1.865,Avg.Loss: -1.781,LR: 3.25E-04]Training epoch 41:  34%|███▍      | 52/153 [00:01<00:01, 52.25it/s, Epoch: 41, Batch: 53,Loss: -2.445,Avg.Loss: -1.793,LR: 3.25E-04]Training epoch 41:  35%|███▍      | 53/153 [00:01<00:01, 52.25it/s, Epoch: 41, Batch: 54,Loss: -2.549,Avg.Loss: -1.807,LR: 3.25E-04]Training epoch 41:  35%|███▌      | 54/153 [00:01<00:01, 52.40it/s, Epoch: 41, Batch: 54,Loss: -2.549,Avg.Loss: -1.807,LR: 3.25E-04]Training epoch 41:  35%|███▌      | 54/153 [00:01<00:01, 52.40it/s, Epoch: 41, Batch: 55,Loss: -2.585,Avg.Loss: -1.822,LR: 3.25E-04]Training epoch 41:  36%|███▌      | 55/153 [00:01<00:01, 52.40it/s, Epoch: 41, Batch: 56,Loss: -2.293,Avg.Loss: -1.830,LR: 3.25E-04]Training epoch 41:  37%|███▋      | 56/153 [00:01<00:01, 52.40it/s, Epoch: 41, Batch: 57,Loss: -2.506,Avg.Loss: -1.842,LR: 3.24E-04]Training epoch 41:  37%|███▋      | 57/153 [00:01<00:01, 52.40it/s, Epoch: 41, Batch: 58,Loss: -2.863,Avg.Loss: -1.859,LR: 3.24E-04]Training epoch 41:  38%|███▊      | 58/153 [00:01<00:01, 52.40it/s, Epoch: 41, Batch: 59,Loss: -2.330,Avg.Loss: -1.867,LR: 3.24E-04]Training epoch 41:  39%|███▊      | 59/153 [00:01<00:01, 52.40it/s, Epoch: 41, Batch: 60,Loss: -2.151,Avg.Loss: -1.872,LR: 3.24E-04]Training epoch 41:  39%|███▉      | 60/153 [00:01<00:01, 52.66it/s, Epoch: 41, Batch: 60,Loss: -2.151,Avg.Loss: -1.872,LR: 3.24E-04]Training epoch 41:  39%|███▉      | 60/153 [00:01<00:01, 52.66it/s, Epoch: 41, Batch: 61,Loss: -2.404,Avg.Loss: -1.881,LR: 3.24E-04]Training epoch 41:  40%|███▉      | 61/153 [00:01<00:01, 52.66it/s, Epoch: 41, Batch: 62,Loss: -2.266,Avg.Loss: -1.887,LR: 3.24E-04]Training epoch 41:  41%|████      | 62/153 [00:01<00:01, 52.66it/s, Epoch: 41, Batch: 63,Loss: -2.330,Avg.Loss: -1.894,LR: 3.24E-04]Training epoch 41:  41%|████      | 63/153 [00:01<00:01, 52.66it/s, Epoch: 41, Batch: 64,Loss: -2.888,Avg.Loss: -1.910,LR: 3.24E-04]Training epoch 41:  42%|████▏     | 64/153 [00:01<00:01, 52.66it/s, Epoch: 41, Batch: 65,Loss: -2.345,Avg.Loss: -1.916,LR: 3.24E-04]Training epoch 41:  42%|████▏     | 65/153 [00:01<00:01, 52.66it/s, Epoch: 41, Batch: 66,Loss: -2.814,Avg.Loss: -1.930,LR: 3.24E-04]Training epoch 41:  43%|████▎     | 66/153 [00:01<00:01, 52.59it/s, Epoch: 41, Batch: 66,Loss: -2.814,Avg.Loss: -1.930,LR: 3.24E-04]Training epoch 41:  43%|████▎     | 66/153 [00:01<00:01, 52.59it/s, Epoch: 41, Batch: 67,Loss: -2.156,Avg.Loss: -1.933,LR: 3.24E-04]Training epoch 41:  44%|████▍     | 67/153 [00:01<00:01, 52.59it/s, Epoch: 41, Batch: 68,Loss: -1.624,Avg.Loss: -1.929,LR: 3.24E-04]Training epoch 41:  44%|████▍     | 68/153 [00:01<00:01, 52.59it/s, Epoch: 41, Batch: 69,Loss: -1.490,Avg.Loss: -1.922,LR: 3.24E-04]Training epoch 41:  45%|████▌     | 69/153 [00:01<00:01, 52.59it/s, Epoch: 41, Batch: 70,Loss: -2.344,Avg.Loss: -1.928,LR: 3.24E-04]Training epoch 41:  46%|████▌     | 70/153 [00:01<00:01, 52.59it/s, Epoch: 41, Batch: 71,Loss: -2.138,Avg.Loss: -1.931,LR: 3.24E-04]Training epoch 41:  46%|████▋     | 71/153 [00:01<00:01, 52.59it/s, Epoch: 41, Batch: 72,Loss: -2.143,Avg.Loss: -1.934,LR: 3.24E-04]Training epoch 41:  47%|████▋     | 72/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 72,Loss: -2.143,Avg.Loss: -1.934,LR: 3.24E-04]Training epoch 41:  47%|████▋     | 72/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 73,Loss: -1.901,Avg.Loss: -1.934,LR: 3.24E-04]Training epoch 41:  48%|████▊     | 73/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 74,Loss: -1.486,Avg.Loss: -1.928,LR: 3.24E-04]Training epoch 41:  48%|████▊     | 74/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 75,Loss: -1.281,Avg.Loss: -1.919,LR: 3.24E-04]Training epoch 41:  49%|████▉     | 75/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 76,Loss: -1.323,Avg.Loss: -1.911,LR: 3.24E-04]Training epoch 41:  50%|████▉     | 76/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 77,Loss: -0.838,Avg.Loss: -1.897,LR: 3.23E-04]Training epoch 41:  50%|█████     | 77/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 78,Loss: -0.592,Avg.Loss: -1.881,LR: 3.23E-04]Training epoch 41:  51%|█████     | 78/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 78,Loss: -0.592,Avg.Loss: -1.881,LR: 3.23E-04]Training epoch 41:  51%|█████     | 78/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 79,Loss: -0.872,Avg.Loss: -1.868,LR: 3.23E-04]Training epoch 41:  52%|█████▏    | 79/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 80,Loss: -0.481,Avg.Loss: -1.851,LR: 3.23E-04]Training epoch 41:  52%|█████▏    | 80/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 81,Loss: 0.434,Avg.Loss: -1.822,LR: 3.23E-04] Training epoch 41:  53%|█████▎    | 81/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 82,Loss: -1.067,Avg.Loss: -1.813,LR: 3.23E-04]Training epoch 41:  54%|█████▎    | 82/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 83,Loss: -1.137,Avg.Loss: -1.805,LR: 3.23E-04]Training epoch 41:  54%|█████▍    | 83/153 [00:01<00:01, 53.18it/s, Epoch: 41, Batch: 84,Loss: -1.734,Avg.Loss: -1.804,LR: 3.23E-04]Training epoch 41:  55%|█████▍    | 84/153 [00:01<00:01, 53.16it/s, Epoch: 41, Batch: 84,Loss: -1.734,Avg.Loss: -1.804,LR: 3.23E-04]Training epoch 41:  55%|█████▍    | 84/153 [00:01<00:01, 53.16it/s, Epoch: 41, Batch: 85,Loss: -1.498,Avg.Loss: -1.801,LR: 3.23E-04]Training epoch 41:  56%|█████▌    | 85/153 [00:01<00:01, 53.16it/s, Epoch: 41, Batch: 86,Loss: -1.384,Avg.Loss: -1.796,LR: 3.23E-04]Training epoch 41:  56%|█████▌    | 86/153 [00:01<00:01, 53.16it/s, Epoch: 41, Batch: 87,Loss: -1.904,Avg.Loss: -1.797,LR: 3.23E-04]Training epoch 41:  57%|█████▋    | 87/153 [00:01<00:01, 53.16it/s, Epoch: 41, Batch: 88,Loss: -1.156,Avg.Loss: -1.790,LR: 3.23E-04]Training epoch 41:  58%|█████▊    | 88/153 [00:01<00:01, 53.16it/s, Epoch: 41, Batch: 89,Loss: -0.752,Avg.Loss: -1.778,LR: 3.23E-04]Training epoch 41:  58%|█████▊    | 89/153 [00:01<00:01, 53.16it/s, Epoch: 41, Batch: 90,Loss: -1.250,Avg.Loss: -1.772,LR: 3.23E-04]Training epoch 41:  59%|█████▉    | 90/153 [00:01<00:01, 53.09it/s, Epoch: 41, Batch: 90,Loss: -1.250,Avg.Loss: -1.772,LR: 3.23E-04]Training epoch 41:  59%|█████▉    | 90/153 [00:01<00:01, 53.09it/s, Epoch: 41, Batch: 91,Loss: -1.554,Avg.Loss: -1.770,LR: 3.23E-04]Training epoch 41:  59%|█████▉    | 91/153 [00:01<00:01, 53.09it/s, Epoch: 41, Batch: 92,Loss: -0.731,Avg.Loss: -1.758,LR: 3.23E-04]Training epoch 41:  60%|██████    | 92/153 [00:01<00:01, 53.09it/s, Epoch: 41, Batch: 93,Loss: -1.625,Avg.Loss: -1.757,LR: 3.23E-04]Training epoch 41:  61%|██████    | 93/153 [00:01<00:01, 53.09it/s, Epoch: 41, Batch: 94,Loss: -2.177,Avg.Loss: -1.761,LR: 3.23E-04]Training epoch 41:  61%|██████▏   | 94/153 [00:01<00:01, 53.09it/s, Epoch: 41, Batch: 95,Loss: -1.142,Avg.Loss: -1.755,LR: 3.23E-04]Training epoch 41:  62%|██████▏   | 95/153 [00:01<00:01, 53.09it/s, Epoch: 41, Batch: 96,Loss: -0.655,Avg.Loss: -1.744,LR: 3.23E-04]Training epoch 41:  63%|██████▎   | 96/153 [00:01<00:01, 52.95it/s, Epoch: 41, Batch: 96,Loss: -0.655,Avg.Loss: -1.744,LR: 3.23E-04]Training epoch 41:  63%|██████▎   | 96/153 [00:01<00:01, 52.95it/s, Epoch: 41, Batch: 97,Loss: -0.808,Avg.Loss: -1.734,LR: 3.23E-04]Training epoch 41:  63%|██████▎   | 97/153 [00:01<00:01, 52.95it/s, Epoch: 41, Batch: 98,Loss: -1.349,Avg.Loss: -1.730,LR: 3.22E-04]Training epoch 41:  64%|██████▍   | 98/153 [00:01<00:01, 52.95it/s, Epoch: 41, Batch: 99,Loss: -0.842,Avg.Loss: -1.721,LR: 3.22E-04]Training epoch 41:  65%|██████▍   | 99/153 [00:01<00:01, 52.95it/s, Epoch: 41, Batch: 100,Loss: -0.709,Avg.Loss: -1.711,LR: 3.22E-04]Training epoch 41:  65%|██████▌   | 100/153 [00:01<00:01, 52.95it/s, Epoch: 41, Batch: 101,Loss: -1.349,Avg.Loss: -1.707,LR: 3.22E-04]Training epoch 41:  66%|██████▌   | 101/153 [00:01<00:00, 52.95it/s, Epoch: 41, Batch: 102,Loss: -2.402,Avg.Loss: -1.714,LR: 3.22E-04]Training epoch 41:  67%|██████▋   | 102/153 [00:01<00:00, 53.00it/s, Epoch: 41, Batch: 102,Loss: -2.402,Avg.Loss: -1.714,LR: 3.22E-04]Training epoch 41:  67%|██████▋   | 102/153 [00:01<00:00, 53.00it/s, Epoch: 41, Batch: 103,Loss: -2.012,Avg.Loss: -1.717,LR: 3.22E-04]Training epoch 41:  67%|██████▋   | 103/153 [00:01<00:00, 53.00it/s, Epoch: 41, Batch: 104,Loss: -0.828,Avg.Loss: -1.708,LR: 3.22E-04]Training epoch 41:  68%|██████▊   | 104/153 [00:01<00:00, 53.00it/s, Epoch: 41, Batch: 105,Loss: -0.900,Avg.Loss: -1.701,LR: 3.22E-04]Training epoch 41:  69%|██████▊   | 105/153 [00:02<00:00, 53.00it/s, Epoch: 41, Batch: 106,Loss: -1.717,Avg.Loss: -1.701,LR: 3.22E-04]Training epoch 41:  69%|██████▉   | 106/153 [00:02<00:00, 53.00it/s, Epoch: 41, Batch: 107,Loss: -1.480,Avg.Loss: -1.699,LR: 3.22E-04]Training epoch 41:  70%|██████▉   | 107/153 [00:02<00:00, 53.00it/s, Epoch: 41, Batch: 108,Loss: -1.265,Avg.Loss: -1.695,LR: 3.22E-04]Training epoch 41:  71%|███████   | 108/153 [00:02<00:00, 52.99it/s, Epoch: 41, Batch: 108,Loss: -1.265,Avg.Loss: -1.695,LR: 3.22E-04]Training epoch 41:  71%|███████   | 108/153 [00:02<00:00, 52.99it/s, Epoch: 41, Batch: 109,Loss: -1.773,Avg.Loss: -1.696,LR: 3.22E-04]Training epoch 41:  71%|███████   | 109/153 [00:02<00:00, 52.99it/s, Epoch: 41, Batch: 110,Loss: -2.786,Avg.Loss: -1.705,LR: 3.22E-04]Training epoch 41:  72%|███████▏  | 110/153 [00:02<00:00, 52.99it/s, Epoch: 41, Batch: 111,Loss: -2.453,Avg.Loss: -1.712,LR: 3.22E-04]Training epoch 41:  73%|███████▎  | 111/153 [00:02<00:00, 52.99it/s, Epoch: 41, Batch: 112,Loss: -2.348,Avg.Loss: -1.718,LR: 3.22E-04]Training epoch 41:  73%|███████▎  | 112/153 [00:02<00:00, 52.99it/s, Epoch: 41, Batch: 113,Loss: -1.888,Avg.Loss: -1.719,LR: 3.22E-04]Training epoch 41:  74%|███████▍  | 113/153 [00:02<00:00, 52.99it/s, Epoch: 41, Batch: 114,Loss: -2.219,Avg.Loss: -1.724,LR: 3.22E-04]Training epoch 41:  75%|███████▍  | 114/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 114,Loss: -2.219,Avg.Loss: -1.724,LR: 3.22E-04]Training epoch 41:  75%|███████▍  | 114/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 115,Loss: -2.432,Avg.Loss: -1.730,LR: 3.22E-04]Training epoch 41:  75%|███████▌  | 115/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 116,Loss: -1.585,Avg.Loss: -1.729,LR: 3.22E-04]Training epoch 41:  76%|███████▌  | 116/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 117,Loss: -1.597,Avg.Loss: -1.728,LR: 3.22E-04]Training epoch 41:  76%|███████▋  | 117/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 118,Loss: -1.820,Avg.Loss: -1.728,LR: 3.21E-04]Training epoch 41:  77%|███████▋  | 118/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 119,Loss: -1.971,Avg.Loss: -1.730,LR: 3.21E-04]Training epoch 41:  78%|███████▊  | 119/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 120,Loss: -1.852,Avg.Loss: -1.731,LR: 3.21E-04]Training epoch 41:  78%|███████▊  | 120/153 [00:02<00:00, 52.62it/s, Epoch: 41, Batch: 120,Loss: -1.852,Avg.Loss: -1.731,LR: 3.21E-04]Training epoch 41:  78%|███████▊  | 120/153 [00:02<00:00, 52.62it/s, Epoch: 41, Batch: 121,Loss: -1.943,Avg.Loss: -1.733,LR: 3.21E-04]Training epoch 41:  79%|███████▉  | 121/153 [00:02<00:00, 52.62it/s, Epoch: 41, Batch: 122,Loss: -1.705,Avg.Loss: -1.733,LR: 3.21E-04]Training epoch 41:  80%|███████▉  | 122/153 [00:02<00:00, 52.62it/s, Epoch: 41, Batch: 123,Loss: -1.176,Avg.Loss: -1.728,LR: 3.21E-04]Training epoch 41:  80%|████████  | 123/153 [00:02<00:00, 52.62it/s, Epoch: 41, Batch: 124,Loss: -1.421,Avg.Loss: -1.726,LR: 3.21E-04]Training epoch 41:  81%|████████  | 124/153 [00:02<00:00, 52.62it/s, Epoch: 41, Batch: 125,Loss: -1.950,Avg.Loss: -1.728,LR: 3.21E-04]Training epoch 41:  82%|████████▏ | 125/153 [00:02<00:00, 52.62it/s, Epoch: 41, Batch: 126,Loss: -2.395,Avg.Loss: -1.733,LR: 3.21E-04]Training epoch 41:  82%|████████▏ | 126/153 [00:02<00:00, 52.65it/s, Epoch: 41, Batch: 126,Loss: -2.395,Avg.Loss: -1.733,LR: 3.21E-04]Training epoch 41:  82%|████████▏ | 126/153 [00:02<00:00, 52.65it/s, Epoch: 41, Batch: 127,Loss: -2.300,Avg.Loss: -1.737,LR: 3.21E-04]Training epoch 41:  83%|████████▎ | 127/153 [00:02<00:00, 52.65it/s, Epoch: 41, Batch: 128,Loss: -2.329,Avg.Loss: -1.742,LR: 3.21E-04]Training epoch 41:  84%|████████▎ | 128/153 [00:02<00:00, 52.65it/s, Epoch: 41, Batch: 129,Loss: -2.145,Avg.Loss: -1.745,LR: 3.21E-04]Training epoch 41:  84%|████████▍ | 129/153 [00:02<00:00, 52.65it/s, Epoch: 41, Batch: 130,Loss: -2.572,Avg.Loss: -1.752,LR: 3.21E-04]Training epoch 41:  85%|████████▍ | 130/153 [00:02<00:00, 52.65it/s, Epoch: 41, Batch: 131,Loss: -2.626,Avg.Loss: -1.758,LR: 3.21E-04]Training epoch 41:  86%|████████▌ | 131/153 [00:02<00:00, 52.65it/s, Epoch: 41, Batch: 132,Loss: -2.373,Avg.Loss: -1.763,LR: 3.21E-04]Training epoch 41:  86%|████████▋ | 132/153 [00:02<00:00, 52.94it/s, Epoch: 41, Batch: 132,Loss: -2.373,Avg.Loss: -1.763,LR: 3.21E-04]Training epoch 41:  86%|████████▋ | 132/153 [00:02<00:00, 52.94it/s, Epoch: 41, Batch: 133,Loss: -1.821,Avg.Loss: -1.763,LR: 3.21E-04]Training epoch 41:  87%|████████▋ | 133/153 [00:02<00:00, 52.94it/s, Epoch: 41, Batch: 134,Loss: -2.132,Avg.Loss: -1.766,LR: 3.21E-04]Training epoch 41:  88%|████████▊ | 134/153 [00:02<00:00, 52.94it/s, Epoch: 41, Batch: 135,Loss: -1.984,Avg.Loss: -1.768,LR: 3.21E-04]Training epoch 41:  88%|████████▊ | 135/153 [00:02<00:00, 52.94it/s, Epoch: 41, Batch: 136,Loss: -2.245,Avg.Loss: -1.771,LR: 3.21E-04]Training epoch 41:  89%|████████▉ | 136/153 [00:02<00:00, 52.94it/s, Epoch: 41, Batch: 137,Loss: -1.922,Avg.Loss: -1.772,LR: 3.21E-04]Training epoch 41:  90%|████████▉ | 137/153 [00:02<00:00, 52.94it/s, Epoch: 41, Batch: 138,Loss: -1.085,Avg.Loss: -1.767,LR: 3.20E-04]Training epoch 41:  90%|█████████ | 138/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 138,Loss: -1.085,Avg.Loss: -1.767,LR: 3.20E-04]Training epoch 41:  90%|█████████ | 138/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 139,Loss: -0.968,Avg.Loss: -1.762,LR: 3.20E-04]Training epoch 41:  91%|█████████ | 139/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 140,Loss: -0.862,Avg.Loss: -1.755,LR: 3.20E-04]Training epoch 41:  92%|█████████▏| 140/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 141,Loss: -2.016,Avg.Loss: -1.757,LR: 3.20E-04]Training epoch 41:  92%|█████████▏| 141/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 142,Loss: -1.894,Avg.Loss: -1.758,LR: 3.20E-04]Training epoch 41:  93%|█████████▎| 142/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 143,Loss: -2.106,Avg.Loss: -1.760,LR: 3.20E-04]Training epoch 41:  93%|█████████▎| 143/153 [00:02<00:00, 52.96it/s, Epoch: 41, Batch: 144,Loss: -1.354,Avg.Loss: -1.758,LR: 3.20E-04]Training epoch 41:  94%|█████████▍| 144/153 [00:02<00:00, 52.95it/s, Epoch: 41, Batch: 144,Loss: -1.354,Avg.Loss: -1.758,LR: 3.20E-04]Training epoch 41:  94%|█████████▍| 144/153 [00:02<00:00, 52.95it/s, Epoch: 41, Batch: 145,Loss: -1.165,Avg.Loss: -1.753,LR: 3.20E-04]Training epoch 41:  95%|█████████▍| 145/153 [00:02<00:00, 52.95it/s, Epoch: 41, Batch: 146,Loss: -1.317,Avg.Loss: -1.750,LR: 3.20E-04]Training epoch 41:  95%|█████████▌| 146/153 [00:02<00:00, 52.95it/s, Epoch: 41, Batch: 147,Loss: -2.233,Avg.Loss: -1.754,LR: 3.20E-04]Training epoch 41:  96%|█████████▌| 147/153 [00:02<00:00, 52.95it/s, Epoch: 41, Batch: 148,Loss: -1.697,Avg.Loss: -1.753,LR: 3.20E-04]Training epoch 41:  97%|█████████▋| 148/153 [00:02<00:00, 52.95it/s, Epoch: 41, Batch: 149,Loss: -1.549,Avg.Loss: -1.752,LR: 3.20E-04]Training epoch 41:  97%|█████████▋| 149/153 [00:02<00:00, 52.95it/s, Epoch: 41, Batch: 150,Loss: -2.401,Avg.Loss: -1.756,LR: 3.20E-04]Training epoch 41:  98%|█████████▊| 150/153 [00:02<00:00, 53.03it/s, Epoch: 41, Batch: 150,Loss: -2.401,Avg.Loss: -1.756,LR: 3.20E-04]Training epoch 41:  98%|█████████▊| 150/153 [00:02<00:00, 53.03it/s, Epoch: 41, Batch: 151,Loss: -1.899,Avg.Loss: -1.757,LR: 3.20E-04]Training epoch 41:  99%|█████████▊| 151/153 [00:02<00:00, 53.03it/s, Epoch: 41, Batch: 152,Loss: -2.051,Avg.Loss: -1.759,LR: 3.20E-04]Training epoch 41:  99%|█████████▉| 152/153 [00:02<00:00, 53.03it/s, Epoch: 41, Batch: 153,Loss: -2.223,Avg.Loss: -1.762,LR: 3.20E-04]Training epoch 41: 100%|██████████| 153/153 [00:02<00:00, 52.76it/s, Epoch: 41, Batch: 153,Loss: -2.223,Avg.Loss: -1.762,LR: 3.20E-04]
Training epoch 42:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 42:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 42, Batch: 1,Loss: -2.286,Avg.Loss: -2.286,LR: 3.20E-04]Training epoch 42:   1%|          | 1/153 [00:00<00:06, 25.25it/s, Epoch: 42, Batch: 2,Loss: -1.960,Avg.Loss: -2.123,LR: 3.20E-04]Training epoch 42:   1%|▏         | 2/153 [00:00<00:04, 34.70it/s, Epoch: 42, Batch: 3,Loss: -2.487,Avg.Loss: -2.244,LR: 3.20E-04]Training epoch 42:   2%|▏         | 3/153 [00:00<00:03, 39.83it/s, Epoch: 42, Batch: 4,Loss: -1.654,Avg.Loss: -2.097,LR: 3.20E-04]Training epoch 42:   3%|▎         | 4/153 [00:00<00:03, 42.47it/s, Epoch: 42, Batch: 5,Loss: -1.964,Avg.Loss: -2.070,LR: 3.20E-04]Training epoch 42:   3%|▎         | 5/153 [00:00<00:03, 44.11it/s, Epoch: 42, Batch: 6,Loss: -1.698,Avg.Loss: -2.008,LR: 3.19E-04]Training epoch 42:   4%|▍         | 6/153 [00:00<00:02, 52.84it/s, Epoch: 42, Batch: 6,Loss: -1.698,Avg.Loss: -2.008,LR: 3.19E-04]Training epoch 42:   4%|▍         | 6/153 [00:00<00:02, 52.84it/s, Epoch: 42, Batch: 7,Loss: -2.227,Avg.Loss: -2.039,LR: 3.19E-04]Training epoch 42:   5%|▍         | 7/153 [00:00<00:02, 52.84it/s, Epoch: 42, Batch: 8,Loss: -2.116,Avg.Loss: -2.049,LR: 3.19E-04]Training epoch 42:   5%|▌         | 8/153 [00:00<00:02, 52.84it/s, Epoch: 42, Batch: 9,Loss: -2.527,Avg.Loss: -2.102,LR: 3.19E-04]Training epoch 42:   6%|▌         | 9/153 [00:00<00:02, 52.84it/s, Epoch: 42, Batch: 10,Loss: -2.101,Avg.Loss: -2.102,LR: 3.19E-04]Training epoch 42:   7%|▋         | 10/153 [00:00<00:02, 52.84it/s, Epoch: 42, Batch: 11,Loss: -1.395,Avg.Loss: -2.038,LR: 3.19E-04]Training epoch 42:   7%|▋         | 11/153 [00:00<00:02, 52.84it/s, Epoch: 42, Batch: 12,Loss: -1.870,Avg.Loss: -2.024,LR: 3.19E-04]Training epoch 42:   8%|▊         | 12/153 [00:00<00:02, 51.91it/s, Epoch: 42, Batch: 12,Loss: -1.870,Avg.Loss: -2.024,LR: 3.19E-04]Training epoch 42:   8%|▊         | 12/153 [00:00<00:02, 51.91it/s, Epoch: 42, Batch: 13,Loss: -1.558,Avg.Loss: -1.988,LR: 3.19E-04]Training epoch 42:   8%|▊         | 13/153 [00:00<00:02, 51.91it/s, Epoch: 42, Batch: 14,Loss: -1.316,Avg.Loss: -1.940,LR: 3.19E-04]Training epoch 42:   9%|▉         | 14/153 [00:00<00:02, 51.91it/s, Epoch: 42, Batch: 15,Loss: -0.921,Avg.Loss: -1.872,LR: 3.19E-04]Training epoch 42:  10%|▉         | 15/153 [00:00<00:02, 51.91it/s, Epoch: 42, Batch: 16,Loss: -1.808,Avg.Loss: -1.868,LR: 3.19E-04]Training epoch 42:  10%|█         | 16/153 [00:00<00:02, 51.91it/s, Epoch: 42, Batch: 17,Loss: -2.080,Avg.Loss: -1.880,LR: 3.19E-04]Training epoch 42:  11%|█         | 17/153 [00:00<00:02, 51.91it/s, Epoch: 42, Batch: 18,Loss: -1.694,Avg.Loss: -1.870,LR: 3.19E-04]Training epoch 42:  12%|█▏        | 18/153 [00:00<00:02, 52.68it/s, Epoch: 42, Batch: 18,Loss: -1.694,Avg.Loss: -1.870,LR: 3.19E-04]Training epoch 42:  12%|█▏        | 18/153 [00:00<00:02, 52.68it/s, Epoch: 42, Batch: 19,Loss: -2.062,Avg.Loss: -1.880,LR: 3.19E-04]Training epoch 42:  12%|█▏        | 19/153 [00:00<00:02, 52.68it/s, Epoch: 42, Batch: 20,Loss: -2.103,Avg.Loss: -1.891,LR: 3.19E-04]Training epoch 42:  13%|█▎        | 20/153 [00:00<00:02, 52.68it/s, Epoch: 42, Batch: 21,Loss: -2.470,Avg.Loss: -1.919,LR: 3.19E-04]Training epoch 42:  14%|█▎        | 21/153 [00:00<00:02, 52.68it/s, Epoch: 42, Batch: 22,Loss: -2.265,Avg.Loss: -1.935,LR: 3.19E-04]Training epoch 42:  14%|█▍        | 22/153 [00:00<00:02, 52.68it/s, Epoch: 42, Batch: 23,Loss: -1.659,Avg.Loss: -1.923,LR: 3.19E-04]Training epoch 42:  15%|█▌        | 23/153 [00:00<00:02, 52.68it/s, Epoch: 42, Batch: 24,Loss: -1.969,Avg.Loss: -1.924,LR: 3.19E-04]Training epoch 42:  16%|█▌        | 24/153 [00:00<00:02, 50.18it/s, Epoch: 42, Batch: 24,Loss: -1.969,Avg.Loss: -1.924,LR: 3.19E-04]Training epoch 42:  16%|█▌        | 24/153 [00:00<00:02, 50.18it/s, Epoch: 42, Batch: 25,Loss: -2.214,Avg.Loss: -1.936,LR: 3.19E-04]Training epoch 42:  16%|█▋        | 25/153 [00:00<00:02, 50.18it/s, Epoch: 42, Batch: 26,Loss: -2.060,Avg.Loss: -1.941,LR: 3.18E-04]Training epoch 42:  17%|█▋        | 26/153 [00:00<00:02, 50.18it/s, Epoch: 42, Batch: 27,Loss: -2.268,Avg.Loss: -1.953,LR: 3.18E-04]Training epoch 42:  18%|█▊        | 27/153 [00:00<00:02, 50.18it/s, Epoch: 42, Batch: 28,Loss: -1.641,Avg.Loss: -1.942,LR: 3.18E-04]Training epoch 42:  18%|█▊        | 28/153 [00:00<00:02, 50.18it/s, Epoch: 42, Batch: 29,Loss: -1.877,Avg.Loss: -1.940,LR: 3.18E-04]Training epoch 42:  19%|█▉        | 29/153 [00:00<00:02, 50.18it/s, Epoch: 42, Batch: 30,Loss: -2.458,Avg.Loss: -1.957,LR: 3.18E-04]Training epoch 42:  20%|█▉        | 30/153 [00:00<00:02, 50.90it/s, Epoch: 42, Batch: 30,Loss: -2.458,Avg.Loss: -1.957,LR: 3.18E-04]Training epoch 42:  20%|█▉        | 30/153 [00:00<00:02, 50.90it/s, Epoch: 42, Batch: 31,Loss: -2.596,Avg.Loss: -1.977,LR: 3.18E-04]Training epoch 42:  20%|██        | 31/153 [00:00<00:02, 50.90it/s, Epoch: 42, Batch: 32,Loss: -2.555,Avg.Loss: -1.996,LR: 3.18E-04]Training epoch 42:  21%|██        | 32/153 [00:00<00:02, 50.90it/s, Epoch: 42, Batch: 33,Loss: -2.423,Avg.Loss: -2.008,LR: 3.18E-04]Training epoch 42:  22%|██▏       | 33/153 [00:00<00:02, 50.90it/s, Epoch: 42, Batch: 34,Loss: -2.521,Avg.Loss: -2.024,LR: 3.18E-04]Training epoch 42:  22%|██▏       | 34/153 [00:00<00:02, 50.90it/s, Epoch: 42, Batch: 35,Loss: -2.223,Avg.Loss: -2.029,LR: 3.18E-04]Training epoch 42:  23%|██▎       | 35/153 [00:00<00:02, 50.90it/s, Epoch: 42, Batch: 36,Loss: -2.489,Avg.Loss: -2.042,LR: 3.18E-04]Training epoch 42:  24%|██▎       | 36/153 [00:00<00:02, 51.47it/s, Epoch: 42, Batch: 36,Loss: -2.489,Avg.Loss: -2.042,LR: 3.18E-04]Training epoch 42:  24%|██▎       | 36/153 [00:00<00:02, 51.47it/s, Epoch: 42, Batch: 37,Loss: -2.435,Avg.Loss: -2.053,LR: 3.18E-04]Training epoch 42:  24%|██▍       | 37/153 [00:00<00:02, 51.47it/s, Epoch: 42, Batch: 38,Loss: -2.092,Avg.Loss: -2.054,LR: 3.18E-04]Training epoch 42:  25%|██▍       | 38/153 [00:00<00:02, 51.47it/s, Epoch: 42, Batch: 39,Loss: -2.393,Avg.Loss: -2.062,LR: 3.18E-04]Training epoch 42:  25%|██▌       | 39/153 [00:00<00:02, 51.47it/s, Epoch: 42, Batch: 40,Loss: -2.324,Avg.Loss: -2.069,LR: 3.18E-04]Training epoch 42:  26%|██▌       | 40/153 [00:00<00:02, 51.47it/s, Epoch: 42, Batch: 41,Loss: -1.920,Avg.Loss: -2.065,LR: 3.18E-04]Training epoch 42:  27%|██▋       | 41/153 [00:00<00:02, 51.47it/s, Epoch: 42, Batch: 42,Loss: -1.296,Avg.Loss: -2.047,LR: 3.18E-04]Training epoch 42:  27%|██▋       | 42/153 [00:00<00:02, 51.95it/s, Epoch: 42, Batch: 42,Loss: -1.296,Avg.Loss: -2.047,LR: 3.18E-04]Training epoch 42:  27%|██▋       | 42/153 [00:00<00:02, 51.95it/s, Epoch: 42, Batch: 43,Loss: -2.041,Avg.Loss: -2.047,LR: 3.18E-04]Training epoch 42:  28%|██▊       | 43/153 [00:00<00:02, 51.95it/s, Epoch: 42, Batch: 44,Loss: -1.723,Avg.Loss: -2.039,LR: 3.18E-04]Training epoch 42:  29%|██▉       | 44/153 [00:00<00:02, 51.95it/s, Epoch: 42, Batch: 45,Loss: -1.818,Avg.Loss: -2.035,LR: 3.18E-04]Training epoch 42:  29%|██▉       | 45/153 [00:00<00:02, 51.95it/s, Epoch: 42, Batch: 46,Loss: -2.004,Avg.Loss: -2.034,LR: 3.17E-04]Training epoch 42:  30%|███       | 46/153 [00:00<00:02, 51.95it/s, Epoch: 42, Batch: 47,Loss: -2.681,Avg.Loss: -2.048,LR: 3.17E-04]Training epoch 42:  31%|███       | 47/153 [00:00<00:02, 51.95it/s, Epoch: 42, Batch: 48,Loss: -2.363,Avg.Loss: -2.054,LR: 3.17E-04]Training epoch 42:  31%|███▏      | 48/153 [00:00<00:02, 52.32it/s, Epoch: 42, Batch: 48,Loss: -2.363,Avg.Loss: -2.054,LR: 3.17E-04]Training epoch 42:  31%|███▏      | 48/153 [00:00<00:02, 52.32it/s, Epoch: 42, Batch: 49,Loss: -2.037,Avg.Loss: -2.054,LR: 3.17E-04]Training epoch 42:  32%|███▏      | 49/153 [00:00<00:01, 52.32it/s, Epoch: 42, Batch: 50,Loss: -2.457,Avg.Loss: -2.062,LR: 3.17E-04]Training epoch 42:  33%|███▎      | 50/153 [00:00<00:01, 52.32it/s, Epoch: 42, Batch: 51,Loss: -2.335,Avg.Loss: -2.067,LR: 3.17E-04]Training epoch 42:  33%|███▎      | 51/153 [00:01<00:01, 52.32it/s, Epoch: 42, Batch: 52,Loss: -2.624,Avg.Loss: -2.078,LR: 3.17E-04]Training epoch 42:  34%|███▍      | 52/153 [00:01<00:01, 52.32it/s, Epoch: 42, Batch: 53,Loss: -2.298,Avg.Loss: -2.082,LR: 3.17E-04]Training epoch 42:  35%|███▍      | 53/153 [00:01<00:01, 52.32it/s, Epoch: 42, Batch: 54,Loss: -2.250,Avg.Loss: -2.085,LR: 3.17E-04]Training epoch 42:  35%|███▌      | 54/153 [00:01<00:01, 52.36it/s, Epoch: 42, Batch: 54,Loss: -2.250,Avg.Loss: -2.085,LR: 3.17E-04]Training epoch 42:  35%|███▌      | 54/153 [00:01<00:01, 52.36it/s, Epoch: 42, Batch: 55,Loss: -2.680,Avg.Loss: -2.096,LR: 3.17E-04]Training epoch 42:  36%|███▌      | 55/153 [00:01<00:01, 52.36it/s, Epoch: 42, Batch: 56,Loss: -2.059,Avg.Loss: -2.095,LR: 3.17E-04]Training epoch 42:  37%|███▋      | 56/153 [00:01<00:01, 52.36it/s, Epoch: 42, Batch: 57,Loss: -2.378,Avg.Loss: -2.100,LR: 3.17E-04]Training epoch 42:  37%|███▋      | 57/153 [00:01<00:01, 52.36it/s, Epoch: 42, Batch: 58,Loss: -2.681,Avg.Loss: -2.110,LR: 3.17E-04]Training epoch 42:  38%|███▊      | 58/153 [00:01<00:01, 52.36it/s, Epoch: 42, Batch: 59,Loss: -2.333,Avg.Loss: -2.114,LR: 3.17E-04]Training epoch 42:  39%|███▊      | 59/153 [00:01<00:01, 52.36it/s, Epoch: 42, Batch: 60,Loss: -2.453,Avg.Loss: -2.120,LR: 3.17E-04]Training epoch 42:  39%|███▉      | 60/153 [00:01<00:01, 52.42it/s, Epoch: 42, Batch: 60,Loss: -2.453,Avg.Loss: -2.120,LR: 3.17E-04]Training epoch 42:  39%|███▉      | 60/153 [00:01<00:01, 52.42it/s, Epoch: 42, Batch: 61,Loss: -2.537,Avg.Loss: -2.127,LR: 3.17E-04]Training epoch 42:  40%|███▉      | 61/153 [00:01<00:01, 52.42it/s, Epoch: 42, Batch: 62,Loss: -1.920,Avg.Loss: -2.123,LR: 3.17E-04]Training epoch 42:  41%|████      | 62/153 [00:01<00:01, 52.42it/s, Epoch: 42, Batch: 63,Loss: -2.503,Avg.Loss: -2.129,LR: 3.17E-04]Training epoch 42:  41%|████      | 63/153 [00:01<00:01, 52.42it/s, Epoch: 42, Batch: 64,Loss: -2.164,Avg.Loss: -2.130,LR: 3.17E-04]Training epoch 42:  42%|████▏     | 64/153 [00:01<00:01, 52.42it/s, Epoch: 42, Batch: 65,Loss: -2.018,Avg.Loss: -2.128,LR: 3.17E-04]Training epoch 42:  42%|████▏     | 65/153 [00:01<00:01, 52.42it/s, Epoch: 42, Batch: 66,Loss: -2.266,Avg.Loss: -2.130,LR: 3.16E-04]Training epoch 42:  43%|████▎     | 66/153 [00:01<00:01, 52.53it/s, Epoch: 42, Batch: 66,Loss: -2.266,Avg.Loss: -2.130,LR: 3.16E-04]Training epoch 42:  43%|████▎     | 66/153 [00:01<00:01, 52.53it/s, Epoch: 42, Batch: 67,Loss: -2.490,Avg.Loss: -2.136,LR: 3.16E-04]Training epoch 42:  44%|████▍     | 67/153 [00:01<00:01, 52.53it/s, Epoch: 42, Batch: 68,Loss: -2.366,Avg.Loss: -2.139,LR: 3.16E-04]Training epoch 42:  44%|████▍     | 68/153 [00:01<00:01, 52.53it/s, Epoch: 42, Batch: 69,Loss: -2.077,Avg.Loss: -2.138,LR: 3.16E-04]Training epoch 42:  45%|████▌     | 69/153 [00:01<00:01, 52.53it/s, Epoch: 42, Batch: 70,Loss: -2.458,Avg.Loss: -2.143,LR: 3.16E-04]Training epoch 42:  46%|████▌     | 70/153 [00:01<00:01, 52.53it/s, Epoch: 42, Batch: 71,Loss: -2.355,Avg.Loss: -2.146,LR: 3.16E-04]Training epoch 42:  46%|████▋     | 71/153 [00:01<00:01, 52.53it/s, Epoch: 42, Batch: 72,Loss: -2.550,Avg.Loss: -2.151,LR: 3.16E-04]Training epoch 42:  47%|████▋     | 72/153 [00:01<00:01, 52.66it/s, Epoch: 42, Batch: 72,Loss: -2.550,Avg.Loss: -2.151,LR: 3.16E-04]Training epoch 42:  47%|████▋     | 72/153 [00:01<00:01, 52.66it/s, Epoch: 42, Batch: 73,Loss: -2.594,Avg.Loss: -2.157,LR: 3.16E-04]Training epoch 42:  48%|████▊     | 73/153 [00:01<00:01, 52.66it/s, Epoch: 42, Batch: 74,Loss: -1.835,Avg.Loss: -2.153,LR: 3.16E-04]Training epoch 42:  48%|████▊     | 74/153 [00:01<00:01, 52.66it/s, Epoch: 42, Batch: 75,Loss: -2.251,Avg.Loss: -2.154,LR: 3.16E-04]Training epoch 42:  49%|████▉     | 75/153 [00:01<00:01, 52.66it/s, Epoch: 42, Batch: 76,Loss: -2.135,Avg.Loss: -2.154,LR: 3.16E-04]Training epoch 42:  50%|████▉     | 76/153 [00:01<00:01, 52.66it/s, Epoch: 42, Batch: 77,Loss: -1.742,Avg.Loss: -2.149,LR: 3.16E-04]Training epoch 42:  50%|█████     | 77/153 [00:01<00:01, 52.66it/s, Epoch: 42, Batch: 78,Loss: -2.392,Avg.Loss: -2.152,LR: 3.16E-04]Training epoch 42:  51%|█████     | 78/153 [00:01<00:01, 52.91it/s, Epoch: 42, Batch: 78,Loss: -2.392,Avg.Loss: -2.152,LR: 3.16E-04]Training epoch 42:  51%|█████     | 78/153 [00:01<00:01, 52.91it/s, Epoch: 42, Batch: 79,Loss: -2.919,Avg.Loss: -2.162,LR: 3.16E-04]Training epoch 42:  52%|█████▏    | 79/153 [00:01<00:01, 52.91it/s, Epoch: 42, Batch: 80,Loss: -1.894,Avg.Loss: -2.158,LR: 3.16E-04]Training epoch 42:  52%|█████▏    | 80/153 [00:01<00:01, 52.91it/s, Epoch: 42, Batch: 81,Loss: -2.638,Avg.Loss: -2.164,LR: 3.16E-04]Training epoch 42:  53%|█████▎    | 81/153 [00:01<00:01, 52.91it/s, Epoch: 42, Batch: 82,Loss: -2.120,Avg.Loss: -2.164,LR: 3.16E-04]Training epoch 42:  54%|█████▎    | 82/153 [00:01<00:01, 52.91it/s, Epoch: 42, Batch: 83,Loss: -2.246,Avg.Loss: -2.165,LR: 3.16E-04]Training epoch 42:  54%|█████▍    | 83/153 [00:01<00:01, 52.91it/s, Epoch: 42, Batch: 84,Loss: -2.476,Avg.Loss: -2.168,LR: 3.16E-04]Training epoch 42:  55%|█████▍    | 84/153 [00:01<00:01, 52.80it/s, Epoch: 42, Batch: 84,Loss: -2.476,Avg.Loss: -2.168,LR: 3.16E-04]Training epoch 42:  55%|█████▍    | 84/153 [00:01<00:01, 52.80it/s, Epoch: 42, Batch: 85,Loss: -2.327,Avg.Loss: -2.170,LR: 3.16E-04]Training epoch 42:  56%|█████▌    | 85/153 [00:01<00:01, 52.80it/s, Epoch: 42, Batch: 86,Loss: -2.347,Avg.Loss: -2.172,LR: 3.15E-04]Training epoch 42:  56%|█████▌    | 86/153 [00:01<00:01, 52.80it/s, Epoch: 42, Batch: 87,Loss: -2.716,Avg.Loss: -2.178,LR: 3.15E-04]Training epoch 42:  57%|█████▋    | 87/153 [00:01<00:01, 52.80it/s, Epoch: 42, Batch: 88,Loss: -2.443,Avg.Loss: -2.181,LR: 3.15E-04]Training epoch 42:  58%|█████▊    | 88/153 [00:01<00:01, 52.80it/s, Epoch: 42, Batch: 89,Loss: -1.954,Avg.Loss: -2.179,LR: 3.15E-04]Training epoch 42:  58%|█████▊    | 89/153 [00:01<00:01, 52.80it/s, Epoch: 42, Batch: 90,Loss: -2.471,Avg.Loss: -2.182,LR: 3.15E-04]Training epoch 42:  59%|█████▉    | 90/153 [00:01<00:01, 52.54it/s, Epoch: 42, Batch: 90,Loss: -2.471,Avg.Loss: -2.182,LR: 3.15E-04]Training epoch 42:  59%|█████▉    | 90/153 [00:01<00:01, 52.54it/s, Epoch: 42, Batch: 91,Loss: -2.409,Avg.Loss: -2.185,LR: 3.15E-04]Training epoch 42:  59%|█████▉    | 91/153 [00:01<00:01, 52.54it/s, Epoch: 42, Batch: 92,Loss: -2.133,Avg.Loss: -2.184,LR: 3.15E-04]Training epoch 42:  60%|██████    | 92/153 [00:01<00:01, 52.54it/s, Epoch: 42, Batch: 93,Loss: -2.372,Avg.Loss: -2.186,LR: 3.15E-04]Training epoch 42:  61%|██████    | 93/153 [00:01<00:01, 52.54it/s, Epoch: 42, Batch: 94,Loss: -2.254,Avg.Loss: -2.187,LR: 3.15E-04]Training epoch 42:  61%|██████▏   | 94/153 [00:01<00:01, 52.54it/s, Epoch: 42, Batch: 95,Loss: -2.373,Avg.Loss: -2.189,LR: 3.15E-04]Training epoch 42:  62%|██████▏   | 95/153 [00:01<00:01, 52.54it/s, Epoch: 42, Batch: 96,Loss: -2.819,Avg.Loss: -2.195,LR: 3.15E-04]Training epoch 42:  63%|██████▎   | 96/153 [00:01<00:01, 52.77it/s, Epoch: 42, Batch: 96,Loss: -2.819,Avg.Loss: -2.195,LR: 3.15E-04]Training epoch 42:  63%|██████▎   | 96/153 [00:01<00:01, 52.77it/s, Epoch: 42, Batch: 97,Loss: -3.037,Avg.Loss: -2.204,LR: 3.15E-04]Training epoch 42:  63%|██████▎   | 97/153 [00:01<00:01, 52.77it/s, Epoch: 42, Batch: 98,Loss: -2.237,Avg.Loss: -2.204,LR: 3.15E-04]Training epoch 42:  64%|██████▍   | 98/153 [00:01<00:01, 52.77it/s, Epoch: 42, Batch: 99,Loss: -2.110,Avg.Loss: -2.203,LR: 3.15E-04]Training epoch 42:  65%|██████▍   | 99/153 [00:01<00:01, 52.77it/s, Epoch: 42, Batch: 100,Loss: -2.646,Avg.Loss: -2.208,LR: 3.15E-04]Training epoch 42:  65%|██████▌   | 100/153 [00:01<00:01, 52.77it/s, Epoch: 42, Batch: 101,Loss: -2.149,Avg.Loss: -2.207,LR: 3.15E-04]Training epoch 42:  66%|██████▌   | 101/153 [00:01<00:00, 52.77it/s, Epoch: 42, Batch: 102,Loss: -2.579,Avg.Loss: -2.211,LR: 3.15E-04]Training epoch 42:  67%|██████▋   | 102/153 [00:01<00:00, 52.79it/s, Epoch: 42, Batch: 102,Loss: -2.579,Avg.Loss: -2.211,LR: 3.15E-04]Training epoch 42:  67%|██████▋   | 102/153 [00:01<00:00, 52.79it/s, Epoch: 42, Batch: 103,Loss: -2.563,Avg.Loss: -2.214,LR: 3.15E-04]Training epoch 42:  67%|██████▋   | 103/153 [00:01<00:00, 52.79it/s, Epoch: 42, Batch: 104,Loss: -2.344,Avg.Loss: -2.216,LR: 3.15E-04]Training epoch 42:  68%|██████▊   | 104/153 [00:02<00:00, 52.79it/s, Epoch: 42, Batch: 105,Loss: -2.248,Avg.Loss: -2.216,LR: 3.15E-04]Training epoch 42:  69%|██████▊   | 105/153 [00:02<00:00, 52.79it/s, Epoch: 42, Batch: 106,Loss: -2.135,Avg.Loss: -2.215,LR: 3.15E-04]Training epoch 42:  69%|██████▉   | 106/153 [00:02<00:00, 52.79it/s, Epoch: 42, Batch: 107,Loss: -2.046,Avg.Loss: -2.214,LR: 3.14E-04]Training epoch 42:  70%|██████▉   | 107/153 [00:02<00:00, 52.79it/s, Epoch: 42, Batch: 108,Loss: -2.620,Avg.Loss: -2.217,LR: 3.14E-04]Training epoch 42:  71%|███████   | 108/153 [00:02<00:00, 52.85it/s, Epoch: 42, Batch: 108,Loss: -2.620,Avg.Loss: -2.217,LR: 3.14E-04]Training epoch 42:  71%|███████   | 108/153 [00:02<00:00, 52.85it/s, Epoch: 42, Batch: 109,Loss: -2.257,Avg.Loss: -2.218,LR: 3.14E-04]Training epoch 42:  71%|███████   | 109/153 [00:02<00:00, 52.85it/s, Epoch: 42, Batch: 110,Loss: -2.104,Avg.Loss: -2.217,LR: 3.14E-04]Training epoch 42:  72%|███████▏  | 110/153 [00:02<00:00, 52.85it/s, Epoch: 42, Batch: 111,Loss: -2.500,Avg.Loss: -2.219,LR: 3.14E-04]Training epoch 42:  73%|███████▎  | 111/153 [00:02<00:00, 52.85it/s, Epoch: 42, Batch: 112,Loss: -2.697,Avg.Loss: -2.223,LR: 3.14E-04]Training epoch 42:  73%|███████▎  | 112/153 [00:02<00:00, 52.85it/s, Epoch: 42, Batch: 113,Loss: -1.528,Avg.Loss: -2.217,LR: 3.14E-04]Training epoch 42:  74%|███████▍  | 113/153 [00:02<00:00, 52.85it/s, Epoch: 42, Batch: 114,Loss: -2.398,Avg.Loss: -2.219,LR: 3.14E-04]Training epoch 42:  75%|███████▍  | 114/153 [00:02<00:00, 53.02it/s, Epoch: 42, Batch: 114,Loss: -2.398,Avg.Loss: -2.219,LR: 3.14E-04]Training epoch 42:  75%|███████▍  | 114/153 [00:02<00:00, 53.02it/s, Epoch: 42, Batch: 115,Loss: -2.306,Avg.Loss: -2.220,LR: 3.14E-04]Training epoch 42:  75%|███████▌  | 115/153 [00:02<00:00, 53.02it/s, Epoch: 42, Batch: 116,Loss: -2.064,Avg.Loss: -2.218,LR: 3.14E-04]Training epoch 42:  76%|███████▌  | 116/153 [00:02<00:00, 53.02it/s, Epoch: 42, Batch: 117,Loss: -2.511,Avg.Loss: -2.221,LR: 3.14E-04]Training epoch 42:  76%|███████▋  | 117/153 [00:02<00:00, 53.02it/s, Epoch: 42, Batch: 118,Loss: -2.064,Avg.Loss: -2.219,LR: 3.14E-04]Training epoch 42:  77%|███████▋  | 118/153 [00:02<00:00, 53.02it/s, Epoch: 42, Batch: 119,Loss: -1.598,Avg.Loss: -2.214,LR: 3.14E-04]Training epoch 42:  78%|███████▊  | 119/153 [00:02<00:00, 53.02it/s, Epoch: 42, Batch: 120,Loss: -2.302,Avg.Loss: -2.215,LR: 3.14E-04]Training epoch 42:  78%|███████▊  | 120/153 [00:02<00:00, 52.91it/s, Epoch: 42, Batch: 120,Loss: -2.302,Avg.Loss: -2.215,LR: 3.14E-04]Training epoch 42:  78%|███████▊  | 120/153 [00:02<00:00, 52.91it/s, Epoch: 42, Batch: 121,Loss: -2.455,Avg.Loss: -2.217,LR: 3.14E-04]Training epoch 42:  79%|███████▉  | 121/153 [00:02<00:00, 52.91it/s, Epoch: 42, Batch: 122,Loss: -1.702,Avg.Loss: -2.213,LR: 3.14E-04]Training epoch 42:  80%|███████▉  | 122/153 [00:02<00:00, 52.91it/s, Epoch: 42, Batch: 123,Loss: -2.026,Avg.Loss: -2.211,LR: 3.14E-04]Training epoch 42:  80%|████████  | 123/153 [00:02<00:00, 52.91it/s, Epoch: 42, Batch: 124,Loss: -1.744,Avg.Loss: -2.207,LR: 3.14E-04]Training epoch 42:  81%|████████  | 124/153 [00:02<00:00, 52.91it/s, Epoch: 42, Batch: 125,Loss: -1.995,Avg.Loss: -2.206,LR: 3.14E-04]Training epoch 42:  82%|████████▏ | 125/153 [00:02<00:00, 52.91it/s, Epoch: 42, Batch: 126,Loss: -2.686,Avg.Loss: -2.210,LR: 3.14E-04]Training epoch 42:  82%|████████▏ | 126/153 [00:02<00:00, 52.98it/s, Epoch: 42, Batch: 126,Loss: -2.686,Avg.Loss: -2.210,LR: 3.14E-04]Training epoch 42:  82%|████████▏ | 126/153 [00:02<00:00, 52.98it/s, Epoch: 42, Batch: 127,Loss: -2.467,Avg.Loss: -2.212,LR: 3.13E-04]Training epoch 42:  83%|████████▎ | 127/153 [00:02<00:00, 52.98it/s, Epoch: 42, Batch: 128,Loss: -1.868,Avg.Loss: -2.209,LR: 3.13E-04]Training epoch 42:  84%|████████▎ | 128/153 [00:02<00:00, 52.98it/s, Epoch: 42, Batch: 129,Loss: -2.489,Avg.Loss: -2.211,LR: 3.13E-04]Training epoch 42:  84%|████████▍ | 129/153 [00:02<00:00, 52.98it/s, Epoch: 42, Batch: 130,Loss: -2.629,Avg.Loss: -2.214,LR: 3.13E-04]Training epoch 42:  85%|████████▍ | 130/153 [00:02<00:00, 52.98it/s, Epoch: 42, Batch: 131,Loss: -2.038,Avg.Loss: -2.213,LR: 3.13E-04]Training epoch 42:  86%|████████▌ | 131/153 [00:02<00:00, 52.98it/s, Epoch: 42, Batch: 132,Loss: -1.848,Avg.Loss: -2.210,LR: 3.13E-04]Training epoch 42:  86%|████████▋ | 132/153 [00:02<00:00, 53.15it/s, Epoch: 42, Batch: 132,Loss: -1.848,Avg.Loss: -2.210,LR: 3.13E-04]Training epoch 42:  86%|████████▋ | 132/153 [00:02<00:00, 53.15it/s, Epoch: 42, Batch: 133,Loss: -2.048,Avg.Loss: -2.209,LR: 3.13E-04]Training epoch 42:  87%|████████▋ | 133/153 [00:02<00:00, 53.15it/s, Epoch: 42, Batch: 134,Loss: -2.420,Avg.Loss: -2.211,LR: 3.13E-04]Training epoch 42:  88%|████████▊ | 134/153 [00:02<00:00, 53.15it/s, Epoch: 42, Batch: 135,Loss: -2.344,Avg.Loss: -2.212,LR: 3.13E-04]Training epoch 42:  88%|████████▊ | 135/153 [00:02<00:00, 53.15it/s, Epoch: 42, Batch: 136,Loss: -1.699,Avg.Loss: -2.208,LR: 3.13E-04]Training epoch 42:  89%|████████▉ | 136/153 [00:02<00:00, 53.15it/s, Epoch: 42, Batch: 137,Loss: -1.754,Avg.Loss: -2.204,LR: 3.13E-04]Training epoch 42:  90%|████████▉ | 137/153 [00:02<00:00, 53.15it/s, Epoch: 42, Batch: 138,Loss: -1.659,Avg.Loss: -2.200,LR: 3.13E-04]Training epoch 42:  90%|█████████ | 138/153 [00:02<00:00, 52.68it/s, Epoch: 42, Batch: 138,Loss: -1.659,Avg.Loss: -2.200,LR: 3.13E-04]Training epoch 42:  90%|█████████ | 138/153 [00:02<00:00, 52.68it/s, Epoch: 42, Batch: 139,Loss: -2.037,Avg.Loss: -2.199,LR: 3.13E-04]Training epoch 42:  91%|█████████ | 139/153 [00:02<00:00, 52.68it/s, Epoch: 42, Batch: 140,Loss: -1.772,Avg.Loss: -2.196,LR: 3.13E-04]Training epoch 42:  92%|█████████▏| 140/153 [00:02<00:00, 52.68it/s, Epoch: 42, Batch: 141,Loss: -1.766,Avg.Loss: -2.193,LR: 3.13E-04]Training epoch 42:  92%|█████████▏| 141/153 [00:02<00:00, 52.68it/s, Epoch: 42, Batch: 142,Loss: -1.498,Avg.Loss: -2.188,LR: 3.13E-04]Training epoch 42:  93%|█████████▎| 142/153 [00:02<00:00, 52.68it/s, Epoch: 42, Batch: 143,Loss: -1.104,Avg.Loss: -2.181,LR: 3.13E-04]Training epoch 42:  93%|█████████▎| 143/153 [00:02<00:00, 52.68it/s, Epoch: 42, Batch: 144,Loss: -1.720,Avg.Loss: -2.178,LR: 3.13E-04]Training epoch 42:  94%|█████████▍| 144/153 [00:02<00:00, 52.77it/s, Epoch: 42, Batch: 144,Loss: -1.720,Avg.Loss: -2.178,LR: 3.13E-04]Training epoch 42:  94%|█████████▍| 144/153 [00:02<00:00, 52.77it/s, Epoch: 42, Batch: 145,Loss: -2.303,Avg.Loss: -2.178,LR: 3.13E-04]Training epoch 42:  95%|█████████▍| 145/153 [00:02<00:00, 52.77it/s, Epoch: 42, Batch: 146,Loss: -1.794,Avg.Loss: -2.176,LR: 3.13E-04]Training epoch 42:  95%|█████████▌| 146/153 [00:02<00:00, 52.77it/s, Epoch: 42, Batch: 147,Loss: -1.632,Avg.Loss: -2.172,LR: 3.12E-04]Training epoch 42:  96%|█████████▌| 147/153 [00:02<00:00, 52.77it/s, Epoch: 42, Batch: 148,Loss: -2.024,Avg.Loss: -2.171,LR: 3.12E-04]Training epoch 42:  97%|█████████▋| 148/153 [00:02<00:00, 52.77it/s, Epoch: 42, Batch: 149,Loss: -2.029,Avg.Loss: -2.170,LR: 3.12E-04]Training epoch 42:  97%|█████████▋| 149/153 [00:02<00:00, 52.77it/s, Epoch: 42, Batch: 150,Loss: -2.147,Avg.Loss: -2.170,LR: 3.12E-04]Training epoch 42:  98%|█████████▊| 150/153 [00:02<00:00, 52.75it/s, Epoch: 42, Batch: 150,Loss: -2.147,Avg.Loss: -2.170,LR: 3.12E-04]Training epoch 42:  98%|█████████▊| 150/153 [00:02<00:00, 52.75it/s, Epoch: 42, Batch: 151,Loss: -2.497,Avg.Loss: -2.172,LR: 3.12E-04]Training epoch 42:  99%|█████████▊| 151/153 [00:02<00:00, 52.75it/s, Epoch: 42, Batch: 152,Loss: -2.002,Avg.Loss: -2.171,LR: 3.12E-04]Training epoch 42:  99%|█████████▉| 152/153 [00:02<00:00, 52.75it/s, Epoch: 42, Batch: 153,Loss: -1.366,Avg.Loss: -2.166,LR: 3.12E-04]Training epoch 42: 100%|██████████| 153/153 [00:02<00:00, 52.44it/s, Epoch: 42, Batch: 153,Loss: -1.366,Avg.Loss: -2.166,LR: 3.12E-04]
Training epoch 43:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 43:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 43, Batch: 1,Loss: -1.352,Avg.Loss: -1.352,LR: 3.12E-04]Training epoch 43:   1%|          | 1/153 [00:00<00:05, 26.90it/s, Epoch: 43, Batch: 2,Loss: -1.535,Avg.Loss: -1.443,LR: 3.12E-04]Training epoch 43:   1%|▏         | 2/153 [00:00<00:03, 38.77it/s, Epoch: 43, Batch: 3,Loss: -1.757,Avg.Loss: -1.548,LR: 3.12E-04]Training epoch 43:   2%|▏         | 3/153 [00:00<00:03, 43.22it/s, Epoch: 43, Batch: 4,Loss: -1.987,Avg.Loss: -1.658,LR: 3.12E-04]Training epoch 43:   3%|▎         | 4/153 [00:00<00:03, 44.99it/s, Epoch: 43, Batch: 5,Loss: -2.369,Avg.Loss: -1.800,LR: 3.12E-04]Training epoch 43:   3%|▎         | 5/153 [00:00<00:03, 46.34it/s, Epoch: 43, Batch: 6,Loss: -1.829,Avg.Loss: -1.805,LR: 3.12E-04]Training epoch 43:   4%|▍         | 6/153 [00:00<00:02, 55.51it/s, Epoch: 43, Batch: 6,Loss: -1.829,Avg.Loss: -1.805,LR: 3.12E-04]Training epoch 43:   4%|▍         | 6/153 [00:00<00:02, 55.51it/s, Epoch: 43, Batch: 7,Loss: -1.910,Avg.Loss: -1.820,LR: 3.12E-04]Training epoch 43:   5%|▍         | 7/153 [00:00<00:02, 55.51it/s, Epoch: 43, Batch: 8,Loss: -1.516,Avg.Loss: -1.782,LR: 3.12E-04]Training epoch 43:   5%|▌         | 8/153 [00:00<00:02, 55.51it/s, Epoch: 43, Batch: 9,Loss: -1.453,Avg.Loss: -1.745,LR: 3.12E-04]Training epoch 43:   6%|▌         | 9/153 [00:00<00:02, 55.51it/s, Epoch: 43, Batch: 10,Loss: -2.103,Avg.Loss: -1.781,LR: 3.12E-04]Training epoch 43:   7%|▋         | 10/153 [00:00<00:02, 55.51it/s, Epoch: 43, Batch: 11,Loss: -2.160,Avg.Loss: -1.816,LR: 3.12E-04]Training epoch 43:   7%|▋         | 11/153 [00:00<00:02, 55.51it/s, Epoch: 43, Batch: 12,Loss: -2.106,Avg.Loss: -1.840,LR: 3.12E-04]Training epoch 43:   8%|▊         | 12/153 [00:00<00:02, 54.07it/s, Epoch: 43, Batch: 12,Loss: -2.106,Avg.Loss: -1.840,LR: 3.12E-04]Training epoch 43:   8%|▊         | 12/153 [00:00<00:02, 54.07it/s, Epoch: 43, Batch: 13,Loss: -2.398,Avg.Loss: -1.883,LR: 3.12E-04]Training epoch 43:   8%|▊         | 13/153 [00:00<00:02, 54.07it/s, Epoch: 43, Batch: 14,Loss: -2.202,Avg.Loss: -1.905,LR: 3.11E-04]Training epoch 43:   9%|▉         | 14/153 [00:00<00:02, 54.07it/s, Epoch: 43, Batch: 15,Loss: -1.818,Avg.Loss: -1.900,LR: 3.11E-04]Training epoch 43:  10%|▉         | 15/153 [00:00<00:02, 54.07it/s, Epoch: 43, Batch: 16,Loss: -1.794,Avg.Loss: -1.893,LR: 3.11E-04]Training epoch 43:  10%|█         | 16/153 [00:00<00:02, 54.07it/s, Epoch: 43, Batch: 17,Loss: -1.255,Avg.Loss: -1.856,LR: 3.11E-04]Training epoch 43:  11%|█         | 17/153 [00:00<00:02, 54.07it/s, Epoch: 43, Batch: 18,Loss: -1.673,Avg.Loss: -1.845,LR: 3.11E-04]Training epoch 43:  12%|█▏        | 18/153 [00:00<00:02, 53.33it/s, Epoch: 43, Batch: 18,Loss: -1.673,Avg.Loss: -1.845,LR: 3.11E-04]Training epoch 43:  12%|█▏        | 18/153 [00:00<00:02, 53.33it/s, Epoch: 43, Batch: 19,Loss: -2.268,Avg.Loss: -1.868,LR: 3.11E-04]Training epoch 43:  12%|█▏        | 19/153 [00:00<00:02, 53.33it/s, Epoch: 43, Batch: 20,Loss: -2.000,Avg.Loss: -1.874,LR: 3.11E-04]Training epoch 43:  13%|█▎        | 20/153 [00:00<00:02, 53.33it/s, Epoch: 43, Batch: 21,Loss: -2.030,Avg.Loss: -1.882,LR: 3.11E-04]Training epoch 43:  14%|█▎        | 21/153 [00:00<00:02, 53.33it/s, Epoch: 43, Batch: 22,Loss: -2.410,Avg.Loss: -1.906,LR: 3.11E-04]Training epoch 43:  14%|█▍        | 22/153 [00:00<00:02, 53.33it/s, Epoch: 43, Batch: 23,Loss: -2.202,Avg.Loss: -1.919,LR: 3.11E-04]Training epoch 43:  15%|█▌        | 23/153 [00:00<00:02, 53.33it/s, Epoch: 43, Batch: 24,Loss: -2.087,Avg.Loss: -1.926,LR: 3.11E-04]Training epoch 43:  16%|█▌        | 24/153 [00:00<00:02, 52.41it/s, Epoch: 43, Batch: 24,Loss: -2.087,Avg.Loss: -1.926,LR: 3.11E-04]Training epoch 43:  16%|█▌        | 24/153 [00:00<00:02, 52.41it/s, Epoch: 43, Batch: 25,Loss: -2.197,Avg.Loss: -1.936,LR: 3.11E-04]Training epoch 43:  16%|█▋        | 25/153 [00:00<00:02, 52.41it/s, Epoch: 43, Batch: 26,Loss: -2.034,Avg.Loss: -1.940,LR: 3.11E-04]Training epoch 43:  17%|█▋        | 26/153 [00:00<00:02, 52.41it/s, Epoch: 43, Batch: 27,Loss: -1.820,Avg.Loss: -1.936,LR: 3.11E-04]Training epoch 43:  18%|█▊        | 27/153 [00:00<00:02, 52.41it/s, Epoch: 43, Batch: 28,Loss: -1.714,Avg.Loss: -1.928,LR: 3.11E-04]Training epoch 43:  18%|█▊        | 28/153 [00:00<00:02, 52.41it/s, Epoch: 43, Batch: 29,Loss: -2.201,Avg.Loss: -1.937,LR: 3.11E-04]Training epoch 43:  19%|█▉        | 29/153 [00:00<00:02, 52.41it/s, Epoch: 43, Batch: 30,Loss: -2.307,Avg.Loss: -1.950,LR: 3.11E-04]Training epoch 43:  20%|█▉        | 30/153 [00:00<00:02, 52.28it/s, Epoch: 43, Batch: 30,Loss: -2.307,Avg.Loss: -1.950,LR: 3.11E-04]Training epoch 43:  20%|█▉        | 30/153 [00:00<00:02, 52.28it/s, Epoch: 43, Batch: 31,Loss: -2.391,Avg.Loss: -1.964,LR: 3.11E-04]Training epoch 43:  20%|██        | 31/153 [00:00<00:02, 52.28it/s, Epoch: 43, Batch: 32,Loss: -1.726,Avg.Loss: -1.956,LR: 3.11E-04]Training epoch 43:  21%|██        | 32/153 [00:00<00:02, 52.28it/s, Epoch: 43, Batch: 33,Loss: -1.630,Avg.Loss: -1.947,LR: 3.11E-04]Training epoch 43:  22%|██▏       | 33/153 [00:00<00:02, 52.28it/s, Epoch: 43, Batch: 34,Loss: -1.956,Avg.Loss: -1.947,LR: 3.10E-04]Training epoch 43:  22%|██▏       | 34/153 [00:00<00:02, 52.28it/s, Epoch: 43, Batch: 35,Loss: -2.313,Avg.Loss: -1.957,LR: 3.10E-04]Training epoch 43:  23%|██▎       | 35/153 [00:00<00:02, 52.28it/s, Epoch: 43, Batch: 36,Loss: -1.796,Avg.Loss: -1.953,LR: 3.10E-04]Training epoch 43:  24%|██▎       | 36/153 [00:00<00:02, 52.40it/s, Epoch: 43, Batch: 36,Loss: -1.796,Avg.Loss: -1.953,LR: 3.10E-04]Training epoch 43:  24%|██▎       | 36/153 [00:00<00:02, 52.40it/s, Epoch: 43, Batch: 37,Loss: -2.583,Avg.Loss: -1.970,LR: 3.10E-04]Training epoch 43:  24%|██▍       | 37/153 [00:00<00:02, 52.40it/s, Epoch: 43, Batch: 38,Loss: -2.287,Avg.Loss: -1.978,LR: 3.10E-04]Training epoch 43:  25%|██▍       | 38/153 [00:00<00:02, 52.40it/s, Epoch: 43, Batch: 39,Loss: -2.535,Avg.Loss: -1.992,LR: 3.10E-04]Training epoch 43:  25%|██▌       | 39/153 [00:00<00:02, 52.40it/s, Epoch: 43, Batch: 40,Loss: -2.130,Avg.Loss: -1.996,LR: 3.10E-04]Training epoch 43:  26%|██▌       | 40/153 [00:00<00:02, 52.40it/s, Epoch: 43, Batch: 41,Loss: -2.422,Avg.Loss: -2.006,LR: 3.10E-04]Training epoch 43:  27%|██▋       | 41/153 [00:00<00:02, 52.40it/s, Epoch: 43, Batch: 42,Loss: -2.138,Avg.Loss: -2.009,LR: 3.10E-04]Training epoch 43:  27%|██▋       | 42/153 [00:00<00:02, 52.50it/s, Epoch: 43, Batch: 42,Loss: -2.138,Avg.Loss: -2.009,LR: 3.10E-04]Training epoch 43:  27%|██▋       | 42/153 [00:00<00:02, 52.50it/s, Epoch: 43, Batch: 43,Loss: -1.875,Avg.Loss: -2.006,LR: 3.10E-04]Training epoch 43:  28%|██▊       | 43/153 [00:00<00:02, 52.50it/s, Epoch: 43, Batch: 44,Loss: -1.005,Avg.Loss: -1.984,LR: 3.10E-04]Training epoch 43:  29%|██▉       | 44/153 [00:00<00:02, 52.50it/s, Epoch: 43, Batch: 45,Loss: -0.836,Avg.Loss: -1.958,LR: 3.10E-04]Training epoch 43:  29%|██▉       | 45/153 [00:00<00:02, 52.50it/s, Epoch: 43, Batch: 46,Loss: -1.099,Avg.Loss: -1.939,LR: 3.10E-04]Training epoch 43:  30%|███       | 46/153 [00:00<00:02, 52.50it/s, Epoch: 43, Batch: 47,Loss: -1.890,Avg.Loss: -1.938,LR: 3.10E-04]Training epoch 43:  31%|███       | 47/153 [00:00<00:02, 52.50it/s, Epoch: 43, Batch: 48,Loss: -1.619,Avg.Loss: -1.932,LR: 3.10E-04]Training epoch 43:  31%|███▏      | 48/153 [00:00<00:01, 52.73it/s, Epoch: 43, Batch: 48,Loss: -1.619,Avg.Loss: -1.932,LR: 3.10E-04]Training epoch 43:  31%|███▏      | 48/153 [00:00<00:01, 52.73it/s, Epoch: 43, Batch: 49,Loss: -1.935,Avg.Loss: -1.932,LR: 3.10E-04]Training epoch 43:  32%|███▏      | 49/153 [00:00<00:01, 52.73it/s, Epoch: 43, Batch: 50,Loss: -1.873,Avg.Loss: -1.931,LR: 3.10E-04]Training epoch 43:  33%|███▎      | 50/153 [00:00<00:01, 52.73it/s, Epoch: 43, Batch: 51,Loss: -1.622,Avg.Loss: -1.925,LR: 3.10E-04]Training epoch 43:  33%|███▎      | 51/153 [00:00<00:01, 52.73it/s, Epoch: 43, Batch: 52,Loss: -0.627,Avg.Loss: -1.900,LR: 3.10E-04]Training epoch 43:  34%|███▍      | 52/153 [00:01<00:01, 52.73it/s, Epoch: 43, Batch: 53,Loss: -1.374,Avg.Loss: -1.890,LR: 3.10E-04]Training epoch 43:  35%|███▍      | 53/153 [00:01<00:01, 52.73it/s, Epoch: 43, Batch: 54,Loss: -1.804,Avg.Loss: -1.888,LR: 3.09E-04]Training epoch 43:  35%|███▌      | 54/153 [00:01<00:01, 52.75it/s, Epoch: 43, Batch: 54,Loss: -1.804,Avg.Loss: -1.888,LR: 3.09E-04]Training epoch 43:  35%|███▌      | 54/153 [00:01<00:01, 52.75it/s, Epoch: 43, Batch: 55,Loss: -1.505,Avg.Loss: -1.881,LR: 3.09E-04]Training epoch 43:  36%|███▌      | 55/153 [00:01<00:01, 52.75it/s, Epoch: 43, Batch: 56,Loss: -1.394,Avg.Loss: -1.872,LR: 3.09E-04]Training epoch 43:  37%|███▋      | 56/153 [00:01<00:01, 52.75it/s, Epoch: 43, Batch: 57,Loss: -2.106,Avg.Loss: -1.876,LR: 3.09E-04]Training epoch 43:  37%|███▋      | 57/153 [00:01<00:01, 52.75it/s, Epoch: 43, Batch: 58,Loss: -1.570,Avg.Loss: -1.871,LR: 3.09E-04]Training epoch 43:  38%|███▊      | 58/153 [00:01<00:01, 52.75it/s, Epoch: 43, Batch: 59,Loss: -1.724,Avg.Loss: -1.869,LR: 3.09E-04]Training epoch 43:  39%|███▊      | 59/153 [00:01<00:01, 52.75it/s, Epoch: 43, Batch: 60,Loss: -2.355,Avg.Loss: -1.877,LR: 3.09E-04]Training epoch 43:  39%|███▉      | 60/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 60,Loss: -2.355,Avg.Loss: -1.877,LR: 3.09E-04]Training epoch 43:  39%|███▉      | 60/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 61,Loss: -2.160,Avg.Loss: -1.881,LR: 3.09E-04]Training epoch 43:  40%|███▉      | 61/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 62,Loss: -2.108,Avg.Loss: -1.885,LR: 3.09E-04]Training epoch 43:  41%|████      | 62/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 63,Loss: -2.352,Avg.Loss: -1.893,LR: 3.09E-04]Training epoch 43:  41%|████      | 63/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 64,Loss: -2.668,Avg.Loss: -1.905,LR: 3.09E-04]Training epoch 43:  42%|████▏     | 64/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 65,Loss: -1.655,Avg.Loss: -1.901,LR: 3.09E-04]Training epoch 43:  42%|████▏     | 65/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 66,Loss: -2.337,Avg.Loss: -1.907,LR: 3.09E-04]Training epoch 43:  43%|████▎     | 66/153 [00:01<00:01, 52.93it/s, Epoch: 43, Batch: 66,Loss: -2.337,Avg.Loss: -1.907,LR: 3.09E-04]Training epoch 43:  43%|████▎     | 66/153 [00:01<00:01, 52.93it/s, Epoch: 43, Batch: 67,Loss: -2.185,Avg.Loss: -1.912,LR: 3.09E-04]Training epoch 43:  44%|████▍     | 67/153 [00:01<00:01, 52.93it/s, Epoch: 43, Batch: 68,Loss: -2.667,Avg.Loss: -1.923,LR: 3.09E-04]Training epoch 43:  44%|████▍     | 68/153 [00:01<00:01, 52.93it/s, Epoch: 43, Batch: 69,Loss: -2.084,Avg.Loss: -1.925,LR: 3.09E-04]Training epoch 43:  45%|████▌     | 69/153 [00:01<00:01, 52.93it/s, Epoch: 43, Batch: 70,Loss: -2.033,Avg.Loss: -1.927,LR: 3.09E-04]Training epoch 43:  46%|████▌     | 70/153 [00:01<00:01, 52.93it/s, Epoch: 43, Batch: 71,Loss: -2.128,Avg.Loss: -1.929,LR: 3.09E-04]Training epoch 43:  46%|████▋     | 71/153 [00:01<00:01, 52.93it/s, Epoch: 43, Batch: 72,Loss: -1.999,Avg.Loss: -1.930,LR: 3.09E-04]Training epoch 43:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 43, Batch: 72,Loss: -1.999,Avg.Loss: -1.930,LR: 3.09E-04]Training epoch 43:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 43, Batch: 73,Loss: -2.065,Avg.Loss: -1.932,LR: 3.09E-04]Training epoch 43:  48%|████▊     | 73/153 [00:01<00:01, 52.96it/s, Epoch: 43, Batch: 74,Loss: -2.192,Avg.Loss: -1.936,LR: 3.08E-04]Training epoch 43:  48%|████▊     | 74/153 [00:01<00:01, 52.96it/s, Epoch: 43, Batch: 75,Loss: -1.688,Avg.Loss: -1.932,LR: 3.08E-04]Training epoch 43:  49%|████▉     | 75/153 [00:01<00:01, 52.96it/s, Epoch: 43, Batch: 76,Loss: -0.748,Avg.Loss: -1.917,LR: 3.08E-04]Training epoch 43:  50%|████▉     | 76/153 [00:01<00:01, 52.96it/s, Epoch: 43, Batch: 77,Loss: -1.393,Avg.Loss: -1.910,LR: 3.08E-04]Training epoch 43:  50%|█████     | 77/153 [00:01<00:01, 52.96it/s, Epoch: 43, Batch: 78,Loss: -2.290,Avg.Loss: -1.915,LR: 3.08E-04]Training epoch 43:  51%|█████     | 78/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 78,Loss: -2.290,Avg.Loss: -1.915,LR: 3.08E-04]Training epoch 43:  51%|█████     | 78/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 79,Loss: -1.941,Avg.Loss: -1.915,LR: 3.08E-04]Training epoch 43:  52%|█████▏    | 79/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 80,Loss: -1.597,Avg.Loss: -1.911,LR: 3.08E-04]Training epoch 43:  52%|█████▏    | 80/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 81,Loss: -2.514,Avg.Loss: -1.919,LR: 3.08E-04]Training epoch 43:  53%|█████▎    | 81/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 82,Loss: -1.925,Avg.Loss: -1.919,LR: 3.08E-04]Training epoch 43:  54%|█████▎    | 82/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 83,Loss: -1.305,Avg.Loss: -1.911,LR: 3.08E-04]Training epoch 43:  54%|█████▍    | 83/153 [00:01<00:01, 52.79it/s, Epoch: 43, Batch: 84,Loss: -1.443,Avg.Loss: -1.906,LR: 3.08E-04]Training epoch 43:  55%|█████▍    | 84/153 [00:01<00:01, 52.68it/s, Epoch: 43, Batch: 84,Loss: -1.443,Avg.Loss: -1.906,LR: 3.08E-04]Training epoch 43:  55%|█████▍    | 84/153 [00:01<00:01, 52.68it/s, Epoch: 43, Batch: 85,Loss: -2.432,Avg.Loss: -1.912,LR: 3.08E-04]Training epoch 43:  56%|█████▌    | 85/153 [00:01<00:01, 52.68it/s, Epoch: 43, Batch: 86,Loss: -1.587,Avg.Loss: -1.908,LR: 3.08E-04]Training epoch 43:  56%|█████▌    | 86/153 [00:01<00:01, 52.68it/s, Epoch: 43, Batch: 87,Loss: -1.351,Avg.Loss: -1.902,LR: 3.08E-04]Training epoch 43:  57%|█████▋    | 87/153 [00:01<00:01, 52.68it/s, Epoch: 43, Batch: 88,Loss: -1.349,Avg.Loss: -1.895,LR: 3.08E-04]Training epoch 43:  58%|█████▊    | 88/153 [00:01<00:01, 52.68it/s, Epoch: 43, Batch: 89,Loss: -1.940,Avg.Loss: -1.896,LR: 3.08E-04]Training epoch 43:  58%|█████▊    | 89/153 [00:01<00:01, 52.68it/s, Epoch: 43, Batch: 90,Loss: -1.666,Avg.Loss: -1.893,LR: 3.08E-04]Training epoch 43:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 43, Batch: 90,Loss: -1.666,Avg.Loss: -1.893,LR: 3.08E-04]Training epoch 43:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 43, Batch: 91,Loss: -1.148,Avg.Loss: -1.885,LR: 3.08E-04]Training epoch 43:  59%|█████▉    | 91/153 [00:01<00:01, 52.91it/s, Epoch: 43, Batch: 92,Loss: -0.875,Avg.Loss: -1.874,LR: 3.08E-04]Training epoch 43:  60%|██████    | 92/153 [00:01<00:01, 52.91it/s, Epoch: 43, Batch: 93,Loss: -2.168,Avg.Loss: -1.877,LR: 3.08E-04]Training epoch 43:  61%|██████    | 93/153 [00:01<00:01, 52.91it/s, Epoch: 43, Batch: 94,Loss: -1.946,Avg.Loss: -1.878,LR: 3.07E-04]Training epoch 43:  61%|██████▏   | 94/153 [00:01<00:01, 52.91it/s, Epoch: 43, Batch: 95,Loss: -1.954,Avg.Loss: -1.879,LR: 3.07E-04]Training epoch 43:  62%|██████▏   | 95/153 [00:01<00:01, 52.91it/s, Epoch: 43, Batch: 96,Loss: -1.561,Avg.Loss: -1.876,LR: 3.07E-04]Training epoch 43:  63%|██████▎   | 96/153 [00:01<00:01, 52.69it/s, Epoch: 43, Batch: 96,Loss: -1.561,Avg.Loss: -1.876,LR: 3.07E-04]Training epoch 43:  63%|██████▎   | 96/153 [00:01<00:01, 52.69it/s, Epoch: 43, Batch: 97,Loss: -2.419,Avg.Loss: -1.881,LR: 3.07E-04]Training epoch 43:  63%|██████▎   | 97/153 [00:01<00:01, 52.69it/s, Epoch: 43, Batch: 98,Loss: -2.260,Avg.Loss: -1.885,LR: 3.07E-04]Training epoch 43:  64%|██████▍   | 98/153 [00:01<00:01, 52.69it/s, Epoch: 43, Batch: 99,Loss: -1.010,Avg.Loss: -1.876,LR: 3.07E-04]Training epoch 43:  65%|██████▍   | 99/153 [00:01<00:01, 52.69it/s, Epoch: 43, Batch: 100,Loss: -1.779,Avg.Loss: -1.875,LR: 3.07E-04]Training epoch 43:  65%|██████▌   | 100/153 [00:01<00:01, 52.69it/s, Epoch: 43, Batch: 101,Loss: -2.143,Avg.Loss: -1.878,LR: 3.07E-04]Training epoch 43:  66%|██████▌   | 101/153 [00:01<00:00, 52.69it/s, Epoch: 43, Batch: 102,Loss: -2.378,Avg.Loss: -1.883,LR: 3.07E-04]Training epoch 43:  67%|██████▋   | 102/153 [00:01<00:00, 52.63it/s, Epoch: 43, Batch: 102,Loss: -2.378,Avg.Loss: -1.883,LR: 3.07E-04]Training epoch 43:  67%|██████▋   | 102/153 [00:01<00:00, 52.63it/s, Epoch: 43, Batch: 103,Loss: -1.538,Avg.Loss: -1.880,LR: 3.07E-04]Training epoch 43:  67%|██████▋   | 103/153 [00:01<00:00, 52.63it/s, Epoch: 43, Batch: 104,Loss: -1.522,Avg.Loss: -1.876,LR: 3.07E-04]Training epoch 43:  68%|██████▊   | 104/153 [00:01<00:00, 52.63it/s, Epoch: 43, Batch: 105,Loss: -2.391,Avg.Loss: -1.881,LR: 3.07E-04]Training epoch 43:  69%|██████▊   | 105/153 [00:02<00:00, 52.63it/s, Epoch: 43, Batch: 106,Loss: -2.142,Avg.Loss: -1.883,LR: 3.07E-04]Training epoch 43:  69%|██████▉   | 106/153 [00:02<00:00, 52.63it/s, Epoch: 43, Batch: 107,Loss: -1.471,Avg.Loss: -1.880,LR: 3.07E-04]Training epoch 43:  70%|██████▉   | 107/153 [00:02<00:00, 52.63it/s, Epoch: 43, Batch: 108,Loss: -1.640,Avg.Loss: -1.877,LR: 3.07E-04]Training epoch 43:  71%|███████   | 108/153 [00:02<00:00, 52.67it/s, Epoch: 43, Batch: 108,Loss: -1.640,Avg.Loss: -1.877,LR: 3.07E-04]Training epoch 43:  71%|███████   | 108/153 [00:02<00:00, 52.67it/s, Epoch: 43, Batch: 109,Loss: -2.657,Avg.Loss: -1.885,LR: 3.07E-04]Training epoch 43:  71%|███████   | 109/153 [00:02<00:00, 52.67it/s, Epoch: 43, Batch: 110,Loss: -1.841,Avg.Loss: -1.884,LR: 3.07E-04]Training epoch 43:  72%|███████▏  | 110/153 [00:02<00:00, 52.67it/s, Epoch: 43, Batch: 111,Loss: -0.937,Avg.Loss: -1.876,LR: 3.07E-04]Training epoch 43:  73%|███████▎  | 111/153 [00:02<00:00, 52.67it/s, Epoch: 43, Batch: 112,Loss: -1.651,Avg.Loss: -1.874,LR: 3.07E-04]Training epoch 43:  73%|███████▎  | 112/153 [00:02<00:00, 52.67it/s, Epoch: 43, Batch: 113,Loss: -2.098,Avg.Loss: -1.876,LR: 3.07E-04]Training epoch 43:  74%|███████▍  | 113/153 [00:02<00:00, 52.67it/s, Epoch: 43, Batch: 114,Loss: -2.083,Avg.Loss: -1.877,LR: 3.06E-04]Training epoch 43:  75%|███████▍  | 114/153 [00:02<00:00, 52.79it/s, Epoch: 43, Batch: 114,Loss: -2.083,Avg.Loss: -1.877,LR: 3.06E-04]Training epoch 43:  75%|███████▍  | 114/153 [00:02<00:00, 52.79it/s, Epoch: 43, Batch: 115,Loss: -1.402,Avg.Loss: -1.873,LR: 3.06E-04]Training epoch 43:  75%|███████▌  | 115/153 [00:02<00:00, 52.79it/s, Epoch: 43, Batch: 116,Loss: -1.602,Avg.Loss: -1.871,LR: 3.06E-04]Training epoch 43:  76%|███████▌  | 116/153 [00:02<00:00, 52.79it/s, Epoch: 43, Batch: 117,Loss: -2.442,Avg.Loss: -1.876,LR: 3.06E-04]Training epoch 43:  76%|███████▋  | 117/153 [00:02<00:00, 52.79it/s, Epoch: 43, Batch: 118,Loss: -2.626,Avg.Loss: -1.882,LR: 3.06E-04]Training epoch 43:  77%|███████▋  | 118/153 [00:02<00:00, 52.79it/s, Epoch: 43, Batch: 119,Loss: -1.708,Avg.Loss: -1.881,LR: 3.06E-04]Training epoch 43:  78%|███████▊  | 119/153 [00:02<00:00, 52.79it/s, Epoch: 43, Batch: 120,Loss: -2.135,Avg.Loss: -1.883,LR: 3.06E-04]Training epoch 43:  78%|███████▊  | 120/153 [00:02<00:00, 52.64it/s, Epoch: 43, Batch: 120,Loss: -2.135,Avg.Loss: -1.883,LR: 3.06E-04]Training epoch 43:  78%|███████▊  | 120/153 [00:02<00:00, 52.64it/s, Epoch: 43, Batch: 121,Loss: -2.422,Avg.Loss: -1.887,LR: 3.06E-04]Training epoch 43:  79%|███████▉  | 121/153 [00:02<00:00, 52.64it/s, Epoch: 43, Batch: 122,Loss: -1.849,Avg.Loss: -1.887,LR: 3.06E-04]Training epoch 43:  80%|███████▉  | 122/153 [00:02<00:00, 52.64it/s, Epoch: 43, Batch: 123,Loss: -1.142,Avg.Loss: -1.881,LR: 3.06E-04]Training epoch 43:  80%|████████  | 123/153 [00:02<00:00, 52.64it/s, Epoch: 43, Batch: 124,Loss: -2.178,Avg.Loss: -1.883,LR: 3.06E-04]Training epoch 43:  81%|████████  | 124/153 [00:02<00:00, 52.64it/s, Epoch: 43, Batch: 125,Loss: -2.218,Avg.Loss: -1.886,LR: 3.06E-04]Training epoch 43:  82%|████████▏ | 125/153 [00:02<00:00, 52.64it/s, Epoch: 43, Batch: 126,Loss: -1.868,Avg.Loss: -1.886,LR: 3.06E-04]Training epoch 43:  82%|████████▏ | 126/153 [00:02<00:00, 52.82it/s, Epoch: 43, Batch: 126,Loss: -1.868,Avg.Loss: -1.886,LR: 3.06E-04]Training epoch 43:  82%|████████▏ | 126/153 [00:02<00:00, 52.82it/s, Epoch: 43, Batch: 127,Loss: -1.117,Avg.Loss: -1.880,LR: 3.06E-04]Training epoch 43:  83%|████████▎ | 127/153 [00:02<00:00, 52.82it/s, Epoch: 43, Batch: 128,Loss: -1.399,Avg.Loss: -1.876,LR: 3.06E-04]Training epoch 43:  84%|████████▎ | 128/153 [00:02<00:00, 52.82it/s, Epoch: 43, Batch: 129,Loss: -2.218,Avg.Loss: -1.879,LR: 3.06E-04]Training epoch 43:  84%|████████▍ | 129/153 [00:02<00:00, 52.82it/s, Epoch: 43, Batch: 130,Loss: -2.132,Avg.Loss: -1.881,LR: 3.06E-04]Training epoch 43:  85%|████████▍ | 130/153 [00:02<00:00, 52.82it/s, Epoch: 43, Batch: 131,Loss: -1.736,Avg.Loss: -1.880,LR: 3.06E-04]Training epoch 43:  86%|████████▌ | 131/153 [00:02<00:00, 52.82it/s, Epoch: 43, Batch: 132,Loss: -1.821,Avg.Loss: -1.879,LR: 3.06E-04]Training epoch 43:  86%|████████▋ | 132/153 [00:02<00:00, 52.91it/s, Epoch: 43, Batch: 132,Loss: -1.821,Avg.Loss: -1.879,LR: 3.06E-04]Training epoch 43:  86%|████████▋ | 132/153 [00:02<00:00, 52.91it/s, Epoch: 43, Batch: 133,Loss: -2.789,Avg.Loss: -1.886,LR: 3.06E-04]Training epoch 43:  87%|████████▋ | 133/153 [00:02<00:00, 52.91it/s, Epoch: 43, Batch: 134,Loss: -1.933,Avg.Loss: -1.886,LR: 3.05E-04]Training epoch 43:  88%|████████▊ | 134/153 [00:02<00:00, 52.91it/s, Epoch: 43, Batch: 135,Loss: -1.532,Avg.Loss: -1.884,LR: 3.05E-04]Training epoch 43:  88%|████████▊ | 135/153 [00:02<00:00, 52.91it/s, Epoch: 43, Batch: 136,Loss: -1.772,Avg.Loss: -1.883,LR: 3.05E-04]Training epoch 43:  89%|████████▉ | 136/153 [00:02<00:00, 52.91it/s, Epoch: 43, Batch: 137,Loss: -2.513,Avg.Loss: -1.887,LR: 3.05E-04]Training epoch 43:  90%|████████▉ | 137/153 [00:02<00:00, 52.91it/s, Epoch: 43, Batch: 138,Loss: -1.616,Avg.Loss: -1.885,LR: 3.05E-04]Training epoch 43:  90%|█████████ | 138/153 [00:02<00:00, 52.83it/s, Epoch: 43, Batch: 138,Loss: -1.616,Avg.Loss: -1.885,LR: 3.05E-04]Training epoch 43:  90%|█████████ | 138/153 [00:02<00:00, 52.83it/s, Epoch: 43, Batch: 139,Loss: -1.538,Avg.Loss: -1.883,LR: 3.05E-04]Training epoch 43:  91%|█████████ | 139/153 [00:02<00:00, 52.83it/s, Epoch: 43, Batch: 140,Loss: -2.160,Avg.Loss: -1.885,LR: 3.05E-04]Training epoch 43:  92%|█████████▏| 140/153 [00:02<00:00, 52.83it/s, Epoch: 43, Batch: 141,Loss: -2.440,Avg.Loss: -1.889,LR: 3.05E-04]Training epoch 43:  92%|█████████▏| 141/153 [00:02<00:00, 52.83it/s, Epoch: 43, Batch: 142,Loss: -2.190,Avg.Loss: -1.891,LR: 3.05E-04]Training epoch 43:  93%|█████████▎| 142/153 [00:02<00:00, 52.83it/s, Epoch: 43, Batch: 143,Loss: -1.646,Avg.Loss: -1.889,LR: 3.05E-04]Training epoch 43:  93%|█████████▎| 143/153 [00:02<00:00, 52.83it/s, Epoch: 43, Batch: 144,Loss: -1.946,Avg.Loss: -1.890,LR: 3.05E-04]Training epoch 43:  94%|█████████▍| 144/153 [00:02<00:00, 52.84it/s, Epoch: 43, Batch: 144,Loss: -1.946,Avg.Loss: -1.890,LR: 3.05E-04]Training epoch 43:  94%|█████████▍| 144/153 [00:02<00:00, 52.84it/s, Epoch: 43, Batch: 145,Loss: -2.481,Avg.Loss: -1.894,LR: 3.05E-04]Training epoch 43:  95%|█████████▍| 145/153 [00:02<00:00, 52.84it/s, Epoch: 43, Batch: 146,Loss: -2.211,Avg.Loss: -1.896,LR: 3.05E-04]Training epoch 43:  95%|█████████▌| 146/153 [00:02<00:00, 52.84it/s, Epoch: 43, Batch: 147,Loss: -1.747,Avg.Loss: -1.895,LR: 3.05E-04]Training epoch 43:  96%|█████████▌| 147/153 [00:02<00:00, 52.84it/s, Epoch: 43, Batch: 148,Loss: -1.820,Avg.Loss: -1.894,LR: 3.05E-04]Training epoch 43:  97%|█████████▋| 148/153 [00:02<00:00, 52.84it/s, Epoch: 43, Batch: 149,Loss: -2.522,Avg.Loss: -1.899,LR: 3.05E-04]Training epoch 43:  97%|█████████▋| 149/153 [00:02<00:00, 52.84it/s, Epoch: 43, Batch: 150,Loss: -2.414,Avg.Loss: -1.902,LR: 3.05E-04]Training epoch 43:  98%|█████████▊| 150/153 [00:02<00:00, 52.80it/s, Epoch: 43, Batch: 150,Loss: -2.414,Avg.Loss: -1.902,LR: 3.05E-04]Training epoch 43:  98%|█████████▊| 150/153 [00:02<00:00, 52.80it/s, Epoch: 43, Batch: 151,Loss: -1.493,Avg.Loss: -1.899,LR: 3.05E-04]Training epoch 43:  99%|█████████▊| 151/153 [00:02<00:00, 52.80it/s, Epoch: 43, Batch: 152,Loss: -1.890,Avg.Loss: -1.899,LR: 3.05E-04]Training epoch 43:  99%|█████████▉| 152/153 [00:02<00:00, 52.80it/s, Epoch: 43, Batch: 153,Loss: -1.904,Avg.Loss: -1.899,LR: 3.05E-04]Training epoch 43: 100%|██████████| 153/153 [00:02<00:00, 52.74it/s, Epoch: 43, Batch: 153,Loss: -1.904,Avg.Loss: -1.899,LR: 3.05E-04]
Training epoch 44:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 44:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 44, Batch: 1,Loss: -1.829,Avg.Loss: -1.829,LR: 3.04E-04]Training epoch 44:   1%|          | 1/153 [00:00<00:06, 23.90it/s, Epoch: 44, Batch: 2,Loss: -1.597,Avg.Loss: -1.713,LR: 3.04E-04]Training epoch 44:   1%|▏         | 2/153 [00:00<00:04, 33.44it/s, Epoch: 44, Batch: 3,Loss: -1.434,Avg.Loss: -1.620,LR: 3.04E-04]Training epoch 44:   2%|▏         | 3/153 [00:00<00:03, 40.54it/s, Epoch: 44, Batch: 4,Loss: -2.575,Avg.Loss: -1.859,LR: 3.04E-04]Training epoch 44:   3%|▎         | 4/153 [00:00<00:03, 43.59it/s, Epoch: 44, Batch: 5,Loss: -2.400,Avg.Loss: -1.967,LR: 3.04E-04]Training epoch 44:   3%|▎         | 5/153 [00:00<00:03, 45.45it/s, Epoch: 44, Batch: 6,Loss: -1.395,Avg.Loss: -1.872,LR: 3.04E-04]Training epoch 44:   4%|▍         | 6/153 [00:00<00:02, 54.45it/s, Epoch: 44, Batch: 6,Loss: -1.395,Avg.Loss: -1.872,LR: 3.04E-04]Training epoch 44:   4%|▍         | 6/153 [00:00<00:02, 54.45it/s, Epoch: 44, Batch: 7,Loss: -2.038,Avg.Loss: -1.895,LR: 3.04E-04]Training epoch 44:   5%|▍         | 7/153 [00:00<00:02, 54.45it/s, Epoch: 44, Batch: 8,Loss: -2.350,Avg.Loss: -1.952,LR: 3.04E-04]Training epoch 44:   5%|▌         | 8/153 [00:00<00:02, 54.45it/s, Epoch: 44, Batch: 9,Loss: -2.513,Avg.Loss: -2.014,LR: 3.04E-04]Training epoch 44:   6%|▌         | 9/153 [00:00<00:02, 54.45it/s, Epoch: 44, Batch: 10,Loss: -1.187,Avg.Loss: -1.932,LR: 3.04E-04]Training epoch 44:   7%|▋         | 10/153 [00:00<00:02, 54.45it/s, Epoch: 44, Batch: 11,Loss: -1.554,Avg.Loss: -1.897,LR: 3.04E-04]Training epoch 44:   7%|▋         | 11/153 [00:00<00:02, 54.45it/s, Epoch: 44, Batch: 12,Loss: -2.205,Avg.Loss: -1.923,LR: 3.04E-04]Training epoch 44:   8%|▊         | 12/153 [00:00<00:02, 53.63it/s, Epoch: 44, Batch: 12,Loss: -2.205,Avg.Loss: -1.923,LR: 3.04E-04]Training epoch 44:   8%|▊         | 12/153 [00:00<00:02, 53.63it/s, Epoch: 44, Batch: 13,Loss: -2.372,Avg.Loss: -1.957,LR: 3.04E-04]Training epoch 44:   8%|▊         | 13/153 [00:00<00:02, 53.63it/s, Epoch: 44, Batch: 14,Loss: -1.559,Avg.Loss: -1.929,LR: 3.04E-04]Training epoch 44:   9%|▉         | 14/153 [00:00<00:02, 53.63it/s, Epoch: 44, Batch: 15,Loss: -1.722,Avg.Loss: -1.915,LR: 3.04E-04]Training epoch 44:  10%|▉         | 15/153 [00:00<00:02, 53.63it/s, Epoch: 44, Batch: 16,Loss: -2.638,Avg.Loss: -1.960,LR: 3.04E-04]Training epoch 44:  10%|█         | 16/153 [00:00<00:02, 53.63it/s, Epoch: 44, Batch: 17,Loss: -2.241,Avg.Loss: -1.977,LR: 3.04E-04]Training epoch 44:  11%|█         | 17/153 [00:00<00:02, 53.63it/s, Epoch: 44, Batch: 18,Loss: -1.306,Avg.Loss: -1.940,LR: 3.04E-04]Training epoch 44:  12%|█▏        | 18/153 [00:00<00:02, 53.55it/s, Epoch: 44, Batch: 18,Loss: -1.306,Avg.Loss: -1.940,LR: 3.04E-04]Training epoch 44:  12%|█▏        | 18/153 [00:00<00:02, 53.55it/s, Epoch: 44, Batch: 19,Loss: -2.244,Avg.Loss: -1.956,LR: 3.04E-04]Training epoch 44:  12%|█▏        | 19/153 [00:00<00:02, 53.55it/s, Epoch: 44, Batch: 20,Loss: -2.108,Avg.Loss: -1.963,LR: 3.04E-04]Training epoch 44:  13%|█▎        | 20/153 [00:00<00:02, 53.55it/s, Epoch: 44, Batch: 21,Loss: -2.211,Avg.Loss: -1.975,LR: 3.03E-04]Training epoch 44:  14%|█▎        | 21/153 [00:00<00:02, 53.55it/s, Epoch: 44, Batch: 22,Loss: -1.648,Avg.Loss: -1.960,LR: 3.03E-04]Training epoch 44:  14%|█▍        | 22/153 [00:00<00:02, 53.55it/s, Epoch: 44, Batch: 23,Loss: -1.599,Avg.Loss: -1.945,LR: 3.03E-04]Training epoch 44:  15%|█▌        | 23/153 [00:00<00:02, 53.55it/s, Epoch: 44, Batch: 24,Loss: -2.319,Avg.Loss: -1.960,LR: 3.03E-04]Training epoch 44:  16%|█▌        | 24/153 [00:00<00:02, 52.69it/s, Epoch: 44, Batch: 24,Loss: -2.319,Avg.Loss: -1.960,LR: 3.03E-04]Training epoch 44:  16%|█▌        | 24/153 [00:00<00:02, 52.69it/s, Epoch: 44, Batch: 25,Loss: -1.997,Avg.Loss: -1.962,LR: 3.03E-04]Training epoch 44:  16%|█▋        | 25/153 [00:00<00:02, 52.69it/s, Epoch: 44, Batch: 26,Loss: -1.546,Avg.Loss: -1.946,LR: 3.03E-04]Training epoch 44:  17%|█▋        | 26/153 [00:00<00:02, 52.69it/s, Epoch: 44, Batch: 27,Loss: -2.456,Avg.Loss: -1.965,LR: 3.03E-04]Training epoch 44:  18%|█▊        | 27/153 [00:00<00:02, 52.69it/s, Epoch: 44, Batch: 28,Loss: -1.838,Avg.Loss: -1.960,LR: 3.03E-04]Training epoch 44:  18%|█▊        | 28/153 [00:00<00:02, 52.69it/s, Epoch: 44, Batch: 29,Loss: -2.288,Avg.Loss: -1.971,LR: 3.03E-04]Training epoch 44:  19%|█▉        | 29/153 [00:00<00:02, 52.69it/s, Epoch: 44, Batch: 30,Loss: -1.698,Avg.Loss: -1.962,LR: 3.03E-04]Training epoch 44:  20%|█▉        | 30/153 [00:00<00:02, 52.30it/s, Epoch: 44, Batch: 30,Loss: -1.698,Avg.Loss: -1.962,LR: 3.03E-04]Training epoch 44:  20%|█▉        | 30/153 [00:00<00:02, 52.30it/s, Epoch: 44, Batch: 31,Loss: -1.610,Avg.Loss: -1.951,LR: 3.03E-04]Training epoch 44:  20%|██        | 31/153 [00:00<00:02, 52.30it/s, Epoch: 44, Batch: 32,Loss: -1.925,Avg.Loss: -1.950,LR: 3.03E-04]Training epoch 44:  21%|██        | 32/153 [00:00<00:02, 52.30it/s, Epoch: 44, Batch: 33,Loss: -2.060,Avg.Loss: -1.953,LR: 3.03E-04]Training epoch 44:  22%|██▏       | 33/153 [00:00<00:02, 52.30it/s, Epoch: 44, Batch: 34,Loss: -2.560,Avg.Loss: -1.971,LR: 3.03E-04]Training epoch 44:  22%|██▏       | 34/153 [00:00<00:02, 52.30it/s, Epoch: 44, Batch: 35,Loss: -2.025,Avg.Loss: -1.973,LR: 3.03E-04]Training epoch 44:  23%|██▎       | 35/153 [00:00<00:02, 52.30it/s, Epoch: 44, Batch: 36,Loss: -1.876,Avg.Loss: -1.970,LR: 3.03E-04]Training epoch 44:  24%|██▎       | 36/153 [00:00<00:02, 52.44it/s, Epoch: 44, Batch: 36,Loss: -1.876,Avg.Loss: -1.970,LR: 3.03E-04]Training epoch 44:  24%|██▎       | 36/153 [00:00<00:02, 52.44it/s, Epoch: 44, Batch: 37,Loss: -2.872,Avg.Loss: -1.994,LR: 3.03E-04]Training epoch 44:  24%|██▍       | 37/153 [00:00<00:02, 52.44it/s, Epoch: 44, Batch: 38,Loss: -2.632,Avg.Loss: -2.011,LR: 3.03E-04]Training epoch 44:  25%|██▍       | 38/153 [00:00<00:02, 52.44it/s, Epoch: 44, Batch: 39,Loss: -2.148,Avg.Loss: -2.015,LR: 3.03E-04]Training epoch 44:  25%|██▌       | 39/153 [00:00<00:02, 52.44it/s, Epoch: 44, Batch: 40,Loss: -2.138,Avg.Loss: -2.018,LR: 3.03E-04]Training epoch 44:  26%|██▌       | 40/153 [00:00<00:02, 52.44it/s, Epoch: 44, Batch: 41,Loss: -2.801,Avg.Loss: -2.037,LR: 3.02E-04]Training epoch 44:  27%|██▋       | 41/153 [00:00<00:02, 52.44it/s, Epoch: 44, Batch: 42,Loss: -2.549,Avg.Loss: -2.049,LR: 3.02E-04]Training epoch 44:  27%|██▋       | 42/153 [00:00<00:02, 52.66it/s, Epoch: 44, Batch: 42,Loss: -2.549,Avg.Loss: -2.049,LR: 3.02E-04]Training epoch 44:  27%|██▋       | 42/153 [00:00<00:02, 52.66it/s, Epoch: 44, Batch: 43,Loss: -2.793,Avg.Loss: -2.066,LR: 3.02E-04]Training epoch 44:  28%|██▊       | 43/153 [00:00<00:02, 52.66it/s, Epoch: 44, Batch: 44,Loss: -2.672,Avg.Loss: -2.080,LR: 3.02E-04]Training epoch 44:  29%|██▉       | 44/153 [00:00<00:02, 52.66it/s, Epoch: 44, Batch: 45,Loss: -2.538,Avg.Loss: -2.090,LR: 3.02E-04]Training epoch 44:  29%|██▉       | 45/153 [00:00<00:02, 52.66it/s, Epoch: 44, Batch: 46,Loss: -2.212,Avg.Loss: -2.093,LR: 3.02E-04]Training epoch 44:  30%|███       | 46/153 [00:00<00:02, 52.66it/s, Epoch: 44, Batch: 47,Loss: -2.383,Avg.Loss: -2.099,LR: 3.02E-04]Training epoch 44:  31%|███       | 47/153 [00:00<00:02, 52.66it/s, Epoch: 44, Batch: 48,Loss: -2.662,Avg.Loss: -2.111,LR: 3.02E-04]Training epoch 44:  31%|███▏      | 48/153 [00:00<00:01, 52.74it/s, Epoch: 44, Batch: 48,Loss: -2.662,Avg.Loss: -2.111,LR: 3.02E-04]Training epoch 44:  31%|███▏      | 48/153 [00:00<00:01, 52.74it/s, Epoch: 44, Batch: 49,Loss: -2.073,Avg.Loss: -2.110,LR: 3.02E-04]Training epoch 44:  32%|███▏      | 49/153 [00:00<00:01, 52.74it/s, Epoch: 44, Batch: 50,Loss: -2.036,Avg.Loss: -2.109,LR: 3.02E-04]Training epoch 44:  33%|███▎      | 50/153 [00:00<00:01, 52.74it/s, Epoch: 44, Batch: 51,Loss: -1.813,Avg.Loss: -2.103,LR: 3.02E-04]Training epoch 44:  33%|███▎      | 51/153 [00:00<00:01, 52.74it/s, Epoch: 44, Batch: 52,Loss: -2.387,Avg.Loss: -2.108,LR: 3.02E-04]Training epoch 44:  34%|███▍      | 52/153 [00:01<00:01, 52.74it/s, Epoch: 44, Batch: 53,Loss: -2.170,Avg.Loss: -2.109,LR: 3.02E-04]Training epoch 44:  35%|███▍      | 53/153 [00:01<00:01, 52.74it/s, Epoch: 44, Batch: 54,Loss: -1.988,Avg.Loss: -2.107,LR: 3.02E-04]Training epoch 44:  35%|███▌      | 54/153 [00:01<00:01, 52.54it/s, Epoch: 44, Batch: 54,Loss: -1.988,Avg.Loss: -2.107,LR: 3.02E-04]Training epoch 44:  35%|███▌      | 54/153 [00:01<00:01, 52.54it/s, Epoch: 44, Batch: 55,Loss: -2.357,Avg.Loss: -2.112,LR: 3.02E-04]Training epoch 44:  36%|███▌      | 55/153 [00:01<00:01, 52.54it/s, Epoch: 44, Batch: 56,Loss: -2.886,Avg.Loss: -2.126,LR: 3.02E-04]Training epoch 44:  37%|███▋      | 56/153 [00:01<00:01, 52.54it/s, Epoch: 44, Batch: 57,Loss: -2.291,Avg.Loss: -2.128,LR: 3.02E-04]Training epoch 44:  37%|███▋      | 57/153 [00:01<00:01, 52.54it/s, Epoch: 44, Batch: 58,Loss: -2.736,Avg.Loss: -2.139,LR: 3.02E-04]Training epoch 44:  38%|███▊      | 58/153 [00:01<00:01, 52.54it/s, Epoch: 44, Batch: 59,Loss: -2.773,Avg.Loss: -2.150,LR: 3.02E-04]Training epoch 44:  39%|███▊      | 59/153 [00:01<00:01, 52.54it/s, Epoch: 44, Batch: 60,Loss: -2.443,Avg.Loss: -2.155,LR: 3.02E-04]Training epoch 44:  39%|███▉      | 60/153 [00:01<00:01, 52.60it/s, Epoch: 44, Batch: 60,Loss: -2.443,Avg.Loss: -2.155,LR: 3.02E-04]Training epoch 44:  39%|███▉      | 60/153 [00:01<00:01, 52.60it/s, Epoch: 44, Batch: 61,Loss: -2.086,Avg.Loss: -2.153,LR: 3.01E-04]Training epoch 44:  40%|███▉      | 61/153 [00:01<00:01, 52.60it/s, Epoch: 44, Batch: 62,Loss: -2.365,Avg.Loss: -2.157,LR: 3.01E-04]Training epoch 44:  41%|████      | 62/153 [00:01<00:01, 52.60it/s, Epoch: 44, Batch: 63,Loss: -1.708,Avg.Loss: -2.150,LR: 3.01E-04]Training epoch 44:  41%|████      | 63/153 [00:01<00:01, 52.60it/s, Epoch: 44, Batch: 64,Loss: -1.693,Avg.Loss: -2.143,LR: 3.01E-04]Training epoch 44:  42%|████▏     | 64/153 [00:01<00:01, 52.60it/s, Epoch: 44, Batch: 65,Loss: -1.888,Avg.Loss: -2.139,LR: 3.01E-04]Training epoch 44:  42%|████▏     | 65/153 [00:01<00:01, 52.60it/s, Epoch: 44, Batch: 66,Loss: -2.084,Avg.Loss: -2.138,LR: 3.01E-04]Training epoch 44:  43%|████▎     | 66/153 [00:01<00:01, 52.69it/s, Epoch: 44, Batch: 66,Loss: -2.084,Avg.Loss: -2.138,LR: 3.01E-04]Training epoch 44:  43%|████▎     | 66/153 [00:01<00:01, 52.69it/s, Epoch: 44, Batch: 67,Loss: -1.609,Avg.Loss: -2.130,LR: 3.01E-04]Training epoch 44:  44%|████▍     | 67/153 [00:01<00:01, 52.69it/s, Epoch: 44, Batch: 68,Loss: -2.308,Avg.Loss: -2.133,LR: 3.01E-04]Training epoch 44:  44%|████▍     | 68/153 [00:01<00:01, 52.69it/s, Epoch: 44, Batch: 69,Loss: -2.183,Avg.Loss: -2.133,LR: 3.01E-04]Training epoch 44:  45%|████▌     | 69/153 [00:01<00:01, 52.69it/s, Epoch: 44, Batch: 70,Loss: -2.431,Avg.Loss: -2.138,LR: 3.01E-04]Training epoch 44:  46%|████▌     | 70/153 [00:01<00:01, 52.69it/s, Epoch: 44, Batch: 71,Loss: -2.543,Avg.Loss: -2.143,LR: 3.01E-04]Training epoch 44:  46%|████▋     | 71/153 [00:01<00:01, 52.69it/s, Epoch: 44, Batch: 72,Loss: -2.186,Avg.Loss: -2.144,LR: 3.01E-04]Training epoch 44:  47%|████▋     | 72/153 [00:01<00:01, 52.91it/s, Epoch: 44, Batch: 72,Loss: -2.186,Avg.Loss: -2.144,LR: 3.01E-04]Training epoch 44:  47%|████▋     | 72/153 [00:01<00:01, 52.91it/s, Epoch: 44, Batch: 73,Loss: -1.748,Avg.Loss: -2.138,LR: 3.01E-04]Training epoch 44:  48%|████▊     | 73/153 [00:01<00:01, 52.91it/s, Epoch: 44, Batch: 74,Loss: -1.642,Avg.Loss: -2.132,LR: 3.01E-04]Training epoch 44:  48%|████▊     | 74/153 [00:01<00:01, 52.91it/s, Epoch: 44, Batch: 75,Loss: -1.805,Avg.Loss: -2.127,LR: 3.01E-04]Training epoch 44:  49%|████▉     | 75/153 [00:01<00:01, 52.91it/s, Epoch: 44, Batch: 76,Loss: -1.911,Avg.Loss: -2.124,LR: 3.01E-04]Training epoch 44:  50%|████▉     | 76/153 [00:01<00:01, 52.91it/s, Epoch: 44, Batch: 77,Loss: -1.756,Avg.Loss: -2.120,LR: 3.01E-04]Training epoch 44:  50%|█████     | 77/153 [00:01<00:01, 52.91it/s, Epoch: 44, Batch: 78,Loss: -2.621,Avg.Loss: -2.126,LR: 3.01E-04]Training epoch 44:  51%|█████     | 78/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 78,Loss: -2.621,Avg.Loss: -2.126,LR: 3.01E-04]Training epoch 44:  51%|█████     | 78/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 79,Loss: -2.262,Avg.Loss: -2.128,LR: 3.01E-04]Training epoch 44:  52%|█████▏    | 79/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 80,Loss: -2.689,Avg.Loss: -2.135,LR: 3.01E-04]Training epoch 44:  52%|█████▏    | 80/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 81,Loss: -2.469,Avg.Loss: -2.139,LR: 3.00E-04]Training epoch 44:  53%|█████▎    | 81/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 82,Loss: -2.473,Avg.Loss: -2.143,LR: 3.00E-04]Training epoch 44:  54%|█████▎    | 82/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 83,Loss: -2.659,Avg.Loss: -2.149,LR: 3.00E-04]Training epoch 44:  54%|█████▍    | 83/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 84,Loss: -2.162,Avg.Loss: -2.149,LR: 3.00E-04]Training epoch 44:  55%|█████▍    | 84/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 84,Loss: -2.162,Avg.Loss: -2.149,LR: 3.00E-04]Training epoch 44:  55%|█████▍    | 84/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 85,Loss: -2.365,Avg.Loss: -2.152,LR: 3.00E-04]Training epoch 44:  56%|█████▌    | 85/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 86,Loss: -2.602,Avg.Loss: -2.157,LR: 3.00E-04]Training epoch 44:  56%|█████▌    | 86/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 87,Loss: -2.594,Avg.Loss: -2.162,LR: 3.00E-04]Training epoch 44:  57%|█████▋    | 87/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 88,Loss: -2.485,Avg.Loss: -2.166,LR: 3.00E-04]Training epoch 44:  58%|█████▊    | 88/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 89,Loss: -2.298,Avg.Loss: -2.167,LR: 3.00E-04]Training epoch 44:  58%|█████▊    | 89/153 [00:01<00:01, 52.75it/s, Epoch: 44, Batch: 90,Loss: -2.089,Avg.Loss: -2.167,LR: 3.00E-04]Training epoch 44:  59%|█████▉    | 90/153 [00:01<00:01, 52.85it/s, Epoch: 44, Batch: 90,Loss: -2.089,Avg.Loss: -2.167,LR: 3.00E-04]Training epoch 44:  59%|█████▉    | 90/153 [00:01<00:01, 52.85it/s, Epoch: 44, Batch: 91,Loss: -2.405,Avg.Loss: -2.169,LR: 3.00E-04]Training epoch 44:  59%|█████▉    | 91/153 [00:01<00:01, 52.85it/s, Epoch: 44, Batch: 92,Loss: -2.699,Avg.Loss: -2.175,LR: 3.00E-04]Training epoch 44:  60%|██████    | 92/153 [00:01<00:01, 52.85it/s, Epoch: 44, Batch: 93,Loss: -2.883,Avg.Loss: -2.183,LR: 3.00E-04]Training epoch 44:  61%|██████    | 93/153 [00:01<00:01, 52.85it/s, Epoch: 44, Batch: 94,Loss: -2.695,Avg.Loss: -2.188,LR: 3.00E-04]Training epoch 44:  61%|██████▏   | 94/153 [00:01<00:01, 52.85it/s, Epoch: 44, Batch: 95,Loss: -2.025,Avg.Loss: -2.186,LR: 3.00E-04]Training epoch 44:  62%|██████▏   | 95/153 [00:01<00:01, 52.85it/s, Epoch: 44, Batch: 96,Loss: -2.253,Avg.Loss: -2.187,LR: 3.00E-04]Training epoch 44:  63%|██████▎   | 96/153 [00:01<00:01, 52.81it/s, Epoch: 44, Batch: 96,Loss: -2.253,Avg.Loss: -2.187,LR: 3.00E-04]Training epoch 44:  63%|██████▎   | 96/153 [00:01<00:01, 52.81it/s, Epoch: 44, Batch: 97,Loss: -2.397,Avg.Loss: -2.189,LR: 3.00E-04]Training epoch 44:  63%|██████▎   | 97/153 [00:01<00:01, 52.81it/s, Epoch: 44, Batch: 98,Loss: -2.067,Avg.Loss: -2.188,LR: 3.00E-04]Training epoch 44:  64%|██████▍   | 98/153 [00:01<00:01, 52.81it/s, Epoch: 44, Batch: 99,Loss: -1.942,Avg.Loss: -2.185,LR: 3.00E-04]Training epoch 44:  65%|██████▍   | 99/153 [00:01<00:01, 52.81it/s, Epoch: 44, Batch: 100,Loss: -2.290,Avg.Loss: -2.186,LR: 3.00E-04]Training epoch 44:  65%|██████▌   | 100/153 [00:01<00:01, 52.81it/s, Epoch: 44, Batch: 101,Loss: -2.625,Avg.Loss: -2.191,LR: 2.99E-04]Training epoch 44:  66%|██████▌   | 101/153 [00:01<00:00, 52.81it/s, Epoch: 44, Batch: 102,Loss: -2.489,Avg.Loss: -2.194,LR: 2.99E-04]Training epoch 44:  67%|██████▋   | 102/153 [00:01<00:00, 52.58it/s, Epoch: 44, Batch: 102,Loss: -2.489,Avg.Loss: -2.194,LR: 2.99E-04]Training epoch 44:  67%|██████▋   | 102/153 [00:01<00:00, 52.58it/s, Epoch: 44, Batch: 103,Loss: -2.292,Avg.Loss: -2.195,LR: 2.99E-04]Training epoch 44:  67%|██████▋   | 103/153 [00:01<00:00, 52.58it/s, Epoch: 44, Batch: 104,Loss: -2.108,Avg.Loss: -2.194,LR: 2.99E-04]Training epoch 44:  68%|██████▊   | 104/153 [00:01<00:00, 52.58it/s, Epoch: 44, Batch: 105,Loss: -1.903,Avg.Loss: -2.191,LR: 2.99E-04]Training epoch 44:  69%|██████▊   | 105/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 106,Loss: -1.799,Avg.Loss: -2.187,LR: 2.99E-04]Training epoch 44:  69%|██████▉   | 106/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 107,Loss: -2.247,Avg.Loss: -2.188,LR: 2.99E-04]Training epoch 44:  70%|██████▉   | 107/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 108,Loss: -2.049,Avg.Loss: -2.187,LR: 2.99E-04]Training epoch 44:  71%|███████   | 108/153 [00:02<00:00, 52.35it/s, Epoch: 44, Batch: 108,Loss: -2.049,Avg.Loss: -2.187,LR: 2.99E-04]Training epoch 44:  71%|███████   | 108/153 [00:02<00:00, 52.35it/s, Epoch: 44, Batch: 109,Loss: -2.735,Avg.Loss: -2.192,LR: 2.99E-04]Training epoch 44:  71%|███████   | 109/153 [00:02<00:00, 52.35it/s, Epoch: 44, Batch: 110,Loss: -2.273,Avg.Loss: -2.192,LR: 2.99E-04]Training epoch 44:  72%|███████▏  | 110/153 [00:02<00:00, 52.35it/s, Epoch: 44, Batch: 111,Loss: -2.133,Avg.Loss: -2.192,LR: 2.99E-04]Training epoch 44:  73%|███████▎  | 111/153 [00:02<00:00, 52.35it/s, Epoch: 44, Batch: 112,Loss: -2.366,Avg.Loss: -2.193,LR: 2.99E-04]Training epoch 44:  73%|███████▎  | 112/153 [00:02<00:00, 52.35it/s, Epoch: 44, Batch: 113,Loss: -2.744,Avg.Loss: -2.198,LR: 2.99E-04]Training epoch 44:  74%|███████▍  | 113/153 [00:02<00:00, 52.35it/s, Epoch: 44, Batch: 114,Loss: -2.622,Avg.Loss: -2.202,LR: 2.99E-04]Training epoch 44:  75%|███████▍  | 114/153 [00:02<00:00, 52.16it/s, Epoch: 44, Batch: 114,Loss: -2.622,Avg.Loss: -2.202,LR: 2.99E-04]Training epoch 44:  75%|███████▍  | 114/153 [00:02<00:00, 52.16it/s, Epoch: 44, Batch: 115,Loss: -2.181,Avg.Loss: -2.202,LR: 2.99E-04]Training epoch 44:  75%|███████▌  | 115/153 [00:02<00:00, 52.16it/s, Epoch: 44, Batch: 116,Loss: -1.893,Avg.Loss: -2.199,LR: 2.99E-04]Training epoch 44:  76%|███████▌  | 116/153 [00:02<00:00, 52.16it/s, Epoch: 44, Batch: 117,Loss: -1.718,Avg.Loss: -2.195,LR: 2.99E-04]Training epoch 44:  76%|███████▋  | 117/153 [00:02<00:00, 52.16it/s, Epoch: 44, Batch: 118,Loss: -2.731,Avg.Loss: -2.200,LR: 2.99E-04]Training epoch 44:  77%|███████▋  | 118/153 [00:02<00:00, 52.16it/s, Epoch: 44, Batch: 119,Loss: -2.243,Avg.Loss: -2.200,LR: 2.99E-04]Training epoch 44:  78%|███████▊  | 119/153 [00:02<00:00, 52.16it/s, Epoch: 44, Batch: 120,Loss: -1.973,Avg.Loss: -2.198,LR: 2.99E-04]Training epoch 44:  78%|███████▊  | 120/153 [00:02<00:00, 52.34it/s, Epoch: 44, Batch: 120,Loss: -1.973,Avg.Loss: -2.198,LR: 2.99E-04]Training epoch 44:  78%|███████▊  | 120/153 [00:02<00:00, 52.34it/s, Epoch: 44, Batch: 121,Loss: -2.100,Avg.Loss: -2.197,LR: 2.98E-04]Training epoch 44:  79%|███████▉  | 121/153 [00:02<00:00, 52.34it/s, Epoch: 44, Batch: 122,Loss: -2.581,Avg.Loss: -2.200,LR: 2.98E-04]Training epoch 44:  80%|███████▉  | 122/153 [00:02<00:00, 52.34it/s, Epoch: 44, Batch: 123,Loss: -2.585,Avg.Loss: -2.204,LR: 2.98E-04]Training epoch 44:  80%|████████  | 123/153 [00:02<00:00, 52.34it/s, Epoch: 44, Batch: 124,Loss: -2.485,Avg.Loss: -2.206,LR: 2.98E-04]Training epoch 44:  81%|████████  | 124/153 [00:02<00:00, 52.34it/s, Epoch: 44, Batch: 125,Loss: -2.574,Avg.Loss: -2.209,LR: 2.98E-04]Training epoch 44:  82%|████████▏ | 125/153 [00:02<00:00, 52.34it/s, Epoch: 44, Batch: 126,Loss: -1.245,Avg.Loss: -2.201,LR: 2.98E-04]Training epoch 44:  82%|████████▏ | 126/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 126,Loss: -1.245,Avg.Loss: -2.201,LR: 2.98E-04]Training epoch 44:  82%|████████▏ | 126/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 127,Loss: -1.853,Avg.Loss: -2.198,LR: 2.98E-04]Training epoch 44:  83%|████████▎ | 127/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 128,Loss: -2.090,Avg.Loss: -2.197,LR: 2.98E-04]Training epoch 44:  84%|████████▎ | 128/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 129,Loss: -2.079,Avg.Loss: -2.197,LR: 2.98E-04]Training epoch 44:  84%|████████▍ | 129/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 130,Loss: -1.764,Avg.Loss: -2.193,LR: 2.98E-04]Training epoch 44:  85%|████████▍ | 130/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 131,Loss: -0.932,Avg.Loss: -2.184,LR: 2.98E-04]Training epoch 44:  86%|████████▌ | 131/153 [00:02<00:00, 52.58it/s, Epoch: 44, Batch: 132,Loss: -0.924,Avg.Loss: -2.174,LR: 2.98E-04]Training epoch 44:  86%|████████▋ | 132/153 [00:02<00:00, 52.74it/s, Epoch: 44, Batch: 132,Loss: -0.924,Avg.Loss: -2.174,LR: 2.98E-04]Training epoch 44:  86%|████████▋ | 132/153 [00:02<00:00, 52.74it/s, Epoch: 44, Batch: 133,Loss: -1.355,Avg.Loss: -2.168,LR: 2.98E-04]Training epoch 44:  87%|████████▋ | 133/153 [00:02<00:00, 52.74it/s, Epoch: 44, Batch: 134,Loss: -0.848,Avg.Loss: -2.158,LR: 2.98E-04]Training epoch 44:  88%|████████▊ | 134/153 [00:02<00:00, 52.74it/s, Epoch: 44, Batch: 135,Loss: -0.383,Avg.Loss: -2.145,LR: 2.98E-04]Training epoch 44:  88%|████████▊ | 135/153 [00:02<00:00, 52.74it/s, Epoch: 44, Batch: 136,Loss: -0.586,Avg.Loss: -2.133,LR: 2.98E-04]Training epoch 44:  89%|████████▉ | 136/153 [00:02<00:00, 52.74it/s, Epoch: 44, Batch: 137,Loss: 0.090,Avg.Loss: -2.117,LR: 2.98E-04] Training epoch 44:  90%|████████▉ | 137/153 [00:02<00:00, 52.74it/s, Epoch: 44, Batch: 138,Loss: 0.598,Avg.Loss: -2.098,LR: 2.98E-04]Training epoch 44:  90%|█████████ | 138/153 [00:02<00:00, 52.65it/s, Epoch: 44, Batch: 138,Loss: 0.598,Avg.Loss: -2.098,LR: 2.98E-04]Training epoch 44:  90%|█████████ | 138/153 [00:02<00:00, 52.65it/s, Epoch: 44, Batch: 139,Loss: -1.699,Avg.Loss: -2.095,LR: 2.98E-04]Training epoch 44:  91%|█████████ | 139/153 [00:02<00:00, 52.65it/s, Epoch: 44, Batch: 140,Loss: -1.591,Avg.Loss: -2.091,LR: 2.98E-04]Training epoch 44:  92%|█████████▏| 140/153 [00:02<00:00, 52.65it/s, Epoch: 44, Batch: 141,Loss: -1.771,Avg.Loss: -2.089,LR: 2.97E-04]Training epoch 44:  92%|█████████▏| 141/153 [00:02<00:00, 52.65it/s, Epoch: 44, Batch: 142,Loss: -2.432,Avg.Loss: -2.091,LR: 2.97E-04]Training epoch 44:  93%|█████████▎| 142/153 [00:02<00:00, 52.65it/s, Epoch: 44, Batch: 143,Loss: -1.679,Avg.Loss: -2.088,LR: 2.97E-04]Training epoch 44:  93%|█████████▎| 143/153 [00:02<00:00, 52.65it/s, Epoch: 44, Batch: 144,Loss: -1.119,Avg.Loss: -2.082,LR: 2.97E-04]Training epoch 44:  94%|█████████▍| 144/153 [00:02<00:00, 52.81it/s, Epoch: 44, Batch: 144,Loss: -1.119,Avg.Loss: -2.082,LR: 2.97E-04]Training epoch 44:  94%|█████████▍| 144/153 [00:02<00:00, 52.81it/s, Epoch: 44, Batch: 145,Loss: -1.945,Avg.Loss: -2.081,LR: 2.97E-04]Training epoch 44:  95%|█████████▍| 145/153 [00:02<00:00, 52.81it/s, Epoch: 44, Batch: 146,Loss: -2.211,Avg.Loss: -2.082,LR: 2.97E-04]Training epoch 44:  95%|█████████▌| 146/153 [00:02<00:00, 52.81it/s, Epoch: 44, Batch: 147,Loss: -1.900,Avg.Loss: -2.080,LR: 2.97E-04]Training epoch 44:  96%|█████████▌| 147/153 [00:02<00:00, 52.81it/s, Epoch: 44, Batch: 148,Loss: -1.794,Avg.Loss: -2.078,LR: 2.97E-04]Training epoch 44:  97%|█████████▋| 148/153 [00:02<00:00, 52.81it/s, Epoch: 44, Batch: 149,Loss: -2.184,Avg.Loss: -2.079,LR: 2.97E-04]Training epoch 44:  97%|█████████▋| 149/153 [00:02<00:00, 52.81it/s, Epoch: 44, Batch: 150,Loss: -1.892,Avg.Loss: -2.078,LR: 2.97E-04]Training epoch 44:  98%|█████████▊| 150/153 [00:02<00:00, 52.86it/s, Epoch: 44, Batch: 150,Loss: -1.892,Avg.Loss: -2.078,LR: 2.97E-04]Training epoch 44:  98%|█████████▊| 150/153 [00:02<00:00, 52.86it/s, Epoch: 44, Batch: 151,Loss: -2.098,Avg.Loss: -2.078,LR: 2.97E-04]Training epoch 44:  99%|█████████▊| 151/153 [00:02<00:00, 52.86it/s, Epoch: 44, Batch: 152,Loss: -2.324,Avg.Loss: -2.080,LR: 2.97E-04]Training epoch 44:  99%|█████████▉| 152/153 [00:02<00:00, 52.86it/s, Epoch: 44, Batch: 153,Loss: -2.367,Avg.Loss: -2.081,LR: 2.97E-04]Training epoch 44: 100%|██████████| 153/153 [00:02<00:00, 52.66it/s, Epoch: 44, Batch: 153,Loss: -2.367,Avg.Loss: -2.081,LR: 2.97E-04]
Training epoch 45:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 45:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 45, Batch: 1,Loss: -0.784,Avg.Loss: -0.784,LR: 2.97E-04]Training epoch 45:   1%|          | 1/153 [00:00<00:05, 30.29it/s, Epoch: 45, Batch: 2,Loss: -1.219,Avg.Loss: -1.002,LR: 2.97E-04]Training epoch 45:   1%|▏         | 2/153 [00:00<00:03, 43.40it/s, Epoch: 45, Batch: 3,Loss: -2.002,Avg.Loss: -1.335,LR: 2.97E-04]Training epoch 45:   2%|▏         | 3/153 [00:00<00:03, 46.87it/s, Epoch: 45, Batch: 4,Loss: -2.207,Avg.Loss: -1.553,LR: 2.97E-04]Training epoch 45:   3%|▎         | 4/153 [00:00<00:03, 49.52it/s, Epoch: 45, Batch: 5,Loss: -2.005,Avg.Loss: -1.643,LR: 2.97E-04]Training epoch 45:   3%|▎         | 5/153 [00:00<00:02, 50.60it/s, Epoch: 45, Batch: 6,Loss: -1.950,Avg.Loss: -1.695,LR: 2.97E-04]Training epoch 45:   4%|▍         | 6/153 [00:00<00:02, 50.73it/s, Epoch: 45, Batch: 7,Loss: -2.556,Avg.Loss: -1.818,LR: 2.96E-04]Training epoch 45:   5%|▍         | 7/153 [00:00<00:02, 59.09it/s, Epoch: 45, Batch: 7,Loss: -2.556,Avg.Loss: -1.818,LR: 2.96E-04]Training epoch 45:   5%|▍         | 7/153 [00:00<00:02, 59.09it/s, Epoch: 45, Batch: 8,Loss: -2.318,Avg.Loss: -1.880,LR: 2.96E-04]Training epoch 45:   5%|▌         | 8/153 [00:00<00:02, 59.09it/s, Epoch: 45, Batch: 9,Loss: -2.512,Avg.Loss: -1.950,LR: 2.96E-04]Training epoch 45:   6%|▌         | 9/153 [00:00<00:02, 59.09it/s, Epoch: 45, Batch: 10,Loss: -1.960,Avg.Loss: -1.951,LR: 2.96E-04]Training epoch 45:   7%|▋         | 10/153 [00:00<00:02, 59.09it/s, Epoch: 45, Batch: 11,Loss: -2.291,Avg.Loss: -1.982,LR: 2.96E-04]Training epoch 45:   7%|▋         | 11/153 [00:00<00:02, 59.09it/s, Epoch: 45, Batch: 12,Loss: -2.042,Avg.Loss: -1.987,LR: 2.96E-04]Training epoch 45:   8%|▊         | 12/153 [00:00<00:02, 59.09it/s, Epoch: 45, Batch: 13,Loss: -2.250,Avg.Loss: -2.007,LR: 2.96E-04]Training epoch 45:   8%|▊         | 13/153 [00:00<00:02, 55.51it/s, Epoch: 45, Batch: 13,Loss: -2.250,Avg.Loss: -2.007,LR: 2.96E-04]Training epoch 45:   8%|▊         | 13/153 [00:00<00:02, 55.51it/s, Epoch: 45, Batch: 14,Loss: -2.411,Avg.Loss: -2.036,LR: 2.96E-04]Training epoch 45:   9%|▉         | 14/153 [00:00<00:02, 55.51it/s, Epoch: 45, Batch: 15,Loss: -2.098,Avg.Loss: -2.040,LR: 2.96E-04]Training epoch 45:  10%|▉         | 15/153 [00:00<00:02, 55.51it/s, Epoch: 45, Batch: 16,Loss: -1.341,Avg.Loss: -1.997,LR: 2.96E-04]Training epoch 45:  10%|█         | 16/153 [00:00<00:02, 55.51it/s, Epoch: 45, Batch: 17,Loss: -2.007,Avg.Loss: -1.997,LR: 2.96E-04]Training epoch 45:  11%|█         | 17/153 [00:00<00:02, 55.51it/s, Epoch: 45, Batch: 18,Loss: -2.537,Avg.Loss: -2.027,LR: 2.96E-04]Training epoch 45:  12%|█▏        | 18/153 [00:00<00:02, 55.51it/s, Epoch: 45, Batch: 19,Loss: -2.490,Avg.Loss: -2.052,LR: 2.96E-04]Training epoch 45:  12%|█▏        | 19/153 [00:00<00:02, 54.66it/s, Epoch: 45, Batch: 19,Loss: -2.490,Avg.Loss: -2.052,LR: 2.96E-04]Training epoch 45:  12%|█▏        | 19/153 [00:00<00:02, 54.66it/s, Epoch: 45, Batch: 20,Loss: -2.415,Avg.Loss: -2.070,LR: 2.96E-04]Training epoch 45:  13%|█▎        | 20/153 [00:00<00:02, 54.66it/s, Epoch: 45, Batch: 21,Loss: -2.018,Avg.Loss: -2.067,LR: 2.96E-04]Training epoch 45:  14%|█▎        | 21/153 [00:00<00:02, 54.66it/s, Epoch: 45, Batch: 22,Loss: -2.190,Avg.Loss: -2.073,LR: 2.96E-04]Training epoch 45:  14%|█▍        | 22/153 [00:00<00:02, 54.66it/s, Epoch: 45, Batch: 23,Loss: -1.942,Avg.Loss: -2.067,LR: 2.96E-04]Training epoch 45:  15%|█▌        | 23/153 [00:00<00:02, 54.66it/s, Epoch: 45, Batch: 24,Loss: -2.427,Avg.Loss: -2.082,LR: 2.96E-04]Training epoch 45:  16%|█▌        | 24/153 [00:00<00:02, 54.66it/s, Epoch: 45, Batch: 25,Loss: -2.823,Avg.Loss: -2.112,LR: 2.96E-04]Training epoch 45:  16%|█▋        | 25/153 [00:00<00:02, 53.22it/s, Epoch: 45, Batch: 25,Loss: -2.823,Avg.Loss: -2.112,LR: 2.96E-04]Training epoch 45:  16%|█▋        | 25/153 [00:00<00:02, 53.22it/s, Epoch: 45, Batch: 26,Loss: -2.579,Avg.Loss: -2.130,LR: 2.96E-04]Training epoch 45:  17%|█▋        | 26/153 [00:00<00:02, 53.22it/s, Epoch: 45, Batch: 27,Loss: -2.319,Avg.Loss: -2.137,LR: 2.95E-04]Training epoch 45:  18%|█▊        | 27/153 [00:00<00:02, 53.22it/s, Epoch: 45, Batch: 28,Loss: -2.674,Avg.Loss: -2.156,LR: 2.95E-04]Training epoch 45:  18%|█▊        | 28/153 [00:00<00:02, 53.22it/s, Epoch: 45, Batch: 29,Loss: -2.682,Avg.Loss: -2.174,LR: 2.95E-04]Training epoch 45:  19%|█▉        | 29/153 [00:00<00:02, 53.22it/s, Epoch: 45, Batch: 30,Loss: -2.573,Avg.Loss: -2.187,LR: 2.95E-04]Training epoch 45:  20%|█▉        | 30/153 [00:00<00:02, 53.22it/s, Epoch: 45, Batch: 31,Loss: -2.784,Avg.Loss: -2.207,LR: 2.95E-04]Training epoch 45:  20%|██        | 31/153 [00:00<00:02, 52.85it/s, Epoch: 45, Batch: 31,Loss: -2.784,Avg.Loss: -2.207,LR: 2.95E-04]Training epoch 45:  20%|██        | 31/153 [00:00<00:02, 52.85it/s, Epoch: 45, Batch: 32,Loss: -1.718,Avg.Loss: -2.191,LR: 2.95E-04]Training epoch 45:  21%|██        | 32/153 [00:00<00:02, 52.85it/s, Epoch: 45, Batch: 33,Loss: -2.093,Avg.Loss: -2.188,LR: 2.95E-04]Training epoch 45:  22%|██▏       | 33/153 [00:00<00:02, 52.85it/s, Epoch: 45, Batch: 34,Loss: -2.185,Avg.Loss: -2.188,LR: 2.95E-04]Training epoch 45:  22%|██▏       | 34/153 [00:00<00:02, 52.85it/s, Epoch: 45, Batch: 35,Loss: -1.768,Avg.Loss: -2.176,LR: 2.95E-04]Training epoch 45:  23%|██▎       | 35/153 [00:00<00:02, 52.85it/s, Epoch: 45, Batch: 36,Loss: -1.895,Avg.Loss: -2.169,LR: 2.95E-04]Training epoch 45:  24%|██▎       | 36/153 [00:00<00:02, 52.85it/s, Epoch: 45, Batch: 37,Loss: -1.784,Avg.Loss: -2.158,LR: 2.95E-04]Training epoch 45:  24%|██▍       | 37/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 37,Loss: -1.784,Avg.Loss: -2.158,LR: 2.95E-04]Training epoch 45:  24%|██▍       | 37/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 38,Loss: -2.122,Avg.Loss: -2.157,LR: 2.95E-04]Training epoch 45:  25%|██▍       | 38/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 39,Loss: -2.242,Avg.Loss: -2.159,LR: 2.95E-04]Training epoch 45:  25%|██▌       | 39/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 40,Loss: -2.476,Avg.Loss: -2.167,LR: 2.95E-04]Training epoch 45:  26%|██▌       | 40/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 41,Loss: -1.811,Avg.Loss: -2.159,LR: 2.95E-04]Training epoch 45:  27%|██▋       | 41/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 42,Loss: -2.406,Avg.Loss: -2.164,LR: 2.95E-04]Training epoch 45:  27%|██▋       | 42/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 43,Loss: -2.375,Avg.Loss: -2.169,LR: 2.95E-04]Training epoch 45:  28%|██▊       | 43/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 43,Loss: -2.375,Avg.Loss: -2.169,LR: 2.95E-04]Training epoch 45:  28%|██▊       | 43/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 44,Loss: -2.605,Avg.Loss: -2.179,LR: 2.95E-04]Training epoch 45:  29%|██▉       | 44/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 45,Loss: -2.140,Avg.Loss: -2.178,LR: 2.95E-04]Training epoch 45:  29%|██▉       | 45/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 46,Loss: -2.035,Avg.Loss: -2.175,LR: 2.95E-04]Training epoch 45:  30%|███       | 46/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 47,Loss: -1.628,Avg.Loss: -2.164,LR: 2.94E-04]Training epoch 45:  31%|███       | 47/153 [00:00<00:02, 52.76it/s, Epoch: 45, Batch: 48,Loss: -2.766,Avg.Loss: -2.176,LR: 2.94E-04]Training epoch 45:  31%|███▏      | 48/153 [00:00<00:01, 52.76it/s, Epoch: 45, Batch: 49,Loss: -1.431,Avg.Loss: -2.161,LR: 2.94E-04]Training epoch 45:  32%|███▏      | 49/153 [00:00<00:01, 52.71it/s, Epoch: 45, Batch: 49,Loss: -1.431,Avg.Loss: -2.161,LR: 2.94E-04]Training epoch 45:  32%|███▏      | 49/153 [00:00<00:01, 52.71it/s, Epoch: 45, Batch: 50,Loss: -0.563,Avg.Loss: -2.129,LR: 2.94E-04]Training epoch 45:  33%|███▎      | 50/153 [00:00<00:01, 52.71it/s, Epoch: 45, Batch: 51,Loss: -1.429,Avg.Loss: -2.115,LR: 2.94E-04]Training epoch 45:  33%|███▎      | 51/153 [00:00<00:01, 52.71it/s, Epoch: 45, Batch: 52,Loss: -2.257,Avg.Loss: -2.118,LR: 2.94E-04]Training epoch 45:  34%|███▍      | 52/153 [00:00<00:01, 52.71it/s, Epoch: 45, Batch: 53,Loss: -1.658,Avg.Loss: -2.109,LR: 2.94E-04]Training epoch 45:  35%|███▍      | 53/153 [00:01<00:01, 52.71it/s, Epoch: 45, Batch: 54,Loss: -2.488,Avg.Loss: -2.116,LR: 2.94E-04]Training epoch 45:  35%|███▌      | 54/153 [00:01<00:01, 52.71it/s, Epoch: 45, Batch: 55,Loss: -1.948,Avg.Loss: -2.113,LR: 2.94E-04]Training epoch 45:  36%|███▌      | 55/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 55,Loss: -1.948,Avg.Loss: -2.113,LR: 2.94E-04]Training epoch 45:  36%|███▌      | 55/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 56,Loss: -1.982,Avg.Loss: -2.111,LR: 2.94E-04]Training epoch 45:  37%|███▋      | 56/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 57,Loss: -2.155,Avg.Loss: -2.112,LR: 2.94E-04]Training epoch 45:  37%|███▋      | 57/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 58,Loss: -2.028,Avg.Loss: -2.110,LR: 2.94E-04]Training epoch 45:  38%|███▊      | 58/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 59,Loss: -1.563,Avg.Loss: -2.101,LR: 2.94E-04]Training epoch 45:  39%|███▊      | 59/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 60,Loss: -2.431,Avg.Loss: -2.106,LR: 2.94E-04]Training epoch 45:  39%|███▉      | 60/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 61,Loss: -1.646,Avg.Loss: -2.099,LR: 2.94E-04]Training epoch 45:  40%|███▉      | 61/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 61,Loss: -1.646,Avg.Loss: -2.099,LR: 2.94E-04]Training epoch 45:  40%|███▉      | 61/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 62,Loss: -1.564,Avg.Loss: -2.090,LR: 2.94E-04]Training epoch 45:  41%|████      | 62/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 63,Loss: -1.515,Avg.Loss: -2.081,LR: 2.94E-04]Training epoch 45:  41%|████      | 63/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 64,Loss: -2.412,Avg.Loss: -2.086,LR: 2.94E-04]Training epoch 45:  42%|████▏     | 64/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 65,Loss: -2.609,Avg.Loss: -2.094,LR: 2.94E-04]Training epoch 45:  42%|████▏     | 65/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 66,Loss: -2.504,Avg.Loss: -2.101,LR: 2.94E-04]Training epoch 45:  43%|████▎     | 66/153 [00:01<00:01, 52.58it/s, Epoch: 45, Batch: 67,Loss: -2.424,Avg.Loss: -2.105,LR: 2.93E-04]Training epoch 45:  44%|████▍     | 67/153 [00:01<00:01, 52.73it/s, Epoch: 45, Batch: 67,Loss: -2.424,Avg.Loss: -2.105,LR: 2.93E-04]Training epoch 45:  44%|████▍     | 67/153 [00:01<00:01, 52.73it/s, Epoch: 45, Batch: 68,Loss: -2.363,Avg.Loss: -2.109,LR: 2.93E-04]Training epoch 45:  44%|████▍     | 68/153 [00:01<00:01, 52.73it/s, Epoch: 45, Batch: 69,Loss: -1.946,Avg.Loss: -2.107,LR: 2.93E-04]Training epoch 45:  45%|████▌     | 69/153 [00:01<00:01, 52.73it/s, Epoch: 45, Batch: 70,Loss: -2.558,Avg.Loss: -2.113,LR: 2.93E-04]Training epoch 45:  46%|████▌     | 70/153 [00:01<00:01, 52.73it/s, Epoch: 45, Batch: 71,Loss: -2.845,Avg.Loss: -2.124,LR: 2.93E-04]Training epoch 45:  46%|████▋     | 71/153 [00:01<00:01, 52.73it/s, Epoch: 45, Batch: 72,Loss: -2.643,Avg.Loss: -2.131,LR: 2.93E-04]Training epoch 45:  47%|████▋     | 72/153 [00:01<00:01, 52.73it/s, Epoch: 45, Batch: 73,Loss: -2.454,Avg.Loss: -2.135,LR: 2.93E-04]Training epoch 45:  48%|████▊     | 73/153 [00:01<00:01, 53.29it/s, Epoch: 45, Batch: 73,Loss: -2.454,Avg.Loss: -2.135,LR: 2.93E-04]Training epoch 45:  48%|████▊     | 73/153 [00:01<00:01, 53.29it/s, Epoch: 45, Batch: 74,Loss: -2.350,Avg.Loss: -2.138,LR: 2.93E-04]Training epoch 45:  48%|████▊     | 74/153 [00:01<00:01, 53.29it/s, Epoch: 45, Batch: 75,Loss: -1.857,Avg.Loss: -2.134,LR: 2.93E-04]Training epoch 45:  49%|████▉     | 75/153 [00:01<00:01, 53.29it/s, Epoch: 45, Batch: 76,Loss: -1.991,Avg.Loss: -2.132,LR: 2.93E-04]Training epoch 45:  50%|████▉     | 76/153 [00:01<00:01, 53.29it/s, Epoch: 45, Batch: 77,Loss: -2.232,Avg.Loss: -2.134,LR: 2.93E-04]Training epoch 45:  50%|█████     | 77/153 [00:01<00:01, 53.29it/s, Epoch: 45, Batch: 78,Loss: -2.485,Avg.Loss: -2.138,LR: 2.93E-04]Training epoch 45:  51%|█████     | 78/153 [00:01<00:01, 53.29it/s, Epoch: 45, Batch: 79,Loss: -2.221,Avg.Loss: -2.139,LR: 2.93E-04]Training epoch 45:  52%|█████▏    | 79/153 [00:01<00:01, 53.27it/s, Epoch: 45, Batch: 79,Loss: -2.221,Avg.Loss: -2.139,LR: 2.93E-04]Training epoch 45:  52%|█████▏    | 79/153 [00:01<00:01, 53.27it/s, Epoch: 45, Batch: 80,Loss: -1.996,Avg.Loss: -2.138,LR: 2.93E-04]Training epoch 45:  52%|█████▏    | 80/153 [00:01<00:01, 53.27it/s, Epoch: 45, Batch: 81,Loss: -1.917,Avg.Loss: -2.135,LR: 2.93E-04]Training epoch 45:  53%|█████▎    | 81/153 [00:01<00:01, 53.27it/s, Epoch: 45, Batch: 82,Loss: -2.303,Avg.Loss: -2.137,LR: 2.93E-04]Training epoch 45:  54%|█████▎    | 82/153 [00:01<00:01, 53.27it/s, Epoch: 45, Batch: 83,Loss: -2.257,Avg.Loss: -2.138,LR: 2.93E-04]Training epoch 45:  54%|█████▍    | 83/153 [00:01<00:01, 53.27it/s, Epoch: 45, Batch: 84,Loss: -2.962,Avg.Loss: -2.148,LR: 2.93E-04]Training epoch 45:  55%|█████▍    | 84/153 [00:01<00:01, 53.27it/s, Epoch: 45, Batch: 85,Loss: -2.174,Avg.Loss: -2.148,LR: 2.93E-04]Training epoch 45:  56%|█████▌    | 85/153 [00:01<00:01, 53.24it/s, Epoch: 45, Batch: 85,Loss: -2.174,Avg.Loss: -2.148,LR: 2.93E-04]Training epoch 45:  56%|█████▌    | 85/153 [00:01<00:01, 53.24it/s, Epoch: 45, Batch: 86,Loss: -2.113,Avg.Loss: -2.148,LR: 2.93E-04]Training epoch 45:  56%|█████▌    | 86/153 [00:01<00:01, 53.24it/s, Epoch: 45, Batch: 87,Loss: -2.344,Avg.Loss: -2.150,LR: 2.92E-04]Training epoch 45:  57%|█████▋    | 87/153 [00:01<00:01, 53.24it/s, Epoch: 45, Batch: 88,Loss: -2.518,Avg.Loss: -2.154,LR: 2.92E-04]Training epoch 45:  58%|█████▊    | 88/153 [00:01<00:01, 53.24it/s, Epoch: 45, Batch: 89,Loss: -2.702,Avg.Loss: -2.161,LR: 2.92E-04]Training epoch 45:  58%|█████▊    | 89/153 [00:01<00:01, 53.24it/s, Epoch: 45, Batch: 90,Loss: -2.606,Avg.Loss: -2.166,LR: 2.92E-04]Training epoch 45:  59%|█████▉    | 90/153 [00:01<00:01, 53.24it/s, Epoch: 45, Batch: 91,Loss: -2.167,Avg.Loss: -2.166,LR: 2.92E-04]Training epoch 45:  59%|█████▉    | 91/153 [00:01<00:01, 53.21it/s, Epoch: 45, Batch: 91,Loss: -2.167,Avg.Loss: -2.166,LR: 2.92E-04]Training epoch 45:  59%|█████▉    | 91/153 [00:01<00:01, 53.21it/s, Epoch: 45, Batch: 92,Loss: -2.594,Avg.Loss: -2.170,LR: 2.92E-04]Training epoch 45:  60%|██████    | 92/153 [00:01<00:01, 53.21it/s, Epoch: 45, Batch: 93,Loss: -2.619,Avg.Loss: -2.175,LR: 2.92E-04]Training epoch 45:  61%|██████    | 93/153 [00:01<00:01, 53.21it/s, Epoch: 45, Batch: 94,Loss: -2.274,Avg.Loss: -2.176,LR: 2.92E-04]Training epoch 45:  61%|██████▏   | 94/153 [00:01<00:01, 53.21it/s, Epoch: 45, Batch: 95,Loss: -2.443,Avg.Loss: -2.179,LR: 2.92E-04]Training epoch 45:  62%|██████▏   | 95/153 [00:01<00:01, 53.21it/s, Epoch: 45, Batch: 96,Loss: -2.401,Avg.Loss: -2.181,LR: 2.92E-04]Training epoch 45:  63%|██████▎   | 96/153 [00:01<00:01, 53.21it/s, Epoch: 45, Batch: 97,Loss: -1.861,Avg.Loss: -2.178,LR: 2.92E-04]Training epoch 45:  63%|██████▎   | 97/153 [00:01<00:01, 53.20it/s, Epoch: 45, Batch: 97,Loss: -1.861,Avg.Loss: -2.178,LR: 2.92E-04]Training epoch 45:  63%|██████▎   | 97/153 [00:01<00:01, 53.20it/s, Epoch: 45, Batch: 98,Loss: -2.514,Avg.Loss: -2.181,LR: 2.92E-04]Training epoch 45:  64%|██████▍   | 98/153 [00:01<00:01, 53.20it/s, Epoch: 45, Batch: 99,Loss: -2.052,Avg.Loss: -2.180,LR: 2.92E-04]Training epoch 45:  65%|██████▍   | 99/153 [00:01<00:01, 53.20it/s, Epoch: 45, Batch: 100,Loss: -2.452,Avg.Loss: -2.183,LR: 2.92E-04]Training epoch 45:  65%|██████▌   | 100/153 [00:01<00:00, 53.20it/s, Epoch: 45, Batch: 101,Loss: -2.241,Avg.Loss: -2.183,LR: 2.92E-04]Training epoch 45:  66%|██████▌   | 101/153 [00:01<00:00, 53.20it/s, Epoch: 45, Batch: 102,Loss: -1.838,Avg.Loss: -2.180,LR: 2.92E-04]Training epoch 45:  67%|██████▋   | 102/153 [00:01<00:00, 53.20it/s, Epoch: 45, Batch: 103,Loss: -1.899,Avg.Loss: -2.177,LR: 2.92E-04]Training epoch 45:  67%|██████▋   | 103/153 [00:01<00:00, 53.04it/s, Epoch: 45, Batch: 103,Loss: -1.899,Avg.Loss: -2.177,LR: 2.92E-04]Training epoch 45:  67%|██████▋   | 103/153 [00:01<00:00, 53.04it/s, Epoch: 45, Batch: 104,Loss: -2.322,Avg.Loss: -2.179,LR: 2.92E-04]Training epoch 45:  68%|██████▊   | 104/153 [00:01<00:00, 53.04it/s, Epoch: 45, Batch: 105,Loss: -2.121,Avg.Loss: -2.178,LR: 2.92E-04]Training epoch 45:  69%|██████▊   | 105/153 [00:01<00:00, 53.04it/s, Epoch: 45, Batch: 106,Loss: -1.627,Avg.Loss: -2.173,LR: 2.91E-04]Training epoch 45:  69%|██████▉   | 106/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 107,Loss: -1.409,Avg.Loss: -2.166,LR: 2.91E-04]Training epoch 45:  70%|██████▉   | 107/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 108,Loss: -1.443,Avg.Loss: -2.159,LR: 2.91E-04]Training epoch 45:  71%|███████   | 108/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 109,Loss: -2.300,Avg.Loss: -2.160,LR: 2.91E-04]Training epoch 45:  71%|███████   | 109/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 109,Loss: -2.300,Avg.Loss: -2.160,LR: 2.91E-04]Training epoch 45:  71%|███████   | 109/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 110,Loss: -2.539,Avg.Loss: -2.164,LR: 2.91E-04]Training epoch 45:  72%|███████▏  | 110/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 111,Loss: -2.201,Avg.Loss: -2.164,LR: 2.91E-04]Training epoch 45:  73%|███████▎  | 111/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 112,Loss: -2.050,Avg.Loss: -2.163,LR: 2.91E-04]Training epoch 45:  73%|███████▎  | 112/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 113,Loss: -1.873,Avg.Loss: -2.161,LR: 2.91E-04]Training epoch 45:  74%|███████▍  | 113/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 114,Loss: -1.945,Avg.Loss: -2.159,LR: 2.91E-04]Training epoch 45:  75%|███████▍  | 114/153 [00:02<00:00, 53.04it/s, Epoch: 45, Batch: 115,Loss: -2.184,Avg.Loss: -2.159,LR: 2.91E-04]Training epoch 45:  75%|███████▌  | 115/153 [00:02<00:00, 53.11it/s, Epoch: 45, Batch: 115,Loss: -2.184,Avg.Loss: -2.159,LR: 2.91E-04]Training epoch 45:  75%|███████▌  | 115/153 [00:02<00:00, 53.11it/s, Epoch: 45, Batch: 116,Loss: -2.174,Avg.Loss: -2.159,LR: 2.91E-04]Training epoch 45:  76%|███████▌  | 116/153 [00:02<00:00, 53.11it/s, Epoch: 45, Batch: 117,Loss: -2.430,Avg.Loss: -2.161,LR: 2.91E-04]Training epoch 45:  76%|███████▋  | 117/153 [00:02<00:00, 53.11it/s, Epoch: 45, Batch: 118,Loss: -2.404,Avg.Loss: -2.163,LR: 2.91E-04]Training epoch 45:  77%|███████▋  | 118/153 [00:02<00:00, 53.11it/s, Epoch: 45, Batch: 119,Loss: -2.632,Avg.Loss: -2.167,LR: 2.91E-04]Training epoch 45:  78%|███████▊  | 119/153 [00:02<00:00, 53.11it/s, Epoch: 45, Batch: 120,Loss: -1.986,Avg.Loss: -2.166,LR: 2.91E-04]Training epoch 45:  78%|███████▊  | 120/153 [00:02<00:00, 53.11it/s, Epoch: 45, Batch: 121,Loss: -1.913,Avg.Loss: -2.164,LR: 2.91E-04]Training epoch 45:  79%|███████▉  | 121/153 [00:02<00:00, 53.21it/s, Epoch: 45, Batch: 121,Loss: -1.913,Avg.Loss: -2.164,LR: 2.91E-04]Training epoch 45:  79%|███████▉  | 121/153 [00:02<00:00, 53.21it/s, Epoch: 45, Batch: 122,Loss: -1.160,Avg.Loss: -2.155,LR: 2.91E-04]Training epoch 45:  80%|███████▉  | 122/153 [00:02<00:00, 53.21it/s, Epoch: 45, Batch: 123,Loss: -1.841,Avg.Loss: -2.153,LR: 2.91E-04]Training epoch 45:  80%|████████  | 123/153 [00:02<00:00, 53.21it/s, Epoch: 45, Batch: 124,Loss: -2.651,Avg.Loss: -2.157,LR: 2.91E-04]Training epoch 45:  81%|████████  | 124/153 [00:02<00:00, 53.21it/s, Epoch: 45, Batch: 125,Loss: -2.651,Avg.Loss: -2.161,LR: 2.91E-04]Training epoch 45:  82%|████████▏ | 125/153 [00:02<00:00, 53.21it/s, Epoch: 45, Batch: 126,Loss: -2.121,Avg.Loss: -2.161,LR: 2.90E-04]Training epoch 45:  82%|████████▏ | 126/153 [00:02<00:00, 53.21it/s, Epoch: 45, Batch: 127,Loss: -2.321,Avg.Loss: -2.162,LR: 2.90E-04]Training epoch 45:  83%|████████▎ | 127/153 [00:02<00:00, 52.93it/s, Epoch: 45, Batch: 127,Loss: -2.321,Avg.Loss: -2.162,LR: 2.90E-04]Training epoch 45:  83%|████████▎ | 127/153 [00:02<00:00, 52.93it/s, Epoch: 45, Batch: 128,Loss: -2.017,Avg.Loss: -2.161,LR: 2.90E-04]Training epoch 45:  84%|████████▎ | 128/153 [00:02<00:00, 52.93it/s, Epoch: 45, Batch: 129,Loss: -1.781,Avg.Loss: -2.158,LR: 2.90E-04]Training epoch 45:  84%|████████▍ | 129/153 [00:02<00:00, 52.93it/s, Epoch: 45, Batch: 130,Loss: -2.224,Avg.Loss: -2.158,LR: 2.90E-04]Training epoch 45:  85%|████████▍ | 130/153 [00:02<00:00, 52.93it/s, Epoch: 45, Batch: 131,Loss: -2.188,Avg.Loss: -2.158,LR: 2.90E-04]Training epoch 45:  86%|████████▌ | 131/153 [00:02<00:00, 52.93it/s, Epoch: 45, Batch: 132,Loss: -1.756,Avg.Loss: -2.155,LR: 2.90E-04]Training epoch 45:  86%|████████▋ | 132/153 [00:02<00:00, 52.93it/s, Epoch: 45, Batch: 133,Loss: -1.852,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  87%|████████▋ | 133/153 [00:02<00:00, 52.91it/s, Epoch: 45, Batch: 133,Loss: -1.852,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  87%|████████▋ | 133/153 [00:02<00:00, 52.91it/s, Epoch: 45, Batch: 134,Loss: -2.114,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  88%|████████▊ | 134/153 [00:02<00:00, 52.91it/s, Epoch: 45, Batch: 135,Loss: -2.105,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  88%|████████▊ | 135/153 [00:02<00:00, 52.91it/s, Epoch: 45, Batch: 136,Loss: -2.447,Avg.Loss: -2.155,LR: 2.90E-04]Training epoch 45:  89%|████████▉ | 136/153 [00:02<00:00, 52.91it/s, Epoch: 45, Batch: 137,Loss: -1.840,Avg.Loss: -2.152,LR: 2.90E-04]Training epoch 45:  90%|████████▉ | 137/153 [00:02<00:00, 52.91it/s, Epoch: 45, Batch: 138,Loss: -1.695,Avg.Loss: -2.149,LR: 2.90E-04]Training epoch 45:  90%|█████████ | 138/153 [00:02<00:00, 52.91it/s, Epoch: 45, Batch: 139,Loss: -2.109,Avg.Loss: -2.149,LR: 2.90E-04]Training epoch 45:  91%|█████████ | 139/153 [00:02<00:00, 52.99it/s, Epoch: 45, Batch: 139,Loss: -2.109,Avg.Loss: -2.149,LR: 2.90E-04]Training epoch 45:  91%|█████████ | 139/153 [00:02<00:00, 52.99it/s, Epoch: 45, Batch: 140,Loss: -2.571,Avg.Loss: -2.152,LR: 2.90E-04]Training epoch 45:  92%|█████████▏| 140/153 [00:02<00:00, 52.99it/s, Epoch: 45, Batch: 141,Loss: -2.315,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  92%|█████████▏| 141/153 [00:02<00:00, 52.99it/s, Epoch: 45, Batch: 142,Loss: -2.406,Avg.Loss: -2.155,LR: 2.90E-04]Training epoch 45:  93%|█████████▎| 142/153 [00:02<00:00, 52.99it/s, Epoch: 45, Batch: 143,Loss: -1.937,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  93%|█████████▎| 143/153 [00:02<00:00, 52.99it/s, Epoch: 45, Batch: 144,Loss: -2.064,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  94%|█████████▍| 144/153 [00:02<00:00, 52.99it/s, Epoch: 45, Batch: 145,Loss: -2.256,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  95%|█████████▍| 145/153 [00:02<00:00, 53.06it/s, Epoch: 45, Batch: 145,Loss: -2.256,Avg.Loss: -2.153,LR: 2.90E-04]Training epoch 45:  95%|█████████▍| 145/153 [00:02<00:00, 53.06it/s, Epoch: 45, Batch: 146,Loss: -2.439,Avg.Loss: -2.155,LR: 2.89E-04]Training epoch 45:  95%|█████████▌| 146/153 [00:02<00:00, 53.06it/s, Epoch: 45, Batch: 147,Loss: -2.255,Avg.Loss: -2.156,LR: 2.89E-04]Training epoch 45:  96%|█████████▌| 147/153 [00:02<00:00, 53.06it/s, Epoch: 45, Batch: 148,Loss: -2.629,Avg.Loss: -2.159,LR: 2.89E-04]Training epoch 45:  97%|█████████▋| 148/153 [00:02<00:00, 53.06it/s, Epoch: 45, Batch: 149,Loss: -2.491,Avg.Loss: -2.161,LR: 2.89E-04]Training epoch 45:  97%|█████████▋| 149/153 [00:02<00:00, 53.06it/s, Epoch: 45, Batch: 150,Loss: -2.344,Avg.Loss: -2.163,LR: 2.89E-04]Training epoch 45:  98%|█████████▊| 150/153 [00:02<00:00, 53.06it/s, Epoch: 45, Batch: 151,Loss: -2.211,Avg.Loss: -2.163,LR: 2.89E-04]Training epoch 45:  99%|█████████▊| 151/153 [00:02<00:00, 53.00it/s, Epoch: 45, Batch: 151,Loss: -2.211,Avg.Loss: -2.163,LR: 2.89E-04]Training epoch 45:  99%|█████████▊| 151/153 [00:02<00:00, 53.00it/s, Epoch: 45, Batch: 152,Loss: -1.887,Avg.Loss: -2.161,LR: 2.89E-04]Training epoch 45:  99%|█████████▉| 152/153 [00:02<00:00, 53.00it/s, Epoch: 45, Batch: 153,Loss: -1.621,Avg.Loss: -2.158,LR: 2.89E-04]Training epoch 45: 100%|██████████| 153/153 [00:02<00:00, 53.10it/s, Epoch: 45, Batch: 153,Loss: -1.621,Avg.Loss: -2.158,LR: 2.89E-04]
Training epoch 46:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 46:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 46, Batch: 1,Loss: -2.734,Avg.Loss: -2.734,LR: 2.89E-04]Training epoch 46:   1%|          | 1/153 [00:00<00:05, 29.30it/s, Epoch: 46, Batch: 2,Loss: -2.537,Avg.Loss: -2.635,LR: 2.89E-04]Training epoch 46:   1%|▏         | 2/153 [00:00<00:03, 42.26it/s, Epoch: 46, Batch: 3,Loss: -1.473,Avg.Loss: -2.248,LR: 2.89E-04]Training epoch 46:   2%|▏         | 3/153 [00:00<00:03, 46.57it/s, Epoch: 46, Batch: 4,Loss: -2.096,Avg.Loss: -2.210,LR: 2.89E-04]Training epoch 46:   3%|▎         | 4/153 [00:00<00:03, 48.20it/s, Epoch: 46, Batch: 5,Loss: -2.029,Avg.Loss: -2.174,LR: 2.89E-04]Training epoch 46:   3%|▎         | 5/153 [00:00<00:03, 49.17it/s, Epoch: 46, Batch: 6,Loss: -2.116,Avg.Loss: -2.164,LR: 2.89E-04]Training epoch 46:   4%|▍         | 6/153 [00:00<00:02, 58.91it/s, Epoch: 46, Batch: 6,Loss: -2.116,Avg.Loss: -2.164,LR: 2.89E-04]Training epoch 46:   4%|▍         | 6/153 [00:00<00:02, 58.91it/s, Epoch: 46, Batch: 7,Loss: -2.594,Avg.Loss: -2.226,LR: 2.89E-04]Training epoch 46:   5%|▍         | 7/153 [00:00<00:02, 58.91it/s, Epoch: 46, Batch: 8,Loss: -2.327,Avg.Loss: -2.238,LR: 2.89E-04]Training epoch 46:   5%|▌         | 8/153 [00:00<00:02, 58.91it/s, Epoch: 46, Batch: 9,Loss: -2.209,Avg.Loss: -2.235,LR: 2.89E-04]Training epoch 46:   6%|▌         | 9/153 [00:00<00:02, 58.91it/s, Epoch: 46, Batch: 10,Loss: -2.047,Avg.Loss: -2.216,LR: 2.89E-04]Training epoch 46:   7%|▋         | 10/153 [00:00<00:02, 58.91it/s, Epoch: 46, Batch: 11,Loss: -2.010,Avg.Loss: -2.197,LR: 2.89E-04]Training epoch 46:   7%|▋         | 11/153 [00:00<00:02, 58.91it/s, Epoch: 46, Batch: 12,Loss: -2.340,Avg.Loss: -2.209,LR: 2.89E-04]Training epoch 46:   8%|▊         | 12/153 [00:00<00:02, 55.41it/s, Epoch: 46, Batch: 12,Loss: -2.340,Avg.Loss: -2.209,LR: 2.89E-04]Training epoch 46:   8%|▊         | 12/153 [00:00<00:02, 55.41it/s, Epoch: 46, Batch: 13,Loss: -2.836,Avg.Loss: -2.258,LR: 2.88E-04]Training epoch 46:   8%|▊         | 13/153 [00:00<00:02, 55.41it/s, Epoch: 46, Batch: 14,Loss: -1.736,Avg.Loss: -2.220,LR: 2.88E-04]Training epoch 46:   9%|▉         | 14/153 [00:00<00:02, 55.41it/s, Epoch: 46, Batch: 15,Loss: -1.366,Avg.Loss: -2.163,LR: 2.88E-04]Training epoch 46:  10%|▉         | 15/153 [00:00<00:02, 55.41it/s, Epoch: 46, Batch: 16,Loss: -2.646,Avg.Loss: -2.193,LR: 2.88E-04]Training epoch 46:  10%|█         | 16/153 [00:00<00:02, 55.41it/s, Epoch: 46, Batch: 17,Loss: -2.653,Avg.Loss: -2.221,LR: 2.88E-04]Training epoch 46:  11%|█         | 17/153 [00:00<00:02, 55.41it/s, Epoch: 46, Batch: 18,Loss: -2.546,Avg.Loss: -2.239,LR: 2.88E-04]Training epoch 46:  12%|█▏        | 18/153 [00:00<00:02, 54.29it/s, Epoch: 46, Batch: 18,Loss: -2.546,Avg.Loss: -2.239,LR: 2.88E-04]Training epoch 46:  12%|█▏        | 18/153 [00:00<00:02, 54.29it/s, Epoch: 46, Batch: 19,Loss: -1.953,Avg.Loss: -2.224,LR: 2.88E-04]Training epoch 46:  12%|█▏        | 19/153 [00:00<00:02, 54.29it/s, Epoch: 46, Batch: 20,Loss: -1.569,Avg.Loss: -2.191,LR: 2.88E-04]Training epoch 46:  13%|█▎        | 20/153 [00:00<00:02, 54.29it/s, Epoch: 46, Batch: 21,Loss: -1.476,Avg.Loss: -2.157,LR: 2.88E-04]Training epoch 46:  14%|█▎        | 21/153 [00:00<00:02, 54.29it/s, Epoch: 46, Batch: 22,Loss: -2.863,Avg.Loss: -2.189,LR: 2.88E-04]Training epoch 46:  14%|█▍        | 22/153 [00:00<00:02, 54.29it/s, Epoch: 46, Batch: 23,Loss: -2.256,Avg.Loss: -2.192,LR: 2.88E-04]Training epoch 46:  15%|█▌        | 23/153 [00:00<00:02, 54.29it/s, Epoch: 46, Batch: 24,Loss: -1.539,Avg.Loss: -2.165,LR: 2.88E-04]Training epoch 46:  16%|█▌        | 24/153 [00:00<00:02, 51.53it/s, Epoch: 46, Batch: 24,Loss: -1.539,Avg.Loss: -2.165,LR: 2.88E-04]Training epoch 46:  16%|█▌        | 24/153 [00:00<00:02, 51.53it/s, Epoch: 46, Batch: 25,Loss: -1.725,Avg.Loss: -2.147,LR: 2.88E-04]Training epoch 46:  16%|█▋        | 25/153 [00:00<00:02, 51.53it/s, Epoch: 46, Batch: 26,Loss: -2.105,Avg.Loss: -2.145,LR: 2.88E-04]Training epoch 46:  17%|█▋        | 26/153 [00:00<00:02, 51.53it/s, Epoch: 46, Batch: 27,Loss: -2.330,Avg.Loss: -2.152,LR: 2.88E-04]Training epoch 46:  18%|█▊        | 27/153 [00:00<00:02, 51.53it/s, Epoch: 46, Batch: 28,Loss: -1.838,Avg.Loss: -2.141,LR: 2.88E-04]Training epoch 46:  18%|█▊        | 28/153 [00:00<00:02, 51.53it/s, Epoch: 46, Batch: 29,Loss: -2.061,Avg.Loss: -2.138,LR: 2.88E-04]Training epoch 46:  19%|█▉        | 29/153 [00:00<00:02, 51.53it/s, Epoch: 46, Batch: 30,Loss: -1.680,Avg.Loss: -2.123,LR: 2.88E-04]Training epoch 46:  20%|█▉        | 30/153 [00:00<00:02, 51.57it/s, Epoch: 46, Batch: 30,Loss: -1.680,Avg.Loss: -2.123,LR: 2.88E-04]Training epoch 46:  20%|█▉        | 30/153 [00:00<00:02, 51.57it/s, Epoch: 46, Batch: 31,Loss: -1.288,Avg.Loss: -2.096,LR: 2.88E-04]Training epoch 46:  20%|██        | 31/153 [00:00<00:02, 51.57it/s, Epoch: 46, Batch: 32,Loss: -2.395,Avg.Loss: -2.105,LR: 2.87E-04]Training epoch 46:  21%|██        | 32/153 [00:00<00:02, 51.57it/s, Epoch: 46, Batch: 33,Loss: -2.367,Avg.Loss: -2.113,LR: 2.87E-04]Training epoch 46:  22%|██▏       | 33/153 [00:00<00:02, 51.57it/s, Epoch: 46, Batch: 34,Loss: -2.106,Avg.Loss: -2.113,LR: 2.87E-04]Training epoch 46:  22%|██▏       | 34/153 [00:00<00:02, 51.57it/s, Epoch: 46, Batch: 35,Loss: -1.285,Avg.Loss: -2.089,LR: 2.87E-04]Training epoch 46:  23%|██▎       | 35/153 [00:00<00:02, 51.57it/s, Epoch: 46, Batch: 36,Loss: -1.249,Avg.Loss: -2.066,LR: 2.87E-04]Training epoch 46:  24%|██▎       | 36/153 [00:00<00:02, 51.88it/s, Epoch: 46, Batch: 36,Loss: -1.249,Avg.Loss: -2.066,LR: 2.87E-04]Training epoch 46:  24%|██▎       | 36/153 [00:00<00:02, 51.88it/s, Epoch: 46, Batch: 37,Loss: -1.021,Avg.Loss: -2.038,LR: 2.87E-04]Training epoch 46:  24%|██▍       | 37/153 [00:00<00:02, 51.88it/s, Epoch: 46, Batch: 38,Loss: -1.734,Avg.Loss: -2.030,LR: 2.87E-04]Training epoch 46:  25%|██▍       | 38/153 [00:00<00:02, 51.88it/s, Epoch: 46, Batch: 39,Loss: 0.157,Avg.Loss: -1.974,LR: 2.87E-04] Training epoch 46:  25%|██▌       | 39/153 [00:00<00:02, 51.88it/s, Epoch: 46, Batch: 40,Loss: -1.761,Avg.Loss: -1.968,LR: 2.87E-04]Training epoch 46:  26%|██▌       | 40/153 [00:00<00:02, 51.88it/s, Epoch: 46, Batch: 41,Loss: -2.003,Avg.Loss: -1.969,LR: 2.87E-04]Training epoch 46:  27%|██▋       | 41/153 [00:00<00:02, 51.88it/s, Epoch: 46, Batch: 42,Loss: -1.218,Avg.Loss: -1.951,LR: 2.87E-04]Training epoch 46:  27%|██▋       | 42/153 [00:00<00:02, 52.26it/s, Epoch: 46, Batch: 42,Loss: -1.218,Avg.Loss: -1.951,LR: 2.87E-04]Training epoch 46:  27%|██▋       | 42/153 [00:00<00:02, 52.26it/s, Epoch: 46, Batch: 43,Loss: 0.082,Avg.Loss: -1.904,LR: 2.87E-04] Training epoch 46:  28%|██▊       | 43/153 [00:00<00:02, 52.26it/s, Epoch: 46, Batch: 44,Loss: -0.576,Avg.Loss: -1.874,LR: 2.87E-04]Training epoch 46:  29%|██▉       | 44/153 [00:00<00:02, 52.26it/s, Epoch: 46, Batch: 45,Loss: -1.721,Avg.Loss: -1.871,LR: 2.87E-04]Training epoch 46:  29%|██▉       | 45/153 [00:00<00:02, 52.26it/s, Epoch: 46, Batch: 46,Loss: -2.112,Avg.Loss: -1.876,LR: 2.87E-04]Training epoch 46:  30%|███       | 46/153 [00:00<00:02, 52.26it/s, Epoch: 46, Batch: 47,Loss: -1.949,Avg.Loss: -1.877,LR: 2.87E-04]Training epoch 46:  31%|███       | 47/153 [00:00<00:02, 52.26it/s, Epoch: 46, Batch: 48,Loss: -2.055,Avg.Loss: -1.881,LR: 2.87E-04]Training epoch 46:  31%|███▏      | 48/153 [00:00<00:02, 52.31it/s, Epoch: 46, Batch: 48,Loss: -2.055,Avg.Loss: -1.881,LR: 2.87E-04]Training epoch 46:  31%|███▏      | 48/153 [00:00<00:02, 52.31it/s, Epoch: 46, Batch: 49,Loss: -2.592,Avg.Loss: -1.896,LR: 2.87E-04]Training epoch 46:  32%|███▏      | 49/153 [00:00<00:01, 52.31it/s, Epoch: 46, Batch: 50,Loss: -2.204,Avg.Loss: -1.902,LR: 2.87E-04]Training epoch 46:  33%|███▎      | 50/153 [00:00<00:01, 52.31it/s, Epoch: 46, Batch: 51,Loss: -1.370,Avg.Loss: -1.891,LR: 2.87E-04]Training epoch 46:  33%|███▎      | 51/153 [00:00<00:01, 52.31it/s, Epoch: 46, Batch: 52,Loss: -1.754,Avg.Loss: -1.889,LR: 2.86E-04]Training epoch 46:  34%|███▍      | 52/153 [00:01<00:01, 52.31it/s, Epoch: 46, Batch: 53,Loss: -2.405,Avg.Loss: -1.898,LR: 2.86E-04]Training epoch 46:  35%|███▍      | 53/153 [00:01<00:01, 52.31it/s, Epoch: 46, Batch: 54,Loss: -2.336,Avg.Loss: -1.906,LR: 2.86E-04]Training epoch 46:  35%|███▌      | 54/153 [00:01<00:01, 52.52it/s, Epoch: 46, Batch: 54,Loss: -2.336,Avg.Loss: -1.906,LR: 2.86E-04]Training epoch 46:  35%|███▌      | 54/153 [00:01<00:01, 52.52it/s, Epoch: 46, Batch: 55,Loss: -1.416,Avg.Loss: -1.898,LR: 2.86E-04]Training epoch 46:  36%|███▌      | 55/153 [00:01<00:01, 52.52it/s, Epoch: 46, Batch: 56,Loss: -1.747,Avg.Loss: -1.895,LR: 2.86E-04]Training epoch 46:  37%|███▋      | 56/153 [00:01<00:01, 52.52it/s, Epoch: 46, Batch: 57,Loss: -2.165,Avg.Loss: -1.900,LR: 2.86E-04]Training epoch 46:  37%|███▋      | 57/153 [00:01<00:01, 52.52it/s, Epoch: 46, Batch: 58,Loss: -1.550,Avg.Loss: -1.894,LR: 2.86E-04]Training epoch 46:  38%|███▊      | 58/153 [00:01<00:01, 52.52it/s, Epoch: 46, Batch: 59,Loss: -0.909,Avg.Loss: -1.877,LR: 2.86E-04]Training epoch 46:  39%|███▊      | 59/153 [00:01<00:01, 52.52it/s, Epoch: 46, Batch: 60,Loss: -1.136,Avg.Loss: -1.865,LR: 2.86E-04]Training epoch 46:  39%|███▉      | 60/153 [00:01<00:01, 52.28it/s, Epoch: 46, Batch: 60,Loss: -1.136,Avg.Loss: -1.865,LR: 2.86E-04]Training epoch 46:  39%|███▉      | 60/153 [00:01<00:01, 52.28it/s, Epoch: 46, Batch: 61,Loss: -1.941,Avg.Loss: -1.866,LR: 2.86E-04]Training epoch 46:  40%|███▉      | 61/153 [00:01<00:01, 52.28it/s, Epoch: 46, Batch: 62,Loss: -2.322,Avg.Loss: -1.873,LR: 2.86E-04]Training epoch 46:  41%|████      | 62/153 [00:01<00:01, 52.28it/s, Epoch: 46, Batch: 63,Loss: -1.798,Avg.Loss: -1.872,LR: 2.86E-04]Training epoch 46:  41%|████      | 63/153 [00:01<00:01, 52.28it/s, Epoch: 46, Batch: 64,Loss: -1.948,Avg.Loss: -1.873,LR: 2.86E-04]Training epoch 46:  42%|████▏     | 64/153 [00:01<00:01, 52.28it/s, Epoch: 46, Batch: 65,Loss: -2.806,Avg.Loss: -1.888,LR: 2.86E-04]Training epoch 46:  42%|████▏     | 65/153 [00:01<00:01, 52.28it/s, Epoch: 46, Batch: 66,Loss: -2.133,Avg.Loss: -1.891,LR: 2.86E-04]Training epoch 46:  43%|████▎     | 66/153 [00:01<00:01, 52.54it/s, Epoch: 46, Batch: 66,Loss: -2.133,Avg.Loss: -1.891,LR: 2.86E-04]Training epoch 46:  43%|████▎     | 66/153 [00:01<00:01, 52.54it/s, Epoch: 46, Batch: 67,Loss: -0.785,Avg.Loss: -1.875,LR: 2.86E-04]Training epoch 46:  44%|████▍     | 67/153 [00:01<00:01, 52.54it/s, Epoch: 46, Batch: 68,Loss: -1.479,Avg.Loss: -1.869,LR: 2.86E-04]Training epoch 46:  44%|████▍     | 68/153 [00:01<00:01, 52.54it/s, Epoch: 46, Batch: 69,Loss: -2.514,Avg.Loss: -1.878,LR: 2.86E-04]Training epoch 46:  45%|████▌     | 69/153 [00:01<00:01, 52.54it/s, Epoch: 46, Batch: 70,Loss: -1.884,Avg.Loss: -1.878,LR: 2.86E-04]Training epoch 46:  46%|████▌     | 70/153 [00:01<00:01, 52.54it/s, Epoch: 46, Batch: 71,Loss: -1.873,Avg.Loss: -1.878,LR: 2.86E-04]Training epoch 46:  46%|████▋     | 71/153 [00:01<00:01, 52.54it/s, Epoch: 46, Batch: 72,Loss: -1.806,Avg.Loss: -1.877,LR: 2.85E-04]Training epoch 46:  47%|████▋     | 72/153 [00:01<00:01, 52.70it/s, Epoch: 46, Batch: 72,Loss: -1.806,Avg.Loss: -1.877,LR: 2.85E-04]Training epoch 46:  47%|████▋     | 72/153 [00:01<00:01, 52.70it/s, Epoch: 46, Batch: 73,Loss: -2.693,Avg.Loss: -1.888,LR: 2.85E-04]Training epoch 46:  48%|████▊     | 73/153 [00:01<00:01, 52.70it/s, Epoch: 46, Batch: 74,Loss: -2.221,Avg.Loss: -1.893,LR: 2.85E-04]Training epoch 46:  48%|████▊     | 74/153 [00:01<00:01, 52.70it/s, Epoch: 46, Batch: 75,Loss: -1.335,Avg.Loss: -1.885,LR: 2.85E-04]Training epoch 46:  49%|████▉     | 75/153 [00:01<00:01, 52.70it/s, Epoch: 46, Batch: 76,Loss: -1.918,Avg.Loss: -1.886,LR: 2.85E-04]Training epoch 46:  50%|████▉     | 76/153 [00:01<00:01, 52.70it/s, Epoch: 46, Batch: 77,Loss: -2.736,Avg.Loss: -1.897,LR: 2.85E-04]Training epoch 46:  50%|█████     | 77/153 [00:01<00:01, 52.70it/s, Epoch: 46, Batch: 78,Loss: -1.680,Avg.Loss: -1.894,LR: 2.85E-04]Training epoch 46:  51%|█████     | 78/153 [00:01<00:01, 52.84it/s, Epoch: 46, Batch: 78,Loss: -1.680,Avg.Loss: -1.894,LR: 2.85E-04]Training epoch 46:  51%|█████     | 78/153 [00:01<00:01, 52.84it/s, Epoch: 46, Batch: 79,Loss: -0.438,Avg.Loss: -1.876,LR: 2.85E-04]Training epoch 46:  52%|█████▏    | 79/153 [00:01<00:01, 52.84it/s, Epoch: 46, Batch: 80,Loss: -1.036,Avg.Loss: -1.865,LR: 2.85E-04]Training epoch 46:  52%|█████▏    | 80/153 [00:01<00:01, 52.84it/s, Epoch: 46, Batch: 81,Loss: -1.837,Avg.Loss: -1.865,LR: 2.85E-04]Training epoch 46:  53%|█████▎    | 81/153 [00:01<00:01, 52.84it/s, Epoch: 46, Batch: 82,Loss: -2.208,Avg.Loss: -1.869,LR: 2.85E-04]Training epoch 46:  54%|█████▎    | 82/153 [00:01<00:01, 52.84it/s, Epoch: 46, Batch: 83,Loss: -2.442,Avg.Loss: -1.876,LR: 2.85E-04]Training epoch 46:  54%|█████▍    | 83/153 [00:01<00:01, 52.84it/s, Epoch: 46, Batch: 84,Loss: -2.157,Avg.Loss: -1.879,LR: 2.85E-04]Training epoch 46:  55%|█████▍    | 84/153 [00:01<00:01, 52.67it/s, Epoch: 46, Batch: 84,Loss: -2.157,Avg.Loss: -1.879,LR: 2.85E-04]Training epoch 46:  55%|█████▍    | 84/153 [00:01<00:01, 52.67it/s, Epoch: 46, Batch: 85,Loss: -2.340,Avg.Loss: -1.885,LR: 2.85E-04]Training epoch 46:  56%|█████▌    | 85/153 [00:01<00:01, 52.67it/s, Epoch: 46, Batch: 86,Loss: -2.545,Avg.Loss: -1.892,LR: 2.85E-04]Training epoch 46:  56%|█████▌    | 86/153 [00:01<00:01, 52.67it/s, Epoch: 46, Batch: 87,Loss: -2.465,Avg.Loss: -1.899,LR: 2.85E-04]Training epoch 46:  57%|█████▋    | 87/153 [00:01<00:01, 52.67it/s, Epoch: 46, Batch: 88,Loss: -2.350,Avg.Loss: -1.904,LR: 2.85E-04]Training epoch 46:  58%|█████▊    | 88/153 [00:01<00:01, 52.67it/s, Epoch: 46, Batch: 89,Loss: -2.484,Avg.Loss: -1.911,LR: 2.85E-04]Training epoch 46:  58%|█████▊    | 89/153 [00:01<00:01, 52.67it/s, Epoch: 46, Batch: 90,Loss: -2.568,Avg.Loss: -1.918,LR: 2.85E-04]Training epoch 46:  59%|█████▉    | 90/153 [00:01<00:01, 52.73it/s, Epoch: 46, Batch: 90,Loss: -2.568,Avg.Loss: -1.918,LR: 2.85E-04]Training epoch 46:  59%|█████▉    | 90/153 [00:01<00:01, 52.73it/s, Epoch: 46, Batch: 91,Loss: -2.590,Avg.Loss: -1.925,LR: 2.84E-04]Training epoch 46:  59%|█████▉    | 91/153 [00:01<00:01, 52.73it/s, Epoch: 46, Batch: 92,Loss: -2.720,Avg.Loss: -1.934,LR: 2.84E-04]Training epoch 46:  60%|██████    | 92/153 [00:01<00:01, 52.73it/s, Epoch: 46, Batch: 93,Loss: -2.077,Avg.Loss: -1.935,LR: 2.84E-04]Training epoch 46:  61%|██████    | 93/153 [00:01<00:01, 52.73it/s, Epoch: 46, Batch: 94,Loss: -2.456,Avg.Loss: -1.941,LR: 2.84E-04]Training epoch 46:  61%|██████▏   | 94/153 [00:01<00:01, 52.73it/s, Epoch: 46, Batch: 95,Loss: -2.371,Avg.Loss: -1.946,LR: 2.84E-04]Training epoch 46:  62%|██████▏   | 95/153 [00:01<00:01, 52.73it/s, Epoch: 46, Batch: 96,Loss: -2.655,Avg.Loss: -1.953,LR: 2.84E-04]Training epoch 46:  63%|██████▎   | 96/153 [00:01<00:01, 52.80it/s, Epoch: 46, Batch: 96,Loss: -2.655,Avg.Loss: -1.953,LR: 2.84E-04]Training epoch 46:  63%|██████▎   | 96/153 [00:01<00:01, 52.80it/s, Epoch: 46, Batch: 97,Loss: -2.300,Avg.Loss: -1.956,LR: 2.84E-04]Training epoch 46:  63%|██████▎   | 97/153 [00:01<00:01, 52.80it/s, Epoch: 46, Batch: 98,Loss: -2.385,Avg.Loss: -1.961,LR: 2.84E-04]Training epoch 46:  64%|██████▍   | 98/153 [00:01<00:01, 52.80it/s, Epoch: 46, Batch: 99,Loss: -2.132,Avg.Loss: -1.963,LR: 2.84E-04]Training epoch 46:  65%|██████▍   | 99/153 [00:01<00:01, 52.80it/s, Epoch: 46, Batch: 100,Loss: -2.139,Avg.Loss: -1.964,LR: 2.84E-04]Training epoch 46:  65%|██████▌   | 100/153 [00:01<00:01, 52.80it/s, Epoch: 46, Batch: 101,Loss: -2.832,Avg.Loss: -1.973,LR: 2.84E-04]Training epoch 46:  66%|██████▌   | 101/153 [00:01<00:00, 52.80it/s, Epoch: 46, Batch: 102,Loss: -2.548,Avg.Loss: -1.979,LR: 2.84E-04]Training epoch 46:  67%|██████▋   | 102/153 [00:01<00:00, 52.28it/s, Epoch: 46, Batch: 102,Loss: -2.548,Avg.Loss: -1.979,LR: 2.84E-04]Training epoch 46:  67%|██████▋   | 102/153 [00:01<00:00, 52.28it/s, Epoch: 46, Batch: 103,Loss: -2.296,Avg.Loss: -1.982,LR: 2.84E-04]Training epoch 46:  67%|██████▋   | 103/153 [00:01<00:00, 52.28it/s, Epoch: 46, Batch: 104,Loss: -2.362,Avg.Loss: -1.985,LR: 2.84E-04]Training epoch 46:  68%|██████▊   | 104/153 [00:01<00:00, 52.28it/s, Epoch: 46, Batch: 105,Loss: -2.417,Avg.Loss: -1.989,LR: 2.84E-04]Training epoch 46:  69%|██████▊   | 105/153 [00:02<00:00, 52.28it/s, Epoch: 46, Batch: 106,Loss: -2.522,Avg.Loss: -1.994,LR: 2.84E-04]Training epoch 46:  69%|██████▉   | 106/153 [00:02<00:00, 52.28it/s, Epoch: 46, Batch: 107,Loss: -2.666,Avg.Loss: -2.001,LR: 2.84E-04]Training epoch 46:  70%|██████▉   | 107/153 [00:02<00:00, 52.28it/s, Epoch: 46, Batch: 108,Loss: -2.306,Avg.Loss: -2.004,LR: 2.84E-04]Training epoch 46:  71%|███████   | 108/153 [00:02<00:00, 52.45it/s, Epoch: 46, Batch: 108,Loss: -2.306,Avg.Loss: -2.004,LR: 2.84E-04]Training epoch 46:  71%|███████   | 108/153 [00:02<00:00, 52.45it/s, Epoch: 46, Batch: 109,Loss: -2.491,Avg.Loss: -2.008,LR: 2.84E-04]Training epoch 46:  71%|███████   | 109/153 [00:02<00:00, 52.45it/s, Epoch: 46, Batch: 110,Loss: -2.959,Avg.Loss: -2.017,LR: 2.84E-04]Training epoch 46:  72%|███████▏  | 110/153 [00:02<00:00, 52.45it/s, Epoch: 46, Batch: 111,Loss: -2.600,Avg.Loss: -2.022,LR: 2.83E-04]Training epoch 46:  73%|███████▎  | 111/153 [00:02<00:00, 52.45it/s, Epoch: 46, Batch: 112,Loss: -2.563,Avg.Loss: -2.027,LR: 2.83E-04]Training epoch 46:  73%|███████▎  | 112/153 [00:02<00:00, 52.45it/s, Epoch: 46, Batch: 113,Loss: -2.444,Avg.Loss: -2.030,LR: 2.83E-04]Training epoch 46:  74%|███████▍  | 113/153 [00:02<00:00, 52.45it/s, Epoch: 46, Batch: 114,Loss: -2.180,Avg.Loss: -2.032,LR: 2.83E-04]Training epoch 46:  75%|███████▍  | 114/153 [00:02<00:00, 52.63it/s, Epoch: 46, Batch: 114,Loss: -2.180,Avg.Loss: -2.032,LR: 2.83E-04]Training epoch 46:  75%|███████▍  | 114/153 [00:02<00:00, 52.63it/s, Epoch: 46, Batch: 115,Loss: -2.617,Avg.Loss: -2.037,LR: 2.83E-04]Training epoch 46:  75%|███████▌  | 115/153 [00:02<00:00, 52.63it/s, Epoch: 46, Batch: 116,Loss: -2.335,Avg.Loss: -2.039,LR: 2.83E-04]Training epoch 46:  76%|███████▌  | 116/153 [00:02<00:00, 52.63it/s, Epoch: 46, Batch: 117,Loss: -1.229,Avg.Loss: -2.032,LR: 2.83E-04]Training epoch 46:  76%|███████▋  | 117/153 [00:02<00:00, 52.63it/s, Epoch: 46, Batch: 118,Loss: -2.441,Avg.Loss: -2.036,LR: 2.83E-04]Training epoch 46:  77%|███████▋  | 118/153 [00:02<00:00, 52.63it/s, Epoch: 46, Batch: 119,Loss: -2.481,Avg.Loss: -2.040,LR: 2.83E-04]Training epoch 46:  78%|███████▊  | 119/153 [00:02<00:00, 52.63it/s, Epoch: 46, Batch: 120,Loss: -2.326,Avg.Loss: -2.042,LR: 2.83E-04]Training epoch 46:  78%|███████▊  | 120/153 [00:02<00:00, 52.75it/s, Epoch: 46, Batch: 120,Loss: -2.326,Avg.Loss: -2.042,LR: 2.83E-04]Training epoch 46:  78%|███████▊  | 120/153 [00:02<00:00, 52.75it/s, Epoch: 46, Batch: 121,Loss: -2.084,Avg.Loss: -2.042,LR: 2.83E-04]Training epoch 46:  79%|███████▉  | 121/153 [00:02<00:00, 52.75it/s, Epoch: 46, Batch: 122,Loss: -2.111,Avg.Loss: -2.043,LR: 2.83E-04]Training epoch 46:  80%|███████▉  | 122/153 [00:02<00:00, 52.75it/s, Epoch: 46, Batch: 123,Loss: -2.669,Avg.Loss: -2.048,LR: 2.83E-04]Training epoch 46:  80%|████████  | 123/153 [00:02<00:00, 52.75it/s, Epoch: 46, Batch: 124,Loss: -2.562,Avg.Loss: -2.052,LR: 2.83E-04]Training epoch 46:  81%|████████  | 124/153 [00:02<00:00, 52.75it/s, Epoch: 46, Batch: 125,Loss: -1.870,Avg.Loss: -2.051,LR: 2.83E-04]Training epoch 46:  82%|████████▏ | 125/153 [00:02<00:00, 52.75it/s, Epoch: 46, Batch: 126,Loss: -1.888,Avg.Loss: -2.049,LR: 2.83E-04]Training epoch 46:  82%|████████▏ | 126/153 [00:02<00:00, 52.95it/s, Epoch: 46, Batch: 126,Loss: -1.888,Avg.Loss: -2.049,LR: 2.83E-04]Training epoch 46:  82%|████████▏ | 126/153 [00:02<00:00, 52.95it/s, Epoch: 46, Batch: 127,Loss: -1.753,Avg.Loss: -2.047,LR: 2.83E-04]Training epoch 46:  83%|████████▎ | 127/153 [00:02<00:00, 52.95it/s, Epoch: 46, Batch: 128,Loss: -1.847,Avg.Loss: -2.046,LR: 2.83E-04]Training epoch 46:  84%|████████▎ | 128/153 [00:02<00:00, 52.95it/s, Epoch: 46, Batch: 129,Loss: -1.825,Avg.Loss: -2.044,LR: 2.83E-04]Training epoch 46:  84%|████████▍ | 129/153 [00:02<00:00, 52.95it/s, Epoch: 46, Batch: 130,Loss: -2.976,Avg.Loss: -2.051,LR: 2.83E-04]Training epoch 46:  85%|████████▍ | 130/153 [00:02<00:00, 52.95it/s, Epoch: 46, Batch: 131,Loss: -2.468,Avg.Loss: -2.054,LR: 2.82E-04]Training epoch 46:  86%|████████▌ | 131/153 [00:02<00:00, 52.95it/s, Epoch: 46, Batch: 132,Loss: -2.745,Avg.Loss: -2.059,LR: 2.82E-04]Training epoch 46:  86%|████████▋ | 132/153 [00:02<00:00, 53.06it/s, Epoch: 46, Batch: 132,Loss: -2.745,Avg.Loss: -2.059,LR: 2.82E-04]Training epoch 46:  86%|████████▋ | 132/153 [00:02<00:00, 53.06it/s, Epoch: 46, Batch: 133,Loss: -2.654,Avg.Loss: -2.064,LR: 2.82E-04]Training epoch 46:  87%|████████▋ | 133/153 [00:02<00:00, 53.06it/s, Epoch: 46, Batch: 134,Loss: -2.049,Avg.Loss: -2.064,LR: 2.82E-04]Training epoch 46:  88%|████████▊ | 134/153 [00:02<00:00, 53.06it/s, Epoch: 46, Batch: 135,Loss: -2.049,Avg.Loss: -2.064,LR: 2.82E-04]Training epoch 46:  88%|████████▊ | 135/153 [00:02<00:00, 53.06it/s, Epoch: 46, Batch: 136,Loss: -1.906,Avg.Loss: -2.063,LR: 2.82E-04]Training epoch 46:  89%|████████▉ | 136/153 [00:02<00:00, 53.06it/s, Epoch: 46, Batch: 137,Loss: -1.936,Avg.Loss: -2.062,LR: 2.82E-04]Training epoch 46:  90%|████████▉ | 137/153 [00:02<00:00, 53.06it/s, Epoch: 46, Batch: 138,Loss: -2.246,Avg.Loss: -2.063,LR: 2.82E-04]Training epoch 46:  90%|█████████ | 138/153 [00:02<00:00, 53.12it/s, Epoch: 46, Batch: 138,Loss: -2.246,Avg.Loss: -2.063,LR: 2.82E-04]Training epoch 46:  90%|█████████ | 138/153 [00:02<00:00, 53.12it/s, Epoch: 46, Batch: 139,Loss: -1.961,Avg.Loss: -2.062,LR: 2.82E-04]Training epoch 46:  91%|█████████ | 139/153 [00:02<00:00, 53.12it/s, Epoch: 46, Batch: 140,Loss: -1.949,Avg.Loss: -2.061,LR: 2.82E-04]Training epoch 46:  92%|█████████▏| 140/153 [00:02<00:00, 53.12it/s, Epoch: 46, Batch: 141,Loss: -2.203,Avg.Loss: -2.062,LR: 2.82E-04]Training epoch 46:  92%|█████████▏| 141/153 [00:02<00:00, 53.12it/s, Epoch: 46, Batch: 142,Loss: -2.459,Avg.Loss: -2.065,LR: 2.82E-04]Training epoch 46:  93%|█████████▎| 142/153 [00:02<00:00, 53.12it/s, Epoch: 46, Batch: 143,Loss: -2.253,Avg.Loss: -2.067,LR: 2.82E-04]Training epoch 46:  93%|█████████▎| 143/153 [00:02<00:00, 53.12it/s, Epoch: 46, Batch: 144,Loss: -1.949,Avg.Loss: -2.066,LR: 2.82E-04]Training epoch 46:  94%|█████████▍| 144/153 [00:02<00:00, 53.27it/s, Epoch: 46, Batch: 144,Loss: -1.949,Avg.Loss: -2.066,LR: 2.82E-04]Training epoch 46:  94%|█████████▍| 144/153 [00:02<00:00, 53.27it/s, Epoch: 46, Batch: 145,Loss: -2.064,Avg.Loss: -2.066,LR: 2.82E-04]Training epoch 46:  95%|█████████▍| 145/153 [00:02<00:00, 53.27it/s, Epoch: 46, Batch: 146,Loss: -2.313,Avg.Loss: -2.067,LR: 2.82E-04]Training epoch 46:  95%|█████████▌| 146/153 [00:02<00:00, 53.27it/s, Epoch: 46, Batch: 147,Loss: -1.830,Avg.Loss: -2.066,LR: 2.82E-04]Training epoch 46:  96%|█████████▌| 147/153 [00:02<00:00, 53.27it/s, Epoch: 46, Batch: 148,Loss: -1.894,Avg.Loss: -2.065,LR: 2.82E-04]Training epoch 46:  97%|█████████▋| 148/153 [00:02<00:00, 53.27it/s, Epoch: 46, Batch: 149,Loss: -2.224,Avg.Loss: -2.066,LR: 2.82E-04]Training epoch 46:  97%|█████████▋| 149/153 [00:02<00:00, 53.27it/s, Epoch: 46, Batch: 150,Loss: -2.732,Avg.Loss: -2.070,LR: 2.81E-04]Training epoch 46:  98%|█████████▊| 150/153 [00:02<00:00, 53.11it/s, Epoch: 46, Batch: 150,Loss: -2.732,Avg.Loss: -2.070,LR: 2.81E-04]Training epoch 46:  98%|█████████▊| 150/153 [00:02<00:00, 53.11it/s, Epoch: 46, Batch: 151,Loss: -1.928,Avg.Loss: -2.069,LR: 2.81E-04]Training epoch 46:  99%|█████████▊| 151/153 [00:02<00:00, 53.11it/s, Epoch: 46, Batch: 152,Loss: -1.617,Avg.Loss: -2.066,LR: 2.81E-04]Training epoch 46:  99%|█████████▉| 152/153 [00:02<00:00, 53.11it/s, Epoch: 46, Batch: 153,Loss: -1.517,Avg.Loss: -2.063,LR: 2.81E-04]Training epoch 46: 100%|██████████| 153/153 [00:02<00:00, 52.74it/s, Epoch: 46, Batch: 153,Loss: -1.517,Avg.Loss: -2.063,LR: 2.81E-04]
Training epoch 47:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 47:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 47, Batch: 1,Loss: -1.800,Avg.Loss: -1.800,LR: 2.81E-04]Training epoch 47:   1%|          | 1/153 [00:00<00:05, 25.94it/s, Epoch: 47, Batch: 2,Loss: -1.795,Avg.Loss: -1.798,LR: 2.81E-04]Training epoch 47:   1%|▏         | 2/153 [00:00<00:03, 38.90it/s, Epoch: 47, Batch: 3,Loss: -2.173,Avg.Loss: -1.923,LR: 2.81E-04]Training epoch 47:   2%|▏         | 3/153 [00:00<00:03, 46.65it/s, Epoch: 47, Batch: 4,Loss: -1.869,Avg.Loss: -1.909,LR: 2.81E-04]Training epoch 47:   3%|▎         | 4/153 [00:00<00:03, 48.40it/s, Epoch: 47, Batch: 5,Loss: -2.147,Avg.Loss: -1.957,LR: 2.81E-04]Training epoch 47:   3%|▎         | 5/153 [00:00<00:03, 49.12it/s, Epoch: 47, Batch: 6,Loss: -1.104,Avg.Loss: -1.815,LR: 2.81E-04]Training epoch 47:   4%|▍         | 6/153 [00:00<00:02, 58.84it/s, Epoch: 47, Batch: 6,Loss: -1.104,Avg.Loss: -1.815,LR: 2.81E-04]Training epoch 47:   4%|▍         | 6/153 [00:00<00:02, 58.84it/s, Epoch: 47, Batch: 7,Loss: -1.649,Avg.Loss: -1.791,LR: 2.81E-04]Training epoch 47:   5%|▍         | 7/153 [00:00<00:02, 58.84it/s, Epoch: 47, Batch: 8,Loss: -1.851,Avg.Loss: -1.798,LR: 2.81E-04]Training epoch 47:   5%|▌         | 8/153 [00:00<00:02, 58.84it/s, Epoch: 47, Batch: 9,Loss: -1.573,Avg.Loss: -1.773,LR: 2.81E-04]Training epoch 47:   6%|▌         | 9/153 [00:00<00:02, 58.84it/s, Epoch: 47, Batch: 10,Loss: -2.332,Avg.Loss: -1.829,LR: 2.81E-04]Training epoch 47:   7%|▋         | 10/153 [00:00<00:02, 58.84it/s, Epoch: 47, Batch: 11,Loss: -2.322,Avg.Loss: -1.874,LR: 2.81E-04]Training epoch 47:   7%|▋         | 11/153 [00:00<00:02, 58.84it/s, Epoch: 47, Batch: 12,Loss: -1.863,Avg.Loss: -1.873,LR: 2.81E-04]Training epoch 47:   8%|▊         | 12/153 [00:00<00:02, 54.80it/s, Epoch: 47, Batch: 12,Loss: -1.863,Avg.Loss: -1.873,LR: 2.81E-04]Training epoch 47:   8%|▊         | 12/153 [00:00<00:02, 54.80it/s, Epoch: 47, Batch: 13,Loss: -2.250,Avg.Loss: -1.902,LR: 2.81E-04]Training epoch 47:   8%|▊         | 13/153 [00:00<00:02, 54.80it/s, Epoch: 47, Batch: 14,Loss: -1.583,Avg.Loss: -1.879,LR: 2.81E-04]Training epoch 47:   9%|▉         | 14/153 [00:00<00:02, 54.80it/s, Epoch: 47, Batch: 15,Loss: -1.386,Avg.Loss: -1.846,LR: 2.81E-04]Training epoch 47:  10%|▉         | 15/153 [00:00<00:02, 54.80it/s, Epoch: 47, Batch: 16,Loss: -1.991,Avg.Loss: -1.855,LR: 2.81E-04]Training epoch 47:  10%|█         | 16/153 [00:00<00:02, 54.80it/s, Epoch: 47, Batch: 17,Loss: -2.283,Avg.Loss: -1.881,LR: 2.80E-04]Training epoch 47:  11%|█         | 17/153 [00:00<00:02, 54.80it/s, Epoch: 47, Batch: 18,Loss: -2.044,Avg.Loss: -1.890,LR: 2.80E-04]Training epoch 47:  12%|█▏        | 18/153 [00:00<00:02, 53.69it/s, Epoch: 47, Batch: 18,Loss: -2.044,Avg.Loss: -1.890,LR: 2.80E-04]Training epoch 47:  12%|█▏        | 18/153 [00:00<00:02, 53.69it/s, Epoch: 47, Batch: 19,Loss: -2.191,Avg.Loss: -1.906,LR: 2.80E-04]Training epoch 47:  12%|█▏        | 19/153 [00:00<00:02, 53.69it/s, Epoch: 47, Batch: 20,Loss: -2.586,Avg.Loss: -1.940,LR: 2.80E-04]Training epoch 47:  13%|█▎        | 20/153 [00:00<00:02, 53.69it/s, Epoch: 47, Batch: 21,Loss: -2.334,Avg.Loss: -1.958,LR: 2.80E-04]Training epoch 47:  14%|█▎        | 21/153 [00:00<00:02, 53.69it/s, Epoch: 47, Batch: 22,Loss: -2.109,Avg.Loss: -1.965,LR: 2.80E-04]Training epoch 47:  14%|█▍        | 22/153 [00:00<00:02, 53.69it/s, Epoch: 47, Batch: 23,Loss: -1.646,Avg.Loss: -1.951,LR: 2.80E-04]Training epoch 47:  15%|█▌        | 23/153 [00:00<00:02, 53.69it/s, Epoch: 47, Batch: 24,Loss: -1.214,Avg.Loss: -1.921,LR: 2.80E-04]Training epoch 47:  16%|█▌        | 24/153 [00:00<00:02, 52.59it/s, Epoch: 47, Batch: 24,Loss: -1.214,Avg.Loss: -1.921,LR: 2.80E-04]Training epoch 47:  16%|█▌        | 24/153 [00:00<00:02, 52.59it/s, Epoch: 47, Batch: 25,Loss: -1.602,Avg.Loss: -1.908,LR: 2.80E-04]Training epoch 47:  16%|█▋        | 25/153 [00:00<00:02, 52.59it/s, Epoch: 47, Batch: 26,Loss: -2.345,Avg.Loss: -1.925,LR: 2.80E-04]Training epoch 47:  17%|█▋        | 26/153 [00:00<00:02, 52.59it/s, Epoch: 47, Batch: 27,Loss: -2.267,Avg.Loss: -1.937,LR: 2.80E-04]Training epoch 47:  18%|█▊        | 27/153 [00:00<00:02, 52.59it/s, Epoch: 47, Batch: 28,Loss: -2.648,Avg.Loss: -1.963,LR: 2.80E-04]Training epoch 47:  18%|█▊        | 28/153 [00:00<00:02, 52.59it/s, Epoch: 47, Batch: 29,Loss: -2.269,Avg.Loss: -1.973,LR: 2.80E-04]Training epoch 47:  19%|█▉        | 29/153 [00:00<00:02, 52.59it/s, Epoch: 47, Batch: 30,Loss: -1.904,Avg.Loss: -1.971,LR: 2.80E-04]Training epoch 47:  20%|█▉        | 30/153 [00:00<00:02, 52.54it/s, Epoch: 47, Batch: 30,Loss: -1.904,Avg.Loss: -1.971,LR: 2.80E-04]Training epoch 47:  20%|█▉        | 30/153 [00:00<00:02, 52.54it/s, Epoch: 47, Batch: 31,Loss: -2.187,Avg.Loss: -1.978,LR: 2.80E-04]Training epoch 47:  20%|██        | 31/153 [00:00<00:02, 52.54it/s, Epoch: 47, Batch: 32,Loss: -2.150,Avg.Loss: -1.983,LR: 2.80E-04]Training epoch 47:  21%|██        | 32/153 [00:00<00:02, 52.54it/s, Epoch: 47, Batch: 33,Loss: -2.205,Avg.Loss: -1.990,LR: 2.80E-04]Training epoch 47:  22%|██▏       | 33/153 [00:00<00:02, 52.54it/s, Epoch: 47, Batch: 34,Loss: -2.339,Avg.Loss: -2.000,LR: 2.80E-04]Training epoch 47:  22%|██▏       | 34/153 [00:00<00:02, 52.54it/s, Epoch: 47, Batch: 35,Loss: -2.426,Avg.Loss: -2.013,LR: 2.80E-04]Training epoch 47:  23%|██▎       | 35/153 [00:00<00:02, 52.54it/s, Epoch: 47, Batch: 36,Loss: -2.378,Avg.Loss: -2.023,LR: 2.79E-04]Training epoch 47:  24%|██▎       | 36/153 [00:00<00:02, 52.64it/s, Epoch: 47, Batch: 36,Loss: -2.378,Avg.Loss: -2.023,LR: 2.79E-04]Training epoch 47:  24%|██▎       | 36/153 [00:00<00:02, 52.64it/s, Epoch: 47, Batch: 37,Loss: -2.707,Avg.Loss: -2.041,LR: 2.79E-04]Training epoch 47:  24%|██▍       | 37/153 [00:00<00:02, 52.64it/s, Epoch: 47, Batch: 38,Loss: -2.059,Avg.Loss: -2.042,LR: 2.79E-04]Training epoch 47:  25%|██▍       | 38/153 [00:00<00:02, 52.64it/s, Epoch: 47, Batch: 39,Loss: -1.877,Avg.Loss: -2.037,LR: 2.79E-04]Training epoch 47:  25%|██▌       | 39/153 [00:00<00:02, 52.64it/s, Epoch: 47, Batch: 40,Loss: -2.553,Avg.Loss: -2.050,LR: 2.79E-04]Training epoch 47:  26%|██▌       | 40/153 [00:00<00:02, 52.64it/s, Epoch: 47, Batch: 41,Loss: -2.287,Avg.Loss: -2.056,LR: 2.79E-04]Training epoch 47:  27%|██▋       | 41/153 [00:00<00:02, 52.64it/s, Epoch: 47, Batch: 42,Loss: -2.471,Avg.Loss: -2.066,LR: 2.79E-04]Training epoch 47:  27%|██▋       | 42/153 [00:00<00:02, 52.51it/s, Epoch: 47, Batch: 42,Loss: -2.471,Avg.Loss: -2.066,LR: 2.79E-04]Training epoch 47:  27%|██▋       | 42/153 [00:00<00:02, 52.51it/s, Epoch: 47, Batch: 43,Loss: -2.932,Avg.Loss: -2.086,LR: 2.79E-04]Training epoch 47:  28%|██▊       | 43/153 [00:00<00:02, 52.51it/s, Epoch: 47, Batch: 44,Loss: -1.756,Avg.Loss: -2.079,LR: 2.79E-04]Training epoch 47:  29%|██▉       | 44/153 [00:00<00:02, 52.51it/s, Epoch: 47, Batch: 45,Loss: -1.245,Avg.Loss: -2.060,LR: 2.79E-04]Training epoch 47:  29%|██▉       | 45/153 [00:00<00:02, 52.51it/s, Epoch: 47, Batch: 46,Loss: -1.519,Avg.Loss: -2.048,LR: 2.79E-04]Training epoch 47:  30%|███       | 46/153 [00:00<00:02, 52.51it/s, Epoch: 47, Batch: 47,Loss: -2.216,Avg.Loss: -2.052,LR: 2.79E-04]Training epoch 47:  31%|███       | 47/153 [00:00<00:02, 52.51it/s, Epoch: 47, Batch: 48,Loss: -2.268,Avg.Loss: -2.056,LR: 2.79E-04]Training epoch 47:  31%|███▏      | 48/153 [00:00<00:01, 52.58it/s, Epoch: 47, Batch: 48,Loss: -2.268,Avg.Loss: -2.056,LR: 2.79E-04]Training epoch 47:  31%|███▏      | 48/153 [00:00<00:01, 52.58it/s, Epoch: 47, Batch: 49,Loss: -2.420,Avg.Loss: -2.064,LR: 2.79E-04]Training epoch 47:  32%|███▏      | 49/153 [00:00<00:01, 52.58it/s, Epoch: 47, Batch: 50,Loss: -2.357,Avg.Loss: -2.070,LR: 2.79E-04]Training epoch 47:  33%|███▎      | 50/153 [00:00<00:01, 52.58it/s, Epoch: 47, Batch: 51,Loss: -2.462,Avg.Loss: -2.077,LR: 2.79E-04]Training epoch 47:  33%|███▎      | 51/153 [00:00<00:01, 52.58it/s, Epoch: 47, Batch: 52,Loss: -2.003,Avg.Loss: -2.076,LR: 2.79E-04]Training epoch 47:  34%|███▍      | 52/153 [00:00<00:01, 52.58it/s, Epoch: 47, Batch: 53,Loss: -2.699,Avg.Loss: -2.088,LR: 2.79E-04]Training epoch 47:  35%|███▍      | 53/153 [00:01<00:01, 52.58it/s, Epoch: 47, Batch: 54,Loss: -2.643,Avg.Loss: -2.098,LR: 2.79E-04]Training epoch 47:  35%|███▌      | 54/153 [00:01<00:01, 52.86it/s, Epoch: 47, Batch: 54,Loss: -2.643,Avg.Loss: -2.098,LR: 2.79E-04]Training epoch 47:  35%|███▌      | 54/153 [00:01<00:01, 52.86it/s, Epoch: 47, Batch: 55,Loss: -2.098,Avg.Loss: -2.098,LR: 2.79E-04]Training epoch 47:  36%|███▌      | 55/153 [00:01<00:01, 52.86it/s, Epoch: 47, Batch: 56,Loss: -2.515,Avg.Loss: -2.105,LR: 2.78E-04]Training epoch 47:  37%|███▋      | 56/153 [00:01<00:01, 52.86it/s, Epoch: 47, Batch: 57,Loss: -2.730,Avg.Loss: -2.116,LR: 2.78E-04]Training epoch 47:  37%|███▋      | 57/153 [00:01<00:01, 52.86it/s, Epoch: 47, Batch: 58,Loss: -2.452,Avg.Loss: -2.122,LR: 2.78E-04]Training epoch 47:  38%|███▊      | 58/153 [00:01<00:01, 52.86it/s, Epoch: 47, Batch: 59,Loss: -2.113,Avg.Loss: -2.122,LR: 2.78E-04]Training epoch 47:  39%|███▊      | 59/153 [00:01<00:01, 52.86it/s, Epoch: 47, Batch: 60,Loss: -2.343,Avg.Loss: -2.126,LR: 2.78E-04]Training epoch 47:  39%|███▉      | 60/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 60,Loss: -2.343,Avg.Loss: -2.126,LR: 2.78E-04]Training epoch 47:  39%|███▉      | 60/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 61,Loss: -1.743,Avg.Loss: -2.119,LR: 2.78E-04]Training epoch 47:  40%|███▉      | 61/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 62,Loss: -2.542,Avg.Loss: -2.126,LR: 2.78E-04]Training epoch 47:  41%|████      | 62/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 63,Loss: -2.402,Avg.Loss: -2.131,LR: 2.78E-04]Training epoch 47:  41%|████      | 63/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 64,Loss: -2.480,Avg.Loss: -2.136,LR: 2.78E-04]Training epoch 47:  42%|████▏     | 64/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 65,Loss: -2.094,Avg.Loss: -2.135,LR: 2.78E-04]Training epoch 47:  42%|████▏     | 65/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 66,Loss: -1.642,Avg.Loss: -2.128,LR: 2.78E-04]Training epoch 47:  43%|████▎     | 66/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 66,Loss: -1.642,Avg.Loss: -2.128,LR: 2.78E-04]Training epoch 47:  43%|████▎     | 66/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 67,Loss: -1.739,Avg.Loss: -2.122,LR: 2.78E-04]Training epoch 47:  44%|████▍     | 67/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 68,Loss: -2.242,Avg.Loss: -2.124,LR: 2.78E-04]Training epoch 47:  44%|████▍     | 68/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 69,Loss: -2.698,Avg.Loss: -2.132,LR: 2.78E-04]Training epoch 47:  45%|████▌     | 69/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 70,Loss: -2.093,Avg.Loss: -2.132,LR: 2.78E-04]Training epoch 47:  46%|████▌     | 70/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 71,Loss: -1.808,Avg.Loss: -2.127,LR: 2.78E-04]Training epoch 47:  46%|████▋     | 71/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 72,Loss: -1.963,Avg.Loss: -2.125,LR: 2.78E-04]Training epoch 47:  47%|████▋     | 72/153 [00:01<00:01, 52.93it/s, Epoch: 47, Batch: 72,Loss: -1.963,Avg.Loss: -2.125,LR: 2.78E-04]Training epoch 47:  47%|████▋     | 72/153 [00:01<00:01, 52.93it/s, Epoch: 47, Batch: 73,Loss: -2.586,Avg.Loss: -2.131,LR: 2.78E-04]Training epoch 47:  48%|████▊     | 73/153 [00:01<00:01, 52.93it/s, Epoch: 47, Batch: 74,Loss: -2.405,Avg.Loss: -2.135,LR: 2.78E-04]Training epoch 47:  48%|████▊     | 74/153 [00:01<00:01, 52.93it/s, Epoch: 47, Batch: 75,Loss: -2.647,Avg.Loss: -2.142,LR: 2.78E-04]Training epoch 47:  49%|████▉     | 75/153 [00:01<00:01, 52.93it/s, Epoch: 47, Batch: 76,Loss: -2.480,Avg.Loss: -2.146,LR: 2.77E-04]Training epoch 47:  50%|████▉     | 76/153 [00:01<00:01, 52.93it/s, Epoch: 47, Batch: 77,Loss: -2.669,Avg.Loss: -2.153,LR: 2.77E-04]Training epoch 47:  50%|█████     | 77/153 [00:01<00:01, 52.93it/s, Epoch: 47, Batch: 78,Loss: -2.181,Avg.Loss: -2.153,LR: 2.77E-04]Training epoch 47:  51%|█████     | 78/153 [00:01<00:01, 52.99it/s, Epoch: 47, Batch: 78,Loss: -2.181,Avg.Loss: -2.153,LR: 2.77E-04]Training epoch 47:  51%|█████     | 78/153 [00:01<00:01, 52.99it/s, Epoch: 47, Batch: 79,Loss: -2.621,Avg.Loss: -2.159,LR: 2.77E-04]Training epoch 47:  52%|█████▏    | 79/153 [00:01<00:01, 52.99it/s, Epoch: 47, Batch: 80,Loss: -2.343,Avg.Loss: -2.162,LR: 2.77E-04]Training epoch 47:  52%|█████▏    | 80/153 [00:01<00:01, 52.99it/s, Epoch: 47, Batch: 81,Loss: -1.555,Avg.Loss: -2.154,LR: 2.77E-04]Training epoch 47:  53%|█████▎    | 81/153 [00:01<00:01, 52.99it/s, Epoch: 47, Batch: 82,Loss: -1.306,Avg.Loss: -2.144,LR: 2.77E-04]Training epoch 47:  54%|█████▎    | 82/153 [00:01<00:01, 52.99it/s, Epoch: 47, Batch: 83,Loss: -1.447,Avg.Loss: -2.135,LR: 2.77E-04]Training epoch 47:  54%|█████▍    | 83/153 [00:01<00:01, 52.99it/s, Epoch: 47, Batch: 84,Loss: -1.640,Avg.Loss: -2.129,LR: 2.77E-04]Training epoch 47:  55%|█████▍    | 84/153 [00:01<00:01, 52.98it/s, Epoch: 47, Batch: 84,Loss: -1.640,Avg.Loss: -2.129,LR: 2.77E-04]Training epoch 47:  55%|█████▍    | 84/153 [00:01<00:01, 52.98it/s, Epoch: 47, Batch: 85,Loss: -2.008,Avg.Loss: -2.128,LR: 2.77E-04]Training epoch 47:  56%|█████▌    | 85/153 [00:01<00:01, 52.98it/s, Epoch: 47, Batch: 86,Loss: -2.073,Avg.Loss: -2.127,LR: 2.77E-04]Training epoch 47:  56%|█████▌    | 86/153 [00:01<00:01, 52.98it/s, Epoch: 47, Batch: 87,Loss: -1.736,Avg.Loss: -2.123,LR: 2.77E-04]Training epoch 47:  57%|█████▋    | 87/153 [00:01<00:01, 52.98it/s, Epoch: 47, Batch: 88,Loss: -1.733,Avg.Loss: -2.118,LR: 2.77E-04]Training epoch 47:  58%|█████▊    | 88/153 [00:01<00:01, 52.98it/s, Epoch: 47, Batch: 89,Loss: -0.994,Avg.Loss: -2.106,LR: 2.77E-04]Training epoch 47:  58%|█████▊    | 89/153 [00:01<00:01, 52.98it/s, Epoch: 47, Batch: 90,Loss: -1.611,Avg.Loss: -2.100,LR: 2.77E-04]Training epoch 47:  59%|█████▉    | 90/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 90,Loss: -1.611,Avg.Loss: -2.100,LR: 2.77E-04]Training epoch 47:  59%|█████▉    | 90/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 91,Loss: -1.617,Avg.Loss: -2.095,LR: 2.77E-04]Training epoch 47:  59%|█████▉    | 91/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 92,Loss: -2.244,Avg.Loss: -2.097,LR: 2.77E-04]Training epoch 47:  60%|██████    | 92/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 93,Loss: -2.020,Avg.Loss: -2.096,LR: 2.77E-04]Training epoch 47:  61%|██████    | 93/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 94,Loss: -1.360,Avg.Loss: -2.088,LR: 2.77E-04]Training epoch 47:  61%|██████▏   | 94/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 95,Loss: -1.493,Avg.Loss: -2.082,LR: 2.76E-04]Training epoch 47:  62%|██████▏   | 95/153 [00:01<00:01, 52.92it/s, Epoch: 47, Batch: 96,Loss: -1.678,Avg.Loss: -2.077,LR: 2.76E-04]Training epoch 47:  63%|██████▎   | 96/153 [00:01<00:01, 53.14it/s, Epoch: 47, Batch: 96,Loss: -1.678,Avg.Loss: -2.077,LR: 2.76E-04]Training epoch 47:  63%|██████▎   | 96/153 [00:01<00:01, 53.14it/s, Epoch: 47, Batch: 97,Loss: -2.274,Avg.Loss: -2.079,LR: 2.76E-04]Training epoch 47:  63%|██████▎   | 97/153 [00:01<00:01, 53.14it/s, Epoch: 47, Batch: 98,Loss: -2.102,Avg.Loss: -2.080,LR: 2.76E-04]Training epoch 47:  64%|██████▍   | 98/153 [00:01<00:01, 53.14it/s, Epoch: 47, Batch: 99,Loss: -2.441,Avg.Loss: -2.083,LR: 2.76E-04]Training epoch 47:  65%|██████▍   | 99/153 [00:01<00:01, 53.14it/s, Epoch: 47, Batch: 100,Loss: -2.550,Avg.Loss: -2.088,LR: 2.76E-04]Training epoch 47:  65%|██████▌   | 100/153 [00:01<00:00, 53.14it/s, Epoch: 47, Batch: 101,Loss: -2.492,Avg.Loss: -2.092,LR: 2.76E-04]Training epoch 47:  66%|██████▌   | 101/153 [00:01<00:00, 53.14it/s, Epoch: 47, Batch: 102,Loss: -2.118,Avg.Loss: -2.092,LR: 2.76E-04]Training epoch 47:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 47, Batch: 102,Loss: -2.118,Avg.Loss: -2.092,LR: 2.76E-04]Training epoch 47:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 47, Batch: 103,Loss: -2.389,Avg.Loss: -2.095,LR: 2.76E-04]Training epoch 47:  67%|██████▋   | 103/153 [00:01<00:00, 53.09it/s, Epoch: 47, Batch: 104,Loss: -2.325,Avg.Loss: -2.097,LR: 2.76E-04]Training epoch 47:  68%|██████▊   | 104/153 [00:01<00:00, 53.09it/s, Epoch: 47, Batch: 105,Loss: -2.699,Avg.Loss: -2.103,LR: 2.76E-04]Training epoch 47:  69%|██████▊   | 105/153 [00:01<00:00, 53.09it/s, Epoch: 47, Batch: 106,Loss: -2.717,Avg.Loss: -2.109,LR: 2.76E-04]Training epoch 47:  69%|██████▉   | 106/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 107,Loss: -2.513,Avg.Loss: -2.113,LR: 2.76E-04]Training epoch 47:  70%|██████▉   | 107/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 108,Loss: -1.848,Avg.Loss: -2.110,LR: 2.76E-04]Training epoch 47:  71%|███████   | 108/153 [00:02<00:00, 52.99it/s, Epoch: 47, Batch: 108,Loss: -1.848,Avg.Loss: -2.110,LR: 2.76E-04]Training epoch 47:  71%|███████   | 108/153 [00:02<00:00, 52.99it/s, Epoch: 47, Batch: 109,Loss: -2.178,Avg.Loss: -2.111,LR: 2.76E-04]Training epoch 47:  71%|███████   | 109/153 [00:02<00:00, 52.99it/s, Epoch: 47, Batch: 110,Loss: -2.389,Avg.Loss: -2.113,LR: 2.76E-04]Training epoch 47:  72%|███████▏  | 110/153 [00:02<00:00, 52.99it/s, Epoch: 47, Batch: 111,Loss: -2.144,Avg.Loss: -2.114,LR: 2.76E-04]Training epoch 47:  73%|███████▎  | 111/153 [00:02<00:00, 52.99it/s, Epoch: 47, Batch: 112,Loss: -2.589,Avg.Loss: -2.118,LR: 2.76E-04]Training epoch 47:  73%|███████▎  | 112/153 [00:02<00:00, 52.99it/s, Epoch: 47, Batch: 113,Loss: -2.580,Avg.Loss: -2.122,LR: 2.76E-04]Training epoch 47:  74%|███████▍  | 113/153 [00:02<00:00, 52.99it/s, Epoch: 47, Batch: 114,Loss: -2.399,Avg.Loss: -2.124,LR: 2.76E-04]Training epoch 47:  75%|███████▍  | 114/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 114,Loss: -2.399,Avg.Loss: -2.124,LR: 2.76E-04]Training epoch 47:  75%|███████▍  | 114/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 115,Loss: -2.966,Avg.Loss: -2.132,LR: 2.75E-04]Training epoch 47:  75%|███████▌  | 115/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 116,Loss: -1.746,Avg.Loss: -2.128,LR: 2.75E-04]Training epoch 47:  76%|███████▌  | 116/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 117,Loss: -2.190,Avg.Loss: -2.129,LR: 2.75E-04]Training epoch 47:  76%|███████▋  | 117/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 118,Loss: -2.604,Avg.Loss: -2.133,LR: 2.75E-04]Training epoch 47:  77%|███████▋  | 118/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 119,Loss: -2.647,Avg.Loss: -2.137,LR: 2.75E-04]Training epoch 47:  78%|███████▊  | 119/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 120,Loss: -2.219,Avg.Loss: -2.138,LR: 2.75E-04]Training epoch 47:  78%|███████▊  | 120/153 [00:02<00:00, 53.30it/s, Epoch: 47, Batch: 120,Loss: -2.219,Avg.Loss: -2.138,LR: 2.75E-04]Training epoch 47:  78%|███████▊  | 120/153 [00:02<00:00, 53.30it/s, Epoch: 47, Batch: 121,Loss: -2.257,Avg.Loss: -2.139,LR: 2.75E-04]Training epoch 47:  79%|███████▉  | 121/153 [00:02<00:00, 53.30it/s, Epoch: 47, Batch: 122,Loss: -2.367,Avg.Loss: -2.141,LR: 2.75E-04]Training epoch 47:  80%|███████▉  | 122/153 [00:02<00:00, 53.30it/s, Epoch: 47, Batch: 123,Loss: -1.829,Avg.Loss: -2.138,LR: 2.75E-04]Training epoch 47:  80%|████████  | 123/153 [00:02<00:00, 53.30it/s, Epoch: 47, Batch: 124,Loss: -2.488,Avg.Loss: -2.141,LR: 2.75E-04]Training epoch 47:  81%|████████  | 124/153 [00:02<00:00, 53.30it/s, Epoch: 47, Batch: 125,Loss: -2.477,Avg.Loss: -2.144,LR: 2.75E-04]Training epoch 47:  82%|████████▏ | 125/153 [00:02<00:00, 53.30it/s, Epoch: 47, Batch: 126,Loss: -2.404,Avg.Loss: -2.146,LR: 2.75E-04]Training epoch 47:  82%|████████▏ | 126/153 [00:02<00:00, 53.40it/s, Epoch: 47, Batch: 126,Loss: -2.404,Avg.Loss: -2.146,LR: 2.75E-04]Training epoch 47:  82%|████████▏ | 126/153 [00:02<00:00, 53.40it/s, Epoch: 47, Batch: 127,Loss: -2.430,Avg.Loss: -2.148,LR: 2.75E-04]Training epoch 47:  83%|████████▎ | 127/153 [00:02<00:00, 53.40it/s, Epoch: 47, Batch: 128,Loss: -2.581,Avg.Loss: -2.151,LR: 2.75E-04]Training epoch 47:  84%|████████▎ | 128/153 [00:02<00:00, 53.40it/s, Epoch: 47, Batch: 129,Loss: -2.124,Avg.Loss: -2.151,LR: 2.75E-04]Training epoch 47:  84%|████████▍ | 129/153 [00:02<00:00, 53.40it/s, Epoch: 47, Batch: 130,Loss: -2.346,Avg.Loss: -2.153,LR: 2.75E-04]Training epoch 47:  85%|████████▍ | 130/153 [00:02<00:00, 53.40it/s, Epoch: 47, Batch: 131,Loss: -1.931,Avg.Loss: -2.151,LR: 2.75E-04]Training epoch 47:  86%|████████▌ | 131/153 [00:02<00:00, 53.40it/s, Epoch: 47, Batch: 132,Loss: -1.336,Avg.Loss: -2.145,LR: 2.75E-04]Training epoch 47:  86%|████████▋ | 132/153 [00:02<00:00, 53.59it/s, Epoch: 47, Batch: 132,Loss: -1.336,Avg.Loss: -2.145,LR: 2.75E-04]Training epoch 47:  86%|████████▋ | 132/153 [00:02<00:00, 53.59it/s, Epoch: 47, Batch: 133,Loss: -2.021,Avg.Loss: -2.144,LR: 2.75E-04]Training epoch 47:  87%|████████▋ | 133/153 [00:02<00:00, 53.59it/s, Epoch: 47, Batch: 134,Loss: -2.407,Avg.Loss: -2.146,LR: 2.74E-04]Training epoch 47:  88%|████████▊ | 134/153 [00:02<00:00, 53.59it/s, Epoch: 47, Batch: 135,Loss: -2.671,Avg.Loss: -2.150,LR: 2.74E-04]Training epoch 47:  88%|████████▊ | 135/153 [00:02<00:00, 53.59it/s, Epoch: 47, Batch: 136,Loss: -2.558,Avg.Loss: -2.153,LR: 2.74E-04]Training epoch 47:  89%|████████▉ | 136/153 [00:02<00:00, 53.59it/s, Epoch: 47, Batch: 137,Loss: -2.755,Avg.Loss: -2.157,LR: 2.74E-04]Training epoch 47:  90%|████████▉ | 137/153 [00:02<00:00, 53.59it/s, Epoch: 47, Batch: 138,Loss: -2.603,Avg.Loss: -2.160,LR: 2.74E-04]Training epoch 47:  90%|█████████ | 138/153 [00:02<00:00, 53.63it/s, Epoch: 47, Batch: 138,Loss: -2.603,Avg.Loss: -2.160,LR: 2.74E-04]Training epoch 47:  90%|█████████ | 138/153 [00:02<00:00, 53.63it/s, Epoch: 47, Batch: 139,Loss: -2.586,Avg.Loss: -2.163,LR: 2.74E-04]Training epoch 47:  91%|█████████ | 139/153 [00:02<00:00, 53.63it/s, Epoch: 47, Batch: 140,Loss: -2.566,Avg.Loss: -2.166,LR: 2.74E-04]Training epoch 47:  92%|█████████▏| 140/153 [00:02<00:00, 53.63it/s, Epoch: 47, Batch: 141,Loss: -1.706,Avg.Loss: -2.163,LR: 2.74E-04]Training epoch 47:  92%|█████████▏| 141/153 [00:02<00:00, 53.63it/s, Epoch: 47, Batch: 142,Loss: -1.723,Avg.Loss: -2.160,LR: 2.74E-04]Training epoch 47:  93%|█████████▎| 142/153 [00:02<00:00, 53.63it/s, Epoch: 47, Batch: 143,Loss: -2.430,Avg.Loss: -2.162,LR: 2.74E-04]Training epoch 47:  93%|█████████▎| 143/153 [00:02<00:00, 53.63it/s, Epoch: 47, Batch: 144,Loss: -1.967,Avg.Loss: -2.161,LR: 2.74E-04]Training epoch 47:  94%|█████████▍| 144/153 [00:02<00:00, 53.25it/s, Epoch: 47, Batch: 144,Loss: -1.967,Avg.Loss: -2.161,LR: 2.74E-04]Training epoch 47:  94%|█████████▍| 144/153 [00:02<00:00, 53.25it/s, Epoch: 47, Batch: 145,Loss: -2.457,Avg.Loss: -2.163,LR: 2.74E-04]Training epoch 47:  95%|█████████▍| 145/153 [00:02<00:00, 53.25it/s, Epoch: 47, Batch: 146,Loss: -1.877,Avg.Loss: -2.161,LR: 2.74E-04]Training epoch 47:  95%|█████████▌| 146/153 [00:02<00:00, 53.25it/s, Epoch: 47, Batch: 147,Loss: -1.196,Avg.Loss: -2.154,LR: 2.74E-04]Training epoch 47:  96%|█████████▌| 147/153 [00:02<00:00, 53.25it/s, Epoch: 47, Batch: 148,Loss: -1.126,Avg.Loss: -2.147,LR: 2.74E-04]Training epoch 47:  97%|█████████▋| 148/153 [00:02<00:00, 53.25it/s, Epoch: 47, Batch: 149,Loss: -2.306,Avg.Loss: -2.148,LR: 2.74E-04]Training epoch 47:  97%|█████████▋| 149/153 [00:02<00:00, 53.25it/s, Epoch: 47, Batch: 150,Loss: -2.822,Avg.Loss: -2.153,LR: 2.74E-04]Training epoch 47:  98%|█████████▊| 150/153 [00:02<00:00, 53.24it/s, Epoch: 47, Batch: 150,Loss: -2.822,Avg.Loss: -2.153,LR: 2.74E-04]Training epoch 47:  98%|█████████▊| 150/153 [00:02<00:00, 53.24it/s, Epoch: 47, Batch: 151,Loss: -2.402,Avg.Loss: -2.154,LR: 2.74E-04]Training epoch 47:  99%|█████████▊| 151/153 [00:02<00:00, 53.24it/s, Epoch: 47, Batch: 152,Loss: -2.201,Avg.Loss: -2.155,LR: 2.74E-04]Training epoch 47:  99%|█████████▉| 152/153 [00:02<00:00, 53.24it/s, Epoch: 47, Batch: 153,Loss: -2.024,Avg.Loss: -2.154,LR: 2.74E-04]Training epoch 47: 100%|██████████| 153/153 [00:02<00:00, 53.09it/s, Epoch: 47, Batch: 153,Loss: -2.024,Avg.Loss: -2.154,LR: 2.74E-04]
Training epoch 48:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 48:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 48, Batch: 1,Loss: -2.662,Avg.Loss: -2.662,LR: 2.73E-04]Training epoch 48:   1%|          | 1/153 [00:00<00:05, 26.30it/s, Epoch: 48, Batch: 2,Loss: -2.670,Avg.Loss: -2.666,LR: 2.73E-04]Training epoch 48:   1%|▏         | 2/153 [00:00<00:03, 38.90it/s, Epoch: 48, Batch: 3,Loss: -2.638,Avg.Loss: -2.657,LR: 2.73E-04]Training epoch 48:   2%|▏         | 3/153 [00:00<00:03, 46.68it/s, Epoch: 48, Batch: 4,Loss: -2.187,Avg.Loss: -2.539,LR: 2.73E-04]Training epoch 48:   3%|▎         | 4/153 [00:00<00:03, 48.88it/s, Epoch: 48, Batch: 5,Loss: -1.518,Avg.Loss: -2.335,LR: 2.73E-04]Training epoch 48:   3%|▎         | 5/153 [00:00<00:02, 50.33it/s, Epoch: 48, Batch: 6,Loss: -1.113,Avg.Loss: -2.131,LR: 2.73E-04]Training epoch 48:   4%|▍         | 6/153 [00:00<00:02, 50.70it/s, Epoch: 48, Batch: 7,Loss: -0.994,Avg.Loss: -1.969,LR: 2.73E-04]Training epoch 48:   5%|▍         | 7/153 [00:00<00:02, 59.05it/s, Epoch: 48, Batch: 7,Loss: -0.994,Avg.Loss: -1.969,LR: 2.73E-04]Training epoch 48:   5%|▍         | 7/153 [00:00<00:02, 59.05it/s, Epoch: 48, Batch: 8,Loss: -2.228,Avg.Loss: -2.001,LR: 2.73E-04]Training epoch 48:   5%|▌         | 8/153 [00:00<00:02, 59.05it/s, Epoch: 48, Batch: 9,Loss: -1.712,Avg.Loss: -1.969,LR: 2.73E-04]Training epoch 48:   6%|▌         | 9/153 [00:00<00:02, 59.05it/s, Epoch: 48, Batch: 10,Loss: -1.405,Avg.Loss: -1.913,LR: 2.73E-04]Training epoch 48:   7%|▋         | 10/153 [00:00<00:02, 59.05it/s, Epoch: 48, Batch: 11,Loss: -1.349,Avg.Loss: -1.861,LR: 2.73E-04]Training epoch 48:   7%|▋         | 11/153 [00:00<00:02, 59.05it/s, Epoch: 48, Batch: 12,Loss: -0.643,Avg.Loss: -1.760,LR: 2.73E-04]Training epoch 48:   8%|▊         | 12/153 [00:00<00:02, 59.05it/s, Epoch: 48, Batch: 13,Loss: -0.727,Avg.Loss: -1.680,LR: 2.73E-04]Training epoch 48:   8%|▊         | 13/153 [00:00<00:02, 54.66it/s, Epoch: 48, Batch: 13,Loss: -0.727,Avg.Loss: -1.680,LR: 2.73E-04]Training epoch 48:   8%|▊         | 13/153 [00:00<00:02, 54.66it/s, Epoch: 48, Batch: 14,Loss: -1.579,Avg.Loss: -1.673,LR: 2.73E-04]Training epoch 48:   9%|▉         | 14/153 [00:00<00:02, 54.66it/s, Epoch: 48, Batch: 15,Loss: -1.225,Avg.Loss: -1.643,LR: 2.73E-04]Training epoch 48:  10%|▉         | 15/153 [00:00<00:02, 54.66it/s, Epoch: 48, Batch: 16,Loss: -1.891,Avg.Loss: -1.659,LR: 2.73E-04]Training epoch 48:  10%|█         | 16/153 [00:00<00:02, 54.66it/s, Epoch: 48, Batch: 17,Loss: -1.098,Avg.Loss: -1.626,LR: 2.73E-04]Training epoch 48:  11%|█         | 17/153 [00:00<00:02, 54.66it/s, Epoch: 48, Batch: 18,Loss: -1.123,Avg.Loss: -1.598,LR: 2.73E-04]Training epoch 48:  12%|█▏        | 18/153 [00:00<00:02, 54.66it/s, Epoch: 48, Batch: 19,Loss: -1.528,Avg.Loss: -1.594,LR: 2.73E-04]Training epoch 48:  12%|█▏        | 19/153 [00:00<00:02, 53.84it/s, Epoch: 48, Batch: 19,Loss: -1.528,Avg.Loss: -1.594,LR: 2.73E-04]Training epoch 48:  12%|█▏        | 19/153 [00:00<00:02, 53.84it/s, Epoch: 48, Batch: 20,Loss: -1.120,Avg.Loss: -1.571,LR: 2.73E-04]Training epoch 48:  13%|█▎        | 20/153 [00:00<00:02, 53.84it/s, Epoch: 48, Batch: 21,Loss: -1.348,Avg.Loss: -1.560,LR: 2.72E-04]Training epoch 48:  14%|█▎        | 21/153 [00:00<00:02, 53.84it/s, Epoch: 48, Batch: 22,Loss: -1.686,Avg.Loss: -1.566,LR: 2.72E-04]Training epoch 48:  14%|█▍        | 22/153 [00:00<00:02, 53.84it/s, Epoch: 48, Batch: 23,Loss: -2.656,Avg.Loss: -1.613,LR: 2.72E-04]Training epoch 48:  15%|█▌        | 23/153 [00:00<00:02, 53.84it/s, Epoch: 48, Batch: 24,Loss: -2.028,Avg.Loss: -1.630,LR: 2.72E-04]Training epoch 48:  16%|█▌        | 24/153 [00:00<00:02, 53.84it/s, Epoch: 48, Batch: 25,Loss: -1.202,Avg.Loss: -1.613,LR: 2.72E-04]Training epoch 48:  16%|█▋        | 25/153 [00:00<00:02, 52.92it/s, Epoch: 48, Batch: 25,Loss: -1.202,Avg.Loss: -1.613,LR: 2.72E-04]Training epoch 48:  16%|█▋        | 25/153 [00:00<00:02, 52.92it/s, Epoch: 48, Batch: 26,Loss: -0.949,Avg.Loss: -1.588,LR: 2.72E-04]Training epoch 48:  17%|█▋        | 26/153 [00:00<00:02, 52.92it/s, Epoch: 48, Batch: 27,Loss: -2.256,Avg.Loss: -1.612,LR: 2.72E-04]Training epoch 48:  18%|█▊        | 27/153 [00:00<00:02, 52.92it/s, Epoch: 48, Batch: 28,Loss: -2.615,Avg.Loss: -1.648,LR: 2.72E-04]Training epoch 48:  18%|█▊        | 28/153 [00:00<00:02, 52.92it/s, Epoch: 48, Batch: 29,Loss: -1.302,Avg.Loss: -1.636,LR: 2.72E-04]Training epoch 48:  19%|█▉        | 29/153 [00:00<00:02, 52.92it/s, Epoch: 48, Batch: 30,Loss: -1.548,Avg.Loss: -1.633,LR: 2.72E-04]Training epoch 48:  20%|█▉        | 30/153 [00:00<00:02, 52.92it/s, Epoch: 48, Batch: 31,Loss: -2.465,Avg.Loss: -1.660,LR: 2.72E-04]Training epoch 48:  20%|██        | 31/153 [00:00<00:02, 52.78it/s, Epoch: 48, Batch: 31,Loss: -2.465,Avg.Loss: -1.660,LR: 2.72E-04]Training epoch 48:  20%|██        | 31/153 [00:00<00:02, 52.78it/s, Epoch: 48, Batch: 32,Loss: -2.205,Avg.Loss: -1.677,LR: 2.72E-04]Training epoch 48:  21%|██        | 32/153 [00:00<00:02, 52.78it/s, Epoch: 48, Batch: 33,Loss: -1.345,Avg.Loss: -1.667,LR: 2.72E-04]Training epoch 48:  22%|██▏       | 33/153 [00:00<00:02, 52.78it/s, Epoch: 48, Batch: 34,Loss: -1.933,Avg.Loss: -1.675,LR: 2.72E-04]Training epoch 48:  22%|██▏       | 34/153 [00:00<00:02, 52.78it/s, Epoch: 48, Batch: 35,Loss: -3.069,Avg.Loss: -1.715,LR: 2.72E-04]Training epoch 48:  23%|██▎       | 35/153 [00:00<00:02, 52.78it/s, Epoch: 48, Batch: 36,Loss: -2.034,Avg.Loss: -1.724,LR: 2.72E-04]Training epoch 48:  24%|██▎       | 36/153 [00:00<00:02, 52.78it/s, Epoch: 48, Batch: 37,Loss: -1.233,Avg.Loss: -1.710,LR: 2.72E-04]Training epoch 48:  24%|██▍       | 37/153 [00:00<00:02, 52.80it/s, Epoch: 48, Batch: 37,Loss: -1.233,Avg.Loss: -1.710,LR: 2.72E-04]Training epoch 48:  24%|██▍       | 37/153 [00:00<00:02, 52.80it/s, Epoch: 48, Batch: 38,Loss: -1.284,Avg.Loss: -1.699,LR: 2.72E-04]Training epoch 48:  25%|██▍       | 38/153 [00:00<00:02, 52.80it/s, Epoch: 48, Batch: 39,Loss: -2.082,Avg.Loss: -1.709,LR: 2.72E-04]Training epoch 48:  25%|██▌       | 39/153 [00:00<00:02, 52.80it/s, Epoch: 48, Batch: 40,Loss: -2.253,Avg.Loss: -1.723,LR: 2.71E-04]Training epoch 48:  26%|██▌       | 40/153 [00:00<00:02, 52.80it/s, Epoch: 48, Batch: 41,Loss: -1.502,Avg.Loss: -1.717,LR: 2.71E-04]Training epoch 48:  27%|██▋       | 41/153 [00:00<00:02, 52.80it/s, Epoch: 48, Batch: 42,Loss: -2.119,Avg.Loss: -1.727,LR: 2.71E-04]Training epoch 48:  27%|██▋       | 42/153 [00:00<00:02, 52.80it/s, Epoch: 48, Batch: 43,Loss: -2.696,Avg.Loss: -1.749,LR: 2.71E-04]Training epoch 48:  28%|██▊       | 43/153 [00:00<00:02, 52.15it/s, Epoch: 48, Batch: 43,Loss: -2.696,Avg.Loss: -1.749,LR: 2.71E-04]Training epoch 48:  28%|██▊       | 43/153 [00:00<00:02, 52.15it/s, Epoch: 48, Batch: 44,Loss: -1.877,Avg.Loss: -1.752,LR: 2.71E-04]Training epoch 48:  29%|██▉       | 44/153 [00:00<00:02, 52.15it/s, Epoch: 48, Batch: 45,Loss: -1.482,Avg.Loss: -1.746,LR: 2.71E-04]Training epoch 48:  29%|██▉       | 45/153 [00:00<00:02, 52.15it/s, Epoch: 48, Batch: 46,Loss: -1.684,Avg.Loss: -1.745,LR: 2.71E-04]Training epoch 48:  30%|███       | 46/153 [00:00<00:02, 52.15it/s, Epoch: 48, Batch: 47,Loss: -2.268,Avg.Loss: -1.756,LR: 2.71E-04]Training epoch 48:  31%|███       | 47/153 [00:00<00:02, 52.15it/s, Epoch: 48, Batch: 48,Loss: -2.327,Avg.Loss: -1.768,LR: 2.71E-04]Training epoch 48:  31%|███▏      | 48/153 [00:00<00:02, 52.15it/s, Epoch: 48, Batch: 49,Loss: -1.728,Avg.Loss: -1.767,LR: 2.71E-04]Training epoch 48:  32%|███▏      | 49/153 [00:00<00:01, 52.26it/s, Epoch: 48, Batch: 49,Loss: -1.728,Avg.Loss: -1.767,LR: 2.71E-04]Training epoch 48:  32%|███▏      | 49/153 [00:00<00:01, 52.26it/s, Epoch: 48, Batch: 50,Loss: -1.906,Avg.Loss: -1.770,LR: 2.71E-04]Training epoch 48:  33%|███▎      | 50/153 [00:00<00:01, 52.26it/s, Epoch: 48, Batch: 51,Loss: -2.534,Avg.Loss: -1.785,LR: 2.71E-04]Training epoch 48:  33%|███▎      | 51/153 [00:00<00:01, 52.26it/s, Epoch: 48, Batch: 52,Loss: -2.329,Avg.Loss: -1.795,LR: 2.71E-04]Training epoch 48:  34%|███▍      | 52/153 [00:01<00:01, 52.26it/s, Epoch: 48, Batch: 53,Loss: -1.852,Avg.Loss: -1.796,LR: 2.71E-04]Training epoch 48:  35%|███▍      | 53/153 [00:01<00:01, 52.26it/s, Epoch: 48, Batch: 54,Loss: -1.711,Avg.Loss: -1.795,LR: 2.71E-04]Training epoch 48:  35%|███▌      | 54/153 [00:01<00:01, 52.26it/s, Epoch: 48, Batch: 55,Loss: -1.928,Avg.Loss: -1.797,LR: 2.71E-04]Training epoch 48:  36%|███▌      | 55/153 [00:01<00:01, 52.48it/s, Epoch: 48, Batch: 55,Loss: -1.928,Avg.Loss: -1.797,LR: 2.71E-04]Training epoch 48:  36%|███▌      | 55/153 [00:01<00:01, 52.48it/s, Epoch: 48, Batch: 56,Loss: -1.663,Avg.Loss: -1.795,LR: 2.71E-04]Training epoch 48:  37%|███▋      | 56/153 [00:01<00:01, 52.48it/s, Epoch: 48, Batch: 57,Loss: -0.881,Avg.Loss: -1.779,LR: 2.71E-04]Training epoch 48:  37%|███▋      | 57/153 [00:01<00:01, 52.48it/s, Epoch: 48, Batch: 58,Loss: -0.820,Avg.Loss: -1.762,LR: 2.71E-04]Training epoch 48:  38%|███▊      | 58/153 [00:01<00:01, 52.48it/s, Epoch: 48, Batch: 59,Loss: -1.741,Avg.Loss: -1.762,LR: 2.71E-04]Training epoch 48:  39%|███▊      | 59/153 [00:01<00:01, 52.48it/s, Epoch: 48, Batch: 60,Loss: -2.230,Avg.Loss: -1.770,LR: 2.70E-04]Training epoch 48:  39%|███▉      | 60/153 [00:01<00:01, 52.48it/s, Epoch: 48, Batch: 61,Loss: -1.977,Avg.Loss: -1.773,LR: 2.70E-04]Training epoch 48:  40%|███▉      | 61/153 [00:01<00:01, 52.35it/s, Epoch: 48, Batch: 61,Loss: -1.977,Avg.Loss: -1.773,LR: 2.70E-04]Training epoch 48:  40%|███▉      | 61/153 [00:01<00:01, 52.35it/s, Epoch: 48, Batch: 62,Loss: -1.830,Avg.Loss: -1.774,LR: 2.70E-04]Training epoch 48:  41%|████      | 62/153 [00:01<00:01, 52.35it/s, Epoch: 48, Batch: 63,Loss: -2.661,Avg.Loss: -1.788,LR: 2.70E-04]Training epoch 48:  41%|████      | 63/153 [00:01<00:01, 52.35it/s, Epoch: 48, Batch: 64,Loss: -2.231,Avg.Loss: -1.795,LR: 2.70E-04]Training epoch 48:  42%|████▏     | 64/153 [00:01<00:01, 52.35it/s, Epoch: 48, Batch: 65,Loss: -1.584,Avg.Loss: -1.792,LR: 2.70E-04]Training epoch 48:  42%|████▏     | 65/153 [00:01<00:01, 52.35it/s, Epoch: 48, Batch: 66,Loss: -2.260,Avg.Loss: -1.799,LR: 2.70E-04]Training epoch 48:  43%|████▎     | 66/153 [00:01<00:01, 52.35it/s, Epoch: 48, Batch: 67,Loss: -2.235,Avg.Loss: -1.805,LR: 2.70E-04]Training epoch 48:  44%|████▍     | 67/153 [00:01<00:01, 52.32it/s, Epoch: 48, Batch: 67,Loss: -2.235,Avg.Loss: -1.805,LR: 2.70E-04]Training epoch 48:  44%|████▍     | 67/153 [00:01<00:01, 52.32it/s, Epoch: 48, Batch: 68,Loss: -1.749,Avg.Loss: -1.805,LR: 2.70E-04]Training epoch 48:  44%|████▍     | 68/153 [00:01<00:01, 52.32it/s, Epoch: 48, Batch: 69,Loss: -2.095,Avg.Loss: -1.809,LR: 2.70E-04]Training epoch 48:  45%|████▌     | 69/153 [00:01<00:01, 52.32it/s, Epoch: 48, Batch: 70,Loss: -2.283,Avg.Loss: -1.816,LR: 2.70E-04]Training epoch 48:  46%|████▌     | 70/153 [00:01<00:01, 52.32it/s, Epoch: 48, Batch: 71,Loss: -2.965,Avg.Loss: -1.832,LR: 2.70E-04]Training epoch 48:  46%|████▋     | 71/153 [00:01<00:01, 52.32it/s, Epoch: 48, Batch: 72,Loss: -2.797,Avg.Loss: -1.845,LR: 2.70E-04]Training epoch 48:  47%|████▋     | 72/153 [00:01<00:01, 52.32it/s, Epoch: 48, Batch: 73,Loss: -2.455,Avg.Loss: -1.853,LR: 2.70E-04]Training epoch 48:  48%|████▊     | 73/153 [00:01<00:01, 52.56it/s, Epoch: 48, Batch: 73,Loss: -2.455,Avg.Loss: -1.853,LR: 2.70E-04]Training epoch 48:  48%|████▊     | 73/153 [00:01<00:01, 52.56it/s, Epoch: 48, Batch: 74,Loss: -2.742,Avg.Loss: -1.865,LR: 2.70E-04]Training epoch 48:  48%|████▊     | 74/153 [00:01<00:01, 52.56it/s, Epoch: 48, Batch: 75,Loss: -1.849,Avg.Loss: -1.865,LR: 2.70E-04]Training epoch 48:  49%|████▉     | 75/153 [00:01<00:01, 52.56it/s, Epoch: 48, Batch: 76,Loss: -2.296,Avg.Loss: -1.871,LR: 2.70E-04]Training epoch 48:  50%|████▉     | 76/153 [00:01<00:01, 52.56it/s, Epoch: 48, Batch: 77,Loss: -1.759,Avg.Loss: -1.869,LR: 2.70E-04]Training epoch 48:  50%|█████     | 77/153 [00:01<00:01, 52.56it/s, Epoch: 48, Batch: 78,Loss: -2.170,Avg.Loss: -1.873,LR: 2.70E-04]Training epoch 48:  51%|█████     | 78/153 [00:01<00:01, 52.56it/s, Epoch: 48, Batch: 79,Loss: -2.281,Avg.Loss: -1.878,LR: 2.69E-04]Training epoch 48:  52%|█████▏    | 79/153 [00:01<00:01, 52.59it/s, Epoch: 48, Batch: 79,Loss: -2.281,Avg.Loss: -1.878,LR: 2.69E-04]Training epoch 48:  52%|█████▏    | 79/153 [00:01<00:01, 52.59it/s, Epoch: 48, Batch: 80,Loss: -2.200,Avg.Loss: -1.883,LR: 2.69E-04]Training epoch 48:  52%|█████▏    | 80/153 [00:01<00:01, 52.59it/s, Epoch: 48, Batch: 81,Loss: -2.492,Avg.Loss: -1.890,LR: 2.69E-04]Training epoch 48:  53%|█████▎    | 81/153 [00:01<00:01, 52.59it/s, Epoch: 48, Batch: 82,Loss: -2.023,Avg.Loss: -1.892,LR: 2.69E-04]Training epoch 48:  54%|█████▎    | 82/153 [00:01<00:01, 52.59it/s, Epoch: 48, Batch: 83,Loss: -2.113,Avg.Loss: -1.894,LR: 2.69E-04]Training epoch 48:  54%|█████▍    | 83/153 [00:01<00:01, 52.59it/s, Epoch: 48, Batch: 84,Loss: -2.417,Avg.Loss: -1.901,LR: 2.69E-04]Training epoch 48:  55%|█████▍    | 84/153 [00:01<00:01, 52.59it/s, Epoch: 48, Batch: 85,Loss: -2.751,Avg.Loss: -1.911,LR: 2.69E-04]Training epoch 48:  56%|█████▌    | 85/153 [00:01<00:01, 52.62it/s, Epoch: 48, Batch: 85,Loss: -2.751,Avg.Loss: -1.911,LR: 2.69E-04]Training epoch 48:  56%|█████▌    | 85/153 [00:01<00:01, 52.62it/s, Epoch: 48, Batch: 86,Loss: -2.765,Avg.Loss: -1.920,LR: 2.69E-04]Training epoch 48:  56%|█████▌    | 86/153 [00:01<00:01, 52.62it/s, Epoch: 48, Batch: 87,Loss: -2.964,Avg.Loss: -1.932,LR: 2.69E-04]Training epoch 48:  57%|█████▋    | 87/153 [00:01<00:01, 52.62it/s, Epoch: 48, Batch: 88,Loss: -2.399,Avg.Loss: -1.938,LR: 2.69E-04]Training epoch 48:  58%|█████▊    | 88/153 [00:01<00:01, 52.62it/s, Epoch: 48, Batch: 89,Loss: -1.564,Avg.Loss: -1.934,LR: 2.69E-04]Training epoch 48:  58%|█████▊    | 89/153 [00:01<00:01, 52.62it/s, Epoch: 48, Batch: 90,Loss: -1.611,Avg.Loss: -1.930,LR: 2.69E-04]Training epoch 48:  59%|█████▉    | 90/153 [00:01<00:01, 52.62it/s, Epoch: 48, Batch: 91,Loss: -1.579,Avg.Loss: -1.926,LR: 2.69E-04]Training epoch 48:  59%|█████▉    | 91/153 [00:01<00:01, 52.61it/s, Epoch: 48, Batch: 91,Loss: -1.579,Avg.Loss: -1.926,LR: 2.69E-04]Training epoch 48:  59%|█████▉    | 91/153 [00:01<00:01, 52.61it/s, Epoch: 48, Batch: 92,Loss: -2.502,Avg.Loss: -1.932,LR: 2.69E-04]Training epoch 48:  60%|██████    | 92/153 [00:01<00:01, 52.61it/s, Epoch: 48, Batch: 93,Loss: -2.743,Avg.Loss: -1.941,LR: 2.69E-04]Training epoch 48:  61%|██████    | 93/153 [00:01<00:01, 52.61it/s, Epoch: 48, Batch: 94,Loss: -1.167,Avg.Loss: -1.933,LR: 2.69E-04]Training epoch 48:  61%|██████▏   | 94/153 [00:01<00:01, 52.61it/s, Epoch: 48, Batch: 95,Loss: -1.501,Avg.Loss: -1.928,LR: 2.69E-04]Training epoch 48:  62%|██████▏   | 95/153 [00:01<00:01, 52.61it/s, Epoch: 48, Batch: 96,Loss: -1.525,Avg.Loss: -1.924,LR: 2.69E-04]Training epoch 48:  63%|██████▎   | 96/153 [00:01<00:01, 52.61it/s, Epoch: 48, Batch: 97,Loss: -1.896,Avg.Loss: -1.924,LR: 2.69E-04]Training epoch 48:  63%|██████▎   | 97/153 [00:01<00:01, 52.58it/s, Epoch: 48, Batch: 97,Loss: -1.896,Avg.Loss: -1.924,LR: 2.69E-04]Training epoch 48:  63%|██████▎   | 97/153 [00:01<00:01, 52.58it/s, Epoch: 48, Batch: 98,Loss: -2.098,Avg.Loss: -1.926,LR: 2.69E-04]Training epoch 48:  64%|██████▍   | 98/153 [00:01<00:01, 52.58it/s, Epoch: 48, Batch: 99,Loss: -2.287,Avg.Loss: -1.929,LR: 2.68E-04]Training epoch 48:  65%|██████▍   | 99/153 [00:01<00:01, 52.58it/s, Epoch: 48, Batch: 100,Loss: -2.058,Avg.Loss: -1.931,LR: 2.68E-04]Training epoch 48:  65%|██████▌   | 100/153 [00:01<00:01, 52.58it/s, Epoch: 48, Batch: 101,Loss: -1.187,Avg.Loss: -1.923,LR: 2.68E-04]Training epoch 48:  66%|██████▌   | 101/153 [00:01<00:00, 52.58it/s, Epoch: 48, Batch: 102,Loss: -1.513,Avg.Loss: -1.919,LR: 2.68E-04]Training epoch 48:  67%|██████▋   | 102/153 [00:01<00:00, 52.58it/s, Epoch: 48, Batch: 103,Loss: -1.991,Avg.Loss: -1.920,LR: 2.68E-04]Training epoch 48:  67%|██████▋   | 103/153 [00:01<00:00, 52.57it/s, Epoch: 48, Batch: 103,Loss: -1.991,Avg.Loss: -1.920,LR: 2.68E-04]Training epoch 48:  67%|██████▋   | 103/153 [00:01<00:00, 52.57it/s, Epoch: 48, Batch: 104,Loss: -1.367,Avg.Loss: -1.915,LR: 2.68E-04]Training epoch 48:  68%|██████▊   | 104/153 [00:01<00:00, 52.57it/s, Epoch: 48, Batch: 105,Loss: -1.543,Avg.Loss: -1.911,LR: 2.68E-04]Training epoch 48:  69%|██████▊   | 105/153 [00:02<00:00, 52.57it/s, Epoch: 48, Batch: 106,Loss: -2.131,Avg.Loss: -1.913,LR: 2.68E-04]Training epoch 48:  69%|██████▉   | 106/153 [00:02<00:00, 52.57it/s, Epoch: 48, Batch: 107,Loss: -2.129,Avg.Loss: -1.915,LR: 2.68E-04]Training epoch 48:  70%|██████▉   | 107/153 [00:02<00:00, 52.57it/s, Epoch: 48, Batch: 108,Loss: -1.890,Avg.Loss: -1.915,LR: 2.68E-04]Training epoch 48:  71%|███████   | 108/153 [00:02<00:00, 52.57it/s, Epoch: 48, Batch: 109,Loss: -0.925,Avg.Loss: -1.906,LR: 2.68E-04]Training epoch 48:  71%|███████   | 109/153 [00:02<00:00, 52.76it/s, Epoch: 48, Batch: 109,Loss: -0.925,Avg.Loss: -1.906,LR: 2.68E-04]Training epoch 48:  71%|███████   | 109/153 [00:02<00:00, 52.76it/s, Epoch: 48, Batch: 110,Loss: -1.732,Avg.Loss: -1.904,LR: 2.68E-04]Training epoch 48:  72%|███████▏  | 110/153 [00:02<00:00, 52.76it/s, Epoch: 48, Batch: 111,Loss: -1.995,Avg.Loss: -1.905,LR: 2.68E-04]Training epoch 48:  73%|███████▎  | 111/153 [00:02<00:00, 52.76it/s, Epoch: 48, Batch: 112,Loss: -2.009,Avg.Loss: -1.906,LR: 2.68E-04]Training epoch 48:  73%|███████▎  | 112/153 [00:02<00:00, 52.76it/s, Epoch: 48, Batch: 113,Loss: -0.859,Avg.Loss: -1.897,LR: 2.68E-04]Training epoch 48:  74%|███████▍  | 113/153 [00:02<00:00, 52.76it/s, Epoch: 48, Batch: 114,Loss: -1.263,Avg.Loss: -1.891,LR: 2.68E-04]Training epoch 48:  75%|███████▍  | 114/153 [00:02<00:00, 52.76it/s, Epoch: 48, Batch: 115,Loss: -2.236,Avg.Loss: -1.894,LR: 2.68E-04]Training epoch 48:  75%|███████▌  | 115/153 [00:02<00:00, 52.91it/s, Epoch: 48, Batch: 115,Loss: -2.236,Avg.Loss: -1.894,LR: 2.68E-04]Training epoch 48:  75%|███████▌  | 115/153 [00:02<00:00, 52.91it/s, Epoch: 48, Batch: 116,Loss: -1.940,Avg.Loss: -1.895,LR: 2.68E-04]Training epoch 48:  76%|███████▌  | 116/153 [00:02<00:00, 52.91it/s, Epoch: 48, Batch: 117,Loss: -1.383,Avg.Loss: -1.890,LR: 2.68E-04]Training epoch 48:  76%|███████▋  | 117/153 [00:02<00:00, 52.91it/s, Epoch: 48, Batch: 118,Loss: -1.405,Avg.Loss: -1.886,LR: 2.67E-04]Training epoch 48:  77%|███████▋  | 118/153 [00:02<00:00, 52.91it/s, Epoch: 48, Batch: 119,Loss: -2.763,Avg.Loss: -1.893,LR: 2.67E-04]Training epoch 48:  78%|███████▊  | 119/153 [00:02<00:00, 52.91it/s, Epoch: 48, Batch: 120,Loss: -2.592,Avg.Loss: -1.899,LR: 2.67E-04]Training epoch 48:  78%|███████▊  | 120/153 [00:02<00:00, 52.91it/s, Epoch: 48, Batch: 121,Loss: -1.954,Avg.Loss: -1.900,LR: 2.67E-04]Training epoch 48:  79%|███████▉  | 121/153 [00:02<00:00, 52.48it/s, Epoch: 48, Batch: 121,Loss: -1.954,Avg.Loss: -1.900,LR: 2.67E-04]Training epoch 48:  79%|███████▉  | 121/153 [00:02<00:00, 52.48it/s, Epoch: 48, Batch: 122,Loss: -2.221,Avg.Loss: -1.902,LR: 2.67E-04]Training epoch 48:  80%|███████▉  | 122/153 [00:02<00:00, 52.48it/s, Epoch: 48, Batch: 123,Loss: -2.385,Avg.Loss: -1.906,LR: 2.67E-04]Training epoch 48:  80%|████████  | 123/153 [00:02<00:00, 52.48it/s, Epoch: 48, Batch: 124,Loss: -2.402,Avg.Loss: -1.910,LR: 2.67E-04]Training epoch 48:  81%|████████  | 124/153 [00:02<00:00, 52.48it/s, Epoch: 48, Batch: 125,Loss: -1.892,Avg.Loss: -1.910,LR: 2.67E-04]Training epoch 48:  82%|████████▏ | 125/153 [00:02<00:00, 52.48it/s, Epoch: 48, Batch: 126,Loss: -2.466,Avg.Loss: -1.914,LR: 2.67E-04]Training epoch 48:  82%|████████▏ | 126/153 [00:02<00:00, 52.48it/s, Epoch: 48, Batch: 127,Loss: -2.167,Avg.Loss: -1.916,LR: 2.67E-04]Training epoch 48:  83%|████████▎ | 127/153 [00:02<00:00, 52.61it/s, Epoch: 48, Batch: 127,Loss: -2.167,Avg.Loss: -1.916,LR: 2.67E-04]Training epoch 48:  83%|████████▎ | 127/153 [00:02<00:00, 52.61it/s, Epoch: 48, Batch: 128,Loss: -1.794,Avg.Loss: -1.916,LR: 2.67E-04]Training epoch 48:  84%|████████▎ | 128/153 [00:02<00:00, 52.61it/s, Epoch: 48, Batch: 129,Loss: -2.074,Avg.Loss: -1.917,LR: 2.67E-04]Training epoch 48:  84%|████████▍ | 129/153 [00:02<00:00, 52.61it/s, Epoch: 48, Batch: 130,Loss: -2.379,Avg.Loss: -1.920,LR: 2.67E-04]Training epoch 48:  85%|████████▍ | 130/153 [00:02<00:00, 52.61it/s, Epoch: 48, Batch: 131,Loss: -2.236,Avg.Loss: -1.923,LR: 2.67E-04]Training epoch 48:  86%|████████▌ | 131/153 [00:02<00:00, 52.61it/s, Epoch: 48, Batch: 132,Loss: -2.430,Avg.Loss: -1.927,LR: 2.67E-04]Training epoch 48:  86%|████████▋ | 132/153 [00:02<00:00, 52.61it/s, Epoch: 48, Batch: 133,Loss: -2.822,Avg.Loss: -1.933,LR: 2.67E-04]Training epoch 48:  87%|████████▋ | 133/153 [00:02<00:00, 52.88it/s, Epoch: 48, Batch: 133,Loss: -2.822,Avg.Loss: -1.933,LR: 2.67E-04]Training epoch 48:  87%|████████▋ | 133/153 [00:02<00:00, 52.88it/s, Epoch: 48, Batch: 134,Loss: -1.860,Avg.Loss: -1.933,LR: 2.67E-04]Training epoch 48:  88%|████████▊ | 134/153 [00:02<00:00, 52.88it/s, Epoch: 48, Batch: 135,Loss: -2.865,Avg.Loss: -1.940,LR: 2.67E-04]Training epoch 48:  88%|████████▊ | 135/153 [00:02<00:00, 52.88it/s, Epoch: 48, Batch: 136,Loss: -2.652,Avg.Loss: -1.945,LR: 2.67E-04]Training epoch 48:  89%|████████▉ | 136/153 [00:02<00:00, 52.88it/s, Epoch: 48, Batch: 137,Loss: -2.317,Avg.Loss: -1.948,LR: 2.67E-04]Training epoch 48:  90%|████████▉ | 137/153 [00:02<00:00, 52.88it/s, Epoch: 48, Batch: 138,Loss: -2.873,Avg.Loss: -1.954,LR: 2.66E-04]Training epoch 48:  90%|█████████ | 138/153 [00:02<00:00, 52.88it/s, Epoch: 48, Batch: 139,Loss: -2.651,Avg.Loss: -1.959,LR: 2.66E-04]Training epoch 48:  91%|█████████ | 139/153 [00:02<00:00, 53.12it/s, Epoch: 48, Batch: 139,Loss: -2.651,Avg.Loss: -1.959,LR: 2.66E-04]Training epoch 48:  91%|█████████ | 139/153 [00:02<00:00, 53.12it/s, Epoch: 48, Batch: 140,Loss: -2.190,Avg.Loss: -1.961,LR: 2.66E-04]Training epoch 48:  92%|█████████▏| 140/153 [00:02<00:00, 53.12it/s, Epoch: 48, Batch: 141,Loss: -2.083,Avg.Loss: -1.962,LR: 2.66E-04]Training epoch 48:  92%|█████████▏| 141/153 [00:02<00:00, 53.12it/s, Epoch: 48, Batch: 142,Loss: -2.652,Avg.Loss: -1.967,LR: 2.66E-04]Training epoch 48:  93%|█████████▎| 142/153 [00:02<00:00, 53.12it/s, Epoch: 48, Batch: 143,Loss: -2.287,Avg.Loss: -1.969,LR: 2.66E-04]Training epoch 48:  93%|█████████▎| 143/153 [00:02<00:00, 53.12it/s, Epoch: 48, Batch: 144,Loss: -2.686,Avg.Loss: -1.974,LR: 2.66E-04]Training epoch 48:  94%|█████████▍| 144/153 [00:02<00:00, 53.12it/s, Epoch: 48, Batch: 145,Loss: -2.722,Avg.Loss: -1.979,LR: 2.66E-04]Training epoch 48:  95%|█████████▍| 145/153 [00:02<00:00, 53.30it/s, Epoch: 48, Batch: 145,Loss: -2.722,Avg.Loss: -1.979,LR: 2.66E-04]Training epoch 48:  95%|█████████▍| 145/153 [00:02<00:00, 53.30it/s, Epoch: 48, Batch: 146,Loss: -2.581,Avg.Loss: -1.983,LR: 2.66E-04]Training epoch 48:  95%|█████████▌| 146/153 [00:02<00:00, 53.30it/s, Epoch: 48, Batch: 147,Loss: -2.685,Avg.Loss: -1.988,LR: 2.66E-04]Training epoch 48:  96%|█████████▌| 147/153 [00:02<00:00, 53.30it/s, Epoch: 48, Batch: 148,Loss: -2.434,Avg.Loss: -1.991,LR: 2.66E-04]Training epoch 48:  97%|█████████▋| 148/153 [00:02<00:00, 53.30it/s, Epoch: 48, Batch: 149,Loss: -2.579,Avg.Loss: -1.995,LR: 2.66E-04]Training epoch 48:  97%|█████████▋| 149/153 [00:02<00:00, 53.30it/s, Epoch: 48, Batch: 150,Loss: -2.765,Avg.Loss: -2.000,LR: 2.66E-04]Training epoch 48:  98%|█████████▊| 150/153 [00:02<00:00, 53.30it/s, Epoch: 48, Batch: 151,Loss: -2.377,Avg.Loss: -2.003,LR: 2.66E-04]Training epoch 48:  99%|█████████▊| 151/153 [00:02<00:00, 53.21it/s, Epoch: 48, Batch: 151,Loss: -2.377,Avg.Loss: -2.003,LR: 2.66E-04]Training epoch 48:  99%|█████████▊| 151/153 [00:02<00:00, 53.21it/s, Epoch: 48, Batch: 152,Loss: -2.272,Avg.Loss: -2.004,LR: 2.66E-04]Training epoch 48:  99%|█████████▉| 152/153 [00:02<00:00, 53.21it/s, Epoch: 48, Batch: 153,Loss: -2.252,Avg.Loss: -2.006,LR: 2.66E-04]Training epoch 48: 100%|██████████| 153/153 [00:02<00:00, 52.80it/s, Epoch: 48, Batch: 153,Loss: -2.252,Avg.Loss: -2.006,LR: 2.66E-04]
Training epoch 49:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 49:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 49, Batch: 1,Loss: -2.414,Avg.Loss: -2.414,LR: 2.66E-04]Training epoch 49:   1%|          | 1/153 [00:00<00:05, 27.26it/s, Epoch: 49, Batch: 2,Loss: -1.687,Avg.Loss: -2.051,LR: 2.66E-04]Training epoch 49:   1%|▏         | 2/153 [00:00<00:04, 36.97it/s, Epoch: 49, Batch: 3,Loss: -2.307,Avg.Loss: -2.136,LR: 2.66E-04]Training epoch 49:   2%|▏         | 3/153 [00:00<00:03, 41.57it/s, Epoch: 49, Batch: 4,Loss: -1.859,Avg.Loss: -2.067,LR: 2.65E-04]Training epoch 49:   3%|▎         | 4/153 [00:00<00:03, 43.84it/s, Epoch: 49, Batch: 5,Loss: -1.657,Avg.Loss: -1.985,LR: 2.65E-04]Training epoch 49:   3%|▎         | 5/153 [00:00<00:03, 45.50it/s, Epoch: 49, Batch: 6,Loss: -2.240,Avg.Loss: -2.027,LR: 2.65E-04]Training epoch 49:   4%|▍         | 6/153 [00:00<00:02, 54.51it/s, Epoch: 49, Batch: 6,Loss: -2.240,Avg.Loss: -2.027,LR: 2.65E-04]Training epoch 49:   4%|▍         | 6/153 [00:00<00:02, 54.51it/s, Epoch: 49, Batch: 7,Loss: -1.602,Avg.Loss: -1.967,LR: 2.65E-04]Training epoch 49:   5%|▍         | 7/153 [00:00<00:02, 54.51it/s, Epoch: 49, Batch: 8,Loss: -1.445,Avg.Loss: -1.901,LR: 2.65E-04]Training epoch 49:   5%|▌         | 8/153 [00:00<00:02, 54.51it/s, Epoch: 49, Batch: 9,Loss: -1.848,Avg.Loss: -1.895,LR: 2.65E-04]Training epoch 49:   6%|▌         | 9/153 [00:00<00:02, 54.51it/s, Epoch: 49, Batch: 10,Loss: -1.792,Avg.Loss: -1.885,LR: 2.65E-04]Training epoch 49:   7%|▋         | 10/153 [00:00<00:02, 54.51it/s, Epoch: 49, Batch: 11,Loss: -1.320,Avg.Loss: -1.834,LR: 2.65E-04]Training epoch 49:   7%|▋         | 11/153 [00:00<00:02, 54.51it/s, Epoch: 49, Batch: 12,Loss: -2.363,Avg.Loss: -1.878,LR: 2.65E-04]Training epoch 49:   8%|▊         | 12/153 [00:00<00:02, 53.46it/s, Epoch: 49, Batch: 12,Loss: -2.363,Avg.Loss: -1.878,LR: 2.65E-04]Training epoch 49:   8%|▊         | 12/153 [00:00<00:02, 53.46it/s, Epoch: 49, Batch: 13,Loss: -2.695,Avg.Loss: -1.941,LR: 2.65E-04]Training epoch 49:   8%|▊         | 13/153 [00:00<00:02, 53.46it/s, Epoch: 49, Batch: 14,Loss: -1.846,Avg.Loss: -1.934,LR: 2.65E-04]Training epoch 49:   9%|▉         | 14/153 [00:00<00:02, 53.46it/s, Epoch: 49, Batch: 15,Loss: -0.349,Avg.Loss: -1.828,LR: 2.65E-04]Training epoch 49:  10%|▉         | 15/153 [00:00<00:02, 53.46it/s, Epoch: 49, Batch: 16,Loss: -0.730,Avg.Loss: -1.760,LR: 2.65E-04]Training epoch 49:  10%|█         | 16/153 [00:00<00:02, 53.46it/s, Epoch: 49, Batch: 17,Loss: -1.749,Avg.Loss: -1.759,LR: 2.65E-04]Training epoch 49:  11%|█         | 17/153 [00:00<00:02, 53.46it/s, Epoch: 49, Batch: 18,Loss: -2.049,Avg.Loss: -1.775,LR: 2.65E-04]Training epoch 49:  12%|█▏        | 18/153 [00:00<00:02, 53.57it/s, Epoch: 49, Batch: 18,Loss: -2.049,Avg.Loss: -1.775,LR: 2.65E-04]Training epoch 49:  12%|█▏        | 18/153 [00:00<00:02, 53.57it/s, Epoch: 49, Batch: 19,Loss: -1.821,Avg.Loss: -1.777,LR: 2.65E-04]Training epoch 49:  12%|█▏        | 19/153 [00:00<00:02, 53.57it/s, Epoch: 49, Batch: 20,Loss: -2.241,Avg.Loss: -1.801,LR: 2.65E-04]Training epoch 49:  13%|█▎        | 20/153 [00:00<00:02, 53.57it/s, Epoch: 49, Batch: 21,Loss: -2.439,Avg.Loss: -1.831,LR: 2.65E-04]Training epoch 49:  14%|█▎        | 21/153 [00:00<00:02, 53.57it/s, Epoch: 49, Batch: 22,Loss: -1.916,Avg.Loss: -1.835,LR: 2.65E-04]Training epoch 49:  14%|█▍        | 22/153 [00:00<00:02, 53.57it/s, Epoch: 49, Batch: 23,Loss: -0.589,Avg.Loss: -1.781,LR: 2.65E-04]Training epoch 49:  15%|█▌        | 23/153 [00:00<00:02, 53.57it/s, Epoch: 49, Batch: 24,Loss: -1.302,Avg.Loss: -1.761,LR: 2.64E-04]Training epoch 49:  16%|█▌        | 24/153 [00:00<00:02, 52.68it/s, Epoch: 49, Batch: 24,Loss: -1.302,Avg.Loss: -1.761,LR: 2.64E-04]Training epoch 49:  16%|█▌        | 24/153 [00:00<00:02, 52.68it/s, Epoch: 49, Batch: 25,Loss: -2.614,Avg.Loss: -1.795,LR: 2.64E-04]Training epoch 49:  16%|█▋        | 25/153 [00:00<00:02, 52.68it/s, Epoch: 49, Batch: 26,Loss: -2.054,Avg.Loss: -1.805,LR: 2.64E-04]Training epoch 49:  17%|█▋        | 26/153 [00:00<00:02, 52.68it/s, Epoch: 49, Batch: 27,Loss: -1.800,Avg.Loss: -1.805,LR: 2.64E-04]Training epoch 49:  18%|█▊        | 27/153 [00:00<00:02, 52.68it/s, Epoch: 49, Batch: 28,Loss: -2.082,Avg.Loss: -1.815,LR: 2.64E-04]Training epoch 49:  18%|█▊        | 28/153 [00:00<00:02, 52.68it/s, Epoch: 49, Batch: 29,Loss: -2.632,Avg.Loss: -1.843,LR: 2.64E-04]Training epoch 49:  19%|█▉        | 29/153 [00:00<00:02, 52.68it/s, Epoch: 49, Batch: 30,Loss: -1.994,Avg.Loss: -1.848,LR: 2.64E-04]Training epoch 49:  20%|█▉        | 30/153 [00:00<00:02, 52.01it/s, Epoch: 49, Batch: 30,Loss: -1.994,Avg.Loss: -1.848,LR: 2.64E-04]Training epoch 49:  20%|█▉        | 30/153 [00:00<00:02, 52.01it/s, Epoch: 49, Batch: 31,Loss: -1.591,Avg.Loss: -1.840,LR: 2.64E-04]Training epoch 49:  20%|██        | 31/153 [00:00<00:02, 52.01it/s, Epoch: 49, Batch: 32,Loss: -1.849,Avg.Loss: -1.840,LR: 2.64E-04]Training epoch 49:  21%|██        | 32/153 [00:00<00:02, 52.01it/s, Epoch: 49, Batch: 33,Loss: -2.291,Avg.Loss: -1.854,LR: 2.64E-04]Training epoch 49:  22%|██▏       | 33/153 [00:00<00:02, 52.01it/s, Epoch: 49, Batch: 34,Loss: -2.434,Avg.Loss: -1.871,LR: 2.64E-04]Training epoch 49:  22%|██▏       | 34/153 [00:00<00:02, 52.01it/s, Epoch: 49, Batch: 35,Loss: -2.173,Avg.Loss: -1.879,LR: 2.64E-04]Training epoch 49:  23%|██▎       | 35/153 [00:00<00:02, 52.01it/s, Epoch: 49, Batch: 36,Loss: -1.930,Avg.Loss: -1.881,LR: 2.64E-04]Training epoch 49:  24%|██▎       | 36/153 [00:00<00:02, 52.27it/s, Epoch: 49, Batch: 36,Loss: -1.930,Avg.Loss: -1.881,LR: 2.64E-04]Training epoch 49:  24%|██▎       | 36/153 [00:00<00:02, 52.27it/s, Epoch: 49, Batch: 37,Loss: -2.548,Avg.Loss: -1.899,LR: 2.64E-04]Training epoch 49:  24%|██▍       | 37/153 [00:00<00:02, 52.27it/s, Epoch: 49, Batch: 38,Loss: -2.655,Avg.Loss: -1.919,LR: 2.64E-04]Training epoch 49:  25%|██▍       | 38/153 [00:00<00:02, 52.27it/s, Epoch: 49, Batch: 39,Loss: -1.774,Avg.Loss: -1.915,LR: 2.64E-04]Training epoch 49:  25%|██▌       | 39/153 [00:00<00:02, 52.27it/s, Epoch: 49, Batch: 40,Loss: -2.559,Avg.Loss: -1.931,LR: 2.64E-04]Training epoch 49:  26%|██▌       | 40/153 [00:00<00:02, 52.27it/s, Epoch: 49, Batch: 41,Loss: -2.387,Avg.Loss: -1.942,LR: 2.64E-04]Training epoch 49:  27%|██▋       | 41/153 [00:00<00:02, 52.27it/s, Epoch: 49, Batch: 42,Loss: -2.241,Avg.Loss: -1.949,LR: 2.64E-04]Training epoch 49:  27%|██▋       | 42/153 [00:00<00:02, 52.53it/s, Epoch: 49, Batch: 42,Loss: -2.241,Avg.Loss: -1.949,LR: 2.64E-04]Training epoch 49:  27%|██▋       | 42/153 [00:00<00:02, 52.53it/s, Epoch: 49, Batch: 43,Loss: -1.440,Avg.Loss: -1.937,LR: 2.63E-04]Training epoch 49:  28%|██▊       | 43/153 [00:00<00:02, 52.53it/s, Epoch: 49, Batch: 44,Loss: -1.825,Avg.Loss: -1.935,LR: 2.63E-04]Training epoch 49:  29%|██▉       | 44/153 [00:00<00:02, 52.53it/s, Epoch: 49, Batch: 45,Loss: -2.535,Avg.Loss: -1.948,LR: 2.63E-04]Training epoch 49:  29%|██▉       | 45/153 [00:00<00:02, 52.53it/s, Epoch: 49, Batch: 46,Loss: -2.040,Avg.Loss: -1.950,LR: 2.63E-04]Training epoch 49:  30%|███       | 46/153 [00:00<00:02, 52.53it/s, Epoch: 49, Batch: 47,Loss: -1.281,Avg.Loss: -1.936,LR: 2.63E-04]Training epoch 49:  31%|███       | 47/153 [00:00<00:02, 52.53it/s, Epoch: 49, Batch: 48,Loss: -1.790,Avg.Loss: -1.933,LR: 2.63E-04]Training epoch 49:  31%|███▏      | 48/153 [00:00<00:01, 52.54it/s, Epoch: 49, Batch: 48,Loss: -1.790,Avg.Loss: -1.933,LR: 2.63E-04]Training epoch 49:  31%|███▏      | 48/153 [00:00<00:01, 52.54it/s, Epoch: 49, Batch: 49,Loss: -2.499,Avg.Loss: -1.944,LR: 2.63E-04]Training epoch 49:  32%|███▏      | 49/153 [00:00<00:01, 52.54it/s, Epoch: 49, Batch: 50,Loss: -2.552,Avg.Loss: -1.957,LR: 2.63E-04]Training epoch 49:  33%|███▎      | 50/153 [00:00<00:01, 52.54it/s, Epoch: 49, Batch: 51,Loss: -1.767,Avg.Loss: -1.953,LR: 2.63E-04]Training epoch 49:  33%|███▎      | 51/153 [00:00<00:01, 52.54it/s, Epoch: 49, Batch: 52,Loss: -2.358,Avg.Loss: -1.961,LR: 2.63E-04]Training epoch 49:  34%|███▍      | 52/153 [00:01<00:01, 52.54it/s, Epoch: 49, Batch: 53,Loss: -2.750,Avg.Loss: -1.976,LR: 2.63E-04]Training epoch 49:  35%|███▍      | 53/153 [00:01<00:01, 52.54it/s, Epoch: 49, Batch: 54,Loss: -2.314,Avg.Loss: -1.982,LR: 2.63E-04]Training epoch 49:  35%|███▌      | 54/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 54,Loss: -2.314,Avg.Loss: -1.982,LR: 2.63E-04]Training epoch 49:  35%|███▌      | 54/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 55,Loss: -1.821,Avg.Loss: -1.979,LR: 2.63E-04]Training epoch 49:  36%|███▌      | 55/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 56,Loss: -2.007,Avg.Loss: -1.979,LR: 2.63E-04]Training epoch 49:  37%|███▋      | 56/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 57,Loss: -2.684,Avg.Loss: -1.992,LR: 2.63E-04]Training epoch 49:  37%|███▋      | 57/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 58,Loss: -2.143,Avg.Loss: -1.994,LR: 2.63E-04]Training epoch 49:  38%|███▊      | 58/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 59,Loss: -1.495,Avg.Loss: -1.986,LR: 2.63E-04]Training epoch 49:  39%|███▊      | 59/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 60,Loss: -1.694,Avg.Loss: -1.981,LR: 2.63E-04]Training epoch 49:  39%|███▉      | 60/153 [00:01<00:01, 52.74it/s, Epoch: 49, Batch: 60,Loss: -1.694,Avg.Loss: -1.981,LR: 2.63E-04]Training epoch 49:  39%|███▉      | 60/153 [00:01<00:01, 52.74it/s, Epoch: 49, Batch: 61,Loss: -2.178,Avg.Loss: -1.984,LR: 2.63E-04]Training epoch 49:  40%|███▉      | 61/153 [00:01<00:01, 52.74it/s, Epoch: 49, Batch: 62,Loss: -2.241,Avg.Loss: -1.988,LR: 2.63E-04]Training epoch 49:  41%|████      | 62/153 [00:01<00:01, 52.74it/s, Epoch: 49, Batch: 63,Loss: -1.727,Avg.Loss: -1.984,LR: 2.62E-04]Training epoch 49:  41%|████      | 63/153 [00:01<00:01, 52.74it/s, Epoch: 49, Batch: 64,Loss: -1.906,Avg.Loss: -1.983,LR: 2.62E-04]Training epoch 49:  42%|████▏     | 64/153 [00:01<00:01, 52.74it/s, Epoch: 49, Batch: 65,Loss: -2.848,Avg.Loss: -1.996,LR: 2.62E-04]Training epoch 49:  42%|████▏     | 65/153 [00:01<00:01, 52.74it/s, Epoch: 49, Batch: 66,Loss: -2.223,Avg.Loss: -2.000,LR: 2.62E-04]Training epoch 49:  43%|████▎     | 66/153 [00:01<00:01, 52.86it/s, Epoch: 49, Batch: 66,Loss: -2.223,Avg.Loss: -2.000,LR: 2.62E-04]Training epoch 49:  43%|████▎     | 66/153 [00:01<00:01, 52.86it/s, Epoch: 49, Batch: 67,Loss: -1.477,Avg.Loss: -1.992,LR: 2.62E-04]Training epoch 49:  44%|████▍     | 67/153 [00:01<00:01, 52.86it/s, Epoch: 49, Batch: 68,Loss: -1.709,Avg.Loss: -1.988,LR: 2.62E-04]Training epoch 49:  44%|████▍     | 68/153 [00:01<00:01, 52.86it/s, Epoch: 49, Batch: 69,Loss: -2.379,Avg.Loss: -1.993,LR: 2.62E-04]Training epoch 49:  45%|████▌     | 69/153 [00:01<00:01, 52.86it/s, Epoch: 49, Batch: 70,Loss: -2.485,Avg.Loss: -2.001,LR: 2.62E-04]Training epoch 49:  46%|████▌     | 70/153 [00:01<00:01, 52.86it/s, Epoch: 49, Batch: 71,Loss: -1.343,Avg.Loss: -1.991,LR: 2.62E-04]Training epoch 49:  46%|████▋     | 71/153 [00:01<00:01, 52.86it/s, Epoch: 49, Batch: 72,Loss: -2.137,Avg.Loss: -1.993,LR: 2.62E-04]Training epoch 49:  47%|████▋     | 72/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 72,Loss: -2.137,Avg.Loss: -1.993,LR: 2.62E-04]Training epoch 49:  47%|████▋     | 72/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 73,Loss: -2.534,Avg.Loss: -2.001,LR: 2.62E-04]Training epoch 49:  48%|████▊     | 73/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 74,Loss: -2.559,Avg.Loss: -2.008,LR: 2.62E-04]Training epoch 49:  48%|████▊     | 74/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 75,Loss: -2.143,Avg.Loss: -2.010,LR: 2.62E-04]Training epoch 49:  49%|████▉     | 75/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 76,Loss: -1.958,Avg.Loss: -2.009,LR: 2.62E-04]Training epoch 49:  50%|████▉     | 76/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 77,Loss: -2.569,Avg.Loss: -2.017,LR: 2.62E-04]Training epoch 49:  50%|█████     | 77/153 [00:01<00:01, 52.70it/s, Epoch: 49, Batch: 78,Loss: -2.358,Avg.Loss: -2.021,LR: 2.62E-04]Training epoch 49:  51%|█████     | 78/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 78,Loss: -2.358,Avg.Loss: -2.021,LR: 2.62E-04]Training epoch 49:  51%|█████     | 78/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 79,Loss: -1.676,Avg.Loss: -2.017,LR: 2.62E-04]Training epoch 49:  52%|█████▏    | 79/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 80,Loss: -1.911,Avg.Loss: -2.015,LR: 2.62E-04]Training epoch 49:  52%|█████▏    | 80/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 81,Loss: -2.525,Avg.Loss: -2.022,LR: 2.62E-04]Training epoch 49:  53%|█████▎    | 81/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 82,Loss: -2.550,Avg.Loss: -2.028,LR: 2.61E-04]Training epoch 49:  54%|█████▎    | 82/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 83,Loss: -1.957,Avg.Loss: -2.027,LR: 2.61E-04]Training epoch 49:  54%|█████▍    | 83/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 84,Loss: -2.168,Avg.Loss: -2.029,LR: 2.61E-04]Training epoch 49:  55%|█████▍    | 84/153 [00:01<00:01, 52.30it/s, Epoch: 49, Batch: 84,Loss: -2.168,Avg.Loss: -2.029,LR: 2.61E-04]Training epoch 49:  55%|█████▍    | 84/153 [00:01<00:01, 52.30it/s, Epoch: 49, Batch: 85,Loss: -2.095,Avg.Loss: -2.030,LR: 2.61E-04]Training epoch 49:  56%|█████▌    | 85/153 [00:01<00:01, 52.30it/s, Epoch: 49, Batch: 86,Loss: -2.633,Avg.Loss: -2.037,LR: 2.61E-04]Training epoch 49:  56%|█████▌    | 86/153 [00:01<00:01, 52.30it/s, Epoch: 49, Batch: 87,Loss: -2.381,Avg.Loss: -2.041,LR: 2.61E-04]Training epoch 49:  57%|█████▋    | 87/153 [00:01<00:01, 52.30it/s, Epoch: 49, Batch: 88,Loss: -2.758,Avg.Loss: -2.049,LR: 2.61E-04]Training epoch 49:  58%|█████▊    | 88/153 [00:01<00:01, 52.30it/s, Epoch: 49, Batch: 89,Loss: -2.449,Avg.Loss: -2.053,LR: 2.61E-04]Training epoch 49:  58%|█████▊    | 89/153 [00:01<00:01, 52.30it/s, Epoch: 49, Batch: 90,Loss: -2.121,Avg.Loss: -2.054,LR: 2.61E-04]Training epoch 49:  59%|█████▉    | 90/153 [00:01<00:01, 52.33it/s, Epoch: 49, Batch: 90,Loss: -2.121,Avg.Loss: -2.054,LR: 2.61E-04]Training epoch 49:  59%|█████▉    | 90/153 [00:01<00:01, 52.33it/s, Epoch: 49, Batch: 91,Loss: -1.819,Avg.Loss: -2.051,LR: 2.61E-04]Training epoch 49:  59%|█████▉    | 91/153 [00:01<00:01, 52.33it/s, Epoch: 49, Batch: 92,Loss: -2.336,Avg.Loss: -2.055,LR: 2.61E-04]Training epoch 49:  60%|██████    | 92/153 [00:01<00:01, 52.33it/s, Epoch: 49, Batch: 93,Loss: -2.915,Avg.Loss: -2.064,LR: 2.61E-04]Training epoch 49:  61%|██████    | 93/153 [00:01<00:01, 52.33it/s, Epoch: 49, Batch: 94,Loss: -2.652,Avg.Loss: -2.070,LR: 2.61E-04]Training epoch 49:  61%|██████▏   | 94/153 [00:01<00:01, 52.33it/s, Epoch: 49, Batch: 95,Loss: -2.147,Avg.Loss: -2.071,LR: 2.61E-04]Training epoch 49:  62%|██████▏   | 95/153 [00:01<00:01, 52.33it/s, Epoch: 49, Batch: 96,Loss: -2.759,Avg.Loss: -2.078,LR: 2.61E-04]Training epoch 49:  63%|██████▎   | 96/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 96,Loss: -2.759,Avg.Loss: -2.078,LR: 2.61E-04]Training epoch 49:  63%|██████▎   | 96/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 97,Loss: -2.746,Avg.Loss: -2.085,LR: 2.61E-04]Training epoch 49:  63%|██████▎   | 97/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 98,Loss: -2.673,Avg.Loss: -2.091,LR: 2.61E-04]Training epoch 49:  64%|██████▍   | 98/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 99,Loss: -2.342,Avg.Loss: -2.093,LR: 2.61E-04]Training epoch 49:  65%|██████▍   | 99/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 100,Loss: -2.572,Avg.Loss: -2.098,LR: 2.61E-04]Training epoch 49:  65%|██████▌   | 100/153 [00:01<00:01, 52.48it/s, Epoch: 49, Batch: 101,Loss: -2.521,Avg.Loss: -2.102,LR: 2.61E-04]Training epoch 49:  66%|██████▌   | 101/153 [00:01<00:00, 52.48it/s, Epoch: 49, Batch: 102,Loss: -2.363,Avg.Loss: -2.105,LR: 2.60E-04]Training epoch 49:  67%|██████▋   | 102/153 [00:01<00:00, 52.53it/s, Epoch: 49, Batch: 102,Loss: -2.363,Avg.Loss: -2.105,LR: 2.60E-04]Training epoch 49:  67%|██████▋   | 102/153 [00:01<00:00, 52.53it/s, Epoch: 49, Batch: 103,Loss: -2.748,Avg.Loss: -2.111,LR: 2.60E-04]Training epoch 49:  67%|██████▋   | 103/153 [00:01<00:00, 52.53it/s, Epoch: 49, Batch: 104,Loss: -2.509,Avg.Loss: -2.115,LR: 2.60E-04]Training epoch 49:  68%|██████▊   | 104/153 [00:01<00:00, 52.53it/s, Epoch: 49, Batch: 105,Loss: -2.404,Avg.Loss: -2.118,LR: 2.60E-04]Training epoch 49:  69%|██████▊   | 105/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 106,Loss: -2.670,Avg.Loss: -2.123,LR: 2.60E-04]Training epoch 49:  69%|██████▉   | 106/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 107,Loss: -2.612,Avg.Loss: -2.128,LR: 2.60E-04]Training epoch 49:  70%|██████▉   | 107/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 108,Loss: -2.481,Avg.Loss: -2.131,LR: 2.60E-04]Training epoch 49:  71%|███████   | 108/153 [00:02<00:00, 52.60it/s, Epoch: 49, Batch: 108,Loss: -2.481,Avg.Loss: -2.131,LR: 2.60E-04]Training epoch 49:  71%|███████   | 108/153 [00:02<00:00, 52.60it/s, Epoch: 49, Batch: 109,Loss: -2.942,Avg.Loss: -2.138,LR: 2.60E-04]Training epoch 49:  71%|███████   | 109/153 [00:02<00:00, 52.60it/s, Epoch: 49, Batch: 110,Loss: -2.654,Avg.Loss: -2.143,LR: 2.60E-04]Training epoch 49:  72%|███████▏  | 110/153 [00:02<00:00, 52.60it/s, Epoch: 49, Batch: 111,Loss: -2.585,Avg.Loss: -2.147,LR: 2.60E-04]Training epoch 49:  73%|███████▎  | 111/153 [00:02<00:00, 52.60it/s, Epoch: 49, Batch: 112,Loss: -2.973,Avg.Loss: -2.154,LR: 2.60E-04]Training epoch 49:  73%|███████▎  | 112/153 [00:02<00:00, 52.60it/s, Epoch: 49, Batch: 113,Loss: -2.139,Avg.Loss: -2.154,LR: 2.60E-04]Training epoch 49:  74%|███████▍  | 113/153 [00:02<00:00, 52.60it/s, Epoch: 49, Batch: 114,Loss: -2.015,Avg.Loss: -2.153,LR: 2.60E-04]Training epoch 49:  75%|███████▍  | 114/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 114,Loss: -2.015,Avg.Loss: -2.153,LR: 2.60E-04]Training epoch 49:  75%|███████▍  | 114/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 115,Loss: -2.374,Avg.Loss: -2.155,LR: 2.60E-04]Training epoch 49:  75%|███████▌  | 115/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 116,Loss: -3.020,Avg.Loss: -2.162,LR: 2.60E-04]Training epoch 49:  76%|███████▌  | 116/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 117,Loss: -2.619,Avg.Loss: -2.166,LR: 2.60E-04]Training epoch 49:  76%|███████▋  | 117/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 118,Loss: -2.760,Avg.Loss: -2.171,LR: 2.60E-04]Training epoch 49:  77%|███████▋  | 118/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 119,Loss: -2.854,Avg.Loss: -2.177,LR: 2.60E-04]Training epoch 49:  78%|███████▊  | 119/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 120,Loss: -2.388,Avg.Loss: -2.179,LR: 2.60E-04]Training epoch 49:  78%|███████▊  | 120/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 120,Loss: -2.388,Avg.Loss: -2.179,LR: 2.60E-04]Training epoch 49:  78%|███████▊  | 120/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 121,Loss: -2.241,Avg.Loss: -2.179,LR: 2.59E-04]Training epoch 49:  79%|███████▉  | 121/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 122,Loss: -2.266,Avg.Loss: -2.180,LR: 2.59E-04]Training epoch 49:  80%|███████▉  | 122/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 123,Loss: -2.166,Avg.Loss: -2.180,LR: 2.59E-04]Training epoch 49:  80%|████████  | 123/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 124,Loss: -2.684,Avg.Loss: -2.184,LR: 2.59E-04]Training epoch 49:  81%|████████  | 124/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 125,Loss: -2.163,Avg.Loss: -2.184,LR: 2.59E-04]Training epoch 49:  82%|████████▏ | 125/153 [00:02<00:00, 52.53it/s, Epoch: 49, Batch: 126,Loss: -1.450,Avg.Loss: -2.178,LR: 2.59E-04]Training epoch 49:  82%|████████▏ | 126/153 [00:02<00:00, 52.45it/s, Epoch: 49, Batch: 126,Loss: -1.450,Avg.Loss: -2.178,LR: 2.59E-04]Training epoch 49:  82%|████████▏ | 126/153 [00:02<00:00, 52.45it/s, Epoch: 49, Batch: 127,Loss: -1.599,Avg.Loss: -2.173,LR: 2.59E-04]Training epoch 49:  83%|████████▎ | 127/153 [00:02<00:00, 52.45it/s, Epoch: 49, Batch: 128,Loss: -1.538,Avg.Loss: -2.168,LR: 2.59E-04]Training epoch 49:  84%|████████▎ | 128/153 [00:02<00:00, 52.45it/s, Epoch: 49, Batch: 129,Loss: -0.978,Avg.Loss: -2.159,LR: 2.59E-04]Training epoch 49:  84%|████████▍ | 129/153 [00:02<00:00, 52.45it/s, Epoch: 49, Batch: 130,Loss: -1.114,Avg.Loss: -2.151,LR: 2.59E-04]Training epoch 49:  85%|████████▍ | 130/153 [00:02<00:00, 52.45it/s, Epoch: 49, Batch: 131,Loss: -1.439,Avg.Loss: -2.146,LR: 2.59E-04]Training epoch 49:  86%|████████▌ | 131/153 [00:02<00:00, 52.45it/s, Epoch: 49, Batch: 132,Loss: -1.764,Avg.Loss: -2.143,LR: 2.59E-04]Training epoch 49:  86%|████████▋ | 132/153 [00:02<00:00, 52.46it/s, Epoch: 49, Batch: 132,Loss: -1.764,Avg.Loss: -2.143,LR: 2.59E-04]Training epoch 49:  86%|████████▋ | 132/153 [00:02<00:00, 52.46it/s, Epoch: 49, Batch: 133,Loss: -1.963,Avg.Loss: -2.141,LR: 2.59E-04]Training epoch 49:  87%|████████▋ | 133/153 [00:02<00:00, 52.46it/s, Epoch: 49, Batch: 134,Loss: -2.713,Avg.Loss: -2.146,LR: 2.59E-04]Training epoch 49:  88%|████████▊ | 134/153 [00:02<00:00, 52.46it/s, Epoch: 49, Batch: 135,Loss: -2.481,Avg.Loss: -2.148,LR: 2.59E-04]Training epoch 49:  88%|████████▊ | 135/153 [00:02<00:00, 52.46it/s, Epoch: 49, Batch: 136,Loss: -1.532,Avg.Loss: -2.144,LR: 2.59E-04]Training epoch 49:  89%|████████▉ | 136/153 [00:02<00:00, 52.46it/s, Epoch: 49, Batch: 137,Loss: -1.689,Avg.Loss: -2.140,LR: 2.59E-04]Training epoch 49:  90%|████████▉ | 137/153 [00:02<00:00, 52.46it/s, Epoch: 49, Batch: 138,Loss: -1.199,Avg.Loss: -2.134,LR: 2.59E-04]Training epoch 49:  90%|█████████ | 138/153 [00:02<00:00, 52.89it/s, Epoch: 49, Batch: 138,Loss: -1.199,Avg.Loss: -2.134,LR: 2.59E-04]Training epoch 49:  90%|█████████ | 138/153 [00:02<00:00, 52.89it/s, Epoch: 49, Batch: 139,Loss: -1.021,Avg.Loss: -2.126,LR: 2.59E-04]Training epoch 49:  91%|█████████ | 139/153 [00:02<00:00, 52.89it/s, Epoch: 49, Batch: 140,Loss: -0.678,Avg.Loss: -2.115,LR: 2.59E-04]Training epoch 49:  92%|█████████▏| 140/153 [00:02<00:00, 52.89it/s, Epoch: 49, Batch: 141,Loss: -1.821,Avg.Loss: -2.113,LR: 2.58E-04]Training epoch 49:  92%|█████████▏| 141/153 [00:02<00:00, 52.89it/s, Epoch: 49, Batch: 142,Loss: -1.759,Avg.Loss: -2.111,LR: 2.58E-04]Training epoch 49:  93%|█████████▎| 142/153 [00:02<00:00, 52.89it/s, Epoch: 49, Batch: 143,Loss: -2.136,Avg.Loss: -2.111,LR: 2.58E-04]Training epoch 49:  93%|█████████▎| 143/153 [00:02<00:00, 52.89it/s, Epoch: 49, Batch: 144,Loss: -2.280,Avg.Loss: -2.112,LR: 2.58E-04]Training epoch 49:  94%|█████████▍| 144/153 [00:02<00:00, 51.77it/s, Epoch: 49, Batch: 144,Loss: -2.280,Avg.Loss: -2.112,LR: 2.58E-04]Training epoch 49:  94%|█████████▍| 144/153 [00:02<00:00, 51.77it/s, Epoch: 49, Batch: 145,Loss: -2.241,Avg.Loss: -2.113,LR: 2.58E-04]Training epoch 49:  95%|█████████▍| 145/153 [00:02<00:00, 51.77it/s, Epoch: 49, Batch: 146,Loss: -2.190,Avg.Loss: -2.113,LR: 2.58E-04]Training epoch 49:  95%|█████████▌| 146/153 [00:02<00:00, 51.77it/s, Epoch: 49, Batch: 147,Loss: -2.245,Avg.Loss: -2.114,LR: 2.58E-04]Training epoch 49:  96%|█████████▌| 147/153 [00:02<00:00, 51.77it/s, Epoch: 49, Batch: 148,Loss: -2.577,Avg.Loss: -2.117,LR: 2.58E-04]Training epoch 49:  97%|█████████▋| 148/153 [00:02<00:00, 51.77it/s, Epoch: 49, Batch: 149,Loss: -2.590,Avg.Loss: -2.121,LR: 2.58E-04]Training epoch 49:  97%|█████████▋| 149/153 [00:02<00:00, 51.77it/s, Epoch: 49, Batch: 150,Loss: -2.331,Avg.Loss: -2.122,LR: 2.58E-04]Training epoch 49:  98%|█████████▊| 150/153 [00:02<00:00, 52.13it/s, Epoch: 49, Batch: 150,Loss: -2.331,Avg.Loss: -2.122,LR: 2.58E-04]Training epoch 49:  98%|█████████▊| 150/153 [00:02<00:00, 52.13it/s, Epoch: 49, Batch: 151,Loss: -1.794,Avg.Loss: -2.120,LR: 2.58E-04]Training epoch 49:  99%|█████████▊| 151/153 [00:02<00:00, 52.13it/s, Epoch: 49, Batch: 152,Loss: -2.230,Avg.Loss: -2.121,LR: 2.58E-04]Training epoch 49:  99%|█████████▉| 152/153 [00:02<00:00, 52.13it/s, Epoch: 49, Batch: 153,Loss: -2.132,Avg.Loss: -2.121,LR: 2.58E-04]Training epoch 49: 100%|██████████| 153/153 [00:02<00:00, 52.46it/s, Epoch: 49, Batch: 153,Loss: -2.132,Avg.Loss: -2.121,LR: 2.58E-04]
Training epoch 50:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 50:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 50, Batch: 1,Loss: -0.804,Avg.Loss: -0.804,LR: 2.58E-04]Training epoch 50:   1%|          | 1/153 [00:00<00:05, 27.15it/s, Epoch: 50, Batch: 2,Loss: -1.580,Avg.Loss: -1.192,LR: 2.58E-04]Training epoch 50:   1%|▏         | 2/153 [00:00<00:04, 36.55it/s, Epoch: 50, Batch: 3,Loss: -2.127,Avg.Loss: -1.504,LR: 2.58E-04]Training epoch 50:   2%|▏         | 3/153 [00:00<00:03, 42.17it/s, Epoch: 50, Batch: 4,Loss: -1.492,Avg.Loss: -1.501,LR: 2.58E-04]Training epoch 50:   3%|▎         | 4/153 [00:00<00:03, 45.13it/s, Epoch: 50, Batch: 5,Loss: -0.667,Avg.Loss: -1.334,LR: 2.58E-04]Training epoch 50:   3%|▎         | 5/153 [00:00<00:03, 46.87it/s, Epoch: 50, Batch: 6,Loss: -1.430,Avg.Loss: -1.350,LR: 2.58E-04]Training epoch 50:   4%|▍         | 6/153 [00:00<00:02, 56.14it/s, Epoch: 50, Batch: 6,Loss: -1.430,Avg.Loss: -1.350,LR: 2.58E-04]Training epoch 50:   4%|▍         | 6/153 [00:00<00:02, 56.14it/s, Epoch: 50, Batch: 7,Loss: -2.026,Avg.Loss: -1.446,LR: 2.57E-04]Training epoch 50:   5%|▍         | 7/153 [00:00<00:02, 56.14it/s, Epoch: 50, Batch: 8,Loss: -1.873,Avg.Loss: -1.500,LR: 2.57E-04]Training epoch 50:   5%|▌         | 8/153 [00:00<00:02, 56.14it/s, Epoch: 50, Batch: 9,Loss: -1.275,Avg.Loss: -1.475,LR: 2.57E-04]Training epoch 50:   6%|▌         | 9/153 [00:00<00:02, 56.14it/s, Epoch: 50, Batch: 10,Loss: -2.288,Avg.Loss: -1.556,LR: 2.57E-04]Training epoch 50:   7%|▋         | 10/153 [00:00<00:02, 56.14it/s, Epoch: 50, Batch: 11,Loss: -2.356,Avg.Loss: -1.629,LR: 2.57E-04]Training epoch 50:   7%|▋         | 11/153 [00:00<00:02, 56.14it/s, Epoch: 50, Batch: 12,Loss: -1.518,Avg.Loss: -1.620,LR: 2.57E-04]Training epoch 50:   8%|▊         | 12/153 [00:00<00:02, 54.51it/s, Epoch: 50, Batch: 12,Loss: -1.518,Avg.Loss: -1.620,LR: 2.57E-04]Training epoch 50:   8%|▊         | 12/153 [00:00<00:02, 54.51it/s, Epoch: 50, Batch: 13,Loss: -1.323,Avg.Loss: -1.597,LR: 2.57E-04]Training epoch 50:   8%|▊         | 13/153 [00:00<00:02, 54.51it/s, Epoch: 50, Batch: 14,Loss: -1.183,Avg.Loss: -1.567,LR: 2.57E-04]Training epoch 50:   9%|▉         | 14/153 [00:00<00:02, 54.51it/s, Epoch: 50, Batch: 15,Loss: -1.821,Avg.Loss: -1.584,LR: 2.57E-04]Training epoch 50:  10%|▉         | 15/153 [00:00<00:02, 54.51it/s, Epoch: 50, Batch: 16,Loss: -2.118,Avg.Loss: -1.618,LR: 2.57E-04]Training epoch 50:  10%|█         | 16/153 [00:00<00:02, 54.51it/s, Epoch: 50, Batch: 17,Loss: -1.772,Avg.Loss: -1.627,LR: 2.57E-04]Training epoch 50:  11%|█         | 17/153 [00:00<00:02, 54.51it/s, Epoch: 50, Batch: 18,Loss: -1.746,Avg.Loss: -1.633,LR: 2.57E-04]Training epoch 50:  12%|█▏        | 18/153 [00:00<00:02, 54.01it/s, Epoch: 50, Batch: 18,Loss: -1.746,Avg.Loss: -1.633,LR: 2.57E-04]Training epoch 50:  12%|█▏        | 18/153 [00:00<00:02, 54.01it/s, Epoch: 50, Batch: 19,Loss: -2.715,Avg.Loss: -1.690,LR: 2.57E-04]Training epoch 50:  12%|█▏        | 19/153 [00:00<00:02, 54.01it/s, Epoch: 50, Batch: 20,Loss: -2.059,Avg.Loss: -1.709,LR: 2.57E-04]Training epoch 50:  13%|█▎        | 20/153 [00:00<00:02, 54.01it/s, Epoch: 50, Batch: 21,Loss: -1.775,Avg.Loss: -1.712,LR: 2.57E-04]Training epoch 50:  14%|█▎        | 21/153 [00:00<00:02, 54.01it/s, Epoch: 50, Batch: 22,Loss: -2.543,Avg.Loss: -1.750,LR: 2.57E-04]Training epoch 50:  14%|█▍        | 22/153 [00:00<00:02, 54.01it/s, Epoch: 50, Batch: 23,Loss: -2.363,Avg.Loss: -1.776,LR: 2.57E-04]Training epoch 50:  15%|█▌        | 23/153 [00:00<00:02, 54.01it/s, Epoch: 50, Batch: 24,Loss: -1.816,Avg.Loss: -1.778,LR: 2.57E-04]Training epoch 50:  16%|█▌        | 24/153 [00:00<00:02, 52.22it/s, Epoch: 50, Batch: 24,Loss: -1.816,Avg.Loss: -1.778,LR: 2.57E-04]Training epoch 50:  16%|█▌        | 24/153 [00:00<00:02, 52.22it/s, Epoch: 50, Batch: 25,Loss: -0.490,Avg.Loss: -1.726,LR: 2.57E-04]Training epoch 50:  16%|█▋        | 25/153 [00:00<00:02, 52.22it/s, Epoch: 50, Batch: 26,Loss: -1.217,Avg.Loss: -1.707,LR: 2.57E-04]Training epoch 50:  17%|█▋        | 26/153 [00:00<00:02, 52.22it/s, Epoch: 50, Batch: 27,Loss: -2.065,Avg.Loss: -1.720,LR: 2.56E-04]Training epoch 50:  18%|█▊        | 27/153 [00:00<00:02, 52.22it/s, Epoch: 50, Batch: 28,Loss: -2.114,Avg.Loss: -1.734,LR: 2.56E-04]Training epoch 50:  18%|█▊        | 28/153 [00:00<00:02, 52.22it/s, Epoch: 50, Batch: 29,Loss: -1.429,Avg.Loss: -1.724,LR: 2.56E-04]Training epoch 50:  19%|█▉        | 29/153 [00:00<00:02, 52.22it/s, Epoch: 50, Batch: 30,Loss: -1.428,Avg.Loss: -1.714,LR: 2.56E-04]Training epoch 50:  20%|█▉        | 30/153 [00:00<00:02, 52.59it/s, Epoch: 50, Batch: 30,Loss: -1.428,Avg.Loss: -1.714,LR: 2.56E-04]Training epoch 50:  20%|█▉        | 30/153 [00:00<00:02, 52.59it/s, Epoch: 50, Batch: 31,Loss: -2.234,Avg.Loss: -1.730,LR: 2.56E-04]Training epoch 50:  20%|██        | 31/153 [00:00<00:02, 52.59it/s, Epoch: 50, Batch: 32,Loss: -1.951,Avg.Loss: -1.737,LR: 2.56E-04]Training epoch 50:  21%|██        | 32/153 [00:00<00:02, 52.59it/s, Epoch: 50, Batch: 33,Loss: -1.830,Avg.Loss: -1.740,LR: 2.56E-04]Training epoch 50:  22%|██▏       | 33/153 [00:00<00:02, 52.59it/s, Epoch: 50, Batch: 34,Loss: -2.164,Avg.Loss: -1.753,LR: 2.56E-04]Training epoch 50:  22%|██▏       | 34/153 [00:00<00:02, 52.59it/s, Epoch: 50, Batch: 35,Loss: -2.603,Avg.Loss: -1.777,LR: 2.56E-04]Training epoch 50:  23%|██▎       | 35/153 [00:00<00:02, 52.59it/s, Epoch: 50, Batch: 36,Loss: -1.927,Avg.Loss: -1.781,LR: 2.56E-04]Training epoch 50:  24%|██▎       | 36/153 [00:00<00:02, 52.82it/s, Epoch: 50, Batch: 36,Loss: -1.927,Avg.Loss: -1.781,LR: 2.56E-04]Training epoch 50:  24%|██▎       | 36/153 [00:00<00:02, 52.82it/s, Epoch: 50, Batch: 37,Loss: -1.626,Avg.Loss: -1.777,LR: 2.56E-04]Training epoch 50:  24%|██▍       | 37/153 [00:00<00:02, 52.82it/s, Epoch: 50, Batch: 38,Loss: -1.987,Avg.Loss: -1.782,LR: 2.56E-04]Training epoch 50:  25%|██▍       | 38/153 [00:00<00:02, 52.82it/s, Epoch: 50, Batch: 39,Loss: -2.070,Avg.Loss: -1.790,LR: 2.56E-04]Training epoch 50:  25%|██▌       | 39/153 [00:00<00:02, 52.82it/s, Epoch: 50, Batch: 40,Loss: -1.987,Avg.Loss: -1.795,LR: 2.56E-04]Training epoch 50:  26%|██▌       | 40/153 [00:00<00:02, 52.82it/s, Epoch: 50, Batch: 41,Loss: -1.976,Avg.Loss: -1.799,LR: 2.56E-04]Training epoch 50:  27%|██▋       | 41/153 [00:00<00:02, 52.82it/s, Epoch: 50, Batch: 42,Loss: -1.651,Avg.Loss: -1.796,LR: 2.56E-04]Training epoch 50:  27%|██▋       | 42/153 [00:00<00:02, 52.93it/s, Epoch: 50, Batch: 42,Loss: -1.651,Avg.Loss: -1.796,LR: 2.56E-04]Training epoch 50:  27%|██▋       | 42/153 [00:00<00:02, 52.93it/s, Epoch: 50, Batch: 43,Loss: -2.529,Avg.Loss: -1.813,LR: 2.56E-04]Training epoch 50:  28%|██▊       | 43/153 [00:00<00:02, 52.93it/s, Epoch: 50, Batch: 44,Loss: -2.397,Avg.Loss: -1.826,LR: 2.56E-04]Training epoch 50:  29%|██▉       | 44/153 [00:00<00:02, 52.93it/s, Epoch: 50, Batch: 45,Loss: -1.894,Avg.Loss: -1.827,LR: 2.56E-04]Training epoch 50:  29%|██▉       | 45/153 [00:00<00:02, 52.93it/s, Epoch: 50, Batch: 46,Loss: -1.972,Avg.Loss: -1.831,LR: 2.55E-04]Training epoch 50:  30%|███       | 46/153 [00:00<00:02, 52.93it/s, Epoch: 50, Batch: 47,Loss: -2.395,Avg.Loss: -1.843,LR: 2.55E-04]Training epoch 50:  31%|███       | 47/153 [00:00<00:02, 52.93it/s, Epoch: 50, Batch: 48,Loss: -2.607,Avg.Loss: -1.859,LR: 2.55E-04]Training epoch 50:  31%|███▏      | 48/153 [00:00<00:01, 53.17it/s, Epoch: 50, Batch: 48,Loss: -2.607,Avg.Loss: -1.859,LR: 2.55E-04]Training epoch 50:  31%|███▏      | 48/153 [00:00<00:01, 53.17it/s, Epoch: 50, Batch: 49,Loss: -1.633,Avg.Loss: -1.854,LR: 2.55E-04]Training epoch 50:  32%|███▏      | 49/153 [00:00<00:01, 53.17it/s, Epoch: 50, Batch: 50,Loss: -2.214,Avg.Loss: -1.861,LR: 2.55E-04]Training epoch 50:  33%|███▎      | 50/153 [00:00<00:01, 53.17it/s, Epoch: 50, Batch: 51,Loss: -2.395,Avg.Loss: -1.872,LR: 2.55E-04]Training epoch 50:  33%|███▎      | 51/153 [00:00<00:01, 53.17it/s, Epoch: 50, Batch: 52,Loss: -2.953,Avg.Loss: -1.892,LR: 2.55E-04]Training epoch 50:  34%|███▍      | 52/153 [00:00<00:01, 53.17it/s, Epoch: 50, Batch: 53,Loss: -1.945,Avg.Loss: -1.893,LR: 2.55E-04]Training epoch 50:  35%|███▍      | 53/153 [00:01<00:01, 53.17it/s, Epoch: 50, Batch: 54,Loss: -2.019,Avg.Loss: -1.896,LR: 2.55E-04]Training epoch 50:  35%|███▌      | 54/153 [00:01<00:01, 53.32it/s, Epoch: 50, Batch: 54,Loss: -2.019,Avg.Loss: -1.896,LR: 2.55E-04]Training epoch 50:  35%|███▌      | 54/153 [00:01<00:01, 53.32it/s, Epoch: 50, Batch: 55,Loss: -2.773,Avg.Loss: -1.912,LR: 2.55E-04]Training epoch 50:  36%|███▌      | 55/153 [00:01<00:01, 53.32it/s, Epoch: 50, Batch: 56,Loss: -2.268,Avg.Loss: -1.918,LR: 2.55E-04]Training epoch 50:  37%|███▋      | 56/153 [00:01<00:01, 53.32it/s, Epoch: 50, Batch: 57,Loss: -0.601,Avg.Loss: -1.895,LR: 2.55E-04]Training epoch 50:  37%|███▋      | 57/153 [00:01<00:01, 53.32it/s, Epoch: 50, Batch: 58,Loss: -1.299,Avg.Loss: -1.885,LR: 2.55E-04]Training epoch 50:  38%|███▊      | 58/153 [00:01<00:01, 53.32it/s, Epoch: 50, Batch: 59,Loss: -2.315,Avg.Loss: -1.892,LR: 2.55E-04]Training epoch 50:  39%|███▊      | 59/153 [00:01<00:01, 53.32it/s, Epoch: 50, Batch: 60,Loss: -2.384,Avg.Loss: -1.900,LR: 2.55E-04]Training epoch 50:  39%|███▉      | 60/153 [00:01<00:01, 53.25it/s, Epoch: 50, Batch: 60,Loss: -2.384,Avg.Loss: -1.900,LR: 2.55E-04]Training epoch 50:  39%|███▉      | 60/153 [00:01<00:01, 53.25it/s, Epoch: 50, Batch: 61,Loss: -1.832,Avg.Loss: -1.899,LR: 2.55E-04]Training epoch 50:  40%|███▉      | 61/153 [00:01<00:01, 53.25it/s, Epoch: 50, Batch: 62,Loss: -1.797,Avg.Loss: -1.897,LR: 2.55E-04]Training epoch 50:  41%|████      | 62/153 [00:01<00:01, 53.25it/s, Epoch: 50, Batch: 63,Loss: -2.052,Avg.Loss: -1.900,LR: 2.55E-04]Training epoch 50:  41%|████      | 63/153 [00:01<00:01, 53.25it/s, Epoch: 50, Batch: 64,Loss: -2.231,Avg.Loss: -1.905,LR: 2.55E-04]Training epoch 50:  42%|████▏     | 64/153 [00:01<00:01, 53.25it/s, Epoch: 50, Batch: 65,Loss: -2.001,Avg.Loss: -1.906,LR: 2.55E-04]Training epoch 50:  42%|████▏     | 65/153 [00:01<00:01, 53.25it/s, Epoch: 50, Batch: 66,Loss: 0.625,Avg.Loss: -1.868,LR: 2.54E-04] Training epoch 50:  43%|████▎     | 66/153 [00:01<00:01, 53.18it/s, Epoch: 50, Batch: 66,Loss: 0.625,Avg.Loss: -1.868,LR: 2.54E-04]Training epoch 50:  43%|████▎     | 66/153 [00:01<00:01, 53.18it/s, Epoch: 50, Batch: 67,Loss: -0.080,Avg.Loss: -1.841,LR: 2.54E-04]Training epoch 50:  44%|████▍     | 67/153 [00:01<00:01, 53.18it/s, Epoch: 50, Batch: 68,Loss: -0.557,Avg.Loss: -1.823,LR: 2.54E-04]Training epoch 50:  44%|████▍     | 68/153 [00:01<00:01, 53.18it/s, Epoch: 50, Batch: 69,Loss: -1.382,Avg.Loss: -1.816,LR: 2.54E-04]Training epoch 50:  45%|████▌     | 69/153 [00:01<00:01, 53.18it/s, Epoch: 50, Batch: 70,Loss: -1.824,Avg.Loss: -1.816,LR: 2.54E-04]Training epoch 50:  46%|████▌     | 70/153 [00:01<00:01, 53.18it/s, Epoch: 50, Batch: 71,Loss: -2.252,Avg.Loss: -1.822,LR: 2.54E-04]Training epoch 50:  46%|████▋     | 71/153 [00:01<00:01, 53.18it/s, Epoch: 50, Batch: 72,Loss: -2.088,Avg.Loss: -1.826,LR: 2.54E-04]Training epoch 50:  47%|████▋     | 72/153 [00:01<00:01, 53.14it/s, Epoch: 50, Batch: 72,Loss: -2.088,Avg.Loss: -1.826,LR: 2.54E-04]Training epoch 50:  47%|████▋     | 72/153 [00:01<00:01, 53.14it/s, Epoch: 50, Batch: 73,Loss: -2.046,Avg.Loss: -1.829,LR: 2.54E-04]Training epoch 50:  48%|████▊     | 73/153 [00:01<00:01, 53.14it/s, Epoch: 50, Batch: 74,Loss: -1.867,Avg.Loss: -1.830,LR: 2.54E-04]Training epoch 50:  48%|████▊     | 74/153 [00:01<00:01, 53.14it/s, Epoch: 50, Batch: 75,Loss: -2.459,Avg.Loss: -1.838,LR: 2.54E-04]Training epoch 50:  49%|████▉     | 75/153 [00:01<00:01, 53.14it/s, Epoch: 50, Batch: 76,Loss: -2.552,Avg.Loss: -1.847,LR: 2.54E-04]Training epoch 50:  50%|████▉     | 76/153 [00:01<00:01, 53.14it/s, Epoch: 50, Batch: 77,Loss: -2.166,Avg.Loss: -1.852,LR: 2.54E-04]Training epoch 50:  50%|█████     | 77/153 [00:01<00:01, 53.14it/s, Epoch: 50, Batch: 78,Loss: -2.228,Avg.Loss: -1.856,LR: 2.54E-04]Training epoch 50:  51%|█████     | 78/153 [00:01<00:01, 52.96it/s, Epoch: 50, Batch: 78,Loss: -2.228,Avg.Loss: -1.856,LR: 2.54E-04]Training epoch 50:  51%|█████     | 78/153 [00:01<00:01, 52.96it/s, Epoch: 50, Batch: 79,Loss: -2.125,Avg.Loss: -1.860,LR: 2.54E-04]Training epoch 50:  52%|█████▏    | 79/153 [00:01<00:01, 52.96it/s, Epoch: 50, Batch: 80,Loss: -2.032,Avg.Loss: -1.862,LR: 2.54E-04]Training epoch 50:  52%|█████▏    | 80/153 [00:01<00:01, 52.96it/s, Epoch: 50, Batch: 81,Loss: -2.146,Avg.Loss: -1.865,LR: 2.54E-04]Training epoch 50:  53%|█████▎    | 81/153 [00:01<00:01, 52.96it/s, Epoch: 50, Batch: 82,Loss: -1.994,Avg.Loss: -1.867,LR: 2.54E-04]Training epoch 50:  54%|█████▎    | 82/153 [00:01<00:01, 52.96it/s, Epoch: 50, Batch: 83,Loss: -2.356,Avg.Loss: -1.873,LR: 2.54E-04]Training epoch 50:  54%|█████▍    | 83/153 [00:01<00:01, 52.96it/s, Epoch: 50, Batch: 84,Loss: -2.512,Avg.Loss: -1.880,LR: 2.54E-04]Training epoch 50:  55%|█████▍    | 84/153 [00:01<00:01, 52.86it/s, Epoch: 50, Batch: 84,Loss: -2.512,Avg.Loss: -1.880,LR: 2.54E-04]Training epoch 50:  55%|█████▍    | 84/153 [00:01<00:01, 52.86it/s, Epoch: 50, Batch: 85,Loss: -2.004,Avg.Loss: -1.882,LR: 2.53E-04]Training epoch 50:  56%|█████▌    | 85/153 [00:01<00:01, 52.86it/s, Epoch: 50, Batch: 86,Loss: -1.998,Avg.Loss: -1.883,LR: 2.53E-04]Training epoch 50:  56%|█████▌    | 86/153 [00:01<00:01, 52.86it/s, Epoch: 50, Batch: 87,Loss: -2.071,Avg.Loss: -1.885,LR: 2.53E-04]Training epoch 50:  57%|█████▋    | 87/153 [00:01<00:01, 52.86it/s, Epoch: 50, Batch: 88,Loss: -2.305,Avg.Loss: -1.890,LR: 2.53E-04]Training epoch 50:  58%|█████▊    | 88/153 [00:01<00:01, 52.86it/s, Epoch: 50, Batch: 89,Loss: -2.114,Avg.Loss: -1.893,LR: 2.53E-04]Training epoch 50:  58%|█████▊    | 89/153 [00:01<00:01, 52.86it/s, Epoch: 50, Batch: 90,Loss: -2.328,Avg.Loss: -1.898,LR: 2.53E-04]Training epoch 50:  59%|█████▉    | 90/153 [00:01<00:01, 52.92it/s, Epoch: 50, Batch: 90,Loss: -2.328,Avg.Loss: -1.898,LR: 2.53E-04]Training epoch 50:  59%|█████▉    | 90/153 [00:01<00:01, 52.92it/s, Epoch: 50, Batch: 91,Loss: -2.600,Avg.Loss: -1.905,LR: 2.53E-04]Training epoch 50:  59%|█████▉    | 91/153 [00:01<00:01, 52.92it/s, Epoch: 50, Batch: 92,Loss: -2.365,Avg.Loss: -1.910,LR: 2.53E-04]Training epoch 50:  60%|██████    | 92/153 [00:01<00:01, 52.92it/s, Epoch: 50, Batch: 93,Loss: -1.916,Avg.Loss: -1.910,LR: 2.53E-04]Training epoch 50:  61%|██████    | 93/153 [00:01<00:01, 52.92it/s, Epoch: 50, Batch: 94,Loss: -1.526,Avg.Loss: -1.906,LR: 2.53E-04]Training epoch 50:  61%|██████▏   | 94/153 [00:01<00:01, 52.92it/s, Epoch: 50, Batch: 95,Loss: -1.328,Avg.Loss: -1.900,LR: 2.53E-04]Training epoch 50:  62%|██████▏   | 95/153 [00:01<00:01, 52.92it/s, Epoch: 50, Batch: 96,Loss: -1.284,Avg.Loss: -1.894,LR: 2.53E-04]Training epoch 50:  63%|██████▎   | 96/153 [00:01<00:01, 53.11it/s, Epoch: 50, Batch: 96,Loss: -1.284,Avg.Loss: -1.894,LR: 2.53E-04]Training epoch 50:  63%|██████▎   | 96/153 [00:01<00:01, 53.11it/s, Epoch: 50, Batch: 97,Loss: -2.287,Avg.Loss: -1.898,LR: 2.53E-04]Training epoch 50:  63%|██████▎   | 97/153 [00:01<00:01, 53.11it/s, Epoch: 50, Batch: 98,Loss: -2.490,Avg.Loss: -1.904,LR: 2.53E-04]Training epoch 50:  64%|██████▍   | 98/153 [00:01<00:01, 53.11it/s, Epoch: 50, Batch: 99,Loss: -2.086,Avg.Loss: -1.906,LR: 2.53E-04]Training epoch 50:  65%|██████▍   | 99/153 [00:01<00:01, 53.11it/s, Epoch: 50, Batch: 100,Loss: -2.177,Avg.Loss: -1.908,LR: 2.53E-04]Training epoch 50:  65%|██████▌   | 100/153 [00:01<00:00, 53.11it/s, Epoch: 50, Batch: 101,Loss: -1.668,Avg.Loss: -1.906,LR: 2.53E-04]Training epoch 50:  66%|██████▌   | 101/153 [00:01<00:00, 53.11it/s, Epoch: 50, Batch: 102,Loss: -2.085,Avg.Loss: -1.908,LR: 2.53E-04]Training epoch 50:  67%|██████▋   | 102/153 [00:01<00:00, 53.23it/s, Epoch: 50, Batch: 102,Loss: -2.085,Avg.Loss: -1.908,LR: 2.53E-04]Training epoch 50:  67%|██████▋   | 102/153 [00:01<00:00, 53.23it/s, Epoch: 50, Batch: 103,Loss: -2.042,Avg.Loss: -1.909,LR: 2.53E-04]Training epoch 50:  67%|██████▋   | 103/153 [00:01<00:00, 53.23it/s, Epoch: 50, Batch: 104,Loss: -2.419,Avg.Loss: -1.914,LR: 2.53E-04]Training epoch 50:  68%|██████▊   | 104/153 [00:01<00:00, 53.23it/s, Epoch: 50, Batch: 105,Loss: -2.252,Avg.Loss: -1.917,LR: 2.52E-04]Training epoch 50:  69%|██████▊   | 105/153 [00:01<00:00, 53.23it/s, Epoch: 50, Batch: 106,Loss: -2.373,Avg.Loss: -1.922,LR: 2.52E-04]Training epoch 50:  69%|██████▉   | 106/153 [00:02<00:00, 53.23it/s, Epoch: 50, Batch: 107,Loss: -2.164,Avg.Loss: -1.924,LR: 2.52E-04]Training epoch 50:  70%|██████▉   | 107/153 [00:02<00:00, 53.23it/s, Epoch: 50, Batch: 108,Loss: -1.840,Avg.Loss: -1.923,LR: 2.52E-04]Training epoch 50:  71%|███████   | 108/153 [00:02<00:00, 53.28it/s, Epoch: 50, Batch: 108,Loss: -1.840,Avg.Loss: -1.923,LR: 2.52E-04]Training epoch 50:  71%|███████   | 108/153 [00:02<00:00, 53.28it/s, Epoch: 50, Batch: 109,Loss: -2.040,Avg.Loss: -1.924,LR: 2.52E-04]Training epoch 50:  71%|███████   | 109/153 [00:02<00:00, 53.28it/s, Epoch: 50, Batch: 110,Loss: -1.657,Avg.Loss: -1.922,LR: 2.52E-04]Training epoch 50:  72%|███████▏  | 110/153 [00:02<00:00, 53.28it/s, Epoch: 50, Batch: 111,Loss: -1.984,Avg.Loss: -1.922,LR: 2.52E-04]Training epoch 50:  73%|███████▎  | 111/153 [00:02<00:00, 53.28it/s, Epoch: 50, Batch: 112,Loss: -2.263,Avg.Loss: -1.925,LR: 2.52E-04]Training epoch 50:  73%|███████▎  | 112/153 [00:02<00:00, 53.28it/s, Epoch: 50, Batch: 113,Loss: -2.608,Avg.Loss: -1.931,LR: 2.52E-04]Training epoch 50:  74%|███████▍  | 113/153 [00:02<00:00, 53.28it/s, Epoch: 50, Batch: 114,Loss: -2.254,Avg.Loss: -1.934,LR: 2.52E-04]Training epoch 50:  75%|███████▍  | 114/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 114,Loss: -2.254,Avg.Loss: -1.934,LR: 2.52E-04]Training epoch 50:  75%|███████▍  | 114/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 115,Loss: -2.655,Avg.Loss: -1.940,LR: 2.52E-04]Training epoch 50:  75%|███████▌  | 115/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 116,Loss: -2.520,Avg.Loss: -1.945,LR: 2.52E-04]Training epoch 50:  76%|███████▌  | 116/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 117,Loss: -2.160,Avg.Loss: -1.947,LR: 2.52E-04]Training epoch 50:  76%|███████▋  | 117/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 118,Loss: -1.984,Avg.Loss: -1.948,LR: 2.52E-04]Training epoch 50:  77%|███████▋  | 118/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 119,Loss: -1.801,Avg.Loss: -1.946,LR: 2.52E-04]Training epoch 50:  78%|███████▊  | 119/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 120,Loss: -2.138,Avg.Loss: -1.948,LR: 2.52E-04]Training epoch 50:  78%|███████▊  | 120/153 [00:02<00:00, 53.19it/s, Epoch: 50, Batch: 120,Loss: -2.138,Avg.Loss: -1.948,LR: 2.52E-04]Training epoch 50:  78%|███████▊  | 120/153 [00:02<00:00, 53.19it/s, Epoch: 50, Batch: 121,Loss: -2.436,Avg.Loss: -1.952,LR: 2.52E-04]Training epoch 50:  79%|███████▉  | 121/153 [00:02<00:00, 53.19it/s, Epoch: 50, Batch: 122,Loss: -2.262,Avg.Loss: -1.954,LR: 2.52E-04]Training epoch 50:  80%|███████▉  | 122/153 [00:02<00:00, 53.19it/s, Epoch: 50, Batch: 123,Loss: -2.005,Avg.Loss: -1.955,LR: 2.52E-04]Training epoch 50:  80%|████████  | 123/153 [00:02<00:00, 53.19it/s, Epoch: 50, Batch: 124,Loss: -2.011,Avg.Loss: -1.955,LR: 2.51E-04]Training epoch 50:  81%|████████  | 124/153 [00:02<00:00, 53.19it/s, Epoch: 50, Batch: 125,Loss: -2.209,Avg.Loss: -1.957,LR: 2.51E-04]Training epoch 50:  82%|████████▏ | 125/153 [00:02<00:00, 53.19it/s, Epoch: 50, Batch: 126,Loss: -1.508,Avg.Loss: -1.954,LR: 2.51E-04]Training epoch 50:  82%|████████▏ | 126/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 126,Loss: -1.508,Avg.Loss: -1.954,LR: 2.51E-04]Training epoch 50:  82%|████████▏ | 126/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 127,Loss: -2.071,Avg.Loss: -1.955,LR: 2.51E-04]Training epoch 50:  83%|████████▎ | 127/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 128,Loss: -2.049,Avg.Loss: -1.955,LR: 2.51E-04]Training epoch 50:  84%|████████▎ | 128/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 129,Loss: -1.927,Avg.Loss: -1.955,LR: 2.51E-04]Training epoch 50:  84%|████████▍ | 129/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 130,Loss: -1.743,Avg.Loss: -1.954,LR: 2.51E-04]Training epoch 50:  85%|████████▍ | 130/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 131,Loss: -1.826,Avg.Loss: -1.953,LR: 2.51E-04]Training epoch 50:  86%|████████▌ | 131/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 132,Loss: -2.312,Avg.Loss: -1.955,LR: 2.51E-04]Training epoch 50:  86%|████████▋ | 132/153 [00:02<00:00, 53.38it/s, Epoch: 50, Batch: 132,Loss: -2.312,Avg.Loss: -1.955,LR: 2.51E-04]Training epoch 50:  86%|████████▋ | 132/153 [00:02<00:00, 53.38it/s, Epoch: 50, Batch: 133,Loss: -2.232,Avg.Loss: -1.957,LR: 2.51E-04]Training epoch 50:  87%|████████▋ | 133/153 [00:02<00:00, 53.38it/s, Epoch: 50, Batch: 134,Loss: -2.264,Avg.Loss: -1.960,LR: 2.51E-04]Training epoch 50:  88%|████████▊ | 134/153 [00:02<00:00, 53.38it/s, Epoch: 50, Batch: 135,Loss: -1.919,Avg.Loss: -1.959,LR: 2.51E-04]Training epoch 50:  88%|████████▊ | 135/153 [00:02<00:00, 53.38it/s, Epoch: 50, Batch: 136,Loss: -1.565,Avg.Loss: -1.957,LR: 2.51E-04]Training epoch 50:  89%|████████▉ | 136/153 [00:02<00:00, 53.38it/s, Epoch: 50, Batch: 137,Loss: -2.011,Avg.Loss: -1.957,LR: 2.51E-04]Training epoch 50:  90%|████████▉ | 137/153 [00:02<00:00, 53.38it/s, Epoch: 50, Batch: 138,Loss: -2.638,Avg.Loss: -1.962,LR: 2.51E-04]Training epoch 50:  90%|█████████ | 138/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 138,Loss: -2.638,Avg.Loss: -1.962,LR: 2.51E-04]Training epoch 50:  90%|█████████ | 138/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 139,Loss: -1.899,Avg.Loss: -1.961,LR: 2.51E-04]Training epoch 50:  91%|█████████ | 139/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 140,Loss: -2.428,Avg.Loss: -1.965,LR: 2.51E-04]Training epoch 50:  92%|█████████▏| 140/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 141,Loss: -1.799,Avg.Loss: -1.964,LR: 2.51E-04]Training epoch 50:  92%|█████████▏| 141/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 142,Loss: -1.843,Avg.Loss: -1.963,LR: 2.51E-04]Training epoch 50:  93%|█████████▎| 142/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 143,Loss: -1.472,Avg.Loss: -1.959,LR: 2.51E-04]Training epoch 50:  93%|█████████▎| 143/153 [00:02<00:00, 53.31it/s, Epoch: 50, Batch: 144,Loss: -2.038,Avg.Loss: -1.960,LR: 2.50E-04]Training epoch 50:  94%|█████████▍| 144/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 144,Loss: -2.038,Avg.Loss: -1.960,LR: 2.50E-04]Training epoch 50:  94%|█████████▍| 144/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 145,Loss: -2.746,Avg.Loss: -1.965,LR: 2.50E-04]Training epoch 50:  95%|█████████▍| 145/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 146,Loss: -2.680,Avg.Loss: -1.970,LR: 2.50E-04]Training epoch 50:  95%|█████████▌| 146/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 147,Loss: -2.433,Avg.Loss: -1.973,LR: 2.50E-04]Training epoch 50:  96%|█████████▌| 147/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 148,Loss: -2.294,Avg.Loss: -1.975,LR: 2.50E-04]Training epoch 50:  97%|█████████▋| 148/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 149,Loss: -1.601,Avg.Loss: -1.973,LR: 2.50E-04]Training epoch 50:  97%|█████████▋| 149/153 [00:02<00:00, 53.15it/s, Epoch: 50, Batch: 150,Loss: -2.734,Avg.Loss: -1.978,LR: 2.50E-04]Training epoch 50:  98%|█████████▊| 150/153 [00:02<00:00, 53.01it/s, Epoch: 50, Batch: 150,Loss: -2.734,Avg.Loss: -1.978,LR: 2.50E-04]Training epoch 50:  98%|█████████▊| 150/153 [00:02<00:00, 53.01it/s, Epoch: 50, Batch: 151,Loss: -1.969,Avg.Loss: -1.978,LR: 2.50E-04]Training epoch 50:  99%|█████████▊| 151/153 [00:02<00:00, 53.01it/s, Epoch: 50, Batch: 152,Loss: -2.118,Avg.Loss: -1.979,LR: 2.50E-04]Training epoch 50:  99%|█████████▉| 152/153 [00:02<00:00, 53.01it/s, Epoch: 50, Batch: 153,Loss: -1.940,Avg.Loss: -1.979,LR: 2.50E-04]Training epoch 50: 100%|██████████| 153/153 [00:02<00:00, 53.12it/s, Epoch: 50, Batch: 153,Loss: -1.940,Avg.Loss: -1.979,LR: 2.50E-04]
Training epoch 51:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 51:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 51, Batch: 1,Loss: -2.560,Avg.Loss: -2.560,LR: 2.50E-04]Training epoch 51:   1%|          | 1/153 [00:00<00:05, 25.56it/s, Epoch: 51, Batch: 2,Loss: -2.204,Avg.Loss: -2.382,LR: 2.50E-04]Training epoch 51:   1%|▏         | 2/153 [00:00<00:03, 37.78it/s, Epoch: 51, Batch: 3,Loss: -2.605,Avg.Loss: -2.456,LR: 2.50E-04]Training epoch 51:   2%|▏         | 3/153 [00:00<00:03, 42.29it/s, Epoch: 51, Batch: 4,Loss: -2.423,Avg.Loss: -2.448,LR: 2.50E-04]Training epoch 51:   3%|▎         | 4/153 [00:00<00:03, 44.91it/s, Epoch: 51, Batch: 5,Loss: -2.371,Avg.Loss: -2.433,LR: 2.50E-04]Training epoch 51:   3%|▎         | 5/153 [00:00<00:03, 46.18it/s, Epoch: 51, Batch: 6,Loss: -2.259,Avg.Loss: -2.404,LR: 2.50E-04]Training epoch 51:   4%|▍         | 6/153 [00:00<00:02, 55.32it/s, Epoch: 51, Batch: 6,Loss: -2.259,Avg.Loss: -2.404,LR: 2.50E-04]Training epoch 51:   4%|▍         | 6/153 [00:00<00:02, 55.32it/s, Epoch: 51, Batch: 7,Loss: -2.452,Avg.Loss: -2.411,LR: 2.50E-04]Training epoch 51:   5%|▍         | 7/153 [00:00<00:02, 55.32it/s, Epoch: 51, Batch: 8,Loss: -2.531,Avg.Loss: -2.426,LR: 2.50E-04]Training epoch 51:   5%|▌         | 8/153 [00:00<00:02, 55.32it/s, Epoch: 51, Batch: 9,Loss: -1.964,Avg.Loss: -2.374,LR: 2.50E-04]Training epoch 51:   6%|▌         | 9/153 [00:00<00:02, 55.32it/s, Epoch: 51, Batch: 10,Loss: -2.282,Avg.Loss: -2.365,LR: 2.49E-04]Training epoch 51:   7%|▋         | 10/153 [00:00<00:02, 55.32it/s, Epoch: 51, Batch: 11,Loss: -1.977,Avg.Loss: -2.330,LR: 2.49E-04]Training epoch 51:   7%|▋         | 11/153 [00:00<00:02, 55.32it/s, Epoch: 51, Batch: 12,Loss: -1.924,Avg.Loss: -2.296,LR: 2.49E-04]Training epoch 51:   8%|▊         | 12/153 [00:00<00:02, 54.10it/s, Epoch: 51, Batch: 12,Loss: -1.924,Avg.Loss: -2.296,LR: 2.49E-04]Training epoch 51:   8%|▊         | 12/153 [00:00<00:02, 54.10it/s, Epoch: 51, Batch: 13,Loss: -2.371,Avg.Loss: -2.302,LR: 2.49E-04]Training epoch 51:   8%|▊         | 13/153 [00:00<00:02, 54.10it/s, Epoch: 51, Batch: 14,Loss: -2.399,Avg.Loss: -2.309,LR: 2.49E-04]Training epoch 51:   9%|▉         | 14/153 [00:00<00:02, 54.10it/s, Epoch: 51, Batch: 15,Loss: -2.746,Avg.Loss: -2.338,LR: 2.49E-04]Training epoch 51:  10%|▉         | 15/153 [00:00<00:02, 54.10it/s, Epoch: 51, Batch: 16,Loss: -1.570,Avg.Loss: -2.290,LR: 2.49E-04]Training epoch 51:  10%|█         | 16/153 [00:00<00:02, 54.10it/s, Epoch: 51, Batch: 17,Loss: -1.572,Avg.Loss: -2.248,LR: 2.49E-04]Training epoch 51:  11%|█         | 17/153 [00:00<00:02, 54.10it/s, Epoch: 51, Batch: 18,Loss: -1.908,Avg.Loss: -2.229,LR: 2.49E-04]Training epoch 51:  12%|█▏        | 18/153 [00:00<00:02, 53.53it/s, Epoch: 51, Batch: 18,Loss: -1.908,Avg.Loss: -2.229,LR: 2.49E-04]Training epoch 51:  12%|█▏        | 18/153 [00:00<00:02, 53.53it/s, Epoch: 51, Batch: 19,Loss: -2.031,Avg.Loss: -2.218,LR: 2.49E-04]Training epoch 51:  12%|█▏        | 19/153 [00:00<00:02, 53.53it/s, Epoch: 51, Batch: 20,Loss: -1.928,Avg.Loss: -2.204,LR: 2.49E-04]Training epoch 51:  13%|█▎        | 20/153 [00:00<00:02, 53.53it/s, Epoch: 51, Batch: 21,Loss: -1.549,Avg.Loss: -2.173,LR: 2.49E-04]Training epoch 51:  14%|█▎        | 21/153 [00:00<00:02, 53.53it/s, Epoch: 51, Batch: 22,Loss: -2.391,Avg.Loss: -2.183,LR: 2.49E-04]Training epoch 51:  14%|█▍        | 22/153 [00:00<00:02, 53.53it/s, Epoch: 51, Batch: 23,Loss: -1.916,Avg.Loss: -2.171,LR: 2.49E-04]Training epoch 51:  15%|█▌        | 23/153 [00:00<00:02, 53.53it/s, Epoch: 51, Batch: 24,Loss: -0.110,Avg.Loss: -2.085,LR: 2.49E-04]Training epoch 51:  16%|█▌        | 24/153 [00:00<00:02, 52.94it/s, Epoch: 51, Batch: 24,Loss: -0.110,Avg.Loss: -2.085,LR: 2.49E-04]Training epoch 51:  16%|█▌        | 24/153 [00:00<00:02, 52.94it/s, Epoch: 51, Batch: 25,Loss: -0.545,Avg.Loss: -2.024,LR: 2.49E-04]Training epoch 51:  16%|█▋        | 25/153 [00:00<00:02, 52.94it/s, Epoch: 51, Batch: 26,Loss: -1.992,Avg.Loss: -2.022,LR: 2.49E-04]Training epoch 51:  17%|█▋        | 26/153 [00:00<00:02, 52.94it/s, Epoch: 51, Batch: 27,Loss: -2.294,Avg.Loss: -2.032,LR: 2.49E-04]Training epoch 51:  18%|█▊        | 27/153 [00:00<00:02, 52.94it/s, Epoch: 51, Batch: 28,Loss: -1.933,Avg.Loss: -2.029,LR: 2.49E-04]Training epoch 51:  18%|█▊        | 28/153 [00:00<00:02, 52.94it/s, Epoch: 51, Batch: 29,Loss: -0.483,Avg.Loss: -1.976,LR: 2.49E-04]Training epoch 51:  19%|█▉        | 29/153 [00:00<00:02, 52.94it/s, Epoch: 51, Batch: 30,Loss: -0.389,Avg.Loss: -1.923,LR: 2.48E-04]Training epoch 51:  20%|█▉        | 30/153 [00:00<00:02, 52.49it/s, Epoch: 51, Batch: 30,Loss: -0.389,Avg.Loss: -1.923,LR: 2.48E-04]Training epoch 51:  20%|█▉        | 30/153 [00:00<00:02, 52.49it/s, Epoch: 51, Batch: 31,Loss: -0.663,Avg.Loss: -1.882,LR: 2.48E-04]Training epoch 51:  20%|██        | 31/153 [00:00<00:02, 52.49it/s, Epoch: 51, Batch: 32,Loss: -2.011,Avg.Loss: -1.886,LR: 2.48E-04]Training epoch 51:  21%|██        | 32/153 [00:00<00:02, 52.49it/s, Epoch: 51, Batch: 33,Loss: -1.320,Avg.Loss: -1.869,LR: 2.48E-04]Training epoch 51:  22%|██▏       | 33/153 [00:00<00:02, 52.49it/s, Epoch: 51, Batch: 34,Loss: -0.450,Avg.Loss: -1.827,LR: 2.48E-04]Training epoch 51:  22%|██▏       | 34/153 [00:00<00:02, 52.49it/s, Epoch: 51, Batch: 35,Loss: 0.166,Avg.Loss: -1.770,LR: 2.48E-04] Training epoch 51:  23%|██▎       | 35/153 [00:00<00:02, 52.49it/s, Epoch: 51, Batch: 36,Loss: -0.858,Avg.Loss: -1.745,LR: 2.48E-04]Training epoch 51:  24%|██▎       | 36/153 [00:00<00:02, 52.68it/s, Epoch: 51, Batch: 36,Loss: -0.858,Avg.Loss: -1.745,LR: 2.48E-04]Training epoch 51:  24%|██▎       | 36/153 [00:00<00:02, 52.68it/s, Epoch: 51, Batch: 37,Loss: -1.955,Avg.Loss: -1.751,LR: 2.48E-04]Training epoch 51:  24%|██▍       | 37/153 [00:00<00:02, 52.68it/s, Epoch: 51, Batch: 38,Loss: -2.216,Avg.Loss: -1.763,LR: 2.48E-04]Training epoch 51:  25%|██▍       | 38/153 [00:00<00:02, 52.68it/s, Epoch: 51, Batch: 39,Loss: -0.774,Avg.Loss: -1.737,LR: 2.48E-04]Training epoch 51:  25%|██▌       | 39/153 [00:00<00:02, 52.68it/s, Epoch: 51, Batch: 40,Loss: -0.711,Avg.Loss: -1.712,LR: 2.48E-04]Training epoch 51:  26%|██▌       | 40/153 [00:00<00:02, 52.68it/s, Epoch: 51, Batch: 41,Loss: -1.507,Avg.Loss: -1.707,LR: 2.48E-04]Training epoch 51:  27%|██▋       | 41/153 [00:00<00:02, 52.68it/s, Epoch: 51, Batch: 42,Loss: -2.104,Avg.Loss: -1.716,LR: 2.48E-04]Training epoch 51:  27%|██▋       | 42/153 [00:00<00:02, 52.82it/s, Epoch: 51, Batch: 42,Loss: -2.104,Avg.Loss: -1.716,LR: 2.48E-04]Training epoch 51:  27%|██▋       | 42/153 [00:00<00:02, 52.82it/s, Epoch: 51, Batch: 43,Loss: -1.844,Avg.Loss: -1.719,LR: 2.48E-04]Training epoch 51:  28%|██▊       | 43/153 [00:00<00:02, 52.82it/s, Epoch: 51, Batch: 44,Loss: -1.350,Avg.Loss: -1.711,LR: 2.48E-04]Training epoch 51:  29%|██▉       | 44/153 [00:00<00:02, 52.82it/s, Epoch: 51, Batch: 45,Loss: -0.607,Avg.Loss: -1.686,LR: 2.48E-04]Training epoch 51:  29%|██▉       | 45/153 [00:00<00:02, 52.82it/s, Epoch: 51, Batch: 46,Loss: -1.940,Avg.Loss: -1.692,LR: 2.48E-04]Training epoch 51:  30%|███       | 46/153 [00:00<00:02, 52.82it/s, Epoch: 51, Batch: 47,Loss: -2.317,Avg.Loss: -1.705,LR: 2.48E-04]Training epoch 51:  31%|███       | 47/153 [00:00<00:02, 52.82it/s, Epoch: 51, Batch: 48,Loss: -2.006,Avg.Loss: -1.711,LR: 2.48E-04]Training epoch 51:  31%|███▏      | 48/153 [00:00<00:01, 52.77it/s, Epoch: 51, Batch: 48,Loss: -2.006,Avg.Loss: -1.711,LR: 2.48E-04]Training epoch 51:  31%|███▏      | 48/153 [00:00<00:01, 52.77it/s, Epoch: 51, Batch: 49,Loss: -1.135,Avg.Loss: -1.700,LR: 2.47E-04]Training epoch 51:  32%|███▏      | 49/153 [00:00<00:01, 52.77it/s, Epoch: 51, Batch: 50,Loss: -1.321,Avg.Loss: -1.692,LR: 2.47E-04]Training epoch 51:  33%|███▎      | 50/153 [00:00<00:01, 52.77it/s, Epoch: 51, Batch: 51,Loss: -2.173,Avg.Loss: -1.701,LR: 2.47E-04]Training epoch 51:  33%|███▎      | 51/153 [00:00<00:01, 52.77it/s, Epoch: 51, Batch: 52,Loss: -2.191,Avg.Loss: -1.711,LR: 2.47E-04]Training epoch 51:  34%|███▍      | 52/153 [00:01<00:01, 52.77it/s, Epoch: 51, Batch: 53,Loss: -2.238,Avg.Loss: -1.721,LR: 2.47E-04]Training epoch 51:  35%|███▍      | 53/153 [00:01<00:01, 52.77it/s, Epoch: 51, Batch: 54,Loss: -1.687,Avg.Loss: -1.720,LR: 2.47E-04]Training epoch 51:  35%|███▌      | 54/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 54,Loss: -1.687,Avg.Loss: -1.720,LR: 2.47E-04]Training epoch 51:  35%|███▌      | 54/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 55,Loss: -1.964,Avg.Loss: -1.725,LR: 2.47E-04]Training epoch 51:  36%|███▌      | 55/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 56,Loss: -1.649,Avg.Loss: -1.723,LR: 2.47E-04]Training epoch 51:  37%|███▋      | 56/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 57,Loss: -2.150,Avg.Loss: -1.731,LR: 2.47E-04]Training epoch 51:  37%|███▋      | 57/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 58,Loss: -1.620,Avg.Loss: -1.729,LR: 2.47E-04]Training epoch 51:  38%|███▊      | 58/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 59,Loss: -2.330,Avg.Loss: -1.739,LR: 2.47E-04]Training epoch 51:  39%|███▊      | 59/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 60,Loss: -2.336,Avg.Loss: -1.749,LR: 2.47E-04]Training epoch 51:  39%|███▉      | 60/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 60,Loss: -2.336,Avg.Loss: -1.749,LR: 2.47E-04]Training epoch 51:  39%|███▉      | 60/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 61,Loss: -2.848,Avg.Loss: -1.767,LR: 2.47E-04]Training epoch 51:  40%|███▉      | 61/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 62,Loss: -2.564,Avg.Loss: -1.780,LR: 2.47E-04]Training epoch 51:  41%|████      | 62/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 63,Loss: -2.223,Avg.Loss: -1.787,LR: 2.47E-04]Training epoch 51:  41%|████      | 63/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 64,Loss: -2.359,Avg.Loss: -1.796,LR: 2.47E-04]Training epoch 51:  42%|████▏     | 64/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 65,Loss: -2.126,Avg.Loss: -1.801,LR: 2.47E-04]Training epoch 51:  42%|████▏     | 65/153 [00:01<00:01, 52.89it/s, Epoch: 51, Batch: 66,Loss: -2.235,Avg.Loss: -1.808,LR: 2.47E-04]Training epoch 51:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 66,Loss: -2.235,Avg.Loss: -1.808,LR: 2.47E-04]Training epoch 51:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 67,Loss: -2.004,Avg.Loss: -1.810,LR: 2.47E-04]Training epoch 51:  44%|████▍     | 67/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 68,Loss: -2.430,Avg.Loss: -1.820,LR: 2.47E-04]Training epoch 51:  44%|████▍     | 68/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 69,Loss: -2.655,Avg.Loss: -1.832,LR: 2.46E-04]Training epoch 51:  45%|████▌     | 69/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 70,Loss: -2.037,Avg.Loss: -1.835,LR: 2.46E-04]Training epoch 51:  46%|████▌     | 70/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 71,Loss: -0.769,Avg.Loss: -1.820,LR: 2.46E-04]Training epoch 51:  46%|████▋     | 71/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 72,Loss: -1.767,Avg.Loss: -1.819,LR: 2.46E-04]Training epoch 51:  47%|████▋     | 72/153 [00:01<00:01, 53.02it/s, Epoch: 51, Batch: 72,Loss: -1.767,Avg.Loss: -1.819,LR: 2.46E-04]Training epoch 51:  47%|████▋     | 72/153 [00:01<00:01, 53.02it/s, Epoch: 51, Batch: 73,Loss: -2.191,Avg.Loss: -1.824,LR: 2.46E-04]Training epoch 51:  48%|████▊     | 73/153 [00:01<00:01, 53.02it/s, Epoch: 51, Batch: 74,Loss: -2.243,Avg.Loss: -1.830,LR: 2.46E-04]Training epoch 51:  48%|████▊     | 74/153 [00:01<00:01, 53.02it/s, Epoch: 51, Batch: 75,Loss: -1.496,Avg.Loss: -1.825,LR: 2.46E-04]Training epoch 51:  49%|████▉     | 75/153 [00:01<00:01, 53.02it/s, Epoch: 51, Batch: 76,Loss: -1.655,Avg.Loss: -1.823,LR: 2.46E-04]Training epoch 51:  50%|████▉     | 76/153 [00:01<00:01, 53.02it/s, Epoch: 51, Batch: 77,Loss: -2.170,Avg.Loss: -1.827,LR: 2.46E-04]Training epoch 51:  50%|█████     | 77/153 [00:01<00:01, 53.02it/s, Epoch: 51, Batch: 78,Loss: -2.373,Avg.Loss: -1.834,LR: 2.46E-04]Training epoch 51:  51%|█████     | 78/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 78,Loss: -2.373,Avg.Loss: -1.834,LR: 2.46E-04]Training epoch 51:  51%|█████     | 78/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 79,Loss: -2.113,Avg.Loss: -1.838,LR: 2.46E-04]Training epoch 51:  52%|█████▏    | 79/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 80,Loss: -2.416,Avg.Loss: -1.845,LR: 2.46E-04]Training epoch 51:  52%|█████▏    | 80/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 81,Loss: -2.628,Avg.Loss: -1.855,LR: 2.46E-04]Training epoch 51:  53%|█████▎    | 81/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 82,Loss: -2.407,Avg.Loss: -1.862,LR: 2.46E-04]Training epoch 51:  54%|█████▎    | 82/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 83,Loss: -1.477,Avg.Loss: -1.857,LR: 2.46E-04]Training epoch 51:  54%|█████▍    | 83/153 [00:01<00:01, 52.84it/s, Epoch: 51, Batch: 84,Loss: -1.530,Avg.Loss: -1.853,LR: 2.46E-04]Training epoch 51:  55%|█████▍    | 84/153 [00:01<00:01, 52.50it/s, Epoch: 51, Batch: 84,Loss: -1.530,Avg.Loss: -1.853,LR: 2.46E-04]Training epoch 51:  55%|█████▍    | 84/153 [00:01<00:01, 52.50it/s, Epoch: 51, Batch: 85,Loss: -1.713,Avg.Loss: -1.851,LR: 2.46E-04]Training epoch 51:  56%|█████▌    | 85/153 [00:01<00:01, 52.50it/s, Epoch: 51, Batch: 86,Loss: -1.701,Avg.Loss: -1.850,LR: 2.46E-04]Training epoch 51:  56%|█████▌    | 86/153 [00:01<00:01, 52.50it/s, Epoch: 51, Batch: 87,Loss: -2.695,Avg.Loss: -1.859,LR: 2.46E-04]Training epoch 51:  57%|█████▋    | 87/153 [00:01<00:01, 52.50it/s, Epoch: 51, Batch: 88,Loss: -2.398,Avg.Loss: -1.866,LR: 2.45E-04]Training epoch 51:  58%|█████▊    | 88/153 [00:01<00:01, 52.50it/s, Epoch: 51, Batch: 89,Loss: -2.591,Avg.Loss: -1.874,LR: 2.45E-04]Training epoch 51:  58%|█████▊    | 89/153 [00:01<00:01, 52.50it/s, Epoch: 51, Batch: 90,Loss: -2.502,Avg.Loss: -1.881,LR: 2.45E-04]Training epoch 51:  59%|█████▉    | 90/153 [00:01<00:01, 52.67it/s, Epoch: 51, Batch: 90,Loss: -2.502,Avg.Loss: -1.881,LR: 2.45E-04]Training epoch 51:  59%|█████▉    | 90/153 [00:01<00:01, 52.67it/s, Epoch: 51, Batch: 91,Loss: -2.149,Avg.Loss: -1.884,LR: 2.45E-04]Training epoch 51:  59%|█████▉    | 91/153 [00:01<00:01, 52.67it/s, Epoch: 51, Batch: 92,Loss: -1.763,Avg.Loss: -1.882,LR: 2.45E-04]Training epoch 51:  60%|██████    | 92/153 [00:01<00:01, 52.67it/s, Epoch: 51, Batch: 93,Loss: -2.361,Avg.Loss: -1.887,LR: 2.45E-04]Training epoch 51:  61%|██████    | 93/153 [00:01<00:01, 52.67it/s, Epoch: 51, Batch: 94,Loss: -1.591,Avg.Loss: -1.884,LR: 2.45E-04]Training epoch 51:  61%|██████▏   | 94/153 [00:01<00:01, 52.67it/s, Epoch: 51, Batch: 95,Loss: -1.796,Avg.Loss: -1.883,LR: 2.45E-04]Training epoch 51:  62%|██████▏   | 95/153 [00:01<00:01, 52.67it/s, Epoch: 51, Batch: 96,Loss: -2.453,Avg.Loss: -1.889,LR: 2.45E-04]Training epoch 51:  63%|██████▎   | 96/153 [00:01<00:01, 52.83it/s, Epoch: 51, Batch: 96,Loss: -2.453,Avg.Loss: -1.889,LR: 2.45E-04]Training epoch 51:  63%|██████▎   | 96/153 [00:01<00:01, 52.83it/s, Epoch: 51, Batch: 97,Loss: -2.020,Avg.Loss: -1.891,LR: 2.45E-04]Training epoch 51:  63%|██████▎   | 97/153 [00:01<00:01, 52.83it/s, Epoch: 51, Batch: 98,Loss: -2.154,Avg.Loss: -1.893,LR: 2.45E-04]Training epoch 51:  64%|██████▍   | 98/153 [00:01<00:01, 52.83it/s, Epoch: 51, Batch: 99,Loss: -1.721,Avg.Loss: -1.892,LR: 2.45E-04]Training epoch 51:  65%|██████▍   | 99/153 [00:01<00:01, 52.83it/s, Epoch: 51, Batch: 100,Loss: -2.584,Avg.Loss: -1.899,LR: 2.45E-04]Training epoch 51:  65%|██████▌   | 100/153 [00:01<00:01, 52.83it/s, Epoch: 51, Batch: 101,Loss: -2.355,Avg.Loss: -1.903,LR: 2.45E-04]Training epoch 51:  66%|██████▌   | 101/153 [00:01<00:00, 52.83it/s, Epoch: 51, Batch: 102,Loss: -2.584,Avg.Loss: -1.910,LR: 2.45E-04]Training epoch 51:  67%|██████▋   | 102/153 [00:01<00:00, 52.73it/s, Epoch: 51, Batch: 102,Loss: -2.584,Avg.Loss: -1.910,LR: 2.45E-04]Training epoch 51:  67%|██████▋   | 102/153 [00:01<00:00, 52.73it/s, Epoch: 51, Batch: 103,Loss: -2.211,Avg.Loss: -1.913,LR: 2.45E-04]Training epoch 51:  67%|██████▋   | 103/153 [00:01<00:00, 52.73it/s, Epoch: 51, Batch: 104,Loss: -2.200,Avg.Loss: -1.915,LR: 2.45E-04]Training epoch 51:  68%|██████▊   | 104/153 [00:01<00:00, 52.73it/s, Epoch: 51, Batch: 105,Loss: -2.618,Avg.Loss: -1.922,LR: 2.45E-04]Training epoch 51:  69%|██████▊   | 105/153 [00:02<00:00, 52.73it/s, Epoch: 51, Batch: 106,Loss: -2.309,Avg.Loss: -1.926,LR: 2.45E-04]Training epoch 51:  69%|██████▉   | 106/153 [00:02<00:00, 52.73it/s, Epoch: 51, Batch: 107,Loss: -2.582,Avg.Loss: -1.932,LR: 2.45E-04]Training epoch 51:  70%|██████▉   | 107/153 [00:02<00:00, 52.73it/s, Epoch: 51, Batch: 108,Loss: -2.432,Avg.Loss: -1.936,LR: 2.44E-04]Training epoch 51:  71%|███████   | 108/153 [00:02<00:00, 52.95it/s, Epoch: 51, Batch: 108,Loss: -2.432,Avg.Loss: -1.936,LR: 2.44E-04]Training epoch 51:  71%|███████   | 108/153 [00:02<00:00, 52.95it/s, Epoch: 51, Batch: 109,Loss: -2.664,Avg.Loss: -1.943,LR: 2.44E-04]Training epoch 51:  71%|███████   | 109/153 [00:02<00:00, 52.95it/s, Epoch: 51, Batch: 110,Loss: -2.353,Avg.Loss: -1.947,LR: 2.44E-04]Training epoch 51:  72%|███████▏  | 110/153 [00:02<00:00, 52.95it/s, Epoch: 51, Batch: 111,Loss: -2.307,Avg.Loss: -1.950,LR: 2.44E-04]Training epoch 51:  73%|███████▎  | 111/153 [00:02<00:00, 52.95it/s, Epoch: 51, Batch: 112,Loss: -2.675,Avg.Loss: -1.957,LR: 2.44E-04]Training epoch 51:  73%|███████▎  | 112/153 [00:02<00:00, 52.95it/s, Epoch: 51, Batch: 113,Loss: -1.907,Avg.Loss: -1.956,LR: 2.44E-04]Training epoch 51:  74%|███████▍  | 113/153 [00:02<00:00, 52.95it/s, Epoch: 51, Batch: 114,Loss: -2.415,Avg.Loss: -1.960,LR: 2.44E-04]Training epoch 51:  75%|███████▍  | 114/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 114,Loss: -2.415,Avg.Loss: -1.960,LR: 2.44E-04]Training epoch 51:  75%|███████▍  | 114/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 115,Loss: -2.680,Avg.Loss: -1.966,LR: 2.44E-04]Training epoch 51:  75%|███████▌  | 115/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 116,Loss: -2.412,Avg.Loss: -1.970,LR: 2.44E-04]Training epoch 51:  76%|███████▌  | 116/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 117,Loss: -2.546,Avg.Loss: -1.975,LR: 2.44E-04]Training epoch 51:  76%|███████▋  | 117/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 118,Loss: -2.625,Avg.Loss: -1.981,LR: 2.44E-04]Training epoch 51:  77%|███████▋  | 118/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 119,Loss: -2.346,Avg.Loss: -1.984,LR: 2.44E-04]Training epoch 51:  78%|███████▊  | 119/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 120,Loss: -2.622,Avg.Loss: -1.989,LR: 2.44E-04]Training epoch 51:  78%|███████▊  | 120/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 120,Loss: -2.622,Avg.Loss: -1.989,LR: 2.44E-04]Training epoch 51:  78%|███████▊  | 120/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 121,Loss: -2.540,Avg.Loss: -1.994,LR: 2.44E-04]Training epoch 51:  79%|███████▉  | 121/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 122,Loss: -2.285,Avg.Loss: -1.996,LR: 2.44E-04]Training epoch 51:  80%|███████▉  | 122/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 123,Loss: -2.344,Avg.Loss: -1.999,LR: 2.44E-04]Training epoch 51:  80%|████████  | 123/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 124,Loss: -2.735,Avg.Loss: -2.005,LR: 2.44E-04]Training epoch 51:  81%|████████  | 124/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 125,Loss: -2.005,Avg.Loss: -2.005,LR: 2.44E-04]Training epoch 51:  82%|████████▏ | 125/153 [00:02<00:00, 53.01it/s, Epoch: 51, Batch: 126,Loss: -2.486,Avg.Loss: -2.009,LR: 2.44E-04]Training epoch 51:  82%|████████▏ | 126/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 126,Loss: -2.486,Avg.Loss: -2.009,LR: 2.44E-04]Training epoch 51:  82%|████████▏ | 126/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 127,Loss: -2.588,Avg.Loss: -2.013,LR: 2.43E-04]Training epoch 51:  83%|████████▎ | 127/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 128,Loss: -2.525,Avg.Loss: -2.017,LR: 2.43E-04]Training epoch 51:  84%|████████▎ | 128/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 129,Loss: -2.219,Avg.Loss: -2.019,LR: 2.43E-04]Training epoch 51:  84%|████████▍ | 129/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 130,Loss: -2.378,Avg.Loss: -2.022,LR: 2.43E-04]Training epoch 51:  85%|████████▍ | 130/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 131,Loss: -2.210,Avg.Loss: -2.023,LR: 2.43E-04]Training epoch 51:  86%|████████▌ | 131/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 132,Loss: -2.678,Avg.Loss: -2.028,LR: 2.43E-04]Training epoch 51:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 51, Batch: 132,Loss: -2.678,Avg.Loss: -2.028,LR: 2.43E-04]Training epoch 51:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 51, Batch: 133,Loss: -2.482,Avg.Loss: -2.031,LR: 2.43E-04]Training epoch 51:  87%|████████▋ | 133/153 [00:02<00:00, 53.28it/s, Epoch: 51, Batch: 134,Loss: -2.402,Avg.Loss: -2.034,LR: 2.43E-04]Training epoch 51:  88%|████████▊ | 134/153 [00:02<00:00, 53.28it/s, Epoch: 51, Batch: 135,Loss: -2.254,Avg.Loss: -2.036,LR: 2.43E-04]Training epoch 51:  88%|████████▊ | 135/153 [00:02<00:00, 53.28it/s, Epoch: 51, Batch: 136,Loss: -2.087,Avg.Loss: -2.036,LR: 2.43E-04]Training epoch 51:  89%|████████▉ | 136/153 [00:02<00:00, 53.28it/s, Epoch: 51, Batch: 137,Loss: -2.020,Avg.Loss: -2.036,LR: 2.43E-04]Training epoch 51:  90%|████████▉ | 137/153 [00:02<00:00, 53.28it/s, Epoch: 51, Batch: 138,Loss: -2.492,Avg.Loss: -2.039,LR: 2.43E-04]Training epoch 51:  90%|█████████ | 138/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 138,Loss: -2.492,Avg.Loss: -2.039,LR: 2.43E-04]Training epoch 51:  90%|█████████ | 138/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 139,Loss: -2.646,Avg.Loss: -2.044,LR: 2.43E-04]Training epoch 51:  91%|█████████ | 139/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 140,Loss: -2.614,Avg.Loss: -2.048,LR: 2.43E-04]Training epoch 51:  92%|█████████▏| 140/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 141,Loss: -2.557,Avg.Loss: -2.051,LR: 2.43E-04]Training epoch 51:  92%|█████████▏| 141/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 142,Loss: -2.542,Avg.Loss: -2.055,LR: 2.43E-04]Training epoch 51:  93%|█████████▎| 142/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 143,Loss: -2.811,Avg.Loss: -2.060,LR: 2.43E-04]Training epoch 51:  93%|█████████▎| 143/153 [00:02<00:00, 53.11it/s, Epoch: 51, Batch: 144,Loss: -2.620,Avg.Loss: -2.064,LR: 2.43E-04]Training epoch 51:  94%|█████████▍| 144/153 [00:02<00:00, 53.19it/s, Epoch: 51, Batch: 144,Loss: -2.620,Avg.Loss: -2.064,LR: 2.43E-04]Training epoch 51:  94%|█████████▍| 144/153 [00:02<00:00, 53.19it/s, Epoch: 51, Batch: 145,Loss: -2.927,Avg.Loss: -2.070,LR: 2.43E-04]Training epoch 51:  95%|█████████▍| 145/153 [00:02<00:00, 53.19it/s, Epoch: 51, Batch: 146,Loss: -2.520,Avg.Loss: -2.073,LR: 2.43E-04]Training epoch 51:  95%|█████████▌| 146/153 [00:02<00:00, 53.19it/s, Epoch: 51, Batch: 147,Loss: -2.738,Avg.Loss: -2.078,LR: 2.42E-04]Training epoch 51:  96%|█████████▌| 147/153 [00:02<00:00, 53.19it/s, Epoch: 51, Batch: 148,Loss: -2.147,Avg.Loss: -2.078,LR: 2.42E-04]Training epoch 51:  97%|█████████▋| 148/153 [00:02<00:00, 53.19it/s, Epoch: 51, Batch: 149,Loss: -2.242,Avg.Loss: -2.079,LR: 2.42E-04]Training epoch 51:  97%|█████████▋| 149/153 [00:02<00:00, 53.19it/s, Epoch: 51, Batch: 150,Loss: -2.306,Avg.Loss: -2.081,LR: 2.42E-04]Training epoch 51:  98%|█████████▊| 150/153 [00:02<00:00, 53.17it/s, Epoch: 51, Batch: 150,Loss: -2.306,Avg.Loss: -2.081,LR: 2.42E-04]Training epoch 51:  98%|█████████▊| 150/153 [00:02<00:00, 53.17it/s, Epoch: 51, Batch: 151,Loss: -2.457,Avg.Loss: -2.083,LR: 2.42E-04]Training epoch 51:  99%|█████████▊| 151/153 [00:02<00:00, 53.17it/s, Epoch: 51, Batch: 152,Loss: -1.651,Avg.Loss: -2.080,LR: 2.42E-04]Training epoch 51:  99%|█████████▉| 152/153 [00:02<00:00, 53.17it/s, Epoch: 51, Batch: 153,Loss: -2.198,Avg.Loss: -2.081,LR: 2.42E-04]Training epoch 51: 100%|██████████| 153/153 [00:02<00:00, 52.95it/s, Epoch: 51, Batch: 153,Loss: -2.198,Avg.Loss: -2.081,LR: 2.42E-04]
Training epoch 52:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 52:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 52, Batch: 1,Loss: -1.107,Avg.Loss: -1.107,LR: 2.42E-04]Training epoch 52:   1%|          | 1/153 [00:00<00:06, 25.24it/s, Epoch: 52, Batch: 2,Loss: -1.138,Avg.Loss: -1.122,LR: 2.42E-04]Training epoch 52:   1%|▏         | 2/153 [00:00<00:04, 37.50it/s, Epoch: 52, Batch: 3,Loss: -1.152,Avg.Loss: -1.132,LR: 2.42E-04]Training epoch 52:   2%|▏         | 3/153 [00:00<00:03, 44.87it/s, Epoch: 52, Batch: 4,Loss: -2.013,Avg.Loss: -1.352,LR: 2.42E-04]Training epoch 52:   3%|▎         | 4/153 [00:00<00:03, 46.75it/s, Epoch: 52, Batch: 5,Loss: -1.730,Avg.Loss: -1.428,LR: 2.42E-04]Training epoch 52:   3%|▎         | 5/153 [00:00<00:03, 48.38it/s, Epoch: 52, Batch: 6,Loss: -2.183,Avg.Loss: -1.554,LR: 2.42E-04]Training epoch 52:   4%|▍         | 6/153 [00:00<00:02, 57.95it/s, Epoch: 52, Batch: 6,Loss: -2.183,Avg.Loss: -1.554,LR: 2.42E-04]Training epoch 52:   4%|▍         | 6/153 [00:00<00:02, 57.95it/s, Epoch: 52, Batch: 7,Loss: -2.009,Avg.Loss: -1.619,LR: 2.42E-04]Training epoch 52:   5%|▍         | 7/153 [00:00<00:02, 57.95it/s, Epoch: 52, Batch: 8,Loss: -2.429,Avg.Loss: -1.720,LR: 2.42E-04]Training epoch 52:   5%|▌         | 8/153 [00:00<00:02, 57.95it/s, Epoch: 52, Batch: 9,Loss: -2.099,Avg.Loss: -1.762,LR: 2.42E-04]Training epoch 52:   6%|▌         | 9/153 [00:00<00:02, 57.95it/s, Epoch: 52, Batch: 10,Loss: -2.410,Avg.Loss: -1.827,LR: 2.42E-04]Training epoch 52:   7%|▋         | 10/153 [00:00<00:02, 57.95it/s, Epoch: 52, Batch: 11,Loss: -1.794,Avg.Loss: -1.824,LR: 2.42E-04]Training epoch 52:   7%|▋         | 11/153 [00:00<00:02, 57.95it/s, Epoch: 52, Batch: 12,Loss: -2.690,Avg.Loss: -1.896,LR: 2.42E-04]Training epoch 52:   8%|▊         | 12/153 [00:00<00:02, 54.42it/s, Epoch: 52, Batch: 12,Loss: -2.690,Avg.Loss: -1.896,LR: 2.42E-04]Training epoch 52:   8%|▊         | 12/153 [00:00<00:02, 54.42it/s, Epoch: 52, Batch: 13,Loss: -1.883,Avg.Loss: -1.895,LR: 2.41E-04]Training epoch 52:   8%|▊         | 13/153 [00:00<00:02, 54.42it/s, Epoch: 52, Batch: 14,Loss: -2.401,Avg.Loss: -1.931,LR: 2.41E-04]Training epoch 52:   9%|▉         | 14/153 [00:00<00:02, 54.42it/s, Epoch: 52, Batch: 15,Loss: -2.563,Avg.Loss: -1.973,LR: 2.41E-04]Training epoch 52:  10%|▉         | 15/153 [00:00<00:02, 54.42it/s, Epoch: 52, Batch: 16,Loss: -2.090,Avg.Loss: -1.981,LR: 2.41E-04]Training epoch 52:  10%|█         | 16/153 [00:00<00:02, 54.42it/s, Epoch: 52, Batch: 17,Loss: -1.894,Avg.Loss: -1.976,LR: 2.41E-04]Training epoch 52:  11%|█         | 17/153 [00:00<00:02, 54.42it/s, Epoch: 52, Batch: 18,Loss: -2.188,Avg.Loss: -1.987,LR: 2.41E-04]Training epoch 52:  12%|█▏        | 18/153 [00:00<00:02, 53.56it/s, Epoch: 52, Batch: 18,Loss: -2.188,Avg.Loss: -1.987,LR: 2.41E-04]Training epoch 52:  12%|█▏        | 18/153 [00:00<00:02, 53.56it/s, Epoch: 52, Batch: 19,Loss: -2.032,Avg.Loss: -1.990,LR: 2.41E-04]Training epoch 52:  12%|█▏        | 19/153 [00:00<00:02, 53.56it/s, Epoch: 52, Batch: 20,Loss: -2.179,Avg.Loss: -1.999,LR: 2.41E-04]Training epoch 52:  13%|█▎        | 20/153 [00:00<00:02, 53.56it/s, Epoch: 52, Batch: 21,Loss: -1.699,Avg.Loss: -1.985,LR: 2.41E-04]Training epoch 52:  14%|█▎        | 21/153 [00:00<00:02, 53.56it/s, Epoch: 52, Batch: 22,Loss: -1.877,Avg.Loss: -1.980,LR: 2.41E-04]Training epoch 52:  14%|█▍        | 22/153 [00:00<00:02, 53.56it/s, Epoch: 52, Batch: 23,Loss: -2.670,Avg.Loss: -2.010,LR: 2.41E-04]Training epoch 52:  15%|█▌        | 23/153 [00:00<00:02, 53.56it/s, Epoch: 52, Batch: 24,Loss: -2.403,Avg.Loss: -2.026,LR: 2.41E-04]Training epoch 52:  16%|█▌        | 24/153 [00:00<00:02, 52.72it/s, Epoch: 52, Batch: 24,Loss: -2.403,Avg.Loss: -2.026,LR: 2.41E-04]Training epoch 52:  16%|█▌        | 24/153 [00:00<00:02, 52.72it/s, Epoch: 52, Batch: 25,Loss: -2.064,Avg.Loss: -2.028,LR: 2.41E-04]Training epoch 52:  16%|█▋        | 25/153 [00:00<00:02, 52.72it/s, Epoch: 52, Batch: 26,Loss: -1.991,Avg.Loss: -2.026,LR: 2.41E-04]Training epoch 52:  17%|█▋        | 26/153 [00:00<00:02, 52.72it/s, Epoch: 52, Batch: 27,Loss: -2.570,Avg.Loss: -2.047,LR: 2.41E-04]Training epoch 52:  18%|█▊        | 27/153 [00:00<00:02, 52.72it/s, Epoch: 52, Batch: 28,Loss: -1.842,Avg.Loss: -2.039,LR: 2.41E-04]Training epoch 52:  18%|█▊        | 28/153 [00:00<00:02, 52.72it/s, Epoch: 52, Batch: 29,Loss: -2.466,Avg.Loss: -2.054,LR: 2.41E-04]Training epoch 52:  19%|█▉        | 29/153 [00:00<00:02, 52.72it/s, Epoch: 52, Batch: 30,Loss: -2.563,Avg.Loss: -2.071,LR: 2.41E-04]Training epoch 52:  20%|█▉        | 30/153 [00:00<00:02, 52.51it/s, Epoch: 52, Batch: 30,Loss: -2.563,Avg.Loss: -2.071,LR: 2.41E-04]Training epoch 52:  20%|█▉        | 30/153 [00:00<00:02, 52.51it/s, Epoch: 52, Batch: 31,Loss: -2.357,Avg.Loss: -2.080,LR: 2.41E-04]Training epoch 52:  20%|██        | 31/153 [00:00<00:02, 52.51it/s, Epoch: 52, Batch: 32,Loss: -2.211,Avg.Loss: -2.084,LR: 2.41E-04]Training epoch 52:  21%|██        | 32/153 [00:00<00:02, 52.51it/s, Epoch: 52, Batch: 33,Loss: -1.960,Avg.Loss: -2.080,LR: 2.40E-04]Training epoch 52:  22%|██▏       | 33/153 [00:00<00:02, 52.51it/s, Epoch: 52, Batch: 34,Loss: -2.403,Avg.Loss: -2.090,LR: 2.40E-04]Training epoch 52:  22%|██▏       | 34/153 [00:00<00:02, 52.51it/s, Epoch: 52, Batch: 35,Loss: -2.363,Avg.Loss: -2.098,LR: 2.40E-04]Training epoch 52:  23%|██▎       | 35/153 [00:00<00:02, 52.51it/s, Epoch: 52, Batch: 36,Loss: -1.980,Avg.Loss: -2.094,LR: 2.40E-04]Training epoch 52:  24%|██▎       | 36/153 [00:00<00:02, 53.05it/s, Epoch: 52, Batch: 36,Loss: -1.980,Avg.Loss: -2.094,LR: 2.40E-04]Training epoch 52:  24%|██▎       | 36/153 [00:00<00:02, 53.05it/s, Epoch: 52, Batch: 37,Loss: -3.057,Avg.Loss: -2.120,LR: 2.40E-04]Training epoch 52:  24%|██▍       | 37/153 [00:00<00:02, 53.05it/s, Epoch: 52, Batch: 38,Loss: -2.956,Avg.Loss: -2.142,LR: 2.40E-04]Training epoch 52:  25%|██▍       | 38/153 [00:00<00:02, 53.05it/s, Epoch: 52, Batch: 39,Loss: -2.880,Avg.Loss: -2.161,LR: 2.40E-04]Training epoch 52:  25%|██▌       | 39/153 [00:00<00:02, 53.05it/s, Epoch: 52, Batch: 40,Loss: -2.905,Avg.Loss: -2.180,LR: 2.40E-04]Training epoch 52:  26%|██▌       | 40/153 [00:00<00:02, 53.05it/s, Epoch: 52, Batch: 41,Loss: -2.156,Avg.Loss: -2.179,LR: 2.40E-04]Training epoch 52:  27%|██▋       | 41/153 [00:00<00:02, 53.05it/s, Epoch: 52, Batch: 42,Loss: -2.657,Avg.Loss: -2.191,LR: 2.40E-04]Training epoch 52:  27%|██▋       | 42/153 [00:00<00:02, 52.94it/s, Epoch: 52, Batch: 42,Loss: -2.657,Avg.Loss: -2.191,LR: 2.40E-04]Training epoch 52:  27%|██▋       | 42/153 [00:00<00:02, 52.94it/s, Epoch: 52, Batch: 43,Loss: -1.965,Avg.Loss: -2.186,LR: 2.40E-04]Training epoch 52:  28%|██▊       | 43/153 [00:00<00:02, 52.94it/s, Epoch: 52, Batch: 44,Loss: -1.591,Avg.Loss: -2.172,LR: 2.40E-04]Training epoch 52:  29%|██▉       | 44/153 [00:00<00:02, 52.94it/s, Epoch: 52, Batch: 45,Loss: -1.616,Avg.Loss: -2.160,LR: 2.40E-04]Training epoch 52:  29%|██▉       | 45/153 [00:00<00:02, 52.94it/s, Epoch: 52, Batch: 46,Loss: -1.843,Avg.Loss: -2.153,LR: 2.40E-04]Training epoch 52:  30%|███       | 46/153 [00:00<00:02, 52.94it/s, Epoch: 52, Batch: 47,Loss: -2.532,Avg.Loss: -2.161,LR: 2.40E-04]Training epoch 52:  31%|███       | 47/153 [00:00<00:02, 52.94it/s, Epoch: 52, Batch: 48,Loss: -2.162,Avg.Loss: -2.161,LR: 2.40E-04]Training epoch 52:  31%|███▏      | 48/153 [00:00<00:01, 52.97it/s, Epoch: 52, Batch: 48,Loss: -2.162,Avg.Loss: -2.161,LR: 2.40E-04]Training epoch 52:  31%|███▏      | 48/153 [00:00<00:01, 52.97it/s, Epoch: 52, Batch: 49,Loss: -1.953,Avg.Loss: -2.157,LR: 2.40E-04]Training epoch 52:  32%|███▏      | 49/153 [00:00<00:01, 52.97it/s, Epoch: 52, Batch: 50,Loss: -1.407,Avg.Loss: -2.142,LR: 2.40E-04]Training epoch 52:  33%|███▎      | 50/153 [00:00<00:01, 52.97it/s, Epoch: 52, Batch: 51,Loss: -2.386,Avg.Loss: -2.146,LR: 2.40E-04]Training epoch 52:  33%|███▎      | 51/153 [00:00<00:01, 52.97it/s, Epoch: 52, Batch: 52,Loss: -1.730,Avg.Loss: -2.138,LR: 2.39E-04]Training epoch 52:  34%|███▍      | 52/153 [00:00<00:01, 52.97it/s, Epoch: 52, Batch: 53,Loss: -1.855,Avg.Loss: -2.133,LR: 2.39E-04]Training epoch 52:  35%|███▍      | 53/153 [00:01<00:01, 52.97it/s, Epoch: 52, Batch: 54,Loss: -2.040,Avg.Loss: -2.131,LR: 2.39E-04]Training epoch 52:  35%|███▌      | 54/153 [00:01<00:01, 52.89it/s, Epoch: 52, Batch: 54,Loss: -2.040,Avg.Loss: -2.131,LR: 2.39E-04]Training epoch 52:  35%|███▌      | 54/153 [00:01<00:01, 52.89it/s, Epoch: 52, Batch: 55,Loss: -1.951,Avg.Loss: -2.128,LR: 2.39E-04]Training epoch 52:  36%|███▌      | 55/153 [00:01<00:01, 52.89it/s, Epoch: 52, Batch: 56,Loss: -2.216,Avg.Loss: -2.130,LR: 2.39E-04]Training epoch 52:  37%|███▋      | 56/153 [00:01<00:01, 52.89it/s, Epoch: 52, Batch: 57,Loss: -2.464,Avg.Loss: -2.136,LR: 2.39E-04]Training epoch 52:  37%|███▋      | 57/153 [00:01<00:01, 52.89it/s, Epoch: 52, Batch: 58,Loss: -2.309,Avg.Loss: -2.138,LR: 2.39E-04]Training epoch 52:  38%|███▊      | 58/153 [00:01<00:01, 52.89it/s, Epoch: 52, Batch: 59,Loss: -2.355,Avg.Loss: -2.142,LR: 2.39E-04]Training epoch 52:  39%|███▊      | 59/153 [00:01<00:01, 52.89it/s, Epoch: 52, Batch: 60,Loss: -2.107,Avg.Loss: -2.142,LR: 2.39E-04]Training epoch 52:  39%|███▉      | 60/153 [00:01<00:01, 53.01it/s, Epoch: 52, Batch: 60,Loss: -2.107,Avg.Loss: -2.142,LR: 2.39E-04]Training epoch 52:  39%|███▉      | 60/153 [00:01<00:01, 53.01it/s, Epoch: 52, Batch: 61,Loss: -1.140,Avg.Loss: -2.125,LR: 2.39E-04]Training epoch 52:  40%|███▉      | 61/153 [00:01<00:01, 53.01it/s, Epoch: 52, Batch: 62,Loss: -1.611,Avg.Loss: -2.117,LR: 2.39E-04]Training epoch 52:  41%|████      | 62/153 [00:01<00:01, 53.01it/s, Epoch: 52, Batch: 63,Loss: -1.530,Avg.Loss: -2.108,LR: 2.39E-04]Training epoch 52:  41%|████      | 63/153 [00:01<00:01, 53.01it/s, Epoch: 52, Batch: 64,Loss: -1.754,Avg.Loss: -2.102,LR: 2.39E-04]Training epoch 52:  42%|████▏     | 64/153 [00:01<00:01, 53.01it/s, Epoch: 52, Batch: 65,Loss: -1.393,Avg.Loss: -2.091,LR: 2.39E-04]Training epoch 52:  42%|████▏     | 65/153 [00:01<00:01, 53.01it/s, Epoch: 52, Batch: 66,Loss: -1.790,Avg.Loss: -2.087,LR: 2.39E-04]Training epoch 52:  43%|████▎     | 66/153 [00:01<00:01, 52.57it/s, Epoch: 52, Batch: 66,Loss: -1.790,Avg.Loss: -2.087,LR: 2.39E-04]Training epoch 52:  43%|████▎     | 66/153 [00:01<00:01, 52.57it/s, Epoch: 52, Batch: 67,Loss: -2.795,Avg.Loss: -2.097,LR: 2.39E-04]Training epoch 52:  44%|████▍     | 67/153 [00:01<00:01, 52.57it/s, Epoch: 52, Batch: 68,Loss: -1.978,Avg.Loss: -2.095,LR: 2.39E-04]Training epoch 52:  44%|████▍     | 68/153 [00:01<00:01, 52.57it/s, Epoch: 52, Batch: 69,Loss: -0.392,Avg.Loss: -2.071,LR: 2.39E-04]Training epoch 52:  45%|████▌     | 69/153 [00:01<00:01, 52.57it/s, Epoch: 52, Batch: 70,Loss: -1.120,Avg.Loss: -2.057,LR: 2.39E-04]Training epoch 52:  46%|████▌     | 70/153 [00:01<00:01, 52.57it/s, Epoch: 52, Batch: 71,Loss: -2.172,Avg.Loss: -2.059,LR: 2.39E-04]Training epoch 52:  46%|████▋     | 71/153 [00:01<00:01, 52.57it/s, Epoch: 52, Batch: 72,Loss: -2.179,Avg.Loss: -2.060,LR: 2.38E-04]Training epoch 52:  47%|████▋     | 72/153 [00:01<00:01, 52.74it/s, Epoch: 52, Batch: 72,Loss: -2.179,Avg.Loss: -2.060,LR: 2.38E-04]Training epoch 52:  47%|████▋     | 72/153 [00:01<00:01, 52.74it/s, Epoch: 52, Batch: 73,Loss: -2.061,Avg.Loss: -2.060,LR: 2.38E-04]Training epoch 52:  48%|████▊     | 73/153 [00:01<00:01, 52.74it/s, Epoch: 52, Batch: 74,Loss: -1.829,Avg.Loss: -2.057,LR: 2.38E-04]Training epoch 52:  48%|████▊     | 74/153 [00:01<00:01, 52.74it/s, Epoch: 52, Batch: 75,Loss: -2.389,Avg.Loss: -2.062,LR: 2.38E-04]Training epoch 52:  49%|████▉     | 75/153 [00:01<00:01, 52.74it/s, Epoch: 52, Batch: 76,Loss: -2.108,Avg.Loss: -2.062,LR: 2.38E-04]Training epoch 52:  50%|████▉     | 76/153 [00:01<00:01, 52.74it/s, Epoch: 52, Batch: 77,Loss: -1.984,Avg.Loss: -2.061,LR: 2.38E-04]Training epoch 52:  50%|█████     | 77/153 [00:01<00:01, 52.74it/s, Epoch: 52, Batch: 78,Loss: -2.415,Avg.Loss: -2.066,LR: 2.38E-04]Training epoch 52:  51%|█████     | 78/153 [00:01<00:01, 52.99it/s, Epoch: 52, Batch: 78,Loss: -2.415,Avg.Loss: -2.066,LR: 2.38E-04]Training epoch 52:  51%|█████     | 78/153 [00:01<00:01, 52.99it/s, Epoch: 52, Batch: 79,Loss: -2.398,Avg.Loss: -2.070,LR: 2.38E-04]Training epoch 52:  52%|█████▏    | 79/153 [00:01<00:01, 52.99it/s, Epoch: 52, Batch: 80,Loss: -1.974,Avg.Loss: -2.069,LR: 2.38E-04]Training epoch 52:  52%|█████▏    | 80/153 [00:01<00:01, 52.99it/s, Epoch: 52, Batch: 81,Loss: -2.248,Avg.Loss: -2.071,LR: 2.38E-04]Training epoch 52:  53%|█████▎    | 81/153 [00:01<00:01, 52.99it/s, Epoch: 52, Batch: 82,Loss: -2.391,Avg.Loss: -2.075,LR: 2.38E-04]Training epoch 52:  54%|█████▎    | 82/153 [00:01<00:01, 52.99it/s, Epoch: 52, Batch: 83,Loss: -2.111,Avg.Loss: -2.075,LR: 2.38E-04]Training epoch 52:  54%|█████▍    | 83/153 [00:01<00:01, 52.99it/s, Epoch: 52, Batch: 84,Loss: -2.678,Avg.Loss: -2.083,LR: 2.38E-04]Training epoch 52:  55%|█████▍    | 84/153 [00:01<00:01, 53.20it/s, Epoch: 52, Batch: 84,Loss: -2.678,Avg.Loss: -2.083,LR: 2.38E-04]Training epoch 52:  55%|█████▍    | 84/153 [00:01<00:01, 53.20it/s, Epoch: 52, Batch: 85,Loss: -2.653,Avg.Loss: -2.089,LR: 2.38E-04]Training epoch 52:  56%|█████▌    | 85/153 [00:01<00:01, 53.20it/s, Epoch: 52, Batch: 86,Loss: -2.771,Avg.Loss: -2.097,LR: 2.38E-04]Training epoch 52:  56%|█████▌    | 86/153 [00:01<00:01, 53.20it/s, Epoch: 52, Batch: 87,Loss: -2.642,Avg.Loss: -2.103,LR: 2.38E-04]Training epoch 52:  57%|█████▋    | 87/153 [00:01<00:01, 53.20it/s, Epoch: 52, Batch: 88,Loss: -2.839,Avg.Loss: -2.112,LR: 2.38E-04]Training epoch 52:  58%|█████▊    | 88/153 [00:01<00:01, 53.20it/s, Epoch: 52, Batch: 89,Loss: -3.037,Avg.Loss: -2.122,LR: 2.38E-04]Training epoch 52:  58%|█████▊    | 89/153 [00:01<00:01, 53.20it/s, Epoch: 52, Batch: 90,Loss: -2.593,Avg.Loss: -2.127,LR: 2.38E-04]Training epoch 52:  59%|█████▉    | 90/153 [00:01<00:01, 53.12it/s, Epoch: 52, Batch: 90,Loss: -2.593,Avg.Loss: -2.127,LR: 2.38E-04]Training epoch 52:  59%|█████▉    | 90/153 [00:01<00:01, 53.12it/s, Epoch: 52, Batch: 91,Loss: -2.015,Avg.Loss: -2.126,LR: 2.37E-04]Training epoch 52:  59%|█████▉    | 91/153 [00:01<00:01, 53.12it/s, Epoch: 52, Batch: 92,Loss: -2.047,Avg.Loss: -2.125,LR: 2.37E-04]Training epoch 52:  60%|██████    | 92/153 [00:01<00:01, 53.12it/s, Epoch: 52, Batch: 93,Loss: -2.265,Avg.Loss: -2.127,LR: 2.37E-04]Training epoch 52:  61%|██████    | 93/153 [00:01<00:01, 53.12it/s, Epoch: 52, Batch: 94,Loss: -2.261,Avg.Loss: -2.128,LR: 2.37E-04]Training epoch 52:  61%|██████▏   | 94/153 [00:01<00:01, 53.12it/s, Epoch: 52, Batch: 95,Loss: -2.457,Avg.Loss: -2.132,LR: 2.37E-04]Training epoch 52:  62%|██████▏   | 95/153 [00:01<00:01, 53.12it/s, Epoch: 52, Batch: 96,Loss: -2.312,Avg.Loss: -2.134,LR: 2.37E-04]Training epoch 52:  63%|██████▎   | 96/153 [00:01<00:01, 53.16it/s, Epoch: 52, Batch: 96,Loss: -2.312,Avg.Loss: -2.134,LR: 2.37E-04]Training epoch 52:  63%|██████▎   | 96/153 [00:01<00:01, 53.16it/s, Epoch: 52, Batch: 97,Loss: -2.836,Avg.Loss: -2.141,LR: 2.37E-04]Training epoch 52:  63%|██████▎   | 97/153 [00:01<00:01, 53.16it/s, Epoch: 52, Batch: 98,Loss: -2.713,Avg.Loss: -2.147,LR: 2.37E-04]Training epoch 52:  64%|██████▍   | 98/153 [00:01<00:01, 53.16it/s, Epoch: 52, Batch: 99,Loss: -2.528,Avg.Loss: -2.151,LR: 2.37E-04]Training epoch 52:  65%|██████▍   | 99/153 [00:01<00:01, 53.16it/s, Epoch: 52, Batch: 100,Loss: -2.218,Avg.Loss: -2.151,LR: 2.37E-04]Training epoch 52:  65%|██████▌   | 100/153 [00:01<00:00, 53.16it/s, Epoch: 52, Batch: 101,Loss: -2.624,Avg.Loss: -2.156,LR: 2.37E-04]Training epoch 52:  66%|██████▌   | 101/153 [00:01<00:00, 53.16it/s, Epoch: 52, Batch: 102,Loss: -2.638,Avg.Loss: -2.161,LR: 2.37E-04]Training epoch 52:  67%|██████▋   | 102/153 [00:01<00:00, 53.12it/s, Epoch: 52, Batch: 102,Loss: -2.638,Avg.Loss: -2.161,LR: 2.37E-04]Training epoch 52:  67%|██████▋   | 102/153 [00:01<00:00, 53.12it/s, Epoch: 52, Batch: 103,Loss: -2.684,Avg.Loss: -2.166,LR: 2.37E-04]Training epoch 52:  67%|██████▋   | 103/153 [00:01<00:00, 53.12it/s, Epoch: 52, Batch: 104,Loss: -2.651,Avg.Loss: -2.170,LR: 2.37E-04]Training epoch 52:  68%|██████▊   | 104/153 [00:01<00:00, 53.12it/s, Epoch: 52, Batch: 105,Loss: -2.954,Avg.Loss: -2.178,LR: 2.37E-04]Training epoch 52:  69%|██████▊   | 105/153 [00:01<00:00, 53.12it/s, Epoch: 52, Batch: 106,Loss: -2.813,Avg.Loss: -2.184,LR: 2.37E-04]Training epoch 52:  69%|██████▉   | 106/153 [00:02<00:00, 53.12it/s, Epoch: 52, Batch: 107,Loss: -2.241,Avg.Loss: -2.184,LR: 2.37E-04]Training epoch 52:  70%|██████▉   | 107/153 [00:02<00:00, 53.12it/s, Epoch: 52, Batch: 108,Loss: -2.482,Avg.Loss: -2.187,LR: 2.37E-04]Training epoch 52:  71%|███████   | 108/153 [00:02<00:00, 53.00it/s, Epoch: 52, Batch: 108,Loss: -2.482,Avg.Loss: -2.187,LR: 2.37E-04]Training epoch 52:  71%|███████   | 108/153 [00:02<00:00, 53.00it/s, Epoch: 52, Batch: 109,Loss: -2.431,Avg.Loss: -2.189,LR: 2.37E-04]Training epoch 52:  71%|███████   | 109/153 [00:02<00:00, 53.00it/s, Epoch: 52, Batch: 110,Loss: -2.490,Avg.Loss: -2.192,LR: 2.37E-04]Training epoch 52:  72%|███████▏  | 110/153 [00:02<00:00, 53.00it/s, Epoch: 52, Batch: 111,Loss: -2.445,Avg.Loss: -2.194,LR: 2.36E-04]Training epoch 52:  73%|███████▎  | 111/153 [00:02<00:00, 53.00it/s, Epoch: 52, Batch: 112,Loss: -2.652,Avg.Loss: -2.198,LR: 2.36E-04]Training epoch 52:  73%|███████▎  | 112/153 [00:02<00:00, 53.00it/s, Epoch: 52, Batch: 113,Loss: -2.572,Avg.Loss: -2.202,LR: 2.36E-04]Training epoch 52:  74%|███████▍  | 113/153 [00:02<00:00, 53.00it/s, Epoch: 52, Batch: 114,Loss: -1.716,Avg.Loss: -2.197,LR: 2.36E-04]Training epoch 52:  75%|███████▍  | 114/153 [00:02<00:00, 53.05it/s, Epoch: 52, Batch: 114,Loss: -1.716,Avg.Loss: -2.197,LR: 2.36E-04]Training epoch 52:  75%|███████▍  | 114/153 [00:02<00:00, 53.05it/s, Epoch: 52, Batch: 115,Loss: -2.039,Avg.Loss: -2.196,LR: 2.36E-04]Training epoch 52:  75%|███████▌  | 115/153 [00:02<00:00, 53.05it/s, Epoch: 52, Batch: 116,Loss: -2.135,Avg.Loss: -2.196,LR: 2.36E-04]Training epoch 52:  76%|███████▌  | 116/153 [00:02<00:00, 53.05it/s, Epoch: 52, Batch: 117,Loss: -2.607,Avg.Loss: -2.199,LR: 2.36E-04]Training epoch 52:  76%|███████▋  | 117/153 [00:02<00:00, 53.05it/s, Epoch: 52, Batch: 118,Loss: -2.058,Avg.Loss: -2.198,LR: 2.36E-04]Training epoch 52:  77%|███████▋  | 118/153 [00:02<00:00, 53.05it/s, Epoch: 52, Batch: 119,Loss: -1.652,Avg.Loss: -2.193,LR: 2.36E-04]Training epoch 52:  78%|███████▊  | 119/153 [00:02<00:00, 53.05it/s, Epoch: 52, Batch: 120,Loss: -1.992,Avg.Loss: -2.192,LR: 2.36E-04]Training epoch 52:  78%|███████▊  | 120/153 [00:02<00:00, 52.96it/s, Epoch: 52, Batch: 120,Loss: -1.992,Avg.Loss: -2.192,LR: 2.36E-04]Training epoch 52:  78%|███████▊  | 120/153 [00:02<00:00, 52.96it/s, Epoch: 52, Batch: 121,Loss: -2.783,Avg.Loss: -2.197,LR: 2.36E-04]Training epoch 52:  79%|███████▉  | 121/153 [00:02<00:00, 52.96it/s, Epoch: 52, Batch: 122,Loss: -2.721,Avg.Loss: -2.201,LR: 2.36E-04]Training epoch 52:  80%|███████▉  | 122/153 [00:02<00:00, 52.96it/s, Epoch: 52, Batch: 123,Loss: -1.769,Avg.Loss: -2.197,LR: 2.36E-04]Training epoch 52:  80%|████████  | 123/153 [00:02<00:00, 52.96it/s, Epoch: 52, Batch: 124,Loss: -1.902,Avg.Loss: -2.195,LR: 2.36E-04]Training epoch 52:  81%|████████  | 124/153 [00:02<00:00, 52.96it/s, Epoch: 52, Batch: 125,Loss: -2.192,Avg.Loss: -2.195,LR: 2.36E-04]Training epoch 52:  82%|████████▏ | 125/153 [00:02<00:00, 52.96it/s, Epoch: 52, Batch: 126,Loss: -2.489,Avg.Loss: -2.197,LR: 2.36E-04]Training epoch 52:  82%|████████▏ | 126/153 [00:02<00:00, 53.11it/s, Epoch: 52, Batch: 126,Loss: -2.489,Avg.Loss: -2.197,LR: 2.36E-04]Training epoch 52:  82%|████████▏ | 126/153 [00:02<00:00, 53.11it/s, Epoch: 52, Batch: 127,Loss: -2.592,Avg.Loss: -2.200,LR: 2.36E-04]Training epoch 52:  83%|████████▎ | 127/153 [00:02<00:00, 53.11it/s, Epoch: 52, Batch: 128,Loss: -2.019,Avg.Loss: -2.199,LR: 2.36E-04]Training epoch 52:  84%|████████▎ | 128/153 [00:02<00:00, 53.11it/s, Epoch: 52, Batch: 129,Loss: -2.437,Avg.Loss: -2.201,LR: 2.36E-04]Training epoch 52:  84%|████████▍ | 129/153 [00:02<00:00, 53.11it/s, Epoch: 52, Batch: 130,Loss: -2.066,Avg.Loss: -2.200,LR: 2.35E-04]Training epoch 52:  85%|████████▍ | 130/153 [00:02<00:00, 53.11it/s, Epoch: 52, Batch: 131,Loss: -1.859,Avg.Loss: -2.197,LR: 2.35E-04]Training epoch 52:  86%|████████▌ | 131/153 [00:02<00:00, 53.11it/s, Epoch: 52, Batch: 132,Loss: -2.494,Avg.Loss: -2.199,LR: 2.35E-04]Training epoch 52:  86%|████████▋ | 132/153 [00:02<00:00, 53.19it/s, Epoch: 52, Batch: 132,Loss: -2.494,Avg.Loss: -2.199,LR: 2.35E-04]Training epoch 52:  86%|████████▋ | 132/153 [00:02<00:00, 53.19it/s, Epoch: 52, Batch: 133,Loss: -2.594,Avg.Loss: -2.202,LR: 2.35E-04]Training epoch 52:  87%|████████▋ | 133/153 [00:02<00:00, 53.19it/s, Epoch: 52, Batch: 134,Loss: -2.816,Avg.Loss: -2.207,LR: 2.35E-04]Training epoch 52:  88%|████████▊ | 134/153 [00:02<00:00, 53.19it/s, Epoch: 52, Batch: 135,Loss: -2.833,Avg.Loss: -2.212,LR: 2.35E-04]Training epoch 52:  88%|████████▊ | 135/153 [00:02<00:00, 53.19it/s, Epoch: 52, Batch: 136,Loss: -2.782,Avg.Loss: -2.216,LR: 2.35E-04]Training epoch 52:  89%|████████▉ | 136/153 [00:02<00:00, 53.19it/s, Epoch: 52, Batch: 137,Loss: -2.338,Avg.Loss: -2.217,LR: 2.35E-04]Training epoch 52:  90%|████████▉ | 137/153 [00:02<00:00, 53.19it/s, Epoch: 52, Batch: 138,Loss: -2.418,Avg.Loss: -2.218,LR: 2.35E-04]Training epoch 52:  90%|█████████ | 138/153 [00:02<00:00, 53.29it/s, Epoch: 52, Batch: 138,Loss: -2.418,Avg.Loss: -2.218,LR: 2.35E-04]Training epoch 52:  90%|█████████ | 138/153 [00:02<00:00, 53.29it/s, Epoch: 52, Batch: 139,Loss: -2.845,Avg.Loss: -2.223,LR: 2.35E-04]Training epoch 52:  91%|█████████ | 139/153 [00:02<00:00, 53.29it/s, Epoch: 52, Batch: 140,Loss: -2.809,Avg.Loss: -2.227,LR: 2.35E-04]Training epoch 52:  92%|█████████▏| 140/153 [00:02<00:00, 53.29it/s, Epoch: 52, Batch: 141,Loss: -2.548,Avg.Loss: -2.229,LR: 2.35E-04]Training epoch 52:  92%|█████████▏| 141/153 [00:02<00:00, 53.29it/s, Epoch: 52, Batch: 142,Loss: -2.406,Avg.Loss: -2.230,LR: 2.35E-04]Training epoch 52:  93%|█████████▎| 142/153 [00:02<00:00, 53.29it/s, Epoch: 52, Batch: 143,Loss: -2.756,Avg.Loss: -2.234,LR: 2.35E-04]Training epoch 52:  93%|█████████▎| 143/153 [00:02<00:00, 53.29it/s, Epoch: 52, Batch: 144,Loss: -2.532,Avg.Loss: -2.236,LR: 2.35E-04]Training epoch 52:  94%|█████████▍| 144/153 [00:02<00:00, 53.36it/s, Epoch: 52, Batch: 144,Loss: -2.532,Avg.Loss: -2.236,LR: 2.35E-04]Training epoch 52:  94%|█████████▍| 144/153 [00:02<00:00, 53.36it/s, Epoch: 52, Batch: 145,Loss: -2.596,Avg.Loss: -2.239,LR: 2.35E-04]Training epoch 52:  95%|█████████▍| 145/153 [00:02<00:00, 53.36it/s, Epoch: 52, Batch: 146,Loss: -2.162,Avg.Loss: -2.238,LR: 2.35E-04]Training epoch 52:  95%|█████████▌| 146/153 [00:02<00:00, 53.36it/s, Epoch: 52, Batch: 147,Loss: -2.234,Avg.Loss: -2.238,LR: 2.35E-04]Training epoch 52:  96%|█████████▌| 147/153 [00:02<00:00, 53.36it/s, Epoch: 52, Batch: 148,Loss: -2.298,Avg.Loss: -2.238,LR: 2.35E-04]Training epoch 52:  97%|█████████▋| 148/153 [00:02<00:00, 53.36it/s, Epoch: 52, Batch: 149,Loss: -2.649,Avg.Loss: -2.241,LR: 2.35E-04]Training epoch 52:  97%|█████████▋| 149/153 [00:02<00:00, 53.36it/s, Epoch: 52, Batch: 150,Loss: -2.005,Avg.Loss: -2.240,LR: 2.34E-04]Training epoch 52:  98%|█████████▊| 150/153 [00:02<00:00, 53.32it/s, Epoch: 52, Batch: 150,Loss: -2.005,Avg.Loss: -2.240,LR: 2.34E-04]Training epoch 52:  98%|█████████▊| 150/153 [00:02<00:00, 53.32it/s, Epoch: 52, Batch: 151,Loss: -2.036,Avg.Loss: -2.238,LR: 2.34E-04]Training epoch 52:  99%|█████████▊| 151/153 [00:02<00:00, 53.32it/s, Epoch: 52, Batch: 152,Loss: -2.134,Avg.Loss: -2.238,LR: 2.34E-04]Training epoch 52:  99%|█████████▉| 152/153 [00:02<00:00, 53.32it/s, Epoch: 52, Batch: 153,Loss: -2.207,Avg.Loss: -2.237,LR: 2.34E-04]Training epoch 52: 100%|██████████| 153/153 [00:02<00:00, 53.07it/s, Epoch: 52, Batch: 153,Loss: -2.207,Avg.Loss: -2.237,LR: 2.34E-04]
Training epoch 53:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 53:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 53, Batch: 1,Loss: -2.711,Avg.Loss: -2.711,LR: 2.34E-04]Training epoch 53:   1%|          | 1/153 [00:00<00:06, 23.63it/s, Epoch: 53, Batch: 2,Loss: -2.339,Avg.Loss: -2.525,LR: 2.34E-04]Training epoch 53:   1%|▏         | 2/153 [00:00<00:04, 33.64it/s, Epoch: 53, Batch: 3,Loss: -1.472,Avg.Loss: -2.174,LR: 2.34E-04]Training epoch 53:   2%|▏         | 3/153 [00:00<00:03, 38.34it/s, Epoch: 53, Batch: 4,Loss: -1.592,Avg.Loss: -2.028,LR: 2.34E-04]Training epoch 53:   3%|▎         | 4/153 [00:00<00:03, 41.06it/s, Epoch: 53, Batch: 5,Loss: -2.124,Avg.Loss: -2.048,LR: 2.34E-04]Training epoch 53:   3%|▎         | 5/153 [00:00<00:03, 42.88it/s, Epoch: 53, Batch: 6,Loss: -2.860,Avg.Loss: -2.183,LR: 2.34E-04]Training epoch 53:   4%|▍         | 6/153 [00:00<00:02, 51.37it/s, Epoch: 53, Batch: 6,Loss: -2.860,Avg.Loss: -2.183,LR: 2.34E-04]Training epoch 53:   4%|▍         | 6/153 [00:00<00:02, 51.37it/s, Epoch: 53, Batch: 7,Loss: -1.956,Avg.Loss: -2.151,LR: 2.34E-04]Training epoch 53:   5%|▍         | 7/153 [00:00<00:02, 51.37it/s, Epoch: 53, Batch: 8,Loss: -1.988,Avg.Loss: -2.130,LR: 2.34E-04]Training epoch 53:   5%|▌         | 8/153 [00:00<00:02, 51.37it/s, Epoch: 53, Batch: 9,Loss: -2.321,Avg.Loss: -2.152,LR: 2.34E-04]Training epoch 53:   6%|▌         | 9/153 [00:00<00:02, 51.37it/s, Epoch: 53, Batch: 10,Loss: -1.728,Avg.Loss: -2.109,LR: 2.34E-04]Training epoch 53:   7%|▋         | 10/153 [00:00<00:02, 51.37it/s, Epoch: 53, Batch: 11,Loss: -2.076,Avg.Loss: -2.106,LR: 2.34E-04]Training epoch 53:   7%|▋         | 11/153 [00:00<00:02, 51.37it/s, Epoch: 53, Batch: 12,Loss: -2.818,Avg.Loss: -2.165,LR: 2.34E-04]Training epoch 53:   8%|▊         | 12/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 12,Loss: -2.818,Avg.Loss: -2.165,LR: 2.34E-04]Training epoch 53:   8%|▊         | 12/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 13,Loss: -1.863,Avg.Loss: -2.142,LR: 2.34E-04]Training epoch 53:   8%|▊         | 13/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 14,Loss: -1.718,Avg.Loss: -2.112,LR: 2.34E-04]Training epoch 53:   9%|▉         | 14/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 15,Loss: -1.323,Avg.Loss: -2.059,LR: 2.34E-04]Training epoch 53:  10%|▉         | 15/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 16,Loss: -1.902,Avg.Loss: -2.049,LR: 2.33E-04]Training epoch 53:  10%|█         | 16/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 17,Loss: -2.662,Avg.Loss: -2.086,LR: 2.33E-04]Training epoch 53:  11%|█         | 17/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 18,Loss: -2.613,Avg.Loss: -2.115,LR: 2.33E-04]Training epoch 53:  12%|█▏        | 18/153 [00:00<00:02, 52.27it/s, Epoch: 53, Batch: 18,Loss: -2.613,Avg.Loss: -2.115,LR: 2.33E-04]Training epoch 53:  12%|█▏        | 18/153 [00:00<00:02, 52.27it/s, Epoch: 53, Batch: 19,Loss: -2.426,Avg.Loss: -2.131,LR: 2.33E-04]Training epoch 53:  12%|█▏        | 19/153 [00:00<00:02, 52.27it/s, Epoch: 53, Batch: 20,Loss: -2.404,Avg.Loss: -2.145,LR: 2.33E-04]Training epoch 53:  13%|█▎        | 20/153 [00:00<00:02, 52.27it/s, Epoch: 53, Batch: 21,Loss: -1.982,Avg.Loss: -2.137,LR: 2.33E-04]Training epoch 53:  14%|█▎        | 21/153 [00:00<00:02, 52.27it/s, Epoch: 53, Batch: 22,Loss: -2.922,Avg.Loss: -2.173,LR: 2.33E-04]Training epoch 53:  14%|█▍        | 22/153 [00:00<00:02, 52.27it/s, Epoch: 53, Batch: 23,Loss: -2.981,Avg.Loss: -2.208,LR: 2.33E-04]Training epoch 53:  15%|█▌        | 23/153 [00:00<00:02, 52.27it/s, Epoch: 53, Batch: 24,Loss: -2.445,Avg.Loss: -2.218,LR: 2.33E-04]Training epoch 53:  16%|█▌        | 24/153 [00:00<00:02, 51.40it/s, Epoch: 53, Batch: 24,Loss: -2.445,Avg.Loss: -2.218,LR: 2.33E-04]Training epoch 53:  16%|█▌        | 24/153 [00:00<00:02, 51.40it/s, Epoch: 53, Batch: 25,Loss: -2.619,Avg.Loss: -2.234,LR: 2.33E-04]Training epoch 53:  16%|█▋        | 25/153 [00:00<00:02, 51.40it/s, Epoch: 53, Batch: 26,Loss: -2.825,Avg.Loss: -2.257,LR: 2.33E-04]Training epoch 53:  17%|█▋        | 26/153 [00:00<00:02, 51.40it/s, Epoch: 53, Batch: 27,Loss: -2.366,Avg.Loss: -2.261,LR: 2.33E-04]Training epoch 53:  18%|█▊        | 27/153 [00:00<00:02, 51.40it/s, Epoch: 53, Batch: 28,Loss: -2.737,Avg.Loss: -2.278,LR: 2.33E-04]Training epoch 53:  18%|█▊        | 28/153 [00:00<00:02, 51.40it/s, Epoch: 53, Batch: 29,Loss: -2.820,Avg.Loss: -2.296,LR: 2.33E-04]Training epoch 53:  19%|█▉        | 29/153 [00:00<00:02, 51.40it/s, Epoch: 53, Batch: 30,Loss: -2.282,Avg.Loss: -2.296,LR: 2.33E-04]Training epoch 53:  20%|█▉        | 30/153 [00:00<00:02, 51.24it/s, Epoch: 53, Batch: 30,Loss: -2.282,Avg.Loss: -2.296,LR: 2.33E-04]Training epoch 53:  20%|█▉        | 30/153 [00:00<00:02, 51.24it/s, Epoch: 53, Batch: 31,Loss: -2.468,Avg.Loss: -2.301,LR: 2.33E-04]Training epoch 53:  20%|██        | 31/153 [00:00<00:02, 51.24it/s, Epoch: 53, Batch: 32,Loss: -2.356,Avg.Loss: -2.303,LR: 2.33E-04]Training epoch 53:  21%|██        | 32/153 [00:00<00:02, 51.24it/s, Epoch: 53, Batch: 33,Loss: -2.312,Avg.Loss: -2.303,LR: 2.33E-04]Training epoch 53:  22%|██▏       | 33/153 [00:00<00:02, 51.24it/s, Epoch: 53, Batch: 34,Loss: -2.402,Avg.Loss: -2.306,LR: 2.33E-04]Training epoch 53:  22%|██▏       | 34/153 [00:00<00:02, 51.24it/s, Epoch: 53, Batch: 35,Loss: -2.618,Avg.Loss: -2.315,LR: 2.33E-04]Training epoch 53:  23%|██▎       | 35/153 [00:00<00:02, 51.24it/s, Epoch: 53, Batch: 36,Loss: -2.492,Avg.Loss: -2.320,LR: 2.32E-04]Training epoch 53:  24%|██▎       | 36/153 [00:00<00:02, 51.54it/s, Epoch: 53, Batch: 36,Loss: -2.492,Avg.Loss: -2.320,LR: 2.32E-04]Training epoch 53:  24%|██▎       | 36/153 [00:00<00:02, 51.54it/s, Epoch: 53, Batch: 37,Loss: -1.972,Avg.Loss: -2.311,LR: 2.32E-04]Training epoch 53:  24%|██▍       | 37/153 [00:00<00:02, 51.54it/s, Epoch: 53, Batch: 38,Loss: -2.260,Avg.Loss: -2.309,LR: 2.32E-04]Training epoch 53:  25%|██▍       | 38/153 [00:00<00:02, 51.54it/s, Epoch: 53, Batch: 39,Loss: -2.228,Avg.Loss: -2.307,LR: 2.32E-04]Training epoch 53:  25%|██▌       | 39/153 [00:00<00:02, 51.54it/s, Epoch: 53, Batch: 40,Loss: -2.479,Avg.Loss: -2.312,LR: 2.32E-04]Training epoch 53:  26%|██▌       | 40/153 [00:00<00:02, 51.54it/s, Epoch: 53, Batch: 41,Loss: -2.693,Avg.Loss: -2.321,LR: 2.32E-04]Training epoch 53:  27%|██▋       | 41/153 [00:00<00:02, 51.54it/s, Epoch: 53, Batch: 42,Loss: -1.605,Avg.Loss: -2.304,LR: 2.32E-04]Training epoch 53:  27%|██▋       | 42/153 [00:00<00:02, 51.52it/s, Epoch: 53, Batch: 42,Loss: -1.605,Avg.Loss: -2.304,LR: 2.32E-04]Training epoch 53:  27%|██▋       | 42/153 [00:00<00:02, 51.52it/s, Epoch: 53, Batch: 43,Loss: -1.087,Avg.Loss: -2.276,LR: 2.32E-04]Training epoch 53:  28%|██▊       | 43/153 [00:00<00:02, 51.52it/s, Epoch: 53, Batch: 44,Loss: -1.034,Avg.Loss: -2.247,LR: 2.32E-04]Training epoch 53:  29%|██▉       | 44/153 [00:00<00:02, 51.52it/s, Epoch: 53, Batch: 45,Loss: -1.762,Avg.Loss: -2.237,LR: 2.32E-04]Training epoch 53:  29%|██▉       | 45/153 [00:00<00:02, 51.52it/s, Epoch: 53, Batch: 46,Loss: -1.343,Avg.Loss: -2.217,LR: 2.32E-04]Training epoch 53:  30%|███       | 46/153 [00:00<00:02, 51.52it/s, Epoch: 53, Batch: 47,Loss: -0.875,Avg.Loss: -2.189,LR: 2.32E-04]Training epoch 53:  31%|███       | 47/153 [00:00<00:02, 51.52it/s, Epoch: 53, Batch: 48,Loss: -1.256,Avg.Loss: -2.169,LR: 2.32E-04]Training epoch 53:  31%|███▏      | 48/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 48,Loss: -1.256,Avg.Loss: -2.169,LR: 2.32E-04]Training epoch 53:  31%|███▏      | 48/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 49,Loss: -1.838,Avg.Loss: -2.162,LR: 2.32E-04]Training epoch 53:  32%|███▏      | 49/153 [00:00<00:02, 51.94it/s, Epoch: 53, Batch: 50,Loss: -2.407,Avg.Loss: -2.167,LR: 2.32E-04]Training epoch 53:  33%|███▎      | 50/153 [00:00<00:01, 51.94it/s, Epoch: 53, Batch: 51,Loss: -2.336,Avg.Loss: -2.171,LR: 2.32E-04]Training epoch 53:  33%|███▎      | 51/153 [00:01<00:01, 51.94it/s, Epoch: 53, Batch: 52,Loss: -1.651,Avg.Loss: -2.161,LR: 2.32E-04]Training epoch 53:  34%|███▍      | 52/153 [00:01<00:01, 51.94it/s, Epoch: 53, Batch: 53,Loss: -2.363,Avg.Loss: -2.164,LR: 2.32E-04]Training epoch 53:  35%|███▍      | 53/153 [00:01<00:01, 51.94it/s, Epoch: 53, Batch: 54,Loss: -2.411,Avg.Loss: -2.169,LR: 2.32E-04]Training epoch 53:  35%|███▌      | 54/153 [00:01<00:01, 52.30it/s, Epoch: 53, Batch: 54,Loss: -2.411,Avg.Loss: -2.169,LR: 2.32E-04]Training epoch 53:  35%|███▌      | 54/153 [00:01<00:01, 52.30it/s, Epoch: 53, Batch: 55,Loss: -2.670,Avg.Loss: -2.178,LR: 2.31E-04]Training epoch 53:  36%|███▌      | 55/153 [00:01<00:01, 52.30it/s, Epoch: 53, Batch: 56,Loss: -2.159,Avg.Loss: -2.178,LR: 2.31E-04]Training epoch 53:  37%|███▋      | 56/153 [00:01<00:01, 52.30it/s, Epoch: 53, Batch: 57,Loss: -2.043,Avg.Loss: -2.175,LR: 2.31E-04]Training epoch 53:  37%|███▋      | 57/153 [00:01<00:01, 52.30it/s, Epoch: 53, Batch: 58,Loss: -2.397,Avg.Loss: -2.179,LR: 2.31E-04]Training epoch 53:  38%|███▊      | 58/153 [00:01<00:01, 52.30it/s, Epoch: 53, Batch: 59,Loss: -1.450,Avg.Loss: -2.167,LR: 2.31E-04]Training epoch 53:  39%|███▊      | 59/153 [00:01<00:01, 52.30it/s, Epoch: 53, Batch: 60,Loss: -1.446,Avg.Loss: -2.155,LR: 2.31E-04]Training epoch 53:  39%|███▉      | 60/153 [00:01<00:01, 52.56it/s, Epoch: 53, Batch: 60,Loss: -1.446,Avg.Loss: -2.155,LR: 2.31E-04]Training epoch 53:  39%|███▉      | 60/153 [00:01<00:01, 52.56it/s, Epoch: 53, Batch: 61,Loss: -1.925,Avg.Loss: -2.151,LR: 2.31E-04]Training epoch 53:  40%|███▉      | 61/153 [00:01<00:01, 52.56it/s, Epoch: 53, Batch: 62,Loss: -2.585,Avg.Loss: -2.158,LR: 2.31E-04]Training epoch 53:  41%|████      | 62/153 [00:01<00:01, 52.56it/s, Epoch: 53, Batch: 63,Loss: -2.201,Avg.Loss: -2.159,LR: 2.31E-04]Training epoch 53:  41%|████      | 63/153 [00:01<00:01, 52.56it/s, Epoch: 53, Batch: 64,Loss: -1.377,Avg.Loss: -2.147,LR: 2.31E-04]Training epoch 53:  42%|████▏     | 64/153 [00:01<00:01, 52.56it/s, Epoch: 53, Batch: 65,Loss: -1.283,Avg.Loss: -2.133,LR: 2.31E-04]Training epoch 53:  42%|████▏     | 65/153 [00:01<00:01, 52.56it/s, Epoch: 53, Batch: 66,Loss: -2.586,Avg.Loss: -2.140,LR: 2.31E-04]Training epoch 53:  43%|████▎     | 66/153 [00:01<00:01, 52.65it/s, Epoch: 53, Batch: 66,Loss: -2.586,Avg.Loss: -2.140,LR: 2.31E-04]Training epoch 53:  43%|████▎     | 66/153 [00:01<00:01, 52.65it/s, Epoch: 53, Batch: 67,Loss: -2.215,Avg.Loss: -2.141,LR: 2.31E-04]Training epoch 53:  44%|████▍     | 67/153 [00:01<00:01, 52.65it/s, Epoch: 53, Batch: 68,Loss: -0.581,Avg.Loss: -2.118,LR: 2.31E-04]Training epoch 53:  44%|████▍     | 68/153 [00:01<00:01, 52.65it/s, Epoch: 53, Batch: 69,Loss: -0.663,Avg.Loss: -2.097,LR: 2.31E-04]Training epoch 53:  45%|████▌     | 69/153 [00:01<00:01, 52.65it/s, Epoch: 53, Batch: 70,Loss: -1.637,Avg.Loss: -2.091,LR: 2.31E-04]Training epoch 53:  46%|████▌     | 70/153 [00:01<00:01, 52.65it/s, Epoch: 53, Batch: 71,Loss: -2.390,Avg.Loss: -2.095,LR: 2.31E-04]Training epoch 53:  46%|████▋     | 71/153 [00:01<00:01, 52.65it/s, Epoch: 53, Batch: 72,Loss: -1.638,Avg.Loss: -2.088,LR: 2.31E-04]Training epoch 53:  47%|████▋     | 72/153 [00:01<00:01, 52.71it/s, Epoch: 53, Batch: 72,Loss: -1.638,Avg.Loss: -2.088,LR: 2.31E-04]Training epoch 53:  47%|████▋     | 72/153 [00:01<00:01, 52.71it/s, Epoch: 53, Batch: 73,Loss: -1.477,Avg.Loss: -2.080,LR: 2.31E-04]Training epoch 53:  48%|████▊     | 73/153 [00:01<00:01, 52.71it/s, Epoch: 53, Batch: 74,Loss: -2.050,Avg.Loss: -2.080,LR: 2.31E-04]Training epoch 53:  48%|████▊     | 74/153 [00:01<00:01, 52.71it/s, Epoch: 53, Batch: 75,Loss: -1.628,Avg.Loss: -2.074,LR: 2.30E-04]Training epoch 53:  49%|████▉     | 75/153 [00:01<00:01, 52.71it/s, Epoch: 53, Batch: 76,Loss: -1.872,Avg.Loss: -2.071,LR: 2.30E-04]Training epoch 53:  50%|████▉     | 76/153 [00:01<00:01, 52.71it/s, Epoch: 53, Batch: 77,Loss: -1.106,Avg.Loss: -2.058,LR: 2.30E-04]Training epoch 53:  50%|█████     | 77/153 [00:01<00:01, 52.71it/s, Epoch: 53, Batch: 78,Loss: -1.530,Avg.Loss: -2.052,LR: 2.30E-04]Training epoch 53:  51%|█████     | 78/153 [00:01<00:01, 52.64it/s, Epoch: 53, Batch: 78,Loss: -1.530,Avg.Loss: -2.052,LR: 2.30E-04]Training epoch 53:  51%|█████     | 78/153 [00:01<00:01, 52.64it/s, Epoch: 53, Batch: 79,Loss: -2.073,Avg.Loss: -2.052,LR: 2.30E-04]Training epoch 53:  52%|█████▏    | 79/153 [00:01<00:01, 52.64it/s, Epoch: 53, Batch: 80,Loss: -2.246,Avg.Loss: -2.054,LR: 2.30E-04]Training epoch 53:  52%|█████▏    | 80/153 [00:01<00:01, 52.64it/s, Epoch: 53, Batch: 81,Loss: -0.365,Avg.Loss: -2.034,LR: 2.30E-04]Training epoch 53:  53%|█████▎    | 81/153 [00:01<00:01, 52.64it/s, Epoch: 53, Batch: 82,Loss: -0.824,Avg.Loss: -2.019,LR: 2.30E-04]Training epoch 53:  54%|█████▎    | 82/153 [00:01<00:01, 52.64it/s, Epoch: 53, Batch: 83,Loss: -1.627,Avg.Loss: -2.014,LR: 2.30E-04]Training epoch 53:  54%|█████▍    | 83/153 [00:01<00:01, 52.64it/s, Epoch: 53, Batch: 84,Loss: -1.265,Avg.Loss: -2.005,LR: 2.30E-04]Training epoch 53:  55%|█████▍    | 84/153 [00:01<00:01, 52.72it/s, Epoch: 53, Batch: 84,Loss: -1.265,Avg.Loss: -2.005,LR: 2.30E-04]Training epoch 53:  55%|█████▍    | 84/153 [00:01<00:01, 52.72it/s, Epoch: 53, Batch: 85,Loss: -0.296,Avg.Loss: -1.985,LR: 2.30E-04]Training epoch 53:  56%|█████▌    | 85/153 [00:01<00:01, 52.72it/s, Epoch: 53, Batch: 86,Loss: -1.788,Avg.Loss: -1.983,LR: 2.30E-04]Training epoch 53:  56%|█████▌    | 86/153 [00:01<00:01, 52.72it/s, Epoch: 53, Batch: 87,Loss: -1.907,Avg.Loss: -1.982,LR: 2.30E-04]Training epoch 53:  57%|█████▋    | 87/153 [00:01<00:01, 52.72it/s, Epoch: 53, Batch: 88,Loss: -2.888,Avg.Loss: -1.992,LR: 2.30E-04]Training epoch 53:  58%|█████▊    | 88/153 [00:01<00:01, 52.72it/s, Epoch: 53, Batch: 89,Loss: -2.071,Avg.Loss: -1.993,LR: 2.30E-04]Training epoch 53:  58%|█████▊    | 89/153 [00:01<00:01, 52.72it/s, Epoch: 53, Batch: 90,Loss: -1.188,Avg.Loss: -1.984,LR: 2.30E-04]Training epoch 53:  59%|█████▉    | 90/153 [00:01<00:01, 52.83it/s, Epoch: 53, Batch: 90,Loss: -1.188,Avg.Loss: -1.984,LR: 2.30E-04]Training epoch 53:  59%|█████▉    | 90/153 [00:01<00:01, 52.83it/s, Epoch: 53, Batch: 91,Loss: -1.456,Avg.Loss: -1.978,LR: 2.30E-04]Training epoch 53:  59%|█████▉    | 91/153 [00:01<00:01, 52.83it/s, Epoch: 53, Batch: 92,Loss: -1.469,Avg.Loss: -1.973,LR: 2.30E-04]Training epoch 53:  60%|██████    | 92/153 [00:01<00:01, 52.83it/s, Epoch: 53, Batch: 93,Loss: -2.285,Avg.Loss: -1.976,LR: 2.30E-04]Training epoch 53:  61%|██████    | 93/153 [00:01<00:01, 52.83it/s, Epoch: 53, Batch: 94,Loss: -2.102,Avg.Loss: -1.977,LR: 2.29E-04]Training epoch 53:  61%|██████▏   | 94/153 [00:01<00:01, 52.83it/s, Epoch: 53, Batch: 95,Loss: -2.200,Avg.Loss: -1.980,LR: 2.29E-04]Training epoch 53:  62%|██████▏   | 95/153 [00:01<00:01, 52.83it/s, Epoch: 53, Batch: 96,Loss: -2.591,Avg.Loss: -1.986,LR: 2.29E-04]Training epoch 53:  63%|██████▎   | 96/153 [00:01<00:01, 52.82it/s, Epoch: 53, Batch: 96,Loss: -2.591,Avg.Loss: -1.986,LR: 2.29E-04]Training epoch 53:  63%|██████▎   | 96/153 [00:01<00:01, 52.82it/s, Epoch: 53, Batch: 97,Loss: -2.599,Avg.Loss: -1.992,LR: 2.29E-04]Training epoch 53:  63%|██████▎   | 97/153 [00:01<00:01, 52.82it/s, Epoch: 53, Batch: 98,Loss: -2.272,Avg.Loss: -1.995,LR: 2.29E-04]Training epoch 53:  64%|██████▍   | 98/153 [00:01<00:01, 52.82it/s, Epoch: 53, Batch: 99,Loss: -2.234,Avg.Loss: -1.998,LR: 2.29E-04]Training epoch 53:  65%|██████▍   | 99/153 [00:01<00:01, 52.82it/s, Epoch: 53, Batch: 100,Loss: -2.493,Avg.Loss: -2.003,LR: 2.29E-04]Training epoch 53:  65%|██████▌   | 100/153 [00:01<00:01, 52.82it/s, Epoch: 53, Batch: 101,Loss: -2.836,Avg.Loss: -2.011,LR: 2.29E-04]Training epoch 53:  66%|██████▌   | 101/153 [00:01<00:00, 52.82it/s, Epoch: 53, Batch: 102,Loss: -3.129,Avg.Loss: -2.022,LR: 2.29E-04]Training epoch 53:  67%|██████▋   | 102/153 [00:01<00:00, 52.74it/s, Epoch: 53, Batch: 102,Loss: -3.129,Avg.Loss: -2.022,LR: 2.29E-04]Training epoch 53:  67%|██████▋   | 102/153 [00:01<00:00, 52.74it/s, Epoch: 53, Batch: 103,Loss: -2.762,Avg.Loss: -2.029,LR: 2.29E-04]Training epoch 53:  67%|██████▋   | 103/153 [00:01<00:00, 52.74it/s, Epoch: 53, Batch: 104,Loss: -2.830,Avg.Loss: -2.037,LR: 2.29E-04]Training epoch 53:  68%|██████▊   | 104/153 [00:02<00:00, 52.74it/s, Epoch: 53, Batch: 105,Loss: -2.164,Avg.Loss: -2.038,LR: 2.29E-04]Training epoch 53:  69%|██████▊   | 105/153 [00:02<00:00, 52.74it/s, Epoch: 53, Batch: 106,Loss: -3.038,Avg.Loss: -2.047,LR: 2.29E-04]Training epoch 53:  69%|██████▉   | 106/153 [00:02<00:00, 52.74it/s, Epoch: 53, Batch: 107,Loss: -2.888,Avg.Loss: -2.055,LR: 2.29E-04]Training epoch 53:  70%|██████▉   | 107/153 [00:02<00:00, 52.74it/s, Epoch: 53, Batch: 108,Loss: -2.582,Avg.Loss: -2.060,LR: 2.29E-04]Training epoch 53:  71%|███████   | 108/153 [00:02<00:00, 52.84it/s, Epoch: 53, Batch: 108,Loss: -2.582,Avg.Loss: -2.060,LR: 2.29E-04]Training epoch 53:  71%|███████   | 108/153 [00:02<00:00, 52.84it/s, Epoch: 53, Batch: 109,Loss: -2.761,Avg.Loss: -2.067,LR: 2.29E-04]Training epoch 53:  71%|███████   | 109/153 [00:02<00:00, 52.84it/s, Epoch: 53, Batch: 110,Loss: -2.505,Avg.Loss: -2.071,LR: 2.29E-04]Training epoch 53:  72%|███████▏  | 110/153 [00:02<00:00, 52.84it/s, Epoch: 53, Batch: 111,Loss: -2.758,Avg.Loss: -2.077,LR: 2.29E-04]Training epoch 53:  73%|███████▎  | 111/153 [00:02<00:00, 52.84it/s, Epoch: 53, Batch: 112,Loss: -1.910,Avg.Loss: -2.075,LR: 2.29E-04]Training epoch 53:  73%|███████▎  | 112/153 [00:02<00:00, 52.84it/s, Epoch: 53, Batch: 113,Loss: -2.181,Avg.Loss: -2.076,LR: 2.29E-04]Training epoch 53:  74%|███████▍  | 113/153 [00:02<00:00, 52.84it/s, Epoch: 53, Batch: 114,Loss: -2.707,Avg.Loss: -2.082,LR: 2.28E-04]Training epoch 53:  75%|███████▍  | 114/153 [00:02<00:00, 52.69it/s, Epoch: 53, Batch: 114,Loss: -2.707,Avg.Loss: -2.082,LR: 2.28E-04]Training epoch 53:  75%|███████▍  | 114/153 [00:02<00:00, 52.69it/s, Epoch: 53, Batch: 115,Loss: -2.830,Avg.Loss: -2.088,LR: 2.28E-04]Training epoch 53:  75%|███████▌  | 115/153 [00:02<00:00, 52.69it/s, Epoch: 53, Batch: 116,Loss: -2.828,Avg.Loss: -2.095,LR: 2.28E-04]Training epoch 53:  76%|███████▌  | 116/153 [00:02<00:00, 52.69it/s, Epoch: 53, Batch: 117,Loss: -2.841,Avg.Loss: -2.101,LR: 2.28E-04]Training epoch 53:  76%|███████▋  | 117/153 [00:02<00:00, 52.69it/s, Epoch: 53, Batch: 118,Loss: -2.896,Avg.Loss: -2.108,LR: 2.28E-04]Training epoch 53:  77%|███████▋  | 118/153 [00:02<00:00, 52.69it/s, Epoch: 53, Batch: 119,Loss: -2.655,Avg.Loss: -2.112,LR: 2.28E-04]Training epoch 53:  78%|███████▊  | 119/153 [00:02<00:00, 52.69it/s, Epoch: 53, Batch: 120,Loss: -2.685,Avg.Loss: -2.117,LR: 2.28E-04]Training epoch 53:  78%|███████▊  | 120/153 [00:02<00:00, 52.73it/s, Epoch: 53, Batch: 120,Loss: -2.685,Avg.Loss: -2.117,LR: 2.28E-04]Training epoch 53:  78%|███████▊  | 120/153 [00:02<00:00, 52.73it/s, Epoch: 53, Batch: 121,Loss: -2.609,Avg.Loss: -2.121,LR: 2.28E-04]Training epoch 53:  79%|███████▉  | 121/153 [00:02<00:00, 52.73it/s, Epoch: 53, Batch: 122,Loss: -2.243,Avg.Loss: -2.122,LR: 2.28E-04]Training epoch 53:  80%|███████▉  | 122/153 [00:02<00:00, 52.73it/s, Epoch: 53, Batch: 123,Loss: -1.763,Avg.Loss: -2.119,LR: 2.28E-04]Training epoch 53:  80%|████████  | 123/153 [00:02<00:00, 52.73it/s, Epoch: 53, Batch: 124,Loss: -2.709,Avg.Loss: -2.124,LR: 2.28E-04]Training epoch 53:  81%|████████  | 124/153 [00:02<00:00, 52.73it/s, Epoch: 53, Batch: 125,Loss: -2.299,Avg.Loss: -2.125,LR: 2.28E-04]Training epoch 53:  82%|████████▏ | 125/153 [00:02<00:00, 52.73it/s, Epoch: 53, Batch: 126,Loss: -1.911,Avg.Loss: -2.124,LR: 2.28E-04]Training epoch 53:  82%|████████▏ | 126/153 [00:02<00:00, 53.01it/s, Epoch: 53, Batch: 126,Loss: -1.911,Avg.Loss: -2.124,LR: 2.28E-04]Training epoch 53:  82%|████████▏ | 126/153 [00:02<00:00, 53.01it/s, Epoch: 53, Batch: 127,Loss: -2.363,Avg.Loss: -2.126,LR: 2.28E-04]Training epoch 53:  83%|████████▎ | 127/153 [00:02<00:00, 53.01it/s, Epoch: 53, Batch: 128,Loss: -2.982,Avg.Loss: -2.132,LR: 2.28E-04]Training epoch 53:  84%|████████▎ | 128/153 [00:02<00:00, 53.01it/s, Epoch: 53, Batch: 129,Loss: -2.455,Avg.Loss: -2.135,LR: 2.28E-04]Training epoch 53:  84%|████████▍ | 129/153 [00:02<00:00, 53.01it/s, Epoch: 53, Batch: 130,Loss: -2.289,Avg.Loss: -2.136,LR: 2.28E-04]Training epoch 53:  85%|████████▍ | 130/153 [00:02<00:00, 53.01it/s, Epoch: 53, Batch: 131,Loss: -2.643,Avg.Loss: -2.140,LR: 2.28E-04]Training epoch 53:  86%|████████▌ | 131/153 [00:02<00:00, 53.01it/s, Epoch: 53, Batch: 132,Loss: -1.954,Avg.Loss: -2.138,LR: 2.28E-04]Training epoch 53:  86%|████████▋ | 132/153 [00:02<00:00, 53.08it/s, Epoch: 53, Batch: 132,Loss: -1.954,Avg.Loss: -2.138,LR: 2.28E-04]Training epoch 53:  86%|████████▋ | 132/153 [00:02<00:00, 53.08it/s, Epoch: 53, Batch: 133,Loss: -1.728,Avg.Loss: -2.135,LR: 2.27E-04]Training epoch 53:  87%|████████▋ | 133/153 [00:02<00:00, 53.08it/s, Epoch: 53, Batch: 134,Loss: -2.294,Avg.Loss: -2.137,LR: 2.27E-04]Training epoch 53:  88%|████████▊ | 134/153 [00:02<00:00, 53.08it/s, Epoch: 53, Batch: 135,Loss: -2.532,Avg.Loss: -2.139,LR: 2.27E-04]Training epoch 53:  88%|████████▊ | 135/153 [00:02<00:00, 53.08it/s, Epoch: 53, Batch: 136,Loss: -2.072,Avg.Loss: -2.139,LR: 2.27E-04]Training epoch 53:  89%|████████▉ | 136/153 [00:02<00:00, 53.08it/s, Epoch: 53, Batch: 137,Loss: -2.510,Avg.Loss: -2.142,LR: 2.27E-04]Training epoch 53:  90%|████████▉ | 137/153 [00:02<00:00, 53.08it/s, Epoch: 53, Batch: 138,Loss: -2.282,Avg.Loss: -2.143,LR: 2.27E-04]Training epoch 53:  90%|█████████ | 138/153 [00:02<00:00, 52.89it/s, Epoch: 53, Batch: 138,Loss: -2.282,Avg.Loss: -2.143,LR: 2.27E-04]Training epoch 53:  90%|█████████ | 138/153 [00:02<00:00, 52.89it/s, Epoch: 53, Batch: 139,Loss: -2.622,Avg.Loss: -2.146,LR: 2.27E-04]Training epoch 53:  91%|█████████ | 139/153 [00:02<00:00, 52.89it/s, Epoch: 53, Batch: 140,Loss: -2.002,Avg.Loss: -2.145,LR: 2.27E-04]Training epoch 53:  92%|█████████▏| 140/153 [00:02<00:00, 52.89it/s, Epoch: 53, Batch: 141,Loss: -1.927,Avg.Loss: -2.144,LR: 2.27E-04]Training epoch 53:  92%|█████████▏| 141/153 [00:02<00:00, 52.89it/s, Epoch: 53, Batch: 142,Loss: -1.446,Avg.Loss: -2.139,LR: 2.27E-04]Training epoch 53:  93%|█████████▎| 142/153 [00:02<00:00, 52.89it/s, Epoch: 53, Batch: 143,Loss: -1.762,Avg.Loss: -2.136,LR: 2.27E-04]Training epoch 53:  93%|█████████▎| 143/153 [00:02<00:00, 52.89it/s, Epoch: 53, Batch: 144,Loss: -2.849,Avg.Loss: -2.141,LR: 2.27E-04]Training epoch 53:  94%|█████████▍| 144/153 [00:02<00:00, 52.92it/s, Epoch: 53, Batch: 144,Loss: -2.849,Avg.Loss: -2.141,LR: 2.27E-04]Training epoch 53:  94%|█████████▍| 144/153 [00:02<00:00, 52.92it/s, Epoch: 53, Batch: 145,Loss: -1.983,Avg.Loss: -2.140,LR: 2.27E-04]Training epoch 53:  95%|█████████▍| 145/153 [00:02<00:00, 52.92it/s, Epoch: 53, Batch: 146,Loss: -2.343,Avg.Loss: -2.141,LR: 2.27E-04]Training epoch 53:  95%|█████████▌| 146/153 [00:02<00:00, 52.92it/s, Epoch: 53, Batch: 147,Loss: -2.742,Avg.Loss: -2.145,LR: 2.27E-04]Training epoch 53:  96%|█████████▌| 147/153 [00:02<00:00, 52.92it/s, Epoch: 53, Batch: 148,Loss: -2.792,Avg.Loss: -2.150,LR: 2.27E-04]Training epoch 53:  97%|█████████▋| 148/153 [00:02<00:00, 52.92it/s, Epoch: 53, Batch: 149,Loss: -2.583,Avg.Loss: -2.153,LR: 2.27E-04]Training epoch 53:  97%|█████████▋| 149/153 [00:02<00:00, 52.92it/s, Epoch: 53, Batch: 150,Loss: -2.361,Avg.Loss: -2.154,LR: 2.27E-04]Training epoch 53:  98%|█████████▊| 150/153 [00:02<00:00, 52.99it/s, Epoch: 53, Batch: 150,Loss: -2.361,Avg.Loss: -2.154,LR: 2.27E-04]Training epoch 53:  98%|█████████▊| 150/153 [00:02<00:00, 52.99it/s, Epoch: 53, Batch: 151,Loss: -2.833,Avg.Loss: -2.159,LR: 2.27E-04]Training epoch 53:  99%|█████████▊| 151/153 [00:02<00:00, 52.99it/s, Epoch: 53, Batch: 152,Loss: -2.156,Avg.Loss: -2.158,LR: 2.27E-04]Training epoch 53:  99%|█████████▉| 152/153 [00:02<00:00, 52.99it/s, Epoch: 53, Batch: 153,Loss: -2.563,Avg.Loss: -2.161,LR: 2.26E-04]Training epoch 53: 100%|██████████| 153/153 [00:02<00:00, 52.46it/s, Epoch: 53, Batch: 153,Loss: -2.563,Avg.Loss: -2.161,LR: 2.26E-04]
Training epoch 54:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 54:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 54, Batch: 1,Loss: -2.423,Avg.Loss: -2.423,LR: 2.26E-04]Training epoch 54:   1%|          | 1/153 [00:00<00:06, 24.54it/s, Epoch: 54, Batch: 2,Loss: -1.997,Avg.Loss: -2.210,LR: 2.26E-04]Training epoch 54:   1%|▏         | 2/153 [00:00<00:04, 34.05it/s, Epoch: 54, Batch: 3,Loss: -2.547,Avg.Loss: -2.322,LR: 2.26E-04]Training epoch 54:   2%|▏         | 3/153 [00:00<00:03, 38.79it/s, Epoch: 54, Batch: 4,Loss: -1.726,Avg.Loss: -2.173,LR: 2.26E-04]Training epoch 54:   3%|▎         | 4/153 [00:00<00:03, 41.37it/s, Epoch: 54, Batch: 5,Loss: -1.660,Avg.Loss: -2.071,LR: 2.26E-04]Training epoch 54:   3%|▎         | 5/153 [00:00<00:03, 43.09it/s, Epoch: 54, Batch: 6,Loss: -2.896,Avg.Loss: -2.208,LR: 2.26E-04]Training epoch 54:   4%|▍         | 6/153 [00:00<00:02, 51.63it/s, Epoch: 54, Batch: 6,Loss: -2.896,Avg.Loss: -2.208,LR: 2.26E-04]Training epoch 54:   4%|▍         | 6/153 [00:00<00:02, 51.63it/s, Epoch: 54, Batch: 7,Loss: -2.421,Avg.Loss: -2.239,LR: 2.26E-04]Training epoch 54:   5%|▍         | 7/153 [00:00<00:02, 51.63it/s, Epoch: 54, Batch: 8,Loss: -2.598,Avg.Loss: -2.283,LR: 2.26E-04]Training epoch 54:   5%|▌         | 8/153 [00:00<00:02, 51.63it/s, Epoch: 54, Batch: 9,Loss: -2.738,Avg.Loss: -2.334,LR: 2.26E-04]Training epoch 54:   6%|▌         | 9/153 [00:00<00:02, 51.63it/s, Epoch: 54, Batch: 10,Loss: -2.321,Avg.Loss: -2.333,LR: 2.26E-04]Training epoch 54:   7%|▋         | 10/153 [00:00<00:02, 51.63it/s, Epoch: 54, Batch: 11,Loss: -2.076,Avg.Loss: -2.309,LR: 2.26E-04]Training epoch 54:   7%|▋         | 11/153 [00:00<00:02, 51.63it/s, Epoch: 54, Batch: 12,Loss: -2.806,Avg.Loss: -2.351,LR: 2.26E-04]Training epoch 54:   8%|▊         | 12/153 [00:00<00:02, 52.52it/s, Epoch: 54, Batch: 12,Loss: -2.806,Avg.Loss: -2.351,LR: 2.26E-04]Training epoch 54:   8%|▊         | 12/153 [00:00<00:02, 52.52it/s, Epoch: 54, Batch: 13,Loss: -2.837,Avg.Loss: -2.388,LR: 2.26E-04]Training epoch 54:   8%|▊         | 13/153 [00:00<00:02, 52.52it/s, Epoch: 54, Batch: 14,Loss: -2.540,Avg.Loss: -2.399,LR: 2.26E-04]Training epoch 54:   9%|▉         | 14/153 [00:00<00:02, 52.52it/s, Epoch: 54, Batch: 15,Loss: -2.273,Avg.Loss: -2.391,LR: 2.26E-04]Training epoch 54:  10%|▉         | 15/153 [00:00<00:02, 52.52it/s, Epoch: 54, Batch: 16,Loss: -2.473,Avg.Loss: -2.396,LR: 2.26E-04]Training epoch 54:  10%|█         | 16/153 [00:00<00:02, 52.52it/s, Epoch: 54, Batch: 17,Loss: -2.508,Avg.Loss: -2.402,LR: 2.26E-04]Training epoch 54:  11%|█         | 17/153 [00:00<00:02, 52.52it/s, Epoch: 54, Batch: 18,Loss: -2.173,Avg.Loss: -2.390,LR: 2.26E-04]Training epoch 54:  12%|█▏        | 18/153 [00:00<00:02, 52.62it/s, Epoch: 54, Batch: 18,Loss: -2.173,Avg.Loss: -2.390,LR: 2.26E-04]Training epoch 54:  12%|█▏        | 18/153 [00:00<00:02, 52.62it/s, Epoch: 54, Batch: 19,Loss: -2.328,Avg.Loss: -2.386,LR: 2.26E-04]Training epoch 54:  12%|█▏        | 19/153 [00:00<00:02, 52.62it/s, Epoch: 54, Batch: 20,Loss: -2.425,Avg.Loss: -2.388,LR: 2.25E-04]Training epoch 54:  13%|█▎        | 20/153 [00:00<00:02, 52.62it/s, Epoch: 54, Batch: 21,Loss: -2.044,Avg.Loss: -2.372,LR: 2.25E-04]Training epoch 54:  14%|█▎        | 21/153 [00:00<00:02, 52.62it/s, Epoch: 54, Batch: 22,Loss: -2.212,Avg.Loss: -2.365,LR: 2.25E-04]Training epoch 54:  14%|█▍        | 22/153 [00:00<00:02, 52.62it/s, Epoch: 54, Batch: 23,Loss: -2.400,Avg.Loss: -2.366,LR: 2.25E-04]Training epoch 54:  15%|█▌        | 23/153 [00:00<00:02, 52.62it/s, Epoch: 54, Batch: 24,Loss: -2.082,Avg.Loss: -2.354,LR: 2.25E-04]Training epoch 54:  16%|█▌        | 24/153 [00:00<00:02, 51.57it/s, Epoch: 54, Batch: 24,Loss: -2.082,Avg.Loss: -2.354,LR: 2.25E-04]Training epoch 54:  16%|█▌        | 24/153 [00:00<00:02, 51.57it/s, Epoch: 54, Batch: 25,Loss: -1.062,Avg.Loss: -2.303,LR: 2.25E-04]Training epoch 54:  16%|█▋        | 25/153 [00:00<00:02, 51.57it/s, Epoch: 54, Batch: 26,Loss: -1.083,Avg.Loss: -2.256,LR: 2.25E-04]Training epoch 54:  17%|█▋        | 26/153 [00:00<00:02, 51.57it/s, Epoch: 54, Batch: 27,Loss: -2.430,Avg.Loss: -2.262,LR: 2.25E-04]Training epoch 54:  18%|█▊        | 27/153 [00:00<00:02, 51.57it/s, Epoch: 54, Batch: 28,Loss: -2.281,Avg.Loss: -2.263,LR: 2.25E-04]Training epoch 54:  18%|█▊        | 28/153 [00:00<00:02, 51.57it/s, Epoch: 54, Batch: 29,Loss: -1.431,Avg.Loss: -2.234,LR: 2.25E-04]Training epoch 54:  19%|█▉        | 29/153 [00:00<00:02, 51.57it/s, Epoch: 54, Batch: 30,Loss: -1.995,Avg.Loss: -2.226,LR: 2.25E-04]Training epoch 54:  20%|█▉        | 30/153 [00:00<00:02, 51.98it/s, Epoch: 54, Batch: 30,Loss: -1.995,Avg.Loss: -2.226,LR: 2.25E-04]Training epoch 54:  20%|█▉        | 30/153 [00:00<00:02, 51.98it/s, Epoch: 54, Batch: 31,Loss: -2.881,Avg.Loss: -2.247,LR: 2.25E-04]Training epoch 54:  20%|██        | 31/153 [00:00<00:02, 51.98it/s, Epoch: 54, Batch: 32,Loss: -2.260,Avg.Loss: -2.248,LR: 2.25E-04]Training epoch 54:  21%|██        | 32/153 [00:00<00:02, 51.98it/s, Epoch: 54, Batch: 33,Loss: -1.030,Avg.Loss: -2.211,LR: 2.25E-04]Training epoch 54:  22%|██▏       | 33/153 [00:00<00:02, 51.98it/s, Epoch: 54, Batch: 34,Loss: -1.723,Avg.Loss: -2.196,LR: 2.25E-04]Training epoch 54:  22%|██▏       | 34/153 [00:00<00:02, 51.98it/s, Epoch: 54, Batch: 35,Loss: -2.306,Avg.Loss: -2.200,LR: 2.25E-04]Training epoch 54:  23%|██▎       | 35/153 [00:00<00:02, 51.98it/s, Epoch: 54, Batch: 36,Loss: -1.601,Avg.Loss: -2.183,LR: 2.25E-04]Training epoch 54:  24%|██▎       | 36/153 [00:00<00:02, 52.43it/s, Epoch: 54, Batch: 36,Loss: -1.601,Avg.Loss: -2.183,LR: 2.25E-04]Training epoch 54:  24%|██▎       | 36/153 [00:00<00:02, 52.43it/s, Epoch: 54, Batch: 37,Loss: -2.074,Avg.Loss: -2.180,LR: 2.25E-04]Training epoch 54:  24%|██▍       | 37/153 [00:00<00:02, 52.43it/s, Epoch: 54, Batch: 38,Loss: -2.195,Avg.Loss: -2.180,LR: 2.25E-04]Training epoch 54:  25%|██▍       | 38/153 [00:00<00:02, 52.43it/s, Epoch: 54, Batch: 39,Loss: -2.593,Avg.Loss: -2.191,LR: 2.24E-04]Training epoch 54:  25%|██▌       | 39/153 [00:00<00:02, 52.43it/s, Epoch: 54, Batch: 40,Loss: -2.643,Avg.Loss: -2.202,LR: 2.24E-04]Training epoch 54:  26%|██▌       | 40/153 [00:00<00:02, 52.43it/s, Epoch: 54, Batch: 41,Loss: -2.380,Avg.Loss: -2.207,LR: 2.24E-04]Training epoch 54:  27%|██▋       | 41/153 [00:00<00:02, 52.43it/s, Epoch: 54, Batch: 42,Loss: -2.447,Avg.Loss: -2.212,LR: 2.24E-04]Training epoch 54:  27%|██▋       | 42/153 [00:00<00:02, 52.57it/s, Epoch: 54, Batch: 42,Loss: -2.447,Avg.Loss: -2.212,LR: 2.24E-04]Training epoch 54:  27%|██▋       | 42/153 [00:00<00:02, 52.57it/s, Epoch: 54, Batch: 43,Loss: -2.280,Avg.Loss: -2.214,LR: 2.24E-04]Training epoch 54:  28%|██▊       | 43/153 [00:00<00:02, 52.57it/s, Epoch: 54, Batch: 44,Loss: -1.909,Avg.Loss: -2.207,LR: 2.24E-04]Training epoch 54:  29%|██▉       | 44/153 [00:00<00:02, 52.57it/s, Epoch: 54, Batch: 45,Loss: -2.561,Avg.Loss: -2.215,LR: 2.24E-04]Training epoch 54:  29%|██▉       | 45/153 [00:00<00:02, 52.57it/s, Epoch: 54, Batch: 46,Loss: -2.470,Avg.Loss: -2.220,LR: 2.24E-04]Training epoch 54:  30%|███       | 46/153 [00:00<00:02, 52.57it/s, Epoch: 54, Batch: 47,Loss: -2.361,Avg.Loss: -2.223,LR: 2.24E-04]Training epoch 54:  31%|███       | 47/153 [00:00<00:02, 52.57it/s, Epoch: 54, Batch: 48,Loss: -2.647,Avg.Loss: -2.232,LR: 2.24E-04]Training epoch 54:  31%|███▏      | 48/153 [00:00<00:01, 52.61it/s, Epoch: 54, Batch: 48,Loss: -2.647,Avg.Loss: -2.232,LR: 2.24E-04]Training epoch 54:  31%|███▏      | 48/153 [00:00<00:01, 52.61it/s, Epoch: 54, Batch: 49,Loss: -2.731,Avg.Loss: -2.242,LR: 2.24E-04]Training epoch 54:  32%|███▏      | 49/153 [00:00<00:01, 52.61it/s, Epoch: 54, Batch: 50,Loss: -2.888,Avg.Loss: -2.255,LR: 2.24E-04]Training epoch 54:  33%|███▎      | 50/153 [00:00<00:01, 52.61it/s, Epoch: 54, Batch: 51,Loss: -2.904,Avg.Loss: -2.268,LR: 2.24E-04]Training epoch 54:  33%|███▎      | 51/153 [00:00<00:01, 52.61it/s, Epoch: 54, Batch: 52,Loss: -2.692,Avg.Loss: -2.276,LR: 2.24E-04]Training epoch 54:  34%|███▍      | 52/153 [00:01<00:01, 52.61it/s, Epoch: 54, Batch: 53,Loss: -2.706,Avg.Loss: -2.284,LR: 2.24E-04]Training epoch 54:  35%|███▍      | 53/153 [00:01<00:01, 52.61it/s, Epoch: 54, Batch: 54,Loss: -2.093,Avg.Loss: -2.281,LR: 2.24E-04]Training epoch 54:  35%|███▌      | 54/153 [00:01<00:01, 52.65it/s, Epoch: 54, Batch: 54,Loss: -2.093,Avg.Loss: -2.281,LR: 2.24E-04]Training epoch 54:  35%|███▌      | 54/153 [00:01<00:01, 52.65it/s, Epoch: 54, Batch: 55,Loss: -2.589,Avg.Loss: -2.286,LR: 2.24E-04]Training epoch 54:  36%|███▌      | 55/153 [00:01<00:01, 52.65it/s, Epoch: 54, Batch: 56,Loss: -2.835,Avg.Loss: -2.296,LR: 2.24E-04]Training epoch 54:  37%|███▋      | 56/153 [00:01<00:01, 52.65it/s, Epoch: 54, Batch: 57,Loss: -2.741,Avg.Loss: -2.304,LR: 2.24E-04]Training epoch 54:  37%|███▋      | 57/153 [00:01<00:01, 52.65it/s, Epoch: 54, Batch: 58,Loss: -2.195,Avg.Loss: -2.302,LR: 2.24E-04]Training epoch 54:  38%|███▊      | 58/153 [00:01<00:01, 52.65it/s, Epoch: 54, Batch: 59,Loss: -2.851,Avg.Loss: -2.311,LR: 2.23E-04]Training epoch 54:  39%|███▊      | 59/153 [00:01<00:01, 52.65it/s, Epoch: 54, Batch: 60,Loss: -2.287,Avg.Loss: -2.311,LR: 2.23E-04]Training epoch 54:  39%|███▉      | 60/153 [00:01<00:01, 52.73it/s, Epoch: 54, Batch: 60,Loss: -2.287,Avg.Loss: -2.311,LR: 2.23E-04]Training epoch 54:  39%|███▉      | 60/153 [00:01<00:01, 52.73it/s, Epoch: 54, Batch: 61,Loss: -2.360,Avg.Loss: -2.312,LR: 2.23E-04]Training epoch 54:  40%|███▉      | 61/153 [00:01<00:01, 52.73it/s, Epoch: 54, Batch: 62,Loss: -3.035,Avg.Loss: -2.323,LR: 2.23E-04]Training epoch 54:  41%|████      | 62/153 [00:01<00:01, 52.73it/s, Epoch: 54, Batch: 63,Loss: -2.509,Avg.Loss: -2.326,LR: 2.23E-04]Training epoch 54:  41%|████      | 63/153 [00:01<00:01, 52.73it/s, Epoch: 54, Batch: 64,Loss: -1.397,Avg.Loss: -2.312,LR: 2.23E-04]Training epoch 54:  42%|████▏     | 64/153 [00:01<00:01, 52.73it/s, Epoch: 54, Batch: 65,Loss: -2.271,Avg.Loss: -2.311,LR: 2.23E-04]Training epoch 54:  42%|████▏     | 65/153 [00:01<00:01, 52.73it/s, Epoch: 54, Batch: 66,Loss: -2.467,Avg.Loss: -2.314,LR: 2.23E-04]Training epoch 54:  43%|████▎     | 66/153 [00:01<00:01, 52.89it/s, Epoch: 54, Batch: 66,Loss: -2.467,Avg.Loss: -2.314,LR: 2.23E-04]Training epoch 54:  43%|████▎     | 66/153 [00:01<00:01, 52.89it/s, Epoch: 54, Batch: 67,Loss: -2.206,Avg.Loss: -2.312,LR: 2.23E-04]Training epoch 54:  44%|████▍     | 67/153 [00:01<00:01, 52.89it/s, Epoch: 54, Batch: 68,Loss: -2.193,Avg.Loss: -2.310,LR: 2.23E-04]Training epoch 54:  44%|████▍     | 68/153 [00:01<00:01, 52.89it/s, Epoch: 54, Batch: 69,Loss: -2.158,Avg.Loss: -2.308,LR: 2.23E-04]Training epoch 54:  45%|████▌     | 69/153 [00:01<00:01, 52.89it/s, Epoch: 54, Batch: 70,Loss: -2.204,Avg.Loss: -2.307,LR: 2.23E-04]Training epoch 54:  46%|████▌     | 70/153 [00:01<00:01, 52.89it/s, Epoch: 54, Batch: 71,Loss: -0.974,Avg.Loss: -2.288,LR: 2.23E-04]Training epoch 54:  46%|████▋     | 71/153 [00:01<00:01, 52.89it/s, Epoch: 54, Batch: 72,Loss: -1.642,Avg.Loss: -2.279,LR: 2.23E-04]Training epoch 54:  47%|████▋     | 72/153 [00:01<00:01, 52.80it/s, Epoch: 54, Batch: 72,Loss: -1.642,Avg.Loss: -2.279,LR: 2.23E-04]Training epoch 54:  47%|████▋     | 72/153 [00:01<00:01, 52.80it/s, Epoch: 54, Batch: 73,Loss: -2.666,Avg.Loss: -2.284,LR: 2.23E-04]Training epoch 54:  48%|████▊     | 73/153 [00:01<00:01, 52.80it/s, Epoch: 54, Batch: 74,Loss: -2.103,Avg.Loss: -2.282,LR: 2.23E-04]Training epoch 54:  48%|████▊     | 74/153 [00:01<00:01, 52.80it/s, Epoch: 54, Batch: 75,Loss: -2.730,Avg.Loss: -2.288,LR: 2.23E-04]Training epoch 54:  49%|████▉     | 75/153 [00:01<00:01, 52.80it/s, Epoch: 54, Batch: 76,Loss: -2.409,Avg.Loss: -2.289,LR: 2.23E-04]Training epoch 54:  50%|████▉     | 76/153 [00:01<00:01, 52.80it/s, Epoch: 54, Batch: 77,Loss: -2.310,Avg.Loss: -2.290,LR: 2.23E-04]Training epoch 54:  50%|█████     | 77/153 [00:01<00:01, 52.80it/s, Epoch: 54, Batch: 78,Loss: -1.568,Avg.Loss: -2.280,LR: 2.22E-04]Training epoch 54:  51%|█████     | 78/153 [00:01<00:01, 52.83it/s, Epoch: 54, Batch: 78,Loss: -1.568,Avg.Loss: -2.280,LR: 2.22E-04]Training epoch 54:  51%|█████     | 78/153 [00:01<00:01, 52.83it/s, Epoch: 54, Batch: 79,Loss: -0.246,Avg.Loss: -2.255,LR: 2.22E-04]Training epoch 54:  52%|█████▏    | 79/153 [00:01<00:01, 52.83it/s, Epoch: 54, Batch: 80,Loss: 0.102,Avg.Loss: -2.225,LR: 2.22E-04] Training epoch 54:  52%|█████▏    | 80/153 [00:01<00:01, 52.83it/s, Epoch: 54, Batch: 81,Loss: -1.174,Avg.Loss: -2.212,LR: 2.22E-04]Training epoch 54:  53%|█████▎    | 81/153 [00:01<00:01, 52.83it/s, Epoch: 54, Batch: 82,Loss: -1.190,Avg.Loss: -2.200,LR: 2.22E-04]Training epoch 54:  54%|█████▎    | 82/153 [00:01<00:01, 52.83it/s, Epoch: 54, Batch: 83,Loss: 0.162,Avg.Loss: -2.171,LR: 2.22E-04] Training epoch 54:  54%|█████▍    | 83/153 [00:01<00:01, 52.83it/s, Epoch: 54, Batch: 84,Loss: -0.710,Avg.Loss: -2.154,LR: 2.22E-04]Training epoch 54:  55%|█████▍    | 84/153 [00:01<00:01, 52.77it/s, Epoch: 54, Batch: 84,Loss: -0.710,Avg.Loss: -2.154,LR: 2.22E-04]Training epoch 54:  55%|█████▍    | 84/153 [00:01<00:01, 52.77it/s, Epoch: 54, Batch: 85,Loss: -0.710,Avg.Loss: -2.137,LR: 2.22E-04]Training epoch 54:  56%|█████▌    | 85/153 [00:01<00:01, 52.77it/s, Epoch: 54, Batch: 86,Loss: -1.303,Avg.Loss: -2.127,LR: 2.22E-04]Training epoch 54:  56%|█████▌    | 86/153 [00:01<00:01, 52.77it/s, Epoch: 54, Batch: 87,Loss: -2.096,Avg.Loss: -2.127,LR: 2.22E-04]Training epoch 54:  57%|█████▋    | 87/153 [00:01<00:01, 52.77it/s, Epoch: 54, Batch: 88,Loss: -1.579,Avg.Loss: -2.120,LR: 2.22E-04]Training epoch 54:  58%|█████▊    | 88/153 [00:01<00:01, 52.77it/s, Epoch: 54, Batch: 89,Loss: 0.710,Avg.Loss: -2.089,LR: 2.22E-04] Training epoch 54:  58%|█████▊    | 89/153 [00:01<00:01, 52.77it/s, Epoch: 54, Batch: 90,Loss: 0.559,Avg.Loss: -2.059,LR: 2.22E-04]Training epoch 54:  59%|█████▉    | 90/153 [00:01<00:01, 52.68it/s, Epoch: 54, Batch: 90,Loss: 0.559,Avg.Loss: -2.059,LR: 2.22E-04]Training epoch 54:  59%|█████▉    | 90/153 [00:01<00:01, 52.68it/s, Epoch: 54, Batch: 91,Loss: 0.184,Avg.Loss: -2.035,LR: 2.22E-04]Training epoch 54:  59%|█████▉    | 91/153 [00:01<00:01, 52.68it/s, Epoch: 54, Batch: 92,Loss: -2.080,Avg.Loss: -2.035,LR: 2.22E-04]Training epoch 54:  60%|██████    | 92/153 [00:01<00:01, 52.68it/s, Epoch: 54, Batch: 93,Loss: -2.596,Avg.Loss: -2.041,LR: 2.22E-04]Training epoch 54:  61%|██████    | 93/153 [00:01<00:01, 52.68it/s, Epoch: 54, Batch: 94,Loss: -2.171,Avg.Loss: -2.043,LR: 2.22E-04]Training epoch 54:  61%|██████▏   | 94/153 [00:01<00:01, 52.68it/s, Epoch: 54, Batch: 95,Loss: -1.205,Avg.Loss: -2.034,LR: 2.22E-04]Training epoch 54:  62%|██████▏   | 95/153 [00:01<00:01, 52.68it/s, Epoch: 54, Batch: 96,Loss: -0.439,Avg.Loss: -2.017,LR: 2.22E-04]Training epoch 54:  63%|██████▎   | 96/153 [00:01<00:01, 52.55it/s, Epoch: 54, Batch: 96,Loss: -0.439,Avg.Loss: -2.017,LR: 2.22E-04]Training epoch 54:  63%|██████▎   | 96/153 [00:01<00:01, 52.55it/s, Epoch: 54, Batch: 97,Loss: -1.764,Avg.Loss: -2.014,LR: 2.22E-04]Training epoch 54:  63%|██████▎   | 97/153 [00:01<00:01, 52.55it/s, Epoch: 54, Batch: 98,Loss: -1.708,Avg.Loss: -2.011,LR: 2.21E-04]Training epoch 54:  64%|██████▍   | 98/153 [00:01<00:01, 52.55it/s, Epoch: 54, Batch: 99,Loss: -1.486,Avg.Loss: -2.006,LR: 2.21E-04]Training epoch 54:  65%|██████▍   | 99/153 [00:01<00:01, 52.55it/s, Epoch: 54, Batch: 100,Loss: -2.212,Avg.Loss: -2.008,LR: 2.21E-04]Training epoch 54:  65%|██████▌   | 100/153 [00:01<00:01, 52.55it/s, Epoch: 54, Batch: 101,Loss: -2.734,Avg.Loss: -2.015,LR: 2.21E-04]Training epoch 54:  66%|██████▌   | 101/153 [00:01<00:00, 52.55it/s, Epoch: 54, Batch: 102,Loss: -2.321,Avg.Loss: -2.018,LR: 2.21E-04]Training epoch 54:  67%|██████▋   | 102/153 [00:01<00:00, 52.48it/s, Epoch: 54, Batch: 102,Loss: -2.321,Avg.Loss: -2.018,LR: 2.21E-04]Training epoch 54:  67%|██████▋   | 102/153 [00:01<00:00, 52.48it/s, Epoch: 54, Batch: 103,Loss: -1.247,Avg.Loss: -2.011,LR: 2.21E-04]Training epoch 54:  67%|██████▋   | 103/153 [00:01<00:00, 52.48it/s, Epoch: 54, Batch: 104,Loss: -0.194,Avg.Loss: -1.993,LR: 2.21E-04]Training epoch 54:  68%|██████▊   | 104/153 [00:01<00:00, 52.48it/s, Epoch: 54, Batch: 105,Loss: -1.913,Avg.Loss: -1.993,LR: 2.21E-04]Training epoch 54:  69%|██████▊   | 105/153 [00:02<00:00, 52.48it/s, Epoch: 54, Batch: 106,Loss: -1.215,Avg.Loss: -1.985,LR: 2.21E-04]Training epoch 54:  69%|██████▉   | 106/153 [00:02<00:00, 52.48it/s, Epoch: 54, Batch: 107,Loss: -1.574,Avg.Loss: -1.981,LR: 2.21E-04]Training epoch 54:  70%|██████▉   | 107/153 [00:02<00:00, 52.48it/s, Epoch: 54, Batch: 108,Loss: -2.048,Avg.Loss: -1.982,LR: 2.21E-04]Training epoch 54:  71%|███████   | 108/153 [00:02<00:00, 52.61it/s, Epoch: 54, Batch: 108,Loss: -2.048,Avg.Loss: -1.982,LR: 2.21E-04]Training epoch 54:  71%|███████   | 108/153 [00:02<00:00, 52.61it/s, Epoch: 54, Batch: 109,Loss: -2.424,Avg.Loss: -1.986,LR: 2.21E-04]Training epoch 54:  71%|███████   | 109/153 [00:02<00:00, 52.61it/s, Epoch: 54, Batch: 110,Loss: -1.916,Avg.Loss: -1.985,LR: 2.21E-04]Training epoch 54:  72%|███████▏  | 110/153 [00:02<00:00, 52.61it/s, Epoch: 54, Batch: 111,Loss: -2.165,Avg.Loss: -1.987,LR: 2.21E-04]Training epoch 54:  73%|███████▎  | 111/153 [00:02<00:00, 52.61it/s, Epoch: 54, Batch: 112,Loss: -1.247,Avg.Loss: -1.980,LR: 2.21E-04]Training epoch 54:  73%|███████▎  | 112/153 [00:02<00:00, 52.61it/s, Epoch: 54, Batch: 113,Loss: -1.702,Avg.Loss: -1.978,LR: 2.21E-04]Training epoch 54:  74%|███████▍  | 113/153 [00:02<00:00, 52.61it/s, Epoch: 54, Batch: 114,Loss: -1.612,Avg.Loss: -1.975,LR: 2.21E-04]Training epoch 54:  75%|███████▍  | 114/153 [00:02<00:00, 52.66it/s, Epoch: 54, Batch: 114,Loss: -1.612,Avg.Loss: -1.975,LR: 2.21E-04]Training epoch 54:  75%|███████▍  | 114/153 [00:02<00:00, 52.66it/s, Epoch: 54, Batch: 115,Loss: -1.459,Avg.Loss: -1.970,LR: 2.21E-04]Training epoch 54:  75%|███████▌  | 115/153 [00:02<00:00, 52.66it/s, Epoch: 54, Batch: 116,Loss: -2.260,Avg.Loss: -1.973,LR: 2.21E-04]Training epoch 54:  76%|███████▌  | 116/153 [00:02<00:00, 52.66it/s, Epoch: 54, Batch: 117,Loss: -2.407,Avg.Loss: -1.976,LR: 2.21E-04]Training epoch 54:  76%|███████▋  | 117/153 [00:02<00:00, 52.66it/s, Epoch: 54, Batch: 118,Loss: -2.693,Avg.Loss: -1.983,LR: 2.20E-04]Training epoch 54:  77%|███████▋  | 118/153 [00:02<00:00, 52.66it/s, Epoch: 54, Batch: 119,Loss: -2.071,Avg.Loss: -1.983,LR: 2.20E-04]Training epoch 54:  78%|███████▊  | 119/153 [00:02<00:00, 52.66it/s, Epoch: 54, Batch: 120,Loss: -2.063,Avg.Loss: -1.984,LR: 2.20E-04]Training epoch 54:  78%|███████▊  | 120/153 [00:02<00:00, 52.87it/s, Epoch: 54, Batch: 120,Loss: -2.063,Avg.Loss: -1.984,LR: 2.20E-04]Training epoch 54:  78%|███████▊  | 120/153 [00:02<00:00, 52.87it/s, Epoch: 54, Batch: 121,Loss: -2.560,Avg.Loss: -1.989,LR: 2.20E-04]Training epoch 54:  79%|███████▉  | 121/153 [00:02<00:00, 52.87it/s, Epoch: 54, Batch: 122,Loss: -1.890,Avg.Loss: -1.988,LR: 2.20E-04]Training epoch 54:  80%|███████▉  | 122/153 [00:02<00:00, 52.87it/s, Epoch: 54, Batch: 123,Loss: -1.901,Avg.Loss: -1.987,LR: 2.20E-04]Training epoch 54:  80%|████████  | 123/153 [00:02<00:00, 52.87it/s, Epoch: 54, Batch: 124,Loss: -2.200,Avg.Loss: -1.989,LR: 2.20E-04]Training epoch 54:  81%|████████  | 124/153 [00:02<00:00, 52.87it/s, Epoch: 54, Batch: 125,Loss: -2.229,Avg.Loss: -1.991,LR: 2.20E-04]Training epoch 54:  82%|████████▏ | 125/153 [00:02<00:00, 52.87it/s, Epoch: 54, Batch: 126,Loss: -2.716,Avg.Loss: -1.997,LR: 2.20E-04]Training epoch 54:  82%|████████▏ | 126/153 [00:02<00:00, 52.75it/s, Epoch: 54, Batch: 126,Loss: -2.716,Avg.Loss: -1.997,LR: 2.20E-04]Training epoch 54:  82%|████████▏ | 126/153 [00:02<00:00, 52.75it/s, Epoch: 54, Batch: 127,Loss: -2.765,Avg.Loss: -2.003,LR: 2.20E-04]Training epoch 54:  83%|████████▎ | 127/153 [00:02<00:00, 52.75it/s, Epoch: 54, Batch: 128,Loss: -2.583,Avg.Loss: -2.007,LR: 2.20E-04]Training epoch 54:  84%|████████▎ | 128/153 [00:02<00:00, 52.75it/s, Epoch: 54, Batch: 129,Loss: -2.540,Avg.Loss: -2.011,LR: 2.20E-04]Training epoch 54:  84%|████████▍ | 129/153 [00:02<00:00, 52.75it/s, Epoch: 54, Batch: 130,Loss: -2.679,Avg.Loss: -2.016,LR: 2.20E-04]Training epoch 54:  85%|████████▍ | 130/153 [00:02<00:00, 52.75it/s, Epoch: 54, Batch: 131,Loss: -2.654,Avg.Loss: -2.021,LR: 2.20E-04]Training epoch 54:  86%|████████▌ | 131/153 [00:02<00:00, 52.75it/s, Epoch: 54, Batch: 132,Loss: -2.303,Avg.Loss: -2.023,LR: 2.20E-04]Training epoch 54:  86%|████████▋ | 132/153 [00:02<00:00, 53.51it/s, Epoch: 54, Batch: 132,Loss: -2.303,Avg.Loss: -2.023,LR: 2.20E-04]Training epoch 54:  86%|████████▋ | 132/153 [00:02<00:00, 53.51it/s, Epoch: 54, Batch: 133,Loss: -2.838,Avg.Loss: -2.030,LR: 2.20E-04]Training epoch 54:  87%|████████▋ | 133/153 [00:02<00:00, 53.51it/s, Epoch: 54, Batch: 134,Loss: -2.425,Avg.Loss: -2.033,LR: 2.20E-04]Training epoch 54:  88%|████████▊ | 134/153 [00:02<00:00, 53.51it/s, Epoch: 54, Batch: 135,Loss: -2.331,Avg.Loss: -2.035,LR: 2.20E-04]Training epoch 54:  88%|████████▊ | 135/153 [00:02<00:00, 53.51it/s, Epoch: 54, Batch: 136,Loss: -2.040,Avg.Loss: -2.035,LR: 2.20E-04]Training epoch 54:  89%|████████▉ | 136/153 [00:02<00:00, 53.51it/s, Epoch: 54, Batch: 137,Loss: -2.314,Avg.Loss: -2.037,LR: 2.19E-04]Training epoch 54:  90%|████████▉ | 137/153 [00:02<00:00, 53.51it/s, Epoch: 54, Batch: 138,Loss: -2.053,Avg.Loss: -2.037,LR: 2.19E-04]Training epoch 54:  90%|█████████ | 138/153 [00:02<00:00, 53.23it/s, Epoch: 54, Batch: 138,Loss: -2.053,Avg.Loss: -2.037,LR: 2.19E-04]Training epoch 54:  90%|█████████ | 138/153 [00:02<00:00, 53.23it/s, Epoch: 54, Batch: 139,Loss: -2.068,Avg.Loss: -2.037,LR: 2.19E-04]Training epoch 54:  91%|█████████ | 139/153 [00:02<00:00, 53.23it/s, Epoch: 54, Batch: 140,Loss: -2.328,Avg.Loss: -2.039,LR: 2.19E-04]Training epoch 54:  92%|█████████▏| 140/153 [00:02<00:00, 53.23it/s, Epoch: 54, Batch: 141,Loss: -1.861,Avg.Loss: -2.038,LR: 2.19E-04]Training epoch 54:  92%|█████████▏| 141/153 [00:02<00:00, 53.23it/s, Epoch: 54, Batch: 142,Loss: -2.382,Avg.Loss: -2.040,LR: 2.19E-04]Training epoch 54:  93%|█████████▎| 142/153 [00:02<00:00, 53.23it/s, Epoch: 54, Batch: 143,Loss: -2.213,Avg.Loss: -2.042,LR: 2.19E-04]Training epoch 54:  93%|█████████▎| 143/153 [00:02<00:00, 53.23it/s, Epoch: 54, Batch: 144,Loss: -2.384,Avg.Loss: -2.044,LR: 2.19E-04]Training epoch 54:  94%|█████████▍| 144/153 [00:02<00:00, 53.93it/s, Epoch: 54, Batch: 144,Loss: -2.384,Avg.Loss: -2.044,LR: 2.19E-04]Training epoch 54:  94%|█████████▍| 144/153 [00:02<00:00, 53.93it/s, Epoch: 54, Batch: 145,Loss: -2.252,Avg.Loss: -2.045,LR: 2.19E-04]Training epoch 54:  95%|█████████▍| 145/153 [00:02<00:00, 53.93it/s, Epoch: 54, Batch: 146,Loss: -2.755,Avg.Loss: -2.050,LR: 2.19E-04]Training epoch 54:  95%|█████████▌| 146/153 [00:02<00:00, 53.93it/s, Epoch: 54, Batch: 147,Loss: -2.553,Avg.Loss: -2.054,LR: 2.19E-04]Training epoch 54:  96%|█████████▌| 147/153 [00:02<00:00, 53.93it/s, Epoch: 54, Batch: 148,Loss: -2.136,Avg.Loss: -2.054,LR: 2.19E-04]Training epoch 54:  97%|█████████▋| 148/153 [00:02<00:00, 53.93it/s, Epoch: 54, Batch: 149,Loss: -2.490,Avg.Loss: -2.057,LR: 2.19E-04]Training epoch 54:  97%|█████████▋| 149/153 [00:02<00:00, 53.93it/s, Epoch: 54, Batch: 150,Loss: -2.764,Avg.Loss: -2.062,LR: 2.19E-04]Training epoch 54:  98%|█████████▊| 150/153 [00:02<00:00, 53.44it/s, Epoch: 54, Batch: 150,Loss: -2.764,Avg.Loss: -2.062,LR: 2.19E-04]Training epoch 54:  98%|█████████▊| 150/153 [00:02<00:00, 53.44it/s, Epoch: 54, Batch: 151,Loss: -1.574,Avg.Loss: -2.059,LR: 2.19E-04]Training epoch 54:  99%|█████████▊| 151/153 [00:02<00:00, 53.44it/s, Epoch: 54, Batch: 152,Loss: -0.175,Avg.Loss: -2.046,LR: 2.19E-04]Training epoch 54:  99%|█████████▉| 152/153 [00:02<00:00, 53.44it/s, Epoch: 54, Batch: 153,Loss: -0.291,Avg.Loss: -2.035,LR: 2.19E-04]Training epoch 54: 100%|██████████| 153/153 [00:02<00:00, 52.76it/s, Epoch: 54, Batch: 153,Loss: -0.291,Avg.Loss: -2.035,LR: 2.19E-04]
Training epoch 55:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 55:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 55, Batch: 1,Loss: -2.073,Avg.Loss: -2.073,LR: 2.19E-04]Training epoch 55:   1%|          | 1/153 [00:00<00:05, 25.83it/s, Epoch: 55, Batch: 2,Loss: -2.306,Avg.Loss: -2.189,LR: 2.19E-04]Training epoch 55:   1%|▏         | 2/153 [00:00<00:04, 37.33it/s, Epoch: 55, Batch: 3,Loss: -1.723,Avg.Loss: -2.034,LR: 2.19E-04]Training epoch 55:   2%|▏         | 3/153 [00:00<00:03, 42.71it/s, Epoch: 55, Batch: 4,Loss: -1.575,Avg.Loss: -1.919,LR: 2.18E-04]Training epoch 55:   3%|▎         | 4/153 [00:00<00:03, 45.03it/s, Epoch: 55, Batch: 5,Loss: -0.741,Avg.Loss: -1.683,LR: 2.18E-04]Training epoch 55:   3%|▎         | 5/153 [00:00<00:03, 46.53it/s, Epoch: 55, Batch: 6,Loss: -1.408,Avg.Loss: -1.637,LR: 2.18E-04]Training epoch 55:   4%|▍         | 6/153 [00:00<00:02, 55.74it/s, Epoch: 55, Batch: 6,Loss: -1.408,Avg.Loss: -1.637,LR: 2.18E-04]Training epoch 55:   4%|▍         | 6/153 [00:00<00:02, 55.74it/s, Epoch: 55, Batch: 7,Loss: -1.915,Avg.Loss: -1.677,LR: 2.18E-04]Training epoch 55:   5%|▍         | 7/153 [00:00<00:02, 55.74it/s, Epoch: 55, Batch: 8,Loss: -2.682,Avg.Loss: -1.803,LR: 2.18E-04]Training epoch 55:   5%|▌         | 8/153 [00:00<00:02, 55.74it/s, Epoch: 55, Batch: 9,Loss: -1.990,Avg.Loss: -1.824,LR: 2.18E-04]Training epoch 55:   6%|▌         | 9/153 [00:00<00:02, 55.74it/s, Epoch: 55, Batch: 10,Loss: -1.928,Avg.Loss: -1.834,LR: 2.18E-04]Training epoch 55:   7%|▋         | 10/153 [00:00<00:02, 55.74it/s, Epoch: 55, Batch: 11,Loss: -2.292,Avg.Loss: -1.876,LR: 2.18E-04]Training epoch 55:   7%|▋         | 11/153 [00:00<00:02, 55.74it/s, Epoch: 55, Batch: 12,Loss: -2.468,Avg.Loss: -1.925,LR: 2.18E-04]Training epoch 55:   8%|▊         | 12/153 [00:00<00:02, 54.35it/s, Epoch: 55, Batch: 12,Loss: -2.468,Avg.Loss: -1.925,LR: 2.18E-04]Training epoch 55:   8%|▊         | 12/153 [00:00<00:02, 54.35it/s, Epoch: 55, Batch: 13,Loss: -2.779,Avg.Loss: -1.991,LR: 2.18E-04]Training epoch 55:   8%|▊         | 13/153 [00:00<00:02, 54.35it/s, Epoch: 55, Batch: 14,Loss: -2.787,Avg.Loss: -2.048,LR: 2.18E-04]Training epoch 55:   9%|▉         | 14/153 [00:00<00:02, 54.35it/s, Epoch: 55, Batch: 15,Loss: -2.416,Avg.Loss: -2.072,LR: 2.18E-04]Training epoch 55:  10%|▉         | 15/153 [00:00<00:02, 54.35it/s, Epoch: 55, Batch: 16,Loss: -2.239,Avg.Loss: -2.083,LR: 2.18E-04]Training epoch 55:  10%|█         | 16/153 [00:00<00:02, 54.35it/s, Epoch: 55, Batch: 17,Loss: -3.022,Avg.Loss: -2.138,LR: 2.18E-04]Training epoch 55:  11%|█         | 17/153 [00:00<00:02, 54.35it/s, Epoch: 55, Batch: 18,Loss: -2.282,Avg.Loss: -2.146,LR: 2.18E-04]Training epoch 55:  12%|█▏        | 18/153 [00:00<00:02, 53.70it/s, Epoch: 55, Batch: 18,Loss: -2.282,Avg.Loss: -2.146,LR: 2.18E-04]Training epoch 55:  12%|█▏        | 18/153 [00:00<00:02, 53.70it/s, Epoch: 55, Batch: 19,Loss: -1.229,Avg.Loss: -2.098,LR: 2.18E-04]Training epoch 55:  12%|█▏        | 19/153 [00:00<00:02, 53.70it/s, Epoch: 55, Batch: 20,Loss: -2.295,Avg.Loss: -2.107,LR: 2.18E-04]Training epoch 55:  13%|█▎        | 20/153 [00:00<00:02, 53.70it/s, Epoch: 55, Batch: 21,Loss: -2.117,Avg.Loss: -2.108,LR: 2.18E-04]Training epoch 55:  14%|█▎        | 21/153 [00:00<00:02, 53.70it/s, Epoch: 55, Batch: 22,Loss: -2.306,Avg.Loss: -2.117,LR: 2.18E-04]Training epoch 55:  14%|█▍        | 22/153 [00:00<00:02, 53.70it/s, Epoch: 55, Batch: 23,Loss: -2.831,Avg.Loss: -2.148,LR: 2.17E-04]Training epoch 55:  15%|█▌        | 23/153 [00:00<00:02, 53.70it/s, Epoch: 55, Batch: 24,Loss: -2.041,Avg.Loss: -2.143,LR: 2.17E-04]Training epoch 55:  16%|█▌        | 24/153 [00:00<00:02, 52.92it/s, Epoch: 55, Batch: 24,Loss: -2.041,Avg.Loss: -2.143,LR: 2.17E-04]Training epoch 55:  16%|█▌        | 24/153 [00:00<00:02, 52.92it/s, Epoch: 55, Batch: 25,Loss: -1.803,Avg.Loss: -2.130,LR: 2.17E-04]Training epoch 55:  16%|█▋        | 25/153 [00:00<00:02, 52.92it/s, Epoch: 55, Batch: 26,Loss: -1.352,Avg.Loss: -2.100,LR: 2.17E-04]Training epoch 55:  17%|█▋        | 26/153 [00:00<00:02, 52.92it/s, Epoch: 55, Batch: 27,Loss: -2.375,Avg.Loss: -2.110,LR: 2.17E-04]Training epoch 55:  18%|█▊        | 27/153 [00:00<00:02, 52.92it/s, Epoch: 55, Batch: 28,Loss: -2.412,Avg.Loss: -2.121,LR: 2.17E-04]Training epoch 55:  18%|█▊        | 28/153 [00:00<00:02, 52.92it/s, Epoch: 55, Batch: 29,Loss: -2.030,Avg.Loss: -2.118,LR: 2.17E-04]Training epoch 55:  19%|█▉        | 29/153 [00:00<00:02, 52.92it/s, Epoch: 55, Batch: 30,Loss: -0.555,Avg.Loss: -2.066,LR: 2.17E-04]Training epoch 55:  20%|█▉        | 30/153 [00:00<00:02, 52.59it/s, Epoch: 55, Batch: 30,Loss: -0.555,Avg.Loss: -2.066,LR: 2.17E-04]Training epoch 55:  20%|█▉        | 30/153 [00:00<00:02, 52.59it/s, Epoch: 55, Batch: 31,Loss: -0.856,Avg.Loss: -2.027,LR: 2.17E-04]Training epoch 55:  20%|██        | 31/153 [00:00<00:02, 52.59it/s, Epoch: 55, Batch: 32,Loss: -0.504,Avg.Loss: -1.979,LR: 2.17E-04]Training epoch 55:  21%|██        | 32/153 [00:00<00:02, 52.59it/s, Epoch: 55, Batch: 33,Loss: -1.017,Avg.Loss: -1.950,LR: 2.17E-04]Training epoch 55:  22%|██▏       | 33/153 [00:00<00:02, 52.59it/s, Epoch: 55, Batch: 34,Loss: -1.786,Avg.Loss: -1.945,LR: 2.17E-04]Training epoch 55:  22%|██▏       | 34/153 [00:00<00:02, 52.59it/s, Epoch: 55, Batch: 35,Loss: -2.458,Avg.Loss: -1.960,LR: 2.17E-04]Training epoch 55:  23%|██▎       | 35/153 [00:00<00:02, 52.59it/s, Epoch: 55, Batch: 36,Loss: -2.838,Avg.Loss: -1.984,LR: 2.17E-04]Training epoch 55:  24%|██▎       | 36/153 [00:00<00:02, 52.73it/s, Epoch: 55, Batch: 36,Loss: -2.838,Avg.Loss: -1.984,LR: 2.17E-04]Training epoch 55:  24%|██▎       | 36/153 [00:00<00:02, 52.73it/s, Epoch: 55, Batch: 37,Loss: -1.498,Avg.Loss: -1.971,LR: 2.17E-04]Training epoch 55:  24%|██▍       | 37/153 [00:00<00:02, 52.73it/s, Epoch: 55, Batch: 38,Loss: -0.907,Avg.Loss: -1.943,LR: 2.17E-04]Training epoch 55:  25%|██▍       | 38/153 [00:00<00:02, 52.73it/s, Epoch: 55, Batch: 39,Loss: -0.895,Avg.Loss: -1.916,LR: 2.17E-04]Training epoch 55:  25%|██▌       | 39/153 [00:00<00:02, 52.73it/s, Epoch: 55, Batch: 40,Loss: -1.390,Avg.Loss: -1.903,LR: 2.17E-04]Training epoch 55:  26%|██▌       | 40/153 [00:00<00:02, 52.73it/s, Epoch: 55, Batch: 41,Loss: -1.659,Avg.Loss: -1.897,LR: 2.17E-04]Training epoch 55:  27%|██▋       | 41/153 [00:00<00:02, 52.73it/s, Epoch: 55, Batch: 42,Loss: -2.174,Avg.Loss: -1.904,LR: 2.17E-04]Training epoch 55:  27%|██▋       | 42/153 [00:00<00:02, 52.80it/s, Epoch: 55, Batch: 42,Loss: -2.174,Avg.Loss: -1.904,LR: 2.17E-04]Training epoch 55:  27%|██▋       | 42/153 [00:00<00:02, 52.80it/s, Epoch: 55, Batch: 43,Loss: -2.545,Avg.Loss: -1.919,LR: 2.16E-04]Training epoch 55:  28%|██▊       | 43/153 [00:00<00:02, 52.80it/s, Epoch: 55, Batch: 44,Loss: -2.546,Avg.Loss: -1.933,LR: 2.16E-04]Training epoch 55:  29%|██▉       | 44/153 [00:00<00:02, 52.80it/s, Epoch: 55, Batch: 45,Loss: -2.191,Avg.Loss: -1.939,LR: 2.16E-04]Training epoch 55:  29%|██▉       | 45/153 [00:00<00:02, 52.80it/s, Epoch: 55, Batch: 46,Loss: -1.576,Avg.Loss: -1.931,LR: 2.16E-04]Training epoch 55:  30%|███       | 46/153 [00:00<00:02, 52.80it/s, Epoch: 55, Batch: 47,Loss: -2.305,Avg.Loss: -1.939,LR: 2.16E-04]Training epoch 55:  31%|███       | 47/153 [00:00<00:02, 52.80it/s, Epoch: 55, Batch: 48,Loss: -2.316,Avg.Loss: -1.947,LR: 2.16E-04]Training epoch 55:  31%|███▏      | 48/153 [00:00<00:01, 52.93it/s, Epoch: 55, Batch: 48,Loss: -2.316,Avg.Loss: -1.947,LR: 2.16E-04]Training epoch 55:  31%|███▏      | 48/153 [00:00<00:01, 52.93it/s, Epoch: 55, Batch: 49,Loss: -2.437,Avg.Loss: -1.957,LR: 2.16E-04]Training epoch 55:  32%|███▏      | 49/153 [00:00<00:01, 52.93it/s, Epoch: 55, Batch: 50,Loss: -2.160,Avg.Loss: -1.961,LR: 2.16E-04]Training epoch 55:  33%|███▎      | 50/153 [00:00<00:01, 52.93it/s, Epoch: 55, Batch: 51,Loss: -2.739,Avg.Loss: -1.976,LR: 2.16E-04]Training epoch 55:  33%|███▎      | 51/153 [00:00<00:01, 52.93it/s, Epoch: 55, Batch: 52,Loss: -1.695,Avg.Loss: -1.970,LR: 2.16E-04]Training epoch 55:  34%|███▍      | 52/153 [00:00<00:01, 52.93it/s, Epoch: 55, Batch: 53,Loss: -2.432,Avg.Loss: -1.979,LR: 2.16E-04]Training epoch 55:  35%|███▍      | 53/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 54,Loss: -2.066,Avg.Loss: -1.981,LR: 2.16E-04]Training epoch 55:  35%|███▌      | 54/153 [00:01<00:01, 52.74it/s, Epoch: 55, Batch: 54,Loss: -2.066,Avg.Loss: -1.981,LR: 2.16E-04]Training epoch 55:  35%|███▌      | 54/153 [00:01<00:01, 52.74it/s, Epoch: 55, Batch: 55,Loss: -1.324,Avg.Loss: -1.969,LR: 2.16E-04]Training epoch 55:  36%|███▌      | 55/153 [00:01<00:01, 52.74it/s, Epoch: 55, Batch: 56,Loss: -2.128,Avg.Loss: -1.972,LR: 2.16E-04]Training epoch 55:  37%|███▋      | 56/153 [00:01<00:01, 52.74it/s, Epoch: 55, Batch: 57,Loss: -2.362,Avg.Loss: -1.979,LR: 2.16E-04]Training epoch 55:  37%|███▋      | 57/153 [00:01<00:01, 52.74it/s, Epoch: 55, Batch: 58,Loss: -1.340,Avg.Loss: -1.968,LR: 2.16E-04]Training epoch 55:  38%|███▊      | 58/153 [00:01<00:01, 52.74it/s, Epoch: 55, Batch: 59,Loss: -1.216,Avg.Loss: -1.955,LR: 2.16E-04]Training epoch 55:  39%|███▊      | 59/153 [00:01<00:01, 52.74it/s, Epoch: 55, Batch: 60,Loss: -1.283,Avg.Loss: -1.944,LR: 2.16E-04]Training epoch 55:  39%|███▉      | 60/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 60,Loss: -1.283,Avg.Loss: -1.944,LR: 2.16E-04]Training epoch 55:  39%|███▉      | 60/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 61,Loss: -2.277,Avg.Loss: -1.949,LR: 2.16E-04]Training epoch 55:  40%|███▉      | 61/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 62,Loss: -2.281,Avg.Loss: -1.954,LR: 2.16E-04]Training epoch 55:  41%|████      | 62/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 63,Loss: -1.953,Avg.Loss: -1.954,LR: 2.15E-04]Training epoch 55:  41%|████      | 63/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 64,Loss: -2.278,Avg.Loss: -1.959,LR: 2.15E-04]Training epoch 55:  42%|████▏     | 64/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 65,Loss: -2.640,Avg.Loss: -1.970,LR: 2.15E-04]Training epoch 55:  42%|████▏     | 65/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 66,Loss: -2.152,Avg.Loss: -1.973,LR: 2.15E-04]Training epoch 55:  43%|████▎     | 66/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 66,Loss: -2.152,Avg.Loss: -1.973,LR: 2.15E-04]Training epoch 55:  43%|████▎     | 66/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 67,Loss: -2.020,Avg.Loss: -1.973,LR: 2.15E-04]Training epoch 55:  44%|████▍     | 67/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 68,Loss: -2.144,Avg.Loss: -1.976,LR: 2.15E-04]Training epoch 55:  44%|████▍     | 68/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 69,Loss: -2.740,Avg.Loss: -1.987,LR: 2.15E-04]Training epoch 55:  45%|████▌     | 69/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 70,Loss: -1.614,Avg.Loss: -1.982,LR: 2.15E-04]Training epoch 55:  46%|████▌     | 70/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 71,Loss: -1.875,Avg.Loss: -1.980,LR: 2.15E-04]Training epoch 55:  46%|████▋     | 71/153 [00:01<00:01, 52.62it/s, Epoch: 55, Batch: 72,Loss: -1.944,Avg.Loss: -1.980,LR: 2.15E-04]Training epoch 55:  47%|████▋     | 72/153 [00:01<00:01, 52.58it/s, Epoch: 55, Batch: 72,Loss: -1.944,Avg.Loss: -1.980,LR: 2.15E-04]Training epoch 55:  47%|████▋     | 72/153 [00:01<00:01, 52.58it/s, Epoch: 55, Batch: 73,Loss: -2.554,Avg.Loss: -1.988,LR: 2.15E-04]Training epoch 55:  48%|████▊     | 73/153 [00:01<00:01, 52.58it/s, Epoch: 55, Batch: 74,Loss: -2.802,Avg.Loss: -1.999,LR: 2.15E-04]Training epoch 55:  48%|████▊     | 74/153 [00:01<00:01, 52.58it/s, Epoch: 55, Batch: 75,Loss: -1.787,Avg.Loss: -1.996,LR: 2.15E-04]Training epoch 55:  49%|████▉     | 75/153 [00:01<00:01, 52.58it/s, Epoch: 55, Batch: 76,Loss: -2.209,Avg.Loss: -1.999,LR: 2.15E-04]Training epoch 55:  50%|████▉     | 76/153 [00:01<00:01, 52.58it/s, Epoch: 55, Batch: 77,Loss: -2.473,Avg.Loss: -2.005,LR: 2.15E-04]Training epoch 55:  50%|█████     | 77/153 [00:01<00:01, 52.58it/s, Epoch: 55, Batch: 78,Loss: -2.555,Avg.Loss: -2.012,LR: 2.15E-04]Training epoch 55:  51%|█████     | 78/153 [00:01<00:01, 52.71it/s, Epoch: 55, Batch: 78,Loss: -2.555,Avg.Loss: -2.012,LR: 2.15E-04]Training epoch 55:  51%|█████     | 78/153 [00:01<00:01, 52.71it/s, Epoch: 55, Batch: 79,Loss: -2.206,Avg.Loss: -2.014,LR: 2.15E-04]Training epoch 55:  52%|█████▏    | 79/153 [00:01<00:01, 52.71it/s, Epoch: 55, Batch: 80,Loss: -2.006,Avg.Loss: -2.014,LR: 2.15E-04]Training epoch 55:  52%|█████▏    | 80/153 [00:01<00:01, 52.71it/s, Epoch: 55, Batch: 81,Loss: -2.509,Avg.Loss: -2.020,LR: 2.15E-04]Training epoch 55:  53%|█████▎    | 81/153 [00:01<00:01, 52.71it/s, Epoch: 55, Batch: 82,Loss: -2.589,Avg.Loss: -2.027,LR: 2.14E-04]Training epoch 55:  54%|█████▎    | 82/153 [00:01<00:01, 52.71it/s, Epoch: 55, Batch: 83,Loss: -2.038,Avg.Loss: -2.027,LR: 2.14E-04]Training epoch 55:  54%|█████▍    | 83/153 [00:01<00:01, 52.71it/s, Epoch: 55, Batch: 84,Loss: -1.739,Avg.Loss: -2.024,LR: 2.14E-04]Training epoch 55:  55%|█████▍    | 84/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 84,Loss: -1.739,Avg.Loss: -2.024,LR: 2.14E-04]Training epoch 55:  55%|█████▍    | 84/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 85,Loss: -2.432,Avg.Loss: -2.029,LR: 2.14E-04]Training epoch 55:  56%|█████▌    | 85/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 86,Loss: -1.903,Avg.Loss: -2.027,LR: 2.14E-04]Training epoch 55:  56%|█████▌    | 86/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 87,Loss: -1.587,Avg.Loss: -2.022,LR: 2.14E-04]Training epoch 55:  57%|█████▋    | 87/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 88,Loss: -1.506,Avg.Loss: -2.016,LR: 2.14E-04]Training epoch 55:  58%|█████▊    | 88/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 89,Loss: -2.911,Avg.Loss: -2.026,LR: 2.14E-04]Training epoch 55:  58%|█████▊    | 89/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 90,Loss: -2.875,Avg.Loss: -2.036,LR: 2.14E-04]Training epoch 55:  59%|█████▉    | 90/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 90,Loss: -2.875,Avg.Loss: -2.036,LR: 2.14E-04]Training epoch 55:  59%|█████▉    | 90/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 91,Loss: -1.934,Avg.Loss: -2.035,LR: 2.14E-04]Training epoch 55:  59%|█████▉    | 91/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 92,Loss: -1.923,Avg.Loss: -2.033,LR: 2.14E-04]Training epoch 55:  60%|██████    | 92/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 93,Loss: -2.795,Avg.Loss: -2.042,LR: 2.14E-04]Training epoch 55:  61%|██████    | 93/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 94,Loss: -2.514,Avg.Loss: -2.047,LR: 2.14E-04]Training epoch 55:  61%|██████▏   | 94/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 95,Loss: -2.294,Avg.Loss: -2.049,LR: 2.14E-04]Training epoch 55:  62%|██████▏   | 95/153 [00:01<00:01, 52.93it/s, Epoch: 55, Batch: 96,Loss: -2.024,Avg.Loss: -2.049,LR: 2.14E-04]Training epoch 55:  63%|██████▎   | 96/153 [00:01<00:01, 52.85it/s, Epoch: 55, Batch: 96,Loss: -2.024,Avg.Loss: -2.049,LR: 2.14E-04]Training epoch 55:  63%|██████▎   | 96/153 [00:01<00:01, 52.85it/s, Epoch: 55, Batch: 97,Loss: -2.829,Avg.Loss: -2.057,LR: 2.14E-04]Training epoch 55:  63%|██████▎   | 97/153 [00:01<00:01, 52.85it/s, Epoch: 55, Batch: 98,Loss: -2.100,Avg.Loss: -2.057,LR: 2.14E-04]Training epoch 55:  64%|██████▍   | 98/153 [00:01<00:01, 52.85it/s, Epoch: 55, Batch: 99,Loss: -1.650,Avg.Loss: -2.053,LR: 2.14E-04]Training epoch 55:  65%|██████▍   | 99/153 [00:01<00:01, 52.85it/s, Epoch: 55, Batch: 100,Loss: -1.775,Avg.Loss: -2.051,LR: 2.14E-04]Training epoch 55:  65%|██████▌   | 100/153 [00:01<00:01, 52.85it/s, Epoch: 55, Batch: 101,Loss: -2.813,Avg.Loss: -2.058,LR: 2.14E-04]Training epoch 55:  66%|██████▌   | 101/153 [00:01<00:00, 52.85it/s, Epoch: 55, Batch: 102,Loss: -2.342,Avg.Loss: -2.061,LR: 2.13E-04]Training epoch 55:  67%|██████▋   | 102/153 [00:01<00:00, 52.69it/s, Epoch: 55, Batch: 102,Loss: -2.342,Avg.Loss: -2.061,LR: 2.13E-04]Training epoch 55:  67%|██████▋   | 102/153 [00:01<00:00, 52.69it/s, Epoch: 55, Batch: 103,Loss: -2.441,Avg.Loss: -2.065,LR: 2.13E-04]Training epoch 55:  67%|██████▋   | 103/153 [00:01<00:00, 52.69it/s, Epoch: 55, Batch: 104,Loss: -2.416,Avg.Loss: -2.068,LR: 2.13E-04]Training epoch 55:  68%|██████▊   | 104/153 [00:01<00:00, 52.69it/s, Epoch: 55, Batch: 105,Loss: -2.698,Avg.Loss: -2.074,LR: 2.13E-04]Training epoch 55:  69%|██████▊   | 105/153 [00:02<00:00, 52.69it/s, Epoch: 55, Batch: 106,Loss: -2.325,Avg.Loss: -2.076,LR: 2.13E-04]Training epoch 55:  69%|██████▉   | 106/153 [00:02<00:00, 52.69it/s, Epoch: 55, Batch: 107,Loss: -2.150,Avg.Loss: -2.077,LR: 2.13E-04]Training epoch 55:  70%|██████▉   | 107/153 [00:02<00:00, 52.69it/s, Epoch: 55, Batch: 108,Loss: -1.318,Avg.Loss: -2.070,LR: 2.13E-04]Training epoch 55:  71%|███████   | 108/153 [00:02<00:00, 52.81it/s, Epoch: 55, Batch: 108,Loss: -1.318,Avg.Loss: -2.070,LR: 2.13E-04]Training epoch 55:  71%|███████   | 108/153 [00:02<00:00, 52.81it/s, Epoch: 55, Batch: 109,Loss: -2.295,Avg.Loss: -2.072,LR: 2.13E-04]Training epoch 55:  71%|███████   | 109/153 [00:02<00:00, 52.81it/s, Epoch: 55, Batch: 110,Loss: -2.757,Avg.Loss: -2.078,LR: 2.13E-04]Training epoch 55:  72%|███████▏  | 110/153 [00:02<00:00, 52.81it/s, Epoch: 55, Batch: 111,Loss: -2.360,Avg.Loss: -2.081,LR: 2.13E-04]Training epoch 55:  73%|███████▎  | 111/153 [00:02<00:00, 52.81it/s, Epoch: 55, Batch: 112,Loss: -2.627,Avg.Loss: -2.086,LR: 2.13E-04]Training epoch 55:  73%|███████▎  | 112/153 [00:02<00:00, 52.81it/s, Epoch: 55, Batch: 113,Loss: -2.374,Avg.Loss: -2.088,LR: 2.13E-04]Training epoch 55:  74%|███████▍  | 113/153 [00:02<00:00, 52.81it/s, Epoch: 55, Batch: 114,Loss: -2.152,Avg.Loss: -2.089,LR: 2.13E-04]Training epoch 55:  75%|███████▍  | 114/153 [00:02<00:00, 52.86it/s, Epoch: 55, Batch: 114,Loss: -2.152,Avg.Loss: -2.089,LR: 2.13E-04]Training epoch 55:  75%|███████▍  | 114/153 [00:02<00:00, 52.86it/s, Epoch: 55, Batch: 115,Loss: -1.955,Avg.Loss: -2.088,LR: 2.13E-04]Training epoch 55:  75%|███████▌  | 115/153 [00:02<00:00, 52.86it/s, Epoch: 55, Batch: 116,Loss: -1.828,Avg.Loss: -2.085,LR: 2.13E-04]Training epoch 55:  76%|███████▌  | 116/153 [00:02<00:00, 52.86it/s, Epoch: 55, Batch: 117,Loss: -2.517,Avg.Loss: -2.089,LR: 2.13E-04]Training epoch 55:  76%|███████▋  | 117/153 [00:02<00:00, 52.86it/s, Epoch: 55, Batch: 118,Loss: -2.392,Avg.Loss: -2.092,LR: 2.13E-04]Training epoch 55:  77%|███████▋  | 118/153 [00:02<00:00, 52.86it/s, Epoch: 55, Batch: 119,Loss: -2.576,Avg.Loss: -2.096,LR: 2.13E-04]Training epoch 55:  78%|███████▊  | 119/153 [00:02<00:00, 52.86it/s, Epoch: 55, Batch: 120,Loss: -2.199,Avg.Loss: -2.097,LR: 2.13E-04]Training epoch 55:  78%|███████▊  | 120/153 [00:02<00:00, 52.82it/s, Epoch: 55, Batch: 120,Loss: -2.199,Avg.Loss: -2.097,LR: 2.13E-04]Training epoch 55:  78%|███████▊  | 120/153 [00:02<00:00, 52.82it/s, Epoch: 55, Batch: 121,Loss: -2.315,Avg.Loss: -2.098,LR: 2.13E-04]Training epoch 55:  79%|███████▉  | 121/153 [00:02<00:00, 52.82it/s, Epoch: 55, Batch: 122,Loss: -2.681,Avg.Loss: -2.103,LR: 2.12E-04]Training epoch 55:  80%|███████▉  | 122/153 [00:02<00:00, 52.82it/s, Epoch: 55, Batch: 123,Loss: -2.192,Avg.Loss: -2.104,LR: 2.12E-04]Training epoch 55:  80%|████████  | 123/153 [00:02<00:00, 52.82it/s, Epoch: 55, Batch: 124,Loss: -2.425,Avg.Loss: -2.106,LR: 2.12E-04]Training epoch 55:  81%|████████  | 124/153 [00:02<00:00, 52.82it/s, Epoch: 55, Batch: 125,Loss: -1.395,Avg.Loss: -2.101,LR: 2.12E-04]Training epoch 55:  82%|████████▏ | 125/153 [00:02<00:00, 52.82it/s, Epoch: 55, Batch: 126,Loss: -2.515,Avg.Loss: -2.104,LR: 2.12E-04]Training epoch 55:  82%|████████▏ | 126/153 [00:02<00:00, 53.02it/s, Epoch: 55, Batch: 126,Loss: -2.515,Avg.Loss: -2.104,LR: 2.12E-04]Training epoch 55:  82%|████████▏ | 126/153 [00:02<00:00, 53.02it/s, Epoch: 55, Batch: 127,Loss: -2.454,Avg.Loss: -2.107,LR: 2.12E-04]Training epoch 55:  83%|████████▎ | 127/153 [00:02<00:00, 53.02it/s, Epoch: 55, Batch: 128,Loss: -2.928,Avg.Loss: -2.113,LR: 2.12E-04]Training epoch 55:  84%|████████▎ | 128/153 [00:02<00:00, 53.02it/s, Epoch: 55, Batch: 129,Loss: -2.809,Avg.Loss: -2.119,LR: 2.12E-04]Training epoch 55:  84%|████████▍ | 129/153 [00:02<00:00, 53.02it/s, Epoch: 55, Batch: 130,Loss: -2.766,Avg.Loss: -2.124,LR: 2.12E-04]Training epoch 55:  85%|████████▍ | 130/153 [00:02<00:00, 53.02it/s, Epoch: 55, Batch: 131,Loss: -2.794,Avg.Loss: -2.129,LR: 2.12E-04]Training epoch 55:  86%|████████▌ | 131/153 [00:02<00:00, 53.02it/s, Epoch: 55, Batch: 132,Loss: -2.550,Avg.Loss: -2.132,LR: 2.12E-04]Training epoch 55:  86%|████████▋ | 132/153 [00:02<00:00, 53.08it/s, Epoch: 55, Batch: 132,Loss: -2.550,Avg.Loss: -2.132,LR: 2.12E-04]Training epoch 55:  86%|████████▋ | 132/153 [00:02<00:00, 53.08it/s, Epoch: 55, Batch: 133,Loss: -2.369,Avg.Loss: -2.134,LR: 2.12E-04]Training epoch 55:  87%|████████▋ | 133/153 [00:02<00:00, 53.08it/s, Epoch: 55, Batch: 134,Loss: -2.178,Avg.Loss: -2.134,LR: 2.12E-04]Training epoch 55:  88%|████████▊ | 134/153 [00:02<00:00, 53.08it/s, Epoch: 55, Batch: 135,Loss: -2.108,Avg.Loss: -2.134,LR: 2.12E-04]Training epoch 55:  88%|████████▊ | 135/153 [00:02<00:00, 53.08it/s, Epoch: 55, Batch: 136,Loss: -1.948,Avg.Loss: -2.132,LR: 2.12E-04]Training epoch 55:  89%|████████▉ | 136/153 [00:02<00:00, 53.08it/s, Epoch: 55, Batch: 137,Loss: -2.707,Avg.Loss: -2.137,LR: 2.12E-04]Training epoch 55:  90%|████████▉ | 137/153 [00:02<00:00, 53.08it/s, Epoch: 55, Batch: 138,Loss: -2.154,Avg.Loss: -2.137,LR: 2.12E-04]Training epoch 55:  90%|█████████ | 138/153 [00:02<00:00, 53.27it/s, Epoch: 55, Batch: 138,Loss: -2.154,Avg.Loss: -2.137,LR: 2.12E-04]Training epoch 55:  90%|█████████ | 138/153 [00:02<00:00, 53.27it/s, Epoch: 55, Batch: 139,Loss: -2.152,Avg.Loss: -2.137,LR: 2.12E-04]Training epoch 55:  91%|█████████ | 139/153 [00:02<00:00, 53.27it/s, Epoch: 55, Batch: 140,Loss: -2.204,Avg.Loss: -2.137,LR: 2.12E-04]Training epoch 55:  92%|█████████▏| 140/153 [00:02<00:00, 53.27it/s, Epoch: 55, Batch: 141,Loss: -1.320,Avg.Loss: -2.132,LR: 2.11E-04]Training epoch 55:  92%|█████████▏| 141/153 [00:02<00:00, 53.27it/s, Epoch: 55, Batch: 142,Loss: -1.636,Avg.Loss: -2.128,LR: 2.11E-04]Training epoch 55:  93%|█████████▎| 142/153 [00:02<00:00, 53.27it/s, Epoch: 55, Batch: 143,Loss: -1.363,Avg.Loss: -2.123,LR: 2.11E-04]Training epoch 55:  93%|█████████▎| 143/153 [00:02<00:00, 53.27it/s, Epoch: 55, Batch: 144,Loss: -2.287,Avg.Loss: -2.124,LR: 2.11E-04]Training epoch 55:  94%|█████████▍| 144/153 [00:02<00:00, 53.26it/s, Epoch: 55, Batch: 144,Loss: -2.287,Avg.Loss: -2.124,LR: 2.11E-04]Training epoch 55:  94%|█████████▍| 144/153 [00:02<00:00, 53.26it/s, Epoch: 55, Batch: 145,Loss: -2.970,Avg.Loss: -2.130,LR: 2.11E-04]Training epoch 55:  95%|█████████▍| 145/153 [00:02<00:00, 53.26it/s, Epoch: 55, Batch: 146,Loss: -2.933,Avg.Loss: -2.135,LR: 2.11E-04]Training epoch 55:  95%|█████████▌| 146/153 [00:02<00:00, 53.26it/s, Epoch: 55, Batch: 147,Loss: -2.453,Avg.Loss: -2.137,LR: 2.11E-04]Training epoch 55:  96%|█████████▌| 147/153 [00:02<00:00, 53.26it/s, Epoch: 55, Batch: 148,Loss: -1.908,Avg.Loss: -2.136,LR: 2.11E-04]Training epoch 55:  97%|█████████▋| 148/153 [00:02<00:00, 53.26it/s, Epoch: 55, Batch: 149,Loss: -2.168,Avg.Loss: -2.136,LR: 2.11E-04]Training epoch 55:  97%|█████████▋| 149/153 [00:02<00:00, 53.26it/s, Epoch: 55, Batch: 150,Loss: -1.966,Avg.Loss: -2.135,LR: 2.11E-04]Training epoch 55:  98%|█████████▊| 150/153 [00:02<00:00, 53.28it/s, Epoch: 55, Batch: 150,Loss: -1.966,Avg.Loss: -2.135,LR: 2.11E-04]Training epoch 55:  98%|█████████▊| 150/153 [00:02<00:00, 53.28it/s, Epoch: 55, Batch: 151,Loss: -2.261,Avg.Loss: -2.136,LR: 2.11E-04]Training epoch 55:  99%|█████████▊| 151/153 [00:02<00:00, 53.28it/s, Epoch: 55, Batch: 152,Loss: -2.131,Avg.Loss: -2.136,LR: 2.11E-04]Training epoch 55:  99%|█████████▉| 152/153 [00:02<00:00, 53.28it/s, Epoch: 55, Batch: 153,Loss: -1.880,Avg.Loss: -2.134,LR: 2.11E-04]Training epoch 55: 100%|██████████| 153/153 [00:02<00:00, 52.95it/s, Epoch: 55, Batch: 153,Loss: -1.880,Avg.Loss: -2.134,LR: 2.11E-04]
Training epoch 56:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 56:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 56, Batch: 1,Loss: -2.161,Avg.Loss: -2.161,LR: 2.11E-04]Training epoch 56:   1%|          | 1/153 [00:00<00:05, 28.35it/s, Epoch: 56, Batch: 2,Loss: -1.813,Avg.Loss: -1.987,LR: 2.11E-04]Training epoch 56:   1%|▏         | 2/153 [00:00<00:03, 39.75it/s, Epoch: 56, Batch: 3,Loss: -1.711,Avg.Loss: -1.895,LR: 2.11E-04]Training epoch 56:   2%|▏         | 3/153 [00:00<00:03, 44.59it/s, Epoch: 56, Batch: 4,Loss: -2.051,Avg.Loss: -1.934,LR: 2.11E-04]Training epoch 56:   3%|▎         | 4/153 [00:00<00:03, 46.26it/s, Epoch: 56, Batch: 5,Loss: -2.265,Avg.Loss: -2.000,LR: 2.11E-04]Training epoch 56:   3%|▎         | 5/153 [00:00<00:03, 47.25it/s, Epoch: 56, Batch: 6,Loss: -2.194,Avg.Loss: -2.033,LR: 2.11E-04]Training epoch 56:   4%|▍         | 6/153 [00:00<00:02, 56.60it/s, Epoch: 56, Batch: 6,Loss: -2.194,Avg.Loss: -2.033,LR: 2.11E-04]Training epoch 56:   4%|▍         | 6/153 [00:00<00:02, 56.60it/s, Epoch: 56, Batch: 7,Loss: -2.428,Avg.Loss: -2.089,LR: 2.11E-04]Training epoch 56:   5%|▍         | 7/153 [00:00<00:02, 56.60it/s, Epoch: 56, Batch: 8,Loss: -2.302,Avg.Loss: -2.116,LR: 2.10E-04]Training epoch 56:   5%|▌         | 8/153 [00:00<00:02, 56.60it/s, Epoch: 56, Batch: 9,Loss: -1.777,Avg.Loss: -2.078,LR: 2.10E-04]Training epoch 56:   6%|▌         | 9/153 [00:00<00:02, 56.60it/s, Epoch: 56, Batch: 10,Loss: -2.443,Avg.Loss: -2.115,LR: 2.10E-04]Training epoch 56:   7%|▋         | 10/153 [00:00<00:02, 56.60it/s, Epoch: 56, Batch: 11,Loss: -2.661,Avg.Loss: -2.164,LR: 2.10E-04]Training epoch 56:   7%|▋         | 11/153 [00:00<00:02, 56.60it/s, Epoch: 56, Batch: 12,Loss: -2.305,Avg.Loss: -2.176,LR: 2.10E-04]Training epoch 56:   8%|▊         | 12/153 [00:00<00:02, 53.20it/s, Epoch: 56, Batch: 12,Loss: -2.305,Avg.Loss: -2.176,LR: 2.10E-04]Training epoch 56:   8%|▊         | 12/153 [00:00<00:02, 53.20it/s, Epoch: 56, Batch: 13,Loss: -1.972,Avg.Loss: -2.160,LR: 2.10E-04]Training epoch 56:   8%|▊         | 13/153 [00:00<00:02, 53.20it/s, Epoch: 56, Batch: 14,Loss: -2.127,Avg.Loss: -2.158,LR: 2.10E-04]Training epoch 56:   9%|▉         | 14/153 [00:00<00:02, 53.20it/s, Epoch: 56, Batch: 15,Loss: -2.340,Avg.Loss: -2.170,LR: 2.10E-04]Training epoch 56:  10%|▉         | 15/153 [00:00<00:02, 53.20it/s, Epoch: 56, Batch: 16,Loss: -1.533,Avg.Loss: -2.130,LR: 2.10E-04]Training epoch 56:  10%|█         | 16/153 [00:00<00:02, 53.20it/s, Epoch: 56, Batch: 17,Loss: -2.404,Avg.Loss: -2.146,LR: 2.10E-04]Training epoch 56:  11%|█         | 17/153 [00:00<00:02, 53.20it/s, Epoch: 56, Batch: 18,Loss: -2.188,Avg.Loss: -2.149,LR: 2.10E-04]Training epoch 56:  12%|█▏        | 18/153 [00:00<00:02, 52.99it/s, Epoch: 56, Batch: 18,Loss: -2.188,Avg.Loss: -2.149,LR: 2.10E-04]Training epoch 56:  12%|█▏        | 18/153 [00:00<00:02, 52.99it/s, Epoch: 56, Batch: 19,Loss: -2.396,Avg.Loss: -2.162,LR: 2.10E-04]Training epoch 56:  12%|█▏        | 19/153 [00:00<00:02, 52.99it/s, Epoch: 56, Batch: 20,Loss: -1.388,Avg.Loss: -2.123,LR: 2.10E-04]Training epoch 56:  13%|█▎        | 20/153 [00:00<00:02, 52.99it/s, Epoch: 56, Batch: 21,Loss: -1.347,Avg.Loss: -2.086,LR: 2.10E-04]Training epoch 56:  14%|█▎        | 21/153 [00:00<00:02, 52.99it/s, Epoch: 56, Batch: 22,Loss: -1.769,Avg.Loss: -2.072,LR: 2.10E-04]Training epoch 56:  14%|█▍        | 22/153 [00:00<00:02, 52.99it/s, Epoch: 56, Batch: 23,Loss: -2.060,Avg.Loss: -2.071,LR: 2.10E-04]Training epoch 56:  15%|█▌        | 23/153 [00:00<00:02, 52.99it/s, Epoch: 56, Batch: 24,Loss: -2.487,Avg.Loss: -2.088,LR: 2.10E-04]Training epoch 56:  16%|█▌        | 24/153 [00:00<00:02, 49.91it/s, Epoch: 56, Batch: 24,Loss: -2.487,Avg.Loss: -2.088,LR: 2.10E-04]Training epoch 56:  16%|█▌        | 24/153 [00:00<00:02, 49.91it/s, Epoch: 56, Batch: 25,Loss: -1.919,Avg.Loss: -2.082,LR: 2.10E-04]Training epoch 56:  16%|█▋        | 25/153 [00:00<00:02, 49.91it/s, Epoch: 56, Batch: 26,Loss: -1.639,Avg.Loss: -2.065,LR: 2.10E-04]Training epoch 56:  17%|█▋        | 26/153 [00:00<00:02, 49.91it/s, Epoch: 56, Batch: 27,Loss: -1.653,Avg.Loss: -2.049,LR: 2.10E-04]Training epoch 56:  18%|█▊        | 27/153 [00:00<00:02, 49.91it/s, Epoch: 56, Batch: 28,Loss: -2.830,Avg.Loss: -2.077,LR: 2.09E-04]Training epoch 56:  18%|█▊        | 28/153 [00:00<00:02, 49.91it/s, Epoch: 56, Batch: 29,Loss: -2.177,Avg.Loss: -2.081,LR: 2.09E-04]Training epoch 56:  19%|█▉        | 29/153 [00:00<00:02, 49.91it/s, Epoch: 56, Batch: 30,Loss: -2.251,Avg.Loss: -2.086,LR: 2.09E-04]Training epoch 56:  20%|█▉        | 30/153 [00:00<00:02, 50.64it/s, Epoch: 56, Batch: 30,Loss: -2.251,Avg.Loss: -2.086,LR: 2.09E-04]Training epoch 56:  20%|█▉        | 30/153 [00:00<00:02, 50.64it/s, Epoch: 56, Batch: 31,Loss: -2.206,Avg.Loss: -2.090,LR: 2.09E-04]Training epoch 56:  20%|██        | 31/153 [00:00<00:02, 50.64it/s, Epoch: 56, Batch: 32,Loss: -1.839,Avg.Loss: -2.082,LR: 2.09E-04]Training epoch 56:  21%|██        | 32/153 [00:00<00:02, 50.64it/s, Epoch: 56, Batch: 33,Loss: -2.230,Avg.Loss: -2.087,LR: 2.09E-04]Training epoch 56:  22%|██▏       | 33/153 [00:00<00:02, 50.64it/s, Epoch: 56, Batch: 34,Loss: -1.821,Avg.Loss: -2.079,LR: 2.09E-04]Training epoch 56:  22%|██▏       | 34/153 [00:00<00:02, 50.64it/s, Epoch: 56, Batch: 35,Loss: -2.125,Avg.Loss: -2.080,LR: 2.09E-04]Training epoch 56:  23%|██▎       | 35/153 [00:00<00:02, 50.64it/s, Epoch: 56, Batch: 36,Loss: -2.050,Avg.Loss: -2.079,LR: 2.09E-04]Training epoch 56:  24%|██▎       | 36/153 [00:00<00:02, 51.42it/s, Epoch: 56, Batch: 36,Loss: -2.050,Avg.Loss: -2.079,LR: 2.09E-04]Training epoch 56:  24%|██▎       | 36/153 [00:00<00:02, 51.42it/s, Epoch: 56, Batch: 37,Loss: -2.187,Avg.Loss: -2.082,LR: 2.09E-04]Training epoch 56:  24%|██▍       | 37/153 [00:00<00:02, 51.42it/s, Epoch: 56, Batch: 38,Loss: -2.392,Avg.Loss: -2.091,LR: 2.09E-04]Training epoch 56:  25%|██▍       | 38/153 [00:00<00:02, 51.42it/s, Epoch: 56, Batch: 39,Loss: -2.078,Avg.Loss: -2.090,LR: 2.09E-04]Training epoch 56:  25%|██▌       | 39/153 [00:00<00:02, 51.42it/s, Epoch: 56, Batch: 40,Loss: -2.383,Avg.Loss: -2.098,LR: 2.09E-04]Training epoch 56:  26%|██▌       | 40/153 [00:00<00:02, 51.42it/s, Epoch: 56, Batch: 41,Loss: -2.524,Avg.Loss: -2.108,LR: 2.09E-04]Training epoch 56:  27%|██▋       | 41/153 [00:00<00:02, 51.42it/s, Epoch: 56, Batch: 42,Loss: -2.528,Avg.Loss: -2.118,LR: 2.09E-04]Training epoch 56:  27%|██▋       | 42/153 [00:00<00:02, 52.03it/s, Epoch: 56, Batch: 42,Loss: -2.528,Avg.Loss: -2.118,LR: 2.09E-04]Training epoch 56:  27%|██▋       | 42/153 [00:00<00:02, 52.03it/s, Epoch: 56, Batch: 43,Loss: -2.642,Avg.Loss: -2.130,LR: 2.09E-04]Training epoch 56:  28%|██▊       | 43/153 [00:00<00:02, 52.03it/s, Epoch: 56, Batch: 44,Loss: -2.138,Avg.Loss: -2.130,LR: 2.09E-04]Training epoch 56:  29%|██▉       | 44/153 [00:00<00:02, 52.03it/s, Epoch: 56, Batch: 45,Loss: -2.133,Avg.Loss: -2.130,LR: 2.09E-04]Training epoch 56:  29%|██▉       | 45/153 [00:00<00:02, 52.03it/s, Epoch: 56, Batch: 46,Loss: -2.553,Avg.Loss: -2.140,LR: 2.09E-04]Training epoch 56:  30%|███       | 46/153 [00:00<00:02, 52.03it/s, Epoch: 56, Batch: 47,Loss: -2.283,Avg.Loss: -2.143,LR: 2.09E-04]Training epoch 56:  31%|███       | 47/153 [00:00<00:02, 52.03it/s, Epoch: 56, Batch: 48,Loss: -1.986,Avg.Loss: -2.139,LR: 2.08E-04]Training epoch 56:  31%|███▏      | 48/153 [00:00<00:02, 52.31it/s, Epoch: 56, Batch: 48,Loss: -1.986,Avg.Loss: -2.139,LR: 2.08E-04]Training epoch 56:  31%|███▏      | 48/153 [00:00<00:02, 52.31it/s, Epoch: 56, Batch: 49,Loss: -2.090,Avg.Loss: -2.138,LR: 2.08E-04]Training epoch 56:  32%|███▏      | 49/153 [00:00<00:01, 52.31it/s, Epoch: 56, Batch: 50,Loss: -2.497,Avg.Loss: -2.146,LR: 2.08E-04]Training epoch 56:  33%|███▎      | 50/153 [00:00<00:01, 52.31it/s, Epoch: 56, Batch: 51,Loss: -2.021,Avg.Loss: -2.143,LR: 2.08E-04]Training epoch 56:  33%|███▎      | 51/153 [00:00<00:01, 52.31it/s, Epoch: 56, Batch: 52,Loss: -2.070,Avg.Loss: -2.142,LR: 2.08E-04]Training epoch 56:  34%|███▍      | 52/153 [00:01<00:01, 52.31it/s, Epoch: 56, Batch: 53,Loss: -2.271,Avg.Loss: -2.144,LR: 2.08E-04]Training epoch 56:  35%|███▍      | 53/153 [00:01<00:01, 52.31it/s, Epoch: 56, Batch: 54,Loss: -2.382,Avg.Loss: -2.149,LR: 2.08E-04]Training epoch 56:  35%|███▌      | 54/153 [00:01<00:01, 52.64it/s, Epoch: 56, Batch: 54,Loss: -2.382,Avg.Loss: -2.149,LR: 2.08E-04]Training epoch 56:  35%|███▌      | 54/153 [00:01<00:01, 52.64it/s, Epoch: 56, Batch: 55,Loss: -2.530,Avg.Loss: -2.155,LR: 2.08E-04]Training epoch 56:  36%|███▌      | 55/153 [00:01<00:01, 52.64it/s, Epoch: 56, Batch: 56,Loss: -2.667,Avg.Loss: -2.165,LR: 2.08E-04]Training epoch 56:  37%|███▋      | 56/153 [00:01<00:01, 52.64it/s, Epoch: 56, Batch: 57,Loss: -2.681,Avg.Loss: -2.174,LR: 2.08E-04]Training epoch 56:  37%|███▋      | 57/153 [00:01<00:01, 52.64it/s, Epoch: 56, Batch: 58,Loss: -2.212,Avg.Loss: -2.174,LR: 2.08E-04]Training epoch 56:  38%|███▊      | 58/153 [00:01<00:01, 52.64it/s, Epoch: 56, Batch: 59,Loss: -2.512,Avg.Loss: -2.180,LR: 2.08E-04]Training epoch 56:  39%|███▊      | 59/153 [00:01<00:01, 52.64it/s, Epoch: 56, Batch: 60,Loss: -1.870,Avg.Loss: -2.175,LR: 2.08E-04]Training epoch 56:  39%|███▉      | 60/153 [00:01<00:01, 52.69it/s, Epoch: 56, Batch: 60,Loss: -1.870,Avg.Loss: -2.175,LR: 2.08E-04]Training epoch 56:  39%|███▉      | 60/153 [00:01<00:01, 52.69it/s, Epoch: 56, Batch: 61,Loss: -1.647,Avg.Loss: -2.166,LR: 2.08E-04]Training epoch 56:  40%|███▉      | 61/153 [00:01<00:01, 52.69it/s, Epoch: 56, Batch: 62,Loss: -2.475,Avg.Loss: -2.171,LR: 2.08E-04]Training epoch 56:  41%|████      | 62/153 [00:01<00:01, 52.69it/s, Epoch: 56, Batch: 63,Loss: -2.520,Avg.Loss: -2.177,LR: 2.08E-04]Training epoch 56:  41%|████      | 63/153 [00:01<00:01, 52.69it/s, Epoch: 56, Batch: 64,Loss: -2.775,Avg.Loss: -2.186,LR: 2.08E-04]Training epoch 56:  42%|████▏     | 64/153 [00:01<00:01, 52.69it/s, Epoch: 56, Batch: 65,Loss: -2.505,Avg.Loss: -2.191,LR: 2.08E-04]Training epoch 56:  42%|████▏     | 65/153 [00:01<00:01, 52.69it/s, Epoch: 56, Batch: 66,Loss: -2.502,Avg.Loss: -2.196,LR: 2.08E-04]Training epoch 56:  43%|████▎     | 66/153 [00:01<00:01, 52.54it/s, Epoch: 56, Batch: 66,Loss: -2.502,Avg.Loss: -2.196,LR: 2.08E-04]Training epoch 56:  43%|████▎     | 66/153 [00:01<00:01, 52.54it/s, Epoch: 56, Batch: 67,Loss: -2.487,Avg.Loss: -2.200,LR: 2.07E-04]Training epoch 56:  44%|████▍     | 67/153 [00:01<00:01, 52.54it/s, Epoch: 56, Batch: 68,Loss: -2.440,Avg.Loss: -2.204,LR: 2.07E-04]Training epoch 56:  44%|████▍     | 68/153 [00:01<00:01, 52.54it/s, Epoch: 56, Batch: 69,Loss: -2.726,Avg.Loss: -2.211,LR: 2.07E-04]Training epoch 56:  45%|████▌     | 69/153 [00:01<00:01, 52.54it/s, Epoch: 56, Batch: 70,Loss: -2.308,Avg.Loss: -2.213,LR: 2.07E-04]Training epoch 56:  46%|████▌     | 70/153 [00:01<00:01, 52.54it/s, Epoch: 56, Batch: 71,Loss: -2.080,Avg.Loss: -2.211,LR: 2.07E-04]Training epoch 56:  46%|████▋     | 71/153 [00:01<00:01, 52.54it/s, Epoch: 56, Batch: 72,Loss: -1.946,Avg.Loss: -2.207,LR: 2.07E-04]Training epoch 56:  47%|████▋     | 72/153 [00:01<00:01, 52.60it/s, Epoch: 56, Batch: 72,Loss: -1.946,Avg.Loss: -2.207,LR: 2.07E-04]Training epoch 56:  47%|████▋     | 72/153 [00:01<00:01, 52.60it/s, Epoch: 56, Batch: 73,Loss: -2.426,Avg.Loss: -2.210,LR: 2.07E-04]Training epoch 56:  48%|████▊     | 73/153 [00:01<00:01, 52.60it/s, Epoch: 56, Batch: 74,Loss: -2.164,Avg.Loss: -2.209,LR: 2.07E-04]Training epoch 56:  48%|████▊     | 74/153 [00:01<00:01, 52.60it/s, Epoch: 56, Batch: 75,Loss: -2.759,Avg.Loss: -2.217,LR: 2.07E-04]Training epoch 56:  49%|████▉     | 75/153 [00:01<00:01, 52.60it/s, Epoch: 56, Batch: 76,Loss: -2.926,Avg.Loss: -2.226,LR: 2.07E-04]Training epoch 56:  50%|████▉     | 76/153 [00:01<00:01, 52.60it/s, Epoch: 56, Batch: 77,Loss: -2.691,Avg.Loss: -2.232,LR: 2.07E-04]Training epoch 56:  50%|█████     | 77/153 [00:01<00:01, 52.60it/s, Epoch: 56, Batch: 78,Loss: -2.272,Avg.Loss: -2.233,LR: 2.07E-04]Training epoch 56:  51%|█████     | 78/153 [00:01<00:01, 52.65it/s, Epoch: 56, Batch: 78,Loss: -2.272,Avg.Loss: -2.233,LR: 2.07E-04]Training epoch 56:  51%|█████     | 78/153 [00:01<00:01, 52.65it/s, Epoch: 56, Batch: 79,Loss: -1.733,Avg.Loss: -2.226,LR: 2.07E-04]Training epoch 56:  52%|█████▏    | 79/153 [00:01<00:01, 52.65it/s, Epoch: 56, Batch: 80,Loss: -2.570,Avg.Loss: -2.231,LR: 2.07E-04]Training epoch 56:  52%|█████▏    | 80/153 [00:01<00:01, 52.65it/s, Epoch: 56, Batch: 81,Loss: -2.292,Avg.Loss: -2.231,LR: 2.07E-04]Training epoch 56:  53%|█████▎    | 81/153 [00:01<00:01, 52.65it/s, Epoch: 56, Batch: 82,Loss: -2.263,Avg.Loss: -2.232,LR: 2.07E-04]Training epoch 56:  54%|█████▎    | 82/153 [00:01<00:01, 52.65it/s, Epoch: 56, Batch: 83,Loss: -2.451,Avg.Loss: -2.234,LR: 2.07E-04]Training epoch 56:  54%|█████▍    | 83/153 [00:01<00:01, 52.65it/s, Epoch: 56, Batch: 84,Loss: -2.310,Avg.Loss: -2.235,LR: 2.07E-04]Training epoch 56:  55%|█████▍    | 84/153 [00:01<00:01, 52.78it/s, Epoch: 56, Batch: 84,Loss: -2.310,Avg.Loss: -2.235,LR: 2.07E-04]Training epoch 56:  55%|█████▍    | 84/153 [00:01<00:01, 52.78it/s, Epoch: 56, Batch: 85,Loss: -2.060,Avg.Loss: -2.233,LR: 2.07E-04]Training epoch 56:  56%|█████▌    | 85/153 [00:01<00:01, 52.78it/s, Epoch: 56, Batch: 86,Loss: -2.744,Avg.Loss: -2.239,LR: 2.07E-04]Training epoch 56:  56%|█████▌    | 86/153 [00:01<00:01, 52.78it/s, Epoch: 56, Batch: 87,Loss: -2.546,Avg.Loss: -2.243,LR: 2.06E-04]Training epoch 56:  57%|█████▋    | 87/153 [00:01<00:01, 52.78it/s, Epoch: 56, Batch: 88,Loss: -2.086,Avg.Loss: -2.241,LR: 2.06E-04]Training epoch 56:  58%|█████▊    | 88/153 [00:01<00:01, 52.78it/s, Epoch: 56, Batch: 89,Loss: -1.891,Avg.Loss: -2.237,LR: 2.06E-04]Training epoch 56:  58%|█████▊    | 89/153 [00:01<00:01, 52.78it/s, Epoch: 56, Batch: 90,Loss: -2.870,Avg.Loss: -2.244,LR: 2.06E-04]Training epoch 56:  59%|█████▉    | 90/153 [00:01<00:01, 52.77it/s, Epoch: 56, Batch: 90,Loss: -2.870,Avg.Loss: -2.244,LR: 2.06E-04]Training epoch 56:  59%|█████▉    | 90/153 [00:01<00:01, 52.77it/s, Epoch: 56, Batch: 91,Loss: -2.512,Avg.Loss: -2.247,LR: 2.06E-04]Training epoch 56:  59%|█████▉    | 91/153 [00:01<00:01, 52.77it/s, Epoch: 56, Batch: 92,Loss: -2.328,Avg.Loss: -2.248,LR: 2.06E-04]Training epoch 56:  60%|██████    | 92/153 [00:01<00:01, 52.77it/s, Epoch: 56, Batch: 93,Loss: -1.995,Avg.Loss: -2.245,LR: 2.06E-04]Training epoch 56:  61%|██████    | 93/153 [00:01<00:01, 52.77it/s, Epoch: 56, Batch: 94,Loss: -2.151,Avg.Loss: -2.244,LR: 2.06E-04]Training epoch 56:  61%|██████▏   | 94/153 [00:01<00:01, 52.77it/s, Epoch: 56, Batch: 95,Loss: -2.552,Avg.Loss: -2.247,LR: 2.06E-04]Training epoch 56:  62%|██████▏   | 95/153 [00:01<00:01, 52.77it/s, Epoch: 56, Batch: 96,Loss: -2.137,Avg.Loss: -2.246,LR: 2.06E-04]Training epoch 56:  63%|██████▎   | 96/153 [00:01<00:01, 52.76it/s, Epoch: 56, Batch: 96,Loss: -2.137,Avg.Loss: -2.246,LR: 2.06E-04]Training epoch 56:  63%|██████▎   | 96/153 [00:01<00:01, 52.76it/s, Epoch: 56, Batch: 97,Loss: -2.359,Avg.Loss: -2.247,LR: 2.06E-04]Training epoch 56:  63%|██████▎   | 97/153 [00:01<00:01, 52.76it/s, Epoch: 56, Batch: 98,Loss: -2.358,Avg.Loss: -2.248,LR: 2.06E-04]Training epoch 56:  64%|██████▍   | 98/153 [00:01<00:01, 52.76it/s, Epoch: 56, Batch: 99,Loss: -2.428,Avg.Loss: -2.250,LR: 2.06E-04]Training epoch 56:  65%|██████▍   | 99/153 [00:01<00:01, 52.76it/s, Epoch: 56, Batch: 100,Loss: -2.486,Avg.Loss: -2.253,LR: 2.06E-04]Training epoch 56:  65%|██████▌   | 100/153 [00:01<00:01, 52.76it/s, Epoch: 56, Batch: 101,Loss: -2.153,Avg.Loss: -2.252,LR: 2.06E-04]Training epoch 56:  66%|██████▌   | 101/153 [00:01<00:00, 52.76it/s, Epoch: 56, Batch: 102,Loss: -2.600,Avg.Loss: -2.255,LR: 2.06E-04]Training epoch 56:  67%|██████▋   | 102/153 [00:01<00:00, 52.36it/s, Epoch: 56, Batch: 102,Loss: -2.600,Avg.Loss: -2.255,LR: 2.06E-04]Training epoch 56:  67%|██████▋   | 102/153 [00:01<00:00, 52.36it/s, Epoch: 56, Batch: 103,Loss: -2.427,Avg.Loss: -2.257,LR: 2.06E-04]Training epoch 56:  67%|██████▋   | 103/153 [00:01<00:00, 52.36it/s, Epoch: 56, Batch: 104,Loss: -2.644,Avg.Loss: -2.260,LR: 2.06E-04]Training epoch 56:  68%|██████▊   | 104/153 [00:02<00:00, 52.36it/s, Epoch: 56, Batch: 105,Loss: -2.532,Avg.Loss: -2.263,LR: 2.06E-04]Training epoch 56:  69%|██████▊   | 105/153 [00:02<00:00, 52.36it/s, Epoch: 56, Batch: 106,Loss: -2.552,Avg.Loss: -2.266,LR: 2.06E-04]Training epoch 56:  69%|██████▉   | 106/153 [00:02<00:00, 52.36it/s, Epoch: 56, Batch: 107,Loss: -2.289,Avg.Loss: -2.266,LR: 2.05E-04]Training epoch 56:  70%|██████▉   | 107/153 [00:02<00:00, 52.36it/s, Epoch: 56, Batch: 108,Loss: -2.542,Avg.Loss: -2.269,LR: 2.05E-04]Training epoch 56:  71%|███████   | 108/153 [00:02<00:00, 52.32it/s, Epoch: 56, Batch: 108,Loss: -2.542,Avg.Loss: -2.269,LR: 2.05E-04]Training epoch 56:  71%|███████   | 108/153 [00:02<00:00, 52.32it/s, Epoch: 56, Batch: 109,Loss: -2.935,Avg.Loss: -2.275,LR: 2.05E-04]Training epoch 56:  71%|███████   | 109/153 [00:02<00:00, 52.32it/s, Epoch: 56, Batch: 110,Loss: -2.379,Avg.Loss: -2.276,LR: 2.05E-04]Training epoch 56:  72%|███████▏  | 110/153 [00:02<00:00, 52.32it/s, Epoch: 56, Batch: 111,Loss: -2.074,Avg.Loss: -2.274,LR: 2.05E-04]Training epoch 56:  73%|███████▎  | 111/153 [00:02<00:00, 52.32it/s, Epoch: 56, Batch: 112,Loss: -2.226,Avg.Loss: -2.273,LR: 2.05E-04]Training epoch 56:  73%|███████▎  | 112/153 [00:02<00:00, 52.32it/s, Epoch: 56, Batch: 113,Loss: -2.162,Avg.Loss: -2.272,LR: 2.05E-04]Training epoch 56:  74%|███████▍  | 113/153 [00:02<00:00, 52.32it/s, Epoch: 56, Batch: 114,Loss: -3.049,Avg.Loss: -2.279,LR: 2.05E-04]Training epoch 56:  75%|███████▍  | 114/153 [00:02<00:00, 52.59it/s, Epoch: 56, Batch: 114,Loss: -3.049,Avg.Loss: -2.279,LR: 2.05E-04]Training epoch 56:  75%|███████▍  | 114/153 [00:02<00:00, 52.59it/s, Epoch: 56, Batch: 115,Loss: -2.201,Avg.Loss: -2.279,LR: 2.05E-04]Training epoch 56:  75%|███████▌  | 115/153 [00:02<00:00, 52.59it/s, Epoch: 56, Batch: 116,Loss: -2.983,Avg.Loss: -2.285,LR: 2.05E-04]Training epoch 56:  76%|███████▌  | 116/153 [00:02<00:00, 52.59it/s, Epoch: 56, Batch: 117,Loss: -3.069,Avg.Loss: -2.291,LR: 2.05E-04]Training epoch 56:  76%|███████▋  | 117/153 [00:02<00:00, 52.59it/s, Epoch: 56, Batch: 118,Loss: -2.758,Avg.Loss: -2.295,LR: 2.05E-04]Training epoch 56:  77%|███████▋  | 118/153 [00:02<00:00, 52.59it/s, Epoch: 56, Batch: 119,Loss: -2.641,Avg.Loss: -2.298,LR: 2.05E-04]Training epoch 56:  78%|███████▊  | 119/153 [00:02<00:00, 52.59it/s, Epoch: 56, Batch: 120,Loss: -2.458,Avg.Loss: -2.299,LR: 2.05E-04]Training epoch 56:  78%|███████▊  | 120/153 [00:02<00:00, 52.65it/s, Epoch: 56, Batch: 120,Loss: -2.458,Avg.Loss: -2.299,LR: 2.05E-04]Training epoch 56:  78%|███████▊  | 120/153 [00:02<00:00, 52.65it/s, Epoch: 56, Batch: 121,Loss: -1.966,Avg.Loss: -2.297,LR: 2.05E-04]Training epoch 56:  79%|███████▉  | 121/153 [00:02<00:00, 52.65it/s, Epoch: 56, Batch: 122,Loss: -2.794,Avg.Loss: -2.301,LR: 2.05E-04]Training epoch 56:  80%|███████▉  | 122/153 [00:02<00:00, 52.65it/s, Epoch: 56, Batch: 123,Loss: -2.611,Avg.Loss: -2.303,LR: 2.05E-04]Training epoch 56:  80%|████████  | 123/153 [00:02<00:00, 52.65it/s, Epoch: 56, Batch: 124,Loss: -2.822,Avg.Loss: -2.308,LR: 2.05E-04]Training epoch 56:  81%|████████  | 124/153 [00:02<00:00, 52.65it/s, Epoch: 56, Batch: 125,Loss: -2.506,Avg.Loss: -2.309,LR: 2.05E-04]Training epoch 56:  82%|████████▏ | 125/153 [00:02<00:00, 52.65it/s, Epoch: 56, Batch: 126,Loss: -2.501,Avg.Loss: -2.311,LR: 2.05E-04]Training epoch 56:  82%|████████▏ | 126/153 [00:02<00:00, 52.60it/s, Epoch: 56, Batch: 126,Loss: -2.501,Avg.Loss: -2.311,LR: 2.05E-04]Training epoch 56:  82%|████████▏ | 126/153 [00:02<00:00, 52.60it/s, Epoch: 56, Batch: 127,Loss: -1.475,Avg.Loss: -2.304,LR: 2.04E-04]Training epoch 56:  83%|████████▎ | 127/153 [00:02<00:00, 52.60it/s, Epoch: 56, Batch: 128,Loss: -1.673,Avg.Loss: -2.299,LR: 2.04E-04]Training epoch 56:  84%|████████▎ | 128/153 [00:02<00:00, 52.60it/s, Epoch: 56, Batch: 129,Loss: -0.880,Avg.Loss: -2.288,LR: 2.04E-04]Training epoch 56:  84%|████████▍ | 129/153 [00:02<00:00, 52.60it/s, Epoch: 56, Batch: 130,Loss: -1.426,Avg.Loss: -2.281,LR: 2.04E-04]Training epoch 56:  85%|████████▍ | 130/153 [00:02<00:00, 52.60it/s, Epoch: 56, Batch: 131,Loss: -2.341,Avg.Loss: -2.282,LR: 2.04E-04]Training epoch 56:  86%|████████▌ | 131/153 [00:02<00:00, 52.60it/s, Epoch: 56, Batch: 132,Loss: -2.484,Avg.Loss: -2.283,LR: 2.04E-04]Training epoch 56:  86%|████████▋ | 132/153 [00:02<00:00, 52.91it/s, Epoch: 56, Batch: 132,Loss: -2.484,Avg.Loss: -2.283,LR: 2.04E-04]Training epoch 56:  86%|████████▋ | 132/153 [00:02<00:00, 52.91it/s, Epoch: 56, Batch: 133,Loss: -1.905,Avg.Loss: -2.281,LR: 2.04E-04]Training epoch 56:  87%|████████▋ | 133/153 [00:02<00:00, 52.91it/s, Epoch: 56, Batch: 134,Loss: -1.818,Avg.Loss: -2.277,LR: 2.04E-04]Training epoch 56:  88%|████████▊ | 134/153 [00:02<00:00, 52.91it/s, Epoch: 56, Batch: 135,Loss: -2.048,Avg.Loss: -2.275,LR: 2.04E-04]Training epoch 56:  88%|████████▊ | 135/153 [00:02<00:00, 52.91it/s, Epoch: 56, Batch: 136,Loss: -2.598,Avg.Loss: -2.278,LR: 2.04E-04]Training epoch 56:  89%|████████▉ | 136/153 [00:02<00:00, 52.91it/s, Epoch: 56, Batch: 137,Loss: -2.694,Avg.Loss: -2.281,LR: 2.04E-04]Training epoch 56:  90%|████████▉ | 137/153 [00:02<00:00, 52.91it/s, Epoch: 56, Batch: 138,Loss: -2.342,Avg.Loss: -2.281,LR: 2.04E-04]Training epoch 56:  90%|█████████ | 138/153 [00:02<00:00, 52.85it/s, Epoch: 56, Batch: 138,Loss: -2.342,Avg.Loss: -2.281,LR: 2.04E-04]Training epoch 56:  90%|█████████ | 138/153 [00:02<00:00, 52.85it/s, Epoch: 56, Batch: 139,Loss: -2.747,Avg.Loss: -2.285,LR: 2.04E-04]Training epoch 56:  91%|█████████ | 139/153 [00:02<00:00, 52.85it/s, Epoch: 56, Batch: 140,Loss: -2.041,Avg.Loss: -2.283,LR: 2.04E-04]Training epoch 56:  92%|█████████▏| 140/153 [00:02<00:00, 52.85it/s, Epoch: 56, Batch: 141,Loss: -2.154,Avg.Loss: -2.282,LR: 2.04E-04]Training epoch 56:  92%|█████████▏| 141/153 [00:02<00:00, 52.85it/s, Epoch: 56, Batch: 142,Loss: -2.003,Avg.Loss: -2.280,LR: 2.04E-04]Training epoch 56:  93%|█████████▎| 142/153 [00:02<00:00, 52.85it/s, Epoch: 56, Batch: 143,Loss: -1.631,Avg.Loss: -2.276,LR: 2.04E-04]Training epoch 56:  93%|█████████▎| 143/153 [00:02<00:00, 52.85it/s, Epoch: 56, Batch: 144,Loss: -2.267,Avg.Loss: -2.275,LR: 2.04E-04]Training epoch 56:  94%|█████████▍| 144/153 [00:02<00:00, 52.84it/s, Epoch: 56, Batch: 144,Loss: -2.267,Avg.Loss: -2.275,LR: 2.04E-04]Training epoch 56:  94%|█████████▍| 144/153 [00:02<00:00, 52.84it/s, Epoch: 56, Batch: 145,Loss: -2.145,Avg.Loss: -2.275,LR: 2.04E-04]Training epoch 56:  95%|█████████▍| 145/153 [00:02<00:00, 52.84it/s, Epoch: 56, Batch: 146,Loss: -2.565,Avg.Loss: -2.277,LR: 2.04E-04]Training epoch 56:  95%|█████████▌| 146/153 [00:02<00:00, 52.84it/s, Epoch: 56, Batch: 147,Loss: -2.922,Avg.Loss: -2.281,LR: 2.03E-04]Training epoch 56:  96%|█████████▌| 147/153 [00:02<00:00, 52.84it/s, Epoch: 56, Batch: 148,Loss: -2.835,Avg.Loss: -2.285,LR: 2.03E-04]Training epoch 56:  97%|█████████▋| 148/153 [00:02<00:00, 52.84it/s, Epoch: 56, Batch: 149,Loss: -2.308,Avg.Loss: -2.285,LR: 2.03E-04]Training epoch 56:  97%|█████████▋| 149/153 [00:02<00:00, 52.84it/s, Epoch: 56, Batch: 150,Loss: -2.338,Avg.Loss: -2.285,LR: 2.03E-04]Training epoch 56:  98%|█████████▊| 150/153 [00:02<00:00, 53.01it/s, Epoch: 56, Batch: 150,Loss: -2.338,Avg.Loss: -2.285,LR: 2.03E-04]Training epoch 56:  98%|█████████▊| 150/153 [00:02<00:00, 53.01it/s, Epoch: 56, Batch: 151,Loss: -1.786,Avg.Loss: -2.282,LR: 2.03E-04]Training epoch 56:  99%|█████████▊| 151/153 [00:02<00:00, 53.01it/s, Epoch: 56, Batch: 152,Loss: -1.667,Avg.Loss: -2.278,LR: 2.03E-04]Training epoch 56:  99%|█████████▉| 152/153 [00:02<00:00, 53.01it/s, Epoch: 56, Batch: 153,Loss: -1.983,Avg.Loss: -2.276,LR: 2.03E-04]Training epoch 56: 100%|██████████| 153/153 [00:02<00:00, 52.46it/s, Epoch: 56, Batch: 153,Loss: -1.983,Avg.Loss: -2.276,LR: 2.03E-04]
Training epoch 57:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 57:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 57, Batch: 1,Loss: -2.426,Avg.Loss: -2.426,LR: 2.03E-04]Training epoch 57:   1%|          | 1/153 [00:00<00:06, 24.50it/s, Epoch: 57, Batch: 2,Loss: -2.107,Avg.Loss: -2.266,LR: 2.03E-04]Training epoch 57:   1%|▏         | 2/153 [00:00<00:04, 34.08it/s, Epoch: 57, Batch: 3,Loss: -1.097,Avg.Loss: -1.877,LR: 2.03E-04]Training epoch 57:   2%|▏         | 3/153 [00:00<00:03, 39.19it/s, Epoch: 57, Batch: 4,Loss: -1.679,Avg.Loss: -1.827,LR: 2.03E-04]Training epoch 57:   3%|▎         | 4/153 [00:00<00:03, 42.57it/s, Epoch: 57, Batch: 5,Loss: -2.429,Avg.Loss: -1.947,LR: 2.03E-04]Training epoch 57:   3%|▎         | 5/153 [00:00<00:03, 44.19it/s, Epoch: 57, Batch: 6,Loss: -2.357,Avg.Loss: -2.016,LR: 2.03E-04]Training epoch 57:   4%|▍         | 6/153 [00:00<00:02, 52.94it/s, Epoch: 57, Batch: 6,Loss: -2.357,Avg.Loss: -2.016,LR: 2.03E-04]Training epoch 57:   4%|▍         | 6/153 [00:00<00:02, 52.94it/s, Epoch: 57, Batch: 7,Loss: -2.024,Avg.Loss: -2.017,LR: 2.03E-04]Training epoch 57:   5%|▍         | 7/153 [00:00<00:02, 52.94it/s, Epoch: 57, Batch: 8,Loss: -1.414,Avg.Loss: -1.942,LR: 2.03E-04]Training epoch 57:   5%|▌         | 8/153 [00:00<00:02, 52.94it/s, Epoch: 57, Batch: 9,Loss: -1.922,Avg.Loss: -1.939,LR: 2.03E-04]Training epoch 57:   6%|▌         | 9/153 [00:00<00:02, 52.94it/s, Epoch: 57, Batch: 10,Loss: -2.445,Avg.Loss: -1.990,LR: 2.03E-04]Training epoch 57:   7%|▋         | 10/153 [00:00<00:02, 52.94it/s, Epoch: 57, Batch: 11,Loss: -1.367,Avg.Loss: -1.933,LR: 2.03E-04]Training epoch 57:   7%|▋         | 11/153 [00:00<00:02, 52.94it/s, Epoch: 57, Batch: 12,Loss: -1.684,Avg.Loss: -1.912,LR: 2.03E-04]Training epoch 57:   8%|▊         | 12/153 [00:00<00:02, 53.17it/s, Epoch: 57, Batch: 12,Loss: -1.684,Avg.Loss: -1.912,LR: 2.03E-04]Training epoch 57:   8%|▊         | 12/153 [00:00<00:02, 53.17it/s, Epoch: 57, Batch: 13,Loss: -2.407,Avg.Loss: -1.951,LR: 2.02E-04]Training epoch 57:   8%|▊         | 13/153 [00:00<00:02, 53.17it/s, Epoch: 57, Batch: 14,Loss: -2.180,Avg.Loss: -1.967,LR: 2.02E-04]Training epoch 57:   9%|▉         | 14/153 [00:00<00:02, 53.17it/s, Epoch: 57, Batch: 15,Loss: -2.737,Avg.Loss: -2.018,LR: 2.02E-04]Training epoch 57:  10%|▉         | 15/153 [00:00<00:02, 53.17it/s, Epoch: 57, Batch: 16,Loss: -2.198,Avg.Loss: -2.030,LR: 2.02E-04]Training epoch 57:  10%|█         | 16/153 [00:00<00:02, 53.17it/s, Epoch: 57, Batch: 17,Loss: -2.428,Avg.Loss: -2.053,LR: 2.02E-04]Training epoch 57:  11%|█         | 17/153 [00:00<00:02, 53.17it/s, Epoch: 57, Batch: 18,Loss: -2.108,Avg.Loss: -2.056,LR: 2.02E-04]Training epoch 57:  12%|█▏        | 18/153 [00:00<00:02, 53.16it/s, Epoch: 57, Batch: 18,Loss: -2.108,Avg.Loss: -2.056,LR: 2.02E-04]Training epoch 57:  12%|█▏        | 18/153 [00:00<00:02, 53.16it/s, Epoch: 57, Batch: 19,Loss: -2.001,Avg.Loss: -2.053,LR: 2.02E-04]Training epoch 57:  12%|█▏        | 19/153 [00:00<00:02, 53.16it/s, Epoch: 57, Batch: 20,Loss: -2.151,Avg.Loss: -2.058,LR: 2.02E-04]Training epoch 57:  13%|█▎        | 20/153 [00:00<00:02, 53.16it/s, Epoch: 57, Batch: 21,Loss: -2.927,Avg.Loss: -2.099,LR: 2.02E-04]Training epoch 57:  14%|█▎        | 21/153 [00:00<00:02, 53.16it/s, Epoch: 57, Batch: 22,Loss: -2.165,Avg.Loss: -2.102,LR: 2.02E-04]Training epoch 57:  14%|█▍        | 22/153 [00:00<00:02, 53.16it/s, Epoch: 57, Batch: 23,Loss: -1.813,Avg.Loss: -2.090,LR: 2.02E-04]Training epoch 57:  15%|█▌        | 23/153 [00:00<00:02, 53.16it/s, Epoch: 57, Batch: 24,Loss: -1.560,Avg.Loss: -2.068,LR: 2.02E-04]Training epoch 57:  16%|█▌        | 24/153 [00:00<00:02, 52.79it/s, Epoch: 57, Batch: 24,Loss: -1.560,Avg.Loss: -2.068,LR: 2.02E-04]Training epoch 57:  16%|█▌        | 24/153 [00:00<00:02, 52.79it/s, Epoch: 57, Batch: 25,Loss: -1.857,Avg.Loss: -2.059,LR: 2.02E-04]Training epoch 57:  16%|█▋        | 25/153 [00:00<00:02, 52.79it/s, Epoch: 57, Batch: 26,Loss: -2.366,Avg.Loss: -2.071,LR: 2.02E-04]Training epoch 57:  17%|█▋        | 26/153 [00:00<00:02, 52.79it/s, Epoch: 57, Batch: 27,Loss: -2.243,Avg.Loss: -2.077,LR: 2.02E-04]Training epoch 57:  18%|█▊        | 27/153 [00:00<00:02, 52.79it/s, Epoch: 57, Batch: 28,Loss: -2.232,Avg.Loss: -2.083,LR: 2.02E-04]Training epoch 57:  18%|█▊        | 28/153 [00:00<00:02, 52.79it/s, Epoch: 57, Batch: 29,Loss: -2.517,Avg.Loss: -2.098,LR: 2.02E-04]Training epoch 57:  19%|█▉        | 29/153 [00:00<00:02, 52.79it/s, Epoch: 57, Batch: 30,Loss: -2.179,Avg.Loss: -2.101,LR: 2.02E-04]Training epoch 57:  20%|█▉        | 30/153 [00:00<00:02, 52.54it/s, Epoch: 57, Batch: 30,Loss: -2.179,Avg.Loss: -2.101,LR: 2.02E-04]Training epoch 57:  20%|█▉        | 30/153 [00:00<00:02, 52.54it/s, Epoch: 57, Batch: 31,Loss: -2.247,Avg.Loss: -2.105,LR: 2.02E-04]Training epoch 57:  20%|██        | 31/153 [00:00<00:02, 52.54it/s, Epoch: 57, Batch: 32,Loss: -1.990,Avg.Loss: -2.102,LR: 2.02E-04]Training epoch 57:  21%|██        | 32/153 [00:00<00:02, 52.54it/s, Epoch: 57, Batch: 33,Loss: -2.753,Avg.Loss: -2.121,LR: 2.01E-04]Training epoch 57:  22%|██▏       | 33/153 [00:00<00:02, 52.54it/s, Epoch: 57, Batch: 34,Loss: -2.159,Avg.Loss: -2.123,LR: 2.01E-04]Training epoch 57:  22%|██▏       | 34/153 [00:00<00:02, 52.54it/s, Epoch: 57, Batch: 35,Loss: -1.711,Avg.Loss: -2.111,LR: 2.01E-04]Training epoch 57:  23%|██▎       | 35/153 [00:00<00:02, 52.54it/s, Epoch: 57, Batch: 36,Loss: -2.133,Avg.Loss: -2.111,LR: 2.01E-04]Training epoch 57:  24%|██▎       | 36/153 [00:00<00:02, 52.66it/s, Epoch: 57, Batch: 36,Loss: -2.133,Avg.Loss: -2.111,LR: 2.01E-04]Training epoch 57:  24%|██▎       | 36/153 [00:00<00:02, 52.66it/s, Epoch: 57, Batch: 37,Loss: -2.717,Avg.Loss: -2.128,LR: 2.01E-04]Training epoch 57:  24%|██▍       | 37/153 [00:00<00:02, 52.66it/s, Epoch: 57, Batch: 38,Loss: -2.679,Avg.Loss: -2.142,LR: 2.01E-04]Training epoch 57:  25%|██▍       | 38/153 [00:00<00:02, 52.66it/s, Epoch: 57, Batch: 39,Loss: -2.490,Avg.Loss: -2.151,LR: 2.01E-04]Training epoch 57:  25%|██▌       | 39/153 [00:00<00:02, 52.66it/s, Epoch: 57, Batch: 40,Loss: -2.345,Avg.Loss: -2.156,LR: 2.01E-04]Training epoch 57:  26%|██▌       | 40/153 [00:00<00:02, 52.66it/s, Epoch: 57, Batch: 41,Loss: -2.195,Avg.Loss: -2.157,LR: 2.01E-04]Training epoch 57:  27%|██▋       | 41/153 [00:00<00:02, 52.66it/s, Epoch: 57, Batch: 42,Loss: -2.587,Avg.Loss: -2.167,LR: 2.01E-04]Training epoch 57:  27%|██▋       | 42/153 [00:00<00:02, 52.28it/s, Epoch: 57, Batch: 42,Loss: -2.587,Avg.Loss: -2.167,LR: 2.01E-04]Training epoch 57:  27%|██▋       | 42/153 [00:00<00:02, 52.28it/s, Epoch: 57, Batch: 43,Loss: -3.009,Avg.Loss: -2.187,LR: 2.01E-04]Training epoch 57:  28%|██▊       | 43/153 [00:00<00:02, 52.28it/s, Epoch: 57, Batch: 44,Loss: -2.818,Avg.Loss: -2.201,LR: 2.01E-04]Training epoch 57:  29%|██▉       | 44/153 [00:00<00:02, 52.28it/s, Epoch: 57, Batch: 45,Loss: -2.776,Avg.Loss: -2.214,LR: 2.01E-04]Training epoch 57:  29%|██▉       | 45/153 [00:00<00:02, 52.28it/s, Epoch: 57, Batch: 46,Loss: -2.637,Avg.Loss: -2.223,LR: 2.01E-04]Training epoch 57:  30%|███       | 46/153 [00:00<00:02, 52.28it/s, Epoch: 57, Batch: 47,Loss: -2.868,Avg.Loss: -2.237,LR: 2.01E-04]Training epoch 57:  31%|███       | 47/153 [00:00<00:02, 52.28it/s, Epoch: 57, Batch: 48,Loss: -2.593,Avg.Loss: -2.244,LR: 2.01E-04]Training epoch 57:  31%|███▏      | 48/153 [00:00<00:02, 52.46it/s, Epoch: 57, Batch: 48,Loss: -2.593,Avg.Loss: -2.244,LR: 2.01E-04]Training epoch 57:  31%|███▏      | 48/153 [00:00<00:02, 52.46it/s, Epoch: 57, Batch: 49,Loss: -2.468,Avg.Loss: -2.249,LR: 2.01E-04]Training epoch 57:  32%|███▏      | 49/153 [00:00<00:01, 52.46it/s, Epoch: 57, Batch: 50,Loss: -2.759,Avg.Loss: -2.259,LR: 2.01E-04]Training epoch 57:  33%|███▎      | 50/153 [00:00<00:01, 52.46it/s, Epoch: 57, Batch: 51,Loss: -2.668,Avg.Loss: -2.267,LR: 2.01E-04]Training epoch 57:  33%|███▎      | 51/153 [00:00<00:01, 52.46it/s, Epoch: 57, Batch: 52,Loss: -2.667,Avg.Loss: -2.275,LR: 2.01E-04]Training epoch 57:  34%|███▍      | 52/153 [00:01<00:01, 52.46it/s, Epoch: 57, Batch: 53,Loss: -2.546,Avg.Loss: -2.280,LR: 2.00E-04]Training epoch 57:  35%|███▍      | 53/153 [00:01<00:01, 52.46it/s, Epoch: 57, Batch: 54,Loss: -2.633,Avg.Loss: -2.286,LR: 2.00E-04]Training epoch 57:  35%|███▌      | 54/153 [00:01<00:01, 52.59it/s, Epoch: 57, Batch: 54,Loss: -2.633,Avg.Loss: -2.286,LR: 2.00E-04]Training epoch 57:  35%|███▌      | 54/153 [00:01<00:01, 52.59it/s, Epoch: 57, Batch: 55,Loss: -2.910,Avg.Loss: -2.298,LR: 2.00E-04]Training epoch 57:  36%|███▌      | 55/153 [00:01<00:01, 52.59it/s, Epoch: 57, Batch: 56,Loss: -2.849,Avg.Loss: -2.308,LR: 2.00E-04]Training epoch 57:  37%|███▋      | 56/153 [00:01<00:01, 52.59it/s, Epoch: 57, Batch: 57,Loss: -2.945,Avg.Loss: -2.319,LR: 2.00E-04]Training epoch 57:  37%|███▋      | 57/153 [00:01<00:01, 52.59it/s, Epoch: 57, Batch: 58,Loss: -2.346,Avg.Loss: -2.319,LR: 2.00E-04]Training epoch 57:  38%|███▊      | 58/153 [00:01<00:01, 52.59it/s, Epoch: 57, Batch: 59,Loss: -2.599,Avg.Loss: -2.324,LR: 2.00E-04]Training epoch 57:  39%|███▊      | 59/153 [00:01<00:01, 52.59it/s, Epoch: 57, Batch: 60,Loss: -2.310,Avg.Loss: -2.324,LR: 2.00E-04]Training epoch 57:  39%|███▉      | 60/153 [00:01<00:01, 52.69it/s, Epoch: 57, Batch: 60,Loss: -2.310,Avg.Loss: -2.324,LR: 2.00E-04]Training epoch 57:  39%|███▉      | 60/153 [00:01<00:01, 52.69it/s, Epoch: 57, Batch: 61,Loss: -2.635,Avg.Loss: -2.329,LR: 2.00E-04]Training epoch 57:  40%|███▉      | 61/153 [00:01<00:01, 52.69it/s, Epoch: 57, Batch: 62,Loss: -2.243,Avg.Loss: -2.328,LR: 2.00E-04]Training epoch 57:  41%|████      | 62/153 [00:01<00:01, 52.69it/s, Epoch: 57, Batch: 63,Loss: -2.255,Avg.Loss: -2.326,LR: 2.00E-04]Training epoch 57:  41%|████      | 63/153 [00:01<00:01, 52.69it/s, Epoch: 57, Batch: 64,Loss: -2.243,Avg.Loss: -2.325,LR: 2.00E-04]Training epoch 57:  42%|████▏     | 64/153 [00:01<00:01, 52.69it/s, Epoch: 57, Batch: 65,Loss: -2.834,Avg.Loss: -2.333,LR: 2.00E-04]Training epoch 57:  42%|████▏     | 65/153 [00:01<00:01, 52.69it/s, Epoch: 57, Batch: 66,Loss: -3.238,Avg.Loss: -2.347,LR: 2.00E-04]Training epoch 57:  43%|████▎     | 66/153 [00:01<00:01, 52.86it/s, Epoch: 57, Batch: 66,Loss: -3.238,Avg.Loss: -2.347,LR: 2.00E-04]Training epoch 57:  43%|████▎     | 66/153 [00:01<00:01, 52.86it/s, Epoch: 57, Batch: 67,Loss: -2.573,Avg.Loss: -2.350,LR: 2.00E-04]Training epoch 57:  44%|████▍     | 67/153 [00:01<00:01, 52.86it/s, Epoch: 57, Batch: 68,Loss: -1.687,Avg.Loss: -2.340,LR: 2.00E-04]Training epoch 57:  44%|████▍     | 68/153 [00:01<00:01, 52.86it/s, Epoch: 57, Batch: 69,Loss: -2.252,Avg.Loss: -2.339,LR: 2.00E-04]Training epoch 57:  45%|████▌     | 69/153 [00:01<00:01, 52.86it/s, Epoch: 57, Batch: 70,Loss: -2.684,Avg.Loss: -2.344,LR: 2.00E-04]Training epoch 57:  46%|████▌     | 70/153 [00:01<00:01, 52.86it/s, Epoch: 57, Batch: 71,Loss: -2.330,Avg.Loss: -2.344,LR: 2.00E-04]Training epoch 57:  46%|████▋     | 71/153 [00:01<00:01, 52.86it/s, Epoch: 57, Batch: 72,Loss: -2.559,Avg.Loss: -2.347,LR: 2.00E-04]Training epoch 57:  47%|████▋     | 72/153 [00:01<00:01, 52.81it/s, Epoch: 57, Batch: 72,Loss: -2.559,Avg.Loss: -2.347,LR: 2.00E-04]Training epoch 57:  47%|████▋     | 72/153 [00:01<00:01, 52.81it/s, Epoch: 57, Batch: 73,Loss: -2.502,Avg.Loss: -2.349,LR: 1.99E-04]Training epoch 57:  48%|████▊     | 73/153 [00:01<00:01, 52.81it/s, Epoch: 57, Batch: 74,Loss: -2.824,Avg.Loss: -2.355,LR: 1.99E-04]Training epoch 57:  48%|████▊     | 74/153 [00:01<00:01, 52.81it/s, Epoch: 57, Batch: 75,Loss: -3.007,Avg.Loss: -2.364,LR: 1.99E-04]Training epoch 57:  49%|████▉     | 75/153 [00:01<00:01, 52.81it/s, Epoch: 57, Batch: 76,Loss: -2.687,Avg.Loss: -2.368,LR: 1.99E-04]Training epoch 57:  50%|████▉     | 76/153 [00:01<00:01, 52.81it/s, Epoch: 57, Batch: 77,Loss: -1.619,Avg.Loss: -2.358,LR: 1.99E-04]Training epoch 57:  50%|█████     | 77/153 [00:01<00:01, 52.81it/s, Epoch: 57, Batch: 78,Loss: -2.582,Avg.Loss: -2.361,LR: 1.99E-04]Training epoch 57:  51%|█████     | 78/153 [00:01<00:01, 52.84it/s, Epoch: 57, Batch: 78,Loss: -2.582,Avg.Loss: -2.361,LR: 1.99E-04]Training epoch 57:  51%|█████     | 78/153 [00:01<00:01, 52.84it/s, Epoch: 57, Batch: 79,Loss: -2.620,Avg.Loss: -2.365,LR: 1.99E-04]Training epoch 57:  52%|█████▏    | 79/153 [00:01<00:01, 52.84it/s, Epoch: 57, Batch: 80,Loss: -2.217,Avg.Loss: -2.363,LR: 1.99E-04]Training epoch 57:  52%|█████▏    | 80/153 [00:01<00:01, 52.84it/s, Epoch: 57, Batch: 81,Loss: -2.745,Avg.Loss: -2.367,LR: 1.99E-04]Training epoch 57:  53%|█████▎    | 81/153 [00:01<00:01, 52.84it/s, Epoch: 57, Batch: 82,Loss: -2.687,Avg.Loss: -2.371,LR: 1.99E-04]Training epoch 57:  54%|█████▎    | 82/153 [00:01<00:01, 52.84it/s, Epoch: 57, Batch: 83,Loss: -2.490,Avg.Loss: -2.373,LR: 1.99E-04]Training epoch 57:  54%|█████▍    | 83/153 [00:01<00:01, 52.84it/s, Epoch: 57, Batch: 84,Loss: -2.693,Avg.Loss: -2.377,LR: 1.99E-04]Training epoch 57:  55%|█████▍    | 84/153 [00:01<00:01, 52.78it/s, Epoch: 57, Batch: 84,Loss: -2.693,Avg.Loss: -2.377,LR: 1.99E-04]Training epoch 57:  55%|█████▍    | 84/153 [00:01<00:01, 52.78it/s, Epoch: 57, Batch: 85,Loss: -2.339,Avg.Loss: -2.376,LR: 1.99E-04]Training epoch 57:  56%|█████▌    | 85/153 [00:01<00:01, 52.78it/s, Epoch: 57, Batch: 86,Loss: -2.569,Avg.Loss: -2.378,LR: 1.99E-04]Training epoch 57:  56%|█████▌    | 86/153 [00:01<00:01, 52.78it/s, Epoch: 57, Batch: 87,Loss: -2.406,Avg.Loss: -2.379,LR: 1.99E-04]Training epoch 57:  57%|█████▋    | 87/153 [00:01<00:01, 52.78it/s, Epoch: 57, Batch: 88,Loss: -2.779,Avg.Loss: -2.383,LR: 1.99E-04]Training epoch 57:  58%|█████▊    | 88/153 [00:01<00:01, 52.78it/s, Epoch: 57, Batch: 89,Loss: -2.847,Avg.Loss: -2.388,LR: 1.99E-04]Training epoch 57:  58%|█████▊    | 89/153 [00:01<00:01, 52.78it/s, Epoch: 57, Batch: 90,Loss: -2.120,Avg.Loss: -2.385,LR: 1.99E-04]Training epoch 57:  59%|█████▉    | 90/153 [00:01<00:01, 52.73it/s, Epoch: 57, Batch: 90,Loss: -2.120,Avg.Loss: -2.385,LR: 1.99E-04]Training epoch 57:  59%|█████▉    | 90/153 [00:01<00:01, 52.73it/s, Epoch: 57, Batch: 91,Loss: -2.495,Avg.Loss: -2.387,LR: 1.99E-04]Training epoch 57:  59%|█████▉    | 91/153 [00:01<00:01, 52.73it/s, Epoch: 57, Batch: 92,Loss: -2.675,Avg.Loss: -2.390,LR: 1.99E-04]Training epoch 57:  60%|██████    | 92/153 [00:01<00:01, 52.73it/s, Epoch: 57, Batch: 93,Loss: -2.295,Avg.Loss: -2.389,LR: 1.98E-04]Training epoch 57:  61%|██████    | 93/153 [00:01<00:01, 52.73it/s, Epoch: 57, Batch: 94,Loss: -2.954,Avg.Loss: -2.395,LR: 1.98E-04]Training epoch 57:  61%|██████▏   | 94/153 [00:01<00:01, 52.73it/s, Epoch: 57, Batch: 95,Loss: -2.352,Avg.Loss: -2.394,LR: 1.98E-04]Training epoch 57:  62%|██████▏   | 95/153 [00:01<00:01, 52.73it/s, Epoch: 57, Batch: 96,Loss: -2.351,Avg.Loss: -2.394,LR: 1.98E-04]Training epoch 57:  63%|██████▎   | 96/153 [00:01<00:01, 52.70it/s, Epoch: 57, Batch: 96,Loss: -2.351,Avg.Loss: -2.394,LR: 1.98E-04]Training epoch 57:  63%|██████▎   | 96/153 [00:01<00:01, 52.70it/s, Epoch: 57, Batch: 97,Loss: -2.045,Avg.Loss: -2.390,LR: 1.98E-04]Training epoch 57:  63%|██████▎   | 97/153 [00:01<00:01, 52.70it/s, Epoch: 57, Batch: 98,Loss: -2.724,Avg.Loss: -2.394,LR: 1.98E-04]Training epoch 57:  64%|██████▍   | 98/153 [00:01<00:01, 52.70it/s, Epoch: 57, Batch: 99,Loss: -2.687,Avg.Loss: -2.397,LR: 1.98E-04]Training epoch 57:  65%|██████▍   | 99/153 [00:01<00:01, 52.70it/s, Epoch: 57, Batch: 100,Loss: -2.725,Avg.Loss: -2.400,LR: 1.98E-04]Training epoch 57:  65%|██████▌   | 100/153 [00:01<00:01, 52.70it/s, Epoch: 57, Batch: 101,Loss: -3.079,Avg.Loss: -2.407,LR: 1.98E-04]Training epoch 57:  66%|██████▌   | 101/153 [00:01<00:00, 52.70it/s, Epoch: 57, Batch: 102,Loss: -2.273,Avg.Loss: -2.405,LR: 1.98E-04]Training epoch 57:  67%|██████▋   | 102/153 [00:01<00:00, 52.82it/s, Epoch: 57, Batch: 102,Loss: -2.273,Avg.Loss: -2.405,LR: 1.98E-04]Training epoch 57:  67%|██████▋   | 102/153 [00:01<00:00, 52.82it/s, Epoch: 57, Batch: 103,Loss: -2.492,Avg.Loss: -2.406,LR: 1.98E-04]Training epoch 57:  67%|██████▋   | 103/153 [00:01<00:00, 52.82it/s, Epoch: 57, Batch: 104,Loss: -2.315,Avg.Loss: -2.405,LR: 1.98E-04]Training epoch 57:  68%|██████▊   | 104/153 [00:01<00:00, 52.82it/s, Epoch: 57, Batch: 105,Loss: -2.565,Avg.Loss: -2.407,LR: 1.98E-04]Training epoch 57:  69%|██████▊   | 105/153 [00:02<00:00, 52.82it/s, Epoch: 57, Batch: 106,Loss: -2.206,Avg.Loss: -2.405,LR: 1.98E-04]Training epoch 57:  69%|██████▉   | 106/153 [00:02<00:00, 52.82it/s, Epoch: 57, Batch: 107,Loss: -2.866,Avg.Loss: -2.409,LR: 1.98E-04]Training epoch 57:  70%|██████▉   | 107/153 [00:02<00:00, 52.82it/s, Epoch: 57, Batch: 108,Loss: -2.707,Avg.Loss: -2.412,LR: 1.98E-04]Training epoch 57:  71%|███████   | 108/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 108,Loss: -2.707,Avg.Loss: -2.412,LR: 1.98E-04]Training epoch 57:  71%|███████   | 108/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 109,Loss: -2.336,Avg.Loss: -2.411,LR: 1.98E-04]Training epoch 57:  71%|███████   | 109/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 110,Loss: -2.685,Avg.Loss: -2.414,LR: 1.98E-04]Training epoch 57:  72%|███████▏  | 110/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 111,Loss: -2.749,Avg.Loss: -2.417,LR: 1.98E-04]Training epoch 57:  73%|███████▎  | 111/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 112,Loss: -2.755,Avg.Loss: -2.420,LR: 1.98E-04]Training epoch 57:  73%|███████▎  | 112/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 113,Loss: -3.019,Avg.Loss: -2.425,LR: 1.97E-04]Training epoch 57:  74%|███████▍  | 113/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 114,Loss: -2.396,Avg.Loss: -2.425,LR: 1.97E-04]Training epoch 57:  75%|███████▍  | 114/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 114,Loss: -2.396,Avg.Loss: -2.425,LR: 1.97E-04]Training epoch 57:  75%|███████▍  | 114/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 115,Loss: -2.547,Avg.Loss: -2.426,LR: 1.97E-04]Training epoch 57:  75%|███████▌  | 115/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 116,Loss: -2.895,Avg.Loss: -2.430,LR: 1.97E-04]Training epoch 57:  76%|███████▌  | 116/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 117,Loss: -2.019,Avg.Loss: -2.427,LR: 1.97E-04]Training epoch 57:  76%|███████▋  | 117/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 118,Loss: -2.119,Avg.Loss: -2.424,LR: 1.97E-04]Training epoch 57:  77%|███████▋  | 118/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 119,Loss: -2.269,Avg.Loss: -2.423,LR: 1.97E-04]Training epoch 57:  78%|███████▊  | 119/153 [00:02<00:00, 52.69it/s, Epoch: 57, Batch: 120,Loss: -2.729,Avg.Loss: -2.425,LR: 1.97E-04]Training epoch 57:  78%|███████▊  | 120/153 [00:02<00:00, 52.79it/s, Epoch: 57, Batch: 120,Loss: -2.729,Avg.Loss: -2.425,LR: 1.97E-04]Training epoch 57:  78%|███████▊  | 120/153 [00:02<00:00, 52.79it/s, Epoch: 57, Batch: 121,Loss: -1.822,Avg.Loss: -2.420,LR: 1.97E-04]Training epoch 57:  79%|███████▉  | 121/153 [00:02<00:00, 52.79it/s, Epoch: 57, Batch: 122,Loss: -1.006,Avg.Loss: -2.409,LR: 1.97E-04]Training epoch 57:  80%|███████▉  | 122/153 [00:02<00:00, 52.79it/s, Epoch: 57, Batch: 123,Loss: -0.731,Avg.Loss: -2.395,LR: 1.97E-04]Training epoch 57:  80%|████████  | 123/153 [00:02<00:00, 52.79it/s, Epoch: 57, Batch: 124,Loss: -2.001,Avg.Loss: -2.392,LR: 1.97E-04]Training epoch 57:  81%|████████  | 124/153 [00:02<00:00, 52.79it/s, Epoch: 57, Batch: 125,Loss: -2.631,Avg.Loss: -2.394,LR: 1.97E-04]Training epoch 57:  82%|████████▏ | 125/153 [00:02<00:00, 52.79it/s, Epoch: 57, Batch: 126,Loss: -2.387,Avg.Loss: -2.394,LR: 1.97E-04]Training epoch 57:  82%|████████▏ | 126/153 [00:02<00:00, 52.88it/s, Epoch: 57, Batch: 126,Loss: -2.387,Avg.Loss: -2.394,LR: 1.97E-04]Training epoch 57:  82%|████████▏ | 126/153 [00:02<00:00, 52.88it/s, Epoch: 57, Batch: 127,Loss: -0.923,Avg.Loss: -2.382,LR: 1.97E-04]Training epoch 57:  83%|████████▎ | 127/153 [00:02<00:00, 52.88it/s, Epoch: 57, Batch: 128,Loss: -0.355,Avg.Loss: -2.366,LR: 1.97E-04]Training epoch 57:  84%|████████▎ | 128/153 [00:02<00:00, 52.88it/s, Epoch: 57, Batch: 129,Loss: -1.640,Avg.Loss: -2.361,LR: 1.97E-04]Training epoch 57:  84%|████████▍ | 129/153 [00:02<00:00, 52.88it/s, Epoch: 57, Batch: 130,Loss: -2.415,Avg.Loss: -2.361,LR: 1.97E-04]Training epoch 57:  85%|████████▍ | 130/153 [00:02<00:00, 52.88it/s, Epoch: 57, Batch: 131,Loss: -2.970,Avg.Loss: -2.366,LR: 1.97E-04]Training epoch 57:  86%|████████▌ | 131/153 [00:02<00:00, 52.88it/s, Epoch: 57, Batch: 132,Loss: -1.886,Avg.Loss: -2.362,LR: 1.97E-04]Training epoch 57:  86%|████████▋ | 132/153 [00:02<00:00, 52.91it/s, Epoch: 57, Batch: 132,Loss: -1.886,Avg.Loss: -2.362,LR: 1.97E-04]Training epoch 57:  86%|████████▋ | 132/153 [00:02<00:00, 52.91it/s, Epoch: 57, Batch: 133,Loss: -1.549,Avg.Loss: -2.356,LR: 1.96E-04]Training epoch 57:  87%|████████▋ | 133/153 [00:02<00:00, 52.91it/s, Epoch: 57, Batch: 134,Loss: -2.372,Avg.Loss: -2.356,LR: 1.96E-04]Training epoch 57:  88%|████████▊ | 134/153 [00:02<00:00, 52.91it/s, Epoch: 57, Batch: 135,Loss: -3.121,Avg.Loss: -2.362,LR: 1.96E-04]Training epoch 57:  88%|████████▊ | 135/153 [00:02<00:00, 52.91it/s, Epoch: 57, Batch: 136,Loss: -1.550,Avg.Loss: -2.356,LR: 1.96E-04]Training epoch 57:  89%|████████▉ | 136/153 [00:02<00:00, 52.91it/s, Epoch: 57, Batch: 137,Loss: -1.246,Avg.Loss: -2.348,LR: 1.96E-04]Training epoch 57:  90%|████████▉ | 137/153 [00:02<00:00, 52.91it/s, Epoch: 57, Batch: 138,Loss: -0.911,Avg.Loss: -2.337,LR: 1.96E-04]Training epoch 57:  90%|█████████ | 138/153 [00:02<00:00, 53.14it/s, Epoch: 57, Batch: 138,Loss: -0.911,Avg.Loss: -2.337,LR: 1.96E-04]Training epoch 57:  90%|█████████ | 138/153 [00:02<00:00, 53.14it/s, Epoch: 57, Batch: 139,Loss: -2.020,Avg.Loss: -2.335,LR: 1.96E-04]Training epoch 57:  91%|█████████ | 139/153 [00:02<00:00, 53.14it/s, Epoch: 57, Batch: 140,Loss: -1.911,Avg.Loss: -2.332,LR: 1.96E-04]Training epoch 57:  92%|█████████▏| 140/153 [00:02<00:00, 53.14it/s, Epoch: 57, Batch: 141,Loss: -2.006,Avg.Loss: -2.330,LR: 1.96E-04]Training epoch 57:  92%|█████████▏| 141/153 [00:02<00:00, 53.14it/s, Epoch: 57, Batch: 142,Loss: -1.178,Avg.Loss: -2.321,LR: 1.96E-04]Training epoch 57:  93%|█████████▎| 142/153 [00:02<00:00, 53.14it/s, Epoch: 57, Batch: 143,Loss: -0.414,Avg.Loss: -2.308,LR: 1.96E-04]Training epoch 57:  93%|█████████▎| 143/153 [00:02<00:00, 53.14it/s, Epoch: 57, Batch: 144,Loss: -2.055,Avg.Loss: -2.306,LR: 1.96E-04]Training epoch 57:  94%|█████████▍| 144/153 [00:02<00:00, 53.16it/s, Epoch: 57, Batch: 144,Loss: -2.055,Avg.Loss: -2.306,LR: 1.96E-04]Training epoch 57:  94%|█████████▍| 144/153 [00:02<00:00, 53.16it/s, Epoch: 57, Batch: 145,Loss: -2.310,Avg.Loss: -2.306,LR: 1.96E-04]Training epoch 57:  95%|█████████▍| 145/153 [00:02<00:00, 53.16it/s, Epoch: 57, Batch: 146,Loss: -1.644,Avg.Loss: -2.302,LR: 1.96E-04]Training epoch 57:  95%|█████████▌| 146/153 [00:02<00:00, 53.16it/s, Epoch: 57, Batch: 147,Loss: -1.501,Avg.Loss: -2.296,LR: 1.96E-04]Training epoch 57:  96%|█████████▌| 147/153 [00:02<00:00, 53.16it/s, Epoch: 57, Batch: 148,Loss: -1.255,Avg.Loss: -2.289,LR: 1.96E-04]Training epoch 57:  97%|█████████▋| 148/153 [00:02<00:00, 53.16it/s, Epoch: 57, Batch: 149,Loss: -1.816,Avg.Loss: -2.286,LR: 1.96E-04]Training epoch 57:  97%|█████████▋| 149/153 [00:02<00:00, 53.16it/s, Epoch: 57, Batch: 150,Loss: -2.546,Avg.Loss: -2.288,LR: 1.96E-04]Training epoch 57:  98%|█████████▊| 150/153 [00:02<00:00, 53.26it/s, Epoch: 57, Batch: 150,Loss: -2.546,Avg.Loss: -2.288,LR: 1.96E-04]Training epoch 57:  98%|█████████▊| 150/153 [00:02<00:00, 53.26it/s, Epoch: 57, Batch: 151,Loss: -2.299,Avg.Loss: -2.288,LR: 1.96E-04]Training epoch 57:  99%|█████████▊| 151/153 [00:02<00:00, 53.26it/s, Epoch: 57, Batch: 152,Loss: -0.652,Avg.Loss: -2.277,LR: 1.96E-04]Training epoch 57:  99%|█████████▉| 152/153 [00:02<00:00, 53.26it/s, Epoch: 57, Batch: 153,Loss: -0.538,Avg.Loss: -2.266,LR: 1.95E-04]Training epoch 57: 100%|██████████| 153/153 [00:02<00:00, 52.80it/s, Epoch: 57, Batch: 153,Loss: -0.538,Avg.Loss: -2.266,LR: 1.95E-04]
Training epoch 58:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 58:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 58, Batch: 1,Loss: -1.539,Avg.Loss: -1.539,LR: 1.95E-04]Training epoch 58:   1%|          | 1/153 [00:00<00:06, 25.30it/s, Epoch: 58, Batch: 2,Loss: -2.018,Avg.Loss: -1.779,LR: 1.95E-04]Training epoch 58:   1%|▏         | 2/153 [00:00<00:04, 37.64it/s, Epoch: 58, Batch: 3,Loss: -1.275,Avg.Loss: -1.611,LR: 1.95E-04]Training epoch 58:   2%|▏         | 3/153 [00:00<00:03, 45.54it/s, Epoch: 58, Batch: 4,Loss: -1.061,Avg.Loss: -1.473,LR: 1.95E-04]Training epoch 58:   3%|▎         | 4/153 [00:00<00:02, 50.49it/s, Epoch: 58, Batch: 5,Loss: -0.588,Avg.Loss: -1.296,LR: 1.95E-04]Training epoch 58:   3%|▎         | 5/153 [00:00<00:02, 52.26it/s, Epoch: 58, Batch: 6,Loss: -1.272,Avg.Loss: -1.292,LR: 1.95E-04]Training epoch 58:   4%|▍         | 6/153 [00:00<00:02, 53.01it/s, Epoch: 58, Batch: 7,Loss: -2.300,Avg.Loss: -1.436,LR: 1.95E-04]Training epoch 58:   5%|▍         | 7/153 [00:00<00:02, 61.76it/s, Epoch: 58, Batch: 7,Loss: -2.300,Avg.Loss: -1.436,LR: 1.95E-04]Training epoch 58:   5%|▍         | 7/153 [00:00<00:02, 61.76it/s, Epoch: 58, Batch: 8,Loss: -2.635,Avg.Loss: -1.586,LR: 1.95E-04]Training epoch 58:   5%|▌         | 8/153 [00:00<00:02, 61.76it/s, Epoch: 58, Batch: 9,Loss: -2.059,Avg.Loss: -1.639,LR: 1.95E-04]Training epoch 58:   6%|▌         | 9/153 [00:00<00:02, 61.76it/s, Epoch: 58, Batch: 10,Loss: -1.758,Avg.Loss: -1.651,LR: 1.95E-04]Training epoch 58:   7%|▋         | 10/153 [00:00<00:02, 61.76it/s, Epoch: 58, Batch: 11,Loss: -2.597,Avg.Loss: -1.737,LR: 1.95E-04]Training epoch 58:   7%|▋         | 11/153 [00:00<00:02, 61.76it/s, Epoch: 58, Batch: 12,Loss: -2.206,Avg.Loss: -1.776,LR: 1.95E-04]Training epoch 58:   8%|▊         | 12/153 [00:00<00:02, 61.76it/s, Epoch: 58, Batch: 13,Loss: -2.489,Avg.Loss: -1.831,LR: 1.95E-04]Training epoch 58:   8%|▊         | 13/153 [00:00<00:02, 61.76it/s, Epoch: 58, Batch: 14,Loss: -3.012,Avg.Loss: -1.915,LR: 1.95E-04]Training epoch 58:   9%|▉         | 14/153 [00:00<00:02, 56.36it/s, Epoch: 58, Batch: 14,Loss: -3.012,Avg.Loss: -1.915,LR: 1.95E-04]Training epoch 58:   9%|▉         | 14/153 [00:00<00:02, 56.36it/s, Epoch: 58, Batch: 15,Loss: -2.499,Avg.Loss: -1.954,LR: 1.95E-04]Training epoch 58:  10%|▉         | 15/153 [00:00<00:02, 56.36it/s, Epoch: 58, Batch: 16,Loss: -2.159,Avg.Loss: -1.967,LR: 1.95E-04]Training epoch 58:  10%|█         | 16/153 [00:00<00:02, 56.36it/s, Epoch: 58, Batch: 17,Loss: -2.246,Avg.Loss: -1.983,LR: 1.95E-04]Training epoch 58:  11%|█         | 17/153 [00:00<00:02, 56.36it/s, Epoch: 58, Batch: 18,Loss: -2.148,Avg.Loss: -1.992,LR: 1.95E-04]Training epoch 58:  12%|█▏        | 18/153 [00:00<00:02, 56.36it/s, Epoch: 58, Batch: 19,Loss: -2.027,Avg.Loss: -1.994,LR: 1.95E-04]Training epoch 58:  12%|█▏        | 19/153 [00:00<00:02, 56.36it/s, Epoch: 58, Batch: 20,Loss: -2.338,Avg.Loss: -2.011,LR: 1.94E-04]Training epoch 58:  13%|█▎        | 20/153 [00:00<00:02, 54.86it/s, Epoch: 58, Batch: 20,Loss: -2.338,Avg.Loss: -2.011,LR: 1.94E-04]Training epoch 58:  13%|█▎        | 20/153 [00:00<00:02, 54.86it/s, Epoch: 58, Batch: 21,Loss: -2.891,Avg.Loss: -2.053,LR: 1.94E-04]Training epoch 58:  14%|█▎        | 21/153 [00:00<00:02, 54.86it/s, Epoch: 58, Batch: 22,Loss: -2.808,Avg.Loss: -2.088,LR: 1.94E-04]Training epoch 58:  14%|█▍        | 22/153 [00:00<00:02, 54.86it/s, Epoch: 58, Batch: 23,Loss: -2.577,Avg.Loss: -2.109,LR: 1.94E-04]Training epoch 58:  15%|█▌        | 23/153 [00:00<00:02, 54.86it/s, Epoch: 58, Batch: 24,Loss: -3.179,Avg.Loss: -2.153,LR: 1.94E-04]Training epoch 58:  16%|█▌        | 24/153 [00:00<00:02, 54.86it/s, Epoch: 58, Batch: 25,Loss: -2.632,Avg.Loss: -2.173,LR: 1.94E-04]Training epoch 58:  16%|█▋        | 25/153 [00:00<00:02, 54.86it/s, Epoch: 58, Batch: 26,Loss: -2.081,Avg.Loss: -2.169,LR: 1.94E-04]Training epoch 58:  17%|█▋        | 26/153 [00:00<00:02, 53.35it/s, Epoch: 58, Batch: 26,Loss: -2.081,Avg.Loss: -2.169,LR: 1.94E-04]Training epoch 58:  17%|█▋        | 26/153 [00:00<00:02, 53.35it/s, Epoch: 58, Batch: 27,Loss: -2.247,Avg.Loss: -2.172,LR: 1.94E-04]Training epoch 58:  18%|█▊        | 27/153 [00:00<00:02, 53.35it/s, Epoch: 58, Batch: 28,Loss: -2.386,Avg.Loss: -2.180,LR: 1.94E-04]Training epoch 58:  18%|█▊        | 28/153 [00:00<00:02, 53.35it/s, Epoch: 58, Batch: 29,Loss: -1.527,Avg.Loss: -2.157,LR: 1.94E-04]Training epoch 58:  19%|█▉        | 29/153 [00:00<00:02, 53.35it/s, Epoch: 58, Batch: 30,Loss: -2.616,Avg.Loss: -2.172,LR: 1.94E-04]Training epoch 58:  20%|█▉        | 30/153 [00:00<00:02, 53.35it/s, Epoch: 58, Batch: 31,Loss: -2.996,Avg.Loss: -2.199,LR: 1.94E-04]Training epoch 58:  20%|██        | 31/153 [00:00<00:02, 53.35it/s, Epoch: 58, Batch: 32,Loss: -2.469,Avg.Loss: -2.207,LR: 1.94E-04]Training epoch 58:  21%|██        | 32/153 [00:00<00:02, 52.60it/s, Epoch: 58, Batch: 32,Loss: -2.469,Avg.Loss: -2.207,LR: 1.94E-04]Training epoch 58:  21%|██        | 32/153 [00:00<00:02, 52.60it/s, Epoch: 58, Batch: 33,Loss: -1.851,Avg.Loss: -2.197,LR: 1.94E-04]Training epoch 58:  22%|██▏       | 33/153 [00:00<00:02, 52.60it/s, Epoch: 58, Batch: 34,Loss: -1.890,Avg.Loss: -2.188,LR: 1.94E-04]Training epoch 58:  22%|██▏       | 34/153 [00:00<00:02, 52.60it/s, Epoch: 58, Batch: 35,Loss: -1.788,Avg.Loss: -2.176,LR: 1.94E-04]Training epoch 58:  23%|██▎       | 35/153 [00:00<00:02, 52.60it/s, Epoch: 58, Batch: 36,Loss: -1.808,Avg.Loss: -2.166,LR: 1.94E-04]Training epoch 58:  24%|██▎       | 36/153 [00:00<00:02, 52.60it/s, Epoch: 58, Batch: 37,Loss: -2.128,Avg.Loss: -2.165,LR: 1.94E-04]Training epoch 58:  24%|██▍       | 37/153 [00:00<00:02, 52.60it/s, Epoch: 58, Batch: 38,Loss: -2.770,Avg.Loss: -2.181,LR: 1.94E-04]Training epoch 58:  25%|██▍       | 38/153 [00:00<00:02, 52.40it/s, Epoch: 58, Batch: 38,Loss: -2.770,Avg.Loss: -2.181,LR: 1.94E-04]Training epoch 58:  25%|██▍       | 38/153 [00:00<00:02, 52.40it/s, Epoch: 58, Batch: 39,Loss: -2.163,Avg.Loss: -2.180,LR: 1.94E-04]Training epoch 58:  25%|██▌       | 39/153 [00:00<00:02, 52.40it/s, Epoch: 58, Batch: 40,Loss: -2.643,Avg.Loss: -2.192,LR: 1.93E-04]Training epoch 58:  26%|██▌       | 40/153 [00:00<00:02, 52.40it/s, Epoch: 58, Batch: 41,Loss: -2.164,Avg.Loss: -2.191,LR: 1.93E-04]Training epoch 58:  27%|██▋       | 41/153 [00:00<00:02, 52.40it/s, Epoch: 58, Batch: 42,Loss: -2.173,Avg.Loss: -2.191,LR: 1.93E-04]Training epoch 58:  27%|██▋       | 42/153 [00:00<00:02, 52.40it/s, Epoch: 58, Batch: 43,Loss: -1.480,Avg.Loss: -2.174,LR: 1.93E-04]Training epoch 58:  28%|██▊       | 43/153 [00:00<00:02, 52.40it/s, Epoch: 58, Batch: 44,Loss: -2.871,Avg.Loss: -2.190,LR: 1.93E-04]Training epoch 58:  29%|██▉       | 44/153 [00:00<00:02, 52.50it/s, Epoch: 58, Batch: 44,Loss: -2.871,Avg.Loss: -2.190,LR: 1.93E-04]Training epoch 58:  29%|██▉       | 44/153 [00:00<00:02, 52.50it/s, Epoch: 58, Batch: 45,Loss: -2.532,Avg.Loss: -2.198,LR: 1.93E-04]Training epoch 58:  29%|██▉       | 45/153 [00:00<00:02, 52.50it/s, Epoch: 58, Batch: 46,Loss: -2.620,Avg.Loss: -2.207,LR: 1.93E-04]Training epoch 58:  30%|███       | 46/153 [00:00<00:02, 52.50it/s, Epoch: 58, Batch: 47,Loss: -2.903,Avg.Loss: -2.222,LR: 1.93E-04]Training epoch 58:  31%|███       | 47/153 [00:00<00:02, 52.50it/s, Epoch: 58, Batch: 48,Loss: -2.837,Avg.Loss: -2.235,LR: 1.93E-04]Training epoch 58:  31%|███▏      | 48/153 [00:00<00:01, 52.50it/s, Epoch: 58, Batch: 49,Loss: -2.133,Avg.Loss: -2.232,LR: 1.93E-04]Training epoch 58:  32%|███▏      | 49/153 [00:00<00:01, 52.50it/s, Epoch: 58, Batch: 50,Loss: -2.755,Avg.Loss: -2.243,LR: 1.93E-04]Training epoch 58:  33%|███▎      | 50/153 [00:00<00:01, 52.83it/s, Epoch: 58, Batch: 50,Loss: -2.755,Avg.Loss: -2.243,LR: 1.93E-04]Training epoch 58:  33%|███▎      | 50/153 [00:00<00:01, 52.83it/s, Epoch: 58, Batch: 51,Loss: -2.920,Avg.Loss: -2.256,LR: 1.93E-04]Training epoch 58:  33%|███▎      | 51/153 [00:00<00:01, 52.83it/s, Epoch: 58, Batch: 52,Loss: -2.282,Avg.Loss: -2.257,LR: 1.93E-04]Training epoch 58:  34%|███▍      | 52/153 [00:01<00:01, 52.83it/s, Epoch: 58, Batch: 53,Loss: -2.300,Avg.Loss: -2.258,LR: 1.93E-04]Training epoch 58:  35%|███▍      | 53/153 [00:01<00:01, 52.83it/s, Epoch: 58, Batch: 54,Loss: -2.629,Avg.Loss: -2.264,LR: 1.93E-04]Training epoch 58:  35%|███▌      | 54/153 [00:01<00:01, 52.83it/s, Epoch: 58, Batch: 55,Loss: -2.162,Avg.Loss: -2.263,LR: 1.93E-04]Training epoch 58:  36%|███▌      | 55/153 [00:01<00:01, 52.83it/s, Epoch: 58, Batch: 56,Loss: -2.045,Avg.Loss: -2.259,LR: 1.93E-04]Training epoch 58:  37%|███▋      | 56/153 [00:01<00:01, 51.46it/s, Epoch: 58, Batch: 56,Loss: -2.045,Avg.Loss: -2.259,LR: 1.93E-04]Training epoch 58:  37%|███▋      | 56/153 [00:01<00:01, 51.46it/s, Epoch: 58, Batch: 57,Loss: -2.774,Avg.Loss: -2.268,LR: 1.93E-04]Training epoch 58:  37%|███▋      | 57/153 [00:01<00:01, 51.46it/s, Epoch: 58, Batch: 58,Loss: -2.188,Avg.Loss: -2.266,LR: 1.93E-04]Training epoch 58:  38%|███▊      | 58/153 [00:01<00:01, 51.46it/s, Epoch: 58, Batch: 59,Loss: -2.460,Avg.Loss: -2.270,LR: 1.93E-04]Training epoch 58:  39%|███▊      | 59/153 [00:01<00:01, 51.46it/s, Epoch: 58, Batch: 60,Loss: -2.714,Avg.Loss: -2.277,LR: 1.92E-04]Training epoch 58:  39%|███▉      | 60/153 [00:01<00:01, 51.46it/s, Epoch: 58, Batch: 61,Loss: -2.427,Avg.Loss: -2.279,LR: 1.92E-04]Training epoch 58:  40%|███▉      | 61/153 [00:01<00:01, 51.46it/s, Epoch: 58, Batch: 62,Loss: -2.513,Avg.Loss: -2.283,LR: 1.92E-04]Training epoch 58:  41%|████      | 62/153 [00:01<00:01, 51.81it/s, Epoch: 58, Batch: 62,Loss: -2.513,Avg.Loss: -2.283,LR: 1.92E-04]Training epoch 58:  41%|████      | 62/153 [00:01<00:01, 51.81it/s, Epoch: 58, Batch: 63,Loss: -2.743,Avg.Loss: -2.291,LR: 1.92E-04]Training epoch 58:  41%|████      | 63/153 [00:01<00:01, 51.81it/s, Epoch: 58, Batch: 64,Loss: -2.673,Avg.Loss: -2.297,LR: 1.92E-04]Training epoch 58:  42%|████▏     | 64/153 [00:01<00:01, 51.81it/s, Epoch: 58, Batch: 65,Loss: -2.116,Avg.Loss: -2.294,LR: 1.92E-04]Training epoch 58:  42%|████▏     | 65/153 [00:01<00:01, 51.81it/s, Epoch: 58, Batch: 66,Loss: -2.648,Avg.Loss: -2.299,LR: 1.92E-04]Training epoch 58:  43%|████▎     | 66/153 [00:01<00:01, 51.81it/s, Epoch: 58, Batch: 67,Loss: -2.887,Avg.Loss: -2.308,LR: 1.92E-04]Training epoch 58:  44%|████▍     | 67/153 [00:01<00:01, 51.81it/s, Epoch: 58, Batch: 68,Loss: -2.156,Avg.Loss: -2.306,LR: 1.92E-04]Training epoch 58:  44%|████▍     | 68/153 [00:01<00:01, 52.13it/s, Epoch: 58, Batch: 68,Loss: -2.156,Avg.Loss: -2.306,LR: 1.92E-04]Training epoch 58:  44%|████▍     | 68/153 [00:01<00:01, 52.13it/s, Epoch: 58, Batch: 69,Loss: -1.229,Avg.Loss: -2.290,LR: 1.92E-04]Training epoch 58:  45%|████▌     | 69/153 [00:01<00:01, 52.13it/s, Epoch: 58, Batch: 70,Loss: -1.474,Avg.Loss: -2.278,LR: 1.92E-04]Training epoch 58:  46%|████▌     | 70/153 [00:01<00:01, 52.13it/s, Epoch: 58, Batch: 71,Loss: -2.644,Avg.Loss: -2.284,LR: 1.92E-04]Training epoch 58:  46%|████▋     | 71/153 [00:01<00:01, 52.13it/s, Epoch: 58, Batch: 72,Loss: -2.625,Avg.Loss: -2.288,LR: 1.92E-04]Training epoch 58:  47%|████▋     | 72/153 [00:01<00:01, 52.13it/s, Epoch: 58, Batch: 73,Loss: -2.892,Avg.Loss: -2.297,LR: 1.92E-04]Training epoch 58:  48%|████▊     | 73/153 [00:01<00:01, 52.13it/s, Epoch: 58, Batch: 74,Loss: -2.111,Avg.Loss: -2.294,LR: 1.92E-04]Training epoch 58:  48%|████▊     | 74/153 [00:01<00:01, 52.20it/s, Epoch: 58, Batch: 74,Loss: -2.111,Avg.Loss: -2.294,LR: 1.92E-04]Training epoch 58:  48%|████▊     | 74/153 [00:01<00:01, 52.20it/s, Epoch: 58, Batch: 75,Loss: -3.046,Avg.Loss: -2.304,LR: 1.92E-04]Training epoch 58:  49%|████▉     | 75/153 [00:01<00:01, 52.20it/s, Epoch: 58, Batch: 76,Loss: -2.530,Avg.Loss: -2.307,LR: 1.92E-04]Training epoch 58:  50%|████▉     | 76/153 [00:01<00:01, 52.20it/s, Epoch: 58, Batch: 77,Loss: -2.884,Avg.Loss: -2.315,LR: 1.92E-04]Training epoch 58:  50%|█████     | 77/153 [00:01<00:01, 52.20it/s, Epoch: 58, Batch: 78,Loss: -2.538,Avg.Loss: -2.317,LR: 1.92E-04]Training epoch 58:  51%|█████     | 78/153 [00:01<00:01, 52.20it/s, Epoch: 58, Batch: 79,Loss: -2.730,Avg.Loss: -2.323,LR: 1.92E-04]Training epoch 58:  52%|█████▏    | 79/153 [00:01<00:01, 52.20it/s, Epoch: 58, Batch: 80,Loss: -2.976,Avg.Loss: -2.331,LR: 1.91E-04]Training epoch 58:  52%|█████▏    | 80/153 [00:01<00:01, 52.42it/s, Epoch: 58, Batch: 80,Loss: -2.976,Avg.Loss: -2.331,LR: 1.91E-04]Training epoch 58:  52%|█████▏    | 80/153 [00:01<00:01, 52.42it/s, Epoch: 58, Batch: 81,Loss: -2.506,Avg.Loss: -2.333,LR: 1.91E-04]Training epoch 58:  53%|█████▎    | 81/153 [00:01<00:01, 52.42it/s, Epoch: 58, Batch: 82,Loss: -2.995,Avg.Loss: -2.341,LR: 1.91E-04]Training epoch 58:  54%|█████▎    | 82/153 [00:01<00:01, 52.42it/s, Epoch: 58, Batch: 83,Loss: -2.766,Avg.Loss: -2.346,LR: 1.91E-04]Training epoch 58:  54%|█████▍    | 83/153 [00:01<00:01, 52.42it/s, Epoch: 58, Batch: 84,Loss: -3.358,Avg.Loss: -2.358,LR: 1.91E-04]Training epoch 58:  55%|█████▍    | 84/153 [00:01<00:01, 52.42it/s, Epoch: 58, Batch: 85,Loss: -2.551,Avg.Loss: -2.360,LR: 1.91E-04]Training epoch 58:  56%|█████▌    | 85/153 [00:01<00:01, 52.42it/s, Epoch: 58, Batch: 86,Loss: -2.184,Avg.Loss: -2.358,LR: 1.91E-04]Training epoch 58:  56%|█████▌    | 86/153 [00:01<00:01, 52.77it/s, Epoch: 58, Batch: 86,Loss: -2.184,Avg.Loss: -2.358,LR: 1.91E-04]Training epoch 58:  56%|█████▌    | 86/153 [00:01<00:01, 52.77it/s, Epoch: 58, Batch: 87,Loss: -2.923,Avg.Loss: -2.365,LR: 1.91E-04]Training epoch 58:  57%|█████▋    | 87/153 [00:01<00:01, 52.77it/s, Epoch: 58, Batch: 88,Loss: -2.762,Avg.Loss: -2.369,LR: 1.91E-04]Training epoch 58:  58%|█████▊    | 88/153 [00:01<00:01, 52.77it/s, Epoch: 58, Batch: 89,Loss: -1.921,Avg.Loss: -2.364,LR: 1.91E-04]Training epoch 58:  58%|█████▊    | 89/153 [00:01<00:01, 52.77it/s, Epoch: 58, Batch: 90,Loss: -2.147,Avg.Loss: -2.362,LR: 1.91E-04]Training epoch 58:  59%|█████▉    | 90/153 [00:01<00:01, 52.77it/s, Epoch: 58, Batch: 91,Loss: -2.379,Avg.Loss: -2.362,LR: 1.91E-04]Training epoch 58:  59%|█████▉    | 91/153 [00:01<00:01, 52.77it/s, Epoch: 58, Batch: 92,Loss: -2.628,Avg.Loss: -2.365,LR: 1.91E-04]Training epoch 58:  60%|██████    | 92/153 [00:01<00:01, 52.91it/s, Epoch: 58, Batch: 92,Loss: -2.628,Avg.Loss: -2.365,LR: 1.91E-04]Training epoch 58:  60%|██████    | 92/153 [00:01<00:01, 52.91it/s, Epoch: 58, Batch: 93,Loss: -2.288,Avg.Loss: -2.364,LR: 1.91E-04]Training epoch 58:  61%|██████    | 93/153 [00:01<00:01, 52.91it/s, Epoch: 58, Batch: 94,Loss: -2.151,Avg.Loss: -2.362,LR: 1.91E-04]Training epoch 58:  61%|██████▏   | 94/153 [00:01<00:01, 52.91it/s, Epoch: 58, Batch: 95,Loss: -2.679,Avg.Loss: -2.365,LR: 1.91E-04]Training epoch 58:  62%|██████▏   | 95/153 [00:01<00:01, 52.91it/s, Epoch: 58, Batch: 96,Loss: -2.009,Avg.Loss: -2.362,LR: 1.91E-04]Training epoch 58:  63%|██████▎   | 96/153 [00:01<00:01, 52.91it/s, Epoch: 58, Batch: 97,Loss: -1.875,Avg.Loss: -2.357,LR: 1.91E-04]Training epoch 58:  63%|██████▎   | 97/153 [00:01<00:01, 52.91it/s, Epoch: 58, Batch: 98,Loss: -2.629,Avg.Loss: -2.359,LR: 1.91E-04]Training epoch 58:  64%|██████▍   | 98/153 [00:01<00:01, 53.04it/s, Epoch: 58, Batch: 98,Loss: -2.629,Avg.Loss: -2.359,LR: 1.91E-04]Training epoch 58:  64%|██████▍   | 98/153 [00:01<00:01, 53.04it/s, Epoch: 58, Batch: 99,Loss: -2.207,Avg.Loss: -2.358,LR: 1.91E-04]Training epoch 58:  65%|██████▍   | 99/153 [00:01<00:01, 53.04it/s, Epoch: 58, Batch: 100,Loss: -2.361,Avg.Loss: -2.358,LR: 1.90E-04]Training epoch 58:  65%|██████▌   | 100/153 [00:01<00:00, 53.04it/s, Epoch: 58, Batch: 101,Loss: -2.419,Avg.Loss: -2.358,LR: 1.90E-04]Training epoch 58:  66%|██████▌   | 101/153 [00:01<00:00, 53.04it/s, Epoch: 58, Batch: 102,Loss: -2.789,Avg.Loss: -2.363,LR: 1.90E-04]Training epoch 58:  67%|██████▋   | 102/153 [00:01<00:00, 53.04it/s, Epoch: 58, Batch: 103,Loss: -2.908,Avg.Loss: -2.368,LR: 1.90E-04]Training epoch 58:  67%|██████▋   | 103/153 [00:01<00:00, 53.04it/s, Epoch: 58, Batch: 104,Loss: -2.785,Avg.Loss: -2.372,LR: 1.90E-04]Training epoch 58:  68%|██████▊   | 104/153 [00:01<00:00, 53.03it/s, Epoch: 58, Batch: 104,Loss: -2.785,Avg.Loss: -2.372,LR: 1.90E-04]Training epoch 58:  68%|██████▊   | 104/153 [00:01<00:00, 53.03it/s, Epoch: 58, Batch: 105,Loss: -2.304,Avg.Loss: -2.371,LR: 1.90E-04]Training epoch 58:  69%|██████▊   | 105/153 [00:02<00:00, 53.03it/s, Epoch: 58, Batch: 106,Loss: -2.642,Avg.Loss: -2.374,LR: 1.90E-04]Training epoch 58:  69%|██████▉   | 106/153 [00:02<00:00, 53.03it/s, Epoch: 58, Batch: 107,Loss: -2.509,Avg.Loss: -2.375,LR: 1.90E-04]Training epoch 58:  70%|██████▉   | 107/153 [00:02<00:00, 53.03it/s, Epoch: 58, Batch: 108,Loss: -2.597,Avg.Loss: -2.377,LR: 1.90E-04]Training epoch 58:  71%|███████   | 108/153 [00:02<00:00, 53.03it/s, Epoch: 58, Batch: 109,Loss: -2.941,Avg.Loss: -2.382,LR: 1.90E-04]Training epoch 58:  71%|███████   | 109/153 [00:02<00:00, 53.03it/s, Epoch: 58, Batch: 110,Loss: -2.708,Avg.Loss: -2.385,LR: 1.90E-04]Training epoch 58:  72%|███████▏  | 110/153 [00:02<00:00, 52.91it/s, Epoch: 58, Batch: 110,Loss: -2.708,Avg.Loss: -2.385,LR: 1.90E-04]Training epoch 58:  72%|███████▏  | 110/153 [00:02<00:00, 52.91it/s, Epoch: 58, Batch: 111,Loss: -1.902,Avg.Loss: -2.381,LR: 1.90E-04]Training epoch 58:  73%|███████▎  | 111/153 [00:02<00:00, 52.91it/s, Epoch: 58, Batch: 112,Loss: -2.232,Avg.Loss: -2.380,LR: 1.90E-04]Training epoch 58:  73%|███████▎  | 112/153 [00:02<00:00, 52.91it/s, Epoch: 58, Batch: 113,Loss: -2.425,Avg.Loss: -2.380,LR: 1.90E-04]Training epoch 58:  74%|███████▍  | 113/153 [00:02<00:00, 52.91it/s, Epoch: 58, Batch: 114,Loss: -2.121,Avg.Loss: -2.378,LR: 1.90E-04]Training epoch 58:  75%|███████▍  | 114/153 [00:02<00:00, 52.91it/s, Epoch: 58, Batch: 115,Loss: -2.330,Avg.Loss: -2.377,LR: 1.90E-04]Training epoch 58:  75%|███████▌  | 115/153 [00:02<00:00, 52.91it/s, Epoch: 58, Batch: 116,Loss: -2.498,Avg.Loss: -2.378,LR: 1.90E-04]Training epoch 58:  76%|███████▌  | 116/153 [00:02<00:00, 52.98it/s, Epoch: 58, Batch: 116,Loss: -2.498,Avg.Loss: -2.378,LR: 1.90E-04]Training epoch 58:  76%|███████▌  | 116/153 [00:02<00:00, 52.98it/s, Epoch: 58, Batch: 117,Loss: -2.206,Avg.Loss: -2.377,LR: 1.90E-04]Training epoch 58:  76%|███████▋  | 117/153 [00:02<00:00, 52.98it/s, Epoch: 58, Batch: 118,Loss: -2.638,Avg.Loss: -2.379,LR: 1.90E-04]Training epoch 58:  77%|███████▋  | 118/153 [00:02<00:00, 52.98it/s, Epoch: 58, Batch: 119,Loss: -2.871,Avg.Loss: -2.383,LR: 1.90E-04]Training epoch 58:  78%|███████▊  | 119/153 [00:02<00:00, 52.98it/s, Epoch: 58, Batch: 120,Loss: -2.746,Avg.Loss: -2.386,LR: 1.89E-04]Training epoch 58:  78%|███████▊  | 120/153 [00:02<00:00, 52.98it/s, Epoch: 58, Batch: 121,Loss: -2.126,Avg.Loss: -2.384,LR: 1.89E-04]Training epoch 58:  79%|███████▉  | 121/153 [00:02<00:00, 52.98it/s, Epoch: 58, Batch: 122,Loss: -2.460,Avg.Loss: -2.385,LR: 1.89E-04]Training epoch 58:  80%|███████▉  | 122/153 [00:02<00:00, 52.89it/s, Epoch: 58, Batch: 122,Loss: -2.460,Avg.Loss: -2.385,LR: 1.89E-04]Training epoch 58:  80%|███████▉  | 122/153 [00:02<00:00, 52.89it/s, Epoch: 58, Batch: 123,Loss: -2.448,Avg.Loss: -2.385,LR: 1.89E-04]Training epoch 58:  80%|████████  | 123/153 [00:02<00:00, 52.89it/s, Epoch: 58, Batch: 124,Loss: -2.807,Avg.Loss: -2.389,LR: 1.89E-04]Training epoch 58:  81%|████████  | 124/153 [00:02<00:00, 52.89it/s, Epoch: 58, Batch: 125,Loss: -2.576,Avg.Loss: -2.390,LR: 1.89E-04]Training epoch 58:  82%|████████▏ | 125/153 [00:02<00:00, 52.89it/s, Epoch: 58, Batch: 126,Loss: -2.523,Avg.Loss: -2.391,LR: 1.89E-04]Training epoch 58:  82%|████████▏ | 126/153 [00:02<00:00, 52.89it/s, Epoch: 58, Batch: 127,Loss: -2.598,Avg.Loss: -2.393,LR: 1.89E-04]Training epoch 58:  83%|████████▎ | 127/153 [00:02<00:00, 52.89it/s, Epoch: 58, Batch: 128,Loss: -2.139,Avg.Loss: -2.391,LR: 1.89E-04]Training epoch 58:  84%|████████▎ | 128/153 [00:02<00:00, 52.99it/s, Epoch: 58, Batch: 128,Loss: -2.139,Avg.Loss: -2.391,LR: 1.89E-04]Training epoch 58:  84%|████████▎ | 128/153 [00:02<00:00, 52.99it/s, Epoch: 58, Batch: 129,Loss: -2.164,Avg.Loss: -2.389,LR: 1.89E-04]Training epoch 58:  84%|████████▍ | 129/153 [00:02<00:00, 52.99it/s, Epoch: 58, Batch: 130,Loss: -2.623,Avg.Loss: -2.391,LR: 1.89E-04]Training epoch 58:  85%|████████▍ | 130/153 [00:02<00:00, 52.99it/s, Epoch: 58, Batch: 131,Loss: -2.694,Avg.Loss: -2.393,LR: 1.89E-04]Training epoch 58:  86%|████████▌ | 131/153 [00:02<00:00, 52.99it/s, Epoch: 58, Batch: 132,Loss: -2.012,Avg.Loss: -2.390,LR: 1.89E-04]Training epoch 58:  86%|████████▋ | 132/153 [00:02<00:00, 52.99it/s, Epoch: 58, Batch: 133,Loss: -1.919,Avg.Loss: -2.387,LR: 1.89E-04]Training epoch 58:  87%|████████▋ | 133/153 [00:02<00:00, 52.99it/s, Epoch: 58, Batch: 134,Loss: -2.226,Avg.Loss: -2.386,LR: 1.89E-04]Training epoch 58:  88%|████████▊ | 134/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 134,Loss: -2.226,Avg.Loss: -2.386,LR: 1.89E-04]Training epoch 58:  88%|████████▊ | 134/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 135,Loss: -1.187,Avg.Loss: -2.377,LR: 1.89E-04]Training epoch 58:  88%|████████▊ | 135/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 136,Loss: -1.923,Avg.Loss: -2.373,LR: 1.89E-04]Training epoch 58:  89%|████████▉ | 136/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 137,Loss: -1.050,Avg.Loss: -2.364,LR: 1.89E-04]Training epoch 58:  90%|████████▉ | 137/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 138,Loss: -2.193,Avg.Loss: -2.362,LR: 1.89E-04]Training epoch 58:  90%|█████████ | 138/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 139,Loss: -1.985,Avg.Loss: -2.360,LR: 1.89E-04]Training epoch 58:  91%|█████████ | 139/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 140,Loss: -1.745,Avg.Loss: -2.355,LR: 1.88E-04]Training epoch 58:  92%|█████████▏| 140/153 [00:02<00:00, 53.07it/s, Epoch: 58, Batch: 140,Loss: -1.745,Avg.Loss: -2.355,LR: 1.88E-04]Training epoch 58:  92%|█████████▏| 140/153 [00:02<00:00, 53.07it/s, Epoch: 58, Batch: 141,Loss: -1.056,Avg.Loss: -2.346,LR: 1.88E-04]Training epoch 58:  92%|█████████▏| 141/153 [00:02<00:00, 53.07it/s, Epoch: 58, Batch: 142,Loss: -2.365,Avg.Loss: -2.346,LR: 1.88E-04]Training epoch 58:  93%|█████████▎| 142/153 [00:02<00:00, 53.07it/s, Epoch: 58, Batch: 143,Loss: -2.794,Avg.Loss: -2.349,LR: 1.88E-04]Training epoch 58:  93%|█████████▎| 143/153 [00:02<00:00, 53.07it/s, Epoch: 58, Batch: 144,Loss: -2.693,Avg.Loss: -2.352,LR: 1.88E-04]Training epoch 58:  94%|█████████▍| 144/153 [00:02<00:00, 53.07it/s, Epoch: 58, Batch: 145,Loss: -2.675,Avg.Loss: -2.354,LR: 1.88E-04]Training epoch 58:  95%|█████████▍| 145/153 [00:02<00:00, 53.07it/s, Epoch: 58, Batch: 146,Loss: -2.771,Avg.Loss: -2.357,LR: 1.88E-04]Training epoch 58:  95%|█████████▌| 146/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 146,Loss: -2.771,Avg.Loss: -2.357,LR: 1.88E-04]Training epoch 58:  95%|█████████▌| 146/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 147,Loss: -2.608,Avg.Loss: -2.359,LR: 1.88E-04]Training epoch 58:  96%|█████████▌| 147/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 148,Loss: -2.835,Avg.Loss: -2.362,LR: 1.88E-04]Training epoch 58:  97%|█████████▋| 148/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 149,Loss: -2.544,Avg.Loss: -2.363,LR: 1.88E-04]Training epoch 58:  97%|█████████▋| 149/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 150,Loss: -2.519,Avg.Loss: -2.364,LR: 1.88E-04]Training epoch 58:  98%|█████████▊| 150/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 151,Loss: -2.481,Avg.Loss: -2.365,LR: 1.88E-04]Training epoch 58:  99%|█████████▊| 151/153 [00:02<00:00, 52.92it/s, Epoch: 58, Batch: 152,Loss: -2.731,Avg.Loss: -2.367,LR: 1.88E-04]Training epoch 58:  99%|█████████▉| 152/153 [00:02<00:00, 53.06it/s, Epoch: 58, Batch: 152,Loss: -2.731,Avg.Loss: -2.367,LR: 1.88E-04]Training epoch 58:  99%|█████████▉| 152/153 [00:02<00:00, 53.06it/s, Epoch: 58, Batch: 153,Loss: -2.479,Avg.Loss: -2.368,LR: 1.88E-04]Training epoch 58: 100%|██████████| 153/153 [00:02<00:00, 52.90it/s, Epoch: 58, Batch: 153,Loss: -2.479,Avg.Loss: -2.368,LR: 1.88E-04]
Training epoch 59:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 59:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 59, Batch: 1,Loss: -2.288,Avg.Loss: -2.288,LR: 1.88E-04]Training epoch 59:   1%|          | 1/153 [00:00<00:05, 27.65it/s, Epoch: 59, Batch: 2,Loss: -2.158,Avg.Loss: -2.223,LR: 1.88E-04]Training epoch 59:   1%|▏         | 2/153 [00:00<00:04, 37.14it/s, Epoch: 59, Batch: 3,Loss: -2.594,Avg.Loss: -2.347,LR: 1.88E-04]Training epoch 59:   2%|▏         | 3/153 [00:00<00:03, 44.74it/s, Epoch: 59, Batch: 4,Loss: -2.350,Avg.Loss: -2.348,LR: 1.88E-04]Training epoch 59:   3%|▎         | 4/153 [00:00<00:03, 47.25it/s, Epoch: 59, Batch: 5,Loss: -1.966,Avg.Loss: -2.271,LR: 1.88E-04]Training epoch 59:   3%|▎         | 5/153 [00:00<00:03, 47.74it/s, Epoch: 59, Batch: 6,Loss: -1.849,Avg.Loss: -2.201,LR: 1.88E-04]Training epoch 59:   4%|▍         | 6/153 [00:00<00:02, 57.18it/s, Epoch: 59, Batch: 6,Loss: -1.849,Avg.Loss: -2.201,LR: 1.88E-04]Training epoch 59:   4%|▍         | 6/153 [00:00<00:02, 57.18it/s, Epoch: 59, Batch: 7,Loss: -2.060,Avg.Loss: -2.181,LR: 1.87E-04]Training epoch 59:   5%|▍         | 7/153 [00:00<00:02, 57.18it/s, Epoch: 59, Batch: 8,Loss: -2.562,Avg.Loss: -2.228,LR: 1.87E-04]Training epoch 59:   5%|▌         | 8/153 [00:00<00:02, 57.18it/s, Epoch: 59, Batch: 9,Loss: -2.529,Avg.Loss: -2.262,LR: 1.87E-04]Training epoch 59:   6%|▌         | 9/153 [00:00<00:02, 57.18it/s, Epoch: 59, Batch: 10,Loss: -1.916,Avg.Loss: -2.227,LR: 1.87E-04]Training epoch 59:   7%|▋         | 10/153 [00:00<00:02, 57.18it/s, Epoch: 59, Batch: 11,Loss: -1.984,Avg.Loss: -2.205,LR: 1.87E-04]Training epoch 59:   7%|▋         | 11/153 [00:00<00:02, 57.18it/s, Epoch: 59, Batch: 12,Loss: -2.627,Avg.Loss: -2.240,LR: 1.87E-04]Training epoch 59:   8%|▊         | 12/153 [00:00<00:02, 54.01it/s, Epoch: 59, Batch: 12,Loss: -2.627,Avg.Loss: -2.240,LR: 1.87E-04]Training epoch 59:   8%|▊         | 12/153 [00:00<00:02, 54.01it/s, Epoch: 59, Batch: 13,Loss: -2.384,Avg.Loss: -2.251,LR: 1.87E-04]Training epoch 59:   8%|▊         | 13/153 [00:00<00:02, 54.01it/s, Epoch: 59, Batch: 14,Loss: -1.848,Avg.Loss: -2.223,LR: 1.87E-04]Training epoch 59:   9%|▉         | 14/153 [00:00<00:02, 54.01it/s, Epoch: 59, Batch: 15,Loss: -2.027,Avg.Loss: -2.210,LR: 1.87E-04]Training epoch 59:  10%|▉         | 15/153 [00:00<00:02, 54.01it/s, Epoch: 59, Batch: 16,Loss: -2.667,Avg.Loss: -2.238,LR: 1.87E-04]Training epoch 59:  10%|█         | 16/153 [00:00<00:02, 54.01it/s, Epoch: 59, Batch: 17,Loss: -2.360,Avg.Loss: -2.245,LR: 1.87E-04]Training epoch 59:  11%|█         | 17/153 [00:00<00:02, 54.01it/s, Epoch: 59, Batch: 18,Loss: -2.038,Avg.Loss: -2.234,LR: 1.87E-04]Training epoch 59:  12%|█▏        | 18/153 [00:00<00:02, 53.83it/s, Epoch: 59, Batch: 18,Loss: -2.038,Avg.Loss: -2.234,LR: 1.87E-04]Training epoch 59:  12%|█▏        | 18/153 [00:00<00:02, 53.83it/s, Epoch: 59, Batch: 19,Loss: -1.922,Avg.Loss: -2.217,LR: 1.87E-04]Training epoch 59:  12%|█▏        | 19/153 [00:00<00:02, 53.83it/s, Epoch: 59, Batch: 20,Loss: -3.256,Avg.Loss: -2.269,LR: 1.87E-04]Training epoch 59:  13%|█▎        | 20/153 [00:00<00:02, 53.83it/s, Epoch: 59, Batch: 21,Loss: -2.619,Avg.Loss: -2.286,LR: 1.87E-04]Training epoch 59:  14%|█▎        | 21/153 [00:00<00:02, 53.83it/s, Epoch: 59, Batch: 22,Loss: -2.389,Avg.Loss: -2.291,LR: 1.87E-04]Training epoch 59:  14%|█▍        | 22/153 [00:00<00:02, 53.83it/s, Epoch: 59, Batch: 23,Loss: -2.701,Avg.Loss: -2.309,LR: 1.87E-04]Training epoch 59:  15%|█▌        | 23/153 [00:00<00:02, 53.83it/s, Epoch: 59, Batch: 24,Loss: -3.060,Avg.Loss: -2.340,LR: 1.87E-04]Training epoch 59:  16%|█▌        | 24/153 [00:00<00:02, 52.25it/s, Epoch: 59, Batch: 24,Loss: -3.060,Avg.Loss: -2.340,LR: 1.87E-04]Training epoch 59:  16%|█▌        | 24/153 [00:00<00:02, 52.25it/s, Epoch: 59, Batch: 25,Loss: -2.716,Avg.Loss: -2.355,LR: 1.87E-04]Training epoch 59:  16%|█▋        | 25/153 [00:00<00:02, 52.25it/s, Epoch: 59, Batch: 26,Loss: -2.276,Avg.Loss: -2.352,LR: 1.87E-04]Training epoch 59:  17%|█▋        | 26/153 [00:00<00:02, 52.25it/s, Epoch: 59, Batch: 27,Loss: -2.236,Avg.Loss: -2.348,LR: 1.86E-04]Training epoch 59:  18%|█▊        | 27/153 [00:00<00:02, 52.25it/s, Epoch: 59, Batch: 28,Loss: -2.702,Avg.Loss: -2.360,LR: 1.86E-04]Training epoch 59:  18%|█▊        | 28/153 [00:00<00:02, 52.25it/s, Epoch: 59, Batch: 29,Loss: -2.424,Avg.Loss: -2.362,LR: 1.86E-04]Training epoch 59:  19%|█▉        | 29/153 [00:00<00:02, 52.25it/s, Epoch: 59, Batch: 30,Loss: -2.038,Avg.Loss: -2.352,LR: 1.86E-04]Training epoch 59:  20%|█▉        | 30/153 [00:00<00:02, 51.96it/s, Epoch: 59, Batch: 30,Loss: -2.038,Avg.Loss: -2.352,LR: 1.86E-04]Training epoch 59:  20%|█▉        | 30/153 [00:00<00:02, 51.96it/s, Epoch: 59, Batch: 31,Loss: -2.699,Avg.Loss: -2.363,LR: 1.86E-04]Training epoch 59:  20%|██        | 31/153 [00:00<00:02, 51.96it/s, Epoch: 59, Batch: 32,Loss: -2.774,Avg.Loss: -2.376,LR: 1.86E-04]Training epoch 59:  21%|██        | 32/153 [00:00<00:02, 51.96it/s, Epoch: 59, Batch: 33,Loss: -2.831,Avg.Loss: -2.389,LR: 1.86E-04]Training epoch 59:  22%|██▏       | 33/153 [00:00<00:02, 51.96it/s, Epoch: 59, Batch: 34,Loss: -2.285,Avg.Loss: -2.386,LR: 1.86E-04]Training epoch 59:  22%|██▏       | 34/153 [00:00<00:02, 51.96it/s, Epoch: 59, Batch: 35,Loss: -2.078,Avg.Loss: -2.378,LR: 1.86E-04]Training epoch 59:  23%|██▎       | 35/153 [00:00<00:02, 51.96it/s, Epoch: 59, Batch: 36,Loss: -1.903,Avg.Loss: -2.364,LR: 1.86E-04]Training epoch 59:  24%|██▎       | 36/153 [00:00<00:02, 52.35it/s, Epoch: 59, Batch: 36,Loss: -1.903,Avg.Loss: -2.364,LR: 1.86E-04]Training epoch 59:  24%|██▎       | 36/153 [00:00<00:02, 52.35it/s, Epoch: 59, Batch: 37,Loss: -1.910,Avg.Loss: -2.352,LR: 1.86E-04]Training epoch 59:  24%|██▍       | 37/153 [00:00<00:02, 52.35it/s, Epoch: 59, Batch: 38,Loss: -2.716,Avg.Loss: -2.362,LR: 1.86E-04]Training epoch 59:  25%|██▍       | 38/153 [00:00<00:02, 52.35it/s, Epoch: 59, Batch: 39,Loss: -2.369,Avg.Loss: -2.362,LR: 1.86E-04]Training epoch 59:  25%|██▌       | 39/153 [00:00<00:02, 52.35it/s, Epoch: 59, Batch: 40,Loss: -1.957,Avg.Loss: -2.352,LR: 1.86E-04]Training epoch 59:  26%|██▌       | 40/153 [00:00<00:02, 52.35it/s, Epoch: 59, Batch: 41,Loss: -1.575,Avg.Loss: -2.333,LR: 1.86E-04]Training epoch 59:  27%|██▋       | 41/153 [00:00<00:02, 52.35it/s, Epoch: 59, Batch: 42,Loss: -2.296,Avg.Loss: -2.332,LR: 1.86E-04]Training epoch 59:  27%|██▋       | 42/153 [00:00<00:02, 52.55it/s, Epoch: 59, Batch: 42,Loss: -2.296,Avg.Loss: -2.332,LR: 1.86E-04]Training epoch 59:  27%|██▋       | 42/153 [00:00<00:02, 52.55it/s, Epoch: 59, Batch: 43,Loss: -2.538,Avg.Loss: -2.337,LR: 1.86E-04]Training epoch 59:  28%|██▊       | 43/153 [00:00<00:02, 52.55it/s, Epoch: 59, Batch: 44,Loss: -2.199,Avg.Loss: -2.334,LR: 1.86E-04]Training epoch 59:  29%|██▉       | 44/153 [00:00<00:02, 52.55it/s, Epoch: 59, Batch: 45,Loss: -2.569,Avg.Loss: -2.339,LR: 1.86E-04]Training epoch 59:  29%|██▉       | 45/153 [00:00<00:02, 52.55it/s, Epoch: 59, Batch: 46,Loss: -1.998,Avg.Loss: -2.331,LR: 1.86E-04]Training epoch 59:  30%|███       | 46/153 [00:00<00:02, 52.55it/s, Epoch: 59, Batch: 47,Loss: -1.918,Avg.Loss: -2.323,LR: 1.85E-04]Training epoch 59:  31%|███       | 47/153 [00:00<00:02, 52.55it/s, Epoch: 59, Batch: 48,Loss: -2.417,Avg.Loss: -2.325,LR: 1.85E-04]Training epoch 59:  31%|███▏      | 48/153 [00:00<00:01, 52.72it/s, Epoch: 59, Batch: 48,Loss: -2.417,Avg.Loss: -2.325,LR: 1.85E-04]Training epoch 59:  31%|███▏      | 48/153 [00:00<00:01, 52.72it/s, Epoch: 59, Batch: 49,Loss: -2.345,Avg.Loss: -2.325,LR: 1.85E-04]Training epoch 59:  32%|███▏      | 49/153 [00:00<00:01, 52.72it/s, Epoch: 59, Batch: 50,Loss: -2.586,Avg.Loss: -2.330,LR: 1.85E-04]Training epoch 59:  33%|███▎      | 50/153 [00:00<00:01, 52.72it/s, Epoch: 59, Batch: 51,Loss: -2.843,Avg.Loss: -2.340,LR: 1.85E-04]Training epoch 59:  33%|███▎      | 51/153 [00:00<00:01, 52.72it/s, Epoch: 59, Batch: 52,Loss: -2.765,Avg.Loss: -2.348,LR: 1.85E-04]Training epoch 59:  34%|███▍      | 52/153 [00:01<00:01, 52.72it/s, Epoch: 59, Batch: 53,Loss: -2.593,Avg.Loss: -2.353,LR: 1.85E-04]Training epoch 59:  35%|███▍      | 53/153 [00:01<00:01, 52.72it/s, Epoch: 59, Batch: 54,Loss: -2.514,Avg.Loss: -2.356,LR: 1.85E-04]Training epoch 59:  35%|███▌      | 54/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 54,Loss: -2.514,Avg.Loss: -2.356,LR: 1.85E-04]Training epoch 59:  35%|███▌      | 54/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 55,Loss: -2.574,Avg.Loss: -2.360,LR: 1.85E-04]Training epoch 59:  36%|███▌      | 55/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 56,Loss: -2.513,Avg.Loss: -2.363,LR: 1.85E-04]Training epoch 59:  37%|███▋      | 56/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 57,Loss: -2.124,Avg.Loss: -2.359,LR: 1.85E-04]Training epoch 59:  37%|███▋      | 57/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 58,Loss: -2.495,Avg.Loss: -2.361,LR: 1.85E-04]Training epoch 59:  38%|███▊      | 58/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 59,Loss: -2.919,Avg.Loss: -2.370,LR: 1.85E-04]Training epoch 59:  39%|███▊      | 59/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 60,Loss: -2.209,Avg.Loss: -2.368,LR: 1.85E-04]Training epoch 59:  39%|███▉      | 60/153 [00:01<00:01, 52.81it/s, Epoch: 59, Batch: 60,Loss: -2.209,Avg.Loss: -2.368,LR: 1.85E-04]Training epoch 59:  39%|███▉      | 60/153 [00:01<00:01, 52.81it/s, Epoch: 59, Batch: 61,Loss: -2.668,Avg.Loss: -2.373,LR: 1.85E-04]Training epoch 59:  40%|███▉      | 61/153 [00:01<00:01, 52.81it/s, Epoch: 59, Batch: 62,Loss: -2.717,Avg.Loss: -2.378,LR: 1.85E-04]Training epoch 59:  41%|████      | 62/153 [00:01<00:01, 52.81it/s, Epoch: 59, Batch: 63,Loss: -2.341,Avg.Loss: -2.378,LR: 1.85E-04]Training epoch 59:  41%|████      | 63/153 [00:01<00:01, 52.81it/s, Epoch: 59, Batch: 64,Loss: -2.884,Avg.Loss: -2.385,LR: 1.85E-04]Training epoch 59:  42%|████▏     | 64/153 [00:01<00:01, 52.81it/s, Epoch: 59, Batch: 65,Loss: -2.768,Avg.Loss: -2.391,LR: 1.85E-04]Training epoch 59:  42%|████▏     | 65/153 [00:01<00:01, 52.81it/s, Epoch: 59, Batch: 66,Loss: -2.767,Avg.Loss: -2.397,LR: 1.85E-04]Training epoch 59:  43%|████▎     | 66/153 [00:01<00:01, 52.96it/s, Epoch: 59, Batch: 66,Loss: -2.767,Avg.Loss: -2.397,LR: 1.85E-04]Training epoch 59:  43%|████▎     | 66/153 [00:01<00:01, 52.96it/s, Epoch: 59, Batch: 67,Loss: -2.612,Avg.Loss: -2.400,LR: 1.85E-04]Training epoch 59:  44%|████▍     | 67/153 [00:01<00:01, 52.96it/s, Epoch: 59, Batch: 68,Loss: -2.210,Avg.Loss: -2.397,LR: 1.84E-04]Training epoch 59:  44%|████▍     | 68/153 [00:01<00:01, 52.96it/s, Epoch: 59, Batch: 69,Loss: -2.833,Avg.Loss: -2.404,LR: 1.84E-04]Training epoch 59:  45%|████▌     | 69/153 [00:01<00:01, 52.96it/s, Epoch: 59, Batch: 70,Loss: -2.675,Avg.Loss: -2.408,LR: 1.84E-04]Training epoch 59:  46%|████▌     | 70/153 [00:01<00:01, 52.96it/s, Epoch: 59, Batch: 71,Loss: -2.403,Avg.Loss: -2.408,LR: 1.84E-04]Training epoch 59:  46%|████▋     | 71/153 [00:01<00:01, 52.96it/s, Epoch: 59, Batch: 72,Loss: -2.014,Avg.Loss: -2.402,LR: 1.84E-04]Training epoch 59:  47%|████▋     | 72/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 72,Loss: -2.014,Avg.Loss: -2.402,LR: 1.84E-04]Training epoch 59:  47%|████▋     | 72/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 73,Loss: -2.532,Avg.Loss: -2.404,LR: 1.84E-04]Training epoch 59:  48%|████▊     | 73/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 74,Loss: -2.812,Avg.Loss: -2.409,LR: 1.84E-04]Training epoch 59:  48%|████▊     | 74/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 75,Loss: -2.081,Avg.Loss: -2.405,LR: 1.84E-04]Training epoch 59:  49%|████▉     | 75/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 76,Loss: -2.193,Avg.Loss: -2.402,LR: 1.84E-04]Training epoch 59:  50%|████▉     | 76/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 77,Loss: -2.754,Avg.Loss: -2.407,LR: 1.84E-04]Training epoch 59:  50%|█████     | 77/153 [00:01<00:01, 52.82it/s, Epoch: 59, Batch: 78,Loss: -2.301,Avg.Loss: -2.405,LR: 1.84E-04]Training epoch 59:  51%|█████     | 78/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 78,Loss: -2.301,Avg.Loss: -2.405,LR: 1.84E-04]Training epoch 59:  51%|█████     | 78/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 79,Loss: -2.508,Avg.Loss: -2.407,LR: 1.84E-04]Training epoch 59:  52%|█████▏    | 79/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 80,Loss: -2.218,Avg.Loss: -2.404,LR: 1.84E-04]Training epoch 59:  52%|█████▏    | 80/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 81,Loss: -2.531,Avg.Loss: -2.406,LR: 1.84E-04]Training epoch 59:  53%|█████▎    | 81/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 82,Loss: -2.370,Avg.Loss: -2.405,LR: 1.84E-04]Training epoch 59:  54%|█████▎    | 82/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 83,Loss: -1.610,Avg.Loss: -2.396,LR: 1.84E-04]Training epoch 59:  54%|█████▍    | 83/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 84,Loss: -1.277,Avg.Loss: -2.383,LR: 1.84E-04]Training epoch 59:  55%|█████▍    | 84/153 [00:01<00:01, 52.86it/s, Epoch: 59, Batch: 84,Loss: -1.277,Avg.Loss: -2.383,LR: 1.84E-04]Training epoch 59:  55%|█████▍    | 84/153 [00:01<00:01, 52.86it/s, Epoch: 59, Batch: 85,Loss: -1.687,Avg.Loss: -2.374,LR: 1.84E-04]Training epoch 59:  56%|█████▌    | 85/153 [00:01<00:01, 52.86it/s, Epoch: 59, Batch: 86,Loss: -1.895,Avg.Loss: -2.369,LR: 1.84E-04]Training epoch 59:  56%|█████▌    | 86/153 [00:01<00:01, 52.86it/s, Epoch: 59, Batch: 87,Loss: -2.183,Avg.Loss: -2.367,LR: 1.84E-04]Training epoch 59:  57%|█████▋    | 87/153 [00:01<00:01, 52.86it/s, Epoch: 59, Batch: 88,Loss: -2.393,Avg.Loss: -2.367,LR: 1.83E-04]Training epoch 59:  58%|█████▊    | 88/153 [00:01<00:01, 52.86it/s, Epoch: 59, Batch: 89,Loss: -1.722,Avg.Loss: -2.360,LR: 1.83E-04]Training epoch 59:  58%|█████▊    | 89/153 [00:01<00:01, 52.86it/s, Epoch: 59, Batch: 90,Loss: -1.395,Avg.Loss: -2.349,LR: 1.83E-04]Training epoch 59:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 59, Batch: 90,Loss: -1.395,Avg.Loss: -2.349,LR: 1.83E-04]Training epoch 59:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 59, Batch: 91,Loss: -1.505,Avg.Loss: -2.340,LR: 1.83E-04]Training epoch 59:  59%|█████▉    | 91/153 [00:01<00:01, 52.91it/s, Epoch: 59, Batch: 92,Loss: -2.660,Avg.Loss: -2.343,LR: 1.83E-04]Training epoch 59:  60%|██████    | 92/153 [00:01<00:01, 52.91it/s, Epoch: 59, Batch: 93,Loss: -1.425,Avg.Loss: -2.333,LR: 1.83E-04]Training epoch 59:  61%|██████    | 93/153 [00:01<00:01, 52.91it/s, Epoch: 59, Batch: 94,Loss: -2.398,Avg.Loss: -2.334,LR: 1.83E-04]Training epoch 59:  61%|██████▏   | 94/153 [00:01<00:01, 52.91it/s, Epoch: 59, Batch: 95,Loss: -3.211,Avg.Loss: -2.343,LR: 1.83E-04]Training epoch 59:  62%|██████▏   | 95/153 [00:01<00:01, 52.91it/s, Epoch: 59, Batch: 96,Loss: -2.408,Avg.Loss: -2.344,LR: 1.83E-04]Training epoch 59:  63%|██████▎   | 96/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 96,Loss: -2.408,Avg.Loss: -2.344,LR: 1.83E-04]Training epoch 59:  63%|██████▎   | 96/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 97,Loss: -1.858,Avg.Loss: -2.339,LR: 1.83E-04]Training epoch 59:  63%|██████▎   | 97/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 98,Loss: -2.150,Avg.Loss: -2.337,LR: 1.83E-04]Training epoch 59:  64%|██████▍   | 98/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 99,Loss: -2.153,Avg.Loss: -2.335,LR: 1.83E-04]Training epoch 59:  65%|██████▍   | 99/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 100,Loss: -2.099,Avg.Loss: -2.333,LR: 1.83E-04]Training epoch 59:  65%|██████▌   | 100/153 [00:01<00:01, 52.83it/s, Epoch: 59, Batch: 101,Loss: -1.969,Avg.Loss: -2.329,LR: 1.83E-04]Training epoch 59:  66%|██████▌   | 101/153 [00:01<00:00, 52.83it/s, Epoch: 59, Batch: 102,Loss: -1.991,Avg.Loss: -2.326,LR: 1.83E-04]Training epoch 59:  67%|██████▋   | 102/153 [00:01<00:00, 53.00it/s, Epoch: 59, Batch: 102,Loss: -1.991,Avg.Loss: -2.326,LR: 1.83E-04]Training epoch 59:  67%|██████▋   | 102/153 [00:01<00:00, 53.00it/s, Epoch: 59, Batch: 103,Loss: -2.028,Avg.Loss: -2.323,LR: 1.83E-04]Training epoch 59:  67%|██████▋   | 103/153 [00:01<00:00, 53.00it/s, Epoch: 59, Batch: 104,Loss: -2.739,Avg.Loss: -2.327,LR: 1.83E-04]Training epoch 59:  68%|██████▊   | 104/153 [00:01<00:00, 53.00it/s, Epoch: 59, Batch: 105,Loss: -2.537,Avg.Loss: -2.329,LR: 1.83E-04]Training epoch 59:  69%|██████▊   | 105/153 [00:02<00:00, 53.00it/s, Epoch: 59, Batch: 106,Loss: -2.196,Avg.Loss: -2.328,LR: 1.83E-04]Training epoch 59:  69%|██████▉   | 106/153 [00:02<00:00, 53.00it/s, Epoch: 59, Batch: 107,Loss: -2.328,Avg.Loss: -2.328,LR: 1.83E-04]Training epoch 59:  70%|██████▉   | 107/153 [00:02<00:00, 53.00it/s, Epoch: 59, Batch: 108,Loss: -2.785,Avg.Loss: -2.332,LR: 1.82E-04]Training epoch 59:  71%|███████   | 108/153 [00:02<00:00, 52.65it/s, Epoch: 59, Batch: 108,Loss: -2.785,Avg.Loss: -2.332,LR: 1.82E-04]Training epoch 59:  71%|███████   | 108/153 [00:02<00:00, 52.65it/s, Epoch: 59, Batch: 109,Loss: -2.509,Avg.Loss: -2.334,LR: 1.82E-04]Training epoch 59:  71%|███████   | 109/153 [00:02<00:00, 52.65it/s, Epoch: 59, Batch: 110,Loss: -2.487,Avg.Loss: -2.335,LR: 1.82E-04]Training epoch 59:  72%|███████▏  | 110/153 [00:02<00:00, 52.65it/s, Epoch: 59, Batch: 111,Loss: -2.951,Avg.Loss: -2.341,LR: 1.82E-04]Training epoch 59:  73%|███████▎  | 111/153 [00:02<00:00, 52.65it/s, Epoch: 59, Batch: 112,Loss: -2.544,Avg.Loss: -2.342,LR: 1.82E-04]Training epoch 59:  73%|███████▎  | 112/153 [00:02<00:00, 52.65it/s, Epoch: 59, Batch: 113,Loss: -1.793,Avg.Loss: -2.337,LR: 1.82E-04]Training epoch 59:  74%|███████▍  | 113/153 [00:02<00:00, 52.65it/s, Epoch: 59, Batch: 114,Loss: -1.306,Avg.Loss: -2.328,LR: 1.82E-04]Training epoch 59:  75%|███████▍  | 114/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 114,Loss: -1.306,Avg.Loss: -2.328,LR: 1.82E-04]Training epoch 59:  75%|███████▍  | 114/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 115,Loss: -1.861,Avg.Loss: -2.324,LR: 1.82E-04]Training epoch 59:  75%|███████▌  | 115/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 116,Loss: -2.000,Avg.Loss: -2.322,LR: 1.82E-04]Training epoch 59:  76%|███████▌  | 116/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 117,Loss: -2.322,Avg.Loss: -2.322,LR: 1.82E-04]Training epoch 59:  76%|███████▋  | 117/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 118,Loss: -2.467,Avg.Loss: -2.323,LR: 1.82E-04]Training epoch 59:  77%|███████▋  | 118/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 119,Loss: -2.371,Avg.Loss: -2.323,LR: 1.82E-04]Training epoch 59:  78%|███████▊  | 119/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 120,Loss: -2.437,Avg.Loss: -2.324,LR: 1.82E-04]Training epoch 59:  78%|███████▊  | 120/153 [00:02<00:00, 52.57it/s, Epoch: 59, Batch: 120,Loss: -2.437,Avg.Loss: -2.324,LR: 1.82E-04]Training epoch 59:  78%|███████▊  | 120/153 [00:02<00:00, 52.57it/s, Epoch: 59, Batch: 121,Loss: -2.198,Avg.Loss: -2.323,LR: 1.82E-04]Training epoch 59:  79%|███████▉  | 121/153 [00:02<00:00, 52.57it/s, Epoch: 59, Batch: 122,Loss: -2.289,Avg.Loss: -2.323,LR: 1.82E-04]Training epoch 59:  80%|███████▉  | 122/153 [00:02<00:00, 52.57it/s, Epoch: 59, Batch: 123,Loss: -2.325,Avg.Loss: -2.323,LR: 1.82E-04]Training epoch 59:  80%|████████  | 123/153 [00:02<00:00, 52.57it/s, Epoch: 59, Batch: 124,Loss: -2.481,Avg.Loss: -2.324,LR: 1.82E-04]Training epoch 59:  81%|████████  | 124/153 [00:02<00:00, 52.57it/s, Epoch: 59, Batch: 125,Loss: -2.417,Avg.Loss: -2.325,LR: 1.82E-04]Training epoch 59:  82%|████████▏ | 125/153 [00:02<00:00, 52.57it/s, Epoch: 59, Batch: 126,Loss: -2.361,Avg.Loss: -2.325,LR: 1.82E-04]Training epoch 59:  82%|████████▏ | 126/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 126,Loss: -2.361,Avg.Loss: -2.325,LR: 1.82E-04]Training epoch 59:  82%|████████▏ | 126/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 127,Loss: -1.435,Avg.Loss: -2.318,LR: 1.82E-04]Training epoch 59:  83%|████████▎ | 127/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 128,Loss: -2.457,Avg.Loss: -2.319,LR: 1.81E-04]Training epoch 59:  84%|████████▎ | 128/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 129,Loss: -2.729,Avg.Loss: -2.322,LR: 1.81E-04]Training epoch 59:  84%|████████▍ | 129/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 130,Loss: -1.792,Avg.Loss: -2.318,LR: 1.81E-04]Training epoch 59:  85%|████████▍ | 130/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 131,Loss: -1.336,Avg.Loss: -2.311,LR: 1.81E-04]Training epoch 59:  86%|████████▌ | 131/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 132,Loss: -2.515,Avg.Loss: -2.312,LR: 1.81E-04]Training epoch 59:  86%|████████▋ | 132/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 132,Loss: -2.515,Avg.Loss: -2.312,LR: 1.81E-04]Training epoch 59:  86%|████████▋ | 132/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 133,Loss: -2.668,Avg.Loss: -2.315,LR: 1.81E-04]Training epoch 59:  87%|████████▋ | 133/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 134,Loss: -2.289,Avg.Loss: -2.315,LR: 1.81E-04]Training epoch 59:  88%|████████▊ | 134/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 135,Loss: -2.525,Avg.Loss: -2.316,LR: 1.81E-04]Training epoch 59:  88%|████████▊ | 135/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 136,Loss: -2.618,Avg.Loss: -2.319,LR: 1.81E-04]Training epoch 59:  89%|████████▉ | 136/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 137,Loss: -2.441,Avg.Loss: -2.320,LR: 1.81E-04]Training epoch 59:  90%|████████▉ | 137/153 [00:02<00:00, 52.66it/s, Epoch: 59, Batch: 138,Loss: -2.858,Avg.Loss: -2.323,LR: 1.81E-04]Training epoch 59:  90%|█████████ | 138/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 138,Loss: -2.858,Avg.Loss: -2.323,LR: 1.81E-04]Training epoch 59:  90%|█████████ | 138/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 139,Loss: -2.691,Avg.Loss: -2.326,LR: 1.81E-04]Training epoch 59:  91%|█████████ | 139/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 140,Loss: -2.688,Avg.Loss: -2.329,LR: 1.81E-04]Training epoch 59:  92%|█████████▏| 140/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 141,Loss: -2.121,Avg.Loss: -2.327,LR: 1.81E-04]Training epoch 59:  92%|█████████▏| 141/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 142,Loss: -2.027,Avg.Loss: -2.325,LR: 1.81E-04]Training epoch 59:  93%|█████████▎| 142/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 143,Loss: -2.727,Avg.Loss: -2.328,LR: 1.81E-04]Training epoch 59:  93%|█████████▎| 143/153 [00:02<00:00, 52.58it/s, Epoch: 59, Batch: 144,Loss: -2.254,Avg.Loss: -2.327,LR: 1.81E-04]Training epoch 59:  94%|█████████▍| 144/153 [00:02<00:00, 52.78it/s, Epoch: 59, Batch: 144,Loss: -2.254,Avg.Loss: -2.327,LR: 1.81E-04]Training epoch 59:  94%|█████████▍| 144/153 [00:02<00:00, 52.78it/s, Epoch: 59, Batch: 145,Loss: -2.332,Avg.Loss: -2.327,LR: 1.81E-04]Training epoch 59:  95%|█████████▍| 145/153 [00:02<00:00, 52.78it/s, Epoch: 59, Batch: 146,Loss: -2.774,Avg.Loss: -2.330,LR: 1.81E-04]Training epoch 59:  95%|█████████▌| 146/153 [00:02<00:00, 52.78it/s, Epoch: 59, Batch: 147,Loss: -3.025,Avg.Loss: -2.335,LR: 1.81E-04]Training epoch 59:  96%|█████████▌| 147/153 [00:02<00:00, 52.78it/s, Epoch: 59, Batch: 148,Loss: -2.192,Avg.Loss: -2.334,LR: 1.80E-04]Training epoch 59:  97%|█████████▋| 148/153 [00:02<00:00, 52.78it/s, Epoch: 59, Batch: 149,Loss: -2.929,Avg.Loss: -2.338,LR: 1.80E-04]Training epoch 59:  97%|█████████▋| 149/153 [00:02<00:00, 52.78it/s, Epoch: 59, Batch: 150,Loss: -2.986,Avg.Loss: -2.343,LR: 1.80E-04]Training epoch 59:  98%|█████████▊| 150/153 [00:02<00:00, 52.87it/s, Epoch: 59, Batch: 150,Loss: -2.986,Avg.Loss: -2.343,LR: 1.80E-04]Training epoch 59:  98%|█████████▊| 150/153 [00:02<00:00, 52.87it/s, Epoch: 59, Batch: 151,Loss: -2.563,Avg.Loss: -2.344,LR: 1.80E-04]Training epoch 59:  99%|█████████▊| 151/153 [00:02<00:00, 52.87it/s, Epoch: 59, Batch: 152,Loss: -2.545,Avg.Loss: -2.345,LR: 1.80E-04]Training epoch 59:  99%|█████████▉| 152/153 [00:02<00:00, 52.87it/s, Epoch: 59, Batch: 153,Loss: -2.776,Avg.Loss: -2.348,LR: 1.80E-04]Training epoch 59: 100%|██████████| 153/153 [00:02<00:00, 52.77it/s, Epoch: 59, Batch: 153,Loss: -2.776,Avg.Loss: -2.348,LR: 1.80E-04]
Training epoch 60:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 60:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 60, Batch: 1,Loss: -2.216,Avg.Loss: -2.216,LR: 1.80E-04]Training epoch 60:   1%|          | 1/153 [00:00<00:05, 28.48it/s, Epoch: 60, Batch: 2,Loss: -2.780,Avg.Loss: -2.498,LR: 1.80E-04]Training epoch 60:   1%|▏         | 2/153 [00:00<00:03, 38.05it/s, Epoch: 60, Batch: 3,Loss: -2.534,Avg.Loss: -2.510,LR: 1.80E-04]Training epoch 60:   2%|▏         | 3/153 [00:00<00:03, 45.82it/s, Epoch: 60, Batch: 4,Loss: -2.506,Avg.Loss: -2.509,LR: 1.80E-04]Training epoch 60:   3%|▎         | 4/153 [00:00<00:02, 50.18it/s, Epoch: 60, Batch: 5,Loss: -2.971,Avg.Loss: -2.601,LR: 1.80E-04]Training epoch 60:   3%|▎         | 5/153 [00:00<00:02, 54.06it/s, Epoch: 60, Batch: 6,Loss: -2.823,Avg.Loss: -2.638,LR: 1.80E-04]Training epoch 60:   4%|▍         | 6/153 [00:00<00:02, 55.18it/s, Epoch: 60, Batch: 7,Loss: -2.327,Avg.Loss: -2.594,LR: 1.80E-04]Training epoch 60:   5%|▍         | 7/153 [00:00<00:02, 64.29it/s, Epoch: 60, Batch: 7,Loss: -2.327,Avg.Loss: -2.594,LR: 1.80E-04]Training epoch 60:   5%|▍         | 7/153 [00:00<00:02, 64.29it/s, Epoch: 60, Batch: 8,Loss: -2.727,Avg.Loss: -2.610,LR: 1.80E-04]Training epoch 60:   5%|▌         | 8/153 [00:00<00:02, 64.29it/s, Epoch: 60, Batch: 9,Loss: -2.028,Avg.Loss: -2.546,LR: 1.80E-04]Training epoch 60:   6%|▌         | 9/153 [00:00<00:02, 64.29it/s, Epoch: 60, Batch: 10,Loss: -2.537,Avg.Loss: -2.545,LR: 1.80E-04]Training epoch 60:   7%|▋         | 10/153 [00:00<00:02, 64.29it/s, Epoch: 60, Batch: 11,Loss: -2.172,Avg.Loss: -2.511,LR: 1.80E-04]Training epoch 60:   7%|▋         | 11/153 [00:00<00:02, 64.29it/s, Epoch: 60, Batch: 12,Loss: -2.342,Avg.Loss: -2.497,LR: 1.80E-04]Training epoch 60:   8%|▊         | 12/153 [00:00<00:02, 64.29it/s, Epoch: 60, Batch: 13,Loss: -2.007,Avg.Loss: -2.459,LR: 1.80E-04]Training epoch 60:   8%|▊         | 13/153 [00:00<00:02, 64.29it/s, Epoch: 60, Batch: 14,Loss: -3.075,Avg.Loss: -2.503,LR: 1.80E-04]Training epoch 60:   9%|▉         | 14/153 [00:00<00:02, 60.05it/s, Epoch: 60, Batch: 14,Loss: -3.075,Avg.Loss: -2.503,LR: 1.80E-04]Training epoch 60:   9%|▉         | 14/153 [00:00<00:02, 60.05it/s, Epoch: 60, Batch: 15,Loss: -2.804,Avg.Loss: -2.523,LR: 1.80E-04]Training epoch 60:  10%|▉         | 15/153 [00:00<00:02, 60.05it/s, Epoch: 60, Batch: 16,Loss: -2.628,Avg.Loss: -2.530,LR: 1.79E-04]Training epoch 60:  10%|█         | 16/153 [00:00<00:02, 60.05it/s, Epoch: 60, Batch: 17,Loss: -2.812,Avg.Loss: -2.546,LR: 1.79E-04]Training epoch 60:  11%|█         | 17/153 [00:00<00:02, 60.05it/s, Epoch: 60, Batch: 18,Loss: -2.687,Avg.Loss: -2.554,LR: 1.79E-04]Training epoch 60:  12%|█▏        | 18/153 [00:00<00:02, 60.05it/s, Epoch: 60, Batch: 19,Loss: -2.815,Avg.Loss: -2.568,LR: 1.79E-04]Training epoch 60:  12%|█▏        | 19/153 [00:00<00:02, 60.05it/s, Epoch: 60, Batch: 20,Loss: -2.524,Avg.Loss: -2.566,LR: 1.79E-04]Training epoch 60:  13%|█▎        | 20/153 [00:00<00:02, 60.05it/s, Epoch: 60, Batch: 21,Loss: -2.103,Avg.Loss: -2.544,LR: 1.79E-04]Training epoch 60:  14%|█▎        | 21/153 [00:00<00:02, 56.32it/s, Epoch: 60, Batch: 21,Loss: -2.103,Avg.Loss: -2.544,LR: 1.79E-04]Training epoch 60:  14%|█▎        | 21/153 [00:00<00:02, 56.32it/s, Epoch: 60, Batch: 22,Loss: -2.551,Avg.Loss: -2.544,LR: 1.79E-04]Training epoch 60:  14%|█▍        | 22/153 [00:00<00:02, 56.32it/s, Epoch: 60, Batch: 23,Loss: -3.028,Avg.Loss: -2.565,LR: 1.79E-04]Training epoch 60:  15%|█▌        | 23/153 [00:00<00:02, 56.32it/s, Epoch: 60, Batch: 24,Loss: -2.764,Avg.Loss: -2.573,LR: 1.79E-04]Training epoch 60:  16%|█▌        | 24/153 [00:00<00:02, 56.32it/s, Epoch: 60, Batch: 25,Loss: -2.761,Avg.Loss: -2.581,LR: 1.79E-04]Training epoch 60:  16%|█▋        | 25/153 [00:00<00:02, 56.32it/s, Epoch: 60, Batch: 26,Loss: -2.452,Avg.Loss: -2.576,LR: 1.79E-04]Training epoch 60:  17%|█▋        | 26/153 [00:00<00:02, 56.32it/s, Epoch: 60, Batch: 27,Loss: -2.956,Avg.Loss: -2.590,LR: 1.79E-04]Training epoch 60:  18%|█▊        | 27/153 [00:00<00:02, 54.03it/s, Epoch: 60, Batch: 27,Loss: -2.956,Avg.Loss: -2.590,LR: 1.79E-04]Training epoch 60:  18%|█▊        | 27/153 [00:00<00:02, 54.03it/s, Epoch: 60, Batch: 28,Loss: -2.917,Avg.Loss: -2.602,LR: 1.79E-04]Training epoch 60:  18%|█▊        | 28/153 [00:00<00:02, 54.03it/s, Epoch: 60, Batch: 29,Loss: -2.600,Avg.Loss: -2.602,LR: 1.79E-04]Training epoch 60:  19%|█▉        | 29/153 [00:00<00:02, 54.03it/s, Epoch: 60, Batch: 30,Loss: -2.742,Avg.Loss: -2.606,LR: 1.79E-04]Training epoch 60:  20%|█▉        | 30/153 [00:00<00:02, 54.03it/s, Epoch: 60, Batch: 31,Loss: -2.955,Avg.Loss: -2.617,LR: 1.79E-04]Training epoch 60:  20%|██        | 31/153 [00:00<00:02, 54.03it/s, Epoch: 60, Batch: 32,Loss: -1.763,Avg.Loss: -2.591,LR: 1.79E-04]Training epoch 60:  21%|██        | 32/153 [00:00<00:02, 54.03it/s, Epoch: 60, Batch: 33,Loss: -1.625,Avg.Loss: -2.561,LR: 1.79E-04]Training epoch 60:  22%|██▏       | 33/153 [00:00<00:02, 53.02it/s, Epoch: 60, Batch: 33,Loss: -1.625,Avg.Loss: -2.561,LR: 1.79E-04]Training epoch 60:  22%|██▏       | 33/153 [00:00<00:02, 53.02it/s, Epoch: 60, Batch: 34,Loss: -1.994,Avg.Loss: -2.545,LR: 1.79E-04]Training epoch 60:  22%|██▏       | 34/153 [00:00<00:02, 53.02it/s, Epoch: 60, Batch: 35,Loss: -2.278,Avg.Loss: -2.537,LR: 1.79E-04]Training epoch 60:  23%|██▎       | 35/153 [00:00<00:02, 53.02it/s, Epoch: 60, Batch: 36,Loss: -2.149,Avg.Loss: -2.526,LR: 1.78E-04]Training epoch 60:  24%|██▎       | 36/153 [00:00<00:02, 53.02it/s, Epoch: 60, Batch: 37,Loss: -2.145,Avg.Loss: -2.516,LR: 1.78E-04]Training epoch 60:  24%|██▍       | 37/153 [00:00<00:02, 53.02it/s, Epoch: 60, Batch: 38,Loss: -2.036,Avg.Loss: -2.503,LR: 1.78E-04]Training epoch 60:  25%|██▍       | 38/153 [00:00<00:02, 53.02it/s, Epoch: 60, Batch: 39,Loss: -2.612,Avg.Loss: -2.506,LR: 1.78E-04]Training epoch 60:  25%|██▌       | 39/153 [00:00<00:02, 53.01it/s, Epoch: 60, Batch: 39,Loss: -2.612,Avg.Loss: -2.506,LR: 1.78E-04]Training epoch 60:  25%|██▌       | 39/153 [00:00<00:02, 53.01it/s, Epoch: 60, Batch: 40,Loss: -2.398,Avg.Loss: -2.503,LR: 1.78E-04]Training epoch 60:  26%|██▌       | 40/153 [00:00<00:02, 53.01it/s, Epoch: 60, Batch: 41,Loss: -2.416,Avg.Loss: -2.501,LR: 1.78E-04]Training epoch 60:  27%|██▋       | 41/153 [00:00<00:02, 53.01it/s, Epoch: 60, Batch: 42,Loss: -2.660,Avg.Loss: -2.505,LR: 1.78E-04]Training epoch 60:  27%|██▋       | 42/153 [00:00<00:02, 53.01it/s, Epoch: 60, Batch: 43,Loss: -2.587,Avg.Loss: -2.507,LR: 1.78E-04]Training epoch 60:  28%|██▊       | 43/153 [00:00<00:02, 53.01it/s, Epoch: 60, Batch: 44,Loss: -2.928,Avg.Loss: -2.517,LR: 1.78E-04]Training epoch 60:  29%|██▉       | 44/153 [00:00<00:02, 53.01it/s, Epoch: 60, Batch: 45,Loss: -2.612,Avg.Loss: -2.519,LR: 1.78E-04]Training epoch 60:  29%|██▉       | 45/153 [00:00<00:02, 52.91it/s, Epoch: 60, Batch: 45,Loss: -2.612,Avg.Loss: -2.519,LR: 1.78E-04]Training epoch 60:  29%|██▉       | 45/153 [00:00<00:02, 52.91it/s, Epoch: 60, Batch: 46,Loss: -3.029,Avg.Loss: -2.530,LR: 1.78E-04]Training epoch 60:  30%|███       | 46/153 [00:00<00:02, 52.91it/s, Epoch: 60, Batch: 47,Loss: -2.375,Avg.Loss: -2.527,LR: 1.78E-04]Training epoch 60:  31%|███       | 47/153 [00:00<00:02, 52.91it/s, Epoch: 60, Batch: 48,Loss: -2.875,Avg.Loss: -2.534,LR: 1.78E-04]Training epoch 60:  31%|███▏      | 48/153 [00:00<00:01, 52.91it/s, Epoch: 60, Batch: 49,Loss: -3.081,Avg.Loss: -2.545,LR: 1.78E-04]Training epoch 60:  32%|███▏      | 49/153 [00:00<00:01, 52.91it/s, Epoch: 60, Batch: 50,Loss: -2.680,Avg.Loss: -2.548,LR: 1.78E-04]Training epoch 60:  33%|███▎      | 50/153 [00:00<00:01, 52.91it/s, Epoch: 60, Batch: 51,Loss: -2.621,Avg.Loss: -2.549,LR: 1.78E-04]Training epoch 60:  33%|███▎      | 51/153 [00:00<00:01, 52.79it/s, Epoch: 60, Batch: 51,Loss: -2.621,Avg.Loss: -2.549,LR: 1.78E-04]Training epoch 60:  33%|███▎      | 51/153 [00:00<00:01, 52.79it/s, Epoch: 60, Batch: 52,Loss: -2.773,Avg.Loss: -2.553,LR: 1.78E-04]Training epoch 60:  34%|███▍      | 52/153 [00:00<00:01, 52.79it/s, Epoch: 60, Batch: 53,Loss: -2.477,Avg.Loss: -2.552,LR: 1.78E-04]Training epoch 60:  35%|███▍      | 53/153 [00:00<00:01, 52.79it/s, Epoch: 60, Batch: 54,Loss: -3.134,Avg.Loss: -2.563,LR: 1.78E-04]Training epoch 60:  35%|███▌      | 54/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 55,Loss: -2.891,Avg.Loss: -2.569,LR: 1.78E-04]Training epoch 60:  36%|███▌      | 55/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 56,Loss: -2.899,Avg.Loss: -2.575,LR: 1.77E-04]Training epoch 60:  37%|███▋      | 56/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 57,Loss: -2.764,Avg.Loss: -2.578,LR: 1.77E-04]Training epoch 60:  37%|███▋      | 57/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 57,Loss: -2.764,Avg.Loss: -2.578,LR: 1.77E-04]Training epoch 60:  37%|███▋      | 57/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 58,Loss: -2.656,Avg.Loss: -2.579,LR: 1.77E-04]Training epoch 60:  38%|███▊      | 58/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 59,Loss: -2.022,Avg.Loss: -2.570,LR: 1.77E-04]Training epoch 60:  39%|███▊      | 59/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 60,Loss: -2.200,Avg.Loss: -2.564,LR: 1.77E-04]Training epoch 60:  39%|███▉      | 60/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 61,Loss: -1.782,Avg.Loss: -2.551,LR: 1.77E-04]Training epoch 60:  40%|███▉      | 61/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 62,Loss: -1.314,Avg.Loss: -2.531,LR: 1.77E-04]Training epoch 60:  41%|████      | 62/153 [00:01<00:01, 52.79it/s, Epoch: 60, Batch: 63,Loss: -2.368,Avg.Loss: -2.528,LR: 1.77E-04]Training epoch 60:  41%|████      | 63/153 [00:01<00:01, 52.95it/s, Epoch: 60, Batch: 63,Loss: -2.368,Avg.Loss: -2.528,LR: 1.77E-04]Training epoch 60:  41%|████      | 63/153 [00:01<00:01, 52.95it/s, Epoch: 60, Batch: 64,Loss: -2.991,Avg.Loss: -2.536,LR: 1.77E-04]Training epoch 60:  42%|████▏     | 64/153 [00:01<00:01, 52.95it/s, Epoch: 60, Batch: 65,Loss: -2.784,Avg.Loss: -2.539,LR: 1.77E-04]Training epoch 60:  42%|████▏     | 65/153 [00:01<00:01, 52.95it/s, Epoch: 60, Batch: 66,Loss: -2.892,Avg.Loss: -2.545,LR: 1.77E-04]Training epoch 60:  43%|████▎     | 66/153 [00:01<00:01, 52.95it/s, Epoch: 60, Batch: 67,Loss: -2.431,Avg.Loss: -2.543,LR: 1.77E-04]Training epoch 60:  44%|████▍     | 67/153 [00:01<00:01, 52.95it/s, Epoch: 60, Batch: 68,Loss: -2.319,Avg.Loss: -2.540,LR: 1.77E-04]Training epoch 60:  44%|████▍     | 68/153 [00:01<00:01, 52.95it/s, Epoch: 60, Batch: 69,Loss: -2.211,Avg.Loss: -2.535,LR: 1.77E-04]Training epoch 60:  45%|████▌     | 69/153 [00:01<00:01, 52.99it/s, Epoch: 60, Batch: 69,Loss: -2.211,Avg.Loss: -2.535,LR: 1.77E-04]Training epoch 60:  45%|████▌     | 69/153 [00:01<00:01, 52.99it/s, Epoch: 60, Batch: 70,Loss: -3.079,Avg.Loss: -2.543,LR: 1.77E-04]Training epoch 60:  46%|████▌     | 70/153 [00:01<00:01, 52.99it/s, Epoch: 60, Batch: 71,Loss: -2.909,Avg.Loss: -2.548,LR: 1.77E-04]Training epoch 60:  46%|████▋     | 71/153 [00:01<00:01, 52.99it/s, Epoch: 60, Batch: 72,Loss: -2.808,Avg.Loss: -2.551,LR: 1.77E-04]Training epoch 60:  47%|████▋     | 72/153 [00:01<00:01, 52.99it/s, Epoch: 60, Batch: 73,Loss: -2.247,Avg.Loss: -2.547,LR: 1.77E-04]Training epoch 60:  48%|████▊     | 73/153 [00:01<00:01, 52.99it/s, Epoch: 60, Batch: 74,Loss: -2.391,Avg.Loss: -2.545,LR: 1.77E-04]Training epoch 60:  48%|████▊     | 74/153 [00:01<00:01, 52.99it/s, Epoch: 60, Batch: 75,Loss: -1.909,Avg.Loss: -2.537,LR: 1.77E-04]Training epoch 60:  49%|████▉     | 75/153 [00:01<00:01, 52.88it/s, Epoch: 60, Batch: 75,Loss: -1.909,Avg.Loss: -2.537,LR: 1.77E-04]Training epoch 60:  49%|████▉     | 75/153 [00:01<00:01, 52.88it/s, Epoch: 60, Batch: 76,Loss: -2.257,Avg.Loss: -2.533,LR: 1.77E-04]Training epoch 60:  50%|████▉     | 76/153 [00:01<00:01, 52.88it/s, Epoch: 60, Batch: 77,Loss: -2.174,Avg.Loss: -2.528,LR: 1.76E-04]Training epoch 60:  50%|█████     | 77/153 [00:01<00:01, 52.88it/s, Epoch: 60, Batch: 78,Loss: -2.399,Avg.Loss: -2.527,LR: 1.76E-04]Training epoch 60:  51%|█████     | 78/153 [00:01<00:01, 52.88it/s, Epoch: 60, Batch: 79,Loss: -2.805,Avg.Loss: -2.530,LR: 1.76E-04]Training epoch 60:  52%|█████▏    | 79/153 [00:01<00:01, 52.88it/s, Epoch: 60, Batch: 80,Loss: -2.448,Avg.Loss: -2.529,LR: 1.76E-04]Training epoch 60:  52%|█████▏    | 80/153 [00:01<00:01, 52.88it/s, Epoch: 60, Batch: 81,Loss: -2.324,Avg.Loss: -2.527,LR: 1.76E-04]Training epoch 60:  53%|█████▎    | 81/153 [00:01<00:01, 53.12it/s, Epoch: 60, Batch: 81,Loss: -2.324,Avg.Loss: -2.527,LR: 1.76E-04]Training epoch 60:  53%|█████▎    | 81/153 [00:01<00:01, 53.12it/s, Epoch: 60, Batch: 82,Loss: -2.922,Avg.Loss: -2.532,LR: 1.76E-04]Training epoch 60:  54%|█████▎    | 82/153 [00:01<00:01, 53.12it/s, Epoch: 60, Batch: 83,Loss: -2.343,Avg.Loss: -2.529,LR: 1.76E-04]Training epoch 60:  54%|█████▍    | 83/153 [00:01<00:01, 53.12it/s, Epoch: 60, Batch: 84,Loss: -2.240,Avg.Loss: -2.526,LR: 1.76E-04]Training epoch 60:  55%|█████▍    | 84/153 [00:01<00:01, 53.12it/s, Epoch: 60, Batch: 85,Loss: -1.978,Avg.Loss: -2.519,LR: 1.76E-04]Training epoch 60:  56%|█████▌    | 85/153 [00:01<00:01, 53.12it/s, Epoch: 60, Batch: 86,Loss: -1.449,Avg.Loss: -2.507,LR: 1.76E-04]Training epoch 60:  56%|█████▌    | 86/153 [00:01<00:01, 53.12it/s, Epoch: 60, Batch: 87,Loss: -1.861,Avg.Loss: -2.499,LR: 1.76E-04]Training epoch 60:  57%|█████▋    | 87/153 [00:01<00:01, 53.21it/s, Epoch: 60, Batch: 87,Loss: -1.861,Avg.Loss: -2.499,LR: 1.76E-04]Training epoch 60:  57%|█████▋    | 87/153 [00:01<00:01, 53.21it/s, Epoch: 60, Batch: 88,Loss: -2.247,Avg.Loss: -2.497,LR: 1.76E-04]Training epoch 60:  58%|█████▊    | 88/153 [00:01<00:01, 53.21it/s, Epoch: 60, Batch: 89,Loss: -2.504,Avg.Loss: -2.497,LR: 1.76E-04]Training epoch 60:  58%|█████▊    | 89/153 [00:01<00:01, 53.21it/s, Epoch: 60, Batch: 90,Loss: -2.925,Avg.Loss: -2.501,LR: 1.76E-04]Training epoch 60:  59%|█████▉    | 90/153 [00:01<00:01, 53.21it/s, Epoch: 60, Batch: 91,Loss: -2.077,Avg.Loss: -2.497,LR: 1.76E-04]Training epoch 60:  59%|█████▉    | 91/153 [00:01<00:01, 53.21it/s, Epoch: 60, Batch: 92,Loss: -2.324,Avg.Loss: -2.495,LR: 1.76E-04]Training epoch 60:  60%|██████    | 92/153 [00:01<00:01, 53.21it/s, Epoch: 60, Batch: 93,Loss: -2.296,Avg.Loss: -2.493,LR: 1.76E-04]Training epoch 60:  61%|██████    | 93/153 [00:01<00:01, 52.96it/s, Epoch: 60, Batch: 93,Loss: -2.296,Avg.Loss: -2.493,LR: 1.76E-04]Training epoch 60:  61%|██████    | 93/153 [00:01<00:01, 52.96it/s, Epoch: 60, Batch: 94,Loss: -1.708,Avg.Loss: -2.484,LR: 1.76E-04]Training epoch 60:  61%|██████▏   | 94/153 [00:01<00:01, 52.96it/s, Epoch: 60, Batch: 95,Loss: -2.533,Avg.Loss: -2.485,LR: 1.76E-04]Training epoch 60:  62%|██████▏   | 95/153 [00:01<00:01, 52.96it/s, Epoch: 60, Batch: 96,Loss: -2.873,Avg.Loss: -2.489,LR: 1.76E-04]Training epoch 60:  63%|██████▎   | 96/153 [00:01<00:01, 52.96it/s, Epoch: 60, Batch: 97,Loss: -2.514,Avg.Loss: -2.489,LR: 1.75E-04]Training epoch 60:  63%|██████▎   | 97/153 [00:01<00:01, 52.96it/s, Epoch: 60, Batch: 98,Loss: -2.321,Avg.Loss: -2.488,LR: 1.75E-04]Training epoch 60:  64%|██████▍   | 98/153 [00:01<00:01, 52.96it/s, Epoch: 60, Batch: 99,Loss: -2.565,Avg.Loss: -2.488,LR: 1.75E-04]Training epoch 60:  65%|██████▍   | 99/153 [00:01<00:01, 52.91it/s, Epoch: 60, Batch: 99,Loss: -2.565,Avg.Loss: -2.488,LR: 1.75E-04]Training epoch 60:  65%|██████▍   | 99/153 [00:01<00:01, 52.91it/s, Epoch: 60, Batch: 100,Loss: -2.424,Avg.Loss: -2.488,LR: 1.75E-04]Training epoch 60:  65%|██████▌   | 100/153 [00:01<00:01, 52.91it/s, Epoch: 60, Batch: 101,Loss: -3.056,Avg.Loss: -2.493,LR: 1.75E-04]Training epoch 60:  66%|██████▌   | 101/153 [00:01<00:00, 52.91it/s, Epoch: 60, Batch: 102,Loss: -2.672,Avg.Loss: -2.495,LR: 1.75E-04]Training epoch 60:  67%|██████▋   | 102/153 [00:01<00:00, 52.91it/s, Epoch: 60, Batch: 103,Loss: -2.560,Avg.Loss: -2.496,LR: 1.75E-04]Training epoch 60:  67%|██████▋   | 103/153 [00:01<00:00, 52.91it/s, Epoch: 60, Batch: 104,Loss: -2.188,Avg.Loss: -2.493,LR: 1.75E-04]Training epoch 60:  68%|██████▊   | 104/153 [00:01<00:00, 52.91it/s, Epoch: 60, Batch: 105,Loss: -2.361,Avg.Loss: -2.491,LR: 1.75E-04]Training epoch 60:  69%|██████▊   | 105/153 [00:01<00:00, 52.88it/s, Epoch: 60, Batch: 105,Loss: -2.361,Avg.Loss: -2.491,LR: 1.75E-04]Training epoch 60:  69%|██████▊   | 105/153 [00:01<00:00, 52.88it/s, Epoch: 60, Batch: 106,Loss: -2.747,Avg.Loss: -2.494,LR: 1.75E-04]Training epoch 60:  69%|██████▉   | 106/153 [00:01<00:00, 52.88it/s, Epoch: 60, Batch: 107,Loss: -2.660,Avg.Loss: -2.495,LR: 1.75E-04]Training epoch 60:  70%|██████▉   | 107/153 [00:02<00:00, 52.88it/s, Epoch: 60, Batch: 108,Loss: -2.316,Avg.Loss: -2.494,LR: 1.75E-04]Training epoch 60:  71%|███████   | 108/153 [00:02<00:00, 52.88it/s, Epoch: 60, Batch: 109,Loss: -2.229,Avg.Loss: -2.491,LR: 1.75E-04]Training epoch 60:  71%|███████   | 109/153 [00:02<00:00, 52.88it/s, Epoch: 60, Batch: 110,Loss: -1.221,Avg.Loss: -2.480,LR: 1.75E-04]Training epoch 60:  72%|███████▏  | 110/153 [00:02<00:00, 52.88it/s, Epoch: 60, Batch: 111,Loss: -1.320,Avg.Loss: -2.469,LR: 1.75E-04]Training epoch 60:  73%|███████▎  | 111/153 [00:02<00:00, 52.83it/s, Epoch: 60, Batch: 111,Loss: -1.320,Avg.Loss: -2.469,LR: 1.75E-04]Training epoch 60:  73%|███████▎  | 111/153 [00:02<00:00, 52.83it/s, Epoch: 60, Batch: 112,Loss: -1.573,Avg.Loss: -2.461,LR: 1.75E-04]Training epoch 60:  73%|███████▎  | 112/153 [00:02<00:00, 52.83it/s, Epoch: 60, Batch: 113,Loss: -1.650,Avg.Loss: -2.454,LR: 1.75E-04]Training epoch 60:  74%|███████▍  | 113/153 [00:02<00:00, 52.83it/s, Epoch: 60, Batch: 114,Loss: -3.131,Avg.Loss: -2.460,LR: 1.75E-04]Training epoch 60:  75%|███████▍  | 114/153 [00:02<00:00, 52.83it/s, Epoch: 60, Batch: 115,Loss: -2.941,Avg.Loss: -2.464,LR: 1.75E-04]Training epoch 60:  75%|███████▌  | 115/153 [00:02<00:00, 52.83it/s, Epoch: 60, Batch: 116,Loss: -2.498,Avg.Loss: -2.465,LR: 1.75E-04]Training epoch 60:  76%|███████▌  | 116/153 [00:02<00:00, 52.83it/s, Epoch: 60, Batch: 117,Loss: -2.693,Avg.Loss: -2.466,LR: 1.75E-04]Training epoch 60:  76%|███████▋  | 117/153 [00:02<00:00, 52.84it/s, Epoch: 60, Batch: 117,Loss: -2.693,Avg.Loss: -2.466,LR: 1.75E-04]Training epoch 60:  76%|███████▋  | 117/153 [00:02<00:00, 52.84it/s, Epoch: 60, Batch: 118,Loss: -2.622,Avg.Loss: -2.468,LR: 1.74E-04]Training epoch 60:  77%|███████▋  | 118/153 [00:02<00:00, 52.84it/s, Epoch: 60, Batch: 119,Loss: -2.108,Avg.Loss: -2.465,LR: 1.74E-04]Training epoch 60:  78%|███████▊  | 119/153 [00:02<00:00, 52.84it/s, Epoch: 60, Batch: 120,Loss: -2.322,Avg.Loss: -2.464,LR: 1.74E-04]Training epoch 60:  78%|███████▊  | 120/153 [00:02<00:00, 52.84it/s, Epoch: 60, Batch: 121,Loss: -2.262,Avg.Loss: -2.462,LR: 1.74E-04]Training epoch 60:  79%|███████▉  | 121/153 [00:02<00:00, 52.84it/s, Epoch: 60, Batch: 122,Loss: -1.930,Avg.Loss: -2.458,LR: 1.74E-04]Training epoch 60:  80%|███████▉  | 122/153 [00:02<00:00, 52.84it/s, Epoch: 60, Batch: 123,Loss: -2.802,Avg.Loss: -2.460,LR: 1.74E-04]Training epoch 60:  80%|████████  | 123/153 [00:02<00:00, 52.74it/s, Epoch: 60, Batch: 123,Loss: -2.802,Avg.Loss: -2.460,LR: 1.74E-04]Training epoch 60:  80%|████████  | 123/153 [00:02<00:00, 52.74it/s, Epoch: 60, Batch: 124,Loss: -2.169,Avg.Loss: -2.458,LR: 1.74E-04]Training epoch 60:  81%|████████  | 124/153 [00:02<00:00, 52.74it/s, Epoch: 60, Batch: 125,Loss: -1.432,Avg.Loss: -2.450,LR: 1.74E-04]Training epoch 60:  82%|████████▏ | 125/153 [00:02<00:00, 52.74it/s, Epoch: 60, Batch: 126,Loss: -1.212,Avg.Loss: -2.440,LR: 1.74E-04]Training epoch 60:  82%|████████▏ | 126/153 [00:02<00:00, 52.74it/s, Epoch: 60, Batch: 127,Loss: -2.017,Avg.Loss: -2.437,LR: 1.74E-04]Training epoch 60:  83%|████████▎ | 127/153 [00:02<00:00, 52.74it/s, Epoch: 60, Batch: 128,Loss: -2.981,Avg.Loss: -2.441,LR: 1.74E-04]Training epoch 60:  84%|████████▎ | 128/153 [00:02<00:00, 52.74it/s, Epoch: 60, Batch: 129,Loss: -1.780,Avg.Loss: -2.436,LR: 1.74E-04]Training epoch 60:  84%|████████▍ | 129/153 [00:02<00:00, 52.79it/s, Epoch: 60, Batch: 129,Loss: -1.780,Avg.Loss: -2.436,LR: 1.74E-04]Training epoch 60:  84%|████████▍ | 129/153 [00:02<00:00, 52.79it/s, Epoch: 60, Batch: 130,Loss: -1.517,Avg.Loss: -2.429,LR: 1.74E-04]Training epoch 60:  85%|████████▍ | 130/153 [00:02<00:00, 52.79it/s, Epoch: 60, Batch: 131,Loss: -0.885,Avg.Loss: -2.417,LR: 1.74E-04]Training epoch 60:  86%|████████▌ | 131/153 [00:02<00:00, 52.79it/s, Epoch: 60, Batch: 132,Loss: -0.463,Avg.Loss: -2.402,LR: 1.74E-04]Training epoch 60:  86%|████████▋ | 132/153 [00:02<00:00, 52.79it/s, Epoch: 60, Batch: 133,Loss: -2.868,Avg.Loss: -2.406,LR: 1.74E-04]Training epoch 60:  87%|████████▋ | 133/153 [00:02<00:00, 52.79it/s, Epoch: 60, Batch: 134,Loss: -2.330,Avg.Loss: -2.405,LR: 1.74E-04]Training epoch 60:  88%|████████▊ | 134/153 [00:02<00:00, 52.79it/s, Epoch: 60, Batch: 135,Loss: -1.529,Avg.Loss: -2.399,LR: 1.74E-04]Training epoch 60:  88%|████████▊ | 135/153 [00:02<00:00, 52.86it/s, Epoch: 60, Batch: 135,Loss: -1.529,Avg.Loss: -2.399,LR: 1.74E-04]Training epoch 60:  88%|████████▊ | 135/153 [00:02<00:00, 52.86it/s, Epoch: 60, Batch: 136,Loss: -1.618,Avg.Loss: -2.393,LR: 1.74E-04]Training epoch 60:  89%|████████▉ | 136/153 [00:02<00:00, 52.86it/s, Epoch: 60, Batch: 137,Loss: -2.693,Avg.Loss: -2.395,LR: 1.74E-04]Training epoch 60:  90%|████████▉ | 137/153 [00:02<00:00, 52.86it/s, Epoch: 60, Batch: 138,Loss: -2.892,Avg.Loss: -2.399,LR: 1.73E-04]Training epoch 60:  90%|█████████ | 138/153 [00:02<00:00, 52.86it/s, Epoch: 60, Batch: 139,Loss: -1.686,Avg.Loss: -2.394,LR: 1.73E-04]Training epoch 60:  91%|█████████ | 139/153 [00:02<00:00, 52.86it/s, Epoch: 60, Batch: 140,Loss: -1.033,Avg.Loss: -2.384,LR: 1.73E-04]Training epoch 60:  92%|█████████▏| 140/153 [00:02<00:00, 52.86it/s, Epoch: 60, Batch: 141,Loss: -0.739,Avg.Loss: -2.372,LR: 1.73E-04]Training epoch 60:  92%|█████████▏| 141/153 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 141,Loss: -0.739,Avg.Loss: -2.372,LR: 1.73E-04]Training epoch 60:  92%|█████████▏| 141/153 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 142,Loss: -1.293,Avg.Loss: -2.365,LR: 1.73E-04]Training epoch 60:  93%|█████████▎| 142/153 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 143,Loss: -1.637,Avg.Loss: -2.359,LR: 1.73E-04]Training epoch 60:  93%|█████████▎| 143/153 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 144,Loss: -2.490,Avg.Loss: -2.360,LR: 1.73E-04]Training epoch 60:  94%|█████████▍| 144/153 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 145,Loss: -2.388,Avg.Loss: -2.361,LR: 1.73E-04]Training epoch 60:  95%|█████████▍| 145/153 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 146,Loss: -2.346,Avg.Loss: -2.360,LR: 1.73E-04]Training epoch 60:  95%|█████████▌| 146/153 [00:02<00:00, 53.08it/s, Epoch: 60, Batch: 147,Loss: -2.311,Avg.Loss: -2.360,LR: 1.73E-04]Training epoch 60:  96%|█████████▌| 147/153 [00:02<00:00, 52.97it/s, Epoch: 60, Batch: 147,Loss: -2.311,Avg.Loss: -2.360,LR: 1.73E-04]Training epoch 60:  96%|█████████▌| 147/153 [00:02<00:00, 52.97it/s, Epoch: 60, Batch: 148,Loss: -2.550,Avg.Loss: -2.361,LR: 1.73E-04]Training epoch 60:  97%|█████████▋| 148/153 [00:02<00:00, 52.97it/s, Epoch: 60, Batch: 149,Loss: -2.544,Avg.Loss: -2.363,LR: 1.73E-04]Training epoch 60:  97%|█████████▋| 149/153 [00:02<00:00, 52.97it/s, Epoch: 60, Batch: 150,Loss: -1.765,Avg.Loss: -2.359,LR: 1.73E-04]Training epoch 60:  98%|█████████▊| 150/153 [00:02<00:00, 52.97it/s, Epoch: 60, Batch: 151,Loss: -1.480,Avg.Loss: -2.353,LR: 1.73E-04]Training epoch 60:  99%|█████████▊| 151/153 [00:02<00:00, 52.97it/s, Epoch: 60, Batch: 152,Loss: -2.196,Avg.Loss: -2.352,LR: 1.73E-04]Training epoch 60:  99%|█████████▉| 152/153 [00:02<00:00, 52.97it/s, Epoch: 60, Batch: 153,Loss: -2.571,Avg.Loss: -2.353,LR: 1.73E-04]Training epoch 60: 100%|██████████| 153/153 [00:02<00:00, 52.55it/s, Epoch: 60, Batch: 153,Loss: -2.571,Avg.Loss: -2.353,LR: 1.73E-04]Training epoch 60: 100%|██████████| 153/153 [00:02<00:00, 53.26it/s, Epoch: 60, Batch: 153,Loss: -2.571,Avg.Loss: -2.353,LR: 1.73E-04]
Training epoch 61:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 61:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 61, Batch: 1,Loss: -2.292,Avg.Loss: -2.292,LR: 1.73E-04]Training epoch 61:   1%|          | 1/153 [00:00<00:05, 27.11it/s, Epoch: 61, Batch: 2,Loss: -2.067,Avg.Loss: -2.180,LR: 1.73E-04]Training epoch 61:   1%|▏         | 2/153 [00:00<00:03, 39.63it/s, Epoch: 61, Batch: 3,Loss: -1.057,Avg.Loss: -1.805,LR: 1.73E-04]Training epoch 61:   2%|▏         | 3/153 [00:00<00:03, 44.05it/s, Epoch: 61, Batch: 4,Loss: -2.082,Avg.Loss: -1.875,LR: 1.73E-04]Training epoch 61:   3%|▎         | 4/153 [00:00<00:03, 45.99it/s, Epoch: 61, Batch: 5,Loss: -1.139,Avg.Loss: -1.727,LR: 1.73E-04]Training epoch 61:   3%|▎         | 5/153 [00:00<00:03, 46.98it/s, Epoch: 61, Batch: 6,Loss: -1.849,Avg.Loss: -1.748,LR: 1.72E-04]Training epoch 61:   4%|▍         | 6/153 [00:00<00:02, 56.28it/s, Epoch: 61, Batch: 6,Loss: -1.849,Avg.Loss: -1.748,LR: 1.72E-04]Training epoch 61:   4%|▍         | 6/153 [00:00<00:02, 56.28it/s, Epoch: 61, Batch: 7,Loss: -2.084,Avg.Loss: -1.796,LR: 1.72E-04]Training epoch 61:   5%|▍         | 7/153 [00:00<00:02, 56.28it/s, Epoch: 61, Batch: 8,Loss: -3.060,Avg.Loss: -1.954,LR: 1.72E-04]Training epoch 61:   5%|▌         | 8/153 [00:00<00:02, 56.28it/s, Epoch: 61, Batch: 9,Loss: -2.861,Avg.Loss: -2.055,LR: 1.72E-04]Training epoch 61:   6%|▌         | 9/153 [00:00<00:02, 56.28it/s, Epoch: 61, Batch: 10,Loss: -2.483,Avg.Loss: -2.097,LR: 1.72E-04]Training epoch 61:   7%|▋         | 10/153 [00:00<00:02, 56.28it/s, Epoch: 61, Batch: 11,Loss: -2.023,Avg.Loss: -2.091,LR: 1.72E-04]Training epoch 61:   7%|▋         | 11/153 [00:00<00:02, 56.28it/s, Epoch: 61, Batch: 12,Loss: -2.169,Avg.Loss: -2.097,LR: 1.72E-04]Training epoch 61:   8%|▊         | 12/153 [00:00<00:02, 54.30it/s, Epoch: 61, Batch: 12,Loss: -2.169,Avg.Loss: -2.097,LR: 1.72E-04]Training epoch 61:   8%|▊         | 12/153 [00:00<00:02, 54.30it/s, Epoch: 61, Batch: 13,Loss: -2.659,Avg.Loss: -2.140,LR: 1.72E-04]Training epoch 61:   8%|▊         | 13/153 [00:00<00:02, 54.30it/s, Epoch: 61, Batch: 14,Loss: -2.914,Avg.Loss: -2.196,LR: 1.72E-04]Training epoch 61:   9%|▉         | 14/153 [00:00<00:02, 54.30it/s, Epoch: 61, Batch: 15,Loss: -2.172,Avg.Loss: -2.194,LR: 1.72E-04]Training epoch 61:  10%|▉         | 15/153 [00:00<00:02, 54.30it/s, Epoch: 61, Batch: 16,Loss: -2.136,Avg.Loss: -2.191,LR: 1.72E-04]Training epoch 61:  10%|█         | 16/153 [00:00<00:02, 54.30it/s, Epoch: 61, Batch: 17,Loss: -2.247,Avg.Loss: -2.194,LR: 1.72E-04]Training epoch 61:  11%|█         | 17/153 [00:00<00:02, 54.30it/s, Epoch: 61, Batch: 18,Loss: -1.749,Avg.Loss: -2.169,LR: 1.72E-04]Training epoch 61:  12%|█▏        | 18/153 [00:00<00:02, 53.40it/s, Epoch: 61, Batch: 18,Loss: -1.749,Avg.Loss: -2.169,LR: 1.72E-04]Training epoch 61:  12%|█▏        | 18/153 [00:00<00:02, 53.40it/s, Epoch: 61, Batch: 19,Loss: -2.122,Avg.Loss: -2.167,LR: 1.72E-04]Training epoch 61:  12%|█▏        | 19/153 [00:00<00:02, 53.40it/s, Epoch: 61, Batch: 20,Loss: -2.466,Avg.Loss: -2.182,LR: 1.72E-04]Training epoch 61:  13%|█▎        | 20/153 [00:00<00:02, 53.40it/s, Epoch: 61, Batch: 21,Loss: -2.355,Avg.Loss: -2.190,LR: 1.72E-04]Training epoch 61:  14%|█▎        | 21/153 [00:00<00:02, 53.40it/s, Epoch: 61, Batch: 22,Loss: -2.831,Avg.Loss: -2.219,LR: 1.72E-04]Training epoch 61:  14%|█▍        | 22/153 [00:00<00:02, 53.40it/s, Epoch: 61, Batch: 23,Loss: -2.225,Avg.Loss: -2.219,LR: 1.72E-04]Training epoch 61:  15%|█▌        | 23/153 [00:00<00:02, 53.40it/s, Epoch: 61, Batch: 24,Loss: -2.644,Avg.Loss: -2.237,LR: 1.72E-04]Training epoch 61:  16%|█▌        | 24/153 [00:00<00:02, 52.30it/s, Epoch: 61, Batch: 24,Loss: -2.644,Avg.Loss: -2.237,LR: 1.72E-04]Training epoch 61:  16%|█▌        | 24/153 [00:00<00:02, 52.30it/s, Epoch: 61, Batch: 25,Loss: -2.604,Avg.Loss: -2.252,LR: 1.72E-04]Training epoch 61:  16%|█▋        | 25/153 [00:00<00:02, 52.30it/s, Epoch: 61, Batch: 26,Loss: -2.516,Avg.Loss: -2.262,LR: 1.71E-04]Training epoch 61:  17%|█▋        | 26/153 [00:00<00:02, 52.30it/s, Epoch: 61, Batch: 27,Loss: -2.793,Avg.Loss: -2.281,LR: 1.71E-04]Training epoch 61:  18%|█▊        | 27/153 [00:00<00:02, 52.30it/s, Epoch: 61, Batch: 28,Loss: -2.832,Avg.Loss: -2.301,LR: 1.71E-04]Training epoch 61:  18%|█▊        | 28/153 [00:00<00:02, 52.30it/s, Epoch: 61, Batch: 29,Loss: -2.142,Avg.Loss: -2.296,LR: 1.71E-04]Training epoch 61:  19%|█▉        | 29/153 [00:00<00:02, 52.30it/s, Epoch: 61, Batch: 30,Loss: -2.890,Avg.Loss: -2.315,LR: 1.71E-04]Training epoch 61:  20%|█▉        | 30/153 [00:00<00:02, 51.75it/s, Epoch: 61, Batch: 30,Loss: -2.890,Avg.Loss: -2.315,LR: 1.71E-04]Training epoch 61:  20%|█▉        | 30/153 [00:00<00:02, 51.75it/s, Epoch: 61, Batch: 31,Loss: -2.793,Avg.Loss: -2.331,LR: 1.71E-04]Training epoch 61:  20%|██        | 31/153 [00:00<00:02, 51.75it/s, Epoch: 61, Batch: 32,Loss: -2.623,Avg.Loss: -2.340,LR: 1.71E-04]Training epoch 61:  21%|██        | 32/153 [00:00<00:02, 51.75it/s, Epoch: 61, Batch: 33,Loss: -2.370,Avg.Loss: -2.341,LR: 1.71E-04]Training epoch 61:  22%|██▏       | 33/153 [00:00<00:02, 51.75it/s, Epoch: 61, Batch: 34,Loss: -2.674,Avg.Loss: -2.351,LR: 1.71E-04]Training epoch 61:  22%|██▏       | 34/153 [00:00<00:02, 51.75it/s, Epoch: 61, Batch: 35,Loss: -2.656,Avg.Loss: -2.359,LR: 1.71E-04]Training epoch 61:  23%|██▎       | 35/153 [00:00<00:02, 51.75it/s, Epoch: 61, Batch: 36,Loss: -2.113,Avg.Loss: -2.353,LR: 1.71E-04]Training epoch 61:  24%|██▎       | 36/153 [00:00<00:02, 52.14it/s, Epoch: 61, Batch: 36,Loss: -2.113,Avg.Loss: -2.353,LR: 1.71E-04]Training epoch 61:  24%|██▎       | 36/153 [00:00<00:02, 52.14it/s, Epoch: 61, Batch: 37,Loss: -1.950,Avg.Loss: -2.342,LR: 1.71E-04]Training epoch 61:  24%|██▍       | 37/153 [00:00<00:02, 52.14it/s, Epoch: 61, Batch: 38,Loss: -2.439,Avg.Loss: -2.344,LR: 1.71E-04]Training epoch 61:  25%|██▍       | 38/153 [00:00<00:02, 52.14it/s, Epoch: 61, Batch: 39,Loss: -2.486,Avg.Loss: -2.348,LR: 1.71E-04]Training epoch 61:  25%|██▌       | 39/153 [00:00<00:02, 52.14it/s, Epoch: 61, Batch: 40,Loss: -2.355,Avg.Loss: -2.348,LR: 1.71E-04]Training epoch 61:  26%|██▌       | 40/153 [00:00<00:02, 52.14it/s, Epoch: 61, Batch: 41,Loss: -1.652,Avg.Loss: -2.331,LR: 1.71E-04]Training epoch 61:  27%|██▋       | 41/153 [00:00<00:02, 52.14it/s, Epoch: 61, Batch: 42,Loss: -1.801,Avg.Loss: -2.318,LR: 1.71E-04]Training epoch 61:  27%|██▋       | 42/153 [00:00<00:02, 52.54it/s, Epoch: 61, Batch: 42,Loss: -1.801,Avg.Loss: -2.318,LR: 1.71E-04]Training epoch 61:  27%|██▋       | 42/153 [00:00<00:02, 52.54it/s, Epoch: 61, Batch: 43,Loss: -2.407,Avg.Loss: -2.320,LR: 1.71E-04]Training epoch 61:  28%|██▊       | 43/153 [00:00<00:02, 52.54it/s, Epoch: 61, Batch: 44,Loss: -2.282,Avg.Loss: -2.320,LR: 1.71E-04]Training epoch 61:  29%|██▉       | 44/153 [00:00<00:02, 52.54it/s, Epoch: 61, Batch: 45,Loss: -2.075,Avg.Loss: -2.314,LR: 1.71E-04]Training epoch 61:  29%|██▉       | 45/153 [00:00<00:02, 52.54it/s, Epoch: 61, Batch: 46,Loss: -2.479,Avg.Loss: -2.318,LR: 1.71E-04]Training epoch 61:  30%|███       | 46/153 [00:00<00:02, 52.54it/s, Epoch: 61, Batch: 47,Loss: -2.493,Avg.Loss: -2.321,LR: 1.70E-04]Training epoch 61:  31%|███       | 47/153 [00:00<00:02, 52.54it/s, Epoch: 61, Batch: 48,Loss: -2.889,Avg.Loss: -2.333,LR: 1.70E-04]Training epoch 61:  31%|███▏      | 48/153 [00:00<00:02, 51.20it/s, Epoch: 61, Batch: 48,Loss: -2.889,Avg.Loss: -2.333,LR: 1.70E-04]Training epoch 61:  31%|███▏      | 48/153 [00:00<00:02, 51.20it/s, Epoch: 61, Batch: 49,Loss: -2.981,Avg.Loss: -2.347,LR: 1.70E-04]Training epoch 61:  32%|███▏      | 49/153 [00:00<00:02, 51.20it/s, Epoch: 61, Batch: 50,Loss: -2.954,Avg.Loss: -2.359,LR: 1.70E-04]Training epoch 61:  33%|███▎      | 50/153 [00:00<00:02, 51.20it/s, Epoch: 61, Batch: 51,Loss: -2.606,Avg.Loss: -2.364,LR: 1.70E-04]Training epoch 61:  33%|███▎      | 51/153 [00:00<00:01, 51.20it/s, Epoch: 61, Batch: 52,Loss: -2.617,Avg.Loss: -2.368,LR: 1.70E-04]Training epoch 61:  34%|███▍      | 52/153 [00:01<00:01, 51.20it/s, Epoch: 61, Batch: 53,Loss: -3.043,Avg.Loss: -2.381,LR: 1.70E-04]Training epoch 61:  35%|███▍      | 53/153 [00:01<00:01, 51.20it/s, Epoch: 61, Batch: 54,Loss: -2.837,Avg.Loss: -2.390,LR: 1.70E-04]Training epoch 61:  35%|███▌      | 54/153 [00:01<00:01, 51.66it/s, Epoch: 61, Batch: 54,Loss: -2.837,Avg.Loss: -2.390,LR: 1.70E-04]Training epoch 61:  35%|███▌      | 54/153 [00:01<00:01, 51.66it/s, Epoch: 61, Batch: 55,Loss: -2.871,Avg.Loss: -2.398,LR: 1.70E-04]Training epoch 61:  36%|███▌      | 55/153 [00:01<00:01, 51.66it/s, Epoch: 61, Batch: 56,Loss: -2.483,Avg.Loss: -2.400,LR: 1.70E-04]Training epoch 61:  37%|███▋      | 56/153 [00:01<00:01, 51.66it/s, Epoch: 61, Batch: 57,Loss: -3.053,Avg.Loss: -2.411,LR: 1.70E-04]Training epoch 61:  37%|███▋      | 57/153 [00:01<00:01, 51.66it/s, Epoch: 61, Batch: 58,Loss: -2.238,Avg.Loss: -2.408,LR: 1.70E-04]Training epoch 61:  38%|███▊      | 58/153 [00:01<00:01, 51.66it/s, Epoch: 61, Batch: 59,Loss: -2.898,Avg.Loss: -2.417,LR: 1.70E-04]Training epoch 61:  39%|███▊      | 59/153 [00:01<00:01, 51.66it/s, Epoch: 61, Batch: 60,Loss: -2.756,Avg.Loss: -2.422,LR: 1.70E-04]Training epoch 61:  39%|███▉      | 60/153 [00:01<00:01, 52.05it/s, Epoch: 61, Batch: 60,Loss: -2.756,Avg.Loss: -2.422,LR: 1.70E-04]Training epoch 61:  39%|███▉      | 60/153 [00:01<00:01, 52.05it/s, Epoch: 61, Batch: 61,Loss: -2.772,Avg.Loss: -2.428,LR: 1.70E-04]Training epoch 61:  40%|███▉      | 61/153 [00:01<00:01, 52.05it/s, Epoch: 61, Batch: 62,Loss: -3.218,Avg.Loss: -2.441,LR: 1.70E-04]Training epoch 61:  41%|████      | 62/153 [00:01<00:01, 52.05it/s, Epoch: 61, Batch: 63,Loss: -2.817,Avg.Loss: -2.447,LR: 1.70E-04]Training epoch 61:  41%|████      | 63/153 [00:01<00:01, 52.05it/s, Epoch: 61, Batch: 64,Loss: -3.145,Avg.Loss: -2.458,LR: 1.70E-04]Training epoch 61:  42%|████▏     | 64/153 [00:01<00:01, 52.05it/s, Epoch: 61, Batch: 65,Loss: -2.607,Avg.Loss: -2.460,LR: 1.70E-04]Training epoch 61:  42%|████▏     | 65/153 [00:01<00:01, 52.05it/s, Epoch: 61, Batch: 66,Loss: -2.839,Avg.Loss: -2.466,LR: 1.70E-04]Training epoch 61:  43%|████▎     | 66/153 [00:01<00:01, 52.51it/s, Epoch: 61, Batch: 66,Loss: -2.839,Avg.Loss: -2.466,LR: 1.70E-04]Training epoch 61:  43%|████▎     | 66/153 [00:01<00:01, 52.51it/s, Epoch: 61, Batch: 67,Loss: -2.677,Avg.Loss: -2.469,LR: 1.69E-04]Training epoch 61:  44%|████▍     | 67/153 [00:01<00:01, 52.51it/s, Epoch: 61, Batch: 68,Loss: -2.486,Avg.Loss: -2.469,LR: 1.69E-04]Training epoch 61:  44%|████▍     | 68/153 [00:01<00:01, 52.51it/s, Epoch: 61, Batch: 69,Loss: -2.778,Avg.Loss: -2.474,LR: 1.69E-04]Training epoch 61:  45%|████▌     | 69/153 [00:01<00:01, 52.51it/s, Epoch: 61, Batch: 70,Loss: -2.621,Avg.Loss: -2.476,LR: 1.69E-04]Training epoch 61:  46%|████▌     | 70/153 [00:01<00:01, 52.51it/s, Epoch: 61, Batch: 71,Loss: -2.675,Avg.Loss: -2.478,LR: 1.69E-04]Training epoch 61:  46%|████▋     | 71/153 [00:01<00:01, 52.51it/s, Epoch: 61, Batch: 72,Loss: -2.405,Avg.Loss: -2.477,LR: 1.69E-04]Training epoch 61:  47%|████▋     | 72/153 [00:01<00:01, 52.55it/s, Epoch: 61, Batch: 72,Loss: -2.405,Avg.Loss: -2.477,LR: 1.69E-04]Training epoch 61:  47%|████▋     | 72/153 [00:01<00:01, 52.55it/s, Epoch: 61, Batch: 73,Loss: -2.940,Avg.Loss: -2.484,LR: 1.69E-04]Training epoch 61:  48%|████▊     | 73/153 [00:01<00:01, 52.55it/s, Epoch: 61, Batch: 74,Loss: -2.396,Avg.Loss: -2.483,LR: 1.69E-04]Training epoch 61:  48%|████▊     | 74/153 [00:01<00:01, 52.55it/s, Epoch: 61, Batch: 75,Loss: -2.593,Avg.Loss: -2.484,LR: 1.69E-04]Training epoch 61:  49%|████▉     | 75/153 [00:01<00:01, 52.55it/s, Epoch: 61, Batch: 76,Loss: -2.621,Avg.Loss: -2.486,LR: 1.69E-04]Training epoch 61:  50%|████▉     | 76/153 [00:01<00:01, 52.55it/s, Epoch: 61, Batch: 77,Loss: -2.661,Avg.Loss: -2.488,LR: 1.69E-04]Training epoch 61:  50%|█████     | 77/153 [00:01<00:01, 52.55it/s, Epoch: 61, Batch: 78,Loss: -2.492,Avg.Loss: -2.488,LR: 1.69E-04]Training epoch 61:  51%|█████     | 78/153 [00:01<00:01, 52.80it/s, Epoch: 61, Batch: 78,Loss: -2.492,Avg.Loss: -2.488,LR: 1.69E-04]Training epoch 61:  51%|█████     | 78/153 [00:01<00:01, 52.80it/s, Epoch: 61, Batch: 79,Loss: -2.684,Avg.Loss: -2.491,LR: 1.69E-04]Training epoch 61:  52%|█████▏    | 79/153 [00:01<00:01, 52.80it/s, Epoch: 61, Batch: 80,Loss: -2.409,Avg.Loss: -2.490,LR: 1.69E-04]Training epoch 61:  52%|█████▏    | 80/153 [00:01<00:01, 52.80it/s, Epoch: 61, Batch: 81,Loss: -2.190,Avg.Loss: -2.486,LR: 1.69E-04]Training epoch 61:  53%|█████▎    | 81/153 [00:01<00:01, 52.80it/s, Epoch: 61, Batch: 82,Loss: -2.476,Avg.Loss: -2.486,LR: 1.69E-04]Training epoch 61:  54%|█████▎    | 82/153 [00:01<00:01, 52.80it/s, Epoch: 61, Batch: 83,Loss: -2.683,Avg.Loss: -2.488,LR: 1.69E-04]Training epoch 61:  54%|█████▍    | 83/153 [00:01<00:01, 52.80it/s, Epoch: 61, Batch: 84,Loss: -2.548,Avg.Loss: -2.489,LR: 1.69E-04]Training epoch 61:  55%|█████▍    | 84/153 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 84,Loss: -2.548,Avg.Loss: -2.489,LR: 1.69E-04]Training epoch 61:  55%|█████▍    | 84/153 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 85,Loss: -2.265,Avg.Loss: -2.486,LR: 1.69E-04]Training epoch 61:  56%|█████▌    | 85/153 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 86,Loss: -2.832,Avg.Loss: -2.490,LR: 1.69E-04]Training epoch 61:  56%|█████▌    | 86/153 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 87,Loss: -2.736,Avg.Loss: -2.493,LR: 1.69E-04]Training epoch 61:  57%|█████▋    | 87/153 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 88,Loss: -2.685,Avg.Loss: -2.495,LR: 1.68E-04]Training epoch 61:  58%|█████▊    | 88/153 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 89,Loss: -2.221,Avg.Loss: -2.492,LR: 1.68E-04]Training epoch 61:  58%|█████▊    | 89/153 [00:01<00:01, 52.92it/s, Epoch: 61, Batch: 90,Loss: -2.765,Avg.Loss: -2.495,LR: 1.68E-04]Training epoch 61:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 61, Batch: 90,Loss: -2.765,Avg.Loss: -2.495,LR: 1.68E-04]Training epoch 61:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 61, Batch: 91,Loss: -2.491,Avg.Loss: -2.495,LR: 1.68E-04]Training epoch 61:  59%|█████▉    | 91/153 [00:01<00:01, 53.06it/s, Epoch: 61, Batch: 92,Loss: -2.834,Avg.Loss: -2.499,LR: 1.68E-04]Training epoch 61:  60%|██████    | 92/153 [00:01<00:01, 53.06it/s, Epoch: 61, Batch: 93,Loss: -2.702,Avg.Loss: -2.501,LR: 1.68E-04]Training epoch 61:  61%|██████    | 93/153 [00:01<00:01, 53.06it/s, Epoch: 61, Batch: 94,Loss: -2.287,Avg.Loss: -2.499,LR: 1.68E-04]Training epoch 61:  61%|██████▏   | 94/153 [00:01<00:01, 53.06it/s, Epoch: 61, Batch: 95,Loss: -2.544,Avg.Loss: -2.499,LR: 1.68E-04]Training epoch 61:  62%|██████▏   | 95/153 [00:01<00:01, 53.06it/s, Epoch: 61, Batch: 96,Loss: -2.549,Avg.Loss: -2.500,LR: 1.68E-04]Training epoch 61:  63%|██████▎   | 96/153 [00:01<00:01, 53.26it/s, Epoch: 61, Batch: 96,Loss: -2.549,Avg.Loss: -2.500,LR: 1.68E-04]Training epoch 61:  63%|██████▎   | 96/153 [00:01<00:01, 53.26it/s, Epoch: 61, Batch: 97,Loss: -3.073,Avg.Loss: -2.506,LR: 1.68E-04]Training epoch 61:  63%|██████▎   | 97/153 [00:01<00:01, 53.26it/s, Epoch: 61, Batch: 98,Loss: -3.066,Avg.Loss: -2.511,LR: 1.68E-04]Training epoch 61:  64%|██████▍   | 98/153 [00:01<00:01, 53.26it/s, Epoch: 61, Batch: 99,Loss: -2.919,Avg.Loss: -2.516,LR: 1.68E-04]Training epoch 61:  65%|██████▍   | 99/153 [00:01<00:01, 53.26it/s, Epoch: 61, Batch: 100,Loss: -2.711,Avg.Loss: -2.518,LR: 1.68E-04]Training epoch 61:  65%|██████▌   | 100/153 [00:01<00:00, 53.26it/s, Epoch: 61, Batch: 101,Loss: -2.134,Avg.Loss: -2.514,LR: 1.68E-04]Training epoch 61:  66%|██████▌   | 101/153 [00:01<00:00, 53.26it/s, Epoch: 61, Batch: 102,Loss: -3.072,Avg.Loss: -2.519,LR: 1.68E-04]Training epoch 61:  67%|██████▋   | 102/153 [00:01<00:00, 53.29it/s, Epoch: 61, Batch: 102,Loss: -3.072,Avg.Loss: -2.519,LR: 1.68E-04]Training epoch 61:  67%|██████▋   | 102/153 [00:01<00:00, 53.29it/s, Epoch: 61, Batch: 103,Loss: -2.553,Avg.Loss: -2.520,LR: 1.68E-04]Training epoch 61:  67%|██████▋   | 103/153 [00:01<00:00, 53.29it/s, Epoch: 61, Batch: 104,Loss: -2.725,Avg.Loss: -2.521,LR: 1.68E-04]Training epoch 61:  68%|██████▊   | 104/153 [00:01<00:00, 53.29it/s, Epoch: 61, Batch: 105,Loss: -2.948,Avg.Loss: -2.526,LR: 1.68E-04]Training epoch 61:  69%|██████▊   | 105/153 [00:02<00:00, 53.29it/s, Epoch: 61, Batch: 106,Loss: -2.733,Avg.Loss: -2.528,LR: 1.68E-04]Training epoch 61:  69%|██████▉   | 106/153 [00:02<00:00, 53.29it/s, Epoch: 61, Batch: 107,Loss: -2.751,Avg.Loss: -2.530,LR: 1.68E-04]Training epoch 61:  70%|██████▉   | 107/153 [00:02<00:00, 53.29it/s, Epoch: 61, Batch: 108,Loss: -2.986,Avg.Loss: -2.534,LR: 1.67E-04]Training epoch 61:  71%|███████   | 108/153 [00:02<00:00, 53.76it/s, Epoch: 61, Batch: 108,Loss: -2.986,Avg.Loss: -2.534,LR: 1.67E-04]Training epoch 61:  71%|███████   | 108/153 [00:02<00:00, 53.76it/s, Epoch: 61, Batch: 109,Loss: -2.888,Avg.Loss: -2.537,LR: 1.67E-04]Training epoch 61:  71%|███████   | 109/153 [00:02<00:00, 53.76it/s, Epoch: 61, Batch: 110,Loss: -3.172,Avg.Loss: -2.543,LR: 1.67E-04]Training epoch 61:  72%|███████▏  | 110/153 [00:02<00:00, 53.76it/s, Epoch: 61, Batch: 111,Loss: -2.651,Avg.Loss: -2.544,LR: 1.67E-04]Training epoch 61:  73%|███████▎  | 111/153 [00:02<00:00, 53.76it/s, Epoch: 61, Batch: 112,Loss: -2.556,Avg.Loss: -2.544,LR: 1.67E-04]Training epoch 61:  73%|███████▎  | 112/153 [00:02<00:00, 53.76it/s, Epoch: 61, Batch: 113,Loss: -2.722,Avg.Loss: -2.546,LR: 1.67E-04]Training epoch 61:  74%|███████▍  | 113/153 [00:02<00:00, 53.76it/s, Epoch: 61, Batch: 114,Loss: -2.763,Avg.Loss: -2.547,LR: 1.67E-04]Training epoch 61:  75%|███████▍  | 114/153 [00:02<00:00, 53.87it/s, Epoch: 61, Batch: 114,Loss: -2.763,Avg.Loss: -2.547,LR: 1.67E-04]Training epoch 61:  75%|███████▍  | 114/153 [00:02<00:00, 53.87it/s, Epoch: 61, Batch: 115,Loss: -2.522,Avg.Loss: -2.547,LR: 1.67E-04]Training epoch 61:  75%|███████▌  | 115/153 [00:02<00:00, 53.87it/s, Epoch: 61, Batch: 116,Loss: -1.816,Avg.Loss: -2.541,LR: 1.67E-04]Training epoch 61:  76%|███████▌  | 116/153 [00:02<00:00, 53.87it/s, Epoch: 61, Batch: 117,Loss: -1.679,Avg.Loss: -2.534,LR: 1.67E-04]Training epoch 61:  76%|███████▋  | 117/153 [00:02<00:00, 53.87it/s, Epoch: 61, Batch: 118,Loss: -1.324,Avg.Loss: -2.523,LR: 1.67E-04]Training epoch 61:  77%|███████▋  | 118/153 [00:02<00:00, 53.87it/s, Epoch: 61, Batch: 119,Loss: -2.342,Avg.Loss: -2.522,LR: 1.67E-04]Training epoch 61:  78%|███████▊  | 119/153 [00:02<00:00, 53.87it/s, Epoch: 61, Batch: 120,Loss: -1.843,Avg.Loss: -2.516,LR: 1.67E-04]Training epoch 61:  78%|███████▊  | 120/153 [00:02<00:00, 53.40it/s, Epoch: 61, Batch: 120,Loss: -1.843,Avg.Loss: -2.516,LR: 1.67E-04]Training epoch 61:  78%|███████▊  | 120/153 [00:02<00:00, 53.40it/s, Epoch: 61, Batch: 121,Loss: -2.199,Avg.Loss: -2.513,LR: 1.67E-04]Training epoch 61:  79%|███████▉  | 121/153 [00:02<00:00, 53.40it/s, Epoch: 61, Batch: 122,Loss: -2.335,Avg.Loss: -2.512,LR: 1.67E-04]Training epoch 61:  80%|███████▉  | 122/153 [00:02<00:00, 53.40it/s, Epoch: 61, Batch: 123,Loss: -3.023,Avg.Loss: -2.516,LR: 1.67E-04]Training epoch 61:  80%|████████  | 123/153 [00:02<00:00, 53.40it/s, Epoch: 61, Batch: 124,Loss: -1.846,Avg.Loss: -2.511,LR: 1.67E-04]Training epoch 61:  81%|████████  | 124/153 [00:02<00:00, 53.40it/s, Epoch: 61, Batch: 125,Loss: -2.253,Avg.Loss: -2.509,LR: 1.67E-04]Training epoch 61:  82%|████████▏ | 125/153 [00:02<00:00, 53.40it/s, Epoch: 61, Batch: 126,Loss: -2.223,Avg.Loss: -2.506,LR: 1.67E-04]Training epoch 61:  82%|████████▏ | 126/153 [00:02<00:00, 53.09it/s, Epoch: 61, Batch: 126,Loss: -2.223,Avg.Loss: -2.506,LR: 1.67E-04]Training epoch 61:  82%|████████▏ | 126/153 [00:02<00:00, 53.09it/s, Epoch: 61, Batch: 127,Loss: -2.292,Avg.Loss: -2.505,LR: 1.67E-04]Training epoch 61:  83%|████████▎ | 127/153 [00:02<00:00, 53.09it/s, Epoch: 61, Batch: 128,Loss: -2.560,Avg.Loss: -2.505,LR: 1.67E-04]Training epoch 61:  84%|████████▎ | 128/153 [00:02<00:00, 53.09it/s, Epoch: 61, Batch: 129,Loss: -2.580,Avg.Loss: -2.506,LR: 1.66E-04]Training epoch 61:  84%|████████▍ | 129/153 [00:02<00:00, 53.09it/s, Epoch: 61, Batch: 130,Loss: -3.068,Avg.Loss: -2.510,LR: 1.66E-04]Training epoch 61:  85%|████████▍ | 130/153 [00:02<00:00, 53.09it/s, Epoch: 61, Batch: 131,Loss: -2.751,Avg.Loss: -2.512,LR: 1.66E-04]Training epoch 61:  86%|████████▌ | 131/153 [00:02<00:00, 53.09it/s, Epoch: 61, Batch: 132,Loss: -2.482,Avg.Loss: -2.512,LR: 1.66E-04]Training epoch 61:  86%|████████▋ | 132/153 [00:02<00:00, 52.90it/s, Epoch: 61, Batch: 132,Loss: -2.482,Avg.Loss: -2.512,LR: 1.66E-04]Training epoch 61:  86%|████████▋ | 132/153 [00:02<00:00, 52.90it/s, Epoch: 61, Batch: 133,Loss: -2.994,Avg.Loss: -2.515,LR: 1.66E-04]Training epoch 61:  87%|████████▋ | 133/153 [00:02<00:00, 52.90it/s, Epoch: 61, Batch: 134,Loss: -2.197,Avg.Loss: -2.513,LR: 1.66E-04]Training epoch 61:  88%|████████▊ | 134/153 [00:02<00:00, 52.90it/s, Epoch: 61, Batch: 135,Loss: -2.204,Avg.Loss: -2.511,LR: 1.66E-04]Training epoch 61:  88%|████████▊ | 135/153 [00:02<00:00, 52.90it/s, Epoch: 61, Batch: 136,Loss: -2.560,Avg.Loss: -2.511,LR: 1.66E-04]Training epoch 61:  89%|████████▉ | 136/153 [00:02<00:00, 52.90it/s, Epoch: 61, Batch: 137,Loss: -2.721,Avg.Loss: -2.513,LR: 1.66E-04]Training epoch 61:  90%|████████▉ | 137/153 [00:02<00:00, 52.90it/s, Epoch: 61, Batch: 138,Loss: -2.572,Avg.Loss: -2.513,LR: 1.66E-04]Training epoch 61:  90%|█████████ | 138/153 [00:02<00:00, 52.98it/s, Epoch: 61, Batch: 138,Loss: -2.572,Avg.Loss: -2.513,LR: 1.66E-04]Training epoch 61:  90%|█████████ | 138/153 [00:02<00:00, 52.98it/s, Epoch: 61, Batch: 139,Loss: -3.211,Avg.Loss: -2.518,LR: 1.66E-04]Training epoch 61:  91%|█████████ | 139/153 [00:02<00:00, 52.98it/s, Epoch: 61, Batch: 140,Loss: -3.108,Avg.Loss: -2.522,LR: 1.66E-04]Training epoch 61:  92%|█████████▏| 140/153 [00:02<00:00, 52.98it/s, Epoch: 61, Batch: 141,Loss: -2.064,Avg.Loss: -2.519,LR: 1.66E-04]Training epoch 61:  92%|█████████▏| 141/153 [00:02<00:00, 52.98it/s, Epoch: 61, Batch: 142,Loss: -1.996,Avg.Loss: -2.515,LR: 1.66E-04]Training epoch 61:  93%|█████████▎| 142/153 [00:02<00:00, 52.98it/s, Epoch: 61, Batch: 143,Loss: -2.071,Avg.Loss: -2.512,LR: 1.66E-04]Training epoch 61:  93%|█████████▎| 143/153 [00:02<00:00, 52.98it/s, Epoch: 61, Batch: 144,Loss: -2.888,Avg.Loss: -2.515,LR: 1.66E-04]Training epoch 61:  94%|█████████▍| 144/153 [00:02<00:00, 53.07it/s, Epoch: 61, Batch: 144,Loss: -2.888,Avg.Loss: -2.515,LR: 1.66E-04]Training epoch 61:  94%|█████████▍| 144/153 [00:02<00:00, 53.07it/s, Epoch: 61, Batch: 145,Loss: -2.884,Avg.Loss: -2.517,LR: 1.66E-04]Training epoch 61:  95%|█████████▍| 145/153 [00:02<00:00, 53.07it/s, Epoch: 61, Batch: 146,Loss: -2.422,Avg.Loss: -2.517,LR: 1.66E-04]Training epoch 61:  95%|█████████▌| 146/153 [00:02<00:00, 53.07it/s, Epoch: 61, Batch: 147,Loss: -2.496,Avg.Loss: -2.517,LR: 1.66E-04]Training epoch 61:  96%|█████████▌| 147/153 [00:02<00:00, 53.07it/s, Epoch: 61, Batch: 148,Loss: -1.053,Avg.Loss: -2.507,LR: 1.66E-04]Training epoch 61:  97%|█████████▋| 148/153 [00:02<00:00, 53.07it/s, Epoch: 61, Batch: 149,Loss: -2.373,Avg.Loss: -2.506,LR: 1.66E-04]Training epoch 61:  97%|█████████▋| 149/153 [00:02<00:00, 53.07it/s, Epoch: 61, Batch: 150,Loss: -2.544,Avg.Loss: -2.506,LR: 1.65E-04]Training epoch 61:  98%|█████████▊| 150/153 [00:02<00:00, 52.88it/s, Epoch: 61, Batch: 150,Loss: -2.544,Avg.Loss: -2.506,LR: 1.65E-04]Training epoch 61:  98%|█████████▊| 150/153 [00:02<00:00, 52.88it/s, Epoch: 61, Batch: 151,Loss: -2.475,Avg.Loss: -2.506,LR: 1.65E-04]Training epoch 61:  99%|█████████▊| 151/153 [00:02<00:00, 52.88it/s, Epoch: 61, Batch: 152,Loss: -2.583,Avg.Loss: -2.506,LR: 1.65E-04]Training epoch 61:  99%|█████████▉| 152/153 [00:02<00:00, 52.88it/s, Epoch: 61, Batch: 153,Loss: -2.776,Avg.Loss: -2.508,LR: 1.65E-04]Training epoch 61: 100%|██████████| 153/153 [00:02<00:00, 52.79it/s, Epoch: 61, Batch: 153,Loss: -2.776,Avg.Loss: -2.508,LR: 1.65E-04]
Training epoch 62:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 62:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 62, Batch: 1,Loss: -2.789,Avg.Loss: -2.789,LR: 1.65E-04]Training epoch 62:   1%|          | 1/153 [00:00<00:06, 23.34it/s, Epoch: 62, Batch: 2,Loss: -2.620,Avg.Loss: -2.705,LR: 1.65E-04]Training epoch 62:   1%|▏         | 2/153 [00:00<00:04, 34.59it/s, Epoch: 62, Batch: 3,Loss: -2.483,Avg.Loss: -2.631,LR: 1.65E-04]Training epoch 62:   2%|▏         | 3/153 [00:00<00:03, 41.54it/s, Epoch: 62, Batch: 4,Loss: -2.295,Avg.Loss: -2.547,LR: 1.65E-04]Training epoch 62:   3%|▎         | 4/153 [00:00<00:03, 43.95it/s, Epoch: 62, Batch: 5,Loss: -2.563,Avg.Loss: -2.550,LR: 1.65E-04]Training epoch 62:   3%|▎         | 5/153 [00:00<00:03, 46.67it/s, Epoch: 62, Batch: 6,Loss: -2.739,Avg.Loss: -2.582,LR: 1.65E-04]Training epoch 62:   4%|▍         | 6/153 [00:00<00:02, 55.90it/s, Epoch: 62, Batch: 6,Loss: -2.739,Avg.Loss: -2.582,LR: 1.65E-04]Training epoch 62:   4%|▍         | 6/153 [00:00<00:02, 55.90it/s, Epoch: 62, Batch: 7,Loss: -2.990,Avg.Loss: -2.640,LR: 1.65E-04]Training epoch 62:   5%|▍         | 7/153 [00:00<00:02, 55.90it/s, Epoch: 62, Batch: 8,Loss: -2.828,Avg.Loss: -2.663,LR: 1.65E-04]Training epoch 62:   5%|▌         | 8/153 [00:00<00:02, 55.90it/s, Epoch: 62, Batch: 9,Loss: -2.502,Avg.Loss: -2.645,LR: 1.65E-04]Training epoch 62:   6%|▌         | 9/153 [00:00<00:02, 55.90it/s, Epoch: 62, Batch: 10,Loss: -2.293,Avg.Loss: -2.610,LR: 1.65E-04]Training epoch 62:   7%|▋         | 10/153 [00:00<00:02, 55.90it/s, Epoch: 62, Batch: 11,Loss: -2.808,Avg.Loss: -2.628,LR: 1.65E-04]Training epoch 62:   7%|▋         | 11/153 [00:00<00:02, 55.90it/s, Epoch: 62, Batch: 12,Loss: -2.040,Avg.Loss: -2.579,LR: 1.65E-04]Training epoch 62:   8%|▊         | 12/153 [00:00<00:02, 54.07it/s, Epoch: 62, Batch: 12,Loss: -2.040,Avg.Loss: -2.579,LR: 1.65E-04]Training epoch 62:   8%|▊         | 12/153 [00:00<00:02, 54.07it/s, Epoch: 62, Batch: 13,Loss: -2.934,Avg.Loss: -2.606,LR: 1.65E-04]Training epoch 62:   8%|▊         | 13/153 [00:00<00:02, 54.07it/s, Epoch: 62, Batch: 14,Loss: -2.217,Avg.Loss: -2.579,LR: 1.65E-04]Training epoch 62:   9%|▉         | 14/153 [00:00<00:02, 54.07it/s, Epoch: 62, Batch: 15,Loss: -1.984,Avg.Loss: -2.539,LR: 1.65E-04]Training epoch 62:  10%|▉         | 15/153 [00:00<00:02, 54.07it/s, Epoch: 62, Batch: 16,Loss: -2.211,Avg.Loss: -2.518,LR: 1.65E-04]Training epoch 62:  10%|█         | 16/153 [00:00<00:02, 54.07it/s, Epoch: 62, Batch: 17,Loss: -2.155,Avg.Loss: -2.497,LR: 1.64E-04]Training epoch 62:  11%|█         | 17/153 [00:00<00:02, 54.07it/s, Epoch: 62, Batch: 18,Loss: -2.548,Avg.Loss: -2.500,LR: 1.64E-04]Training epoch 62:  12%|█▏        | 18/153 [00:00<00:02, 53.57it/s, Epoch: 62, Batch: 18,Loss: -2.548,Avg.Loss: -2.500,LR: 1.64E-04]Training epoch 62:  12%|█▏        | 18/153 [00:00<00:02, 53.57it/s, Epoch: 62, Batch: 19,Loss: -2.689,Avg.Loss: -2.510,LR: 1.64E-04]Training epoch 62:  12%|█▏        | 19/153 [00:00<00:02, 53.57it/s, Epoch: 62, Batch: 20,Loss: -2.462,Avg.Loss: -2.507,LR: 1.64E-04]Training epoch 62:  13%|█▎        | 20/153 [00:00<00:02, 53.57it/s, Epoch: 62, Batch: 21,Loss: -3.060,Avg.Loss: -2.534,LR: 1.64E-04]Training epoch 62:  14%|█▎        | 21/153 [00:00<00:02, 53.57it/s, Epoch: 62, Batch: 22,Loss: -2.992,Avg.Loss: -2.555,LR: 1.64E-04]Training epoch 62:  14%|█▍        | 22/153 [00:00<00:02, 53.57it/s, Epoch: 62, Batch: 23,Loss: -2.733,Avg.Loss: -2.562,LR: 1.64E-04]Training epoch 62:  15%|█▌        | 23/153 [00:00<00:02, 53.57it/s, Epoch: 62, Batch: 24,Loss: -2.409,Avg.Loss: -2.556,LR: 1.64E-04]Training epoch 62:  16%|█▌        | 24/153 [00:00<00:02, 51.95it/s, Epoch: 62, Batch: 24,Loss: -2.409,Avg.Loss: -2.556,LR: 1.64E-04]Training epoch 62:  16%|█▌        | 24/153 [00:00<00:02, 51.95it/s, Epoch: 62, Batch: 25,Loss: -2.777,Avg.Loss: -2.565,LR: 1.64E-04]Training epoch 62:  16%|█▋        | 25/153 [00:00<00:02, 51.95it/s, Epoch: 62, Batch: 26,Loss: -2.490,Avg.Loss: -2.562,LR: 1.64E-04]Training epoch 62:  17%|█▋        | 26/153 [00:00<00:02, 51.95it/s, Epoch: 62, Batch: 27,Loss: -2.469,Avg.Loss: -2.558,LR: 1.64E-04]Training epoch 62:  18%|█▊        | 27/153 [00:00<00:02, 51.95it/s, Epoch: 62, Batch: 28,Loss: -3.089,Avg.Loss: -2.577,LR: 1.64E-04]Training epoch 62:  18%|█▊        | 28/153 [00:00<00:02, 51.95it/s, Epoch: 62, Batch: 29,Loss: -2.119,Avg.Loss: -2.562,LR: 1.64E-04]Training epoch 62:  19%|█▉        | 29/153 [00:00<00:02, 51.95it/s, Epoch: 62, Batch: 30,Loss: -2.375,Avg.Loss: -2.555,LR: 1.64E-04]Training epoch 62:  20%|█▉        | 30/153 [00:00<00:02, 51.81it/s, Epoch: 62, Batch: 30,Loss: -2.375,Avg.Loss: -2.555,LR: 1.64E-04]Training epoch 62:  20%|█▉        | 30/153 [00:00<00:02, 51.81it/s, Epoch: 62, Batch: 31,Loss: -1.955,Avg.Loss: -2.536,LR: 1.64E-04]Training epoch 62:  20%|██        | 31/153 [00:00<00:02, 51.81it/s, Epoch: 62, Batch: 32,Loss: -2.346,Avg.Loss: -2.530,LR: 1.64E-04]Training epoch 62:  21%|██        | 32/153 [00:00<00:02, 51.81it/s, Epoch: 62, Batch: 33,Loss: -2.691,Avg.Loss: -2.535,LR: 1.64E-04]Training epoch 62:  22%|██▏       | 33/153 [00:00<00:02, 51.81it/s, Epoch: 62, Batch: 34,Loss: -2.245,Avg.Loss: -2.526,LR: 1.64E-04]Training epoch 62:  22%|██▏       | 34/153 [00:00<00:02, 51.81it/s, Epoch: 62, Batch: 35,Loss: -2.163,Avg.Loss: -2.516,LR: 1.64E-04]Training epoch 62:  23%|██▎       | 35/153 [00:00<00:02, 51.81it/s, Epoch: 62, Batch: 36,Loss: -1.980,Avg.Loss: -2.501,LR: 1.64E-04]Training epoch 62:  24%|██▎       | 36/153 [00:00<00:02, 52.32it/s, Epoch: 62, Batch: 36,Loss: -1.980,Avg.Loss: -2.501,LR: 1.64E-04]Training epoch 62:  24%|██▎       | 36/153 [00:00<00:02, 52.32it/s, Epoch: 62, Batch: 37,Loss: -2.132,Avg.Loss: -2.491,LR: 1.64E-04]Training epoch 62:  24%|██▍       | 37/153 [00:00<00:02, 52.32it/s, Epoch: 62, Batch: 38,Loss: -2.051,Avg.Loss: -2.480,LR: 1.63E-04]Training epoch 62:  25%|██▍       | 38/153 [00:00<00:02, 52.32it/s, Epoch: 62, Batch: 39,Loss: -2.013,Avg.Loss: -2.468,LR: 1.63E-04]Training epoch 62:  25%|██▌       | 39/153 [00:00<00:02, 52.32it/s, Epoch: 62, Batch: 40,Loss: -2.597,Avg.Loss: -2.471,LR: 1.63E-04]Training epoch 62:  26%|██▌       | 40/153 [00:00<00:02, 52.32it/s, Epoch: 62, Batch: 41,Loss: -2.308,Avg.Loss: -2.467,LR: 1.63E-04]Training epoch 62:  27%|██▋       | 41/153 [00:00<00:02, 52.32it/s, Epoch: 62, Batch: 42,Loss: -2.914,Avg.Loss: -2.478,LR: 1.63E-04]Training epoch 62:  27%|██▋       | 42/153 [00:00<00:02, 52.64it/s, Epoch: 62, Batch: 42,Loss: -2.914,Avg.Loss: -2.478,LR: 1.63E-04]Training epoch 62:  27%|██▋       | 42/153 [00:00<00:02, 52.64it/s, Epoch: 62, Batch: 43,Loss: -2.875,Avg.Loss: -2.487,LR: 1.63E-04]Training epoch 62:  28%|██▊       | 43/153 [00:00<00:02, 52.64it/s, Epoch: 62, Batch: 44,Loss: -2.661,Avg.Loss: -2.491,LR: 1.63E-04]Training epoch 62:  29%|██▉       | 44/153 [00:00<00:02, 52.64it/s, Epoch: 62, Batch: 45,Loss: -2.667,Avg.Loss: -2.495,LR: 1.63E-04]Training epoch 62:  29%|██▉       | 45/153 [00:00<00:02, 52.64it/s, Epoch: 62, Batch: 46,Loss: -2.721,Avg.Loss: -2.500,LR: 1.63E-04]Training epoch 62:  30%|███       | 46/153 [00:00<00:02, 52.64it/s, Epoch: 62, Batch: 47,Loss: -3.266,Avg.Loss: -2.516,LR: 1.63E-04]Training epoch 62:  31%|███       | 47/153 [00:00<00:02, 52.64it/s, Epoch: 62, Batch: 48,Loss: -3.242,Avg.Loss: -2.531,LR: 1.63E-04]Training epoch 62:  31%|███▏      | 48/153 [00:00<00:01, 52.98it/s, Epoch: 62, Batch: 48,Loss: -3.242,Avg.Loss: -2.531,LR: 1.63E-04]Training epoch 62:  31%|███▏      | 48/153 [00:00<00:01, 52.98it/s, Epoch: 62, Batch: 49,Loss: -2.408,Avg.Loss: -2.529,LR: 1.63E-04]Training epoch 62:  32%|███▏      | 49/153 [00:00<00:01, 52.98it/s, Epoch: 62, Batch: 50,Loss: -1.522,Avg.Loss: -2.508,LR: 1.63E-04]Training epoch 62:  33%|███▎      | 50/153 [00:00<00:01, 52.98it/s, Epoch: 62, Batch: 51,Loss: -1.784,Avg.Loss: -2.494,LR: 1.63E-04]Training epoch 62:  33%|███▎      | 51/153 [00:00<00:01, 52.98it/s, Epoch: 62, Batch: 52,Loss: -1.765,Avg.Loss: -2.480,LR: 1.63E-04]Training epoch 62:  34%|███▍      | 52/153 [00:01<00:01, 52.98it/s, Epoch: 62, Batch: 53,Loss: -2.283,Avg.Loss: -2.476,LR: 1.63E-04]Training epoch 62:  35%|███▍      | 53/153 [00:01<00:01, 52.98it/s, Epoch: 62, Batch: 54,Loss: -2.681,Avg.Loss: -2.480,LR: 1.63E-04]Training epoch 62:  35%|███▌      | 54/153 [00:01<00:01, 53.16it/s, Epoch: 62, Batch: 54,Loss: -2.681,Avg.Loss: -2.480,LR: 1.63E-04]Training epoch 62:  35%|███▌      | 54/153 [00:01<00:01, 53.16it/s, Epoch: 62, Batch: 55,Loss: -2.052,Avg.Loss: -2.472,LR: 1.63E-04]Training epoch 62:  36%|███▌      | 55/153 [00:01<00:01, 53.16it/s, Epoch: 62, Batch: 56,Loss: -2.249,Avg.Loss: -2.468,LR: 1.63E-04]Training epoch 62:  37%|███▋      | 56/153 [00:01<00:01, 53.16it/s, Epoch: 62, Batch: 57,Loss: -2.214,Avg.Loss: -2.464,LR: 1.63E-04]Training epoch 62:  37%|███▋      | 57/153 [00:01<00:01, 53.16it/s, Epoch: 62, Batch: 58,Loss: -2.473,Avg.Loss: -2.464,LR: 1.63E-04]Training epoch 62:  38%|███▊      | 58/153 [00:01<00:01, 53.16it/s, Epoch: 62, Batch: 59,Loss: -1.893,Avg.Loss: -2.454,LR: 1.62E-04]Training epoch 62:  39%|███▊      | 59/153 [00:01<00:01, 53.16it/s, Epoch: 62, Batch: 60,Loss: -0.936,Avg.Loss: -2.429,LR: 1.62E-04]Training epoch 62:  39%|███▉      | 60/153 [00:01<00:01, 53.14it/s, Epoch: 62, Batch: 60,Loss: -0.936,Avg.Loss: -2.429,LR: 1.62E-04]Training epoch 62:  39%|███▉      | 60/153 [00:01<00:01, 53.14it/s, Epoch: 62, Batch: 61,Loss: -1.161,Avg.Loss: -2.408,LR: 1.62E-04]Training epoch 62:  40%|███▉      | 61/153 [00:01<00:01, 53.14it/s, Epoch: 62, Batch: 62,Loss: -2.533,Avg.Loss: -2.410,LR: 1.62E-04]Training epoch 62:  41%|████      | 62/153 [00:01<00:01, 53.14it/s, Epoch: 62, Batch: 63,Loss: -2.944,Avg.Loss: -2.419,LR: 1.62E-04]Training epoch 62:  41%|████      | 63/153 [00:01<00:01, 53.14it/s, Epoch: 62, Batch: 64,Loss: -1.901,Avg.Loss: -2.411,LR: 1.62E-04]Training epoch 62:  42%|████▏     | 64/153 [00:01<00:01, 53.14it/s, Epoch: 62, Batch: 65,Loss: -0.521,Avg.Loss: -2.382,LR: 1.62E-04]Training epoch 62:  42%|████▏     | 65/153 [00:01<00:01, 53.14it/s, Epoch: 62, Batch: 66,Loss: -0.725,Avg.Loss: -2.357,LR: 1.62E-04]Training epoch 62:  43%|████▎     | 66/153 [00:01<00:01, 53.24it/s, Epoch: 62, Batch: 66,Loss: -0.725,Avg.Loss: -2.357,LR: 1.62E-04]Training epoch 62:  43%|████▎     | 66/153 [00:01<00:01, 53.24it/s, Epoch: 62, Batch: 67,Loss: -1.404,Avg.Loss: -2.342,LR: 1.62E-04]Training epoch 62:  44%|████▍     | 67/153 [00:01<00:01, 53.24it/s, Epoch: 62, Batch: 68,Loss: -1.614,Avg.Loss: -2.332,LR: 1.62E-04]Training epoch 62:  44%|████▍     | 68/153 [00:01<00:01, 53.24it/s, Epoch: 62, Batch: 69,Loss: -1.796,Avg.Loss: -2.324,LR: 1.62E-04]Training epoch 62:  45%|████▌     | 69/153 [00:01<00:01, 53.24it/s, Epoch: 62, Batch: 70,Loss: -1.506,Avg.Loss: -2.312,LR: 1.62E-04]Training epoch 62:  46%|████▌     | 70/153 [00:01<00:01, 53.24it/s, Epoch: 62, Batch: 71,Loss: -2.410,Avg.Loss: -2.314,LR: 1.62E-04]Training epoch 62:  46%|████▋     | 71/153 [00:01<00:01, 53.24it/s, Epoch: 62, Batch: 72,Loss: -2.538,Avg.Loss: -2.317,LR: 1.62E-04]Training epoch 62:  47%|████▋     | 72/153 [00:01<00:01, 53.39it/s, Epoch: 62, Batch: 72,Loss: -2.538,Avg.Loss: -2.317,LR: 1.62E-04]Training epoch 62:  47%|████▋     | 72/153 [00:01<00:01, 53.39it/s, Epoch: 62, Batch: 73,Loss: -2.157,Avg.Loss: -2.315,LR: 1.62E-04]Training epoch 62:  48%|████▊     | 73/153 [00:01<00:01, 53.39it/s, Epoch: 62, Batch: 74,Loss: -0.694,Avg.Loss: -2.293,LR: 1.62E-04]Training epoch 62:  48%|████▊     | 74/153 [00:01<00:01, 53.39it/s, Epoch: 62, Batch: 75,Loss: -0.783,Avg.Loss: -2.272,LR: 1.62E-04]Training epoch 62:  49%|████▉     | 75/153 [00:01<00:01, 53.39it/s, Epoch: 62, Batch: 76,Loss: -1.381,Avg.Loss: -2.261,LR: 1.62E-04]Training epoch 62:  50%|████▉     | 76/153 [00:01<00:01, 53.39it/s, Epoch: 62, Batch: 77,Loss: -2.017,Avg.Loss: -2.258,LR: 1.62E-04]Training epoch 62:  50%|█████     | 77/153 [00:01<00:01, 53.39it/s, Epoch: 62, Batch: 78,Loss: -0.947,Avg.Loss: -2.241,LR: 1.62E-04]Training epoch 62:  51%|█████     | 78/153 [00:01<00:01, 52.95it/s, Epoch: 62, Batch: 78,Loss: -0.947,Avg.Loss: -2.241,LR: 1.62E-04]Training epoch 62:  51%|█████     | 78/153 [00:01<00:01, 52.95it/s, Epoch: 62, Batch: 79,Loss: -1.015,Avg.Loss: -2.225,LR: 1.62E-04]Training epoch 62:  52%|█████▏    | 79/153 [00:01<00:01, 52.95it/s, Epoch: 62, Batch: 80,Loss: -0.943,Avg.Loss: -2.209,LR: 1.61E-04]Training epoch 62:  52%|█████▏    | 80/153 [00:01<00:01, 52.95it/s, Epoch: 62, Batch: 81,Loss: -1.714,Avg.Loss: -2.203,LR: 1.61E-04]Training epoch 62:  53%|█████▎    | 81/153 [00:01<00:01, 52.95it/s, Epoch: 62, Batch: 82,Loss: -2.453,Avg.Loss: -2.206,LR: 1.61E-04]Training epoch 62:  54%|█████▎    | 82/153 [00:01<00:01, 52.95it/s, Epoch: 62, Batch: 83,Loss: -1.779,Avg.Loss: -2.201,LR: 1.61E-04]Training epoch 62:  54%|█████▍    | 83/153 [00:01<00:01, 52.95it/s, Epoch: 62, Batch: 84,Loss: -2.162,Avg.Loss: -2.201,LR: 1.61E-04]Training epoch 62:  55%|█████▍    | 84/153 [00:01<00:01, 52.94it/s, Epoch: 62, Batch: 84,Loss: -2.162,Avg.Loss: -2.201,LR: 1.61E-04]Training epoch 62:  55%|█████▍    | 84/153 [00:01<00:01, 52.94it/s, Epoch: 62, Batch: 85,Loss: -1.924,Avg.Loss: -2.197,LR: 1.61E-04]Training epoch 62:  56%|█████▌    | 85/153 [00:01<00:01, 52.94it/s, Epoch: 62, Batch: 86,Loss: -1.935,Avg.Loss: -2.194,LR: 1.61E-04]Training epoch 62:  56%|█████▌    | 86/153 [00:01<00:01, 52.94it/s, Epoch: 62, Batch: 87,Loss: -2.553,Avg.Loss: -2.198,LR: 1.61E-04]Training epoch 62:  57%|█████▋    | 87/153 [00:01<00:01, 52.94it/s, Epoch: 62, Batch: 88,Loss: -2.659,Avg.Loss: -2.204,LR: 1.61E-04]Training epoch 62:  58%|█████▊    | 88/153 [00:01<00:01, 52.94it/s, Epoch: 62, Batch: 89,Loss: -2.674,Avg.Loss: -2.209,LR: 1.61E-04]Training epoch 62:  58%|█████▊    | 89/153 [00:01<00:01, 52.94it/s, Epoch: 62, Batch: 90,Loss: -2.737,Avg.Loss: -2.215,LR: 1.61E-04]Training epoch 62:  59%|█████▉    | 90/153 [00:01<00:01, 53.08it/s, Epoch: 62, Batch: 90,Loss: -2.737,Avg.Loss: -2.215,LR: 1.61E-04]Training epoch 62:  59%|█████▉    | 90/153 [00:01<00:01, 53.08it/s, Epoch: 62, Batch: 91,Loss: -2.727,Avg.Loss: -2.220,LR: 1.61E-04]Training epoch 62:  59%|█████▉    | 91/153 [00:01<00:01, 53.08it/s, Epoch: 62, Batch: 92,Loss: -2.544,Avg.Loss: -2.224,LR: 1.61E-04]Training epoch 62:  60%|██████    | 92/153 [00:01<00:01, 53.08it/s, Epoch: 62, Batch: 93,Loss: -3.269,Avg.Loss: -2.235,LR: 1.61E-04]Training epoch 62:  61%|██████    | 93/153 [00:01<00:01, 53.08it/s, Epoch: 62, Batch: 94,Loss: -2.592,Avg.Loss: -2.239,LR: 1.61E-04]Training epoch 62:  61%|██████▏   | 94/153 [00:01<00:01, 53.08it/s, Epoch: 62, Batch: 95,Loss: -2.685,Avg.Loss: -2.244,LR: 1.61E-04]Training epoch 62:  62%|██████▏   | 95/153 [00:01<00:01, 53.08it/s, Epoch: 62, Batch: 96,Loss: -2.946,Avg.Loss: -2.251,LR: 1.61E-04]Training epoch 62:  63%|██████▎   | 96/153 [00:01<00:01, 53.12it/s, Epoch: 62, Batch: 96,Loss: -2.946,Avg.Loss: -2.251,LR: 1.61E-04]Training epoch 62:  63%|██████▎   | 96/153 [00:01<00:01, 53.12it/s, Epoch: 62, Batch: 97,Loss: -2.833,Avg.Loss: -2.257,LR: 1.61E-04]Training epoch 62:  63%|██████▎   | 97/153 [00:01<00:01, 53.12it/s, Epoch: 62, Batch: 98,Loss: -3.288,Avg.Loss: -2.267,LR: 1.61E-04]Training epoch 62:  64%|██████▍   | 98/153 [00:01<00:01, 53.12it/s, Epoch: 62, Batch: 99,Loss: -3.343,Avg.Loss: -2.278,LR: 1.61E-04]Training epoch 62:  65%|██████▍   | 99/153 [00:01<00:01, 53.12it/s, Epoch: 62, Batch: 100,Loss: -2.328,Avg.Loss: -2.279,LR: 1.61E-04]Training epoch 62:  65%|██████▌   | 100/153 [00:01<00:00, 53.12it/s, Epoch: 62, Batch: 101,Loss: -2.789,Avg.Loss: -2.284,LR: 1.60E-04]Training epoch 62:  66%|██████▌   | 101/153 [00:01<00:00, 53.12it/s, Epoch: 62, Batch: 102,Loss: -2.859,Avg.Loss: -2.290,LR: 1.60E-04]Training epoch 62:  67%|██████▋   | 102/153 [00:01<00:00, 53.14it/s, Epoch: 62, Batch: 102,Loss: -2.859,Avg.Loss: -2.290,LR: 1.60E-04]Training epoch 62:  67%|██████▋   | 102/153 [00:01<00:00, 53.14it/s, Epoch: 62, Batch: 103,Loss: -2.573,Avg.Loss: -2.292,LR: 1.60E-04]Training epoch 62:  67%|██████▋   | 103/153 [00:01<00:00, 53.14it/s, Epoch: 62, Batch: 104,Loss: -2.316,Avg.Loss: -2.293,LR: 1.60E-04]Training epoch 62:  68%|██████▊   | 104/153 [00:01<00:00, 53.14it/s, Epoch: 62, Batch: 105,Loss: -2.277,Avg.Loss: -2.292,LR: 1.60E-04]Training epoch 62:  69%|██████▊   | 105/153 [00:01<00:00, 53.14it/s, Epoch: 62, Batch: 106,Loss: -3.067,Avg.Loss: -2.300,LR: 1.60E-04]Training epoch 62:  69%|██████▉   | 106/153 [00:02<00:00, 53.14it/s, Epoch: 62, Batch: 107,Loss: -2.672,Avg.Loss: -2.303,LR: 1.60E-04]Training epoch 62:  70%|██████▉   | 107/153 [00:02<00:00, 53.14it/s, Epoch: 62, Batch: 108,Loss: -2.583,Avg.Loss: -2.306,LR: 1.60E-04]Training epoch 62:  71%|███████   | 108/153 [00:02<00:00, 53.26it/s, Epoch: 62, Batch: 108,Loss: -2.583,Avg.Loss: -2.306,LR: 1.60E-04]Training epoch 62:  71%|███████   | 108/153 [00:02<00:00, 53.26it/s, Epoch: 62, Batch: 109,Loss: -2.514,Avg.Loss: -2.308,LR: 1.60E-04]Training epoch 62:  71%|███████   | 109/153 [00:02<00:00, 53.26it/s, Epoch: 62, Batch: 110,Loss: -2.449,Avg.Loss: -2.309,LR: 1.60E-04]Training epoch 62:  72%|███████▏  | 110/153 [00:02<00:00, 53.26it/s, Epoch: 62, Batch: 111,Loss: -2.760,Avg.Loss: -2.313,LR: 1.60E-04]Training epoch 62:  73%|███████▎  | 111/153 [00:02<00:00, 53.26it/s, Epoch: 62, Batch: 112,Loss: -2.306,Avg.Loss: -2.313,LR: 1.60E-04]Training epoch 62:  73%|███████▎  | 112/153 [00:02<00:00, 53.26it/s, Epoch: 62, Batch: 113,Loss: -2.893,Avg.Loss: -2.318,LR: 1.60E-04]Training epoch 62:  74%|███████▍  | 113/153 [00:02<00:00, 53.26it/s, Epoch: 62, Batch: 114,Loss: -2.518,Avg.Loss: -2.320,LR: 1.60E-04]Training epoch 62:  75%|███████▍  | 114/153 [00:02<00:00, 53.38it/s, Epoch: 62, Batch: 114,Loss: -2.518,Avg.Loss: -2.320,LR: 1.60E-04]Training epoch 62:  75%|███████▍  | 114/153 [00:02<00:00, 53.38it/s, Epoch: 62, Batch: 115,Loss: -2.617,Avg.Loss: -2.322,LR: 1.60E-04]Training epoch 62:  75%|███████▌  | 115/153 [00:02<00:00, 53.38it/s, Epoch: 62, Batch: 116,Loss: -2.168,Avg.Loss: -2.321,LR: 1.60E-04]Training epoch 62:  76%|███████▌  | 116/153 [00:02<00:00, 53.38it/s, Epoch: 62, Batch: 117,Loss: -2.191,Avg.Loss: -2.320,LR: 1.60E-04]Training epoch 62:  76%|███████▋  | 117/153 [00:02<00:00, 53.38it/s, Epoch: 62, Batch: 118,Loss: -2.835,Avg.Loss: -2.324,LR: 1.60E-04]Training epoch 62:  77%|███████▋  | 118/153 [00:02<00:00, 53.38it/s, Epoch: 62, Batch: 119,Loss: -2.550,Avg.Loss: -2.326,LR: 1.60E-04]Training epoch 62:  78%|███████▊  | 119/153 [00:02<00:00, 53.38it/s, Epoch: 62, Batch: 120,Loss: -2.588,Avg.Loss: -2.328,LR: 1.60E-04]Training epoch 62:  78%|███████▊  | 120/153 [00:02<00:00, 53.28it/s, Epoch: 62, Batch: 120,Loss: -2.588,Avg.Loss: -2.328,LR: 1.60E-04]Training epoch 62:  78%|███████▊  | 120/153 [00:02<00:00, 53.28it/s, Epoch: 62, Batch: 121,Loss: -2.282,Avg.Loss: -2.328,LR: 1.59E-04]Training epoch 62:  79%|███████▉  | 121/153 [00:02<00:00, 53.28it/s, Epoch: 62, Batch: 122,Loss: -1.974,Avg.Loss: -2.325,LR: 1.59E-04]Training epoch 62:  80%|███████▉  | 122/153 [00:02<00:00, 53.28it/s, Epoch: 62, Batch: 123,Loss: -2.651,Avg.Loss: -2.328,LR: 1.59E-04]Training epoch 62:  80%|████████  | 123/153 [00:02<00:00, 53.28it/s, Epoch: 62, Batch: 124,Loss: -2.605,Avg.Loss: -2.330,LR: 1.59E-04]Training epoch 62:  81%|████████  | 124/153 [00:02<00:00, 53.28it/s, Epoch: 62, Batch: 125,Loss: -2.879,Avg.Loss: -2.334,LR: 1.59E-04]Training epoch 62:  82%|████████▏ | 125/153 [00:02<00:00, 53.28it/s, Epoch: 62, Batch: 126,Loss: -2.590,Avg.Loss: -2.336,LR: 1.59E-04]Training epoch 62:  82%|████████▏ | 126/153 [00:02<00:00, 53.30it/s, Epoch: 62, Batch: 126,Loss: -2.590,Avg.Loss: -2.336,LR: 1.59E-04]Training epoch 62:  82%|████████▏ | 126/153 [00:02<00:00, 53.30it/s, Epoch: 62, Batch: 127,Loss: -2.455,Avg.Loss: -2.337,LR: 1.59E-04]Training epoch 62:  83%|████████▎ | 127/153 [00:02<00:00, 53.30it/s, Epoch: 62, Batch: 128,Loss: -2.472,Avg.Loss: -2.338,LR: 1.59E-04]Training epoch 62:  84%|████████▎ | 128/153 [00:02<00:00, 53.30it/s, Epoch: 62, Batch: 129,Loss: -2.796,Avg.Loss: -2.342,LR: 1.59E-04]Training epoch 62:  84%|████████▍ | 129/153 [00:02<00:00, 53.30it/s, Epoch: 62, Batch: 130,Loss: -2.640,Avg.Loss: -2.344,LR: 1.59E-04]Training epoch 62:  85%|████████▍ | 130/153 [00:02<00:00, 53.30it/s, Epoch: 62, Batch: 131,Loss: -2.700,Avg.Loss: -2.347,LR: 1.59E-04]Training epoch 62:  86%|████████▌ | 131/153 [00:02<00:00, 53.30it/s, Epoch: 62, Batch: 132,Loss: -1.597,Avg.Loss: -2.341,LR: 1.59E-04]Training epoch 62:  86%|████████▋ | 132/153 [00:02<00:00, 53.24it/s, Epoch: 62, Batch: 132,Loss: -1.597,Avg.Loss: -2.341,LR: 1.59E-04]Training epoch 62:  86%|████████▋ | 132/153 [00:02<00:00, 53.24it/s, Epoch: 62, Batch: 133,Loss: -2.120,Avg.Loss: -2.340,LR: 1.59E-04]Training epoch 62:  87%|████████▋ | 133/153 [00:02<00:00, 53.24it/s, Epoch: 62, Batch: 134,Loss: -1.864,Avg.Loss: -2.336,LR: 1.59E-04]Training epoch 62:  88%|████████▊ | 134/153 [00:02<00:00, 53.24it/s, Epoch: 62, Batch: 135,Loss: -2.220,Avg.Loss: -2.335,LR: 1.59E-04]Training epoch 62:  88%|████████▊ | 135/153 [00:02<00:00, 53.24it/s, Epoch: 62, Batch: 136,Loss: -2.614,Avg.Loss: -2.337,LR: 1.59E-04]Training epoch 62:  89%|████████▉ | 136/153 [00:02<00:00, 53.24it/s, Epoch: 62, Batch: 137,Loss: -2.893,Avg.Loss: -2.341,LR: 1.59E-04]Training epoch 62:  90%|████████▉ | 137/153 [00:02<00:00, 53.24it/s, Epoch: 62, Batch: 138,Loss: -2.594,Avg.Loss: -2.343,LR: 1.59E-04]Training epoch 62:  90%|█████████ | 138/153 [00:02<00:00, 53.22it/s, Epoch: 62, Batch: 138,Loss: -2.594,Avg.Loss: -2.343,LR: 1.59E-04]Training epoch 62:  90%|█████████ | 138/153 [00:02<00:00, 53.22it/s, Epoch: 62, Batch: 139,Loss: -3.045,Avg.Loss: -2.348,LR: 1.59E-04]Training epoch 62:  91%|█████████ | 139/153 [00:02<00:00, 53.22it/s, Epoch: 62, Batch: 140,Loss: -2.736,Avg.Loss: -2.351,LR: 1.59E-04]Training epoch 62:  92%|█████████▏| 140/153 [00:02<00:00, 53.22it/s, Epoch: 62, Batch: 141,Loss: -2.712,Avg.Loss: -2.354,LR: 1.59E-04]Training epoch 62:  92%|█████████▏| 141/153 [00:02<00:00, 53.22it/s, Epoch: 62, Batch: 142,Loss: -2.209,Avg.Loss: -2.353,LR: 1.58E-04]Training epoch 62:  93%|█████████▎| 142/153 [00:02<00:00, 53.22it/s, Epoch: 62, Batch: 143,Loss: -1.912,Avg.Loss: -2.349,LR: 1.58E-04]Training epoch 62:  93%|█████████▎| 143/153 [00:02<00:00, 53.22it/s, Epoch: 62, Batch: 144,Loss: -2.619,Avg.Loss: -2.351,LR: 1.58E-04]Training epoch 62:  94%|█████████▍| 144/153 [00:02<00:00, 53.33it/s, Epoch: 62, Batch: 144,Loss: -2.619,Avg.Loss: -2.351,LR: 1.58E-04]Training epoch 62:  94%|█████████▍| 144/153 [00:02<00:00, 53.33it/s, Epoch: 62, Batch: 145,Loss: -2.133,Avg.Loss: -2.350,LR: 1.58E-04]Training epoch 62:  95%|█████████▍| 145/153 [00:02<00:00, 53.33it/s, Epoch: 62, Batch: 146,Loss: -3.152,Avg.Loss: -2.355,LR: 1.58E-04]Training epoch 62:  95%|█████████▌| 146/153 [00:02<00:00, 53.33it/s, Epoch: 62, Batch: 147,Loss: -2.613,Avg.Loss: -2.357,LR: 1.58E-04]Training epoch 62:  96%|█████████▌| 147/153 [00:02<00:00, 53.33it/s, Epoch: 62, Batch: 148,Loss: -3.153,Avg.Loss: -2.362,LR: 1.58E-04]Training epoch 62:  97%|█████████▋| 148/153 [00:02<00:00, 53.33it/s, Epoch: 62, Batch: 149,Loss: -2.740,Avg.Loss: -2.365,LR: 1.58E-04]Training epoch 62:  97%|█████████▋| 149/153 [00:02<00:00, 53.33it/s, Epoch: 62, Batch: 150,Loss: -2.551,Avg.Loss: -2.366,LR: 1.58E-04]Training epoch 62:  98%|█████████▊| 150/153 [00:02<00:00, 52.94it/s, Epoch: 62, Batch: 150,Loss: -2.551,Avg.Loss: -2.366,LR: 1.58E-04]Training epoch 62:  98%|█████████▊| 150/153 [00:02<00:00, 52.94it/s, Epoch: 62, Batch: 151,Loss: -2.542,Avg.Loss: -2.367,LR: 1.58E-04]Training epoch 62:  99%|█████████▊| 151/153 [00:02<00:00, 52.94it/s, Epoch: 62, Batch: 152,Loss: -2.230,Avg.Loss: -2.366,LR: 1.58E-04]Training epoch 62:  99%|█████████▉| 152/153 [00:02<00:00, 52.94it/s, Epoch: 62, Batch: 153,Loss: -2.525,Avg.Loss: -2.368,LR: 1.58E-04]Training epoch 62: 100%|██████████| 153/153 [00:02<00:00, 53.00it/s, Epoch: 62, Batch: 153,Loss: -2.525,Avg.Loss: -2.368,LR: 1.58E-04]
Training epoch 63:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 63:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 63, Batch: 1,Loss: -2.545,Avg.Loss: -2.545,LR: 1.58E-04]Training epoch 63:   1%|          | 1/153 [00:00<00:05, 26.93it/s, Epoch: 63, Batch: 2,Loss: -2.876,Avg.Loss: -2.710,LR: 1.58E-04]Training epoch 63:   1%|▏         | 2/153 [00:00<00:04, 36.56it/s, Epoch: 63, Batch: 3,Loss: -2.807,Avg.Loss: -2.743,LR: 1.58E-04]Training epoch 63:   2%|▏         | 3/153 [00:00<00:03, 41.55it/s, Epoch: 63, Batch: 4,Loss: -2.663,Avg.Loss: -2.723,LR: 1.58E-04]Training epoch 63:   3%|▎         | 4/153 [00:00<00:03, 44.54it/s, Epoch: 63, Batch: 5,Loss: -2.820,Avg.Loss: -2.742,LR: 1.58E-04]Training epoch 63:   3%|▎         | 5/153 [00:00<00:03, 45.72it/s, Epoch: 63, Batch: 6,Loss: -2.925,Avg.Loss: -2.773,LR: 1.58E-04]Training epoch 63:   4%|▍         | 6/153 [00:00<00:02, 54.76it/s, Epoch: 63, Batch: 6,Loss: -2.925,Avg.Loss: -2.773,LR: 1.58E-04]Training epoch 63:   4%|▍         | 6/153 [00:00<00:02, 54.76it/s, Epoch: 63, Batch: 7,Loss: -2.551,Avg.Loss: -2.741,LR: 1.58E-04]Training epoch 63:   5%|▍         | 7/153 [00:00<00:02, 54.76it/s, Epoch: 63, Batch: 8,Loss: -2.639,Avg.Loss: -2.728,LR: 1.58E-04]Training epoch 63:   5%|▌         | 8/153 [00:00<00:02, 54.76it/s, Epoch: 63, Batch: 9,Loss: -2.619,Avg.Loss: -2.716,LR: 1.58E-04]Training epoch 63:   6%|▌         | 9/153 [00:00<00:02, 54.76it/s, Epoch: 63, Batch: 10,Loss: -2.795,Avg.Loss: -2.724,LR: 1.57E-04]Training epoch 63:   7%|▋         | 10/153 [00:00<00:02, 54.76it/s, Epoch: 63, Batch: 11,Loss: -2.927,Avg.Loss: -2.742,LR: 1.57E-04]Training epoch 63:   7%|▋         | 11/153 [00:00<00:02, 54.76it/s, Epoch: 63, Batch: 12,Loss: -2.340,Avg.Loss: -2.709,LR: 1.57E-04]Training epoch 63:   8%|▊         | 12/153 [00:00<00:02, 53.44it/s, Epoch: 63, Batch: 12,Loss: -2.340,Avg.Loss: -2.709,LR: 1.57E-04]Training epoch 63:   8%|▊         | 12/153 [00:00<00:02, 53.44it/s, Epoch: 63, Batch: 13,Loss: -3.031,Avg.Loss: -2.734,LR: 1.57E-04]Training epoch 63:   8%|▊         | 13/153 [00:00<00:02, 53.44it/s, Epoch: 63, Batch: 14,Loss: -2.928,Avg.Loss: -2.748,LR: 1.57E-04]Training epoch 63:   9%|▉         | 14/153 [00:00<00:02, 53.44it/s, Epoch: 63, Batch: 15,Loss: -2.238,Avg.Loss: -2.714,LR: 1.57E-04]Training epoch 63:  10%|▉         | 15/153 [00:00<00:02, 53.44it/s, Epoch: 63, Batch: 16,Loss: -2.345,Avg.Loss: -2.691,LR: 1.57E-04]Training epoch 63:  10%|█         | 16/153 [00:00<00:02, 53.44it/s, Epoch: 63, Batch: 17,Loss: -2.851,Avg.Loss: -2.700,LR: 1.57E-04]Training epoch 63:  11%|█         | 17/153 [00:00<00:02, 53.44it/s, Epoch: 63, Batch: 18,Loss: -2.437,Avg.Loss: -2.685,LR: 1.57E-04]Training epoch 63:  12%|█▏        | 18/153 [00:00<00:02, 53.11it/s, Epoch: 63, Batch: 18,Loss: -2.437,Avg.Loss: -2.685,LR: 1.57E-04]Training epoch 63:  12%|█▏        | 18/153 [00:00<00:02, 53.11it/s, Epoch: 63, Batch: 19,Loss: -2.369,Avg.Loss: -2.669,LR: 1.57E-04]Training epoch 63:  12%|█▏        | 19/153 [00:00<00:02, 53.11it/s, Epoch: 63, Batch: 20,Loss: -2.219,Avg.Loss: -2.646,LR: 1.57E-04]Training epoch 63:  13%|█▎        | 20/153 [00:00<00:02, 53.11it/s, Epoch: 63, Batch: 21,Loss: -2.399,Avg.Loss: -2.634,LR: 1.57E-04]Training epoch 63:  14%|█▎        | 21/153 [00:00<00:02, 53.11it/s, Epoch: 63, Batch: 22,Loss: -2.742,Avg.Loss: -2.639,LR: 1.57E-04]Training epoch 63:  14%|█▍        | 22/153 [00:00<00:02, 53.11it/s, Epoch: 63, Batch: 23,Loss: -2.595,Avg.Loss: -2.637,LR: 1.57E-04]Training epoch 63:  15%|█▌        | 23/153 [00:00<00:02, 53.11it/s, Epoch: 63, Batch: 24,Loss: -2.328,Avg.Loss: -2.625,LR: 1.57E-04]Training epoch 63:  16%|█▌        | 24/153 [00:00<00:02, 52.61it/s, Epoch: 63, Batch: 24,Loss: -2.328,Avg.Loss: -2.625,LR: 1.57E-04]Training epoch 63:  16%|█▌        | 24/153 [00:00<00:02, 52.61it/s, Epoch: 63, Batch: 25,Loss: -2.905,Avg.Loss: -2.636,LR: 1.57E-04]Training epoch 63:  16%|█▋        | 25/153 [00:00<00:02, 52.61it/s, Epoch: 63, Batch: 26,Loss: -2.462,Avg.Loss: -2.629,LR: 1.57E-04]Training epoch 63:  17%|█▋        | 26/153 [00:00<00:02, 52.61it/s, Epoch: 63, Batch: 27,Loss: -2.747,Avg.Loss: -2.633,LR: 1.57E-04]Training epoch 63:  18%|█▊        | 27/153 [00:00<00:02, 52.61it/s, Epoch: 63, Batch: 28,Loss: -2.814,Avg.Loss: -2.640,LR: 1.57E-04]Training epoch 63:  18%|█▊        | 28/153 [00:00<00:02, 52.61it/s, Epoch: 63, Batch: 29,Loss: -2.523,Avg.Loss: -2.636,LR: 1.57E-04]Training epoch 63:  19%|█▉        | 29/153 [00:00<00:02, 52.61it/s, Epoch: 63, Batch: 30,Loss: -2.542,Avg.Loss: -2.633,LR: 1.57E-04]Training epoch 63:  20%|█▉        | 30/153 [00:00<00:02, 52.43it/s, Epoch: 63, Batch: 30,Loss: -2.542,Avg.Loss: -2.633,LR: 1.57E-04]Training epoch 63:  20%|█▉        | 30/153 [00:00<00:02, 52.43it/s, Epoch: 63, Batch: 31,Loss: -1.662,Avg.Loss: -2.601,LR: 1.56E-04]Training epoch 63:  20%|██        | 31/153 [00:00<00:02, 52.43it/s, Epoch: 63, Batch: 32,Loss: -2.217,Avg.Loss: -2.589,LR: 1.56E-04]Training epoch 63:  21%|██        | 32/153 [00:00<00:02, 52.43it/s, Epoch: 63, Batch: 33,Loss: -2.450,Avg.Loss: -2.585,LR: 1.56E-04]Training epoch 63:  22%|██▏       | 33/153 [00:00<00:02, 52.43it/s, Epoch: 63, Batch: 34,Loss: -2.500,Avg.Loss: -2.583,LR: 1.56E-04]Training epoch 63:  22%|██▏       | 34/153 [00:00<00:02, 52.43it/s, Epoch: 63, Batch: 35,Loss: -2.100,Avg.Loss: -2.569,LR: 1.56E-04]Training epoch 63:  23%|██▎       | 35/153 [00:00<00:02, 52.43it/s, Epoch: 63, Batch: 36,Loss: -2.512,Avg.Loss: -2.567,LR: 1.56E-04]Training epoch 63:  24%|██▎       | 36/153 [00:00<00:02, 52.49it/s, Epoch: 63, Batch: 36,Loss: -2.512,Avg.Loss: -2.567,LR: 1.56E-04]Training epoch 63:  24%|██▎       | 36/153 [00:00<00:02, 52.49it/s, Epoch: 63, Batch: 37,Loss: -2.673,Avg.Loss: -2.570,LR: 1.56E-04]Training epoch 63:  24%|██▍       | 37/153 [00:00<00:02, 52.49it/s, Epoch: 63, Batch: 38,Loss: -2.699,Avg.Loss: -2.574,LR: 1.56E-04]Training epoch 63:  25%|██▍       | 38/153 [00:00<00:02, 52.49it/s, Epoch: 63, Batch: 39,Loss: -2.652,Avg.Loss: -2.576,LR: 1.56E-04]Training epoch 63:  25%|██▌       | 39/153 [00:00<00:02, 52.49it/s, Epoch: 63, Batch: 40,Loss: -2.118,Avg.Loss: -2.564,LR: 1.56E-04]Training epoch 63:  26%|██▌       | 40/153 [00:00<00:02, 52.49it/s, Epoch: 63, Batch: 41,Loss: -2.032,Avg.Loss: -2.551,LR: 1.56E-04]Training epoch 63:  27%|██▋       | 41/153 [00:00<00:02, 52.49it/s, Epoch: 63, Batch: 42,Loss: -2.524,Avg.Loss: -2.551,LR: 1.56E-04]Training epoch 63:  27%|██▋       | 42/153 [00:00<00:02, 52.46it/s, Epoch: 63, Batch: 42,Loss: -2.524,Avg.Loss: -2.551,LR: 1.56E-04]Training epoch 63:  27%|██▋       | 42/153 [00:00<00:02, 52.46it/s, Epoch: 63, Batch: 43,Loss: -2.556,Avg.Loss: -2.551,LR: 1.56E-04]Training epoch 63:  28%|██▊       | 43/153 [00:00<00:02, 52.46it/s, Epoch: 63, Batch: 44,Loss: -2.580,Avg.Loss: -2.551,LR: 1.56E-04]Training epoch 63:  29%|██▉       | 44/153 [00:00<00:02, 52.46it/s, Epoch: 63, Batch: 45,Loss: -2.764,Avg.Loss: -2.556,LR: 1.56E-04]Training epoch 63:  29%|██▉       | 45/153 [00:00<00:02, 52.46it/s, Epoch: 63, Batch: 46,Loss: -2.380,Avg.Loss: -2.552,LR: 1.56E-04]Training epoch 63:  30%|███       | 46/153 [00:00<00:02, 52.46it/s, Epoch: 63, Batch: 47,Loss: -2.553,Avg.Loss: -2.552,LR: 1.56E-04]Training epoch 63:  31%|███       | 47/153 [00:00<00:02, 52.46it/s, Epoch: 63, Batch: 48,Loss: -2.613,Avg.Loss: -2.554,LR: 1.56E-04]Training epoch 63:  31%|███▏      | 48/153 [00:00<00:01, 52.61it/s, Epoch: 63, Batch: 48,Loss: -2.613,Avg.Loss: -2.554,LR: 1.56E-04]Training epoch 63:  31%|███▏      | 48/153 [00:00<00:01, 52.61it/s, Epoch: 63, Batch: 49,Loss: -2.604,Avg.Loss: -2.555,LR: 1.56E-04]Training epoch 63:  32%|███▏      | 49/153 [00:00<00:01, 52.61it/s, Epoch: 63, Batch: 50,Loss: -2.935,Avg.Loss: -2.562,LR: 1.56E-04]Training epoch 63:  33%|███▎      | 50/153 [00:00<00:01, 52.61it/s, Epoch: 63, Batch: 51,Loss: -2.553,Avg.Loss: -2.562,LR: 1.56E-04]Training epoch 63:  33%|███▎      | 51/153 [00:00<00:01, 52.61it/s, Epoch: 63, Batch: 52,Loss: -2.523,Avg.Loss: -2.561,LR: 1.55E-04]Training epoch 63:  34%|███▍      | 52/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 53,Loss: -2.907,Avg.Loss: -2.568,LR: 1.55E-04]Training epoch 63:  35%|███▍      | 53/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 54,Loss: -2.587,Avg.Loss: -2.568,LR: 1.55E-04]Training epoch 63:  35%|███▌      | 54/153 [00:01<00:01, 52.77it/s, Epoch: 63, Batch: 54,Loss: -2.587,Avg.Loss: -2.568,LR: 1.55E-04]Training epoch 63:  35%|███▌      | 54/153 [00:01<00:01, 52.77it/s, Epoch: 63, Batch: 55,Loss: -2.833,Avg.Loss: -2.573,LR: 1.55E-04]Training epoch 63:  36%|███▌      | 55/153 [00:01<00:01, 52.77it/s, Epoch: 63, Batch: 56,Loss: -2.642,Avg.Loss: -2.574,LR: 1.55E-04]Training epoch 63:  37%|███▋      | 56/153 [00:01<00:01, 52.77it/s, Epoch: 63, Batch: 57,Loss: -2.515,Avg.Loss: -2.573,LR: 1.55E-04]Training epoch 63:  37%|███▋      | 57/153 [00:01<00:01, 52.77it/s, Epoch: 63, Batch: 58,Loss: -3.053,Avg.Loss: -2.581,LR: 1.55E-04]Training epoch 63:  38%|███▊      | 58/153 [00:01<00:01, 52.77it/s, Epoch: 63, Batch: 59,Loss: -2.072,Avg.Loss: -2.573,LR: 1.55E-04]Training epoch 63:  39%|███▊      | 59/153 [00:01<00:01, 52.77it/s, Epoch: 63, Batch: 60,Loss: -2.606,Avg.Loss: -2.573,LR: 1.55E-04]Training epoch 63:  39%|███▉      | 60/153 [00:01<00:01, 52.96it/s, Epoch: 63, Batch: 60,Loss: -2.606,Avg.Loss: -2.573,LR: 1.55E-04]Training epoch 63:  39%|███▉      | 60/153 [00:01<00:01, 52.96it/s, Epoch: 63, Batch: 61,Loss: -2.119,Avg.Loss: -2.566,LR: 1.55E-04]Training epoch 63:  40%|███▉      | 61/153 [00:01<00:01, 52.96it/s, Epoch: 63, Batch: 62,Loss: -2.055,Avg.Loss: -2.558,LR: 1.55E-04]Training epoch 63:  41%|████      | 62/153 [00:01<00:01, 52.96it/s, Epoch: 63, Batch: 63,Loss: -1.403,Avg.Loss: -2.539,LR: 1.55E-04]Training epoch 63:  41%|████      | 63/153 [00:01<00:01, 52.96it/s, Epoch: 63, Batch: 64,Loss: -1.696,Avg.Loss: -2.526,LR: 1.55E-04]Training epoch 63:  42%|████▏     | 64/153 [00:01<00:01, 52.96it/s, Epoch: 63, Batch: 65,Loss: -2.364,Avg.Loss: -2.524,LR: 1.55E-04]Training epoch 63:  42%|████▏     | 65/153 [00:01<00:01, 52.96it/s, Epoch: 63, Batch: 66,Loss: -2.616,Avg.Loss: -2.525,LR: 1.55E-04]Training epoch 63:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 63, Batch: 66,Loss: -2.616,Avg.Loss: -2.525,LR: 1.55E-04]Training epoch 63:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 63, Batch: 67,Loss: -2.034,Avg.Loss: -2.518,LR: 1.55E-04]Training epoch 63:  44%|████▍     | 67/153 [00:01<00:01, 52.84it/s, Epoch: 63, Batch: 68,Loss: -2.551,Avg.Loss: -2.518,LR: 1.55E-04]Training epoch 63:  44%|████▍     | 68/153 [00:01<00:01, 52.84it/s, Epoch: 63, Batch: 69,Loss: -2.371,Avg.Loss: -2.516,LR: 1.55E-04]Training epoch 63:  45%|████▌     | 69/153 [00:01<00:01, 52.84it/s, Epoch: 63, Batch: 70,Loss: -2.210,Avg.Loss: -2.512,LR: 1.55E-04]Training epoch 63:  46%|████▌     | 70/153 [00:01<00:01, 52.84it/s, Epoch: 63, Batch: 71,Loss: -2.560,Avg.Loss: -2.512,LR: 1.55E-04]Training epoch 63:  46%|████▋     | 71/153 [00:01<00:01, 52.84it/s, Epoch: 63, Batch: 72,Loss: -2.173,Avg.Loss: -2.508,LR: 1.55E-04]Training epoch 63:  47%|████▋     | 72/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 72,Loss: -2.173,Avg.Loss: -2.508,LR: 1.55E-04]Training epoch 63:  47%|████▋     | 72/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 73,Loss: -2.409,Avg.Loss: -2.506,LR: 1.54E-04]Training epoch 63:  48%|████▊     | 73/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 74,Loss: -2.318,Avg.Loss: -2.504,LR: 1.54E-04]Training epoch 63:  48%|████▊     | 74/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 75,Loss: -1.984,Avg.Loss: -2.497,LR: 1.54E-04]Training epoch 63:  49%|████▉     | 75/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 76,Loss: -2.647,Avg.Loss: -2.499,LR: 1.54E-04]Training epoch 63:  50%|████▉     | 76/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 77,Loss: -2.386,Avg.Loss: -2.497,LR: 1.54E-04]Training epoch 63:  50%|█████     | 77/153 [00:01<00:01, 52.61it/s, Epoch: 63, Batch: 78,Loss: -2.470,Avg.Loss: -2.497,LR: 1.54E-04]Training epoch 63:  51%|█████     | 78/153 [00:01<00:01, 52.55it/s, Epoch: 63, Batch: 78,Loss: -2.470,Avg.Loss: -2.497,LR: 1.54E-04]Training epoch 63:  51%|█████     | 78/153 [00:01<00:01, 52.55it/s, Epoch: 63, Batch: 79,Loss: -2.206,Avg.Loss: -2.493,LR: 1.54E-04]Training epoch 63:  52%|█████▏    | 79/153 [00:01<00:01, 52.55it/s, Epoch: 63, Batch: 80,Loss: -2.912,Avg.Loss: -2.499,LR: 1.54E-04]Training epoch 63:  52%|█████▏    | 80/153 [00:01<00:01, 52.55it/s, Epoch: 63, Batch: 81,Loss: -2.960,Avg.Loss: -2.504,LR: 1.54E-04]Training epoch 63:  53%|█████▎    | 81/153 [00:01<00:01, 52.55it/s, Epoch: 63, Batch: 82,Loss: -2.103,Avg.Loss: -2.499,LR: 1.54E-04]Training epoch 63:  54%|█████▎    | 82/153 [00:01<00:01, 52.55it/s, Epoch: 63, Batch: 83,Loss: -2.764,Avg.Loss: -2.502,LR: 1.54E-04]Training epoch 63:  54%|█████▍    | 83/153 [00:01<00:01, 52.55it/s, Epoch: 63, Batch: 84,Loss: -3.212,Avg.Loss: -2.511,LR: 1.54E-04]Training epoch 63:  55%|█████▍    | 84/153 [00:01<00:01, 52.66it/s, Epoch: 63, Batch: 84,Loss: -3.212,Avg.Loss: -2.511,LR: 1.54E-04]Training epoch 63:  55%|█████▍    | 84/153 [00:01<00:01, 52.66it/s, Epoch: 63, Batch: 85,Loss: -2.841,Avg.Loss: -2.515,LR: 1.54E-04]Training epoch 63:  56%|█████▌    | 85/153 [00:01<00:01, 52.66it/s, Epoch: 63, Batch: 86,Loss: -1.852,Avg.Loss: -2.507,LR: 1.54E-04]Training epoch 63:  56%|█████▌    | 86/153 [00:01<00:01, 52.66it/s, Epoch: 63, Batch: 87,Loss: -1.733,Avg.Loss: -2.498,LR: 1.54E-04]Training epoch 63:  57%|█████▋    | 87/153 [00:01<00:01, 52.66it/s, Epoch: 63, Batch: 88,Loss: -1.355,Avg.Loss: -2.485,LR: 1.54E-04]Training epoch 63:  58%|█████▊    | 88/153 [00:01<00:01, 52.66it/s, Epoch: 63, Batch: 89,Loss: -2.515,Avg.Loss: -2.486,LR: 1.54E-04]Training epoch 63:  58%|█████▊    | 89/153 [00:01<00:01, 52.66it/s, Epoch: 63, Batch: 90,Loss: -2.062,Avg.Loss: -2.481,LR: 1.54E-04]Training epoch 63:  59%|█████▉    | 90/153 [00:01<00:01, 52.45it/s, Epoch: 63, Batch: 90,Loss: -2.062,Avg.Loss: -2.481,LR: 1.54E-04]Training epoch 63:  59%|█████▉    | 90/153 [00:01<00:01, 52.45it/s, Epoch: 63, Batch: 91,Loss: -2.598,Avg.Loss: -2.482,LR: 1.54E-04]Training epoch 63:  59%|█████▉    | 91/153 [00:01<00:01, 52.45it/s, Epoch: 63, Batch: 92,Loss: -2.912,Avg.Loss: -2.487,LR: 1.54E-04]Training epoch 63:  60%|██████    | 92/153 [00:01<00:01, 52.45it/s, Epoch: 63, Batch: 93,Loss: -2.938,Avg.Loss: -2.492,LR: 1.54E-04]Training epoch 63:  61%|██████    | 93/153 [00:01<00:01, 52.45it/s, Epoch: 63, Batch: 94,Loss: -2.408,Avg.Loss: -2.491,LR: 1.53E-04]Training epoch 63:  61%|██████▏   | 94/153 [00:01<00:01, 52.45it/s, Epoch: 63, Batch: 95,Loss: -2.668,Avg.Loss: -2.493,LR: 1.53E-04]Training epoch 63:  62%|██████▏   | 95/153 [00:01<00:01, 52.45it/s, Epoch: 63, Batch: 96,Loss: -2.969,Avg.Loss: -2.498,LR: 1.53E-04]Training epoch 63:  63%|██████▎   | 96/153 [00:01<00:01, 52.60it/s, Epoch: 63, Batch: 96,Loss: -2.969,Avg.Loss: -2.498,LR: 1.53E-04]Training epoch 63:  63%|██████▎   | 96/153 [00:01<00:01, 52.60it/s, Epoch: 63, Batch: 97,Loss: -2.383,Avg.Loss: -2.496,LR: 1.53E-04]Training epoch 63:  63%|██████▎   | 97/153 [00:01<00:01, 52.60it/s, Epoch: 63, Batch: 98,Loss: -2.658,Avg.Loss: -2.498,LR: 1.53E-04]Training epoch 63:  64%|██████▍   | 98/153 [00:01<00:01, 52.60it/s, Epoch: 63, Batch: 99,Loss: -2.817,Avg.Loss: -2.501,LR: 1.53E-04]Training epoch 63:  65%|██████▍   | 99/153 [00:01<00:01, 52.60it/s, Epoch: 63, Batch: 100,Loss: -2.477,Avg.Loss: -2.501,LR: 1.53E-04]Training epoch 63:  65%|██████▌   | 100/153 [00:01<00:01, 52.60it/s, Epoch: 63, Batch: 101,Loss: -3.080,Avg.Loss: -2.507,LR: 1.53E-04]Training epoch 63:  66%|██████▌   | 101/153 [00:01<00:00, 52.60it/s, Epoch: 63, Batch: 102,Loss: -2.504,Avg.Loss: -2.507,LR: 1.53E-04]Training epoch 63:  67%|██████▋   | 102/153 [00:01<00:00, 52.94it/s, Epoch: 63, Batch: 102,Loss: -2.504,Avg.Loss: -2.507,LR: 1.53E-04]Training epoch 63:  67%|██████▋   | 102/153 [00:01<00:00, 52.94it/s, Epoch: 63, Batch: 103,Loss: -2.129,Avg.Loss: -2.503,LR: 1.53E-04]Training epoch 63:  67%|██████▋   | 103/153 [00:01<00:00, 52.94it/s, Epoch: 63, Batch: 104,Loss: -2.828,Avg.Loss: -2.506,LR: 1.53E-04]Training epoch 63:  68%|██████▊   | 104/153 [00:01<00:00, 52.94it/s, Epoch: 63, Batch: 105,Loss: -2.622,Avg.Loss: -2.507,LR: 1.53E-04]Training epoch 63:  69%|██████▊   | 105/153 [00:02<00:00, 52.94it/s, Epoch: 63, Batch: 106,Loss: -2.857,Avg.Loss: -2.511,LR: 1.53E-04]Training epoch 63:  69%|██████▉   | 106/153 [00:02<00:00, 52.94it/s, Epoch: 63, Batch: 107,Loss: -2.781,Avg.Loss: -2.513,LR: 1.53E-04]Training epoch 63:  70%|██████▉   | 107/153 [00:02<00:00, 52.94it/s, Epoch: 63, Batch: 108,Loss: -2.994,Avg.Loss: -2.518,LR: 1.53E-04]Training epoch 63:  71%|███████   | 108/153 [00:02<00:00, 53.14it/s, Epoch: 63, Batch: 108,Loss: -2.994,Avg.Loss: -2.518,LR: 1.53E-04]Training epoch 63:  71%|███████   | 108/153 [00:02<00:00, 53.14it/s, Epoch: 63, Batch: 109,Loss: -2.624,Avg.Loss: -2.519,LR: 1.53E-04]Training epoch 63:  71%|███████   | 109/153 [00:02<00:00, 53.14it/s, Epoch: 63, Batch: 110,Loss: -2.744,Avg.Loss: -2.521,LR: 1.53E-04]Training epoch 63:  72%|███████▏  | 110/153 [00:02<00:00, 53.14it/s, Epoch: 63, Batch: 111,Loss: -2.901,Avg.Loss: -2.524,LR: 1.53E-04]Training epoch 63:  73%|███████▎  | 111/153 [00:02<00:00, 53.14it/s, Epoch: 63, Batch: 112,Loss: -2.848,Avg.Loss: -2.527,LR: 1.53E-04]Training epoch 63:  73%|███████▎  | 112/153 [00:02<00:00, 53.14it/s, Epoch: 63, Batch: 113,Loss: -2.991,Avg.Loss: -2.531,LR: 1.53E-04]Training epoch 63:  74%|███████▍  | 113/153 [00:02<00:00, 53.14it/s, Epoch: 63, Batch: 114,Loss: -2.631,Avg.Loss: -2.532,LR: 1.53E-04]Training epoch 63:  75%|███████▍  | 114/153 [00:02<00:00, 53.13it/s, Epoch: 63, Batch: 114,Loss: -2.631,Avg.Loss: -2.532,LR: 1.53E-04]Training epoch 63:  75%|███████▍  | 114/153 [00:02<00:00, 53.13it/s, Epoch: 63, Batch: 115,Loss: -2.802,Avg.Loss: -2.534,LR: 1.53E-04]Training epoch 63:  75%|███████▌  | 115/153 [00:02<00:00, 53.13it/s, Epoch: 63, Batch: 116,Loss: -2.986,Avg.Loss: -2.538,LR: 1.52E-04]Training epoch 63:  76%|███████▌  | 116/153 [00:02<00:00, 53.13it/s, Epoch: 63, Batch: 117,Loss: -2.788,Avg.Loss: -2.540,LR: 1.52E-04]Training epoch 63:  76%|███████▋  | 117/153 [00:02<00:00, 53.13it/s, Epoch: 63, Batch: 118,Loss: -2.360,Avg.Loss: -2.539,LR: 1.52E-04]Training epoch 63:  77%|███████▋  | 118/153 [00:02<00:00, 53.13it/s, Epoch: 63, Batch: 119,Loss: -2.771,Avg.Loss: -2.541,LR: 1.52E-04]Training epoch 63:  78%|███████▊  | 119/153 [00:02<00:00, 53.13it/s, Epoch: 63, Batch: 120,Loss: -3.143,Avg.Loss: -2.546,LR: 1.52E-04]Training epoch 63:  78%|███████▊  | 120/153 [00:02<00:00, 53.23it/s, Epoch: 63, Batch: 120,Loss: -3.143,Avg.Loss: -2.546,LR: 1.52E-04]Training epoch 63:  78%|███████▊  | 120/153 [00:02<00:00, 53.23it/s, Epoch: 63, Batch: 121,Loss: -2.705,Avg.Loss: -2.547,LR: 1.52E-04]Training epoch 63:  79%|███████▉  | 121/153 [00:02<00:00, 53.23it/s, Epoch: 63, Batch: 122,Loss: -2.894,Avg.Loss: -2.550,LR: 1.52E-04]Training epoch 63:  80%|███████▉  | 122/153 [00:02<00:00, 53.23it/s, Epoch: 63, Batch: 123,Loss: -3.027,Avg.Loss: -2.554,LR: 1.52E-04]Training epoch 63:  80%|████████  | 123/153 [00:02<00:00, 53.23it/s, Epoch: 63, Batch: 124,Loss: -2.830,Avg.Loss: -2.556,LR: 1.52E-04]Training epoch 63:  81%|████████  | 124/153 [00:02<00:00, 53.23it/s, Epoch: 63, Batch: 125,Loss: -2.713,Avg.Loss: -2.557,LR: 1.52E-04]Training epoch 63:  82%|████████▏ | 125/153 [00:02<00:00, 53.23it/s, Epoch: 63, Batch: 126,Loss: -3.047,Avg.Loss: -2.561,LR: 1.52E-04]Training epoch 63:  82%|████████▏ | 126/153 [00:02<00:00, 53.25it/s, Epoch: 63, Batch: 126,Loss: -3.047,Avg.Loss: -2.561,LR: 1.52E-04]Training epoch 63:  82%|████████▏ | 126/153 [00:02<00:00, 53.25it/s, Epoch: 63, Batch: 127,Loss: -3.132,Avg.Loss: -2.566,LR: 1.52E-04]Training epoch 63:  83%|████████▎ | 127/153 [00:02<00:00, 53.25it/s, Epoch: 63, Batch: 128,Loss: -2.885,Avg.Loss: -2.568,LR: 1.52E-04]Training epoch 63:  84%|████████▎ | 128/153 [00:02<00:00, 53.25it/s, Epoch: 63, Batch: 129,Loss: -2.757,Avg.Loss: -2.570,LR: 1.52E-04]Training epoch 63:  84%|████████▍ | 129/153 [00:02<00:00, 53.25it/s, Epoch: 63, Batch: 130,Loss: -2.874,Avg.Loss: -2.572,LR: 1.52E-04]Training epoch 63:  85%|████████▍ | 130/153 [00:02<00:00, 53.25it/s, Epoch: 63, Batch: 131,Loss: -3.139,Avg.Loss: -2.576,LR: 1.52E-04]Training epoch 63:  86%|████████▌ | 131/153 [00:02<00:00, 53.25it/s, Epoch: 63, Batch: 132,Loss: -2.730,Avg.Loss: -2.577,LR: 1.52E-04]Training epoch 63:  86%|████████▋ | 132/153 [00:02<00:00, 53.47it/s, Epoch: 63, Batch: 132,Loss: -2.730,Avg.Loss: -2.577,LR: 1.52E-04]Training epoch 63:  86%|████████▋ | 132/153 [00:02<00:00, 53.47it/s, Epoch: 63, Batch: 133,Loss: -2.961,Avg.Loss: -2.580,LR: 1.52E-04]Training epoch 63:  87%|████████▋ | 133/153 [00:02<00:00, 53.47it/s, Epoch: 63, Batch: 134,Loss: -2.892,Avg.Loss: -2.583,LR: 1.52E-04]Training epoch 63:  88%|████████▊ | 134/153 [00:02<00:00, 53.47it/s, Epoch: 63, Batch: 135,Loss: -2.472,Avg.Loss: -2.582,LR: 1.52E-04]Training epoch 63:  88%|████████▊ | 135/153 [00:02<00:00, 53.47it/s, Epoch: 63, Batch: 136,Loss: -2.953,Avg.Loss: -2.585,LR: 1.52E-04]Training epoch 63:  89%|████████▉ | 136/153 [00:02<00:00, 53.47it/s, Epoch: 63, Batch: 137,Loss: -2.970,Avg.Loss: -2.587,LR: 1.51E-04]Training epoch 63:  90%|████████▉ | 137/153 [00:02<00:00, 53.47it/s, Epoch: 63, Batch: 138,Loss: -2.506,Avg.Loss: -2.587,LR: 1.51E-04]Training epoch 63:  90%|█████████ | 138/153 [00:02<00:00, 53.50it/s, Epoch: 63, Batch: 138,Loss: -2.506,Avg.Loss: -2.587,LR: 1.51E-04]Training epoch 63:  90%|█████████ | 138/153 [00:02<00:00, 53.50it/s, Epoch: 63, Batch: 139,Loss: -2.645,Avg.Loss: -2.587,LR: 1.51E-04]Training epoch 63:  91%|█████████ | 139/153 [00:02<00:00, 53.50it/s, Epoch: 63, Batch: 140,Loss: -2.881,Avg.Loss: -2.589,LR: 1.51E-04]Training epoch 63:  92%|█████████▏| 140/153 [00:02<00:00, 53.50it/s, Epoch: 63, Batch: 141,Loss: -2.668,Avg.Loss: -2.590,LR: 1.51E-04]Training epoch 63:  92%|█████████▏| 141/153 [00:02<00:00, 53.50it/s, Epoch: 63, Batch: 142,Loss: -2.786,Avg.Loss: -2.591,LR: 1.51E-04]Training epoch 63:  93%|█████████▎| 142/153 [00:02<00:00, 53.50it/s, Epoch: 63, Batch: 143,Loss: -2.520,Avg.Loss: -2.591,LR: 1.51E-04]Training epoch 63:  93%|█████████▎| 143/153 [00:02<00:00, 53.50it/s, Epoch: 63, Batch: 144,Loss: -2.767,Avg.Loss: -2.592,LR: 1.51E-04]Training epoch 63:  94%|█████████▍| 144/153 [00:02<00:00, 53.48it/s, Epoch: 63, Batch: 144,Loss: -2.767,Avg.Loss: -2.592,LR: 1.51E-04]Training epoch 63:  94%|█████████▍| 144/153 [00:02<00:00, 53.48it/s, Epoch: 63, Batch: 145,Loss: -2.946,Avg.Loss: -2.594,LR: 1.51E-04]Training epoch 63:  95%|█████████▍| 145/153 [00:02<00:00, 53.48it/s, Epoch: 63, Batch: 146,Loss: -2.871,Avg.Loss: -2.596,LR: 1.51E-04]Training epoch 63:  95%|█████████▌| 146/153 [00:02<00:00, 53.48it/s, Epoch: 63, Batch: 147,Loss: -2.792,Avg.Loss: -2.598,LR: 1.51E-04]Training epoch 63:  96%|█████████▌| 147/153 [00:02<00:00, 53.48it/s, Epoch: 63, Batch: 148,Loss: -2.873,Avg.Loss: -2.599,LR: 1.51E-04]Training epoch 63:  97%|█████████▋| 148/153 [00:02<00:00, 53.48it/s, Epoch: 63, Batch: 149,Loss: -2.409,Avg.Loss: -2.598,LR: 1.51E-04]Training epoch 63:  97%|█████████▋| 149/153 [00:02<00:00, 53.48it/s, Epoch: 63, Batch: 150,Loss: -2.528,Avg.Loss: -2.598,LR: 1.51E-04]Training epoch 63:  98%|█████████▊| 150/153 [00:02<00:00, 53.68it/s, Epoch: 63, Batch: 150,Loss: -2.528,Avg.Loss: -2.598,LR: 1.51E-04]Training epoch 63:  98%|█████████▊| 150/153 [00:02<00:00, 53.68it/s, Epoch: 63, Batch: 151,Loss: -2.687,Avg.Loss: -2.598,LR: 1.51E-04]Training epoch 63:  99%|█████████▊| 151/153 [00:02<00:00, 53.68it/s, Epoch: 63, Batch: 152,Loss: -2.624,Avg.Loss: -2.599,LR: 1.51E-04]Training epoch 63:  99%|█████████▉| 152/153 [00:02<00:00, 53.68it/s, Epoch: 63, Batch: 153,Loss: -3.146,Avg.Loss: -2.602,LR: 1.51E-04]Training epoch 63: 100%|██████████| 153/153 [00:02<00:00, 52.94it/s, Epoch: 63, Batch: 153,Loss: -3.146,Avg.Loss: -2.602,LR: 1.51E-04]
Training epoch 64:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 64:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 64, Batch: 1,Loss: -2.894,Avg.Loss: -2.894,LR: 1.51E-04]Training epoch 64:   1%|          | 1/153 [00:00<00:06, 23.62it/s, Epoch: 64, Batch: 2,Loss: -2.491,Avg.Loss: -2.692,LR: 1.51E-04]Training epoch 64:   1%|▏         | 2/153 [00:00<00:04, 33.43it/s, Epoch: 64, Batch: 3,Loss: -2.285,Avg.Loss: -2.556,LR: 1.51E-04]Training epoch 64:   2%|▏         | 3/153 [00:00<00:03, 38.98it/s, Epoch: 64, Batch: 4,Loss: -2.481,Avg.Loss: -2.538,LR: 1.51E-04]Training epoch 64:   3%|▎         | 4/153 [00:00<00:03, 42.19it/s, Epoch: 64, Batch: 5,Loss: -2.649,Avg.Loss: -2.560,LR: 1.50E-04]Training epoch 64:   3%|▎         | 5/153 [00:00<00:03, 44.04it/s, Epoch: 64, Batch: 6,Loss: -2.823,Avg.Loss: -2.604,LR: 1.50E-04]Training epoch 64:   4%|▍         | 6/153 [00:00<00:02, 52.76it/s, Epoch: 64, Batch: 6,Loss: -2.823,Avg.Loss: -2.604,LR: 1.50E-04]Training epoch 64:   4%|▍         | 6/153 [00:00<00:02, 52.76it/s, Epoch: 64, Batch: 7,Loss: -2.384,Avg.Loss: -2.572,LR: 1.50E-04]Training epoch 64:   5%|▍         | 7/153 [00:00<00:02, 52.76it/s, Epoch: 64, Batch: 8,Loss: -2.235,Avg.Loss: -2.530,LR: 1.50E-04]Training epoch 64:   5%|▌         | 8/153 [00:00<00:02, 52.76it/s, Epoch: 64, Batch: 9,Loss: -2.547,Avg.Loss: -2.532,LR: 1.50E-04]Training epoch 64:   6%|▌         | 9/153 [00:00<00:02, 52.76it/s, Epoch: 64, Batch: 10,Loss: -2.625,Avg.Loss: -2.541,LR: 1.50E-04]Training epoch 64:   7%|▋         | 10/153 [00:00<00:02, 52.76it/s, Epoch: 64, Batch: 11,Loss: -2.847,Avg.Loss: -2.569,LR: 1.50E-04]Training epoch 64:   7%|▋         | 11/153 [00:00<00:02, 52.76it/s, Epoch: 64, Batch: 12,Loss: -2.279,Avg.Loss: -2.545,LR: 1.50E-04]Training epoch 64:   8%|▊         | 12/153 [00:00<00:02, 52.92it/s, Epoch: 64, Batch: 12,Loss: -2.279,Avg.Loss: -2.545,LR: 1.50E-04]Training epoch 64:   8%|▊         | 12/153 [00:00<00:02, 52.92it/s, Epoch: 64, Batch: 13,Loss: -1.756,Avg.Loss: -2.484,LR: 1.50E-04]Training epoch 64:   8%|▊         | 13/153 [00:00<00:02, 52.92it/s, Epoch: 64, Batch: 14,Loss: -2.356,Avg.Loss: -2.475,LR: 1.50E-04]Training epoch 64:   9%|▉         | 14/153 [00:00<00:02, 52.92it/s, Epoch: 64, Batch: 15,Loss: -2.045,Avg.Loss: -2.447,LR: 1.50E-04]Training epoch 64:  10%|▉         | 15/153 [00:00<00:02, 52.92it/s, Epoch: 64, Batch: 16,Loss: -2.699,Avg.Loss: -2.462,LR: 1.50E-04]Training epoch 64:  10%|█         | 16/153 [00:00<00:02, 52.92it/s, Epoch: 64, Batch: 17,Loss: -1.665,Avg.Loss: -2.415,LR: 1.50E-04]Training epoch 64:  11%|█         | 17/153 [00:00<00:02, 52.92it/s, Epoch: 64, Batch: 18,Loss: -2.292,Avg.Loss: -2.409,LR: 1.50E-04]Training epoch 64:  12%|█▏        | 18/153 [00:00<00:02, 53.13it/s, Epoch: 64, Batch: 18,Loss: -2.292,Avg.Loss: -2.409,LR: 1.50E-04]Training epoch 64:  12%|█▏        | 18/153 [00:00<00:02, 53.13it/s, Epoch: 64, Batch: 19,Loss: -3.239,Avg.Loss: -2.452,LR: 1.50E-04]Training epoch 64:  12%|█▏        | 19/153 [00:00<00:02, 53.13it/s, Epoch: 64, Batch: 20,Loss: -3.071,Avg.Loss: -2.483,LR: 1.50E-04]Training epoch 64:  13%|█▎        | 20/153 [00:00<00:02, 53.13it/s, Epoch: 64, Batch: 21,Loss: -2.769,Avg.Loss: -2.497,LR: 1.50E-04]Training epoch 64:  14%|█▎        | 21/153 [00:00<00:02, 53.13it/s, Epoch: 64, Batch: 22,Loss: -2.531,Avg.Loss: -2.498,LR: 1.50E-04]Training epoch 64:  14%|█▍        | 22/153 [00:00<00:02, 53.13it/s, Epoch: 64, Batch: 23,Loss: -3.037,Avg.Loss: -2.522,LR: 1.50E-04]Training epoch 64:  15%|█▌        | 23/153 [00:00<00:02, 53.13it/s, Epoch: 64, Batch: 24,Loss: -2.406,Avg.Loss: -2.517,LR: 1.50E-04]Training epoch 64:  16%|█▌        | 24/153 [00:00<00:02, 52.57it/s, Epoch: 64, Batch: 24,Loss: -2.406,Avg.Loss: -2.517,LR: 1.50E-04]Training epoch 64:  16%|█▌        | 24/153 [00:00<00:02, 52.57it/s, Epoch: 64, Batch: 25,Loss: -1.900,Avg.Loss: -2.492,LR: 1.50E-04]Training epoch 64:  16%|█▋        | 25/153 [00:00<00:02, 52.57it/s, Epoch: 64, Batch: 26,Loss: -1.721,Avg.Loss: -2.463,LR: 1.49E-04]Training epoch 64:  17%|█▋        | 26/153 [00:00<00:02, 52.57it/s, Epoch: 64, Batch: 27,Loss: -2.474,Avg.Loss: -2.463,LR: 1.49E-04]Training epoch 64:  18%|█▊        | 27/153 [00:00<00:02, 52.57it/s, Epoch: 64, Batch: 28,Loss: -2.838,Avg.Loss: -2.476,LR: 1.49E-04]Training epoch 64:  18%|█▊        | 28/153 [00:00<00:02, 52.57it/s, Epoch: 64, Batch: 29,Loss: -1.885,Avg.Loss: -2.456,LR: 1.49E-04]Training epoch 64:  19%|█▉        | 29/153 [00:00<00:02, 52.57it/s, Epoch: 64, Batch: 30,Loss: -2.511,Avg.Loss: -2.458,LR: 1.49E-04]Training epoch 64:  20%|█▉        | 30/153 [00:00<00:02, 52.34it/s, Epoch: 64, Batch: 30,Loss: -2.511,Avg.Loss: -2.458,LR: 1.49E-04]Training epoch 64:  20%|█▉        | 30/153 [00:00<00:02, 52.34it/s, Epoch: 64, Batch: 31,Loss: -3.016,Avg.Loss: -2.476,LR: 1.49E-04]Training epoch 64:  20%|██        | 31/153 [00:00<00:02, 52.34it/s, Epoch: 64, Batch: 32,Loss: -2.870,Avg.Loss: -2.488,LR: 1.49E-04]Training epoch 64:  21%|██        | 32/153 [00:00<00:02, 52.34it/s, Epoch: 64, Batch: 33,Loss: -2.929,Avg.Loss: -2.501,LR: 1.49E-04]Training epoch 64:  22%|██▏       | 33/153 [00:00<00:02, 52.34it/s, Epoch: 64, Batch: 34,Loss: -2.564,Avg.Loss: -2.503,LR: 1.49E-04]Training epoch 64:  22%|██▏       | 34/153 [00:00<00:02, 52.34it/s, Epoch: 64, Batch: 35,Loss: -2.720,Avg.Loss: -2.510,LR: 1.49E-04]Training epoch 64:  23%|██▎       | 35/153 [00:00<00:02, 52.34it/s, Epoch: 64, Batch: 36,Loss: -3.105,Avg.Loss: -2.526,LR: 1.49E-04]Training epoch 64:  24%|██▎       | 36/153 [00:00<00:02, 52.91it/s, Epoch: 64, Batch: 36,Loss: -3.105,Avg.Loss: -2.526,LR: 1.49E-04]Training epoch 64:  24%|██▎       | 36/153 [00:00<00:02, 52.91it/s, Epoch: 64, Batch: 37,Loss: -1.846,Avg.Loss: -2.508,LR: 1.49E-04]Training epoch 64:  24%|██▍       | 37/153 [00:00<00:02, 52.91it/s, Epoch: 64, Batch: 38,Loss: -3.065,Avg.Loss: -2.522,LR: 1.49E-04]Training epoch 64:  25%|██▍       | 38/153 [00:00<00:02, 52.91it/s, Epoch: 64, Batch: 39,Loss: -2.480,Avg.Loss: -2.521,LR: 1.49E-04]Training epoch 64:  25%|██▌       | 39/153 [00:00<00:02, 52.91it/s, Epoch: 64, Batch: 40,Loss: -2.661,Avg.Loss: -2.525,LR: 1.49E-04]Training epoch 64:  26%|██▌       | 40/153 [00:00<00:02, 52.91it/s, Epoch: 64, Batch: 41,Loss: -2.746,Avg.Loss: -2.530,LR: 1.49E-04]Training epoch 64:  27%|██▋       | 41/153 [00:00<00:02, 52.91it/s, Epoch: 64, Batch: 42,Loss: -2.695,Avg.Loss: -2.534,LR: 1.49E-04]Training epoch 64:  27%|██▋       | 42/153 [00:00<00:02, 53.29it/s, Epoch: 64, Batch: 42,Loss: -2.695,Avg.Loss: -2.534,LR: 1.49E-04]Training epoch 64:  27%|██▋       | 42/153 [00:00<00:02, 53.29it/s, Epoch: 64, Batch: 43,Loss: -2.762,Avg.Loss: -2.539,LR: 1.49E-04]Training epoch 64:  28%|██▊       | 43/153 [00:00<00:02, 53.29it/s, Epoch: 64, Batch: 44,Loss: -2.776,Avg.Loss: -2.545,LR: 1.49E-04]Training epoch 64:  29%|██▉       | 44/153 [00:00<00:02, 53.29it/s, Epoch: 64, Batch: 45,Loss: -2.445,Avg.Loss: -2.543,LR: 1.49E-04]Training epoch 64:  29%|██▉       | 45/153 [00:00<00:02, 53.29it/s, Epoch: 64, Batch: 46,Loss: -2.688,Avg.Loss: -2.546,LR: 1.49E-04]Training epoch 64:  30%|███       | 46/153 [00:00<00:02, 53.29it/s, Epoch: 64, Batch: 47,Loss: -2.417,Avg.Loss: -2.543,LR: 1.49E-04]Training epoch 64:  31%|███       | 47/153 [00:00<00:01, 53.29it/s, Epoch: 64, Batch: 48,Loss: -2.493,Avg.Loss: -2.542,LR: 1.48E-04]Training epoch 64:  31%|███▏      | 48/153 [00:00<00:01, 53.55it/s, Epoch: 64, Batch: 48,Loss: -2.493,Avg.Loss: -2.542,LR: 1.48E-04]Training epoch 64:  31%|███▏      | 48/153 [00:00<00:01, 53.55it/s, Epoch: 64, Batch: 49,Loss: -2.624,Avg.Loss: -2.544,LR: 1.48E-04]Training epoch 64:  32%|███▏      | 49/153 [00:00<00:01, 53.55it/s, Epoch: 64, Batch: 50,Loss: -2.591,Avg.Loss: -2.545,LR: 1.48E-04]Training epoch 64:  33%|███▎      | 50/153 [00:00<00:01, 53.55it/s, Epoch: 64, Batch: 51,Loss: -2.653,Avg.Loss: -2.547,LR: 1.48E-04]Training epoch 64:  33%|███▎      | 51/153 [00:00<00:01, 53.55it/s, Epoch: 64, Batch: 52,Loss: -2.925,Avg.Loss: -2.554,LR: 1.48E-04]Training epoch 64:  34%|███▍      | 52/153 [00:00<00:01, 53.55it/s, Epoch: 64, Batch: 53,Loss: -2.518,Avg.Loss: -2.553,LR: 1.48E-04]Training epoch 64:  35%|███▍      | 53/153 [00:01<00:01, 53.55it/s, Epoch: 64, Batch: 54,Loss: -2.667,Avg.Loss: -2.555,LR: 1.48E-04]Training epoch 64:  35%|███▌      | 54/153 [00:01<00:01, 53.81it/s, Epoch: 64, Batch: 54,Loss: -2.667,Avg.Loss: -2.555,LR: 1.48E-04]Training epoch 64:  35%|███▌      | 54/153 [00:01<00:01, 53.81it/s, Epoch: 64, Batch: 55,Loss: -2.727,Avg.Loss: -2.558,LR: 1.48E-04]Training epoch 64:  36%|███▌      | 55/153 [00:01<00:01, 53.81it/s, Epoch: 64, Batch: 56,Loss: -2.517,Avg.Loss: -2.558,LR: 1.48E-04]Training epoch 64:  37%|███▋      | 56/153 [00:01<00:01, 53.81it/s, Epoch: 64, Batch: 57,Loss: -1.761,Avg.Loss: -2.544,LR: 1.48E-04]Training epoch 64:  37%|███▋      | 57/153 [00:01<00:01, 53.81it/s, Epoch: 64, Batch: 58,Loss: -2.273,Avg.Loss: -2.539,LR: 1.48E-04]Training epoch 64:  38%|███▊      | 58/153 [00:01<00:01, 53.81it/s, Epoch: 64, Batch: 59,Loss: -2.659,Avg.Loss: -2.541,LR: 1.48E-04]Training epoch 64:  39%|███▊      | 59/153 [00:01<00:01, 53.81it/s, Epoch: 64, Batch: 60,Loss: -2.852,Avg.Loss: -2.546,LR: 1.48E-04]Training epoch 64:  39%|███▉      | 60/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 60,Loss: -2.852,Avg.Loss: -2.546,LR: 1.48E-04]Training epoch 64:  39%|███▉      | 60/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 61,Loss: -2.828,Avg.Loss: -2.551,LR: 1.48E-04]Training epoch 64:  40%|███▉      | 61/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 62,Loss: -2.105,Avg.Loss: -2.544,LR: 1.48E-04]Training epoch 64:  41%|████      | 62/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 63,Loss: -2.595,Avg.Loss: -2.545,LR: 1.48E-04]Training epoch 64:  41%|████      | 63/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 64,Loss: -2.790,Avg.Loss: -2.548,LR: 1.48E-04]Training epoch 64:  42%|████▏     | 64/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 65,Loss: -2.803,Avg.Loss: -2.552,LR: 1.48E-04]Training epoch 64:  42%|████▏     | 65/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 66,Loss: -2.877,Avg.Loss: -2.557,LR: 1.48E-04]Training epoch 64:  43%|████▎     | 66/153 [00:01<00:01, 53.97it/s, Epoch: 64, Batch: 66,Loss: -2.877,Avg.Loss: -2.557,LR: 1.48E-04]Training epoch 64:  43%|████▎     | 66/153 [00:01<00:01, 53.97it/s, Epoch: 64, Batch: 67,Loss: -3.404,Avg.Loss: -2.570,LR: 1.48E-04]Training epoch 64:  44%|████▍     | 67/153 [00:01<00:01, 53.97it/s, Epoch: 64, Batch: 68,Loss: -2.152,Avg.Loss: -2.564,LR: 1.48E-04]Training epoch 64:  44%|████▍     | 68/153 [00:01<00:01, 53.97it/s, Epoch: 64, Batch: 69,Loss: -2.692,Avg.Loss: -2.566,LR: 1.47E-04]Training epoch 64:  45%|████▌     | 69/153 [00:01<00:01, 53.97it/s, Epoch: 64, Batch: 70,Loss: -2.125,Avg.Loss: -2.559,LR: 1.47E-04]Training epoch 64:  46%|████▌     | 70/153 [00:01<00:01, 53.97it/s, Epoch: 64, Batch: 71,Loss: -1.451,Avg.Loss: -2.544,LR: 1.47E-04]Training epoch 64:  46%|████▋     | 71/153 [00:01<00:01, 53.97it/s, Epoch: 64, Batch: 72,Loss: -2.819,Avg.Loss: -2.547,LR: 1.47E-04]Training epoch 64:  47%|████▋     | 72/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 72,Loss: -2.819,Avg.Loss: -2.547,LR: 1.47E-04]Training epoch 64:  47%|████▋     | 72/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 73,Loss: -2.905,Avg.Loss: -2.552,LR: 1.47E-04]Training epoch 64:  48%|████▊     | 73/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 74,Loss: -2.325,Avg.Loss: -2.549,LR: 1.47E-04]Training epoch 64:  48%|████▊     | 74/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 75,Loss: -2.079,Avg.Loss: -2.543,LR: 1.47E-04]Training epoch 64:  49%|████▉     | 75/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 76,Loss: -2.738,Avg.Loss: -2.546,LR: 1.47E-04]Training epoch 64:  50%|████▉     | 76/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 77,Loss: -2.766,Avg.Loss: -2.548,LR: 1.47E-04]Training epoch 64:  50%|█████     | 77/153 [00:01<00:01, 53.89it/s, Epoch: 64, Batch: 78,Loss: -2.492,Avg.Loss: -2.548,LR: 1.47E-04]Training epoch 64:  51%|█████     | 78/153 [00:01<00:01, 53.85it/s, Epoch: 64, Batch: 78,Loss: -2.492,Avg.Loss: -2.548,LR: 1.47E-04]Training epoch 64:  51%|█████     | 78/153 [00:01<00:01, 53.85it/s, Epoch: 64, Batch: 79,Loss: -2.046,Avg.Loss: -2.541,LR: 1.47E-04]Training epoch 64:  52%|█████▏    | 79/153 [00:01<00:01, 53.85it/s, Epoch: 64, Batch: 80,Loss: -2.179,Avg.Loss: -2.537,LR: 1.47E-04]Training epoch 64:  52%|█████▏    | 80/153 [00:01<00:01, 53.85it/s, Epoch: 64, Batch: 81,Loss: -1.823,Avg.Loss: -2.528,LR: 1.47E-04]Training epoch 64:  53%|█████▎    | 81/153 [00:01<00:01, 53.85it/s, Epoch: 64, Batch: 82,Loss: -2.301,Avg.Loss: -2.525,LR: 1.47E-04]Training epoch 64:  54%|█████▎    | 82/153 [00:01<00:01, 53.85it/s, Epoch: 64, Batch: 83,Loss: -2.262,Avg.Loss: -2.522,LR: 1.47E-04]Training epoch 64:  54%|█████▍    | 83/153 [00:01<00:01, 53.85it/s, Epoch: 64, Batch: 84,Loss: -2.326,Avg.Loss: -2.520,LR: 1.47E-04]Training epoch 64:  55%|█████▍    | 84/153 [00:01<00:01, 53.94it/s, Epoch: 64, Batch: 84,Loss: -2.326,Avg.Loss: -2.520,LR: 1.47E-04]Training epoch 64:  55%|█████▍    | 84/153 [00:01<00:01, 53.94it/s, Epoch: 64, Batch: 85,Loss: -2.482,Avg.Loss: -2.519,LR: 1.47E-04]Training epoch 64:  56%|█████▌    | 85/153 [00:01<00:01, 53.94it/s, Epoch: 64, Batch: 86,Loss: -2.799,Avg.Loss: -2.523,LR: 1.47E-04]Training epoch 64:  56%|█████▌    | 86/153 [00:01<00:01, 53.94it/s, Epoch: 64, Batch: 87,Loss: -2.568,Avg.Loss: -2.523,LR: 1.47E-04]Training epoch 64:  57%|█████▋    | 87/153 [00:01<00:01, 53.94it/s, Epoch: 64, Batch: 88,Loss: -2.940,Avg.Loss: -2.528,LR: 1.47E-04]Training epoch 64:  58%|█████▊    | 88/153 [00:01<00:01, 53.94it/s, Epoch: 64, Batch: 89,Loss: -2.820,Avg.Loss: -2.531,LR: 1.47E-04]Training epoch 64:  58%|█████▊    | 89/153 [00:01<00:01, 53.94it/s, Epoch: 64, Batch: 90,Loss: -2.486,Avg.Loss: -2.531,LR: 1.46E-04]Training epoch 64:  59%|█████▉    | 90/153 [00:01<00:01, 53.46it/s, Epoch: 64, Batch: 90,Loss: -2.486,Avg.Loss: -2.531,LR: 1.46E-04]Training epoch 64:  59%|█████▉    | 90/153 [00:01<00:01, 53.46it/s, Epoch: 64, Batch: 91,Loss: -2.560,Avg.Loss: -2.531,LR: 1.46E-04]Training epoch 64:  59%|█████▉    | 91/153 [00:01<00:01, 53.46it/s, Epoch: 64, Batch: 92,Loss: -3.325,Avg.Loss: -2.540,LR: 1.46E-04]Training epoch 64:  60%|██████    | 92/153 [00:01<00:01, 53.46it/s, Epoch: 64, Batch: 93,Loss: -2.940,Avg.Loss: -2.544,LR: 1.46E-04]Training epoch 64:  61%|██████    | 93/153 [00:01<00:01, 53.46it/s, Epoch: 64, Batch: 94,Loss: -1.811,Avg.Loss: -2.536,LR: 1.46E-04]Training epoch 64:  61%|██████▏   | 94/153 [00:01<00:01, 53.46it/s, Epoch: 64, Batch: 95,Loss: -2.311,Avg.Loss: -2.534,LR: 1.46E-04]Training epoch 64:  62%|██████▏   | 95/153 [00:01<00:01, 53.46it/s, Epoch: 64, Batch: 96,Loss: -2.750,Avg.Loss: -2.536,LR: 1.46E-04]Training epoch 64:  63%|██████▎   | 96/153 [00:01<00:01, 53.40it/s, Epoch: 64, Batch: 96,Loss: -2.750,Avg.Loss: -2.536,LR: 1.46E-04]Training epoch 64:  63%|██████▎   | 96/153 [00:01<00:01, 53.40it/s, Epoch: 64, Batch: 97,Loss: -2.809,Avg.Loss: -2.539,LR: 1.46E-04]Training epoch 64:  63%|██████▎   | 97/153 [00:01<00:01, 53.40it/s, Epoch: 64, Batch: 98,Loss: -2.260,Avg.Loss: -2.536,LR: 1.46E-04]Training epoch 64:  64%|██████▍   | 98/153 [00:01<00:01, 53.40it/s, Epoch: 64, Batch: 99,Loss: -2.120,Avg.Loss: -2.532,LR: 1.46E-04]Training epoch 64:  65%|██████▍   | 99/153 [00:01<00:01, 53.40it/s, Epoch: 64, Batch: 100,Loss: -2.813,Avg.Loss: -2.535,LR: 1.46E-04]Training epoch 64:  65%|██████▌   | 100/153 [00:01<00:00, 53.40it/s, Epoch: 64, Batch: 101,Loss: -2.815,Avg.Loss: -2.537,LR: 1.46E-04]Training epoch 64:  66%|██████▌   | 101/153 [00:01<00:00, 53.40it/s, Epoch: 64, Batch: 102,Loss: -2.913,Avg.Loss: -2.541,LR: 1.46E-04]Training epoch 64:  67%|██████▋   | 102/153 [00:01<00:00, 53.40it/s, Epoch: 64, Batch: 102,Loss: -2.913,Avg.Loss: -2.541,LR: 1.46E-04]Training epoch 64:  67%|██████▋   | 102/153 [00:01<00:00, 53.40it/s, Epoch: 64, Batch: 103,Loss: -2.758,Avg.Loss: -2.543,LR: 1.46E-04]Training epoch 64:  67%|██████▋   | 103/153 [00:01<00:00, 53.40it/s, Epoch: 64, Batch: 104,Loss: -2.472,Avg.Loss: -2.542,LR: 1.46E-04]Training epoch 64:  68%|██████▊   | 104/153 [00:01<00:00, 53.40it/s, Epoch: 64, Batch: 105,Loss: -3.094,Avg.Loss: -2.548,LR: 1.46E-04]Training epoch 64:  69%|██████▊   | 105/153 [00:01<00:00, 53.40it/s, Epoch: 64, Batch: 106,Loss: -2.231,Avg.Loss: -2.545,LR: 1.46E-04]Training epoch 64:  69%|██████▉   | 106/153 [00:02<00:00, 53.40it/s, Epoch: 64, Batch: 107,Loss: -2.489,Avg.Loss: -2.544,LR: 1.46E-04]Training epoch 64:  70%|██████▉   | 107/153 [00:02<00:00, 53.40it/s, Epoch: 64, Batch: 108,Loss: -2.619,Avg.Loss: -2.545,LR: 1.46E-04]Training epoch 64:  71%|███████   | 108/153 [00:02<00:00, 53.60it/s, Epoch: 64, Batch: 108,Loss: -2.619,Avg.Loss: -2.545,LR: 1.46E-04]Training epoch 64:  71%|███████   | 108/153 [00:02<00:00, 53.60it/s, Epoch: 64, Batch: 109,Loss: -2.722,Avg.Loss: -2.547,LR: 1.46E-04]Training epoch 64:  71%|███████   | 109/153 [00:02<00:00, 53.60it/s, Epoch: 64, Batch: 110,Loss: -1.931,Avg.Loss: -2.541,LR: 1.46E-04]Training epoch 64:  72%|███████▏  | 110/153 [00:02<00:00, 53.60it/s, Epoch: 64, Batch: 111,Loss: -2.326,Avg.Loss: -2.539,LR: 1.46E-04]Training epoch 64:  73%|███████▎  | 111/153 [00:02<00:00, 53.60it/s, Epoch: 64, Batch: 112,Loss: -2.279,Avg.Loss: -2.537,LR: 1.45E-04]Training epoch 64:  73%|███████▎  | 112/153 [00:02<00:00, 53.60it/s, Epoch: 64, Batch: 113,Loss: -2.878,Avg.Loss: -2.540,LR: 1.45E-04]Training epoch 64:  74%|███████▍  | 113/153 [00:02<00:00, 53.60it/s, Epoch: 64, Batch: 114,Loss: -2.110,Avg.Loss: -2.536,LR: 1.45E-04]Training epoch 64:  75%|███████▍  | 114/153 [00:02<00:00, 53.26it/s, Epoch: 64, Batch: 114,Loss: -2.110,Avg.Loss: -2.536,LR: 1.45E-04]Training epoch 64:  75%|███████▍  | 114/153 [00:02<00:00, 53.26it/s, Epoch: 64, Batch: 115,Loss: -2.791,Avg.Loss: -2.538,LR: 1.45E-04]Training epoch 64:  75%|███████▌  | 115/153 [00:02<00:00, 53.26it/s, Epoch: 64, Batch: 116,Loss: -3.072,Avg.Loss: -2.543,LR: 1.45E-04]Training epoch 64:  76%|███████▌  | 116/153 [00:02<00:00, 53.26it/s, Epoch: 64, Batch: 117,Loss: -2.876,Avg.Loss: -2.546,LR: 1.45E-04]Training epoch 64:  76%|███████▋  | 117/153 [00:02<00:00, 53.26it/s, Epoch: 64, Batch: 118,Loss: -2.079,Avg.Loss: -2.542,LR: 1.45E-04]Training epoch 64:  77%|███████▋  | 118/153 [00:02<00:00, 53.26it/s, Epoch: 64, Batch: 119,Loss: -2.753,Avg.Loss: -2.543,LR: 1.45E-04]Training epoch 64:  78%|███████▊  | 119/153 [00:02<00:00, 53.26it/s, Epoch: 64, Batch: 120,Loss: -3.106,Avg.Loss: -2.548,LR: 1.45E-04]Training epoch 64:  78%|███████▊  | 120/153 [00:02<00:00, 53.29it/s, Epoch: 64, Batch: 120,Loss: -3.106,Avg.Loss: -2.548,LR: 1.45E-04]Training epoch 64:  78%|███████▊  | 120/153 [00:02<00:00, 53.29it/s, Epoch: 64, Batch: 121,Loss: -2.038,Avg.Loss: -2.544,LR: 1.45E-04]Training epoch 64:  79%|███████▉  | 121/153 [00:02<00:00, 53.29it/s, Epoch: 64, Batch: 122,Loss: -1.919,Avg.Loss: -2.539,LR: 1.45E-04]Training epoch 64:  80%|███████▉  | 122/153 [00:02<00:00, 53.29it/s, Epoch: 64, Batch: 123,Loss: -2.143,Avg.Loss: -2.536,LR: 1.45E-04]Training epoch 64:  80%|████████  | 123/153 [00:02<00:00, 53.29it/s, Epoch: 64, Batch: 124,Loss: -2.605,Avg.Loss: -2.536,LR: 1.45E-04]Training epoch 64:  81%|████████  | 124/153 [00:02<00:00, 53.29it/s, Epoch: 64, Batch: 125,Loss: -2.797,Avg.Loss: -2.538,LR: 1.45E-04]Training epoch 64:  82%|████████▏ | 125/153 [00:02<00:00, 53.29it/s, Epoch: 64, Batch: 126,Loss: -2.553,Avg.Loss: -2.538,LR: 1.45E-04]Training epoch 64:  82%|████████▏ | 126/153 [00:02<00:00, 53.25it/s, Epoch: 64, Batch: 126,Loss: -2.553,Avg.Loss: -2.538,LR: 1.45E-04]Training epoch 64:  82%|████████▏ | 126/153 [00:02<00:00, 53.25it/s, Epoch: 64, Batch: 127,Loss: -2.920,Avg.Loss: -2.541,LR: 1.45E-04]Training epoch 64:  83%|████████▎ | 127/153 [00:02<00:00, 53.25it/s, Epoch: 64, Batch: 128,Loss: -2.258,Avg.Loss: -2.539,LR: 1.45E-04]Training epoch 64:  84%|████████▎ | 128/153 [00:02<00:00, 53.25it/s, Epoch: 64, Batch: 129,Loss: -2.907,Avg.Loss: -2.542,LR: 1.45E-04]Training epoch 64:  84%|████████▍ | 129/153 [00:02<00:00, 53.25it/s, Epoch: 64, Batch: 130,Loss: -2.143,Avg.Loss: -2.539,LR: 1.45E-04]Training epoch 64:  85%|████████▍ | 130/153 [00:02<00:00, 53.25it/s, Epoch: 64, Batch: 131,Loss: -2.844,Avg.Loss: -2.541,LR: 1.45E-04]Training epoch 64:  86%|████████▌ | 131/153 [00:02<00:00, 53.25it/s, Epoch: 64, Batch: 132,Loss: -2.927,Avg.Loss: -2.544,LR: 1.45E-04]Training epoch 64:  86%|████████▋ | 132/153 [00:02<00:00, 53.39it/s, Epoch: 64, Batch: 132,Loss: -2.927,Avg.Loss: -2.544,LR: 1.45E-04]Training epoch 64:  86%|████████▋ | 132/153 [00:02<00:00, 53.39it/s, Epoch: 64, Batch: 133,Loss: -2.921,Avg.Loss: -2.547,LR: 1.44E-04]Training epoch 64:  87%|████████▋ | 133/153 [00:02<00:00, 53.39it/s, Epoch: 64, Batch: 134,Loss: -2.671,Avg.Loss: -2.548,LR: 1.44E-04]Training epoch 64:  88%|████████▊ | 134/153 [00:02<00:00, 53.39it/s, Epoch: 64, Batch: 135,Loss: -2.282,Avg.Loss: -2.546,LR: 1.44E-04]Training epoch 64:  88%|████████▊ | 135/153 [00:02<00:00, 53.39it/s, Epoch: 64, Batch: 136,Loss: -3.014,Avg.Loss: -2.549,LR: 1.44E-04]Training epoch 64:  89%|████████▉ | 136/153 [00:02<00:00, 53.39it/s, Epoch: 64, Batch: 137,Loss: -2.938,Avg.Loss: -2.552,LR: 1.44E-04]Training epoch 64:  90%|████████▉ | 137/153 [00:02<00:00, 53.39it/s, Epoch: 64, Batch: 138,Loss: -2.278,Avg.Loss: -2.550,LR: 1.44E-04]Training epoch 64:  90%|█████████ | 138/153 [00:02<00:00, 53.36it/s, Epoch: 64, Batch: 138,Loss: -2.278,Avg.Loss: -2.550,LR: 1.44E-04]Training epoch 64:  90%|█████████ | 138/153 [00:02<00:00, 53.36it/s, Epoch: 64, Batch: 139,Loss: -2.366,Avg.Loss: -2.549,LR: 1.44E-04]Training epoch 64:  91%|█████████ | 139/153 [00:02<00:00, 53.36it/s, Epoch: 64, Batch: 140,Loss: -3.069,Avg.Loss: -2.553,LR: 1.44E-04]Training epoch 64:  92%|█████████▏| 140/153 [00:02<00:00, 53.36it/s, Epoch: 64, Batch: 141,Loss: -2.429,Avg.Loss: -2.552,LR: 1.44E-04]Training epoch 64:  92%|█████████▏| 141/153 [00:02<00:00, 53.36it/s, Epoch: 64, Batch: 142,Loss: -2.171,Avg.Loss: -2.549,LR: 1.44E-04]Training epoch 64:  93%|█████████▎| 142/153 [00:02<00:00, 53.36it/s, Epoch: 64, Batch: 143,Loss: -2.145,Avg.Loss: -2.546,LR: 1.44E-04]Training epoch 64:  93%|█████████▎| 143/153 [00:02<00:00, 53.36it/s, Epoch: 64, Batch: 144,Loss: -2.753,Avg.Loss: -2.548,LR: 1.44E-04]Training epoch 64:  94%|█████████▍| 144/153 [00:02<00:00, 53.14it/s, Epoch: 64, Batch: 144,Loss: -2.753,Avg.Loss: -2.548,LR: 1.44E-04]Training epoch 64:  94%|█████████▍| 144/153 [00:02<00:00, 53.14it/s, Epoch: 64, Batch: 145,Loss: -3.040,Avg.Loss: -2.551,LR: 1.44E-04]Training epoch 64:  95%|█████████▍| 145/153 [00:02<00:00, 53.14it/s, Epoch: 64, Batch: 146,Loss: -2.437,Avg.Loss: -2.550,LR: 1.44E-04]Training epoch 64:  95%|█████████▌| 146/153 [00:02<00:00, 53.14it/s, Epoch: 64, Batch: 147,Loss: -2.388,Avg.Loss: -2.549,LR: 1.44E-04]Training epoch 64:  96%|█████████▌| 147/153 [00:02<00:00, 53.14it/s, Epoch: 64, Batch: 148,Loss: -2.888,Avg.Loss: -2.551,LR: 1.44E-04]Training epoch 64:  97%|█████████▋| 148/153 [00:02<00:00, 53.14it/s, Epoch: 64, Batch: 149,Loss: -2.827,Avg.Loss: -2.553,LR: 1.44E-04]Training epoch 64:  97%|█████████▋| 149/153 [00:02<00:00, 53.14it/s, Epoch: 64, Batch: 150,Loss: -1.987,Avg.Loss: -2.549,LR: 1.44E-04]Training epoch 64:  98%|█████████▊| 150/153 [00:02<00:00, 53.16it/s, Epoch: 64, Batch: 150,Loss: -1.987,Avg.Loss: -2.549,LR: 1.44E-04]Training epoch 64:  98%|█████████▊| 150/153 [00:02<00:00, 53.16it/s, Epoch: 64, Batch: 151,Loss: -2.381,Avg.Loss: -2.548,LR: 1.44E-04]Training epoch 64:  99%|█████████▊| 151/153 [00:02<00:00, 53.16it/s, Epoch: 64, Batch: 152,Loss: -3.084,Avg.Loss: -2.552,LR: 1.44E-04]Training epoch 64:  99%|█████████▉| 152/153 [00:02<00:00, 53.16it/s, Epoch: 64, Batch: 153,Loss: -3.303,Avg.Loss: -2.557,LR: 1.44E-04]Training epoch 64: 100%|██████████| 153/153 [00:02<00:00, 53.29it/s, Epoch: 64, Batch: 153,Loss: -3.303,Avg.Loss: -2.557,LR: 1.44E-04]
Training epoch 65:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 65:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 65, Batch: 1,Loss: -2.355,Avg.Loss: -2.355,LR: 1.44E-04]Training epoch 65:   1%|          | 1/153 [00:00<00:06, 23.76it/s, Epoch: 65, Batch: 2,Loss: -3.054,Avg.Loss: -2.705,LR: 1.43E-04]Training epoch 65:   1%|▏         | 2/153 [00:00<00:04, 33.65it/s, Epoch: 65, Batch: 3,Loss: -2.882,Avg.Loss: -2.764,LR: 1.43E-04]Training epoch 65:   2%|▏         | 3/153 [00:00<00:03, 41.06it/s, Epoch: 65, Batch: 4,Loss: -2.044,Avg.Loss: -2.584,LR: 1.43E-04]Training epoch 65:   3%|▎         | 4/153 [00:00<00:03, 44.38it/s, Epoch: 65, Batch: 5,Loss: -2.469,Avg.Loss: -2.561,LR: 1.43E-04]Training epoch 65:   3%|▎         | 5/153 [00:00<00:03, 45.85it/s, Epoch: 65, Batch: 6,Loss: -2.374,Avg.Loss: -2.530,LR: 1.43E-04]Training epoch 65:   4%|▍         | 6/153 [00:00<00:02, 54.92it/s, Epoch: 65, Batch: 6,Loss: -2.374,Avg.Loss: -2.530,LR: 1.43E-04]Training epoch 65:   4%|▍         | 6/153 [00:00<00:02, 54.92it/s, Epoch: 65, Batch: 7,Loss: -2.986,Avg.Loss: -2.595,LR: 1.43E-04]Training epoch 65:   5%|▍         | 7/153 [00:00<00:02, 54.92it/s, Epoch: 65, Batch: 8,Loss: -2.277,Avg.Loss: -2.555,LR: 1.43E-04]Training epoch 65:   5%|▌         | 8/153 [00:00<00:02, 54.92it/s, Epoch: 65, Batch: 9,Loss: -2.705,Avg.Loss: -2.572,LR: 1.43E-04]Training epoch 65:   6%|▌         | 9/153 [00:00<00:02, 54.92it/s, Epoch: 65, Batch: 10,Loss: -2.076,Avg.Loss: -2.522,LR: 1.43E-04]Training epoch 65:   7%|▋         | 10/153 [00:00<00:02, 54.92it/s, Epoch: 65, Batch: 11,Loss: -2.784,Avg.Loss: -2.546,LR: 1.43E-04]Training epoch 65:   7%|▋         | 11/153 [00:00<00:02, 54.92it/s, Epoch: 65, Batch: 12,Loss: -2.689,Avg.Loss: -2.558,LR: 1.43E-04]Training epoch 65:   8%|▊         | 12/153 [00:00<00:02, 53.47it/s, Epoch: 65, Batch: 12,Loss: -2.689,Avg.Loss: -2.558,LR: 1.43E-04]Training epoch 65:   8%|▊         | 12/153 [00:00<00:02, 53.47it/s, Epoch: 65, Batch: 13,Loss: -2.485,Avg.Loss: -2.552,LR: 1.43E-04]Training epoch 65:   8%|▊         | 13/153 [00:00<00:02, 53.47it/s, Epoch: 65, Batch: 14,Loss: -2.336,Avg.Loss: -2.537,LR: 1.43E-04]Training epoch 65:   9%|▉         | 14/153 [00:00<00:02, 53.47it/s, Epoch: 65, Batch: 15,Loss: -3.027,Avg.Loss: -2.570,LR: 1.43E-04]Training epoch 65:  10%|▉         | 15/153 [00:00<00:02, 53.47it/s, Epoch: 65, Batch: 16,Loss: -2.927,Avg.Loss: -2.592,LR: 1.43E-04]Training epoch 65:  10%|█         | 16/153 [00:00<00:02, 53.47it/s, Epoch: 65, Batch: 17,Loss: -2.122,Avg.Loss: -2.564,LR: 1.43E-04]Training epoch 65:  11%|█         | 17/153 [00:00<00:02, 53.47it/s, Epoch: 65, Batch: 18,Loss: -2.462,Avg.Loss: -2.559,LR: 1.43E-04]Training epoch 65:  12%|█▏        | 18/153 [00:00<00:02, 53.30it/s, Epoch: 65, Batch: 18,Loss: -2.462,Avg.Loss: -2.559,LR: 1.43E-04]Training epoch 65:  12%|█▏        | 18/153 [00:00<00:02, 53.30it/s, Epoch: 65, Batch: 19,Loss: -2.817,Avg.Loss: -2.572,LR: 1.43E-04]Training epoch 65:  12%|█▏        | 19/153 [00:00<00:02, 53.30it/s, Epoch: 65, Batch: 20,Loss: -2.972,Avg.Loss: -2.592,LR: 1.43E-04]Training epoch 65:  13%|█▎        | 20/153 [00:00<00:02, 53.30it/s, Epoch: 65, Batch: 21,Loss: -2.529,Avg.Loss: -2.589,LR: 1.43E-04]Training epoch 65:  14%|█▎        | 21/153 [00:00<00:02, 53.30it/s, Epoch: 65, Batch: 22,Loss: -2.855,Avg.Loss: -2.601,LR: 1.43E-04]Training epoch 65:  14%|█▍        | 22/153 [00:00<00:02, 53.30it/s, Epoch: 65, Batch: 23,Loss: -3.088,Avg.Loss: -2.622,LR: 1.42E-04]Training epoch 65:  15%|█▌        | 23/153 [00:00<00:02, 53.30it/s, Epoch: 65, Batch: 24,Loss: -2.654,Avg.Loss: -2.624,LR: 1.42E-04]Training epoch 65:  16%|█▌        | 24/153 [00:00<00:02, 50.38it/s, Epoch: 65, Batch: 24,Loss: -2.654,Avg.Loss: -2.624,LR: 1.42E-04]Training epoch 65:  16%|█▌        | 24/153 [00:00<00:02, 50.38it/s, Epoch: 65, Batch: 25,Loss: -2.458,Avg.Loss: -2.617,LR: 1.42E-04]Training epoch 65:  16%|█▋        | 25/153 [00:00<00:02, 50.38it/s, Epoch: 65, Batch: 26,Loss: -2.964,Avg.Loss: -2.630,LR: 1.42E-04]Training epoch 65:  17%|█▋        | 26/153 [00:00<00:02, 50.38it/s, Epoch: 65, Batch: 27,Loss: -2.692,Avg.Loss: -2.633,LR: 1.42E-04]Training epoch 65:  18%|█▊        | 27/153 [00:00<00:02, 50.38it/s, Epoch: 65, Batch: 28,Loss: -2.931,Avg.Loss: -2.643,LR: 1.42E-04]Training epoch 65:  18%|█▊        | 28/153 [00:00<00:02, 50.38it/s, Epoch: 65, Batch: 29,Loss: -2.891,Avg.Loss: -2.652,LR: 1.42E-04]Training epoch 65:  19%|█▉        | 29/153 [00:00<00:02, 50.38it/s, Epoch: 65, Batch: 30,Loss: -2.173,Avg.Loss: -2.636,LR: 1.42E-04]Training epoch 65:  20%|█▉        | 30/153 [00:00<00:02, 51.63it/s, Epoch: 65, Batch: 30,Loss: -2.173,Avg.Loss: -2.636,LR: 1.42E-04]Training epoch 65:  20%|█▉        | 30/153 [00:00<00:02, 51.63it/s, Epoch: 65, Batch: 31,Loss: -2.821,Avg.Loss: -2.642,LR: 1.42E-04]Training epoch 65:  20%|██        | 31/153 [00:00<00:02, 51.63it/s, Epoch: 65, Batch: 32,Loss: -2.866,Avg.Loss: -2.649,LR: 1.42E-04]Training epoch 65:  21%|██        | 32/153 [00:00<00:02, 51.63it/s, Epoch: 65, Batch: 33,Loss: -2.739,Avg.Loss: -2.652,LR: 1.42E-04]Training epoch 65:  22%|██▏       | 33/153 [00:00<00:02, 51.63it/s, Epoch: 65, Batch: 34,Loss: -2.680,Avg.Loss: -2.652,LR: 1.42E-04]Training epoch 65:  22%|██▏       | 34/153 [00:00<00:02, 51.63it/s, Epoch: 65, Batch: 35,Loss: -2.811,Avg.Loss: -2.657,LR: 1.42E-04]Training epoch 65:  23%|██▎       | 35/153 [00:00<00:02, 51.63it/s, Epoch: 65, Batch: 36,Loss: -2.279,Avg.Loss: -2.647,LR: 1.42E-04]Training epoch 65:  24%|██▎       | 36/153 [00:00<00:02, 52.13it/s, Epoch: 65, Batch: 36,Loss: -2.279,Avg.Loss: -2.647,LR: 1.42E-04]Training epoch 65:  24%|██▎       | 36/153 [00:00<00:02, 52.13it/s, Epoch: 65, Batch: 37,Loss: -2.676,Avg.Loss: -2.647,LR: 1.42E-04]Training epoch 65:  24%|██▍       | 37/153 [00:00<00:02, 52.13it/s, Epoch: 65, Batch: 38,Loss: -2.499,Avg.Loss: -2.643,LR: 1.42E-04]Training epoch 65:  25%|██▍       | 38/153 [00:00<00:02, 52.13it/s, Epoch: 65, Batch: 39,Loss: -2.898,Avg.Loss: -2.650,LR: 1.42E-04]Training epoch 65:  25%|██▌       | 39/153 [00:00<00:02, 52.13it/s, Epoch: 65, Batch: 40,Loss: -2.246,Avg.Loss: -2.640,LR: 1.42E-04]Training epoch 65:  26%|██▌       | 40/153 [00:00<00:02, 52.13it/s, Epoch: 65, Batch: 41,Loss: -1.954,Avg.Loss: -2.623,LR: 1.42E-04]Training epoch 65:  27%|██▋       | 41/153 [00:00<00:02, 52.13it/s, Epoch: 65, Batch: 42,Loss: -2.400,Avg.Loss: -2.618,LR: 1.42E-04]Training epoch 65:  27%|██▋       | 42/153 [00:00<00:02, 52.37it/s, Epoch: 65, Batch: 42,Loss: -2.400,Avg.Loss: -2.618,LR: 1.42E-04]Training epoch 65:  27%|██▋       | 42/153 [00:00<00:02, 52.37it/s, Epoch: 65, Batch: 43,Loss: -2.666,Avg.Loss: -2.619,LR: 1.42E-04]Training epoch 65:  28%|██▊       | 43/153 [00:00<00:02, 52.37it/s, Epoch: 65, Batch: 44,Loss: -2.649,Avg.Loss: -2.620,LR: 1.42E-04]Training epoch 65:  29%|██▉       | 44/153 [00:00<00:02, 52.37it/s, Epoch: 65, Batch: 45,Loss: -2.641,Avg.Loss: -2.620,LR: 1.41E-04]Training epoch 65:  29%|██▉       | 45/153 [00:00<00:02, 52.37it/s, Epoch: 65, Batch: 46,Loss: -3.165,Avg.Loss: -2.632,LR: 1.41E-04]Training epoch 65:  30%|███       | 46/153 [00:00<00:02, 52.37it/s, Epoch: 65, Batch: 47,Loss: -2.757,Avg.Loss: -2.635,LR: 1.41E-04]Training epoch 65:  31%|███       | 47/153 [00:00<00:02, 52.37it/s, Epoch: 65, Batch: 48,Loss: -2.033,Avg.Loss: -2.622,LR: 1.41E-04]Training epoch 65:  31%|███▏      | 48/153 [00:00<00:01, 52.75it/s, Epoch: 65, Batch: 48,Loss: -2.033,Avg.Loss: -2.622,LR: 1.41E-04]Training epoch 65:  31%|███▏      | 48/153 [00:00<00:01, 52.75it/s, Epoch: 65, Batch: 49,Loss: -2.436,Avg.Loss: -2.618,LR: 1.41E-04]Training epoch 65:  32%|███▏      | 49/153 [00:00<00:01, 52.75it/s, Epoch: 65, Batch: 50,Loss: -2.581,Avg.Loss: -2.618,LR: 1.41E-04]Training epoch 65:  33%|███▎      | 50/153 [00:00<00:01, 52.75it/s, Epoch: 65, Batch: 51,Loss: -2.836,Avg.Loss: -2.622,LR: 1.41E-04]Training epoch 65:  33%|███▎      | 51/153 [00:00<00:01, 52.75it/s, Epoch: 65, Batch: 52,Loss: -2.161,Avg.Loss: -2.613,LR: 1.41E-04]Training epoch 65:  34%|███▍      | 52/153 [00:01<00:01, 52.75it/s, Epoch: 65, Batch: 53,Loss: -2.526,Avg.Loss: -2.611,LR: 1.41E-04]Training epoch 65:  35%|███▍      | 53/153 [00:01<00:01, 52.75it/s, Epoch: 65, Batch: 54,Loss: -3.182,Avg.Loss: -2.622,LR: 1.41E-04]Training epoch 65:  35%|███▌      | 54/153 [00:01<00:01, 52.74it/s, Epoch: 65, Batch: 54,Loss: -3.182,Avg.Loss: -2.622,LR: 1.41E-04]Training epoch 65:  35%|███▌      | 54/153 [00:01<00:01, 52.74it/s, Epoch: 65, Batch: 55,Loss: -2.772,Avg.Loss: -2.625,LR: 1.41E-04]Training epoch 65:  36%|███▌      | 55/153 [00:01<00:01, 52.74it/s, Epoch: 65, Batch: 56,Loss: -2.236,Avg.Loss: -2.618,LR: 1.41E-04]Training epoch 65:  37%|███▋      | 56/153 [00:01<00:01, 52.74it/s, Epoch: 65, Batch: 57,Loss: -2.467,Avg.Loss: -2.615,LR: 1.41E-04]Training epoch 65:  37%|███▋      | 57/153 [00:01<00:01, 52.74it/s, Epoch: 65, Batch: 58,Loss: -2.420,Avg.Loss: -2.612,LR: 1.41E-04]Training epoch 65:  38%|███▊      | 58/153 [00:01<00:01, 52.74it/s, Epoch: 65, Batch: 59,Loss: -2.955,Avg.Loss: -2.617,LR: 1.41E-04]Training epoch 65:  39%|███▊      | 59/153 [00:01<00:01, 52.74it/s, Epoch: 65, Batch: 60,Loss: -2.076,Avg.Loss: -2.608,LR: 1.41E-04]Training epoch 65:  39%|███▉      | 60/153 [00:01<00:01, 52.68it/s, Epoch: 65, Batch: 60,Loss: -2.076,Avg.Loss: -2.608,LR: 1.41E-04]Training epoch 65:  39%|███▉      | 60/153 [00:01<00:01, 52.68it/s, Epoch: 65, Batch: 61,Loss: -2.537,Avg.Loss: -2.607,LR: 1.41E-04]Training epoch 65:  40%|███▉      | 61/153 [00:01<00:01, 52.68it/s, Epoch: 65, Batch: 62,Loss: -2.681,Avg.Loss: -2.608,LR: 1.41E-04]Training epoch 65:  41%|████      | 62/153 [00:01<00:01, 52.68it/s, Epoch: 65, Batch: 63,Loss: -2.533,Avg.Loss: -2.607,LR: 1.41E-04]Training epoch 65:  41%|████      | 63/153 [00:01<00:01, 52.68it/s, Epoch: 65, Batch: 64,Loss: -2.273,Avg.Loss: -2.602,LR: 1.41E-04]Training epoch 65:  42%|████▏     | 64/153 [00:01<00:01, 52.68it/s, Epoch: 65, Batch: 65,Loss: -2.321,Avg.Loss: -2.598,LR: 1.41E-04]Training epoch 65:  42%|████▏     | 65/153 [00:01<00:01, 52.68it/s, Epoch: 65, Batch: 66,Loss: -2.629,Avg.Loss: -2.598,LR: 1.40E-04]Training epoch 65:  43%|████▎     | 66/153 [00:01<00:01, 52.41it/s, Epoch: 65, Batch: 66,Loss: -2.629,Avg.Loss: -2.598,LR: 1.40E-04]Training epoch 65:  43%|████▎     | 66/153 [00:01<00:01, 52.41it/s, Epoch: 65, Batch: 67,Loss: -2.498,Avg.Loss: -2.597,LR: 1.40E-04]Training epoch 65:  44%|████▍     | 67/153 [00:01<00:01, 52.41it/s, Epoch: 65, Batch: 68,Loss: -2.492,Avg.Loss: -2.595,LR: 1.40E-04]Training epoch 65:  44%|████▍     | 68/153 [00:01<00:01, 52.41it/s, Epoch: 65, Batch: 69,Loss: -2.679,Avg.Loss: -2.596,LR: 1.40E-04]Training epoch 65:  45%|████▌     | 69/153 [00:01<00:01, 52.41it/s, Epoch: 65, Batch: 70,Loss: -2.972,Avg.Loss: -2.602,LR: 1.40E-04]Training epoch 65:  46%|████▌     | 70/153 [00:01<00:01, 52.41it/s, Epoch: 65, Batch: 71,Loss: -2.714,Avg.Loss: -2.603,LR: 1.40E-04]Training epoch 65:  46%|████▋     | 71/153 [00:01<00:01, 52.41it/s, Epoch: 65, Batch: 72,Loss: -2.526,Avg.Loss: -2.602,LR: 1.40E-04]Training epoch 65:  47%|████▋     | 72/153 [00:01<00:01, 52.43it/s, Epoch: 65, Batch: 72,Loss: -2.526,Avg.Loss: -2.602,LR: 1.40E-04]Training epoch 65:  47%|████▋     | 72/153 [00:01<00:01, 52.43it/s, Epoch: 65, Batch: 73,Loss: -2.814,Avg.Loss: -2.605,LR: 1.40E-04]Training epoch 65:  48%|████▊     | 73/153 [00:01<00:01, 52.43it/s, Epoch: 65, Batch: 74,Loss: -2.680,Avg.Loss: -2.606,LR: 1.40E-04]Training epoch 65:  48%|████▊     | 74/153 [00:01<00:01, 52.43it/s, Epoch: 65, Batch: 75,Loss: -2.173,Avg.Loss: -2.600,LR: 1.40E-04]Training epoch 65:  49%|████▉     | 75/153 [00:01<00:01, 52.43it/s, Epoch: 65, Batch: 76,Loss: -2.473,Avg.Loss: -2.599,LR: 1.40E-04]Training epoch 65:  50%|████▉     | 76/153 [00:01<00:01, 52.43it/s, Epoch: 65, Batch: 77,Loss: -2.897,Avg.Loss: -2.603,LR: 1.40E-04]Training epoch 65:  50%|█████     | 77/153 [00:01<00:01, 52.43it/s, Epoch: 65, Batch: 78,Loss: -2.428,Avg.Loss: -2.600,LR: 1.40E-04]Training epoch 65:  51%|█████     | 78/153 [00:01<00:01, 52.57it/s, Epoch: 65, Batch: 78,Loss: -2.428,Avg.Loss: -2.600,LR: 1.40E-04]Training epoch 65:  51%|█████     | 78/153 [00:01<00:01, 52.57it/s, Epoch: 65, Batch: 79,Loss: -2.643,Avg.Loss: -2.601,LR: 1.40E-04]Training epoch 65:  52%|█████▏    | 79/153 [00:01<00:01, 52.57it/s, Epoch: 65, Batch: 80,Loss: -1.863,Avg.Loss: -2.592,LR: 1.40E-04]Training epoch 65:  52%|█████▏    | 80/153 [00:01<00:01, 52.57it/s, Epoch: 65, Batch: 81,Loss: -2.766,Avg.Loss: -2.594,LR: 1.40E-04]Training epoch 65:  53%|█████▎    | 81/153 [00:01<00:01, 52.57it/s, Epoch: 65, Batch: 82,Loss: -2.489,Avg.Loss: -2.593,LR: 1.40E-04]Training epoch 65:  54%|█████▎    | 82/153 [00:01<00:01, 52.57it/s, Epoch: 65, Batch: 83,Loss: -2.716,Avg.Loss: -2.594,LR: 1.40E-04]Training epoch 65:  54%|█████▍    | 83/153 [00:01<00:01, 52.57it/s, Epoch: 65, Batch: 84,Loss: -3.107,Avg.Loss: -2.600,LR: 1.40E-04]Training epoch 65:  55%|█████▍    | 84/153 [00:01<00:01, 52.59it/s, Epoch: 65, Batch: 84,Loss: -3.107,Avg.Loss: -2.600,LR: 1.40E-04]Training epoch 65:  55%|█████▍    | 84/153 [00:01<00:01, 52.59it/s, Epoch: 65, Batch: 85,Loss: -2.297,Avg.Loss: -2.597,LR: 1.40E-04]Training epoch 65:  56%|█████▌    | 85/153 [00:01<00:01, 52.59it/s, Epoch: 65, Batch: 86,Loss: -2.581,Avg.Loss: -2.596,LR: 1.40E-04]Training epoch 65:  56%|█████▌    | 86/153 [00:01<00:01, 52.59it/s, Epoch: 65, Batch: 87,Loss: -2.507,Avg.Loss: -2.595,LR: 1.40E-04]Training epoch 65:  57%|█████▋    | 87/153 [00:01<00:01, 52.59it/s, Epoch: 65, Batch: 88,Loss: -2.914,Avg.Loss: -2.599,LR: 1.39E-04]Training epoch 65:  58%|█████▊    | 88/153 [00:01<00:01, 52.59it/s, Epoch: 65, Batch: 89,Loss: -2.648,Avg.Loss: -2.600,LR: 1.39E-04]Training epoch 65:  58%|█████▊    | 89/153 [00:01<00:01, 52.59it/s, Epoch: 65, Batch: 90,Loss: -2.359,Avg.Loss: -2.597,LR: 1.39E-04]Training epoch 65:  59%|█████▉    | 90/153 [00:01<00:01, 52.60it/s, Epoch: 65, Batch: 90,Loss: -2.359,Avg.Loss: -2.597,LR: 1.39E-04]Training epoch 65:  59%|█████▉    | 90/153 [00:01<00:01, 52.60it/s, Epoch: 65, Batch: 91,Loss: -2.584,Avg.Loss: -2.597,LR: 1.39E-04]Training epoch 65:  59%|█████▉    | 91/153 [00:01<00:01, 52.60it/s, Epoch: 65, Batch: 92,Loss: -3.044,Avg.Loss: -2.602,LR: 1.39E-04]Training epoch 65:  60%|██████    | 92/153 [00:01<00:01, 52.60it/s, Epoch: 65, Batch: 93,Loss: -2.631,Avg.Loss: -2.602,LR: 1.39E-04]Training epoch 65:  61%|██████    | 93/153 [00:01<00:01, 52.60it/s, Epoch: 65, Batch: 94,Loss: -1.896,Avg.Loss: -2.594,LR: 1.39E-04]Training epoch 65:  61%|██████▏   | 94/153 [00:01<00:01, 52.60it/s, Epoch: 65, Batch: 95,Loss: -2.690,Avg.Loss: -2.595,LR: 1.39E-04]Training epoch 65:  62%|██████▏   | 95/153 [00:01<00:01, 52.60it/s, Epoch: 65, Batch: 96,Loss: -1.968,Avg.Loss: -2.589,LR: 1.39E-04]Training epoch 65:  63%|██████▎   | 96/153 [00:01<00:01, 52.76it/s, Epoch: 65, Batch: 96,Loss: -1.968,Avg.Loss: -2.589,LR: 1.39E-04]Training epoch 65:  63%|██████▎   | 96/153 [00:01<00:01, 52.76it/s, Epoch: 65, Batch: 97,Loss: -2.372,Avg.Loss: -2.587,LR: 1.39E-04]Training epoch 65:  63%|██████▎   | 97/153 [00:01<00:01, 52.76it/s, Epoch: 65, Batch: 98,Loss: -2.395,Avg.Loss: -2.585,LR: 1.39E-04]Training epoch 65:  64%|██████▍   | 98/153 [00:01<00:01, 52.76it/s, Epoch: 65, Batch: 99,Loss: -2.896,Avg.Loss: -2.588,LR: 1.39E-04]Training epoch 65:  65%|██████▍   | 99/153 [00:01<00:01, 52.76it/s, Epoch: 65, Batch: 100,Loss: -2.327,Avg.Loss: -2.585,LR: 1.39E-04]Training epoch 65:  65%|██████▌   | 100/153 [00:01<00:01, 52.76it/s, Epoch: 65, Batch: 101,Loss: -2.213,Avg.Loss: -2.582,LR: 1.39E-04]Training epoch 65:  66%|██████▌   | 101/153 [00:01<00:00, 52.76it/s, Epoch: 65, Batch: 102,Loss: -2.771,Avg.Loss: -2.583,LR: 1.39E-04]Training epoch 65:  67%|██████▋   | 102/153 [00:01<00:00, 52.93it/s, Epoch: 65, Batch: 102,Loss: -2.771,Avg.Loss: -2.583,LR: 1.39E-04]Training epoch 65:  67%|██████▋   | 102/153 [00:01<00:00, 52.93it/s, Epoch: 65, Batch: 103,Loss: -2.469,Avg.Loss: -2.582,LR: 1.39E-04]Training epoch 65:  67%|██████▋   | 103/153 [00:01<00:00, 52.93it/s, Epoch: 65, Batch: 104,Loss: -2.592,Avg.Loss: -2.582,LR: 1.39E-04]Training epoch 65:  68%|██████▊   | 104/153 [00:01<00:00, 52.93it/s, Epoch: 65, Batch: 105,Loss: -3.152,Avg.Loss: -2.588,LR: 1.39E-04]Training epoch 65:  69%|██████▊   | 105/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 106,Loss: -3.083,Avg.Loss: -2.592,LR: 1.39E-04]Training epoch 65:  69%|██████▉   | 106/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 107,Loss: -2.904,Avg.Loss: -2.595,LR: 1.39E-04]Training epoch 65:  70%|██████▉   | 107/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 108,Loss: -2.816,Avg.Loss: -2.597,LR: 1.39E-04]Training epoch 65:  71%|███████   | 108/153 [00:02<00:00, 52.76it/s, Epoch: 65, Batch: 108,Loss: -2.816,Avg.Loss: -2.597,LR: 1.39E-04]Training epoch 65:  71%|███████   | 108/153 [00:02<00:00, 52.76it/s, Epoch: 65, Batch: 109,Loss: -2.347,Avg.Loss: -2.595,LR: 1.39E-04]Training epoch 65:  71%|███████   | 109/153 [00:02<00:00, 52.76it/s, Epoch: 65, Batch: 110,Loss: -1.985,Avg.Loss: -2.590,LR: 1.38E-04]Training epoch 65:  72%|███████▏  | 110/153 [00:02<00:00, 52.76it/s, Epoch: 65, Batch: 111,Loss: -3.025,Avg.Loss: -2.593,LR: 1.38E-04]Training epoch 65:  73%|███████▎  | 111/153 [00:02<00:00, 52.76it/s, Epoch: 65, Batch: 112,Loss: -2.789,Avg.Loss: -2.595,LR: 1.38E-04]Training epoch 65:  73%|███████▎  | 112/153 [00:02<00:00, 52.76it/s, Epoch: 65, Batch: 113,Loss: -1.949,Avg.Loss: -2.589,LR: 1.38E-04]Training epoch 65:  74%|███████▍  | 113/153 [00:02<00:00, 52.76it/s, Epoch: 65, Batch: 114,Loss: -1.779,Avg.Loss: -2.582,LR: 1.38E-04]Training epoch 65:  75%|███████▍  | 114/153 [00:02<00:00, 52.89it/s, Epoch: 65, Batch: 114,Loss: -1.779,Avg.Loss: -2.582,LR: 1.38E-04]Training epoch 65:  75%|███████▍  | 114/153 [00:02<00:00, 52.89it/s, Epoch: 65, Batch: 115,Loss: -2.520,Avg.Loss: -2.582,LR: 1.38E-04]Training epoch 65:  75%|███████▌  | 115/153 [00:02<00:00, 52.89it/s, Epoch: 65, Batch: 116,Loss: -2.860,Avg.Loss: -2.584,LR: 1.38E-04]Training epoch 65:  76%|███████▌  | 116/153 [00:02<00:00, 52.89it/s, Epoch: 65, Batch: 117,Loss: -2.666,Avg.Loss: -2.585,LR: 1.38E-04]Training epoch 65:  76%|███████▋  | 117/153 [00:02<00:00, 52.89it/s, Epoch: 65, Batch: 118,Loss: -2.357,Avg.Loss: -2.583,LR: 1.38E-04]Training epoch 65:  77%|███████▋  | 118/153 [00:02<00:00, 52.89it/s, Epoch: 65, Batch: 119,Loss: -3.009,Avg.Loss: -2.587,LR: 1.38E-04]Training epoch 65:  78%|███████▊  | 119/153 [00:02<00:00, 52.89it/s, Epoch: 65, Batch: 120,Loss: -2.903,Avg.Loss: -2.589,LR: 1.38E-04]Training epoch 65:  78%|███████▊  | 120/153 [00:02<00:00, 52.85it/s, Epoch: 65, Batch: 120,Loss: -2.903,Avg.Loss: -2.589,LR: 1.38E-04]Training epoch 65:  78%|███████▊  | 120/153 [00:02<00:00, 52.85it/s, Epoch: 65, Batch: 121,Loss: -2.695,Avg.Loss: -2.590,LR: 1.38E-04]Training epoch 65:  79%|███████▉  | 121/153 [00:02<00:00, 52.85it/s, Epoch: 65, Batch: 122,Loss: -2.926,Avg.Loss: -2.593,LR: 1.38E-04]Training epoch 65:  80%|███████▉  | 122/153 [00:02<00:00, 52.85it/s, Epoch: 65, Batch: 123,Loss: -2.736,Avg.Loss: -2.594,LR: 1.38E-04]Training epoch 65:  80%|████████  | 123/153 [00:02<00:00, 52.85it/s, Epoch: 65, Batch: 124,Loss: -2.583,Avg.Loss: -2.594,LR: 1.38E-04]Training epoch 65:  81%|████████  | 124/153 [00:02<00:00, 52.85it/s, Epoch: 65, Batch: 125,Loss: -3.333,Avg.Loss: -2.600,LR: 1.38E-04]Training epoch 65:  82%|████████▏ | 125/153 [00:02<00:00, 52.85it/s, Epoch: 65, Batch: 126,Loss: -2.929,Avg.Loss: -2.602,LR: 1.38E-04]Training epoch 65:  82%|████████▏ | 126/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 126,Loss: -2.929,Avg.Loss: -2.602,LR: 1.38E-04]Training epoch 65:  82%|████████▏ | 126/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 127,Loss: -2.925,Avg.Loss: -2.605,LR: 1.38E-04]Training epoch 65:  83%|████████▎ | 127/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 128,Loss: -3.036,Avg.Loss: -2.608,LR: 1.38E-04]Training epoch 65:  84%|████████▎ | 128/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 129,Loss: -2.977,Avg.Loss: -2.611,LR: 1.38E-04]Training epoch 65:  84%|████████▍ | 129/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 130,Loss: -2.623,Avg.Loss: -2.611,LR: 1.38E-04]Training epoch 65:  85%|████████▍ | 130/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 131,Loss: -2.421,Avg.Loss: -2.610,LR: 1.38E-04]Training epoch 65:  86%|████████▌ | 131/153 [00:02<00:00, 52.93it/s, Epoch: 65, Batch: 132,Loss: -2.416,Avg.Loss: -2.608,LR: 1.37E-04]Training epoch 65:  86%|████████▋ | 132/153 [00:02<00:00, 52.94it/s, Epoch: 65, Batch: 132,Loss: -2.416,Avg.Loss: -2.608,LR: 1.37E-04]Training epoch 65:  86%|████████▋ | 132/153 [00:02<00:00, 52.94it/s, Epoch: 65, Batch: 133,Loss: -2.923,Avg.Loss: -2.611,LR: 1.37E-04]Training epoch 65:  87%|████████▋ | 133/153 [00:02<00:00, 52.94it/s, Epoch: 65, Batch: 134,Loss: -3.146,Avg.Loss: -2.615,LR: 1.37E-04]Training epoch 65:  88%|████████▊ | 134/153 [00:02<00:00, 52.94it/s, Epoch: 65, Batch: 135,Loss: -2.937,Avg.Loss: -2.617,LR: 1.37E-04]Training epoch 65:  88%|████████▊ | 135/153 [00:02<00:00, 52.94it/s, Epoch: 65, Batch: 136,Loss: -3.034,Avg.Loss: -2.620,LR: 1.37E-04]Training epoch 65:  89%|████████▉ | 136/153 [00:02<00:00, 52.94it/s, Epoch: 65, Batch: 137,Loss: -2.878,Avg.Loss: -2.622,LR: 1.37E-04]Training epoch 65:  90%|████████▉ | 137/153 [00:02<00:00, 52.94it/s, Epoch: 65, Batch: 138,Loss: -2.914,Avg.Loss: -2.624,LR: 1.37E-04]Training epoch 65:  90%|█████████ | 138/153 [00:02<00:00, 52.86it/s, Epoch: 65, Batch: 138,Loss: -2.914,Avg.Loss: -2.624,LR: 1.37E-04]Training epoch 65:  90%|█████████ | 138/153 [00:02<00:00, 52.86it/s, Epoch: 65, Batch: 139,Loss: -2.789,Avg.Loss: -2.625,LR: 1.37E-04]Training epoch 65:  91%|█████████ | 139/153 [00:02<00:00, 52.86it/s, Epoch: 65, Batch: 140,Loss: -2.363,Avg.Loss: -2.624,LR: 1.37E-04]Training epoch 65:  92%|█████████▏| 140/153 [00:02<00:00, 52.86it/s, Epoch: 65, Batch: 141,Loss: -3.021,Avg.Loss: -2.626,LR: 1.37E-04]Training epoch 65:  92%|█████████▏| 141/153 [00:02<00:00, 52.86it/s, Epoch: 65, Batch: 142,Loss: -2.807,Avg.Loss: -2.628,LR: 1.37E-04]Training epoch 65:  93%|█████████▎| 142/153 [00:02<00:00, 52.86it/s, Epoch: 65, Batch: 143,Loss: -3.265,Avg.Loss: -2.632,LR: 1.37E-04]Training epoch 65:  93%|█████████▎| 143/153 [00:02<00:00, 52.86it/s, Epoch: 65, Batch: 144,Loss: -2.852,Avg.Loss: -2.634,LR: 1.37E-04]Training epoch 65:  94%|█████████▍| 144/153 [00:02<00:00, 52.84it/s, Epoch: 65, Batch: 144,Loss: -2.852,Avg.Loss: -2.634,LR: 1.37E-04]Training epoch 65:  94%|█████████▍| 144/153 [00:02<00:00, 52.84it/s, Epoch: 65, Batch: 145,Loss: -2.608,Avg.Loss: -2.633,LR: 1.37E-04]Training epoch 65:  95%|█████████▍| 145/153 [00:02<00:00, 52.84it/s, Epoch: 65, Batch: 146,Loss: -2.561,Avg.Loss: -2.633,LR: 1.37E-04]Training epoch 65:  95%|█████████▌| 146/153 [00:02<00:00, 52.84it/s, Epoch: 65, Batch: 147,Loss: -2.500,Avg.Loss: -2.632,LR: 1.37E-04]Training epoch 65:  96%|█████████▌| 147/153 [00:02<00:00, 52.84it/s, Epoch: 65, Batch: 148,Loss: -2.824,Avg.Loss: -2.633,LR: 1.37E-04]Training epoch 65:  97%|█████████▋| 148/153 [00:02<00:00, 52.84it/s, Epoch: 65, Batch: 149,Loss: -2.078,Avg.Loss: -2.630,LR: 1.37E-04]Training epoch 65:  97%|█████████▋| 149/153 [00:02<00:00, 52.84it/s, Epoch: 65, Batch: 150,Loss: -2.647,Avg.Loss: -2.630,LR: 1.37E-04]Training epoch 65:  98%|█████████▊| 150/153 [00:02<00:00, 53.00it/s, Epoch: 65, Batch: 150,Loss: -2.647,Avg.Loss: -2.630,LR: 1.37E-04]Training epoch 65:  98%|█████████▊| 150/153 [00:02<00:00, 53.00it/s, Epoch: 65, Batch: 151,Loss: -2.285,Avg.Loss: -2.627,LR: 1.37E-04]Training epoch 65:  99%|█████████▊| 151/153 [00:02<00:00, 53.00it/s, Epoch: 65, Batch: 152,Loss: -2.533,Avg.Loss: -2.627,LR: 1.37E-04]Training epoch 65:  99%|█████████▉| 152/153 [00:02<00:00, 53.00it/s, Epoch: 65, Batch: 153,Loss: -2.526,Avg.Loss: -2.626,LR: 1.37E-04]Training epoch 65: 100%|██████████| 153/153 [00:02<00:00, 52.62it/s, Epoch: 65, Batch: 153,Loss: -2.526,Avg.Loss: -2.626,LR: 1.37E-04]
Training epoch 66:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 66:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 66, Batch: 1,Loss: -2.477,Avg.Loss: -2.477,LR: 1.36E-04]Training epoch 66:   1%|          | 1/153 [00:00<00:06, 23.71it/s, Epoch: 66, Batch: 2,Loss: -2.404,Avg.Loss: -2.441,LR: 1.36E-04]Training epoch 66:   1%|▏         | 2/153 [00:00<00:04, 35.35it/s, Epoch: 66, Batch: 3,Loss: -2.703,Avg.Loss: -2.528,LR: 1.36E-04]Training epoch 66:   2%|▏         | 3/153 [00:00<00:03, 42.99it/s, Epoch: 66, Batch: 4,Loss: -2.229,Avg.Loss: -2.453,LR: 1.36E-04]Training epoch 66:   3%|▎         | 4/153 [00:00<00:03, 45.65it/s, Epoch: 66, Batch: 5,Loss: -2.485,Avg.Loss: -2.460,LR: 1.36E-04]Training epoch 66:   3%|▎         | 5/153 [00:00<00:03, 46.78it/s, Epoch: 66, Batch: 6,Loss: -2.302,Avg.Loss: -2.433,LR: 1.36E-04]Training epoch 66:   4%|▍         | 6/153 [00:00<00:02, 56.04it/s, Epoch: 66, Batch: 6,Loss: -2.302,Avg.Loss: -2.433,LR: 1.36E-04]Training epoch 66:   4%|▍         | 6/153 [00:00<00:02, 56.04it/s, Epoch: 66, Batch: 7,Loss: -1.873,Avg.Loss: -2.353,LR: 1.36E-04]Training epoch 66:   5%|▍         | 7/153 [00:00<00:02, 56.04it/s, Epoch: 66, Batch: 8,Loss: -2.462,Avg.Loss: -2.367,LR: 1.36E-04]Training epoch 66:   5%|▌         | 8/153 [00:00<00:02, 56.04it/s, Epoch: 66, Batch: 9,Loss: -2.104,Avg.Loss: -2.338,LR: 1.36E-04]Training epoch 66:   6%|▌         | 9/153 [00:00<00:02, 56.04it/s, Epoch: 66, Batch: 10,Loss: -2.572,Avg.Loss: -2.361,LR: 1.36E-04]Training epoch 66:   7%|▋         | 10/153 [00:00<00:02, 56.04it/s, Epoch: 66, Batch: 11,Loss: -2.890,Avg.Loss: -2.409,LR: 1.36E-04]Training epoch 66:   7%|▋         | 11/153 [00:00<00:02, 56.04it/s, Epoch: 66, Batch: 12,Loss: -2.805,Avg.Loss: -2.442,LR: 1.36E-04]Training epoch 66:   8%|▊         | 12/153 [00:00<00:02, 53.94it/s, Epoch: 66, Batch: 12,Loss: -2.805,Avg.Loss: -2.442,LR: 1.36E-04]Training epoch 66:   8%|▊         | 12/153 [00:00<00:02, 53.94it/s, Epoch: 66, Batch: 13,Loss: -1.915,Avg.Loss: -2.402,LR: 1.36E-04]Training epoch 66:   8%|▊         | 13/153 [00:00<00:02, 53.94it/s, Epoch: 66, Batch: 14,Loss: -1.925,Avg.Loss: -2.368,LR: 1.36E-04]Training epoch 66:   9%|▉         | 14/153 [00:00<00:02, 53.94it/s, Epoch: 66, Batch: 15,Loss: -2.197,Avg.Loss: -2.356,LR: 1.36E-04]Training epoch 66:  10%|▉         | 15/153 [00:00<00:02, 53.94it/s, Epoch: 66, Batch: 16,Loss: -2.364,Avg.Loss: -2.357,LR: 1.36E-04]Training epoch 66:  10%|█         | 16/153 [00:00<00:02, 53.94it/s, Epoch: 66, Batch: 17,Loss: -1.756,Avg.Loss: -2.321,LR: 1.36E-04]Training epoch 66:  11%|█         | 17/153 [00:00<00:02, 53.94it/s, Epoch: 66, Batch: 18,Loss: -1.618,Avg.Loss: -2.282,LR: 1.36E-04]Training epoch 66:  12%|█▏        | 18/153 [00:00<00:02, 53.67it/s, Epoch: 66, Batch: 18,Loss: -1.618,Avg.Loss: -2.282,LR: 1.36E-04]Training epoch 66:  12%|█▏        | 18/153 [00:00<00:02, 53.67it/s, Epoch: 66, Batch: 19,Loss: -2.264,Avg.Loss: -2.281,LR: 1.36E-04]Training epoch 66:  12%|█▏        | 19/153 [00:00<00:02, 53.67it/s, Epoch: 66, Batch: 20,Loss: -2.905,Avg.Loss: -2.312,LR: 1.36E-04]Training epoch 66:  13%|█▎        | 20/153 [00:00<00:02, 53.67it/s, Epoch: 66, Batch: 21,Loss: -2.504,Avg.Loss: -2.322,LR: 1.36E-04]Training epoch 66:  14%|█▎        | 21/153 [00:00<00:02, 53.67it/s, Epoch: 66, Batch: 22,Loss: -2.709,Avg.Loss: -2.339,LR: 1.35E-04]Training epoch 66:  14%|█▍        | 22/153 [00:00<00:02, 53.67it/s, Epoch: 66, Batch: 23,Loss: -2.440,Avg.Loss: -2.344,LR: 1.35E-04]Training epoch 66:  15%|█▌        | 23/153 [00:00<00:02, 53.67it/s, Epoch: 66, Batch: 24,Loss: -2.415,Avg.Loss: -2.347,LR: 1.35E-04]Training epoch 66:  16%|█▌        | 24/153 [00:00<00:02, 52.56it/s, Epoch: 66, Batch: 24,Loss: -2.415,Avg.Loss: -2.347,LR: 1.35E-04]Training epoch 66:  16%|█▌        | 24/153 [00:00<00:02, 52.56it/s, Epoch: 66, Batch: 25,Loss: -2.545,Avg.Loss: -2.355,LR: 1.35E-04]Training epoch 66:  16%|█▋        | 25/153 [00:00<00:02, 52.56it/s, Epoch: 66, Batch: 26,Loss: -2.691,Avg.Loss: -2.367,LR: 1.35E-04]Training epoch 66:  17%|█▋        | 26/153 [00:00<00:02, 52.56it/s, Epoch: 66, Batch: 27,Loss: -2.864,Avg.Loss: -2.386,LR: 1.35E-04]Training epoch 66:  18%|█▊        | 27/153 [00:00<00:02, 52.56it/s, Epoch: 66, Batch: 28,Loss: -3.172,Avg.Loss: -2.414,LR: 1.35E-04]Training epoch 66:  18%|█▊        | 28/153 [00:00<00:02, 52.56it/s, Epoch: 66, Batch: 29,Loss: -2.910,Avg.Loss: -2.431,LR: 1.35E-04]Training epoch 66:  19%|█▉        | 29/153 [00:00<00:02, 52.56it/s, Epoch: 66, Batch: 30,Loss: -2.814,Avg.Loss: -2.444,LR: 1.35E-04]Training epoch 66:  20%|█▉        | 30/153 [00:00<00:02, 53.57it/s, Epoch: 66, Batch: 30,Loss: -2.814,Avg.Loss: -2.444,LR: 1.35E-04]Training epoch 66:  20%|█▉        | 30/153 [00:00<00:02, 53.57it/s, Epoch: 66, Batch: 31,Loss: -2.443,Avg.Loss: -2.444,LR: 1.35E-04]Training epoch 66:  20%|██        | 31/153 [00:00<00:02, 53.57it/s, Epoch: 66, Batch: 32,Loss: -3.084,Avg.Loss: -2.464,LR: 1.35E-04]Training epoch 66:  21%|██        | 32/153 [00:00<00:02, 53.57it/s, Epoch: 66, Batch: 33,Loss: -3.101,Avg.Loss: -2.483,LR: 1.35E-04]Training epoch 66:  22%|██▏       | 33/153 [00:00<00:02, 53.57it/s, Epoch: 66, Batch: 34,Loss: -2.607,Avg.Loss: -2.487,LR: 1.35E-04]Training epoch 66:  22%|██▏       | 34/153 [00:00<00:02, 53.57it/s, Epoch: 66, Batch: 35,Loss: -2.639,Avg.Loss: -2.491,LR: 1.35E-04]Training epoch 66:  23%|██▎       | 35/153 [00:00<00:02, 53.57it/s, Epoch: 66, Batch: 36,Loss: -3.036,Avg.Loss: -2.506,LR: 1.35E-04]Training epoch 66:  24%|██▎       | 36/153 [00:00<00:02, 53.51it/s, Epoch: 66, Batch: 36,Loss: -3.036,Avg.Loss: -2.506,LR: 1.35E-04]Training epoch 66:  24%|██▎       | 36/153 [00:00<00:02, 53.51it/s, Epoch: 66, Batch: 37,Loss: -2.866,Avg.Loss: -2.516,LR: 1.35E-04]Training epoch 66:  24%|██▍       | 37/153 [00:00<00:02, 53.51it/s, Epoch: 66, Batch: 38,Loss: -3.064,Avg.Loss: -2.530,LR: 1.35E-04]Training epoch 66:  25%|██▍       | 38/153 [00:00<00:02, 53.51it/s, Epoch: 66, Batch: 39,Loss: -2.686,Avg.Loss: -2.534,LR: 1.35E-04]Training epoch 66:  25%|██▌       | 39/153 [00:00<00:02, 53.51it/s, Epoch: 66, Batch: 40,Loss: -3.101,Avg.Loss: -2.548,LR: 1.35E-04]Training epoch 66:  26%|██▌       | 40/153 [00:00<00:02, 53.51it/s, Epoch: 66, Batch: 41,Loss: -2.961,Avg.Loss: -2.559,LR: 1.35E-04]Training epoch 66:  27%|██▋       | 41/153 [00:00<00:02, 53.51it/s, Epoch: 66, Batch: 42,Loss: -3.282,Avg.Loss: -2.576,LR: 1.35E-04]Training epoch 66:  27%|██▋       | 42/153 [00:00<00:02, 53.16it/s, Epoch: 66, Batch: 42,Loss: -3.282,Avg.Loss: -2.576,LR: 1.35E-04]Training epoch 66:  27%|██▋       | 42/153 [00:00<00:02, 53.16it/s, Epoch: 66, Batch: 43,Loss: -3.071,Avg.Loss: -2.587,LR: 1.35E-04]Training epoch 66:  28%|██▊       | 43/153 [00:00<00:02, 53.16it/s, Epoch: 66, Batch: 44,Loss: -2.699,Avg.Loss: -2.590,LR: 1.34E-04]Training epoch 66:  29%|██▉       | 44/153 [00:00<00:02, 53.16it/s, Epoch: 66, Batch: 45,Loss: -3.157,Avg.Loss: -2.602,LR: 1.34E-04]Training epoch 66:  29%|██▉       | 45/153 [00:00<00:02, 53.16it/s, Epoch: 66, Batch: 46,Loss: -2.656,Avg.Loss: -2.604,LR: 1.34E-04]Training epoch 66:  30%|███       | 46/153 [00:00<00:02, 53.16it/s, Epoch: 66, Batch: 47,Loss: -2.536,Avg.Loss: -2.602,LR: 1.34E-04]Training epoch 66:  31%|███       | 47/153 [00:00<00:01, 53.16it/s, Epoch: 66, Batch: 48,Loss: -2.247,Avg.Loss: -2.595,LR: 1.34E-04]Training epoch 66:  31%|███▏      | 48/153 [00:00<00:01, 53.06it/s, Epoch: 66, Batch: 48,Loss: -2.247,Avg.Loss: -2.595,LR: 1.34E-04]Training epoch 66:  31%|███▏      | 48/153 [00:00<00:01, 53.06it/s, Epoch: 66, Batch: 49,Loss: -2.515,Avg.Loss: -2.593,LR: 1.34E-04]Training epoch 66:  32%|███▏      | 49/153 [00:00<00:01, 53.06it/s, Epoch: 66, Batch: 50,Loss: -2.879,Avg.Loss: -2.599,LR: 1.34E-04]Training epoch 66:  33%|███▎      | 50/153 [00:00<00:01, 53.06it/s, Epoch: 66, Batch: 51,Loss: -2.768,Avg.Loss: -2.602,LR: 1.34E-04]Training epoch 66:  33%|███▎      | 51/153 [00:00<00:01, 53.06it/s, Epoch: 66, Batch: 52,Loss: -2.807,Avg.Loss: -2.606,LR: 1.34E-04]Training epoch 66:  34%|███▍      | 52/153 [00:00<00:01, 53.06it/s, Epoch: 66, Batch: 53,Loss: -2.815,Avg.Loss: -2.610,LR: 1.34E-04]Training epoch 66:  35%|███▍      | 53/153 [00:01<00:01, 53.06it/s, Epoch: 66, Batch: 54,Loss: -1.962,Avg.Loss: -2.598,LR: 1.34E-04]Training epoch 66:  35%|███▌      | 54/153 [00:01<00:01, 53.19it/s, Epoch: 66, Batch: 54,Loss: -1.962,Avg.Loss: -2.598,LR: 1.34E-04]Training epoch 66:  35%|███▌      | 54/153 [00:01<00:01, 53.19it/s, Epoch: 66, Batch: 55,Loss: -2.738,Avg.Loss: -2.601,LR: 1.34E-04]Training epoch 66:  36%|███▌      | 55/153 [00:01<00:01, 53.19it/s, Epoch: 66, Batch: 56,Loss: -2.511,Avg.Loss: -2.599,LR: 1.34E-04]Training epoch 66:  37%|███▋      | 56/153 [00:01<00:01, 53.19it/s, Epoch: 66, Batch: 57,Loss: -3.013,Avg.Loss: -2.606,LR: 1.34E-04]Training epoch 66:  37%|███▋      | 57/153 [00:01<00:01, 53.19it/s, Epoch: 66, Batch: 58,Loss: -2.920,Avg.Loss: -2.612,LR: 1.34E-04]Training epoch 66:  38%|███▊      | 58/153 [00:01<00:01, 53.19it/s, Epoch: 66, Batch: 59,Loss: -2.922,Avg.Loss: -2.617,LR: 1.34E-04]Training epoch 66:  39%|███▊      | 59/153 [00:01<00:01, 53.19it/s, Epoch: 66, Batch: 60,Loss: -2.432,Avg.Loss: -2.614,LR: 1.34E-04]Training epoch 66:  39%|███▉      | 60/153 [00:01<00:01, 53.17it/s, Epoch: 66, Batch: 60,Loss: -2.432,Avg.Loss: -2.614,LR: 1.34E-04]Training epoch 66:  39%|███▉      | 60/153 [00:01<00:01, 53.17it/s, Epoch: 66, Batch: 61,Loss: -2.849,Avg.Loss: -2.618,LR: 1.34E-04]Training epoch 66:  40%|███▉      | 61/153 [00:01<00:01, 53.17it/s, Epoch: 66, Batch: 62,Loss: -2.197,Avg.Loss: -2.611,LR: 1.34E-04]Training epoch 66:  41%|████      | 62/153 [00:01<00:01, 53.17it/s, Epoch: 66, Batch: 63,Loss: -2.448,Avg.Loss: -2.608,LR: 1.34E-04]Training epoch 66:  41%|████      | 63/153 [00:01<00:01, 53.17it/s, Epoch: 66, Batch: 64,Loss: -2.443,Avg.Loss: -2.606,LR: 1.34E-04]Training epoch 66:  42%|████▏     | 64/153 [00:01<00:01, 53.17it/s, Epoch: 66, Batch: 65,Loss: -2.513,Avg.Loss: -2.604,LR: 1.34E-04]Training epoch 66:  42%|████▏     | 65/153 [00:01<00:01, 53.17it/s, Epoch: 66, Batch: 66,Loss: -2.808,Avg.Loss: -2.607,LR: 1.33E-04]Training epoch 66:  43%|████▎     | 66/153 [00:01<00:01, 53.32it/s, Epoch: 66, Batch: 66,Loss: -2.808,Avg.Loss: -2.607,LR: 1.33E-04]Training epoch 66:  43%|████▎     | 66/153 [00:01<00:01, 53.32it/s, Epoch: 66, Batch: 67,Loss: -3.083,Avg.Loss: -2.615,LR: 1.33E-04]Training epoch 66:  44%|████▍     | 67/153 [00:01<00:01, 53.32it/s, Epoch: 66, Batch: 68,Loss: -2.760,Avg.Loss: -2.617,LR: 1.33E-04]Training epoch 66:  44%|████▍     | 68/153 [00:01<00:01, 53.32it/s, Epoch: 66, Batch: 69,Loss: -3.114,Avg.Loss: -2.624,LR: 1.33E-04]Training epoch 66:  45%|████▌     | 69/153 [00:01<00:01, 53.32it/s, Epoch: 66, Batch: 70,Loss: -3.026,Avg.Loss: -2.630,LR: 1.33E-04]Training epoch 66:  46%|████▌     | 70/153 [00:01<00:01, 53.32it/s, Epoch: 66, Batch: 71,Loss: -2.465,Avg.Loss: -2.627,LR: 1.33E-04]Training epoch 66:  46%|████▋     | 71/153 [00:01<00:01, 53.32it/s, Epoch: 66, Batch: 72,Loss: -2.211,Avg.Loss: -2.622,LR: 1.33E-04]Training epoch 66:  47%|████▋     | 72/153 [00:01<00:01, 53.18it/s, Epoch: 66, Batch: 72,Loss: -2.211,Avg.Loss: -2.622,LR: 1.33E-04]Training epoch 66:  47%|████▋     | 72/153 [00:01<00:01, 53.18it/s, Epoch: 66, Batch: 73,Loss: -2.561,Avg.Loss: -2.621,LR: 1.33E-04]Training epoch 66:  48%|████▊     | 73/153 [00:01<00:01, 53.18it/s, Epoch: 66, Batch: 74,Loss: -2.559,Avg.Loss: -2.620,LR: 1.33E-04]Training epoch 66:  48%|████▊     | 74/153 [00:01<00:01, 53.18it/s, Epoch: 66, Batch: 75,Loss: -3.271,Avg.Loss: -2.629,LR: 1.33E-04]Training epoch 66:  49%|████▉     | 75/153 [00:01<00:01, 53.18it/s, Epoch: 66, Batch: 76,Loss: -2.459,Avg.Loss: -2.626,LR: 1.33E-04]Training epoch 66:  50%|████▉     | 76/153 [00:01<00:01, 53.18it/s, Epoch: 66, Batch: 77,Loss: -2.973,Avg.Loss: -2.631,LR: 1.33E-04]Training epoch 66:  50%|█████     | 77/153 [00:01<00:01, 53.18it/s, Epoch: 66, Batch: 78,Loss: -2.657,Avg.Loss: -2.631,LR: 1.33E-04]Training epoch 66:  51%|█████     | 78/153 [00:01<00:01, 52.46it/s, Epoch: 66, Batch: 78,Loss: -2.657,Avg.Loss: -2.631,LR: 1.33E-04]Training epoch 66:  51%|█████     | 78/153 [00:01<00:01, 52.46it/s, Epoch: 66, Batch: 79,Loss: -2.841,Avg.Loss: -2.634,LR: 1.33E-04]Training epoch 66:  52%|█████▏    | 79/153 [00:01<00:01, 52.46it/s, Epoch: 66, Batch: 80,Loss: -2.768,Avg.Loss: -2.635,LR: 1.33E-04]Training epoch 66:  52%|█████▏    | 80/153 [00:01<00:01, 52.46it/s, Epoch: 66, Batch: 81,Loss: -2.815,Avg.Loss: -2.638,LR: 1.33E-04]Training epoch 66:  53%|█████▎    | 81/153 [00:01<00:01, 52.46it/s, Epoch: 66, Batch: 82,Loss: -2.064,Avg.Loss: -2.631,LR: 1.33E-04]Training epoch 66:  54%|█████▎    | 82/153 [00:01<00:01, 52.46it/s, Epoch: 66, Batch: 83,Loss: -3.226,Avg.Loss: -2.638,LR: 1.33E-04]Training epoch 66:  54%|█████▍    | 83/153 [00:01<00:01, 52.46it/s, Epoch: 66, Batch: 84,Loss: -2.340,Avg.Loss: -2.634,LR: 1.33E-04]Training epoch 66:  55%|█████▍    | 84/153 [00:01<00:01, 52.69it/s, Epoch: 66, Batch: 84,Loss: -2.340,Avg.Loss: -2.634,LR: 1.33E-04]Training epoch 66:  55%|█████▍    | 84/153 [00:01<00:01, 52.69it/s, Epoch: 66, Batch: 85,Loss: -1.630,Avg.Loss: -2.623,LR: 1.33E-04]Training epoch 66:  56%|█████▌    | 85/153 [00:01<00:01, 52.69it/s, Epoch: 66, Batch: 86,Loss: -2.530,Avg.Loss: -2.621,LR: 1.33E-04]Training epoch 66:  56%|█████▌    | 86/153 [00:01<00:01, 52.69it/s, Epoch: 66, Batch: 87,Loss: -2.436,Avg.Loss: -2.619,LR: 1.33E-04]Training epoch 66:  57%|█████▋    | 87/153 [00:01<00:01, 52.69it/s, Epoch: 66, Batch: 88,Loss: -3.214,Avg.Loss: -2.626,LR: 1.32E-04]Training epoch 66:  58%|█████▊    | 88/153 [00:01<00:01, 52.69it/s, Epoch: 66, Batch: 89,Loss: -3.037,Avg.Loss: -2.631,LR: 1.32E-04]Training epoch 66:  58%|█████▊    | 89/153 [00:01<00:01, 52.69it/s, Epoch: 66, Batch: 90,Loss: -3.094,Avg.Loss: -2.636,LR: 1.32E-04]Training epoch 66:  59%|█████▉    | 90/153 [00:01<00:01, 52.94it/s, Epoch: 66, Batch: 90,Loss: -3.094,Avg.Loss: -2.636,LR: 1.32E-04]Training epoch 66:  59%|█████▉    | 90/153 [00:01<00:01, 52.94it/s, Epoch: 66, Batch: 91,Loss: -2.745,Avg.Loss: -2.637,LR: 1.32E-04]Training epoch 66:  59%|█████▉    | 91/153 [00:01<00:01, 52.94it/s, Epoch: 66, Batch: 92,Loss: -2.147,Avg.Loss: -2.632,LR: 1.32E-04]Training epoch 66:  60%|██████    | 92/153 [00:01<00:01, 52.94it/s, Epoch: 66, Batch: 93,Loss: -2.141,Avg.Loss: -2.626,LR: 1.32E-04]Training epoch 66:  61%|██████    | 93/153 [00:01<00:01, 52.94it/s, Epoch: 66, Batch: 94,Loss: -2.073,Avg.Loss: -2.621,LR: 1.32E-04]Training epoch 66:  61%|██████▏   | 94/153 [00:01<00:01, 52.94it/s, Epoch: 66, Batch: 95,Loss: -2.138,Avg.Loss: -2.615,LR: 1.32E-04]Training epoch 66:  62%|██████▏   | 95/153 [00:01<00:01, 52.94it/s, Epoch: 66, Batch: 96,Loss: -2.441,Avg.Loss: -2.614,LR: 1.32E-04]Training epoch 66:  63%|██████▎   | 96/153 [00:01<00:01, 53.07it/s, Epoch: 66, Batch: 96,Loss: -2.441,Avg.Loss: -2.614,LR: 1.32E-04]Training epoch 66:  63%|██████▎   | 96/153 [00:01<00:01, 53.07it/s, Epoch: 66, Batch: 97,Loss: -2.373,Avg.Loss: -2.611,LR: 1.32E-04]Training epoch 66:  63%|██████▎   | 97/153 [00:01<00:01, 53.07it/s, Epoch: 66, Batch: 98,Loss: -2.286,Avg.Loss: -2.608,LR: 1.32E-04]Training epoch 66:  64%|██████▍   | 98/153 [00:01<00:01, 53.07it/s, Epoch: 66, Batch: 99,Loss: -2.777,Avg.Loss: -2.610,LR: 1.32E-04]Training epoch 66:  65%|██████▍   | 99/153 [00:01<00:01, 53.07it/s, Epoch: 66, Batch: 100,Loss: -2.097,Avg.Loss: -2.604,LR: 1.32E-04]Training epoch 66:  65%|██████▌   | 100/153 [00:01<00:00, 53.07it/s, Epoch: 66, Batch: 101,Loss: -2.956,Avg.Loss: -2.608,LR: 1.32E-04]Training epoch 66:  66%|██████▌   | 101/153 [00:01<00:00, 53.07it/s, Epoch: 66, Batch: 102,Loss: -3.050,Avg.Loss: -2.612,LR: 1.32E-04]Training epoch 66:  67%|██████▋   | 102/153 [00:01<00:00, 52.89it/s, Epoch: 66, Batch: 102,Loss: -3.050,Avg.Loss: -2.612,LR: 1.32E-04]Training epoch 66:  67%|██████▋   | 102/153 [00:01<00:00, 52.89it/s, Epoch: 66, Batch: 103,Loss: -2.989,Avg.Loss: -2.616,LR: 1.32E-04]Training epoch 66:  67%|██████▋   | 103/153 [00:01<00:00, 52.89it/s, Epoch: 66, Batch: 104,Loss: -2.960,Avg.Loss: -2.619,LR: 1.32E-04]Training epoch 66:  68%|██████▊   | 104/153 [00:01<00:00, 52.89it/s, Epoch: 66, Batch: 105,Loss: -2.908,Avg.Loss: -2.622,LR: 1.32E-04]Training epoch 66:  69%|██████▊   | 105/153 [00:01<00:00, 52.89it/s, Epoch: 66, Batch: 106,Loss: -2.850,Avg.Loss: -2.624,LR: 1.32E-04]Training epoch 66:  69%|██████▉   | 106/153 [00:02<00:00, 52.89it/s, Epoch: 66, Batch: 107,Loss: -3.016,Avg.Loss: -2.628,LR: 1.32E-04]Training epoch 66:  70%|██████▉   | 107/153 [00:02<00:00, 52.89it/s, Epoch: 66, Batch: 108,Loss: -2.591,Avg.Loss: -2.627,LR: 1.32E-04]Training epoch 66:  71%|███████   | 108/153 [00:02<00:00, 52.95it/s, Epoch: 66, Batch: 108,Loss: -2.591,Avg.Loss: -2.627,LR: 1.32E-04]Training epoch 66:  71%|███████   | 108/153 [00:02<00:00, 52.95it/s, Epoch: 66, Batch: 109,Loss: -2.693,Avg.Loss: -2.628,LR: 1.32E-04]Training epoch 66:  71%|███████   | 109/153 [00:02<00:00, 52.95it/s, Epoch: 66, Batch: 110,Loss: -2.323,Avg.Loss: -2.625,LR: 1.32E-04]Training epoch 66:  72%|███████▏  | 110/153 [00:02<00:00, 52.95it/s, Epoch: 66, Batch: 111,Loss: -3.117,Avg.Loss: -2.630,LR: 1.31E-04]Training epoch 66:  73%|███████▎  | 111/153 [00:02<00:00, 52.95it/s, Epoch: 66, Batch: 112,Loss: -2.403,Avg.Loss: -2.628,LR: 1.31E-04]Training epoch 66:  73%|███████▎  | 112/153 [00:02<00:00, 52.95it/s, Epoch: 66, Batch: 113,Loss: -2.929,Avg.Loss: -2.630,LR: 1.31E-04]Training epoch 66:  74%|███████▍  | 113/153 [00:02<00:00, 52.95it/s, Epoch: 66, Batch: 114,Loss: -2.266,Avg.Loss: -2.627,LR: 1.31E-04]Training epoch 66:  75%|███████▍  | 114/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 114,Loss: -2.266,Avg.Loss: -2.627,LR: 1.31E-04]Training epoch 66:  75%|███████▍  | 114/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 115,Loss: -2.307,Avg.Loss: -2.624,LR: 1.31E-04]Training epoch 66:  75%|███████▌  | 115/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 116,Loss: -2.159,Avg.Loss: -2.620,LR: 1.31E-04]Training epoch 66:  76%|███████▌  | 116/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 117,Loss: -2.470,Avg.Loss: -2.619,LR: 1.31E-04]Training epoch 66:  76%|███████▋  | 117/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 118,Loss: -2.868,Avg.Loss: -2.621,LR: 1.31E-04]Training epoch 66:  77%|███████▋  | 118/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 119,Loss: -2.750,Avg.Loss: -2.622,LR: 1.31E-04]Training epoch 66:  78%|███████▊  | 119/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 120,Loss: -2.342,Avg.Loss: -2.620,LR: 1.31E-04]Training epoch 66:  78%|███████▊  | 120/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 120,Loss: -2.342,Avg.Loss: -2.620,LR: 1.31E-04]Training epoch 66:  78%|███████▊  | 120/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 121,Loss: -2.304,Avg.Loss: -2.617,LR: 1.31E-04]Training epoch 66:  79%|███████▉  | 121/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 122,Loss: -2.044,Avg.Loss: -2.613,LR: 1.31E-04]Training epoch 66:  80%|███████▉  | 122/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 123,Loss: -2.507,Avg.Loss: -2.612,LR: 1.31E-04]Training epoch 66:  80%|████████  | 123/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 124,Loss: -2.794,Avg.Loss: -2.613,LR: 1.31E-04]Training epoch 66:  81%|████████  | 124/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 125,Loss: -2.133,Avg.Loss: -2.609,LR: 1.31E-04]Training epoch 66:  82%|████████▏ | 125/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 126,Loss: -1.727,Avg.Loss: -2.602,LR: 1.31E-04]Training epoch 66:  82%|████████▏ | 126/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 126,Loss: -1.727,Avg.Loss: -2.602,LR: 1.31E-04]Training epoch 66:  82%|████████▏ | 126/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 127,Loss: -1.168,Avg.Loss: -2.591,LR: 1.31E-04]Training epoch 66:  83%|████████▎ | 127/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 128,Loss: -1.791,Avg.Loss: -2.585,LR: 1.31E-04]Training epoch 66:  84%|████████▎ | 128/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 129,Loss: -2.353,Avg.Loss: -2.583,LR: 1.31E-04]Training epoch 66:  84%|████████▍ | 129/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 130,Loss: -2.066,Avg.Loss: -2.579,LR: 1.31E-04]Training epoch 66:  85%|████████▍ | 130/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 131,Loss: -0.960,Avg.Loss: -2.567,LR: 1.31E-04]Training epoch 66:  86%|████████▌ | 131/153 [00:02<00:00, 53.15it/s, Epoch: 66, Batch: 132,Loss: -0.799,Avg.Loss: -2.553,LR: 1.31E-04]Training epoch 66:  86%|████████▋ | 132/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 132,Loss: -0.799,Avg.Loss: -2.553,LR: 1.31E-04]Training epoch 66:  86%|████████▋ | 132/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 133,Loss: -2.356,Avg.Loss: -2.552,LR: 1.30E-04]Training epoch 66:  87%|████████▋ | 133/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 134,Loss: -3.405,Avg.Loss: -2.558,LR: 1.30E-04]Training epoch 66:  88%|████████▊ | 134/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 135,Loss: -2.969,Avg.Loss: -2.561,LR: 1.30E-04]Training epoch 66:  88%|████████▊ | 135/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 136,Loss: -1.999,Avg.Loss: -2.557,LR: 1.30E-04]Training epoch 66:  89%|████████▉ | 136/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 137,Loss: -1.768,Avg.Loss: -2.551,LR: 1.30E-04]Training epoch 66:  90%|████████▉ | 137/153 [00:02<00:00, 53.26it/s, Epoch: 66, Batch: 138,Loss: -1.947,Avg.Loss: -2.547,LR: 1.30E-04]Training epoch 66:  90%|█████████ | 138/153 [00:02<00:00, 53.28it/s, Epoch: 66, Batch: 138,Loss: -1.947,Avg.Loss: -2.547,LR: 1.30E-04]Training epoch 66:  90%|█████████ | 138/153 [00:02<00:00, 53.28it/s, Epoch: 66, Batch: 139,Loss: -2.756,Avg.Loss: -2.548,LR: 1.30E-04]Training epoch 66:  91%|█████████ | 139/153 [00:02<00:00, 53.28it/s, Epoch: 66, Batch: 140,Loss: -2.668,Avg.Loss: -2.549,LR: 1.30E-04]Training epoch 66:  92%|█████████▏| 140/153 [00:02<00:00, 53.28it/s, Epoch: 66, Batch: 141,Loss: -2.624,Avg.Loss: -2.550,LR: 1.30E-04]Training epoch 66:  92%|█████████▏| 141/153 [00:02<00:00, 53.28it/s, Epoch: 66, Batch: 142,Loss: -2.332,Avg.Loss: -2.548,LR: 1.30E-04]Training epoch 66:  93%|█████████▎| 142/153 [00:02<00:00, 53.28it/s, Epoch: 66, Batch: 143,Loss: -2.382,Avg.Loss: -2.547,LR: 1.30E-04]Training epoch 66:  93%|█████████▎| 143/153 [00:02<00:00, 53.28it/s, Epoch: 66, Batch: 144,Loss: -2.994,Avg.Loss: -2.550,LR: 1.30E-04]Training epoch 66:  94%|█████████▍| 144/153 [00:02<00:00, 52.41it/s, Epoch: 66, Batch: 144,Loss: -2.994,Avg.Loss: -2.550,LR: 1.30E-04]Training epoch 66:  94%|█████████▍| 144/153 [00:02<00:00, 52.41it/s, Epoch: 66, Batch: 145,Loss: -2.906,Avg.Loss: -2.553,LR: 1.30E-04]Training epoch 66:  95%|█████████▍| 145/153 [00:02<00:00, 52.41it/s, Epoch: 66, Batch: 146,Loss: -3.052,Avg.Loss: -2.556,LR: 1.30E-04]Training epoch 66:  95%|█████████▌| 146/153 [00:02<00:00, 52.41it/s, Epoch: 66, Batch: 147,Loss: -2.421,Avg.Loss: -2.555,LR: 1.30E-04]Training epoch 66:  96%|█████████▌| 147/153 [00:02<00:00, 52.41it/s, Epoch: 66, Batch: 148,Loss: -2.509,Avg.Loss: -2.555,LR: 1.30E-04]Training epoch 66:  97%|█████████▋| 148/153 [00:02<00:00, 52.41it/s, Epoch: 66, Batch: 149,Loss: -3.393,Avg.Loss: -2.560,LR: 1.30E-04]Training epoch 66:  97%|█████████▋| 149/153 [00:02<00:00, 52.41it/s, Epoch: 66, Batch: 150,Loss: -2.795,Avg.Loss: -2.562,LR: 1.30E-04]Training epoch 66:  98%|█████████▊| 150/153 [00:02<00:00, 52.75it/s, Epoch: 66, Batch: 150,Loss: -2.795,Avg.Loss: -2.562,LR: 1.30E-04]Training epoch 66:  98%|█████████▊| 150/153 [00:02<00:00, 52.75it/s, Epoch: 66, Batch: 151,Loss: -2.516,Avg.Loss: -2.562,LR: 1.30E-04]Training epoch 66:  99%|█████████▊| 151/153 [00:02<00:00, 52.75it/s, Epoch: 66, Batch: 152,Loss: -2.580,Avg.Loss: -2.562,LR: 1.30E-04]Training epoch 66:  99%|█████████▉| 152/153 [00:02<00:00, 52.75it/s, Epoch: 66, Batch: 153,Loss: -2.247,Avg.Loss: -2.560,LR: 1.30E-04]Training epoch 66: 100%|██████████| 153/153 [00:02<00:00, 53.03it/s, Epoch: 66, Batch: 153,Loss: -2.247,Avg.Loss: -2.560,LR: 1.30E-04]
Training epoch 67:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 67:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 67, Batch: 1,Loss: -2.433,Avg.Loss: -2.433,LR: 1.30E-04]Training epoch 67:   1%|          | 1/153 [00:00<00:06, 24.39it/s, Epoch: 67, Batch: 2,Loss: -2.872,Avg.Loss: -2.652,LR: 1.29E-04]Training epoch 67:   1%|▏         | 2/153 [00:00<00:04, 33.71it/s, Epoch: 67, Batch: 3,Loss: -2.559,Avg.Loss: -2.621,LR: 1.29E-04]Training epoch 67:   2%|▏         | 3/153 [00:00<00:03, 38.45it/s, Epoch: 67, Batch: 4,Loss: -2.892,Avg.Loss: -2.689,LR: 1.29E-04]Training epoch 67:   3%|▎         | 4/153 [00:00<00:03, 41.14it/s, Epoch: 67, Batch: 5,Loss: -2.871,Avg.Loss: -2.725,LR: 1.29E-04]Training epoch 67:   3%|▎         | 5/153 [00:00<00:03, 42.82it/s, Epoch: 67, Batch: 6,Loss: -2.671,Avg.Loss: -2.716,LR: 1.29E-04]Training epoch 67:   4%|▍         | 6/153 [00:00<00:02, 51.30it/s, Epoch: 67, Batch: 6,Loss: -2.671,Avg.Loss: -2.716,LR: 1.29E-04]Training epoch 67:   4%|▍         | 6/153 [00:00<00:02, 51.30it/s, Epoch: 67, Batch: 7,Loss: -2.536,Avg.Loss: -2.691,LR: 1.29E-04]Training epoch 67:   5%|▍         | 7/153 [00:00<00:02, 51.30it/s, Epoch: 67, Batch: 8,Loss: -2.572,Avg.Loss: -2.676,LR: 1.29E-04]Training epoch 67:   5%|▌         | 8/153 [00:00<00:02, 51.30it/s, Epoch: 67, Batch: 9,Loss: -2.848,Avg.Loss: -2.695,LR: 1.29E-04]Training epoch 67:   6%|▌         | 9/153 [00:00<00:02, 51.30it/s, Epoch: 67, Batch: 10,Loss: -2.645,Avg.Loss: -2.690,LR: 1.29E-04]Training epoch 67:   7%|▋         | 10/153 [00:00<00:02, 51.30it/s, Epoch: 67, Batch: 11,Loss: -2.585,Avg.Loss: -2.680,LR: 1.29E-04]Training epoch 67:   7%|▋         | 11/153 [00:00<00:02, 51.30it/s, Epoch: 67, Batch: 12,Loss: -2.319,Avg.Loss: -2.650,LR: 1.29E-04]Training epoch 67:   8%|▊         | 12/153 [00:00<00:02, 52.13it/s, Epoch: 67, Batch: 12,Loss: -2.319,Avg.Loss: -2.650,LR: 1.29E-04]Training epoch 67:   8%|▊         | 12/153 [00:00<00:02, 52.13it/s, Epoch: 67, Batch: 13,Loss: -2.924,Avg.Loss: -2.671,LR: 1.29E-04]Training epoch 67:   8%|▊         | 13/153 [00:00<00:02, 52.13it/s, Epoch: 67, Batch: 14,Loss: -2.695,Avg.Loss: -2.673,LR: 1.29E-04]Training epoch 67:   9%|▉         | 14/153 [00:00<00:02, 52.13it/s, Epoch: 67, Batch: 15,Loss: -2.838,Avg.Loss: -2.684,LR: 1.29E-04]Training epoch 67:  10%|▉         | 15/153 [00:00<00:02, 52.13it/s, Epoch: 67, Batch: 16,Loss: -2.719,Avg.Loss: -2.686,LR: 1.29E-04]Training epoch 67:  10%|█         | 16/153 [00:00<00:02, 52.13it/s, Epoch: 67, Batch: 17,Loss: -1.677,Avg.Loss: -2.627,LR: 1.29E-04]Training epoch 67:  11%|█         | 17/153 [00:00<00:02, 52.13it/s, Epoch: 67, Batch: 18,Loss: -1.370,Avg.Loss: -2.557,LR: 1.29E-04]Training epoch 67:  12%|█▏        | 18/153 [00:00<00:02, 52.34it/s, Epoch: 67, Batch: 18,Loss: -1.370,Avg.Loss: -2.557,LR: 1.29E-04]Training epoch 67:  12%|█▏        | 18/153 [00:00<00:02, 52.34it/s, Epoch: 67, Batch: 19,Loss: -1.907,Avg.Loss: -2.523,LR: 1.29E-04]Training epoch 67:  12%|█▏        | 19/153 [00:00<00:02, 52.34it/s, Epoch: 67, Batch: 20,Loss: -1.593,Avg.Loss: -2.476,LR: 1.29E-04]Training epoch 67:  13%|█▎        | 20/153 [00:00<00:02, 52.34it/s, Epoch: 67, Batch: 21,Loss: -2.469,Avg.Loss: -2.476,LR: 1.29E-04]Training epoch 67:  14%|█▎        | 21/153 [00:00<00:02, 52.34it/s, Epoch: 67, Batch: 22,Loss: -2.083,Avg.Loss: -2.458,LR: 1.29E-04]Training epoch 67:  14%|█▍        | 22/153 [00:00<00:02, 52.34it/s, Epoch: 67, Batch: 23,Loss: -1.141,Avg.Loss: -2.401,LR: 1.29E-04]Training epoch 67:  15%|█▌        | 23/153 [00:00<00:02, 52.34it/s, Epoch: 67, Batch: 24,Loss: -1.206,Avg.Loss: -2.351,LR: 1.28E-04]Training epoch 67:  16%|█▌        | 24/153 [00:00<00:02, 51.34it/s, Epoch: 67, Batch: 24,Loss: -1.206,Avg.Loss: -2.351,LR: 1.28E-04]Training epoch 67:  16%|█▌        | 24/153 [00:00<00:02, 51.34it/s, Epoch: 67, Batch: 25,Loss: -1.497,Avg.Loss: -2.317,LR: 1.28E-04]Training epoch 67:  16%|█▋        | 25/153 [00:00<00:02, 51.34it/s, Epoch: 67, Batch: 26,Loss: -2.554,Avg.Loss: -2.326,LR: 1.28E-04]Training epoch 67:  17%|█▋        | 26/153 [00:00<00:02, 51.34it/s, Epoch: 67, Batch: 27,Loss: -2.786,Avg.Loss: -2.343,LR: 1.28E-04]Training epoch 67:  18%|█▊        | 27/153 [00:00<00:02, 51.34it/s, Epoch: 67, Batch: 28,Loss: -2.221,Avg.Loss: -2.339,LR: 1.28E-04]Training epoch 67:  18%|█▊        | 28/153 [00:00<00:02, 51.34it/s, Epoch: 67, Batch: 29,Loss: -2.353,Avg.Loss: -2.339,LR: 1.28E-04]Training epoch 67:  19%|█▉        | 29/153 [00:00<00:02, 51.34it/s, Epoch: 67, Batch: 30,Loss: -2.545,Avg.Loss: -2.346,LR: 1.28E-04]Training epoch 67:  20%|█▉        | 30/153 [00:00<00:02, 51.39it/s, Epoch: 67, Batch: 30,Loss: -2.545,Avg.Loss: -2.346,LR: 1.28E-04]Training epoch 67:  20%|█▉        | 30/153 [00:00<00:02, 51.39it/s, Epoch: 67, Batch: 31,Loss: -2.640,Avg.Loss: -2.355,LR: 1.28E-04]Training epoch 67:  20%|██        | 31/153 [00:00<00:02, 51.39it/s, Epoch: 67, Batch: 32,Loss: -2.290,Avg.Loss: -2.353,LR: 1.28E-04]Training epoch 67:  21%|██        | 32/153 [00:00<00:02, 51.39it/s, Epoch: 67, Batch: 33,Loss: -1.362,Avg.Loss: -2.323,LR: 1.28E-04]Training epoch 67:  22%|██▏       | 33/153 [00:00<00:02, 51.39it/s, Epoch: 67, Batch: 34,Loss: -1.740,Avg.Loss: -2.306,LR: 1.28E-04]Training epoch 67:  22%|██▏       | 34/153 [00:00<00:02, 51.39it/s, Epoch: 67, Batch: 35,Loss: -1.883,Avg.Loss: -2.294,LR: 1.28E-04]Training epoch 67:  23%|██▎       | 35/153 [00:00<00:02, 51.39it/s, Epoch: 67, Batch: 36,Loss: -2.118,Avg.Loss: -2.289,LR: 1.28E-04]Training epoch 67:  24%|██▎       | 36/153 [00:00<00:02, 51.93it/s, Epoch: 67, Batch: 36,Loss: -2.118,Avg.Loss: -2.289,LR: 1.28E-04]Training epoch 67:  24%|██▎       | 36/153 [00:00<00:02, 51.93it/s, Epoch: 67, Batch: 37,Loss: -2.916,Avg.Loss: -2.306,LR: 1.28E-04]Training epoch 67:  24%|██▍       | 37/153 [00:00<00:02, 51.93it/s, Epoch: 67, Batch: 38,Loss: -1.954,Avg.Loss: -2.297,LR: 1.28E-04]Training epoch 67:  25%|██▍       | 38/153 [00:00<00:02, 51.93it/s, Epoch: 67, Batch: 39,Loss: -1.696,Avg.Loss: -2.282,LR: 1.28E-04]Training epoch 67:  25%|██▌       | 39/153 [00:00<00:02, 51.93it/s, Epoch: 67, Batch: 40,Loss: -2.545,Avg.Loss: -2.288,LR: 1.28E-04]Training epoch 67:  26%|██▌       | 40/153 [00:00<00:02, 51.93it/s, Epoch: 67, Batch: 41,Loss: -3.206,Avg.Loss: -2.311,LR: 1.28E-04]Training epoch 67:  27%|██▋       | 41/153 [00:00<00:02, 51.93it/s, Epoch: 67, Batch: 42,Loss: -2.622,Avg.Loss: -2.318,LR: 1.28E-04]Training epoch 67:  27%|██▋       | 42/153 [00:00<00:02, 52.44it/s, Epoch: 67, Batch: 42,Loss: -2.622,Avg.Loss: -2.318,LR: 1.28E-04]Training epoch 67:  27%|██▋       | 42/153 [00:00<00:02, 52.44it/s, Epoch: 67, Batch: 43,Loss: -1.992,Avg.Loss: -2.310,LR: 1.28E-04]Training epoch 67:  28%|██▊       | 43/153 [00:00<00:02, 52.44it/s, Epoch: 67, Batch: 44,Loss: -1.348,Avg.Loss: -2.289,LR: 1.28E-04]Training epoch 67:  29%|██▉       | 44/153 [00:00<00:02, 52.44it/s, Epoch: 67, Batch: 45,Loss: -2.680,Avg.Loss: -2.297,LR: 1.28E-04]Training epoch 67:  29%|██▉       | 45/153 [00:00<00:02, 52.44it/s, Epoch: 67, Batch: 46,Loss: -2.945,Avg.Loss: -2.311,LR: 1.27E-04]Training epoch 67:  30%|███       | 46/153 [00:00<00:02, 52.44it/s, Epoch: 67, Batch: 47,Loss: -2.154,Avg.Loss: -2.308,LR: 1.27E-04]Training epoch 67:  31%|███       | 47/153 [00:00<00:02, 52.44it/s, Epoch: 67, Batch: 48,Loss: -1.589,Avg.Loss: -2.293,LR: 1.27E-04]Training epoch 67:  31%|███▏      | 48/153 [00:00<00:01, 52.60it/s, Epoch: 67, Batch: 48,Loss: -1.589,Avg.Loss: -2.293,LR: 1.27E-04]Training epoch 67:  31%|███▏      | 48/153 [00:00<00:01, 52.60it/s, Epoch: 67, Batch: 49,Loss: -1.199,Avg.Loss: -2.271,LR: 1.27E-04]Training epoch 67:  32%|███▏      | 49/153 [00:00<00:01, 52.60it/s, Epoch: 67, Batch: 50,Loss: -2.546,Avg.Loss: -2.276,LR: 1.27E-04]Training epoch 67:  33%|███▎      | 50/153 [00:00<00:01, 52.60it/s, Epoch: 67, Batch: 51,Loss: -1.837,Avg.Loss: -2.268,LR: 1.27E-04]Training epoch 67:  33%|███▎      | 51/153 [00:00<00:01, 52.60it/s, Epoch: 67, Batch: 52,Loss: -2.308,Avg.Loss: -2.268,LR: 1.27E-04]Training epoch 67:  34%|███▍      | 52/153 [00:01<00:01, 52.60it/s, Epoch: 67, Batch: 53,Loss: -1.984,Avg.Loss: -2.263,LR: 1.27E-04]Training epoch 67:  35%|███▍      | 53/153 [00:01<00:01, 52.60it/s, Epoch: 67, Batch: 54,Loss: -2.598,Avg.Loss: -2.269,LR: 1.27E-04]Training epoch 67:  35%|███▌      | 54/153 [00:01<00:01, 52.85it/s, Epoch: 67, Batch: 54,Loss: -2.598,Avg.Loss: -2.269,LR: 1.27E-04]Training epoch 67:  35%|███▌      | 54/153 [00:01<00:01, 52.85it/s, Epoch: 67, Batch: 55,Loss: -2.485,Avg.Loss: -2.273,LR: 1.27E-04]Training epoch 67:  36%|███▌      | 55/153 [00:01<00:01, 52.85it/s, Epoch: 67, Batch: 56,Loss: -2.196,Avg.Loss: -2.272,LR: 1.27E-04]Training epoch 67:  37%|███▋      | 56/153 [00:01<00:01, 52.85it/s, Epoch: 67, Batch: 57,Loss: -1.715,Avg.Loss: -2.262,LR: 1.27E-04]Training epoch 67:  37%|███▋      | 57/153 [00:01<00:01, 52.85it/s, Epoch: 67, Batch: 58,Loss: -1.322,Avg.Loss: -2.246,LR: 1.27E-04]Training epoch 67:  38%|███▊      | 58/153 [00:01<00:01, 52.85it/s, Epoch: 67, Batch: 59,Loss: -1.645,Avg.Loss: -2.236,LR: 1.27E-04]Training epoch 67:  39%|███▊      | 59/153 [00:01<00:01, 52.85it/s, Epoch: 67, Batch: 60,Loss: -1.833,Avg.Loss: -2.229,LR: 1.27E-04]Training epoch 67:  39%|███▉      | 60/153 [00:01<00:01, 52.82it/s, Epoch: 67, Batch: 60,Loss: -1.833,Avg.Loss: -2.229,LR: 1.27E-04]Training epoch 67:  39%|███▉      | 60/153 [00:01<00:01, 52.82it/s, Epoch: 67, Batch: 61,Loss: -2.333,Avg.Loss: -2.231,LR: 1.27E-04]Training epoch 67:  40%|███▉      | 61/153 [00:01<00:01, 52.82it/s, Epoch: 67, Batch: 62,Loss: -2.236,Avg.Loss: -2.231,LR: 1.27E-04]Training epoch 67:  41%|████      | 62/153 [00:01<00:01, 52.82it/s, Epoch: 67, Batch: 63,Loss: -1.905,Avg.Loss: -2.225,LR: 1.27E-04]Training epoch 67:  41%|████      | 63/153 [00:01<00:01, 52.82it/s, Epoch: 67, Batch: 64,Loss: -2.815,Avg.Loss: -2.235,LR: 1.27E-04]Training epoch 67:  42%|████▏     | 64/153 [00:01<00:01, 52.82it/s, Epoch: 67, Batch: 65,Loss: -2.877,Avg.Loss: -2.245,LR: 1.27E-04]Training epoch 67:  42%|████▏     | 65/153 [00:01<00:01, 52.82it/s, Epoch: 67, Batch: 66,Loss: -2.728,Avg.Loss: -2.252,LR: 1.27E-04]Training epoch 67:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 67, Batch: 66,Loss: -2.728,Avg.Loss: -2.252,LR: 1.27E-04]Training epoch 67:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 67, Batch: 67,Loss: -2.720,Avg.Loss: -2.259,LR: 1.27E-04]Training epoch 67:  44%|████▍     | 67/153 [00:01<00:01, 52.84it/s, Epoch: 67, Batch: 68,Loss: -2.966,Avg.Loss: -2.269,LR: 1.27E-04]Training epoch 67:  44%|████▍     | 68/153 [00:01<00:01, 52.84it/s, Epoch: 67, Batch: 69,Loss: -3.294,Avg.Loss: -2.284,LR: 1.26E-04]Training epoch 67:  45%|████▌     | 69/153 [00:01<00:01, 52.84it/s, Epoch: 67, Batch: 70,Loss: -3.002,Avg.Loss: -2.294,LR: 1.26E-04]Training epoch 67:  46%|████▌     | 70/153 [00:01<00:01, 52.84it/s, Epoch: 67, Batch: 71,Loss: -2.894,Avg.Loss: -2.303,LR: 1.26E-04]Training epoch 67:  46%|████▋     | 71/153 [00:01<00:01, 52.84it/s, Epoch: 67, Batch: 72,Loss: -2.827,Avg.Loss: -2.310,LR: 1.26E-04]Training epoch 67:  47%|████▋     | 72/153 [00:01<00:01, 52.78it/s, Epoch: 67, Batch: 72,Loss: -2.827,Avg.Loss: -2.310,LR: 1.26E-04]Training epoch 67:  47%|████▋     | 72/153 [00:01<00:01, 52.78it/s, Epoch: 67, Batch: 73,Loss: -2.964,Avg.Loss: -2.319,LR: 1.26E-04]Training epoch 67:  48%|████▊     | 73/153 [00:01<00:01, 52.78it/s, Epoch: 67, Batch: 74,Loss: -2.447,Avg.Loss: -2.321,LR: 1.26E-04]Training epoch 67:  48%|████▊     | 74/153 [00:01<00:01, 52.78it/s, Epoch: 67, Batch: 75,Loss: -2.927,Avg.Loss: -2.329,LR: 1.26E-04]Training epoch 67:  49%|████▉     | 75/153 [00:01<00:01, 52.78it/s, Epoch: 67, Batch: 76,Loss: -2.487,Avg.Loss: -2.331,LR: 1.26E-04]Training epoch 67:  50%|████▉     | 76/153 [00:01<00:01, 52.78it/s, Epoch: 67, Batch: 77,Loss: -2.971,Avg.Loss: -2.339,LR: 1.26E-04]Training epoch 67:  50%|█████     | 77/153 [00:01<00:01, 52.78it/s, Epoch: 67, Batch: 78,Loss: -2.046,Avg.Loss: -2.335,LR: 1.26E-04]Training epoch 67:  51%|█████     | 78/153 [00:01<00:01, 52.92it/s, Epoch: 67, Batch: 78,Loss: -2.046,Avg.Loss: -2.335,LR: 1.26E-04]Training epoch 67:  51%|█████     | 78/153 [00:01<00:01, 52.92it/s, Epoch: 67, Batch: 79,Loss: -2.531,Avg.Loss: -2.338,LR: 1.26E-04]Training epoch 67:  52%|█████▏    | 79/153 [00:01<00:01, 52.92it/s, Epoch: 67, Batch: 80,Loss: -2.530,Avg.Loss: -2.340,LR: 1.26E-04]Training epoch 67:  52%|█████▏    | 80/153 [00:01<00:01, 52.92it/s, Epoch: 67, Batch: 81,Loss: -2.577,Avg.Loss: -2.343,LR: 1.26E-04]Training epoch 67:  53%|█████▎    | 81/153 [00:01<00:01, 52.92it/s, Epoch: 67, Batch: 82,Loss: -2.683,Avg.Loss: -2.347,LR: 1.26E-04]Training epoch 67:  54%|█████▎    | 82/153 [00:01<00:01, 52.92it/s, Epoch: 67, Batch: 83,Loss: -2.719,Avg.Loss: -2.352,LR: 1.26E-04]Training epoch 67:  54%|█████▍    | 83/153 [00:01<00:01, 52.92it/s, Epoch: 67, Batch: 84,Loss: -2.794,Avg.Loss: -2.357,LR: 1.26E-04]Training epoch 67:  55%|█████▍    | 84/153 [00:01<00:01, 53.11it/s, Epoch: 67, Batch: 84,Loss: -2.794,Avg.Loss: -2.357,LR: 1.26E-04]Training epoch 67:  55%|█████▍    | 84/153 [00:01<00:01, 53.11it/s, Epoch: 67, Batch: 85,Loss: -1.908,Avg.Loss: -2.352,LR: 1.26E-04]Training epoch 67:  56%|█████▌    | 85/153 [00:01<00:01, 53.11it/s, Epoch: 67, Batch: 86,Loss: -2.296,Avg.Loss: -2.351,LR: 1.26E-04]Training epoch 67:  56%|█████▌    | 86/153 [00:01<00:01, 53.11it/s, Epoch: 67, Batch: 87,Loss: -2.339,Avg.Loss: -2.351,LR: 1.26E-04]Training epoch 67:  57%|█████▋    | 87/153 [00:01<00:01, 53.11it/s, Epoch: 67, Batch: 88,Loss: -2.123,Avg.Loss: -2.348,LR: 1.26E-04]Training epoch 67:  58%|█████▊    | 88/153 [00:01<00:01, 53.11it/s, Epoch: 67, Batch: 89,Loss: -2.426,Avg.Loss: -2.349,LR: 1.26E-04]Training epoch 67:  58%|█████▊    | 89/153 [00:01<00:01, 53.11it/s, Epoch: 67, Batch: 90,Loss: -2.638,Avg.Loss: -2.353,LR: 1.26E-04]Training epoch 67:  59%|█████▉    | 90/153 [00:01<00:01, 53.08it/s, Epoch: 67, Batch: 90,Loss: -2.638,Avg.Loss: -2.353,LR: 1.26E-04]Training epoch 67:  59%|█████▉    | 90/153 [00:01<00:01, 53.08it/s, Epoch: 67, Batch: 91,Loss: -2.594,Avg.Loss: -2.355,LR: 1.25E-04]Training epoch 67:  59%|█████▉    | 91/153 [00:01<00:01, 53.08it/s, Epoch: 67, Batch: 92,Loss: -2.766,Avg.Loss: -2.360,LR: 1.25E-04]Training epoch 67:  60%|██████    | 92/153 [00:01<00:01, 53.08it/s, Epoch: 67, Batch: 93,Loss: -2.610,Avg.Loss: -2.362,LR: 1.25E-04]Training epoch 67:  61%|██████    | 93/153 [00:01<00:01, 53.08it/s, Epoch: 67, Batch: 94,Loss: -2.949,Avg.Loss: -2.369,LR: 1.25E-04]Training epoch 67:  61%|██████▏   | 94/153 [00:01<00:01, 53.08it/s, Epoch: 67, Batch: 95,Loss: -2.761,Avg.Loss: -2.373,LR: 1.25E-04]Training epoch 67:  62%|██████▏   | 95/153 [00:01<00:01, 53.08it/s, Epoch: 67, Batch: 96,Loss: -2.845,Avg.Loss: -2.378,LR: 1.25E-04]Training epoch 67:  63%|██████▎   | 96/153 [00:01<00:01, 53.37it/s, Epoch: 67, Batch: 96,Loss: -2.845,Avg.Loss: -2.378,LR: 1.25E-04]Training epoch 67:  63%|██████▎   | 96/153 [00:01<00:01, 53.37it/s, Epoch: 67, Batch: 97,Loss: -2.500,Avg.Loss: -2.379,LR: 1.25E-04]Training epoch 67:  63%|██████▎   | 97/153 [00:01<00:01, 53.37it/s, Epoch: 67, Batch: 98,Loss: -2.528,Avg.Loss: -2.380,LR: 1.25E-04]Training epoch 67:  64%|██████▍   | 98/153 [00:01<00:01, 53.37it/s, Epoch: 67, Batch: 99,Loss: -2.648,Avg.Loss: -2.383,LR: 1.25E-04]Training epoch 67:  65%|██████▍   | 99/153 [00:01<00:01, 53.37it/s, Epoch: 67, Batch: 100,Loss: -2.553,Avg.Loss: -2.385,LR: 1.25E-04]Training epoch 67:  65%|██████▌   | 100/153 [00:01<00:00, 53.37it/s, Epoch: 67, Batch: 101,Loss: -2.698,Avg.Loss: -2.388,LR: 1.25E-04]Training epoch 67:  66%|██████▌   | 101/153 [00:01<00:00, 53.37it/s, Epoch: 67, Batch: 102,Loss: -3.067,Avg.Loss: -2.395,LR: 1.25E-04]Training epoch 67:  67%|██████▋   | 102/153 [00:01<00:00, 52.98it/s, Epoch: 67, Batch: 102,Loss: -3.067,Avg.Loss: -2.395,LR: 1.25E-04]Training epoch 67:  67%|██████▋   | 102/153 [00:01<00:00, 52.98it/s, Epoch: 67, Batch: 103,Loss: -2.077,Avg.Loss: -2.392,LR: 1.25E-04]Training epoch 67:  67%|██████▋   | 103/153 [00:01<00:00, 52.98it/s, Epoch: 67, Batch: 104,Loss: -2.417,Avg.Loss: -2.392,LR: 1.25E-04]Training epoch 67:  68%|██████▊   | 104/153 [00:01<00:00, 52.98it/s, Epoch: 67, Batch: 105,Loss: -2.531,Avg.Loss: -2.393,LR: 1.25E-04]Training epoch 67:  69%|██████▊   | 105/153 [00:02<00:00, 52.98it/s, Epoch: 67, Batch: 106,Loss: -2.831,Avg.Loss: -2.397,LR: 1.25E-04]Training epoch 67:  69%|██████▉   | 106/153 [00:02<00:00, 52.98it/s, Epoch: 67, Batch: 107,Loss: -2.903,Avg.Loss: -2.402,LR: 1.25E-04]Training epoch 67:  70%|██████▉   | 107/153 [00:02<00:00, 52.98it/s, Epoch: 67, Batch: 108,Loss: -2.144,Avg.Loss: -2.400,LR: 1.25E-04]Training epoch 67:  71%|███████   | 108/153 [00:02<00:00, 52.91it/s, Epoch: 67, Batch: 108,Loss: -2.144,Avg.Loss: -2.400,LR: 1.25E-04]Training epoch 67:  71%|███████   | 108/153 [00:02<00:00, 52.91it/s, Epoch: 67, Batch: 109,Loss: -2.732,Avg.Loss: -2.403,LR: 1.25E-04]Training epoch 67:  71%|███████   | 109/153 [00:02<00:00, 52.91it/s, Epoch: 67, Batch: 110,Loss: -2.581,Avg.Loss: -2.404,LR: 1.25E-04]Training epoch 67:  72%|███████▏  | 110/153 [00:02<00:00, 52.91it/s, Epoch: 67, Batch: 111,Loss: -2.386,Avg.Loss: -2.404,LR: 1.25E-04]Training epoch 67:  73%|███████▎  | 111/153 [00:02<00:00, 52.91it/s, Epoch: 67, Batch: 112,Loss: -2.044,Avg.Loss: -2.401,LR: 1.25E-04]Training epoch 67:  73%|███████▎  | 112/153 [00:02<00:00, 52.91it/s, Epoch: 67, Batch: 113,Loss: -2.298,Avg.Loss: -2.400,LR: 1.25E-04]Training epoch 67:  74%|███████▍  | 113/153 [00:02<00:00, 52.91it/s, Epoch: 67, Batch: 114,Loss: -2.619,Avg.Loss: -2.402,LR: 1.24E-04]Training epoch 67:  75%|███████▍  | 114/153 [00:02<00:00, 53.11it/s, Epoch: 67, Batch: 114,Loss: -2.619,Avg.Loss: -2.402,LR: 1.24E-04]Training epoch 67:  75%|███████▍  | 114/153 [00:02<00:00, 53.11it/s, Epoch: 67, Batch: 115,Loss: -2.908,Avg.Loss: -2.406,LR: 1.24E-04]Training epoch 67:  75%|███████▌  | 115/153 [00:02<00:00, 53.11it/s, Epoch: 67, Batch: 116,Loss: -2.632,Avg.Loss: -2.408,LR: 1.24E-04]Training epoch 67:  76%|███████▌  | 116/153 [00:02<00:00, 53.11it/s, Epoch: 67, Batch: 117,Loss: -2.399,Avg.Loss: -2.408,LR: 1.24E-04]Training epoch 67:  76%|███████▋  | 117/153 [00:02<00:00, 53.11it/s, Epoch: 67, Batch: 118,Loss: -3.044,Avg.Loss: -2.414,LR: 1.24E-04]Training epoch 67:  77%|███████▋  | 118/153 [00:02<00:00, 53.11it/s, Epoch: 67, Batch: 119,Loss: -3.275,Avg.Loss: -2.421,LR: 1.24E-04]Training epoch 67:  78%|███████▊  | 119/153 [00:02<00:00, 53.11it/s, Epoch: 67, Batch: 120,Loss: -2.739,Avg.Loss: -2.423,LR: 1.24E-04]Training epoch 67:  78%|███████▊  | 120/153 [00:02<00:00, 53.19it/s, Epoch: 67, Batch: 120,Loss: -2.739,Avg.Loss: -2.423,LR: 1.24E-04]Training epoch 67:  78%|███████▊  | 120/153 [00:02<00:00, 53.19it/s, Epoch: 67, Batch: 121,Loss: -2.699,Avg.Loss: -2.426,LR: 1.24E-04]Training epoch 67:  79%|███████▉  | 121/153 [00:02<00:00, 53.19it/s, Epoch: 67, Batch: 122,Loss: -2.642,Avg.Loss: -2.427,LR: 1.24E-04]Training epoch 67:  80%|███████▉  | 122/153 [00:02<00:00, 53.19it/s, Epoch: 67, Batch: 123,Loss: -2.914,Avg.Loss: -2.431,LR: 1.24E-04]Training epoch 67:  80%|████████  | 123/153 [00:02<00:00, 53.19it/s, Epoch: 67, Batch: 124,Loss: -2.614,Avg.Loss: -2.433,LR: 1.24E-04]Training epoch 67:  81%|████████  | 124/153 [00:02<00:00, 53.19it/s, Epoch: 67, Batch: 125,Loss: -2.747,Avg.Loss: -2.435,LR: 1.24E-04]Training epoch 67:  82%|████████▏ | 125/153 [00:02<00:00, 53.19it/s, Epoch: 67, Batch: 126,Loss: -2.955,Avg.Loss: -2.440,LR: 1.24E-04]Training epoch 67:  82%|████████▏ | 126/153 [00:02<00:00, 53.45it/s, Epoch: 67, Batch: 126,Loss: -2.955,Avg.Loss: -2.440,LR: 1.24E-04]Training epoch 67:  82%|████████▏ | 126/153 [00:02<00:00, 53.45it/s, Epoch: 67, Batch: 127,Loss: -2.972,Avg.Loss: -2.444,LR: 1.24E-04]Training epoch 67:  83%|████████▎ | 127/153 [00:02<00:00, 53.45it/s, Epoch: 67, Batch: 128,Loss: -2.291,Avg.Loss: -2.443,LR: 1.24E-04]Training epoch 67:  84%|████████▎ | 128/153 [00:02<00:00, 53.45it/s, Epoch: 67, Batch: 129,Loss: -2.739,Avg.Loss: -2.445,LR: 1.24E-04]Training epoch 67:  84%|████████▍ | 129/153 [00:02<00:00, 53.45it/s, Epoch: 67, Batch: 130,Loss: -2.797,Avg.Loss: -2.448,LR: 1.24E-04]Training epoch 67:  85%|████████▍ | 130/153 [00:02<00:00, 53.45it/s, Epoch: 67, Batch: 131,Loss: -2.654,Avg.Loss: -2.449,LR: 1.24E-04]Training epoch 67:  86%|████████▌ | 131/153 [00:02<00:00, 53.45it/s, Epoch: 67, Batch: 132,Loss: -2.720,Avg.Loss: -2.451,LR: 1.24E-04]Training epoch 67:  86%|████████▋ | 132/153 [00:02<00:00, 53.06it/s, Epoch: 67, Batch: 132,Loss: -2.720,Avg.Loss: -2.451,LR: 1.24E-04]Training epoch 67:  86%|████████▋ | 132/153 [00:02<00:00, 53.06it/s, Epoch: 67, Batch: 133,Loss: -2.411,Avg.Loss: -2.451,LR: 1.24E-04]Training epoch 67:  87%|████████▋ | 133/153 [00:02<00:00, 53.06it/s, Epoch: 67, Batch: 134,Loss: -3.252,Avg.Loss: -2.457,LR: 1.24E-04]Training epoch 67:  88%|████████▊ | 134/153 [00:02<00:00, 53.06it/s, Epoch: 67, Batch: 135,Loss: -3.135,Avg.Loss: -2.462,LR: 1.24E-04]Training epoch 67:  88%|████████▊ | 135/153 [00:02<00:00, 53.06it/s, Epoch: 67, Batch: 136,Loss: -2.761,Avg.Loss: -2.464,LR: 1.23E-04]Training epoch 67:  89%|████████▉ | 136/153 [00:02<00:00, 53.06it/s, Epoch: 67, Batch: 137,Loss: -2.339,Avg.Loss: -2.463,LR: 1.23E-04]Training epoch 67:  90%|████████▉ | 137/153 [00:02<00:00, 53.06it/s, Epoch: 67, Batch: 138,Loss: -2.904,Avg.Loss: -2.466,LR: 1.23E-04]Training epoch 67:  90%|█████████ | 138/153 [00:02<00:00, 53.08it/s, Epoch: 67, Batch: 138,Loss: -2.904,Avg.Loss: -2.466,LR: 1.23E-04]Training epoch 67:  90%|█████████ | 138/153 [00:02<00:00, 53.08it/s, Epoch: 67, Batch: 139,Loss: -2.435,Avg.Loss: -2.466,LR: 1.23E-04]Training epoch 67:  91%|█████████ | 139/153 [00:02<00:00, 53.08it/s, Epoch: 67, Batch: 140,Loss: -3.043,Avg.Loss: -2.470,LR: 1.23E-04]Training epoch 67:  92%|█████████▏| 140/153 [00:02<00:00, 53.08it/s, Epoch: 67, Batch: 141,Loss: -2.533,Avg.Loss: -2.471,LR: 1.23E-04]Training epoch 67:  92%|█████████▏| 141/153 [00:02<00:00, 53.08it/s, Epoch: 67, Batch: 142,Loss: -3.159,Avg.Loss: -2.476,LR: 1.23E-04]Training epoch 67:  93%|█████████▎| 142/153 [00:02<00:00, 53.08it/s, Epoch: 67, Batch: 143,Loss: -3.133,Avg.Loss: -2.480,LR: 1.23E-04]Training epoch 67:  93%|█████████▎| 143/153 [00:02<00:00, 53.08it/s, Epoch: 67, Batch: 144,Loss: -2.540,Avg.Loss: -2.481,LR: 1.23E-04]Training epoch 67:  94%|█████████▍| 144/153 [00:02<00:00, 52.83it/s, Epoch: 67, Batch: 144,Loss: -2.540,Avg.Loss: -2.481,LR: 1.23E-04]Training epoch 67:  94%|█████████▍| 144/153 [00:02<00:00, 52.83it/s, Epoch: 67, Batch: 145,Loss: -2.711,Avg.Loss: -2.482,LR: 1.23E-04]Training epoch 67:  95%|█████████▍| 145/153 [00:02<00:00, 52.83it/s, Epoch: 67, Batch: 146,Loss: -2.287,Avg.Loss: -2.481,LR: 1.23E-04]Training epoch 67:  95%|█████████▌| 146/153 [00:02<00:00, 52.83it/s, Epoch: 67, Batch: 147,Loss: -3.227,Avg.Loss: -2.486,LR: 1.23E-04]Training epoch 67:  96%|█████████▌| 147/153 [00:02<00:00, 52.83it/s, Epoch: 67, Batch: 148,Loss: -2.506,Avg.Loss: -2.486,LR: 1.23E-04]Training epoch 67:  97%|█████████▋| 148/153 [00:02<00:00, 52.83it/s, Epoch: 67, Batch: 149,Loss: -3.150,Avg.Loss: -2.490,LR: 1.23E-04]Training epoch 67:  97%|█████████▋| 149/153 [00:02<00:00, 52.83it/s, Epoch: 67, Batch: 150,Loss: -3.101,Avg.Loss: -2.495,LR: 1.23E-04]Training epoch 67:  98%|█████████▊| 150/153 [00:02<00:00, 52.88it/s, Epoch: 67, Batch: 150,Loss: -3.101,Avg.Loss: -2.495,LR: 1.23E-04]Training epoch 67:  98%|█████████▊| 150/153 [00:02<00:00, 52.88it/s, Epoch: 67, Batch: 151,Loss: -2.600,Avg.Loss: -2.495,LR: 1.23E-04]Training epoch 67:  99%|█████████▊| 151/153 [00:02<00:00, 52.88it/s, Epoch: 67, Batch: 152,Loss: -2.715,Avg.Loss: -2.497,LR: 1.23E-04]Training epoch 67:  99%|█████████▉| 152/153 [00:02<00:00, 52.88it/s, Epoch: 67, Batch: 153,Loss: -2.665,Avg.Loss: -2.498,LR: 1.23E-04]Training epoch 67: 100%|██████████| 153/153 [00:02<00:00, 52.69it/s, Epoch: 67, Batch: 153,Loss: -2.665,Avg.Loss: -2.498,LR: 1.23E-04]
Training epoch 68:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 68:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 68, Batch: 1,Loss: -2.090,Avg.Loss: -2.090,LR: 1.23E-04]Training epoch 68:   1%|          | 1/153 [00:00<00:05, 27.71it/s, Epoch: 68, Batch: 2,Loss: -2.288,Avg.Loss: -2.189,LR: 1.23E-04]Training epoch 68:   1%|▏         | 2/153 [00:00<00:04, 36.72it/s, Epoch: 68, Batch: 3,Loss: -2.350,Avg.Loss: -2.242,LR: 1.23E-04]Training epoch 68:   2%|▏         | 3/153 [00:00<00:03, 42.06it/s, Epoch: 68, Batch: 4,Loss: -2.842,Avg.Loss: -2.392,LR: 1.23E-04]Training epoch 68:   3%|▎         | 4/153 [00:00<00:03, 44.65it/s, Epoch: 68, Batch: 5,Loss: -2.494,Avg.Loss: -2.413,LR: 1.23E-04]Training epoch 68:   3%|▎         | 5/153 [00:00<00:03, 46.74it/s, Epoch: 68, Batch: 6,Loss: -2.770,Avg.Loss: -2.472,LR: 1.22E-04]Training epoch 68:   4%|▍         | 6/153 [00:00<00:02, 56.01it/s, Epoch: 68, Batch: 6,Loss: -2.770,Avg.Loss: -2.472,LR: 1.22E-04]Training epoch 68:   4%|▍         | 6/153 [00:00<00:02, 56.01it/s, Epoch: 68, Batch: 7,Loss: -2.403,Avg.Loss: -2.462,LR: 1.22E-04]Training epoch 68:   5%|▍         | 7/153 [00:00<00:02, 56.01it/s, Epoch: 68, Batch: 8,Loss: -2.371,Avg.Loss: -2.451,LR: 1.22E-04]Training epoch 68:   5%|▌         | 8/153 [00:00<00:02, 56.01it/s, Epoch: 68, Batch: 9,Loss: -2.180,Avg.Loss: -2.421,LR: 1.22E-04]Training epoch 68:   6%|▌         | 9/153 [00:00<00:02, 56.01it/s, Epoch: 68, Batch: 10,Loss: -2.594,Avg.Loss: -2.438,LR: 1.22E-04]Training epoch 68:   7%|▋         | 10/153 [00:00<00:02, 56.01it/s, Epoch: 68, Batch: 11,Loss: -2.506,Avg.Loss: -2.444,LR: 1.22E-04]Training epoch 68:   7%|▋         | 11/153 [00:00<00:02, 56.01it/s, Epoch: 68, Batch: 12,Loss: -2.026,Avg.Loss: -2.409,LR: 1.22E-04]Training epoch 68:   8%|▊         | 12/153 [00:00<00:02, 54.05it/s, Epoch: 68, Batch: 12,Loss: -2.026,Avg.Loss: -2.409,LR: 1.22E-04]Training epoch 68:   8%|▊         | 12/153 [00:00<00:02, 54.05it/s, Epoch: 68, Batch: 13,Loss: -1.346,Avg.Loss: -2.328,LR: 1.22E-04]Training epoch 68:   8%|▊         | 13/153 [00:00<00:02, 54.05it/s, Epoch: 68, Batch: 14,Loss: -1.880,Avg.Loss: -2.296,LR: 1.22E-04]Training epoch 68:   9%|▉         | 14/153 [00:00<00:02, 54.05it/s, Epoch: 68, Batch: 15,Loss: -2.137,Avg.Loss: -2.285,LR: 1.22E-04]Training epoch 68:  10%|▉         | 15/153 [00:00<00:02, 54.05it/s, Epoch: 68, Batch: 16,Loss: -2.413,Avg.Loss: -2.293,LR: 1.22E-04]Training epoch 68:  10%|█         | 16/153 [00:00<00:02, 54.05it/s, Epoch: 68, Batch: 17,Loss: -2.396,Avg.Loss: -2.299,LR: 1.22E-04]Training epoch 68:  11%|█         | 17/153 [00:00<00:02, 54.05it/s, Epoch: 68, Batch: 18,Loss: -1.365,Avg.Loss: -2.247,LR: 1.22E-04]Training epoch 68:  12%|█▏        | 18/153 [00:00<00:02, 53.37it/s, Epoch: 68, Batch: 18,Loss: -1.365,Avg.Loss: -2.247,LR: 1.22E-04]Training epoch 68:  12%|█▏        | 18/153 [00:00<00:02, 53.37it/s, Epoch: 68, Batch: 19,Loss: -1.652,Avg.Loss: -2.216,LR: 1.22E-04]Training epoch 68:  12%|█▏        | 19/153 [00:00<00:02, 53.37it/s, Epoch: 68, Batch: 20,Loss: -2.428,Avg.Loss: -2.226,LR: 1.22E-04]Training epoch 68:  13%|█▎        | 20/153 [00:00<00:02, 53.37it/s, Epoch: 68, Batch: 21,Loss: -2.567,Avg.Loss: -2.243,LR: 1.22E-04]Training epoch 68:  14%|█▎        | 21/153 [00:00<00:02, 53.37it/s, Epoch: 68, Batch: 22,Loss: -2.829,Avg.Loss: -2.269,LR: 1.22E-04]Training epoch 68:  14%|█▍        | 22/153 [00:00<00:02, 53.37it/s, Epoch: 68, Batch: 23,Loss: -2.193,Avg.Loss: -2.266,LR: 1.22E-04]Training epoch 68:  15%|█▌        | 23/153 [00:00<00:02, 53.37it/s, Epoch: 68, Batch: 24,Loss: -2.391,Avg.Loss: -2.271,LR: 1.22E-04]Training epoch 68:  16%|█▌        | 24/153 [00:00<00:02, 52.28it/s, Epoch: 68, Batch: 24,Loss: -2.391,Avg.Loss: -2.271,LR: 1.22E-04]Training epoch 68:  16%|█▌        | 24/153 [00:00<00:02, 52.28it/s, Epoch: 68, Batch: 25,Loss: -2.621,Avg.Loss: -2.285,LR: 1.22E-04]Training epoch 68:  16%|█▋        | 25/153 [00:00<00:02, 52.28it/s, Epoch: 68, Batch: 26,Loss: -3.051,Avg.Loss: -2.315,LR: 1.22E-04]Training epoch 68:  17%|█▋        | 26/153 [00:00<00:02, 52.28it/s, Epoch: 68, Batch: 27,Loss: -2.501,Avg.Loss: -2.322,LR: 1.22E-04]Training epoch 68:  18%|█▊        | 27/153 [00:00<00:02, 52.28it/s, Epoch: 68, Batch: 28,Loss: -1.455,Avg.Loss: -2.291,LR: 1.22E-04]Training epoch 68:  18%|█▊        | 28/153 [00:00<00:02, 52.28it/s, Epoch: 68, Batch: 29,Loss: -1.611,Avg.Loss: -2.267,LR: 1.21E-04]Training epoch 68:  19%|█▉        | 29/153 [00:00<00:02, 52.28it/s, Epoch: 68, Batch: 30,Loss: -1.963,Avg.Loss: -2.257,LR: 1.21E-04]Training epoch 68:  20%|█▉        | 30/153 [00:00<00:02, 51.95it/s, Epoch: 68, Batch: 30,Loss: -1.963,Avg.Loss: -2.257,LR: 1.21E-04]Training epoch 68:  20%|█▉        | 30/153 [00:00<00:02, 51.95it/s, Epoch: 68, Batch: 31,Loss: -2.566,Avg.Loss: -2.267,LR: 1.21E-04]Training epoch 68:  20%|██        | 31/153 [00:00<00:02, 51.95it/s, Epoch: 68, Batch: 32,Loss: -2.651,Avg.Loss: -2.279,LR: 1.21E-04]Training epoch 68:  21%|██        | 32/153 [00:00<00:02, 51.95it/s, Epoch: 68, Batch: 33,Loss: -2.338,Avg.Loss: -2.281,LR: 1.21E-04]Training epoch 68:  22%|██▏       | 33/153 [00:00<00:02, 51.95it/s, Epoch: 68, Batch: 34,Loss: -2.201,Avg.Loss: -2.278,LR: 1.21E-04]Training epoch 68:  22%|██▏       | 34/153 [00:00<00:02, 51.95it/s, Epoch: 68, Batch: 35,Loss: -2.541,Avg.Loss: -2.286,LR: 1.21E-04]Training epoch 68:  23%|██▎       | 35/153 [00:00<00:02, 51.95it/s, Epoch: 68, Batch: 36,Loss: -2.347,Avg.Loss: -2.288,LR: 1.21E-04]Training epoch 68:  24%|██▎       | 36/153 [00:00<00:02, 52.31it/s, Epoch: 68, Batch: 36,Loss: -2.347,Avg.Loss: -2.288,LR: 1.21E-04]Training epoch 68:  24%|██▎       | 36/153 [00:00<00:02, 52.31it/s, Epoch: 68, Batch: 37,Loss: -2.891,Avg.Loss: -2.304,LR: 1.21E-04]Training epoch 68:  24%|██▍       | 37/153 [00:00<00:02, 52.31it/s, Epoch: 68, Batch: 38,Loss: -1.789,Avg.Loss: -2.290,LR: 1.21E-04]Training epoch 68:  25%|██▍       | 38/153 [00:00<00:02, 52.31it/s, Epoch: 68, Batch: 39,Loss: -2.026,Avg.Loss: -2.284,LR: 1.21E-04]Training epoch 68:  25%|██▌       | 39/153 [00:00<00:02, 52.31it/s, Epoch: 68, Batch: 40,Loss: -2.257,Avg.Loss: -2.283,LR: 1.21E-04]Training epoch 68:  26%|██▌       | 40/153 [00:00<00:02, 52.31it/s, Epoch: 68, Batch: 41,Loss: -2.950,Avg.Loss: -2.299,LR: 1.21E-04]Training epoch 68:  27%|██▋       | 41/153 [00:00<00:02, 52.31it/s, Epoch: 68, Batch: 42,Loss: -2.805,Avg.Loss: -2.311,LR: 1.21E-04]Training epoch 68:  27%|██▋       | 42/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 42,Loss: -2.805,Avg.Loss: -2.311,LR: 1.21E-04]Training epoch 68:  27%|██▋       | 42/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 43,Loss: -2.114,Avg.Loss: -2.307,LR: 1.21E-04]Training epoch 68:  28%|██▊       | 43/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 44,Loss: -2.022,Avg.Loss: -2.300,LR: 1.21E-04]Training epoch 68:  29%|██▉       | 44/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 45,Loss: -2.492,Avg.Loss: -2.304,LR: 1.21E-04]Training epoch 68:  29%|██▉       | 45/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 46,Loss: -2.513,Avg.Loss: -2.309,LR: 1.21E-04]Training epoch 68:  30%|███       | 46/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 47,Loss: -2.890,Avg.Loss: -2.321,LR: 1.21E-04]Training epoch 68:  31%|███       | 47/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 48,Loss: -2.143,Avg.Loss: -2.318,LR: 1.21E-04]Training epoch 68:  31%|███▏      | 48/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 48,Loss: -2.143,Avg.Loss: -2.318,LR: 1.21E-04]Training epoch 68:  31%|███▏      | 48/153 [00:00<00:02, 52.43it/s, Epoch: 68, Batch: 49,Loss: -1.955,Avg.Loss: -2.310,LR: 1.21E-04]Training epoch 68:  32%|███▏      | 49/153 [00:00<00:01, 52.43it/s, Epoch: 68, Batch: 50,Loss: -2.432,Avg.Loss: -2.313,LR: 1.21E-04]Training epoch 68:  33%|███▎      | 50/153 [00:00<00:01, 52.43it/s, Epoch: 68, Batch: 51,Loss: -2.844,Avg.Loss: -2.323,LR: 1.20E-04]Training epoch 68:  33%|███▎      | 51/153 [00:00<00:01, 52.43it/s, Epoch: 68, Batch: 52,Loss: -2.093,Avg.Loss: -2.319,LR: 1.20E-04]Training epoch 68:  34%|███▍      | 52/153 [00:01<00:01, 52.43it/s, Epoch: 68, Batch: 53,Loss: -1.532,Avg.Loss: -2.304,LR: 1.20E-04]Training epoch 68:  35%|███▍      | 53/153 [00:01<00:01, 52.43it/s, Epoch: 68, Batch: 54,Loss: -1.605,Avg.Loss: -2.291,LR: 1.20E-04]Training epoch 68:  35%|███▌      | 54/153 [00:01<00:01, 51.98it/s, Epoch: 68, Batch: 54,Loss: -1.605,Avg.Loss: -2.291,LR: 1.20E-04]Training epoch 68:  35%|███▌      | 54/153 [00:01<00:01, 51.98it/s, Epoch: 68, Batch: 55,Loss: -2.275,Avg.Loss: -2.291,LR: 1.20E-04]Training epoch 68:  36%|███▌      | 55/153 [00:01<00:01, 51.98it/s, Epoch: 68, Batch: 56,Loss: -3.014,Avg.Loss: -2.304,LR: 1.20E-04]Training epoch 68:  37%|███▋      | 56/153 [00:01<00:01, 51.98it/s, Epoch: 68, Batch: 57,Loss: -2.866,Avg.Loss: -2.313,LR: 1.20E-04]Training epoch 68:  37%|███▋      | 57/153 [00:01<00:01, 51.98it/s, Epoch: 68, Batch: 58,Loss: -2.418,Avg.Loss: -2.315,LR: 1.20E-04]Training epoch 68:  38%|███▊      | 58/153 [00:01<00:01, 51.98it/s, Epoch: 68, Batch: 59,Loss: -2.526,Avg.Loss: -2.319,LR: 1.20E-04]Training epoch 68:  39%|███▊      | 59/153 [00:01<00:01, 51.98it/s, Epoch: 68, Batch: 60,Loss: -2.151,Avg.Loss: -2.316,LR: 1.20E-04]Training epoch 68:  39%|███▉      | 60/153 [00:01<00:01, 52.11it/s, Epoch: 68, Batch: 60,Loss: -2.151,Avg.Loss: -2.316,LR: 1.20E-04]Training epoch 68:  39%|███▉      | 60/153 [00:01<00:01, 52.11it/s, Epoch: 68, Batch: 61,Loss: -3.033,Avg.Loss: -2.328,LR: 1.20E-04]Training epoch 68:  40%|███▉      | 61/153 [00:01<00:01, 52.11it/s, Epoch: 68, Batch: 62,Loss: -2.916,Avg.Loss: -2.337,LR: 1.20E-04]Training epoch 68:  41%|████      | 62/153 [00:01<00:01, 52.11it/s, Epoch: 68, Batch: 63,Loss: -2.333,Avg.Loss: -2.337,LR: 1.20E-04]Training epoch 68:  41%|████      | 63/153 [00:01<00:01, 52.11it/s, Epoch: 68, Batch: 64,Loss: -2.042,Avg.Loss: -2.333,LR: 1.20E-04]Training epoch 68:  42%|████▏     | 64/153 [00:01<00:01, 52.11it/s, Epoch: 68, Batch: 65,Loss: -2.549,Avg.Loss: -2.336,LR: 1.20E-04]Training epoch 68:  42%|████▏     | 65/153 [00:01<00:01, 52.11it/s, Epoch: 68, Batch: 66,Loss: -2.532,Avg.Loss: -2.339,LR: 1.20E-04]Training epoch 68:  43%|████▎     | 66/153 [00:01<00:01, 52.22it/s, Epoch: 68, Batch: 66,Loss: -2.532,Avg.Loss: -2.339,LR: 1.20E-04]Training epoch 68:  43%|████▎     | 66/153 [00:01<00:01, 52.22it/s, Epoch: 68, Batch: 67,Loss: -2.199,Avg.Loss: -2.337,LR: 1.20E-04]Training epoch 68:  44%|████▍     | 67/153 [00:01<00:01, 52.22it/s, Epoch: 68, Batch: 68,Loss: -2.148,Avg.Loss: -2.334,LR: 1.20E-04]Training epoch 68:  44%|████▍     | 68/153 [00:01<00:01, 52.22it/s, Epoch: 68, Batch: 69,Loss: -2.384,Avg.Loss: -2.335,LR: 1.20E-04]Training epoch 68:  45%|████▌     | 69/153 [00:01<00:01, 52.22it/s, Epoch: 68, Batch: 70,Loss: -2.591,Avg.Loss: -2.338,LR: 1.20E-04]Training epoch 68:  46%|████▌     | 70/153 [00:01<00:01, 52.22it/s, Epoch: 68, Batch: 71,Loss: -2.552,Avg.Loss: -2.341,LR: 1.20E-04]Training epoch 68:  46%|████▋     | 71/153 [00:01<00:01, 52.22it/s, Epoch: 68, Batch: 72,Loss: -2.467,Avg.Loss: -2.343,LR: 1.20E-04]Training epoch 68:  47%|████▋     | 72/153 [00:01<00:01, 52.02it/s, Epoch: 68, Batch: 72,Loss: -2.467,Avg.Loss: -2.343,LR: 1.20E-04]Training epoch 68:  47%|████▋     | 72/153 [00:01<00:01, 52.02it/s, Epoch: 68, Batch: 73,Loss: -2.687,Avg.Loss: -2.348,LR: 1.20E-04]Training epoch 68:  48%|████▊     | 73/153 [00:01<00:01, 52.02it/s, Epoch: 68, Batch: 74,Loss: -2.604,Avg.Loss: -2.351,LR: 1.19E-04]Training epoch 68:  48%|████▊     | 74/153 [00:01<00:01, 52.02it/s, Epoch: 68, Batch: 75,Loss: -2.270,Avg.Loss: -2.350,LR: 1.19E-04]Training epoch 68:  49%|████▉     | 75/153 [00:01<00:01, 52.02it/s, Epoch: 68, Batch: 76,Loss: -2.991,Avg.Loss: -2.359,LR: 1.19E-04]Training epoch 68:  50%|████▉     | 76/153 [00:01<00:01, 52.02it/s, Epoch: 68, Batch: 77,Loss: -2.542,Avg.Loss: -2.361,LR: 1.19E-04]Training epoch 68:  50%|█████     | 77/153 [00:01<00:01, 52.02it/s, Epoch: 68, Batch: 78,Loss: -2.801,Avg.Loss: -2.367,LR: 1.19E-04]Training epoch 68:  51%|█████     | 78/153 [00:01<00:01, 52.28it/s, Epoch: 68, Batch: 78,Loss: -2.801,Avg.Loss: -2.367,LR: 1.19E-04]Training epoch 68:  51%|█████     | 78/153 [00:01<00:01, 52.28it/s, Epoch: 68, Batch: 79,Loss: -2.514,Avg.Loss: -2.369,LR: 1.19E-04]Training epoch 68:  52%|█████▏    | 79/153 [00:01<00:01, 52.28it/s, Epoch: 68, Batch: 80,Loss: -2.813,Avg.Loss: -2.374,LR: 1.19E-04]Training epoch 68:  52%|█████▏    | 80/153 [00:01<00:01, 52.28it/s, Epoch: 68, Batch: 81,Loss: -2.456,Avg.Loss: -2.375,LR: 1.19E-04]Training epoch 68:  53%|█████▎    | 81/153 [00:01<00:01, 52.28it/s, Epoch: 68, Batch: 82,Loss: -2.257,Avg.Loss: -2.374,LR: 1.19E-04]Training epoch 68:  54%|█████▎    | 82/153 [00:01<00:01, 52.28it/s, Epoch: 68, Batch: 83,Loss: -2.801,Avg.Loss: -2.379,LR: 1.19E-04]Training epoch 68:  54%|█████▍    | 83/153 [00:01<00:01, 52.28it/s, Epoch: 68, Batch: 84,Loss: -2.958,Avg.Loss: -2.386,LR: 1.19E-04]Training epoch 68:  55%|█████▍    | 84/153 [00:01<00:01, 52.29it/s, Epoch: 68, Batch: 84,Loss: -2.958,Avg.Loss: -2.386,LR: 1.19E-04]Training epoch 68:  55%|█████▍    | 84/153 [00:01<00:01, 52.29it/s, Epoch: 68, Batch: 85,Loss: -2.877,Avg.Loss: -2.392,LR: 1.19E-04]Training epoch 68:  56%|█████▌    | 85/153 [00:01<00:01, 52.29it/s, Epoch: 68, Batch: 86,Loss: -2.599,Avg.Loss: -2.394,LR: 1.19E-04]Training epoch 68:  56%|█████▌    | 86/153 [00:01<00:01, 52.29it/s, Epoch: 68, Batch: 87,Loss: -2.246,Avg.Loss: -2.392,LR: 1.19E-04]Training epoch 68:  57%|█████▋    | 87/153 [00:01<00:01, 52.29it/s, Epoch: 68, Batch: 88,Loss: -2.864,Avg.Loss: -2.398,LR: 1.19E-04]Training epoch 68:  58%|█████▊    | 88/153 [00:01<00:01, 52.29it/s, Epoch: 68, Batch: 89,Loss: -2.897,Avg.Loss: -2.403,LR: 1.19E-04]Training epoch 68:  58%|█████▊    | 89/153 [00:01<00:01, 52.29it/s, Epoch: 68, Batch: 90,Loss: -2.477,Avg.Loss: -2.404,LR: 1.19E-04]Training epoch 68:  59%|█████▉    | 90/153 [00:01<00:01, 52.64it/s, Epoch: 68, Batch: 90,Loss: -2.477,Avg.Loss: -2.404,LR: 1.19E-04]Training epoch 68:  59%|█████▉    | 90/153 [00:01<00:01, 52.64it/s, Epoch: 68, Batch: 91,Loss: -2.265,Avg.Loss: -2.402,LR: 1.19E-04]Training epoch 68:  59%|█████▉    | 91/153 [00:01<00:01, 52.64it/s, Epoch: 68, Batch: 92,Loss: -1.863,Avg.Loss: -2.397,LR: 1.19E-04]Training epoch 68:  60%|██████    | 92/153 [00:01<00:01, 52.64it/s, Epoch: 68, Batch: 93,Loss: -2.395,Avg.Loss: -2.397,LR: 1.19E-04]Training epoch 68:  61%|██████    | 93/153 [00:01<00:01, 52.64it/s, Epoch: 68, Batch: 94,Loss: -2.829,Avg.Loss: -2.401,LR: 1.19E-04]Training epoch 68:  61%|██████▏   | 94/153 [00:01<00:01, 52.64it/s, Epoch: 68, Batch: 95,Loss: -2.935,Avg.Loss: -2.407,LR: 1.19E-04]Training epoch 68:  62%|██████▏   | 95/153 [00:01<00:01, 52.64it/s, Epoch: 68, Batch: 96,Loss: -2.992,Avg.Loss: -2.413,LR: 1.19E-04]Training epoch 68:  63%|██████▎   | 96/153 [00:01<00:01, 52.57it/s, Epoch: 68, Batch: 96,Loss: -2.992,Avg.Loss: -2.413,LR: 1.19E-04]Training epoch 68:  63%|██████▎   | 96/153 [00:01<00:01, 52.57it/s, Epoch: 68, Batch: 97,Loss: -2.860,Avg.Loss: -2.418,LR: 1.18E-04]Training epoch 68:  63%|██████▎   | 97/153 [00:01<00:01, 52.57it/s, Epoch: 68, Batch: 98,Loss: -2.913,Avg.Loss: -2.423,LR: 1.18E-04]Training epoch 68:  64%|██████▍   | 98/153 [00:01<00:01, 52.57it/s, Epoch: 68, Batch: 99,Loss: -3.097,Avg.Loss: -2.429,LR: 1.18E-04]Training epoch 68:  65%|██████▍   | 99/153 [00:01<00:01, 52.57it/s, Epoch: 68, Batch: 100,Loss: -3.336,Avg.Loss: -2.438,LR: 1.18E-04]Training epoch 68:  65%|██████▌   | 100/153 [00:01<00:01, 52.57it/s, Epoch: 68, Batch: 101,Loss: -2.891,Avg.Loss: -2.443,LR: 1.18E-04]Training epoch 68:  66%|██████▌   | 101/153 [00:01<00:00, 52.57it/s, Epoch: 68, Batch: 102,Loss: -2.710,Avg.Loss: -2.446,LR: 1.18E-04]Training epoch 68:  67%|██████▋   | 102/153 [00:01<00:00, 52.60it/s, Epoch: 68, Batch: 102,Loss: -2.710,Avg.Loss: -2.446,LR: 1.18E-04]Training epoch 68:  67%|██████▋   | 102/153 [00:01<00:00, 52.60it/s, Epoch: 68, Batch: 103,Loss: -2.942,Avg.Loss: -2.450,LR: 1.18E-04]Training epoch 68:  67%|██████▋   | 103/153 [00:01<00:00, 52.60it/s, Epoch: 68, Batch: 104,Loss: -2.355,Avg.Loss: -2.449,LR: 1.18E-04]Training epoch 68:  68%|██████▊   | 104/153 [00:01<00:00, 52.60it/s, Epoch: 68, Batch: 105,Loss: -2.778,Avg.Loss: -2.453,LR: 1.18E-04]Training epoch 68:  69%|██████▊   | 105/153 [00:02<00:00, 52.60it/s, Epoch: 68, Batch: 106,Loss: -2.914,Avg.Loss: -2.457,LR: 1.18E-04]Training epoch 68:  69%|██████▉   | 106/153 [00:02<00:00, 52.60it/s, Epoch: 68, Batch: 107,Loss: -2.736,Avg.Loss: -2.460,LR: 1.18E-04]Training epoch 68:  70%|██████▉   | 107/153 [00:02<00:00, 52.60it/s, Epoch: 68, Batch: 108,Loss: -2.917,Avg.Loss: -2.464,LR: 1.18E-04]Training epoch 68:  71%|███████   | 108/153 [00:02<00:00, 52.69it/s, Epoch: 68, Batch: 108,Loss: -2.917,Avg.Loss: -2.464,LR: 1.18E-04]Training epoch 68:  71%|███████   | 108/153 [00:02<00:00, 52.69it/s, Epoch: 68, Batch: 109,Loss: -2.827,Avg.Loss: -2.467,LR: 1.18E-04]Training epoch 68:  71%|███████   | 109/153 [00:02<00:00, 52.69it/s, Epoch: 68, Batch: 110,Loss: -2.758,Avg.Loss: -2.470,LR: 1.18E-04]Training epoch 68:  72%|███████▏  | 110/153 [00:02<00:00, 52.69it/s, Epoch: 68, Batch: 111,Loss: -2.684,Avg.Loss: -2.472,LR: 1.18E-04]Training epoch 68:  73%|███████▎  | 111/153 [00:02<00:00, 52.69it/s, Epoch: 68, Batch: 112,Loss: -2.355,Avg.Loss: -2.471,LR: 1.18E-04]Training epoch 68:  73%|███████▎  | 112/153 [00:02<00:00, 52.69it/s, Epoch: 68, Batch: 113,Loss: -2.875,Avg.Loss: -2.474,LR: 1.18E-04]Training epoch 68:  74%|███████▍  | 113/153 [00:02<00:00, 52.69it/s, Epoch: 68, Batch: 114,Loss: -2.295,Avg.Loss: -2.473,LR: 1.18E-04]Training epoch 68:  75%|███████▍  | 114/153 [00:02<00:00, 52.74it/s, Epoch: 68, Batch: 114,Loss: -2.295,Avg.Loss: -2.473,LR: 1.18E-04]Training epoch 68:  75%|███████▍  | 114/153 [00:02<00:00, 52.74it/s, Epoch: 68, Batch: 115,Loss: -2.345,Avg.Loss: -2.472,LR: 1.18E-04]Training epoch 68:  75%|███████▌  | 115/153 [00:02<00:00, 52.74it/s, Epoch: 68, Batch: 116,Loss: -2.839,Avg.Loss: -2.475,LR: 1.18E-04]Training epoch 68:  76%|███████▌  | 116/153 [00:02<00:00, 52.74it/s, Epoch: 68, Batch: 117,Loss: -2.503,Avg.Loss: -2.475,LR: 1.18E-04]Training epoch 68:  76%|███████▋  | 117/153 [00:02<00:00, 52.74it/s, Epoch: 68, Batch: 118,Loss: -2.868,Avg.Loss: -2.478,LR: 1.18E-04]Training epoch 68:  77%|███████▋  | 118/153 [00:02<00:00, 52.74it/s, Epoch: 68, Batch: 119,Loss: -2.567,Avg.Loss: -2.479,LR: 1.18E-04]Training epoch 68:  78%|███████▊  | 119/153 [00:02<00:00, 52.74it/s, Epoch: 68, Batch: 120,Loss: -2.901,Avg.Loss: -2.483,LR: 1.17E-04]Training epoch 68:  78%|███████▊  | 120/153 [00:02<00:00, 52.71it/s, Epoch: 68, Batch: 120,Loss: -2.901,Avg.Loss: -2.483,LR: 1.17E-04]Training epoch 68:  78%|███████▊  | 120/153 [00:02<00:00, 52.71it/s, Epoch: 68, Batch: 121,Loss: -2.993,Avg.Loss: -2.487,LR: 1.17E-04]Training epoch 68:  79%|███████▉  | 121/153 [00:02<00:00, 52.71it/s, Epoch: 68, Batch: 122,Loss: -3.130,Avg.Loss: -2.492,LR: 1.17E-04]Training epoch 68:  80%|███████▉  | 122/153 [00:02<00:00, 52.71it/s, Epoch: 68, Batch: 123,Loss: -3.044,Avg.Loss: -2.497,LR: 1.17E-04]Training epoch 68:  80%|████████  | 123/153 [00:02<00:00, 52.71it/s, Epoch: 68, Batch: 124,Loss: -2.777,Avg.Loss: -2.499,LR: 1.17E-04]Training epoch 68:  81%|████████  | 124/153 [00:02<00:00, 52.71it/s, Epoch: 68, Batch: 125,Loss: -2.507,Avg.Loss: -2.499,LR: 1.17E-04]Training epoch 68:  82%|████████▏ | 125/153 [00:02<00:00, 52.71it/s, Epoch: 68, Batch: 126,Loss: -1.893,Avg.Loss: -2.494,LR: 1.17E-04]Training epoch 68:  82%|████████▏ | 126/153 [00:02<00:00, 52.92it/s, Epoch: 68, Batch: 126,Loss: -1.893,Avg.Loss: -2.494,LR: 1.17E-04]Training epoch 68:  82%|████████▏ | 126/153 [00:02<00:00, 52.92it/s, Epoch: 68, Batch: 127,Loss: -2.267,Avg.Loss: -2.492,LR: 1.17E-04]Training epoch 68:  83%|████████▎ | 127/153 [00:02<00:00, 52.92it/s, Epoch: 68, Batch: 128,Loss: -2.792,Avg.Loss: -2.495,LR: 1.17E-04]Training epoch 68:  84%|████████▎ | 128/153 [00:02<00:00, 52.92it/s, Epoch: 68, Batch: 129,Loss: -2.676,Avg.Loss: -2.496,LR: 1.17E-04]Training epoch 68:  84%|████████▍ | 129/153 [00:02<00:00, 52.92it/s, Epoch: 68, Batch: 130,Loss: -2.611,Avg.Loss: -2.497,LR: 1.17E-04]Training epoch 68:  85%|████████▍ | 130/153 [00:02<00:00, 52.92it/s, Epoch: 68, Batch: 131,Loss: -2.780,Avg.Loss: -2.499,LR: 1.17E-04]Training epoch 68:  86%|████████▌ | 131/153 [00:02<00:00, 52.92it/s, Epoch: 68, Batch: 132,Loss: -3.148,Avg.Loss: -2.504,LR: 1.17E-04]Training epoch 68:  86%|████████▋ | 132/153 [00:02<00:00, 52.91it/s, Epoch: 68, Batch: 132,Loss: -3.148,Avg.Loss: -2.504,LR: 1.17E-04]Training epoch 68:  86%|████████▋ | 132/153 [00:02<00:00, 52.91it/s, Epoch: 68, Batch: 133,Loss: -3.184,Avg.Loss: -2.509,LR: 1.17E-04]Training epoch 68:  87%|████████▋ | 133/153 [00:02<00:00, 52.91it/s, Epoch: 68, Batch: 134,Loss: -2.693,Avg.Loss: -2.510,LR: 1.17E-04]Training epoch 68:  88%|████████▊ | 134/153 [00:02<00:00, 52.91it/s, Epoch: 68, Batch: 135,Loss: -3.067,Avg.Loss: -2.515,LR: 1.17E-04]Training epoch 68:  88%|████████▊ | 135/153 [00:02<00:00, 52.91it/s, Epoch: 68, Batch: 136,Loss: -3.093,Avg.Loss: -2.519,LR: 1.17E-04]Training epoch 68:  89%|████████▉ | 136/153 [00:02<00:00, 52.91it/s, Epoch: 68, Batch: 137,Loss: -2.349,Avg.Loss: -2.518,LR: 1.17E-04]Training epoch 68:  90%|████████▉ | 137/153 [00:02<00:00, 52.91it/s, Epoch: 68, Batch: 138,Loss: -2.489,Avg.Loss: -2.517,LR: 1.17E-04]Training epoch 68:  90%|█████████ | 138/153 [00:02<00:00, 53.02it/s, Epoch: 68, Batch: 138,Loss: -2.489,Avg.Loss: -2.517,LR: 1.17E-04]Training epoch 68:  90%|█████████ | 138/153 [00:02<00:00, 53.02it/s, Epoch: 68, Batch: 139,Loss: -2.507,Avg.Loss: -2.517,LR: 1.17E-04]Training epoch 68:  91%|█████████ | 139/153 [00:02<00:00, 53.02it/s, Epoch: 68, Batch: 140,Loss: -2.854,Avg.Loss: -2.520,LR: 1.17E-04]Training epoch 68:  92%|█████████▏| 140/153 [00:02<00:00, 53.02it/s, Epoch: 68, Batch: 141,Loss: -2.939,Avg.Loss: -2.523,LR: 1.17E-04]Training epoch 68:  92%|█████████▏| 141/153 [00:02<00:00, 53.02it/s, Epoch: 68, Batch: 142,Loss: -2.472,Avg.Loss: -2.522,LR: 1.17E-04]Training epoch 68:  93%|█████████▎| 142/153 [00:02<00:00, 53.02it/s, Epoch: 68, Batch: 143,Loss: -2.604,Avg.Loss: -2.523,LR: 1.16E-04]Training epoch 68:  93%|█████████▎| 143/153 [00:02<00:00, 53.02it/s, Epoch: 68, Batch: 144,Loss: -2.277,Avg.Loss: -2.521,LR: 1.16E-04]Training epoch 68:  94%|█████████▍| 144/153 [00:02<00:00, 53.32it/s, Epoch: 68, Batch: 144,Loss: -2.277,Avg.Loss: -2.521,LR: 1.16E-04]Training epoch 68:  94%|█████████▍| 144/153 [00:02<00:00, 53.32it/s, Epoch: 68, Batch: 145,Loss: -2.746,Avg.Loss: -2.523,LR: 1.16E-04]Training epoch 68:  95%|█████████▍| 145/153 [00:02<00:00, 53.32it/s, Epoch: 68, Batch: 146,Loss: -2.647,Avg.Loss: -2.524,LR: 1.16E-04]Training epoch 68:  95%|█████████▌| 146/153 [00:02<00:00, 53.32it/s, Epoch: 68, Batch: 147,Loss: -2.834,Avg.Loss: -2.526,LR: 1.16E-04]Training epoch 68:  96%|█████████▌| 147/153 [00:02<00:00, 53.32it/s, Epoch: 68, Batch: 148,Loss: -2.981,Avg.Loss: -2.529,LR: 1.16E-04]Training epoch 68:  97%|█████████▋| 148/153 [00:02<00:00, 53.32it/s, Epoch: 68, Batch: 149,Loss: -2.353,Avg.Loss: -2.528,LR: 1.16E-04]Training epoch 68:  97%|█████████▋| 149/153 [00:02<00:00, 53.32it/s, Epoch: 68, Batch: 150,Loss: -2.756,Avg.Loss: -2.529,LR: 1.16E-04]Training epoch 68:  98%|█████████▊| 150/153 [00:02<00:00, 53.15it/s, Epoch: 68, Batch: 150,Loss: -2.756,Avg.Loss: -2.529,LR: 1.16E-04]Training epoch 68:  98%|█████████▊| 150/153 [00:02<00:00, 53.15it/s, Epoch: 68, Batch: 151,Loss: -2.763,Avg.Loss: -2.531,LR: 1.16E-04]Training epoch 68:  99%|█████████▊| 151/153 [00:02<00:00, 53.15it/s, Epoch: 68, Batch: 152,Loss: -2.940,Avg.Loss: -2.533,LR: 1.16E-04]Training epoch 68:  99%|█████████▉| 152/153 [00:02<00:00, 53.15it/s, Epoch: 68, Batch: 153,Loss: -2.999,Avg.Loss: -2.536,LR: 1.16E-04]Training epoch 68: 100%|██████████| 153/153 [00:02<00:00, 52.62it/s, Epoch: 68, Batch: 153,Loss: -2.999,Avg.Loss: -2.536,LR: 1.16E-04]
Training epoch 69:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 69:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 69, Batch: 1,Loss: -2.414,Avg.Loss: -2.414,LR: 1.16E-04]Training epoch 69:   1%|          | 1/153 [00:00<00:05, 28.87it/s, Epoch: 69, Batch: 2,Loss: -2.709,Avg.Loss: -2.562,LR: 1.16E-04]Training epoch 69:   1%|▏         | 2/153 [00:00<00:03, 40.84it/s, Epoch: 69, Batch: 3,Loss: -2.877,Avg.Loss: -2.667,LR: 1.16E-04]Training epoch 69:   2%|▏         | 3/153 [00:00<00:03, 44.75it/s, Epoch: 69, Batch: 4,Loss: -2.994,Avg.Loss: -2.748,LR: 1.16E-04]Training epoch 69:   3%|▎         | 4/153 [00:00<00:03, 46.64it/s, Epoch: 69, Batch: 5,Loss: -2.557,Avg.Loss: -2.710,LR: 1.16E-04]Training epoch 69:   3%|▎         | 5/153 [00:00<00:03, 47.55it/s, Epoch: 69, Batch: 6,Loss: -3.062,Avg.Loss: -2.769,LR: 1.16E-04]Training epoch 69:   4%|▍         | 6/153 [00:00<00:02, 56.95it/s, Epoch: 69, Batch: 6,Loss: -3.062,Avg.Loss: -2.769,LR: 1.16E-04]Training epoch 69:   4%|▍         | 6/153 [00:00<00:02, 56.95it/s, Epoch: 69, Batch: 7,Loss: -2.960,Avg.Loss: -2.796,LR: 1.16E-04]Training epoch 69:   5%|▍         | 7/153 [00:00<00:02, 56.95it/s, Epoch: 69, Batch: 8,Loss: -2.679,Avg.Loss: -2.782,LR: 1.16E-04]Training epoch 69:   5%|▌         | 8/153 [00:00<00:02, 56.95it/s, Epoch: 69, Batch: 9,Loss: -1.360,Avg.Loss: -2.624,LR: 1.16E-04]Training epoch 69:   6%|▌         | 9/153 [00:00<00:02, 56.95it/s, Epoch: 69, Batch: 10,Loss: -2.354,Avg.Loss: -2.597,LR: 1.16E-04]Training epoch 69:   7%|▋         | 10/153 [00:00<00:02, 56.95it/s, Epoch: 69, Batch: 11,Loss: -1.454,Avg.Loss: -2.493,LR: 1.16E-04]Training epoch 69:   7%|▋         | 11/153 [00:00<00:02, 56.95it/s, Epoch: 69, Batch: 12,Loss: -2.374,Avg.Loss: -2.483,LR: 1.16E-04]Training epoch 69:   8%|▊         | 12/153 [00:00<00:02, 53.77it/s, Epoch: 69, Batch: 12,Loss: -2.374,Avg.Loss: -2.483,LR: 1.16E-04]Training epoch 69:   8%|▊         | 12/153 [00:00<00:02, 53.77it/s, Epoch: 69, Batch: 13,Loss: -2.397,Avg.Loss: -2.476,LR: 1.15E-04]Training epoch 69:   8%|▊         | 13/153 [00:00<00:02, 53.77it/s, Epoch: 69, Batch: 14,Loss: -1.951,Avg.Loss: -2.439,LR: 1.15E-04]Training epoch 69:   9%|▉         | 14/153 [00:00<00:02, 53.77it/s, Epoch: 69, Batch: 15,Loss: -2.802,Avg.Loss: -2.463,LR: 1.15E-04]Training epoch 69:  10%|▉         | 15/153 [00:00<00:02, 53.77it/s, Epoch: 69, Batch: 16,Loss: -3.072,Avg.Loss: -2.501,LR: 1.15E-04]Training epoch 69:  10%|█         | 16/153 [00:00<00:02, 53.77it/s, Epoch: 69, Batch: 17,Loss: -2.618,Avg.Loss: -2.508,LR: 1.15E-04]Training epoch 69:  11%|█         | 17/153 [00:00<00:02, 53.77it/s, Epoch: 69, Batch: 18,Loss: -2.415,Avg.Loss: -2.503,LR: 1.15E-04]Training epoch 69:  12%|█▏        | 18/153 [00:00<00:02, 53.22it/s, Epoch: 69, Batch: 18,Loss: -2.415,Avg.Loss: -2.503,LR: 1.15E-04]Training epoch 69:  12%|█▏        | 18/153 [00:00<00:02, 53.22it/s, Epoch: 69, Batch: 19,Loss: -3.025,Avg.Loss: -2.530,LR: 1.15E-04]Training epoch 69:  12%|█▏        | 19/153 [00:00<00:02, 53.22it/s, Epoch: 69, Batch: 20,Loss: -2.742,Avg.Loss: -2.541,LR: 1.15E-04]Training epoch 69:  13%|█▎        | 20/153 [00:00<00:02, 53.22it/s, Epoch: 69, Batch: 21,Loss: -2.659,Avg.Loss: -2.546,LR: 1.15E-04]Training epoch 69:  14%|█▎        | 21/153 [00:00<00:02, 53.22it/s, Epoch: 69, Batch: 22,Loss: -3.019,Avg.Loss: -2.568,LR: 1.15E-04]Training epoch 69:  14%|█▍        | 22/153 [00:00<00:02, 53.22it/s, Epoch: 69, Batch: 23,Loss: -2.762,Avg.Loss: -2.576,LR: 1.15E-04]Training epoch 69:  15%|█▌        | 23/153 [00:00<00:02, 53.22it/s, Epoch: 69, Batch: 24,Loss: -3.028,Avg.Loss: -2.595,LR: 1.15E-04]Training epoch 69:  16%|█▌        | 24/153 [00:00<00:02, 52.48it/s, Epoch: 69, Batch: 24,Loss: -3.028,Avg.Loss: -2.595,LR: 1.15E-04]Training epoch 69:  16%|█▌        | 24/153 [00:00<00:02, 52.48it/s, Epoch: 69, Batch: 25,Loss: -2.799,Avg.Loss: -2.603,LR: 1.15E-04]Training epoch 69:  16%|█▋        | 25/153 [00:00<00:02, 52.48it/s, Epoch: 69, Batch: 26,Loss: -2.443,Avg.Loss: -2.597,LR: 1.15E-04]Training epoch 69:  17%|█▋        | 26/153 [00:00<00:02, 52.48it/s, Epoch: 69, Batch: 27,Loss: -2.744,Avg.Loss: -2.603,LR: 1.15E-04]Training epoch 69:  18%|█▊        | 27/153 [00:00<00:02, 52.48it/s, Epoch: 69, Batch: 28,Loss: -2.640,Avg.Loss: -2.604,LR: 1.15E-04]Training epoch 69:  18%|█▊        | 28/153 [00:00<00:02, 52.48it/s, Epoch: 69, Batch: 29,Loss: -3.049,Avg.Loss: -2.619,LR: 1.15E-04]Training epoch 69:  19%|█▉        | 29/153 [00:00<00:02, 52.48it/s, Epoch: 69, Batch: 30,Loss: -2.526,Avg.Loss: -2.616,LR: 1.15E-04]Training epoch 69:  20%|█▉        | 30/153 [00:00<00:02, 52.27it/s, Epoch: 69, Batch: 30,Loss: -2.526,Avg.Loss: -2.616,LR: 1.15E-04]Training epoch 69:  20%|█▉        | 30/153 [00:00<00:02, 52.27it/s, Epoch: 69, Batch: 31,Loss: -3.013,Avg.Loss: -2.629,LR: 1.15E-04]Training epoch 69:  20%|██        | 31/153 [00:00<00:02, 52.27it/s, Epoch: 69, Batch: 32,Loss: -2.976,Avg.Loss: -2.640,LR: 1.15E-04]Training epoch 69:  21%|██        | 32/153 [00:00<00:02, 52.27it/s, Epoch: 69, Batch: 33,Loss: -2.692,Avg.Loss: -2.641,LR: 1.15E-04]Training epoch 69:  22%|██▏       | 33/153 [00:00<00:02, 52.27it/s, Epoch: 69, Batch: 34,Loss: -2.876,Avg.Loss: -2.648,LR: 1.15E-04]Training epoch 69:  22%|██▏       | 34/153 [00:00<00:02, 52.27it/s, Epoch: 69, Batch: 35,Loss: -2.411,Avg.Loss: -2.642,LR: 1.15E-04]Training epoch 69:  23%|██▎       | 35/153 [00:00<00:02, 52.27it/s, Epoch: 69, Batch: 36,Loss: -2.356,Avg.Loss: -2.634,LR: 1.14E-04]Training epoch 69:  24%|██▎       | 36/153 [00:00<00:02, 52.59it/s, Epoch: 69, Batch: 36,Loss: -2.356,Avg.Loss: -2.634,LR: 1.14E-04]Training epoch 69:  24%|██▎       | 36/153 [00:00<00:02, 52.59it/s, Epoch: 69, Batch: 37,Loss: -2.283,Avg.Loss: -2.624,LR: 1.14E-04]Training epoch 69:  24%|██▍       | 37/153 [00:00<00:02, 52.59it/s, Epoch: 69, Batch: 38,Loss: -2.290,Avg.Loss: -2.615,LR: 1.14E-04]Training epoch 69:  25%|██▍       | 38/153 [00:00<00:02, 52.59it/s, Epoch: 69, Batch: 39,Loss: -2.791,Avg.Loss: -2.620,LR: 1.14E-04]Training epoch 69:  25%|██▌       | 39/153 [00:00<00:02, 52.59it/s, Epoch: 69, Batch: 40,Loss: -2.611,Avg.Loss: -2.620,LR: 1.14E-04]Training epoch 69:  26%|██▌       | 40/153 [00:00<00:02, 52.59it/s, Epoch: 69, Batch: 41,Loss: -2.229,Avg.Loss: -2.610,LR: 1.14E-04]Training epoch 69:  27%|██▋       | 41/153 [00:00<00:02, 52.59it/s, Epoch: 69, Batch: 42,Loss: -3.098,Avg.Loss: -2.622,LR: 1.14E-04]Training epoch 69:  27%|██▋       | 42/153 [00:00<00:02, 52.79it/s, Epoch: 69, Batch: 42,Loss: -3.098,Avg.Loss: -2.622,LR: 1.14E-04]Training epoch 69:  27%|██▋       | 42/153 [00:00<00:02, 52.79it/s, Epoch: 69, Batch: 43,Loss: -3.060,Avg.Loss: -2.632,LR: 1.14E-04]Training epoch 69:  28%|██▊       | 43/153 [00:00<00:02, 52.79it/s, Epoch: 69, Batch: 44,Loss: -2.475,Avg.Loss: -2.628,LR: 1.14E-04]Training epoch 69:  29%|██▉       | 44/153 [00:00<00:02, 52.79it/s, Epoch: 69, Batch: 45,Loss: -2.905,Avg.Loss: -2.635,LR: 1.14E-04]Training epoch 69:  29%|██▉       | 45/153 [00:00<00:02, 52.79it/s, Epoch: 69, Batch: 46,Loss: -2.425,Avg.Loss: -2.630,LR: 1.14E-04]Training epoch 69:  30%|███       | 46/153 [00:00<00:02, 52.79it/s, Epoch: 69, Batch: 47,Loss: -2.207,Avg.Loss: -2.621,LR: 1.14E-04]Training epoch 69:  31%|███       | 47/153 [00:00<00:02, 52.79it/s, Epoch: 69, Batch: 48,Loss: -2.281,Avg.Loss: -2.614,LR: 1.14E-04]Training epoch 69:  31%|███▏      | 48/153 [00:00<00:01, 52.64it/s, Epoch: 69, Batch: 48,Loss: -2.281,Avg.Loss: -2.614,LR: 1.14E-04]Training epoch 69:  31%|███▏      | 48/153 [00:00<00:01, 52.64it/s, Epoch: 69, Batch: 49,Loss: -2.906,Avg.Loss: -2.620,LR: 1.14E-04]Training epoch 69:  32%|███▏      | 49/153 [00:00<00:01, 52.64it/s, Epoch: 69, Batch: 50,Loss: -2.632,Avg.Loss: -2.620,LR: 1.14E-04]Training epoch 69:  33%|███▎      | 50/153 [00:00<00:01, 52.64it/s, Epoch: 69, Batch: 51,Loss: -2.504,Avg.Loss: -2.618,LR: 1.14E-04]Training epoch 69:  33%|███▎      | 51/153 [00:00<00:01, 52.64it/s, Epoch: 69, Batch: 52,Loss: -2.858,Avg.Loss: -2.622,LR: 1.14E-04]Training epoch 69:  34%|███▍      | 52/153 [00:01<00:01, 52.64it/s, Epoch: 69, Batch: 53,Loss: -3.081,Avg.Loss: -2.631,LR: 1.14E-04]Training epoch 69:  35%|███▍      | 53/153 [00:01<00:01, 52.64it/s, Epoch: 69, Batch: 54,Loss: -2.882,Avg.Loss: -2.636,LR: 1.14E-04]Training epoch 69:  35%|███▌      | 54/153 [00:01<00:01, 52.75it/s, Epoch: 69, Batch: 54,Loss: -2.882,Avg.Loss: -2.636,LR: 1.14E-04]Training epoch 69:  35%|███▌      | 54/153 [00:01<00:01, 52.75it/s, Epoch: 69, Batch: 55,Loss: -2.555,Avg.Loss: -2.634,LR: 1.14E-04]Training epoch 69:  36%|███▌      | 55/153 [00:01<00:01, 52.75it/s, Epoch: 69, Batch: 56,Loss: -3.001,Avg.Loss: -2.641,LR: 1.14E-04]Training epoch 69:  37%|███▋      | 56/153 [00:01<00:01, 52.75it/s, Epoch: 69, Batch: 57,Loss: -2.683,Avg.Loss: -2.642,LR: 1.14E-04]Training epoch 69:  37%|███▋      | 57/153 [00:01<00:01, 52.75it/s, Epoch: 69, Batch: 58,Loss: -3.043,Avg.Loss: -2.648,LR: 1.14E-04]Training epoch 69:  38%|███▊      | 58/153 [00:01<00:01, 52.75it/s, Epoch: 69, Batch: 59,Loss: -2.395,Avg.Loss: -2.644,LR: 1.13E-04]Training epoch 69:  39%|███▊      | 59/153 [00:01<00:01, 52.75it/s, Epoch: 69, Batch: 60,Loss: -3.068,Avg.Loss: -2.651,LR: 1.13E-04]Training epoch 69:  39%|███▉      | 60/153 [00:01<00:01, 52.85it/s, Epoch: 69, Batch: 60,Loss: -3.068,Avg.Loss: -2.651,LR: 1.13E-04]Training epoch 69:  39%|███▉      | 60/153 [00:01<00:01, 52.85it/s, Epoch: 69, Batch: 61,Loss: -2.784,Avg.Loss: -2.653,LR: 1.13E-04]Training epoch 69:  40%|███▉      | 61/153 [00:01<00:01, 52.85it/s, Epoch: 69, Batch: 62,Loss: -2.808,Avg.Loss: -2.656,LR: 1.13E-04]Training epoch 69:  41%|████      | 62/153 [00:01<00:01, 52.85it/s, Epoch: 69, Batch: 63,Loss: -2.693,Avg.Loss: -2.657,LR: 1.13E-04]Training epoch 69:  41%|████      | 63/153 [00:01<00:01, 52.85it/s, Epoch: 69, Batch: 64,Loss: -2.296,Avg.Loss: -2.651,LR: 1.13E-04]Training epoch 69:  42%|████▏     | 64/153 [00:01<00:01, 52.85it/s, Epoch: 69, Batch: 65,Loss: -2.884,Avg.Loss: -2.654,LR: 1.13E-04]Training epoch 69:  42%|████▏     | 65/153 [00:01<00:01, 52.85it/s, Epoch: 69, Batch: 66,Loss: -2.858,Avg.Loss: -2.658,LR: 1.13E-04]Training epoch 69:  43%|████▎     | 66/153 [00:01<00:01, 52.76it/s, Epoch: 69, Batch: 66,Loss: -2.858,Avg.Loss: -2.658,LR: 1.13E-04]Training epoch 69:  43%|████▎     | 66/153 [00:01<00:01, 52.76it/s, Epoch: 69, Batch: 67,Loss: -2.353,Avg.Loss: -2.653,LR: 1.13E-04]Training epoch 69:  44%|████▍     | 67/153 [00:01<00:01, 52.76it/s, Epoch: 69, Batch: 68,Loss: -2.427,Avg.Loss: -2.650,LR: 1.13E-04]Training epoch 69:  44%|████▍     | 68/153 [00:01<00:01, 52.76it/s, Epoch: 69, Batch: 69,Loss: -3.023,Avg.Loss: -2.655,LR: 1.13E-04]Training epoch 69:  45%|████▌     | 69/153 [00:01<00:01, 52.76it/s, Epoch: 69, Batch: 70,Loss: -2.858,Avg.Loss: -2.658,LR: 1.13E-04]Training epoch 69:  46%|████▌     | 70/153 [00:01<00:01, 52.76it/s, Epoch: 69, Batch: 71,Loss: -2.954,Avg.Loss: -2.662,LR: 1.13E-04]Training epoch 69:  46%|████▋     | 71/153 [00:01<00:01, 52.76it/s, Epoch: 69, Batch: 72,Loss: -2.185,Avg.Loss: -2.656,LR: 1.13E-04]Training epoch 69:  47%|████▋     | 72/153 [00:01<00:01, 53.18it/s, Epoch: 69, Batch: 72,Loss: -2.185,Avg.Loss: -2.656,LR: 1.13E-04]Training epoch 69:  47%|████▋     | 72/153 [00:01<00:01, 53.18it/s, Epoch: 69, Batch: 73,Loss: -2.854,Avg.Loss: -2.658,LR: 1.13E-04]Training epoch 69:  48%|████▊     | 73/153 [00:01<00:01, 53.18it/s, Epoch: 69, Batch: 74,Loss: -2.763,Avg.Loss: -2.660,LR: 1.13E-04]Training epoch 69:  48%|████▊     | 74/153 [00:01<00:01, 53.18it/s, Epoch: 69, Batch: 75,Loss: -2.892,Avg.Loss: -2.663,LR: 1.13E-04]Training epoch 69:  49%|████▉     | 75/153 [00:01<00:01, 53.18it/s, Epoch: 69, Batch: 76,Loss: -2.768,Avg.Loss: -2.664,LR: 1.13E-04]Training epoch 69:  50%|████▉     | 76/153 [00:01<00:01, 53.18it/s, Epoch: 69, Batch: 77,Loss: -2.816,Avg.Loss: -2.666,LR: 1.13E-04]Training epoch 69:  50%|█████     | 77/153 [00:01<00:01, 53.18it/s, Epoch: 69, Batch: 78,Loss: -2.452,Avg.Loss: -2.663,LR: 1.13E-04]Training epoch 69:  51%|█████     | 78/153 [00:01<00:01, 53.15it/s, Epoch: 69, Batch: 78,Loss: -2.452,Avg.Loss: -2.663,LR: 1.13E-04]Training epoch 69:  51%|█████     | 78/153 [00:01<00:01, 53.15it/s, Epoch: 69, Batch: 79,Loss: -2.828,Avg.Loss: -2.665,LR: 1.13E-04]Training epoch 69:  52%|█████▏    | 79/153 [00:01<00:01, 53.15it/s, Epoch: 69, Batch: 80,Loss: -2.883,Avg.Loss: -2.668,LR: 1.13E-04]Training epoch 69:  52%|█████▏    | 80/153 [00:01<00:01, 53.15it/s, Epoch: 69, Batch: 81,Loss: -2.778,Avg.Loss: -2.670,LR: 1.13E-04]Training epoch 69:  53%|█████▎    | 81/153 [00:01<00:01, 53.15it/s, Epoch: 69, Batch: 82,Loss: -2.172,Avg.Loss: -2.663,LR: 1.13E-04]Training epoch 69:  54%|█████▎    | 82/153 [00:01<00:01, 53.15it/s, Epoch: 69, Batch: 83,Loss: -2.611,Avg.Loss: -2.663,LR: 1.12E-04]Training epoch 69:  54%|█████▍    | 83/153 [00:01<00:01, 53.15it/s, Epoch: 69, Batch: 84,Loss: -2.686,Avg.Loss: -2.663,LR: 1.12E-04]Training epoch 69:  55%|█████▍    | 84/153 [00:01<00:01, 53.11it/s, Epoch: 69, Batch: 84,Loss: -2.686,Avg.Loss: -2.663,LR: 1.12E-04]Training epoch 69:  55%|█████▍    | 84/153 [00:01<00:01, 53.11it/s, Epoch: 69, Batch: 85,Loss: -2.207,Avg.Loss: -2.658,LR: 1.12E-04]Training epoch 69:  56%|█████▌    | 85/153 [00:01<00:01, 53.11it/s, Epoch: 69, Batch: 86,Loss: -2.158,Avg.Loss: -2.652,LR: 1.12E-04]Training epoch 69:  56%|█████▌    | 86/153 [00:01<00:01, 53.11it/s, Epoch: 69, Batch: 87,Loss: -2.683,Avg.Loss: -2.652,LR: 1.12E-04]Training epoch 69:  57%|█████▋    | 87/153 [00:01<00:01, 53.11it/s, Epoch: 69, Batch: 88,Loss: -3.177,Avg.Loss: -2.658,LR: 1.12E-04]Training epoch 69:  58%|█████▊    | 88/153 [00:01<00:01, 53.11it/s, Epoch: 69, Batch: 89,Loss: -2.611,Avg.Loss: -2.658,LR: 1.12E-04]Training epoch 69:  58%|█████▊    | 89/153 [00:01<00:01, 53.11it/s, Epoch: 69, Batch: 90,Loss: -2.235,Avg.Loss: -2.653,LR: 1.12E-04]Training epoch 69:  59%|█████▉    | 90/153 [00:01<00:01, 53.30it/s, Epoch: 69, Batch: 90,Loss: -2.235,Avg.Loss: -2.653,LR: 1.12E-04]Training epoch 69:  59%|█████▉    | 90/153 [00:01<00:01, 53.30it/s, Epoch: 69, Batch: 91,Loss: -2.450,Avg.Loss: -2.651,LR: 1.12E-04]Training epoch 69:  59%|█████▉    | 91/153 [00:01<00:01, 53.30it/s, Epoch: 69, Batch: 92,Loss: -2.324,Avg.Loss: -2.647,LR: 1.12E-04]Training epoch 69:  60%|██████    | 92/153 [00:01<00:01, 53.30it/s, Epoch: 69, Batch: 93,Loss: -1.909,Avg.Loss: -2.639,LR: 1.12E-04]Training epoch 69:  61%|██████    | 93/153 [00:01<00:01, 53.30it/s, Epoch: 69, Batch: 94,Loss: -2.273,Avg.Loss: -2.635,LR: 1.12E-04]Training epoch 69:  61%|██████▏   | 94/153 [00:01<00:01, 53.30it/s, Epoch: 69, Batch: 95,Loss: -2.674,Avg.Loss: -2.636,LR: 1.12E-04]Training epoch 69:  62%|██████▏   | 95/153 [00:01<00:01, 53.30it/s, Epoch: 69, Batch: 96,Loss: -2.854,Avg.Loss: -2.638,LR: 1.12E-04]Training epoch 69:  63%|██████▎   | 96/153 [00:01<00:01, 53.41it/s, Epoch: 69, Batch: 96,Loss: -2.854,Avg.Loss: -2.638,LR: 1.12E-04]Training epoch 69:  63%|██████▎   | 96/153 [00:01<00:01, 53.41it/s, Epoch: 69, Batch: 97,Loss: -2.993,Avg.Loss: -2.642,LR: 1.12E-04]Training epoch 69:  63%|██████▎   | 97/153 [00:01<00:01, 53.41it/s, Epoch: 69, Batch: 98,Loss: -2.710,Avg.Loss: -2.642,LR: 1.12E-04]Training epoch 69:  64%|██████▍   | 98/153 [00:01<00:01, 53.41it/s, Epoch: 69, Batch: 99,Loss: -2.336,Avg.Loss: -2.639,LR: 1.12E-04]Training epoch 69:  65%|██████▍   | 99/153 [00:01<00:01, 53.41it/s, Epoch: 69, Batch: 100,Loss: -2.432,Avg.Loss: -2.637,LR: 1.12E-04]Training epoch 69:  65%|██████▌   | 100/153 [00:01<00:00, 53.41it/s, Epoch: 69, Batch: 101,Loss: -1.931,Avg.Loss: -2.630,LR: 1.12E-04]Training epoch 69:  66%|██████▌   | 101/153 [00:01<00:00, 53.41it/s, Epoch: 69, Batch: 102,Loss: -2.184,Avg.Loss: -2.626,LR: 1.12E-04]Training epoch 69:  67%|██████▋   | 102/153 [00:01<00:00, 53.49it/s, Epoch: 69, Batch: 102,Loss: -2.184,Avg.Loss: -2.626,LR: 1.12E-04]Training epoch 69:  67%|██████▋   | 102/153 [00:01<00:00, 53.49it/s, Epoch: 69, Batch: 103,Loss: -1.713,Avg.Loss: -2.617,LR: 1.12E-04]Training epoch 69:  67%|██████▋   | 103/153 [00:01<00:00, 53.49it/s, Epoch: 69, Batch: 104,Loss: -3.275,Avg.Loss: -2.623,LR: 1.12E-04]Training epoch 69:  68%|██████▊   | 104/153 [00:01<00:00, 53.49it/s, Epoch: 69, Batch: 105,Loss: -2.921,Avg.Loss: -2.626,LR: 1.12E-04]Training epoch 69:  69%|██████▊   | 105/153 [00:01<00:00, 53.49it/s, Epoch: 69, Batch: 106,Loss: -2.677,Avg.Loss: -2.627,LR: 1.11E-04]Training epoch 69:  69%|██████▉   | 106/153 [00:02<00:00, 53.49it/s, Epoch: 69, Batch: 107,Loss: -2.196,Avg.Loss: -2.623,LR: 1.11E-04]Training epoch 69:  70%|██████▉   | 107/153 [00:02<00:00, 53.49it/s, Epoch: 69, Batch: 108,Loss: -2.779,Avg.Loss: -2.624,LR: 1.11E-04]Training epoch 69:  71%|███████   | 108/153 [00:02<00:00, 53.52it/s, Epoch: 69, Batch: 108,Loss: -2.779,Avg.Loss: -2.624,LR: 1.11E-04]Training epoch 69:  71%|███████   | 108/153 [00:02<00:00, 53.52it/s, Epoch: 69, Batch: 109,Loss: -2.847,Avg.Loss: -2.626,LR: 1.11E-04]Training epoch 69:  71%|███████   | 109/153 [00:02<00:00, 53.52it/s, Epoch: 69, Batch: 110,Loss: -2.190,Avg.Loss: -2.622,LR: 1.11E-04]Training epoch 69:  72%|███████▏  | 110/153 [00:02<00:00, 53.52it/s, Epoch: 69, Batch: 111,Loss: -2.395,Avg.Loss: -2.620,LR: 1.11E-04]Training epoch 69:  73%|███████▎  | 111/153 [00:02<00:00, 53.52it/s, Epoch: 69, Batch: 112,Loss: -2.987,Avg.Loss: -2.623,LR: 1.11E-04]Training epoch 69:  73%|███████▎  | 112/153 [00:02<00:00, 53.52it/s, Epoch: 69, Batch: 113,Loss: -3.408,Avg.Loss: -2.630,LR: 1.11E-04]Training epoch 69:  74%|███████▍  | 113/153 [00:02<00:00, 53.52it/s, Epoch: 69, Batch: 114,Loss: -2.374,Avg.Loss: -2.628,LR: 1.11E-04]Training epoch 69:  75%|███████▍  | 114/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 114,Loss: -2.374,Avg.Loss: -2.628,LR: 1.11E-04]Training epoch 69:  75%|███████▍  | 114/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 115,Loss: -2.587,Avg.Loss: -2.628,LR: 1.11E-04]Training epoch 69:  75%|███████▌  | 115/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 116,Loss: -3.059,Avg.Loss: -2.632,LR: 1.11E-04]Training epoch 69:  76%|███████▌  | 116/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 117,Loss: -3.165,Avg.Loss: -2.636,LR: 1.11E-04]Training epoch 69:  76%|███████▋  | 117/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 118,Loss: -1.835,Avg.Loss: -2.629,LR: 1.11E-04]Training epoch 69:  77%|███████▋  | 118/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 119,Loss: -2.580,Avg.Loss: -2.629,LR: 1.11E-04]Training epoch 69:  78%|███████▊  | 119/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 120,Loss: -1.708,Avg.Loss: -2.621,LR: 1.11E-04]Training epoch 69:  78%|███████▊  | 120/153 [00:02<00:00, 53.45it/s, Epoch: 69, Batch: 120,Loss: -1.708,Avg.Loss: -2.621,LR: 1.11E-04]Training epoch 69:  78%|███████▊  | 120/153 [00:02<00:00, 53.45it/s, Epoch: 69, Batch: 121,Loss: -2.760,Avg.Loss: -2.622,LR: 1.11E-04]Training epoch 69:  79%|███████▉  | 121/153 [00:02<00:00, 53.45it/s, Epoch: 69, Batch: 122,Loss: -2.886,Avg.Loss: -2.624,LR: 1.11E-04]Training epoch 69:  80%|███████▉  | 122/153 [00:02<00:00, 53.45it/s, Epoch: 69, Batch: 123,Loss: -3.149,Avg.Loss: -2.629,LR: 1.11E-04]Training epoch 69:  80%|████████  | 123/153 [00:02<00:00, 53.45it/s, Epoch: 69, Batch: 124,Loss: -3.166,Avg.Loss: -2.633,LR: 1.11E-04]Training epoch 69:  81%|████████  | 124/153 [00:02<00:00, 53.45it/s, Epoch: 69, Batch: 125,Loss: -2.549,Avg.Loss: -2.632,LR: 1.11E-04]Training epoch 69:  82%|████████▏ | 125/153 [00:02<00:00, 53.45it/s, Epoch: 69, Batch: 126,Loss: -2.486,Avg.Loss: -2.631,LR: 1.11E-04]Training epoch 69:  82%|████████▏ | 126/153 [00:02<00:00, 53.27it/s, Epoch: 69, Batch: 126,Loss: -2.486,Avg.Loss: -2.631,LR: 1.11E-04]Training epoch 69:  82%|████████▏ | 126/153 [00:02<00:00, 53.27it/s, Epoch: 69, Batch: 127,Loss: -2.611,Avg.Loss: -2.631,LR: 1.11E-04]Training epoch 69:  83%|████████▎ | 127/153 [00:02<00:00, 53.27it/s, Epoch: 69, Batch: 128,Loss: -2.744,Avg.Loss: -2.632,LR: 1.11E-04]Training epoch 69:  84%|████████▎ | 128/153 [00:02<00:00, 53.27it/s, Epoch: 69, Batch: 129,Loss: -2.873,Avg.Loss: -2.634,LR: 1.10E-04]Training epoch 69:  84%|████████▍ | 129/153 [00:02<00:00, 53.27it/s, Epoch: 69, Batch: 130,Loss: -2.667,Avg.Loss: -2.634,LR: 1.10E-04]Training epoch 69:  85%|████████▍ | 130/153 [00:02<00:00, 53.27it/s, Epoch: 69, Batch: 131,Loss: -3.122,Avg.Loss: -2.638,LR: 1.10E-04]Training epoch 69:  86%|████████▌ | 131/153 [00:02<00:00, 53.27it/s, Epoch: 69, Batch: 132,Loss: -2.931,Avg.Loss: -2.640,LR: 1.10E-04]Training epoch 69:  86%|████████▋ | 132/153 [00:02<00:00, 53.07it/s, Epoch: 69, Batch: 132,Loss: -2.931,Avg.Loss: -2.640,LR: 1.10E-04]Training epoch 69:  86%|████████▋ | 132/153 [00:02<00:00, 53.07it/s, Epoch: 69, Batch: 133,Loss: -2.897,Avg.Loss: -2.642,LR: 1.10E-04]Training epoch 69:  87%|████████▋ | 133/153 [00:02<00:00, 53.07it/s, Epoch: 69, Batch: 134,Loss: -2.922,Avg.Loss: -2.644,LR: 1.10E-04]Training epoch 69:  88%|████████▊ | 134/153 [00:02<00:00, 53.07it/s, Epoch: 69, Batch: 135,Loss: -2.665,Avg.Loss: -2.644,LR: 1.10E-04]Training epoch 69:  88%|████████▊ | 135/153 [00:02<00:00, 53.07it/s, Epoch: 69, Batch: 136,Loss: -3.359,Avg.Loss: -2.649,LR: 1.10E-04]Training epoch 69:  89%|████████▉ | 136/153 [00:02<00:00, 53.07it/s, Epoch: 69, Batch: 137,Loss: -2.830,Avg.Loss: -2.651,LR: 1.10E-04]Training epoch 69:  90%|████████▉ | 137/153 [00:02<00:00, 53.07it/s, Epoch: 69, Batch: 138,Loss: -2.991,Avg.Loss: -2.653,LR: 1.10E-04]Training epoch 69:  90%|█████████ | 138/153 [00:02<00:00, 53.22it/s, Epoch: 69, Batch: 138,Loss: -2.991,Avg.Loss: -2.653,LR: 1.10E-04]Training epoch 69:  90%|█████████ | 138/153 [00:02<00:00, 53.22it/s, Epoch: 69, Batch: 139,Loss: -2.698,Avg.Loss: -2.654,LR: 1.10E-04]Training epoch 69:  91%|█████████ | 139/153 [00:02<00:00, 53.22it/s, Epoch: 69, Batch: 140,Loss: -2.624,Avg.Loss: -2.653,LR: 1.10E-04]Training epoch 69:  92%|█████████▏| 140/153 [00:02<00:00, 53.22it/s, Epoch: 69, Batch: 141,Loss: -2.422,Avg.Loss: -2.652,LR: 1.10E-04]Training epoch 69:  92%|█████████▏| 141/153 [00:02<00:00, 53.22it/s, Epoch: 69, Batch: 142,Loss: -2.941,Avg.Loss: -2.654,LR: 1.10E-04]Training epoch 69:  93%|█████████▎| 142/153 [00:02<00:00, 53.22it/s, Epoch: 69, Batch: 143,Loss: -2.966,Avg.Loss: -2.656,LR: 1.10E-04]Training epoch 69:  93%|█████████▎| 143/153 [00:02<00:00, 53.22it/s, Epoch: 69, Batch: 144,Loss: -2.833,Avg.Loss: -2.657,LR: 1.10E-04]Training epoch 69:  94%|█████████▍| 144/153 [00:02<00:00, 53.33it/s, Epoch: 69, Batch: 144,Loss: -2.833,Avg.Loss: -2.657,LR: 1.10E-04]Training epoch 69:  94%|█████████▍| 144/153 [00:02<00:00, 53.33it/s, Epoch: 69, Batch: 145,Loss: -3.061,Avg.Loss: -2.660,LR: 1.10E-04]Training epoch 69:  95%|█████████▍| 145/153 [00:02<00:00, 53.33it/s, Epoch: 69, Batch: 146,Loss: -2.282,Avg.Loss: -2.657,LR: 1.10E-04]Training epoch 69:  95%|█████████▌| 146/153 [00:02<00:00, 53.33it/s, Epoch: 69, Batch: 147,Loss: -2.738,Avg.Loss: -2.658,LR: 1.10E-04]Training epoch 69:  96%|█████████▌| 147/153 [00:02<00:00, 53.33it/s, Epoch: 69, Batch: 148,Loss: -2.867,Avg.Loss: -2.659,LR: 1.10E-04]Training epoch 69:  97%|█████████▋| 148/153 [00:02<00:00, 53.33it/s, Epoch: 69, Batch: 149,Loss: -2.639,Avg.Loss: -2.659,LR: 1.10E-04]Training epoch 69:  97%|█████████▋| 149/153 [00:02<00:00, 53.33it/s, Epoch: 69, Batch: 150,Loss: -3.109,Avg.Loss: -2.662,LR: 1.10E-04]Training epoch 69:  98%|█████████▊| 150/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 150,Loss: -3.109,Avg.Loss: -2.662,LR: 1.10E-04]Training epoch 69:  98%|█████████▊| 150/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 151,Loss: -2.724,Avg.Loss: -2.663,LR: 1.10E-04]Training epoch 69:  99%|█████████▊| 151/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 152,Loss: -2.789,Avg.Loss: -2.663,LR: 1.10E-04]Training epoch 69:  99%|█████████▉| 152/153 [00:02<00:00, 53.34it/s, Epoch: 69, Batch: 153,Loss: -2.484,Avg.Loss: -2.662,LR: 1.09E-04]Training epoch 69: 100%|██████████| 153/153 [00:02<00:00, 53.11it/s, Epoch: 69, Batch: 153,Loss: -2.484,Avg.Loss: -2.662,LR: 1.09E-04]
Training epoch 70:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 70:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 70, Batch: 1,Loss: -2.605,Avg.Loss: -2.605,LR: 1.09E-04]Training epoch 70:   1%|          | 1/153 [00:00<00:05, 26.27it/s, Epoch: 70, Batch: 2,Loss: -2.957,Avg.Loss: -2.781,LR: 1.09E-04]Training epoch 70:   1%|▏         | 2/153 [00:00<00:03, 38.10it/s, Epoch: 70, Batch: 3,Loss: -2.534,Avg.Loss: -2.699,LR: 1.09E-04]Training epoch 70:   2%|▏         | 3/153 [00:00<00:03, 43.00it/s, Epoch: 70, Batch: 4,Loss: -2.658,Avg.Loss: -2.689,LR: 1.09E-04]Training epoch 70:   3%|▎         | 4/153 [00:00<00:03, 45.62it/s, Epoch: 70, Batch: 5,Loss: -2.458,Avg.Loss: -2.642,LR: 1.09E-04]Training epoch 70:   3%|▎         | 5/153 [00:00<00:03, 47.09it/s, Epoch: 70, Batch: 6,Loss: -2.684,Avg.Loss: -2.649,LR: 1.09E-04]Training epoch 70:   4%|▍         | 6/153 [00:00<00:02, 56.41it/s, Epoch: 70, Batch: 6,Loss: -2.684,Avg.Loss: -2.649,LR: 1.09E-04]Training epoch 70:   4%|▍         | 6/153 [00:00<00:02, 56.41it/s, Epoch: 70, Batch: 7,Loss: -2.990,Avg.Loss: -2.698,LR: 1.09E-04]Training epoch 70:   5%|▍         | 7/153 [00:00<00:02, 56.41it/s, Epoch: 70, Batch: 8,Loss: -2.719,Avg.Loss: -2.701,LR: 1.09E-04]Training epoch 70:   5%|▌         | 8/153 [00:00<00:02, 56.41it/s, Epoch: 70, Batch: 9,Loss: -2.669,Avg.Loss: -2.697,LR: 1.09E-04]Training epoch 70:   6%|▌         | 9/153 [00:00<00:02, 56.41it/s, Epoch: 70, Batch: 10,Loss: -2.756,Avg.Loss: -2.703,LR: 1.09E-04]Training epoch 70:   7%|▋         | 10/153 [00:00<00:02, 56.41it/s, Epoch: 70, Batch: 11,Loss: -2.874,Avg.Loss: -2.719,LR: 1.09E-04]Training epoch 70:   7%|▋         | 11/153 [00:00<00:02, 56.41it/s, Epoch: 70, Batch: 12,Loss: -2.300,Avg.Loss: -2.684,LR: 1.09E-04]Training epoch 70:   8%|▊         | 12/153 [00:00<00:02, 55.06it/s, Epoch: 70, Batch: 12,Loss: -2.300,Avg.Loss: -2.684,LR: 1.09E-04]Training epoch 70:   8%|▊         | 12/153 [00:00<00:02, 55.06it/s, Epoch: 70, Batch: 13,Loss: -2.354,Avg.Loss: -2.658,LR: 1.09E-04]Training epoch 70:   8%|▊         | 13/153 [00:00<00:02, 55.06it/s, Epoch: 70, Batch: 14,Loss: -2.239,Avg.Loss: -2.628,LR: 1.09E-04]Training epoch 70:   9%|▉         | 14/153 [00:00<00:02, 55.06it/s, Epoch: 70, Batch: 15,Loss: -2.715,Avg.Loss: -2.634,LR: 1.09E-04]Training epoch 70:  10%|▉         | 15/153 [00:00<00:02, 55.06it/s, Epoch: 70, Batch: 16,Loss: -3.117,Avg.Loss: -2.664,LR: 1.09E-04]Training epoch 70:  10%|█         | 16/153 [00:00<00:02, 55.06it/s, Epoch: 70, Batch: 17,Loss: -3.018,Avg.Loss: -2.685,LR: 1.09E-04]Training epoch 70:  11%|█         | 17/153 [00:00<00:02, 55.06it/s, Epoch: 70, Batch: 18,Loss: -2.403,Avg.Loss: -2.669,LR: 1.09E-04]Training epoch 70:  12%|█▏        | 18/153 [00:00<00:02, 54.95it/s, Epoch: 70, Batch: 18,Loss: -2.403,Avg.Loss: -2.669,LR: 1.09E-04]Training epoch 70:  12%|█▏        | 18/153 [00:00<00:02, 54.95it/s, Epoch: 70, Batch: 19,Loss: -2.823,Avg.Loss: -2.678,LR: 1.09E-04]Training epoch 70:  12%|█▏        | 19/153 [00:00<00:02, 54.95it/s, Epoch: 70, Batch: 20,Loss: -2.773,Avg.Loss: -2.682,LR: 1.09E-04]Training epoch 70:  13%|█▎        | 20/153 [00:00<00:02, 54.95it/s, Epoch: 70, Batch: 21,Loss: -2.621,Avg.Loss: -2.679,LR: 1.09E-04]Training epoch 70:  14%|█▎        | 21/153 [00:00<00:02, 54.95it/s, Epoch: 70, Batch: 22,Loss: -2.977,Avg.Loss: -2.693,LR: 1.09E-04]Training epoch 70:  14%|█▍        | 22/153 [00:00<00:02, 54.95it/s, Epoch: 70, Batch: 23,Loss: -2.524,Avg.Loss: -2.686,LR: 1.09E-04]Training epoch 70:  15%|█▌        | 23/153 [00:00<00:02, 54.95it/s, Epoch: 70, Batch: 24,Loss: -2.575,Avg.Loss: -2.681,LR: 1.08E-04]Training epoch 70:  16%|█▌        | 24/153 [00:00<00:02, 54.23it/s, Epoch: 70, Batch: 24,Loss: -2.575,Avg.Loss: -2.681,LR: 1.08E-04]Training epoch 70:  16%|█▌        | 24/153 [00:00<00:02, 54.23it/s, Epoch: 70, Batch: 25,Loss: -2.250,Avg.Loss: -2.664,LR: 1.08E-04]Training epoch 70:  16%|█▋        | 25/153 [00:00<00:02, 54.23it/s, Epoch: 70, Batch: 26,Loss: -2.435,Avg.Loss: -2.655,LR: 1.08E-04]Training epoch 70:  17%|█▋        | 26/153 [00:00<00:02, 54.23it/s, Epoch: 70, Batch: 27,Loss: -2.155,Avg.Loss: -2.636,LR: 1.08E-04]Training epoch 70:  18%|█▊        | 27/153 [00:00<00:02, 54.23it/s, Epoch: 70, Batch: 28,Loss: -1.791,Avg.Loss: -2.606,LR: 1.08E-04]Training epoch 70:  18%|█▊        | 28/153 [00:00<00:02, 54.23it/s, Epoch: 70, Batch: 29,Loss: -2.904,Avg.Loss: -2.617,LR: 1.08E-04]Training epoch 70:  19%|█▉        | 29/153 [00:00<00:02, 54.23it/s, Epoch: 70, Batch: 30,Loss: -3.431,Avg.Loss: -2.644,LR: 1.08E-04]Training epoch 70:  20%|█▉        | 30/153 [00:00<00:02, 53.67it/s, Epoch: 70, Batch: 30,Loss: -3.431,Avg.Loss: -2.644,LR: 1.08E-04]Training epoch 70:  20%|█▉        | 30/153 [00:00<00:02, 53.67it/s, Epoch: 70, Batch: 31,Loss: -2.939,Avg.Loss: -2.653,LR: 1.08E-04]Training epoch 70:  20%|██        | 31/153 [00:00<00:02, 53.67it/s, Epoch: 70, Batch: 32,Loss: -2.892,Avg.Loss: -2.661,LR: 1.08E-04]Training epoch 70:  21%|██        | 32/153 [00:00<00:02, 53.67it/s, Epoch: 70, Batch: 33,Loss: -2.497,Avg.Loss: -2.656,LR: 1.08E-04]Training epoch 70:  22%|██▏       | 33/153 [00:00<00:02, 53.67it/s, Epoch: 70, Batch: 34,Loss: -2.091,Avg.Loss: -2.639,LR: 1.08E-04]Training epoch 70:  22%|██▏       | 34/153 [00:00<00:02, 53.67it/s, Epoch: 70, Batch: 35,Loss: -2.489,Avg.Loss: -2.635,LR: 1.08E-04]Training epoch 70:  23%|██▎       | 35/153 [00:00<00:02, 53.67it/s, Epoch: 70, Batch: 36,Loss: -2.893,Avg.Loss: -2.642,LR: 1.08E-04]Training epoch 70:  24%|██▎       | 36/153 [00:00<00:02, 53.65it/s, Epoch: 70, Batch: 36,Loss: -2.893,Avg.Loss: -2.642,LR: 1.08E-04]Training epoch 70:  24%|██▎       | 36/153 [00:00<00:02, 53.65it/s, Epoch: 70, Batch: 37,Loss: -2.880,Avg.Loss: -2.648,LR: 1.08E-04]Training epoch 70:  24%|██▍       | 37/153 [00:00<00:02, 53.65it/s, Epoch: 70, Batch: 38,Loss: -2.440,Avg.Loss: -2.643,LR: 1.08E-04]Training epoch 70:  25%|██▍       | 38/153 [00:00<00:02, 53.65it/s, Epoch: 70, Batch: 39,Loss: -2.814,Avg.Loss: -2.647,LR: 1.08E-04]Training epoch 70:  25%|██▌       | 39/153 [00:00<00:02, 53.65it/s, Epoch: 70, Batch: 40,Loss: -2.426,Avg.Loss: -2.642,LR: 1.08E-04]Training epoch 70:  26%|██▌       | 40/153 [00:00<00:02, 53.65it/s, Epoch: 70, Batch: 41,Loss: -2.880,Avg.Loss: -2.648,LR: 1.08E-04]Training epoch 70:  27%|██▋       | 41/153 [00:00<00:02, 53.65it/s, Epoch: 70, Batch: 42,Loss: -2.881,Avg.Loss: -2.653,LR: 1.08E-04]Training epoch 70:  27%|██▋       | 42/153 [00:00<00:02, 53.91it/s, Epoch: 70, Batch: 42,Loss: -2.881,Avg.Loss: -2.653,LR: 1.08E-04]Training epoch 70:  27%|██▋       | 42/153 [00:00<00:02, 53.91it/s, Epoch: 70, Batch: 43,Loss: -2.864,Avg.Loss: -2.658,LR: 1.08E-04]Training epoch 70:  28%|██▊       | 43/153 [00:00<00:02, 53.91it/s, Epoch: 70, Batch: 44,Loss: -3.164,Avg.Loss: -2.670,LR: 1.08E-04]Training epoch 70:  29%|██▉       | 44/153 [00:00<00:02, 53.91it/s, Epoch: 70, Batch: 45,Loss: -2.690,Avg.Loss: -2.670,LR: 1.08E-04]Training epoch 70:  29%|██▉       | 45/153 [00:00<00:02, 53.91it/s, Epoch: 70, Batch: 46,Loss: -2.740,Avg.Loss: -2.672,LR: 1.08E-04]Training epoch 70:  30%|███       | 46/153 [00:00<00:01, 53.91it/s, Epoch: 70, Batch: 47,Loss: -2.726,Avg.Loss: -2.673,LR: 1.07E-04]Training epoch 70:  31%|███       | 47/153 [00:00<00:01, 53.91it/s, Epoch: 70, Batch: 48,Loss: -3.098,Avg.Loss: -2.682,LR: 1.07E-04]Training epoch 70:  31%|███▏      | 48/153 [00:00<00:01, 54.03it/s, Epoch: 70, Batch: 48,Loss: -3.098,Avg.Loss: -2.682,LR: 1.07E-04]Training epoch 70:  31%|███▏      | 48/153 [00:00<00:01, 54.03it/s, Epoch: 70, Batch: 49,Loss: -3.156,Avg.Loss: -2.691,LR: 1.07E-04]Training epoch 70:  32%|███▏      | 49/153 [00:00<00:01, 54.03it/s, Epoch: 70, Batch: 50,Loss: -1.968,Avg.Loss: -2.677,LR: 1.07E-04]Training epoch 70:  33%|███▎      | 50/153 [00:00<00:01, 54.03it/s, Epoch: 70, Batch: 51,Loss: -2.191,Avg.Loss: -2.667,LR: 1.07E-04]Training epoch 70:  33%|███▎      | 51/153 [00:00<00:01, 54.03it/s, Epoch: 70, Batch: 52,Loss: -2.672,Avg.Loss: -2.667,LR: 1.07E-04]Training epoch 70:  34%|███▍      | 52/153 [00:00<00:01, 54.03it/s, Epoch: 70, Batch: 53,Loss: -2.288,Avg.Loss: -2.660,LR: 1.07E-04]Training epoch 70:  35%|███▍      | 53/153 [00:00<00:01, 54.03it/s, Epoch: 70, Batch: 54,Loss: -2.416,Avg.Loss: -2.656,LR: 1.07E-04]Training epoch 70:  35%|███▌      | 54/153 [00:00<00:01, 54.62it/s, Epoch: 70, Batch: 54,Loss: -2.416,Avg.Loss: -2.656,LR: 1.07E-04]Training epoch 70:  35%|███▌      | 54/153 [00:01<00:01, 54.62it/s, Epoch: 70, Batch: 55,Loss: -2.678,Avg.Loss: -2.656,LR: 1.07E-04]Training epoch 70:  36%|███▌      | 55/153 [00:01<00:01, 54.62it/s, Epoch: 70, Batch: 56,Loss: -2.751,Avg.Loss: -2.658,LR: 1.07E-04]Training epoch 70:  37%|███▋      | 56/153 [00:01<00:01, 54.62it/s, Epoch: 70, Batch: 57,Loss: -3.169,Avg.Loss: -2.667,LR: 1.07E-04]Training epoch 70:  37%|███▋      | 57/153 [00:01<00:01, 54.62it/s, Epoch: 70, Batch: 58,Loss: -2.784,Avg.Loss: -2.669,LR: 1.07E-04]Training epoch 70:  38%|███▊      | 58/153 [00:01<00:01, 54.62it/s, Epoch: 70, Batch: 59,Loss: -2.722,Avg.Loss: -2.670,LR: 1.07E-04]Training epoch 70:  39%|███▊      | 59/153 [00:01<00:01, 54.62it/s, Epoch: 70, Batch: 60,Loss: -2.516,Avg.Loss: -2.667,LR: 1.07E-04]Training epoch 70:  39%|███▉      | 60/153 [00:01<00:01, 54.50it/s, Epoch: 70, Batch: 60,Loss: -2.516,Avg.Loss: -2.667,LR: 1.07E-04]Training epoch 70:  39%|███▉      | 60/153 [00:01<00:01, 54.50it/s, Epoch: 70, Batch: 61,Loss: -2.632,Avg.Loss: -2.667,LR: 1.07E-04]Training epoch 70:  40%|███▉      | 61/153 [00:01<00:01, 54.50it/s, Epoch: 70, Batch: 62,Loss: -2.160,Avg.Loss: -2.658,LR: 1.07E-04]Training epoch 70:  41%|████      | 62/153 [00:01<00:01, 54.50it/s, Epoch: 70, Batch: 63,Loss: -2.615,Avg.Loss: -2.658,LR: 1.07E-04]Training epoch 70:  41%|████      | 63/153 [00:01<00:01, 54.50it/s, Epoch: 70, Batch: 64,Loss: -2.688,Avg.Loss: -2.658,LR: 1.07E-04]Training epoch 70:  42%|████▏     | 64/153 [00:01<00:01, 54.50it/s, Epoch: 70, Batch: 65,Loss: -3.278,Avg.Loss: -2.668,LR: 1.07E-04]Training epoch 70:  42%|████▏     | 65/153 [00:01<00:01, 54.50it/s, Epoch: 70, Batch: 66,Loss: -2.694,Avg.Loss: -2.668,LR: 1.07E-04]Training epoch 70:  43%|████▎     | 66/153 [00:01<00:01, 54.39it/s, Epoch: 70, Batch: 66,Loss: -2.694,Avg.Loss: -2.668,LR: 1.07E-04]Training epoch 70:  43%|████▎     | 66/153 [00:01<00:01, 54.39it/s, Epoch: 70, Batch: 67,Loss: -2.392,Avg.Loss: -2.664,LR: 1.07E-04]Training epoch 70:  44%|████▍     | 67/153 [00:01<00:01, 54.39it/s, Epoch: 70, Batch: 68,Loss: -3.143,Avg.Loss: -2.671,LR: 1.07E-04]Training epoch 70:  44%|████▍     | 68/153 [00:01<00:01, 54.39it/s, Epoch: 70, Batch: 69,Loss: -2.463,Avg.Loss: -2.668,LR: 1.07E-04]Training epoch 70:  45%|████▌     | 69/153 [00:01<00:01, 54.39it/s, Epoch: 70, Batch: 70,Loss: -2.564,Avg.Loss: -2.666,LR: 1.07E-04]Training epoch 70:  46%|████▌     | 70/153 [00:01<00:01, 54.39it/s, Epoch: 70, Batch: 71,Loss: -2.430,Avg.Loss: -2.663,LR: 1.06E-04]Training epoch 70:  46%|████▋     | 71/153 [00:01<00:01, 54.39it/s, Epoch: 70, Batch: 72,Loss: -3.087,Avg.Loss: -2.669,LR: 1.06E-04]Training epoch 70:  47%|████▋     | 72/153 [00:01<00:01, 54.29it/s, Epoch: 70, Batch: 72,Loss: -3.087,Avg.Loss: -2.669,LR: 1.06E-04]Training epoch 70:  47%|████▋     | 72/153 [00:01<00:01, 54.29it/s, Epoch: 70, Batch: 73,Loss: -2.927,Avg.Loss: -2.673,LR: 1.06E-04]Training epoch 70:  48%|████▊     | 73/153 [00:01<00:01, 54.29it/s, Epoch: 70, Batch: 74,Loss: -2.996,Avg.Loss: -2.677,LR: 1.06E-04]Training epoch 70:  48%|████▊     | 74/153 [00:01<00:01, 54.29it/s, Epoch: 70, Batch: 75,Loss: -3.156,Avg.Loss: -2.683,LR: 1.06E-04]Training epoch 70:  49%|████▉     | 75/153 [00:01<00:01, 54.29it/s, Epoch: 70, Batch: 76,Loss: -2.794,Avg.Loss: -2.685,LR: 1.06E-04]Training epoch 70:  50%|████▉     | 76/153 [00:01<00:01, 54.29it/s, Epoch: 70, Batch: 77,Loss: -2.684,Avg.Loss: -2.685,LR: 1.06E-04]Training epoch 70:  50%|█████     | 77/153 [00:01<00:01, 54.29it/s, Epoch: 70, Batch: 78,Loss: -2.133,Avg.Loss: -2.678,LR: 1.06E-04]Training epoch 70:  51%|█████     | 78/153 [00:01<00:01, 54.24it/s, Epoch: 70, Batch: 78,Loss: -2.133,Avg.Loss: -2.678,LR: 1.06E-04]Training epoch 70:  51%|█████     | 78/153 [00:01<00:01, 54.24it/s, Epoch: 70, Batch: 79,Loss: -2.761,Avg.Loss: -2.679,LR: 1.06E-04]Training epoch 70:  52%|█████▏    | 79/153 [00:01<00:01, 54.24it/s, Epoch: 70, Batch: 80,Loss: -3.194,Avg.Loss: -2.685,LR: 1.06E-04]Training epoch 70:  52%|█████▏    | 80/153 [00:01<00:01, 54.24it/s, Epoch: 70, Batch: 81,Loss: -3.000,Avg.Loss: -2.689,LR: 1.06E-04]Training epoch 70:  53%|█████▎    | 81/153 [00:01<00:01, 54.24it/s, Epoch: 70, Batch: 82,Loss: -3.117,Avg.Loss: -2.694,LR: 1.06E-04]Training epoch 70:  54%|█████▎    | 82/153 [00:01<00:01, 54.24it/s, Epoch: 70, Batch: 83,Loss: -2.886,Avg.Loss: -2.697,LR: 1.06E-04]Training epoch 70:  54%|█████▍    | 83/153 [00:01<00:01, 54.24it/s, Epoch: 70, Batch: 84,Loss: -2.489,Avg.Loss: -2.694,LR: 1.06E-04]Training epoch 70:  55%|█████▍    | 84/153 [00:01<00:01, 54.26it/s, Epoch: 70, Batch: 84,Loss: -2.489,Avg.Loss: -2.694,LR: 1.06E-04]Training epoch 70:  55%|█████▍    | 84/153 [00:01<00:01, 54.26it/s, Epoch: 70, Batch: 85,Loss: -2.743,Avg.Loss: -2.695,LR: 1.06E-04]Training epoch 70:  56%|█████▌    | 85/153 [00:01<00:01, 54.26it/s, Epoch: 70, Batch: 86,Loss: -2.555,Avg.Loss: -2.693,LR: 1.06E-04]Training epoch 70:  56%|█████▌    | 86/153 [00:01<00:01, 54.26it/s, Epoch: 70, Batch: 87,Loss: -2.347,Avg.Loss: -2.689,LR: 1.06E-04]Training epoch 70:  57%|█████▋    | 87/153 [00:01<00:01, 54.26it/s, Epoch: 70, Batch: 88,Loss: -2.624,Avg.Loss: -2.688,LR: 1.06E-04]Training epoch 70:  58%|█████▊    | 88/153 [00:01<00:01, 54.26it/s, Epoch: 70, Batch: 89,Loss: -2.568,Avg.Loss: -2.687,LR: 1.06E-04]Training epoch 70:  58%|█████▊    | 89/153 [00:01<00:01, 54.26it/s, Epoch: 70, Batch: 90,Loss: -2.078,Avg.Loss: -2.680,LR: 1.06E-04]Training epoch 70:  59%|█████▉    | 90/153 [00:01<00:01, 54.00it/s, Epoch: 70, Batch: 90,Loss: -2.078,Avg.Loss: -2.680,LR: 1.06E-04]Training epoch 70:  59%|█████▉    | 90/153 [00:01<00:01, 54.00it/s, Epoch: 70, Batch: 91,Loss: -1.818,Avg.Loss: -2.671,LR: 1.06E-04]Training epoch 70:  59%|█████▉    | 91/153 [00:01<00:01, 54.00it/s, Epoch: 70, Batch: 92,Loss: -2.724,Avg.Loss: -2.671,LR: 1.06E-04]Training epoch 70:  60%|██████    | 92/153 [00:01<00:01, 54.00it/s, Epoch: 70, Batch: 93,Loss: -2.911,Avg.Loss: -2.674,LR: 1.06E-04]Training epoch 70:  61%|██████    | 93/153 [00:01<00:01, 54.00it/s, Epoch: 70, Batch: 94,Loss: -2.941,Avg.Loss: -2.677,LR: 1.06E-04]Training epoch 70:  61%|██████▏   | 94/153 [00:01<00:01, 54.00it/s, Epoch: 70, Batch: 95,Loss: -2.894,Avg.Loss: -2.679,LR: 1.05E-04]Training epoch 70:  62%|██████▏   | 95/153 [00:01<00:01, 54.00it/s, Epoch: 70, Batch: 96,Loss: -1.749,Avg.Loss: -2.669,LR: 1.05E-04]Training epoch 70:  63%|██████▎   | 96/153 [00:01<00:01, 53.62it/s, Epoch: 70, Batch: 96,Loss: -1.749,Avg.Loss: -2.669,LR: 1.05E-04]Training epoch 70:  63%|██████▎   | 96/153 [00:01<00:01, 53.62it/s, Epoch: 70, Batch: 97,Loss: -2.907,Avg.Loss: -2.672,LR: 1.05E-04]Training epoch 70:  63%|██████▎   | 97/153 [00:01<00:01, 53.62it/s, Epoch: 70, Batch: 98,Loss: -2.909,Avg.Loss: -2.674,LR: 1.05E-04]Training epoch 70:  64%|██████▍   | 98/153 [00:01<00:01, 53.62it/s, Epoch: 70, Batch: 99,Loss: -2.787,Avg.Loss: -2.675,LR: 1.05E-04]Training epoch 70:  65%|██████▍   | 99/153 [00:01<00:01, 53.62it/s, Epoch: 70, Batch: 100,Loss: -2.693,Avg.Loss: -2.676,LR: 1.05E-04]Training epoch 70:  65%|██████▌   | 100/153 [00:01<00:00, 53.62it/s, Epoch: 70, Batch: 101,Loss: -2.693,Avg.Loss: -2.676,LR: 1.05E-04]Training epoch 70:  66%|██████▌   | 101/153 [00:01<00:00, 53.62it/s, Epoch: 70, Batch: 102,Loss: -3.129,Avg.Loss: -2.680,LR: 1.05E-04]Training epoch 70:  67%|██████▋   | 102/153 [00:01<00:00, 53.52it/s, Epoch: 70, Batch: 102,Loss: -3.129,Avg.Loss: -2.680,LR: 1.05E-04]Training epoch 70:  67%|██████▋   | 102/153 [00:01<00:00, 53.52it/s, Epoch: 70, Batch: 103,Loss: -2.579,Avg.Loss: -2.679,LR: 1.05E-04]Training epoch 70:  67%|██████▋   | 103/153 [00:01<00:00, 53.52it/s, Epoch: 70, Batch: 104,Loss: -2.670,Avg.Loss: -2.679,LR: 1.05E-04]Training epoch 70:  68%|██████▊   | 104/153 [00:01<00:00, 53.52it/s, Epoch: 70, Batch: 105,Loss: -2.733,Avg.Loss: -2.680,LR: 1.05E-04]Training epoch 70:  69%|██████▊   | 105/153 [00:01<00:00, 53.52it/s, Epoch: 70, Batch: 106,Loss: -2.742,Avg.Loss: -2.680,LR: 1.05E-04]Training epoch 70:  69%|██████▉   | 106/153 [00:01<00:00, 53.52it/s, Epoch: 70, Batch: 107,Loss: -2.754,Avg.Loss: -2.681,LR: 1.05E-04]Training epoch 70:  70%|██████▉   | 107/153 [00:01<00:00, 53.52it/s, Epoch: 70, Batch: 108,Loss: -3.027,Avg.Loss: -2.684,LR: 1.05E-04]Training epoch 70:  71%|███████   | 108/153 [00:01<00:00, 53.62it/s, Epoch: 70, Batch: 108,Loss: -3.027,Avg.Loss: -2.684,LR: 1.05E-04]Training epoch 70:  71%|███████   | 108/153 [00:02<00:00, 53.62it/s, Epoch: 70, Batch: 109,Loss: -3.065,Avg.Loss: -2.688,LR: 1.05E-04]Training epoch 70:  71%|███████   | 109/153 [00:02<00:00, 53.62it/s, Epoch: 70, Batch: 110,Loss: -2.747,Avg.Loss: -2.688,LR: 1.05E-04]Training epoch 70:  72%|███████▏  | 110/153 [00:02<00:00, 53.62it/s, Epoch: 70, Batch: 111,Loss: -1.976,Avg.Loss: -2.682,LR: 1.05E-04]Training epoch 70:  73%|███████▎  | 111/153 [00:02<00:00, 53.62it/s, Epoch: 70, Batch: 112,Loss: -2.568,Avg.Loss: -2.681,LR: 1.05E-04]Training epoch 70:  73%|███████▎  | 112/153 [00:02<00:00, 53.62it/s, Epoch: 70, Batch: 113,Loss: -2.999,Avg.Loss: -2.684,LR: 1.05E-04]Training epoch 70:  74%|███████▍  | 113/153 [00:02<00:00, 53.62it/s, Epoch: 70, Batch: 114,Loss: -2.733,Avg.Loss: -2.684,LR: 1.05E-04]Training epoch 70:  75%|███████▍  | 114/153 [00:02<00:00, 53.48it/s, Epoch: 70, Batch: 114,Loss: -2.733,Avg.Loss: -2.684,LR: 1.05E-04]Training epoch 70:  75%|███████▍  | 114/153 [00:02<00:00, 53.48it/s, Epoch: 70, Batch: 115,Loss: -2.703,Avg.Loss: -2.684,LR: 1.05E-04]Training epoch 70:  75%|███████▌  | 115/153 [00:02<00:00, 53.48it/s, Epoch: 70, Batch: 116,Loss: -2.766,Avg.Loss: -2.685,LR: 1.05E-04]Training epoch 70:  76%|███████▌  | 116/153 [00:02<00:00, 53.48it/s, Epoch: 70, Batch: 117,Loss: -3.137,Avg.Loss: -2.689,LR: 1.05E-04]Training epoch 70:  76%|███████▋  | 117/153 [00:02<00:00, 53.48it/s, Epoch: 70, Batch: 118,Loss: -2.415,Avg.Loss: -2.686,LR: 1.05E-04]Training epoch 70:  77%|███████▋  | 118/153 [00:02<00:00, 53.48it/s, Epoch: 70, Batch: 119,Loss: -2.912,Avg.Loss: -2.688,LR: 1.04E-04]Training epoch 70:  78%|███████▊  | 119/153 [00:02<00:00, 53.48it/s, Epoch: 70, Batch: 120,Loss: -3.084,Avg.Loss: -2.692,LR: 1.04E-04]Training epoch 70:  78%|███████▊  | 120/153 [00:02<00:00, 53.37it/s, Epoch: 70, Batch: 120,Loss: -3.084,Avg.Loss: -2.692,LR: 1.04E-04]Training epoch 70:  78%|███████▊  | 120/153 [00:02<00:00, 53.37it/s, Epoch: 70, Batch: 121,Loss: -2.968,Avg.Loss: -2.694,LR: 1.04E-04]Training epoch 70:  79%|███████▉  | 121/153 [00:02<00:00, 53.37it/s, Epoch: 70, Batch: 122,Loss: -3.070,Avg.Loss: -2.697,LR: 1.04E-04]Training epoch 70:  80%|███████▉  | 122/153 [00:02<00:00, 53.37it/s, Epoch: 70, Batch: 123,Loss: -3.121,Avg.Loss: -2.700,LR: 1.04E-04]Training epoch 70:  80%|████████  | 123/153 [00:02<00:00, 53.37it/s, Epoch: 70, Batch: 124,Loss: -3.092,Avg.Loss: -2.704,LR: 1.04E-04]Training epoch 70:  81%|████████  | 124/153 [00:02<00:00, 53.37it/s, Epoch: 70, Batch: 125,Loss: -2.780,Avg.Loss: -2.704,LR: 1.04E-04]Training epoch 70:  82%|████████▏ | 125/153 [00:02<00:00, 53.37it/s, Epoch: 70, Batch: 126,Loss: -2.917,Avg.Loss: -2.706,LR: 1.04E-04]Training epoch 70:  82%|████████▏ | 126/153 [00:02<00:00, 53.64it/s, Epoch: 70, Batch: 126,Loss: -2.917,Avg.Loss: -2.706,LR: 1.04E-04]Training epoch 70:  82%|████████▏ | 126/153 [00:02<00:00, 53.64it/s, Epoch: 70, Batch: 127,Loss: -2.131,Avg.Loss: -2.701,LR: 1.04E-04]Training epoch 70:  83%|████████▎ | 127/153 [00:02<00:00, 53.64it/s, Epoch: 70, Batch: 128,Loss: -1.266,Avg.Loss: -2.690,LR: 1.04E-04]Training epoch 70:  84%|████████▎ | 128/153 [00:02<00:00, 53.64it/s, Epoch: 70, Batch: 129,Loss: -2.095,Avg.Loss: -2.685,LR: 1.04E-04]Training epoch 70:  84%|████████▍ | 129/153 [00:02<00:00, 53.64it/s, Epoch: 70, Batch: 130,Loss: -1.932,Avg.Loss: -2.680,LR: 1.04E-04]Training epoch 70:  85%|████████▍ | 130/153 [00:02<00:00, 53.64it/s, Epoch: 70, Batch: 131,Loss: -3.242,Avg.Loss: -2.684,LR: 1.04E-04]Training epoch 70:  86%|████████▌ | 131/153 [00:02<00:00, 53.64it/s, Epoch: 70, Batch: 132,Loss: -2.613,Avg.Loss: -2.683,LR: 1.04E-04]Training epoch 70:  86%|████████▋ | 132/153 [00:02<00:00, 53.81it/s, Epoch: 70, Batch: 132,Loss: -2.613,Avg.Loss: -2.683,LR: 1.04E-04]Training epoch 70:  86%|████████▋ | 132/153 [00:02<00:00, 53.81it/s, Epoch: 70, Batch: 133,Loss: -2.370,Avg.Loss: -2.681,LR: 1.04E-04]Training epoch 70:  87%|████████▋ | 133/153 [00:02<00:00, 53.81it/s, Epoch: 70, Batch: 134,Loss: -1.953,Avg.Loss: -2.676,LR: 1.04E-04]Training epoch 70:  88%|████████▊ | 134/153 [00:02<00:00, 53.81it/s, Epoch: 70, Batch: 135,Loss: -2.172,Avg.Loss: -2.672,LR: 1.04E-04]Training epoch 70:  88%|████████▊ | 135/153 [00:02<00:00, 53.81it/s, Epoch: 70, Batch: 136,Loss: -2.182,Avg.Loss: -2.668,LR: 1.04E-04]Training epoch 70:  89%|████████▉ | 136/153 [00:02<00:00, 53.81it/s, Epoch: 70, Batch: 137,Loss: -2.965,Avg.Loss: -2.670,LR: 1.04E-04]Training epoch 70:  90%|████████▉ | 137/153 [00:02<00:00, 53.81it/s, Epoch: 70, Batch: 138,Loss: -2.388,Avg.Loss: -2.668,LR: 1.04E-04]Training epoch 70:  90%|█████████ | 138/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 138,Loss: -2.388,Avg.Loss: -2.668,LR: 1.04E-04]Training epoch 70:  90%|█████████ | 138/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 139,Loss: -2.045,Avg.Loss: -2.664,LR: 1.04E-04]Training epoch 70:  91%|█████████ | 139/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 140,Loss: -2.256,Avg.Loss: -2.661,LR: 1.04E-04]Training epoch 70:  92%|█████████▏| 140/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 141,Loss: -2.956,Avg.Loss: -2.663,LR: 1.04E-04]Training epoch 70:  92%|█████████▏| 141/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 142,Loss: -2.852,Avg.Loss: -2.664,LR: 1.04E-04]Training epoch 70:  93%|█████████▎| 142/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 143,Loss: -2.721,Avg.Loss: -2.665,LR: 1.03E-04]Training epoch 70:  93%|█████████▎| 143/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 144,Loss: -2.756,Avg.Loss: -2.665,LR: 1.03E-04]Training epoch 70:  94%|█████████▍| 144/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 144,Loss: -2.756,Avg.Loss: -2.665,LR: 1.03E-04]Training epoch 70:  94%|█████████▍| 144/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 145,Loss: -3.056,Avg.Loss: -2.668,LR: 1.03E-04]Training epoch 70:  95%|█████████▍| 145/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 146,Loss: -2.976,Avg.Loss: -2.670,LR: 1.03E-04]Training epoch 70:  95%|█████████▌| 146/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 147,Loss: -2.532,Avg.Loss: -2.669,LR: 1.03E-04]Training epoch 70:  96%|█████████▌| 147/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 148,Loss: -1.791,Avg.Loss: -2.663,LR: 1.03E-04]Training epoch 70:  97%|█████████▋| 148/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 149,Loss: -2.049,Avg.Loss: -2.659,LR: 1.03E-04]Training epoch 70:  97%|█████████▋| 149/153 [00:02<00:00, 53.89it/s, Epoch: 70, Batch: 150,Loss: -2.423,Avg.Loss: -2.658,LR: 1.03E-04]Training epoch 70:  98%|█████████▊| 150/153 [00:02<00:00, 53.86it/s, Epoch: 70, Batch: 150,Loss: -2.423,Avg.Loss: -2.658,LR: 1.03E-04]Training epoch 70:  98%|█████████▊| 150/153 [00:02<00:00, 53.86it/s, Epoch: 70, Batch: 151,Loss: -2.748,Avg.Loss: -2.658,LR: 1.03E-04]Training epoch 70:  99%|█████████▊| 151/153 [00:02<00:00, 53.86it/s, Epoch: 70, Batch: 152,Loss: -2.930,Avg.Loss: -2.660,LR: 1.03E-04]Training epoch 70:  99%|█████████▉| 152/153 [00:02<00:00, 53.86it/s, Epoch: 70, Batch: 153,Loss: -1.393,Avg.Loss: -2.652,LR: 1.03E-04]Training epoch 70: 100%|██████████| 153/153 [00:02<00:00, 53.93it/s, Epoch: 70, Batch: 153,Loss: -1.393,Avg.Loss: -2.652,LR: 1.03E-04]
Training epoch 71:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 71:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 71, Batch: 1,Loss: -2.614,Avg.Loss: -2.614,LR: 1.03E-04]Training epoch 71:   1%|          | 1/153 [00:00<00:06, 25.24it/s, Epoch: 71, Batch: 2,Loss: -2.404,Avg.Loss: -2.509,LR: 1.03E-04]Training epoch 71:   1%|▏         | 2/153 [00:00<00:04, 35.53it/s, Epoch: 71, Batch: 3,Loss: -2.970,Avg.Loss: -2.663,LR: 1.03E-04]Training epoch 71:   2%|▏         | 3/153 [00:00<00:03, 40.31it/s, Epoch: 71, Batch: 4,Loss: -2.607,Avg.Loss: -2.649,LR: 1.03E-04]Training epoch 71:   3%|▎         | 4/153 [00:00<00:03, 42.87it/s, Epoch: 71, Batch: 5,Loss: -2.610,Avg.Loss: -2.641,LR: 1.03E-04]Training epoch 71:   3%|▎         | 5/153 [00:00<00:03, 44.74it/s, Epoch: 71, Batch: 6,Loss: -2.010,Avg.Loss: -2.536,LR: 1.03E-04]Training epoch 71:   4%|▍         | 6/153 [00:00<00:02, 53.60it/s, Epoch: 71, Batch: 6,Loss: -2.010,Avg.Loss: -2.536,LR: 1.03E-04]Training epoch 71:   4%|▍         | 6/153 [00:00<00:02, 53.60it/s, Epoch: 71, Batch: 7,Loss: -2.448,Avg.Loss: -2.523,LR: 1.03E-04]Training epoch 71:   5%|▍         | 7/153 [00:00<00:02, 53.60it/s, Epoch: 71, Batch: 8,Loss: -2.584,Avg.Loss: -2.531,LR: 1.03E-04]Training epoch 71:   5%|▌         | 8/153 [00:00<00:02, 53.60it/s, Epoch: 71, Batch: 9,Loss: -2.628,Avg.Loss: -2.542,LR: 1.03E-04]Training epoch 71:   6%|▌         | 9/153 [00:00<00:02, 53.60it/s, Epoch: 71, Batch: 10,Loss: -2.665,Avg.Loss: -2.554,LR: 1.03E-04]Training epoch 71:   7%|▋         | 10/153 [00:00<00:02, 53.60it/s, Epoch: 71, Batch: 11,Loss: -2.398,Avg.Loss: -2.540,LR: 1.03E-04]Training epoch 71:   7%|▋         | 11/153 [00:00<00:02, 53.60it/s, Epoch: 71, Batch: 12,Loss: -2.822,Avg.Loss: -2.563,LR: 1.03E-04]Training epoch 71:   8%|▊         | 12/153 [00:00<00:02, 54.02it/s, Epoch: 71, Batch: 12,Loss: -2.822,Avg.Loss: -2.563,LR: 1.03E-04]Training epoch 71:   8%|▊         | 12/153 [00:00<00:02, 54.02it/s, Epoch: 71, Batch: 13,Loss: -2.265,Avg.Loss: -2.540,LR: 1.03E-04]Training epoch 71:   8%|▊         | 13/153 [00:00<00:02, 54.02it/s, Epoch: 71, Batch: 14,Loss: -2.388,Avg.Loss: -2.529,LR: 1.02E-04]Training epoch 71:   9%|▉         | 14/153 [00:00<00:02, 54.02it/s, Epoch: 71, Batch: 15,Loss: -1.618,Avg.Loss: -2.469,LR: 1.02E-04]Training epoch 71:  10%|▉         | 15/153 [00:00<00:02, 54.02it/s, Epoch: 71, Batch: 16,Loss: -2.167,Avg.Loss: -2.450,LR: 1.02E-04]Training epoch 71:  10%|█         | 16/153 [00:00<00:02, 54.02it/s, Epoch: 71, Batch: 17,Loss: -2.387,Avg.Loss: -2.446,LR: 1.02E-04]Training epoch 71:  11%|█         | 17/153 [00:00<00:02, 54.02it/s, Epoch: 71, Batch: 18,Loss: -2.914,Avg.Loss: -2.472,LR: 1.02E-04]Training epoch 71:  12%|█▏        | 18/153 [00:00<00:02, 53.83it/s, Epoch: 71, Batch: 18,Loss: -2.914,Avg.Loss: -2.472,LR: 1.02E-04]Training epoch 71:  12%|█▏        | 18/153 [00:00<00:02, 53.83it/s, Epoch: 71, Batch: 19,Loss: -2.381,Avg.Loss: -2.467,LR: 1.02E-04]Training epoch 71:  12%|█▏        | 19/153 [00:00<00:02, 53.83it/s, Epoch: 71, Batch: 20,Loss: -2.691,Avg.Loss: -2.479,LR: 1.02E-04]Training epoch 71:  13%|█▎        | 20/153 [00:00<00:02, 53.83it/s, Epoch: 71, Batch: 21,Loss: -2.688,Avg.Loss: -2.489,LR: 1.02E-04]Training epoch 71:  14%|█▎        | 21/153 [00:00<00:02, 53.83it/s, Epoch: 71, Batch: 22,Loss: -3.101,Avg.Loss: -2.516,LR: 1.02E-04]Training epoch 71:  14%|█▍        | 22/153 [00:00<00:02, 53.83it/s, Epoch: 71, Batch: 23,Loss: -2.312,Avg.Loss: -2.507,LR: 1.02E-04]Training epoch 71:  15%|█▌        | 23/153 [00:00<00:02, 53.83it/s, Epoch: 71, Batch: 24,Loss: -2.636,Avg.Loss: -2.513,LR: 1.02E-04]Training epoch 71:  16%|█▌        | 24/153 [00:00<00:02, 51.16it/s, Epoch: 71, Batch: 24,Loss: -2.636,Avg.Loss: -2.513,LR: 1.02E-04]Training epoch 71:  16%|█▌        | 24/153 [00:00<00:02, 51.16it/s, Epoch: 71, Batch: 25,Loss: -2.439,Avg.Loss: -2.510,LR: 1.02E-04]Training epoch 71:  16%|█▋        | 25/153 [00:00<00:02, 51.16it/s, Epoch: 71, Batch: 26,Loss: -2.201,Avg.Loss: -2.498,LR: 1.02E-04]Training epoch 71:  17%|█▋        | 26/153 [00:00<00:02, 51.16it/s, Epoch: 71, Batch: 27,Loss: -2.416,Avg.Loss: -2.495,LR: 1.02E-04]Training epoch 71:  18%|█▊        | 27/153 [00:00<00:02, 51.16it/s, Epoch: 71, Batch: 28,Loss: -1.507,Avg.Loss: -2.460,LR: 1.02E-04]Training epoch 71:  18%|█▊        | 28/153 [00:00<00:02, 51.16it/s, Epoch: 71, Batch: 29,Loss: -1.866,Avg.Loss: -2.439,LR: 1.02E-04]Training epoch 71:  19%|█▉        | 29/153 [00:00<00:02, 51.16it/s, Epoch: 71, Batch: 30,Loss: -2.689,Avg.Loss: -2.448,LR: 1.02E-04]Training epoch 71:  20%|█▉        | 30/153 [00:00<00:02, 51.28it/s, Epoch: 71, Batch: 30,Loss: -2.689,Avg.Loss: -2.448,LR: 1.02E-04]Training epoch 71:  20%|█▉        | 30/153 [00:00<00:02, 51.28it/s, Epoch: 71, Batch: 31,Loss: -2.180,Avg.Loss: -2.439,LR: 1.02E-04]Training epoch 71:  20%|██        | 31/153 [00:00<00:02, 51.28it/s, Epoch: 71, Batch: 32,Loss: -1.393,Avg.Loss: -2.406,LR: 1.02E-04]Training epoch 71:  21%|██        | 32/153 [00:00<00:02, 51.28it/s, Epoch: 71, Batch: 33,Loss: -1.966,Avg.Loss: -2.393,LR: 1.02E-04]Training epoch 71:  22%|██▏       | 33/153 [00:00<00:02, 51.28it/s, Epoch: 71, Batch: 34,Loss: -2.268,Avg.Loss: -2.389,LR: 1.02E-04]Training epoch 71:  22%|██▏       | 34/153 [00:00<00:02, 51.28it/s, Epoch: 71, Batch: 35,Loss: -2.758,Avg.Loss: -2.400,LR: 1.02E-04]Training epoch 71:  23%|██▎       | 35/153 [00:00<00:02, 51.28it/s, Epoch: 71, Batch: 36,Loss: -2.874,Avg.Loss: -2.413,LR: 1.02E-04]Training epoch 71:  24%|██▎       | 36/153 [00:00<00:02, 51.88it/s, Epoch: 71, Batch: 36,Loss: -2.874,Avg.Loss: -2.413,LR: 1.02E-04]Training epoch 71:  24%|██▎       | 36/153 [00:00<00:02, 51.88it/s, Epoch: 71, Batch: 37,Loss: -2.384,Avg.Loss: -2.412,LR: 1.02E-04]Training epoch 71:  24%|██▍       | 37/153 [00:00<00:02, 51.88it/s, Epoch: 71, Batch: 38,Loss: -2.680,Avg.Loss: -2.419,LR: 1.01E-04]Training epoch 71:  25%|██▍       | 38/153 [00:00<00:02, 51.88it/s, Epoch: 71, Batch: 39,Loss: -2.098,Avg.Loss: -2.411,LR: 1.01E-04]Training epoch 71:  25%|██▌       | 39/153 [00:00<00:02, 51.88it/s, Epoch: 71, Batch: 40,Loss: -3.107,Avg.Loss: -2.428,LR: 1.01E-04]Training epoch 71:  26%|██▌       | 40/153 [00:00<00:02, 51.88it/s, Epoch: 71, Batch: 41,Loss: -2.630,Avg.Loss: -2.433,LR: 1.01E-04]Training epoch 71:  27%|██▋       | 41/153 [00:00<00:02, 51.88it/s, Epoch: 71, Batch: 42,Loss: -2.345,Avg.Loss: -2.431,LR: 1.01E-04]Training epoch 71:  27%|██▋       | 42/153 [00:00<00:02, 52.44it/s, Epoch: 71, Batch: 42,Loss: -2.345,Avg.Loss: -2.431,LR: 1.01E-04]Training epoch 71:  27%|██▋       | 42/153 [00:00<00:02, 52.44it/s, Epoch: 71, Batch: 43,Loss: -2.417,Avg.Loss: -2.431,LR: 1.01E-04]Training epoch 71:  28%|██▊       | 43/153 [00:00<00:02, 52.44it/s, Epoch: 71, Batch: 44,Loss: -1.900,Avg.Loss: -2.419,LR: 1.01E-04]Training epoch 71:  29%|██▉       | 44/153 [00:00<00:02, 52.44it/s, Epoch: 71, Batch: 45,Loss: -2.573,Avg.Loss: -2.422,LR: 1.01E-04]Training epoch 71:  29%|██▉       | 45/153 [00:00<00:02, 52.44it/s, Epoch: 71, Batch: 46,Loss: -1.915,Avg.Loss: -2.411,LR: 1.01E-04]Training epoch 71:  30%|███       | 46/153 [00:00<00:02, 52.44it/s, Epoch: 71, Batch: 47,Loss: -1.942,Avg.Loss: -2.401,LR: 1.01E-04]Training epoch 71:  31%|███       | 47/153 [00:00<00:02, 52.44it/s, Epoch: 71, Batch: 48,Loss: -1.940,Avg.Loss: -2.392,LR: 1.01E-04]Training epoch 71:  31%|███▏      | 48/153 [00:00<00:02, 52.49it/s, Epoch: 71, Batch: 48,Loss: -1.940,Avg.Loss: -2.392,LR: 1.01E-04]Training epoch 71:  31%|███▏      | 48/153 [00:00<00:02, 52.49it/s, Epoch: 71, Batch: 49,Loss: -2.158,Avg.Loss: -2.387,LR: 1.01E-04]Training epoch 71:  32%|███▏      | 49/153 [00:00<00:01, 52.49it/s, Epoch: 71, Batch: 50,Loss: -2.307,Avg.Loss: -2.385,LR: 1.01E-04]Training epoch 71:  33%|███▎      | 50/153 [00:00<00:01, 52.49it/s, Epoch: 71, Batch: 51,Loss: -2.753,Avg.Loss: -2.392,LR: 1.01E-04]Training epoch 71:  33%|███▎      | 51/153 [00:00<00:01, 52.49it/s, Epoch: 71, Batch: 52,Loss: -2.559,Avg.Loss: -2.396,LR: 1.01E-04]Training epoch 71:  34%|███▍      | 52/153 [00:01<00:01, 52.49it/s, Epoch: 71, Batch: 53,Loss: -2.524,Avg.Loss: -2.398,LR: 1.01E-04]Training epoch 71:  35%|███▍      | 53/153 [00:01<00:01, 52.49it/s, Epoch: 71, Batch: 54,Loss: -2.724,Avg.Loss: -2.404,LR: 1.01E-04]Training epoch 71:  35%|███▌      | 54/153 [00:01<00:01, 52.64it/s, Epoch: 71, Batch: 54,Loss: -2.724,Avg.Loss: -2.404,LR: 1.01E-04]Training epoch 71:  35%|███▌      | 54/153 [00:01<00:01, 52.64it/s, Epoch: 71, Batch: 55,Loss: -2.612,Avg.Loss: -2.408,LR: 1.01E-04]Training epoch 71:  36%|███▌      | 55/153 [00:01<00:01, 52.64it/s, Epoch: 71, Batch: 56,Loss: -2.038,Avg.Loss: -2.401,LR: 1.01E-04]Training epoch 71:  37%|███▋      | 56/153 [00:01<00:01, 52.64it/s, Epoch: 71, Batch: 57,Loss: -1.439,Avg.Loss: -2.384,LR: 1.01E-04]Training epoch 71:  37%|███▋      | 57/153 [00:01<00:01, 52.64it/s, Epoch: 71, Batch: 58,Loss: -1.704,Avg.Loss: -2.373,LR: 1.01E-04]Training epoch 71:  38%|███▊      | 58/153 [00:01<00:01, 52.64it/s, Epoch: 71, Batch: 59,Loss: -2.398,Avg.Loss: -2.373,LR: 1.01E-04]Training epoch 71:  39%|███▊      | 59/153 [00:01<00:01, 52.64it/s, Epoch: 71, Batch: 60,Loss: -2.853,Avg.Loss: -2.381,LR: 1.01E-04]Training epoch 71:  39%|███▉      | 60/153 [00:01<00:01, 52.85it/s, Epoch: 71, Batch: 60,Loss: -2.853,Avg.Loss: -2.381,LR: 1.01E-04]Training epoch 71:  39%|███▉      | 60/153 [00:01<00:01, 52.85it/s, Epoch: 71, Batch: 61,Loss: -3.333,Avg.Loss: -2.397,LR: 1.01E-04]Training epoch 71:  40%|███▉      | 61/153 [00:01<00:01, 52.85it/s, Epoch: 71, Batch: 62,Loss: -3.166,Avg.Loss: -2.409,LR: 1.00E-04]Training epoch 71:  41%|████      | 62/153 [00:01<00:01, 52.85it/s, Epoch: 71, Batch: 63,Loss: -2.335,Avg.Loss: -2.408,LR: 1.00E-04]Training epoch 71:  41%|████      | 63/153 [00:01<00:01, 52.85it/s, Epoch: 71, Batch: 64,Loss: -3.042,Avg.Loss: -2.418,LR: 1.00E-04]Training epoch 71:  42%|████▏     | 64/153 [00:01<00:01, 52.85it/s, Epoch: 71, Batch: 65,Loss: -2.908,Avg.Loss: -2.425,LR: 1.00E-04]Training epoch 71:  42%|████▏     | 65/153 [00:01<00:01, 52.85it/s, Epoch: 71, Batch: 66,Loss: -2.789,Avg.Loss: -2.431,LR: 1.00E-04]Training epoch 71:  43%|████▎     | 66/153 [00:01<00:01, 52.82it/s, Epoch: 71, Batch: 66,Loss: -2.789,Avg.Loss: -2.431,LR: 1.00E-04]Training epoch 71:  43%|████▎     | 66/153 [00:01<00:01, 52.82it/s, Epoch: 71, Batch: 67,Loss: -2.751,Avg.Loss: -2.436,LR: 1.00E-04]Training epoch 71:  44%|████▍     | 67/153 [00:01<00:01, 52.82it/s, Epoch: 71, Batch: 68,Loss: -2.578,Avg.Loss: -2.438,LR: 1.00E-04]Training epoch 71:  44%|████▍     | 68/153 [00:01<00:01, 52.82it/s, Epoch: 71, Batch: 69,Loss: -2.824,Avg.Loss: -2.443,LR: 1.00E-04]Training epoch 71:  45%|████▌     | 69/153 [00:01<00:01, 52.82it/s, Epoch: 71, Batch: 70,Loss: -2.820,Avg.Loss: -2.449,LR: 1.00E-04]Training epoch 71:  46%|████▌     | 70/153 [00:01<00:01, 52.82it/s, Epoch: 71, Batch: 71,Loss: -2.354,Avg.Loss: -2.447,LR: 1.00E-04]Training epoch 71:  46%|████▋     | 71/153 [00:01<00:01, 52.82it/s, Epoch: 71, Batch: 72,Loss: -2.732,Avg.Loss: -2.451,LR: 1.00E-04]Training epoch 71:  47%|████▋     | 72/153 [00:01<00:01, 52.94it/s, Epoch: 71, Batch: 72,Loss: -2.732,Avg.Loss: -2.451,LR: 1.00E-04]Training epoch 71:  47%|████▋     | 72/153 [00:01<00:01, 52.94it/s, Epoch: 71, Batch: 73,Loss: -2.533,Avg.Loss: -2.452,LR: 1.00E-04]Training epoch 71:  48%|████▊     | 73/153 [00:01<00:01, 52.94it/s, Epoch: 71, Batch: 74,Loss: -3.312,Avg.Loss: -2.464,LR: 1.00E-04]Training epoch 71:  48%|████▊     | 74/153 [00:01<00:01, 52.94it/s, Epoch: 71, Batch: 75,Loss: -2.864,Avg.Loss: -2.469,LR: 1.00E-04]Training epoch 71:  49%|████▉     | 75/153 [00:01<00:01, 52.94it/s, Epoch: 71, Batch: 76,Loss: -2.395,Avg.Loss: -2.468,LR: 9.99E-05]Training epoch 71:  50%|████▉     | 76/153 [00:01<00:01, 52.94it/s, Epoch: 71, Batch: 77,Loss: -2.577,Avg.Loss: -2.470,LR: 9.99E-05]Training epoch 71:  50%|█████     | 77/153 [00:01<00:01, 52.94it/s, Epoch: 71, Batch: 78,Loss: -2.530,Avg.Loss: -2.471,LR: 9.98E-05]Training epoch 71:  51%|█████     | 78/153 [00:01<00:01, 53.01it/s, Epoch: 71, Batch: 78,Loss: -2.530,Avg.Loss: -2.471,LR: 9.98E-05]Training epoch 71:  51%|█████     | 78/153 [00:01<00:01, 53.01it/s, Epoch: 71, Batch: 79,Loss: -2.617,Avg.Loss: -2.472,LR: 9.98E-05]Training epoch 71:  52%|█████▏    | 79/153 [00:01<00:01, 53.01it/s, Epoch: 71, Batch: 80,Loss: -3.087,Avg.Loss: -2.480,LR: 9.98E-05]Training epoch 71:  52%|█████▏    | 80/153 [00:01<00:01, 53.01it/s, Epoch: 71, Batch: 81,Loss: -2.667,Avg.Loss: -2.482,LR: 9.97E-05]Training epoch 71:  53%|█████▎    | 81/153 [00:01<00:01, 53.01it/s, Epoch: 71, Batch: 82,Loss: -2.798,Avg.Loss: -2.486,LR: 9.97E-05]Training epoch 71:  54%|█████▎    | 82/153 [00:01<00:01, 53.01it/s, Epoch: 71, Batch: 83,Loss: -2.686,Avg.Loss: -2.489,LR: 9.96E-05]Training epoch 71:  54%|█████▍    | 83/153 [00:01<00:01, 53.01it/s, Epoch: 71, Batch: 84,Loss: -2.566,Avg.Loss: -2.490,LR: 9.96E-05]Training epoch 71:  55%|█████▍    | 84/153 [00:01<00:01, 53.15it/s, Epoch: 71, Batch: 84,Loss: -2.566,Avg.Loss: -2.490,LR: 9.96E-05]Training epoch 71:  55%|█████▍    | 84/153 [00:01<00:01, 53.15it/s, Epoch: 71, Batch: 85,Loss: -2.491,Avg.Loss: -2.490,LR: 9.95E-05]Training epoch 71:  56%|█████▌    | 85/153 [00:01<00:01, 53.15it/s, Epoch: 71, Batch: 86,Loss: -2.520,Avg.Loss: -2.490,LR: 9.95E-05]Training epoch 71:  56%|█████▌    | 86/153 [00:01<00:01, 53.15it/s, Epoch: 71, Batch: 87,Loss: -2.920,Avg.Loss: -2.495,LR: 9.95E-05]Training epoch 71:  57%|█████▋    | 87/153 [00:01<00:01, 53.15it/s, Epoch: 71, Batch: 88,Loss: -3.053,Avg.Loss: -2.501,LR: 9.94E-05]Training epoch 71:  58%|█████▊    | 88/153 [00:01<00:01, 53.15it/s, Epoch: 71, Batch: 89,Loss: -3.196,Avg.Loss: -2.509,LR: 9.94E-05]Training epoch 71:  58%|█████▊    | 89/153 [00:01<00:01, 53.15it/s, Epoch: 71, Batch: 90,Loss: -2.804,Avg.Loss: -2.512,LR: 9.93E-05]Training epoch 71:  59%|█████▉    | 90/153 [00:01<00:01, 53.32it/s, Epoch: 71, Batch: 90,Loss: -2.804,Avg.Loss: -2.512,LR: 9.93E-05]Training epoch 71:  59%|█████▉    | 90/153 [00:01<00:01, 53.32it/s, Epoch: 71, Batch: 91,Loss: -3.013,Avg.Loss: -2.518,LR: 9.93E-05]Training epoch 71:  59%|█████▉    | 91/153 [00:01<00:01, 53.32it/s, Epoch: 71, Batch: 92,Loss: -3.001,Avg.Loss: -2.523,LR: 9.93E-05]Training epoch 71:  60%|██████    | 92/153 [00:01<00:01, 53.32it/s, Epoch: 71, Batch: 93,Loss: -2.739,Avg.Loss: -2.525,LR: 9.92E-05]Training epoch 71:  61%|██████    | 93/153 [00:01<00:01, 53.32it/s, Epoch: 71, Batch: 94,Loss: -2.652,Avg.Loss: -2.527,LR: 9.92E-05]Training epoch 71:  61%|██████▏   | 94/153 [00:01<00:01, 53.32it/s, Epoch: 71, Batch: 95,Loss: -2.830,Avg.Loss: -2.530,LR: 9.91E-05]Training epoch 71:  62%|██████▏   | 95/153 [00:01<00:01, 53.32it/s, Epoch: 71, Batch: 96,Loss: -3.314,Avg.Loss: -2.538,LR: 9.91E-05]Training epoch 71:  63%|██████▎   | 96/153 [00:01<00:01, 53.49it/s, Epoch: 71, Batch: 96,Loss: -3.314,Avg.Loss: -2.538,LR: 9.91E-05]Training epoch 71:  63%|██████▎   | 96/153 [00:01<00:01, 53.49it/s, Epoch: 71, Batch: 97,Loss: -2.839,Avg.Loss: -2.541,LR: 9.91E-05]Training epoch 71:  63%|██████▎   | 97/153 [00:01<00:01, 53.49it/s, Epoch: 71, Batch: 98,Loss: -2.545,Avg.Loss: -2.541,LR: 9.90E-05]Training epoch 71:  64%|██████▍   | 98/153 [00:01<00:01, 53.49it/s, Epoch: 71, Batch: 99,Loss: -2.413,Avg.Loss: -2.540,LR: 9.90E-05]Training epoch 71:  65%|██████▍   | 99/153 [00:01<00:01, 53.49it/s, Epoch: 71, Batch: 100,Loss: -2.831,Avg.Loss: -2.543,LR: 9.89E-05]Training epoch 71:  65%|██████▌   | 100/153 [00:01<00:00, 53.49it/s, Epoch: 71, Batch: 101,Loss: -3.077,Avg.Loss: -2.548,LR: 9.89E-05]Training epoch 71:  66%|██████▌   | 101/153 [00:01<00:00, 53.49it/s, Epoch: 71, Batch: 102,Loss: -2.579,Avg.Loss: -2.548,LR: 9.89E-05]Training epoch 71:  67%|██████▋   | 102/153 [00:01<00:00, 53.46it/s, Epoch: 71, Batch: 102,Loss: -2.579,Avg.Loss: -2.548,LR: 9.89E-05]Training epoch 71:  67%|██████▋   | 102/153 [00:01<00:00, 53.46it/s, Epoch: 71, Batch: 103,Loss: -2.879,Avg.Loss: -2.552,LR: 9.88E-05]Training epoch 71:  67%|██████▋   | 103/153 [00:01<00:00, 53.46it/s, Epoch: 71, Batch: 104,Loss: -2.474,Avg.Loss: -2.551,LR: 9.88E-05]Training epoch 71:  68%|██████▊   | 104/153 [00:01<00:00, 53.46it/s, Epoch: 71, Batch: 105,Loss: -2.987,Avg.Loss: -2.555,LR: 9.87E-05]Training epoch 71:  69%|██████▊   | 105/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 106,Loss: -2.954,Avg.Loss: -2.559,LR: 9.87E-05]Training epoch 71:  69%|██████▉   | 106/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 107,Loss: -3.211,Avg.Loss: -2.565,LR: 9.86E-05]Training epoch 71:  70%|██████▉   | 107/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 108,Loss: -2.338,Avg.Loss: -2.563,LR: 9.86E-05]Training epoch 71:  71%|███████   | 108/153 [00:02<00:00, 53.39it/s, Epoch: 71, Batch: 108,Loss: -2.338,Avg.Loss: -2.563,LR: 9.86E-05]Training epoch 71:  71%|███████   | 108/153 [00:02<00:00, 53.39it/s, Epoch: 71, Batch: 109,Loss: -2.599,Avg.Loss: -2.563,LR: 9.86E-05]Training epoch 71:  71%|███████   | 109/153 [00:02<00:00, 53.39it/s, Epoch: 71, Batch: 110,Loss: -2.694,Avg.Loss: -2.564,LR: 9.85E-05]Training epoch 71:  72%|███████▏  | 110/153 [00:02<00:00, 53.39it/s, Epoch: 71, Batch: 111,Loss: -2.502,Avg.Loss: -2.564,LR: 9.85E-05]Training epoch 71:  73%|███████▎  | 111/153 [00:02<00:00, 53.39it/s, Epoch: 71, Batch: 112,Loss: -2.494,Avg.Loss: -2.563,LR: 9.84E-05]Training epoch 71:  73%|███████▎  | 112/153 [00:02<00:00, 53.39it/s, Epoch: 71, Batch: 113,Loss: -2.767,Avg.Loss: -2.565,LR: 9.84E-05]Training epoch 71:  74%|███████▍  | 113/153 [00:02<00:00, 53.39it/s, Epoch: 71, Batch: 114,Loss: -3.146,Avg.Loss: -2.570,LR: 9.84E-05]Training epoch 71:  75%|███████▍  | 114/153 [00:02<00:00, 53.41it/s, Epoch: 71, Batch: 114,Loss: -3.146,Avg.Loss: -2.570,LR: 9.84E-05]Training epoch 71:  75%|███████▍  | 114/153 [00:02<00:00, 53.41it/s, Epoch: 71, Batch: 115,Loss: -2.461,Avg.Loss: -2.569,LR: 9.83E-05]Training epoch 71:  75%|███████▌  | 115/153 [00:02<00:00, 53.41it/s, Epoch: 71, Batch: 116,Loss: -2.063,Avg.Loss: -2.565,LR: 9.83E-05]Training epoch 71:  76%|███████▌  | 116/153 [00:02<00:00, 53.41it/s, Epoch: 71, Batch: 117,Loss: -1.961,Avg.Loss: -2.560,LR: 9.82E-05]Training epoch 71:  76%|███████▋  | 117/153 [00:02<00:00, 53.41it/s, Epoch: 71, Batch: 118,Loss: -2.254,Avg.Loss: -2.557,LR: 9.82E-05]Training epoch 71:  77%|███████▋  | 118/153 [00:02<00:00, 53.41it/s, Epoch: 71, Batch: 119,Loss: -2.383,Avg.Loss: -2.556,LR: 9.82E-05]Training epoch 71:  78%|███████▊  | 119/153 [00:02<00:00, 53.41it/s, Epoch: 71, Batch: 120,Loss: -2.703,Avg.Loss: -2.557,LR: 9.81E-05]Training epoch 71:  78%|███████▊  | 120/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 120,Loss: -2.703,Avg.Loss: -2.557,LR: 9.81E-05]Training epoch 71:  78%|███████▊  | 120/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 121,Loss: -2.769,Avg.Loss: -2.559,LR: 9.81E-05]Training epoch 71:  79%|███████▉  | 121/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 122,Loss: -2.724,Avg.Loss: -2.560,LR: 9.80E-05]Training epoch 71:  80%|███████▉  | 122/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 123,Loss: -2.725,Avg.Loss: -2.561,LR: 9.80E-05]Training epoch 71:  80%|████████  | 123/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 124,Loss: -2.595,Avg.Loss: -2.561,LR: 9.80E-05]Training epoch 71:  81%|████████  | 124/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 125,Loss: -2.641,Avg.Loss: -2.562,LR: 9.79E-05]Training epoch 71:  82%|████████▏ | 125/153 [00:02<00:00, 53.46it/s, Epoch: 71, Batch: 126,Loss: -2.792,Avg.Loss: -2.564,LR: 9.79E-05]Training epoch 71:  82%|████████▏ | 126/153 [00:02<00:00, 53.33it/s, Epoch: 71, Batch: 126,Loss: -2.792,Avg.Loss: -2.564,LR: 9.79E-05]Training epoch 71:  82%|████████▏ | 126/153 [00:02<00:00, 53.33it/s, Epoch: 71, Batch: 127,Loss: -2.815,Avg.Loss: -2.566,LR: 9.78E-05]Training epoch 71:  83%|████████▎ | 127/153 [00:02<00:00, 53.33it/s, Epoch: 71, Batch: 128,Loss: -2.942,Avg.Loss: -2.569,LR: 9.78E-05]Training epoch 71:  84%|████████▎ | 128/153 [00:02<00:00, 53.33it/s, Epoch: 71, Batch: 129,Loss: -2.658,Avg.Loss: -2.570,LR: 9.77E-05]Training epoch 71:  84%|████████▍ | 129/153 [00:02<00:00, 53.33it/s, Epoch: 71, Batch: 130,Loss: -2.689,Avg.Loss: -2.570,LR: 9.77E-05]Training epoch 71:  85%|████████▍ | 130/153 [00:02<00:00, 53.33it/s, Epoch: 71, Batch: 131,Loss: -2.601,Avg.Loss: -2.571,LR: 9.77E-05]Training epoch 71:  86%|████████▌ | 131/153 [00:02<00:00, 53.33it/s, Epoch: 71, Batch: 132,Loss: -2.489,Avg.Loss: -2.570,LR: 9.76E-05]Training epoch 71:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 71, Batch: 132,Loss: -2.489,Avg.Loss: -2.570,LR: 9.76E-05]Training epoch 71:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 71, Batch: 133,Loss: -2.400,Avg.Loss: -2.569,LR: 9.76E-05]Training epoch 71:  87%|████████▋ | 133/153 [00:02<00:00, 53.28it/s, Epoch: 71, Batch: 134,Loss: -2.953,Avg.Loss: -2.572,LR: 9.75E-05]Training epoch 71:  88%|████████▊ | 134/153 [00:02<00:00, 53.28it/s, Epoch: 71, Batch: 135,Loss: -2.913,Avg.Loss: -2.574,LR: 9.75E-05]Training epoch 71:  88%|████████▊ | 135/153 [00:02<00:00, 53.28it/s, Epoch: 71, Batch: 136,Loss: -3.008,Avg.Loss: -2.577,LR: 9.75E-05]Training epoch 71:  89%|████████▉ | 136/153 [00:02<00:00, 53.28it/s, Epoch: 71, Batch: 137,Loss: -2.344,Avg.Loss: -2.576,LR: 9.74E-05]Training epoch 71:  90%|████████▉ | 137/153 [00:02<00:00, 53.28it/s, Epoch: 71, Batch: 138,Loss: -2.269,Avg.Loss: -2.573,LR: 9.74E-05]Training epoch 71:  90%|█████████ | 138/153 [00:02<00:00, 53.54it/s, Epoch: 71, Batch: 138,Loss: -2.269,Avg.Loss: -2.573,LR: 9.74E-05]Training epoch 71:  90%|█████████ | 138/153 [00:02<00:00, 53.54it/s, Epoch: 71, Batch: 139,Loss: -2.625,Avg.Loss: -2.574,LR: 9.73E-05]Training epoch 71:  91%|█████████ | 139/153 [00:02<00:00, 53.54it/s, Epoch: 71, Batch: 140,Loss: -2.754,Avg.Loss: -2.575,LR: 9.73E-05]Training epoch 71:  92%|█████████▏| 140/153 [00:02<00:00, 53.54it/s, Epoch: 71, Batch: 141,Loss: -2.403,Avg.Loss: -2.574,LR: 9.73E-05]Training epoch 71:  92%|█████████▏| 141/153 [00:02<00:00, 53.54it/s, Epoch: 71, Batch: 142,Loss: -2.108,Avg.Loss: -2.571,LR: 9.72E-05]Training epoch 71:  93%|█████████▎| 142/153 [00:02<00:00, 53.54it/s, Epoch: 71, Batch: 143,Loss: -1.526,Avg.Loss: -2.563,LR: 9.72E-05]Training epoch 71:  93%|█████████▎| 143/153 [00:02<00:00, 53.54it/s, Epoch: 71, Batch: 144,Loss: -2.675,Avg.Loss: -2.564,LR: 9.71E-05]Training epoch 71:  94%|█████████▍| 144/153 [00:02<00:00, 53.48it/s, Epoch: 71, Batch: 144,Loss: -2.675,Avg.Loss: -2.564,LR: 9.71E-05]Training epoch 71:  94%|█████████▍| 144/153 [00:02<00:00, 53.48it/s, Epoch: 71, Batch: 145,Loss: -2.891,Avg.Loss: -2.566,LR: 9.71E-05]Training epoch 71:  95%|█████████▍| 145/153 [00:02<00:00, 53.48it/s, Epoch: 71, Batch: 146,Loss: -2.723,Avg.Loss: -2.567,LR: 9.71E-05]Training epoch 71:  95%|█████████▌| 146/153 [00:02<00:00, 53.48it/s, Epoch: 71, Batch: 147,Loss: -2.133,Avg.Loss: -2.564,LR: 9.70E-05]Training epoch 71:  96%|█████████▌| 147/153 [00:02<00:00, 53.48it/s, Epoch: 71, Batch: 148,Loss: -2.643,Avg.Loss: -2.565,LR: 9.70E-05]Training epoch 71:  97%|█████████▋| 148/153 [00:02<00:00, 53.48it/s, Epoch: 71, Batch: 149,Loss: -2.563,Avg.Loss: -2.565,LR: 9.69E-05]Training epoch 71:  97%|█████████▋| 149/153 [00:02<00:00, 53.48it/s, Epoch: 71, Batch: 150,Loss: -3.051,Avg.Loss: -2.568,LR: 9.69E-05]Training epoch 71:  98%|█████████▊| 150/153 [00:02<00:00, 53.50it/s, Epoch: 71, Batch: 150,Loss: -3.051,Avg.Loss: -2.568,LR: 9.69E-05]Training epoch 71:  98%|█████████▊| 150/153 [00:02<00:00, 53.50it/s, Epoch: 71, Batch: 151,Loss: -2.846,Avg.Loss: -2.570,LR: 9.69E-05]Training epoch 71:  99%|█████████▊| 151/153 [00:02<00:00, 53.50it/s, Epoch: 71, Batch: 152,Loss: -2.379,Avg.Loss: -2.569,LR: 9.68E-05]Training epoch 71:  99%|█████████▉| 152/153 [00:02<00:00, 53.50it/s, Epoch: 71, Batch: 153,Loss: -2.149,Avg.Loss: -2.566,LR: 9.68E-05]Training epoch 71: 100%|██████████| 153/153 [00:02<00:00, 52.98it/s, Epoch: 71, Batch: 153,Loss: -2.149,Avg.Loss: -2.566,LR: 9.68E-05]
Training epoch 72:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 72:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 72, Batch: 1,Loss: -2.253,Avg.Loss: -2.253,LR: 9.67E-05]Training epoch 72:   1%|          | 1/153 [00:00<00:05, 26.61it/s, Epoch: 72, Batch: 2,Loss: -2.983,Avg.Loss: -2.618,LR: 9.67E-05]Training epoch 72:   1%|▏         | 2/153 [00:00<00:03, 38.56it/s, Epoch: 72, Batch: 3,Loss: -2.849,Avg.Loss: -2.695,LR: 9.67E-05]Training epoch 72:   2%|▏         | 3/153 [00:00<00:03, 42.88it/s, Epoch: 72, Batch: 4,Loss: -2.812,Avg.Loss: -2.724,LR: 9.66E-05]Training epoch 72:   3%|▎         | 4/153 [00:00<00:03, 46.14it/s, Epoch: 72, Batch: 5,Loss: -2.692,Avg.Loss: -2.718,LR: 9.66E-05]Training epoch 72:   3%|▎         | 5/153 [00:00<00:03, 48.01it/s, Epoch: 72, Batch: 6,Loss: -2.431,Avg.Loss: -2.670,LR: 9.65E-05]Training epoch 72:   4%|▍         | 6/153 [00:00<00:02, 57.54it/s, Epoch: 72, Batch: 6,Loss: -2.431,Avg.Loss: -2.670,LR: 9.65E-05]Training epoch 72:   4%|▍         | 6/153 [00:00<00:02, 57.54it/s, Epoch: 72, Batch: 7,Loss: -2.823,Avg.Loss: -2.692,LR: 9.65E-05]Training epoch 72:   5%|▍         | 7/153 [00:00<00:02, 57.54it/s, Epoch: 72, Batch: 8,Loss: -2.342,Avg.Loss: -2.648,LR: 9.64E-05]Training epoch 72:   5%|▌         | 8/153 [00:00<00:02, 57.54it/s, Epoch: 72, Batch: 9,Loss: -2.405,Avg.Loss: -2.621,LR: 9.64E-05]Training epoch 72:   6%|▌         | 9/153 [00:00<00:02, 57.54it/s, Epoch: 72, Batch: 10,Loss: -2.910,Avg.Loss: -2.650,LR: 9.64E-05]Training epoch 72:   7%|▋         | 10/153 [00:00<00:02, 57.54it/s, Epoch: 72, Batch: 11,Loss: -2.271,Avg.Loss: -2.616,LR: 9.63E-05]Training epoch 72:   7%|▋         | 11/153 [00:00<00:02, 57.54it/s, Epoch: 72, Batch: 12,Loss: -2.443,Avg.Loss: -2.601,LR: 9.63E-05]Training epoch 72:   8%|▊         | 12/153 [00:00<00:02, 54.57it/s, Epoch: 72, Batch: 12,Loss: -2.443,Avg.Loss: -2.601,LR: 9.63E-05]Training epoch 72:   8%|▊         | 12/153 [00:00<00:02, 54.57it/s, Epoch: 72, Batch: 13,Loss: -2.790,Avg.Loss: -2.616,LR: 9.62E-05]Training epoch 72:   8%|▊         | 13/153 [00:00<00:02, 54.57it/s, Epoch: 72, Batch: 14,Loss: -2.385,Avg.Loss: -2.599,LR: 9.62E-05]Training epoch 72:   9%|▉         | 14/153 [00:00<00:02, 54.57it/s, Epoch: 72, Batch: 15,Loss: -2.379,Avg.Loss: -2.585,LR: 9.62E-05]Training epoch 72:  10%|▉         | 15/153 [00:00<00:02, 54.57it/s, Epoch: 72, Batch: 16,Loss: -2.706,Avg.Loss: -2.592,LR: 9.61E-05]Training epoch 72:  10%|█         | 16/153 [00:00<00:02, 54.57it/s, Epoch: 72, Batch: 17,Loss: -3.239,Avg.Loss: -2.630,LR: 9.61E-05]Training epoch 72:  11%|█         | 17/153 [00:00<00:02, 54.57it/s, Epoch: 72, Batch: 18,Loss: -2.653,Avg.Loss: -2.631,LR: 9.60E-05]Training epoch 72:  12%|█▏        | 18/153 [00:00<00:02, 53.77it/s, Epoch: 72, Batch: 18,Loss: -2.653,Avg.Loss: -2.631,LR: 9.60E-05]Training epoch 72:  12%|█▏        | 18/153 [00:00<00:02, 53.77it/s, Epoch: 72, Batch: 19,Loss: -2.602,Avg.Loss: -2.630,LR: 9.60E-05]Training epoch 72:  12%|█▏        | 19/153 [00:00<00:02, 53.77it/s, Epoch: 72, Batch: 20,Loss: -1.893,Avg.Loss: -2.593,LR: 9.60E-05]Training epoch 72:  13%|█▎        | 20/153 [00:00<00:02, 53.77it/s, Epoch: 72, Batch: 21,Loss: -3.021,Avg.Loss: -2.613,LR: 9.59E-05]Training epoch 72:  14%|█▎        | 21/153 [00:00<00:02, 53.77it/s, Epoch: 72, Batch: 22,Loss: -2.698,Avg.Loss: -2.617,LR: 9.59E-05]Training epoch 72:  14%|█▍        | 22/153 [00:00<00:02, 53.77it/s, Epoch: 72, Batch: 23,Loss: -3.264,Avg.Loss: -2.645,LR: 9.58E-05]Training epoch 72:  15%|█▌        | 23/153 [00:00<00:02, 53.77it/s, Epoch: 72, Batch: 24,Loss: -2.832,Avg.Loss: -2.653,LR: 9.58E-05]Training epoch 72:  16%|█▌        | 24/153 [00:00<00:02, 52.99it/s, Epoch: 72, Batch: 24,Loss: -2.832,Avg.Loss: -2.653,LR: 9.58E-05]Training epoch 72:  16%|█▌        | 24/153 [00:00<00:02, 52.99it/s, Epoch: 72, Batch: 25,Loss: -2.815,Avg.Loss: -2.660,LR: 9.58E-05]Training epoch 72:  16%|█▋        | 25/153 [00:00<00:02, 52.99it/s, Epoch: 72, Batch: 26,Loss: -2.848,Avg.Loss: -2.667,LR: 9.57E-05]Training epoch 72:  17%|█▋        | 26/153 [00:00<00:02, 52.99it/s, Epoch: 72, Batch: 27,Loss: -2.703,Avg.Loss: -2.668,LR: 9.57E-05]Training epoch 72:  18%|█▊        | 27/153 [00:00<00:02, 52.99it/s, Epoch: 72, Batch: 28,Loss: -2.640,Avg.Loss: -2.667,LR: 9.56E-05]Training epoch 72:  18%|█▊        | 28/153 [00:00<00:02, 52.99it/s, Epoch: 72, Batch: 29,Loss: -2.539,Avg.Loss: -2.663,LR: 9.56E-05]Training epoch 72:  19%|█▉        | 29/153 [00:00<00:02, 52.99it/s, Epoch: 72, Batch: 30,Loss: -2.650,Avg.Loss: -2.662,LR: 9.56E-05]Training epoch 72:  20%|█▉        | 30/153 [00:00<00:02, 52.33it/s, Epoch: 72, Batch: 30,Loss: -2.650,Avg.Loss: -2.662,LR: 9.56E-05]Training epoch 72:  20%|█▉        | 30/153 [00:00<00:02, 52.33it/s, Epoch: 72, Batch: 31,Loss: -2.865,Avg.Loss: -2.669,LR: 9.55E-05]Training epoch 72:  20%|██        | 31/153 [00:00<00:02, 52.33it/s, Epoch: 72, Batch: 32,Loss: -2.361,Avg.Loss: -2.659,LR: 9.55E-05]Training epoch 72:  21%|██        | 32/153 [00:00<00:02, 52.33it/s, Epoch: 72, Batch: 33,Loss: -2.392,Avg.Loss: -2.651,LR: 9.54E-05]Training epoch 72:  22%|██▏       | 33/153 [00:00<00:02, 52.33it/s, Epoch: 72, Batch: 34,Loss: -3.108,Avg.Loss: -2.665,LR: 9.54E-05]Training epoch 72:  22%|██▏       | 34/153 [00:00<00:02, 52.33it/s, Epoch: 72, Batch: 35,Loss: -2.709,Avg.Loss: -2.666,LR: 9.54E-05]Training epoch 72:  23%|██▎       | 35/153 [00:00<00:02, 52.33it/s, Epoch: 72, Batch: 36,Loss: -2.803,Avg.Loss: -2.670,LR: 9.53E-05]Training epoch 72:  24%|██▎       | 36/153 [00:00<00:02, 52.51it/s, Epoch: 72, Batch: 36,Loss: -2.803,Avg.Loss: -2.670,LR: 9.53E-05]Training epoch 72:  24%|██▎       | 36/153 [00:00<00:02, 52.51it/s, Epoch: 72, Batch: 37,Loss: -2.777,Avg.Loss: -2.673,LR: 9.53E-05]Training epoch 72:  24%|██▍       | 37/153 [00:00<00:02, 52.51it/s, Epoch: 72, Batch: 38,Loss: -2.698,Avg.Loss: -2.673,LR: 9.52E-05]Training epoch 72:  25%|██▍       | 38/153 [00:00<00:02, 52.51it/s, Epoch: 72, Batch: 39,Loss: -2.950,Avg.Loss: -2.680,LR: 9.52E-05]Training epoch 72:  25%|██▌       | 39/153 [00:00<00:02, 52.51it/s, Epoch: 72, Batch: 40,Loss: -2.058,Avg.Loss: -2.665,LR: 9.52E-05]Training epoch 72:  26%|██▌       | 40/153 [00:00<00:02, 52.51it/s, Epoch: 72, Batch: 41,Loss: -3.052,Avg.Loss: -2.674,LR: 9.51E-05]Training epoch 72:  27%|██▋       | 41/153 [00:00<00:02, 52.51it/s, Epoch: 72, Batch: 42,Loss: -2.885,Avg.Loss: -2.679,LR: 9.51E-05]Training epoch 72:  27%|██▋       | 42/153 [00:00<00:02, 52.63it/s, Epoch: 72, Batch: 42,Loss: -2.885,Avg.Loss: -2.679,LR: 9.51E-05]Training epoch 72:  27%|██▋       | 42/153 [00:00<00:02, 52.63it/s, Epoch: 72, Batch: 43,Loss: -2.787,Avg.Loss: -2.682,LR: 9.50E-05]Training epoch 72:  28%|██▊       | 43/153 [00:00<00:02, 52.63it/s, Epoch: 72, Batch: 44,Loss: -3.351,Avg.Loss: -2.697,LR: 9.50E-05]Training epoch 72:  29%|██▉       | 44/153 [00:00<00:02, 52.63it/s, Epoch: 72, Batch: 45,Loss: -2.701,Avg.Loss: -2.697,LR: 9.50E-05]Training epoch 72:  29%|██▉       | 45/153 [00:00<00:02, 52.63it/s, Epoch: 72, Batch: 46,Loss: -2.666,Avg.Loss: -2.696,LR: 9.49E-05]Training epoch 72:  30%|███       | 46/153 [00:00<00:02, 52.63it/s, Epoch: 72, Batch: 47,Loss: -3.489,Avg.Loss: -2.713,LR: 9.49E-05]Training epoch 72:  31%|███       | 47/153 [00:00<00:02, 52.63it/s, Epoch: 72, Batch: 48,Loss: -2.641,Avg.Loss: -2.712,LR: 9.48E-05]Training epoch 72:  31%|███▏      | 48/153 [00:00<00:01, 52.70it/s, Epoch: 72, Batch: 48,Loss: -2.641,Avg.Loss: -2.712,LR: 9.48E-05]Training epoch 72:  31%|███▏      | 48/153 [00:00<00:01, 52.70it/s, Epoch: 72, Batch: 49,Loss: -3.196,Avg.Loss: -2.722,LR: 9.48E-05]Training epoch 72:  32%|███▏      | 49/153 [00:00<00:01, 52.70it/s, Epoch: 72, Batch: 50,Loss: -2.885,Avg.Loss: -2.725,LR: 9.48E-05]Training epoch 72:  33%|███▎      | 50/153 [00:00<00:01, 52.70it/s, Epoch: 72, Batch: 51,Loss: -2.924,Avg.Loss: -2.729,LR: 9.47E-05]Training epoch 72:  33%|███▎      | 51/153 [00:00<00:01, 52.70it/s, Epoch: 72, Batch: 52,Loss: -3.070,Avg.Loss: -2.735,LR: 9.47E-05]Training epoch 72:  34%|███▍      | 52/153 [00:00<00:01, 52.70it/s, Epoch: 72, Batch: 53,Loss: -2.803,Avg.Loss: -2.737,LR: 9.46E-05]Training epoch 72:  35%|███▍      | 53/153 [00:01<00:01, 52.70it/s, Epoch: 72, Batch: 54,Loss: -3.027,Avg.Loss: -2.742,LR: 9.46E-05]Training epoch 72:  35%|███▌      | 54/153 [00:01<00:01, 52.93it/s, Epoch: 72, Batch: 54,Loss: -3.027,Avg.Loss: -2.742,LR: 9.46E-05]Training epoch 72:  35%|███▌      | 54/153 [00:01<00:01, 52.93it/s, Epoch: 72, Batch: 55,Loss: -3.215,Avg.Loss: -2.751,LR: 9.46E-05]Training epoch 72:  36%|███▌      | 55/153 [00:01<00:01, 52.93it/s, Epoch: 72, Batch: 56,Loss: -2.680,Avg.Loss: -2.749,LR: 9.45E-05]Training epoch 72:  37%|███▋      | 56/153 [00:01<00:01, 52.93it/s, Epoch: 72, Batch: 57,Loss: -2.465,Avg.Loss: -2.744,LR: 9.45E-05]Training epoch 72:  37%|███▋      | 57/153 [00:01<00:01, 52.93it/s, Epoch: 72, Batch: 58,Loss: -2.608,Avg.Loss: -2.742,LR: 9.44E-05]Training epoch 72:  38%|███▊      | 58/153 [00:01<00:01, 52.93it/s, Epoch: 72, Batch: 59,Loss: -3.043,Avg.Loss: -2.747,LR: 9.44E-05]Training epoch 72:  39%|███▊      | 59/153 [00:01<00:01, 52.93it/s, Epoch: 72, Batch: 60,Loss: -3.427,Avg.Loss: -2.758,LR: 9.44E-05]Training epoch 72:  39%|███▉      | 60/153 [00:01<00:01, 52.91it/s, Epoch: 72, Batch: 60,Loss: -3.427,Avg.Loss: -2.758,LR: 9.44E-05]Training epoch 72:  39%|███▉      | 60/153 [00:01<00:01, 52.91it/s, Epoch: 72, Batch: 61,Loss: -2.676,Avg.Loss: -2.757,LR: 9.43E-05]Training epoch 72:  40%|███▉      | 61/153 [00:01<00:01, 52.91it/s, Epoch: 72, Batch: 62,Loss: -2.109,Avg.Loss: -2.747,LR: 9.43E-05]Training epoch 72:  41%|████      | 62/153 [00:01<00:01, 52.91it/s, Epoch: 72, Batch: 63,Loss: -2.302,Avg.Loss: -2.740,LR: 9.42E-05]Training epoch 72:  41%|████      | 63/153 [00:01<00:01, 52.91it/s, Epoch: 72, Batch: 64,Loss: -2.101,Avg.Loss: -2.730,LR: 9.42E-05]Training epoch 72:  42%|████▏     | 64/153 [00:01<00:01, 52.91it/s, Epoch: 72, Batch: 65,Loss: -2.756,Avg.Loss: -2.730,LR: 9.42E-05]Training epoch 72:  42%|████▏     | 65/153 [00:01<00:01, 52.91it/s, Epoch: 72, Batch: 66,Loss: -2.556,Avg.Loss: -2.727,LR: 9.41E-05]Training epoch 72:  43%|████▎     | 66/153 [00:01<00:01, 52.79it/s, Epoch: 72, Batch: 66,Loss: -2.556,Avg.Loss: -2.727,LR: 9.41E-05]Training epoch 72:  43%|████▎     | 66/153 [00:01<00:01, 52.79it/s, Epoch: 72, Batch: 67,Loss: -3.151,Avg.Loss: -2.734,LR: 9.41E-05]Training epoch 72:  44%|████▍     | 67/153 [00:01<00:01, 52.79it/s, Epoch: 72, Batch: 68,Loss: -2.749,Avg.Loss: -2.734,LR: 9.40E-05]Training epoch 72:  44%|████▍     | 68/153 [00:01<00:01, 52.79it/s, Epoch: 72, Batch: 69,Loss: -2.865,Avg.Loss: -2.736,LR: 9.40E-05]Training epoch 72:  45%|████▌     | 69/153 [00:01<00:01, 52.79it/s, Epoch: 72, Batch: 70,Loss: -1.908,Avg.Loss: -2.724,LR: 9.39E-05]Training epoch 72:  46%|████▌     | 70/153 [00:01<00:01, 52.79it/s, Epoch: 72, Batch: 71,Loss: -2.305,Avg.Loss: -2.718,LR: 9.39E-05]Training epoch 72:  46%|████▋     | 71/153 [00:01<00:01, 52.79it/s, Epoch: 72, Batch: 72,Loss: -1.639,Avg.Loss: -2.703,LR: 9.39E-05]Training epoch 72:  47%|████▋     | 72/153 [00:01<00:01, 52.50it/s, Epoch: 72, Batch: 72,Loss: -1.639,Avg.Loss: -2.703,LR: 9.39E-05]Training epoch 72:  47%|████▋     | 72/153 [00:01<00:01, 52.50it/s, Epoch: 72, Batch: 73,Loss: -2.280,Avg.Loss: -2.697,LR: 9.38E-05]Training epoch 72:  48%|████▊     | 73/153 [00:01<00:01, 52.50it/s, Epoch: 72, Batch: 74,Loss: -2.722,Avg.Loss: -2.698,LR: 9.38E-05]Training epoch 72:  48%|████▊     | 74/153 [00:01<00:01, 52.50it/s, Epoch: 72, Batch: 75,Loss: -2.481,Avg.Loss: -2.695,LR: 9.37E-05]Training epoch 72:  49%|████▉     | 75/153 [00:01<00:01, 52.50it/s, Epoch: 72, Batch: 76,Loss: -3.039,Avg.Loss: -2.699,LR: 9.37E-05]Training epoch 72:  50%|████▉     | 76/153 [00:01<00:01, 52.50it/s, Epoch: 72, Batch: 77,Loss: -2.795,Avg.Loss: -2.701,LR: 9.37E-05]Training epoch 72:  50%|█████     | 77/153 [00:01<00:01, 52.50it/s, Epoch: 72, Batch: 78,Loss: -2.912,Avg.Loss: -2.703,LR: 9.36E-05]Training epoch 72:  51%|█████     | 78/153 [00:01<00:01, 52.68it/s, Epoch: 72, Batch: 78,Loss: -2.912,Avg.Loss: -2.703,LR: 9.36E-05]Training epoch 72:  51%|█████     | 78/153 [00:01<00:01, 52.68it/s, Epoch: 72, Batch: 79,Loss: -2.910,Avg.Loss: -2.706,LR: 9.36E-05]Training epoch 72:  52%|█████▏    | 79/153 [00:01<00:01, 52.68it/s, Epoch: 72, Batch: 80,Loss: -2.733,Avg.Loss: -2.706,LR: 9.35E-05]Training epoch 72:  52%|█████▏    | 80/153 [00:01<00:01, 52.68it/s, Epoch: 72, Batch: 81,Loss: -2.520,Avg.Loss: -2.704,LR: 9.35E-05]Training epoch 72:  53%|█████▎    | 81/153 [00:01<00:01, 52.68it/s, Epoch: 72, Batch: 82,Loss: -2.901,Avg.Loss: -2.706,LR: 9.35E-05]Training epoch 72:  54%|█████▎    | 82/153 [00:01<00:01, 52.68it/s, Epoch: 72, Batch: 83,Loss: -2.498,Avg.Loss: -2.704,LR: 9.34E-05]Training epoch 72:  54%|█████▍    | 83/153 [00:01<00:01, 52.68it/s, Epoch: 72, Batch: 84,Loss: -2.771,Avg.Loss: -2.705,LR: 9.34E-05]Training epoch 72:  55%|█████▍    | 84/153 [00:01<00:01, 52.71it/s, Epoch: 72, Batch: 84,Loss: -2.771,Avg.Loss: -2.705,LR: 9.34E-05]Training epoch 72:  55%|█████▍    | 84/153 [00:01<00:01, 52.71it/s, Epoch: 72, Batch: 85,Loss: -2.789,Avg.Loss: -2.706,LR: 9.33E-05]Training epoch 72:  56%|█████▌    | 85/153 [00:01<00:01, 52.71it/s, Epoch: 72, Batch: 86,Loss: -2.937,Avg.Loss: -2.708,LR: 9.33E-05]Training epoch 72:  56%|█████▌    | 86/153 [00:01<00:01, 52.71it/s, Epoch: 72, Batch: 87,Loss: -2.749,Avg.Loss: -2.709,LR: 9.33E-05]Training epoch 72:  57%|█████▋    | 87/153 [00:01<00:01, 52.71it/s, Epoch: 72, Batch: 88,Loss: -2.848,Avg.Loss: -2.710,LR: 9.32E-05]Training epoch 72:  58%|█████▊    | 88/153 [00:01<00:01, 52.71it/s, Epoch: 72, Batch: 89,Loss: -2.963,Avg.Loss: -2.713,LR: 9.32E-05]Training epoch 72:  58%|█████▊    | 89/153 [00:01<00:01, 52.71it/s, Epoch: 72, Batch: 90,Loss: -2.651,Avg.Loss: -2.712,LR: 9.31E-05]Training epoch 72:  59%|█████▉    | 90/153 [00:01<00:01, 52.87it/s, Epoch: 72, Batch: 90,Loss: -2.651,Avg.Loss: -2.712,LR: 9.31E-05]Training epoch 72:  59%|█████▉    | 90/153 [00:01<00:01, 52.87it/s, Epoch: 72, Batch: 91,Loss: -3.039,Avg.Loss: -2.716,LR: 9.31E-05]Training epoch 72:  59%|█████▉    | 91/153 [00:01<00:01, 52.87it/s, Epoch: 72, Batch: 92,Loss: -2.732,Avg.Loss: -2.716,LR: 9.31E-05]Training epoch 72:  60%|██████    | 92/153 [00:01<00:01, 52.87it/s, Epoch: 72, Batch: 93,Loss: -2.391,Avg.Loss: -2.713,LR: 9.30E-05]Training epoch 72:  61%|██████    | 93/153 [00:01<00:01, 52.87it/s, Epoch: 72, Batch: 94,Loss: -2.660,Avg.Loss: -2.712,LR: 9.30E-05]Training epoch 72:  61%|██████▏   | 94/153 [00:01<00:01, 52.87it/s, Epoch: 72, Batch: 95,Loss: -2.882,Avg.Loss: -2.714,LR: 9.29E-05]Training epoch 72:  62%|██████▏   | 95/153 [00:01<00:01, 52.87it/s, Epoch: 72, Batch: 96,Loss: -3.395,Avg.Loss: -2.721,LR: 9.29E-05]Training epoch 72:  63%|██████▎   | 96/153 [00:01<00:01, 52.89it/s, Epoch: 72, Batch: 96,Loss: -3.395,Avg.Loss: -2.721,LR: 9.29E-05]Training epoch 72:  63%|██████▎   | 96/153 [00:01<00:01, 52.89it/s, Epoch: 72, Batch: 97,Loss: -2.647,Avg.Loss: -2.720,LR: 9.29E-05]Training epoch 72:  63%|██████▎   | 97/153 [00:01<00:01, 52.89it/s, Epoch: 72, Batch: 98,Loss: -2.775,Avg.Loss: -2.721,LR: 9.28E-05]Training epoch 72:  64%|██████▍   | 98/153 [00:01<00:01, 52.89it/s, Epoch: 72, Batch: 99,Loss: -2.850,Avg.Loss: -2.722,LR: 9.28E-05]Training epoch 72:  65%|██████▍   | 99/153 [00:01<00:01, 52.89it/s, Epoch: 72, Batch: 100,Loss: -3.257,Avg.Loss: -2.727,LR: 9.27E-05]Training epoch 72:  65%|██████▌   | 100/153 [00:01<00:01, 52.89it/s, Epoch: 72, Batch: 101,Loss: -2.363,Avg.Loss: -2.724,LR: 9.27E-05]Training epoch 72:  66%|██████▌   | 101/153 [00:01<00:00, 52.89it/s, Epoch: 72, Batch: 102,Loss: -3.125,Avg.Loss: -2.728,LR: 9.27E-05]Training epoch 72:  67%|██████▋   | 102/153 [00:01<00:00, 52.86it/s, Epoch: 72, Batch: 102,Loss: -3.125,Avg.Loss: -2.728,LR: 9.27E-05]Training epoch 72:  67%|██████▋   | 102/153 [00:01<00:00, 52.86it/s, Epoch: 72, Batch: 103,Loss: -2.616,Avg.Loss: -2.727,LR: 9.26E-05]Training epoch 72:  67%|██████▋   | 103/153 [00:01<00:00, 52.86it/s, Epoch: 72, Batch: 104,Loss: -3.273,Avg.Loss: -2.732,LR: 9.26E-05]Training epoch 72:  68%|██████▊   | 104/153 [00:01<00:00, 52.86it/s, Epoch: 72, Batch: 105,Loss: -2.676,Avg.Loss: -2.731,LR: 9.26E-05]Training epoch 72:  69%|██████▊   | 105/153 [00:02<00:00, 52.86it/s, Epoch: 72, Batch: 106,Loss: -2.528,Avg.Loss: -2.730,LR: 9.25E-05]Training epoch 72:  69%|██████▉   | 106/153 [00:02<00:00, 52.86it/s, Epoch: 72, Batch: 107,Loss: -2.905,Avg.Loss: -2.731,LR: 9.25E-05]Training epoch 72:  70%|██████▉   | 107/153 [00:02<00:00, 52.86it/s, Epoch: 72, Batch: 108,Loss: -3.247,Avg.Loss: -2.736,LR: 9.24E-05]Training epoch 72:  71%|███████   | 108/153 [00:02<00:00, 52.84it/s, Epoch: 72, Batch: 108,Loss: -3.247,Avg.Loss: -2.736,LR: 9.24E-05]Training epoch 72:  71%|███████   | 108/153 [00:02<00:00, 52.84it/s, Epoch: 72, Batch: 109,Loss: -2.849,Avg.Loss: -2.737,LR: 9.24E-05]Training epoch 72:  71%|███████   | 109/153 [00:02<00:00, 52.84it/s, Epoch: 72, Batch: 110,Loss: -3.431,Avg.Loss: -2.743,LR: 9.24E-05]Training epoch 72:  72%|███████▏  | 110/153 [00:02<00:00, 52.84it/s, Epoch: 72, Batch: 111,Loss: -3.016,Avg.Loss: -2.746,LR: 9.23E-05]Training epoch 72:  73%|███████▎  | 111/153 [00:02<00:00, 52.84it/s, Epoch: 72, Batch: 112,Loss: -2.166,Avg.Loss: -2.741,LR: 9.23E-05]Training epoch 72:  73%|███████▎  | 112/153 [00:02<00:00, 52.84it/s, Epoch: 72, Batch: 113,Loss: -2.509,Avg.Loss: -2.738,LR: 9.22E-05]Training epoch 72:  74%|███████▍  | 113/153 [00:02<00:00, 52.84it/s, Epoch: 72, Batch: 114,Loss: -2.484,Avg.Loss: -2.736,LR: 9.22E-05]Training epoch 72:  75%|███████▍  | 114/153 [00:02<00:00, 52.69it/s, Epoch: 72, Batch: 114,Loss: -2.484,Avg.Loss: -2.736,LR: 9.22E-05]Training epoch 72:  75%|███████▍  | 114/153 [00:02<00:00, 52.69it/s, Epoch: 72, Batch: 115,Loss: -2.402,Avg.Loss: -2.733,LR: 9.22E-05]Training epoch 72:  75%|███████▌  | 115/153 [00:02<00:00, 52.69it/s, Epoch: 72, Batch: 116,Loss: -2.694,Avg.Loss: -2.733,LR: 9.21E-05]Training epoch 72:  76%|███████▌  | 116/153 [00:02<00:00, 52.69it/s, Epoch: 72, Batch: 117,Loss: -2.784,Avg.Loss: -2.733,LR: 9.21E-05]Training epoch 72:  76%|███████▋  | 117/153 [00:02<00:00, 52.69it/s, Epoch: 72, Batch: 118,Loss: -2.728,Avg.Loss: -2.733,LR: 9.20E-05]Training epoch 72:  77%|███████▋  | 118/153 [00:02<00:00, 52.69it/s, Epoch: 72, Batch: 119,Loss: -2.981,Avg.Loss: -2.735,LR: 9.20E-05]Training epoch 72:  78%|███████▊  | 119/153 [00:02<00:00, 52.69it/s, Epoch: 72, Batch: 120,Loss: -2.882,Avg.Loss: -2.737,LR: 9.20E-05]Training epoch 72:  78%|███████▊  | 120/153 [00:02<00:00, 52.75it/s, Epoch: 72, Batch: 120,Loss: -2.882,Avg.Loss: -2.737,LR: 9.20E-05]Training epoch 72:  78%|███████▊  | 120/153 [00:02<00:00, 52.75it/s, Epoch: 72, Batch: 121,Loss: -2.497,Avg.Loss: -2.735,LR: 9.19E-05]Training epoch 72:  79%|███████▉  | 121/153 [00:02<00:00, 52.75it/s, Epoch: 72, Batch: 122,Loss: -2.743,Avg.Loss: -2.735,LR: 9.19E-05]Training epoch 72:  80%|███████▉  | 122/153 [00:02<00:00, 52.75it/s, Epoch: 72, Batch: 123,Loss: -3.178,Avg.Loss: -2.738,LR: 9.18E-05]Training epoch 72:  80%|████████  | 123/153 [00:02<00:00, 52.75it/s, Epoch: 72, Batch: 124,Loss: -2.926,Avg.Loss: -2.740,LR: 9.18E-05]Training epoch 72:  81%|████████  | 124/153 [00:02<00:00, 52.75it/s, Epoch: 72, Batch: 125,Loss: -3.040,Avg.Loss: -2.742,LR: 9.18E-05]Training epoch 72:  82%|████████▏ | 125/153 [00:02<00:00, 52.75it/s, Epoch: 72, Batch: 126,Loss: -2.909,Avg.Loss: -2.744,LR: 9.17E-05]Training epoch 72:  82%|████████▏ | 126/153 [00:02<00:00, 52.80it/s, Epoch: 72, Batch: 126,Loss: -2.909,Avg.Loss: -2.744,LR: 9.17E-05]Training epoch 72:  82%|████████▏ | 126/153 [00:02<00:00, 52.80it/s, Epoch: 72, Batch: 127,Loss: -2.800,Avg.Loss: -2.744,LR: 9.17E-05]Training epoch 72:  83%|████████▎ | 127/153 [00:02<00:00, 52.80it/s, Epoch: 72, Batch: 128,Loss: -3.043,Avg.Loss: -2.746,LR: 9.16E-05]Training epoch 72:  84%|████████▎ | 128/153 [00:02<00:00, 52.80it/s, Epoch: 72, Batch: 129,Loss: -2.786,Avg.Loss: -2.747,LR: 9.16E-05]Training epoch 72:  84%|████████▍ | 129/153 [00:02<00:00, 52.80it/s, Epoch: 72, Batch: 130,Loss: -2.729,Avg.Loss: -2.747,LR: 9.16E-05]Training epoch 72:  85%|████████▍ | 130/153 [00:02<00:00, 52.80it/s, Epoch: 72, Batch: 131,Loss: -3.515,Avg.Loss: -2.752,LR: 9.15E-05]Training epoch 72:  86%|████████▌ | 131/153 [00:02<00:00, 52.80it/s, Epoch: 72, Batch: 132,Loss: -2.582,Avg.Loss: -2.751,LR: 9.15E-05]Training epoch 72:  86%|████████▋ | 132/153 [00:02<00:00, 52.87it/s, Epoch: 72, Batch: 132,Loss: -2.582,Avg.Loss: -2.751,LR: 9.15E-05]Training epoch 72:  86%|████████▋ | 132/153 [00:02<00:00, 52.87it/s, Epoch: 72, Batch: 133,Loss: -2.502,Avg.Loss: -2.749,LR: 9.14E-05]Training epoch 72:  87%|████████▋ | 133/153 [00:02<00:00, 52.87it/s, Epoch: 72, Batch: 134,Loss: -3.276,Avg.Loss: -2.753,LR: 9.14E-05]Training epoch 72:  88%|████████▊ | 134/153 [00:02<00:00, 52.87it/s, Epoch: 72, Batch: 135,Loss: -2.604,Avg.Loss: -2.752,LR: 9.14E-05]Training epoch 72:  88%|████████▊ | 135/153 [00:02<00:00, 52.87it/s, Epoch: 72, Batch: 136,Loss: -2.821,Avg.Loss: -2.753,LR: 9.13E-05]Training epoch 72:  89%|████████▉ | 136/153 [00:02<00:00, 52.87it/s, Epoch: 72, Batch: 137,Loss: -2.815,Avg.Loss: -2.753,LR: 9.13E-05]Training epoch 72:  90%|████████▉ | 137/153 [00:02<00:00, 52.87it/s, Epoch: 72, Batch: 138,Loss: -2.816,Avg.Loss: -2.754,LR: 9.12E-05]Training epoch 72:  90%|█████████ | 138/153 [00:02<00:00, 53.02it/s, Epoch: 72, Batch: 138,Loss: -2.816,Avg.Loss: -2.754,LR: 9.12E-05]Training epoch 72:  90%|█████████ | 138/153 [00:02<00:00, 53.02it/s, Epoch: 72, Batch: 139,Loss: -2.740,Avg.Loss: -2.753,LR: 9.12E-05]Training epoch 72:  91%|█████████ | 139/153 [00:02<00:00, 53.02it/s, Epoch: 72, Batch: 140,Loss: -2.964,Avg.Loss: -2.755,LR: 9.12E-05]Training epoch 72:  92%|█████████▏| 140/153 [00:02<00:00, 53.02it/s, Epoch: 72, Batch: 141,Loss: -2.762,Avg.Loss: -2.755,LR: 9.11E-05]Training epoch 72:  92%|█████████▏| 141/153 [00:02<00:00, 53.02it/s, Epoch: 72, Batch: 142,Loss: -2.947,Avg.Loss: -2.756,LR: 9.11E-05]Training epoch 72:  93%|█████████▎| 142/153 [00:02<00:00, 53.02it/s, Epoch: 72, Batch: 143,Loss: -2.769,Avg.Loss: -2.756,LR: 9.10E-05]Training epoch 72:  93%|█████████▎| 143/153 [00:02<00:00, 53.02it/s, Epoch: 72, Batch: 144,Loss: -2.957,Avg.Loss: -2.758,LR: 9.10E-05]Training epoch 72:  94%|█████████▍| 144/153 [00:02<00:00, 53.03it/s, Epoch: 72, Batch: 144,Loss: -2.957,Avg.Loss: -2.758,LR: 9.10E-05]Training epoch 72:  94%|█████████▍| 144/153 [00:02<00:00, 53.03it/s, Epoch: 72, Batch: 145,Loss: -3.127,Avg.Loss: -2.760,LR: 9.10E-05]Training epoch 72:  95%|█████████▍| 145/153 [00:02<00:00, 53.03it/s, Epoch: 72, Batch: 146,Loss: -2.991,Avg.Loss: -2.762,LR: 9.09E-05]Training epoch 72:  95%|█████████▌| 146/153 [00:02<00:00, 53.03it/s, Epoch: 72, Batch: 147,Loss: -3.100,Avg.Loss: -2.764,LR: 9.09E-05]Training epoch 72:  96%|█████████▌| 147/153 [00:02<00:00, 53.03it/s, Epoch: 72, Batch: 148,Loss: -2.588,Avg.Loss: -2.763,LR: 9.08E-05]Training epoch 72:  97%|█████████▋| 148/153 [00:02<00:00, 53.03it/s, Epoch: 72, Batch: 149,Loss: -2.838,Avg.Loss: -2.764,LR: 9.08E-05]Training epoch 72:  97%|█████████▋| 149/153 [00:02<00:00, 53.03it/s, Epoch: 72, Batch: 150,Loss: -2.812,Avg.Loss: -2.764,LR: 9.08E-05]Training epoch 72:  98%|█████████▊| 150/153 [00:02<00:00, 53.29it/s, Epoch: 72, Batch: 150,Loss: -2.812,Avg.Loss: -2.764,LR: 9.08E-05]Training epoch 72:  98%|█████████▊| 150/153 [00:02<00:00, 53.29it/s, Epoch: 72, Batch: 151,Loss: -2.646,Avg.Loss: -2.763,LR: 9.07E-05]Training epoch 72:  99%|█████████▊| 151/153 [00:02<00:00, 53.29it/s, Epoch: 72, Batch: 152,Loss: -2.579,Avg.Loss: -2.762,LR: 9.07E-05]Training epoch 72:  99%|█████████▉| 152/153 [00:02<00:00, 53.29it/s, Epoch: 72, Batch: 153,Loss: -2.514,Avg.Loss: -2.760,LR: 9.06E-05]Training epoch 72: 100%|██████████| 153/153 [00:02<00:00, 52.91it/s, Epoch: 72, Batch: 153,Loss: -2.514,Avg.Loss: -2.760,LR: 9.06E-05]
Training epoch 73:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 73:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 73, Batch: 1,Loss: -2.648,Avg.Loss: -2.648,LR: 9.06E-05]Training epoch 73:   1%|          | 1/153 [00:00<00:04, 30.81it/s, Epoch: 73, Batch: 2,Loss: -2.688,Avg.Loss: -2.668,LR: 9.06E-05]Training epoch 73:   1%|▏         | 2/153 [00:00<00:03, 37.98it/s, Epoch: 73, Batch: 3,Loss: -2.767,Avg.Loss: -2.701,LR: 9.05E-05]Training epoch 73:   2%|▏         | 3/153 [00:00<00:03, 42.06it/s, Epoch: 73, Batch: 4,Loss: -2.842,Avg.Loss: -2.736,LR: 9.05E-05]Training epoch 73:   3%|▎         | 4/153 [00:00<00:03, 44.21it/s, Epoch: 73, Batch: 5,Loss: -2.596,Avg.Loss: -2.708,LR: 9.04E-05]Training epoch 73:   3%|▎         | 5/153 [00:00<00:03, 45.42it/s, Epoch: 73, Batch: 6,Loss: -2.959,Avg.Loss: -2.750,LR: 9.04E-05]Training epoch 73:   4%|▍         | 6/153 [00:00<00:02, 54.41it/s, Epoch: 73, Batch: 6,Loss: -2.959,Avg.Loss: -2.750,LR: 9.04E-05]Training epoch 73:   4%|▍         | 6/153 [00:00<00:02, 54.41it/s, Epoch: 73, Batch: 7,Loss: -2.903,Avg.Loss: -2.772,LR: 9.04E-05]Training epoch 73:   5%|▍         | 7/153 [00:00<00:02, 54.41it/s, Epoch: 73, Batch: 8,Loss: -2.523,Avg.Loss: -2.741,LR: 9.03E-05]Training epoch 73:   5%|▌         | 8/153 [00:00<00:02, 54.41it/s, Epoch: 73, Batch: 9,Loss: -2.528,Avg.Loss: -2.717,LR: 9.03E-05]Training epoch 73:   6%|▌         | 9/153 [00:00<00:02, 54.41it/s, Epoch: 73, Batch: 10,Loss: -2.393,Avg.Loss: -2.685,LR: 9.02E-05]Training epoch 73:   7%|▋         | 10/153 [00:00<00:02, 54.41it/s, Epoch: 73, Batch: 11,Loss: -2.659,Avg.Loss: -2.682,LR: 9.02E-05]Training epoch 73:   7%|▋         | 11/153 [00:00<00:02, 54.41it/s, Epoch: 73, Batch: 12,Loss: -2.006,Avg.Loss: -2.626,LR: 9.02E-05]Training epoch 73:   8%|▊         | 12/153 [00:00<00:02, 53.78it/s, Epoch: 73, Batch: 12,Loss: -2.006,Avg.Loss: -2.626,LR: 9.02E-05]Training epoch 73:   8%|▊         | 12/153 [00:00<00:02, 53.78it/s, Epoch: 73, Batch: 13,Loss: -2.664,Avg.Loss: -2.629,LR: 9.01E-05]Training epoch 73:   8%|▊         | 13/153 [00:00<00:02, 53.78it/s, Epoch: 73, Batch: 14,Loss: -3.059,Avg.Loss: -2.660,LR: 9.01E-05]Training epoch 73:   9%|▉         | 14/153 [00:00<00:02, 53.78it/s, Epoch: 73, Batch: 15,Loss: -2.981,Avg.Loss: -2.681,LR: 9.01E-05]Training epoch 73:  10%|▉         | 15/153 [00:00<00:02, 53.78it/s, Epoch: 73, Batch: 16,Loss: -2.614,Avg.Loss: -2.677,LR: 9.00E-05]Training epoch 73:  10%|█         | 16/153 [00:00<00:02, 53.78it/s, Epoch: 73, Batch: 17,Loss: -1.876,Avg.Loss: -2.630,LR: 9.00E-05]Training epoch 73:  11%|█         | 17/153 [00:00<00:02, 53.78it/s, Epoch: 73, Batch: 18,Loss: -1.757,Avg.Loss: -2.581,LR: 8.99E-05]Training epoch 73:  12%|█▏        | 18/153 [00:00<00:02, 53.43it/s, Epoch: 73, Batch: 18,Loss: -1.757,Avg.Loss: -2.581,LR: 8.99E-05]Training epoch 73:  12%|█▏        | 18/153 [00:00<00:02, 53.43it/s, Epoch: 73, Batch: 19,Loss: -2.666,Avg.Loss: -2.586,LR: 8.99E-05]Training epoch 73:  12%|█▏        | 19/153 [00:00<00:02, 53.43it/s, Epoch: 73, Batch: 20,Loss: -2.210,Avg.Loss: -2.567,LR: 8.99E-05]Training epoch 73:  13%|█▎        | 20/153 [00:00<00:02, 53.43it/s, Epoch: 73, Batch: 21,Loss: -2.932,Avg.Loss: -2.584,LR: 8.98E-05]Training epoch 73:  14%|█▎        | 21/153 [00:00<00:02, 53.43it/s, Epoch: 73, Batch: 22,Loss: -2.570,Avg.Loss: -2.584,LR: 8.98E-05]Training epoch 73:  14%|█▍        | 22/153 [00:00<00:02, 53.43it/s, Epoch: 73, Batch: 23,Loss: -2.390,Avg.Loss: -2.575,LR: 8.97E-05]Training epoch 73:  15%|█▌        | 23/153 [00:00<00:02, 53.43it/s, Epoch: 73, Batch: 24,Loss: -2.509,Avg.Loss: -2.572,LR: 8.97E-05]Training epoch 73:  16%|█▌        | 24/153 [00:00<00:02, 52.20it/s, Epoch: 73, Batch: 24,Loss: -2.509,Avg.Loss: -2.572,LR: 8.97E-05]Training epoch 73:  16%|█▌        | 24/153 [00:00<00:02, 52.20it/s, Epoch: 73, Batch: 25,Loss: -2.848,Avg.Loss: -2.583,LR: 8.97E-05]Training epoch 73:  16%|█▋        | 25/153 [00:00<00:02, 52.20it/s, Epoch: 73, Batch: 26,Loss: -2.207,Avg.Loss: -2.569,LR: 8.96E-05]Training epoch 73:  17%|█▋        | 26/153 [00:00<00:02, 52.20it/s, Epoch: 73, Batch: 27,Loss: -2.103,Avg.Loss: -2.552,LR: 8.96E-05]Training epoch 73:  18%|█▊        | 27/153 [00:00<00:02, 52.20it/s, Epoch: 73, Batch: 28,Loss: -2.589,Avg.Loss: -2.553,LR: 8.95E-05]Training epoch 73:  18%|█▊        | 28/153 [00:00<00:02, 52.20it/s, Epoch: 73, Batch: 29,Loss: -2.606,Avg.Loss: -2.555,LR: 8.95E-05]Training epoch 73:  19%|█▉        | 29/153 [00:00<00:02, 52.20it/s, Epoch: 73, Batch: 30,Loss: -3.285,Avg.Loss: -2.579,LR: 8.95E-05]Training epoch 73:  20%|█▉        | 30/153 [00:00<00:02, 51.92it/s, Epoch: 73, Batch: 30,Loss: -3.285,Avg.Loss: -2.579,LR: 8.95E-05]Training epoch 73:  20%|█▉        | 30/153 [00:00<00:02, 51.92it/s, Epoch: 73, Batch: 31,Loss: -2.343,Avg.Loss: -2.572,LR: 8.94E-05]Training epoch 73:  20%|██        | 31/153 [00:00<00:02, 51.92it/s, Epoch: 73, Batch: 32,Loss: -2.510,Avg.Loss: -2.570,LR: 8.94E-05]Training epoch 73:  21%|██        | 32/153 [00:00<00:02, 51.92it/s, Epoch: 73, Batch: 33,Loss: -2.773,Avg.Loss: -2.576,LR: 8.93E-05]Training epoch 73:  22%|██▏       | 33/153 [00:00<00:02, 51.92it/s, Epoch: 73, Batch: 34,Loss: -3.187,Avg.Loss: -2.594,LR: 8.93E-05]Training epoch 73:  22%|██▏       | 34/153 [00:00<00:02, 51.92it/s, Epoch: 73, Batch: 35,Loss: -2.645,Avg.Loss: -2.595,LR: 8.93E-05]Training epoch 73:  23%|██▎       | 35/153 [00:00<00:02, 51.92it/s, Epoch: 73, Batch: 36,Loss: -2.982,Avg.Loss: -2.606,LR: 8.92E-05]Training epoch 73:  24%|██▎       | 36/153 [00:00<00:02, 51.99it/s, Epoch: 73, Batch: 36,Loss: -2.982,Avg.Loss: -2.606,LR: 8.92E-05]Training epoch 73:  24%|██▎       | 36/153 [00:00<00:02, 51.99it/s, Epoch: 73, Batch: 37,Loss: -2.488,Avg.Loss: -2.603,LR: 8.92E-05]Training epoch 73:  24%|██▍       | 37/153 [00:00<00:02, 51.99it/s, Epoch: 73, Batch: 38,Loss: -2.744,Avg.Loss: -2.607,LR: 8.91E-05]Training epoch 73:  25%|██▍       | 38/153 [00:00<00:02, 51.99it/s, Epoch: 73, Batch: 39,Loss: -3.053,Avg.Loss: -2.618,LR: 8.91E-05]Training epoch 73:  25%|██▌       | 39/153 [00:00<00:02, 51.99it/s, Epoch: 73, Batch: 40,Loss: -3.013,Avg.Loss: -2.628,LR: 8.91E-05]Training epoch 73:  26%|██▌       | 40/153 [00:00<00:02, 51.99it/s, Epoch: 73, Batch: 41,Loss: -3.140,Avg.Loss: -2.640,LR: 8.90E-05]Training epoch 73:  27%|██▋       | 41/153 [00:00<00:02, 51.99it/s, Epoch: 73, Batch: 42,Loss: -3.067,Avg.Loss: -2.651,LR: 8.90E-05]Training epoch 73:  27%|██▋       | 42/153 [00:00<00:02, 52.19it/s, Epoch: 73, Batch: 42,Loss: -3.067,Avg.Loss: -2.651,LR: 8.90E-05]Training epoch 73:  27%|██▋       | 42/153 [00:00<00:02, 52.19it/s, Epoch: 73, Batch: 43,Loss: -2.837,Avg.Loss: -2.655,LR: 8.89E-05]Training epoch 73:  28%|██▊       | 43/153 [00:00<00:02, 52.19it/s, Epoch: 73, Batch: 44,Loss: -2.903,Avg.Loss: -2.660,LR: 8.89E-05]Training epoch 73:  29%|██▉       | 44/153 [00:00<00:02, 52.19it/s, Epoch: 73, Batch: 45,Loss: -3.357,Avg.Loss: -2.676,LR: 8.89E-05]Training epoch 73:  29%|██▉       | 45/153 [00:00<00:02, 52.19it/s, Epoch: 73, Batch: 46,Loss: -2.847,Avg.Loss: -2.680,LR: 8.88E-05]Training epoch 73:  30%|███       | 46/153 [00:00<00:02, 52.19it/s, Epoch: 73, Batch: 47,Loss: -3.151,Avg.Loss: -2.690,LR: 8.88E-05]Training epoch 73:  31%|███       | 47/153 [00:00<00:02, 52.19it/s, Epoch: 73, Batch: 48,Loss: -3.224,Avg.Loss: -2.701,LR: 8.88E-05]Training epoch 73:  31%|███▏      | 48/153 [00:00<00:02, 52.41it/s, Epoch: 73, Batch: 48,Loss: -3.224,Avg.Loss: -2.701,LR: 8.88E-05]Training epoch 73:  31%|███▏      | 48/153 [00:00<00:02, 52.41it/s, Epoch: 73, Batch: 49,Loss: -3.163,Avg.Loss: -2.710,LR: 8.87E-05]Training epoch 73:  32%|███▏      | 49/153 [00:00<00:01, 52.41it/s, Epoch: 73, Batch: 50,Loss: -2.773,Avg.Loss: -2.712,LR: 8.87E-05]Training epoch 73:  33%|███▎      | 50/153 [00:00<00:01, 52.41it/s, Epoch: 73, Batch: 51,Loss: -2.265,Avg.Loss: -2.703,LR: 8.86E-05]Training epoch 73:  33%|███▎      | 51/153 [00:00<00:01, 52.41it/s, Epoch: 73, Batch: 52,Loss: -2.548,Avg.Loss: -2.700,LR: 8.86E-05]Training epoch 73:  34%|███▍      | 52/153 [00:01<00:01, 52.41it/s, Epoch: 73, Batch: 53,Loss: -2.863,Avg.Loss: -2.703,LR: 8.86E-05]Training epoch 73:  35%|███▍      | 53/153 [00:01<00:01, 52.41it/s, Epoch: 73, Batch: 54,Loss: -2.918,Avg.Loss: -2.707,LR: 8.85E-05]Training epoch 73:  35%|███▌      | 54/153 [00:01<00:01, 52.64it/s, Epoch: 73, Batch: 54,Loss: -2.918,Avg.Loss: -2.707,LR: 8.85E-05]Training epoch 73:  35%|███▌      | 54/153 [00:01<00:01, 52.64it/s, Epoch: 73, Batch: 55,Loss: -3.285,Avg.Loss: -2.717,LR: 8.85E-05]Training epoch 73:  36%|███▌      | 55/153 [00:01<00:01, 52.64it/s, Epoch: 73, Batch: 56,Loss: -2.649,Avg.Loss: -2.716,LR: 8.84E-05]Training epoch 73:  37%|███▋      | 56/153 [00:01<00:01, 52.64it/s, Epoch: 73, Batch: 57,Loss: -3.001,Avg.Loss: -2.721,LR: 8.84E-05]Training epoch 73:  37%|███▋      | 57/153 [00:01<00:01, 52.64it/s, Epoch: 73, Batch: 58,Loss: -2.852,Avg.Loss: -2.723,LR: 8.84E-05]Training epoch 73:  38%|███▊      | 58/153 [00:01<00:01, 52.64it/s, Epoch: 73, Batch: 59,Loss: -3.123,Avg.Loss: -2.730,LR: 8.83E-05]Training epoch 73:  39%|███▊      | 59/153 [00:01<00:01, 52.64it/s, Epoch: 73, Batch: 60,Loss: -3.307,Avg.Loss: -2.740,LR: 8.83E-05]Training epoch 73:  39%|███▉      | 60/153 [00:01<00:01, 52.65it/s, Epoch: 73, Batch: 60,Loss: -3.307,Avg.Loss: -2.740,LR: 8.83E-05]Training epoch 73:  39%|███▉      | 60/153 [00:01<00:01, 52.65it/s, Epoch: 73, Batch: 61,Loss: -2.872,Avg.Loss: -2.742,LR: 8.82E-05]Training epoch 73:  40%|███▉      | 61/153 [00:01<00:01, 52.65it/s, Epoch: 73, Batch: 62,Loss: -2.754,Avg.Loss: -2.742,LR: 8.82E-05]Training epoch 73:  41%|████      | 62/153 [00:01<00:01, 52.65it/s, Epoch: 73, Batch: 63,Loss: -2.949,Avg.Loss: -2.745,LR: 8.82E-05]Training epoch 73:  41%|████      | 63/153 [00:01<00:01, 52.65it/s, Epoch: 73, Batch: 64,Loss: -2.945,Avg.Loss: -2.749,LR: 8.81E-05]Training epoch 73:  42%|████▏     | 64/153 [00:01<00:01, 52.65it/s, Epoch: 73, Batch: 65,Loss: -2.790,Avg.Loss: -2.749,LR: 8.81E-05]Training epoch 73:  42%|████▏     | 65/153 [00:01<00:01, 52.65it/s, Epoch: 73, Batch: 66,Loss: -2.946,Avg.Loss: -2.752,LR: 8.80E-05]Training epoch 73:  43%|████▎     | 66/153 [00:01<00:01, 52.70it/s, Epoch: 73, Batch: 66,Loss: -2.946,Avg.Loss: -2.752,LR: 8.80E-05]Training epoch 73:  43%|████▎     | 66/153 [00:01<00:01, 52.70it/s, Epoch: 73, Batch: 67,Loss: -2.826,Avg.Loss: -2.753,LR: 8.80E-05]Training epoch 73:  44%|████▍     | 67/153 [00:01<00:01, 52.70it/s, Epoch: 73, Batch: 68,Loss: -2.654,Avg.Loss: -2.752,LR: 8.80E-05]Training epoch 73:  44%|████▍     | 68/153 [00:01<00:01, 52.70it/s, Epoch: 73, Batch: 69,Loss: -2.662,Avg.Loss: -2.751,LR: 8.79E-05]Training epoch 73:  45%|████▌     | 69/153 [00:01<00:01, 52.70it/s, Epoch: 73, Batch: 70,Loss: -2.628,Avg.Loss: -2.749,LR: 8.79E-05]Training epoch 73:  46%|████▌     | 70/153 [00:01<00:01, 52.70it/s, Epoch: 73, Batch: 71,Loss: -2.837,Avg.Loss: -2.750,LR: 8.79E-05]Training epoch 73:  46%|████▋     | 71/153 [00:01<00:01, 52.70it/s, Epoch: 73, Batch: 72,Loss: -3.008,Avg.Loss: -2.754,LR: 8.78E-05]Training epoch 73:  47%|████▋     | 72/153 [00:01<00:01, 52.79it/s, Epoch: 73, Batch: 72,Loss: -3.008,Avg.Loss: -2.754,LR: 8.78E-05]Training epoch 73:  47%|████▋     | 72/153 [00:01<00:01, 52.79it/s, Epoch: 73, Batch: 73,Loss: -2.969,Avg.Loss: -2.757,LR: 8.78E-05]Training epoch 73:  48%|████▊     | 73/153 [00:01<00:01, 52.79it/s, Epoch: 73, Batch: 74,Loss: -3.142,Avg.Loss: -2.762,LR: 8.77E-05]Training epoch 73:  48%|████▊     | 74/153 [00:01<00:01, 52.79it/s, Epoch: 73, Batch: 75,Loss: -2.517,Avg.Loss: -2.759,LR: 8.77E-05]Training epoch 73:  49%|████▉     | 75/153 [00:01<00:01, 52.79it/s, Epoch: 73, Batch: 76,Loss: -3.262,Avg.Loss: -2.765,LR: 8.77E-05]Training epoch 73:  50%|████▉     | 76/153 [00:01<00:01, 52.79it/s, Epoch: 73, Batch: 77,Loss: -3.000,Avg.Loss: -2.768,LR: 8.76E-05]Training epoch 73:  50%|█████     | 77/153 [00:01<00:01, 52.79it/s, Epoch: 73, Batch: 78,Loss: -2.497,Avg.Loss: -2.765,LR: 8.76E-05]Training epoch 73:  51%|█████     | 78/153 [00:01<00:01, 52.71it/s, Epoch: 73, Batch: 78,Loss: -2.497,Avg.Loss: -2.765,LR: 8.76E-05]Training epoch 73:  51%|█████     | 78/153 [00:01<00:01, 52.71it/s, Epoch: 73, Batch: 79,Loss: -2.692,Avg.Loss: -2.764,LR: 8.75E-05]Training epoch 73:  52%|█████▏    | 79/153 [00:01<00:01, 52.71it/s, Epoch: 73, Batch: 80,Loss: -2.935,Avg.Loss: -2.766,LR: 8.75E-05]Training epoch 73:  52%|█████▏    | 80/153 [00:01<00:01, 52.71it/s, Epoch: 73, Batch: 81,Loss: -3.144,Avg.Loss: -2.771,LR: 8.75E-05]Training epoch 73:  53%|█████▎    | 81/153 [00:01<00:01, 52.71it/s, Epoch: 73, Batch: 82,Loss: -2.654,Avg.Loss: -2.769,LR: 8.74E-05]Training epoch 73:  54%|█████▎    | 82/153 [00:01<00:01, 52.71it/s, Epoch: 73, Batch: 83,Loss: -2.807,Avg.Loss: -2.770,LR: 8.74E-05]Training epoch 73:  54%|█████▍    | 83/153 [00:01<00:01, 52.71it/s, Epoch: 73, Batch: 84,Loss: -2.471,Avg.Loss: -2.766,LR: 8.73E-05]Training epoch 73:  55%|█████▍    | 84/153 [00:01<00:01, 52.67it/s, Epoch: 73, Batch: 84,Loss: -2.471,Avg.Loss: -2.766,LR: 8.73E-05]Training epoch 73:  55%|█████▍    | 84/153 [00:01<00:01, 52.67it/s, Epoch: 73, Batch: 85,Loss: -3.353,Avg.Loss: -2.773,LR: 8.73E-05]Training epoch 73:  56%|█████▌    | 85/153 [00:01<00:01, 52.67it/s, Epoch: 73, Batch: 86,Loss: -2.366,Avg.Loss: -2.768,LR: 8.73E-05]Training epoch 73:  56%|█████▌    | 86/153 [00:01<00:01, 52.67it/s, Epoch: 73, Batch: 87,Loss: -1.501,Avg.Loss: -2.754,LR: 8.72E-05]Training epoch 73:  57%|█████▋    | 87/153 [00:01<00:01, 52.67it/s, Epoch: 73, Batch: 88,Loss: -1.987,Avg.Loss: -2.745,LR: 8.72E-05]Training epoch 73:  58%|█████▊    | 88/153 [00:01<00:01, 52.67it/s, Epoch: 73, Batch: 89,Loss: -2.070,Avg.Loss: -2.737,LR: 8.72E-05]Training epoch 73:  58%|█████▊    | 89/153 [00:01<00:01, 52.67it/s, Epoch: 73, Batch: 90,Loss: -2.467,Avg.Loss: -2.734,LR: 8.71E-05]Training epoch 73:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 73, Batch: 90,Loss: -2.467,Avg.Loss: -2.734,LR: 8.71E-05]Training epoch 73:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 73, Batch: 91,Loss: -2.723,Avg.Loss: -2.734,LR: 8.71E-05]Training epoch 73:  59%|█████▉    | 91/153 [00:01<00:01, 52.91it/s, Epoch: 73, Batch: 92,Loss: -2.493,Avg.Loss: -2.732,LR: 8.70E-05]Training epoch 73:  60%|██████    | 92/153 [00:01<00:01, 52.91it/s, Epoch: 73, Batch: 93,Loss: -1.789,Avg.Loss: -2.721,LR: 8.70E-05]Training epoch 73:  61%|██████    | 93/153 [00:01<00:01, 52.91it/s, Epoch: 73, Batch: 94,Loss: -2.348,Avg.Loss: -2.718,LR: 8.70E-05]Training epoch 73:  61%|██████▏   | 94/153 [00:01<00:01, 52.91it/s, Epoch: 73, Batch: 95,Loss: -2.693,Avg.Loss: -2.717,LR: 8.69E-05]Training epoch 73:  62%|██████▏   | 95/153 [00:01<00:01, 52.91it/s, Epoch: 73, Batch: 96,Loss: -2.661,Avg.Loss: -2.717,LR: 8.69E-05]Training epoch 73:  63%|██████▎   | 96/153 [00:01<00:01, 52.94it/s, Epoch: 73, Batch: 96,Loss: -2.661,Avg.Loss: -2.717,LR: 8.69E-05]Training epoch 73:  63%|██████▎   | 96/153 [00:01<00:01, 52.94it/s, Epoch: 73, Batch: 97,Loss: -2.551,Avg.Loss: -2.715,LR: 8.68E-05]Training epoch 73:  63%|██████▎   | 97/153 [00:01<00:01, 52.94it/s, Epoch: 73, Batch: 98,Loss: -2.526,Avg.Loss: -2.713,LR: 8.68E-05]Training epoch 73:  64%|██████▍   | 98/153 [00:01<00:01, 52.94it/s, Epoch: 73, Batch: 99,Loss: -2.782,Avg.Loss: -2.714,LR: 8.68E-05]Training epoch 73:  65%|██████▍   | 99/153 [00:01<00:01, 52.94it/s, Epoch: 73, Batch: 100,Loss: -3.171,Avg.Loss: -2.718,LR: 8.67E-05]Training epoch 73:  65%|██████▌   | 100/153 [00:01<00:01, 52.94it/s, Epoch: 73, Batch: 101,Loss: -2.599,Avg.Loss: -2.717,LR: 8.67E-05]Training epoch 73:  66%|██████▌   | 101/153 [00:01<00:00, 52.94it/s, Epoch: 73, Batch: 102,Loss: -2.731,Avg.Loss: -2.717,LR: 8.66E-05]Training epoch 73:  67%|██████▋   | 102/153 [00:01<00:00, 53.00it/s, Epoch: 73, Batch: 102,Loss: -2.731,Avg.Loss: -2.717,LR: 8.66E-05]Training epoch 73:  67%|██████▋   | 102/153 [00:01<00:00, 53.00it/s, Epoch: 73, Batch: 103,Loss: -3.067,Avg.Loss: -2.721,LR: 8.66E-05]Training epoch 73:  67%|██████▋   | 103/153 [00:01<00:00, 53.00it/s, Epoch: 73, Batch: 104,Loss: -3.162,Avg.Loss: -2.725,LR: 8.66E-05]Training epoch 73:  68%|██████▊   | 104/153 [00:01<00:00, 53.00it/s, Epoch: 73, Batch: 105,Loss: -2.428,Avg.Loss: -2.722,LR: 8.65E-05]Training epoch 73:  69%|██████▊   | 105/153 [00:02<00:00, 53.00it/s, Epoch: 73, Batch: 106,Loss: -3.532,Avg.Loss: -2.730,LR: 8.65E-05]Training epoch 73:  69%|██████▉   | 106/153 [00:02<00:00, 53.00it/s, Epoch: 73, Batch: 107,Loss: -3.131,Avg.Loss: -2.733,LR: 8.65E-05]Training epoch 73:  70%|██████▉   | 107/153 [00:02<00:00, 53.00it/s, Epoch: 73, Batch: 108,Loss: -2.676,Avg.Loss: -2.733,LR: 8.64E-05]Training epoch 73:  71%|███████   | 108/153 [00:02<00:00, 53.11it/s, Epoch: 73, Batch: 108,Loss: -2.676,Avg.Loss: -2.733,LR: 8.64E-05]Training epoch 73:  71%|███████   | 108/153 [00:02<00:00, 53.11it/s, Epoch: 73, Batch: 109,Loss: -2.949,Avg.Loss: -2.735,LR: 8.64E-05]Training epoch 73:  71%|███████   | 109/153 [00:02<00:00, 53.11it/s, Epoch: 73, Batch: 110,Loss: -2.587,Avg.Loss: -2.734,LR: 8.63E-05]Training epoch 73:  72%|███████▏  | 110/153 [00:02<00:00, 53.11it/s, Epoch: 73, Batch: 111,Loss: -3.069,Avg.Loss: -2.737,LR: 8.63E-05]Training epoch 73:  73%|███████▎  | 111/153 [00:02<00:00, 53.11it/s, Epoch: 73, Batch: 112,Loss: -3.083,Avg.Loss: -2.740,LR: 8.63E-05]Training epoch 73:  73%|███████▎  | 112/153 [00:02<00:00, 53.11it/s, Epoch: 73, Batch: 113,Loss: -2.579,Avg.Loss: -2.738,LR: 8.62E-05]Training epoch 73:  74%|███████▍  | 113/153 [00:02<00:00, 53.11it/s, Epoch: 73, Batch: 114,Loss: -2.696,Avg.Loss: -2.738,LR: 8.62E-05]Training epoch 73:  75%|███████▍  | 114/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 114,Loss: -2.696,Avg.Loss: -2.738,LR: 8.62E-05]Training epoch 73:  75%|███████▍  | 114/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 115,Loss: -2.640,Avg.Loss: -2.737,LR: 8.61E-05]Training epoch 73:  75%|███████▌  | 115/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 116,Loss: -2.958,Avg.Loss: -2.739,LR: 8.61E-05]Training epoch 73:  76%|███████▌  | 116/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 117,Loss: -2.778,Avg.Loss: -2.739,LR: 8.61E-05]Training epoch 73:  76%|███████▋  | 117/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 118,Loss: -2.970,Avg.Loss: -2.741,LR: 8.60E-05]Training epoch 73:  77%|███████▋  | 118/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 119,Loss: -3.181,Avg.Loss: -2.745,LR: 8.60E-05]Training epoch 73:  78%|███████▊  | 119/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 120,Loss: -2.839,Avg.Loss: -2.746,LR: 8.59E-05]Training epoch 73:  78%|███████▊  | 120/153 [00:02<00:00, 52.85it/s, Epoch: 73, Batch: 120,Loss: -2.839,Avg.Loss: -2.746,LR: 8.59E-05]Training epoch 73:  78%|███████▊  | 120/153 [00:02<00:00, 52.85it/s, Epoch: 73, Batch: 121,Loss: -2.242,Avg.Loss: -2.742,LR: 8.59E-05]Training epoch 73:  79%|███████▉  | 121/153 [00:02<00:00, 52.85it/s, Epoch: 73, Batch: 122,Loss: -2.215,Avg.Loss: -2.737,LR: 8.59E-05]Training epoch 73:  80%|███████▉  | 122/153 [00:02<00:00, 52.85it/s, Epoch: 73, Batch: 123,Loss: -1.190,Avg.Loss: -2.725,LR: 8.58E-05]Training epoch 73:  80%|████████  | 123/153 [00:02<00:00, 52.85it/s, Epoch: 73, Batch: 124,Loss: -2.819,Avg.Loss: -2.725,LR: 8.58E-05]Training epoch 73:  81%|████████  | 124/153 [00:02<00:00, 52.85it/s, Epoch: 73, Batch: 125,Loss: -2.735,Avg.Loss: -2.725,LR: 8.58E-05]Training epoch 73:  82%|████████▏ | 125/153 [00:02<00:00, 52.85it/s, Epoch: 73, Batch: 126,Loss: -2.955,Avg.Loss: -2.727,LR: 8.57E-05]Training epoch 73:  82%|████████▏ | 126/153 [00:02<00:00, 52.91it/s, Epoch: 73, Batch: 126,Loss: -2.955,Avg.Loss: -2.727,LR: 8.57E-05]Training epoch 73:  82%|████████▏ | 126/153 [00:02<00:00, 52.91it/s, Epoch: 73, Batch: 127,Loss: -2.622,Avg.Loss: -2.726,LR: 8.57E-05]Training epoch 73:  83%|████████▎ | 127/153 [00:02<00:00, 52.91it/s, Epoch: 73, Batch: 128,Loss: -2.187,Avg.Loss: -2.722,LR: 8.56E-05]Training epoch 73:  84%|████████▎ | 128/153 [00:02<00:00, 52.91it/s, Epoch: 73, Batch: 129,Loss: -2.142,Avg.Loss: -2.718,LR: 8.56E-05]Training epoch 73:  84%|████████▍ | 129/153 [00:02<00:00, 52.91it/s, Epoch: 73, Batch: 130,Loss: -2.442,Avg.Loss: -2.716,LR: 8.56E-05]Training epoch 73:  85%|████████▍ | 130/153 [00:02<00:00, 52.91it/s, Epoch: 73, Batch: 131,Loss: -2.656,Avg.Loss: -2.715,LR: 8.55E-05]Training epoch 73:  86%|████████▌ | 131/153 [00:02<00:00, 52.91it/s, Epoch: 73, Batch: 132,Loss: -1.303,Avg.Loss: -2.704,LR: 8.55E-05]Training epoch 73:  86%|████████▋ | 132/153 [00:02<00:00, 52.99it/s, Epoch: 73, Batch: 132,Loss: -1.303,Avg.Loss: -2.704,LR: 8.55E-05]Training epoch 73:  86%|████████▋ | 132/153 [00:02<00:00, 52.99it/s, Epoch: 73, Batch: 133,Loss: -2.324,Avg.Loss: -2.702,LR: 8.54E-05]Training epoch 73:  87%|████████▋ | 133/153 [00:02<00:00, 52.99it/s, Epoch: 73, Batch: 134,Loss: -2.293,Avg.Loss: -2.699,LR: 8.54E-05]Training epoch 73:  88%|████████▊ | 134/153 [00:02<00:00, 52.99it/s, Epoch: 73, Batch: 135,Loss: -2.337,Avg.Loss: -2.696,LR: 8.54E-05]Training epoch 73:  88%|████████▊ | 135/153 [00:02<00:00, 52.99it/s, Epoch: 73, Batch: 136,Loss: -2.754,Avg.Loss: -2.696,LR: 8.53E-05]Training epoch 73:  89%|████████▉ | 136/153 [00:02<00:00, 52.99it/s, Epoch: 73, Batch: 137,Loss: -2.807,Avg.Loss: -2.697,LR: 8.53E-05]Training epoch 73:  90%|████████▉ | 137/153 [00:02<00:00, 52.99it/s, Epoch: 73, Batch: 138,Loss: -2.776,Avg.Loss: -2.698,LR: 8.53E-05]Training epoch 73:  90%|█████████ | 138/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 138,Loss: -2.776,Avg.Loss: -2.698,LR: 8.53E-05]Training epoch 73:  90%|█████████ | 138/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 139,Loss: -2.966,Avg.Loss: -2.700,LR: 8.52E-05]Training epoch 73:  91%|█████████ | 139/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 140,Loss: -2.864,Avg.Loss: -2.701,LR: 8.52E-05]Training epoch 73:  92%|█████████▏| 140/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 141,Loss: -2.892,Avg.Loss: -2.702,LR: 8.51E-05]Training epoch 73:  92%|█████████▏| 141/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 142,Loss: -2.593,Avg.Loss: -2.701,LR: 8.51E-05]Training epoch 73:  93%|█████████▎| 142/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 143,Loss: -3.092,Avg.Loss: -2.704,LR: 8.51E-05]Training epoch 73:  93%|█████████▎| 143/153 [00:02<00:00, 53.09it/s, Epoch: 73, Batch: 144,Loss: -2.720,Avg.Loss: -2.704,LR: 8.50E-05]Training epoch 73:  94%|█████████▍| 144/153 [00:02<00:00, 53.13it/s, Epoch: 73, Batch: 144,Loss: -2.720,Avg.Loss: -2.704,LR: 8.50E-05]Training epoch 73:  94%|█████████▍| 144/153 [00:02<00:00, 53.13it/s, Epoch: 73, Batch: 145,Loss: -2.978,Avg.Loss: -2.706,LR: 8.50E-05]Training epoch 73:  95%|█████████▍| 145/153 [00:02<00:00, 53.13it/s, Epoch: 73, Batch: 146,Loss: -1.752,Avg.Loss: -2.700,LR: 8.49E-05]Training epoch 73:  95%|█████████▌| 146/153 [00:02<00:00, 53.13it/s, Epoch: 73, Batch: 147,Loss: -2.651,Avg.Loss: -2.699,LR: 8.49E-05]Training epoch 73:  96%|█████████▌| 147/153 [00:02<00:00, 53.13it/s, Epoch: 73, Batch: 148,Loss: -2.783,Avg.Loss: -2.700,LR: 8.49E-05]Training epoch 73:  97%|█████████▋| 148/153 [00:02<00:00, 53.13it/s, Epoch: 73, Batch: 149,Loss: -3.299,Avg.Loss: -2.704,LR: 8.48E-05]Training epoch 73:  97%|█████████▋| 149/153 [00:02<00:00, 53.13it/s, Epoch: 73, Batch: 150,Loss: -2.718,Avg.Loss: -2.704,LR: 8.48E-05]Training epoch 73:  98%|█████████▊| 150/153 [00:02<00:00, 53.04it/s, Epoch: 73, Batch: 150,Loss: -2.718,Avg.Loss: -2.704,LR: 8.48E-05]Training epoch 73:  98%|█████████▊| 150/153 [00:02<00:00, 53.04it/s, Epoch: 73, Batch: 151,Loss: -2.643,Avg.Loss: -2.704,LR: 8.47E-05]Training epoch 73:  99%|█████████▊| 151/153 [00:02<00:00, 53.04it/s, Epoch: 73, Batch: 152,Loss: -2.324,Avg.Loss: -2.701,LR: 8.47E-05]Training epoch 73:  99%|█████████▉| 152/153 [00:02<00:00, 53.04it/s, Epoch: 73, Batch: 153,Loss: -2.004,Avg.Loss: -2.696,LR: 8.47E-05]Training epoch 73: 100%|██████████| 153/153 [00:02<00:00, 52.77it/s, Epoch: 73, Batch: 153,Loss: -2.004,Avg.Loss: -2.696,LR: 8.47E-05]
Training epoch 74:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 74:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 74, Batch: 1,Loss: -2.826,Avg.Loss: -2.826,LR: 8.46E-05]Training epoch 74:   1%|          | 1/153 [00:00<00:05, 30.37it/s, Epoch: 74, Batch: 2,Loss: -2.686,Avg.Loss: -2.756,LR: 8.46E-05]Training epoch 74:   1%|▏         | 2/153 [00:00<00:03, 39.66it/s, Epoch: 74, Batch: 3,Loss: -2.636,Avg.Loss: -2.716,LR: 8.46E-05]Training epoch 74:   2%|▏         | 3/153 [00:00<00:03, 46.51it/s, Epoch: 74, Batch: 4,Loss: -2.619,Avg.Loss: -2.692,LR: 8.45E-05]Training epoch 74:   3%|▎         | 4/153 [00:00<00:03, 48.59it/s, Epoch: 74, Batch: 5,Loss: -2.781,Avg.Loss: -2.710,LR: 8.45E-05]Training epoch 74:   3%|▎         | 5/153 [00:00<00:02, 49.94it/s, Epoch: 74, Batch: 6,Loss: -3.184,Avg.Loss: -2.789,LR: 8.44E-05]Training epoch 74:   4%|▍         | 6/153 [00:00<00:02, 59.82it/s, Epoch: 74, Batch: 6,Loss: -3.184,Avg.Loss: -2.789,LR: 8.44E-05]Training epoch 74:   4%|▍         | 6/153 [00:00<00:02, 59.82it/s, Epoch: 74, Batch: 7,Loss: -2.838,Avg.Loss: -2.796,LR: 8.44E-05]Training epoch 74:   5%|▍         | 7/153 [00:00<00:02, 59.82it/s, Epoch: 74, Batch: 8,Loss: -2.603,Avg.Loss: -2.772,LR: 8.44E-05]Training epoch 74:   5%|▌         | 8/153 [00:00<00:02, 59.82it/s, Epoch: 74, Batch: 9,Loss: -2.933,Avg.Loss: -2.790,LR: 8.43E-05]Training epoch 74:   6%|▌         | 9/153 [00:00<00:02, 59.82it/s, Epoch: 74, Batch: 10,Loss: -2.734,Avg.Loss: -2.784,LR: 8.43E-05]Training epoch 74:   7%|▋         | 10/153 [00:00<00:02, 59.82it/s, Epoch: 74, Batch: 11,Loss: -2.726,Avg.Loss: -2.779,LR: 8.42E-05]Training epoch 74:   7%|▋         | 11/153 [00:00<00:02, 59.82it/s, Epoch: 74, Batch: 12,Loss: -2.647,Avg.Loss: -2.768,LR: 8.42E-05]Training epoch 74:   8%|▊         | 12/153 [00:00<00:02, 55.46it/s, Epoch: 74, Batch: 12,Loss: -2.647,Avg.Loss: -2.768,LR: 8.42E-05]Training epoch 74:   8%|▊         | 12/153 [00:00<00:02, 55.46it/s, Epoch: 74, Batch: 13,Loss: -2.739,Avg.Loss: -2.766,LR: 8.42E-05]Training epoch 74:   8%|▊         | 13/153 [00:00<00:02, 55.46it/s, Epoch: 74, Batch: 14,Loss: -2.949,Avg.Loss: -2.779,LR: 8.41E-05]Training epoch 74:   9%|▉         | 14/153 [00:00<00:02, 55.46it/s, Epoch: 74, Batch: 15,Loss: -2.673,Avg.Loss: -2.772,LR: 8.41E-05]Training epoch 74:  10%|▉         | 15/153 [00:00<00:02, 55.46it/s, Epoch: 74, Batch: 16,Loss: -2.828,Avg.Loss: -2.775,LR: 8.41E-05]Training epoch 74:  10%|█         | 16/153 [00:00<00:02, 55.46it/s, Epoch: 74, Batch: 17,Loss: -2.991,Avg.Loss: -2.788,LR: 8.40E-05]Training epoch 74:  11%|█         | 17/153 [00:00<00:02, 55.46it/s, Epoch: 74, Batch: 18,Loss: -2.889,Avg.Loss: -2.794,LR: 8.40E-05]Training epoch 74:  12%|█▏        | 18/153 [00:00<00:02, 54.59it/s, Epoch: 74, Batch: 18,Loss: -2.889,Avg.Loss: -2.794,LR: 8.40E-05]Training epoch 74:  12%|█▏        | 18/153 [00:00<00:02, 54.59it/s, Epoch: 74, Batch: 19,Loss: -2.816,Avg.Loss: -2.795,LR: 8.39E-05]Training epoch 74:  12%|█▏        | 19/153 [00:00<00:02, 54.59it/s, Epoch: 74, Batch: 20,Loss: -2.951,Avg.Loss: -2.803,LR: 8.39E-05]Training epoch 74:  13%|█▎        | 20/153 [00:00<00:02, 54.59it/s, Epoch: 74, Batch: 21,Loss: -3.088,Avg.Loss: -2.816,LR: 8.39E-05]Training epoch 74:  14%|█▎        | 21/153 [00:00<00:02, 54.59it/s, Epoch: 74, Batch: 22,Loss: -2.727,Avg.Loss: -2.812,LR: 8.38E-05]Training epoch 74:  14%|█▍        | 22/153 [00:00<00:02, 54.59it/s, Epoch: 74, Batch: 23,Loss: -2.697,Avg.Loss: -2.807,LR: 8.38E-05]Training epoch 74:  15%|█▌        | 23/153 [00:00<00:02, 54.59it/s, Epoch: 74, Batch: 24,Loss: -2.745,Avg.Loss: -2.804,LR: 8.37E-05]Training epoch 74:  16%|█▌        | 24/153 [00:00<00:02, 53.41it/s, Epoch: 74, Batch: 24,Loss: -2.745,Avg.Loss: -2.804,LR: 8.37E-05]Training epoch 74:  16%|█▌        | 24/153 [00:00<00:02, 53.41it/s, Epoch: 74, Batch: 25,Loss: -2.338,Avg.Loss: -2.786,LR: 8.37E-05]Training epoch 74:  16%|█▋        | 25/153 [00:00<00:02, 53.41it/s, Epoch: 74, Batch: 26,Loss: -2.898,Avg.Loss: -2.790,LR: 8.37E-05]Training epoch 74:  17%|█▋        | 26/153 [00:00<00:02, 53.41it/s, Epoch: 74, Batch: 27,Loss: -3.079,Avg.Loss: -2.801,LR: 8.36E-05]Training epoch 74:  18%|█▊        | 27/153 [00:00<00:02, 53.41it/s, Epoch: 74, Batch: 28,Loss: -3.044,Avg.Loss: -2.810,LR: 8.36E-05]Training epoch 74:  18%|█▊        | 28/153 [00:00<00:02, 53.41it/s, Epoch: 74, Batch: 29,Loss: -2.464,Avg.Loss: -2.798,LR: 8.36E-05]Training epoch 74:  19%|█▉        | 29/153 [00:00<00:02, 53.41it/s, Epoch: 74, Batch: 30,Loss: -2.657,Avg.Loss: -2.793,LR: 8.35E-05]Training epoch 74:  20%|█▉        | 30/153 [00:00<00:02, 52.59it/s, Epoch: 74, Batch: 30,Loss: -2.657,Avg.Loss: -2.793,LR: 8.35E-05]Training epoch 74:  20%|█▉        | 30/153 [00:00<00:02, 52.59it/s, Epoch: 74, Batch: 31,Loss: -2.588,Avg.Loss: -2.786,LR: 8.35E-05]Training epoch 74:  20%|██        | 31/153 [00:00<00:02, 52.59it/s, Epoch: 74, Batch: 32,Loss: -2.929,Avg.Loss: -2.791,LR: 8.34E-05]Training epoch 74:  21%|██        | 32/153 [00:00<00:02, 52.59it/s, Epoch: 74, Batch: 33,Loss: -2.919,Avg.Loss: -2.795,LR: 8.34E-05]Training epoch 74:  22%|██▏       | 33/153 [00:00<00:02, 52.59it/s, Epoch: 74, Batch: 34,Loss: -2.691,Avg.Loss: -2.792,LR: 8.34E-05]Training epoch 74:  22%|██▏       | 34/153 [00:00<00:02, 52.59it/s, Epoch: 74, Batch: 35,Loss: -2.727,Avg.Loss: -2.790,LR: 8.33E-05]Training epoch 74:  23%|██▎       | 35/153 [00:00<00:02, 52.59it/s, Epoch: 74, Batch: 36,Loss: -2.802,Avg.Loss: -2.790,LR: 8.33E-05]Training epoch 74:  24%|██▎       | 36/153 [00:00<00:02, 52.50it/s, Epoch: 74, Batch: 36,Loss: -2.802,Avg.Loss: -2.790,LR: 8.33E-05]Training epoch 74:  24%|██▎       | 36/153 [00:00<00:02, 52.50it/s, Epoch: 74, Batch: 37,Loss: -2.614,Avg.Loss: -2.785,LR: 8.33E-05]Training epoch 74:  24%|██▍       | 37/153 [00:00<00:02, 52.50it/s, Epoch: 74, Batch: 38,Loss: -3.022,Avg.Loss: -2.792,LR: 8.32E-05]Training epoch 74:  25%|██▍       | 38/153 [00:00<00:02, 52.50it/s, Epoch: 74, Batch: 39,Loss: -2.714,Avg.Loss: -2.790,LR: 8.32E-05]Training epoch 74:  25%|██▌       | 39/153 [00:00<00:02, 52.50it/s, Epoch: 74, Batch: 40,Loss: -3.028,Avg.Loss: -2.796,LR: 8.31E-05]Training epoch 74:  26%|██▌       | 40/153 [00:00<00:02, 52.50it/s, Epoch: 74, Batch: 41,Loss: -2.347,Avg.Loss: -2.785,LR: 8.31E-05]Training epoch 74:  27%|██▋       | 41/153 [00:00<00:02, 52.50it/s, Epoch: 74, Batch: 42,Loss: -2.929,Avg.Loss: -2.788,LR: 8.31E-05]Training epoch 74:  27%|██▋       | 42/153 [00:00<00:02, 52.63it/s, Epoch: 74, Batch: 42,Loss: -2.929,Avg.Loss: -2.788,LR: 8.31E-05]Training epoch 74:  27%|██▋       | 42/153 [00:00<00:02, 52.63it/s, Epoch: 74, Batch: 43,Loss: -2.622,Avg.Loss: -2.784,LR: 8.30E-05]Training epoch 74:  28%|██▊       | 43/153 [00:00<00:02, 52.63it/s, Epoch: 74, Batch: 44,Loss: -3.092,Avg.Loss: -2.791,LR: 8.30E-05]Training epoch 74:  29%|██▉       | 44/153 [00:00<00:02, 52.63it/s, Epoch: 74, Batch: 45,Loss: -2.802,Avg.Loss: -2.791,LR: 8.29E-05]Training epoch 74:  29%|██▉       | 45/153 [00:00<00:02, 52.63it/s, Epoch: 74, Batch: 46,Loss: -2.752,Avg.Loss: -2.791,LR: 8.29E-05]Training epoch 74:  30%|███       | 46/153 [00:00<00:02, 52.63it/s, Epoch: 74, Batch: 47,Loss: -2.774,Avg.Loss: -2.790,LR: 8.29E-05]Training epoch 74:  31%|███       | 47/153 [00:00<00:02, 52.63it/s, Epoch: 74, Batch: 48,Loss: -2.501,Avg.Loss: -2.784,LR: 8.28E-05]Training epoch 74:  31%|███▏      | 48/153 [00:00<00:01, 52.67it/s, Epoch: 74, Batch: 48,Loss: -2.501,Avg.Loss: -2.784,LR: 8.28E-05]Training epoch 74:  31%|███▏      | 48/153 [00:00<00:01, 52.67it/s, Epoch: 74, Batch: 49,Loss: -2.396,Avg.Loss: -2.776,LR: 8.28E-05]Training epoch 74:  32%|███▏      | 49/153 [00:00<00:01, 52.67it/s, Epoch: 74, Batch: 50,Loss: -1.899,Avg.Loss: -2.759,LR: 8.28E-05]Training epoch 74:  33%|███▎      | 50/153 [00:00<00:01, 52.67it/s, Epoch: 74, Batch: 51,Loss: -2.762,Avg.Loss: -2.759,LR: 8.27E-05]Training epoch 74:  33%|███▎      | 51/153 [00:00<00:01, 52.67it/s, Epoch: 74, Batch: 52,Loss: -2.241,Avg.Loss: -2.749,LR: 8.27E-05]Training epoch 74:  34%|███▍      | 52/153 [00:00<00:01, 52.67it/s, Epoch: 74, Batch: 53,Loss: -3.081,Avg.Loss: -2.755,LR: 8.26E-05]Training epoch 74:  35%|███▍      | 53/153 [00:01<00:01, 52.67it/s, Epoch: 74, Batch: 54,Loss: -2.763,Avg.Loss: -2.755,LR: 8.26E-05]Training epoch 74:  35%|███▌      | 54/153 [00:01<00:01, 52.42it/s, Epoch: 74, Batch: 54,Loss: -2.763,Avg.Loss: -2.755,LR: 8.26E-05]Training epoch 74:  35%|███▌      | 54/153 [00:01<00:01, 52.42it/s, Epoch: 74, Batch: 55,Loss: -2.490,Avg.Loss: -2.750,LR: 8.26E-05]Training epoch 74:  36%|███▌      | 55/153 [00:01<00:01, 52.42it/s, Epoch: 74, Batch: 56,Loss: -2.843,Avg.Loss: -2.752,LR: 8.25E-05]Training epoch 74:  37%|███▋      | 56/153 [00:01<00:01, 52.42it/s, Epoch: 74, Batch: 57,Loss: -2.598,Avg.Loss: -2.749,LR: 8.25E-05]Training epoch 74:  37%|███▋      | 57/153 [00:01<00:01, 52.42it/s, Epoch: 74, Batch: 58,Loss: -3.027,Avg.Loss: -2.754,LR: 8.25E-05]Training epoch 74:  38%|███▊      | 58/153 [00:01<00:01, 52.42it/s, Epoch: 74, Batch: 59,Loss: -2.429,Avg.Loss: -2.749,LR: 8.24E-05]Training epoch 74:  39%|███▊      | 59/153 [00:01<00:01, 52.42it/s, Epoch: 74, Batch: 60,Loss: -3.046,Avg.Loss: -2.754,LR: 8.24E-05]Training epoch 74:  39%|███▉      | 60/153 [00:01<00:01, 52.50it/s, Epoch: 74, Batch: 60,Loss: -3.046,Avg.Loss: -2.754,LR: 8.24E-05]Training epoch 74:  39%|███▉      | 60/153 [00:01<00:01, 52.50it/s, Epoch: 74, Batch: 61,Loss: -2.682,Avg.Loss: -2.752,LR: 8.23E-05]Training epoch 74:  40%|███▉      | 61/153 [00:01<00:01, 52.50it/s, Epoch: 74, Batch: 62,Loss: -2.403,Avg.Loss: -2.747,LR: 8.23E-05]Training epoch 74:  41%|████      | 62/153 [00:01<00:01, 52.50it/s, Epoch: 74, Batch: 63,Loss: -2.463,Avg.Loss: -2.742,LR: 8.23E-05]Training epoch 74:  41%|████      | 63/153 [00:01<00:01, 52.50it/s, Epoch: 74, Batch: 64,Loss: -2.567,Avg.Loss: -2.740,LR: 8.22E-05]Training epoch 74:  42%|████▏     | 64/153 [00:01<00:01, 52.50it/s, Epoch: 74, Batch: 65,Loss: -2.880,Avg.Loss: -2.742,LR: 8.22E-05]Training epoch 74:  42%|████▏     | 65/153 [00:01<00:01, 52.50it/s, Epoch: 74, Batch: 66,Loss: -2.659,Avg.Loss: -2.740,LR: 8.21E-05]Training epoch 74:  43%|████▎     | 66/153 [00:01<00:01, 52.69it/s, Epoch: 74, Batch: 66,Loss: -2.659,Avg.Loss: -2.740,LR: 8.21E-05]Training epoch 74:  43%|████▎     | 66/153 [00:01<00:01, 52.69it/s, Epoch: 74, Batch: 67,Loss: -2.770,Avg.Loss: -2.741,LR: 8.21E-05]Training epoch 74:  44%|████▍     | 67/153 [00:01<00:01, 52.69it/s, Epoch: 74, Batch: 68,Loss: -2.937,Avg.Loss: -2.744,LR: 8.21E-05]Training epoch 74:  44%|████▍     | 68/153 [00:01<00:01, 52.69it/s, Epoch: 74, Batch: 69,Loss: -2.589,Avg.Loss: -2.742,LR: 8.20E-05]Training epoch 74:  45%|████▌     | 69/153 [00:01<00:01, 52.69it/s, Epoch: 74, Batch: 70,Loss: -2.317,Avg.Loss: -2.735,LR: 8.20E-05]Training epoch 74:  46%|████▌     | 70/153 [00:01<00:01, 52.69it/s, Epoch: 74, Batch: 71,Loss: -2.082,Avg.Loss: -2.726,LR: 8.20E-05]Training epoch 74:  46%|████▋     | 71/153 [00:01<00:01, 52.69it/s, Epoch: 74, Batch: 72,Loss: -2.545,Avg.Loss: -2.724,LR: 8.19E-05]Training epoch 74:  47%|████▋     | 72/153 [00:01<00:01, 52.83it/s, Epoch: 74, Batch: 72,Loss: -2.545,Avg.Loss: -2.724,LR: 8.19E-05]Training epoch 74:  47%|████▋     | 72/153 [00:01<00:01, 52.83it/s, Epoch: 74, Batch: 73,Loss: -2.421,Avg.Loss: -2.720,LR: 8.19E-05]Training epoch 74:  48%|████▊     | 73/153 [00:01<00:01, 52.83it/s, Epoch: 74, Batch: 74,Loss: -2.823,Avg.Loss: -2.721,LR: 8.18E-05]Training epoch 74:  48%|████▊     | 74/153 [00:01<00:01, 52.83it/s, Epoch: 74, Batch: 75,Loss: -2.386,Avg.Loss: -2.717,LR: 8.18E-05]Training epoch 74:  49%|████▉     | 75/153 [00:01<00:01, 52.83it/s, Epoch: 74, Batch: 76,Loss: -2.330,Avg.Loss: -2.711,LR: 8.18E-05]Training epoch 74:  50%|████▉     | 76/153 [00:01<00:01, 52.83it/s, Epoch: 74, Batch: 77,Loss: -3.010,Avg.Loss: -2.715,LR: 8.17E-05]Training epoch 74:  50%|█████     | 77/153 [00:01<00:01, 52.83it/s, Epoch: 74, Batch: 78,Loss: -2.442,Avg.Loss: -2.712,LR: 8.17E-05]Training epoch 74:  51%|█████     | 78/153 [00:01<00:01, 52.87it/s, Epoch: 74, Batch: 78,Loss: -2.442,Avg.Loss: -2.712,LR: 8.17E-05]Training epoch 74:  51%|█████     | 78/153 [00:01<00:01, 52.87it/s, Epoch: 74, Batch: 79,Loss: -2.209,Avg.Loss: -2.705,LR: 8.17E-05]Training epoch 74:  52%|█████▏    | 79/153 [00:01<00:01, 52.87it/s, Epoch: 74, Batch: 80,Loss: -2.549,Avg.Loss: -2.703,LR: 8.16E-05]Training epoch 74:  52%|█████▏    | 80/153 [00:01<00:01, 52.87it/s, Epoch: 74, Batch: 81,Loss: -2.698,Avg.Loss: -2.703,LR: 8.16E-05]Training epoch 74:  53%|█████▎    | 81/153 [00:01<00:01, 52.87it/s, Epoch: 74, Batch: 82,Loss: -2.527,Avg.Loss: -2.701,LR: 8.15E-05]Training epoch 74:  54%|█████▎    | 82/153 [00:01<00:01, 52.87it/s, Epoch: 74, Batch: 83,Loss: -2.925,Avg.Loss: -2.704,LR: 8.15E-05]Training epoch 74:  54%|█████▍    | 83/153 [00:01<00:01, 52.87it/s, Epoch: 74, Batch: 84,Loss: -2.936,Avg.Loss: -2.707,LR: 8.15E-05]Training epoch 74:  55%|█████▍    | 84/153 [00:01<00:01, 52.77it/s, Epoch: 74, Batch: 84,Loss: -2.936,Avg.Loss: -2.707,LR: 8.15E-05]Training epoch 74:  55%|█████▍    | 84/153 [00:01<00:01, 52.77it/s, Epoch: 74, Batch: 85,Loss: -2.862,Avg.Loss: -2.709,LR: 8.14E-05]Training epoch 74:  56%|█████▌    | 85/153 [00:01<00:01, 52.77it/s, Epoch: 74, Batch: 86,Loss: -3.172,Avg.Loss: -2.714,LR: 8.14E-05]Training epoch 74:  56%|█████▌    | 86/153 [00:01<00:01, 52.77it/s, Epoch: 74, Batch: 87,Loss: -2.423,Avg.Loss: -2.711,LR: 8.13E-05]Training epoch 74:  57%|█████▋    | 87/153 [00:01<00:01, 52.77it/s, Epoch: 74, Batch: 88,Loss: -2.573,Avg.Loss: -2.709,LR: 8.13E-05]Training epoch 74:  58%|█████▊    | 88/153 [00:01<00:01, 52.77it/s, Epoch: 74, Batch: 89,Loss: -2.819,Avg.Loss: -2.710,LR: 8.13E-05]Training epoch 74:  58%|█████▊    | 89/153 [00:01<00:01, 52.77it/s, Epoch: 74, Batch: 90,Loss: -2.807,Avg.Loss: -2.711,LR: 8.12E-05]Training epoch 74:  59%|█████▉    | 90/153 [00:01<00:01, 52.62it/s, Epoch: 74, Batch: 90,Loss: -2.807,Avg.Loss: -2.711,LR: 8.12E-05]Training epoch 74:  59%|█████▉    | 90/153 [00:01<00:01, 52.62it/s, Epoch: 74, Batch: 91,Loss: -2.868,Avg.Loss: -2.713,LR: 8.12E-05]Training epoch 74:  59%|█████▉    | 91/153 [00:01<00:01, 52.62it/s, Epoch: 74, Batch: 92,Loss: -3.017,Avg.Loss: -2.716,LR: 8.12E-05]Training epoch 74:  60%|██████    | 92/153 [00:01<00:01, 52.62it/s, Epoch: 74, Batch: 93,Loss: -3.346,Avg.Loss: -2.723,LR: 8.11E-05]Training epoch 74:  61%|██████    | 93/153 [00:01<00:01, 52.62it/s, Epoch: 74, Batch: 94,Loss: -3.056,Avg.Loss: -2.727,LR: 8.11E-05]Training epoch 74:  61%|██████▏   | 94/153 [00:01<00:01, 52.62it/s, Epoch: 74, Batch: 95,Loss: -2.609,Avg.Loss: -2.725,LR: 8.10E-05]Training epoch 74:  62%|██████▏   | 95/153 [00:01<00:01, 52.62it/s, Epoch: 74, Batch: 96,Loss: -2.567,Avg.Loss: -2.724,LR: 8.10E-05]Training epoch 74:  63%|██████▎   | 96/153 [00:01<00:01, 52.74it/s, Epoch: 74, Batch: 96,Loss: -2.567,Avg.Loss: -2.724,LR: 8.10E-05]Training epoch 74:  63%|██████▎   | 96/153 [00:01<00:01, 52.74it/s, Epoch: 74, Batch: 97,Loss: -2.551,Avg.Loss: -2.722,LR: 8.10E-05]Training epoch 74:  63%|██████▎   | 97/153 [00:01<00:01, 52.74it/s, Epoch: 74, Batch: 98,Loss: -2.509,Avg.Loss: -2.720,LR: 8.09E-05]Training epoch 74:  64%|██████▍   | 98/153 [00:01<00:01, 52.74it/s, Epoch: 74, Batch: 99,Loss: -2.392,Avg.Loss: -2.717,LR: 8.09E-05]Training epoch 74:  65%|██████▍   | 99/153 [00:01<00:01, 52.74it/s, Epoch: 74, Batch: 100,Loss: -2.748,Avg.Loss: -2.717,LR: 8.09E-05]Training epoch 74:  65%|██████▌   | 100/153 [00:01<00:01, 52.74it/s, Epoch: 74, Batch: 101,Loss: -3.074,Avg.Loss: -2.720,LR: 8.08E-05]Training epoch 74:  66%|██████▌   | 101/153 [00:01<00:00, 52.74it/s, Epoch: 74, Batch: 102,Loss: -3.666,Avg.Loss: -2.730,LR: 8.08E-05]Training epoch 74:  67%|██████▋   | 102/153 [00:01<00:00, 52.86it/s, Epoch: 74, Batch: 102,Loss: -3.666,Avg.Loss: -2.730,LR: 8.08E-05]Training epoch 74:  67%|██████▋   | 102/153 [00:01<00:00, 52.86it/s, Epoch: 74, Batch: 103,Loss: -3.063,Avg.Loss: -2.733,LR: 8.07E-05]Training epoch 74:  67%|██████▋   | 103/153 [00:01<00:00, 52.86it/s, Epoch: 74, Batch: 104,Loss: -2.315,Avg.Loss: -2.729,LR: 8.07E-05]Training epoch 74:  68%|██████▊   | 104/153 [00:01<00:00, 52.86it/s, Epoch: 74, Batch: 105,Loss: -2.228,Avg.Loss: -2.724,LR: 8.07E-05]Training epoch 74:  69%|██████▊   | 105/153 [00:02<00:00, 52.86it/s, Epoch: 74, Batch: 106,Loss: -1.942,Avg.Loss: -2.717,LR: 8.06E-05]Training epoch 74:  69%|██████▉   | 106/153 [00:02<00:00, 52.86it/s, Epoch: 74, Batch: 107,Loss: -2.612,Avg.Loss: -2.716,LR: 8.06E-05]Training epoch 74:  70%|██████▉   | 107/153 [00:02<00:00, 52.86it/s, Epoch: 74, Batch: 108,Loss: -3.154,Avg.Loss: -2.720,LR: 8.06E-05]Training epoch 74:  71%|███████   | 108/153 [00:02<00:00, 52.83it/s, Epoch: 74, Batch: 108,Loss: -3.154,Avg.Loss: -2.720,LR: 8.06E-05]Training epoch 74:  71%|███████   | 108/153 [00:02<00:00, 52.83it/s, Epoch: 74, Batch: 109,Loss: -2.467,Avg.Loss: -2.717,LR: 8.05E-05]Training epoch 74:  71%|███████   | 109/153 [00:02<00:00, 52.83it/s, Epoch: 74, Batch: 110,Loss: -2.921,Avg.Loss: -2.719,LR: 8.05E-05]Training epoch 74:  72%|███████▏  | 110/153 [00:02<00:00, 52.83it/s, Epoch: 74, Batch: 111,Loss: -2.175,Avg.Loss: -2.714,LR: 8.04E-05]Training epoch 74:  73%|███████▎  | 111/153 [00:02<00:00, 52.83it/s, Epoch: 74, Batch: 112,Loss: -2.907,Avg.Loss: -2.716,LR: 8.04E-05]Training epoch 74:  73%|███████▎  | 112/153 [00:02<00:00, 52.83it/s, Epoch: 74, Batch: 113,Loss: -2.934,Avg.Loss: -2.718,LR: 8.04E-05]Training epoch 74:  74%|███████▍  | 113/153 [00:02<00:00, 52.83it/s, Epoch: 74, Batch: 114,Loss: -2.809,Avg.Loss: -2.719,LR: 8.03E-05]Training epoch 74:  75%|███████▍  | 114/153 [00:02<00:00, 52.50it/s, Epoch: 74, Batch: 114,Loss: -2.809,Avg.Loss: -2.719,LR: 8.03E-05]Training epoch 74:  75%|███████▍  | 114/153 [00:02<00:00, 52.50it/s, Epoch: 74, Batch: 115,Loss: -2.571,Avg.Loss: -2.718,LR: 8.03E-05]Training epoch 74:  75%|███████▌  | 115/153 [00:02<00:00, 52.50it/s, Epoch: 74, Batch: 116,Loss: -2.642,Avg.Loss: -2.717,LR: 8.03E-05]Training epoch 74:  76%|███████▌  | 116/153 [00:02<00:00, 52.50it/s, Epoch: 74, Batch: 117,Loss: -2.752,Avg.Loss: -2.717,LR: 8.02E-05]Training epoch 74:  76%|███████▋  | 117/153 [00:02<00:00, 52.50it/s, Epoch: 74, Batch: 118,Loss: -2.954,Avg.Loss: -2.719,LR: 8.02E-05]Training epoch 74:  77%|███████▋  | 118/153 [00:02<00:00, 52.50it/s, Epoch: 74, Batch: 119,Loss: -2.867,Avg.Loss: -2.720,LR: 8.01E-05]Training epoch 74:  78%|███████▊  | 119/153 [00:02<00:00, 52.50it/s, Epoch: 74, Batch: 120,Loss: -2.781,Avg.Loss: -2.721,LR: 8.01E-05]Training epoch 74:  78%|███████▊  | 120/153 [00:02<00:00, 52.66it/s, Epoch: 74, Batch: 120,Loss: -2.781,Avg.Loss: -2.721,LR: 8.01E-05]Training epoch 74:  78%|███████▊  | 120/153 [00:02<00:00, 52.66it/s, Epoch: 74, Batch: 121,Loss: -2.363,Avg.Loss: -2.718,LR: 8.01E-05]Training epoch 74:  79%|███████▉  | 121/153 [00:02<00:00, 52.66it/s, Epoch: 74, Batch: 122,Loss: -3.036,Avg.Loss: -2.721,LR: 8.00E-05]Training epoch 74:  80%|███████▉  | 122/153 [00:02<00:00, 52.66it/s, Epoch: 74, Batch: 123,Loss: -2.697,Avg.Loss: -2.720,LR: 8.00E-05]Training epoch 74:  80%|████████  | 123/153 [00:02<00:00, 52.66it/s, Epoch: 74, Batch: 124,Loss: -3.336,Avg.Loss: -2.725,LR: 8.00E-05]Training epoch 74:  81%|████████  | 124/153 [00:02<00:00, 52.66it/s, Epoch: 74, Batch: 125,Loss: -3.009,Avg.Loss: -2.728,LR: 7.99E-05]Training epoch 74:  82%|████████▏ | 125/153 [00:02<00:00, 52.66it/s, Epoch: 74, Batch: 126,Loss: -3.086,Avg.Loss: -2.731,LR: 7.99E-05]Training epoch 74:  82%|████████▏ | 126/153 [00:02<00:00, 52.82it/s, Epoch: 74, Batch: 126,Loss: -3.086,Avg.Loss: -2.731,LR: 7.99E-05]Training epoch 74:  82%|████████▏ | 126/153 [00:02<00:00, 52.82it/s, Epoch: 74, Batch: 127,Loss: -3.250,Avg.Loss: -2.735,LR: 7.98E-05]Training epoch 74:  83%|████████▎ | 127/153 [00:02<00:00, 52.82it/s, Epoch: 74, Batch: 128,Loss: -3.310,Avg.Loss: -2.739,LR: 7.98E-05]Training epoch 74:  84%|████████▎ | 128/153 [00:02<00:00, 52.82it/s, Epoch: 74, Batch: 129,Loss: -3.085,Avg.Loss: -2.742,LR: 7.98E-05]Training epoch 74:  84%|████████▍ | 129/153 [00:02<00:00, 52.82it/s, Epoch: 74, Batch: 130,Loss: -3.027,Avg.Loss: -2.744,LR: 7.97E-05]Training epoch 74:  85%|████████▍ | 130/153 [00:02<00:00, 52.82it/s, Epoch: 74, Batch: 131,Loss: -2.808,Avg.Loss: -2.744,LR: 7.97E-05]Training epoch 74:  86%|████████▌ | 131/153 [00:02<00:00, 52.82it/s, Epoch: 74, Batch: 132,Loss: -3.037,Avg.Loss: -2.747,LR: 7.97E-05]Training epoch 74:  86%|████████▋ | 132/153 [00:02<00:00, 53.02it/s, Epoch: 74, Batch: 132,Loss: -3.037,Avg.Loss: -2.747,LR: 7.97E-05]Training epoch 74:  86%|████████▋ | 132/153 [00:02<00:00, 53.02it/s, Epoch: 74, Batch: 133,Loss: -3.292,Avg.Loss: -2.751,LR: 7.96E-05]Training epoch 74:  87%|████████▋ | 133/153 [00:02<00:00, 53.02it/s, Epoch: 74, Batch: 134,Loss: -3.189,Avg.Loss: -2.754,LR: 7.96E-05]Training epoch 74:  88%|████████▊ | 134/153 [00:02<00:00, 53.02it/s, Epoch: 74, Batch: 135,Loss: -2.939,Avg.Loss: -2.755,LR: 7.95E-05]Training epoch 74:  88%|████████▊ | 135/153 [00:02<00:00, 53.02it/s, Epoch: 74, Batch: 136,Loss: -3.184,Avg.Loss: -2.759,LR: 7.95E-05]Training epoch 74:  89%|████████▉ | 136/153 [00:02<00:00, 53.02it/s, Epoch: 74, Batch: 137,Loss: -2.669,Avg.Loss: -2.758,LR: 7.95E-05]Training epoch 74:  90%|████████▉ | 137/153 [00:02<00:00, 53.02it/s, Epoch: 74, Batch: 138,Loss: -2.696,Avg.Loss: -2.757,LR: 7.94E-05]Training epoch 74:  90%|█████████ | 138/153 [00:02<00:00, 53.03it/s, Epoch: 74, Batch: 138,Loss: -2.696,Avg.Loss: -2.757,LR: 7.94E-05]Training epoch 74:  90%|█████████ | 138/153 [00:02<00:00, 53.03it/s, Epoch: 74, Batch: 139,Loss: -2.793,Avg.Loss: -2.758,LR: 7.94E-05]Training epoch 74:  91%|█████████ | 139/153 [00:02<00:00, 53.03it/s, Epoch: 74, Batch: 140,Loss: -3.006,Avg.Loss: -2.760,LR: 7.94E-05]Training epoch 74:  92%|█████████▏| 140/153 [00:02<00:00, 53.03it/s, Epoch: 74, Batch: 141,Loss: -2.548,Avg.Loss: -2.758,LR: 7.93E-05]Training epoch 74:  92%|█████████▏| 141/153 [00:02<00:00, 53.03it/s, Epoch: 74, Batch: 142,Loss: -2.390,Avg.Loss: -2.755,LR: 7.93E-05]Training epoch 74:  93%|█████████▎| 142/153 [00:02<00:00, 53.03it/s, Epoch: 74, Batch: 143,Loss: -2.932,Avg.Loss: -2.757,LR: 7.92E-05]Training epoch 74:  93%|█████████▎| 143/153 [00:02<00:00, 53.03it/s, Epoch: 74, Batch: 144,Loss: -2.652,Avg.Loss: -2.756,LR: 7.92E-05]Training epoch 74:  94%|█████████▍| 144/153 [00:02<00:00, 53.15it/s, Epoch: 74, Batch: 144,Loss: -2.652,Avg.Loss: -2.756,LR: 7.92E-05]Training epoch 74:  94%|█████████▍| 144/153 [00:02<00:00, 53.15it/s, Epoch: 74, Batch: 145,Loss: -3.106,Avg.Loss: -2.758,LR: 7.92E-05]Training epoch 74:  95%|█████████▍| 145/153 [00:02<00:00, 53.15it/s, Epoch: 74, Batch: 146,Loss: -2.736,Avg.Loss: -2.758,LR: 7.91E-05]Training epoch 74:  95%|█████████▌| 146/153 [00:02<00:00, 53.15it/s, Epoch: 74, Batch: 147,Loss: -2.697,Avg.Loss: -2.758,LR: 7.91E-05]Training epoch 74:  96%|█████████▌| 147/153 [00:02<00:00, 53.15it/s, Epoch: 74, Batch: 148,Loss: -2.423,Avg.Loss: -2.756,LR: 7.91E-05]Training epoch 74:  97%|█████████▋| 148/153 [00:02<00:00, 53.15it/s, Epoch: 74, Batch: 149,Loss: -2.363,Avg.Loss: -2.753,LR: 7.90E-05]Training epoch 74:  97%|█████████▋| 149/153 [00:02<00:00, 53.15it/s, Epoch: 74, Batch: 150,Loss: -2.457,Avg.Loss: -2.751,LR: 7.90E-05]Training epoch 74:  98%|█████████▊| 150/153 [00:02<00:00, 53.07it/s, Epoch: 74, Batch: 150,Loss: -2.457,Avg.Loss: -2.751,LR: 7.90E-05]Training epoch 74:  98%|█████████▊| 150/153 [00:02<00:00, 53.07it/s, Epoch: 74, Batch: 151,Loss: -2.506,Avg.Loss: -2.749,LR: 7.89E-05]Training epoch 74:  99%|█████████▊| 151/153 [00:02<00:00, 53.07it/s, Epoch: 74, Batch: 152,Loss: -2.993,Avg.Loss: -2.751,LR: 7.89E-05]Training epoch 74:  99%|█████████▉| 152/153 [00:02<00:00, 53.07it/s, Epoch: 74, Batch: 153,Loss: -2.506,Avg.Loss: -2.749,LR: 7.89E-05]Training epoch 74: 100%|██████████| 153/153 [00:02<00:00, 52.89it/s, Epoch: 74, Batch: 153,Loss: -2.506,Avg.Loss: -2.749,LR: 7.89E-05]
Training epoch 75:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 75:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 75, Batch: 1,Loss: -2.190,Avg.Loss: -2.190,LR: 7.88E-05]Training epoch 75:   1%|          | 1/153 [00:00<00:05, 27.25it/s, Epoch: 75, Batch: 2,Loss: -2.402,Avg.Loss: -2.296,LR: 7.88E-05]Training epoch 75:   1%|▏         | 2/153 [00:00<00:04, 36.78it/s, Epoch: 75, Batch: 3,Loss: -2.951,Avg.Loss: -2.514,LR: 7.88E-05]Training epoch 75:   2%|▏         | 3/153 [00:00<00:03, 41.75it/s, Epoch: 75, Batch: 4,Loss: -3.456,Avg.Loss: -2.750,LR: 7.87E-05]Training epoch 75:   3%|▎         | 4/153 [00:00<00:03, 44.30it/s, Epoch: 75, Batch: 5,Loss: -2.573,Avg.Loss: -2.714,LR: 7.87E-05]Training epoch 75:   3%|▎         | 5/153 [00:00<00:03, 45.67it/s, Epoch: 75, Batch: 6,Loss: -2.735,Avg.Loss: -2.718,LR: 7.86E-05]Training epoch 75:   4%|▍         | 6/153 [00:00<00:02, 54.72it/s, Epoch: 75, Batch: 6,Loss: -2.735,Avg.Loss: -2.718,LR: 7.86E-05]Training epoch 75:   4%|▍         | 6/153 [00:00<00:02, 54.72it/s, Epoch: 75, Batch: 7,Loss: -2.530,Avg.Loss: -2.691,LR: 7.86E-05]Training epoch 75:   5%|▍         | 7/153 [00:00<00:02, 54.72it/s, Epoch: 75, Batch: 8,Loss: -3.096,Avg.Loss: -2.742,LR: 7.86E-05]Training epoch 75:   5%|▌         | 8/153 [00:00<00:02, 54.72it/s, Epoch: 75, Batch: 9,Loss: -2.038,Avg.Loss: -2.663,LR: 7.85E-05]Training epoch 75:   6%|▌         | 9/153 [00:00<00:02, 54.72it/s, Epoch: 75, Batch: 10,Loss: -2.883,Avg.Loss: -2.685,LR: 7.85E-05]Training epoch 75:   7%|▋         | 10/153 [00:00<00:02, 54.72it/s, Epoch: 75, Batch: 11,Loss: -2.944,Avg.Loss: -2.709,LR: 7.85E-05]Training epoch 75:   7%|▋         | 11/153 [00:00<00:02, 54.72it/s, Epoch: 75, Batch: 12,Loss: -2.970,Avg.Loss: -2.731,LR: 7.84E-05]Training epoch 75:   8%|▊         | 12/153 [00:00<00:02, 53.25it/s, Epoch: 75, Batch: 12,Loss: -2.970,Avg.Loss: -2.731,LR: 7.84E-05]Training epoch 75:   8%|▊         | 12/153 [00:00<00:02, 53.25it/s, Epoch: 75, Batch: 13,Loss: -1.841,Avg.Loss: -2.662,LR: 7.84E-05]Training epoch 75:   8%|▊         | 13/153 [00:00<00:02, 53.25it/s, Epoch: 75, Batch: 14,Loss: -3.208,Avg.Loss: -2.701,LR: 7.83E-05]Training epoch 75:   9%|▉         | 14/153 [00:00<00:02, 53.25it/s, Epoch: 75, Batch: 15,Loss: -2.702,Avg.Loss: -2.701,LR: 7.83E-05]Training epoch 75:  10%|▉         | 15/153 [00:00<00:02, 53.25it/s, Epoch: 75, Batch: 16,Loss: -2.719,Avg.Loss: -2.702,LR: 7.83E-05]Training epoch 75:  10%|█         | 16/153 [00:00<00:02, 53.25it/s, Epoch: 75, Batch: 17,Loss: -2.761,Avg.Loss: -2.706,LR: 7.82E-05]Training epoch 75:  11%|█         | 17/153 [00:00<00:02, 53.25it/s, Epoch: 75, Batch: 18,Loss: -2.990,Avg.Loss: -2.722,LR: 7.82E-05]Training epoch 75:  12%|█▏        | 18/153 [00:00<00:02, 53.19it/s, Epoch: 75, Batch: 18,Loss: -2.990,Avg.Loss: -2.722,LR: 7.82E-05]Training epoch 75:  12%|█▏        | 18/153 [00:00<00:02, 53.19it/s, Epoch: 75, Batch: 19,Loss: -2.713,Avg.Loss: -2.721,LR: 7.82E-05]Training epoch 75:  12%|█▏        | 19/153 [00:00<00:02, 53.19it/s, Epoch: 75, Batch: 20,Loss: -2.878,Avg.Loss: -2.729,LR: 7.81E-05]Training epoch 75:  13%|█▎        | 20/153 [00:00<00:02, 53.19it/s, Epoch: 75, Batch: 21,Loss: -2.750,Avg.Loss: -2.730,LR: 7.81E-05]Training epoch 75:  14%|█▎        | 21/153 [00:00<00:02, 53.19it/s, Epoch: 75, Batch: 22,Loss: -2.545,Avg.Loss: -2.722,LR: 7.80E-05]Training epoch 75:  14%|█▍        | 22/153 [00:00<00:02, 53.19it/s, Epoch: 75, Batch: 23,Loss: -2.897,Avg.Loss: -2.729,LR: 7.80E-05]Training epoch 75:  15%|█▌        | 23/153 [00:00<00:02, 53.19it/s, Epoch: 75, Batch: 24,Loss: -2.686,Avg.Loss: -2.727,LR: 7.80E-05]Training epoch 75:  16%|█▌        | 24/153 [00:00<00:02, 52.54it/s, Epoch: 75, Batch: 24,Loss: -2.686,Avg.Loss: -2.727,LR: 7.80E-05]Training epoch 75:  16%|█▌        | 24/153 [00:00<00:02, 52.54it/s, Epoch: 75, Batch: 25,Loss: -3.099,Avg.Loss: -2.742,LR: 7.79E-05]Training epoch 75:  16%|█▋        | 25/153 [00:00<00:02, 52.54it/s, Epoch: 75, Batch: 26,Loss: -3.062,Avg.Loss: -2.755,LR: 7.79E-05]Training epoch 75:  17%|█▋        | 26/153 [00:00<00:02, 52.54it/s, Epoch: 75, Batch: 27,Loss: -2.946,Avg.Loss: -2.762,LR: 7.79E-05]Training epoch 75:  18%|█▊        | 27/153 [00:00<00:02, 52.54it/s, Epoch: 75, Batch: 28,Loss: -2.926,Avg.Loss: -2.768,LR: 7.78E-05]Training epoch 75:  18%|█▊        | 28/153 [00:00<00:02, 52.54it/s, Epoch: 75, Batch: 29,Loss: -2.615,Avg.Loss: -2.762,LR: 7.78E-05]Training epoch 75:  19%|█▉        | 29/153 [00:00<00:02, 52.54it/s, Epoch: 75, Batch: 30,Loss: -3.166,Avg.Loss: -2.776,LR: 7.77E-05]Training epoch 75:  20%|█▉        | 30/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 30,Loss: -3.166,Avg.Loss: -2.776,LR: 7.77E-05]Training epoch 75:  20%|█▉        | 30/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 31,Loss: -2.916,Avg.Loss: -2.780,LR: 7.77E-05]Training epoch 75:  20%|██        | 31/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 32,Loss: -2.638,Avg.Loss: -2.776,LR: 7.77E-05]Training epoch 75:  21%|██        | 32/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 33,Loss: -2.273,Avg.Loss: -2.761,LR: 7.76E-05]Training epoch 75:  22%|██▏       | 33/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 34,Loss: -2.418,Avg.Loss: -2.751,LR: 7.76E-05]Training epoch 75:  22%|██▏       | 34/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 35,Loss: -2.873,Avg.Loss: -2.754,LR: 7.76E-05]Training epoch 75:  23%|██▎       | 35/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 36,Loss: -2.667,Avg.Loss: -2.752,LR: 7.75E-05]Training epoch 75:  24%|██▎       | 36/153 [00:00<00:02, 52.38it/s, Epoch: 75, Batch: 36,Loss: -2.667,Avg.Loss: -2.752,LR: 7.75E-05]Training epoch 75:  24%|██▎       | 36/153 [00:00<00:02, 52.38it/s, Epoch: 75, Batch: 37,Loss: -2.563,Avg.Loss: -2.746,LR: 7.75E-05]Training epoch 75:  24%|██▍       | 37/153 [00:00<00:02, 52.38it/s, Epoch: 75, Batch: 38,Loss: -2.892,Avg.Loss: -2.750,LR: 7.74E-05]Training epoch 75:  25%|██▍       | 38/153 [00:00<00:02, 52.38it/s, Epoch: 75, Batch: 39,Loss: -2.791,Avg.Loss: -2.751,LR: 7.74E-05]Training epoch 75:  25%|██▌       | 39/153 [00:00<00:02, 52.38it/s, Epoch: 75, Batch: 40,Loss: -2.740,Avg.Loss: -2.751,LR: 7.74E-05]Training epoch 75:  26%|██▌       | 40/153 [00:00<00:02, 52.38it/s, Epoch: 75, Batch: 41,Loss: -3.145,Avg.Loss: -2.761,LR: 7.73E-05]Training epoch 75:  27%|██▋       | 41/153 [00:00<00:02, 52.38it/s, Epoch: 75, Batch: 42,Loss: -3.037,Avg.Loss: -2.767,LR: 7.73E-05]Training epoch 75:  27%|██▋       | 42/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 42,Loss: -3.037,Avg.Loss: -2.767,LR: 7.73E-05]Training epoch 75:  27%|██▋       | 42/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 43,Loss: -2.676,Avg.Loss: -2.765,LR: 7.73E-05]Training epoch 75:  28%|██▊       | 43/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 44,Loss: -2.784,Avg.Loss: -2.766,LR: 7.72E-05]Training epoch 75:  29%|██▉       | 44/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 45,Loss: -2.543,Avg.Loss: -2.761,LR: 7.72E-05]Training epoch 75:  29%|██▉       | 45/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 46,Loss: -3.012,Avg.Loss: -2.766,LR: 7.71E-05]Training epoch 75:  30%|███       | 46/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 47,Loss: -3.470,Avg.Loss: -2.781,LR: 7.71E-05]Training epoch 75:  31%|███       | 47/153 [00:00<00:02, 52.44it/s, Epoch: 75, Batch: 48,Loss: -2.891,Avg.Loss: -2.783,LR: 7.71E-05]Training epoch 75:  31%|███▏      | 48/153 [00:00<00:01, 52.61it/s, Epoch: 75, Batch: 48,Loss: -2.891,Avg.Loss: -2.783,LR: 7.71E-05]Training epoch 75:  31%|███▏      | 48/153 [00:00<00:01, 52.61it/s, Epoch: 75, Batch: 49,Loss: -2.655,Avg.Loss: -2.781,LR: 7.70E-05]Training epoch 75:  32%|███▏      | 49/153 [00:00<00:01, 52.61it/s, Epoch: 75, Batch: 50,Loss: -3.077,Avg.Loss: -2.787,LR: 7.70E-05]Training epoch 75:  33%|███▎      | 50/153 [00:00<00:01, 52.61it/s, Epoch: 75, Batch: 51,Loss: -2.636,Avg.Loss: -2.784,LR: 7.70E-05]Training epoch 75:  33%|███▎      | 51/153 [00:00<00:01, 52.61it/s, Epoch: 75, Batch: 52,Loss: -2.775,Avg.Loss: -2.784,LR: 7.69E-05]Training epoch 75:  34%|███▍      | 52/153 [00:01<00:01, 52.61it/s, Epoch: 75, Batch: 53,Loss: -2.505,Avg.Loss: -2.778,LR: 7.69E-05]Training epoch 75:  35%|███▍      | 53/153 [00:01<00:01, 52.61it/s, Epoch: 75, Batch: 54,Loss: -2.822,Avg.Loss: -2.779,LR: 7.69E-05]Training epoch 75:  35%|███▌      | 54/153 [00:01<00:01, 53.39it/s, Epoch: 75, Batch: 54,Loss: -2.822,Avg.Loss: -2.779,LR: 7.69E-05]Training epoch 75:  35%|███▌      | 54/153 [00:01<00:01, 53.39it/s, Epoch: 75, Batch: 55,Loss: -3.164,Avg.Loss: -2.786,LR: 7.68E-05]Training epoch 75:  36%|███▌      | 55/153 [00:01<00:01, 53.39it/s, Epoch: 75, Batch: 56,Loss: -2.868,Avg.Loss: -2.788,LR: 7.68E-05]Training epoch 75:  37%|███▋      | 56/153 [00:01<00:01, 53.39it/s, Epoch: 75, Batch: 57,Loss: -1.828,Avg.Loss: -2.771,LR: 7.67E-05]Training epoch 75:  37%|███▋      | 57/153 [00:01<00:01, 53.39it/s, Epoch: 75, Batch: 58,Loss: -2.348,Avg.Loss: -2.763,LR: 7.67E-05]Training epoch 75:  38%|███▊      | 58/153 [00:01<00:01, 53.39it/s, Epoch: 75, Batch: 59,Loss: -2.142,Avg.Loss: -2.753,LR: 7.67E-05]Training epoch 75:  39%|███▊      | 59/153 [00:01<00:01, 53.39it/s, Epoch: 75, Batch: 60,Loss: -2.240,Avg.Loss: -2.744,LR: 7.66E-05]Training epoch 75:  39%|███▉      | 60/153 [00:01<00:01, 53.28it/s, Epoch: 75, Batch: 60,Loss: -2.240,Avg.Loss: -2.744,LR: 7.66E-05]Training epoch 75:  39%|███▉      | 60/153 [00:01<00:01, 53.28it/s, Epoch: 75, Batch: 61,Loss: -2.643,Avg.Loss: -2.743,LR: 7.66E-05]Training epoch 75:  40%|███▉      | 61/153 [00:01<00:01, 53.28it/s, Epoch: 75, Batch: 62,Loss: -2.621,Avg.Loss: -2.741,LR: 7.66E-05]Training epoch 75:  41%|████      | 62/153 [00:01<00:01, 53.28it/s, Epoch: 75, Batch: 63,Loss: -2.771,Avg.Loss: -2.741,LR: 7.65E-05]Training epoch 75:  41%|████      | 63/153 [00:01<00:01, 53.28it/s, Epoch: 75, Batch: 64,Loss: -2.981,Avg.Loss: -2.745,LR: 7.65E-05]Training epoch 75:  42%|████▏     | 64/153 [00:01<00:01, 53.28it/s, Epoch: 75, Batch: 65,Loss: -2.971,Avg.Loss: -2.748,LR: 7.64E-05]Training epoch 75:  42%|████▏     | 65/153 [00:01<00:01, 53.28it/s, Epoch: 75, Batch: 66,Loss: -3.467,Avg.Loss: -2.759,LR: 7.64E-05]Training epoch 75:  43%|████▎     | 66/153 [00:01<00:01, 53.10it/s, Epoch: 75, Batch: 66,Loss: -3.467,Avg.Loss: -2.759,LR: 7.64E-05]Training epoch 75:  43%|████▎     | 66/153 [00:01<00:01, 53.10it/s, Epoch: 75, Batch: 67,Loss: -3.058,Avg.Loss: -2.764,LR: 7.64E-05]Training epoch 75:  44%|████▍     | 67/153 [00:01<00:01, 53.10it/s, Epoch: 75, Batch: 68,Loss: -2.897,Avg.Loss: -2.766,LR: 7.63E-05]Training epoch 75:  44%|████▍     | 68/153 [00:01<00:01, 53.10it/s, Epoch: 75, Batch: 69,Loss: -3.181,Avg.Loss: -2.772,LR: 7.63E-05]Training epoch 75:  45%|████▌     | 69/153 [00:01<00:01, 53.10it/s, Epoch: 75, Batch: 70,Loss: -2.943,Avg.Loss: -2.774,LR: 7.63E-05]Training epoch 75:  46%|████▌     | 70/153 [00:01<00:01, 53.10it/s, Epoch: 75, Batch: 71,Loss: -3.216,Avg.Loss: -2.780,LR: 7.62E-05]Training epoch 75:  46%|████▋     | 71/153 [00:01<00:01, 53.10it/s, Epoch: 75, Batch: 72,Loss: -3.092,Avg.Loss: -2.785,LR: 7.62E-05]Training epoch 75:  47%|████▋     | 72/153 [00:01<00:01, 52.75it/s, Epoch: 75, Batch: 72,Loss: -3.092,Avg.Loss: -2.785,LR: 7.62E-05]Training epoch 75:  47%|████▋     | 72/153 [00:01<00:01, 52.75it/s, Epoch: 75, Batch: 73,Loss: -2.730,Avg.Loss: -2.784,LR: 7.62E-05]Training epoch 75:  48%|████▊     | 73/153 [00:01<00:01, 52.75it/s, Epoch: 75, Batch: 74,Loss: -2.629,Avg.Loss: -2.782,LR: 7.61E-05]Training epoch 75:  48%|████▊     | 74/153 [00:01<00:01, 52.75it/s, Epoch: 75, Batch: 75,Loss: -2.581,Avg.Loss: -2.779,LR: 7.61E-05]Training epoch 75:  49%|████▉     | 75/153 [00:01<00:01, 52.75it/s, Epoch: 75, Batch: 76,Loss: -2.654,Avg.Loss: -2.778,LR: 7.60E-05]Training epoch 75:  50%|████▉     | 76/153 [00:01<00:01, 52.75it/s, Epoch: 75, Batch: 77,Loss: -3.130,Avg.Loss: -2.782,LR: 7.60E-05]Training epoch 75:  50%|█████     | 77/153 [00:01<00:01, 52.75it/s, Epoch: 75, Batch: 78,Loss: -2.458,Avg.Loss: -2.778,LR: 7.60E-05]Training epoch 75:  51%|█████     | 78/153 [00:01<00:01, 52.96it/s, Epoch: 75, Batch: 78,Loss: -2.458,Avg.Loss: -2.778,LR: 7.60E-05]Training epoch 75:  51%|█████     | 78/153 [00:01<00:01, 52.96it/s, Epoch: 75, Batch: 79,Loss: -2.655,Avg.Loss: -2.776,LR: 7.59E-05]Training epoch 75:  52%|█████▏    | 79/153 [00:01<00:01, 52.96it/s, Epoch: 75, Batch: 80,Loss: -2.656,Avg.Loss: -2.775,LR: 7.59E-05]Training epoch 75:  52%|█████▏    | 80/153 [00:01<00:01, 52.96it/s, Epoch: 75, Batch: 81,Loss: -2.509,Avg.Loss: -2.772,LR: 7.59E-05]Training epoch 75:  53%|█████▎    | 81/153 [00:01<00:01, 52.96it/s, Epoch: 75, Batch: 82,Loss: -2.712,Avg.Loss: -2.771,LR: 7.58E-05]Training epoch 75:  54%|█████▎    | 82/153 [00:01<00:01, 52.96it/s, Epoch: 75, Batch: 83,Loss: -3.004,Avg.Loss: -2.774,LR: 7.58E-05]Training epoch 75:  54%|█████▍    | 83/153 [00:01<00:01, 52.96it/s, Epoch: 75, Batch: 84,Loss: -2.792,Avg.Loss: -2.774,LR: 7.57E-05]Training epoch 75:  55%|█████▍    | 84/153 [00:01<00:01, 53.04it/s, Epoch: 75, Batch: 84,Loss: -2.792,Avg.Loss: -2.774,LR: 7.57E-05]Training epoch 75:  55%|█████▍    | 84/153 [00:01<00:01, 53.04it/s, Epoch: 75, Batch: 85,Loss: -3.179,Avg.Loss: -2.779,LR: 7.57E-05]Training epoch 75:  56%|█████▌    | 85/153 [00:01<00:01, 53.04it/s, Epoch: 75, Batch: 86,Loss: -3.147,Avg.Loss: -2.783,LR: 7.57E-05]Training epoch 75:  56%|█████▌    | 86/153 [00:01<00:01, 53.04it/s, Epoch: 75, Batch: 87,Loss: -2.596,Avg.Loss: -2.781,LR: 7.56E-05]Training epoch 75:  57%|█████▋    | 87/153 [00:01<00:01, 53.04it/s, Epoch: 75, Batch: 88,Loss: -2.638,Avg.Loss: -2.779,LR: 7.56E-05]Training epoch 75:  58%|█████▊    | 88/153 [00:01<00:01, 53.04it/s, Epoch: 75, Batch: 89,Loss: -2.896,Avg.Loss: -2.781,LR: 7.56E-05]Training epoch 75:  58%|█████▊    | 89/153 [00:01<00:01, 53.04it/s, Epoch: 75, Batch: 90,Loss: -2.895,Avg.Loss: -2.782,LR: 7.55E-05]Training epoch 75:  59%|█████▉    | 90/153 [00:01<00:01, 53.12it/s, Epoch: 75, Batch: 90,Loss: -2.895,Avg.Loss: -2.782,LR: 7.55E-05]Training epoch 75:  59%|█████▉    | 90/153 [00:01<00:01, 53.12it/s, Epoch: 75, Batch: 91,Loss: -2.396,Avg.Loss: -2.778,LR: 7.55E-05]Training epoch 75:  59%|█████▉    | 91/153 [00:01<00:01, 53.12it/s, Epoch: 75, Batch: 92,Loss: -2.954,Avg.Loss: -2.779,LR: 7.55E-05]Training epoch 75:  60%|██████    | 92/153 [00:01<00:01, 53.12it/s, Epoch: 75, Batch: 93,Loss: -3.080,Avg.Loss: -2.783,LR: 7.54E-05]Training epoch 75:  61%|██████    | 93/153 [00:01<00:01, 53.12it/s, Epoch: 75, Batch: 94,Loss: -2.856,Avg.Loss: -2.783,LR: 7.54E-05]Training epoch 75:  61%|██████▏   | 94/153 [00:01<00:01, 53.12it/s, Epoch: 75, Batch: 95,Loss: -3.108,Avg.Loss: -2.787,LR: 7.53E-05]Training epoch 75:  62%|██████▏   | 95/153 [00:01<00:01, 53.12it/s, Epoch: 75, Batch: 96,Loss: -2.992,Avg.Loss: -2.789,LR: 7.53E-05]Training epoch 75:  63%|██████▎   | 96/153 [00:01<00:01, 53.05it/s, Epoch: 75, Batch: 96,Loss: -2.992,Avg.Loss: -2.789,LR: 7.53E-05]Training epoch 75:  63%|██████▎   | 96/153 [00:01<00:01, 53.05it/s, Epoch: 75, Batch: 97,Loss: -2.973,Avg.Loss: -2.791,LR: 7.53E-05]Training epoch 75:  63%|██████▎   | 97/153 [00:01<00:01, 53.05it/s, Epoch: 75, Batch: 98,Loss: -3.277,Avg.Loss: -2.796,LR: 7.52E-05]Training epoch 75:  64%|██████▍   | 98/153 [00:01<00:01, 53.05it/s, Epoch: 75, Batch: 99,Loss: -2.354,Avg.Loss: -2.791,LR: 7.52E-05]Training epoch 75:  65%|██████▍   | 99/153 [00:01<00:01, 53.05it/s, Epoch: 75, Batch: 100,Loss: -2.983,Avg.Loss: -2.793,LR: 7.52E-05]Training epoch 75:  65%|██████▌   | 100/153 [00:01<00:00, 53.05it/s, Epoch: 75, Batch: 101,Loss: -3.088,Avg.Loss: -2.796,LR: 7.51E-05]Training epoch 75:  66%|██████▌   | 101/153 [00:01<00:00, 53.05it/s, Epoch: 75, Batch: 102,Loss: -3.333,Avg.Loss: -2.802,LR: 7.51E-05]Training epoch 75:  67%|██████▋   | 102/153 [00:01<00:00, 53.02it/s, Epoch: 75, Batch: 102,Loss: -3.333,Avg.Loss: -2.802,LR: 7.51E-05]Training epoch 75:  67%|██████▋   | 102/153 [00:01<00:00, 53.02it/s, Epoch: 75, Batch: 103,Loss: -2.775,Avg.Loss: -2.801,LR: 7.50E-05]Training epoch 75:  67%|██████▋   | 103/153 [00:01<00:00, 53.02it/s, Epoch: 75, Batch: 104,Loss: -2.837,Avg.Loss: -2.802,LR: 7.50E-05]Training epoch 75:  68%|██████▊   | 104/153 [00:01<00:00, 53.02it/s, Epoch: 75, Batch: 105,Loss: -2.652,Avg.Loss: -2.800,LR: 7.50E-05]Training epoch 75:  69%|██████▊   | 105/153 [00:02<00:00, 53.02it/s, Epoch: 75, Batch: 106,Loss: -2.705,Avg.Loss: -2.799,LR: 7.49E-05]Training epoch 75:  69%|██████▉   | 106/153 [00:02<00:00, 53.02it/s, Epoch: 75, Batch: 107,Loss: -2.168,Avg.Loss: -2.793,LR: 7.49E-05]Training epoch 75:  70%|██████▉   | 107/153 [00:02<00:00, 53.02it/s, Epoch: 75, Batch: 108,Loss: -2.521,Avg.Loss: -2.791,LR: 7.49E-05]Training epoch 75:  71%|███████   | 108/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 108,Loss: -2.521,Avg.Loss: -2.791,LR: 7.49E-05]Training epoch 75:  71%|███████   | 108/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 109,Loss: -2.585,Avg.Loss: -2.789,LR: 7.48E-05]Training epoch 75:  71%|███████   | 109/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 110,Loss: -3.002,Avg.Loss: -2.791,LR: 7.48E-05]Training epoch 75:  72%|███████▏  | 110/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 111,Loss: -2.203,Avg.Loss: -2.786,LR: 7.48E-05]Training epoch 75:  73%|███████▎  | 111/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 112,Loss: -2.707,Avg.Loss: -2.785,LR: 7.47E-05]Training epoch 75:  73%|███████▎  | 112/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 113,Loss: -2.976,Avg.Loss: -2.787,LR: 7.47E-05]Training epoch 75:  74%|███████▍  | 113/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 114,Loss: -2.419,Avg.Loss: -2.783,LR: 7.46E-05]Training epoch 75:  75%|███████▍  | 114/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 114,Loss: -2.419,Avg.Loss: -2.783,LR: 7.46E-05]Training epoch 75:  75%|███████▍  | 114/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 115,Loss: -3.048,Avg.Loss: -2.786,LR: 7.46E-05]Training epoch 75:  75%|███████▌  | 115/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 116,Loss: -2.297,Avg.Loss: -2.781,LR: 7.46E-05]Training epoch 75:  76%|███████▌  | 116/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 117,Loss: -2.974,Avg.Loss: -2.783,LR: 7.45E-05]Training epoch 75:  76%|███████▋  | 117/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 118,Loss: -2.707,Avg.Loss: -2.782,LR: 7.45E-05]Training epoch 75:  77%|███████▋  | 118/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 119,Loss: -2.772,Avg.Loss: -2.782,LR: 7.45E-05]Training epoch 75:  78%|███████▊  | 119/153 [00:02<00:00, 52.78it/s, Epoch: 75, Batch: 120,Loss: -2.790,Avg.Loss: -2.782,LR: 7.44E-05]Training epoch 75:  78%|███████▊  | 120/153 [00:02<00:00, 52.81it/s, Epoch: 75, Batch: 120,Loss: -2.790,Avg.Loss: -2.782,LR: 7.44E-05]Training epoch 75:  78%|███████▊  | 120/153 [00:02<00:00, 52.81it/s, Epoch: 75, Batch: 121,Loss: -3.076,Avg.Loss: -2.785,LR: 7.44E-05]Training epoch 75:  79%|███████▉  | 121/153 [00:02<00:00, 52.81it/s, Epoch: 75, Batch: 122,Loss: -3.335,Avg.Loss: -2.789,LR: 7.44E-05]Training epoch 75:  80%|███████▉  | 122/153 [00:02<00:00, 52.81it/s, Epoch: 75, Batch: 123,Loss: -2.784,Avg.Loss: -2.789,LR: 7.43E-05]Training epoch 75:  80%|████████  | 123/153 [00:02<00:00, 52.81it/s, Epoch: 75, Batch: 124,Loss: -3.017,Avg.Loss: -2.791,LR: 7.43E-05]Training epoch 75:  81%|████████  | 124/153 [00:02<00:00, 52.81it/s, Epoch: 75, Batch: 125,Loss: -2.828,Avg.Loss: -2.791,LR: 7.42E-05]Training epoch 75:  82%|████████▏ | 125/153 [00:02<00:00, 52.81it/s, Epoch: 75, Batch: 126,Loss: -2.686,Avg.Loss: -2.791,LR: 7.42E-05]Training epoch 75:  82%|████████▏ | 126/153 [00:02<00:00, 52.94it/s, Epoch: 75, Batch: 126,Loss: -2.686,Avg.Loss: -2.791,LR: 7.42E-05]Training epoch 75:  82%|████████▏ | 126/153 [00:02<00:00, 52.94it/s, Epoch: 75, Batch: 127,Loss: -2.536,Avg.Loss: -2.789,LR: 7.42E-05]Training epoch 75:  83%|████████▎ | 127/153 [00:02<00:00, 52.94it/s, Epoch: 75, Batch: 128,Loss: -3.284,Avg.Loss: -2.792,LR: 7.41E-05]Training epoch 75:  84%|████████▎ | 128/153 [00:02<00:00, 52.94it/s, Epoch: 75, Batch: 129,Loss: -2.812,Avg.Loss: -2.793,LR: 7.41E-05]Training epoch 75:  84%|████████▍ | 129/153 [00:02<00:00, 52.94it/s, Epoch: 75, Batch: 130,Loss: -3.220,Avg.Loss: -2.796,LR: 7.41E-05]Training epoch 75:  85%|████████▍ | 130/153 [00:02<00:00, 52.94it/s, Epoch: 75, Batch: 131,Loss: -2.685,Avg.Loss: -2.795,LR: 7.40E-05]Training epoch 75:  86%|████████▌ | 131/153 [00:02<00:00, 52.94it/s, Epoch: 75, Batch: 132,Loss: -2.879,Avg.Loss: -2.796,LR: 7.40E-05]Training epoch 75:  86%|████████▋ | 132/153 [00:02<00:00, 52.80it/s, Epoch: 75, Batch: 132,Loss: -2.879,Avg.Loss: -2.796,LR: 7.40E-05]Training epoch 75:  86%|████████▋ | 132/153 [00:02<00:00, 52.80it/s, Epoch: 75, Batch: 133,Loss: -2.658,Avg.Loss: -2.795,LR: 7.40E-05]Training epoch 75:  87%|████████▋ | 133/153 [00:02<00:00, 52.80it/s, Epoch: 75, Batch: 134,Loss: -2.653,Avg.Loss: -2.794,LR: 7.39E-05]Training epoch 75:  88%|████████▊ | 134/153 [00:02<00:00, 52.80it/s, Epoch: 75, Batch: 135,Loss: -2.306,Avg.Loss: -2.790,LR: 7.39E-05]Training epoch 75:  88%|████████▊ | 135/153 [00:02<00:00, 52.80it/s, Epoch: 75, Batch: 136,Loss: -2.878,Avg.Loss: -2.791,LR: 7.38E-05]Training epoch 75:  89%|████████▉ | 136/153 [00:02<00:00, 52.80it/s, Epoch: 75, Batch: 137,Loss: -3.176,Avg.Loss: -2.793,LR: 7.38E-05]Training epoch 75:  90%|████████▉ | 137/153 [00:02<00:00, 52.80it/s, Epoch: 75, Batch: 138,Loss: -3.079,Avg.Loss: -2.796,LR: 7.38E-05]Training epoch 75:  90%|█████████ | 138/153 [00:02<00:00, 52.87it/s, Epoch: 75, Batch: 138,Loss: -3.079,Avg.Loss: -2.796,LR: 7.38E-05]Training epoch 75:  90%|█████████ | 138/153 [00:02<00:00, 52.87it/s, Epoch: 75, Batch: 139,Loss: -2.815,Avg.Loss: -2.796,LR: 7.37E-05]Training epoch 75:  91%|█████████ | 139/153 [00:02<00:00, 52.87it/s, Epoch: 75, Batch: 140,Loss: -3.049,Avg.Loss: -2.798,LR: 7.37E-05]Training epoch 75:  92%|█████████▏| 140/153 [00:02<00:00, 52.87it/s, Epoch: 75, Batch: 141,Loss: -2.905,Avg.Loss: -2.798,LR: 7.37E-05]Training epoch 75:  92%|█████████▏| 141/153 [00:02<00:00, 52.87it/s, Epoch: 75, Batch: 142,Loss: -3.047,Avg.Loss: -2.800,LR: 7.36E-05]Training epoch 75:  93%|█████████▎| 142/153 [00:02<00:00, 52.87it/s, Epoch: 75, Batch: 143,Loss: -2.839,Avg.Loss: -2.800,LR: 7.36E-05]Training epoch 75:  93%|█████████▎| 143/153 [00:02<00:00, 52.87it/s, Epoch: 75, Batch: 144,Loss: -2.515,Avg.Loss: -2.798,LR: 7.36E-05]Training epoch 75:  94%|█████████▍| 144/153 [00:02<00:00, 53.04it/s, Epoch: 75, Batch: 144,Loss: -2.515,Avg.Loss: -2.798,LR: 7.36E-05]Training epoch 75:  94%|█████████▍| 144/153 [00:02<00:00, 53.04it/s, Epoch: 75, Batch: 145,Loss: -2.827,Avg.Loss: -2.799,LR: 7.35E-05]Training epoch 75:  95%|█████████▍| 145/153 [00:02<00:00, 53.04it/s, Epoch: 75, Batch: 146,Loss: -2.977,Avg.Loss: -2.800,LR: 7.35E-05]Training epoch 75:  95%|█████████▌| 146/153 [00:02<00:00, 53.04it/s, Epoch: 75, Batch: 147,Loss: -3.064,Avg.Loss: -2.802,LR: 7.34E-05]Training epoch 75:  96%|█████████▌| 147/153 [00:02<00:00, 53.04it/s, Epoch: 75, Batch: 148,Loss: -3.050,Avg.Loss: -2.803,LR: 7.34E-05]Training epoch 75:  97%|█████████▋| 148/153 [00:02<00:00, 53.04it/s, Epoch: 75, Batch: 149,Loss: -3.056,Avg.Loss: -2.805,LR: 7.34E-05]Training epoch 75:  97%|█████████▋| 149/153 [00:02<00:00, 53.04it/s, Epoch: 75, Batch: 150,Loss: -2.898,Avg.Loss: -2.806,LR: 7.33E-05]Training epoch 75:  98%|█████████▊| 150/153 [00:02<00:00, 53.07it/s, Epoch: 75, Batch: 150,Loss: -2.898,Avg.Loss: -2.806,LR: 7.33E-05]Training epoch 75:  98%|█████████▊| 150/153 [00:02<00:00, 53.07it/s, Epoch: 75, Batch: 151,Loss: -2.646,Avg.Loss: -2.804,LR: 7.33E-05]Training epoch 75:  99%|█████████▊| 151/153 [00:02<00:00, 53.07it/s, Epoch: 75, Batch: 152,Loss: -2.997,Avg.Loss: -2.806,LR: 7.33E-05]Training epoch 75:  99%|█████████▉| 152/153 [00:02<00:00, 53.07it/s, Epoch: 75, Batch: 153,Loss: -2.711,Avg.Loss: -2.805,LR: 7.32E-05]Training epoch 75: 100%|██████████| 153/153 [00:02<00:00, 52.84it/s, Epoch: 75, Batch: 153,Loss: -2.711,Avg.Loss: -2.805,LR: 7.32E-05]
Training epoch 76:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 76:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 76, Batch: 1,Loss: -2.849,Avg.Loss: -2.849,LR: 7.32E-05]Training epoch 76:   1%|          | 1/153 [00:00<00:05, 28.04it/s, Epoch: 76, Batch: 2,Loss: -2.408,Avg.Loss: -2.628,LR: 7.32E-05]Training epoch 76:   1%|▏         | 2/153 [00:00<00:03, 39.37it/s, Epoch: 76, Batch: 3,Loss: -2.852,Avg.Loss: -2.703,LR: 7.31E-05]Training epoch 76:   2%|▏         | 3/153 [00:00<00:03, 43.66it/s, Epoch: 76, Batch: 4,Loss: -3.262,Avg.Loss: -2.843,LR: 7.31E-05]Training epoch 76:   3%|▎         | 4/153 [00:00<00:03, 45.83it/s, Epoch: 76, Batch: 5,Loss: -2.495,Avg.Loss: -2.773,LR: 7.30E-05]Training epoch 76:   3%|▎         | 5/153 [00:00<00:03, 47.24it/s, Epoch: 76, Batch: 6,Loss: -3.327,Avg.Loss: -2.865,LR: 7.30E-05]Training epoch 76:   4%|▍         | 6/153 [00:00<00:02, 56.59it/s, Epoch: 76, Batch: 6,Loss: -3.327,Avg.Loss: -2.865,LR: 7.30E-05]Training epoch 76:   4%|▍         | 6/153 [00:00<00:02, 56.59it/s, Epoch: 76, Batch: 7,Loss: -2.698,Avg.Loss: -2.841,LR: 7.30E-05]Training epoch 76:   5%|▍         | 7/153 [00:00<00:02, 56.59it/s, Epoch: 76, Batch: 8,Loss: -3.197,Avg.Loss: -2.886,LR: 7.29E-05]Training epoch 76:   5%|▌         | 8/153 [00:00<00:02, 56.59it/s, Epoch: 76, Batch: 9,Loss: -2.987,Avg.Loss: -2.897,LR: 7.29E-05]Training epoch 76:   6%|▌         | 9/153 [00:00<00:02, 56.59it/s, Epoch: 76, Batch: 10,Loss: -2.455,Avg.Loss: -2.853,LR: 7.29E-05]Training epoch 76:   7%|▋         | 10/153 [00:00<00:02, 56.59it/s, Epoch: 76, Batch: 11,Loss: -2.760,Avg.Loss: -2.844,LR: 7.28E-05]Training epoch 76:   7%|▋         | 11/153 [00:00<00:02, 56.59it/s, Epoch: 76, Batch: 12,Loss: -3.241,Avg.Loss: -2.877,LR: 7.28E-05]Training epoch 76:   8%|▊         | 12/153 [00:00<00:02, 54.25it/s, Epoch: 76, Batch: 12,Loss: -3.241,Avg.Loss: -2.877,LR: 7.28E-05]Training epoch 76:   8%|▊         | 12/153 [00:00<00:02, 54.25it/s, Epoch: 76, Batch: 13,Loss: -3.152,Avg.Loss: -2.899,LR: 7.28E-05]Training epoch 76:   8%|▊         | 13/153 [00:00<00:02, 54.25it/s, Epoch: 76, Batch: 14,Loss: -3.230,Avg.Loss: -2.922,LR: 7.27E-05]Training epoch 76:   9%|▉         | 14/153 [00:00<00:02, 54.25it/s, Epoch: 76, Batch: 15,Loss: -3.117,Avg.Loss: -2.935,LR: 7.27E-05]Training epoch 76:  10%|▉         | 15/153 [00:00<00:02, 54.25it/s, Epoch: 76, Batch: 16,Loss: -2.341,Avg.Loss: -2.898,LR: 7.26E-05]Training epoch 76:  10%|█         | 16/153 [00:00<00:02, 54.25it/s, Epoch: 76, Batch: 17,Loss: -2.463,Avg.Loss: -2.873,LR: 7.26E-05]Training epoch 76:  11%|█         | 17/153 [00:00<00:02, 54.25it/s, Epoch: 76, Batch: 18,Loss: -3.069,Avg.Loss: -2.883,LR: 7.26E-05]Training epoch 76:  12%|█▏        | 18/153 [00:00<00:02, 53.79it/s, Epoch: 76, Batch: 18,Loss: -3.069,Avg.Loss: -2.883,LR: 7.26E-05]Training epoch 76:  12%|█▏        | 18/153 [00:00<00:02, 53.79it/s, Epoch: 76, Batch: 19,Loss: -3.477,Avg.Loss: -2.915,LR: 7.25E-05]Training epoch 76:  12%|█▏        | 19/153 [00:00<00:02, 53.79it/s, Epoch: 76, Batch: 20,Loss: -2.950,Avg.Loss: -2.916,LR: 7.25E-05]Training epoch 76:  13%|█▎        | 20/153 [00:00<00:02, 53.79it/s, Epoch: 76, Batch: 21,Loss: -2.109,Avg.Loss: -2.878,LR: 7.25E-05]Training epoch 76:  14%|█▎        | 21/153 [00:00<00:02, 53.79it/s, Epoch: 76, Batch: 22,Loss: -2.644,Avg.Loss: -2.867,LR: 7.24E-05]Training epoch 76:  14%|█▍        | 22/153 [00:00<00:02, 53.79it/s, Epoch: 76, Batch: 23,Loss: -3.012,Avg.Loss: -2.874,LR: 7.24E-05]Training epoch 76:  15%|█▌        | 23/153 [00:00<00:02, 53.79it/s, Epoch: 76, Batch: 24,Loss: -2.986,Avg.Loss: -2.878,LR: 7.24E-05]Training epoch 76:  16%|█▌        | 24/153 [00:00<00:02, 52.94it/s, Epoch: 76, Batch: 24,Loss: -2.986,Avg.Loss: -2.878,LR: 7.24E-05]Training epoch 76:  16%|█▌        | 24/153 [00:00<00:02, 52.94it/s, Epoch: 76, Batch: 25,Loss: -2.482,Avg.Loss: -2.862,LR: 7.23E-05]Training epoch 76:  16%|█▋        | 25/153 [00:00<00:02, 52.94it/s, Epoch: 76, Batch: 26,Loss: -2.480,Avg.Loss: -2.848,LR: 7.23E-05]Training epoch 76:  17%|█▋        | 26/153 [00:00<00:02, 52.94it/s, Epoch: 76, Batch: 27,Loss: -2.709,Avg.Loss: -2.843,LR: 7.22E-05]Training epoch 76:  18%|█▊        | 27/153 [00:00<00:02, 52.94it/s, Epoch: 76, Batch: 28,Loss: -2.158,Avg.Loss: -2.818,LR: 7.22E-05]Training epoch 76:  18%|█▊        | 28/153 [00:00<00:02, 52.94it/s, Epoch: 76, Batch: 29,Loss: -2.993,Avg.Loss: -2.824,LR: 7.22E-05]Training epoch 76:  19%|█▉        | 29/153 [00:00<00:02, 52.94it/s, Epoch: 76, Batch: 30,Loss: -2.495,Avg.Loss: -2.813,LR: 7.21E-05]Training epoch 76:  20%|█▉        | 30/153 [00:00<00:02, 51.77it/s, Epoch: 76, Batch: 30,Loss: -2.495,Avg.Loss: -2.813,LR: 7.21E-05]Training epoch 76:  20%|█▉        | 30/153 [00:00<00:02, 51.77it/s, Epoch: 76, Batch: 31,Loss: -2.737,Avg.Loss: -2.811,LR: 7.21E-05]Training epoch 76:  20%|██        | 31/153 [00:00<00:02, 51.77it/s, Epoch: 76, Batch: 32,Loss: -1.843,Avg.Loss: -2.780,LR: 7.21E-05]Training epoch 76:  21%|██        | 32/153 [00:00<00:02, 51.77it/s, Epoch: 76, Batch: 33,Loss: -2.281,Avg.Loss: -2.765,LR: 7.20E-05]Training epoch 76:  22%|██▏       | 33/153 [00:00<00:02, 51.77it/s, Epoch: 76, Batch: 34,Loss: -2.691,Avg.Loss: -2.763,LR: 7.20E-05]Training epoch 76:  22%|██▏       | 34/153 [00:00<00:02, 51.77it/s, Epoch: 76, Batch: 35,Loss: -2.993,Avg.Loss: -2.770,LR: 7.20E-05]Training epoch 76:  23%|██▎       | 35/153 [00:00<00:02, 51.77it/s, Epoch: 76, Batch: 36,Loss: -2.625,Avg.Loss: -2.766,LR: 7.19E-05]Training epoch 76:  24%|██▎       | 36/153 [00:00<00:02, 52.51it/s, Epoch: 76, Batch: 36,Loss: -2.625,Avg.Loss: -2.766,LR: 7.19E-05]Training epoch 76:  24%|██▎       | 36/153 [00:00<00:02, 52.51it/s, Epoch: 76, Batch: 37,Loss: -3.113,Avg.Loss: -2.775,LR: 7.19E-05]Training epoch 76:  24%|██▍       | 37/153 [00:00<00:02, 52.51it/s, Epoch: 76, Batch: 38,Loss: -2.830,Avg.Loss: -2.777,LR: 7.18E-05]Training epoch 76:  25%|██▍       | 38/153 [00:00<00:02, 52.51it/s, Epoch: 76, Batch: 39,Loss: -3.178,Avg.Loss: -2.787,LR: 7.18E-05]Training epoch 76:  25%|██▌       | 39/153 [00:00<00:02, 52.51it/s, Epoch: 76, Batch: 40,Loss: -2.994,Avg.Loss: -2.792,LR: 7.18E-05]Training epoch 76:  26%|██▌       | 40/153 [00:00<00:02, 52.51it/s, Epoch: 76, Batch: 41,Loss: -3.083,Avg.Loss: -2.799,LR: 7.17E-05]Training epoch 76:  27%|██▋       | 41/153 [00:00<00:02, 52.51it/s, Epoch: 76, Batch: 42,Loss: -3.029,Avg.Loss: -2.805,LR: 7.17E-05]Training epoch 76:  27%|██▋       | 42/153 [00:00<00:02, 52.65it/s, Epoch: 76, Batch: 42,Loss: -3.029,Avg.Loss: -2.805,LR: 7.17E-05]Training epoch 76:  27%|██▋       | 42/153 [00:00<00:02, 52.65it/s, Epoch: 76, Batch: 43,Loss: -3.194,Avg.Loss: -2.814,LR: 7.17E-05]Training epoch 76:  28%|██▊       | 43/153 [00:00<00:02, 52.65it/s, Epoch: 76, Batch: 44,Loss: -3.233,Avg.Loss: -2.823,LR: 7.16E-05]Training epoch 76:  29%|██▉       | 44/153 [00:00<00:02, 52.65it/s, Epoch: 76, Batch: 45,Loss: -2.618,Avg.Loss: -2.819,LR: 7.16E-05]Training epoch 76:  29%|██▉       | 45/153 [00:00<00:02, 52.65it/s, Epoch: 76, Batch: 46,Loss: -2.762,Avg.Loss: -2.817,LR: 7.16E-05]Training epoch 76:  30%|███       | 46/153 [00:00<00:02, 52.65it/s, Epoch: 76, Batch: 47,Loss: -3.127,Avg.Loss: -2.824,LR: 7.15E-05]Training epoch 76:  31%|███       | 47/153 [00:00<00:02, 52.65it/s, Epoch: 76, Batch: 48,Loss: -2.542,Avg.Loss: -2.818,LR: 7.15E-05]Training epoch 76:  31%|███▏      | 48/153 [00:00<00:01, 52.80it/s, Epoch: 76, Batch: 48,Loss: -2.542,Avg.Loss: -2.818,LR: 7.15E-05]Training epoch 76:  31%|███▏      | 48/153 [00:00<00:01, 52.80it/s, Epoch: 76, Batch: 49,Loss: -2.820,Avg.Loss: -2.818,LR: 7.15E-05]Training epoch 76:  32%|███▏      | 49/153 [00:00<00:01, 52.80it/s, Epoch: 76, Batch: 50,Loss: -2.244,Avg.Loss: -2.807,LR: 7.14E-05]Training epoch 76:  33%|███▎      | 50/153 [00:00<00:01, 52.80it/s, Epoch: 76, Batch: 51,Loss: -2.791,Avg.Loss: -2.806,LR: 7.14E-05]Training epoch 76:  33%|███▎      | 51/153 [00:00<00:01, 52.80it/s, Epoch: 76, Batch: 52,Loss: -2.859,Avg.Loss: -2.807,LR: 7.13E-05]Training epoch 76:  34%|███▍      | 52/153 [00:00<00:01, 52.80it/s, Epoch: 76, Batch: 53,Loss: -3.110,Avg.Loss: -2.813,LR: 7.13E-05]Training epoch 76:  35%|███▍      | 53/153 [00:01<00:01, 52.80it/s, Epoch: 76, Batch: 54,Loss: -2.989,Avg.Loss: -2.816,LR: 7.13E-05]Training epoch 76:  35%|███▌      | 54/153 [00:01<00:01, 52.96it/s, Epoch: 76, Batch: 54,Loss: -2.989,Avg.Loss: -2.816,LR: 7.13E-05]Training epoch 76:  35%|███▌      | 54/153 [00:01<00:01, 52.96it/s, Epoch: 76, Batch: 55,Loss: -2.877,Avg.Loss: -2.817,LR: 7.12E-05]Training epoch 76:  36%|███▌      | 55/153 [00:01<00:01, 52.96it/s, Epoch: 76, Batch: 56,Loss: -2.703,Avg.Loss: -2.815,LR: 7.12E-05]Training epoch 76:  37%|███▋      | 56/153 [00:01<00:01, 52.96it/s, Epoch: 76, Batch: 57,Loss: -2.690,Avg.Loss: -2.813,LR: 7.12E-05]Training epoch 76:  37%|███▋      | 57/153 [00:01<00:01, 52.96it/s, Epoch: 76, Batch: 58,Loss: -2.591,Avg.Loss: -2.809,LR: 7.11E-05]Training epoch 76:  38%|███▊      | 58/153 [00:01<00:01, 52.96it/s, Epoch: 76, Batch: 59,Loss: -3.052,Avg.Loss: -2.813,LR: 7.11E-05]Training epoch 76:  39%|███▊      | 59/153 [00:01<00:01, 52.96it/s, Epoch: 76, Batch: 60,Loss: -2.446,Avg.Loss: -2.807,LR: 7.11E-05]Training epoch 76:  39%|███▉      | 60/153 [00:01<00:01, 53.04it/s, Epoch: 76, Batch: 60,Loss: -2.446,Avg.Loss: -2.807,LR: 7.11E-05]Training epoch 76:  39%|███▉      | 60/153 [00:01<00:01, 53.04it/s, Epoch: 76, Batch: 61,Loss: -2.557,Avg.Loss: -2.803,LR: 7.10E-05]Training epoch 76:  40%|███▉      | 61/153 [00:01<00:01, 53.04it/s, Epoch: 76, Batch: 62,Loss: -3.071,Avg.Loss: -2.808,LR: 7.10E-05]Training epoch 76:  41%|████      | 62/153 [00:01<00:01, 53.04it/s, Epoch: 76, Batch: 63,Loss: -3.003,Avg.Loss: -2.811,LR: 7.10E-05]Training epoch 76:  41%|████      | 63/153 [00:01<00:01, 53.04it/s, Epoch: 76, Batch: 64,Loss: -2.900,Avg.Loss: -2.812,LR: 7.09E-05]Training epoch 76:  42%|████▏     | 64/153 [00:01<00:01, 53.04it/s, Epoch: 76, Batch: 65,Loss: -2.889,Avg.Loss: -2.813,LR: 7.09E-05]Training epoch 76:  42%|████▏     | 65/153 [00:01<00:01, 53.04it/s, Epoch: 76, Batch: 66,Loss: -2.048,Avg.Loss: -2.802,LR: 7.08E-05]Training epoch 76:  43%|████▎     | 66/153 [00:01<00:01, 52.89it/s, Epoch: 76, Batch: 66,Loss: -2.048,Avg.Loss: -2.802,LR: 7.08E-05]Training epoch 76:  43%|████▎     | 66/153 [00:01<00:01, 52.89it/s, Epoch: 76, Batch: 67,Loss: -3.095,Avg.Loss: -2.806,LR: 7.08E-05]Training epoch 76:  44%|████▍     | 67/153 [00:01<00:01, 52.89it/s, Epoch: 76, Batch: 68,Loss: -3.141,Avg.Loss: -2.811,LR: 7.08E-05]Training epoch 76:  44%|████▍     | 68/153 [00:01<00:01, 52.89it/s, Epoch: 76, Batch: 69,Loss: -2.955,Avg.Loss: -2.813,LR: 7.07E-05]Training epoch 76:  45%|████▌     | 69/153 [00:01<00:01, 52.89it/s, Epoch: 76, Batch: 70,Loss: -3.272,Avg.Loss: -2.820,LR: 7.07E-05]Training epoch 76:  46%|████▌     | 70/153 [00:01<00:01, 52.89it/s, Epoch: 76, Batch: 71,Loss: -3.230,Avg.Loss: -2.825,LR: 7.07E-05]Training epoch 76:  46%|████▋     | 71/153 [00:01<00:01, 52.89it/s, Epoch: 76, Batch: 72,Loss: -2.181,Avg.Loss: -2.816,LR: 7.06E-05]Training epoch 76:  47%|████▋     | 72/153 [00:01<00:01, 52.77it/s, Epoch: 76, Batch: 72,Loss: -2.181,Avg.Loss: -2.816,LR: 7.06E-05]Training epoch 76:  47%|████▋     | 72/153 [00:01<00:01, 52.77it/s, Epoch: 76, Batch: 73,Loss: -2.815,Avg.Loss: -2.816,LR: 7.06E-05]Training epoch 76:  48%|████▊     | 73/153 [00:01<00:01, 52.77it/s, Epoch: 76, Batch: 74,Loss: -2.814,Avg.Loss: -2.816,LR: 7.06E-05]Training epoch 76:  48%|████▊     | 74/153 [00:01<00:01, 52.77it/s, Epoch: 76, Batch: 75,Loss: -2.910,Avg.Loss: -2.818,LR: 7.05E-05]Training epoch 76:  49%|████▉     | 75/153 [00:01<00:01, 52.77it/s, Epoch: 76, Batch: 76,Loss: -2.986,Avg.Loss: -2.820,LR: 7.05E-05]Training epoch 76:  50%|████▉     | 76/153 [00:01<00:01, 52.77it/s, Epoch: 76, Batch: 77,Loss: -2.804,Avg.Loss: -2.820,LR: 7.05E-05]Training epoch 76:  50%|█████     | 77/153 [00:01<00:01, 52.77it/s, Epoch: 76, Batch: 78,Loss: -2.839,Avg.Loss: -2.820,LR: 7.04E-05]Training epoch 76:  51%|█████     | 78/153 [00:01<00:01, 52.83it/s, Epoch: 76, Batch: 78,Loss: -2.839,Avg.Loss: -2.820,LR: 7.04E-05]Training epoch 76:  51%|█████     | 78/153 [00:01<00:01, 52.83it/s, Epoch: 76, Batch: 79,Loss: -3.219,Avg.Loss: -2.825,LR: 7.04E-05]Training epoch 76:  52%|█████▏    | 79/153 [00:01<00:01, 52.83it/s, Epoch: 76, Batch: 80,Loss: -3.052,Avg.Loss: -2.828,LR: 7.03E-05]Training epoch 76:  52%|█████▏    | 80/153 [00:01<00:01, 52.83it/s, Epoch: 76, Batch: 81,Loss: -2.818,Avg.Loss: -2.828,LR: 7.03E-05]Training epoch 76:  53%|█████▎    | 81/153 [00:01<00:01, 52.83it/s, Epoch: 76, Batch: 82,Loss: -2.805,Avg.Loss: -2.827,LR: 7.03E-05]Training epoch 76:  54%|█████▎    | 82/153 [00:01<00:01, 52.83it/s, Epoch: 76, Batch: 83,Loss: -2.709,Avg.Loss: -2.826,LR: 7.02E-05]Training epoch 76:  54%|█████▍    | 83/153 [00:01<00:01, 52.83it/s, Epoch: 76, Batch: 84,Loss: -2.956,Avg.Loss: -2.828,LR: 7.02E-05]Training epoch 76:  55%|█████▍    | 84/153 [00:01<00:01, 52.76it/s, Epoch: 76, Batch: 84,Loss: -2.956,Avg.Loss: -2.828,LR: 7.02E-05]Training epoch 76:  55%|█████▍    | 84/153 [00:01<00:01, 52.76it/s, Epoch: 76, Batch: 85,Loss: -3.015,Avg.Loss: -2.830,LR: 7.02E-05]Training epoch 76:  56%|█████▌    | 85/153 [00:01<00:01, 52.76it/s, Epoch: 76, Batch: 86,Loss: -2.997,Avg.Loss: -2.832,LR: 7.01E-05]Training epoch 76:  56%|█████▌    | 86/153 [00:01<00:01, 52.76it/s, Epoch: 76, Batch: 87,Loss: -3.427,Avg.Loss: -2.839,LR: 7.01E-05]Training epoch 76:  57%|█████▋    | 87/153 [00:01<00:01, 52.76it/s, Epoch: 76, Batch: 88,Loss: -2.833,Avg.Loss: -2.838,LR: 7.01E-05]Training epoch 76:  58%|█████▊    | 88/153 [00:01<00:01, 52.76it/s, Epoch: 76, Batch: 89,Loss: -3.125,Avg.Loss: -2.842,LR: 7.00E-05]Training epoch 76:  58%|█████▊    | 89/153 [00:01<00:01, 52.76it/s, Epoch: 76, Batch: 90,Loss: -2.958,Avg.Loss: -2.843,LR: 7.00E-05]Training epoch 76:  59%|█████▉    | 90/153 [00:01<00:01, 52.81it/s, Epoch: 76, Batch: 90,Loss: -2.958,Avg.Loss: -2.843,LR: 7.00E-05]Training epoch 76:  59%|█████▉    | 90/153 [00:01<00:01, 52.81it/s, Epoch: 76, Batch: 91,Loss: -2.846,Avg.Loss: -2.843,LR: 7.00E-05]Training epoch 76:  59%|█████▉    | 91/153 [00:01<00:01, 52.81it/s, Epoch: 76, Batch: 92,Loss: -3.179,Avg.Loss: -2.847,LR: 6.99E-05]Training epoch 76:  60%|██████    | 92/153 [00:01<00:01, 52.81it/s, Epoch: 76, Batch: 93,Loss: -2.499,Avg.Loss: -2.843,LR: 6.99E-05]Training epoch 76:  61%|██████    | 93/153 [00:01<00:01, 52.81it/s, Epoch: 76, Batch: 94,Loss: -2.456,Avg.Loss: -2.839,LR: 6.98E-05]Training epoch 76:  61%|██████▏   | 94/153 [00:01<00:01, 52.81it/s, Epoch: 76, Batch: 95,Loss: -2.007,Avg.Loss: -2.830,LR: 6.98E-05]Training epoch 76:  62%|██████▏   | 95/153 [00:01<00:01, 52.81it/s, Epoch: 76, Batch: 96,Loss: -3.007,Avg.Loss: -2.832,LR: 6.98E-05]Training epoch 76:  63%|██████▎   | 96/153 [00:01<00:01, 53.00it/s, Epoch: 76, Batch: 96,Loss: -3.007,Avg.Loss: -2.832,LR: 6.98E-05]Training epoch 76:  63%|██████▎   | 96/153 [00:01<00:01, 53.00it/s, Epoch: 76, Batch: 97,Loss: -2.820,Avg.Loss: -2.832,LR: 6.97E-05]Training epoch 76:  63%|██████▎   | 97/153 [00:01<00:01, 53.00it/s, Epoch: 76, Batch: 98,Loss: -3.069,Avg.Loss: -2.834,LR: 6.97E-05]Training epoch 76:  64%|██████▍   | 98/153 [00:01<00:01, 53.00it/s, Epoch: 76, Batch: 99,Loss: -2.713,Avg.Loss: -2.833,LR: 6.97E-05]Training epoch 76:  65%|██████▍   | 99/153 [00:01<00:01, 53.00it/s, Epoch: 76, Batch: 100,Loss: -3.257,Avg.Loss: -2.837,LR: 6.96E-05]Training epoch 76:  65%|██████▌   | 100/153 [00:01<00:01, 53.00it/s, Epoch: 76, Batch: 101,Loss: -3.249,Avg.Loss: -2.841,LR: 6.96E-05]Training epoch 76:  66%|██████▌   | 101/153 [00:01<00:00, 53.00it/s, Epoch: 76, Batch: 102,Loss: -3.066,Avg.Loss: -2.843,LR: 6.96E-05]Training epoch 76:  67%|██████▋   | 102/153 [00:01<00:00, 53.31it/s, Epoch: 76, Batch: 102,Loss: -3.066,Avg.Loss: -2.843,LR: 6.96E-05]Training epoch 76:  67%|██████▋   | 102/153 [00:01<00:00, 53.31it/s, Epoch: 76, Batch: 103,Loss: -2.919,Avg.Loss: -2.844,LR: 6.95E-05]Training epoch 76:  67%|██████▋   | 103/153 [00:01<00:00, 53.31it/s, Epoch: 76, Batch: 104,Loss: -3.356,Avg.Loss: -2.849,LR: 6.95E-05]Training epoch 76:  68%|██████▊   | 104/153 [00:01<00:00, 53.31it/s, Epoch: 76, Batch: 105,Loss: -2.885,Avg.Loss: -2.849,LR: 6.95E-05]Training epoch 76:  69%|██████▊   | 105/153 [00:01<00:00, 53.31it/s, Epoch: 76, Batch: 106,Loss: -2.980,Avg.Loss: -2.851,LR: 6.94E-05]Training epoch 76:  69%|██████▉   | 106/153 [00:02<00:00, 53.31it/s, Epoch: 76, Batch: 107,Loss: -2.224,Avg.Loss: -2.845,LR: 6.94E-05]Training epoch 76:  70%|██████▉   | 107/153 [00:02<00:00, 53.31it/s, Epoch: 76, Batch: 108,Loss: -2.733,Avg.Loss: -2.844,LR: 6.93E-05]Training epoch 76:  71%|███████   | 108/153 [00:02<00:00, 53.08it/s, Epoch: 76, Batch: 108,Loss: -2.733,Avg.Loss: -2.844,LR: 6.93E-05]Training epoch 76:  71%|███████   | 108/153 [00:02<00:00, 53.08it/s, Epoch: 76, Batch: 109,Loss: -3.265,Avg.Loss: -2.848,LR: 6.93E-05]Training epoch 76:  71%|███████   | 109/153 [00:02<00:00, 53.08it/s, Epoch: 76, Batch: 110,Loss: -3.310,Avg.Loss: -2.852,LR: 6.93E-05]Training epoch 76:  72%|███████▏  | 110/153 [00:02<00:00, 53.08it/s, Epoch: 76, Batch: 111,Loss: -2.987,Avg.Loss: -2.853,LR: 6.92E-05]Training epoch 76:  73%|███████▎  | 111/153 [00:02<00:00, 53.08it/s, Epoch: 76, Batch: 112,Loss: -2.745,Avg.Loss: -2.852,LR: 6.92E-05]Training epoch 76:  73%|███████▎  | 112/153 [00:02<00:00, 53.08it/s, Epoch: 76, Batch: 113,Loss: -2.865,Avg.Loss: -2.852,LR: 6.92E-05]Training epoch 76:  74%|███████▍  | 113/153 [00:02<00:00, 53.08it/s, Epoch: 76, Batch: 114,Loss: -2.902,Avg.Loss: -2.853,LR: 6.91E-05]Training epoch 76:  75%|███████▍  | 114/153 [00:02<00:00, 53.71it/s, Epoch: 76, Batch: 114,Loss: -2.902,Avg.Loss: -2.853,LR: 6.91E-05]Training epoch 76:  75%|███████▍  | 114/153 [00:02<00:00, 53.71it/s, Epoch: 76, Batch: 115,Loss: -2.949,Avg.Loss: -2.854,LR: 6.91E-05]Training epoch 76:  75%|███████▌  | 115/153 [00:02<00:00, 53.71it/s, Epoch: 76, Batch: 116,Loss: -3.044,Avg.Loss: -2.855,LR: 6.91E-05]Training epoch 76:  76%|███████▌  | 116/153 [00:02<00:00, 53.71it/s, Epoch: 76, Batch: 117,Loss: -2.431,Avg.Loss: -2.852,LR: 6.90E-05]Training epoch 76:  76%|███████▋  | 117/153 [00:02<00:00, 53.71it/s, Epoch: 76, Batch: 118,Loss: -2.121,Avg.Loss: -2.845,LR: 6.90E-05]Training epoch 76:  77%|███████▋  | 118/153 [00:02<00:00, 53.71it/s, Epoch: 76, Batch: 119,Loss: -2.360,Avg.Loss: -2.841,LR: 6.90E-05]Training epoch 76:  78%|███████▊  | 119/153 [00:02<00:00, 53.71it/s, Epoch: 76, Batch: 120,Loss: -2.657,Avg.Loss: -2.840,LR: 6.89E-05]Training epoch 76:  78%|███████▊  | 120/153 [00:02<00:00, 53.27it/s, Epoch: 76, Batch: 120,Loss: -2.657,Avg.Loss: -2.840,LR: 6.89E-05]Training epoch 76:  78%|███████▊  | 120/153 [00:02<00:00, 53.27it/s, Epoch: 76, Batch: 121,Loss: -2.578,Avg.Loss: -2.838,LR: 6.89E-05]Training epoch 76:  79%|███████▉  | 121/153 [00:02<00:00, 53.27it/s, Epoch: 76, Batch: 122,Loss: -2.423,Avg.Loss: -2.834,LR: 6.89E-05]Training epoch 76:  80%|███████▉  | 122/153 [00:02<00:00, 53.27it/s, Epoch: 76, Batch: 123,Loss: -2.762,Avg.Loss: -2.834,LR: 6.88E-05]Training epoch 76:  80%|████████  | 123/153 [00:02<00:00, 53.27it/s, Epoch: 76, Batch: 124,Loss: -2.535,Avg.Loss: -2.831,LR: 6.88E-05]Training epoch 76:  81%|████████  | 124/153 [00:02<00:00, 53.27it/s, Epoch: 76, Batch: 125,Loss: -3.091,Avg.Loss: -2.833,LR: 6.87E-05]Training epoch 76:  82%|████████▏ | 125/153 [00:02<00:00, 53.27it/s, Epoch: 76, Batch: 126,Loss: -3.136,Avg.Loss: -2.836,LR: 6.87E-05]Training epoch 76:  82%|████████▏ | 126/153 [00:02<00:00, 53.14it/s, Epoch: 76, Batch: 126,Loss: -3.136,Avg.Loss: -2.836,LR: 6.87E-05]Training epoch 76:  82%|████████▏ | 126/153 [00:02<00:00, 53.14it/s, Epoch: 76, Batch: 127,Loss: -2.583,Avg.Loss: -2.834,LR: 6.87E-05]Training epoch 76:  83%|████████▎ | 127/153 [00:02<00:00, 53.14it/s, Epoch: 76, Batch: 128,Loss: -2.730,Avg.Loss: -2.833,LR: 6.86E-05]Training epoch 76:  84%|████████▎ | 128/153 [00:02<00:00, 53.14it/s, Epoch: 76, Batch: 129,Loss: -2.935,Avg.Loss: -2.834,LR: 6.86E-05]Training epoch 76:  84%|████████▍ | 129/153 [00:02<00:00, 53.14it/s, Epoch: 76, Batch: 130,Loss: -3.021,Avg.Loss: -2.835,LR: 6.86E-05]Training epoch 76:  85%|████████▍ | 130/153 [00:02<00:00, 53.14it/s, Epoch: 76, Batch: 131,Loss: -3.178,Avg.Loss: -2.838,LR: 6.85E-05]Training epoch 76:  86%|████████▌ | 131/153 [00:02<00:00, 53.14it/s, Epoch: 76, Batch: 132,Loss: -3.167,Avg.Loss: -2.840,LR: 6.85E-05]Training epoch 76:  86%|████████▋ | 132/153 [00:02<00:00, 53.10it/s, Epoch: 76, Batch: 132,Loss: -3.167,Avg.Loss: -2.840,LR: 6.85E-05]Training epoch 76:  86%|████████▋ | 132/153 [00:02<00:00, 53.10it/s, Epoch: 76, Batch: 133,Loss: -2.932,Avg.Loss: -2.841,LR: 6.85E-05]Training epoch 76:  87%|████████▋ | 133/153 [00:02<00:00, 53.10it/s, Epoch: 76, Batch: 134,Loss: -2.973,Avg.Loss: -2.842,LR: 6.84E-05]Training epoch 76:  88%|████████▊ | 134/153 [00:02<00:00, 53.10it/s, Epoch: 76, Batch: 135,Loss: -3.084,Avg.Loss: -2.844,LR: 6.84E-05]Training epoch 76:  88%|████████▊ | 135/153 [00:02<00:00, 53.10it/s, Epoch: 76, Batch: 136,Loss: -2.756,Avg.Loss: -2.843,LR: 6.84E-05]Training epoch 76:  89%|████████▉ | 136/153 [00:02<00:00, 53.10it/s, Epoch: 76, Batch: 137,Loss: -3.264,Avg.Loss: -2.846,LR: 6.83E-05]Training epoch 76:  90%|████████▉ | 137/153 [00:02<00:00, 53.10it/s, Epoch: 76, Batch: 138,Loss: -3.515,Avg.Loss: -2.851,LR: 6.83E-05]Training epoch 76:  90%|█████████ | 138/153 [00:02<00:00, 52.97it/s, Epoch: 76, Batch: 138,Loss: -3.515,Avg.Loss: -2.851,LR: 6.83E-05]Training epoch 76:  90%|█████████ | 138/153 [00:02<00:00, 52.97it/s, Epoch: 76, Batch: 139,Loss: -2.542,Avg.Loss: -2.849,LR: 6.83E-05]Training epoch 76:  91%|█████████ | 139/153 [00:02<00:00, 52.97it/s, Epoch: 76, Batch: 140,Loss: -2.576,Avg.Loss: -2.847,LR: 6.82E-05]Training epoch 76:  92%|█████████▏| 140/153 [00:02<00:00, 52.97it/s, Epoch: 76, Batch: 141,Loss: -2.937,Avg.Loss: -2.847,LR: 6.82E-05]Training epoch 76:  92%|█████████▏| 141/153 [00:02<00:00, 52.97it/s, Epoch: 76, Batch: 142,Loss: -2.621,Avg.Loss: -2.846,LR: 6.81E-05]Training epoch 76:  93%|█████████▎| 142/153 [00:02<00:00, 52.97it/s, Epoch: 76, Batch: 143,Loss: -2.831,Avg.Loss: -2.846,LR: 6.81E-05]Training epoch 76:  93%|█████████▎| 143/153 [00:02<00:00, 52.97it/s, Epoch: 76, Batch: 144,Loss: -2.946,Avg.Loss: -2.846,LR: 6.81E-05]Training epoch 76:  94%|█████████▍| 144/153 [00:02<00:00, 52.98it/s, Epoch: 76, Batch: 144,Loss: -2.946,Avg.Loss: -2.846,LR: 6.81E-05]Training epoch 76:  94%|█████████▍| 144/153 [00:02<00:00, 52.98it/s, Epoch: 76, Batch: 145,Loss: -3.058,Avg.Loss: -2.848,LR: 6.80E-05]Training epoch 76:  95%|█████████▍| 145/153 [00:02<00:00, 52.98it/s, Epoch: 76, Batch: 146,Loss: -2.145,Avg.Loss: -2.843,LR: 6.80E-05]Training epoch 76:  95%|█████████▌| 146/153 [00:02<00:00, 52.98it/s, Epoch: 76, Batch: 147,Loss: -2.844,Avg.Loss: -2.843,LR: 6.80E-05]Training epoch 76:  96%|█████████▌| 147/153 [00:02<00:00, 52.98it/s, Epoch: 76, Batch: 148,Loss: -3.142,Avg.Loss: -2.845,LR: 6.79E-05]Training epoch 76:  97%|█████████▋| 148/153 [00:02<00:00, 52.98it/s, Epoch: 76, Batch: 149,Loss: -2.514,Avg.Loss: -2.843,LR: 6.79E-05]Training epoch 76:  97%|█████████▋| 149/153 [00:02<00:00, 52.98it/s, Epoch: 76, Batch: 150,Loss: -2.833,Avg.Loss: -2.843,LR: 6.79E-05]Training epoch 76:  98%|█████████▊| 150/153 [00:02<00:00, 52.81it/s, Epoch: 76, Batch: 150,Loss: -2.833,Avg.Loss: -2.843,LR: 6.79E-05]Training epoch 76:  98%|█████████▊| 150/153 [00:02<00:00, 52.81it/s, Epoch: 76, Batch: 151,Loss: -3.142,Avg.Loss: -2.845,LR: 6.78E-05]Training epoch 76:  99%|█████████▊| 151/153 [00:02<00:00, 52.81it/s, Epoch: 76, Batch: 152,Loss: -2.459,Avg.Loss: -2.842,LR: 6.78E-05]Training epoch 76:  99%|█████████▉| 152/153 [00:02<00:00, 52.81it/s, Epoch: 76, Batch: 153,Loss: -3.205,Avg.Loss: -2.845,LR: 6.78E-05]Training epoch 76: 100%|██████████| 153/153 [00:02<00:00, 52.92it/s, Epoch: 76, Batch: 153,Loss: -3.205,Avg.Loss: -2.845,LR: 6.78E-05]
Training epoch 77:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 77:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 77, Batch: 1,Loss: -2.369,Avg.Loss: -2.369,LR: 6.77E-05]Training epoch 77:   1%|          | 1/153 [00:00<00:05, 27.67it/s, Epoch: 77, Batch: 2,Loss: -3.153,Avg.Loss: -2.761,LR: 6.77E-05]Training epoch 77:   1%|▏         | 2/153 [00:00<00:03, 39.05it/s, Epoch: 77, Batch: 3,Loss: -2.710,Avg.Loss: -2.744,LR: 6.77E-05]Training epoch 77:   2%|▏         | 3/153 [00:00<00:03, 43.94it/s, Epoch: 77, Batch: 4,Loss: -2.759,Avg.Loss: -2.748,LR: 6.76E-05]Training epoch 77:   3%|▎         | 4/153 [00:00<00:03, 45.88it/s, Epoch: 77, Batch: 5,Loss: -2.862,Avg.Loss: -2.771,LR: 6.76E-05]Training epoch 77:   3%|▎         | 5/153 [00:00<00:03, 47.35it/s, Epoch: 77, Batch: 6,Loss: -2.706,Avg.Loss: -2.760,LR: 6.75E-05]Training epoch 77:   4%|▍         | 6/153 [00:00<00:02, 56.71it/s, Epoch: 77, Batch: 6,Loss: -2.706,Avg.Loss: -2.760,LR: 6.75E-05]Training epoch 77:   4%|▍         | 6/153 [00:00<00:02, 56.71it/s, Epoch: 77, Batch: 7,Loss: -2.564,Avg.Loss: -2.732,LR: 6.75E-05]Training epoch 77:   5%|▍         | 7/153 [00:00<00:02, 56.71it/s, Epoch: 77, Batch: 8,Loss: -2.900,Avg.Loss: -2.753,LR: 6.75E-05]Training epoch 77:   5%|▌         | 8/153 [00:00<00:02, 56.71it/s, Epoch: 77, Batch: 9,Loss: -2.848,Avg.Loss: -2.763,LR: 6.74E-05]Training epoch 77:   6%|▌         | 9/153 [00:00<00:02, 56.71it/s, Epoch: 77, Batch: 10,Loss: -2.315,Avg.Loss: -2.719,LR: 6.74E-05]Training epoch 77:   7%|▋         | 10/153 [00:00<00:02, 56.71it/s, Epoch: 77, Batch: 11,Loss: -2.511,Avg.Loss: -2.700,LR: 6.74E-05]Training epoch 77:   7%|▋         | 11/153 [00:00<00:02, 56.71it/s, Epoch: 77, Batch: 12,Loss: -3.111,Avg.Loss: -2.734,LR: 6.73E-05]Training epoch 77:   8%|▊         | 12/153 [00:00<00:02, 54.71it/s, Epoch: 77, Batch: 12,Loss: -3.111,Avg.Loss: -2.734,LR: 6.73E-05]Training epoch 77:   8%|▊         | 12/153 [00:00<00:02, 54.71it/s, Epoch: 77, Batch: 13,Loss: -2.862,Avg.Loss: -2.744,LR: 6.73E-05]Training epoch 77:   8%|▊         | 13/153 [00:00<00:02, 54.71it/s, Epoch: 77, Batch: 14,Loss: -3.341,Avg.Loss: -2.786,LR: 6.73E-05]Training epoch 77:   9%|▉         | 14/153 [00:00<00:02, 54.71it/s, Epoch: 77, Batch: 15,Loss: -2.756,Avg.Loss: -2.784,LR: 6.72E-05]Training epoch 77:  10%|▉         | 15/153 [00:00<00:02, 54.71it/s, Epoch: 77, Batch: 16,Loss: -2.630,Avg.Loss: -2.775,LR: 6.72E-05]Training epoch 77:  10%|█         | 16/153 [00:00<00:02, 54.71it/s, Epoch: 77, Batch: 17,Loss: -3.244,Avg.Loss: -2.802,LR: 6.72E-05]Training epoch 77:  11%|█         | 17/153 [00:00<00:02, 54.71it/s, Epoch: 77, Batch: 18,Loss: -2.910,Avg.Loss: -2.808,LR: 6.71E-05]Training epoch 77:  12%|█▏        | 18/153 [00:00<00:02, 54.42it/s, Epoch: 77, Batch: 18,Loss: -2.910,Avg.Loss: -2.808,LR: 6.71E-05]Training epoch 77:  12%|█▏        | 18/153 [00:00<00:02, 54.42it/s, Epoch: 77, Batch: 19,Loss: -2.624,Avg.Loss: -2.799,LR: 6.71E-05]Training epoch 77:  12%|█▏        | 19/153 [00:00<00:02, 54.42it/s, Epoch: 77, Batch: 20,Loss: -2.532,Avg.Loss: -2.785,LR: 6.71E-05]Training epoch 77:  13%|█▎        | 20/153 [00:00<00:02, 54.42it/s, Epoch: 77, Batch: 21,Loss: -2.824,Avg.Loss: -2.787,LR: 6.70E-05]Training epoch 77:  14%|█▎        | 21/153 [00:00<00:02, 54.42it/s, Epoch: 77, Batch: 22,Loss: -2.654,Avg.Loss: -2.781,LR: 6.70E-05]Training epoch 77:  14%|█▍        | 22/153 [00:00<00:02, 54.42it/s, Epoch: 77, Batch: 23,Loss: -2.588,Avg.Loss: -2.773,LR: 6.70E-05]Training epoch 77:  15%|█▌        | 23/153 [00:00<00:02, 54.42it/s, Epoch: 77, Batch: 24,Loss: -2.122,Avg.Loss: -2.746,LR: 6.69E-05]Training epoch 77:  16%|█▌        | 24/153 [00:00<00:02, 52.08it/s, Epoch: 77, Batch: 24,Loss: -2.122,Avg.Loss: -2.746,LR: 6.69E-05]Training epoch 77:  16%|█▌        | 24/153 [00:00<00:02, 52.08it/s, Epoch: 77, Batch: 25,Loss: -2.218,Avg.Loss: -2.725,LR: 6.69E-05]Training epoch 77:  16%|█▋        | 25/153 [00:00<00:02, 52.08it/s, Epoch: 77, Batch: 26,Loss: -2.900,Avg.Loss: -2.731,LR: 6.68E-05]Training epoch 77:  17%|█▋        | 26/153 [00:00<00:02, 52.08it/s, Epoch: 77, Batch: 27,Loss: -2.368,Avg.Loss: -2.718,LR: 6.68E-05]Training epoch 77:  18%|█▊        | 27/153 [00:00<00:02, 52.08it/s, Epoch: 77, Batch: 28,Loss: -2.459,Avg.Loss: -2.709,LR: 6.68E-05]Training epoch 77:  18%|█▊        | 28/153 [00:00<00:02, 52.08it/s, Epoch: 77, Batch: 29,Loss: -2.649,Avg.Loss: -2.706,LR: 6.67E-05]Training epoch 77:  19%|█▉        | 29/153 [00:00<00:02, 52.08it/s, Epoch: 77, Batch: 30,Loss: -2.464,Avg.Loss: -2.698,LR: 6.67E-05]Training epoch 77:  20%|█▉        | 30/153 [00:00<00:02, 51.65it/s, Epoch: 77, Batch: 30,Loss: -2.464,Avg.Loss: -2.698,LR: 6.67E-05]Training epoch 77:  20%|█▉        | 30/153 [00:00<00:02, 51.65it/s, Epoch: 77, Batch: 31,Loss: -2.900,Avg.Loss: -2.705,LR: 6.67E-05]Training epoch 77:  20%|██        | 31/153 [00:00<00:02, 51.65it/s, Epoch: 77, Batch: 32,Loss: -3.208,Avg.Loss: -2.721,LR: 6.66E-05]Training epoch 77:  21%|██        | 32/153 [00:00<00:02, 51.65it/s, Epoch: 77, Batch: 33,Loss: -2.838,Avg.Loss: -2.724,LR: 6.66E-05]Training epoch 77:  22%|██▏       | 33/153 [00:00<00:02, 51.65it/s, Epoch: 77, Batch: 34,Loss: -2.881,Avg.Loss: -2.729,LR: 6.66E-05]Training epoch 77:  22%|██▏       | 34/153 [00:00<00:02, 51.65it/s, Epoch: 77, Batch: 35,Loss: -3.461,Avg.Loss: -2.750,LR: 6.65E-05]Training epoch 77:  23%|██▎       | 35/153 [00:00<00:02, 51.65it/s, Epoch: 77, Batch: 36,Loss: -2.725,Avg.Loss: -2.749,LR: 6.65E-05]Training epoch 77:  24%|██▎       | 36/153 [00:00<00:02, 52.10it/s, Epoch: 77, Batch: 36,Loss: -2.725,Avg.Loss: -2.749,LR: 6.65E-05]Training epoch 77:  24%|██▎       | 36/153 [00:00<00:02, 52.10it/s, Epoch: 77, Batch: 37,Loss: -2.833,Avg.Loss: -2.751,LR: 6.65E-05]Training epoch 77:  24%|██▍       | 37/153 [00:00<00:02, 52.10it/s, Epoch: 77, Batch: 38,Loss: -2.895,Avg.Loss: -2.755,LR: 6.64E-05]Training epoch 77:  25%|██▍       | 38/153 [00:00<00:02, 52.10it/s, Epoch: 77, Batch: 39,Loss: -3.353,Avg.Loss: -2.770,LR: 6.64E-05]Training epoch 77:  25%|██▌       | 39/153 [00:00<00:02, 52.10it/s, Epoch: 77, Batch: 40,Loss: -2.690,Avg.Loss: -2.768,LR: 6.64E-05]Training epoch 77:  26%|██▌       | 40/153 [00:00<00:02, 52.10it/s, Epoch: 77, Batch: 41,Loss: -3.095,Avg.Loss: -2.776,LR: 6.63E-05]Training epoch 77:  27%|██▋       | 41/153 [00:00<00:02, 52.10it/s, Epoch: 77, Batch: 42,Loss: -2.523,Avg.Loss: -2.770,LR: 6.63E-05]Training epoch 77:  27%|██▋       | 42/153 [00:00<00:02, 52.38it/s, Epoch: 77, Batch: 42,Loss: -2.523,Avg.Loss: -2.770,LR: 6.63E-05]Training epoch 77:  27%|██▋       | 42/153 [00:00<00:02, 52.38it/s, Epoch: 77, Batch: 43,Loss: -3.085,Avg.Loss: -2.778,LR: 6.63E-05]Training epoch 77:  28%|██▊       | 43/153 [00:00<00:02, 52.38it/s, Epoch: 77, Batch: 44,Loss: -3.350,Avg.Loss: -2.791,LR: 6.62E-05]Training epoch 77:  29%|██▉       | 44/153 [00:00<00:02, 52.38it/s, Epoch: 77, Batch: 45,Loss: -2.645,Avg.Loss: -2.787,LR: 6.62E-05]Training epoch 77:  29%|██▉       | 45/153 [00:00<00:02, 52.38it/s, Epoch: 77, Batch: 46,Loss: -2.826,Avg.Loss: -2.788,LR: 6.61E-05]Training epoch 77:  30%|███       | 46/153 [00:00<00:02, 52.38it/s, Epoch: 77, Batch: 47,Loss: -3.037,Avg.Loss: -2.794,LR: 6.61E-05]Training epoch 77:  31%|███       | 47/153 [00:00<00:02, 52.38it/s, Epoch: 77, Batch: 48,Loss: -2.400,Avg.Loss: -2.785,LR: 6.61E-05]Training epoch 77:  31%|███▏      | 48/153 [00:00<00:01, 52.57it/s, Epoch: 77, Batch: 48,Loss: -2.400,Avg.Loss: -2.785,LR: 6.61E-05]Training epoch 77:  31%|███▏      | 48/153 [00:00<00:01, 52.57it/s, Epoch: 77, Batch: 49,Loss: -3.175,Avg.Loss: -2.793,LR: 6.60E-05]Training epoch 77:  32%|███▏      | 49/153 [00:00<00:01, 52.57it/s, Epoch: 77, Batch: 50,Loss: -3.300,Avg.Loss: -2.803,LR: 6.60E-05]Training epoch 77:  33%|███▎      | 50/153 [00:00<00:01, 52.57it/s, Epoch: 77, Batch: 51,Loss: -3.017,Avg.Loss: -2.808,LR: 6.60E-05]Training epoch 77:  33%|███▎      | 51/153 [00:00<00:01, 52.57it/s, Epoch: 77, Batch: 52,Loss: -3.119,Avg.Loss: -2.814,LR: 6.59E-05]Training epoch 77:  34%|███▍      | 52/153 [00:01<00:01, 52.57it/s, Epoch: 77, Batch: 53,Loss: -3.117,Avg.Loss: -2.819,LR: 6.59E-05]Training epoch 77:  35%|███▍      | 53/153 [00:01<00:01, 52.57it/s, Epoch: 77, Batch: 54,Loss: -3.204,Avg.Loss: -2.826,LR: 6.59E-05]Training epoch 77:  35%|███▌      | 54/153 [00:01<00:01, 52.71it/s, Epoch: 77, Batch: 54,Loss: -3.204,Avg.Loss: -2.826,LR: 6.59E-05]Training epoch 77:  35%|███▌      | 54/153 [00:01<00:01, 52.71it/s, Epoch: 77, Batch: 55,Loss: -3.264,Avg.Loss: -2.834,LR: 6.58E-05]Training epoch 77:  36%|███▌      | 55/153 [00:01<00:01, 52.71it/s, Epoch: 77, Batch: 56,Loss: -2.921,Avg.Loss: -2.836,LR: 6.58E-05]Training epoch 77:  37%|███▋      | 56/153 [00:01<00:01, 52.71it/s, Epoch: 77, Batch: 57,Loss: -2.850,Avg.Loss: -2.836,LR: 6.58E-05]Training epoch 77:  37%|███▋      | 57/153 [00:01<00:01, 52.71it/s, Epoch: 77, Batch: 58,Loss: -2.667,Avg.Loss: -2.833,LR: 6.57E-05]Training epoch 77:  38%|███▊      | 58/153 [00:01<00:01, 52.71it/s, Epoch: 77, Batch: 59,Loss: -2.605,Avg.Loss: -2.829,LR: 6.57E-05]Training epoch 77:  39%|███▊      | 59/153 [00:01<00:01, 52.71it/s, Epoch: 77, Batch: 60,Loss: -3.094,Avg.Loss: -2.834,LR: 6.57E-05]Training epoch 77:  39%|███▉      | 60/153 [00:01<00:01, 52.89it/s, Epoch: 77, Batch: 60,Loss: -3.094,Avg.Loss: -2.834,LR: 6.57E-05]Training epoch 77:  39%|███▉      | 60/153 [00:01<00:01, 52.89it/s, Epoch: 77, Batch: 61,Loss: -2.462,Avg.Loss: -2.828,LR: 6.56E-05]Training epoch 77:  40%|███▉      | 61/153 [00:01<00:01, 52.89it/s, Epoch: 77, Batch: 62,Loss: -2.608,Avg.Loss: -2.824,LR: 6.56E-05]Training epoch 77:  41%|████      | 62/153 [00:01<00:01, 52.89it/s, Epoch: 77, Batch: 63,Loss: -2.837,Avg.Loss: -2.824,LR: 6.56E-05]Training epoch 77:  41%|████      | 63/153 [00:01<00:01, 52.89it/s, Epoch: 77, Batch: 64,Loss: -3.138,Avg.Loss: -2.829,LR: 6.55E-05]Training epoch 77:  42%|████▏     | 64/153 [00:01<00:01, 52.89it/s, Epoch: 77, Batch: 65,Loss: -3.293,Avg.Loss: -2.836,LR: 6.55E-05]Training epoch 77:  42%|████▏     | 65/153 [00:01<00:01, 52.89it/s, Epoch: 77, Batch: 66,Loss: -2.696,Avg.Loss: -2.834,LR: 6.55E-05]Training epoch 77:  43%|████▎     | 66/153 [00:01<00:01, 52.86it/s, Epoch: 77, Batch: 66,Loss: -2.696,Avg.Loss: -2.834,LR: 6.55E-05]Training epoch 77:  43%|████▎     | 66/153 [00:01<00:01, 52.86it/s, Epoch: 77, Batch: 67,Loss: -3.198,Avg.Loss: -2.840,LR: 6.54E-05]Training epoch 77:  44%|████▍     | 67/153 [00:01<00:01, 52.86it/s, Epoch: 77, Batch: 68,Loss: -2.351,Avg.Loss: -2.833,LR: 6.54E-05]Training epoch 77:  44%|████▍     | 68/153 [00:01<00:01, 52.86it/s, Epoch: 77, Batch: 69,Loss: -2.612,Avg.Loss: -2.829,LR: 6.54E-05]Training epoch 77:  45%|████▌     | 69/153 [00:01<00:01, 52.86it/s, Epoch: 77, Batch: 70,Loss: -2.458,Avg.Loss: -2.824,LR: 6.53E-05]Training epoch 77:  46%|████▌     | 70/153 [00:01<00:01, 52.86it/s, Epoch: 77, Batch: 71,Loss: -2.882,Avg.Loss: -2.825,LR: 6.53E-05]Training epoch 77:  46%|████▋     | 71/153 [00:01<00:01, 52.86it/s, Epoch: 77, Batch: 72,Loss: -2.757,Avg.Loss: -2.824,LR: 6.52E-05]Training epoch 77:  47%|████▋     | 72/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 72,Loss: -2.757,Avg.Loss: -2.824,LR: 6.52E-05]Training epoch 77:  47%|████▋     | 72/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 73,Loss: -2.765,Avg.Loss: -2.823,LR: 6.52E-05]Training epoch 77:  48%|████▊     | 73/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 74,Loss: -2.632,Avg.Loss: -2.821,LR: 6.52E-05]Training epoch 77:  48%|████▊     | 74/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 75,Loss: -2.478,Avg.Loss: -2.816,LR: 6.51E-05]Training epoch 77:  49%|████▉     | 75/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 76,Loss: -2.497,Avg.Loss: -2.812,LR: 6.51E-05]Training epoch 77:  50%|████▉     | 76/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 77,Loss: -3.134,Avg.Loss: -2.816,LR: 6.51E-05]Training epoch 77:  50%|█████     | 77/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 78,Loss: -3.424,Avg.Loss: -2.824,LR: 6.50E-05]Training epoch 77:  51%|█████     | 78/153 [00:01<00:01, 52.94it/s, Epoch: 77, Batch: 78,Loss: -3.424,Avg.Loss: -2.824,LR: 6.50E-05]Training epoch 77:  51%|█████     | 78/153 [00:01<00:01, 52.94it/s, Epoch: 77, Batch: 79,Loss: -2.816,Avg.Loss: -2.824,LR: 6.50E-05]Training epoch 77:  52%|█████▏    | 79/153 [00:01<00:01, 52.94it/s, Epoch: 77, Batch: 80,Loss: -2.954,Avg.Loss: -2.825,LR: 6.50E-05]Training epoch 77:  52%|█████▏    | 80/153 [00:01<00:01, 52.94it/s, Epoch: 77, Batch: 81,Loss: -2.834,Avg.Loss: -2.825,LR: 6.49E-05]Training epoch 77:  53%|█████▎    | 81/153 [00:01<00:01, 52.94it/s, Epoch: 77, Batch: 82,Loss: -2.512,Avg.Loss: -2.822,LR: 6.49E-05]Training epoch 77:  54%|█████▎    | 82/153 [00:01<00:01, 52.94it/s, Epoch: 77, Batch: 83,Loss: -3.153,Avg.Loss: -2.826,LR: 6.49E-05]Training epoch 77:  54%|█████▍    | 83/153 [00:01<00:01, 52.94it/s, Epoch: 77, Batch: 84,Loss: -3.458,Avg.Loss: -2.833,LR: 6.48E-05]Training epoch 77:  55%|█████▍    | 84/153 [00:01<00:01, 52.99it/s, Epoch: 77, Batch: 84,Loss: -3.458,Avg.Loss: -2.833,LR: 6.48E-05]Training epoch 77:  55%|█████▍    | 84/153 [00:01<00:01, 52.99it/s, Epoch: 77, Batch: 85,Loss: -2.684,Avg.Loss: -2.831,LR: 6.48E-05]Training epoch 77:  56%|█████▌    | 85/153 [00:01<00:01, 52.99it/s, Epoch: 77, Batch: 86,Loss: -2.906,Avg.Loss: -2.832,LR: 6.48E-05]Training epoch 77:  56%|█████▌    | 86/153 [00:01<00:01, 52.99it/s, Epoch: 77, Batch: 87,Loss: -2.588,Avg.Loss: -2.829,LR: 6.47E-05]Training epoch 77:  57%|█████▋    | 87/153 [00:01<00:01, 52.99it/s, Epoch: 77, Batch: 88,Loss: -2.834,Avg.Loss: -2.829,LR: 6.47E-05]Training epoch 77:  58%|█████▊    | 88/153 [00:01<00:01, 52.99it/s, Epoch: 77, Batch: 89,Loss: -3.346,Avg.Loss: -2.835,LR: 6.47E-05]Training epoch 77:  58%|█████▊    | 89/153 [00:01<00:01, 52.99it/s, Epoch: 77, Batch: 90,Loss: -2.882,Avg.Loss: -2.836,LR: 6.46E-05]Training epoch 77:  59%|█████▉    | 90/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 90,Loss: -2.882,Avg.Loss: -2.836,LR: 6.46E-05]Training epoch 77:  59%|█████▉    | 90/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 91,Loss: -2.771,Avg.Loss: -2.835,LR: 6.46E-05]Training epoch 77:  59%|█████▉    | 91/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 92,Loss: -2.987,Avg.Loss: -2.837,LR: 6.46E-05]Training epoch 77:  60%|██████    | 92/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 93,Loss: -2.926,Avg.Loss: -2.838,LR: 6.45E-05]Training epoch 77:  61%|██████    | 93/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 94,Loss: -2.725,Avg.Loss: -2.836,LR: 6.45E-05]Training epoch 77:  61%|██████▏   | 94/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 95,Loss: -2.694,Avg.Loss: -2.835,LR: 6.45E-05]Training epoch 77:  62%|██████▏   | 95/153 [00:01<00:01, 52.95it/s, Epoch: 77, Batch: 96,Loss: -2.567,Avg.Loss: -2.832,LR: 6.44E-05]Training epoch 77:  63%|██████▎   | 96/153 [00:01<00:01, 52.79it/s, Epoch: 77, Batch: 96,Loss: -2.567,Avg.Loss: -2.832,LR: 6.44E-05]Training epoch 77:  63%|██████▎   | 96/153 [00:01<00:01, 52.79it/s, Epoch: 77, Batch: 97,Loss: -2.726,Avg.Loss: -2.831,LR: 6.44E-05]Training epoch 77:  63%|██████▎   | 97/153 [00:01<00:01, 52.79it/s, Epoch: 77, Batch: 98,Loss: -3.283,Avg.Loss: -2.836,LR: 6.44E-05]Training epoch 77:  64%|██████▍   | 98/153 [00:01<00:01, 52.79it/s, Epoch: 77, Batch: 99,Loss: -3.135,Avg.Loss: -2.839,LR: 6.43E-05]Training epoch 77:  65%|██████▍   | 99/153 [00:01<00:01, 52.79it/s, Epoch: 77, Batch: 100,Loss: -2.913,Avg.Loss: -2.839,LR: 6.43E-05]Training epoch 77:  65%|██████▌   | 100/153 [00:01<00:01, 52.79it/s, Epoch: 77, Batch: 101,Loss: -3.201,Avg.Loss: -2.843,LR: 6.42E-05]Training epoch 77:  66%|██████▌   | 101/153 [00:01<00:00, 52.79it/s, Epoch: 77, Batch: 102,Loss: -3.141,Avg.Loss: -2.846,LR: 6.42E-05]Training epoch 77:  67%|██████▋   | 102/153 [00:01<00:00, 52.99it/s, Epoch: 77, Batch: 102,Loss: -3.141,Avg.Loss: -2.846,LR: 6.42E-05]Training epoch 77:  67%|██████▋   | 102/153 [00:01<00:00, 52.99it/s, Epoch: 77, Batch: 103,Loss: -2.991,Avg.Loss: -2.847,LR: 6.42E-05]Training epoch 77:  67%|██████▋   | 103/153 [00:01<00:00, 52.99it/s, Epoch: 77, Batch: 104,Loss: -2.581,Avg.Loss: -2.845,LR: 6.41E-05]Training epoch 77:  68%|██████▊   | 104/153 [00:01<00:00, 52.99it/s, Epoch: 77, Batch: 105,Loss: -2.896,Avg.Loss: -2.845,LR: 6.41E-05]Training epoch 77:  69%|██████▊   | 105/153 [00:02<00:00, 52.99it/s, Epoch: 77, Batch: 106,Loss: -3.048,Avg.Loss: -2.847,LR: 6.41E-05]Training epoch 77:  69%|██████▉   | 106/153 [00:02<00:00, 52.99it/s, Epoch: 77, Batch: 107,Loss: -2.749,Avg.Loss: -2.846,LR: 6.40E-05]Training epoch 77:  70%|██████▉   | 107/153 [00:02<00:00, 52.99it/s, Epoch: 77, Batch: 108,Loss: -3.252,Avg.Loss: -2.850,LR: 6.40E-05]Training epoch 77:  71%|███████   | 108/153 [00:02<00:00, 52.89it/s, Epoch: 77, Batch: 108,Loss: -3.252,Avg.Loss: -2.850,LR: 6.40E-05]Training epoch 77:  71%|███████   | 108/153 [00:02<00:00, 52.89it/s, Epoch: 77, Batch: 109,Loss: -2.900,Avg.Loss: -2.851,LR: 6.40E-05]Training epoch 77:  71%|███████   | 109/153 [00:02<00:00, 52.89it/s, Epoch: 77, Batch: 110,Loss: -2.453,Avg.Loss: -2.847,LR: 6.39E-05]Training epoch 77:  72%|███████▏  | 110/153 [00:02<00:00, 52.89it/s, Epoch: 77, Batch: 111,Loss: -2.707,Avg.Loss: -2.846,LR: 6.39E-05]Training epoch 77:  73%|███████▎  | 111/153 [00:02<00:00, 52.89it/s, Epoch: 77, Batch: 112,Loss: -2.530,Avg.Loss: -2.843,LR: 6.39E-05]Training epoch 77:  73%|███████▎  | 112/153 [00:02<00:00, 52.89it/s, Epoch: 77, Batch: 113,Loss: -2.755,Avg.Loss: -2.842,LR: 6.38E-05]Training epoch 77:  74%|███████▍  | 113/153 [00:02<00:00, 52.89it/s, Epoch: 77, Batch: 114,Loss: -3.537,Avg.Loss: -2.848,LR: 6.38E-05]Training epoch 77:  75%|███████▍  | 114/153 [00:02<00:00, 52.95it/s, Epoch: 77, Batch: 114,Loss: -3.537,Avg.Loss: -2.848,LR: 6.38E-05]Training epoch 77:  75%|███████▍  | 114/153 [00:02<00:00, 52.95it/s, Epoch: 77, Batch: 115,Loss: -2.989,Avg.Loss: -2.849,LR: 6.38E-05]Training epoch 77:  75%|███████▌  | 115/153 [00:02<00:00, 52.95it/s, Epoch: 77, Batch: 116,Loss: -3.140,Avg.Loss: -2.852,LR: 6.37E-05]Training epoch 77:  76%|███████▌  | 116/153 [00:02<00:00, 52.95it/s, Epoch: 77, Batch: 117,Loss: -3.465,Avg.Loss: -2.857,LR: 6.37E-05]Training epoch 77:  76%|███████▋  | 117/153 [00:02<00:00, 52.95it/s, Epoch: 77, Batch: 118,Loss: -3.047,Avg.Loss: -2.859,LR: 6.37E-05]Training epoch 77:  77%|███████▋  | 118/153 [00:02<00:00, 52.95it/s, Epoch: 77, Batch: 119,Loss: -2.714,Avg.Loss: -2.858,LR: 6.36E-05]Training epoch 77:  78%|███████▊  | 119/153 [00:02<00:00, 52.95it/s, Epoch: 77, Batch: 120,Loss: -2.715,Avg.Loss: -2.856,LR: 6.36E-05]Training epoch 77:  78%|███████▊  | 120/153 [00:02<00:00, 52.87it/s, Epoch: 77, Batch: 120,Loss: -2.715,Avg.Loss: -2.856,LR: 6.36E-05]Training epoch 77:  78%|███████▊  | 120/153 [00:02<00:00, 52.87it/s, Epoch: 77, Batch: 121,Loss: -2.795,Avg.Loss: -2.856,LR: 6.36E-05]Training epoch 77:  79%|███████▉  | 121/153 [00:02<00:00, 52.87it/s, Epoch: 77, Batch: 122,Loss: -2.472,Avg.Loss: -2.853,LR: 6.35E-05]Training epoch 77:  80%|███████▉  | 122/153 [00:02<00:00, 52.87it/s, Epoch: 77, Batch: 123,Loss: -3.463,Avg.Loss: -2.858,LR: 6.35E-05]Training epoch 77:  80%|████████  | 123/153 [00:02<00:00, 52.87it/s, Epoch: 77, Batch: 124,Loss: -2.916,Avg.Loss: -2.858,LR: 6.35E-05]Training epoch 77:  81%|████████  | 124/153 [00:02<00:00, 52.87it/s, Epoch: 77, Batch: 125,Loss: -3.077,Avg.Loss: -2.860,LR: 6.34E-05]Training epoch 77:  82%|████████▏ | 125/153 [00:02<00:00, 52.87it/s, Epoch: 77, Batch: 126,Loss: -2.957,Avg.Loss: -2.861,LR: 6.34E-05]Training epoch 77:  82%|████████▏ | 126/153 [00:02<00:00, 52.92it/s, Epoch: 77, Batch: 126,Loss: -2.957,Avg.Loss: -2.861,LR: 6.34E-05]Training epoch 77:  82%|████████▏ | 126/153 [00:02<00:00, 52.92it/s, Epoch: 77, Batch: 127,Loss: -2.981,Avg.Loss: -2.862,LR: 6.34E-05]Training epoch 77:  83%|████████▎ | 127/153 [00:02<00:00, 52.92it/s, Epoch: 77, Batch: 128,Loss: -2.677,Avg.Loss: -2.860,LR: 6.33E-05]Training epoch 77:  84%|████████▎ | 128/153 [00:02<00:00, 52.92it/s, Epoch: 77, Batch: 129,Loss: -2.301,Avg.Loss: -2.856,LR: 6.33E-05]Training epoch 77:  84%|████████▍ | 129/153 [00:02<00:00, 52.92it/s, Epoch: 77, Batch: 130,Loss: -2.757,Avg.Loss: -2.855,LR: 6.33E-05]Training epoch 77:  85%|████████▍ | 130/153 [00:02<00:00, 52.92it/s, Epoch: 77, Batch: 131,Loss: -2.644,Avg.Loss: -2.853,LR: 6.32E-05]Training epoch 77:  86%|████████▌ | 131/153 [00:02<00:00, 52.92it/s, Epoch: 77, Batch: 132,Loss: -3.109,Avg.Loss: -2.855,LR: 6.32E-05]Training epoch 77:  86%|████████▋ | 132/153 [00:02<00:00, 53.01it/s, Epoch: 77, Batch: 132,Loss: -3.109,Avg.Loss: -2.855,LR: 6.32E-05]Training epoch 77:  86%|████████▋ | 132/153 [00:02<00:00, 53.01it/s, Epoch: 77, Batch: 133,Loss: -3.019,Avg.Loss: -2.857,LR: 6.32E-05]Training epoch 77:  87%|████████▋ | 133/153 [00:02<00:00, 53.01it/s, Epoch: 77, Batch: 134,Loss: -2.999,Avg.Loss: -2.858,LR: 6.31E-05]Training epoch 77:  88%|████████▊ | 134/153 [00:02<00:00, 53.01it/s, Epoch: 77, Batch: 135,Loss: -2.682,Avg.Loss: -2.856,LR: 6.31E-05]Training epoch 77:  88%|████████▊ | 135/153 [00:02<00:00, 53.01it/s, Epoch: 77, Batch: 136,Loss: -2.965,Avg.Loss: -2.857,LR: 6.31E-05]Training epoch 77:  89%|████████▉ | 136/153 [00:02<00:00, 53.01it/s, Epoch: 77, Batch: 137,Loss: -2.831,Avg.Loss: -2.857,LR: 6.30E-05]Training epoch 77:  90%|████████▉ | 137/153 [00:02<00:00, 53.01it/s, Epoch: 77, Batch: 138,Loss: -2.818,Avg.Loss: -2.857,LR: 6.30E-05]Training epoch 77:  90%|█████████ | 138/153 [00:02<00:00, 53.07it/s, Epoch: 77, Batch: 138,Loss: -2.818,Avg.Loss: -2.857,LR: 6.30E-05]Training epoch 77:  90%|█████████ | 138/153 [00:02<00:00, 53.07it/s, Epoch: 77, Batch: 139,Loss: -2.913,Avg.Loss: -2.857,LR: 6.29E-05]Training epoch 77:  91%|█████████ | 139/153 [00:02<00:00, 53.07it/s, Epoch: 77, Batch: 140,Loss: -2.728,Avg.Loss: -2.856,LR: 6.29E-05]Training epoch 77:  92%|█████████▏| 140/153 [00:02<00:00, 53.07it/s, Epoch: 77, Batch: 141,Loss: -2.745,Avg.Loss: -2.855,LR: 6.29E-05]Training epoch 77:  92%|█████████▏| 141/153 [00:02<00:00, 53.07it/s, Epoch: 77, Batch: 142,Loss: -2.751,Avg.Loss: -2.855,LR: 6.28E-05]Training epoch 77:  93%|█████████▎| 142/153 [00:02<00:00, 53.07it/s, Epoch: 77, Batch: 143,Loss: -2.924,Avg.Loss: -2.855,LR: 6.28E-05]Training epoch 77:  93%|█████████▎| 143/153 [00:02<00:00, 53.07it/s, Epoch: 77, Batch: 144,Loss: -2.471,Avg.Loss: -2.852,LR: 6.28E-05]Training epoch 77:  94%|█████████▍| 144/153 [00:02<00:00, 52.88it/s, Epoch: 77, Batch: 144,Loss: -2.471,Avg.Loss: -2.852,LR: 6.28E-05]Training epoch 77:  94%|█████████▍| 144/153 [00:02<00:00, 52.88it/s, Epoch: 77, Batch: 145,Loss: -2.213,Avg.Loss: -2.848,LR: 6.27E-05]Training epoch 77:  95%|█████████▍| 145/153 [00:02<00:00, 52.88it/s, Epoch: 77, Batch: 146,Loss: -2.870,Avg.Loss: -2.848,LR: 6.27E-05]Training epoch 77:  95%|█████████▌| 146/153 [00:02<00:00, 52.88it/s, Epoch: 77, Batch: 147,Loss: -3.148,Avg.Loss: -2.850,LR: 6.27E-05]Training epoch 77:  96%|█████████▌| 147/153 [00:02<00:00, 52.88it/s, Epoch: 77, Batch: 148,Loss: -2.939,Avg.Loss: -2.851,LR: 6.26E-05]Training epoch 77:  97%|█████████▋| 148/153 [00:02<00:00, 52.88it/s, Epoch: 77, Batch: 149,Loss: -2.858,Avg.Loss: -2.851,LR: 6.26E-05]Training epoch 77:  97%|█████████▋| 149/153 [00:02<00:00, 52.88it/s, Epoch: 77, Batch: 150,Loss: -2.285,Avg.Loss: -2.847,LR: 6.26E-05]Training epoch 77:  98%|█████████▊| 150/153 [00:02<00:00, 52.74it/s, Epoch: 77, Batch: 150,Loss: -2.285,Avg.Loss: -2.847,LR: 6.26E-05]Training epoch 77:  98%|█████████▊| 150/153 [00:02<00:00, 52.74it/s, Epoch: 77, Batch: 151,Loss: -2.430,Avg.Loss: -2.844,LR: 6.25E-05]Training epoch 77:  99%|█████████▊| 151/153 [00:02<00:00, 52.74it/s, Epoch: 77, Batch: 152,Loss: -2.786,Avg.Loss: -2.844,LR: 6.25E-05]Training epoch 77:  99%|█████████▉| 152/153 [00:02<00:00, 52.74it/s, Epoch: 77, Batch: 153,Loss: -2.296,Avg.Loss: -2.840,LR: 6.25E-05]Training epoch 77: 100%|██████████| 153/153 [00:02<00:00, 52.83it/s, Epoch: 77, Batch: 153,Loss: -2.296,Avg.Loss: -2.840,LR: 6.25E-05]
Training epoch 78:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 78:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 78, Batch: 1,Loss: -2.828,Avg.Loss: -2.828,LR: 6.24E-05]Training epoch 78:   1%|          | 1/153 [00:00<00:05, 29.34it/s, Epoch: 78, Batch: 2,Loss: -2.843,Avg.Loss: -2.836,LR: 6.24E-05]Training epoch 78:   1%|▏         | 2/153 [00:00<00:03, 41.18it/s, Epoch: 78, Batch: 3,Loss: -3.213,Avg.Loss: -2.962,LR: 6.24E-05]Training epoch 78:   2%|▏         | 3/153 [00:00<00:03, 46.25it/s, Epoch: 78, Batch: 4,Loss: -2.752,Avg.Loss: -2.909,LR: 6.23E-05]Training epoch 78:   3%|▎         | 4/153 [00:00<00:03, 48.55it/s, Epoch: 78, Batch: 5,Loss: -2.460,Avg.Loss: -2.819,LR: 6.23E-05]Training epoch 78:   3%|▎         | 5/153 [00:00<00:03, 49.29it/s, Epoch: 78, Batch: 6,Loss: -3.015,Avg.Loss: -2.852,LR: 6.23E-05]Training epoch 78:   4%|▍         | 6/153 [00:00<00:02, 59.04it/s, Epoch: 78, Batch: 6,Loss: -3.015,Avg.Loss: -2.852,LR: 6.23E-05]Training epoch 78:   4%|▍         | 6/153 [00:00<00:02, 59.04it/s, Epoch: 78, Batch: 7,Loss: -2.786,Avg.Loss: -2.843,LR: 6.22E-05]Training epoch 78:   5%|▍         | 7/153 [00:00<00:02, 59.04it/s, Epoch: 78, Batch: 8,Loss: -2.396,Avg.Loss: -2.787,LR: 6.22E-05]Training epoch 78:   5%|▌         | 8/153 [00:00<00:02, 59.04it/s, Epoch: 78, Batch: 9,Loss: -2.709,Avg.Loss: -2.778,LR: 6.22E-05]Training epoch 78:   6%|▌         | 9/153 [00:00<00:02, 59.04it/s, Epoch: 78, Batch: 10,Loss: -3.152,Avg.Loss: -2.815,LR: 6.21E-05]Training epoch 78:   7%|▋         | 10/153 [00:00<00:02, 59.04it/s, Epoch: 78, Batch: 11,Loss: -3.139,Avg.Loss: -2.845,LR: 6.21E-05]Training epoch 78:   7%|▋         | 11/153 [00:00<00:02, 59.04it/s, Epoch: 78, Batch: 12,Loss: -2.716,Avg.Loss: -2.834,LR: 6.21E-05]Training epoch 78:   8%|▊         | 12/153 [00:00<00:02, 55.06it/s, Epoch: 78, Batch: 12,Loss: -2.716,Avg.Loss: -2.834,LR: 6.21E-05]Training epoch 78:   8%|▊         | 12/153 [00:00<00:02, 55.06it/s, Epoch: 78, Batch: 13,Loss: -2.624,Avg.Loss: -2.818,LR: 6.20E-05]Training epoch 78:   8%|▊         | 13/153 [00:00<00:02, 55.06it/s, Epoch: 78, Batch: 14,Loss: -3.086,Avg.Loss: -2.837,LR: 6.20E-05]Training epoch 78:   9%|▉         | 14/153 [00:00<00:02, 55.06it/s, Epoch: 78, Batch: 15,Loss: -2.510,Avg.Loss: -2.815,LR: 6.20E-05]Training epoch 78:  10%|▉         | 15/153 [00:00<00:02, 55.06it/s, Epoch: 78, Batch: 16,Loss: -2.940,Avg.Loss: -2.823,LR: 6.19E-05]Training epoch 78:  10%|█         | 16/153 [00:00<00:02, 55.06it/s, Epoch: 78, Batch: 17,Loss: -3.330,Avg.Loss: -2.853,LR: 6.19E-05]Training epoch 78:  11%|█         | 17/153 [00:00<00:02, 55.06it/s, Epoch: 78, Batch: 18,Loss: -3.038,Avg.Loss: -2.863,LR: 6.19E-05]Training epoch 78:  12%|█▏        | 18/153 [00:00<00:02, 53.88it/s, Epoch: 78, Batch: 18,Loss: -3.038,Avg.Loss: -2.863,LR: 6.19E-05]Training epoch 78:  12%|█▏        | 18/153 [00:00<00:02, 53.88it/s, Epoch: 78, Batch: 19,Loss: -2.302,Avg.Loss: -2.834,LR: 6.18E-05]Training epoch 78:  12%|█▏        | 19/153 [00:00<00:02, 53.88it/s, Epoch: 78, Batch: 20,Loss: -2.274,Avg.Loss: -2.806,LR: 6.18E-05]Training epoch 78:  13%|█▎        | 20/153 [00:00<00:02, 53.88it/s, Epoch: 78, Batch: 21,Loss: -2.845,Avg.Loss: -2.807,LR: 6.18E-05]Training epoch 78:  14%|█▎        | 21/153 [00:00<00:02, 53.88it/s, Epoch: 78, Batch: 22,Loss: -3.113,Avg.Loss: -2.821,LR: 6.17E-05]Training epoch 78:  14%|█▍        | 22/153 [00:00<00:02, 53.88it/s, Epoch: 78, Batch: 23,Loss: -3.098,Avg.Loss: -2.833,LR: 6.17E-05]Training epoch 78:  15%|█▌        | 23/153 [00:00<00:02, 53.88it/s, Epoch: 78, Batch: 24,Loss: -2.519,Avg.Loss: -2.820,LR: 6.17E-05]Training epoch 78:  16%|█▌        | 24/153 [00:00<00:02, 53.05it/s, Epoch: 78, Batch: 24,Loss: -2.519,Avg.Loss: -2.820,LR: 6.17E-05]Training epoch 78:  16%|█▌        | 24/153 [00:00<00:02, 53.05it/s, Epoch: 78, Batch: 25,Loss: -2.632,Avg.Loss: -2.813,LR: 6.16E-05]Training epoch 78:  16%|█▋        | 25/153 [00:00<00:02, 53.05it/s, Epoch: 78, Batch: 26,Loss: -2.606,Avg.Loss: -2.805,LR: 6.16E-05]Training epoch 78:  17%|█▋        | 26/153 [00:00<00:02, 53.05it/s, Epoch: 78, Batch: 27,Loss: -2.284,Avg.Loss: -2.786,LR: 6.16E-05]Training epoch 78:  18%|█▊        | 27/153 [00:00<00:02, 53.05it/s, Epoch: 78, Batch: 28,Loss: -2.515,Avg.Loss: -2.776,LR: 6.15E-05]Training epoch 78:  18%|█▊        | 28/153 [00:00<00:02, 53.05it/s, Epoch: 78, Batch: 29,Loss: -2.849,Avg.Loss: -2.778,LR: 6.15E-05]Training epoch 78:  19%|█▉        | 29/153 [00:00<00:02, 53.05it/s, Epoch: 78, Batch: 30,Loss: -3.171,Avg.Loss: -2.791,LR: 6.15E-05]Training epoch 78:  20%|█▉        | 30/153 [00:00<00:02, 52.70it/s, Epoch: 78, Batch: 30,Loss: -3.171,Avg.Loss: -2.791,LR: 6.15E-05]Training epoch 78:  20%|█▉        | 30/153 [00:00<00:02, 52.70it/s, Epoch: 78, Batch: 31,Loss: -2.689,Avg.Loss: -2.788,LR: 6.14E-05]Training epoch 78:  20%|██        | 31/153 [00:00<00:02, 52.70it/s, Epoch: 78, Batch: 32,Loss: -2.878,Avg.Loss: -2.791,LR: 6.14E-05]Training epoch 78:  21%|██        | 32/153 [00:00<00:02, 52.70it/s, Epoch: 78, Batch: 33,Loss: -3.044,Avg.Loss: -2.799,LR: 6.14E-05]Training epoch 78:  22%|██▏       | 33/153 [00:00<00:02, 52.70it/s, Epoch: 78, Batch: 34,Loss: -2.992,Avg.Loss: -2.804,LR: 6.13E-05]Training epoch 78:  22%|██▏       | 34/153 [00:00<00:02, 52.70it/s, Epoch: 78, Batch: 35,Loss: -2.508,Avg.Loss: -2.796,LR: 6.13E-05]Training epoch 78:  23%|██▎       | 35/153 [00:00<00:02, 52.70it/s, Epoch: 78, Batch: 36,Loss: -2.780,Avg.Loss: -2.795,LR: 6.13E-05]Training epoch 78:  24%|██▎       | 36/153 [00:00<00:02, 52.74it/s, Epoch: 78, Batch: 36,Loss: -2.780,Avg.Loss: -2.795,LR: 6.13E-05]Training epoch 78:  24%|██▎       | 36/153 [00:00<00:02, 52.74it/s, Epoch: 78, Batch: 37,Loss: -2.507,Avg.Loss: -2.788,LR: 6.12E-05]Training epoch 78:  24%|██▍       | 37/153 [00:00<00:02, 52.74it/s, Epoch: 78, Batch: 38,Loss: -2.877,Avg.Loss: -2.790,LR: 6.12E-05]Training epoch 78:  25%|██▍       | 38/153 [00:00<00:02, 52.74it/s, Epoch: 78, Batch: 39,Loss: -3.023,Avg.Loss: -2.796,LR: 6.12E-05]Training epoch 78:  25%|██▌       | 39/153 [00:00<00:02, 52.74it/s, Epoch: 78, Batch: 40,Loss: -2.874,Avg.Loss: -2.798,LR: 6.11E-05]Training epoch 78:  26%|██▌       | 40/153 [00:00<00:02, 52.74it/s, Epoch: 78, Batch: 41,Loss: -2.280,Avg.Loss: -2.785,LR: 6.11E-05]Training epoch 78:  27%|██▋       | 41/153 [00:00<00:02, 52.74it/s, Epoch: 78, Batch: 42,Loss: -2.337,Avg.Loss: -2.775,LR: 6.11E-05]Training epoch 78:  27%|██▋       | 42/153 [00:00<00:02, 52.80it/s, Epoch: 78, Batch: 42,Loss: -2.337,Avg.Loss: -2.775,LR: 6.11E-05]Training epoch 78:  27%|██▋       | 42/153 [00:00<00:02, 52.80it/s, Epoch: 78, Batch: 43,Loss: -2.523,Avg.Loss: -2.769,LR: 6.10E-05]Training epoch 78:  28%|██▊       | 43/153 [00:00<00:02, 52.80it/s, Epoch: 78, Batch: 44,Loss: -2.576,Avg.Loss: -2.764,LR: 6.10E-05]Training epoch 78:  29%|██▉       | 44/153 [00:00<00:02, 52.80it/s, Epoch: 78, Batch: 45,Loss: -2.659,Avg.Loss: -2.762,LR: 6.10E-05]Training epoch 78:  29%|██▉       | 45/153 [00:00<00:02, 52.80it/s, Epoch: 78, Batch: 46,Loss: -2.739,Avg.Loss: -2.761,LR: 6.09E-05]Training epoch 78:  30%|███       | 46/153 [00:00<00:02, 52.80it/s, Epoch: 78, Batch: 47,Loss: -2.760,Avg.Loss: -2.761,LR: 6.09E-05]Training epoch 78:  31%|███       | 47/153 [00:00<00:02, 52.80it/s, Epoch: 78, Batch: 48,Loss: -2.480,Avg.Loss: -2.756,LR: 6.09E-05]Training epoch 78:  31%|███▏      | 48/153 [00:00<00:01, 53.03it/s, Epoch: 78, Batch: 48,Loss: -2.480,Avg.Loss: -2.756,LR: 6.09E-05]Training epoch 78:  31%|███▏      | 48/153 [00:00<00:01, 53.03it/s, Epoch: 78, Batch: 49,Loss: -2.861,Avg.Loss: -2.758,LR: 6.08E-05]Training epoch 78:  32%|███▏      | 49/153 [00:00<00:01, 53.03it/s, Epoch: 78, Batch: 50,Loss: -2.509,Avg.Loss: -2.753,LR: 6.08E-05]Training epoch 78:  33%|███▎      | 50/153 [00:00<00:01, 53.03it/s, Epoch: 78, Batch: 51,Loss: -2.862,Avg.Loss: -2.755,LR: 6.08E-05]Training epoch 78:  33%|███▎      | 51/153 [00:00<00:01, 53.03it/s, Epoch: 78, Batch: 52,Loss: -3.103,Avg.Loss: -2.762,LR: 6.07E-05]Training epoch 78:  34%|███▍      | 52/153 [00:00<00:01, 53.03it/s, Epoch: 78, Batch: 53,Loss: -3.055,Avg.Loss: -2.767,LR: 6.07E-05]Training epoch 78:  35%|███▍      | 53/153 [00:01<00:01, 53.03it/s, Epoch: 78, Batch: 54,Loss: -3.157,Avg.Loss: -2.774,LR: 6.07E-05]Training epoch 78:  35%|███▌      | 54/153 [00:01<00:01, 52.92it/s, Epoch: 78, Batch: 54,Loss: -3.157,Avg.Loss: -2.774,LR: 6.07E-05]Training epoch 78:  35%|███▌      | 54/153 [00:01<00:01, 52.92it/s, Epoch: 78, Batch: 55,Loss: -2.954,Avg.Loss: -2.778,LR: 6.06E-05]Training epoch 78:  36%|███▌      | 55/153 [00:01<00:01, 52.92it/s, Epoch: 78, Batch: 56,Loss: -2.763,Avg.Loss: -2.777,LR: 6.06E-05]Training epoch 78:  37%|███▋      | 56/153 [00:01<00:01, 52.92it/s, Epoch: 78, Batch: 57,Loss: -3.272,Avg.Loss: -2.786,LR: 6.06E-05]Training epoch 78:  37%|███▋      | 57/153 [00:01<00:01, 52.92it/s, Epoch: 78, Batch: 58,Loss: -3.258,Avg.Loss: -2.794,LR: 6.05E-05]Training epoch 78:  38%|███▊      | 58/153 [00:01<00:01, 52.92it/s, Epoch: 78, Batch: 59,Loss: -2.887,Avg.Loss: -2.796,LR: 6.05E-05]Training epoch 78:  39%|███▊      | 59/153 [00:01<00:01, 52.92it/s, Epoch: 78, Batch: 60,Loss: -3.236,Avg.Loss: -2.803,LR: 6.04E-05]Training epoch 78:  39%|███▉      | 60/153 [00:01<00:01, 52.95it/s, Epoch: 78, Batch: 60,Loss: -3.236,Avg.Loss: -2.803,LR: 6.04E-05]Training epoch 78:  39%|███▉      | 60/153 [00:01<00:01, 52.95it/s, Epoch: 78, Batch: 61,Loss: -2.663,Avg.Loss: -2.801,LR: 6.04E-05]Training epoch 78:  40%|███▉      | 61/153 [00:01<00:01, 52.95it/s, Epoch: 78, Batch: 62,Loss: -2.602,Avg.Loss: -2.798,LR: 6.04E-05]Training epoch 78:  41%|████      | 62/153 [00:01<00:01, 52.95it/s, Epoch: 78, Batch: 63,Loss: -2.616,Avg.Loss: -2.795,LR: 6.03E-05]Training epoch 78:  41%|████      | 63/153 [00:01<00:01, 52.95it/s, Epoch: 78, Batch: 64,Loss: -2.895,Avg.Loss: -2.796,LR: 6.03E-05]Training epoch 78:  42%|████▏     | 64/153 [00:01<00:01, 52.95it/s, Epoch: 78, Batch: 65,Loss: -2.960,Avg.Loss: -2.799,LR: 6.03E-05]Training epoch 78:  42%|████▏     | 65/153 [00:01<00:01, 52.95it/s, Epoch: 78, Batch: 66,Loss: -2.521,Avg.Loss: -2.795,LR: 6.02E-05]Training epoch 78:  43%|████▎     | 66/153 [00:01<00:01, 52.99it/s, Epoch: 78, Batch: 66,Loss: -2.521,Avg.Loss: -2.795,LR: 6.02E-05]Training epoch 78:  43%|████▎     | 66/153 [00:01<00:01, 52.99it/s, Epoch: 78, Batch: 67,Loss: -3.044,Avg.Loss: -2.798,LR: 6.02E-05]Training epoch 78:  44%|████▍     | 67/153 [00:01<00:01, 52.99it/s, Epoch: 78, Batch: 68,Loss: -2.984,Avg.Loss: -2.801,LR: 6.02E-05]Training epoch 78:  44%|████▍     | 68/153 [00:01<00:01, 52.99it/s, Epoch: 78, Batch: 69,Loss: -3.298,Avg.Loss: -2.808,LR: 6.01E-05]Training epoch 78:  45%|████▌     | 69/153 [00:01<00:01, 52.99it/s, Epoch: 78, Batch: 70,Loss: -3.132,Avg.Loss: -2.813,LR: 6.01E-05]Training epoch 78:  46%|████▌     | 70/153 [00:01<00:01, 52.99it/s, Epoch: 78, Batch: 71,Loss: -2.796,Avg.Loss: -2.813,LR: 6.01E-05]Training epoch 78:  46%|████▋     | 71/153 [00:01<00:01, 52.99it/s, Epoch: 78, Batch: 72,Loss: -2.601,Avg.Loss: -2.810,LR: 6.00E-05]Training epoch 78:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 72,Loss: -2.601,Avg.Loss: -2.810,LR: 6.00E-05]Training epoch 78:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 73,Loss: -2.896,Avg.Loss: -2.811,LR: 6.00E-05]Training epoch 78:  48%|████▊     | 73/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 74,Loss: -2.554,Avg.Loss: -2.807,LR: 6.00E-05]Training epoch 78:  48%|████▊     | 74/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 75,Loss: -3.146,Avg.Loss: -2.812,LR: 5.99E-05]Training epoch 78:  49%|████▉     | 75/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 76,Loss: -2.990,Avg.Loss: -2.814,LR: 5.99E-05]Training epoch 78:  50%|████▉     | 76/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 77,Loss: -3.062,Avg.Loss: -2.817,LR: 5.99E-05]Training epoch 78:  50%|█████     | 77/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 78,Loss: -2.892,Avg.Loss: -2.818,LR: 5.98E-05]Training epoch 78:  51%|█████     | 78/153 [00:01<00:01, 53.03it/s, Epoch: 78, Batch: 78,Loss: -2.892,Avg.Loss: -2.818,LR: 5.98E-05]Training epoch 78:  51%|█████     | 78/153 [00:01<00:01, 53.03it/s, Epoch: 78, Batch: 79,Loss: -3.144,Avg.Loss: -2.823,LR: 5.98E-05]Training epoch 78:  52%|█████▏    | 79/153 [00:01<00:01, 53.03it/s, Epoch: 78, Batch: 80,Loss: -3.180,Avg.Loss: -2.827,LR: 5.98E-05]Training epoch 78:  52%|█████▏    | 80/153 [00:01<00:01, 53.03it/s, Epoch: 78, Batch: 81,Loss: -3.247,Avg.Loss: -2.832,LR: 5.97E-05]Training epoch 78:  53%|█████▎    | 81/153 [00:01<00:01, 53.03it/s, Epoch: 78, Batch: 82,Loss: -3.258,Avg.Loss: -2.837,LR: 5.97E-05]Training epoch 78:  54%|█████▎    | 82/153 [00:01<00:01, 53.03it/s, Epoch: 78, Batch: 83,Loss: -3.549,Avg.Loss: -2.846,LR: 5.97E-05]Training epoch 78:  54%|█████▍    | 83/153 [00:01<00:01, 53.03it/s, Epoch: 78, Batch: 84,Loss: -3.056,Avg.Loss: -2.848,LR: 5.96E-05]Training epoch 78:  55%|█████▍    | 84/153 [00:01<00:01, 53.08it/s, Epoch: 78, Batch: 84,Loss: -3.056,Avg.Loss: -2.848,LR: 5.96E-05]Training epoch 78:  55%|█████▍    | 84/153 [00:01<00:01, 53.08it/s, Epoch: 78, Batch: 85,Loss: -2.566,Avg.Loss: -2.845,LR: 5.96E-05]Training epoch 78:  56%|█████▌    | 85/153 [00:01<00:01, 53.08it/s, Epoch: 78, Batch: 86,Loss: -2.266,Avg.Loss: -2.838,LR: 5.96E-05]Training epoch 78:  56%|█████▌    | 86/153 [00:01<00:01, 53.08it/s, Epoch: 78, Batch: 87,Loss: -2.767,Avg.Loss: -2.838,LR: 5.95E-05]Training epoch 78:  57%|█████▋    | 87/153 [00:01<00:01, 53.08it/s, Epoch: 78, Batch: 88,Loss: -2.448,Avg.Loss: -2.833,LR: 5.95E-05]Training epoch 78:  58%|█████▊    | 88/153 [00:01<00:01, 53.08it/s, Epoch: 78, Batch: 89,Loss: -2.898,Avg.Loss: -2.834,LR: 5.95E-05]Training epoch 78:  58%|█████▊    | 89/153 [00:01<00:01, 53.08it/s, Epoch: 78, Batch: 90,Loss: -3.177,Avg.Loss: -2.838,LR: 5.94E-05]Training epoch 78:  59%|█████▉    | 90/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 90,Loss: -3.177,Avg.Loss: -2.838,LR: 5.94E-05]Training epoch 78:  59%|█████▉    | 90/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 91,Loss: -3.201,Avg.Loss: -2.842,LR: 5.94E-05]Training epoch 78:  59%|█████▉    | 91/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 92,Loss: -2.905,Avg.Loss: -2.842,LR: 5.94E-05]Training epoch 78:  60%|██████    | 92/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 93,Loss: -2.862,Avg.Loss: -2.843,LR: 5.93E-05]Training epoch 78:  61%|██████    | 93/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 94,Loss: -2.638,Avg.Loss: -2.840,LR: 5.93E-05]Training epoch 78:  61%|██████▏   | 94/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 95,Loss: -2.600,Avg.Loss: -2.838,LR: 5.93E-05]Training epoch 78:  62%|██████▏   | 95/153 [00:01<00:01, 52.96it/s, Epoch: 78, Batch: 96,Loss: -3.075,Avg.Loss: -2.840,LR: 5.92E-05]Training epoch 78:  63%|██████▎   | 96/153 [00:01<00:01, 52.78it/s, Epoch: 78, Batch: 96,Loss: -3.075,Avg.Loss: -2.840,LR: 5.92E-05]Training epoch 78:  63%|██████▎   | 96/153 [00:01<00:01, 52.78it/s, Epoch: 78, Batch: 97,Loss: -2.798,Avg.Loss: -2.840,LR: 5.92E-05]Training epoch 78:  63%|██████▎   | 97/153 [00:01<00:01, 52.78it/s, Epoch: 78, Batch: 98,Loss: -2.687,Avg.Loss: -2.838,LR: 5.92E-05]Training epoch 78:  64%|██████▍   | 98/153 [00:01<00:01, 52.78it/s, Epoch: 78, Batch: 99,Loss: -3.375,Avg.Loss: -2.844,LR: 5.92E-05]Training epoch 78:  65%|██████▍   | 99/153 [00:01<00:01, 52.78it/s, Epoch: 78, Batch: 100,Loss: -2.500,Avg.Loss: -2.840,LR: 5.91E-05]Training epoch 78:  65%|██████▌   | 100/153 [00:01<00:01, 52.78it/s, Epoch: 78, Batch: 101,Loss: -2.559,Avg.Loss: -2.838,LR: 5.91E-05]Training epoch 78:  66%|██████▌   | 101/153 [00:01<00:00, 52.78it/s, Epoch: 78, Batch: 102,Loss: -2.941,Avg.Loss: -2.839,LR: 5.91E-05]Training epoch 78:  67%|██████▋   | 102/153 [00:01<00:00, 52.94it/s, Epoch: 78, Batch: 102,Loss: -2.941,Avg.Loss: -2.839,LR: 5.91E-05]Training epoch 78:  67%|██████▋   | 102/153 [00:01<00:00, 52.94it/s, Epoch: 78, Batch: 103,Loss: -2.583,Avg.Loss: -2.836,LR: 5.90E-05]Training epoch 78:  67%|██████▋   | 103/153 [00:01<00:00, 52.94it/s, Epoch: 78, Batch: 104,Loss: -2.993,Avg.Loss: -2.838,LR: 5.90E-05]Training epoch 78:  68%|██████▊   | 104/153 [00:01<00:00, 52.94it/s, Epoch: 78, Batch: 105,Loss: -2.846,Avg.Loss: -2.838,LR: 5.90E-05]Training epoch 78:  69%|██████▊   | 105/153 [00:01<00:00, 52.94it/s, Epoch: 78, Batch: 106,Loss: -2.867,Avg.Loss: -2.838,LR: 5.89E-05]Training epoch 78:  69%|██████▉   | 106/153 [00:02<00:00, 52.94it/s, Epoch: 78, Batch: 107,Loss: -2.992,Avg.Loss: -2.839,LR: 5.89E-05]Training epoch 78:  70%|██████▉   | 107/153 [00:02<00:00, 52.94it/s, Epoch: 78, Batch: 108,Loss: -3.314,Avg.Loss: -2.844,LR: 5.89E-05]Training epoch 78:  71%|███████   | 108/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 108,Loss: -3.314,Avg.Loss: -2.844,LR: 5.89E-05]Training epoch 78:  71%|███████   | 108/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 109,Loss: -2.918,Avg.Loss: -2.844,LR: 5.88E-05]Training epoch 78:  71%|███████   | 109/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 110,Loss: -2.914,Avg.Loss: -2.845,LR: 5.88E-05]Training epoch 78:  72%|███████▏  | 110/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 111,Loss: -2.798,Avg.Loss: -2.845,LR: 5.88E-05]Training epoch 78:  73%|███████▎  | 111/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 112,Loss: -2.802,Avg.Loss: -2.844,LR: 5.87E-05]Training epoch 78:  73%|███████▎  | 112/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 113,Loss: -3.328,Avg.Loss: -2.849,LR: 5.87E-05]Training epoch 78:  74%|███████▍  | 113/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 114,Loss: -3.106,Avg.Loss: -2.851,LR: 5.87E-05]Training epoch 78:  75%|███████▍  | 114/153 [00:02<00:00, 53.03it/s, Epoch: 78, Batch: 114,Loss: -3.106,Avg.Loss: -2.851,LR: 5.87E-05]Training epoch 78:  75%|███████▍  | 114/153 [00:02<00:00, 53.03it/s, Epoch: 78, Batch: 115,Loss: -2.984,Avg.Loss: -2.852,LR: 5.86E-05]Training epoch 78:  75%|███████▌  | 115/153 [00:02<00:00, 53.03it/s, Epoch: 78, Batch: 116,Loss: -2.951,Avg.Loss: -2.853,LR: 5.86E-05]Training epoch 78:  76%|███████▌  | 116/153 [00:02<00:00, 53.03it/s, Epoch: 78, Batch: 117,Loss: -3.115,Avg.Loss: -2.855,LR: 5.86E-05]Training epoch 78:  76%|███████▋  | 117/153 [00:02<00:00, 53.03it/s, Epoch: 78, Batch: 118,Loss: -2.632,Avg.Loss: -2.853,LR: 5.85E-05]Training epoch 78:  77%|███████▋  | 118/153 [00:02<00:00, 53.03it/s, Epoch: 78, Batch: 119,Loss: -3.328,Avg.Loss: -2.857,LR: 5.85E-05]Training epoch 78:  78%|███████▊  | 119/153 [00:02<00:00, 53.03it/s, Epoch: 78, Batch: 120,Loss: -3.348,Avg.Loss: -2.861,LR: 5.85E-05]Training epoch 78:  78%|███████▊  | 120/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 120,Loss: -3.348,Avg.Loss: -2.861,LR: 5.85E-05]Training epoch 78:  78%|███████▊  | 120/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 121,Loss: -2.890,Avg.Loss: -2.862,LR: 5.84E-05]Training epoch 78:  79%|███████▉  | 121/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 122,Loss: -2.951,Avg.Loss: -2.862,LR: 5.84E-05]Training epoch 78:  80%|███████▉  | 122/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 123,Loss: -2.682,Avg.Loss: -2.861,LR: 5.84E-05]Training epoch 78:  80%|████████  | 123/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 124,Loss: -3.192,Avg.Loss: -2.863,LR: 5.83E-05]Training epoch 78:  81%|████████  | 124/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 125,Loss: -2.769,Avg.Loss: -2.863,LR: 5.83E-05]Training epoch 78:  82%|████████▏ | 125/153 [00:02<00:00, 53.07it/s, Epoch: 78, Batch: 126,Loss: -2.648,Avg.Loss: -2.861,LR: 5.83E-05]Training epoch 78:  82%|████████▏ | 126/153 [00:02<00:00, 53.13it/s, Epoch: 78, Batch: 126,Loss: -2.648,Avg.Loss: -2.861,LR: 5.83E-05]Training epoch 78:  82%|████████▏ | 126/153 [00:02<00:00, 53.13it/s, Epoch: 78, Batch: 127,Loss: -2.957,Avg.Loss: -2.862,LR: 5.82E-05]Training epoch 78:  83%|████████▎ | 127/153 [00:02<00:00, 53.13it/s, Epoch: 78, Batch: 128,Loss: -3.234,Avg.Loss: -2.865,LR: 5.82E-05]Training epoch 78:  84%|████████▎ | 128/153 [00:02<00:00, 53.13it/s, Epoch: 78, Batch: 129,Loss: -2.548,Avg.Loss: -2.862,LR: 5.82E-05]Training epoch 78:  84%|████████▍ | 129/153 [00:02<00:00, 53.13it/s, Epoch: 78, Batch: 130,Loss: -3.191,Avg.Loss: -2.865,LR: 5.81E-05]Training epoch 78:  85%|████████▍ | 130/153 [00:02<00:00, 53.13it/s, Epoch: 78, Batch: 131,Loss: -2.958,Avg.Loss: -2.865,LR: 5.81E-05]Training epoch 78:  86%|████████▌ | 131/153 [00:02<00:00, 53.13it/s, Epoch: 78, Batch: 132,Loss: -2.802,Avg.Loss: -2.865,LR: 5.81E-05]Training epoch 78:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 78, Batch: 132,Loss: -2.802,Avg.Loss: -2.865,LR: 5.81E-05]Training epoch 78:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 78, Batch: 133,Loss: -2.968,Avg.Loss: -2.866,LR: 5.80E-05]Training epoch 78:  87%|████████▋ | 133/153 [00:02<00:00, 53.28it/s, Epoch: 78, Batch: 134,Loss: -2.842,Avg.Loss: -2.866,LR: 5.80E-05]Training epoch 78:  88%|████████▊ | 134/153 [00:02<00:00, 53.28it/s, Epoch: 78, Batch: 135,Loss: -3.101,Avg.Loss: -2.867,LR: 5.80E-05]Training epoch 78:  88%|████████▊ | 135/153 [00:02<00:00, 53.28it/s, Epoch: 78, Batch: 136,Loss: -3.246,Avg.Loss: -2.870,LR: 5.79E-05]Training epoch 78:  89%|████████▉ | 136/153 [00:02<00:00, 53.28it/s, Epoch: 78, Batch: 137,Loss: -2.326,Avg.Loss: -2.866,LR: 5.79E-05]Training epoch 78:  90%|████████▉ | 137/153 [00:02<00:00, 53.28it/s, Epoch: 78, Batch: 138,Loss: -2.703,Avg.Loss: -2.865,LR: 5.79E-05]Training epoch 78:  90%|█████████ | 138/153 [00:02<00:00, 52.92it/s, Epoch: 78, Batch: 138,Loss: -2.703,Avg.Loss: -2.865,LR: 5.79E-05]Training epoch 78:  90%|█████████ | 138/153 [00:02<00:00, 52.92it/s, Epoch: 78, Batch: 139,Loss: -2.897,Avg.Loss: -2.865,LR: 5.78E-05]Training epoch 78:  91%|█████████ | 139/153 [00:02<00:00, 52.92it/s, Epoch: 78, Batch: 140,Loss: -2.945,Avg.Loss: -2.866,LR: 5.78E-05]Training epoch 78:  92%|█████████▏| 140/153 [00:02<00:00, 52.92it/s, Epoch: 78, Batch: 141,Loss: -2.789,Avg.Loss: -2.865,LR: 5.78E-05]Training epoch 78:  92%|█████████▏| 141/153 [00:02<00:00, 52.92it/s, Epoch: 78, Batch: 142,Loss: -3.168,Avg.Loss: -2.867,LR: 5.77E-05]Training epoch 78:  93%|█████████▎| 142/153 [00:02<00:00, 52.92it/s, Epoch: 78, Batch: 143,Loss: -2.790,Avg.Loss: -2.867,LR: 5.77E-05]Training epoch 78:  93%|█████████▎| 143/153 [00:02<00:00, 52.92it/s, Epoch: 78, Batch: 144,Loss: -2.967,Avg.Loss: -2.868,LR: 5.77E-05]Training epoch 78:  94%|█████████▍| 144/153 [00:02<00:00, 52.93it/s, Epoch: 78, Batch: 144,Loss: -2.967,Avg.Loss: -2.868,LR: 5.77E-05]Training epoch 78:  94%|█████████▍| 144/153 [00:02<00:00, 52.93it/s, Epoch: 78, Batch: 145,Loss: -3.050,Avg.Loss: -2.869,LR: 5.76E-05]Training epoch 78:  95%|█████████▍| 145/153 [00:02<00:00, 52.93it/s, Epoch: 78, Batch: 146,Loss: -3.054,Avg.Loss: -2.870,LR: 5.76E-05]Training epoch 78:  95%|█████████▌| 146/153 [00:02<00:00, 52.93it/s, Epoch: 78, Batch: 147,Loss: -3.061,Avg.Loss: -2.871,LR: 5.76E-05]Training epoch 78:  96%|█████████▌| 147/153 [00:02<00:00, 52.93it/s, Epoch: 78, Batch: 148,Loss: -3.398,Avg.Loss: -2.875,LR: 5.75E-05]Training epoch 78:  97%|█████████▋| 148/153 [00:02<00:00, 52.93it/s, Epoch: 78, Batch: 149,Loss: -2.762,Avg.Loss: -2.874,LR: 5.75E-05]Training epoch 78:  97%|█████████▋| 149/153 [00:02<00:00, 52.93it/s, Epoch: 78, Batch: 150,Loss: -2.957,Avg.Loss: -2.875,LR: 5.75E-05]Training epoch 78:  98%|█████████▊| 150/153 [00:02<00:00, 52.94it/s, Epoch: 78, Batch: 150,Loss: -2.957,Avg.Loss: -2.875,LR: 5.75E-05]Training epoch 78:  98%|█████████▊| 150/153 [00:02<00:00, 52.94it/s, Epoch: 78, Batch: 151,Loss: -2.943,Avg.Loss: -2.875,LR: 5.74E-05]Training epoch 78:  99%|█████████▊| 151/153 [00:02<00:00, 52.94it/s, Epoch: 78, Batch: 152,Loss: -2.680,Avg.Loss: -2.874,LR: 5.74E-05]Training epoch 78:  99%|█████████▉| 152/153 [00:02<00:00, 52.94it/s, Epoch: 78, Batch: 153,Loss: -2.388,Avg.Loss: -2.871,LR: 5.74E-05]Training epoch 78: 100%|██████████| 153/153 [00:02<00:00, 53.04it/s, Epoch: 78, Batch: 153,Loss: -2.388,Avg.Loss: -2.871,LR: 5.74E-05]
Training epoch 79:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 79:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 79, Batch: 1,Loss: -2.959,Avg.Loss: -2.959,LR: 5.73E-05]Training epoch 79:   1%|          | 1/153 [00:00<00:05, 27.90it/s, Epoch: 79, Batch: 2,Loss: -3.264,Avg.Loss: -3.112,LR: 5.73E-05]Training epoch 79:   1%|▏         | 2/153 [00:00<00:03, 40.98it/s, Epoch: 79, Batch: 3,Loss: -2.843,Avg.Loss: -3.022,LR: 5.73E-05]Training epoch 79:   2%|▏         | 3/153 [00:00<00:03, 45.62it/s, Epoch: 79, Batch: 4,Loss: -2.931,Avg.Loss: -2.999,LR: 5.72E-05]Training epoch 79:   3%|▎         | 4/153 [00:00<00:03, 48.12it/s, Epoch: 79, Batch: 5,Loss: -3.129,Avg.Loss: -3.025,LR: 5.72E-05]Training epoch 79:   3%|▎         | 5/153 [00:00<00:02, 49.41it/s, Epoch: 79, Batch: 6,Loss: -2.715,Avg.Loss: -2.973,LR: 5.72E-05]Training epoch 79:   4%|▍         | 6/153 [00:00<00:02, 59.17it/s, Epoch: 79, Batch: 6,Loss: -2.715,Avg.Loss: -2.973,LR: 5.72E-05]Training epoch 79:   4%|▍         | 6/153 [00:00<00:02, 59.17it/s, Epoch: 79, Batch: 7,Loss: -2.934,Avg.Loss: -2.968,LR: 5.71E-05]Training epoch 79:   5%|▍         | 7/153 [00:00<00:02, 59.17it/s, Epoch: 79, Batch: 8,Loss: -3.111,Avg.Loss: -2.986,LR: 5.71E-05]Training epoch 79:   5%|▌         | 8/153 [00:00<00:02, 59.17it/s, Epoch: 79, Batch: 9,Loss: -2.844,Avg.Loss: -2.970,LR: 5.71E-05]Training epoch 79:   6%|▌         | 9/153 [00:00<00:02, 59.17it/s, Epoch: 79, Batch: 10,Loss: -2.565,Avg.Loss: -2.929,LR: 5.70E-05]Training epoch 79:   7%|▋         | 10/153 [00:00<00:02, 59.17it/s, Epoch: 79, Batch: 11,Loss: -2.496,Avg.Loss: -2.890,LR: 5.70E-05]Training epoch 79:   7%|▋         | 11/153 [00:00<00:02, 59.17it/s, Epoch: 79, Batch: 12,Loss: -2.756,Avg.Loss: -2.879,LR: 5.70E-05]Training epoch 79:   8%|▊         | 12/153 [00:00<00:02, 55.32it/s, Epoch: 79, Batch: 12,Loss: -2.756,Avg.Loss: -2.879,LR: 5.70E-05]Training epoch 79:   8%|▊         | 12/153 [00:00<00:02, 55.32it/s, Epoch: 79, Batch: 13,Loss: -2.355,Avg.Loss: -2.839,LR: 5.69E-05]Training epoch 79:   8%|▊         | 13/153 [00:00<00:02, 55.32it/s, Epoch: 79, Batch: 14,Loss: -3.128,Avg.Loss: -2.859,LR: 5.69E-05]Training epoch 79:   9%|▉         | 14/153 [00:00<00:02, 55.32it/s, Epoch: 79, Batch: 15,Loss: -3.013,Avg.Loss: -2.869,LR: 5.69E-05]Training epoch 79:  10%|▉         | 15/153 [00:00<00:02, 55.32it/s, Epoch: 79, Batch: 16,Loss: -3.121,Avg.Loss: -2.885,LR: 5.68E-05]Training epoch 79:  10%|█         | 16/153 [00:00<00:02, 55.32it/s, Epoch: 79, Batch: 17,Loss: -2.626,Avg.Loss: -2.870,LR: 5.68E-05]Training epoch 79:  11%|█         | 17/153 [00:00<00:02, 55.32it/s, Epoch: 79, Batch: 18,Loss: -3.130,Avg.Loss: -2.884,LR: 5.68E-05]Training epoch 79:  12%|█▏        | 18/153 [00:00<00:02, 54.14it/s, Epoch: 79, Batch: 18,Loss: -3.130,Avg.Loss: -2.884,LR: 5.68E-05]Training epoch 79:  12%|█▏        | 18/153 [00:00<00:02, 54.14it/s, Epoch: 79, Batch: 19,Loss: -3.054,Avg.Loss: -2.893,LR: 5.68E-05]Training epoch 79:  12%|█▏        | 19/153 [00:00<00:02, 54.14it/s, Epoch: 79, Batch: 20,Loss: -2.817,Avg.Loss: -2.890,LR: 5.67E-05]Training epoch 79:  13%|█▎        | 20/153 [00:00<00:02, 54.14it/s, Epoch: 79, Batch: 21,Loss: -2.739,Avg.Loss: -2.882,LR: 5.67E-05]Training epoch 79:  14%|█▎        | 21/153 [00:00<00:02, 54.14it/s, Epoch: 79, Batch: 22,Loss: -3.300,Avg.Loss: -2.901,LR: 5.67E-05]Training epoch 79:  14%|█▍        | 22/153 [00:00<00:02, 54.14it/s, Epoch: 79, Batch: 23,Loss: -2.499,Avg.Loss: -2.884,LR: 5.66E-05]Training epoch 79:  15%|█▌        | 23/153 [00:00<00:02, 54.14it/s, Epoch: 79, Batch: 24,Loss: -2.584,Avg.Loss: -2.871,LR: 5.66E-05]Training epoch 79:  16%|█▌        | 24/153 [00:00<00:02, 52.06it/s, Epoch: 79, Batch: 24,Loss: -2.584,Avg.Loss: -2.871,LR: 5.66E-05]Training epoch 79:  16%|█▌        | 24/153 [00:00<00:02, 52.06it/s, Epoch: 79, Batch: 25,Loss: -2.821,Avg.Loss: -2.869,LR: 5.66E-05]Training epoch 79:  16%|█▋        | 25/153 [00:00<00:02, 52.06it/s, Epoch: 79, Batch: 26,Loss: -2.929,Avg.Loss: -2.872,LR: 5.65E-05]Training epoch 79:  17%|█▋        | 26/153 [00:00<00:02, 52.06it/s, Epoch: 79, Batch: 27,Loss: -2.649,Avg.Loss: -2.863,LR: 5.65E-05]Training epoch 79:  18%|█▊        | 27/153 [00:00<00:02, 52.06it/s, Epoch: 79, Batch: 28,Loss: -2.784,Avg.Loss: -2.861,LR: 5.65E-05]Training epoch 79:  18%|█▊        | 28/153 [00:00<00:02, 52.06it/s, Epoch: 79, Batch: 29,Loss: -3.008,Avg.Loss: -2.866,LR: 5.64E-05]Training epoch 79:  19%|█▉        | 29/153 [00:00<00:02, 52.06it/s, Epoch: 79, Batch: 30,Loss: -2.968,Avg.Loss: -2.869,LR: 5.64E-05]Training epoch 79:  20%|█▉        | 30/153 [00:00<00:02, 50.41it/s, Epoch: 79, Batch: 30,Loss: -2.968,Avg.Loss: -2.869,LR: 5.64E-05]Training epoch 79:  20%|█▉        | 30/153 [00:00<00:02, 50.41it/s, Epoch: 79, Batch: 31,Loss: -3.063,Avg.Loss: -2.875,LR: 5.64E-05]Training epoch 79:  20%|██        | 31/153 [00:00<00:02, 50.41it/s, Epoch: 79, Batch: 32,Loss: -3.060,Avg.Loss: -2.881,LR: 5.63E-05]Training epoch 79:  21%|██        | 32/153 [00:00<00:02, 50.41it/s, Epoch: 79, Batch: 33,Loss: -2.203,Avg.Loss: -2.861,LR: 5.63E-05]Training epoch 79:  22%|██▏       | 33/153 [00:00<00:02, 50.41it/s, Epoch: 79, Batch: 34,Loss: -2.636,Avg.Loss: -2.854,LR: 5.63E-05]Training epoch 79:  22%|██▏       | 34/153 [00:00<00:02, 50.41it/s, Epoch: 79, Batch: 35,Loss: -2.698,Avg.Loss: -2.849,LR: 5.62E-05]Training epoch 79:  23%|██▎       | 35/153 [00:00<00:02, 50.41it/s, Epoch: 79, Batch: 36,Loss: -3.032,Avg.Loss: -2.855,LR: 5.62E-05]Training epoch 79:  24%|██▎       | 36/153 [00:00<00:02, 50.94it/s, Epoch: 79, Batch: 36,Loss: -3.032,Avg.Loss: -2.855,LR: 5.62E-05]Training epoch 79:  24%|██▎       | 36/153 [00:00<00:02, 50.94it/s, Epoch: 79, Batch: 37,Loss: -2.788,Avg.Loss: -2.853,LR: 5.62E-05]Training epoch 79:  24%|██▍       | 37/153 [00:00<00:02, 50.94it/s, Epoch: 79, Batch: 38,Loss: -3.295,Avg.Loss: -2.864,LR: 5.61E-05]Training epoch 79:  25%|██▍       | 38/153 [00:00<00:02, 50.94it/s, Epoch: 79, Batch: 39,Loss: -2.254,Avg.Loss: -2.849,LR: 5.61E-05]Training epoch 79:  25%|██▌       | 39/153 [00:00<00:02, 50.94it/s, Epoch: 79, Batch: 40,Loss: -2.583,Avg.Loss: -2.842,LR: 5.61E-05]Training epoch 79:  26%|██▌       | 40/153 [00:00<00:02, 50.94it/s, Epoch: 79, Batch: 41,Loss: -2.777,Avg.Loss: -2.841,LR: 5.60E-05]Training epoch 79:  27%|██▋       | 41/153 [00:00<00:02, 50.94it/s, Epoch: 79, Batch: 42,Loss: -2.920,Avg.Loss: -2.842,LR: 5.60E-05]Training epoch 79:  27%|██▋       | 42/153 [00:00<00:02, 51.48it/s, Epoch: 79, Batch: 42,Loss: -2.920,Avg.Loss: -2.842,LR: 5.60E-05]Training epoch 79:  27%|██▋       | 42/153 [00:00<00:02, 51.48it/s, Epoch: 79, Batch: 43,Loss: -3.382,Avg.Loss: -2.855,LR: 5.60E-05]Training epoch 79:  28%|██▊       | 43/153 [00:00<00:02, 51.48it/s, Epoch: 79, Batch: 44,Loss: -3.186,Avg.Loss: -2.862,LR: 5.59E-05]Training epoch 79:  29%|██▉       | 44/153 [00:00<00:02, 51.48it/s, Epoch: 79, Batch: 45,Loss: -3.204,Avg.Loss: -2.870,LR: 5.59E-05]Training epoch 79:  29%|██▉       | 45/153 [00:00<00:02, 51.48it/s, Epoch: 79, Batch: 46,Loss: -2.877,Avg.Loss: -2.870,LR: 5.59E-05]Training epoch 79:  30%|███       | 46/153 [00:00<00:02, 51.48it/s, Epoch: 79, Batch: 47,Loss: -3.410,Avg.Loss: -2.882,LR: 5.58E-05]Training epoch 79:  31%|███       | 47/153 [00:00<00:02, 51.48it/s, Epoch: 79, Batch: 48,Loss: -2.832,Avg.Loss: -2.881,LR: 5.58E-05]Training epoch 79:  31%|███▏      | 48/153 [00:00<00:02, 52.13it/s, Epoch: 79, Batch: 48,Loss: -2.832,Avg.Loss: -2.881,LR: 5.58E-05]Training epoch 79:  31%|███▏      | 48/153 [00:00<00:02, 52.13it/s, Epoch: 79, Batch: 49,Loss: -2.982,Avg.Loss: -2.883,LR: 5.58E-05]Training epoch 79:  32%|███▏      | 49/153 [00:00<00:01, 52.13it/s, Epoch: 79, Batch: 50,Loss: -2.310,Avg.Loss: -2.871,LR: 5.57E-05]Training epoch 79:  33%|███▎      | 50/153 [00:00<00:01, 52.13it/s, Epoch: 79, Batch: 51,Loss: -2.919,Avg.Loss: -2.872,LR: 5.57E-05]Training epoch 79:  33%|███▎      | 51/153 [00:00<00:01, 52.13it/s, Epoch: 79, Batch: 52,Loss: -2.779,Avg.Loss: -2.870,LR: 5.57E-05]Training epoch 79:  34%|███▍      | 52/153 [00:01<00:01, 52.13it/s, Epoch: 79, Batch: 53,Loss: -3.055,Avg.Loss: -2.874,LR: 5.56E-05]Training epoch 79:  35%|███▍      | 53/153 [00:01<00:01, 52.13it/s, Epoch: 79, Batch: 54,Loss: -2.626,Avg.Loss: -2.869,LR: 5.56E-05]Training epoch 79:  35%|███▌      | 54/153 [00:01<00:01, 52.24it/s, Epoch: 79, Batch: 54,Loss: -2.626,Avg.Loss: -2.869,LR: 5.56E-05]Training epoch 79:  35%|███▌      | 54/153 [00:01<00:01, 52.24it/s, Epoch: 79, Batch: 55,Loss: -2.774,Avg.Loss: -2.868,LR: 5.56E-05]Training epoch 79:  36%|███▌      | 55/153 [00:01<00:01, 52.24it/s, Epoch: 79, Batch: 56,Loss: -2.680,Avg.Loss: -2.864,LR: 5.56E-05]Training epoch 79:  37%|███▋      | 56/153 [00:01<00:01, 52.24it/s, Epoch: 79, Batch: 57,Loss: -2.706,Avg.Loss: -2.862,LR: 5.55E-05]Training epoch 79:  37%|███▋      | 57/153 [00:01<00:01, 52.24it/s, Epoch: 79, Batch: 58,Loss: -2.900,Avg.Loss: -2.862,LR: 5.55E-05]Training epoch 79:  38%|███▊      | 58/153 [00:01<00:01, 52.24it/s, Epoch: 79, Batch: 59,Loss: -3.089,Avg.Loss: -2.866,LR: 5.55E-05]Training epoch 79:  39%|███▊      | 59/153 [00:01<00:01, 52.24it/s, Epoch: 79, Batch: 60,Loss: -2.923,Avg.Loss: -2.867,LR: 5.54E-05]Training epoch 79:  39%|███▉      | 60/153 [00:01<00:01, 52.36it/s, Epoch: 79, Batch: 60,Loss: -2.923,Avg.Loss: -2.867,LR: 5.54E-05]Training epoch 79:  39%|███▉      | 60/153 [00:01<00:01, 52.36it/s, Epoch: 79, Batch: 61,Loss: -2.715,Avg.Loss: -2.864,LR: 5.54E-05]Training epoch 79:  40%|███▉      | 61/153 [00:01<00:01, 52.36it/s, Epoch: 79, Batch: 62,Loss: -2.612,Avg.Loss: -2.860,LR: 5.54E-05]Training epoch 79:  41%|████      | 62/153 [00:01<00:01, 52.36it/s, Epoch: 79, Batch: 63,Loss: -2.822,Avg.Loss: -2.860,LR: 5.53E-05]Training epoch 79:  41%|████      | 63/153 [00:01<00:01, 52.36it/s, Epoch: 79, Batch: 64,Loss: -3.175,Avg.Loss: -2.865,LR: 5.53E-05]Training epoch 79:  42%|████▏     | 64/153 [00:01<00:01, 52.36it/s, Epoch: 79, Batch: 65,Loss: -2.708,Avg.Loss: -2.862,LR: 5.53E-05]Training epoch 79:  42%|████▏     | 65/153 [00:01<00:01, 52.36it/s, Epoch: 79, Batch: 66,Loss: -3.390,Avg.Loss: -2.870,LR: 5.52E-05]Training epoch 79:  43%|████▎     | 66/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 66,Loss: -3.390,Avg.Loss: -2.870,LR: 5.52E-05]Training epoch 79:  43%|████▎     | 66/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 67,Loss: -2.658,Avg.Loss: -2.867,LR: 5.52E-05]Training epoch 79:  44%|████▍     | 67/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 68,Loss: -2.933,Avg.Loss: -2.868,LR: 5.52E-05]Training epoch 79:  44%|████▍     | 68/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 69,Loss: -3.113,Avg.Loss: -2.872,LR: 5.51E-05]Training epoch 79:  45%|████▌     | 69/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 70,Loss: -2.586,Avg.Loss: -2.868,LR: 5.51E-05]Training epoch 79:  46%|████▌     | 70/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 71,Loss: -2.744,Avg.Loss: -2.866,LR: 5.51E-05]Training epoch 79:  46%|████▋     | 71/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 72,Loss: -2.598,Avg.Loss: -2.862,LR: 5.50E-05]Training epoch 79:  47%|████▋     | 72/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 72,Loss: -2.598,Avg.Loss: -2.862,LR: 5.50E-05]Training epoch 79:  47%|████▋     | 72/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 73,Loss: -3.052,Avg.Loss: -2.865,LR: 5.50E-05]Training epoch 79:  48%|████▊     | 73/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 74,Loss: -3.332,Avg.Loss: -2.871,LR: 5.50E-05]Training epoch 79:  48%|████▊     | 74/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 75,Loss: -2.924,Avg.Loss: -2.872,LR: 5.49E-05]Training epoch 79:  49%|████▉     | 75/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 76,Loss: -3.372,Avg.Loss: -2.878,LR: 5.49E-05]Training epoch 79:  50%|████▉     | 76/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 77,Loss: -2.804,Avg.Loss: -2.877,LR: 5.49E-05]Training epoch 79:  50%|█████     | 77/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 78,Loss: -2.737,Avg.Loss: -2.876,LR: 5.48E-05]Training epoch 79:  51%|█████     | 78/153 [00:01<00:01, 52.64it/s, Epoch: 79, Batch: 78,Loss: -2.737,Avg.Loss: -2.876,LR: 5.48E-05]Training epoch 79:  51%|█████     | 78/153 [00:01<00:01, 52.64it/s, Epoch: 79, Batch: 79,Loss: -2.781,Avg.Loss: -2.874,LR: 5.48E-05]Training epoch 79:  52%|█████▏    | 79/153 [00:01<00:01, 52.64it/s, Epoch: 79, Batch: 80,Loss: -2.881,Avg.Loss: -2.874,LR: 5.48E-05]Training epoch 79:  52%|█████▏    | 80/153 [00:01<00:01, 52.64it/s, Epoch: 79, Batch: 81,Loss: -3.388,Avg.Loss: -2.881,LR: 5.47E-05]Training epoch 79:  53%|█████▎    | 81/153 [00:01<00:01, 52.64it/s, Epoch: 79, Batch: 82,Loss: -2.879,Avg.Loss: -2.881,LR: 5.47E-05]Training epoch 79:  54%|█████▎    | 82/153 [00:01<00:01, 52.64it/s, Epoch: 79, Batch: 83,Loss: -2.998,Avg.Loss: -2.882,LR: 5.47E-05]Training epoch 79:  54%|█████▍    | 83/153 [00:01<00:01, 52.64it/s, Epoch: 79, Batch: 84,Loss: -2.962,Avg.Loss: -2.883,LR: 5.47E-05]Training epoch 79:  55%|█████▍    | 84/153 [00:01<00:01, 52.68it/s, Epoch: 79, Batch: 84,Loss: -2.962,Avg.Loss: -2.883,LR: 5.47E-05]Training epoch 79:  55%|█████▍    | 84/153 [00:01<00:01, 52.68it/s, Epoch: 79, Batch: 85,Loss: -2.826,Avg.Loss: -2.882,LR: 5.46E-05]Training epoch 79:  56%|█████▌    | 85/153 [00:01<00:01, 52.68it/s, Epoch: 79, Batch: 86,Loss: -3.159,Avg.Loss: -2.886,LR: 5.46E-05]Training epoch 79:  56%|█████▌    | 86/153 [00:01<00:01, 52.68it/s, Epoch: 79, Batch: 87,Loss: -2.894,Avg.Loss: -2.886,LR: 5.46E-05]Training epoch 79:  57%|█████▋    | 87/153 [00:01<00:01, 52.68it/s, Epoch: 79, Batch: 88,Loss: -2.820,Avg.Loss: -2.885,LR: 5.45E-05]Training epoch 79:  58%|█████▊    | 88/153 [00:01<00:01, 52.68it/s, Epoch: 79, Batch: 89,Loss: -2.450,Avg.Loss: -2.880,LR: 5.45E-05]Training epoch 79:  58%|█████▊    | 89/153 [00:01<00:01, 52.68it/s, Epoch: 79, Batch: 90,Loss: -2.678,Avg.Loss: -2.878,LR: 5.45E-05]Training epoch 79:  59%|█████▉    | 90/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 90,Loss: -2.678,Avg.Loss: -2.878,LR: 5.45E-05]Training epoch 79:  59%|█████▉    | 90/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 91,Loss: -2.679,Avg.Loss: -2.876,LR: 5.44E-05]Training epoch 79:  59%|█████▉    | 91/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 92,Loss: -3.121,Avg.Loss: -2.878,LR: 5.44E-05]Training epoch 79:  60%|██████    | 92/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 93,Loss: -2.916,Avg.Loss: -2.879,LR: 5.44E-05]Training epoch 79:  61%|██████    | 93/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 94,Loss: -2.673,Avg.Loss: -2.877,LR: 5.43E-05]Training epoch 79:  61%|██████▏   | 94/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 95,Loss: -3.036,Avg.Loss: -2.878,LR: 5.43E-05]Training epoch 79:  62%|██████▏   | 95/153 [00:01<00:01, 52.67it/s, Epoch: 79, Batch: 96,Loss: -2.869,Avg.Loss: -2.878,LR: 5.43E-05]Training epoch 79:  63%|██████▎   | 96/153 [00:01<00:01, 52.99it/s, Epoch: 79, Batch: 96,Loss: -2.869,Avg.Loss: -2.878,LR: 5.43E-05]Training epoch 79:  63%|██████▎   | 96/153 [00:01<00:01, 52.99it/s, Epoch: 79, Batch: 97,Loss: -2.668,Avg.Loss: -2.876,LR: 5.42E-05]Training epoch 79:  63%|██████▎   | 97/153 [00:01<00:01, 52.99it/s, Epoch: 79, Batch: 98,Loss: -2.695,Avg.Loss: -2.874,LR: 5.42E-05]Training epoch 79:  64%|██████▍   | 98/153 [00:01<00:01, 52.99it/s, Epoch: 79, Batch: 99,Loss: -2.255,Avg.Loss: -2.868,LR: 5.42E-05]Training epoch 79:  65%|██████▍   | 99/153 [00:01<00:01, 52.99it/s, Epoch: 79, Batch: 100,Loss: -3.134,Avg.Loss: -2.871,LR: 5.41E-05]Training epoch 79:  65%|██████▌   | 100/153 [00:01<00:01, 52.99it/s, Epoch: 79, Batch: 101,Loss: -2.093,Avg.Loss: -2.863,LR: 5.41E-05]Training epoch 79:  66%|██████▌   | 101/153 [00:01<00:00, 52.99it/s, Epoch: 79, Batch: 102,Loss: -2.800,Avg.Loss: -2.862,LR: 5.41E-05]Training epoch 79:  67%|██████▋   | 102/153 [00:01<00:00, 53.06it/s, Epoch: 79, Batch: 102,Loss: -2.800,Avg.Loss: -2.862,LR: 5.41E-05]Training epoch 79:  67%|██████▋   | 102/153 [00:01<00:00, 53.06it/s, Epoch: 79, Batch: 103,Loss: -3.067,Avg.Loss: -2.864,LR: 5.40E-05]Training epoch 79:  67%|██████▋   | 103/153 [00:01<00:00, 53.06it/s, Epoch: 79, Batch: 104,Loss: -2.934,Avg.Loss: -2.865,LR: 5.40E-05]Training epoch 79:  68%|██████▊   | 104/153 [00:01<00:00, 53.06it/s, Epoch: 79, Batch: 105,Loss: -2.775,Avg.Loss: -2.864,LR: 5.40E-05]Training epoch 79:  69%|██████▊   | 105/153 [00:02<00:00, 53.06it/s, Epoch: 79, Batch: 106,Loss: -2.676,Avg.Loss: -2.862,LR: 5.39E-05]Training epoch 79:  69%|██████▉   | 106/153 [00:02<00:00, 53.06it/s, Epoch: 79, Batch: 107,Loss: -3.016,Avg.Loss: -2.864,LR: 5.39E-05]Training epoch 79:  70%|██████▉   | 107/153 [00:02<00:00, 53.06it/s, Epoch: 79, Batch: 108,Loss: -2.592,Avg.Loss: -2.861,LR: 5.39E-05]Training epoch 79:  71%|███████   | 108/153 [00:02<00:00, 52.95it/s, Epoch: 79, Batch: 108,Loss: -2.592,Avg.Loss: -2.861,LR: 5.39E-05]Training epoch 79:  71%|███████   | 108/153 [00:02<00:00, 52.95it/s, Epoch: 79, Batch: 109,Loss: -2.945,Avg.Loss: -2.862,LR: 5.39E-05]Training epoch 79:  71%|███████   | 109/153 [00:02<00:00, 52.95it/s, Epoch: 79, Batch: 110,Loss: -2.906,Avg.Loss: -2.862,LR: 5.38E-05]Training epoch 79:  72%|███████▏  | 110/153 [00:02<00:00, 52.95it/s, Epoch: 79, Batch: 111,Loss: -2.594,Avg.Loss: -2.860,LR: 5.38E-05]Training epoch 79:  73%|███████▎  | 111/153 [00:02<00:00, 52.95it/s, Epoch: 79, Batch: 112,Loss: -2.725,Avg.Loss: -2.859,LR: 5.38E-05]Training epoch 79:  73%|███████▎  | 112/153 [00:02<00:00, 52.95it/s, Epoch: 79, Batch: 113,Loss: -2.879,Avg.Loss: -2.859,LR: 5.37E-05]Training epoch 79:  74%|███████▍  | 113/153 [00:02<00:00, 52.95it/s, Epoch: 79, Batch: 114,Loss: -2.631,Avg.Loss: -2.857,LR: 5.37E-05]Training epoch 79:  75%|███████▍  | 114/153 [00:02<00:00, 53.15it/s, Epoch: 79, Batch: 114,Loss: -2.631,Avg.Loss: -2.857,LR: 5.37E-05]Training epoch 79:  75%|███████▍  | 114/153 [00:02<00:00, 53.15it/s, Epoch: 79, Batch: 115,Loss: -2.929,Avg.Loss: -2.858,LR: 5.37E-05]Training epoch 79:  75%|███████▌  | 115/153 [00:02<00:00, 53.15it/s, Epoch: 79, Batch: 116,Loss: -2.733,Avg.Loss: -2.856,LR: 5.36E-05]Training epoch 79:  76%|███████▌  | 116/153 [00:02<00:00, 53.15it/s, Epoch: 79, Batch: 117,Loss: -3.199,Avg.Loss: -2.859,LR: 5.36E-05]Training epoch 79:  76%|███████▋  | 117/153 [00:02<00:00, 53.15it/s, Epoch: 79, Batch: 118,Loss: -2.640,Avg.Loss: -2.858,LR: 5.36E-05]Training epoch 79:  77%|███████▋  | 118/153 [00:02<00:00, 53.15it/s, Epoch: 79, Batch: 119,Loss: -3.513,Avg.Loss: -2.863,LR: 5.35E-05]Training epoch 79:  78%|███████▊  | 119/153 [00:02<00:00, 53.15it/s, Epoch: 79, Batch: 120,Loss: -2.866,Avg.Loss: -2.863,LR: 5.35E-05]Training epoch 79:  78%|███████▊  | 120/153 [00:02<00:00, 53.12it/s, Epoch: 79, Batch: 120,Loss: -2.866,Avg.Loss: -2.863,LR: 5.35E-05]Training epoch 79:  78%|███████▊  | 120/153 [00:02<00:00, 53.12it/s, Epoch: 79, Batch: 121,Loss: -3.132,Avg.Loss: -2.865,LR: 5.35E-05]Training epoch 79:  79%|███████▉  | 121/153 [00:02<00:00, 53.12it/s, Epoch: 79, Batch: 122,Loss: -2.980,Avg.Loss: -2.866,LR: 5.34E-05]Training epoch 79:  80%|███████▉  | 122/153 [00:02<00:00, 53.12it/s, Epoch: 79, Batch: 123,Loss: -3.015,Avg.Loss: -2.867,LR: 5.34E-05]Training epoch 79:  80%|████████  | 123/153 [00:02<00:00, 53.12it/s, Epoch: 79, Batch: 124,Loss: -2.825,Avg.Loss: -2.867,LR: 5.34E-05]Training epoch 79:  81%|████████  | 124/153 [00:02<00:00, 53.12it/s, Epoch: 79, Batch: 125,Loss: -2.996,Avg.Loss: -2.868,LR: 5.33E-05]Training epoch 79:  82%|████████▏ | 125/153 [00:02<00:00, 53.12it/s, Epoch: 79, Batch: 126,Loss: -2.849,Avg.Loss: -2.868,LR: 5.33E-05]Training epoch 79:  82%|████████▏ | 126/153 [00:02<00:00, 53.20it/s, Epoch: 79, Batch: 126,Loss: -2.849,Avg.Loss: -2.868,LR: 5.33E-05]Training epoch 79:  82%|████████▏ | 126/153 [00:02<00:00, 53.20it/s, Epoch: 79, Batch: 127,Loss: -2.881,Avg.Loss: -2.868,LR: 5.33E-05]Training epoch 79:  83%|████████▎ | 127/153 [00:02<00:00, 53.20it/s, Epoch: 79, Batch: 128,Loss: -2.732,Avg.Loss: -2.867,LR: 5.33E-05]Training epoch 79:  84%|████████▎ | 128/153 [00:02<00:00, 53.20it/s, Epoch: 79, Batch: 129,Loss: -3.105,Avg.Loss: -2.869,LR: 5.32E-05]Training epoch 79:  84%|████████▍ | 129/153 [00:02<00:00, 53.20it/s, Epoch: 79, Batch: 130,Loss: -2.546,Avg.Loss: -2.866,LR: 5.32E-05]Training epoch 79:  85%|████████▍ | 130/153 [00:02<00:00, 53.20it/s, Epoch: 79, Batch: 131,Loss: -2.809,Avg.Loss: -2.866,LR: 5.32E-05]Training epoch 79:  86%|████████▌ | 131/153 [00:02<00:00, 53.20it/s, Epoch: 79, Batch: 132,Loss: -2.813,Avg.Loss: -2.866,LR: 5.31E-05]Training epoch 79:  86%|████████▋ | 132/153 [00:02<00:00, 53.07it/s, Epoch: 79, Batch: 132,Loss: -2.813,Avg.Loss: -2.866,LR: 5.31E-05]Training epoch 79:  86%|████████▋ | 132/153 [00:02<00:00, 53.07it/s, Epoch: 79, Batch: 133,Loss: -3.360,Avg.Loss: -2.869,LR: 5.31E-05]Training epoch 79:  87%|████████▋ | 133/153 [00:02<00:00, 53.07it/s, Epoch: 79, Batch: 134,Loss: -2.984,Avg.Loss: -2.870,LR: 5.31E-05]Training epoch 79:  88%|████████▊ | 134/153 [00:02<00:00, 53.07it/s, Epoch: 79, Batch: 135,Loss: -3.257,Avg.Loss: -2.873,LR: 5.30E-05]Training epoch 79:  88%|████████▊ | 135/153 [00:02<00:00, 53.07it/s, Epoch: 79, Batch: 136,Loss: -2.883,Avg.Loss: -2.873,LR: 5.30E-05]Training epoch 79:  89%|████████▉ | 136/153 [00:02<00:00, 53.07it/s, Epoch: 79, Batch: 137,Loss: -3.260,Avg.Loss: -2.876,LR: 5.30E-05]Training epoch 79:  90%|████████▉ | 137/153 [00:02<00:00, 53.07it/s, Epoch: 79, Batch: 138,Loss: -2.876,Avg.Loss: -2.876,LR: 5.29E-05]Training epoch 79:  90%|█████████ | 138/153 [00:02<00:00, 53.26it/s, Epoch: 79, Batch: 138,Loss: -2.876,Avg.Loss: -2.876,LR: 5.29E-05]Training epoch 79:  90%|█████████ | 138/153 [00:02<00:00, 53.26it/s, Epoch: 79, Batch: 139,Loss: -2.829,Avg.Loss: -2.876,LR: 5.29E-05]Training epoch 79:  91%|█████████ | 139/153 [00:02<00:00, 53.26it/s, Epoch: 79, Batch: 140,Loss: -2.609,Avg.Loss: -2.874,LR: 5.29E-05]Training epoch 79:  92%|█████████▏| 140/153 [00:02<00:00, 53.26it/s, Epoch: 79, Batch: 141,Loss: -2.760,Avg.Loss: -2.873,LR: 5.28E-05]Training epoch 79:  92%|█████████▏| 141/153 [00:02<00:00, 53.26it/s, Epoch: 79, Batch: 142,Loss: -2.726,Avg.Loss: -2.872,LR: 5.28E-05]Training epoch 79:  93%|█████████▎| 142/153 [00:02<00:00, 53.26it/s, Epoch: 79, Batch: 143,Loss: -2.763,Avg.Loss: -2.871,LR: 5.28E-05]Training epoch 79:  93%|█████████▎| 143/153 [00:02<00:00, 53.26it/s, Epoch: 79, Batch: 144,Loss: -3.054,Avg.Loss: -2.872,LR: 5.27E-05]Training epoch 79:  94%|█████████▍| 144/153 [00:02<00:00, 53.18it/s, Epoch: 79, Batch: 144,Loss: -3.054,Avg.Loss: -2.872,LR: 5.27E-05]Training epoch 79:  94%|█████████▍| 144/153 [00:02<00:00, 53.18it/s, Epoch: 79, Batch: 145,Loss: -3.157,Avg.Loss: -2.874,LR: 5.27E-05]Training epoch 79:  95%|█████████▍| 145/153 [00:02<00:00, 53.18it/s, Epoch: 79, Batch: 146,Loss: -3.051,Avg.Loss: -2.875,LR: 5.27E-05]Training epoch 79:  95%|█████████▌| 146/153 [00:02<00:00, 53.18it/s, Epoch: 79, Batch: 147,Loss: -3.335,Avg.Loss: -2.879,LR: 5.27E-05]Training epoch 79:  96%|█████████▌| 147/153 [00:02<00:00, 53.18it/s, Epoch: 79, Batch: 148,Loss: -3.123,Avg.Loss: -2.880,LR: 5.26E-05]Training epoch 79:  97%|█████████▋| 148/153 [00:02<00:00, 53.18it/s, Epoch: 79, Batch: 149,Loss: -2.581,Avg.Loss: -2.878,LR: 5.26E-05]Training epoch 79:  97%|█████████▋| 149/153 [00:02<00:00, 53.18it/s, Epoch: 79, Batch: 150,Loss: -2.992,Avg.Loss: -2.879,LR: 5.26E-05]Training epoch 79:  98%|█████████▊| 150/153 [00:02<00:00, 53.21it/s, Epoch: 79, Batch: 150,Loss: -2.992,Avg.Loss: -2.879,LR: 5.26E-05]Training epoch 79:  98%|█████████▊| 150/153 [00:02<00:00, 53.21it/s, Epoch: 79, Batch: 151,Loss: -2.850,Avg.Loss: -2.879,LR: 5.25E-05]Training epoch 79:  99%|█████████▊| 151/153 [00:02<00:00, 53.21it/s, Epoch: 79, Batch: 152,Loss: -2.632,Avg.Loss: -2.877,LR: 5.25E-05]Training epoch 79:  99%|█████████▉| 152/153 [00:02<00:00, 53.21it/s, Epoch: 79, Batch: 153,Loss: -3.065,Avg.Loss: -2.878,LR: 5.25E-05]Training epoch 79: 100%|██████████| 153/153 [00:02<00:00, 52.75it/s, Epoch: 79, Batch: 153,Loss: -3.065,Avg.Loss: -2.878,LR: 5.25E-05]
Training epoch 80:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 80:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 80, Batch: 1,Loss: -3.084,Avg.Loss: -3.084,LR: 5.24E-05]Training epoch 80:   1%|          | 1/153 [00:00<00:05, 29.84it/s, Epoch: 80, Batch: 2,Loss: -2.609,Avg.Loss: -2.847,LR: 5.24E-05]Training epoch 80:   1%|▏         | 2/153 [00:00<00:03, 42.44it/s, Epoch: 80, Batch: 3,Loss: -2.893,Avg.Loss: -2.862,LR: 5.24E-05]Training epoch 80:   2%|▏         | 3/153 [00:00<00:03, 46.97it/s, Epoch: 80, Batch: 4,Loss: -2.868,Avg.Loss: -2.864,LR: 5.23E-05]Training epoch 80:   3%|▎         | 4/153 [00:00<00:03, 49.14it/s, Epoch: 80, Batch: 5,Loss: -2.845,Avg.Loss: -2.860,LR: 5.23E-05]Training epoch 80:   3%|▎         | 5/153 [00:00<00:02, 50.20it/s, Epoch: 80, Batch: 6,Loss: -2.920,Avg.Loss: -2.870,LR: 5.23E-05]Training epoch 80:   4%|▍         | 6/153 [00:00<00:02, 50.34it/s, Epoch: 80, Batch: 7,Loss: -2.766,Avg.Loss: -2.855,LR: 5.22E-05]Training epoch 80:   5%|▍         | 7/153 [00:00<00:02, 58.64it/s, Epoch: 80, Batch: 7,Loss: -2.766,Avg.Loss: -2.855,LR: 5.22E-05]Training epoch 80:   5%|▍         | 7/153 [00:00<00:02, 58.64it/s, Epoch: 80, Batch: 8,Loss: -2.341,Avg.Loss: -2.791,LR: 5.22E-05]Training epoch 80:   5%|▌         | 8/153 [00:00<00:02, 58.64it/s, Epoch: 80, Batch: 9,Loss: -2.498,Avg.Loss: -2.758,LR: 5.22E-05]Training epoch 80:   6%|▌         | 9/153 [00:00<00:02, 58.64it/s, Epoch: 80, Batch: 10,Loss: -2.698,Avg.Loss: -2.752,LR: 5.21E-05]Training epoch 80:   7%|▋         | 10/153 [00:00<00:02, 58.64it/s, Epoch: 80, Batch: 11,Loss: -2.197,Avg.Loss: -2.702,LR: 5.21E-05]Training epoch 80:   7%|▋         | 11/153 [00:00<00:02, 58.64it/s, Epoch: 80, Batch: 12,Loss: -2.672,Avg.Loss: -2.699,LR: 5.21E-05]Training epoch 80:   8%|▊         | 12/153 [00:00<00:02, 58.64it/s, Epoch: 80, Batch: 13,Loss: -3.060,Avg.Loss: -2.727,LR: 5.21E-05]Training epoch 80:   8%|▊         | 13/153 [00:00<00:02, 54.69it/s, Epoch: 80, Batch: 13,Loss: -3.060,Avg.Loss: -2.727,LR: 5.21E-05]Training epoch 80:   8%|▊         | 13/153 [00:00<00:02, 54.69it/s, Epoch: 80, Batch: 14,Loss: -2.308,Avg.Loss: -2.697,LR: 5.20E-05]Training epoch 80:   9%|▉         | 14/153 [00:00<00:02, 54.69it/s, Epoch: 80, Batch: 15,Loss: -2.790,Avg.Loss: -2.703,LR: 5.20E-05]Training epoch 80:  10%|▉         | 15/153 [00:00<00:02, 54.69it/s, Epoch: 80, Batch: 16,Loss: -2.423,Avg.Loss: -2.686,LR: 5.20E-05]Training epoch 80:  10%|█         | 16/153 [00:00<00:02, 54.69it/s, Epoch: 80, Batch: 17,Loss: -2.712,Avg.Loss: -2.687,LR: 5.19E-05]Training epoch 80:  11%|█         | 17/153 [00:00<00:02, 54.69it/s, Epoch: 80, Batch: 18,Loss: -3.032,Avg.Loss: -2.706,LR: 5.19E-05]Training epoch 80:  12%|█▏        | 18/153 [00:00<00:02, 54.69it/s, Epoch: 80, Batch: 19,Loss: -3.030,Avg.Loss: -2.724,LR: 5.19E-05]Training epoch 80:  12%|█▏        | 19/153 [00:00<00:02, 53.80it/s, Epoch: 80, Batch: 19,Loss: -3.030,Avg.Loss: -2.724,LR: 5.19E-05]Training epoch 80:  12%|█▏        | 19/153 [00:00<00:02, 53.80it/s, Epoch: 80, Batch: 20,Loss: -2.809,Avg.Loss: -2.728,LR: 5.18E-05]Training epoch 80:  13%|█▎        | 20/153 [00:00<00:02, 53.80it/s, Epoch: 80, Batch: 21,Loss: -3.074,Avg.Loss: -2.744,LR: 5.18E-05]Training epoch 80:  14%|█▎        | 21/153 [00:00<00:02, 53.80it/s, Epoch: 80, Batch: 22,Loss: -3.143,Avg.Loss: -2.762,LR: 5.18E-05]Training epoch 80:  14%|█▍        | 22/153 [00:00<00:02, 53.80it/s, Epoch: 80, Batch: 23,Loss: -3.255,Avg.Loss: -2.784,LR: 5.17E-05]Training epoch 80:  15%|█▌        | 23/153 [00:00<00:02, 53.80it/s, Epoch: 80, Batch: 24,Loss: -2.580,Avg.Loss: -2.775,LR: 5.17E-05]Training epoch 80:  16%|█▌        | 24/153 [00:00<00:02, 53.80it/s, Epoch: 80, Batch: 25,Loss: -2.969,Avg.Loss: -2.783,LR: 5.17E-05]Training epoch 80:  16%|█▋        | 25/153 [00:00<00:02, 52.85it/s, Epoch: 80, Batch: 25,Loss: -2.969,Avg.Loss: -2.783,LR: 5.17E-05]Training epoch 80:  16%|█▋        | 25/153 [00:00<00:02, 52.85it/s, Epoch: 80, Batch: 26,Loss: -2.471,Avg.Loss: -2.771,LR: 5.16E-05]Training epoch 80:  17%|█▋        | 26/153 [00:00<00:02, 52.85it/s, Epoch: 80, Batch: 27,Loss: -2.882,Avg.Loss: -2.775,LR: 5.16E-05]Training epoch 80:  18%|█▊        | 27/153 [00:00<00:02, 52.85it/s, Epoch: 80, Batch: 28,Loss: -2.586,Avg.Loss: -2.768,LR: 5.16E-05]Training epoch 80:  18%|█▊        | 28/153 [00:00<00:02, 52.85it/s, Epoch: 80, Batch: 29,Loss: -2.342,Avg.Loss: -2.754,LR: 5.16E-05]Training epoch 80:  19%|█▉        | 29/153 [00:00<00:02, 52.85it/s, Epoch: 80, Batch: 30,Loss: -2.045,Avg.Loss: -2.730,LR: 5.15E-05]Training epoch 80:  20%|█▉        | 30/153 [00:00<00:02, 52.85it/s, Epoch: 80, Batch: 31,Loss: -2.948,Avg.Loss: -2.737,LR: 5.15E-05]Training epoch 80:  20%|██        | 31/153 [00:00<00:02, 52.48it/s, Epoch: 80, Batch: 31,Loss: -2.948,Avg.Loss: -2.737,LR: 5.15E-05]Training epoch 80:  20%|██        | 31/153 [00:00<00:02, 52.48it/s, Epoch: 80, Batch: 32,Loss: -2.863,Avg.Loss: -2.741,LR: 5.15E-05]Training epoch 80:  21%|██        | 32/153 [00:00<00:02, 52.48it/s, Epoch: 80, Batch: 33,Loss: -3.369,Avg.Loss: -2.760,LR: 5.14E-05]Training epoch 80:  22%|██▏       | 33/153 [00:00<00:02, 52.48it/s, Epoch: 80, Batch: 34,Loss: -2.170,Avg.Loss: -2.743,LR: 5.14E-05]Training epoch 80:  22%|██▏       | 34/153 [00:00<00:02, 52.48it/s, Epoch: 80, Batch: 35,Loss: -2.658,Avg.Loss: -2.740,LR: 5.14E-05]Training epoch 80:  23%|██▎       | 35/153 [00:00<00:02, 52.48it/s, Epoch: 80, Batch: 36,Loss: -2.463,Avg.Loss: -2.733,LR: 5.13E-05]Training epoch 80:  24%|██▎       | 36/153 [00:00<00:02, 52.48it/s, Epoch: 80, Batch: 37,Loss: -2.112,Avg.Loss: -2.716,LR: 5.13E-05]Training epoch 80:  24%|██▍       | 37/153 [00:00<00:02, 52.84it/s, Epoch: 80, Batch: 37,Loss: -2.112,Avg.Loss: -2.716,LR: 5.13E-05]Training epoch 80:  24%|██▍       | 37/153 [00:00<00:02, 52.84it/s, Epoch: 80, Batch: 38,Loss: -3.015,Avg.Loss: -2.724,LR: 5.13E-05]Training epoch 80:  25%|██▍       | 38/153 [00:00<00:02, 52.84it/s, Epoch: 80, Batch: 39,Loss: -2.748,Avg.Loss: -2.724,LR: 5.12E-05]Training epoch 80:  25%|██▌       | 39/153 [00:00<00:02, 52.84it/s, Epoch: 80, Batch: 40,Loss: -2.842,Avg.Loss: -2.727,LR: 5.12E-05]Training epoch 80:  26%|██▌       | 40/153 [00:00<00:02, 52.84it/s, Epoch: 80, Batch: 41,Loss: -2.403,Avg.Loss: -2.719,LR: 5.12E-05]Training epoch 80:  27%|██▋       | 41/153 [00:00<00:02, 52.84it/s, Epoch: 80, Batch: 42,Loss: -2.434,Avg.Loss: -2.713,LR: 5.11E-05]Training epoch 80:  27%|██▋       | 42/153 [00:00<00:02, 52.84it/s, Epoch: 80, Batch: 43,Loss: -1.469,Avg.Loss: -2.684,LR: 5.11E-05]Training epoch 80:  28%|██▊       | 43/153 [00:00<00:02, 52.91it/s, Epoch: 80, Batch: 43,Loss: -1.469,Avg.Loss: -2.684,LR: 5.11E-05]Training epoch 80:  28%|██▊       | 43/153 [00:00<00:02, 52.91it/s, Epoch: 80, Batch: 44,Loss: -1.987,Avg.Loss: -2.668,LR: 5.11E-05]Training epoch 80:  29%|██▉       | 44/153 [00:00<00:02, 52.91it/s, Epoch: 80, Batch: 45,Loss: -1.881,Avg.Loss: -2.650,LR: 5.11E-05]Training epoch 80:  29%|██▉       | 45/153 [00:00<00:02, 52.91it/s, Epoch: 80, Batch: 46,Loss: -2.582,Avg.Loss: -2.649,LR: 5.10E-05]Training epoch 80:  30%|███       | 46/153 [00:00<00:02, 52.91it/s, Epoch: 80, Batch: 47,Loss: -3.303,Avg.Loss: -2.663,LR: 5.10E-05]Training epoch 80:  31%|███       | 47/153 [00:00<00:02, 52.91it/s, Epoch: 80, Batch: 48,Loss: -2.838,Avg.Loss: -2.666,LR: 5.10E-05]Training epoch 80:  31%|███▏      | 48/153 [00:00<00:01, 52.91it/s, Epoch: 80, Batch: 49,Loss: -2.955,Avg.Loss: -2.672,LR: 5.09E-05]Training epoch 80:  32%|███▏      | 49/153 [00:00<00:01, 52.98it/s, Epoch: 80, Batch: 49,Loss: -2.955,Avg.Loss: -2.672,LR: 5.09E-05]Training epoch 80:  32%|███▏      | 49/153 [00:00<00:01, 52.98it/s, Epoch: 80, Batch: 50,Loss: -2.696,Avg.Loss: -2.673,LR: 5.09E-05]Training epoch 80:  33%|███▎      | 50/153 [00:00<00:01, 52.98it/s, Epoch: 80, Batch: 51,Loss: -3.143,Avg.Loss: -2.682,LR: 5.09E-05]Training epoch 80:  33%|███▎      | 51/153 [00:00<00:01, 52.98it/s, Epoch: 80, Batch: 52,Loss: -2.742,Avg.Loss: -2.683,LR: 5.08E-05]Training epoch 80:  34%|███▍      | 52/153 [00:00<00:01, 52.98it/s, Epoch: 80, Batch: 53,Loss: -3.064,Avg.Loss: -2.690,LR: 5.08E-05]Training epoch 80:  35%|███▍      | 53/153 [00:01<00:01, 52.98it/s, Epoch: 80, Batch: 54,Loss: -3.344,Avg.Loss: -2.702,LR: 5.08E-05]Training epoch 80:  35%|███▌      | 54/153 [00:01<00:01, 52.98it/s, Epoch: 80, Batch: 55,Loss: -3.315,Avg.Loss: -2.714,LR: 5.07E-05]Training epoch 80:  36%|███▌      | 55/153 [00:01<00:01, 53.15it/s, Epoch: 80, Batch: 55,Loss: -3.315,Avg.Loss: -2.714,LR: 5.07E-05]Training epoch 80:  36%|███▌      | 55/153 [00:01<00:01, 53.15it/s, Epoch: 80, Batch: 56,Loss: -3.440,Avg.Loss: -2.727,LR: 5.07E-05]Training epoch 80:  37%|███▋      | 56/153 [00:01<00:01, 53.15it/s, Epoch: 80, Batch: 57,Loss: -3.307,Avg.Loss: -2.737,LR: 5.07E-05]Training epoch 80:  37%|███▋      | 57/153 [00:01<00:01, 53.15it/s, Epoch: 80, Batch: 58,Loss: -2.944,Avg.Loss: -2.740,LR: 5.07E-05]Training epoch 80:  38%|███▊      | 58/153 [00:01<00:01, 53.15it/s, Epoch: 80, Batch: 59,Loss: -3.265,Avg.Loss: -2.749,LR: 5.06E-05]Training epoch 80:  39%|███▊      | 59/153 [00:01<00:01, 53.15it/s, Epoch: 80, Batch: 60,Loss: -2.581,Avg.Loss: -2.746,LR: 5.06E-05]Training epoch 80:  39%|███▉      | 60/153 [00:01<00:01, 53.15it/s, Epoch: 80, Batch: 61,Loss: -2.828,Avg.Loss: -2.748,LR: 5.06E-05]Training epoch 80:  40%|███▉      | 61/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 61,Loss: -2.828,Avg.Loss: -2.748,LR: 5.06E-05]Training epoch 80:  40%|███▉      | 61/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 62,Loss: -2.381,Avg.Loss: -2.742,LR: 5.05E-05]Training epoch 80:  41%|████      | 62/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 63,Loss: -3.477,Avg.Loss: -2.753,LR: 5.05E-05]Training epoch 80:  41%|████      | 63/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 64,Loss: -2.782,Avg.Loss: -2.754,LR: 5.05E-05]Training epoch 80:  42%|████▏     | 64/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 65,Loss: -2.697,Avg.Loss: -2.753,LR: 5.04E-05]Training epoch 80:  42%|████▏     | 65/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 66,Loss: -2.621,Avg.Loss: -2.751,LR: 5.04E-05]Training epoch 80:  43%|████▎     | 66/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 67,Loss: -3.268,Avg.Loss: -2.759,LR: 5.04E-05]Training epoch 80:  44%|████▍     | 67/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 67,Loss: -3.268,Avg.Loss: -2.759,LR: 5.04E-05]Training epoch 80:  44%|████▍     | 67/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 68,Loss: -3.235,Avg.Loss: -2.766,LR: 5.03E-05]Training epoch 80:  44%|████▍     | 68/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 69,Loss: -2.199,Avg.Loss: -2.758,LR: 5.03E-05]Training epoch 80:  45%|████▌     | 69/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 70,Loss: -3.159,Avg.Loss: -2.763,LR: 5.03E-05]Training epoch 80:  46%|████▌     | 70/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 71,Loss: -2.731,Avg.Loss: -2.763,LR: 5.02E-05]Training epoch 80:  46%|████▋     | 71/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 72,Loss: -2.480,Avg.Loss: -2.759,LR: 5.02E-05]Training epoch 80:  47%|████▋     | 72/153 [00:01<00:01, 53.17it/s, Epoch: 80, Batch: 73,Loss: -2.908,Avg.Loss: -2.761,LR: 5.02E-05]Training epoch 80:  48%|████▊     | 73/153 [00:01<00:01, 53.13it/s, Epoch: 80, Batch: 73,Loss: -2.908,Avg.Loss: -2.761,LR: 5.02E-05]Training epoch 80:  48%|████▊     | 73/153 [00:01<00:01, 53.13it/s, Epoch: 80, Batch: 74,Loss: -2.559,Avg.Loss: -2.758,LR: 5.02E-05]Training epoch 80:  48%|████▊     | 74/153 [00:01<00:01, 53.13it/s, Epoch: 80, Batch: 75,Loss: -3.251,Avg.Loss: -2.765,LR: 5.01E-05]Training epoch 80:  49%|████▉     | 75/153 [00:01<00:01, 53.13it/s, Epoch: 80, Batch: 76,Loss: -2.752,Avg.Loss: -2.765,LR: 5.01E-05]Training epoch 80:  50%|████▉     | 76/153 [00:01<00:01, 53.13it/s, Epoch: 80, Batch: 77,Loss: -2.910,Avg.Loss: -2.767,LR: 5.01E-05]Training epoch 80:  50%|█████     | 77/153 [00:01<00:01, 53.13it/s, Epoch: 80, Batch: 78,Loss: -2.837,Avg.Loss: -2.767,LR: 5.00E-05]Training epoch 80:  51%|█████     | 78/153 [00:01<00:01, 53.13it/s, Epoch: 80, Batch: 79,Loss: -2.706,Avg.Loss: -2.767,LR: 5.00E-05]Training epoch 80:  52%|█████▏    | 79/153 [00:01<00:01, 53.07it/s, Epoch: 80, Batch: 79,Loss: -2.706,Avg.Loss: -2.767,LR: 5.00E-05]Training epoch 80:  52%|█████▏    | 79/153 [00:01<00:01, 53.07it/s, Epoch: 80, Batch: 80,Loss: -3.282,Avg.Loss: -2.773,LR: 5.00E-05]Training epoch 80:  52%|█████▏    | 80/153 [00:01<00:01, 53.07it/s, Epoch: 80, Batch: 81,Loss: -3.280,Avg.Loss: -2.779,LR: 4.99E-05]Training epoch 80:  53%|█████▎    | 81/153 [00:01<00:01, 53.07it/s, Epoch: 80, Batch: 82,Loss: -3.106,Avg.Loss: -2.783,LR: 4.99E-05]Training epoch 80:  54%|█████▎    | 82/153 [00:01<00:01, 53.07it/s, Epoch: 80, Batch: 83,Loss: -3.137,Avg.Loss: -2.788,LR: 4.99E-05]Training epoch 80:  54%|█████▍    | 83/153 [00:01<00:01, 53.07it/s, Epoch: 80, Batch: 84,Loss: -2.433,Avg.Loss: -2.783,LR: 4.98E-05]Training epoch 80:  55%|█████▍    | 84/153 [00:01<00:01, 53.07it/s, Epoch: 80, Batch: 85,Loss: -3.253,Avg.Loss: -2.789,LR: 4.98E-05]Training epoch 80:  56%|█████▌    | 85/153 [00:01<00:01, 53.02it/s, Epoch: 80, Batch: 85,Loss: -3.253,Avg.Loss: -2.789,LR: 4.98E-05]Training epoch 80:  56%|█████▌    | 85/153 [00:01<00:01, 53.02it/s, Epoch: 80, Batch: 86,Loss: -2.990,Avg.Loss: -2.791,LR: 4.98E-05]Training epoch 80:  56%|█████▌    | 86/153 [00:01<00:01, 53.02it/s, Epoch: 80, Batch: 87,Loss: -3.089,Avg.Loss: -2.795,LR: 4.98E-05]Training epoch 80:  57%|█████▋    | 87/153 [00:01<00:01, 53.02it/s, Epoch: 80, Batch: 88,Loss: -2.725,Avg.Loss: -2.794,LR: 4.97E-05]Training epoch 80:  58%|█████▊    | 88/153 [00:01<00:01, 53.02it/s, Epoch: 80, Batch: 89,Loss: -3.029,Avg.Loss: -2.797,LR: 4.97E-05]Training epoch 80:  58%|█████▊    | 89/153 [00:01<00:01, 53.02it/s, Epoch: 80, Batch: 90,Loss: -3.134,Avg.Loss: -2.800,LR: 4.97E-05]Training epoch 80:  59%|█████▉    | 90/153 [00:01<00:01, 53.02it/s, Epoch: 80, Batch: 91,Loss: -3.157,Avg.Loss: -2.804,LR: 4.96E-05]Training epoch 80:  59%|█████▉    | 91/153 [00:01<00:01, 52.24it/s, Epoch: 80, Batch: 91,Loss: -3.157,Avg.Loss: -2.804,LR: 4.96E-05]Training epoch 80:  59%|█████▉    | 91/153 [00:01<00:01, 52.24it/s, Epoch: 80, Batch: 92,Loss: -2.773,Avg.Loss: -2.804,LR: 4.96E-05]Training epoch 80:  60%|██████    | 92/153 [00:01<00:01, 52.24it/s, Epoch: 80, Batch: 93,Loss: -3.318,Avg.Loss: -2.809,LR: 4.96E-05]Training epoch 80:  61%|██████    | 93/153 [00:01<00:01, 52.24it/s, Epoch: 80, Batch: 94,Loss: -2.878,Avg.Loss: -2.810,LR: 4.95E-05]Training epoch 80:  61%|██████▏   | 94/153 [00:01<00:01, 52.24it/s, Epoch: 80, Batch: 95,Loss: -2.626,Avg.Loss: -2.808,LR: 4.95E-05]Training epoch 80:  62%|██████▏   | 95/153 [00:01<00:01, 52.24it/s, Epoch: 80, Batch: 96,Loss: -2.907,Avg.Loss: -2.809,LR: 4.95E-05]Training epoch 80:  63%|██████▎   | 96/153 [00:01<00:01, 52.24it/s, Epoch: 80, Batch: 97,Loss: -3.145,Avg.Loss: -2.813,LR: 4.94E-05]Training epoch 80:  63%|██████▎   | 97/153 [00:01<00:01, 52.55it/s, Epoch: 80, Batch: 97,Loss: -3.145,Avg.Loss: -2.813,LR: 4.94E-05]Training epoch 80:  63%|██████▎   | 97/153 [00:01<00:01, 52.55it/s, Epoch: 80, Batch: 98,Loss: -3.144,Avg.Loss: -2.816,LR: 4.94E-05]Training epoch 80:  64%|██████▍   | 98/153 [00:01<00:01, 52.55it/s, Epoch: 80, Batch: 99,Loss: -3.296,Avg.Loss: -2.821,LR: 4.94E-05]Training epoch 80:  65%|██████▍   | 99/153 [00:01<00:01, 52.55it/s, Epoch: 80, Batch: 100,Loss: -2.542,Avg.Loss: -2.818,LR: 4.94E-05]Training epoch 80:  65%|██████▌   | 100/153 [00:01<00:01, 52.55it/s, Epoch: 80, Batch: 101,Loss: -2.595,Avg.Loss: -2.816,LR: 4.93E-05]Training epoch 80:  66%|██████▌   | 101/153 [00:01<00:00, 52.55it/s, Epoch: 80, Batch: 102,Loss: -3.220,Avg.Loss: -2.820,LR: 4.93E-05]Training epoch 80:  67%|██████▋   | 102/153 [00:01<00:00, 52.55it/s, Epoch: 80, Batch: 103,Loss: -3.022,Avg.Loss: -2.822,LR: 4.93E-05]Training epoch 80:  67%|██████▋   | 103/153 [00:01<00:00, 52.87it/s, Epoch: 80, Batch: 103,Loss: -3.022,Avg.Loss: -2.822,LR: 4.93E-05]Training epoch 80:  67%|██████▋   | 103/153 [00:01<00:00, 52.87it/s, Epoch: 80, Batch: 104,Loss: -2.789,Avg.Loss: -2.822,LR: 4.92E-05]Training epoch 80:  68%|██████▊   | 104/153 [00:01<00:00, 52.87it/s, Epoch: 80, Batch: 105,Loss: -2.939,Avg.Loss: -2.823,LR: 4.92E-05]Training epoch 80:  69%|██████▊   | 105/153 [00:01<00:00, 52.87it/s, Epoch: 80, Batch: 106,Loss: -2.738,Avg.Loss: -2.822,LR: 4.92E-05]Training epoch 80:  69%|██████▉   | 106/153 [00:02<00:00, 52.87it/s, Epoch: 80, Batch: 107,Loss: -3.217,Avg.Loss: -2.826,LR: 4.91E-05]Training epoch 80:  70%|██████▉   | 107/153 [00:02<00:00, 52.87it/s, Epoch: 80, Batch: 108,Loss: -2.544,Avg.Loss: -2.823,LR: 4.91E-05]Training epoch 80:  71%|███████   | 108/153 [00:02<00:00, 52.87it/s, Epoch: 80, Batch: 109,Loss: -3.021,Avg.Loss: -2.825,LR: 4.91E-05]Training epoch 80:  71%|███████   | 109/153 [00:02<00:00, 52.78it/s, Epoch: 80, Batch: 109,Loss: -3.021,Avg.Loss: -2.825,LR: 4.91E-05]Training epoch 80:  71%|███████   | 109/153 [00:02<00:00, 52.78it/s, Epoch: 80, Batch: 110,Loss: -3.129,Avg.Loss: -2.827,LR: 4.91E-05]Training epoch 80:  72%|███████▏  | 110/153 [00:02<00:00, 52.78it/s, Epoch: 80, Batch: 111,Loss: -2.836,Avg.Loss: -2.828,LR: 4.90E-05]Training epoch 80:  73%|███████▎  | 111/153 [00:02<00:00, 52.78it/s, Epoch: 80, Batch: 112,Loss: -3.365,Avg.Loss: -2.832,LR: 4.90E-05]Training epoch 80:  73%|███████▎  | 112/153 [00:02<00:00, 52.78it/s, Epoch: 80, Batch: 113,Loss: -2.626,Avg.Loss: -2.831,LR: 4.90E-05]Training epoch 80:  74%|███████▍  | 113/153 [00:02<00:00, 52.78it/s, Epoch: 80, Batch: 114,Loss: -2.863,Avg.Loss: -2.831,LR: 4.89E-05]Training epoch 80:  75%|███████▍  | 114/153 [00:02<00:00, 52.78it/s, Epoch: 80, Batch: 115,Loss: -2.783,Avg.Loss: -2.830,LR: 4.89E-05]Training epoch 80:  75%|███████▌  | 115/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 115,Loss: -2.783,Avg.Loss: -2.830,LR: 4.89E-05]Training epoch 80:  75%|███████▌  | 115/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 116,Loss: -2.593,Avg.Loss: -2.828,LR: 4.89E-05]Training epoch 80:  76%|███████▌  | 116/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 117,Loss: -3.135,Avg.Loss: -2.831,LR: 4.88E-05]Training epoch 80:  76%|███████▋  | 117/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 118,Loss: -3.052,Avg.Loss: -2.833,LR: 4.88E-05]Training epoch 80:  77%|███████▋  | 118/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 119,Loss: -2.646,Avg.Loss: -2.831,LR: 4.88E-05]Training epoch 80:  78%|███████▊  | 119/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 120,Loss: -2.514,Avg.Loss: -2.829,LR: 4.87E-05]Training epoch 80:  78%|███████▊  | 120/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 121,Loss: -2.333,Avg.Loss: -2.825,LR: 4.87E-05]Training epoch 80:  79%|███████▉  | 121/153 [00:02<00:00, 52.92it/s, Epoch: 80, Batch: 121,Loss: -2.333,Avg.Loss: -2.825,LR: 4.87E-05]Training epoch 80:  79%|███████▉  | 121/153 [00:02<00:00, 52.92it/s, Epoch: 80, Batch: 122,Loss: -2.401,Avg.Loss: -2.821,LR: 4.87E-05]Training epoch 80:  80%|███████▉  | 122/153 [00:02<00:00, 52.92it/s, Epoch: 80, Batch: 123,Loss: -2.778,Avg.Loss: -2.821,LR: 4.87E-05]Training epoch 80:  80%|████████  | 123/153 [00:02<00:00, 52.92it/s, Epoch: 80, Batch: 124,Loss: -2.953,Avg.Loss: -2.822,LR: 4.86E-05]Training epoch 80:  81%|████████  | 124/153 [00:02<00:00, 52.92it/s, Epoch: 80, Batch: 125,Loss: -2.634,Avg.Loss: -2.820,LR: 4.86E-05]Training epoch 80:  82%|████████▏ | 125/153 [00:02<00:00, 52.92it/s, Epoch: 80, Batch: 126,Loss: -3.004,Avg.Loss: -2.822,LR: 4.86E-05]Training epoch 80:  82%|████████▏ | 126/153 [00:02<00:00, 52.92it/s, Epoch: 80, Batch: 127,Loss: -2.895,Avg.Loss: -2.822,LR: 4.85E-05]Training epoch 80:  83%|████████▎ | 127/153 [00:02<00:00, 52.90it/s, Epoch: 80, Batch: 127,Loss: -2.895,Avg.Loss: -2.822,LR: 4.85E-05]Training epoch 80:  83%|████████▎ | 127/153 [00:02<00:00, 52.90it/s, Epoch: 80, Batch: 128,Loss: -3.205,Avg.Loss: -2.825,LR: 4.85E-05]Training epoch 80:  84%|████████▎ | 128/153 [00:02<00:00, 52.90it/s, Epoch: 80, Batch: 129,Loss: -3.123,Avg.Loss: -2.828,LR: 4.85E-05]Training epoch 80:  84%|████████▍ | 129/153 [00:02<00:00, 52.90it/s, Epoch: 80, Batch: 130,Loss: -2.822,Avg.Loss: -2.828,LR: 4.84E-05]Training epoch 80:  85%|████████▍ | 130/153 [00:02<00:00, 52.90it/s, Epoch: 80, Batch: 131,Loss: -3.141,Avg.Loss: -2.830,LR: 4.84E-05]Training epoch 80:  86%|████████▌ | 131/153 [00:02<00:00, 52.90it/s, Epoch: 80, Batch: 132,Loss: -2.487,Avg.Loss: -2.827,LR: 4.84E-05]Training epoch 80:  86%|████████▋ | 132/153 [00:02<00:00, 52.90it/s, Epoch: 80, Batch: 133,Loss: -3.408,Avg.Loss: -2.832,LR: 4.84E-05]Training epoch 80:  87%|████████▋ | 133/153 [00:02<00:00, 52.75it/s, Epoch: 80, Batch: 133,Loss: -3.408,Avg.Loss: -2.832,LR: 4.84E-05]Training epoch 80:  87%|████████▋ | 133/153 [00:02<00:00, 52.75it/s, Epoch: 80, Batch: 134,Loss: -2.271,Avg.Loss: -2.828,LR: 4.83E-05]Training epoch 80:  88%|████████▊ | 134/153 [00:02<00:00, 52.75it/s, Epoch: 80, Batch: 135,Loss: -2.884,Avg.Loss: -2.828,LR: 4.83E-05]Training epoch 80:  88%|████████▊ | 135/153 [00:02<00:00, 52.75it/s, Epoch: 80, Batch: 136,Loss: -2.740,Avg.Loss: -2.827,LR: 4.83E-05]Training epoch 80:  89%|████████▉ | 136/153 [00:02<00:00, 52.75it/s, Epoch: 80, Batch: 137,Loss: -2.650,Avg.Loss: -2.826,LR: 4.82E-05]Training epoch 80:  90%|████████▉ | 137/153 [00:02<00:00, 52.75it/s, Epoch: 80, Batch: 138,Loss: -2.282,Avg.Loss: -2.822,LR: 4.82E-05]Training epoch 80:  90%|█████████ | 138/153 [00:02<00:00, 52.75it/s, Epoch: 80, Batch: 139,Loss: -2.677,Avg.Loss: -2.821,LR: 4.82E-05]Training epoch 80:  91%|█████████ | 139/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 139,Loss: -2.677,Avg.Loss: -2.821,LR: 4.82E-05]Training epoch 80:  91%|█████████ | 139/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 140,Loss: -2.906,Avg.Loss: -2.822,LR: 4.81E-05]Training epoch 80:  92%|█████████▏| 140/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 141,Loss: -3.101,Avg.Loss: -2.824,LR: 4.81E-05]Training epoch 80:  92%|█████████▏| 141/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 142,Loss: -2.620,Avg.Loss: -2.822,LR: 4.81E-05]Training epoch 80:  93%|█████████▎| 142/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 143,Loss: -3.251,Avg.Loss: -2.825,LR: 4.80E-05]Training epoch 80:  93%|█████████▎| 143/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 144,Loss: -3.123,Avg.Loss: -2.827,LR: 4.80E-05]Training epoch 80:  94%|█████████▍| 144/153 [00:02<00:00, 52.82it/s, Epoch: 80, Batch: 145,Loss: -2.601,Avg.Loss: -2.826,LR: 4.80E-05]Training epoch 80:  95%|█████████▍| 145/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 145,Loss: -2.601,Avg.Loss: -2.826,LR: 4.80E-05]Training epoch 80:  95%|█████████▍| 145/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 146,Loss: -3.054,Avg.Loss: -2.827,LR: 4.80E-05]Training epoch 80:  95%|█████████▌| 146/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 147,Loss: -2.730,Avg.Loss: -2.827,LR: 4.79E-05]Training epoch 80:  96%|█████████▌| 147/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 148,Loss: -2.768,Avg.Loss: -2.826,LR: 4.79E-05]Training epoch 80:  97%|█████████▋| 148/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 149,Loss: -2.803,Avg.Loss: -2.826,LR: 4.79E-05]Training epoch 80:  97%|█████████▋| 149/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 150,Loss: -2.823,Avg.Loss: -2.826,LR: 4.78E-05]Training epoch 80:  98%|█████████▊| 150/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 151,Loss: -3.300,Avg.Loss: -2.829,LR: 4.78E-05]Training epoch 80:  99%|█████████▊| 151/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 151,Loss: -3.300,Avg.Loss: -2.829,LR: 4.78E-05]Training epoch 80:  99%|█████████▊| 151/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 152,Loss: -2.861,Avg.Loss: -2.829,LR: 4.78E-05]Training epoch 80:  99%|█████████▉| 152/153 [00:02<00:00, 52.80it/s, Epoch: 80, Batch: 153,Loss: -2.650,Avg.Loss: -2.828,LR: 4.77E-05]Training epoch 80: 100%|██████████| 153/153 [00:02<00:00, 52.93it/s, Epoch: 80, Batch: 153,Loss: -2.650,Avg.Loss: -2.828,LR: 4.77E-05]
Training epoch 81:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 81:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 81, Batch: 1,Loss: -2.780,Avg.Loss: -2.780,LR: 4.77E-05]Training epoch 81:   1%|          | 1/153 [00:00<00:05, 25.75it/s, Epoch: 81, Batch: 2,Loss: -3.096,Avg.Loss: -2.938,LR: 4.77E-05]Training epoch 81:   1%|▏         | 2/153 [00:00<00:04, 37.21it/s, Epoch: 81, Batch: 3,Loss: -2.742,Avg.Loss: -2.873,LR: 4.77E-05]Training epoch 81:   2%|▏         | 3/153 [00:00<00:03, 42.61it/s, Epoch: 81, Batch: 4,Loss: -2.222,Avg.Loss: -2.710,LR: 4.76E-05]Training epoch 81:   3%|▎         | 4/153 [00:00<00:03, 45.02it/s, Epoch: 81, Batch: 5,Loss: -3.183,Avg.Loss: -2.805,LR: 4.76E-05]Training epoch 81:   3%|▎         | 5/153 [00:00<00:03, 46.29it/s, Epoch: 81, Batch: 6,Loss: -2.843,Avg.Loss: -2.811,LR: 4.76E-05]Training epoch 81:   4%|▍         | 6/153 [00:00<00:02, 55.45it/s, Epoch: 81, Batch: 6,Loss: -2.843,Avg.Loss: -2.811,LR: 4.76E-05]Training epoch 81:   4%|▍         | 6/153 [00:00<00:02, 55.45it/s, Epoch: 81, Batch: 7,Loss: -3.071,Avg.Loss: -2.848,LR: 4.75E-05]Training epoch 81:   5%|▍         | 7/153 [00:00<00:02, 55.45it/s, Epoch: 81, Batch: 8,Loss: -2.683,Avg.Loss: -2.828,LR: 4.75E-05]Training epoch 81:   5%|▌         | 8/153 [00:00<00:02, 55.45it/s, Epoch: 81, Batch: 9,Loss: -2.994,Avg.Loss: -2.846,LR: 4.75E-05]Training epoch 81:   6%|▌         | 9/153 [00:00<00:02, 55.45it/s, Epoch: 81, Batch: 10,Loss: -3.376,Avg.Loss: -2.899,LR: 4.74E-05]Training epoch 81:   7%|▋         | 10/153 [00:00<00:02, 55.45it/s, Epoch: 81, Batch: 11,Loss: -2.894,Avg.Loss: -2.899,LR: 4.74E-05]Training epoch 81:   7%|▋         | 11/153 [00:00<00:02, 55.45it/s, Epoch: 81, Batch: 12,Loss: -3.007,Avg.Loss: -2.908,LR: 4.74E-05]Training epoch 81:   8%|▊         | 12/153 [00:00<00:02, 53.54it/s, Epoch: 81, Batch: 12,Loss: -3.007,Avg.Loss: -2.908,LR: 4.74E-05]Training epoch 81:   8%|▊         | 12/153 [00:00<00:02, 53.54it/s, Epoch: 81, Batch: 13,Loss: -2.828,Avg.Loss: -2.901,LR: 4.74E-05]Training epoch 81:   8%|▊         | 13/153 [00:00<00:02, 53.54it/s, Epoch: 81, Batch: 14,Loss: -2.739,Avg.Loss: -2.890,LR: 4.73E-05]Training epoch 81:   9%|▉         | 14/153 [00:00<00:02, 53.54it/s, Epoch: 81, Batch: 15,Loss: -2.655,Avg.Loss: -2.874,LR: 4.73E-05]Training epoch 81:  10%|▉         | 15/153 [00:00<00:02, 53.54it/s, Epoch: 81, Batch: 16,Loss: -2.768,Avg.Loss: -2.868,LR: 4.73E-05]Training epoch 81:  10%|█         | 16/153 [00:00<00:02, 53.54it/s, Epoch: 81, Batch: 17,Loss: -2.840,Avg.Loss: -2.866,LR: 4.72E-05]Training epoch 81:  11%|█         | 17/153 [00:00<00:02, 53.54it/s, Epoch: 81, Batch: 18,Loss: -2.727,Avg.Loss: -2.858,LR: 4.72E-05]Training epoch 81:  12%|█▏        | 18/153 [00:00<00:02, 53.33it/s, Epoch: 81, Batch: 18,Loss: -2.727,Avg.Loss: -2.858,LR: 4.72E-05]Training epoch 81:  12%|█▏        | 18/153 [00:00<00:02, 53.33it/s, Epoch: 81, Batch: 19,Loss: -2.911,Avg.Loss: -2.861,LR: 4.72E-05]Training epoch 81:  12%|█▏        | 19/153 [00:00<00:02, 53.33it/s, Epoch: 81, Batch: 20,Loss: -2.778,Avg.Loss: -2.857,LR: 4.71E-05]Training epoch 81:  13%|█▎        | 20/153 [00:00<00:02, 53.33it/s, Epoch: 81, Batch: 21,Loss: -2.895,Avg.Loss: -2.859,LR: 4.71E-05]Training epoch 81:  14%|█▎        | 21/153 [00:00<00:02, 53.33it/s, Epoch: 81, Batch: 22,Loss: -2.815,Avg.Loss: -2.857,LR: 4.71E-05]Training epoch 81:  14%|█▍        | 22/153 [00:00<00:02, 53.33it/s, Epoch: 81, Batch: 23,Loss: -2.699,Avg.Loss: -2.850,LR: 4.71E-05]Training epoch 81:  15%|█▌        | 23/153 [00:00<00:02, 53.33it/s, Epoch: 81, Batch: 24,Loss: -3.252,Avg.Loss: -2.867,LR: 4.70E-05]Training epoch 81:  16%|█▌        | 24/153 [00:00<00:02, 52.40it/s, Epoch: 81, Batch: 24,Loss: -3.252,Avg.Loss: -2.867,LR: 4.70E-05]Training epoch 81:  16%|█▌        | 24/153 [00:00<00:02, 52.40it/s, Epoch: 81, Batch: 25,Loss: -2.556,Avg.Loss: -2.854,LR: 4.70E-05]Training epoch 81:  16%|█▋        | 25/153 [00:00<00:02, 52.40it/s, Epoch: 81, Batch: 26,Loss: -2.823,Avg.Loss: -2.853,LR: 4.70E-05]Training epoch 81:  17%|█▋        | 26/153 [00:00<00:02, 52.40it/s, Epoch: 81, Batch: 27,Loss: -2.748,Avg.Loss: -2.849,LR: 4.69E-05]Training epoch 81:  18%|█▊        | 27/153 [00:00<00:02, 52.40it/s, Epoch: 81, Batch: 28,Loss: -2.762,Avg.Loss: -2.846,LR: 4.69E-05]Training epoch 81:  18%|█▊        | 28/153 [00:00<00:02, 52.40it/s, Epoch: 81, Batch: 29,Loss: -3.065,Avg.Loss: -2.854,LR: 4.69E-05]Training epoch 81:  19%|█▉        | 29/153 [00:00<00:02, 52.40it/s, Epoch: 81, Batch: 30,Loss: -3.033,Avg.Loss: -2.860,LR: 4.68E-05]Training epoch 81:  20%|█▉        | 30/153 [00:00<00:02, 52.20it/s, Epoch: 81, Batch: 30,Loss: -3.033,Avg.Loss: -2.860,LR: 4.68E-05]Training epoch 81:  20%|█▉        | 30/153 [00:00<00:02, 52.20it/s, Epoch: 81, Batch: 31,Loss: -3.022,Avg.Loss: -2.865,LR: 4.68E-05]Training epoch 81:  20%|██        | 31/153 [00:00<00:02, 52.20it/s, Epoch: 81, Batch: 32,Loss: -3.197,Avg.Loss: -2.875,LR: 4.68E-05]Training epoch 81:  21%|██        | 32/153 [00:00<00:02, 52.20it/s, Epoch: 81, Batch: 33,Loss: -2.786,Avg.Loss: -2.872,LR: 4.68E-05]Training epoch 81:  22%|██▏       | 33/153 [00:00<00:02, 52.20it/s, Epoch: 81, Batch: 34,Loss: -2.885,Avg.Loss: -2.873,LR: 4.67E-05]Training epoch 81:  22%|██▏       | 34/153 [00:00<00:02, 52.20it/s, Epoch: 81, Batch: 35,Loss: -2.854,Avg.Loss: -2.872,LR: 4.67E-05]Training epoch 81:  23%|██▎       | 35/153 [00:00<00:02, 52.20it/s, Epoch: 81, Batch: 36,Loss: -2.737,Avg.Loss: -2.869,LR: 4.67E-05]Training epoch 81:  24%|██▎       | 36/153 [00:00<00:02, 52.33it/s, Epoch: 81, Batch: 36,Loss: -2.737,Avg.Loss: -2.869,LR: 4.67E-05]Training epoch 81:  24%|██▎       | 36/153 [00:00<00:02, 52.33it/s, Epoch: 81, Batch: 37,Loss: -2.578,Avg.Loss: -2.861,LR: 4.66E-05]Training epoch 81:  24%|██▍       | 37/153 [00:00<00:02, 52.33it/s, Epoch: 81, Batch: 38,Loss: -2.628,Avg.Loss: -2.855,LR: 4.66E-05]Training epoch 81:  25%|██▍       | 38/153 [00:00<00:02, 52.33it/s, Epoch: 81, Batch: 39,Loss: -2.957,Avg.Loss: -2.857,LR: 4.66E-05]Training epoch 81:  25%|██▌       | 39/153 [00:00<00:02, 52.33it/s, Epoch: 81, Batch: 40,Loss: -2.978,Avg.Loss: -2.860,LR: 4.65E-05]Training epoch 81:  26%|██▌       | 40/153 [00:00<00:02, 52.33it/s, Epoch: 81, Batch: 41,Loss: -2.740,Avg.Loss: -2.857,LR: 4.65E-05]Training epoch 81:  27%|██▋       | 41/153 [00:00<00:02, 52.33it/s, Epoch: 81, Batch: 42,Loss: -3.108,Avg.Loss: -2.863,LR: 4.65E-05]Training epoch 81:  27%|██▋       | 42/153 [00:00<00:02, 52.47it/s, Epoch: 81, Batch: 42,Loss: -3.108,Avg.Loss: -2.863,LR: 4.65E-05]Training epoch 81:  27%|██▋       | 42/153 [00:00<00:02, 52.47it/s, Epoch: 81, Batch: 43,Loss: -3.163,Avg.Loss: -2.870,LR: 4.65E-05]Training epoch 81:  28%|██▊       | 43/153 [00:00<00:02, 52.47it/s, Epoch: 81, Batch: 44,Loss: -2.773,Avg.Loss: -2.868,LR: 4.64E-05]Training epoch 81:  29%|██▉       | 44/153 [00:00<00:02, 52.47it/s, Epoch: 81, Batch: 45,Loss: -2.627,Avg.Loss: -2.863,LR: 4.64E-05]Training epoch 81:  29%|██▉       | 45/153 [00:00<00:02, 52.47it/s, Epoch: 81, Batch: 46,Loss: -2.510,Avg.Loss: -2.855,LR: 4.64E-05]Training epoch 81:  30%|███       | 46/153 [00:00<00:02, 52.47it/s, Epoch: 81, Batch: 47,Loss: -3.153,Avg.Loss: -2.861,LR: 4.63E-05]Training epoch 81:  31%|███       | 47/153 [00:00<00:02, 52.47it/s, Epoch: 81, Batch: 48,Loss: -2.973,Avg.Loss: -2.864,LR: 4.63E-05]Training epoch 81:  31%|███▏      | 48/153 [00:00<00:01, 52.63it/s, Epoch: 81, Batch: 48,Loss: -2.973,Avg.Loss: -2.864,LR: 4.63E-05]Training epoch 81:  31%|███▏      | 48/153 [00:00<00:01, 52.63it/s, Epoch: 81, Batch: 49,Loss: -2.837,Avg.Loss: -2.863,LR: 4.63E-05]Training epoch 81:  32%|███▏      | 49/153 [00:00<00:01, 52.63it/s, Epoch: 81, Batch: 50,Loss: -2.735,Avg.Loss: -2.861,LR: 4.62E-05]Training epoch 81:  33%|███▎      | 50/153 [00:00<00:01, 52.63it/s, Epoch: 81, Batch: 51,Loss: -2.973,Avg.Loss: -2.863,LR: 4.62E-05]Training epoch 81:  33%|███▎      | 51/153 [00:00<00:01, 52.63it/s, Epoch: 81, Batch: 52,Loss: -3.278,Avg.Loss: -2.871,LR: 4.62E-05]Training epoch 81:  34%|███▍      | 52/153 [00:01<00:01, 52.63it/s, Epoch: 81, Batch: 53,Loss: -2.708,Avg.Loss: -2.868,LR: 4.62E-05]Training epoch 81:  35%|███▍      | 53/153 [00:01<00:01, 52.63it/s, Epoch: 81, Batch: 54,Loss: -2.838,Avg.Loss: -2.867,LR: 4.61E-05]Training epoch 81:  35%|███▌      | 54/153 [00:01<00:01, 52.73it/s, Epoch: 81, Batch: 54,Loss: -2.838,Avg.Loss: -2.867,LR: 4.61E-05]Training epoch 81:  35%|███▌      | 54/153 [00:01<00:01, 52.73it/s, Epoch: 81, Batch: 55,Loss: -3.267,Avg.Loss: -2.874,LR: 4.61E-05]Training epoch 81:  36%|███▌      | 55/153 [00:01<00:01, 52.73it/s, Epoch: 81, Batch: 56,Loss: -2.939,Avg.Loss: -2.876,LR: 4.61E-05]Training epoch 81:  37%|███▋      | 56/153 [00:01<00:01, 52.73it/s, Epoch: 81, Batch: 57,Loss: -2.982,Avg.Loss: -2.877,LR: 4.60E-05]Training epoch 81:  37%|███▋      | 57/153 [00:01<00:01, 52.73it/s, Epoch: 81, Batch: 58,Loss: -2.602,Avg.Loss: -2.873,LR: 4.60E-05]Training epoch 81:  38%|███▊      | 58/153 [00:01<00:01, 52.73it/s, Epoch: 81, Batch: 59,Loss: -3.227,Avg.Loss: -2.879,LR: 4.60E-05]Training epoch 81:  39%|███▊      | 59/153 [00:01<00:01, 52.73it/s, Epoch: 81, Batch: 60,Loss: -2.879,Avg.Loss: -2.879,LR: 4.60E-05]Training epoch 81:  39%|███▉      | 60/153 [00:01<00:01, 52.64it/s, Epoch: 81, Batch: 60,Loss: -2.879,Avg.Loss: -2.879,LR: 4.60E-05]Training epoch 81:  39%|███▉      | 60/153 [00:01<00:01, 52.64it/s, Epoch: 81, Batch: 61,Loss: -2.778,Avg.Loss: -2.877,LR: 4.59E-05]Training epoch 81:  40%|███▉      | 61/153 [00:01<00:01, 52.64it/s, Epoch: 81, Batch: 62,Loss: -3.328,Avg.Loss: -2.884,LR: 4.59E-05]Training epoch 81:  41%|████      | 62/153 [00:01<00:01, 52.64it/s, Epoch: 81, Batch: 63,Loss: -2.621,Avg.Loss: -2.880,LR: 4.59E-05]Training epoch 81:  41%|████      | 63/153 [00:01<00:01, 52.64it/s, Epoch: 81, Batch: 64,Loss: -2.659,Avg.Loss: -2.877,LR: 4.58E-05]Training epoch 81:  42%|████▏     | 64/153 [00:01<00:01, 52.64it/s, Epoch: 81, Batch: 65,Loss: -3.167,Avg.Loss: -2.881,LR: 4.58E-05]Training epoch 81:  42%|████▏     | 65/153 [00:01<00:01, 52.64it/s, Epoch: 81, Batch: 66,Loss: -3.147,Avg.Loss: -2.885,LR: 4.58E-05]Training epoch 81:  43%|████▎     | 66/153 [00:01<00:01, 52.65it/s, Epoch: 81, Batch: 66,Loss: -3.147,Avg.Loss: -2.885,LR: 4.58E-05]Training epoch 81:  43%|████▎     | 66/153 [00:01<00:01, 52.65it/s, Epoch: 81, Batch: 67,Loss: -2.538,Avg.Loss: -2.880,LR: 4.57E-05]Training epoch 81:  44%|████▍     | 67/153 [00:01<00:01, 52.65it/s, Epoch: 81, Batch: 68,Loss: -2.769,Avg.Loss: -2.878,LR: 4.57E-05]Training epoch 81:  44%|████▍     | 68/153 [00:01<00:01, 52.65it/s, Epoch: 81, Batch: 69,Loss: -2.633,Avg.Loss: -2.875,LR: 4.57E-05]Training epoch 81:  45%|████▌     | 69/153 [00:01<00:01, 52.65it/s, Epoch: 81, Batch: 70,Loss: -2.876,Avg.Loss: -2.875,LR: 4.57E-05]Training epoch 81:  46%|████▌     | 70/153 [00:01<00:01, 52.65it/s, Epoch: 81, Batch: 71,Loss: -3.124,Avg.Loss: -2.878,LR: 4.56E-05]Training epoch 81:  46%|████▋     | 71/153 [00:01<00:01, 52.65it/s, Epoch: 81, Batch: 72,Loss: -2.854,Avg.Loss: -2.878,LR: 4.56E-05]Training epoch 81:  47%|████▋     | 72/153 [00:01<00:01, 52.71it/s, Epoch: 81, Batch: 72,Loss: -2.854,Avg.Loss: -2.878,LR: 4.56E-05]Training epoch 81:  47%|████▋     | 72/153 [00:01<00:01, 52.71it/s, Epoch: 81, Batch: 73,Loss: -2.814,Avg.Loss: -2.877,LR: 4.56E-05]Training epoch 81:  48%|████▊     | 73/153 [00:01<00:01, 52.71it/s, Epoch: 81, Batch: 74,Loss: -2.762,Avg.Loss: -2.876,LR: 4.55E-05]Training epoch 81:  48%|████▊     | 74/153 [00:01<00:01, 52.71it/s, Epoch: 81, Batch: 75,Loss: -3.328,Avg.Loss: -2.882,LR: 4.55E-05]Training epoch 81:  49%|████▉     | 75/153 [00:01<00:01, 52.71it/s, Epoch: 81, Batch: 76,Loss: -3.387,Avg.Loss: -2.888,LR: 4.55E-05]Training epoch 81:  50%|████▉     | 76/153 [00:01<00:01, 52.71it/s, Epoch: 81, Batch: 77,Loss: -2.437,Avg.Loss: -2.882,LR: 4.54E-05]Training epoch 81:  50%|█████     | 77/153 [00:01<00:01, 52.71it/s, Epoch: 81, Batch: 78,Loss: -2.393,Avg.Loss: -2.876,LR: 4.54E-05]Training epoch 81:  51%|█████     | 78/153 [00:01<00:01, 52.87it/s, Epoch: 81, Batch: 78,Loss: -2.393,Avg.Loss: -2.876,LR: 4.54E-05]Training epoch 81:  51%|█████     | 78/153 [00:01<00:01, 52.87it/s, Epoch: 81, Batch: 79,Loss: -2.771,Avg.Loss: -2.875,LR: 4.54E-05]Training epoch 81:  52%|█████▏    | 79/153 [00:01<00:01, 52.87it/s, Epoch: 81, Batch: 80,Loss: -2.645,Avg.Loss: -2.872,LR: 4.54E-05]Training epoch 81:  52%|█████▏    | 80/153 [00:01<00:01, 52.87it/s, Epoch: 81, Batch: 81,Loss: -2.831,Avg.Loss: -2.871,LR: 4.53E-05]Training epoch 81:  53%|█████▎    | 81/153 [00:01<00:01, 52.87it/s, Epoch: 81, Batch: 82,Loss: -2.864,Avg.Loss: -2.871,LR: 4.53E-05]Training epoch 81:  54%|█████▎    | 82/153 [00:01<00:01, 52.87it/s, Epoch: 81, Batch: 83,Loss: -2.746,Avg.Loss: -2.870,LR: 4.53E-05]Training epoch 81:  54%|█████▍    | 83/153 [00:01<00:01, 52.87it/s, Epoch: 81, Batch: 84,Loss: -2.781,Avg.Loss: -2.869,LR: 4.52E-05]Training epoch 81:  55%|█████▍    | 84/153 [00:01<00:01, 52.76it/s, Epoch: 81, Batch: 84,Loss: -2.781,Avg.Loss: -2.869,LR: 4.52E-05]Training epoch 81:  55%|█████▍    | 84/153 [00:01<00:01, 52.76it/s, Epoch: 81, Batch: 85,Loss: -3.057,Avg.Loss: -2.871,LR: 4.52E-05]Training epoch 81:  56%|█████▌    | 85/153 [00:01<00:01, 52.76it/s, Epoch: 81, Batch: 86,Loss: -3.317,Avg.Loss: -2.876,LR: 4.52E-05]Training epoch 81:  56%|█████▌    | 86/153 [00:01<00:01, 52.76it/s, Epoch: 81, Batch: 87,Loss: -2.706,Avg.Loss: -2.874,LR: 4.52E-05]Training epoch 81:  57%|█████▋    | 87/153 [00:01<00:01, 52.76it/s, Epoch: 81, Batch: 88,Loss: -2.991,Avg.Loss: -2.875,LR: 4.51E-05]Training epoch 81:  58%|█████▊    | 88/153 [00:01<00:01, 52.76it/s, Epoch: 81, Batch: 89,Loss: -3.111,Avg.Loss: -2.878,LR: 4.51E-05]Training epoch 81:  58%|█████▊    | 89/153 [00:01<00:01, 52.76it/s, Epoch: 81, Batch: 90,Loss: -3.434,Avg.Loss: -2.884,LR: 4.51E-05]Training epoch 81:  59%|█████▉    | 90/153 [00:01<00:01, 52.92it/s, Epoch: 81, Batch: 90,Loss: -3.434,Avg.Loss: -2.884,LR: 4.51E-05]Training epoch 81:  59%|█████▉    | 90/153 [00:01<00:01, 52.92it/s, Epoch: 81, Batch: 91,Loss: -2.728,Avg.Loss: -2.883,LR: 4.50E-05]Training epoch 81:  59%|█████▉    | 91/153 [00:01<00:01, 52.92it/s, Epoch: 81, Batch: 92,Loss: -2.955,Avg.Loss: -2.883,LR: 4.50E-05]Training epoch 81:  60%|██████    | 92/153 [00:01<00:01, 52.92it/s, Epoch: 81, Batch: 93,Loss: -2.745,Avg.Loss: -2.882,LR: 4.50E-05]Training epoch 81:  61%|██████    | 93/153 [00:01<00:01, 52.92it/s, Epoch: 81, Batch: 94,Loss: -3.043,Avg.Loss: -2.884,LR: 4.49E-05]Training epoch 81:  61%|██████▏   | 94/153 [00:01<00:01, 52.92it/s, Epoch: 81, Batch: 95,Loss: -2.992,Avg.Loss: -2.885,LR: 4.49E-05]Training epoch 81:  62%|██████▏   | 95/153 [00:01<00:01, 52.92it/s, Epoch: 81, Batch: 96,Loss: -3.104,Avg.Loss: -2.887,LR: 4.49E-05]Training epoch 81:  63%|██████▎   | 96/153 [00:01<00:01, 53.09it/s, Epoch: 81, Batch: 96,Loss: -3.104,Avg.Loss: -2.887,LR: 4.49E-05]Training epoch 81:  63%|██████▎   | 96/153 [00:01<00:01, 53.09it/s, Epoch: 81, Batch: 97,Loss: -2.669,Avg.Loss: -2.885,LR: 4.49E-05]Training epoch 81:  63%|██████▎   | 97/153 [00:01<00:01, 53.09it/s, Epoch: 81, Batch: 98,Loss: -3.074,Avg.Loss: -2.887,LR: 4.48E-05]Training epoch 81:  64%|██████▍   | 98/153 [00:01<00:01, 53.09it/s, Epoch: 81, Batch: 99,Loss: -3.175,Avg.Loss: -2.890,LR: 4.48E-05]Training epoch 81:  65%|██████▍   | 99/153 [00:01<00:01, 53.09it/s, Epoch: 81, Batch: 100,Loss: -3.021,Avg.Loss: -2.891,LR: 4.48E-05]Training epoch 81:  65%|██████▌   | 100/153 [00:01<00:00, 53.09it/s, Epoch: 81, Batch: 101,Loss: -2.421,Avg.Loss: -2.886,LR: 4.47E-05]Training epoch 81:  66%|██████▌   | 101/153 [00:01<00:00, 53.09it/s, Epoch: 81, Batch: 102,Loss: -3.597,Avg.Loss: -2.893,LR: 4.47E-05]Training epoch 81:  67%|██████▋   | 102/153 [00:01<00:00, 52.92it/s, Epoch: 81, Batch: 102,Loss: -3.597,Avg.Loss: -2.893,LR: 4.47E-05]Training epoch 81:  67%|██████▋   | 102/153 [00:01<00:00, 52.92it/s, Epoch: 81, Batch: 103,Loss: -2.296,Avg.Loss: -2.887,LR: 4.47E-05]Training epoch 81:  67%|██████▋   | 103/153 [00:01<00:00, 52.92it/s, Epoch: 81, Batch: 104,Loss: -3.039,Avg.Loss: -2.889,LR: 4.47E-05]Training epoch 81:  68%|██████▊   | 104/153 [00:01<00:00, 52.92it/s, Epoch: 81, Batch: 105,Loss: -2.835,Avg.Loss: -2.888,LR: 4.46E-05]Training epoch 81:  69%|██████▊   | 105/153 [00:02<00:00, 52.92it/s, Epoch: 81, Batch: 106,Loss: -2.723,Avg.Loss: -2.887,LR: 4.46E-05]Training epoch 81:  69%|██████▉   | 106/153 [00:02<00:00, 52.92it/s, Epoch: 81, Batch: 107,Loss: -3.133,Avg.Loss: -2.889,LR: 4.46E-05]Training epoch 81:  70%|██████▉   | 107/153 [00:02<00:00, 52.92it/s, Epoch: 81, Batch: 108,Loss: -2.806,Avg.Loss: -2.888,LR: 4.45E-05]Training epoch 81:  71%|███████   | 108/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 108,Loss: -2.806,Avg.Loss: -2.888,LR: 4.45E-05]Training epoch 81:  71%|███████   | 108/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 109,Loss: -3.386,Avg.Loss: -2.893,LR: 4.45E-05]Training epoch 81:  71%|███████   | 109/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 110,Loss: -3.190,Avg.Loss: -2.896,LR: 4.45E-05]Training epoch 81:  72%|███████▏  | 110/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 111,Loss: -2.768,Avg.Loss: -2.895,LR: 4.44E-05]Training epoch 81:  73%|███████▎  | 111/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 112,Loss: -2.982,Avg.Loss: -2.895,LR: 4.44E-05]Training epoch 81:  73%|███████▎  | 112/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 113,Loss: -3.553,Avg.Loss: -2.901,LR: 4.44E-05]Training epoch 81:  74%|███████▍  | 113/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 114,Loss: -3.119,Avg.Loss: -2.903,LR: 4.44E-05]Training epoch 81:  75%|███████▍  | 114/153 [00:02<00:00, 52.95it/s, Epoch: 81, Batch: 114,Loss: -3.119,Avg.Loss: -2.903,LR: 4.44E-05]Training epoch 81:  75%|███████▍  | 114/153 [00:02<00:00, 52.95it/s, Epoch: 81, Batch: 115,Loss: -2.777,Avg.Loss: -2.902,LR: 4.43E-05]Training epoch 81:  75%|███████▌  | 115/153 [00:02<00:00, 52.95it/s, Epoch: 81, Batch: 116,Loss: -3.120,Avg.Loss: -2.904,LR: 4.43E-05]Training epoch 81:  76%|███████▌  | 116/153 [00:02<00:00, 52.95it/s, Epoch: 81, Batch: 117,Loss: -2.771,Avg.Loss: -2.903,LR: 4.43E-05]Training epoch 81:  76%|███████▋  | 117/153 [00:02<00:00, 52.95it/s, Epoch: 81, Batch: 118,Loss: -2.808,Avg.Loss: -2.902,LR: 4.42E-05]Training epoch 81:  77%|███████▋  | 118/153 [00:02<00:00, 52.95it/s, Epoch: 81, Batch: 119,Loss: -2.361,Avg.Loss: -2.897,LR: 4.42E-05]Training epoch 81:  78%|███████▊  | 119/153 [00:02<00:00, 52.95it/s, Epoch: 81, Batch: 120,Loss: -3.081,Avg.Loss: -2.899,LR: 4.42E-05]Training epoch 81:  78%|███████▊  | 120/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 120,Loss: -3.081,Avg.Loss: -2.899,LR: 4.42E-05]Training epoch 81:  78%|███████▊  | 120/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 121,Loss: -2.808,Avg.Loss: -2.898,LR: 4.42E-05]Training epoch 81:  79%|███████▉  | 121/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 122,Loss: -3.196,Avg.Loss: -2.901,LR: 4.41E-05]Training epoch 81:  80%|███████▉  | 122/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 123,Loss: -2.594,Avg.Loss: -2.898,LR: 4.41E-05]Training epoch 81:  80%|████████  | 123/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 124,Loss: -3.091,Avg.Loss: -2.900,LR: 4.41E-05]Training epoch 81:  81%|████████  | 124/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 125,Loss: -3.114,Avg.Loss: -2.901,LR: 4.40E-05]Training epoch 81:  82%|████████▏ | 125/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 126,Loss: -3.021,Avg.Loss: -2.902,LR: 4.40E-05]Training epoch 81:  82%|████████▏ | 126/153 [00:02<00:00, 53.02it/s, Epoch: 81, Batch: 126,Loss: -3.021,Avg.Loss: -2.902,LR: 4.40E-05]Training epoch 81:  82%|████████▏ | 126/153 [00:02<00:00, 53.02it/s, Epoch: 81, Batch: 127,Loss: -2.909,Avg.Loss: -2.902,LR: 4.40E-05]Training epoch 81:  83%|████████▎ | 127/153 [00:02<00:00, 53.02it/s, Epoch: 81, Batch: 128,Loss: -3.051,Avg.Loss: -2.903,LR: 4.40E-05]Training epoch 81:  84%|████████▎ | 128/153 [00:02<00:00, 53.02it/s, Epoch: 81, Batch: 129,Loss: -2.975,Avg.Loss: -2.904,LR: 4.39E-05]Training epoch 81:  84%|████████▍ | 129/153 [00:02<00:00, 53.02it/s, Epoch: 81, Batch: 130,Loss: -3.226,Avg.Loss: -2.907,LR: 4.39E-05]Training epoch 81:  85%|████████▍ | 130/153 [00:02<00:00, 53.02it/s, Epoch: 81, Batch: 131,Loss: -3.268,Avg.Loss: -2.909,LR: 4.39E-05]Training epoch 81:  86%|████████▌ | 131/153 [00:02<00:00, 53.02it/s, Epoch: 81, Batch: 132,Loss: -3.006,Avg.Loss: -2.910,LR: 4.38E-05]Training epoch 81:  86%|████████▋ | 132/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 132,Loss: -3.006,Avg.Loss: -2.910,LR: 4.38E-05]Training epoch 81:  86%|████████▋ | 132/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 133,Loss: -2.722,Avg.Loss: -2.909,LR: 4.38E-05]Training epoch 81:  87%|████████▋ | 133/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 134,Loss: -3.255,Avg.Loss: -2.911,LR: 4.38E-05]Training epoch 81:  88%|████████▊ | 134/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 135,Loss: -3.378,Avg.Loss: -2.915,LR: 4.38E-05]Training epoch 81:  88%|████████▊ | 135/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 136,Loss: -3.248,Avg.Loss: -2.917,LR: 4.37E-05]Training epoch 81:  89%|████████▉ | 136/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 137,Loss: -3.364,Avg.Loss: -2.920,LR: 4.37E-05]Training epoch 81:  90%|████████▉ | 137/153 [00:02<00:00, 53.05it/s, Epoch: 81, Batch: 138,Loss: -2.788,Avg.Loss: -2.919,LR: 4.37E-05]Training epoch 81:  90%|█████████ | 138/153 [00:02<00:00, 52.99it/s, Epoch: 81, Batch: 138,Loss: -2.788,Avg.Loss: -2.919,LR: 4.37E-05]Training epoch 81:  90%|█████████ | 138/153 [00:02<00:00, 52.99it/s, Epoch: 81, Batch: 139,Loss: -2.673,Avg.Loss: -2.918,LR: 4.36E-05]Training epoch 81:  91%|█████████ | 139/153 [00:02<00:00, 52.99it/s, Epoch: 81, Batch: 140,Loss: -2.475,Avg.Loss: -2.914,LR: 4.36E-05]Training epoch 81:  92%|█████████▏| 140/153 [00:02<00:00, 52.99it/s, Epoch: 81, Batch: 141,Loss: -2.346,Avg.Loss: -2.910,LR: 4.36E-05]Training epoch 81:  92%|█████████▏| 141/153 [00:02<00:00, 52.99it/s, Epoch: 81, Batch: 142,Loss: -2.950,Avg.Loss: -2.911,LR: 4.35E-05]Training epoch 81:  93%|█████████▎| 142/153 [00:02<00:00, 52.99it/s, Epoch: 81, Batch: 143,Loss: -2.707,Avg.Loss: -2.909,LR: 4.35E-05]Training epoch 81:  93%|█████████▎| 143/153 [00:02<00:00, 52.99it/s, Epoch: 81, Batch: 144,Loss: -3.270,Avg.Loss: -2.912,LR: 4.35E-05]Training epoch 81:  94%|█████████▍| 144/153 [00:02<00:00, 53.13it/s, Epoch: 81, Batch: 144,Loss: -3.270,Avg.Loss: -2.912,LR: 4.35E-05]Training epoch 81:  94%|█████████▍| 144/153 [00:02<00:00, 53.13it/s, Epoch: 81, Batch: 145,Loss: -2.333,Avg.Loss: -2.908,LR: 4.35E-05]Training epoch 81:  95%|█████████▍| 145/153 [00:02<00:00, 53.13it/s, Epoch: 81, Batch: 146,Loss: -2.623,Avg.Loss: -2.906,LR: 4.34E-05]Training epoch 81:  95%|█████████▌| 146/153 [00:02<00:00, 53.13it/s, Epoch: 81, Batch: 147,Loss: -2.237,Avg.Loss: -2.901,LR: 4.34E-05]Training epoch 81:  96%|█████████▌| 147/153 [00:02<00:00, 53.13it/s, Epoch: 81, Batch: 148,Loss: -2.232,Avg.Loss: -2.897,LR: 4.34E-05]Training epoch 81:  97%|█████████▋| 148/153 [00:02<00:00, 53.13it/s, Epoch: 81, Batch: 149,Loss: -2.533,Avg.Loss: -2.894,LR: 4.33E-05]Training epoch 81:  97%|█████████▋| 149/153 [00:02<00:00, 53.13it/s, Epoch: 81, Batch: 150,Loss: -2.936,Avg.Loss: -2.895,LR: 4.33E-05]Training epoch 81:  98%|█████████▊| 150/153 [00:02<00:00, 53.00it/s, Epoch: 81, Batch: 150,Loss: -2.936,Avg.Loss: -2.895,LR: 4.33E-05]Training epoch 81:  98%|█████████▊| 150/153 [00:02<00:00, 53.00it/s, Epoch: 81, Batch: 151,Loss: -2.857,Avg.Loss: -2.894,LR: 4.33E-05]Training epoch 81:  99%|█████████▊| 151/153 [00:02<00:00, 53.00it/s, Epoch: 81, Batch: 152,Loss: -2.652,Avg.Loss: -2.893,LR: 4.33E-05]Training epoch 81:  99%|█████████▉| 152/153 [00:02<00:00, 53.00it/s, Epoch: 81, Batch: 153,Loss: -2.228,Avg.Loss: -2.888,LR: 4.32E-05]Training epoch 81: 100%|██████████| 153/153 [00:02<00:00, 52.83it/s, Epoch: 81, Batch: 153,Loss: -2.228,Avg.Loss: -2.888,LR: 4.32E-05]
Training epoch 82:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 82:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 82, Batch: 1,Loss: -2.263,Avg.Loss: -2.263,LR: 4.32E-05]Training epoch 82:   1%|          | 1/153 [00:00<00:05, 25.80it/s, Epoch: 82, Batch: 2,Loss: -2.496,Avg.Loss: -2.379,LR: 4.32E-05]Training epoch 82:   1%|▏         | 2/153 [00:00<00:03, 38.46it/s, Epoch: 82, Batch: 3,Loss: -2.193,Avg.Loss: -2.317,LR: 4.31E-05]Training epoch 82:   2%|▏         | 3/153 [00:00<00:03, 43.90it/s, Epoch: 82, Batch: 4,Loss: -2.823,Avg.Loss: -2.444,LR: 4.31E-05]Training epoch 82:   3%|▎         | 4/153 [00:00<00:03, 46.44it/s, Epoch: 82, Batch: 5,Loss: -2.761,Avg.Loss: -2.507,LR: 4.31E-05]Training epoch 82:   3%|▎         | 5/153 [00:00<00:03, 48.12it/s, Epoch: 82, Batch: 6,Loss: -3.261,Avg.Loss: -2.633,LR: 4.31E-05]Training epoch 82:   4%|▍         | 6/153 [00:00<00:02, 57.64it/s, Epoch: 82, Batch: 6,Loss: -3.261,Avg.Loss: -2.633,LR: 4.31E-05]Training epoch 82:   4%|▍         | 6/153 [00:00<00:02, 57.64it/s, Epoch: 82, Batch: 7,Loss: -2.344,Avg.Loss: -2.592,LR: 4.30E-05]Training epoch 82:   5%|▍         | 7/153 [00:00<00:02, 57.64it/s, Epoch: 82, Batch: 8,Loss: -2.668,Avg.Loss: -2.601,LR: 4.30E-05]Training epoch 82:   5%|▌         | 8/153 [00:00<00:02, 57.64it/s, Epoch: 82, Batch: 9,Loss: -3.182,Avg.Loss: -2.666,LR: 4.30E-05]Training epoch 82:   6%|▌         | 9/153 [00:00<00:02, 57.64it/s, Epoch: 82, Batch: 10,Loss: -3.294,Avg.Loss: -2.729,LR: 4.29E-05]Training epoch 82:   7%|▋         | 10/153 [00:00<00:02, 57.64it/s, Epoch: 82, Batch: 11,Loss: -3.291,Avg.Loss: -2.780,LR: 4.29E-05]Training epoch 82:   7%|▋         | 11/153 [00:00<00:02, 57.64it/s, Epoch: 82, Batch: 12,Loss: -2.578,Avg.Loss: -2.763,LR: 4.29E-05]Training epoch 82:   8%|▊         | 12/153 [00:00<00:02, 54.56it/s, Epoch: 82, Batch: 12,Loss: -2.578,Avg.Loss: -2.763,LR: 4.29E-05]Training epoch 82:   8%|▊         | 12/153 [00:00<00:02, 54.56it/s, Epoch: 82, Batch: 13,Loss: -2.980,Avg.Loss: -2.780,LR: 4.29E-05]Training epoch 82:   8%|▊         | 13/153 [00:00<00:02, 54.56it/s, Epoch: 82, Batch: 14,Loss: -2.781,Avg.Loss: -2.780,LR: 4.28E-05]Training epoch 82:   9%|▉         | 14/153 [00:00<00:02, 54.56it/s, Epoch: 82, Batch: 15,Loss: -2.767,Avg.Loss: -2.779,LR: 4.28E-05]Training epoch 82:  10%|▉         | 15/153 [00:00<00:02, 54.56it/s, Epoch: 82, Batch: 16,Loss: -2.955,Avg.Loss: -2.790,LR: 4.28E-05]Training epoch 82:  10%|█         | 16/153 [00:00<00:02, 54.56it/s, Epoch: 82, Batch: 17,Loss: -3.025,Avg.Loss: -2.804,LR: 4.27E-05]Training epoch 82:  11%|█         | 17/153 [00:00<00:02, 54.56it/s, Epoch: 82, Batch: 18,Loss: -3.035,Avg.Loss: -2.817,LR: 4.27E-05]Training epoch 82:  12%|█▏        | 18/153 [00:00<00:02, 53.62it/s, Epoch: 82, Batch: 18,Loss: -3.035,Avg.Loss: -2.817,LR: 4.27E-05]Training epoch 82:  12%|█▏        | 18/153 [00:00<00:02, 53.62it/s, Epoch: 82, Batch: 19,Loss: -2.951,Avg.Loss: -2.824,LR: 4.27E-05]Training epoch 82:  12%|█▏        | 19/153 [00:00<00:02, 53.62it/s, Epoch: 82, Batch: 20,Loss: -3.168,Avg.Loss: -2.841,LR: 4.27E-05]Training epoch 82:  13%|█▎        | 20/153 [00:00<00:02, 53.62it/s, Epoch: 82, Batch: 21,Loss: -3.034,Avg.Loss: -2.850,LR: 4.26E-05]Training epoch 82:  14%|█▎        | 21/153 [00:00<00:02, 53.62it/s, Epoch: 82, Batch: 22,Loss: -3.167,Avg.Loss: -2.864,LR: 4.26E-05]Training epoch 82:  14%|█▍        | 22/153 [00:00<00:02, 53.62it/s, Epoch: 82, Batch: 23,Loss: -3.001,Avg.Loss: -2.870,LR: 4.26E-05]Training epoch 82:  15%|█▌        | 23/153 [00:00<00:02, 53.62it/s, Epoch: 82, Batch: 24,Loss: -2.724,Avg.Loss: -2.864,LR: 4.25E-05]Training epoch 82:  16%|█▌        | 24/153 [00:00<00:02, 52.98it/s, Epoch: 82, Batch: 24,Loss: -2.724,Avg.Loss: -2.864,LR: 4.25E-05]Training epoch 82:  16%|█▌        | 24/153 [00:00<00:02, 52.98it/s, Epoch: 82, Batch: 25,Loss: -3.123,Avg.Loss: -2.875,LR: 4.25E-05]Training epoch 82:  16%|█▋        | 25/153 [00:00<00:02, 52.98it/s, Epoch: 82, Batch: 26,Loss: -2.881,Avg.Loss: -2.875,LR: 4.25E-05]Training epoch 82:  17%|█▋        | 26/153 [00:00<00:02, 52.98it/s, Epoch: 82, Batch: 27,Loss: -3.163,Avg.Loss: -2.886,LR: 4.25E-05]Training epoch 82:  18%|█▊        | 27/153 [00:00<00:02, 52.98it/s, Epoch: 82, Batch: 28,Loss: -3.222,Avg.Loss: -2.898,LR: 4.24E-05]Training epoch 82:  18%|█▊        | 28/153 [00:00<00:02, 52.98it/s, Epoch: 82, Batch: 29,Loss: -2.533,Avg.Loss: -2.885,LR: 4.24E-05]Training epoch 82:  19%|█▉        | 29/153 [00:00<00:02, 52.98it/s, Epoch: 82, Batch: 30,Loss: -3.063,Avg.Loss: -2.891,LR: 4.24E-05]Training epoch 82:  20%|█▉        | 30/153 [00:00<00:02, 52.78it/s, Epoch: 82, Batch: 30,Loss: -3.063,Avg.Loss: -2.891,LR: 4.24E-05]Training epoch 82:  20%|█▉        | 30/153 [00:00<00:02, 52.78it/s, Epoch: 82, Batch: 31,Loss: -2.851,Avg.Loss: -2.890,LR: 4.23E-05]Training epoch 82:  20%|██        | 31/153 [00:00<00:02, 52.78it/s, Epoch: 82, Batch: 32,Loss: -3.283,Avg.Loss: -2.902,LR: 4.23E-05]Training epoch 82:  21%|██        | 32/153 [00:00<00:02, 52.78it/s, Epoch: 82, Batch: 33,Loss: -2.970,Avg.Loss: -2.904,LR: 4.23E-05]Training epoch 82:  22%|██▏       | 33/153 [00:00<00:02, 52.78it/s, Epoch: 82, Batch: 34,Loss: -3.050,Avg.Loss: -2.908,LR: 4.23E-05]Training epoch 82:  22%|██▏       | 34/153 [00:00<00:02, 52.78it/s, Epoch: 82, Batch: 35,Loss: -2.896,Avg.Loss: -2.908,LR: 4.22E-05]Training epoch 82:  23%|██▎       | 35/153 [00:00<00:02, 52.78it/s, Epoch: 82, Batch: 36,Loss: -2.203,Avg.Loss: -2.888,LR: 4.22E-05]Training epoch 82:  24%|██▎       | 36/153 [00:00<00:02, 53.20it/s, Epoch: 82, Batch: 36,Loss: -2.203,Avg.Loss: -2.888,LR: 4.22E-05]Training epoch 82:  24%|██▎       | 36/153 [00:00<00:02, 53.20it/s, Epoch: 82, Batch: 37,Loss: -2.595,Avg.Loss: -2.880,LR: 4.22E-05]Training epoch 82:  24%|██▍       | 37/153 [00:00<00:02, 53.20it/s, Epoch: 82, Batch: 38,Loss: -2.831,Avg.Loss: -2.879,LR: 4.21E-05]Training epoch 82:  25%|██▍       | 38/153 [00:00<00:02, 53.20it/s, Epoch: 82, Batch: 39,Loss: -2.673,Avg.Loss: -2.874,LR: 4.21E-05]Training epoch 82:  25%|██▌       | 39/153 [00:00<00:02, 53.20it/s, Epoch: 82, Batch: 40,Loss: -3.232,Avg.Loss: -2.883,LR: 4.21E-05]Training epoch 82:  26%|██▌       | 40/153 [00:00<00:02, 53.20it/s, Epoch: 82, Batch: 41,Loss: -3.291,Avg.Loss: -2.893,LR: 4.21E-05]Training epoch 82:  27%|██▋       | 41/153 [00:00<00:02, 53.20it/s, Epoch: 82, Batch: 42,Loss: -2.884,Avg.Loss: -2.893,LR: 4.20E-05]Training epoch 82:  27%|██▋       | 42/153 [00:00<00:02, 53.07it/s, Epoch: 82, Batch: 42,Loss: -2.884,Avg.Loss: -2.893,LR: 4.20E-05]Training epoch 82:  27%|██▋       | 42/153 [00:00<00:02, 53.07it/s, Epoch: 82, Batch: 43,Loss: -2.647,Avg.Loss: -2.887,LR: 4.20E-05]Training epoch 82:  28%|██▊       | 43/153 [00:00<00:02, 53.07it/s, Epoch: 82, Batch: 44,Loss: -2.892,Avg.Loss: -2.887,LR: 4.20E-05]Training epoch 82:  29%|██▉       | 44/153 [00:00<00:02, 53.07it/s, Epoch: 82, Batch: 45,Loss: -2.703,Avg.Loss: -2.883,LR: 4.19E-05]Training epoch 82:  29%|██▉       | 45/153 [00:00<00:02, 53.07it/s, Epoch: 82, Batch: 46,Loss: -3.053,Avg.Loss: -2.887,LR: 4.19E-05]Training epoch 82:  30%|███       | 46/153 [00:00<00:02, 53.07it/s, Epoch: 82, Batch: 47,Loss: -2.990,Avg.Loss: -2.889,LR: 4.19E-05]Training epoch 82:  31%|███       | 47/153 [00:00<00:01, 53.07it/s, Epoch: 82, Batch: 48,Loss: -2.931,Avg.Loss: -2.890,LR: 4.19E-05]Training epoch 82:  31%|███▏      | 48/153 [00:00<00:01, 52.91it/s, Epoch: 82, Batch: 48,Loss: -2.931,Avg.Loss: -2.890,LR: 4.19E-05]Training epoch 82:  31%|███▏      | 48/153 [00:00<00:01, 52.91it/s, Epoch: 82, Batch: 49,Loss: -2.483,Avg.Loss: -2.881,LR: 4.18E-05]Training epoch 82:  32%|███▏      | 49/153 [00:00<00:01, 52.91it/s, Epoch: 82, Batch: 50,Loss: -2.636,Avg.Loss: -2.876,LR: 4.18E-05]Training epoch 82:  33%|███▎      | 50/153 [00:00<00:01, 52.91it/s, Epoch: 82, Batch: 51,Loss: -3.209,Avg.Loss: -2.883,LR: 4.18E-05]Training epoch 82:  33%|███▎      | 51/153 [00:00<00:01, 52.91it/s, Epoch: 82, Batch: 52,Loss: -2.537,Avg.Loss: -2.876,LR: 4.17E-05]Training epoch 82:  34%|███▍      | 52/153 [00:00<00:01, 52.91it/s, Epoch: 82, Batch: 53,Loss: -2.888,Avg.Loss: -2.876,LR: 4.17E-05]Training epoch 82:  35%|███▍      | 53/153 [00:01<00:01, 52.91it/s, Epoch: 82, Batch: 54,Loss: -2.672,Avg.Loss: -2.873,LR: 4.17E-05]Training epoch 82:  35%|███▌      | 54/153 [00:01<00:01, 52.86it/s, Epoch: 82, Batch: 54,Loss: -2.672,Avg.Loss: -2.873,LR: 4.17E-05]Training epoch 82:  35%|███▌      | 54/153 [00:01<00:01, 52.86it/s, Epoch: 82, Batch: 55,Loss: -3.216,Avg.Loss: -2.879,LR: 4.17E-05]Training epoch 82:  36%|███▌      | 55/153 [00:01<00:01, 52.86it/s, Epoch: 82, Batch: 56,Loss: -2.869,Avg.Loss: -2.879,LR: 4.16E-05]Training epoch 82:  37%|███▋      | 56/153 [00:01<00:01, 52.86it/s, Epoch: 82, Batch: 57,Loss: -2.438,Avg.Loss: -2.871,LR: 4.16E-05]Training epoch 82:  37%|███▋      | 57/153 [00:01<00:01, 52.86it/s, Epoch: 82, Batch: 58,Loss: -3.107,Avg.Loss: -2.875,LR: 4.16E-05]Training epoch 82:  38%|███▊      | 58/153 [00:01<00:01, 52.86it/s, Epoch: 82, Batch: 59,Loss: -2.938,Avg.Loss: -2.876,LR: 4.15E-05]Training epoch 82:  39%|███▊      | 59/153 [00:01<00:01, 52.86it/s, Epoch: 82, Batch: 60,Loss: -2.710,Avg.Loss: -2.873,LR: 4.15E-05]Training epoch 82:  39%|███▉      | 60/153 [00:01<00:01, 52.75it/s, Epoch: 82, Batch: 60,Loss: -2.710,Avg.Loss: -2.873,LR: 4.15E-05]Training epoch 82:  39%|███▉      | 60/153 [00:01<00:01, 52.75it/s, Epoch: 82, Batch: 61,Loss: -2.673,Avg.Loss: -2.870,LR: 4.15E-05]Training epoch 82:  40%|███▉      | 61/153 [00:01<00:01, 52.75it/s, Epoch: 82, Batch: 62,Loss: -3.438,Avg.Loss: -2.879,LR: 4.15E-05]Training epoch 82:  41%|████      | 62/153 [00:01<00:01, 52.75it/s, Epoch: 82, Batch: 63,Loss: -2.813,Avg.Loss: -2.878,LR: 4.14E-05]Training epoch 82:  41%|████      | 63/153 [00:01<00:01, 52.75it/s, Epoch: 82, Batch: 64,Loss: -3.205,Avg.Loss: -2.883,LR: 4.14E-05]Training epoch 82:  42%|████▏     | 64/153 [00:01<00:01, 52.75it/s, Epoch: 82, Batch: 65,Loss: -2.838,Avg.Loss: -2.883,LR: 4.14E-05]Training epoch 82:  42%|████▏     | 65/153 [00:01<00:01, 52.75it/s, Epoch: 82, Batch: 66,Loss: -2.660,Avg.Loss: -2.879,LR: 4.13E-05]Training epoch 82:  43%|████▎     | 66/153 [00:01<00:01, 52.66it/s, Epoch: 82, Batch: 66,Loss: -2.660,Avg.Loss: -2.879,LR: 4.13E-05]Training epoch 82:  43%|████▎     | 66/153 [00:01<00:01, 52.66it/s, Epoch: 82, Batch: 67,Loss: -3.305,Avg.Loss: -2.886,LR: 4.13E-05]Training epoch 82:  44%|████▍     | 67/153 [00:01<00:01, 52.66it/s, Epoch: 82, Batch: 68,Loss: -2.992,Avg.Loss: -2.887,LR: 4.13E-05]Training epoch 82:  44%|████▍     | 68/153 [00:01<00:01, 52.66it/s, Epoch: 82, Batch: 69,Loss: -2.571,Avg.Loss: -2.883,LR: 4.13E-05]Training epoch 82:  45%|████▌     | 69/153 [00:01<00:01, 52.66it/s, Epoch: 82, Batch: 70,Loss: -3.303,Avg.Loss: -2.889,LR: 4.12E-05]Training epoch 82:  46%|████▌     | 70/153 [00:01<00:01, 52.66it/s, Epoch: 82, Batch: 71,Loss: -2.965,Avg.Loss: -2.890,LR: 4.12E-05]Training epoch 82:  46%|████▋     | 71/153 [00:01<00:01, 52.66it/s, Epoch: 82, Batch: 72,Loss: -2.763,Avg.Loss: -2.888,LR: 4.12E-05]Training epoch 82:  47%|████▋     | 72/153 [00:01<00:01, 52.61it/s, Epoch: 82, Batch: 72,Loss: -2.763,Avg.Loss: -2.888,LR: 4.12E-05]Training epoch 82:  47%|████▋     | 72/153 [00:01<00:01, 52.61it/s, Epoch: 82, Batch: 73,Loss: -3.105,Avg.Loss: -2.891,LR: 4.11E-05]Training epoch 82:  48%|████▊     | 73/153 [00:01<00:01, 52.61it/s, Epoch: 82, Batch: 74,Loss: -3.241,Avg.Loss: -2.896,LR: 4.11E-05]Training epoch 82:  48%|████▊     | 74/153 [00:01<00:01, 52.61it/s, Epoch: 82, Batch: 75,Loss: -2.711,Avg.Loss: -2.893,LR: 4.11E-05]Training epoch 82:  49%|████▉     | 75/153 [00:01<00:01, 52.61it/s, Epoch: 82, Batch: 76,Loss: -2.660,Avg.Loss: -2.890,LR: 4.11E-05]Training epoch 82:  50%|████▉     | 76/153 [00:01<00:01, 52.61it/s, Epoch: 82, Batch: 77,Loss: -3.285,Avg.Loss: -2.895,LR: 4.10E-05]Training epoch 82:  50%|█████     | 77/153 [00:01<00:01, 52.61it/s, Epoch: 82, Batch: 78,Loss: -3.087,Avg.Loss: -2.898,LR: 4.10E-05]Training epoch 82:  51%|█████     | 78/153 [00:01<00:01, 52.57it/s, Epoch: 82, Batch: 78,Loss: -3.087,Avg.Loss: -2.898,LR: 4.10E-05]Training epoch 82:  51%|█████     | 78/153 [00:01<00:01, 52.57it/s, Epoch: 82, Batch: 79,Loss: -2.603,Avg.Loss: -2.894,LR: 4.10E-05]Training epoch 82:  52%|█████▏    | 79/153 [00:01<00:01, 52.57it/s, Epoch: 82, Batch: 80,Loss: -2.491,Avg.Loss: -2.889,LR: 4.09E-05]Training epoch 82:  52%|█████▏    | 80/153 [00:01<00:01, 52.57it/s, Epoch: 82, Batch: 81,Loss: -2.662,Avg.Loss: -2.886,LR: 4.09E-05]Training epoch 82:  53%|█████▎    | 81/153 [00:01<00:01, 52.57it/s, Epoch: 82, Batch: 82,Loss: -2.904,Avg.Loss: -2.886,LR: 4.09E-05]Training epoch 82:  54%|█████▎    | 82/153 [00:01<00:01, 52.57it/s, Epoch: 82, Batch: 83,Loss: -3.250,Avg.Loss: -2.891,LR: 4.09E-05]Training epoch 82:  54%|█████▍    | 83/153 [00:01<00:01, 52.57it/s, Epoch: 82, Batch: 84,Loss: -2.686,Avg.Loss: -2.888,LR: 4.08E-05]Training epoch 82:  55%|█████▍    | 84/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 84,Loss: -2.686,Avg.Loss: -2.888,LR: 4.08E-05]Training epoch 82:  55%|█████▍    | 84/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 85,Loss: -2.702,Avg.Loss: -2.886,LR: 4.08E-05]Training epoch 82:  56%|█████▌    | 85/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 86,Loss: -3.262,Avg.Loss: -2.890,LR: 4.08E-05]Training epoch 82:  56%|█████▌    | 86/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 87,Loss: -2.937,Avg.Loss: -2.891,LR: 4.08E-05]Training epoch 82:  57%|█████▋    | 87/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 88,Loss: -2.554,Avg.Loss: -2.887,LR: 4.07E-05]Training epoch 82:  58%|█████▊    | 88/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 89,Loss: -3.278,Avg.Loss: -2.892,LR: 4.07E-05]Training epoch 82:  58%|█████▊    | 89/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 90,Loss: -2.916,Avg.Loss: -2.892,LR: 4.07E-05]Training epoch 82:  59%|█████▉    | 90/153 [00:01<00:01, 52.49it/s, Epoch: 82, Batch: 90,Loss: -2.916,Avg.Loss: -2.892,LR: 4.07E-05]Training epoch 82:  59%|█████▉    | 90/153 [00:01<00:01, 52.49it/s, Epoch: 82, Batch: 91,Loss: -3.091,Avg.Loss: -2.894,LR: 4.06E-05]Training epoch 82:  59%|█████▉    | 91/153 [00:01<00:01, 52.49it/s, Epoch: 82, Batch: 92,Loss: -2.374,Avg.Loss: -2.888,LR: 4.06E-05]Training epoch 82:  60%|██████    | 92/153 [00:01<00:01, 52.49it/s, Epoch: 82, Batch: 93,Loss: -2.906,Avg.Loss: -2.889,LR: 4.06E-05]Training epoch 82:  61%|██████    | 93/153 [00:01<00:01, 52.49it/s, Epoch: 82, Batch: 94,Loss: -3.127,Avg.Loss: -2.891,LR: 4.06E-05]Training epoch 82:  61%|██████▏   | 94/153 [00:01<00:01, 52.49it/s, Epoch: 82, Batch: 95,Loss: -3.095,Avg.Loss: -2.893,LR: 4.05E-05]Training epoch 82:  62%|██████▏   | 95/153 [00:01<00:01, 52.49it/s, Epoch: 82, Batch: 96,Loss: -3.699,Avg.Loss: -2.902,LR: 4.05E-05]Training epoch 82:  63%|██████▎   | 96/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 96,Loss: -3.699,Avg.Loss: -2.902,LR: 4.05E-05]Training epoch 82:  63%|██████▎   | 96/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 97,Loss: -3.065,Avg.Loss: -2.903,LR: 4.05E-05]Training epoch 82:  63%|██████▎   | 97/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 98,Loss: -2.681,Avg.Loss: -2.901,LR: 4.04E-05]Training epoch 82:  64%|██████▍   | 98/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 99,Loss: -2.809,Avg.Loss: -2.900,LR: 4.04E-05]Training epoch 82:  65%|██████▍   | 99/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 100,Loss: -3.102,Avg.Loss: -2.902,LR: 4.04E-05]Training epoch 82:  65%|██████▌   | 100/153 [00:01<00:01, 52.51it/s, Epoch: 82, Batch: 101,Loss: -3.014,Avg.Loss: -2.903,LR: 4.04E-05]Training epoch 82:  66%|██████▌   | 101/153 [00:01<00:00, 52.51it/s, Epoch: 82, Batch: 102,Loss: -3.021,Avg.Loss: -2.904,LR: 4.03E-05]Training epoch 82:  67%|██████▋   | 102/153 [00:01<00:00, 52.60it/s, Epoch: 82, Batch: 102,Loss: -3.021,Avg.Loss: -2.904,LR: 4.03E-05]Training epoch 82:  67%|██████▋   | 102/153 [00:01<00:00, 52.60it/s, Epoch: 82, Batch: 103,Loss: -2.988,Avg.Loss: -2.905,LR: 4.03E-05]Training epoch 82:  67%|██████▋   | 103/153 [00:01<00:00, 52.60it/s, Epoch: 82, Batch: 104,Loss: -3.370,Avg.Loss: -2.910,LR: 4.03E-05]Training epoch 82:  68%|██████▊   | 104/153 [00:01<00:00, 52.60it/s, Epoch: 82, Batch: 105,Loss: -2.610,Avg.Loss: -2.907,LR: 4.02E-05]Training epoch 82:  69%|██████▊   | 105/153 [00:02<00:00, 52.60it/s, Epoch: 82, Batch: 106,Loss: -3.257,Avg.Loss: -2.910,LR: 4.02E-05]Training epoch 82:  69%|██████▉   | 106/153 [00:02<00:00, 52.60it/s, Epoch: 82, Batch: 107,Loss: -3.248,Avg.Loss: -2.913,LR: 4.02E-05]Training epoch 82:  70%|██████▉   | 107/153 [00:02<00:00, 52.60it/s, Epoch: 82, Batch: 108,Loss: -3.199,Avg.Loss: -2.916,LR: 4.02E-05]Training epoch 82:  71%|███████   | 108/153 [00:02<00:00, 52.65it/s, Epoch: 82, Batch: 108,Loss: -3.199,Avg.Loss: -2.916,LR: 4.02E-05]Training epoch 82:  71%|███████   | 108/153 [00:02<00:00, 52.65it/s, Epoch: 82, Batch: 109,Loss: -3.194,Avg.Loss: -2.919,LR: 4.01E-05]Training epoch 82:  71%|███████   | 109/153 [00:02<00:00, 52.65it/s, Epoch: 82, Batch: 110,Loss: -2.960,Avg.Loss: -2.919,LR: 4.01E-05]Training epoch 82:  72%|███████▏  | 110/153 [00:02<00:00, 52.65it/s, Epoch: 82, Batch: 111,Loss: -2.885,Avg.Loss: -2.919,LR: 4.01E-05]Training epoch 82:  73%|███████▎  | 111/153 [00:02<00:00, 52.65it/s, Epoch: 82, Batch: 112,Loss: -2.900,Avg.Loss: -2.918,LR: 4.01E-05]Training epoch 82:  73%|███████▎  | 112/153 [00:02<00:00, 52.65it/s, Epoch: 82, Batch: 113,Loss: -2.418,Avg.Loss: -2.914,LR: 4.00E-05]Training epoch 82:  74%|███████▍  | 113/153 [00:02<00:00, 52.65it/s, Epoch: 82, Batch: 114,Loss: -2.805,Avg.Loss: -2.913,LR: 4.00E-05]Training epoch 82:  75%|███████▍  | 114/153 [00:02<00:00, 52.61it/s, Epoch: 82, Batch: 114,Loss: -2.805,Avg.Loss: -2.913,LR: 4.00E-05]Training epoch 82:  75%|███████▍  | 114/153 [00:02<00:00, 52.61it/s, Epoch: 82, Batch: 115,Loss: -2.913,Avg.Loss: -2.913,LR: 4.00E-05]Training epoch 82:  75%|███████▌  | 115/153 [00:02<00:00, 52.61it/s, Epoch: 82, Batch: 116,Loss: -2.983,Avg.Loss: -2.914,LR: 3.99E-05]Training epoch 82:  76%|███████▌  | 116/153 [00:02<00:00, 52.61it/s, Epoch: 82, Batch: 117,Loss: -2.873,Avg.Loss: -2.913,LR: 3.99E-05]Training epoch 82:  76%|███████▋  | 117/153 [00:02<00:00, 52.61it/s, Epoch: 82, Batch: 118,Loss: -2.982,Avg.Loss: -2.914,LR: 3.99E-05]Training epoch 82:  77%|███████▋  | 118/153 [00:02<00:00, 52.61it/s, Epoch: 82, Batch: 119,Loss: -2.996,Avg.Loss: -2.915,LR: 3.99E-05]Training epoch 82:  78%|███████▊  | 119/153 [00:02<00:00, 52.61it/s, Epoch: 82, Batch: 120,Loss: -2.679,Avg.Loss: -2.913,LR: 3.98E-05]Training epoch 82:  78%|███████▊  | 120/153 [00:02<00:00, 52.59it/s, Epoch: 82, Batch: 120,Loss: -2.679,Avg.Loss: -2.913,LR: 3.98E-05]Training epoch 82:  78%|███████▊  | 120/153 [00:02<00:00, 52.59it/s, Epoch: 82, Batch: 121,Loss: -3.197,Avg.Loss: -2.915,LR: 3.98E-05]Training epoch 82:  79%|███████▉  | 121/153 [00:02<00:00, 52.59it/s, Epoch: 82, Batch: 122,Loss: -2.793,Avg.Loss: -2.914,LR: 3.98E-05]Training epoch 82:  80%|███████▉  | 122/153 [00:02<00:00, 52.59it/s, Epoch: 82, Batch: 123,Loss: -2.361,Avg.Loss: -2.909,LR: 3.97E-05]Training epoch 82:  80%|████████  | 123/153 [00:02<00:00, 52.59it/s, Epoch: 82, Batch: 124,Loss: -3.114,Avg.Loss: -2.911,LR: 3.97E-05]Training epoch 82:  81%|████████  | 124/153 [00:02<00:00, 52.59it/s, Epoch: 82, Batch: 125,Loss: -3.005,Avg.Loss: -2.912,LR: 3.97E-05]Training epoch 82:  82%|████████▏ | 125/153 [00:02<00:00, 52.59it/s, Epoch: 82, Batch: 126,Loss: -3.040,Avg.Loss: -2.913,LR: 3.97E-05]Training epoch 82:  82%|████████▏ | 126/153 [00:02<00:00, 52.67it/s, Epoch: 82, Batch: 126,Loss: -3.040,Avg.Loss: -2.913,LR: 3.97E-05]Training epoch 82:  82%|████████▏ | 126/153 [00:02<00:00, 52.67it/s, Epoch: 82, Batch: 127,Loss: -2.753,Avg.Loss: -2.912,LR: 3.96E-05]Training epoch 82:  83%|████████▎ | 127/153 [00:02<00:00, 52.67it/s, Epoch: 82, Batch: 128,Loss: -3.502,Avg.Loss: -2.916,LR: 3.96E-05]Training epoch 82:  84%|████████▎ | 128/153 [00:02<00:00, 52.67it/s, Epoch: 82, Batch: 129,Loss: -2.642,Avg.Loss: -2.914,LR: 3.96E-05]Training epoch 82:  84%|████████▍ | 129/153 [00:02<00:00, 52.67it/s, Epoch: 82, Batch: 130,Loss: -3.227,Avg.Loss: -2.917,LR: 3.96E-05]Training epoch 82:  85%|████████▍ | 130/153 [00:02<00:00, 52.67it/s, Epoch: 82, Batch: 131,Loss: -2.967,Avg.Loss: -2.917,LR: 3.95E-05]Training epoch 82:  86%|████████▌ | 131/153 [00:02<00:00, 52.67it/s, Epoch: 82, Batch: 132,Loss: -2.977,Avg.Loss: -2.917,LR: 3.95E-05]Training epoch 82:  86%|████████▋ | 132/153 [00:02<00:00, 52.75it/s, Epoch: 82, Batch: 132,Loss: -2.977,Avg.Loss: -2.917,LR: 3.95E-05]Training epoch 82:  86%|████████▋ | 132/153 [00:02<00:00, 52.75it/s, Epoch: 82, Batch: 133,Loss: -2.852,Avg.Loss: -2.917,LR: 3.95E-05]Training epoch 82:  87%|████████▋ | 133/153 [00:02<00:00, 52.75it/s, Epoch: 82, Batch: 134,Loss: -3.091,Avg.Loss: -2.918,LR: 3.94E-05]Training epoch 82:  88%|████████▊ | 134/153 [00:02<00:00, 52.75it/s, Epoch: 82, Batch: 135,Loss: -3.189,Avg.Loss: -2.920,LR: 3.94E-05]Training epoch 82:  88%|████████▊ | 135/153 [00:02<00:00, 52.75it/s, Epoch: 82, Batch: 136,Loss: -3.172,Avg.Loss: -2.922,LR: 3.94E-05]Training epoch 82:  89%|████████▉ | 136/153 [00:02<00:00, 52.75it/s, Epoch: 82, Batch: 137,Loss: -3.489,Avg.Loss: -2.926,LR: 3.94E-05]Training epoch 82:  90%|████████▉ | 137/153 [00:02<00:00, 52.75it/s, Epoch: 82, Batch: 138,Loss: -3.143,Avg.Loss: -2.928,LR: 3.93E-05]Training epoch 82:  90%|█████████ | 138/153 [00:02<00:00, 52.77it/s, Epoch: 82, Batch: 138,Loss: -3.143,Avg.Loss: -2.928,LR: 3.93E-05]Training epoch 82:  90%|█████████ | 138/153 [00:02<00:00, 52.77it/s, Epoch: 82, Batch: 139,Loss: -2.695,Avg.Loss: -2.926,LR: 3.93E-05]Training epoch 82:  91%|█████████ | 139/153 [00:02<00:00, 52.77it/s, Epoch: 82, Batch: 140,Loss: -2.988,Avg.Loss: -2.926,LR: 3.93E-05]Training epoch 82:  92%|█████████▏| 140/153 [00:02<00:00, 52.77it/s, Epoch: 82, Batch: 141,Loss: -3.191,Avg.Loss: -2.928,LR: 3.92E-05]Training epoch 82:  92%|█████████▏| 141/153 [00:02<00:00, 52.77it/s, Epoch: 82, Batch: 142,Loss: -3.238,Avg.Loss: -2.931,LR: 3.92E-05]Training epoch 82:  93%|█████████▎| 142/153 [00:02<00:00, 52.77it/s, Epoch: 82, Batch: 143,Loss: -3.250,Avg.Loss: -2.933,LR: 3.92E-05]Training epoch 82:  93%|█████████▎| 143/153 [00:02<00:00, 52.77it/s, Epoch: 82, Batch: 144,Loss: -3.004,Avg.Loss: -2.933,LR: 3.92E-05]Training epoch 82:  94%|█████████▍| 144/153 [00:02<00:00, 52.90it/s, Epoch: 82, Batch: 144,Loss: -3.004,Avg.Loss: -2.933,LR: 3.92E-05]Training epoch 82:  94%|█████████▍| 144/153 [00:02<00:00, 52.90it/s, Epoch: 82, Batch: 145,Loss: -2.977,Avg.Loss: -2.934,LR: 3.91E-05]Training epoch 82:  95%|█████████▍| 145/153 [00:02<00:00, 52.90it/s, Epoch: 82, Batch: 146,Loss: -3.007,Avg.Loss: -2.934,LR: 3.91E-05]Training epoch 82:  95%|█████████▌| 146/153 [00:02<00:00, 52.90it/s, Epoch: 82, Batch: 147,Loss: -3.231,Avg.Loss: -2.936,LR: 3.91E-05]Training epoch 82:  96%|█████████▌| 147/153 [00:02<00:00, 52.90it/s, Epoch: 82, Batch: 148,Loss: -2.797,Avg.Loss: -2.935,LR: 3.91E-05]Training epoch 82:  97%|█████████▋| 148/153 [00:02<00:00, 52.90it/s, Epoch: 82, Batch: 149,Loss: -3.107,Avg.Loss: -2.936,LR: 3.90E-05]Training epoch 82:  97%|█████████▋| 149/153 [00:02<00:00, 52.90it/s, Epoch: 82, Batch: 150,Loss: -2.222,Avg.Loss: -2.932,LR: 3.90E-05]Training epoch 82:  98%|█████████▊| 150/153 [00:02<00:00, 52.99it/s, Epoch: 82, Batch: 150,Loss: -2.222,Avg.Loss: -2.932,LR: 3.90E-05]Training epoch 82:  98%|█████████▊| 150/153 [00:02<00:00, 52.99it/s, Epoch: 82, Batch: 151,Loss: -3.021,Avg.Loss: -2.932,LR: 3.90E-05]Training epoch 82:  99%|█████████▊| 151/153 [00:02<00:00, 52.99it/s, Epoch: 82, Batch: 152,Loss: -2.810,Avg.Loss: -2.931,LR: 3.89E-05]Training epoch 82:  99%|█████████▉| 152/153 [00:02<00:00, 52.99it/s, Epoch: 82, Batch: 153,Loss: -3.153,Avg.Loss: -2.933,LR: 3.89E-05]Training epoch 82: 100%|██████████| 153/153 [00:02<00:00, 52.81it/s, Epoch: 82, Batch: 153,Loss: -3.153,Avg.Loss: -2.933,LR: 3.89E-05]
Training epoch 83:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 83:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 83, Batch: 1,Loss: -3.164,Avg.Loss: -3.164,LR: 3.89E-05]Training epoch 83:   1%|          | 1/153 [00:00<00:04, 31.69it/s, Epoch: 83, Batch: 2,Loss: -2.874,Avg.Loss: -3.019,LR: 3.89E-05]Training epoch 83:   1%|▏         | 2/153 [00:00<00:03, 41.27it/s, Epoch: 83, Batch: 3,Loss: -2.931,Avg.Loss: -2.990,LR: 3.88E-05]Training epoch 83:   2%|▏         | 3/153 [00:00<00:03, 47.77it/s, Epoch: 83, Batch: 4,Loss: -3.013,Avg.Loss: -2.996,LR: 3.88E-05]Training epoch 83:   3%|▎         | 4/153 [00:00<00:02, 50.57it/s, Epoch: 83, Batch: 5,Loss: -2.642,Avg.Loss: -2.925,LR: 3.88E-05]Training epoch 83:   3%|▎         | 5/153 [00:00<00:02, 51.12it/s, Epoch: 83, Batch: 6,Loss: -3.475,Avg.Loss: -3.017,LR: 3.88E-05]Training epoch 83:   4%|▍         | 6/153 [00:00<00:02, 51.06it/s, Epoch: 83, Batch: 7,Loss: -2.676,Avg.Loss: -2.968,LR: 3.87E-05]Training epoch 83:   5%|▍         | 7/153 [00:00<00:02, 59.48it/s, Epoch: 83, Batch: 7,Loss: -2.676,Avg.Loss: -2.968,LR: 3.87E-05]Training epoch 83:   5%|▍         | 7/153 [00:00<00:02, 59.48it/s, Epoch: 83, Batch: 8,Loss: -3.172,Avg.Loss: -2.993,LR: 3.87E-05]Training epoch 83:   5%|▌         | 8/153 [00:00<00:02, 59.48it/s, Epoch: 83, Batch: 9,Loss: -2.798,Avg.Loss: -2.972,LR: 3.87E-05]Training epoch 83:   6%|▌         | 9/153 [00:00<00:02, 59.48it/s, Epoch: 83, Batch: 10,Loss: -3.000,Avg.Loss: -2.975,LR: 3.86E-05]Training epoch 83:   7%|▋         | 10/153 [00:00<00:02, 59.48it/s, Epoch: 83, Batch: 11,Loss: -2.837,Avg.Loss: -2.962,LR: 3.86E-05]Training epoch 83:   7%|▋         | 11/153 [00:00<00:02, 59.48it/s, Epoch: 83, Batch: 12,Loss: -2.697,Avg.Loss: -2.940,LR: 3.86E-05]Training epoch 83:   8%|▊         | 12/153 [00:00<00:02, 59.48it/s, Epoch: 83, Batch: 13,Loss: -2.912,Avg.Loss: -2.938,LR: 3.86E-05]Training epoch 83:   8%|▊         | 13/153 [00:00<00:02, 55.50it/s, Epoch: 83, Batch: 13,Loss: -2.912,Avg.Loss: -2.938,LR: 3.86E-05]Training epoch 83:   8%|▊         | 13/153 [00:00<00:02, 55.50it/s, Epoch: 83, Batch: 14,Loss: -2.633,Avg.Loss: -2.916,LR: 3.85E-05]Training epoch 83:   9%|▉         | 14/153 [00:00<00:02, 55.50it/s, Epoch: 83, Batch: 15,Loss: -2.611,Avg.Loss: -2.896,LR: 3.85E-05]Training epoch 83:  10%|▉         | 15/153 [00:00<00:02, 55.50it/s, Epoch: 83, Batch: 16,Loss: -2.914,Avg.Loss: -2.897,LR: 3.85E-05]Training epoch 83:  10%|█         | 16/153 [00:00<00:02, 55.50it/s, Epoch: 83, Batch: 17,Loss: -2.735,Avg.Loss: -2.887,LR: 3.85E-05]Training epoch 83:  11%|█         | 17/153 [00:00<00:02, 55.50it/s, Epoch: 83, Batch: 18,Loss: -2.216,Avg.Loss: -2.850,LR: 3.84E-05]Training epoch 83:  12%|█▏        | 18/153 [00:00<00:02, 55.50it/s, Epoch: 83, Batch: 19,Loss: -2.936,Avg.Loss: -2.855,LR: 3.84E-05]Training epoch 83:  12%|█▏        | 19/153 [00:00<00:02, 54.55it/s, Epoch: 83, Batch: 19,Loss: -2.936,Avg.Loss: -2.855,LR: 3.84E-05]Training epoch 83:  12%|█▏        | 19/153 [00:00<00:02, 54.55it/s, Epoch: 83, Batch: 20,Loss: -2.482,Avg.Loss: -2.836,LR: 3.84E-05]Training epoch 83:  13%|█▎        | 20/153 [00:00<00:02, 54.55it/s, Epoch: 83, Batch: 21,Loss: -2.816,Avg.Loss: -2.835,LR: 3.83E-05]Training epoch 83:  14%|█▎        | 21/153 [00:00<00:02, 54.55it/s, Epoch: 83, Batch: 22,Loss: -2.188,Avg.Loss: -2.806,LR: 3.83E-05]Training epoch 83:  14%|█▍        | 22/153 [00:00<00:02, 54.55it/s, Epoch: 83, Batch: 23,Loss: -2.611,Avg.Loss: -2.797,LR: 3.83E-05]Training epoch 83:  15%|█▌        | 23/153 [00:00<00:02, 54.55it/s, Epoch: 83, Batch: 24,Loss: -3.025,Avg.Loss: -2.807,LR: 3.83E-05]Training epoch 83:  16%|█▌        | 24/153 [00:00<00:02, 54.55it/s, Epoch: 83, Batch: 25,Loss: -2.744,Avg.Loss: -2.804,LR: 3.82E-05]Training epoch 83:  16%|█▋        | 25/153 [00:00<00:02, 53.40it/s, Epoch: 83, Batch: 25,Loss: -2.744,Avg.Loss: -2.804,LR: 3.82E-05]Training epoch 83:  16%|█▋        | 25/153 [00:00<00:02, 53.40it/s, Epoch: 83, Batch: 26,Loss: -2.670,Avg.Loss: -2.799,LR: 3.82E-05]Training epoch 83:  17%|█▋        | 26/153 [00:00<00:02, 53.40it/s, Epoch: 83, Batch: 27,Loss: -2.872,Avg.Loss: -2.802,LR: 3.82E-05]Training epoch 83:  18%|█▊        | 27/153 [00:00<00:02, 53.40it/s, Epoch: 83, Batch: 28,Loss: -3.326,Avg.Loss: -2.820,LR: 3.82E-05]Training epoch 83:  18%|█▊        | 28/153 [00:00<00:02, 53.40it/s, Epoch: 83, Batch: 29,Loss: -2.975,Avg.Loss: -2.826,LR: 3.81E-05]Training epoch 83:  19%|█▉        | 29/153 [00:00<00:02, 53.40it/s, Epoch: 83, Batch: 30,Loss: -2.695,Avg.Loss: -2.821,LR: 3.81E-05]Training epoch 83:  20%|█▉        | 30/153 [00:00<00:02, 53.40it/s, Epoch: 83, Batch: 31,Loss: -2.896,Avg.Loss: -2.824,LR: 3.81E-05]Training epoch 83:  20%|██        | 31/153 [00:00<00:02, 52.93it/s, Epoch: 83, Batch: 31,Loss: -2.896,Avg.Loss: -2.824,LR: 3.81E-05]Training epoch 83:  20%|██        | 31/153 [00:00<00:02, 52.93it/s, Epoch: 83, Batch: 32,Loss: -2.711,Avg.Loss: -2.820,LR: 3.80E-05]Training epoch 83:  21%|██        | 32/153 [00:00<00:02, 52.93it/s, Epoch: 83, Batch: 33,Loss: -3.050,Avg.Loss: -2.827,LR: 3.80E-05]Training epoch 83:  22%|██▏       | 33/153 [00:00<00:02, 52.93it/s, Epoch: 83, Batch: 34,Loss: -3.353,Avg.Loss: -2.843,LR: 3.80E-05]Training epoch 83:  22%|██▏       | 34/153 [00:00<00:02, 52.93it/s, Epoch: 83, Batch: 35,Loss: -3.079,Avg.Loss: -2.849,LR: 3.80E-05]Training epoch 83:  23%|██▎       | 35/153 [00:00<00:02, 52.93it/s, Epoch: 83, Batch: 36,Loss: -2.907,Avg.Loss: -2.851,LR: 3.79E-05]Training epoch 83:  24%|██▎       | 36/153 [00:00<00:02, 52.93it/s, Epoch: 83, Batch: 37,Loss: -3.513,Avg.Loss: -2.869,LR: 3.79E-05]Training epoch 83:  24%|██▍       | 37/153 [00:00<00:02, 52.86it/s, Epoch: 83, Batch: 37,Loss: -3.513,Avg.Loss: -2.869,LR: 3.79E-05]Training epoch 83:  24%|██▍       | 37/153 [00:00<00:02, 52.86it/s, Epoch: 83, Batch: 38,Loss: -2.790,Avg.Loss: -2.867,LR: 3.79E-05]Training epoch 83:  25%|██▍       | 38/153 [00:00<00:02, 52.86it/s, Epoch: 83, Batch: 39,Loss: -2.699,Avg.Loss: -2.862,LR: 3.79E-05]Training epoch 83:  25%|██▌       | 39/153 [00:00<00:02, 52.86it/s, Epoch: 83, Batch: 40,Loss: -3.079,Avg.Loss: -2.868,LR: 3.78E-05]Training epoch 83:  26%|██▌       | 40/153 [00:00<00:02, 52.86it/s, Epoch: 83, Batch: 41,Loss: -3.118,Avg.Loss: -2.874,LR: 3.78E-05]Training epoch 83:  27%|██▋       | 41/153 [00:00<00:02, 52.86it/s, Epoch: 83, Batch: 42,Loss: -3.070,Avg.Loss: -2.879,LR: 3.78E-05]Training epoch 83:  27%|██▋       | 42/153 [00:00<00:02, 52.86it/s, Epoch: 83, Batch: 43,Loss: -2.536,Avg.Loss: -2.871,LR: 3.77E-05]Training epoch 83:  28%|██▊       | 43/153 [00:00<00:02, 52.80it/s, Epoch: 83, Batch: 43,Loss: -2.536,Avg.Loss: -2.871,LR: 3.77E-05]Training epoch 83:  28%|██▊       | 43/153 [00:00<00:02, 52.80it/s, Epoch: 83, Batch: 44,Loss: -3.085,Avg.Loss: -2.876,LR: 3.77E-05]Training epoch 83:  29%|██▉       | 44/153 [00:00<00:02, 52.80it/s, Epoch: 83, Batch: 45,Loss: -3.227,Avg.Loss: -2.883,LR: 3.77E-05]Training epoch 83:  29%|██▉       | 45/153 [00:00<00:02, 52.80it/s, Epoch: 83, Batch: 46,Loss: -2.980,Avg.Loss: -2.885,LR: 3.77E-05]Training epoch 83:  30%|███       | 46/153 [00:00<00:02, 52.80it/s, Epoch: 83, Batch: 47,Loss: -2.637,Avg.Loss: -2.880,LR: 3.76E-05]Training epoch 83:  31%|███       | 47/153 [00:00<00:02, 52.80it/s, Epoch: 83, Batch: 48,Loss: -2.937,Avg.Loss: -2.881,LR: 3.76E-05]Training epoch 83:  31%|███▏      | 48/153 [00:00<00:01, 52.80it/s, Epoch: 83, Batch: 49,Loss: -2.825,Avg.Loss: -2.880,LR: 3.76E-05]Training epoch 83:  32%|███▏      | 49/153 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 49,Loss: -2.825,Avg.Loss: -2.880,LR: 3.76E-05]Training epoch 83:  32%|███▏      | 49/153 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 50,Loss: -2.975,Avg.Loss: -2.882,LR: 3.76E-05]Training epoch 83:  33%|███▎      | 50/153 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 51,Loss: -2.841,Avg.Loss: -2.881,LR: 3.75E-05]Training epoch 83:  33%|███▎      | 51/153 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 52,Loss: -2.929,Avg.Loss: -2.882,LR: 3.75E-05]Training epoch 83:  34%|███▍      | 52/153 [00:00<00:01, 52.65it/s, Epoch: 83, Batch: 53,Loss: -2.660,Avg.Loss: -2.878,LR: 3.75E-05]Training epoch 83:  35%|███▍      | 53/153 [00:01<00:01, 52.65it/s, Epoch: 83, Batch: 54,Loss: -2.175,Avg.Loss: -2.865,LR: 3.74E-05]Training epoch 83:  35%|███▌      | 54/153 [00:01<00:01, 52.65it/s, Epoch: 83, Batch: 55,Loss: -2.768,Avg.Loss: -2.863,LR: 3.74E-05]Training epoch 83:  36%|███▌      | 55/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 55,Loss: -2.768,Avg.Loss: -2.863,LR: 3.74E-05]Training epoch 83:  36%|███▌      | 55/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 56,Loss: -2.529,Avg.Loss: -2.857,LR: 3.74E-05]Training epoch 83:  37%|███▋      | 56/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 57,Loss: -2.617,Avg.Loss: -2.853,LR: 3.74E-05]Training epoch 83:  37%|███▋      | 57/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 58,Loss: -2.879,Avg.Loss: -2.854,LR: 3.73E-05]Training epoch 83:  38%|███▊      | 58/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 59,Loss: -2.391,Avg.Loss: -2.846,LR: 3.73E-05]Training epoch 83:  39%|███▊      | 59/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 60,Loss: -2.639,Avg.Loss: -2.842,LR: 3.73E-05]Training epoch 83:  39%|███▉      | 60/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 61,Loss: -1.818,Avg.Loss: -2.825,LR: 3.73E-05]Training epoch 83:  40%|███▉      | 61/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 61,Loss: -1.818,Avg.Loss: -2.825,LR: 3.73E-05]Training epoch 83:  40%|███▉      | 61/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 62,Loss: -2.593,Avg.Loss: -2.822,LR: 3.72E-05]Training epoch 83:  41%|████      | 62/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 63,Loss: -2.912,Avg.Loss: -2.823,LR: 3.72E-05]Training epoch 83:  41%|████      | 63/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 64,Loss: -2.998,Avg.Loss: -2.826,LR: 3.72E-05]Training epoch 83:  42%|████▏     | 64/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 65,Loss: -2.939,Avg.Loss: -2.828,LR: 3.71E-05]Training epoch 83:  42%|████▏     | 65/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 66,Loss: -2.400,Avg.Loss: -2.821,LR: 3.71E-05]Training epoch 83:  43%|████▎     | 66/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 67,Loss: -2.321,Avg.Loss: -2.814,LR: 3.71E-05]Training epoch 83:  44%|████▍     | 67/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 67,Loss: -2.321,Avg.Loss: -2.814,LR: 3.71E-05]Training epoch 83:  44%|████▍     | 67/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 68,Loss: -2.791,Avg.Loss: -2.813,LR: 3.71E-05]Training epoch 83:  44%|████▍     | 68/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 69,Loss: -2.940,Avg.Loss: -2.815,LR: 3.70E-05]Training epoch 83:  45%|████▌     | 69/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 70,Loss: -3.013,Avg.Loss: -2.818,LR: 3.70E-05]Training epoch 83:  46%|████▌     | 70/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 71,Loss: -3.457,Avg.Loss: -2.827,LR: 3.70E-05]Training epoch 83:  46%|████▋     | 71/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 72,Loss: -3.107,Avg.Loss: -2.831,LR: 3.70E-05]Training epoch 83:  47%|████▋     | 72/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 73,Loss: -2.559,Avg.Loss: -2.827,LR: 3.69E-05]Training epoch 83:  48%|████▊     | 73/153 [00:01<00:01, 52.88it/s, Epoch: 83, Batch: 73,Loss: -2.559,Avg.Loss: -2.827,LR: 3.69E-05]Training epoch 83:  48%|████▊     | 73/153 [00:01<00:01, 52.88it/s, Epoch: 83, Batch: 74,Loss: -2.692,Avg.Loss: -2.825,LR: 3.69E-05]Training epoch 83:  48%|████▊     | 74/153 [00:01<00:01, 52.88it/s, Epoch: 83, Batch: 75,Loss: -2.946,Avg.Loss: -2.827,LR: 3.69E-05]Training epoch 83:  49%|████▉     | 75/153 [00:01<00:01, 52.88it/s, Epoch: 83, Batch: 76,Loss: -2.934,Avg.Loss: -2.828,LR: 3.69E-05]Training epoch 83:  50%|████▉     | 76/153 [00:01<00:01, 52.88it/s, Epoch: 83, Batch: 77,Loss: -2.698,Avg.Loss: -2.827,LR: 3.68E-05]Training epoch 83:  50%|█████     | 77/153 [00:01<00:01, 52.88it/s, Epoch: 83, Batch: 78,Loss: -3.173,Avg.Loss: -2.831,LR: 3.68E-05]Training epoch 83:  51%|█████     | 78/153 [00:01<00:01, 52.88it/s, Epoch: 83, Batch: 79,Loss: -3.367,Avg.Loss: -2.838,LR: 3.68E-05]Training epoch 83:  52%|█████▏    | 79/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 79,Loss: -3.367,Avg.Loss: -2.838,LR: 3.68E-05]Training epoch 83:  52%|█████▏    | 79/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 80,Loss: -3.031,Avg.Loss: -2.840,LR: 3.67E-05]Training epoch 83:  52%|█████▏    | 80/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 81,Loss: -2.813,Avg.Loss: -2.840,LR: 3.67E-05]Training epoch 83:  53%|█████▎    | 81/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 82,Loss: -2.966,Avg.Loss: -2.842,LR: 3.67E-05]Training epoch 83:  54%|█████▎    | 82/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 83,Loss: -3.230,Avg.Loss: -2.846,LR: 3.67E-05]Training epoch 83:  54%|█████▍    | 83/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 84,Loss: -3.070,Avg.Loss: -2.849,LR: 3.66E-05]Training epoch 83:  55%|█████▍    | 84/153 [00:01<00:01, 52.77it/s, Epoch: 83, Batch: 85,Loss: -2.912,Avg.Loss: -2.850,LR: 3.66E-05]Training epoch 83:  56%|█████▌    | 85/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 85,Loss: -2.912,Avg.Loss: -2.850,LR: 3.66E-05]Training epoch 83:  56%|█████▌    | 85/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 86,Loss: -2.712,Avg.Loss: -2.848,LR: 3.66E-05]Training epoch 83:  56%|█████▌    | 86/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 87,Loss: -2.734,Avg.Loss: -2.847,LR: 3.66E-05]Training epoch 83:  57%|█████▋    | 87/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 88,Loss: -3.406,Avg.Loss: -2.853,LR: 3.65E-05]Training epoch 83:  58%|█████▊    | 88/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 89,Loss: -3.211,Avg.Loss: -2.857,LR: 3.65E-05]Training epoch 83:  58%|█████▊    | 89/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 90,Loss: -3.448,Avg.Loss: -2.864,LR: 3.65E-05]Training epoch 83:  59%|█████▉    | 90/153 [00:01<00:01, 52.79it/s, Epoch: 83, Batch: 91,Loss: -3.133,Avg.Loss: -2.867,LR: 3.65E-05]Training epoch 83:  59%|█████▉    | 91/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 91,Loss: -3.133,Avg.Loss: -2.867,LR: 3.65E-05]Training epoch 83:  59%|█████▉    | 91/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 92,Loss: -3.321,Avg.Loss: -2.872,LR: 3.64E-05]Training epoch 83:  60%|██████    | 92/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 93,Loss: -3.255,Avg.Loss: -2.876,LR: 3.64E-05]Training epoch 83:  61%|██████    | 93/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 94,Loss: -3.341,Avg.Loss: -2.881,LR: 3.64E-05]Training epoch 83:  61%|██████▏   | 94/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 95,Loss: -2.855,Avg.Loss: -2.880,LR: 3.63E-05]Training epoch 83:  62%|██████▏   | 95/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 96,Loss: -2.881,Avg.Loss: -2.880,LR: 3.63E-05]Training epoch 83:  63%|██████▎   | 96/153 [00:01<00:01, 52.73it/s, Epoch: 83, Batch: 97,Loss: -3.067,Avg.Loss: -2.882,LR: 3.63E-05]Training epoch 83:  63%|██████▎   | 97/153 [00:01<00:01, 52.85it/s, Epoch: 83, Batch: 97,Loss: -3.067,Avg.Loss: -2.882,LR: 3.63E-05]Training epoch 83:  63%|██████▎   | 97/153 [00:01<00:01, 52.85it/s, Epoch: 83, Batch: 98,Loss: -3.467,Avg.Loss: -2.888,LR: 3.63E-05]Training epoch 83:  64%|██████▍   | 98/153 [00:01<00:01, 52.85it/s, Epoch: 83, Batch: 99,Loss: -2.844,Avg.Loss: -2.888,LR: 3.62E-05]Training epoch 83:  65%|██████▍   | 99/153 [00:01<00:01, 52.85it/s, Epoch: 83, Batch: 100,Loss: -2.913,Avg.Loss: -2.888,LR: 3.62E-05]Training epoch 83:  65%|██████▌   | 100/153 [00:01<00:01, 52.85it/s, Epoch: 83, Batch: 101,Loss: -3.041,Avg.Loss: -2.890,LR: 3.62E-05]Training epoch 83:  66%|██████▌   | 101/153 [00:01<00:00, 52.85it/s, Epoch: 83, Batch: 102,Loss: -2.878,Avg.Loss: -2.889,LR: 3.62E-05]Training epoch 83:  67%|██████▋   | 102/153 [00:01<00:00, 52.85it/s, Epoch: 83, Batch: 103,Loss: -2.889,Avg.Loss: -2.889,LR: 3.61E-05]Training epoch 83:  67%|██████▋   | 103/153 [00:01<00:00, 52.80it/s, Epoch: 83, Batch: 103,Loss: -2.889,Avg.Loss: -2.889,LR: 3.61E-05]Training epoch 83:  67%|██████▋   | 103/153 [00:01<00:00, 52.80it/s, Epoch: 83, Batch: 104,Loss: -3.734,Avg.Loss: -2.898,LR: 3.61E-05]Training epoch 83:  68%|██████▊   | 104/153 [00:01<00:00, 52.80it/s, Epoch: 83, Batch: 105,Loss: -3.094,Avg.Loss: -2.899,LR: 3.61E-05]Training epoch 83:  69%|██████▊   | 105/153 [00:01<00:00, 52.80it/s, Epoch: 83, Batch: 106,Loss: -2.768,Avg.Loss: -2.898,LR: 3.61E-05]Training epoch 83:  69%|██████▉   | 106/153 [00:02<00:00, 52.80it/s, Epoch: 83, Batch: 107,Loss: -3.014,Avg.Loss: -2.899,LR: 3.60E-05]Training epoch 83:  70%|██████▉   | 107/153 [00:02<00:00, 52.80it/s, Epoch: 83, Batch: 108,Loss: -3.007,Avg.Loss: -2.900,LR: 3.60E-05]Training epoch 83:  71%|███████   | 108/153 [00:02<00:00, 52.80it/s, Epoch: 83, Batch: 109,Loss: -2.773,Avg.Loss: -2.899,LR: 3.60E-05]Training epoch 83:  71%|███████   | 109/153 [00:02<00:00, 53.03it/s, Epoch: 83, Batch: 109,Loss: -2.773,Avg.Loss: -2.899,LR: 3.60E-05]Training epoch 83:  71%|███████   | 109/153 [00:02<00:00, 53.03it/s, Epoch: 83, Batch: 110,Loss: -3.048,Avg.Loss: -2.900,LR: 3.59E-05]Training epoch 83:  72%|███████▏  | 110/153 [00:02<00:00, 53.03it/s, Epoch: 83, Batch: 111,Loss: -2.770,Avg.Loss: -2.899,LR: 3.59E-05]Training epoch 83:  73%|███████▎  | 111/153 [00:02<00:00, 53.03it/s, Epoch: 83, Batch: 112,Loss: -2.964,Avg.Loss: -2.900,LR: 3.59E-05]Training epoch 83:  73%|███████▎  | 112/153 [00:02<00:00, 53.03it/s, Epoch: 83, Batch: 113,Loss: -2.944,Avg.Loss: -2.900,LR: 3.59E-05]Training epoch 83:  74%|███████▍  | 113/153 [00:02<00:00, 53.03it/s, Epoch: 83, Batch: 114,Loss: -2.856,Avg.Loss: -2.900,LR: 3.58E-05]Training epoch 83:  75%|███████▍  | 114/153 [00:02<00:00, 53.03it/s, Epoch: 83, Batch: 115,Loss: -2.879,Avg.Loss: -2.900,LR: 3.58E-05]Training epoch 83:  75%|███████▌  | 115/153 [00:02<00:00, 52.89it/s, Epoch: 83, Batch: 115,Loss: -2.879,Avg.Loss: -2.900,LR: 3.58E-05]Training epoch 83:  75%|███████▌  | 115/153 [00:02<00:00, 52.89it/s, Epoch: 83, Batch: 116,Loss: -2.982,Avg.Loss: -2.900,LR: 3.58E-05]Training epoch 83:  76%|███████▌  | 116/153 [00:02<00:00, 52.89it/s, Epoch: 83, Batch: 117,Loss: -2.375,Avg.Loss: -2.896,LR: 3.58E-05]Training epoch 83:  76%|███████▋  | 117/153 [00:02<00:00, 52.89it/s, Epoch: 83, Batch: 118,Loss: -2.790,Avg.Loss: -2.895,LR: 3.57E-05]Training epoch 83:  77%|███████▋  | 118/153 [00:02<00:00, 52.89it/s, Epoch: 83, Batch: 119,Loss: -2.665,Avg.Loss: -2.893,LR: 3.57E-05]Training epoch 83:  78%|███████▊  | 119/153 [00:02<00:00, 52.89it/s, Epoch: 83, Batch: 120,Loss: -2.820,Avg.Loss: -2.892,LR: 3.57E-05]Training epoch 83:  78%|███████▊  | 120/153 [00:02<00:00, 52.89it/s, Epoch: 83, Batch: 121,Loss: -3.008,Avg.Loss: -2.893,LR: 3.57E-05]Training epoch 83:  79%|███████▉  | 121/153 [00:02<00:00, 52.90it/s, Epoch: 83, Batch: 121,Loss: -3.008,Avg.Loss: -2.893,LR: 3.57E-05]Training epoch 83:  79%|███████▉  | 121/153 [00:02<00:00, 52.90it/s, Epoch: 83, Batch: 122,Loss: -3.197,Avg.Loss: -2.896,LR: 3.56E-05]Training epoch 83:  80%|███████▉  | 122/153 [00:02<00:00, 52.90it/s, Epoch: 83, Batch: 123,Loss: -3.177,Avg.Loss: -2.898,LR: 3.56E-05]Training epoch 83:  80%|████████  | 123/153 [00:02<00:00, 52.90it/s, Epoch: 83, Batch: 124,Loss: -2.880,Avg.Loss: -2.898,LR: 3.56E-05]Training epoch 83:  81%|████████  | 124/153 [00:02<00:00, 52.90it/s, Epoch: 83, Batch: 125,Loss: -2.703,Avg.Loss: -2.896,LR: 3.55E-05]Training epoch 83:  82%|████████▏ | 125/153 [00:02<00:00, 52.90it/s, Epoch: 83, Batch: 126,Loss: -3.424,Avg.Loss: -2.901,LR: 3.55E-05]Training epoch 83:  82%|████████▏ | 126/153 [00:02<00:00, 52.90it/s, Epoch: 83, Batch: 127,Loss: -3.036,Avg.Loss: -2.902,LR: 3.55E-05]Training epoch 83:  83%|████████▎ | 127/153 [00:02<00:00, 52.97it/s, Epoch: 83, Batch: 127,Loss: -3.036,Avg.Loss: -2.902,LR: 3.55E-05]Training epoch 83:  83%|████████▎ | 127/153 [00:02<00:00, 52.97it/s, Epoch: 83, Batch: 128,Loss: -3.306,Avg.Loss: -2.905,LR: 3.55E-05]Training epoch 83:  84%|████████▎ | 128/153 [00:02<00:00, 52.97it/s, Epoch: 83, Batch: 129,Loss: -2.956,Avg.Loss: -2.905,LR: 3.54E-05]Training epoch 83:  84%|████████▍ | 129/153 [00:02<00:00, 52.97it/s, Epoch: 83, Batch: 130,Loss: -2.969,Avg.Loss: -2.906,LR: 3.54E-05]Training epoch 83:  85%|████████▍ | 130/153 [00:02<00:00, 52.97it/s, Epoch: 83, Batch: 131,Loss: -3.170,Avg.Loss: -2.908,LR: 3.54E-05]Training epoch 83:  86%|████████▌ | 131/153 [00:02<00:00, 52.97it/s, Epoch: 83, Batch: 132,Loss: -1.985,Avg.Loss: -2.901,LR: 3.54E-05]Training epoch 83:  86%|████████▋ | 132/153 [00:02<00:00, 52.97it/s, Epoch: 83, Batch: 133,Loss: -2.994,Avg.Loss: -2.902,LR: 3.53E-05]Training epoch 83:  87%|████████▋ | 133/153 [00:02<00:00, 53.15it/s, Epoch: 83, Batch: 133,Loss: -2.994,Avg.Loss: -2.902,LR: 3.53E-05]Training epoch 83:  87%|████████▋ | 133/153 [00:02<00:00, 53.15it/s, Epoch: 83, Batch: 134,Loss: -2.378,Avg.Loss: -2.898,LR: 3.53E-05]Training epoch 83:  88%|████████▊ | 134/153 [00:02<00:00, 53.15it/s, Epoch: 83, Batch: 135,Loss: -2.786,Avg.Loss: -2.897,LR: 3.53E-05]Training epoch 83:  88%|████████▊ | 135/153 [00:02<00:00, 53.15it/s, Epoch: 83, Batch: 136,Loss: -3.044,Avg.Loss: -2.898,LR: 3.53E-05]Training epoch 83:  89%|████████▉ | 136/153 [00:02<00:00, 53.15it/s, Epoch: 83, Batch: 137,Loss: -3.003,Avg.Loss: -2.899,LR: 3.52E-05]Training epoch 83:  90%|████████▉ | 137/153 [00:02<00:00, 53.15it/s, Epoch: 83, Batch: 138,Loss: -3.229,Avg.Loss: -2.901,LR: 3.52E-05]Training epoch 83:  90%|█████████ | 138/153 [00:02<00:00, 53.15it/s, Epoch: 83, Batch: 139,Loss: -2.605,Avg.Loss: -2.899,LR: 3.52E-05]Training epoch 83:  91%|█████████ | 139/153 [00:02<00:00, 53.14it/s, Epoch: 83, Batch: 139,Loss: -2.605,Avg.Loss: -2.899,LR: 3.52E-05]Training epoch 83:  91%|█████████ | 139/153 [00:02<00:00, 53.14it/s, Epoch: 83, Batch: 140,Loss: -3.275,Avg.Loss: -2.902,LR: 3.52E-05]Training epoch 83:  92%|█████████▏| 140/153 [00:02<00:00, 53.14it/s, Epoch: 83, Batch: 141,Loss: -3.252,Avg.Loss: -2.904,LR: 3.51E-05]Training epoch 83:  92%|█████████▏| 141/153 [00:02<00:00, 53.14it/s, Epoch: 83, Batch: 142,Loss: -2.993,Avg.Loss: -2.905,LR: 3.51E-05]Training epoch 83:  93%|█████████▎| 142/153 [00:02<00:00, 53.14it/s, Epoch: 83, Batch: 143,Loss: -3.223,Avg.Loss: -2.907,LR: 3.51E-05]Training epoch 83:  93%|█████████▎| 143/153 [00:02<00:00, 53.14it/s, Epoch: 83, Batch: 144,Loss: -3.059,Avg.Loss: -2.908,LR: 3.51E-05]Training epoch 83:  94%|█████████▍| 144/153 [00:02<00:00, 53.14it/s, Epoch: 83, Batch: 145,Loss: -3.227,Avg.Loss: -2.910,LR: 3.50E-05]Training epoch 83:  95%|█████████▍| 145/153 [00:02<00:00, 53.22it/s, Epoch: 83, Batch: 145,Loss: -3.227,Avg.Loss: -2.910,LR: 3.50E-05]Training epoch 83:  95%|█████████▍| 145/153 [00:02<00:00, 53.22it/s, Epoch: 83, Batch: 146,Loss: -3.269,Avg.Loss: -2.913,LR: 3.50E-05]Training epoch 83:  95%|█████████▌| 146/153 [00:02<00:00, 53.22it/s, Epoch: 83, Batch: 147,Loss: -2.760,Avg.Loss: -2.912,LR: 3.50E-05]Training epoch 83:  96%|█████████▌| 147/153 [00:02<00:00, 53.22it/s, Epoch: 83, Batch: 148,Loss: -3.034,Avg.Loss: -2.912,LR: 3.49E-05]Training epoch 83:  97%|█████████▋| 148/153 [00:02<00:00, 53.22it/s, Epoch: 83, Batch: 149,Loss: -2.743,Avg.Loss: -2.911,LR: 3.49E-05]Training epoch 83:  97%|█████████▋| 149/153 [00:02<00:00, 53.22it/s, Epoch: 83, Batch: 150,Loss: -3.215,Avg.Loss: -2.913,LR: 3.49E-05]Training epoch 83:  98%|█████████▊| 150/153 [00:02<00:00, 53.22it/s, Epoch: 83, Batch: 151,Loss: -3.260,Avg.Loss: -2.916,LR: 3.49E-05]Training epoch 83:  99%|█████████▊| 151/153 [00:02<00:00, 53.39it/s, Epoch: 83, Batch: 151,Loss: -3.260,Avg.Loss: -2.916,LR: 3.49E-05]Training epoch 83:  99%|█████████▊| 151/153 [00:02<00:00, 53.39it/s, Epoch: 83, Batch: 152,Loss: -3.279,Avg.Loss: -2.918,LR: 3.48E-05]Training epoch 83:  99%|█████████▉| 152/153 [00:02<00:00, 53.39it/s, Epoch: 83, Batch: 153,Loss: -2.904,Avg.Loss: -2.918,LR: 3.48E-05]Training epoch 83: 100%|██████████| 153/153 [00:02<00:00, 53.09it/s, Epoch: 83, Batch: 153,Loss: -2.904,Avg.Loss: -2.918,LR: 3.48E-05]
Training epoch 84:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 84:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 84, Batch: 1,Loss: -3.013,Avg.Loss: -3.013,LR: 3.48E-05]Training epoch 84:   1%|          | 1/153 [00:00<00:06, 23.97it/s, Epoch: 84, Batch: 2,Loss: -3.050,Avg.Loss: -3.032,LR: 3.48E-05]Training epoch 84:   1%|▏         | 2/153 [00:00<00:04, 36.33it/s, Epoch: 84, Batch: 3,Loss: -2.813,Avg.Loss: -2.959,LR: 3.47E-05]Training epoch 84:   2%|▏         | 3/153 [00:00<00:03, 41.06it/s, Epoch: 84, Batch: 4,Loss: -2.998,Avg.Loss: -2.968,LR: 3.47E-05]Training epoch 84:   3%|▎         | 4/153 [00:00<00:03, 43.37it/s, Epoch: 84, Batch: 5,Loss: -2.532,Avg.Loss: -2.881,LR: 3.47E-05]Training epoch 84:   3%|▎         | 5/153 [00:00<00:03, 44.89it/s, Epoch: 84, Batch: 6,Loss: -3.201,Avg.Loss: -2.934,LR: 3.47E-05]Training epoch 84:   4%|▍         | 6/153 [00:00<00:02, 53.78it/s, Epoch: 84, Batch: 6,Loss: -3.201,Avg.Loss: -2.934,LR: 3.47E-05]Training epoch 84:   4%|▍         | 6/153 [00:00<00:02, 53.78it/s, Epoch: 84, Batch: 7,Loss: -3.065,Avg.Loss: -2.953,LR: 3.46E-05]Training epoch 84:   5%|▍         | 7/153 [00:00<00:02, 53.78it/s, Epoch: 84, Batch: 8,Loss: -2.899,Avg.Loss: -2.946,LR: 3.46E-05]Training epoch 84:   5%|▌         | 8/153 [00:00<00:02, 53.78it/s, Epoch: 84, Batch: 9,Loss: -2.449,Avg.Loss: -2.891,LR: 3.46E-05]Training epoch 84:   6%|▌         | 9/153 [00:00<00:02, 53.78it/s, Epoch: 84, Batch: 10,Loss: -2.745,Avg.Loss: -2.876,LR: 3.46E-05]Training epoch 84:   7%|▋         | 10/153 [00:00<00:02, 53.78it/s, Epoch: 84, Batch: 11,Loss: -2.330,Avg.Loss: -2.827,LR: 3.45E-05]Training epoch 84:   7%|▋         | 11/153 [00:00<00:02, 53.78it/s, Epoch: 84, Batch: 12,Loss: -2.182,Avg.Loss: -2.773,LR: 3.45E-05]Training epoch 84:   8%|▊         | 12/153 [00:00<00:02, 52.79it/s, Epoch: 84, Batch: 12,Loss: -2.182,Avg.Loss: -2.773,LR: 3.45E-05]Training epoch 84:   8%|▊         | 12/153 [00:00<00:02, 52.79it/s, Epoch: 84, Batch: 13,Loss: -2.558,Avg.Loss: -2.757,LR: 3.45E-05]Training epoch 84:   8%|▊         | 13/153 [00:00<00:02, 52.79it/s, Epoch: 84, Batch: 14,Loss: -2.999,Avg.Loss: -2.774,LR: 3.44E-05]Training epoch 84:   9%|▉         | 14/153 [00:00<00:02, 52.79it/s, Epoch: 84, Batch: 15,Loss: -2.482,Avg.Loss: -2.754,LR: 3.44E-05]Training epoch 84:  10%|▉         | 15/153 [00:00<00:02, 52.79it/s, Epoch: 84, Batch: 16,Loss: -3.136,Avg.Loss: -2.778,LR: 3.44E-05]Training epoch 84:  10%|█         | 16/153 [00:00<00:02, 52.79it/s, Epoch: 84, Batch: 17,Loss: -2.656,Avg.Loss: -2.771,LR: 3.44E-05]Training epoch 84:  11%|█         | 17/153 [00:00<00:02, 52.79it/s, Epoch: 84, Batch: 18,Loss: -2.526,Avg.Loss: -2.757,LR: 3.43E-05]Training epoch 84:  12%|█▏        | 18/153 [00:00<00:02, 52.89it/s, Epoch: 84, Batch: 18,Loss: -2.526,Avg.Loss: -2.757,LR: 3.43E-05]Training epoch 84:  12%|█▏        | 18/153 [00:00<00:02, 52.89it/s, Epoch: 84, Batch: 19,Loss: -3.346,Avg.Loss: -2.788,LR: 3.43E-05]Training epoch 84:  12%|█▏        | 19/153 [00:00<00:02, 52.89it/s, Epoch: 84, Batch: 20,Loss: -2.798,Avg.Loss: -2.789,LR: 3.43E-05]Training epoch 84:  13%|█▎        | 20/153 [00:00<00:02, 52.89it/s, Epoch: 84, Batch: 21,Loss: -3.098,Avg.Loss: -2.804,LR: 3.43E-05]Training epoch 84:  14%|█▎        | 21/153 [00:00<00:02, 52.89it/s, Epoch: 84, Batch: 22,Loss: -3.250,Avg.Loss: -2.824,LR: 3.42E-05]Training epoch 84:  14%|█▍        | 22/153 [00:00<00:02, 52.89it/s, Epoch: 84, Batch: 23,Loss: -2.518,Avg.Loss: -2.811,LR: 3.42E-05]Training epoch 84:  15%|█▌        | 23/153 [00:00<00:02, 52.89it/s, Epoch: 84, Batch: 24,Loss: -2.947,Avg.Loss: -2.816,LR: 3.42E-05]Training epoch 84:  16%|█▌        | 24/153 [00:00<00:02, 50.94it/s, Epoch: 84, Batch: 24,Loss: -2.947,Avg.Loss: -2.816,LR: 3.42E-05]Training epoch 84:  16%|█▌        | 24/153 [00:00<00:02, 50.94it/s, Epoch: 84, Batch: 25,Loss: -3.080,Avg.Loss: -2.827,LR: 3.42E-05]Training epoch 84:  16%|█▋        | 25/153 [00:00<00:02, 50.94it/s, Epoch: 84, Batch: 26,Loss: -3.126,Avg.Loss: -2.838,LR: 3.41E-05]Training epoch 84:  17%|█▋        | 26/153 [00:00<00:02, 50.94it/s, Epoch: 84, Batch: 27,Loss: -2.645,Avg.Loss: -2.831,LR: 3.41E-05]Training epoch 84:  18%|█▊        | 27/153 [00:00<00:02, 50.94it/s, Epoch: 84, Batch: 28,Loss: -2.617,Avg.Loss: -2.823,LR: 3.41E-05]Training epoch 84:  18%|█▊        | 28/153 [00:00<00:02, 50.94it/s, Epoch: 84, Batch: 29,Loss: -2.737,Avg.Loss: -2.821,LR: 3.41E-05]Training epoch 84:  19%|█▉        | 29/153 [00:00<00:02, 50.94it/s, Epoch: 84, Batch: 30,Loss: -2.750,Avg.Loss: -2.818,LR: 3.40E-05]Training epoch 84:  20%|█▉        | 30/153 [00:00<00:02, 51.31it/s, Epoch: 84, Batch: 30,Loss: -2.750,Avg.Loss: -2.818,LR: 3.40E-05]Training epoch 84:  20%|█▉        | 30/153 [00:00<00:02, 51.31it/s, Epoch: 84, Batch: 31,Loss: -2.464,Avg.Loss: -2.807,LR: 3.40E-05]Training epoch 84:  20%|██        | 31/153 [00:00<00:02, 51.31it/s, Epoch: 84, Batch: 32,Loss: -3.353,Avg.Loss: -2.824,LR: 3.40E-05]Training epoch 84:  21%|██        | 32/153 [00:00<00:02, 51.31it/s, Epoch: 84, Batch: 33,Loss: -3.055,Avg.Loss: -2.831,LR: 3.40E-05]Training epoch 84:  22%|██▏       | 33/153 [00:00<00:02, 51.31it/s, Epoch: 84, Batch: 34,Loss: -2.858,Avg.Loss: -2.832,LR: 3.39E-05]Training epoch 84:  22%|██▏       | 34/153 [00:00<00:02, 51.31it/s, Epoch: 84, Batch: 35,Loss: -2.037,Avg.Loss: -2.809,LR: 3.39E-05]Training epoch 84:  23%|██▎       | 35/153 [00:00<00:02, 51.31it/s, Epoch: 84, Batch: 36,Loss: -2.738,Avg.Loss: -2.807,LR: 3.39E-05]Training epoch 84:  24%|██▎       | 36/153 [00:00<00:02, 52.18it/s, Epoch: 84, Batch: 36,Loss: -2.738,Avg.Loss: -2.807,LR: 3.39E-05]Training epoch 84:  24%|██▎       | 36/153 [00:00<00:02, 52.18it/s, Epoch: 84, Batch: 37,Loss: -2.777,Avg.Loss: -2.806,LR: 3.39E-05]Training epoch 84:  24%|██▍       | 37/153 [00:00<00:02, 52.18it/s, Epoch: 84, Batch: 38,Loss: -2.908,Avg.Loss: -2.809,LR: 3.38E-05]Training epoch 84:  25%|██▍       | 38/153 [00:00<00:02, 52.18it/s, Epoch: 84, Batch: 39,Loss: -2.874,Avg.Loss: -2.810,LR: 3.38E-05]Training epoch 84:  25%|██▌       | 39/153 [00:00<00:02, 52.18it/s, Epoch: 84, Batch: 40,Loss: -2.512,Avg.Loss: -2.803,LR: 3.38E-05]Training epoch 84:  26%|██▌       | 40/153 [00:00<00:02, 52.18it/s, Epoch: 84, Batch: 41,Loss: -2.687,Avg.Loss: -2.800,LR: 3.38E-05]Training epoch 84:  27%|██▋       | 41/153 [00:00<00:02, 52.18it/s, Epoch: 84, Batch: 42,Loss: -2.867,Avg.Loss: -2.802,LR: 3.37E-05]Training epoch 84:  27%|██▋       | 42/153 [00:00<00:02, 52.53it/s, Epoch: 84, Batch: 42,Loss: -2.867,Avg.Loss: -2.802,LR: 3.37E-05]Training epoch 84:  27%|██▋       | 42/153 [00:00<00:02, 52.53it/s, Epoch: 84, Batch: 43,Loss: -2.741,Avg.Loss: -2.800,LR: 3.37E-05]Training epoch 84:  28%|██▊       | 43/153 [00:00<00:02, 52.53it/s, Epoch: 84, Batch: 44,Loss: -2.884,Avg.Loss: -2.802,LR: 3.37E-05]Training epoch 84:  29%|██▉       | 44/153 [00:00<00:02, 52.53it/s, Epoch: 84, Batch: 45,Loss: -3.039,Avg.Loss: -2.807,LR: 3.36E-05]Training epoch 84:  29%|██▉       | 45/153 [00:00<00:02, 52.53it/s, Epoch: 84, Batch: 46,Loss: -2.954,Avg.Loss: -2.811,LR: 3.36E-05]Training epoch 84:  30%|███       | 46/153 [00:00<00:02, 52.53it/s, Epoch: 84, Batch: 47,Loss: -3.501,Avg.Loss: -2.825,LR: 3.36E-05]Training epoch 84:  31%|███       | 47/153 [00:00<00:02, 52.53it/s, Epoch: 84, Batch: 48,Loss: -3.239,Avg.Loss: -2.834,LR: 3.36E-05]Training epoch 84:  31%|███▏      | 48/153 [00:00<00:01, 52.71it/s, Epoch: 84, Batch: 48,Loss: -3.239,Avg.Loss: -2.834,LR: 3.36E-05]Training epoch 84:  31%|███▏      | 48/153 [00:00<00:01, 52.71it/s, Epoch: 84, Batch: 49,Loss: -2.341,Avg.Loss: -2.824,LR: 3.35E-05]Training epoch 84:  32%|███▏      | 49/153 [00:00<00:01, 52.71it/s, Epoch: 84, Batch: 50,Loss: -2.813,Avg.Loss: -2.824,LR: 3.35E-05]Training epoch 84:  33%|███▎      | 50/153 [00:00<00:01, 52.71it/s, Epoch: 84, Batch: 51,Loss: -2.848,Avg.Loss: -2.824,LR: 3.35E-05]Training epoch 84:  33%|███▎      | 51/153 [00:00<00:01, 52.71it/s, Epoch: 84, Batch: 52,Loss: -3.074,Avg.Loss: -2.829,LR: 3.35E-05]Training epoch 84:  34%|███▍      | 52/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 53,Loss: -3.319,Avg.Loss: -2.838,LR: 3.34E-05]Training epoch 84:  35%|███▍      | 53/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 54,Loss: -3.298,Avg.Loss: -2.847,LR: 3.34E-05]Training epoch 84:  35%|███▌      | 54/153 [00:01<00:01, 52.81it/s, Epoch: 84, Batch: 54,Loss: -3.298,Avg.Loss: -2.847,LR: 3.34E-05]Training epoch 84:  35%|███▌      | 54/153 [00:01<00:01, 52.81it/s, Epoch: 84, Batch: 55,Loss: -2.974,Avg.Loss: -2.849,LR: 3.34E-05]Training epoch 84:  36%|███▌      | 55/153 [00:01<00:01, 52.81it/s, Epoch: 84, Batch: 56,Loss: -3.049,Avg.Loss: -2.853,LR: 3.34E-05]Training epoch 84:  37%|███▋      | 56/153 [00:01<00:01, 52.81it/s, Epoch: 84, Batch: 57,Loss: -2.848,Avg.Loss: -2.853,LR: 3.33E-05]Training epoch 84:  37%|███▋      | 57/153 [00:01<00:01, 52.81it/s, Epoch: 84, Batch: 58,Loss: -3.099,Avg.Loss: -2.857,LR: 3.33E-05]Training epoch 84:  38%|███▊      | 58/153 [00:01<00:01, 52.81it/s, Epoch: 84, Batch: 59,Loss: -3.298,Avg.Loss: -2.864,LR: 3.33E-05]Training epoch 84:  39%|███▊      | 59/153 [00:01<00:01, 52.81it/s, Epoch: 84, Batch: 60,Loss: -3.106,Avg.Loss: -2.868,LR: 3.33E-05]Training epoch 84:  39%|███▉      | 60/153 [00:01<00:01, 52.76it/s, Epoch: 84, Batch: 60,Loss: -3.106,Avg.Loss: -2.868,LR: 3.33E-05]Training epoch 84:  39%|███▉      | 60/153 [00:01<00:01, 52.76it/s, Epoch: 84, Batch: 61,Loss: -2.946,Avg.Loss: -2.870,LR: 3.32E-05]Training epoch 84:  40%|███▉      | 61/153 [00:01<00:01, 52.76it/s, Epoch: 84, Batch: 62,Loss: -2.584,Avg.Loss: -2.865,LR: 3.32E-05]Training epoch 84:  41%|████      | 62/153 [00:01<00:01, 52.76it/s, Epoch: 84, Batch: 63,Loss: -2.840,Avg.Loss: -2.865,LR: 3.32E-05]Training epoch 84:  41%|████      | 63/153 [00:01<00:01, 52.76it/s, Epoch: 84, Batch: 64,Loss: -3.025,Avg.Loss: -2.867,LR: 3.32E-05]Training epoch 84:  42%|████▏     | 64/153 [00:01<00:01, 52.76it/s, Epoch: 84, Batch: 65,Loss: -3.121,Avg.Loss: -2.871,LR: 3.31E-05]Training epoch 84:  42%|████▏     | 65/153 [00:01<00:01, 52.76it/s, Epoch: 84, Batch: 66,Loss: -2.836,Avg.Loss: -2.870,LR: 3.31E-05]Training epoch 84:  43%|████▎     | 66/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 66,Loss: -2.836,Avg.Loss: -2.870,LR: 3.31E-05]Training epoch 84:  43%|████▎     | 66/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 67,Loss: -2.937,Avg.Loss: -2.871,LR: 3.31E-05]Training epoch 84:  44%|████▍     | 67/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 68,Loss: -3.087,Avg.Loss: -2.875,LR: 3.31E-05]Training epoch 84:  44%|████▍     | 68/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 69,Loss: -2.948,Avg.Loss: -2.876,LR: 3.30E-05]Training epoch 84:  45%|████▌     | 69/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 70,Loss: -2.819,Avg.Loss: -2.875,LR: 3.30E-05]Training epoch 84:  46%|████▌     | 70/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 71,Loss: -3.282,Avg.Loss: -2.881,LR: 3.30E-05]Training epoch 84:  46%|████▋     | 71/153 [00:01<00:01, 52.71it/s, Epoch: 84, Batch: 72,Loss: -2.897,Avg.Loss: -2.881,LR: 3.30E-05]Training epoch 84:  47%|████▋     | 72/153 [00:01<00:01, 52.47it/s, Epoch: 84, Batch: 72,Loss: -2.897,Avg.Loss: -2.881,LR: 3.30E-05]Training epoch 84:  47%|████▋     | 72/153 [00:01<00:01, 52.47it/s, Epoch: 84, Batch: 73,Loss: -2.676,Avg.Loss: -2.878,LR: 3.29E-05]Training epoch 84:  48%|████▊     | 73/153 [00:01<00:01, 52.47it/s, Epoch: 84, Batch: 74,Loss: -3.117,Avg.Loss: -2.881,LR: 3.29E-05]Training epoch 84:  48%|████▊     | 74/153 [00:01<00:01, 52.47it/s, Epoch: 84, Batch: 75,Loss: -3.377,Avg.Loss: -2.888,LR: 3.29E-05]Training epoch 84:  49%|████▉     | 75/153 [00:01<00:01, 52.47it/s, Epoch: 84, Batch: 76,Loss: -2.596,Avg.Loss: -2.884,LR: 3.29E-05]Training epoch 84:  50%|████▉     | 76/153 [00:01<00:01, 52.47it/s, Epoch: 84, Batch: 77,Loss: -3.165,Avg.Loss: -2.888,LR: 3.28E-05]Training epoch 84:  50%|█████     | 77/153 [00:01<00:01, 52.47it/s, Epoch: 84, Batch: 78,Loss: -2.888,Avg.Loss: -2.888,LR: 3.28E-05]Training epoch 84:  51%|█████     | 78/153 [00:01<00:01, 53.10it/s, Epoch: 84, Batch: 78,Loss: -2.888,Avg.Loss: -2.888,LR: 3.28E-05]Training epoch 84:  51%|█████     | 78/153 [00:01<00:01, 53.10it/s, Epoch: 84, Batch: 79,Loss: -3.058,Avg.Loss: -2.890,LR: 3.28E-05]Training epoch 84:  52%|█████▏    | 79/153 [00:01<00:01, 53.10it/s, Epoch: 84, Batch: 80,Loss: -3.146,Avg.Loss: -2.893,LR: 3.28E-05]Training epoch 84:  52%|█████▏    | 80/153 [00:01<00:01, 53.10it/s, Epoch: 84, Batch: 81,Loss: -3.311,Avg.Loss: -2.898,LR: 3.27E-05]Training epoch 84:  53%|█████▎    | 81/153 [00:01<00:01, 53.10it/s, Epoch: 84, Batch: 82,Loss: -3.457,Avg.Loss: -2.905,LR: 3.27E-05]Training epoch 84:  54%|█████▎    | 82/153 [00:01<00:01, 53.10it/s, Epoch: 84, Batch: 83,Loss: -2.916,Avg.Loss: -2.905,LR: 3.27E-05]Training epoch 84:  54%|█████▍    | 83/153 [00:01<00:01, 53.10it/s, Epoch: 84, Batch: 84,Loss: -3.280,Avg.Loss: -2.910,LR: 3.27E-05]Training epoch 84:  55%|█████▍    | 84/153 [00:01<00:01, 53.03it/s, Epoch: 84, Batch: 84,Loss: -3.280,Avg.Loss: -2.910,LR: 3.27E-05]Training epoch 84:  55%|█████▍    | 84/153 [00:01<00:01, 53.03it/s, Epoch: 84, Batch: 85,Loss: -3.270,Avg.Loss: -2.914,LR: 3.26E-05]Training epoch 84:  56%|█████▌    | 85/153 [00:01<00:01, 53.03it/s, Epoch: 84, Batch: 86,Loss: -2.364,Avg.Loss: -2.907,LR: 3.26E-05]Training epoch 84:  56%|█████▌    | 86/153 [00:01<00:01, 53.03it/s, Epoch: 84, Batch: 87,Loss: -3.058,Avg.Loss: -2.909,LR: 3.26E-05]Training epoch 84:  57%|█████▋    | 87/153 [00:01<00:01, 53.03it/s, Epoch: 84, Batch: 88,Loss: -3.082,Avg.Loss: -2.911,LR: 3.26E-05]Training epoch 84:  58%|█████▊    | 88/153 [00:01<00:01, 53.03it/s, Epoch: 84, Batch: 89,Loss: -3.246,Avg.Loss: -2.915,LR: 3.25E-05]Training epoch 84:  58%|█████▊    | 89/153 [00:01<00:01, 53.03it/s, Epoch: 84, Batch: 90,Loss: -3.086,Avg.Loss: -2.917,LR: 3.25E-05]Training epoch 84:  59%|█████▉    | 90/153 [00:01<00:01, 52.95it/s, Epoch: 84, Batch: 90,Loss: -3.086,Avg.Loss: -2.917,LR: 3.25E-05]Training epoch 84:  59%|█████▉    | 90/153 [00:01<00:01, 52.95it/s, Epoch: 84, Batch: 91,Loss: -2.972,Avg.Loss: -2.917,LR: 3.25E-05]Training epoch 84:  59%|█████▉    | 91/153 [00:01<00:01, 52.95it/s, Epoch: 84, Batch: 92,Loss: -2.968,Avg.Loss: -2.918,LR: 3.24E-05]Training epoch 84:  60%|██████    | 92/153 [00:01<00:01, 52.95it/s, Epoch: 84, Batch: 93,Loss: -3.076,Avg.Loss: -2.920,LR: 3.24E-05]Training epoch 84:  61%|██████    | 93/153 [00:01<00:01, 52.95it/s, Epoch: 84, Batch: 94,Loss: -2.974,Avg.Loss: -2.920,LR: 3.24E-05]Training epoch 84:  61%|██████▏   | 94/153 [00:01<00:01, 52.95it/s, Epoch: 84, Batch: 95,Loss: -2.613,Avg.Loss: -2.917,LR: 3.24E-05]Training epoch 84:  62%|██████▏   | 95/153 [00:01<00:01, 52.95it/s, Epoch: 84, Batch: 96,Loss: -3.220,Avg.Loss: -2.920,LR: 3.23E-05]Training epoch 84:  63%|██████▎   | 96/153 [00:01<00:01, 52.96it/s, Epoch: 84, Batch: 96,Loss: -3.220,Avg.Loss: -2.920,LR: 3.23E-05]Training epoch 84:  63%|██████▎   | 96/153 [00:01<00:01, 52.96it/s, Epoch: 84, Batch: 97,Loss: -2.694,Avg.Loss: -2.918,LR: 3.23E-05]Training epoch 84:  63%|██████▎   | 97/153 [00:01<00:01, 52.96it/s, Epoch: 84, Batch: 98,Loss: -3.202,Avg.Loss: -2.921,LR: 3.23E-05]Training epoch 84:  64%|██████▍   | 98/153 [00:01<00:01, 52.96it/s, Epoch: 84, Batch: 99,Loss: -2.875,Avg.Loss: -2.920,LR: 3.23E-05]Training epoch 84:  65%|██████▍   | 99/153 [00:01<00:01, 52.96it/s, Epoch: 84, Batch: 100,Loss: -2.892,Avg.Loss: -2.920,LR: 3.22E-05]Training epoch 84:  65%|██████▌   | 100/153 [00:01<00:01, 52.96it/s, Epoch: 84, Batch: 101,Loss: -3.528,Avg.Loss: -2.926,LR: 3.22E-05]Training epoch 84:  66%|██████▌   | 101/153 [00:01<00:00, 52.96it/s, Epoch: 84, Batch: 102,Loss: -3.065,Avg.Loss: -2.927,LR: 3.22E-05]Training epoch 84:  67%|██████▋   | 102/153 [00:01<00:00, 52.84it/s, Epoch: 84, Batch: 102,Loss: -3.065,Avg.Loss: -2.927,LR: 3.22E-05]Training epoch 84:  67%|██████▋   | 102/153 [00:01<00:00, 52.84it/s, Epoch: 84, Batch: 103,Loss: -2.737,Avg.Loss: -2.926,LR: 3.22E-05]Training epoch 84:  67%|██████▋   | 103/153 [00:01<00:00, 52.84it/s, Epoch: 84, Batch: 104,Loss: -3.151,Avg.Loss: -2.928,LR: 3.21E-05]Training epoch 84:  68%|██████▊   | 104/153 [00:01<00:00, 52.84it/s, Epoch: 84, Batch: 105,Loss: -3.259,Avg.Loss: -2.931,LR: 3.21E-05]Training epoch 84:  69%|██████▊   | 105/153 [00:02<00:00, 52.84it/s, Epoch: 84, Batch: 106,Loss: -2.644,Avg.Loss: -2.928,LR: 3.21E-05]Training epoch 84:  69%|██████▉   | 106/153 [00:02<00:00, 52.84it/s, Epoch: 84, Batch: 107,Loss: -3.130,Avg.Loss: -2.930,LR: 3.21E-05]Training epoch 84:  70%|██████▉   | 107/153 [00:02<00:00, 52.84it/s, Epoch: 84, Batch: 108,Loss: -2.869,Avg.Loss: -2.929,LR: 3.20E-05]Training epoch 84:  71%|███████   | 108/153 [00:02<00:00, 52.81it/s, Epoch: 84, Batch: 108,Loss: -2.869,Avg.Loss: -2.929,LR: 3.20E-05]Training epoch 84:  71%|███████   | 108/153 [00:02<00:00, 52.81it/s, Epoch: 84, Batch: 109,Loss: -2.888,Avg.Loss: -2.929,LR: 3.20E-05]Training epoch 84:  71%|███████   | 109/153 [00:02<00:00, 52.81it/s, Epoch: 84, Batch: 110,Loss: -3.026,Avg.Loss: -2.930,LR: 3.20E-05]Training epoch 84:  72%|███████▏  | 110/153 [00:02<00:00, 52.81it/s, Epoch: 84, Batch: 111,Loss: -2.733,Avg.Loss: -2.928,LR: 3.20E-05]Training epoch 84:  73%|███████▎  | 111/153 [00:02<00:00, 52.81it/s, Epoch: 84, Batch: 112,Loss: -3.511,Avg.Loss: -2.933,LR: 3.19E-05]Training epoch 84:  73%|███████▎  | 112/153 [00:02<00:00, 52.81it/s, Epoch: 84, Batch: 113,Loss: -3.220,Avg.Loss: -2.936,LR: 3.19E-05]Training epoch 84:  74%|███████▍  | 113/153 [00:02<00:00, 52.81it/s, Epoch: 84, Batch: 114,Loss: -3.076,Avg.Loss: -2.937,LR: 3.19E-05]Training epoch 84:  75%|███████▍  | 114/153 [00:02<00:00, 52.89it/s, Epoch: 84, Batch: 114,Loss: -3.076,Avg.Loss: -2.937,LR: 3.19E-05]Training epoch 84:  75%|███████▍  | 114/153 [00:02<00:00, 52.89it/s, Epoch: 84, Batch: 115,Loss: -2.873,Avg.Loss: -2.937,LR: 3.19E-05]Training epoch 84:  75%|███████▌  | 115/153 [00:02<00:00, 52.89it/s, Epoch: 84, Batch: 116,Loss: -2.596,Avg.Loss: -2.934,LR: 3.18E-05]Training epoch 84:  76%|███████▌  | 116/153 [00:02<00:00, 52.89it/s, Epoch: 84, Batch: 117,Loss: -2.893,Avg.Loss: -2.933,LR: 3.18E-05]Training epoch 84:  76%|███████▋  | 117/153 [00:02<00:00, 52.89it/s, Epoch: 84, Batch: 118,Loss: -3.085,Avg.Loss: -2.935,LR: 3.18E-05]Training epoch 84:  77%|███████▋  | 118/153 [00:02<00:00, 52.89it/s, Epoch: 84, Batch: 119,Loss: -2.696,Avg.Loss: -2.933,LR: 3.18E-05]Training epoch 84:  78%|███████▊  | 119/153 [00:02<00:00, 52.89it/s, Epoch: 84, Batch: 120,Loss: -3.311,Avg.Loss: -2.936,LR: 3.17E-05]Training epoch 84:  78%|███████▊  | 120/153 [00:02<00:00, 53.18it/s, Epoch: 84, Batch: 120,Loss: -3.311,Avg.Loss: -2.936,LR: 3.17E-05]Training epoch 84:  78%|███████▊  | 120/153 [00:02<00:00, 53.18it/s, Epoch: 84, Batch: 121,Loss: -2.857,Avg.Loss: -2.935,LR: 3.17E-05]Training epoch 84:  79%|███████▉  | 121/153 [00:02<00:00, 53.18it/s, Epoch: 84, Batch: 122,Loss: -2.572,Avg.Loss: -2.932,LR: 3.17E-05]Training epoch 84:  80%|███████▉  | 122/153 [00:02<00:00, 53.18it/s, Epoch: 84, Batch: 123,Loss: -3.168,Avg.Loss: -2.934,LR: 3.17E-05]Training epoch 84:  80%|████████  | 123/153 [00:02<00:00, 53.18it/s, Epoch: 84, Batch: 124,Loss: -2.817,Avg.Loss: -2.933,LR: 3.16E-05]Training epoch 84:  81%|████████  | 124/153 [00:02<00:00, 53.18it/s, Epoch: 84, Batch: 125,Loss: -3.283,Avg.Loss: -2.936,LR: 3.16E-05]Training epoch 84:  82%|████████▏ | 125/153 [00:02<00:00, 53.18it/s, Epoch: 84, Batch: 126,Loss: -3.691,Avg.Loss: -2.942,LR: 3.16E-05]Training epoch 84:  82%|████████▏ | 126/153 [00:02<00:00, 53.32it/s, Epoch: 84, Batch: 126,Loss: -3.691,Avg.Loss: -2.942,LR: 3.16E-05]Training epoch 84:  82%|████████▏ | 126/153 [00:02<00:00, 53.32it/s, Epoch: 84, Batch: 127,Loss: -3.200,Avg.Loss: -2.944,LR: 3.16E-05]Training epoch 84:  83%|████████▎ | 127/153 [00:02<00:00, 53.32it/s, Epoch: 84, Batch: 128,Loss: -3.000,Avg.Loss: -2.944,LR: 3.15E-05]Training epoch 84:  84%|████████▎ | 128/153 [00:02<00:00, 53.32it/s, Epoch: 84, Batch: 129,Loss: -3.201,Avg.Loss: -2.946,LR: 3.15E-05]Training epoch 84:  84%|████████▍ | 129/153 [00:02<00:00, 53.32it/s, Epoch: 84, Batch: 130,Loss: -2.403,Avg.Loss: -2.942,LR: 3.15E-05]Training epoch 84:  85%|████████▍ | 130/153 [00:02<00:00, 53.32it/s, Epoch: 84, Batch: 131,Loss: -3.059,Avg.Loss: -2.943,LR: 3.15E-05]Training epoch 84:  86%|████████▌ | 131/153 [00:02<00:00, 53.32it/s, Epoch: 84, Batch: 132,Loss: -2.585,Avg.Loss: -2.940,LR: 3.14E-05]Training epoch 84:  86%|████████▋ | 132/153 [00:02<00:00, 53.31it/s, Epoch: 84, Batch: 132,Loss: -2.585,Avg.Loss: -2.940,LR: 3.14E-05]Training epoch 84:  86%|████████▋ | 132/153 [00:02<00:00, 53.31it/s, Epoch: 84, Batch: 133,Loss: -3.017,Avg.Loss: -2.941,LR: 3.14E-05]Training epoch 84:  87%|████████▋ | 133/153 [00:02<00:00, 53.31it/s, Epoch: 84, Batch: 134,Loss: -2.832,Avg.Loss: -2.940,LR: 3.14E-05]Training epoch 84:  88%|████████▊ | 134/153 [00:02<00:00, 53.31it/s, Epoch: 84, Batch: 135,Loss: -3.424,Avg.Loss: -2.944,LR: 3.14E-05]Training epoch 84:  88%|████████▊ | 135/153 [00:02<00:00, 53.31it/s, Epoch: 84, Batch: 136,Loss: -2.945,Avg.Loss: -2.944,LR: 3.13E-05]Training epoch 84:  89%|████████▉ | 136/153 [00:02<00:00, 53.31it/s, Epoch: 84, Batch: 137,Loss: -3.140,Avg.Loss: -2.945,LR: 3.13E-05]Training epoch 84:  90%|████████▉ | 137/153 [00:02<00:00, 53.31it/s, Epoch: 84, Batch: 138,Loss: -2.616,Avg.Loss: -2.943,LR: 3.13E-05]Training epoch 84:  90%|█████████ | 138/153 [00:02<00:00, 53.40it/s, Epoch: 84, Batch: 138,Loss: -2.616,Avg.Loss: -2.943,LR: 3.13E-05]Training epoch 84:  90%|█████████ | 138/153 [00:02<00:00, 53.40it/s, Epoch: 84, Batch: 139,Loss: -2.778,Avg.Loss: -2.942,LR: 3.13E-05]Training epoch 84:  91%|█████████ | 139/153 [00:02<00:00, 53.40it/s, Epoch: 84, Batch: 140,Loss: -2.831,Avg.Loss: -2.941,LR: 3.12E-05]Training epoch 84:  92%|█████████▏| 140/153 [00:02<00:00, 53.40it/s, Epoch: 84, Batch: 141,Loss: -3.350,Avg.Loss: -2.944,LR: 3.12E-05]Training epoch 84:  92%|█████████▏| 141/153 [00:02<00:00, 53.40it/s, Epoch: 84, Batch: 142,Loss: -2.676,Avg.Loss: -2.942,LR: 3.12E-05]Training epoch 84:  93%|█████████▎| 142/153 [00:02<00:00, 53.40it/s, Epoch: 84, Batch: 143,Loss: -2.807,Avg.Loss: -2.941,LR: 3.12E-05]Training epoch 84:  93%|█████████▎| 143/153 [00:02<00:00, 53.40it/s, Epoch: 84, Batch: 144,Loss: -3.209,Avg.Loss: -2.943,LR: 3.11E-05]Training epoch 84:  94%|█████████▍| 144/153 [00:02<00:00, 53.46it/s, Epoch: 84, Batch: 144,Loss: -3.209,Avg.Loss: -2.943,LR: 3.11E-05]Training epoch 84:  94%|█████████▍| 144/153 [00:02<00:00, 53.46it/s, Epoch: 84, Batch: 145,Loss: -3.662,Avg.Loss: -2.948,LR: 3.11E-05]Training epoch 84:  95%|█████████▍| 145/153 [00:02<00:00, 53.46it/s, Epoch: 84, Batch: 146,Loss: -2.984,Avg.Loss: -2.948,LR: 3.11E-05]Training epoch 84:  95%|█████████▌| 146/153 [00:02<00:00, 53.46it/s, Epoch: 84, Batch: 147,Loss: -3.197,Avg.Loss: -2.950,LR: 3.11E-05]Training epoch 84:  96%|█████████▌| 147/153 [00:02<00:00, 53.46it/s, Epoch: 84, Batch: 148,Loss: -2.611,Avg.Loss: -2.947,LR: 3.10E-05]Training epoch 84:  97%|█████████▋| 148/153 [00:02<00:00, 53.46it/s, Epoch: 84, Batch: 149,Loss: -2.609,Avg.Loss: -2.945,LR: 3.10E-05]Training epoch 84:  97%|█████████▋| 149/153 [00:02<00:00, 53.46it/s, Epoch: 84, Batch: 150,Loss: -2.809,Avg.Loss: -2.944,LR: 3.10E-05]Training epoch 84:  98%|█████████▊| 150/153 [00:02<00:00, 53.39it/s, Epoch: 84, Batch: 150,Loss: -2.809,Avg.Loss: -2.944,LR: 3.10E-05]Training epoch 84:  98%|█████████▊| 150/153 [00:02<00:00, 53.39it/s, Epoch: 84, Batch: 151,Loss: -2.403,Avg.Loss: -2.941,LR: 3.10E-05]Training epoch 84:  99%|█████████▊| 151/153 [00:02<00:00, 53.39it/s, Epoch: 84, Batch: 152,Loss: -2.876,Avg.Loss: -2.940,LR: 3.09E-05]Training epoch 84:  99%|█████████▉| 152/153 [00:02<00:00, 53.39it/s, Epoch: 84, Batch: 153,Loss: -2.671,Avg.Loss: -2.938,LR: 3.09E-05]Training epoch 84: 100%|██████████| 153/153 [00:02<00:00, 52.80it/s, Epoch: 84, Batch: 153,Loss: -2.671,Avg.Loss: -2.938,LR: 3.09E-05]
Training epoch 85:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 85:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 85, Batch: 1,Loss: -2.759,Avg.Loss: -2.759,LR: 3.09E-05]Training epoch 85:   1%|          | 1/153 [00:00<00:05, 26.00it/s, Epoch: 85, Batch: 2,Loss: -2.652,Avg.Loss: -2.705,LR: 3.09E-05]Training epoch 85:   1%|▏         | 2/153 [00:00<00:04, 37.61it/s, Epoch: 85, Batch: 3,Loss: -3.148,Avg.Loss: -2.853,LR: 3.08E-05]Training epoch 85:   2%|▏         | 3/153 [00:00<00:03, 44.23it/s, Epoch: 85, Batch: 4,Loss: -2.730,Avg.Loss: -2.822,LR: 3.08E-05]Training epoch 85:   3%|▎         | 4/153 [00:00<00:03, 48.78it/s, Epoch: 85, Batch: 5,Loss: -2.793,Avg.Loss: -2.816,LR: 3.08E-05]Training epoch 85:   3%|▎         | 5/153 [00:00<00:02, 49.59it/s, Epoch: 85, Batch: 6,Loss: -2.631,Avg.Loss: -2.786,LR: 3.08E-05]Training epoch 85:   4%|▍         | 6/153 [00:00<00:02, 59.40it/s, Epoch: 85, Batch: 6,Loss: -2.631,Avg.Loss: -2.786,LR: 3.08E-05]Training epoch 85:   4%|▍         | 6/153 [00:00<00:02, 59.40it/s, Epoch: 85, Batch: 7,Loss: -3.325,Avg.Loss: -2.863,LR: 3.08E-05]Training epoch 85:   5%|▍         | 7/153 [00:00<00:02, 59.40it/s, Epoch: 85, Batch: 8,Loss: -3.129,Avg.Loss: -2.896,LR: 3.07E-05]Training epoch 85:   5%|▌         | 8/153 [00:00<00:02, 59.40it/s, Epoch: 85, Batch: 9,Loss: -3.117,Avg.Loss: -2.921,LR: 3.07E-05]Training epoch 85:   6%|▌         | 9/153 [00:00<00:02, 59.40it/s, Epoch: 85, Batch: 10,Loss: -3.026,Avg.Loss: -2.931,LR: 3.07E-05]Training epoch 85:   7%|▋         | 10/153 [00:00<00:02, 59.40it/s, Epoch: 85, Batch: 11,Loss: -2.726,Avg.Loss: -2.912,LR: 3.07E-05]Training epoch 85:   7%|▋         | 11/153 [00:00<00:02, 59.40it/s, Epoch: 85, Batch: 12,Loss: -2.826,Avg.Loss: -2.905,LR: 3.06E-05]Training epoch 85:   8%|▊         | 12/153 [00:00<00:02, 55.07it/s, Epoch: 85, Batch: 12,Loss: -2.826,Avg.Loss: -2.905,LR: 3.06E-05]Training epoch 85:   8%|▊         | 12/153 [00:00<00:02, 55.07it/s, Epoch: 85, Batch: 13,Loss: -2.737,Avg.Loss: -2.892,LR: 3.06E-05]Training epoch 85:   8%|▊         | 13/153 [00:00<00:02, 55.07it/s, Epoch: 85, Batch: 14,Loss: -2.981,Avg.Loss: -2.899,LR: 3.06E-05]Training epoch 85:   9%|▉         | 14/153 [00:00<00:02, 55.07it/s, Epoch: 85, Batch: 15,Loss: -2.969,Avg.Loss: -2.903,LR: 3.06E-05]Training epoch 85:  10%|▉         | 15/153 [00:00<00:02, 55.07it/s, Epoch: 85, Batch: 16,Loss: -3.488,Avg.Loss: -2.940,LR: 3.05E-05]Training epoch 85:  10%|█         | 16/153 [00:00<00:02, 55.07it/s, Epoch: 85, Batch: 17,Loss: -3.684,Avg.Loss: -2.984,LR: 3.05E-05]Training epoch 85:  11%|█         | 17/153 [00:00<00:02, 55.07it/s, Epoch: 85, Batch: 18,Loss: -2.768,Avg.Loss: -2.972,LR: 3.05E-05]Training epoch 85:  12%|█▏        | 18/153 [00:00<00:02, 54.12it/s, Epoch: 85, Batch: 18,Loss: -2.768,Avg.Loss: -2.972,LR: 3.05E-05]Training epoch 85:  12%|█▏        | 18/153 [00:00<00:02, 54.12it/s, Epoch: 85, Batch: 19,Loss: -3.162,Avg.Loss: -2.982,LR: 3.05E-05]Training epoch 85:  12%|█▏        | 19/153 [00:00<00:02, 54.12it/s, Epoch: 85, Batch: 20,Loss: -2.765,Avg.Loss: -2.971,LR: 3.04E-05]Training epoch 85:  13%|█▎        | 20/153 [00:00<00:02, 54.12it/s, Epoch: 85, Batch: 21,Loss: -3.469,Avg.Loss: -2.995,LR: 3.04E-05]Training epoch 85:  14%|█▎        | 21/153 [00:00<00:02, 54.12it/s, Epoch: 85, Batch: 22,Loss: -2.766,Avg.Loss: -2.984,LR: 3.04E-05]Training epoch 85:  14%|█▍        | 22/153 [00:00<00:02, 54.12it/s, Epoch: 85, Batch: 23,Loss: -2.811,Avg.Loss: -2.977,LR: 3.04E-05]Training epoch 85:  15%|█▌        | 23/153 [00:00<00:02, 54.12it/s, Epoch: 85, Batch: 24,Loss: -3.082,Avg.Loss: -2.981,LR: 3.03E-05]Training epoch 85:  16%|█▌        | 24/153 [00:00<00:02, 52.91it/s, Epoch: 85, Batch: 24,Loss: -3.082,Avg.Loss: -2.981,LR: 3.03E-05]Training epoch 85:  16%|█▌        | 24/153 [00:00<00:02, 52.91it/s, Epoch: 85, Batch: 25,Loss: -2.143,Avg.Loss: -2.947,LR: 3.03E-05]Training epoch 85:  16%|█▋        | 25/153 [00:00<00:02, 52.91it/s, Epoch: 85, Batch: 26,Loss: -2.441,Avg.Loss: -2.928,LR: 3.03E-05]Training epoch 85:  17%|█▋        | 26/153 [00:00<00:02, 52.91it/s, Epoch: 85, Batch: 27,Loss: -3.261,Avg.Loss: -2.940,LR: 3.03E-05]Training epoch 85:  18%|█▊        | 27/153 [00:00<00:02, 52.91it/s, Epoch: 85, Batch: 28,Loss: -2.264,Avg.Loss: -2.916,LR: 3.02E-05]Training epoch 85:  18%|█▊        | 28/153 [00:00<00:02, 52.91it/s, Epoch: 85, Batch: 29,Loss: -3.374,Avg.Loss: -2.932,LR: 3.02E-05]Training epoch 85:  19%|█▉        | 29/153 [00:00<00:02, 52.91it/s, Epoch: 85, Batch: 30,Loss: -2.738,Avg.Loss: -2.926,LR: 3.02E-05]Training epoch 85:  20%|█▉        | 30/153 [00:00<00:02, 52.33it/s, Epoch: 85, Batch: 30,Loss: -2.738,Avg.Loss: -2.926,LR: 3.02E-05]Training epoch 85:  20%|█▉        | 30/153 [00:00<00:02, 52.33it/s, Epoch: 85, Batch: 31,Loss: -2.490,Avg.Loss: -2.911,LR: 3.02E-05]Training epoch 85:  20%|██        | 31/153 [00:00<00:02, 52.33it/s, Epoch: 85, Batch: 32,Loss: -3.297,Avg.Loss: -2.924,LR: 3.01E-05]Training epoch 85:  21%|██        | 32/153 [00:00<00:02, 52.33it/s, Epoch: 85, Batch: 33,Loss: -2.727,Avg.Loss: -2.918,LR: 3.01E-05]Training epoch 85:  22%|██▏       | 33/153 [00:00<00:02, 52.33it/s, Epoch: 85, Batch: 34,Loss: -2.628,Avg.Loss: -2.909,LR: 3.01E-05]Training epoch 85:  22%|██▏       | 34/153 [00:00<00:02, 52.33it/s, Epoch: 85, Batch: 35,Loss: -2.969,Avg.Loss: -2.911,LR: 3.01E-05]Training epoch 85:  23%|██▎       | 35/153 [00:00<00:02, 52.33it/s, Epoch: 85, Batch: 36,Loss: -3.438,Avg.Loss: -2.925,LR: 3.00E-05]Training epoch 85:  24%|██▎       | 36/153 [00:00<00:02, 52.57it/s, Epoch: 85, Batch: 36,Loss: -3.438,Avg.Loss: -2.925,LR: 3.00E-05]Training epoch 85:  24%|██▎       | 36/153 [00:00<00:02, 52.57it/s, Epoch: 85, Batch: 37,Loss: -3.045,Avg.Loss: -2.929,LR: 3.00E-05]Training epoch 85:  24%|██▍       | 37/153 [00:00<00:02, 52.57it/s, Epoch: 85, Batch: 38,Loss: -3.187,Avg.Loss: -2.935,LR: 3.00E-05]Training epoch 85:  25%|██▍       | 38/153 [00:00<00:02, 52.57it/s, Epoch: 85, Batch: 39,Loss: -3.215,Avg.Loss: -2.943,LR: 3.00E-05]Training epoch 85:  25%|██▌       | 39/153 [00:00<00:02, 52.57it/s, Epoch: 85, Batch: 40,Loss: -2.989,Avg.Loss: -2.944,LR: 2.99E-05]Training epoch 85:  26%|██▌       | 40/153 [00:00<00:02, 52.57it/s, Epoch: 85, Batch: 41,Loss: -2.884,Avg.Loss: -2.942,LR: 2.99E-05]Training epoch 85:  27%|██▋       | 41/153 [00:00<00:02, 52.57it/s, Epoch: 85, Batch: 42,Loss: -2.772,Avg.Loss: -2.938,LR: 2.99E-05]Training epoch 85:  27%|██▋       | 42/153 [00:00<00:02, 52.75it/s, Epoch: 85, Batch: 42,Loss: -2.772,Avg.Loss: -2.938,LR: 2.99E-05]Training epoch 85:  27%|██▋       | 42/153 [00:00<00:02, 52.75it/s, Epoch: 85, Batch: 43,Loss: -3.393,Avg.Loss: -2.949,LR: 2.99E-05]Training epoch 85:  28%|██▊       | 43/153 [00:00<00:02, 52.75it/s, Epoch: 85, Batch: 44,Loss: -2.991,Avg.Loss: -2.950,LR: 2.98E-05]Training epoch 85:  29%|██▉       | 44/153 [00:00<00:02, 52.75it/s, Epoch: 85, Batch: 45,Loss: -2.922,Avg.Loss: -2.949,LR: 2.98E-05]Training epoch 85:  29%|██▉       | 45/153 [00:00<00:02, 52.75it/s, Epoch: 85, Batch: 46,Loss: -2.822,Avg.Loss: -2.946,LR: 2.98E-05]Training epoch 85:  30%|███       | 46/153 [00:00<00:02, 52.75it/s, Epoch: 85, Batch: 47,Loss: -2.939,Avg.Loss: -2.946,LR: 2.98E-05]Training epoch 85:  31%|███       | 47/153 [00:00<00:02, 52.75it/s, Epoch: 85, Batch: 48,Loss: -3.210,Avg.Loss: -2.952,LR: 2.97E-05]Training epoch 85:  31%|███▏      | 48/153 [00:00<00:01, 52.71it/s, Epoch: 85, Batch: 48,Loss: -3.210,Avg.Loss: -2.952,LR: 2.97E-05]Training epoch 85:  31%|███▏      | 48/153 [00:00<00:01, 52.71it/s, Epoch: 85, Batch: 49,Loss: -2.669,Avg.Loss: -2.946,LR: 2.97E-05]Training epoch 85:  32%|███▏      | 49/153 [00:00<00:01, 52.71it/s, Epoch: 85, Batch: 50,Loss: -2.634,Avg.Loss: -2.940,LR: 2.97E-05]Training epoch 85:  33%|███▎      | 50/153 [00:00<00:01, 52.71it/s, Epoch: 85, Batch: 51,Loss: -2.753,Avg.Loss: -2.936,LR: 2.97E-05]Training epoch 85:  33%|███▎      | 51/153 [00:00<00:01, 52.71it/s, Epoch: 85, Batch: 52,Loss: -3.219,Avg.Loss: -2.942,LR: 2.96E-05]Training epoch 85:  34%|███▍      | 52/153 [00:00<00:01, 52.71it/s, Epoch: 85, Batch: 53,Loss: -2.785,Avg.Loss: -2.939,LR: 2.96E-05]Training epoch 85:  35%|███▍      | 53/153 [00:01<00:01, 52.71it/s, Epoch: 85, Batch: 54,Loss: -3.256,Avg.Loss: -2.944,LR: 2.96E-05]Training epoch 85:  35%|███▌      | 54/153 [00:01<00:01, 52.88it/s, Epoch: 85, Batch: 54,Loss: -3.256,Avg.Loss: -2.944,LR: 2.96E-05]Training epoch 85:  35%|███▌      | 54/153 [00:01<00:01, 52.88it/s, Epoch: 85, Batch: 55,Loss: -3.024,Avg.Loss: -2.946,LR: 2.96E-05]Training epoch 85:  36%|███▌      | 55/153 [00:01<00:01, 52.88it/s, Epoch: 85, Batch: 56,Loss: -2.861,Avg.Loss: -2.944,LR: 2.96E-05]Training epoch 85:  37%|███▋      | 56/153 [00:01<00:01, 52.88it/s, Epoch: 85, Batch: 57,Loss: -3.174,Avg.Loss: -2.948,LR: 2.95E-05]Training epoch 85:  37%|███▋      | 57/153 [00:01<00:01, 52.88it/s, Epoch: 85, Batch: 58,Loss: -2.863,Avg.Loss: -2.947,LR: 2.95E-05]Training epoch 85:  38%|███▊      | 58/153 [00:01<00:01, 52.88it/s, Epoch: 85, Batch: 59,Loss: -3.149,Avg.Loss: -2.950,LR: 2.95E-05]Training epoch 85:  39%|███▊      | 59/153 [00:01<00:01, 52.88it/s, Epoch: 85, Batch: 60,Loss: -3.239,Avg.Loss: -2.955,LR: 2.95E-05]Training epoch 85:  39%|███▉      | 60/153 [00:01<00:01, 52.87it/s, Epoch: 85, Batch: 60,Loss: -3.239,Avg.Loss: -2.955,LR: 2.95E-05]Training epoch 85:  39%|███▉      | 60/153 [00:01<00:01, 52.87it/s, Epoch: 85, Batch: 61,Loss: -3.189,Avg.Loss: -2.959,LR: 2.94E-05]Training epoch 85:  40%|███▉      | 61/153 [00:01<00:01, 52.87it/s, Epoch: 85, Batch: 62,Loss: -2.541,Avg.Loss: -2.952,LR: 2.94E-05]Training epoch 85:  41%|████      | 62/153 [00:01<00:01, 52.87it/s, Epoch: 85, Batch: 63,Loss: -3.064,Avg.Loss: -2.954,LR: 2.94E-05]Training epoch 85:  41%|████      | 63/153 [00:01<00:01, 52.87it/s, Epoch: 85, Batch: 64,Loss: -2.852,Avg.Loss: -2.952,LR: 2.94E-05]Training epoch 85:  42%|████▏     | 64/153 [00:01<00:01, 52.87it/s, Epoch: 85, Batch: 65,Loss: -3.129,Avg.Loss: -2.955,LR: 2.93E-05]Training epoch 85:  42%|████▏     | 65/153 [00:01<00:01, 52.87it/s, Epoch: 85, Batch: 66,Loss: -3.141,Avg.Loss: -2.958,LR: 2.93E-05]Training epoch 85:  43%|████▎     | 66/153 [00:01<00:01, 52.79it/s, Epoch: 85, Batch: 66,Loss: -3.141,Avg.Loss: -2.958,LR: 2.93E-05]Training epoch 85:  43%|████▎     | 66/153 [00:01<00:01, 52.79it/s, Epoch: 85, Batch: 67,Loss: -2.807,Avg.Loss: -2.956,LR: 2.93E-05]Training epoch 85:  44%|████▍     | 67/153 [00:01<00:01, 52.79it/s, Epoch: 85, Batch: 68,Loss: -3.123,Avg.Loss: -2.958,LR: 2.93E-05]Training epoch 85:  44%|████▍     | 68/153 [00:01<00:01, 52.79it/s, Epoch: 85, Batch: 69,Loss: -3.393,Avg.Loss: -2.964,LR: 2.92E-05]Training epoch 85:  45%|████▌     | 69/153 [00:01<00:01, 52.79it/s, Epoch: 85, Batch: 70,Loss: -2.858,Avg.Loss: -2.963,LR: 2.92E-05]Training epoch 85:  46%|████▌     | 70/153 [00:01<00:01, 52.79it/s, Epoch: 85, Batch: 71,Loss: -3.118,Avg.Loss: -2.965,LR: 2.92E-05]Training epoch 85:  46%|████▋     | 71/153 [00:01<00:01, 52.79it/s, Epoch: 85, Batch: 72,Loss: -3.057,Avg.Loss: -2.966,LR: 2.92E-05]Training epoch 85:  47%|████▋     | 72/153 [00:01<00:01, 52.83it/s, Epoch: 85, Batch: 72,Loss: -3.057,Avg.Loss: -2.966,LR: 2.92E-05]Training epoch 85:  47%|████▋     | 72/153 [00:01<00:01, 52.83it/s, Epoch: 85, Batch: 73,Loss: -2.451,Avg.Loss: -2.959,LR: 2.91E-05]Training epoch 85:  48%|████▊     | 73/153 [00:01<00:01, 52.83it/s, Epoch: 85, Batch: 74,Loss: -2.675,Avg.Loss: -2.956,LR: 2.91E-05]Training epoch 85:  48%|████▊     | 74/153 [00:01<00:01, 52.83it/s, Epoch: 85, Batch: 75,Loss: -3.035,Avg.Loss: -2.957,LR: 2.91E-05]Training epoch 85:  49%|████▉     | 75/153 [00:01<00:01, 52.83it/s, Epoch: 85, Batch: 76,Loss: -3.094,Avg.Loss: -2.958,LR: 2.91E-05]Training epoch 85:  50%|████▉     | 76/153 [00:01<00:01, 52.83it/s, Epoch: 85, Batch: 77,Loss: -3.001,Avg.Loss: -2.959,LR: 2.90E-05]Training epoch 85:  50%|█████     | 77/153 [00:01<00:01, 52.83it/s, Epoch: 85, Batch: 78,Loss: -2.850,Avg.Loss: -2.958,LR: 2.90E-05]Training epoch 85:  51%|█████     | 78/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 78,Loss: -2.850,Avg.Loss: -2.958,LR: 2.90E-05]Training epoch 85:  51%|█████     | 78/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 79,Loss: -2.464,Avg.Loss: -2.951,LR: 2.90E-05]Training epoch 85:  52%|█████▏    | 79/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 80,Loss: -2.714,Avg.Loss: -2.948,LR: 2.90E-05]Training epoch 85:  52%|█████▏    | 80/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 81,Loss: -2.676,Avg.Loss: -2.945,LR: 2.90E-05]Training epoch 85:  53%|█████▎    | 81/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 82,Loss: -3.482,Avg.Loss: -2.952,LR: 2.89E-05]Training epoch 85:  54%|█████▎    | 82/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 83,Loss: -2.888,Avg.Loss: -2.951,LR: 2.89E-05]Training epoch 85:  54%|█████▍    | 83/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 84,Loss: -2.788,Avg.Loss: -2.949,LR: 2.89E-05]Training epoch 85:  55%|█████▍    | 84/153 [00:01<00:01, 53.01it/s, Epoch: 85, Batch: 84,Loss: -2.788,Avg.Loss: -2.949,LR: 2.89E-05]Training epoch 85:  55%|█████▍    | 84/153 [00:01<00:01, 53.01it/s, Epoch: 85, Batch: 85,Loss: -2.718,Avg.Loss: -2.946,LR: 2.89E-05]Training epoch 85:  56%|█████▌    | 85/153 [00:01<00:01, 53.01it/s, Epoch: 85, Batch: 86,Loss: -3.047,Avg.Loss: -2.947,LR: 2.88E-05]Training epoch 85:  56%|█████▌    | 86/153 [00:01<00:01, 53.01it/s, Epoch: 85, Batch: 87,Loss: -3.103,Avg.Loss: -2.949,LR: 2.88E-05]Training epoch 85:  57%|█████▋    | 87/153 [00:01<00:01, 53.01it/s, Epoch: 85, Batch: 88,Loss: -3.136,Avg.Loss: -2.951,LR: 2.88E-05]Training epoch 85:  58%|█████▊    | 88/153 [00:01<00:01, 53.01it/s, Epoch: 85, Batch: 89,Loss: -2.789,Avg.Loss: -2.949,LR: 2.88E-05]Training epoch 85:  58%|█████▊    | 89/153 [00:01<00:01, 53.01it/s, Epoch: 85, Batch: 90,Loss: -2.714,Avg.Loss: -2.947,LR: 2.87E-05]Training epoch 85:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 90,Loss: -2.714,Avg.Loss: -2.947,LR: 2.87E-05]Training epoch 85:  59%|█████▉    | 90/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 91,Loss: -3.085,Avg.Loss: -2.948,LR: 2.87E-05]Training epoch 85:  59%|█████▉    | 91/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 92,Loss: -2.838,Avg.Loss: -2.947,LR: 2.87E-05]Training epoch 85:  60%|██████    | 92/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 93,Loss: -3.068,Avg.Loss: -2.948,LR: 2.87E-05]Training epoch 85:  61%|██████    | 93/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 94,Loss: -3.180,Avg.Loss: -2.951,LR: 2.86E-05]Training epoch 85:  61%|██████▏   | 94/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 95,Loss: -2.974,Avg.Loss: -2.951,LR: 2.86E-05]Training epoch 85:  62%|██████▏   | 95/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 96,Loss: -2.420,Avg.Loss: -2.946,LR: 2.86E-05]Training epoch 85:  63%|██████▎   | 96/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 96,Loss: -2.420,Avg.Loss: -2.946,LR: 2.86E-05]Training epoch 85:  63%|██████▎   | 96/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 97,Loss: -2.849,Avg.Loss: -2.945,LR: 2.86E-05]Training epoch 85:  63%|██████▎   | 97/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 98,Loss: -3.188,Avg.Loss: -2.947,LR: 2.85E-05]Training epoch 85:  64%|██████▍   | 98/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 99,Loss: -2.555,Avg.Loss: -2.943,LR: 2.85E-05]Training epoch 85:  65%|██████▍   | 99/153 [00:01<00:01, 53.06it/s, Epoch: 85, Batch: 100,Loss: -3.082,Avg.Loss: -2.944,LR: 2.85E-05]Training epoch 85:  65%|██████▌   | 100/153 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 101,Loss: -3.297,Avg.Loss: -2.948,LR: 2.85E-05]Training epoch 85:  66%|██████▌   | 101/153 [00:01<00:00, 53.06it/s, Epoch: 85, Batch: 102,Loss: -2.937,Avg.Loss: -2.948,LR: 2.84E-05]Training epoch 85:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 85, Batch: 102,Loss: -2.937,Avg.Loss: -2.948,LR: 2.84E-05]Training epoch 85:  67%|██████▋   | 102/153 [00:01<00:00, 53.09it/s, Epoch: 85, Batch: 103,Loss: -3.232,Avg.Loss: -2.951,LR: 2.84E-05]Training epoch 85:  67%|██████▋   | 103/153 [00:01<00:00, 53.09it/s, Epoch: 85, Batch: 104,Loss: -3.215,Avg.Loss: -2.953,LR: 2.84E-05]Training epoch 85:  68%|██████▊   | 104/153 [00:01<00:00, 53.09it/s, Epoch: 85, Batch: 105,Loss: -3.104,Avg.Loss: -2.955,LR: 2.84E-05]Training epoch 85:  69%|██████▊   | 105/153 [00:01<00:00, 53.09it/s, Epoch: 85, Batch: 106,Loss: -3.078,Avg.Loss: -2.956,LR: 2.84E-05]Training epoch 85:  69%|██████▉   | 106/153 [00:02<00:00, 53.09it/s, Epoch: 85, Batch: 107,Loss: -3.310,Avg.Loss: -2.959,LR: 2.83E-05]Training epoch 85:  70%|██████▉   | 107/153 [00:02<00:00, 53.09it/s, Epoch: 85, Batch: 108,Loss: -2.818,Avg.Loss: -2.958,LR: 2.83E-05]Training epoch 85:  71%|███████   | 108/153 [00:02<00:00, 52.75it/s, Epoch: 85, Batch: 108,Loss: -2.818,Avg.Loss: -2.958,LR: 2.83E-05]Training epoch 85:  71%|███████   | 108/153 [00:02<00:00, 52.75it/s, Epoch: 85, Batch: 109,Loss: -3.683,Avg.Loss: -2.964,LR: 2.83E-05]Training epoch 85:  71%|███████   | 109/153 [00:02<00:00, 52.75it/s, Epoch: 85, Batch: 110,Loss: -2.879,Avg.Loss: -2.964,LR: 2.83E-05]Training epoch 85:  72%|███████▏  | 110/153 [00:02<00:00, 52.75it/s, Epoch: 85, Batch: 111,Loss: -3.476,Avg.Loss: -2.968,LR: 2.82E-05]Training epoch 85:  73%|███████▎  | 111/153 [00:02<00:00, 52.75it/s, Epoch: 85, Batch: 112,Loss: -2.884,Avg.Loss: -2.967,LR: 2.82E-05]Training epoch 85:  73%|███████▎  | 112/153 [00:02<00:00, 52.75it/s, Epoch: 85, Batch: 113,Loss: -3.381,Avg.Loss: -2.971,LR: 2.82E-05]Training epoch 85:  74%|███████▍  | 113/153 [00:02<00:00, 52.75it/s, Epoch: 85, Batch: 114,Loss: -3.103,Avg.Loss: -2.972,LR: 2.82E-05]Training epoch 85:  75%|███████▍  | 114/153 [00:02<00:00, 52.59it/s, Epoch: 85, Batch: 114,Loss: -3.103,Avg.Loss: -2.972,LR: 2.82E-05]Training epoch 85:  75%|███████▍  | 114/153 [00:02<00:00, 52.59it/s, Epoch: 85, Batch: 115,Loss: -2.823,Avg.Loss: -2.971,LR: 2.81E-05]Training epoch 85:  75%|███████▌  | 115/153 [00:02<00:00, 52.59it/s, Epoch: 85, Batch: 116,Loss: -2.976,Avg.Loss: -2.971,LR: 2.81E-05]Training epoch 85:  76%|███████▌  | 116/153 [00:02<00:00, 52.59it/s, Epoch: 85, Batch: 117,Loss: -2.834,Avg.Loss: -2.970,LR: 2.81E-05]Training epoch 85:  76%|███████▋  | 117/153 [00:02<00:00, 52.59it/s, Epoch: 85, Batch: 118,Loss: -3.247,Avg.Loss: -2.972,LR: 2.81E-05]Training epoch 85:  77%|███████▋  | 118/153 [00:02<00:00, 52.59it/s, Epoch: 85, Batch: 119,Loss: -3.334,Avg.Loss: -2.975,LR: 2.80E-05]Training epoch 85:  78%|███████▊  | 119/153 [00:02<00:00, 52.59it/s, Epoch: 85, Batch: 120,Loss: -2.788,Avg.Loss: -2.974,LR: 2.80E-05]Training epoch 85:  78%|███████▊  | 120/153 [00:02<00:00, 52.74it/s, Epoch: 85, Batch: 120,Loss: -2.788,Avg.Loss: -2.974,LR: 2.80E-05]Training epoch 85:  78%|███████▊  | 120/153 [00:02<00:00, 52.74it/s, Epoch: 85, Batch: 121,Loss: -2.977,Avg.Loss: -2.974,LR: 2.80E-05]Training epoch 85:  79%|███████▉  | 121/153 [00:02<00:00, 52.74it/s, Epoch: 85, Batch: 122,Loss: -3.364,Avg.Loss: -2.977,LR: 2.80E-05]Training epoch 85:  80%|███████▉  | 122/153 [00:02<00:00, 52.74it/s, Epoch: 85, Batch: 123,Loss: -3.203,Avg.Loss: -2.979,LR: 2.80E-05]Training epoch 85:  80%|████████  | 123/153 [00:02<00:00, 52.74it/s, Epoch: 85, Batch: 124,Loss: -3.242,Avg.Loss: -2.981,LR: 2.79E-05]Training epoch 85:  81%|████████  | 124/153 [00:02<00:00, 52.74it/s, Epoch: 85, Batch: 125,Loss: -3.011,Avg.Loss: -2.981,LR: 2.79E-05]Training epoch 85:  82%|████████▏ | 125/153 [00:02<00:00, 52.74it/s, Epoch: 85, Batch: 126,Loss: -3.224,Avg.Loss: -2.983,LR: 2.79E-05]Training epoch 85:  82%|████████▏ | 126/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 126,Loss: -3.224,Avg.Loss: -2.983,LR: 2.79E-05]Training epoch 85:  82%|████████▏ | 126/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 127,Loss: -3.008,Avg.Loss: -2.983,LR: 2.79E-05]Training epoch 85:  83%|████████▎ | 127/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 128,Loss: -2.880,Avg.Loss: -2.982,LR: 2.78E-05]Training epoch 85:  84%|████████▎ | 128/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 129,Loss: -3.163,Avg.Loss: -2.984,LR: 2.78E-05]Training epoch 85:  84%|████████▍ | 129/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 130,Loss: -3.087,Avg.Loss: -2.985,LR: 2.78E-05]Training epoch 85:  85%|████████▍ | 130/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 131,Loss: -3.201,Avg.Loss: -2.986,LR: 2.78E-05]Training epoch 85:  86%|████████▌ | 131/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 132,Loss: -2.649,Avg.Loss: -2.984,LR: 2.77E-05]Training epoch 85:  86%|████████▋ | 132/153 [00:02<00:00, 53.08it/s, Epoch: 85, Batch: 132,Loss: -2.649,Avg.Loss: -2.984,LR: 2.77E-05]Training epoch 85:  86%|████████▋ | 132/153 [00:02<00:00, 53.08it/s, Epoch: 85, Batch: 133,Loss: -3.053,Avg.Loss: -2.984,LR: 2.77E-05]Training epoch 85:  87%|████████▋ | 133/153 [00:02<00:00, 53.08it/s, Epoch: 85, Batch: 134,Loss: -3.059,Avg.Loss: -2.985,LR: 2.77E-05]Training epoch 85:  88%|████████▊ | 134/153 [00:02<00:00, 53.08it/s, Epoch: 85, Batch: 135,Loss: -2.929,Avg.Loss: -2.984,LR: 2.77E-05]Training epoch 85:  88%|████████▊ | 135/153 [00:02<00:00, 53.08it/s, Epoch: 85, Batch: 136,Loss: -3.484,Avg.Loss: -2.988,LR: 2.76E-05]Training epoch 85:  89%|████████▉ | 136/153 [00:02<00:00, 53.08it/s, Epoch: 85, Batch: 137,Loss: -2.999,Avg.Loss: -2.988,LR: 2.76E-05]Training epoch 85:  90%|████████▉ | 137/153 [00:02<00:00, 53.08it/s, Epoch: 85, Batch: 138,Loss: -3.461,Avg.Loss: -2.992,LR: 2.76E-05]Training epoch 85:  90%|█████████ | 138/153 [00:02<00:00, 53.17it/s, Epoch: 85, Batch: 138,Loss: -3.461,Avg.Loss: -2.992,LR: 2.76E-05]Training epoch 85:  90%|█████████ | 138/153 [00:02<00:00, 53.17it/s, Epoch: 85, Batch: 139,Loss: -2.860,Avg.Loss: -2.991,LR: 2.76E-05]Training epoch 85:  91%|█████████ | 139/153 [00:02<00:00, 53.17it/s, Epoch: 85, Batch: 140,Loss: -2.982,Avg.Loss: -2.991,LR: 2.76E-05]Training epoch 85:  92%|█████████▏| 140/153 [00:02<00:00, 53.17it/s, Epoch: 85, Batch: 141,Loss: -3.546,Avg.Loss: -2.995,LR: 2.75E-05]Training epoch 85:  92%|█████████▏| 141/153 [00:02<00:00, 53.17it/s, Epoch: 85, Batch: 142,Loss: -2.477,Avg.Loss: -2.991,LR: 2.75E-05]Training epoch 85:  93%|█████████▎| 142/153 [00:02<00:00, 53.17it/s, Epoch: 85, Batch: 143,Loss: -3.013,Avg.Loss: -2.991,LR: 2.75E-05]Training epoch 85:  93%|█████████▎| 143/153 [00:02<00:00, 53.17it/s, Epoch: 85, Batch: 144,Loss: -2.561,Avg.Loss: -2.988,LR: 2.75E-05]Training epoch 85:  94%|█████████▍| 144/153 [00:02<00:00, 53.04it/s, Epoch: 85, Batch: 144,Loss: -2.561,Avg.Loss: -2.988,LR: 2.75E-05]Training epoch 85:  94%|█████████▍| 144/153 [00:02<00:00, 53.04it/s, Epoch: 85, Batch: 145,Loss: -3.117,Avg.Loss: -2.989,LR: 2.74E-05]Training epoch 85:  95%|█████████▍| 145/153 [00:02<00:00, 53.04it/s, Epoch: 85, Batch: 146,Loss: -3.033,Avg.Loss: -2.989,LR: 2.74E-05]Training epoch 85:  95%|█████████▌| 146/153 [00:02<00:00, 53.04it/s, Epoch: 85, Batch: 147,Loss: -3.427,Avg.Loss: -2.992,LR: 2.74E-05]Training epoch 85:  96%|█████████▌| 147/153 [00:02<00:00, 53.04it/s, Epoch: 85, Batch: 148,Loss: -3.062,Avg.Loss: -2.993,LR: 2.74E-05]Training epoch 85:  97%|█████████▋| 148/153 [00:02<00:00, 53.04it/s, Epoch: 85, Batch: 149,Loss: -3.213,Avg.Loss: -2.994,LR: 2.73E-05]Training epoch 85:  97%|█████████▋| 149/153 [00:02<00:00, 53.04it/s, Epoch: 85, Batch: 150,Loss: -2.999,Avg.Loss: -2.994,LR: 2.73E-05]Training epoch 85:  98%|█████████▊| 150/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 150,Loss: -2.999,Avg.Loss: -2.994,LR: 2.73E-05]Training epoch 85:  98%|█████████▊| 150/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 151,Loss: -2.639,Avg.Loss: -2.992,LR: 2.73E-05]Training epoch 85:  99%|█████████▊| 151/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 152,Loss: -2.630,Avg.Loss: -2.989,LR: 2.73E-05]Training epoch 85:  99%|█████████▉| 152/153 [00:02<00:00, 52.89it/s, Epoch: 85, Batch: 153,Loss: -2.686,Avg.Loss: -2.987,LR: 2.72E-05]Training epoch 85: 100%|██████████| 153/153 [00:02<00:00, 52.96it/s, Epoch: 85, Batch: 153,Loss: -2.686,Avg.Loss: -2.987,LR: 2.72E-05]
Training epoch 86:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 86:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 86, Batch: 1,Loss: -3.251,Avg.Loss: -3.251,LR: 2.72E-05]Training epoch 86:   1%|          | 1/153 [00:00<00:05, 26.92it/s, Epoch: 86, Batch: 2,Loss: -2.747,Avg.Loss: -2.999,LR: 2.72E-05]Training epoch 86:   1%|▏         | 2/153 [00:00<00:03, 39.05it/s, Epoch: 86, Batch: 3,Loss: -2.946,Avg.Loss: -2.981,LR: 2.72E-05]Training epoch 86:   2%|▏         | 3/153 [00:00<00:03, 45.93it/s, Epoch: 86, Batch: 4,Loss: -3.181,Avg.Loss: -3.031,LR: 2.72E-05]Training epoch 86:   3%|▎         | 4/153 [00:00<00:03, 49.21it/s, Epoch: 86, Batch: 5,Loss: -2.434,Avg.Loss: -2.912,LR: 2.71E-05]Training epoch 86:   3%|▎         | 5/153 [00:00<00:02, 50.92it/s, Epoch: 86, Batch: 6,Loss: -2.405,Avg.Loss: -2.827,LR: 2.71E-05]Training epoch 86:   4%|▍         | 6/153 [00:00<00:02, 51.37it/s, Epoch: 86, Batch: 7,Loss: -2.968,Avg.Loss: -2.847,LR: 2.71E-05]Training epoch 86:   5%|▍         | 7/153 [00:00<00:02, 59.84it/s, Epoch: 86, Batch: 7,Loss: -2.968,Avg.Loss: -2.847,LR: 2.71E-05]Training epoch 86:   5%|▍         | 7/153 [00:00<00:02, 59.84it/s, Epoch: 86, Batch: 8,Loss: -2.275,Avg.Loss: -2.776,LR: 2.71E-05]Training epoch 86:   5%|▌         | 8/153 [00:00<00:02, 59.84it/s, Epoch: 86, Batch: 9,Loss: -3.080,Avg.Loss: -2.809,LR: 2.70E-05]Training epoch 86:   6%|▌         | 9/153 [00:00<00:02, 59.84it/s, Epoch: 86, Batch: 10,Loss: -3.339,Avg.Loss: -2.862,LR: 2.70E-05]Training epoch 86:   7%|▋         | 10/153 [00:00<00:02, 59.84it/s, Epoch: 86, Batch: 11,Loss: -2.691,Avg.Loss: -2.847,LR: 2.70E-05]Training epoch 86:   7%|▋         | 11/153 [00:00<00:02, 59.84it/s, Epoch: 86, Batch: 12,Loss: -2.654,Avg.Loss: -2.831,LR: 2.70E-05]Training epoch 86:   8%|▊         | 12/153 [00:00<00:02, 59.84it/s, Epoch: 86, Batch: 13,Loss: -2.064,Avg.Loss: -2.772,LR: 2.69E-05]Training epoch 86:   8%|▊         | 13/153 [00:00<00:02, 55.90it/s, Epoch: 86, Batch: 13,Loss: -2.064,Avg.Loss: -2.772,LR: 2.69E-05]Training epoch 86:   8%|▊         | 13/153 [00:00<00:02, 55.90it/s, Epoch: 86, Batch: 14,Loss: -2.378,Avg.Loss: -2.744,LR: 2.69E-05]Training epoch 86:   9%|▉         | 14/153 [00:00<00:02, 55.90it/s, Epoch: 86, Batch: 15,Loss: -3.140,Avg.Loss: -2.770,LR: 2.69E-05]Training epoch 86:  10%|▉         | 15/153 [00:00<00:02, 55.90it/s, Epoch: 86, Batch: 16,Loss: -2.812,Avg.Loss: -2.773,LR: 2.69E-05]Training epoch 86:  10%|█         | 16/153 [00:00<00:02, 55.90it/s, Epoch: 86, Batch: 17,Loss: -2.766,Avg.Loss: -2.772,LR: 2.69E-05]Training epoch 86:  11%|█         | 17/153 [00:00<00:02, 55.90it/s, Epoch: 86, Batch: 18,Loss: -2.798,Avg.Loss: -2.774,LR: 2.68E-05]Training epoch 86:  12%|█▏        | 18/153 [00:00<00:02, 55.90it/s, Epoch: 86, Batch: 19,Loss: -3.183,Avg.Loss: -2.795,LR: 2.68E-05]Training epoch 86:  12%|█▏        | 19/153 [00:00<00:02, 54.87it/s, Epoch: 86, Batch: 19,Loss: -3.183,Avg.Loss: -2.795,LR: 2.68E-05]Training epoch 86:  12%|█▏        | 19/153 [00:00<00:02, 54.87it/s, Epoch: 86, Batch: 20,Loss: -2.925,Avg.Loss: -2.802,LR: 2.68E-05]Training epoch 86:  13%|█▎        | 20/153 [00:00<00:02, 54.87it/s, Epoch: 86, Batch: 21,Loss: -3.035,Avg.Loss: -2.813,LR: 2.68E-05]Training epoch 86:  14%|█▎        | 21/153 [00:00<00:02, 54.87it/s, Epoch: 86, Batch: 22,Loss: -2.539,Avg.Loss: -2.800,LR: 2.67E-05]Training epoch 86:  14%|█▍        | 22/153 [00:00<00:02, 54.87it/s, Epoch: 86, Batch: 23,Loss: -2.889,Avg.Loss: -2.804,LR: 2.67E-05]Training epoch 86:  15%|█▌        | 23/153 [00:00<00:02, 54.87it/s, Epoch: 86, Batch: 24,Loss: -2.842,Avg.Loss: -2.806,LR: 2.67E-05]Training epoch 86:  16%|█▌        | 24/153 [00:00<00:02, 54.87it/s, Epoch: 86, Batch: 25,Loss: -3.042,Avg.Loss: -2.815,LR: 2.67E-05]Training epoch 86:  16%|█▋        | 25/153 [00:00<00:02, 53.33it/s, Epoch: 86, Batch: 25,Loss: -3.042,Avg.Loss: -2.815,LR: 2.67E-05]Training epoch 86:  16%|█▋        | 25/153 [00:00<00:02, 53.33it/s, Epoch: 86, Batch: 26,Loss: -3.114,Avg.Loss: -2.827,LR: 2.66E-05]Training epoch 86:  17%|█▋        | 26/153 [00:00<00:02, 53.33it/s, Epoch: 86, Batch: 27,Loss: -2.866,Avg.Loss: -2.828,LR: 2.66E-05]Training epoch 86:  18%|█▊        | 27/153 [00:00<00:02, 53.33it/s, Epoch: 86, Batch: 28,Loss: -3.132,Avg.Loss: -2.839,LR: 2.66E-05]Training epoch 86:  18%|█▊        | 28/153 [00:00<00:02, 53.33it/s, Epoch: 86, Batch: 29,Loss: -3.185,Avg.Loss: -2.851,LR: 2.66E-05]Training epoch 86:  19%|█▉        | 29/153 [00:00<00:02, 53.33it/s, Epoch: 86, Batch: 30,Loss: -3.353,Avg.Loss: -2.868,LR: 2.66E-05]Training epoch 86:  20%|█▉        | 30/153 [00:00<00:02, 53.33it/s, Epoch: 86, Batch: 31,Loss: -2.948,Avg.Loss: -2.870,LR: 2.65E-05]Training epoch 86:  20%|██        | 31/153 [00:00<00:02, 52.97it/s, Epoch: 86, Batch: 31,Loss: -2.948,Avg.Loss: -2.870,LR: 2.65E-05]Training epoch 86:  20%|██        | 31/153 [00:00<00:02, 52.97it/s, Epoch: 86, Batch: 32,Loss: -3.008,Avg.Loss: -2.875,LR: 2.65E-05]Training epoch 86:  21%|██        | 32/153 [00:00<00:02, 52.97it/s, Epoch: 86, Batch: 33,Loss: -2.957,Avg.Loss: -2.877,LR: 2.65E-05]Training epoch 86:  22%|██▏       | 33/153 [00:00<00:02, 52.97it/s, Epoch: 86, Batch: 34,Loss: -3.563,Avg.Loss: -2.897,LR: 2.65E-05]Training epoch 86:  22%|██▏       | 34/153 [00:00<00:02, 52.97it/s, Epoch: 86, Batch: 35,Loss: -2.833,Avg.Loss: -2.895,LR: 2.64E-05]Training epoch 86:  23%|██▎       | 35/153 [00:00<00:02, 52.97it/s, Epoch: 86, Batch: 36,Loss: -3.093,Avg.Loss: -2.901,LR: 2.64E-05]Training epoch 86:  24%|██▎       | 36/153 [00:00<00:02, 52.97it/s, Epoch: 86, Batch: 37,Loss: -2.774,Avg.Loss: -2.898,LR: 2.64E-05]Training epoch 86:  24%|██▍       | 37/153 [00:00<00:02, 53.09it/s, Epoch: 86, Batch: 37,Loss: -2.774,Avg.Loss: -2.898,LR: 2.64E-05]Training epoch 86:  24%|██▍       | 37/153 [00:00<00:02, 53.09it/s, Epoch: 86, Batch: 38,Loss: -2.800,Avg.Loss: -2.895,LR: 2.64E-05]Training epoch 86:  25%|██▍       | 38/153 [00:00<00:02, 53.09it/s, Epoch: 86, Batch: 39,Loss: -3.058,Avg.Loss: -2.899,LR: 2.63E-05]Training epoch 86:  25%|██▌       | 39/153 [00:00<00:02, 53.09it/s, Epoch: 86, Batch: 40,Loss: -3.110,Avg.Loss: -2.904,LR: 2.63E-05]Training epoch 86:  26%|██▌       | 40/153 [00:00<00:02, 53.09it/s, Epoch: 86, Batch: 41,Loss: -3.001,Avg.Loss: -2.907,LR: 2.63E-05]Training epoch 86:  27%|██▋       | 41/153 [00:00<00:02, 53.09it/s, Epoch: 86, Batch: 42,Loss: -3.186,Avg.Loss: -2.913,LR: 2.63E-05]Training epoch 86:  27%|██▋       | 42/153 [00:00<00:02, 53.09it/s, Epoch: 86, Batch: 43,Loss: -3.343,Avg.Loss: -2.923,LR: 2.63E-05]Training epoch 86:  28%|██▊       | 43/153 [00:00<00:02, 53.00it/s, Epoch: 86, Batch: 43,Loss: -3.343,Avg.Loss: -2.923,LR: 2.63E-05]Training epoch 86:  28%|██▊       | 43/153 [00:00<00:02, 53.00it/s, Epoch: 86, Batch: 44,Loss: -3.309,Avg.Loss: -2.932,LR: 2.62E-05]Training epoch 86:  29%|██▉       | 44/153 [00:00<00:02, 53.00it/s, Epoch: 86, Batch: 45,Loss: -3.731,Avg.Loss: -2.950,LR: 2.62E-05]Training epoch 86:  29%|██▉       | 45/153 [00:00<00:02, 53.00it/s, Epoch: 86, Batch: 46,Loss: -3.238,Avg.Loss: -2.956,LR: 2.62E-05]Training epoch 86:  30%|███       | 46/153 [00:00<00:02, 53.00it/s, Epoch: 86, Batch: 47,Loss: -2.488,Avg.Loss: -2.946,LR: 2.62E-05]Training epoch 86:  31%|███       | 47/153 [00:00<00:01, 53.00it/s, Epoch: 86, Batch: 48,Loss: -2.996,Avg.Loss: -2.947,LR: 2.61E-05]Training epoch 86:  31%|███▏      | 48/153 [00:00<00:01, 53.00it/s, Epoch: 86, Batch: 49,Loss: -2.671,Avg.Loss: -2.942,LR: 2.61E-05]Training epoch 86:  32%|███▏      | 49/153 [00:00<00:01, 52.96it/s, Epoch: 86, Batch: 49,Loss: -2.671,Avg.Loss: -2.942,LR: 2.61E-05]Training epoch 86:  32%|███▏      | 49/153 [00:00<00:01, 52.96it/s, Epoch: 86, Batch: 50,Loss: -3.188,Avg.Loss: -2.947,LR: 2.61E-05]Training epoch 86:  33%|███▎      | 50/153 [00:00<00:01, 52.96it/s, Epoch: 86, Batch: 51,Loss: -2.760,Avg.Loss: -2.943,LR: 2.61E-05]Training epoch 86:  33%|███▎      | 51/153 [00:00<00:01, 52.96it/s, Epoch: 86, Batch: 52,Loss: -3.070,Avg.Loss: -2.945,LR: 2.60E-05]Training epoch 86:  34%|███▍      | 52/153 [00:00<00:01, 52.96it/s, Epoch: 86, Batch: 53,Loss: -2.968,Avg.Loss: -2.946,LR: 2.60E-05]Training epoch 86:  35%|███▍      | 53/153 [00:01<00:01, 52.96it/s, Epoch: 86, Batch: 54,Loss: -2.906,Avg.Loss: -2.945,LR: 2.60E-05]Training epoch 86:  35%|███▌      | 54/153 [00:01<00:01, 52.96it/s, Epoch: 86, Batch: 55,Loss: -2.706,Avg.Loss: -2.941,LR: 2.60E-05]Training epoch 86:  36%|███▌      | 55/153 [00:01<00:01, 52.97it/s, Epoch: 86, Batch: 55,Loss: -2.706,Avg.Loss: -2.941,LR: 2.60E-05]Training epoch 86:  36%|███▌      | 55/153 [00:01<00:01, 52.97it/s, Epoch: 86, Batch: 56,Loss: -3.536,Avg.Loss: -2.951,LR: 2.60E-05]Training epoch 86:  37%|███▋      | 56/153 [00:01<00:01, 52.97it/s, Epoch: 86, Batch: 57,Loss: -2.789,Avg.Loss: -2.948,LR: 2.59E-05]Training epoch 86:  37%|███▋      | 57/153 [00:01<00:01, 52.97it/s, Epoch: 86, Batch: 58,Loss: -2.873,Avg.Loss: -2.947,LR: 2.59E-05]Training epoch 86:  38%|███▊      | 58/153 [00:01<00:01, 52.97it/s, Epoch: 86, Batch: 59,Loss: -3.235,Avg.Loss: -2.952,LR: 2.59E-05]Training epoch 86:  39%|███▊      | 59/153 [00:01<00:01, 52.97it/s, Epoch: 86, Batch: 60,Loss: -3.401,Avg.Loss: -2.960,LR: 2.59E-05]Training epoch 86:  39%|███▉      | 60/153 [00:01<00:01, 52.97it/s, Epoch: 86, Batch: 61,Loss: -2.797,Avg.Loss: -2.957,LR: 2.58E-05]Training epoch 86:  40%|███▉      | 61/153 [00:01<00:01, 52.84it/s, Epoch: 86, Batch: 61,Loss: -2.797,Avg.Loss: -2.957,LR: 2.58E-05]Training epoch 86:  40%|███▉      | 61/153 [00:01<00:01, 52.84it/s, Epoch: 86, Batch: 62,Loss: -2.936,Avg.Loss: -2.957,LR: 2.58E-05]Training epoch 86:  41%|████      | 62/153 [00:01<00:01, 52.84it/s, Epoch: 86, Batch: 63,Loss: -2.413,Avg.Loss: -2.948,LR: 2.58E-05]Training epoch 86:  41%|████      | 63/153 [00:01<00:01, 52.84it/s, Epoch: 86, Batch: 64,Loss: -3.233,Avg.Loss: -2.952,LR: 2.58E-05]Training epoch 86:  42%|████▏     | 64/153 [00:01<00:01, 52.84it/s, Epoch: 86, Batch: 65,Loss: -2.903,Avg.Loss: -2.952,LR: 2.58E-05]Training epoch 86:  42%|████▏     | 65/153 [00:01<00:01, 52.84it/s, Epoch: 86, Batch: 66,Loss: -2.804,Avg.Loss: -2.949,LR: 2.57E-05]Training epoch 86:  43%|████▎     | 66/153 [00:01<00:01, 52.84it/s, Epoch: 86, Batch: 67,Loss: -3.233,Avg.Loss: -2.954,LR: 2.57E-05]Training epoch 86:  44%|████▍     | 67/153 [00:01<00:01, 52.81it/s, Epoch: 86, Batch: 67,Loss: -3.233,Avg.Loss: -2.954,LR: 2.57E-05]Training epoch 86:  44%|████▍     | 67/153 [00:01<00:01, 52.81it/s, Epoch: 86, Batch: 68,Loss: -2.673,Avg.Loss: -2.949,LR: 2.57E-05]Training epoch 86:  44%|████▍     | 68/153 [00:01<00:01, 52.81it/s, Epoch: 86, Batch: 69,Loss: -3.216,Avg.Loss: -2.953,LR: 2.57E-05]Training epoch 86:  45%|████▌     | 69/153 [00:01<00:01, 52.81it/s, Epoch: 86, Batch: 70,Loss: -3.146,Avg.Loss: -2.956,LR: 2.56E-05]Training epoch 86:  46%|████▌     | 70/153 [00:01<00:01, 52.81it/s, Epoch: 86, Batch: 71,Loss: -2.948,Avg.Loss: -2.956,LR: 2.56E-05]Training epoch 86:  46%|████▋     | 71/153 [00:01<00:01, 52.81it/s, Epoch: 86, Batch: 72,Loss: -2.774,Avg.Loss: -2.953,LR: 2.56E-05]Training epoch 86:  47%|████▋     | 72/153 [00:01<00:01, 52.81it/s, Epoch: 86, Batch: 73,Loss: -3.022,Avg.Loss: -2.954,LR: 2.56E-05]Training epoch 86:  48%|████▊     | 73/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 73,Loss: -3.022,Avg.Loss: -2.954,LR: 2.56E-05]Training epoch 86:  48%|████▊     | 73/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 74,Loss: -3.047,Avg.Loss: -2.956,LR: 2.55E-05]Training epoch 86:  48%|████▊     | 74/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 75,Loss: -2.802,Avg.Loss: -2.954,LR: 2.55E-05]Training epoch 86:  49%|████▉     | 75/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 76,Loss: -3.351,Avg.Loss: -2.959,LR: 2.55E-05]Training epoch 86:  50%|████▉     | 76/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 77,Loss: -2.631,Avg.Loss: -2.955,LR: 2.55E-05]Training epoch 86:  50%|█████     | 77/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 78,Loss: -3.183,Avg.Loss: -2.957,LR: 2.55E-05]Training epoch 86:  51%|█████     | 78/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 79,Loss: -3.271,Avg.Loss: -2.961,LR: 2.54E-05]Training epoch 86:  52%|█████▏    | 79/153 [00:01<00:01, 52.75it/s, Epoch: 86, Batch: 79,Loss: -3.271,Avg.Loss: -2.961,LR: 2.54E-05]Training epoch 86:  52%|█████▏    | 79/153 [00:01<00:01, 52.75it/s, Epoch: 86, Batch: 80,Loss: -3.122,Avg.Loss: -2.963,LR: 2.54E-05]Training epoch 86:  52%|█████▏    | 80/153 [00:01<00:01, 52.75it/s, Epoch: 86, Batch: 81,Loss: -2.881,Avg.Loss: -2.962,LR: 2.54E-05]Training epoch 86:  53%|█████▎    | 81/153 [00:01<00:01, 52.75it/s, Epoch: 86, Batch: 82,Loss: -3.246,Avg.Loss: -2.966,LR: 2.54E-05]Training epoch 86:  54%|█████▎    | 82/153 [00:01<00:01, 52.75it/s, Epoch: 86, Batch: 83,Loss: -2.710,Avg.Loss: -2.963,LR: 2.53E-05]Training epoch 86:  54%|█████▍    | 83/153 [00:01<00:01, 52.75it/s, Epoch: 86, Batch: 84,Loss: -2.992,Avg.Loss: -2.963,LR: 2.53E-05]Training epoch 86:  55%|█████▍    | 84/153 [00:01<00:01, 52.75it/s, Epoch: 86, Batch: 85,Loss: -2.507,Avg.Loss: -2.958,LR: 2.53E-05]Training epoch 86:  56%|█████▌    | 85/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 85,Loss: -2.507,Avg.Loss: -2.958,LR: 2.53E-05]Training epoch 86:  56%|█████▌    | 85/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 86,Loss: -3.119,Avg.Loss: -2.960,LR: 2.53E-05]Training epoch 86:  56%|█████▌    | 86/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 87,Loss: -3.211,Avg.Loss: -2.963,LR: 2.53E-05]Training epoch 86:  57%|█████▋    | 87/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 88,Loss: -2.559,Avg.Loss: -2.958,LR: 2.52E-05]Training epoch 86:  58%|█████▊    | 88/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 89,Loss: -2.924,Avg.Loss: -2.958,LR: 2.52E-05]Training epoch 86:  58%|█████▊    | 89/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 90,Loss: -2.716,Avg.Loss: -2.955,LR: 2.52E-05]Training epoch 86:  59%|█████▉    | 90/153 [00:01<00:01, 52.83it/s, Epoch: 86, Batch: 91,Loss: -3.001,Avg.Loss: -2.955,LR: 2.52E-05]Training epoch 86:  59%|█████▉    | 91/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 91,Loss: -3.001,Avg.Loss: -2.955,LR: 2.52E-05]Training epoch 86:  59%|█████▉    | 91/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 92,Loss: -3.196,Avg.Loss: -2.958,LR: 2.51E-05]Training epoch 86:  60%|██████    | 92/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 93,Loss: -3.027,Avg.Loss: -2.959,LR: 2.51E-05]Training epoch 86:  61%|██████    | 93/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 94,Loss: -2.698,Avg.Loss: -2.956,LR: 2.51E-05]Training epoch 86:  61%|██████▏   | 94/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 95,Loss: -2.855,Avg.Loss: -2.955,LR: 2.51E-05]Training epoch 86:  62%|██████▏   | 95/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 96,Loss: -3.042,Avg.Loss: -2.956,LR: 2.51E-05]Training epoch 86:  63%|██████▎   | 96/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 97,Loss: -2.487,Avg.Loss: -2.951,LR: 2.50E-05]Training epoch 86:  63%|██████▎   | 97/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 97,Loss: -2.487,Avg.Loss: -2.951,LR: 2.50E-05]Training epoch 86:  63%|██████▎   | 97/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 98,Loss: -2.652,Avg.Loss: -2.948,LR: 2.50E-05]Training epoch 86:  64%|██████▍   | 98/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 99,Loss: -2.581,Avg.Loss: -2.944,LR: 2.50E-05]Training epoch 86:  65%|██████▍   | 99/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 100,Loss: -2.694,Avg.Loss: -2.942,LR: 2.50E-05]Training epoch 86:  65%|██████▌   | 100/153 [00:01<00:01, 52.63it/s, Epoch: 86, Batch: 101,Loss: -2.857,Avg.Loss: -2.941,LR: 2.49E-05]Training epoch 86:  66%|██████▌   | 101/153 [00:01<00:00, 52.63it/s, Epoch: 86, Batch: 102,Loss: -2.871,Avg.Loss: -2.940,LR: 2.49E-05]Training epoch 86:  67%|██████▋   | 102/153 [00:01<00:00, 52.63it/s, Epoch: 86, Batch: 103,Loss: -3.240,Avg.Loss: -2.943,LR: 2.49E-05]Training epoch 86:  67%|██████▋   | 103/153 [00:01<00:00, 52.44it/s, Epoch: 86, Batch: 103,Loss: -3.240,Avg.Loss: -2.943,LR: 2.49E-05]Training epoch 86:  67%|██████▋   | 103/153 [00:01<00:00, 52.44it/s, Epoch: 86, Batch: 104,Loss: -2.820,Avg.Loss: -2.942,LR: 2.49E-05]Training epoch 86:  68%|██████▊   | 104/153 [00:01<00:00, 52.44it/s, Epoch: 86, Batch: 105,Loss: -3.471,Avg.Loss: -2.947,LR: 2.49E-05]Training epoch 86:  69%|██████▊   | 105/153 [00:01<00:00, 52.44it/s, Epoch: 86, Batch: 106,Loss: -3.269,Avg.Loss: -2.950,LR: 2.48E-05]Training epoch 86:  69%|██████▉   | 106/153 [00:02<00:00, 52.44it/s, Epoch: 86, Batch: 107,Loss: -3.288,Avg.Loss: -2.953,LR: 2.48E-05]Training epoch 86:  70%|██████▉   | 107/153 [00:02<00:00, 52.44it/s, Epoch: 86, Batch: 108,Loss: -2.764,Avg.Loss: -2.951,LR: 2.48E-05]Training epoch 86:  71%|███████   | 108/153 [00:02<00:00, 52.44it/s, Epoch: 86, Batch: 109,Loss: -2.866,Avg.Loss: -2.951,LR: 2.48E-05]Training epoch 86:  71%|███████   | 109/153 [00:02<00:00, 52.53it/s, Epoch: 86, Batch: 109,Loss: -2.866,Avg.Loss: -2.951,LR: 2.48E-05]Training epoch 86:  71%|███████   | 109/153 [00:02<00:00, 52.53it/s, Epoch: 86, Batch: 110,Loss: -2.591,Avg.Loss: -2.947,LR: 2.47E-05]Training epoch 86:  72%|███████▏  | 110/153 [00:02<00:00, 52.53it/s, Epoch: 86, Batch: 111,Loss: -3.102,Avg.Loss: -2.949,LR: 2.47E-05]Training epoch 86:  73%|███████▎  | 111/153 [00:02<00:00, 52.53it/s, Epoch: 86, Batch: 112,Loss: -2.863,Avg.Loss: -2.948,LR: 2.47E-05]Training epoch 86:  73%|███████▎  | 112/153 [00:02<00:00, 52.53it/s, Epoch: 86, Batch: 113,Loss: -3.146,Avg.Loss: -2.950,LR: 2.47E-05]Training epoch 86:  74%|███████▍  | 113/153 [00:02<00:00, 52.53it/s, Epoch: 86, Batch: 114,Loss: -2.541,Avg.Loss: -2.946,LR: 2.47E-05]Training epoch 86:  75%|███████▍  | 114/153 [00:02<00:00, 52.53it/s, Epoch: 86, Batch: 115,Loss: -3.010,Avg.Loss: -2.947,LR: 2.46E-05]Training epoch 86:  75%|███████▌  | 115/153 [00:02<00:00, 52.51it/s, Epoch: 86, Batch: 115,Loss: -3.010,Avg.Loss: -2.947,LR: 2.46E-05]Training epoch 86:  75%|███████▌  | 115/153 [00:02<00:00, 52.51it/s, Epoch: 86, Batch: 116,Loss: -3.332,Avg.Loss: -2.950,LR: 2.46E-05]Training epoch 86:  76%|███████▌  | 116/153 [00:02<00:00, 52.51it/s, Epoch: 86, Batch: 117,Loss: -2.699,Avg.Loss: -2.948,LR: 2.46E-05]Training epoch 86:  76%|███████▋  | 117/153 [00:02<00:00, 52.51it/s, Epoch: 86, Batch: 118,Loss: -3.122,Avg.Loss: -2.949,LR: 2.46E-05]Training epoch 86:  77%|███████▋  | 118/153 [00:02<00:00, 52.51it/s, Epoch: 86, Batch: 119,Loss: -2.449,Avg.Loss: -2.945,LR: 2.45E-05]Training epoch 86:  78%|███████▊  | 119/153 [00:02<00:00, 52.51it/s, Epoch: 86, Batch: 120,Loss: -3.128,Avg.Loss: -2.947,LR: 2.45E-05]Training epoch 86:  78%|███████▊  | 120/153 [00:02<00:00, 52.51it/s, Epoch: 86, Batch: 121,Loss: -3.555,Avg.Loss: -2.952,LR: 2.45E-05]Training epoch 86:  79%|███████▉  | 121/153 [00:02<00:00, 52.55it/s, Epoch: 86, Batch: 121,Loss: -3.555,Avg.Loss: -2.952,LR: 2.45E-05]Training epoch 86:  79%|███████▉  | 121/153 [00:02<00:00, 52.55it/s, Epoch: 86, Batch: 122,Loss: -3.336,Avg.Loss: -2.955,LR: 2.45E-05]Training epoch 86:  80%|███████▉  | 122/153 [00:02<00:00, 52.55it/s, Epoch: 86, Batch: 123,Loss: -2.817,Avg.Loss: -2.954,LR: 2.45E-05]Training epoch 86:  80%|████████  | 123/153 [00:02<00:00, 52.55it/s, Epoch: 86, Batch: 124,Loss: -3.032,Avg.Loss: -2.954,LR: 2.44E-05]Training epoch 86:  81%|████████  | 124/153 [00:02<00:00, 52.55it/s, Epoch: 86, Batch: 125,Loss: -2.756,Avg.Loss: -2.953,LR: 2.44E-05]Training epoch 86:  82%|████████▏ | 125/153 [00:02<00:00, 52.55it/s, Epoch: 86, Batch: 126,Loss: -3.056,Avg.Loss: -2.954,LR: 2.44E-05]Training epoch 86:  82%|████████▏ | 126/153 [00:02<00:00, 52.55it/s, Epoch: 86, Batch: 127,Loss: -3.018,Avg.Loss: -2.954,LR: 2.44E-05]Training epoch 86:  83%|████████▎ | 127/153 [00:02<00:00, 52.82it/s, Epoch: 86, Batch: 127,Loss: -3.018,Avg.Loss: -2.954,LR: 2.44E-05]Training epoch 86:  83%|████████▎ | 127/153 [00:02<00:00, 52.82it/s, Epoch: 86, Batch: 128,Loss: -3.600,Avg.Loss: -2.959,LR: 2.43E-05]Training epoch 86:  84%|████████▎ | 128/153 [00:02<00:00, 52.82it/s, Epoch: 86, Batch: 129,Loss: -3.003,Avg.Loss: -2.959,LR: 2.43E-05]Training epoch 86:  84%|████████▍ | 129/153 [00:02<00:00, 52.82it/s, Epoch: 86, Batch: 130,Loss: -2.690,Avg.Loss: -2.957,LR: 2.43E-05]Training epoch 86:  85%|████████▍ | 130/153 [00:02<00:00, 52.82it/s, Epoch: 86, Batch: 131,Loss: -3.074,Avg.Loss: -2.958,LR: 2.43E-05]Training epoch 86:  86%|████████▌ | 131/153 [00:02<00:00, 52.82it/s, Epoch: 86, Batch: 132,Loss: -2.971,Avg.Loss: -2.958,LR: 2.43E-05]Training epoch 86:  86%|████████▋ | 132/153 [00:02<00:00, 52.82it/s, Epoch: 86, Batch: 133,Loss: -2.613,Avg.Loss: -2.956,LR: 2.42E-05]Training epoch 86:  87%|████████▋ | 133/153 [00:02<00:00, 52.90it/s, Epoch: 86, Batch: 133,Loss: -2.613,Avg.Loss: -2.956,LR: 2.42E-05]Training epoch 86:  87%|████████▋ | 133/153 [00:02<00:00, 52.90it/s, Epoch: 86, Batch: 134,Loss: -3.175,Avg.Loss: -2.957,LR: 2.42E-05]Training epoch 86:  88%|████████▊ | 134/153 [00:02<00:00, 52.90it/s, Epoch: 86, Batch: 135,Loss: -2.996,Avg.Loss: -2.958,LR: 2.42E-05]Training epoch 86:  88%|████████▊ | 135/153 [00:02<00:00, 52.90it/s, Epoch: 86, Batch: 136,Loss: -2.700,Avg.Loss: -2.956,LR: 2.42E-05]Training epoch 86:  89%|████████▉ | 136/153 [00:02<00:00, 52.90it/s, Epoch: 86, Batch: 137,Loss: -3.168,Avg.Loss: -2.957,LR: 2.41E-05]Training epoch 86:  90%|████████▉ | 137/153 [00:02<00:00, 52.90it/s, Epoch: 86, Batch: 138,Loss: -3.253,Avg.Loss: -2.960,LR: 2.41E-05]Training epoch 86:  90%|█████████ | 138/153 [00:02<00:00, 52.90it/s, Epoch: 86, Batch: 139,Loss: -3.192,Avg.Loss: -2.961,LR: 2.41E-05]Training epoch 86:  91%|█████████ | 139/153 [00:02<00:00, 52.84it/s, Epoch: 86, Batch: 139,Loss: -3.192,Avg.Loss: -2.961,LR: 2.41E-05]Training epoch 86:  91%|█████████ | 139/153 [00:02<00:00, 52.84it/s, Epoch: 86, Batch: 140,Loss: -2.736,Avg.Loss: -2.960,LR: 2.41E-05]Training epoch 86:  92%|█████████▏| 140/153 [00:02<00:00, 52.84it/s, Epoch: 86, Batch: 141,Loss: -2.732,Avg.Loss: -2.958,LR: 2.41E-05]Training epoch 86:  92%|█████████▏| 141/153 [00:02<00:00, 52.84it/s, Epoch: 86, Batch: 142,Loss: -3.412,Avg.Loss: -2.961,LR: 2.40E-05]Training epoch 86:  93%|█████████▎| 142/153 [00:02<00:00, 52.84it/s, Epoch: 86, Batch: 143,Loss: -3.069,Avg.Loss: -2.962,LR: 2.40E-05]Training epoch 86:  93%|█████████▎| 143/153 [00:02<00:00, 52.84it/s, Epoch: 86, Batch: 144,Loss: -2.997,Avg.Loss: -2.962,LR: 2.40E-05]Training epoch 86:  94%|█████████▍| 144/153 [00:02<00:00, 52.84it/s, Epoch: 86, Batch: 145,Loss: -2.688,Avg.Loss: -2.960,LR: 2.40E-05]Training epoch 86:  95%|█████████▍| 145/153 [00:02<00:00, 52.93it/s, Epoch: 86, Batch: 145,Loss: -2.688,Avg.Loss: -2.960,LR: 2.40E-05]Training epoch 86:  95%|█████████▍| 145/153 [00:02<00:00, 52.93it/s, Epoch: 86, Batch: 146,Loss: -3.457,Avg.Loss: -2.964,LR: 2.39E-05]Training epoch 86:  95%|█████████▌| 146/153 [00:02<00:00, 52.93it/s, Epoch: 86, Batch: 147,Loss: -3.060,Avg.Loss: -2.964,LR: 2.39E-05]Training epoch 86:  96%|█████████▌| 147/153 [00:02<00:00, 52.93it/s, Epoch: 86, Batch: 148,Loss: -2.682,Avg.Loss: -2.962,LR: 2.39E-05]Training epoch 86:  97%|█████████▋| 148/153 [00:02<00:00, 52.93it/s, Epoch: 86, Batch: 149,Loss: -3.231,Avg.Loss: -2.964,LR: 2.39E-05]Training epoch 86:  97%|█████████▋| 149/153 [00:02<00:00, 52.93it/s, Epoch: 86, Batch: 150,Loss: -2.960,Avg.Loss: -2.964,LR: 2.39E-05]Training epoch 86:  98%|█████████▊| 150/153 [00:02<00:00, 52.93it/s, Epoch: 86, Batch: 151,Loss: -3.426,Avg.Loss: -2.967,LR: 2.38E-05]Training epoch 86:  99%|█████████▊| 151/153 [00:02<00:00, 52.95it/s, Epoch: 86, Batch: 151,Loss: -3.426,Avg.Loss: -2.967,LR: 2.38E-05]Training epoch 86:  99%|█████████▊| 151/153 [00:02<00:00, 52.95it/s, Epoch: 86, Batch: 152,Loss: -2.587,Avg.Loss: -2.965,LR: 2.38E-05]Training epoch 86:  99%|█████████▉| 152/153 [00:02<00:00, 52.95it/s, Epoch: 86, Batch: 153,Loss: -3.158,Avg.Loss: -2.966,LR: 2.38E-05]Training epoch 86: 100%|██████████| 153/153 [00:02<00:00, 52.96it/s, Epoch: 86, Batch: 153,Loss: -3.158,Avg.Loss: -2.966,LR: 2.38E-05]
Training epoch 87:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 87:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 87, Batch: 1,Loss: -3.078,Avg.Loss: -3.078,LR: 2.38E-05]Training epoch 87:   1%|          | 1/153 [00:00<00:05, 26.71it/s, Epoch: 87, Batch: 2,Loss: -3.070,Avg.Loss: -3.074,LR: 2.37E-05]Training epoch 87:   1%|▏         | 2/153 [00:00<00:04, 35.90it/s, Epoch: 87, Batch: 3,Loss: -2.634,Avg.Loss: -2.927,LR: 2.37E-05]Training epoch 87:   2%|▏         | 3/153 [00:00<00:03, 40.78it/s, Epoch: 87, Batch: 4,Loss: -2.766,Avg.Loss: -2.887,LR: 2.37E-05]Training epoch 87:   3%|▎         | 4/153 [00:00<00:03, 43.68it/s, Epoch: 87, Batch: 5,Loss: -2.794,Avg.Loss: -2.868,LR: 2.37E-05]Training epoch 87:   3%|▎         | 5/153 [00:00<00:03, 45.25it/s, Epoch: 87, Batch: 6,Loss: -3.151,Avg.Loss: -2.916,LR: 2.37E-05]Training epoch 87:   4%|▍         | 6/153 [00:00<00:02, 54.21it/s, Epoch: 87, Batch: 6,Loss: -3.151,Avg.Loss: -2.916,LR: 2.37E-05]Training epoch 87:   4%|▍         | 6/153 [00:00<00:02, 54.21it/s, Epoch: 87, Batch: 7,Loss: -3.052,Avg.Loss: -2.935,LR: 2.36E-05]Training epoch 87:   5%|▍         | 7/153 [00:00<00:02, 54.21it/s, Epoch: 87, Batch: 8,Loss: -2.965,Avg.Loss: -2.939,LR: 2.36E-05]Training epoch 87:   5%|▌         | 8/153 [00:00<00:02, 54.21it/s, Epoch: 87, Batch: 9,Loss: -3.305,Avg.Loss: -2.979,LR: 2.36E-05]Training epoch 87:   6%|▌         | 9/153 [00:00<00:02, 54.21it/s, Epoch: 87, Batch: 10,Loss: -2.398,Avg.Loss: -2.921,LR: 2.36E-05]Training epoch 87:   7%|▋         | 10/153 [00:00<00:02, 54.21it/s, Epoch: 87, Batch: 11,Loss: -3.532,Avg.Loss: -2.977,LR: 2.36E-05]Training epoch 87:   7%|▋         | 11/153 [00:00<00:02, 54.21it/s, Epoch: 87, Batch: 12,Loss: -3.112,Avg.Loss: -2.988,LR: 2.35E-05]Training epoch 87:   8%|▊         | 12/153 [00:00<00:02, 53.32it/s, Epoch: 87, Batch: 12,Loss: -3.112,Avg.Loss: -2.988,LR: 2.35E-05]Training epoch 87:   8%|▊         | 12/153 [00:00<00:02, 53.32it/s, Epoch: 87, Batch: 13,Loss: -2.896,Avg.Loss: -2.981,LR: 2.35E-05]Training epoch 87:   8%|▊         | 13/153 [00:00<00:02, 53.32it/s, Epoch: 87, Batch: 14,Loss: -2.814,Avg.Loss: -2.969,LR: 2.35E-05]Training epoch 87:   9%|▉         | 14/153 [00:00<00:02, 53.32it/s, Epoch: 87, Batch: 15,Loss: -3.027,Avg.Loss: -2.973,LR: 2.35E-05]Training epoch 87:  10%|▉         | 15/153 [00:00<00:02, 53.32it/s, Epoch: 87, Batch: 16,Loss: -3.370,Avg.Loss: -2.998,LR: 2.34E-05]Training epoch 87:  10%|█         | 16/153 [00:00<00:02, 53.32it/s, Epoch: 87, Batch: 17,Loss: -3.109,Avg.Loss: -3.004,LR: 2.34E-05]Training epoch 87:  11%|█         | 17/153 [00:00<00:02, 53.32it/s, Epoch: 87, Batch: 18,Loss: -3.131,Avg.Loss: -3.011,LR: 2.34E-05]Training epoch 87:  12%|█▏        | 18/153 [00:00<00:02, 53.06it/s, Epoch: 87, Batch: 18,Loss: -3.131,Avg.Loss: -3.011,LR: 2.34E-05]Training epoch 87:  12%|█▏        | 18/153 [00:00<00:02, 53.06it/s, Epoch: 87, Batch: 19,Loss: -3.245,Avg.Loss: -3.024,LR: 2.34E-05]Training epoch 87:  12%|█▏        | 19/153 [00:00<00:02, 53.06it/s, Epoch: 87, Batch: 20,Loss: -2.728,Avg.Loss: -3.009,LR: 2.34E-05]Training epoch 87:  13%|█▎        | 20/153 [00:00<00:02, 53.06it/s, Epoch: 87, Batch: 21,Loss: -3.306,Avg.Loss: -3.023,LR: 2.33E-05]Training epoch 87:  14%|█▎        | 21/153 [00:00<00:02, 53.06it/s, Epoch: 87, Batch: 22,Loss: -3.311,Avg.Loss: -3.036,LR: 2.33E-05]Training epoch 87:  14%|█▍        | 22/153 [00:00<00:02, 53.06it/s, Epoch: 87, Batch: 23,Loss: -2.823,Avg.Loss: -3.027,LR: 2.33E-05]Training epoch 87:  15%|█▌        | 23/153 [00:00<00:02, 53.06it/s, Epoch: 87, Batch: 24,Loss: -3.226,Avg.Loss: -3.035,LR: 2.33E-05]Training epoch 87:  16%|█▌        | 24/153 [00:00<00:02, 52.21it/s, Epoch: 87, Batch: 24,Loss: -3.226,Avg.Loss: -3.035,LR: 2.33E-05]Training epoch 87:  16%|█▌        | 24/153 [00:00<00:02, 52.21it/s, Epoch: 87, Batch: 25,Loss: -2.735,Avg.Loss: -3.023,LR: 2.32E-05]Training epoch 87:  16%|█▋        | 25/153 [00:00<00:02, 52.21it/s, Epoch: 87, Batch: 26,Loss: -2.402,Avg.Loss: -2.999,LR: 2.32E-05]Training epoch 87:  17%|█▋        | 26/153 [00:00<00:02, 52.21it/s, Epoch: 87, Batch: 27,Loss: -3.363,Avg.Loss: -3.013,LR: 2.32E-05]Training epoch 87:  18%|█▊        | 27/153 [00:00<00:02, 52.21it/s, Epoch: 87, Batch: 28,Loss: -3.158,Avg.Loss: -3.018,LR: 2.32E-05]Training epoch 87:  18%|█▊        | 28/153 [00:00<00:02, 52.21it/s, Epoch: 87, Batch: 29,Loss: -2.755,Avg.Loss: -3.009,LR: 2.32E-05]Training epoch 87:  19%|█▉        | 29/153 [00:00<00:02, 52.21it/s, Epoch: 87, Batch: 30,Loss: -3.116,Avg.Loss: -3.012,LR: 2.31E-05]Training epoch 87:  20%|█▉        | 30/153 [00:00<00:02, 52.15it/s, Epoch: 87, Batch: 30,Loss: -3.116,Avg.Loss: -3.012,LR: 2.31E-05]Training epoch 87:  20%|█▉        | 30/153 [00:00<00:02, 52.15it/s, Epoch: 87, Batch: 31,Loss: -3.289,Avg.Loss: -3.021,LR: 2.31E-05]Training epoch 87:  20%|██        | 31/153 [00:00<00:02, 52.15it/s, Epoch: 87, Batch: 32,Loss: -2.784,Avg.Loss: -3.014,LR: 2.31E-05]Training epoch 87:  21%|██        | 32/153 [00:00<00:02, 52.15it/s, Epoch: 87, Batch: 33,Loss: -2.948,Avg.Loss: -3.012,LR: 2.31E-05]Training epoch 87:  22%|██▏       | 33/153 [00:00<00:02, 52.15it/s, Epoch: 87, Batch: 34,Loss: -3.194,Avg.Loss: -3.017,LR: 2.31E-05]Training epoch 87:  22%|██▏       | 34/153 [00:00<00:02, 52.15it/s, Epoch: 87, Batch: 35,Loss: -2.959,Avg.Loss: -3.016,LR: 2.30E-05]Training epoch 87:  23%|██▎       | 35/153 [00:00<00:02, 52.15it/s, Epoch: 87, Batch: 36,Loss: -3.069,Avg.Loss: -3.017,LR: 2.30E-05]Training epoch 87:  24%|██▎       | 36/153 [00:00<00:02, 52.27it/s, Epoch: 87, Batch: 36,Loss: -3.069,Avg.Loss: -3.017,LR: 2.30E-05]Training epoch 87:  24%|██▎       | 36/153 [00:00<00:02, 52.27it/s, Epoch: 87, Batch: 37,Loss: -3.011,Avg.Loss: -3.017,LR: 2.30E-05]Training epoch 87:  24%|██▍       | 37/153 [00:00<00:02, 52.27it/s, Epoch: 87, Batch: 38,Loss: -3.124,Avg.Loss: -3.020,LR: 2.30E-05]Training epoch 87:  25%|██▍       | 38/153 [00:00<00:02, 52.27it/s, Epoch: 87, Batch: 39,Loss: -3.024,Avg.Loss: -3.020,LR: 2.29E-05]Training epoch 87:  25%|██▌       | 39/153 [00:00<00:02, 52.27it/s, Epoch: 87, Batch: 40,Loss: -3.099,Avg.Loss: -3.022,LR: 2.29E-05]Training epoch 87:  26%|██▌       | 40/153 [00:00<00:02, 52.27it/s, Epoch: 87, Batch: 41,Loss: -2.774,Avg.Loss: -3.016,LR: 2.29E-05]Training epoch 87:  27%|██▋       | 41/153 [00:00<00:02, 52.27it/s, Epoch: 87, Batch: 42,Loss: -3.676,Avg.Loss: -3.032,LR: 2.29E-05]Training epoch 87:  27%|██▋       | 42/153 [00:00<00:02, 52.50it/s, Epoch: 87, Batch: 42,Loss: -3.676,Avg.Loss: -3.032,LR: 2.29E-05]Training epoch 87:  27%|██▋       | 42/153 [00:00<00:02, 52.50it/s, Epoch: 87, Batch: 43,Loss: -3.080,Avg.Loss: -3.033,LR: 2.29E-05]Training epoch 87:  28%|██▊       | 43/153 [00:00<00:02, 52.50it/s, Epoch: 87, Batch: 44,Loss: -3.083,Avg.Loss: -3.034,LR: 2.28E-05]Training epoch 87:  29%|██▉       | 44/153 [00:00<00:02, 52.50it/s, Epoch: 87, Batch: 45,Loss: -2.523,Avg.Loss: -3.022,LR: 2.28E-05]Training epoch 87:  29%|██▉       | 45/153 [00:00<00:02, 52.50it/s, Epoch: 87, Batch: 46,Loss: -2.914,Avg.Loss: -3.020,LR: 2.28E-05]Training epoch 87:  30%|███       | 46/153 [00:00<00:02, 52.50it/s, Epoch: 87, Batch: 47,Loss: -2.385,Avg.Loss: -3.007,LR: 2.28E-05]Training epoch 87:  31%|███       | 47/153 [00:00<00:02, 52.50it/s, Epoch: 87, Batch: 48,Loss: -3.303,Avg.Loss: -3.013,LR: 2.28E-05]Training epoch 87:  31%|███▏      | 48/153 [00:00<00:01, 52.91it/s, Epoch: 87, Batch: 48,Loss: -3.303,Avg.Loss: -3.013,LR: 2.28E-05]Training epoch 87:  31%|███▏      | 48/153 [00:00<00:01, 52.91it/s, Epoch: 87, Batch: 49,Loss: -2.787,Avg.Loss: -3.008,LR: 2.27E-05]Training epoch 87:  32%|███▏      | 49/153 [00:00<00:01, 52.91it/s, Epoch: 87, Batch: 50,Loss: -3.291,Avg.Loss: -3.014,LR: 2.27E-05]Training epoch 87:  33%|███▎      | 50/153 [00:00<00:01, 52.91it/s, Epoch: 87, Batch: 51,Loss: -2.911,Avg.Loss: -3.012,LR: 2.27E-05]Training epoch 87:  33%|███▎      | 51/153 [00:00<00:01, 52.91it/s, Epoch: 87, Batch: 52,Loss: -2.919,Avg.Loss: -3.010,LR: 2.27E-05]Training epoch 87:  34%|███▍      | 52/153 [00:01<00:01, 52.91it/s, Epoch: 87, Batch: 53,Loss: -2.750,Avg.Loss: -3.005,LR: 2.26E-05]Training epoch 87:  35%|███▍      | 53/153 [00:01<00:01, 52.91it/s, Epoch: 87, Batch: 54,Loss: -2.573,Avg.Loss: -2.997,LR: 2.26E-05]Training epoch 87:  35%|███▌      | 54/153 [00:01<00:01, 52.89it/s, Epoch: 87, Batch: 54,Loss: -2.573,Avg.Loss: -2.997,LR: 2.26E-05]Training epoch 87:  35%|███▌      | 54/153 [00:01<00:01, 52.89it/s, Epoch: 87, Batch: 55,Loss: -3.084,Avg.Loss: -2.999,LR: 2.26E-05]Training epoch 87:  36%|███▌      | 55/153 [00:01<00:01, 52.89it/s, Epoch: 87, Batch: 56,Loss: -2.930,Avg.Loss: -2.997,LR: 2.26E-05]Training epoch 87:  37%|███▋      | 56/153 [00:01<00:01, 52.89it/s, Epoch: 87, Batch: 57,Loss: -3.227,Avg.Loss: -3.001,LR: 2.26E-05]Training epoch 87:  37%|███▋      | 57/153 [00:01<00:01, 52.89it/s, Epoch: 87, Batch: 58,Loss: -2.857,Avg.Loss: -2.999,LR: 2.25E-05]Training epoch 87:  38%|███▊      | 58/153 [00:01<00:01, 52.89it/s, Epoch: 87, Batch: 59,Loss: -2.677,Avg.Loss: -2.994,LR: 2.25E-05]Training epoch 87:  39%|███▊      | 59/153 [00:01<00:01, 52.89it/s, Epoch: 87, Batch: 60,Loss: -3.123,Avg.Loss: -2.996,LR: 2.25E-05]Training epoch 87:  39%|███▉      | 60/153 [00:01<00:01, 52.53it/s, Epoch: 87, Batch: 60,Loss: -3.123,Avg.Loss: -2.996,LR: 2.25E-05]Training epoch 87:  39%|███▉      | 60/153 [00:01<00:01, 52.53it/s, Epoch: 87, Batch: 61,Loss: -3.063,Avg.Loss: -2.997,LR: 2.25E-05]Training epoch 87:  40%|███▉      | 61/153 [00:01<00:01, 52.53it/s, Epoch: 87, Batch: 62,Loss: -3.163,Avg.Loss: -2.999,LR: 2.25E-05]Training epoch 87:  41%|████      | 62/153 [00:01<00:01, 52.53it/s, Epoch: 87, Batch: 63,Loss: -2.906,Avg.Loss: -2.998,LR: 2.24E-05]Training epoch 87:  41%|████      | 63/153 [00:01<00:01, 52.53it/s, Epoch: 87, Batch: 64,Loss: -3.443,Avg.Loss: -3.005,LR: 2.24E-05]Training epoch 87:  42%|████▏     | 64/153 [00:01<00:01, 52.53it/s, Epoch: 87, Batch: 65,Loss: -2.213,Avg.Loss: -2.993,LR: 2.24E-05]Training epoch 87:  42%|████▏     | 65/153 [00:01<00:01, 52.53it/s, Epoch: 87, Batch: 66,Loss: -2.979,Avg.Loss: -2.993,LR: 2.24E-05]Training epoch 87:  43%|████▎     | 66/153 [00:01<00:01, 52.45it/s, Epoch: 87, Batch: 66,Loss: -2.979,Avg.Loss: -2.993,LR: 2.24E-05]Training epoch 87:  43%|████▎     | 66/153 [00:01<00:01, 52.45it/s, Epoch: 87, Batch: 67,Loss: -2.841,Avg.Loss: -2.990,LR: 2.24E-05]Training epoch 87:  44%|████▍     | 67/153 [00:01<00:01, 52.45it/s, Epoch: 87, Batch: 68,Loss: -2.685,Avg.Loss: -2.986,LR: 2.23E-05]Training epoch 87:  44%|████▍     | 68/153 [00:01<00:01, 52.45it/s, Epoch: 87, Batch: 69,Loss: -3.037,Avg.Loss: -2.987,LR: 2.23E-05]Training epoch 87:  45%|████▌     | 69/153 [00:01<00:01, 52.45it/s, Epoch: 87, Batch: 70,Loss: -3.425,Avg.Loss: -2.993,LR: 2.23E-05]Training epoch 87:  46%|████▌     | 70/153 [00:01<00:01, 52.45it/s, Epoch: 87, Batch: 71,Loss: -2.992,Avg.Loss: -2.993,LR: 2.23E-05]Training epoch 87:  46%|████▋     | 71/153 [00:01<00:01, 52.45it/s, Epoch: 87, Batch: 72,Loss: -3.229,Avg.Loss: -2.996,LR: 2.22E-05]Training epoch 87:  47%|████▋     | 72/153 [00:01<00:01, 52.65it/s, Epoch: 87, Batch: 72,Loss: -3.229,Avg.Loss: -2.996,LR: 2.22E-05]Training epoch 87:  47%|████▋     | 72/153 [00:01<00:01, 52.65it/s, Epoch: 87, Batch: 73,Loss: -2.848,Avg.Loss: -2.994,LR: 2.22E-05]Training epoch 87:  48%|████▊     | 73/153 [00:01<00:01, 52.65it/s, Epoch: 87, Batch: 74,Loss: -2.831,Avg.Loss: -2.992,LR: 2.22E-05]Training epoch 87:  48%|████▊     | 74/153 [00:01<00:01, 52.65it/s, Epoch: 87, Batch: 75,Loss: -3.216,Avg.Loss: -2.995,LR: 2.22E-05]Training epoch 87:  49%|████▉     | 75/153 [00:01<00:01, 52.65it/s, Epoch: 87, Batch: 76,Loss: -3.199,Avg.Loss: -2.998,LR: 2.22E-05]Training epoch 87:  50%|████▉     | 76/153 [00:01<00:01, 52.65it/s, Epoch: 87, Batch: 77,Loss: -3.194,Avg.Loss: -3.000,LR: 2.21E-05]Training epoch 87:  50%|█████     | 77/153 [00:01<00:01, 52.65it/s, Epoch: 87, Batch: 78,Loss: -3.028,Avg.Loss: -3.000,LR: 2.21E-05]Training epoch 87:  51%|█████     | 78/153 [00:01<00:01, 52.70it/s, Epoch: 87, Batch: 78,Loss: -3.028,Avg.Loss: -3.000,LR: 2.21E-05]Training epoch 87:  51%|█████     | 78/153 [00:01<00:01, 52.70it/s, Epoch: 87, Batch: 79,Loss: -3.128,Avg.Loss: -3.002,LR: 2.21E-05]Training epoch 87:  52%|█████▏    | 79/153 [00:01<00:01, 52.70it/s, Epoch: 87, Batch: 80,Loss: -2.638,Avg.Loss: -2.998,LR: 2.21E-05]Training epoch 87:  52%|█████▏    | 80/153 [00:01<00:01, 52.70it/s, Epoch: 87, Batch: 81,Loss: -3.055,Avg.Loss: -2.998,LR: 2.21E-05]Training epoch 87:  53%|█████▎    | 81/153 [00:01<00:01, 52.70it/s, Epoch: 87, Batch: 82,Loss: -2.908,Avg.Loss: -2.997,LR: 2.20E-05]Training epoch 87:  54%|█████▎    | 82/153 [00:01<00:01, 52.70it/s, Epoch: 87, Batch: 83,Loss: -2.977,Avg.Loss: -2.997,LR: 2.20E-05]Training epoch 87:  54%|█████▍    | 83/153 [00:01<00:01, 52.70it/s, Epoch: 87, Batch: 84,Loss: -2.848,Avg.Loss: -2.995,LR: 2.20E-05]Training epoch 87:  55%|█████▍    | 84/153 [00:01<00:01, 52.85it/s, Epoch: 87, Batch: 84,Loss: -2.848,Avg.Loss: -2.995,LR: 2.20E-05]Training epoch 87:  55%|█████▍    | 84/153 [00:01<00:01, 52.85it/s, Epoch: 87, Batch: 85,Loss: -2.599,Avg.Loss: -2.990,LR: 2.20E-05]Training epoch 87:  56%|█████▌    | 85/153 [00:01<00:01, 52.85it/s, Epoch: 87, Batch: 86,Loss: -3.047,Avg.Loss: -2.991,LR: 2.19E-05]Training epoch 87:  56%|█████▌    | 86/153 [00:01<00:01, 52.85it/s, Epoch: 87, Batch: 87,Loss: -2.773,Avg.Loss: -2.989,LR: 2.19E-05]Training epoch 87:  57%|█████▋    | 87/153 [00:01<00:01, 52.85it/s, Epoch: 87, Batch: 88,Loss: -2.957,Avg.Loss: -2.988,LR: 2.19E-05]Training epoch 87:  58%|█████▊    | 88/153 [00:01<00:01, 52.85it/s, Epoch: 87, Batch: 89,Loss: -3.373,Avg.Loss: -2.993,LR: 2.19E-05]Training epoch 87:  58%|█████▊    | 89/153 [00:01<00:01, 52.85it/s, Epoch: 87, Batch: 90,Loss: -3.598,Avg.Loss: -2.999,LR: 2.19E-05]Training epoch 87:  59%|█████▉    | 90/153 [00:01<00:01, 52.81it/s, Epoch: 87, Batch: 90,Loss: -3.598,Avg.Loss: -2.999,LR: 2.19E-05]Training epoch 87:  59%|█████▉    | 90/153 [00:01<00:01, 52.81it/s, Epoch: 87, Batch: 91,Loss: -3.294,Avg.Loss: -3.003,LR: 2.18E-05]Training epoch 87:  59%|█████▉    | 91/153 [00:01<00:01, 52.81it/s, Epoch: 87, Batch: 92,Loss: -2.758,Avg.Loss: -3.000,LR: 2.18E-05]Training epoch 87:  60%|██████    | 92/153 [00:01<00:01, 52.81it/s, Epoch: 87, Batch: 93,Loss: -3.223,Avg.Loss: -3.002,LR: 2.18E-05]Training epoch 87:  61%|██████    | 93/153 [00:01<00:01, 52.81it/s, Epoch: 87, Batch: 94,Loss: -3.145,Avg.Loss: -3.004,LR: 2.18E-05]Training epoch 87:  61%|██████▏   | 94/153 [00:01<00:01, 52.81it/s, Epoch: 87, Batch: 95,Loss: -3.169,Avg.Loss: -3.006,LR: 2.18E-05]Training epoch 87:  62%|██████▏   | 95/153 [00:01<00:01, 52.81it/s, Epoch: 87, Batch: 96,Loss: -2.855,Avg.Loss: -3.004,LR: 2.17E-05]Training epoch 87:  63%|██████▎   | 96/153 [00:01<00:01, 52.83it/s, Epoch: 87, Batch: 96,Loss: -2.855,Avg.Loss: -3.004,LR: 2.17E-05]Training epoch 87:  63%|██████▎   | 96/153 [00:01<00:01, 52.83it/s, Epoch: 87, Batch: 97,Loss: -2.865,Avg.Loss: -3.003,LR: 2.17E-05]Training epoch 87:  63%|██████▎   | 97/153 [00:01<00:01, 52.83it/s, Epoch: 87, Batch: 98,Loss: -3.058,Avg.Loss: -3.003,LR: 2.17E-05]Training epoch 87:  64%|██████▍   | 98/153 [00:01<00:01, 52.83it/s, Epoch: 87, Batch: 99,Loss: -2.919,Avg.Loss: -3.002,LR: 2.17E-05]Training epoch 87:  65%|██████▍   | 99/153 [00:01<00:01, 52.83it/s, Epoch: 87, Batch: 100,Loss: -2.745,Avg.Loss: -3.000,LR: 2.17E-05]Training epoch 87:  65%|██████▌   | 100/153 [00:01<00:01, 52.83it/s, Epoch: 87, Batch: 101,Loss: -3.207,Avg.Loss: -3.002,LR: 2.16E-05]Training epoch 87:  66%|██████▌   | 101/153 [00:01<00:00, 52.83it/s, Epoch: 87, Batch: 102,Loss: -3.477,Avg.Loss: -3.006,LR: 2.16E-05]Training epoch 87:  67%|██████▋   | 102/153 [00:01<00:00, 52.78it/s, Epoch: 87, Batch: 102,Loss: -3.477,Avg.Loss: -3.006,LR: 2.16E-05]Training epoch 87:  67%|██████▋   | 102/153 [00:01<00:00, 52.78it/s, Epoch: 87, Batch: 103,Loss: -2.911,Avg.Loss: -3.005,LR: 2.16E-05]Training epoch 87:  67%|██████▋   | 103/153 [00:01<00:00, 52.78it/s, Epoch: 87, Batch: 104,Loss: -3.385,Avg.Loss: -3.009,LR: 2.16E-05]Training epoch 87:  68%|██████▊   | 104/153 [00:01<00:00, 52.78it/s, Epoch: 87, Batch: 105,Loss: -3.123,Avg.Loss: -3.010,LR: 2.16E-05]Training epoch 87:  69%|██████▊   | 105/153 [00:02<00:00, 52.78it/s, Epoch: 87, Batch: 106,Loss: -3.070,Avg.Loss: -3.011,LR: 2.15E-05]Training epoch 87:  69%|██████▉   | 106/153 [00:02<00:00, 52.78it/s, Epoch: 87, Batch: 107,Loss: -3.285,Avg.Loss: -3.013,LR: 2.15E-05]Training epoch 87:  70%|██████▉   | 107/153 [00:02<00:00, 52.78it/s, Epoch: 87, Batch: 108,Loss: -3.167,Avg.Loss: -3.015,LR: 2.15E-05]Training epoch 87:  71%|███████   | 108/153 [00:02<00:00, 52.83it/s, Epoch: 87, Batch: 108,Loss: -3.167,Avg.Loss: -3.015,LR: 2.15E-05]Training epoch 87:  71%|███████   | 108/153 [00:02<00:00, 52.83it/s, Epoch: 87, Batch: 109,Loss: -2.556,Avg.Loss: -3.011,LR: 2.15E-05]Training epoch 87:  71%|███████   | 109/153 [00:02<00:00, 52.83it/s, Epoch: 87, Batch: 110,Loss: -2.658,Avg.Loss: -3.007,LR: 2.14E-05]Training epoch 87:  72%|███████▏  | 110/153 [00:02<00:00, 52.83it/s, Epoch: 87, Batch: 111,Loss: -3.054,Avg.Loss: -3.008,LR: 2.14E-05]Training epoch 87:  73%|███████▎  | 111/153 [00:02<00:00, 52.83it/s, Epoch: 87, Batch: 112,Loss: -3.098,Avg.Loss: -3.009,LR: 2.14E-05]Training epoch 87:  73%|███████▎  | 112/153 [00:02<00:00, 52.83it/s, Epoch: 87, Batch: 113,Loss: -3.358,Avg.Loss: -3.012,LR: 2.14E-05]Training epoch 87:  74%|███████▍  | 113/153 [00:02<00:00, 52.83it/s, Epoch: 87, Batch: 114,Loss: -3.503,Avg.Loss: -3.016,LR: 2.14E-05]Training epoch 87:  75%|███████▍  | 114/153 [00:02<00:00, 52.93it/s, Epoch: 87, Batch: 114,Loss: -3.503,Avg.Loss: -3.016,LR: 2.14E-05]Training epoch 87:  75%|███████▍  | 114/153 [00:02<00:00, 52.93it/s, Epoch: 87, Batch: 115,Loss: -3.324,Avg.Loss: -3.019,LR: 2.13E-05]Training epoch 87:  75%|███████▌  | 115/153 [00:02<00:00, 52.93it/s, Epoch: 87, Batch: 116,Loss: -3.103,Avg.Loss: -3.019,LR: 2.13E-05]Training epoch 87:  76%|███████▌  | 116/153 [00:02<00:00, 52.93it/s, Epoch: 87, Batch: 117,Loss: -2.389,Avg.Loss: -3.014,LR: 2.13E-05]Training epoch 87:  76%|███████▋  | 117/153 [00:02<00:00, 52.93it/s, Epoch: 87, Batch: 118,Loss: -2.593,Avg.Loss: -3.010,LR: 2.13E-05]Training epoch 87:  77%|███████▋  | 118/153 [00:02<00:00, 52.93it/s, Epoch: 87, Batch: 119,Loss: -3.286,Avg.Loss: -3.013,LR: 2.13E-05]Training epoch 87:  78%|███████▊  | 119/153 [00:02<00:00, 52.93it/s, Epoch: 87, Batch: 120,Loss: -3.369,Avg.Loss: -3.016,LR: 2.12E-05]Training epoch 87:  78%|███████▊  | 120/153 [00:02<00:00, 52.91it/s, Epoch: 87, Batch: 120,Loss: -3.369,Avg.Loss: -3.016,LR: 2.12E-05]Training epoch 87:  78%|███████▊  | 120/153 [00:02<00:00, 52.91it/s, Epoch: 87, Batch: 121,Loss: -3.302,Avg.Loss: -3.018,LR: 2.12E-05]Training epoch 87:  79%|███████▉  | 121/153 [00:02<00:00, 52.91it/s, Epoch: 87, Batch: 122,Loss: -3.151,Avg.Loss: -3.019,LR: 2.12E-05]Training epoch 87:  80%|███████▉  | 122/153 [00:02<00:00, 52.91it/s, Epoch: 87, Batch: 123,Loss: -3.125,Avg.Loss: -3.020,LR: 2.12E-05]Training epoch 87:  80%|████████  | 123/153 [00:02<00:00, 52.91it/s, Epoch: 87, Batch: 124,Loss: -2.689,Avg.Loss: -3.017,LR: 2.12E-05]Training epoch 87:  81%|████████  | 124/153 [00:02<00:00, 52.91it/s, Epoch: 87, Batch: 125,Loss: -2.732,Avg.Loss: -3.015,LR: 2.11E-05]Training epoch 87:  82%|████████▏ | 125/153 [00:02<00:00, 52.91it/s, Epoch: 87, Batch: 126,Loss: -2.803,Avg.Loss: -3.013,LR: 2.11E-05]Training epoch 87:  82%|████████▏ | 126/153 [00:02<00:00, 52.95it/s, Epoch: 87, Batch: 126,Loss: -2.803,Avg.Loss: -3.013,LR: 2.11E-05]Training epoch 87:  82%|████████▏ | 126/153 [00:02<00:00, 52.95it/s, Epoch: 87, Batch: 127,Loss: -3.002,Avg.Loss: -3.013,LR: 2.11E-05]Training epoch 87:  83%|████████▎ | 127/153 [00:02<00:00, 52.95it/s, Epoch: 87, Batch: 128,Loss: -2.697,Avg.Loss: -3.011,LR: 2.11E-05]Training epoch 87:  84%|████████▎ | 128/153 [00:02<00:00, 52.95it/s, Epoch: 87, Batch: 129,Loss: -2.776,Avg.Loss: -3.009,LR: 2.11E-05]Training epoch 87:  84%|████████▍ | 129/153 [00:02<00:00, 52.95it/s, Epoch: 87, Batch: 130,Loss: -2.738,Avg.Loss: -3.007,LR: 2.10E-05]Training epoch 87:  85%|████████▍ | 130/153 [00:02<00:00, 52.95it/s, Epoch: 87, Batch: 131,Loss: -3.116,Avg.Loss: -3.008,LR: 2.10E-05]Training epoch 87:  86%|████████▌ | 131/153 [00:02<00:00, 52.95it/s, Epoch: 87, Batch: 132,Loss: -2.827,Avg.Loss: -3.006,LR: 2.10E-05]Training epoch 87:  86%|████████▋ | 132/153 [00:02<00:00, 52.99it/s, Epoch: 87, Batch: 132,Loss: -2.827,Avg.Loss: -3.006,LR: 2.10E-05]Training epoch 87:  86%|████████▋ | 132/153 [00:02<00:00, 52.99it/s, Epoch: 87, Batch: 133,Loss: -2.777,Avg.Loss: -3.005,LR: 2.10E-05]Training epoch 87:  87%|████████▋ | 133/153 [00:02<00:00, 52.99it/s, Epoch: 87, Batch: 134,Loss: -3.035,Avg.Loss: -3.005,LR: 2.10E-05]Training epoch 87:  88%|████████▊ | 134/153 [00:02<00:00, 52.99it/s, Epoch: 87, Batch: 135,Loss: -3.149,Avg.Loss: -3.006,LR: 2.09E-05]Training epoch 87:  88%|████████▊ | 135/153 [00:02<00:00, 52.99it/s, Epoch: 87, Batch: 136,Loss: -2.739,Avg.Loss: -3.004,LR: 2.09E-05]Training epoch 87:  89%|████████▉ | 136/153 [00:02<00:00, 52.99it/s, Epoch: 87, Batch: 137,Loss: -2.896,Avg.Loss: -3.003,LR: 2.09E-05]Training epoch 87:  90%|████████▉ | 137/153 [00:02<00:00, 52.99it/s, Epoch: 87, Batch: 138,Loss: -2.599,Avg.Loss: -3.000,LR: 2.09E-05]Training epoch 87:  90%|█████████ | 138/153 [00:02<00:00, 53.09it/s, Epoch: 87, Batch: 138,Loss: -2.599,Avg.Loss: -3.000,LR: 2.09E-05]Training epoch 87:  90%|█████████ | 138/153 [00:02<00:00, 53.09it/s, Epoch: 87, Batch: 139,Loss: -3.439,Avg.Loss: -3.003,LR: 2.08E-05]Training epoch 87:  91%|█████████ | 139/153 [00:02<00:00, 53.09it/s, Epoch: 87, Batch: 140,Loss: -2.656,Avg.Loss: -3.001,LR: 2.08E-05]Training epoch 87:  92%|█████████▏| 140/153 [00:02<00:00, 53.09it/s, Epoch: 87, Batch: 141,Loss: -2.957,Avg.Loss: -3.001,LR: 2.08E-05]Training epoch 87:  92%|█████████▏| 141/153 [00:02<00:00, 53.09it/s, Epoch: 87, Batch: 142,Loss: -2.663,Avg.Loss: -2.998,LR: 2.08E-05]Training epoch 87:  93%|█████████▎| 142/153 [00:02<00:00, 53.09it/s, Epoch: 87, Batch: 143,Loss: -2.575,Avg.Loss: -2.995,LR: 2.08E-05]Training epoch 87:  93%|█████████▎| 143/153 [00:02<00:00, 53.09it/s, Epoch: 87, Batch: 144,Loss: -3.071,Avg.Loss: -2.996,LR: 2.07E-05]Training epoch 87:  94%|█████████▍| 144/153 [00:02<00:00, 53.05it/s, Epoch: 87, Batch: 144,Loss: -3.071,Avg.Loss: -2.996,LR: 2.07E-05]Training epoch 87:  94%|█████████▍| 144/153 [00:02<00:00, 53.05it/s, Epoch: 87, Batch: 145,Loss: -2.951,Avg.Loss: -2.996,LR: 2.07E-05]Training epoch 87:  95%|█████████▍| 145/153 [00:02<00:00, 53.05it/s, Epoch: 87, Batch: 146,Loss: -3.022,Avg.Loss: -2.996,LR: 2.07E-05]Training epoch 87:  95%|█████████▌| 146/153 [00:02<00:00, 53.05it/s, Epoch: 87, Batch: 147,Loss: -2.979,Avg.Loss: -2.996,LR: 2.07E-05]Training epoch 87:  96%|█████████▌| 147/153 [00:02<00:00, 53.05it/s, Epoch: 87, Batch: 148,Loss: -3.194,Avg.Loss: -2.997,LR: 2.07E-05]Training epoch 87:  97%|█████████▋| 148/153 [00:02<00:00, 53.05it/s, Epoch: 87, Batch: 149,Loss: -3.770,Avg.Loss: -3.002,LR: 2.06E-05]Training epoch 87:  97%|█████████▋| 149/153 [00:02<00:00, 53.05it/s, Epoch: 87, Batch: 150,Loss: -3.452,Avg.Loss: -3.005,LR: 2.06E-05]Training epoch 87:  98%|█████████▊| 150/153 [00:02<00:00, 53.11it/s, Epoch: 87, Batch: 150,Loss: -3.452,Avg.Loss: -3.005,LR: 2.06E-05]Training epoch 87:  98%|█████████▊| 150/153 [00:02<00:00, 53.11it/s, Epoch: 87, Batch: 151,Loss: -3.246,Avg.Loss: -3.007,LR: 2.06E-05]Training epoch 87:  99%|█████████▊| 151/153 [00:02<00:00, 53.11it/s, Epoch: 87, Batch: 152,Loss: -3.177,Avg.Loss: -3.008,LR: 2.06E-05]Training epoch 87:  99%|█████████▉| 152/153 [00:02<00:00, 53.11it/s, Epoch: 87, Batch: 153,Loss: -2.534,Avg.Loss: -3.005,LR: 2.06E-05]Training epoch 87: 100%|██████████| 153/153 [00:02<00:00, 52.77it/s, Epoch: 87, Batch: 153,Loss: -2.534,Avg.Loss: -3.005,LR: 2.06E-05]
Training epoch 88:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 88:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 88, Batch: 1,Loss: -3.201,Avg.Loss: -3.201,LR: 2.05E-05]Training epoch 88:   1%|          | 1/153 [00:00<00:06, 23.94it/s, Epoch: 88, Batch: 2,Loss: -3.157,Avg.Loss: -3.179,LR: 2.05E-05]Training epoch 88:   1%|▏         | 2/153 [00:00<00:04, 33.47it/s, Epoch: 88, Batch: 3,Loss: -2.481,Avg.Loss: -2.947,LR: 2.05E-05]Training epoch 88:   2%|▏         | 3/153 [00:00<00:03, 38.49it/s, Epoch: 88, Batch: 4,Loss: -2.987,Avg.Loss: -2.957,LR: 2.05E-05]Training epoch 88:   3%|▎         | 4/153 [00:00<00:03, 41.26it/s, Epoch: 88, Batch: 5,Loss: -2.273,Avg.Loss: -2.820,LR: 2.05E-05]Training epoch 88:   3%|▎         | 5/153 [00:00<00:03, 43.13it/s, Epoch: 88, Batch: 6,Loss: -2.648,Avg.Loss: -2.791,LR: 2.04E-05]Training epoch 88:   4%|▍         | 6/153 [00:00<00:02, 51.67it/s, Epoch: 88, Batch: 6,Loss: -2.648,Avg.Loss: -2.791,LR: 2.04E-05]Training epoch 88:   4%|▍         | 6/153 [00:00<00:02, 51.67it/s, Epoch: 88, Batch: 7,Loss: -3.293,Avg.Loss: -2.863,LR: 2.04E-05]Training epoch 88:   5%|▍         | 7/153 [00:00<00:02, 51.67it/s, Epoch: 88, Batch: 8,Loss: -2.848,Avg.Loss: -2.861,LR: 2.04E-05]Training epoch 88:   5%|▌         | 8/153 [00:00<00:02, 51.67it/s, Epoch: 88, Batch: 9,Loss: -2.774,Avg.Loss: -2.851,LR: 2.04E-05]Training epoch 88:   6%|▌         | 9/153 [00:00<00:02, 51.67it/s, Epoch: 88, Batch: 10,Loss: -2.564,Avg.Loss: -2.823,LR: 2.04E-05]Training epoch 88:   7%|▋         | 10/153 [00:00<00:02, 51.67it/s, Epoch: 88, Batch: 11,Loss: -2.981,Avg.Loss: -2.837,LR: 2.03E-05]Training epoch 88:   7%|▋         | 11/153 [00:00<00:02, 51.67it/s, Epoch: 88, Batch: 12,Loss: -3.203,Avg.Loss: -2.868,LR: 2.03E-05]Training epoch 88:   8%|▊         | 12/153 [00:00<00:02, 52.52it/s, Epoch: 88, Batch: 12,Loss: -3.203,Avg.Loss: -2.868,LR: 2.03E-05]Training epoch 88:   8%|▊         | 12/153 [00:00<00:02, 52.52it/s, Epoch: 88, Batch: 13,Loss: -3.299,Avg.Loss: -2.901,LR: 2.03E-05]Training epoch 88:   8%|▊         | 13/153 [00:00<00:02, 52.52it/s, Epoch: 88, Batch: 14,Loss: -2.701,Avg.Loss: -2.886,LR: 2.03E-05]Training epoch 88:   9%|▉         | 14/153 [00:00<00:02, 52.52it/s, Epoch: 88, Batch: 15,Loss: -2.646,Avg.Loss: -2.870,LR: 2.03E-05]Training epoch 88:  10%|▉         | 15/153 [00:00<00:02, 52.52it/s, Epoch: 88, Batch: 16,Loss: -2.675,Avg.Loss: -2.858,LR: 2.02E-05]Training epoch 88:  10%|█         | 16/153 [00:00<00:02, 52.52it/s, Epoch: 88, Batch: 17,Loss: -3.339,Avg.Loss: -2.886,LR: 2.02E-05]Training epoch 88:  11%|█         | 17/153 [00:00<00:02, 52.52it/s, Epoch: 88, Batch: 18,Loss: -3.113,Avg.Loss: -2.899,LR: 2.02E-05]Training epoch 88:  12%|█▏        | 18/153 [00:00<00:02, 52.47it/s, Epoch: 88, Batch: 18,Loss: -3.113,Avg.Loss: -2.899,LR: 2.02E-05]Training epoch 88:  12%|█▏        | 18/153 [00:00<00:02, 52.47it/s, Epoch: 88, Batch: 19,Loss: -2.789,Avg.Loss: -2.893,LR: 2.02E-05]Training epoch 88:  12%|█▏        | 19/153 [00:00<00:02, 52.47it/s, Epoch: 88, Batch: 20,Loss: -2.508,Avg.Loss: -2.874,LR: 2.02E-05]Training epoch 88:  13%|█▎        | 20/153 [00:00<00:02, 52.47it/s, Epoch: 88, Batch: 21,Loss: -3.215,Avg.Loss: -2.890,LR: 2.01E-05]Training epoch 88:  14%|█▎        | 21/153 [00:00<00:02, 52.47it/s, Epoch: 88, Batch: 22,Loss: -2.664,Avg.Loss: -2.880,LR: 2.01E-05]Training epoch 88:  14%|█▍        | 22/153 [00:00<00:02, 52.47it/s, Epoch: 88, Batch: 23,Loss: -2.685,Avg.Loss: -2.871,LR: 2.01E-05]Training epoch 88:  15%|█▌        | 23/153 [00:00<00:02, 52.47it/s, Epoch: 88, Batch: 24,Loss: -2.779,Avg.Loss: -2.868,LR: 2.01E-05]Training epoch 88:  16%|█▌        | 24/153 [00:00<00:02, 51.13it/s, Epoch: 88, Batch: 24,Loss: -2.779,Avg.Loss: -2.868,LR: 2.01E-05]Training epoch 88:  16%|█▌        | 24/153 [00:00<00:02, 51.13it/s, Epoch: 88, Batch: 25,Loss: -2.957,Avg.Loss: -2.871,LR: 2.01E-05]Training epoch 88:  16%|█▋        | 25/153 [00:00<00:02, 51.13it/s, Epoch: 88, Batch: 26,Loss: -3.109,Avg.Loss: -2.880,LR: 2.00E-05]Training epoch 88:  17%|█▋        | 26/153 [00:00<00:02, 51.13it/s, Epoch: 88, Batch: 27,Loss: -2.940,Avg.Loss: -2.883,LR: 2.00E-05]Training epoch 88:  18%|█▊        | 27/153 [00:00<00:02, 51.13it/s, Epoch: 88, Batch: 28,Loss: -3.153,Avg.Loss: -2.892,LR: 2.00E-05]Training epoch 88:  18%|█▊        | 28/153 [00:00<00:02, 51.13it/s, Epoch: 88, Batch: 29,Loss: -2.361,Avg.Loss: -2.874,LR: 2.00E-05]Training epoch 88:  19%|█▉        | 29/153 [00:00<00:02, 51.13it/s, Epoch: 88, Batch: 30,Loss: -2.722,Avg.Loss: -2.869,LR: 2.00E-05]Training epoch 88:  20%|█▉        | 30/153 [00:00<00:02, 51.60it/s, Epoch: 88, Batch: 30,Loss: -2.722,Avg.Loss: -2.869,LR: 2.00E-05]Training epoch 88:  20%|█▉        | 30/153 [00:00<00:02, 51.60it/s, Epoch: 88, Batch: 31,Loss: -3.082,Avg.Loss: -2.876,LR: 1.99E-05]Training epoch 88:  20%|██        | 31/153 [00:00<00:02, 51.60it/s, Epoch: 88, Batch: 32,Loss: -2.120,Avg.Loss: -2.852,LR: 1.99E-05]Training epoch 88:  21%|██        | 32/153 [00:00<00:02, 51.60it/s, Epoch: 88, Batch: 33,Loss: -2.815,Avg.Loss: -2.851,LR: 1.99E-05]Training epoch 88:  22%|██▏       | 33/153 [00:00<00:02, 51.60it/s, Epoch: 88, Batch: 34,Loss: -3.039,Avg.Loss: -2.856,LR: 1.99E-05]Training epoch 88:  22%|██▏       | 34/153 [00:00<00:02, 51.60it/s, Epoch: 88, Batch: 35,Loss: -3.415,Avg.Loss: -2.872,LR: 1.99E-05]Training epoch 88:  23%|██▎       | 35/153 [00:00<00:02, 51.60it/s, Epoch: 88, Batch: 36,Loss: -3.180,Avg.Loss: -2.881,LR: 1.98E-05]Training epoch 88:  24%|██▎       | 36/153 [00:00<00:02, 52.15it/s, Epoch: 88, Batch: 36,Loss: -3.180,Avg.Loss: -2.881,LR: 1.98E-05]Training epoch 88:  24%|██▎       | 36/153 [00:00<00:02, 52.15it/s, Epoch: 88, Batch: 37,Loss: -3.062,Avg.Loss: -2.886,LR: 1.98E-05]Training epoch 88:  24%|██▍       | 37/153 [00:00<00:02, 52.15it/s, Epoch: 88, Batch: 38,Loss: -2.909,Avg.Loss: -2.886,LR: 1.98E-05]Training epoch 88:  25%|██▍       | 38/153 [00:00<00:02, 52.15it/s, Epoch: 88, Batch: 39,Loss: -3.207,Avg.Loss: -2.895,LR: 1.98E-05]Training epoch 88:  25%|██▌       | 39/153 [00:00<00:02, 52.15it/s, Epoch: 88, Batch: 40,Loss: -2.869,Avg.Loss: -2.894,LR: 1.98E-05]Training epoch 88:  26%|██▌       | 40/153 [00:00<00:02, 52.15it/s, Epoch: 88, Batch: 41,Loss: -3.002,Avg.Loss: -2.897,LR: 1.97E-05]Training epoch 88:  27%|██▋       | 41/153 [00:00<00:02, 52.15it/s, Epoch: 88, Batch: 42,Loss: -2.883,Avg.Loss: -2.896,LR: 1.97E-05]Training epoch 88:  27%|██▋       | 42/153 [00:00<00:02, 52.61it/s, Epoch: 88, Batch: 42,Loss: -2.883,Avg.Loss: -2.896,LR: 1.97E-05]Training epoch 88:  27%|██▋       | 42/153 [00:00<00:02, 52.61it/s, Epoch: 88, Batch: 43,Loss: -3.232,Avg.Loss: -2.904,LR: 1.97E-05]Training epoch 88:  28%|██▊       | 43/153 [00:00<00:02, 52.61it/s, Epoch: 88, Batch: 44,Loss: -3.324,Avg.Loss: -2.914,LR: 1.97E-05]Training epoch 88:  29%|██▉       | 44/153 [00:00<00:02, 52.61it/s, Epoch: 88, Batch: 45,Loss: -3.069,Avg.Loss: -2.917,LR: 1.97E-05]Training epoch 88:  29%|██▉       | 45/153 [00:00<00:02, 52.61it/s, Epoch: 88, Batch: 46,Loss: -2.936,Avg.Loss: -2.918,LR: 1.96E-05]Training epoch 88:  30%|███       | 46/153 [00:00<00:02, 52.61it/s, Epoch: 88, Batch: 47,Loss: -3.111,Avg.Loss: -2.922,LR: 1.96E-05]Training epoch 88:  31%|███       | 47/153 [00:00<00:02, 52.61it/s, Epoch: 88, Batch: 48,Loss: -2.991,Avg.Loss: -2.923,LR: 1.96E-05]Training epoch 88:  31%|███▏      | 48/153 [00:00<00:01, 52.92it/s, Epoch: 88, Batch: 48,Loss: -2.991,Avg.Loss: -2.923,LR: 1.96E-05]Training epoch 88:  31%|███▏      | 48/153 [00:00<00:01, 52.92it/s, Epoch: 88, Batch: 49,Loss: -3.099,Avg.Loss: -2.927,LR: 1.96E-05]Training epoch 88:  32%|███▏      | 49/153 [00:00<00:01, 52.92it/s, Epoch: 88, Batch: 50,Loss: -2.944,Avg.Loss: -2.927,LR: 1.96E-05]Training epoch 88:  33%|███▎      | 50/153 [00:00<00:01, 52.92it/s, Epoch: 88, Batch: 51,Loss: -3.271,Avg.Loss: -2.934,LR: 1.95E-05]Training epoch 88:  33%|███▎      | 51/153 [00:00<00:01, 52.92it/s, Epoch: 88, Batch: 52,Loss: -2.655,Avg.Loss: -2.928,LR: 1.95E-05]Training epoch 88:  34%|███▍      | 52/153 [00:01<00:01, 52.92it/s, Epoch: 88, Batch: 53,Loss: -2.828,Avg.Loss: -2.927,LR: 1.95E-05]Training epoch 88:  35%|███▍      | 53/153 [00:01<00:01, 52.92it/s, Epoch: 88, Batch: 54,Loss: -2.576,Avg.Loss: -2.920,LR: 1.95E-05]Training epoch 88:  35%|███▌      | 54/153 [00:01<00:01, 53.06it/s, Epoch: 88, Batch: 54,Loss: -2.576,Avg.Loss: -2.920,LR: 1.95E-05]Training epoch 88:  35%|███▌      | 54/153 [00:01<00:01, 53.06it/s, Epoch: 88, Batch: 55,Loss: -3.462,Avg.Loss: -2.930,LR: 1.95E-05]Training epoch 88:  36%|███▌      | 55/153 [00:01<00:01, 53.06it/s, Epoch: 88, Batch: 56,Loss: -3.207,Avg.Loss: -2.935,LR: 1.94E-05]Training epoch 88:  37%|███▋      | 56/153 [00:01<00:01, 53.06it/s, Epoch: 88, Batch: 57,Loss: -2.668,Avg.Loss: -2.930,LR: 1.94E-05]Training epoch 88:  37%|███▋      | 57/153 [00:01<00:01, 53.06it/s, Epoch: 88, Batch: 58,Loss: -3.085,Avg.Loss: -2.933,LR: 1.94E-05]Training epoch 88:  38%|███▊      | 58/153 [00:01<00:01, 53.06it/s, Epoch: 88, Batch: 59,Loss: -2.583,Avg.Loss: -2.927,LR: 1.94E-05]Training epoch 88:  39%|███▊      | 59/153 [00:01<00:01, 53.06it/s, Epoch: 88, Batch: 60,Loss: -2.579,Avg.Loss: -2.921,LR: 1.94E-05]Training epoch 88:  39%|███▉      | 60/153 [00:01<00:01, 53.11it/s, Epoch: 88, Batch: 60,Loss: -2.579,Avg.Loss: -2.921,LR: 1.94E-05]Training epoch 88:  39%|███▉      | 60/153 [00:01<00:01, 53.11it/s, Epoch: 88, Batch: 61,Loss: -2.914,Avg.Loss: -2.921,LR: 1.93E-05]Training epoch 88:  40%|███▉      | 61/153 [00:01<00:01, 53.11it/s, Epoch: 88, Batch: 62,Loss: -3.166,Avg.Loss: -2.925,LR: 1.93E-05]Training epoch 88:  41%|████      | 62/153 [00:01<00:01, 53.11it/s, Epoch: 88, Batch: 63,Loss: -3.070,Avg.Loss: -2.927,LR: 1.93E-05]Training epoch 88:  41%|████      | 63/153 [00:01<00:01, 53.11it/s, Epoch: 88, Batch: 64,Loss: -3.501,Avg.Loss: -2.936,LR: 1.93E-05]Training epoch 88:  42%|████▏     | 64/153 [00:01<00:01, 53.11it/s, Epoch: 88, Batch: 65,Loss: -3.040,Avg.Loss: -2.938,LR: 1.93E-05]Training epoch 88:  42%|████▏     | 65/153 [00:01<00:01, 53.11it/s, Epoch: 88, Batch: 66,Loss: -3.232,Avg.Loss: -2.942,LR: 1.92E-05]Training epoch 88:  43%|████▎     | 66/153 [00:01<00:01, 53.23it/s, Epoch: 88, Batch: 66,Loss: -3.232,Avg.Loss: -2.942,LR: 1.92E-05]Training epoch 88:  43%|████▎     | 66/153 [00:01<00:01, 53.23it/s, Epoch: 88, Batch: 67,Loss: -2.915,Avg.Loss: -2.942,LR: 1.92E-05]Training epoch 88:  44%|████▍     | 67/153 [00:01<00:01, 53.23it/s, Epoch: 88, Batch: 68,Loss: -2.662,Avg.Loss: -2.938,LR: 1.92E-05]Training epoch 88:  44%|████▍     | 68/153 [00:01<00:01, 53.23it/s, Epoch: 88, Batch: 69,Loss: -2.557,Avg.Loss: -2.932,LR: 1.92E-05]Training epoch 88:  45%|████▌     | 69/153 [00:01<00:01, 53.23it/s, Epoch: 88, Batch: 70,Loss: -2.492,Avg.Loss: -2.926,LR: 1.92E-05]Training epoch 88:  46%|████▌     | 70/153 [00:01<00:01, 53.23it/s, Epoch: 88, Batch: 71,Loss: -3.098,Avg.Loss: -2.928,LR: 1.91E-05]Training epoch 88:  46%|████▋     | 71/153 [00:01<00:01, 53.23it/s, Epoch: 88, Batch: 72,Loss: -3.174,Avg.Loss: -2.932,LR: 1.91E-05]Training epoch 88:  47%|████▋     | 72/153 [00:01<00:01, 53.19it/s, Epoch: 88, Batch: 72,Loss: -3.174,Avg.Loss: -2.932,LR: 1.91E-05]Training epoch 88:  47%|████▋     | 72/153 [00:01<00:01, 53.19it/s, Epoch: 88, Batch: 73,Loss: -2.494,Avg.Loss: -2.926,LR: 1.91E-05]Training epoch 88:  48%|████▊     | 73/153 [00:01<00:01, 53.19it/s, Epoch: 88, Batch: 74,Loss: -3.461,Avg.Loss: -2.933,LR: 1.91E-05]Training epoch 88:  48%|████▊     | 74/153 [00:01<00:01, 53.19it/s, Epoch: 88, Batch: 75,Loss: -2.991,Avg.Loss: -2.934,LR: 1.91E-05]Training epoch 88:  49%|████▉     | 75/153 [00:01<00:01, 53.19it/s, Epoch: 88, Batch: 76,Loss: -2.670,Avg.Loss: -2.930,LR: 1.90E-05]Training epoch 88:  50%|████▉     | 76/153 [00:01<00:01, 53.19it/s, Epoch: 88, Batch: 77,Loss: -3.150,Avg.Loss: -2.933,LR: 1.90E-05]Training epoch 88:  50%|█████     | 77/153 [00:01<00:01, 53.19it/s, Epoch: 88, Batch: 78,Loss: -2.949,Avg.Loss: -2.933,LR: 1.90E-05]Training epoch 88:  51%|█████     | 78/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 78,Loss: -2.949,Avg.Loss: -2.933,LR: 1.90E-05]Training epoch 88:  51%|█████     | 78/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 79,Loss: -3.233,Avg.Loss: -2.937,LR: 1.90E-05]Training epoch 88:  52%|█████▏    | 79/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 80,Loss: -2.927,Avg.Loss: -2.937,LR: 1.90E-05]Training epoch 88:  52%|█████▏    | 80/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 81,Loss: -2.685,Avg.Loss: -2.934,LR: 1.89E-05]Training epoch 88:  53%|█████▎    | 81/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 82,Loss: -2.733,Avg.Loss: -2.931,LR: 1.89E-05]Training epoch 88:  54%|█████▎    | 82/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 83,Loss: -3.440,Avg.Loss: -2.938,LR: 1.89E-05]Training epoch 88:  54%|█████▍    | 83/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 84,Loss: -3.244,Avg.Loss: -2.941,LR: 1.89E-05]Training epoch 88:  55%|█████▍    | 84/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 84,Loss: -3.244,Avg.Loss: -2.941,LR: 1.89E-05]Training epoch 88:  55%|█████▍    | 84/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 85,Loss: -3.014,Avg.Loss: -2.942,LR: 1.89E-05]Training epoch 88:  56%|█████▌    | 85/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 86,Loss: -2.808,Avg.Loss: -2.941,LR: 1.88E-05]Training epoch 88:  56%|█████▌    | 86/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 87,Loss: -2.784,Avg.Loss: -2.939,LR: 1.88E-05]Training epoch 88:  57%|█████▋    | 87/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 88,Loss: -2.985,Avg.Loss: -2.939,LR: 1.88E-05]Training epoch 88:  58%|█████▊    | 88/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 89,Loss: -3.108,Avg.Loss: -2.941,LR: 1.88E-05]Training epoch 88:  58%|█████▊    | 89/153 [00:01<00:01, 52.95it/s, Epoch: 88, Batch: 90,Loss: -2.872,Avg.Loss: -2.940,LR: 1.88E-05]Training epoch 88:  59%|█████▉    | 90/153 [00:01<00:01, 52.88it/s, Epoch: 88, Batch: 90,Loss: -2.872,Avg.Loss: -2.940,LR: 1.88E-05]Training epoch 88:  59%|█████▉    | 90/153 [00:01<00:01, 52.88it/s, Epoch: 88, Batch: 91,Loss: -2.718,Avg.Loss: -2.938,LR: 1.87E-05]Training epoch 88:  59%|█████▉    | 91/153 [00:01<00:01, 52.88it/s, Epoch: 88, Batch: 92,Loss: -3.071,Avg.Loss: -2.939,LR: 1.87E-05]Training epoch 88:  60%|██████    | 92/153 [00:01<00:01, 52.88it/s, Epoch: 88, Batch: 93,Loss: -3.168,Avg.Loss: -2.942,LR: 1.87E-05]Training epoch 88:  61%|██████    | 93/153 [00:01<00:01, 52.88it/s, Epoch: 88, Batch: 94,Loss: -2.946,Avg.Loss: -2.942,LR: 1.87E-05]Training epoch 88:  61%|██████▏   | 94/153 [00:01<00:01, 52.88it/s, Epoch: 88, Batch: 95,Loss: -3.611,Avg.Loss: -2.949,LR: 1.87E-05]Training epoch 88:  62%|██████▏   | 95/153 [00:01<00:01, 52.88it/s, Epoch: 88, Batch: 96,Loss: -2.994,Avg.Loss: -2.949,LR: 1.86E-05]Training epoch 88:  63%|██████▎   | 96/153 [00:01<00:01, 52.93it/s, Epoch: 88, Batch: 96,Loss: -2.994,Avg.Loss: -2.949,LR: 1.86E-05]Training epoch 88:  63%|██████▎   | 96/153 [00:01<00:01, 52.93it/s, Epoch: 88, Batch: 97,Loss: -3.025,Avg.Loss: -2.950,LR: 1.86E-05]Training epoch 88:  63%|██████▎   | 97/153 [00:01<00:01, 52.93it/s, Epoch: 88, Batch: 98,Loss: -2.666,Avg.Loss: -2.947,LR: 1.86E-05]Training epoch 88:  64%|██████▍   | 98/153 [00:01<00:01, 52.93it/s, Epoch: 88, Batch: 99,Loss: -3.324,Avg.Loss: -2.951,LR: 1.86E-05]Training epoch 88:  65%|██████▍   | 99/153 [00:01<00:01, 52.93it/s, Epoch: 88, Batch: 100,Loss: -2.936,Avg.Loss: -2.951,LR: 1.86E-05]Training epoch 88:  65%|██████▌   | 100/153 [00:01<00:01, 52.93it/s, Epoch: 88, Batch: 101,Loss: -3.118,Avg.Loss: -2.953,LR: 1.86E-05]Training epoch 88:  66%|██████▌   | 101/153 [00:01<00:00, 52.93it/s, Epoch: 88, Batch: 102,Loss: -3.320,Avg.Loss: -2.956,LR: 1.85E-05]Training epoch 88:  67%|██████▋   | 102/153 [00:01<00:00, 52.92it/s, Epoch: 88, Batch: 102,Loss: -3.320,Avg.Loss: -2.956,LR: 1.85E-05]Training epoch 88:  67%|██████▋   | 102/153 [00:01<00:00, 52.92it/s, Epoch: 88, Batch: 103,Loss: -2.979,Avg.Loss: -2.956,LR: 1.85E-05]Training epoch 88:  67%|██████▋   | 103/153 [00:01<00:00, 52.92it/s, Epoch: 88, Batch: 104,Loss: -3.496,Avg.Loss: -2.962,LR: 1.85E-05]Training epoch 88:  68%|██████▊   | 104/153 [00:01<00:00, 52.92it/s, Epoch: 88, Batch: 105,Loss: -3.237,Avg.Loss: -2.964,LR: 1.85E-05]Training epoch 88:  69%|██████▊   | 105/153 [00:02<00:00, 52.92it/s, Epoch: 88, Batch: 106,Loss: -2.937,Avg.Loss: -2.964,LR: 1.85E-05]Training epoch 88:  69%|██████▉   | 106/153 [00:02<00:00, 52.92it/s, Epoch: 88, Batch: 107,Loss: -3.409,Avg.Loss: -2.968,LR: 1.84E-05]Training epoch 88:  70%|██████▉   | 107/153 [00:02<00:00, 52.92it/s, Epoch: 88, Batch: 108,Loss: -3.186,Avg.Loss: -2.970,LR: 1.84E-05]Training epoch 88:  71%|███████   | 108/153 [00:02<00:00, 53.06it/s, Epoch: 88, Batch: 108,Loss: -3.186,Avg.Loss: -2.970,LR: 1.84E-05]Training epoch 88:  71%|███████   | 108/153 [00:02<00:00, 53.06it/s, Epoch: 88, Batch: 109,Loss: -2.732,Avg.Loss: -2.968,LR: 1.84E-05]Training epoch 88:  71%|███████   | 109/153 [00:02<00:00, 53.06it/s, Epoch: 88, Batch: 110,Loss: -2.948,Avg.Loss: -2.968,LR: 1.84E-05]Training epoch 88:  72%|███████▏  | 110/153 [00:02<00:00, 53.06it/s, Epoch: 88, Batch: 111,Loss: -2.741,Avg.Loss: -2.966,LR: 1.84E-05]Training epoch 88:  73%|███████▎  | 111/153 [00:02<00:00, 53.06it/s, Epoch: 88, Batch: 112,Loss: -3.255,Avg.Loss: -2.968,LR: 1.83E-05]Training epoch 88:  73%|███████▎  | 112/153 [00:02<00:00, 53.06it/s, Epoch: 88, Batch: 113,Loss: -3.023,Avg.Loss: -2.969,LR: 1.83E-05]Training epoch 88:  74%|███████▍  | 113/153 [00:02<00:00, 53.06it/s, Epoch: 88, Batch: 114,Loss: -2.896,Avg.Loss: -2.968,LR: 1.83E-05]Training epoch 88:  75%|███████▍  | 114/153 [00:02<00:00, 53.09it/s, Epoch: 88, Batch: 114,Loss: -2.896,Avg.Loss: -2.968,LR: 1.83E-05]Training epoch 88:  75%|███████▍  | 114/153 [00:02<00:00, 53.09it/s, Epoch: 88, Batch: 115,Loss: -3.468,Avg.Loss: -2.973,LR: 1.83E-05]Training epoch 88:  75%|███████▌  | 115/153 [00:02<00:00, 53.09it/s, Epoch: 88, Batch: 116,Loss: -2.754,Avg.Loss: -2.971,LR: 1.83E-05]Training epoch 88:  76%|███████▌  | 116/153 [00:02<00:00, 53.09it/s, Epoch: 88, Batch: 117,Loss: -2.931,Avg.Loss: -2.970,LR: 1.82E-05]Training epoch 88:  76%|███████▋  | 117/153 [00:02<00:00, 53.09it/s, Epoch: 88, Batch: 118,Loss: -3.448,Avg.Loss: -2.974,LR: 1.82E-05]Training epoch 88:  77%|███████▋  | 118/153 [00:02<00:00, 53.09it/s, Epoch: 88, Batch: 119,Loss: -3.125,Avg.Loss: -2.976,LR: 1.82E-05]Training epoch 88:  78%|███████▊  | 119/153 [00:02<00:00, 53.09it/s, Epoch: 88, Batch: 120,Loss: -3.337,Avg.Loss: -2.979,LR: 1.82E-05]Training epoch 88:  78%|███████▊  | 120/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 120,Loss: -3.337,Avg.Loss: -2.979,LR: 1.82E-05]Training epoch 88:  78%|███████▊  | 120/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 121,Loss: -2.835,Avg.Loss: -2.977,LR: 1.82E-05]Training epoch 88:  79%|███████▉  | 121/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 122,Loss: -3.336,Avg.Loss: -2.980,LR: 1.81E-05]Training epoch 88:  80%|███████▉  | 122/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 123,Loss: -3.156,Avg.Loss: -2.982,LR: 1.81E-05]Training epoch 88:  80%|████████  | 123/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 124,Loss: -3.056,Avg.Loss: -2.982,LR: 1.81E-05]Training epoch 88:  81%|████████  | 124/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 125,Loss: -3.455,Avg.Loss: -2.986,LR: 1.81E-05]Training epoch 88:  82%|████████▏ | 125/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 126,Loss: -2.568,Avg.Loss: -2.983,LR: 1.81E-05]Training epoch 88:  82%|████████▏ | 126/153 [00:02<00:00, 53.13it/s, Epoch: 88, Batch: 126,Loss: -2.568,Avg.Loss: -2.983,LR: 1.81E-05]Training epoch 88:  82%|████████▏ | 126/153 [00:02<00:00, 53.13it/s, Epoch: 88, Batch: 127,Loss: -3.034,Avg.Loss: -2.983,LR: 1.81E-05]Training epoch 88:  83%|████████▎ | 127/153 [00:02<00:00, 53.13it/s, Epoch: 88, Batch: 128,Loss: -2.879,Avg.Loss: -2.982,LR: 1.80E-05]Training epoch 88:  84%|████████▎ | 128/153 [00:02<00:00, 53.13it/s, Epoch: 88, Batch: 129,Loss: -2.869,Avg.Loss: -2.982,LR: 1.80E-05]Training epoch 88:  84%|████████▍ | 129/153 [00:02<00:00, 53.13it/s, Epoch: 88, Batch: 130,Loss: -3.003,Avg.Loss: -2.982,LR: 1.80E-05]Training epoch 88:  85%|████████▍ | 130/153 [00:02<00:00, 53.13it/s, Epoch: 88, Batch: 131,Loss: -3.221,Avg.Loss: -2.984,LR: 1.80E-05]Training epoch 88:  86%|████████▌ | 131/153 [00:02<00:00, 53.13it/s, Epoch: 88, Batch: 132,Loss: -3.019,Avg.Loss: -2.984,LR: 1.80E-05]Training epoch 88:  86%|████████▋ | 132/153 [00:02<00:00, 52.88it/s, Epoch: 88, Batch: 132,Loss: -3.019,Avg.Loss: -2.984,LR: 1.80E-05]Training epoch 88:  86%|████████▋ | 132/153 [00:02<00:00, 52.88it/s, Epoch: 88, Batch: 133,Loss: -3.197,Avg.Loss: -2.985,LR: 1.79E-05]Training epoch 88:  87%|████████▋ | 133/153 [00:02<00:00, 52.88it/s, Epoch: 88, Batch: 134,Loss: -3.087,Avg.Loss: -2.986,LR: 1.79E-05]Training epoch 88:  88%|████████▊ | 134/153 [00:02<00:00, 52.88it/s, Epoch: 88, Batch: 135,Loss: -3.033,Avg.Loss: -2.987,LR: 1.79E-05]Training epoch 88:  88%|████████▊ | 135/153 [00:02<00:00, 52.88it/s, Epoch: 88, Batch: 136,Loss: -2.963,Avg.Loss: -2.986,LR: 1.79E-05]Training epoch 88:  89%|████████▉ | 136/153 [00:02<00:00, 52.88it/s, Epoch: 88, Batch: 137,Loss: -3.149,Avg.Loss: -2.988,LR: 1.79E-05]Training epoch 88:  90%|████████▉ | 137/153 [00:02<00:00, 52.88it/s, Epoch: 88, Batch: 138,Loss: -3.485,Avg.Loss: -2.991,LR: 1.78E-05]Training epoch 88:  90%|█████████ | 138/153 [00:02<00:00, 52.89it/s, Epoch: 88, Batch: 138,Loss: -3.485,Avg.Loss: -2.991,LR: 1.78E-05]Training epoch 88:  90%|█████████ | 138/153 [00:02<00:00, 52.89it/s, Epoch: 88, Batch: 139,Loss: -2.736,Avg.Loss: -2.989,LR: 1.78E-05]Training epoch 88:  91%|█████████ | 139/153 [00:02<00:00, 52.89it/s, Epoch: 88, Batch: 140,Loss: -3.124,Avg.Loss: -2.990,LR: 1.78E-05]Training epoch 88:  92%|█████████▏| 140/153 [00:02<00:00, 52.89it/s, Epoch: 88, Batch: 141,Loss: -3.201,Avg.Loss: -2.992,LR: 1.78E-05]Training epoch 88:  92%|█████████▏| 141/153 [00:02<00:00, 52.89it/s, Epoch: 88, Batch: 142,Loss: -3.051,Avg.Loss: -2.992,LR: 1.78E-05]Training epoch 88:  93%|█████████▎| 142/153 [00:02<00:00, 52.89it/s, Epoch: 88, Batch: 143,Loss: -3.067,Avg.Loss: -2.993,LR: 1.77E-05]Training epoch 88:  93%|█████████▎| 143/153 [00:02<00:00, 52.89it/s, Epoch: 88, Batch: 144,Loss: -3.236,Avg.Loss: -2.994,LR: 1.77E-05]Training epoch 88:  94%|█████████▍| 144/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 144,Loss: -3.236,Avg.Loss: -2.994,LR: 1.77E-05]Training epoch 88:  94%|█████████▍| 144/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 145,Loss: -2.676,Avg.Loss: -2.992,LR: 1.77E-05]Training epoch 88:  95%|█████████▍| 145/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 146,Loss: -2.823,Avg.Loss: -2.991,LR: 1.77E-05]Training epoch 88:  95%|█████████▌| 146/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 147,Loss: -2.464,Avg.Loss: -2.987,LR: 1.77E-05]Training epoch 88:  96%|█████████▌| 147/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 148,Loss: -3.004,Avg.Loss: -2.988,LR: 1.77E-05]Training epoch 88:  97%|█████████▋| 148/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 149,Loss: -3.335,Avg.Loss: -2.990,LR: 1.76E-05]Training epoch 88:  97%|█████████▋| 149/153 [00:02<00:00, 53.04it/s, Epoch: 88, Batch: 150,Loss: -3.262,Avg.Loss: -2.992,LR: 1.76E-05]Training epoch 88:  98%|█████████▊| 150/153 [00:02<00:00, 52.76it/s, Epoch: 88, Batch: 150,Loss: -3.262,Avg.Loss: -2.992,LR: 1.76E-05]Training epoch 88:  98%|█████████▊| 150/153 [00:02<00:00, 52.76it/s, Epoch: 88, Batch: 151,Loss: -2.954,Avg.Loss: -2.991,LR: 1.76E-05]Training epoch 88:  99%|█████████▊| 151/153 [00:02<00:00, 52.76it/s, Epoch: 88, Batch: 152,Loss: -3.232,Avg.Loss: -2.993,LR: 1.76E-05]Training epoch 88:  99%|█████████▉| 152/153 [00:02<00:00, 52.76it/s, Epoch: 88, Batch: 153,Loss: -2.954,Avg.Loss: -2.993,LR: 1.76E-05]Training epoch 88: 100%|██████████| 153/153 [00:02<00:00, 52.72it/s, Epoch: 88, Batch: 153,Loss: -2.954,Avg.Loss: -2.993,LR: 1.76E-05]
Training epoch 89:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 89:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 89, Batch: 1,Loss: -2.719,Avg.Loss: -2.719,LR: 1.75E-05]Training epoch 89:   1%|          | 1/153 [00:00<00:05, 29.09it/s, Epoch: 89, Batch: 2,Loss: -3.100,Avg.Loss: -2.910,LR: 1.75E-05]Training epoch 89:   1%|▏         | 2/153 [00:00<00:03, 40.30it/s, Epoch: 89, Batch: 3,Loss: -2.903,Avg.Loss: -2.907,LR: 1.75E-05]Training epoch 89:   2%|▏         | 3/153 [00:00<00:03, 45.42it/s, Epoch: 89, Batch: 4,Loss: -2.917,Avg.Loss: -2.910,LR: 1.75E-05]Training epoch 89:   3%|▎         | 4/153 [00:00<00:03, 47.75it/s, Epoch: 89, Batch: 5,Loss: -2.447,Avg.Loss: -2.817,LR: 1.75E-05]Training epoch 89:   3%|▎         | 5/153 [00:00<00:03, 48.46it/s, Epoch: 89, Batch: 6,Loss: -2.707,Avg.Loss: -2.799,LR: 1.74E-05]Training epoch 89:   4%|▍         | 6/153 [00:00<00:02, 58.04it/s, Epoch: 89, Batch: 6,Loss: -2.707,Avg.Loss: -2.799,LR: 1.74E-05]Training epoch 89:   4%|▍         | 6/153 [00:00<00:02, 58.04it/s, Epoch: 89, Batch: 7,Loss: -2.692,Avg.Loss: -2.784,LR: 1.74E-05]Training epoch 89:   5%|▍         | 7/153 [00:00<00:02, 58.04it/s, Epoch: 89, Batch: 8,Loss: -2.841,Avg.Loss: -2.791,LR: 1.74E-05]Training epoch 89:   5%|▌         | 8/153 [00:00<00:02, 58.04it/s, Epoch: 89, Batch: 9,Loss: -3.231,Avg.Loss: -2.840,LR: 1.74E-05]Training epoch 89:   6%|▌         | 9/153 [00:00<00:02, 58.04it/s, Epoch: 89, Batch: 10,Loss: -2.718,Avg.Loss: -2.828,LR: 1.74E-05]Training epoch 89:   7%|▋         | 10/153 [00:00<00:02, 58.04it/s, Epoch: 89, Batch: 11,Loss: -3.023,Avg.Loss: -2.845,LR: 1.73E-05]Training epoch 89:   7%|▋         | 11/153 [00:00<00:02, 58.04it/s, Epoch: 89, Batch: 12,Loss: -2.614,Avg.Loss: -2.826,LR: 1.73E-05]Training epoch 89:   8%|▊         | 12/153 [00:00<00:02, 54.48it/s, Epoch: 89, Batch: 12,Loss: -2.614,Avg.Loss: -2.826,LR: 1.73E-05]Training epoch 89:   8%|▊         | 12/153 [00:00<00:02, 54.48it/s, Epoch: 89, Batch: 13,Loss: -2.772,Avg.Loss: -2.822,LR: 1.73E-05]Training epoch 89:   8%|▊         | 13/153 [00:00<00:02, 54.48it/s, Epoch: 89, Batch: 14,Loss: -3.049,Avg.Loss: -2.838,LR: 1.73E-05]Training epoch 89:   9%|▉         | 14/153 [00:00<00:02, 54.48it/s, Epoch: 89, Batch: 15,Loss: -2.929,Avg.Loss: -2.844,LR: 1.73E-05]Training epoch 89:  10%|▉         | 15/153 [00:00<00:02, 54.48it/s, Epoch: 89, Batch: 16,Loss: -2.918,Avg.Loss: -2.849,LR: 1.73E-05]Training epoch 89:  10%|█         | 16/153 [00:00<00:02, 54.48it/s, Epoch: 89, Batch: 17,Loss: -3.013,Avg.Loss: -2.858,LR: 1.72E-05]Training epoch 89:  11%|█         | 17/153 [00:00<00:02, 54.48it/s, Epoch: 89, Batch: 18,Loss: -2.360,Avg.Loss: -2.831,LR: 1.72E-05]Training epoch 89:  12%|█▏        | 18/153 [00:00<00:02, 53.48it/s, Epoch: 89, Batch: 18,Loss: -2.360,Avg.Loss: -2.831,LR: 1.72E-05]Training epoch 89:  12%|█▏        | 18/153 [00:00<00:02, 53.48it/s, Epoch: 89, Batch: 19,Loss: -3.018,Avg.Loss: -2.841,LR: 1.72E-05]Training epoch 89:  12%|█▏        | 19/153 [00:00<00:02, 53.48it/s, Epoch: 89, Batch: 20,Loss: -3.267,Avg.Loss: -2.862,LR: 1.72E-05]Training epoch 89:  13%|█▎        | 20/153 [00:00<00:02, 53.48it/s, Epoch: 89, Batch: 21,Loss: -2.955,Avg.Loss: -2.866,LR: 1.72E-05]Training epoch 89:  14%|█▎        | 21/153 [00:00<00:02, 53.48it/s, Epoch: 89, Batch: 22,Loss: -3.173,Avg.Loss: -2.880,LR: 1.71E-05]Training epoch 89:  14%|█▍        | 22/153 [00:00<00:02, 53.48it/s, Epoch: 89, Batch: 23,Loss: -3.052,Avg.Loss: -2.888,LR: 1.71E-05]Training epoch 89:  15%|█▌        | 23/153 [00:00<00:02, 53.48it/s, Epoch: 89, Batch: 24,Loss: -2.784,Avg.Loss: -2.883,LR: 1.71E-05]Training epoch 89:  16%|█▌        | 24/153 [00:00<00:02, 52.19it/s, Epoch: 89, Batch: 24,Loss: -2.784,Avg.Loss: -2.883,LR: 1.71E-05]Training epoch 89:  16%|█▌        | 24/153 [00:00<00:02, 52.19it/s, Epoch: 89, Batch: 25,Loss: -3.086,Avg.Loss: -2.891,LR: 1.71E-05]Training epoch 89:  16%|█▋        | 25/153 [00:00<00:02, 52.19it/s, Epoch: 89, Batch: 26,Loss: -2.603,Avg.Loss: -2.880,LR: 1.71E-05]Training epoch 89:  17%|█▋        | 26/153 [00:00<00:02, 52.19it/s, Epoch: 89, Batch: 27,Loss: -3.141,Avg.Loss: -2.890,LR: 1.70E-05]Training epoch 89:  18%|█▊        | 27/153 [00:00<00:02, 52.19it/s, Epoch: 89, Batch: 28,Loss: -2.945,Avg.Loss: -2.892,LR: 1.70E-05]Training epoch 89:  18%|█▊        | 28/153 [00:00<00:02, 52.19it/s, Epoch: 89, Batch: 29,Loss: -2.867,Avg.Loss: -2.891,LR: 1.70E-05]Training epoch 89:  19%|█▉        | 29/153 [00:00<00:02, 52.19it/s, Epoch: 89, Batch: 30,Loss: -2.838,Avg.Loss: -2.889,LR: 1.70E-05]Training epoch 89:  20%|█▉        | 30/153 [00:00<00:02, 52.07it/s, Epoch: 89, Batch: 30,Loss: -2.838,Avg.Loss: -2.889,LR: 1.70E-05]Training epoch 89:  20%|█▉        | 30/153 [00:00<00:02, 52.07it/s, Epoch: 89, Batch: 31,Loss: -3.256,Avg.Loss: -2.901,LR: 1.70E-05]Training epoch 89:  20%|██        | 31/153 [00:00<00:02, 52.07it/s, Epoch: 89, Batch: 32,Loss: -3.298,Avg.Loss: -2.914,LR: 1.70E-05]Training epoch 89:  21%|██        | 32/153 [00:00<00:02, 52.07it/s, Epoch: 89, Batch: 33,Loss: -2.987,Avg.Loss: -2.916,LR: 1.69E-05]Training epoch 89:  22%|██▏       | 33/153 [00:00<00:02, 52.07it/s, Epoch: 89, Batch: 34,Loss: -3.461,Avg.Loss: -2.932,LR: 1.69E-05]Training epoch 89:  22%|██▏       | 34/153 [00:00<00:02, 52.07it/s, Epoch: 89, Batch: 35,Loss: -2.759,Avg.Loss: -2.927,LR: 1.69E-05]Training epoch 89:  23%|██▎       | 35/153 [00:00<00:02, 52.07it/s, Epoch: 89, Batch: 36,Loss: -3.325,Avg.Loss: -2.938,LR: 1.69E-05]Training epoch 89:  24%|██▎       | 36/153 [00:00<00:02, 52.33it/s, Epoch: 89, Batch: 36,Loss: -3.325,Avg.Loss: -2.938,LR: 1.69E-05]Training epoch 89:  24%|██▎       | 36/153 [00:00<00:02, 52.33it/s, Epoch: 89, Batch: 37,Loss: -2.819,Avg.Loss: -2.935,LR: 1.69E-05]Training epoch 89:  24%|██▍       | 37/153 [00:00<00:02, 52.33it/s, Epoch: 89, Batch: 38,Loss: -2.998,Avg.Loss: -2.936,LR: 1.68E-05]Training epoch 89:  25%|██▍       | 38/153 [00:00<00:02, 52.33it/s, Epoch: 89, Batch: 39,Loss: -3.523,Avg.Loss: -2.951,LR: 1.68E-05]Training epoch 89:  25%|██▌       | 39/153 [00:00<00:02, 52.33it/s, Epoch: 89, Batch: 40,Loss: -2.463,Avg.Loss: -2.939,LR: 1.68E-05]Training epoch 89:  26%|██▌       | 40/153 [00:00<00:02, 52.33it/s, Epoch: 89, Batch: 41,Loss: -3.210,Avg.Loss: -2.946,LR: 1.68E-05]Training epoch 89:  27%|██▋       | 41/153 [00:00<00:02, 52.33it/s, Epoch: 89, Batch: 42,Loss: -3.245,Avg.Loss: -2.953,LR: 1.68E-05]Training epoch 89:  27%|██▋       | 42/153 [00:00<00:02, 52.30it/s, Epoch: 89, Batch: 42,Loss: -3.245,Avg.Loss: -2.953,LR: 1.68E-05]Training epoch 89:  27%|██▋       | 42/153 [00:00<00:02, 52.30it/s, Epoch: 89, Batch: 43,Loss: -3.036,Avg.Loss: -2.955,LR: 1.68E-05]Training epoch 89:  28%|██▊       | 43/153 [00:00<00:02, 52.30it/s, Epoch: 89, Batch: 44,Loss: -3.067,Avg.Loss: -2.957,LR: 1.67E-05]Training epoch 89:  29%|██▉       | 44/153 [00:00<00:02, 52.30it/s, Epoch: 89, Batch: 45,Loss: -2.744,Avg.Loss: -2.953,LR: 1.67E-05]Training epoch 89:  29%|██▉       | 45/153 [00:00<00:02, 52.30it/s, Epoch: 89, Batch: 46,Loss: -2.920,Avg.Loss: -2.952,LR: 1.67E-05]Training epoch 89:  30%|███       | 46/153 [00:00<00:02, 52.30it/s, Epoch: 89, Batch: 47,Loss: -3.118,Avg.Loss: -2.956,LR: 1.67E-05]Training epoch 89:  31%|███       | 47/153 [00:00<00:02, 52.30it/s, Epoch: 89, Batch: 48,Loss: -3.034,Avg.Loss: -2.957,LR: 1.67E-05]Training epoch 89:  31%|███▏      | 48/153 [00:00<00:02, 52.43it/s, Epoch: 89, Batch: 48,Loss: -3.034,Avg.Loss: -2.957,LR: 1.67E-05]Training epoch 89:  31%|███▏      | 48/153 [00:00<00:02, 52.43it/s, Epoch: 89, Batch: 49,Loss: -3.370,Avg.Loss: -2.966,LR: 1.66E-05]Training epoch 89:  32%|███▏      | 49/153 [00:00<00:01, 52.43it/s, Epoch: 89, Batch: 50,Loss: -3.234,Avg.Loss: -2.971,LR: 1.66E-05]Training epoch 89:  33%|███▎      | 50/153 [00:00<00:01, 52.43it/s, Epoch: 89, Batch: 51,Loss: -2.977,Avg.Loss: -2.971,LR: 1.66E-05]Training epoch 89:  33%|███▎      | 51/153 [00:00<00:01, 52.43it/s, Epoch: 89, Batch: 52,Loss: -2.901,Avg.Loss: -2.970,LR: 1.66E-05]Training epoch 89:  34%|███▍      | 52/153 [00:01<00:01, 52.43it/s, Epoch: 89, Batch: 53,Loss: -3.203,Avg.Loss: -2.974,LR: 1.66E-05]Training epoch 89:  35%|███▍      | 53/153 [00:01<00:01, 52.43it/s, Epoch: 89, Batch: 54,Loss: -3.076,Avg.Loss: -2.976,LR: 1.65E-05]Training epoch 89:  35%|███▌      | 54/153 [00:01<00:01, 52.61it/s, Epoch: 89, Batch: 54,Loss: -3.076,Avg.Loss: -2.976,LR: 1.65E-05]Training epoch 89:  35%|███▌      | 54/153 [00:01<00:01, 52.61it/s, Epoch: 89, Batch: 55,Loss: -3.171,Avg.Loss: -2.980,LR: 1.65E-05]Training epoch 89:  36%|███▌      | 55/153 [00:01<00:01, 52.61it/s, Epoch: 89, Batch: 56,Loss: -2.398,Avg.Loss: -2.969,LR: 1.65E-05]Training epoch 89:  37%|███▋      | 56/153 [00:01<00:01, 52.61it/s, Epoch: 89, Batch: 57,Loss: -3.505,Avg.Loss: -2.979,LR: 1.65E-05]Training epoch 89:  37%|███▋      | 57/153 [00:01<00:01, 52.61it/s, Epoch: 89, Batch: 58,Loss: -2.677,Avg.Loss: -2.973,LR: 1.65E-05]Training epoch 89:  38%|███▊      | 58/153 [00:01<00:01, 52.61it/s, Epoch: 89, Batch: 59,Loss: -2.494,Avg.Loss: -2.965,LR: 1.65E-05]Training epoch 89:  39%|███▊      | 59/153 [00:01<00:01, 52.61it/s, Epoch: 89, Batch: 60,Loss: -3.239,Avg.Loss: -2.970,LR: 1.64E-05]Training epoch 89:  39%|███▉      | 60/153 [00:01<00:01, 52.83it/s, Epoch: 89, Batch: 60,Loss: -3.239,Avg.Loss: -2.970,LR: 1.64E-05]Training epoch 89:  39%|███▉      | 60/153 [00:01<00:01, 52.83it/s, Epoch: 89, Batch: 61,Loss: -2.773,Avg.Loss: -2.967,LR: 1.64E-05]Training epoch 89:  40%|███▉      | 61/153 [00:01<00:01, 52.83it/s, Epoch: 89, Batch: 62,Loss: -3.189,Avg.Loss: -2.970,LR: 1.64E-05]Training epoch 89:  41%|████      | 62/153 [00:01<00:01, 52.83it/s, Epoch: 89, Batch: 63,Loss: -3.191,Avg.Loss: -2.974,LR: 1.64E-05]Training epoch 89:  41%|████      | 63/153 [00:01<00:01, 52.83it/s, Epoch: 89, Batch: 64,Loss: -2.839,Avg.Loss: -2.972,LR: 1.64E-05]Training epoch 89:  42%|████▏     | 64/153 [00:01<00:01, 52.83it/s, Epoch: 89, Batch: 65,Loss: -3.731,Avg.Loss: -2.983,LR: 1.63E-05]Training epoch 89:  42%|████▏     | 65/153 [00:01<00:01, 52.83it/s, Epoch: 89, Batch: 66,Loss: -3.047,Avg.Loss: -2.984,LR: 1.63E-05]Training epoch 89:  43%|████▎     | 66/153 [00:01<00:01, 52.94it/s, Epoch: 89, Batch: 66,Loss: -3.047,Avg.Loss: -2.984,LR: 1.63E-05]Training epoch 89:  43%|████▎     | 66/153 [00:01<00:01, 52.94it/s, Epoch: 89, Batch: 67,Loss: -3.126,Avg.Loss: -2.986,LR: 1.63E-05]Training epoch 89:  44%|████▍     | 67/153 [00:01<00:01, 52.94it/s, Epoch: 89, Batch: 68,Loss: -3.249,Avg.Loss: -2.990,LR: 1.63E-05]Training epoch 89:  44%|████▍     | 68/153 [00:01<00:01, 52.94it/s, Epoch: 89, Batch: 69,Loss: -3.340,Avg.Loss: -2.995,LR: 1.63E-05]Training epoch 89:  45%|████▌     | 69/153 [00:01<00:01, 52.94it/s, Epoch: 89, Batch: 70,Loss: -3.332,Avg.Loss: -3.000,LR: 1.63E-05]Training epoch 89:  46%|████▌     | 70/153 [00:01<00:01, 52.94it/s, Epoch: 89, Batch: 71,Loss: -2.790,Avg.Loss: -2.997,LR: 1.62E-05]Training epoch 89:  46%|████▋     | 71/153 [00:01<00:01, 52.94it/s, Epoch: 89, Batch: 72,Loss: -2.875,Avg.Loss: -2.995,LR: 1.62E-05]Training epoch 89:  47%|████▋     | 72/153 [00:01<00:01, 52.95it/s, Epoch: 89, Batch: 72,Loss: -2.875,Avg.Loss: -2.995,LR: 1.62E-05]Training epoch 89:  47%|████▋     | 72/153 [00:01<00:01, 52.95it/s, Epoch: 89, Batch: 73,Loss: -3.141,Avg.Loss: -2.997,LR: 1.62E-05]Training epoch 89:  48%|████▊     | 73/153 [00:01<00:01, 52.95it/s, Epoch: 89, Batch: 74,Loss: -3.231,Avg.Loss: -3.001,LR: 1.62E-05]Training epoch 89:  48%|████▊     | 74/153 [00:01<00:01, 52.95it/s, Epoch: 89, Batch: 75,Loss: -3.441,Avg.Loss: -3.006,LR: 1.62E-05]Training epoch 89:  49%|████▉     | 75/153 [00:01<00:01, 52.95it/s, Epoch: 89, Batch: 76,Loss: -3.243,Avg.Loss: -3.010,LR: 1.61E-05]Training epoch 89:  50%|████▉     | 76/153 [00:01<00:01, 52.95it/s, Epoch: 89, Batch: 77,Loss: -2.955,Avg.Loss: -3.009,LR: 1.61E-05]Training epoch 89:  50%|█████     | 77/153 [00:01<00:01, 52.95it/s, Epoch: 89, Batch: 78,Loss: -3.088,Avg.Loss: -3.010,LR: 1.61E-05]Training epoch 89:  51%|█████     | 78/153 [00:01<00:01, 53.00it/s, Epoch: 89, Batch: 78,Loss: -3.088,Avg.Loss: -3.010,LR: 1.61E-05]Training epoch 89:  51%|█████     | 78/153 [00:01<00:01, 53.00it/s, Epoch: 89, Batch: 79,Loss: -2.864,Avg.Loss: -3.008,LR: 1.61E-05]Training epoch 89:  52%|█████▏    | 79/153 [00:01<00:01, 53.00it/s, Epoch: 89, Batch: 80,Loss: -2.605,Avg.Loss: -3.003,LR: 1.61E-05]Training epoch 89:  52%|█████▏    | 80/153 [00:01<00:01, 53.00it/s, Epoch: 89, Batch: 81,Loss: -2.476,Avg.Loss: -2.996,LR: 1.61E-05]Training epoch 89:  53%|█████▎    | 81/153 [00:01<00:01, 53.00it/s, Epoch: 89, Batch: 82,Loss: -3.447,Avg.Loss: -3.002,LR: 1.60E-05]Training epoch 89:  54%|█████▎    | 82/153 [00:01<00:01, 53.00it/s, Epoch: 89, Batch: 83,Loss: -2.552,Avg.Loss: -2.997,LR: 1.60E-05]Training epoch 89:  54%|█████▍    | 83/153 [00:01<00:01, 53.00it/s, Epoch: 89, Batch: 84,Loss: -2.771,Avg.Loss: -2.994,LR: 1.60E-05]Training epoch 89:  55%|█████▍    | 84/153 [00:01<00:01, 53.02it/s, Epoch: 89, Batch: 84,Loss: -2.771,Avg.Loss: -2.994,LR: 1.60E-05]Training epoch 89:  55%|█████▍    | 84/153 [00:01<00:01, 53.02it/s, Epoch: 89, Batch: 85,Loss: -3.003,Avg.Loss: -2.994,LR: 1.60E-05]Training epoch 89:  56%|█████▌    | 85/153 [00:01<00:01, 53.02it/s, Epoch: 89, Batch: 86,Loss: -3.002,Avg.Loss: -2.994,LR: 1.60E-05]Training epoch 89:  56%|█████▌    | 86/153 [00:01<00:01, 53.02it/s, Epoch: 89, Batch: 87,Loss: -2.032,Avg.Loss: -2.983,LR: 1.59E-05]Training epoch 89:  57%|█████▋    | 87/153 [00:01<00:01, 53.02it/s, Epoch: 89, Batch: 88,Loss: -2.467,Avg.Loss: -2.977,LR: 1.59E-05]Training epoch 89:  58%|█████▊    | 88/153 [00:01<00:01, 53.02it/s, Epoch: 89, Batch: 89,Loss: -3.098,Avg.Loss: -2.978,LR: 1.59E-05]Training epoch 89:  58%|█████▊    | 89/153 [00:01<00:01, 53.02it/s, Epoch: 89, Batch: 90,Loss: -3.181,Avg.Loss: -2.981,LR: 1.59E-05]Training epoch 89:  59%|█████▉    | 90/153 [00:01<00:01, 52.74it/s, Epoch: 89, Batch: 90,Loss: -3.181,Avg.Loss: -2.981,LR: 1.59E-05]Training epoch 89:  59%|█████▉    | 90/153 [00:01<00:01, 52.74it/s, Epoch: 89, Batch: 91,Loss: -3.338,Avg.Loss: -2.985,LR: 1.59E-05]Training epoch 89:  59%|█████▉    | 91/153 [00:01<00:01, 52.74it/s, Epoch: 89, Batch: 92,Loss: -3.576,Avg.Loss: -2.991,LR: 1.59E-05]Training epoch 89:  60%|██████    | 92/153 [00:01<00:01, 52.74it/s, Epoch: 89, Batch: 93,Loss: -3.447,Avg.Loss: -2.996,LR: 1.58E-05]Training epoch 89:  61%|██████    | 93/153 [00:01<00:01, 52.74it/s, Epoch: 89, Batch: 94,Loss: -3.174,Avg.Loss: -2.998,LR: 1.58E-05]Training epoch 89:  61%|██████▏   | 94/153 [00:01<00:01, 52.74it/s, Epoch: 89, Batch: 95,Loss: -2.744,Avg.Loss: -2.995,LR: 1.58E-05]Training epoch 89:  62%|██████▏   | 95/153 [00:01<00:01, 52.74it/s, Epoch: 89, Batch: 96,Loss: -2.774,Avg.Loss: -2.993,LR: 1.58E-05]Training epoch 89:  63%|██████▎   | 96/153 [00:01<00:01, 52.82it/s, Epoch: 89, Batch: 96,Loss: -2.774,Avg.Loss: -2.993,LR: 1.58E-05]Training epoch 89:  63%|██████▎   | 96/153 [00:01<00:01, 52.82it/s, Epoch: 89, Batch: 97,Loss: -3.182,Avg.Loss: -2.995,LR: 1.58E-05]Training epoch 89:  63%|██████▎   | 97/153 [00:01<00:01, 52.82it/s, Epoch: 89, Batch: 98,Loss: -3.243,Avg.Loss: -2.997,LR: 1.58E-05]Training epoch 89:  64%|██████▍   | 98/153 [00:01<00:01, 52.82it/s, Epoch: 89, Batch: 99,Loss: -3.273,Avg.Loss: -3.000,LR: 1.57E-05]Training epoch 89:  65%|██████▍   | 99/153 [00:01<00:01, 52.82it/s, Epoch: 89, Batch: 100,Loss: -3.079,Avg.Loss: -3.001,LR: 1.57E-05]Training epoch 89:  65%|██████▌   | 100/153 [00:01<00:01, 52.82it/s, Epoch: 89, Batch: 101,Loss: -3.464,Avg.Loss: -3.006,LR: 1.57E-05]Training epoch 89:  66%|██████▌   | 101/153 [00:01<00:00, 52.82it/s, Epoch: 89, Batch: 102,Loss: -3.002,Avg.Loss: -3.005,LR: 1.57E-05]Training epoch 89:  67%|██████▋   | 102/153 [00:01<00:00, 52.91it/s, Epoch: 89, Batch: 102,Loss: -3.002,Avg.Loss: -3.005,LR: 1.57E-05]Training epoch 89:  67%|██████▋   | 102/153 [00:01<00:00, 52.91it/s, Epoch: 89, Batch: 103,Loss: -3.311,Avg.Loss: -3.008,LR: 1.57E-05]Training epoch 89:  67%|██████▋   | 103/153 [00:01<00:00, 52.91it/s, Epoch: 89, Batch: 104,Loss: -3.142,Avg.Loss: -3.010,LR: 1.56E-05]Training epoch 89:  68%|██████▊   | 104/153 [00:01<00:00, 52.91it/s, Epoch: 89, Batch: 105,Loss: -2.202,Avg.Loss: -3.002,LR: 1.56E-05]Training epoch 89:  69%|██████▊   | 105/153 [00:02<00:00, 52.91it/s, Epoch: 89, Batch: 106,Loss: -3.463,Avg.Loss: -3.006,LR: 1.56E-05]Training epoch 89:  69%|██████▉   | 106/153 [00:02<00:00, 52.91it/s, Epoch: 89, Batch: 107,Loss: -3.042,Avg.Loss: -3.007,LR: 1.56E-05]Training epoch 89:  70%|██████▉   | 107/153 [00:02<00:00, 52.91it/s, Epoch: 89, Batch: 108,Loss: -3.372,Avg.Loss: -3.010,LR: 1.56E-05]Training epoch 89:  71%|███████   | 108/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 108,Loss: -3.372,Avg.Loss: -3.010,LR: 1.56E-05]Training epoch 89:  71%|███████   | 108/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 109,Loss: -2.788,Avg.Loss: -3.008,LR: 1.56E-05]Training epoch 89:  71%|███████   | 109/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 110,Loss: -3.228,Avg.Loss: -3.010,LR: 1.55E-05]Training epoch 89:  72%|███████▏  | 110/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 111,Loss: -3.059,Avg.Loss: -3.011,LR: 1.55E-05]Training epoch 89:  73%|███████▎  | 111/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 112,Loss: -2.909,Avg.Loss: -3.010,LR: 1.55E-05]Training epoch 89:  73%|███████▎  | 112/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 113,Loss: -2.499,Avg.Loss: -3.005,LR: 1.55E-05]Training epoch 89:  74%|███████▍  | 113/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 114,Loss: -2.583,Avg.Loss: -3.001,LR: 1.55E-05]Training epoch 89:  75%|███████▍  | 114/153 [00:02<00:00, 52.92it/s, Epoch: 89, Batch: 114,Loss: -2.583,Avg.Loss: -3.001,LR: 1.55E-05]Training epoch 89:  75%|███████▍  | 114/153 [00:02<00:00, 52.92it/s, Epoch: 89, Batch: 115,Loss: -2.969,Avg.Loss: -3.001,LR: 1.54E-05]Training epoch 89:  75%|███████▌  | 115/153 [00:02<00:00, 52.92it/s, Epoch: 89, Batch: 116,Loss: -3.355,Avg.Loss: -3.004,LR: 1.54E-05]Training epoch 89:  76%|███████▌  | 116/153 [00:02<00:00, 52.92it/s, Epoch: 89, Batch: 117,Loss: -3.528,Avg.Loss: -3.009,LR: 1.54E-05]Training epoch 89:  76%|███████▋  | 117/153 [00:02<00:00, 52.92it/s, Epoch: 89, Batch: 118,Loss: -3.153,Avg.Loss: -3.010,LR: 1.54E-05]Training epoch 89:  77%|███████▋  | 118/153 [00:02<00:00, 52.92it/s, Epoch: 89, Batch: 119,Loss: -3.315,Avg.Loss: -3.012,LR: 1.54E-05]Training epoch 89:  78%|███████▊  | 119/153 [00:02<00:00, 52.92it/s, Epoch: 89, Batch: 120,Loss: -3.283,Avg.Loss: -3.015,LR: 1.54E-05]Training epoch 89:  78%|███████▊  | 120/153 [00:02<00:00, 52.87it/s, Epoch: 89, Batch: 120,Loss: -3.283,Avg.Loss: -3.015,LR: 1.54E-05]Training epoch 89:  78%|███████▊  | 120/153 [00:02<00:00, 52.87it/s, Epoch: 89, Batch: 121,Loss: -2.939,Avg.Loss: -3.014,LR: 1.53E-05]Training epoch 89:  79%|███████▉  | 121/153 [00:02<00:00, 52.87it/s, Epoch: 89, Batch: 122,Loss: -3.059,Avg.Loss: -3.014,LR: 1.53E-05]Training epoch 89:  80%|███████▉  | 122/153 [00:02<00:00, 52.87it/s, Epoch: 89, Batch: 123,Loss: -3.207,Avg.Loss: -3.016,LR: 1.53E-05]Training epoch 89:  80%|████████  | 123/153 [00:02<00:00, 52.87it/s, Epoch: 89, Batch: 124,Loss: -3.310,Avg.Loss: -3.018,LR: 1.53E-05]Training epoch 89:  81%|████████  | 124/153 [00:02<00:00, 52.87it/s, Epoch: 89, Batch: 125,Loss: -3.409,Avg.Loss: -3.021,LR: 1.53E-05]Training epoch 89:  82%|████████▏ | 125/153 [00:02<00:00, 52.87it/s, Epoch: 89, Batch: 126,Loss: -3.053,Avg.Loss: -3.022,LR: 1.53E-05]Training epoch 89:  82%|████████▏ | 126/153 [00:02<00:00, 52.89it/s, Epoch: 89, Batch: 126,Loss: -3.053,Avg.Loss: -3.022,LR: 1.53E-05]Training epoch 89:  82%|████████▏ | 126/153 [00:02<00:00, 52.89it/s, Epoch: 89, Batch: 127,Loss: -3.438,Avg.Loss: -3.025,LR: 1.52E-05]Training epoch 89:  83%|████████▎ | 127/153 [00:02<00:00, 52.89it/s, Epoch: 89, Batch: 128,Loss: -3.443,Avg.Loss: -3.028,LR: 1.52E-05]Training epoch 89:  84%|████████▎ | 128/153 [00:02<00:00, 52.89it/s, Epoch: 89, Batch: 129,Loss: -3.195,Avg.Loss: -3.030,LR: 1.52E-05]Training epoch 89:  84%|████████▍ | 129/153 [00:02<00:00, 52.89it/s, Epoch: 89, Batch: 130,Loss: -2.862,Avg.Loss: -3.028,LR: 1.52E-05]Training epoch 89:  85%|████████▍ | 130/153 [00:02<00:00, 52.89it/s, Epoch: 89, Batch: 131,Loss: -2.995,Avg.Loss: -3.028,LR: 1.52E-05]Training epoch 89:  86%|████████▌ | 131/153 [00:02<00:00, 52.89it/s, Epoch: 89, Batch: 132,Loss: -2.692,Avg.Loss: -3.025,LR: 1.51E-05]Training epoch 89:  86%|████████▋ | 132/153 [00:02<00:00, 53.06it/s, Epoch: 89, Batch: 132,Loss: -2.692,Avg.Loss: -3.025,LR: 1.51E-05]Training epoch 89:  86%|████████▋ | 132/153 [00:02<00:00, 53.06it/s, Epoch: 89, Batch: 133,Loss: -2.987,Avg.Loss: -3.025,LR: 1.51E-05]Training epoch 89:  87%|████████▋ | 133/153 [00:02<00:00, 53.06it/s, Epoch: 89, Batch: 134,Loss: -3.415,Avg.Loss: -3.028,LR: 1.51E-05]Training epoch 89:  88%|████████▊ | 134/153 [00:02<00:00, 53.06it/s, Epoch: 89, Batch: 135,Loss: -3.349,Avg.Loss: -3.030,LR: 1.51E-05]Training epoch 89:  88%|████████▊ | 135/153 [00:02<00:00, 53.06it/s, Epoch: 89, Batch: 136,Loss: -2.971,Avg.Loss: -3.030,LR: 1.51E-05]Training epoch 89:  89%|████████▉ | 136/153 [00:02<00:00, 53.06it/s, Epoch: 89, Batch: 137,Loss: -3.478,Avg.Loss: -3.033,LR: 1.51E-05]Training epoch 89:  90%|████████▉ | 137/153 [00:02<00:00, 53.06it/s, Epoch: 89, Batch: 138,Loss: -2.628,Avg.Loss: -3.030,LR: 1.50E-05]Training epoch 89:  90%|█████████ | 138/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 138,Loss: -2.628,Avg.Loss: -3.030,LR: 1.50E-05]Training epoch 89:  90%|█████████ | 138/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 139,Loss: -2.716,Avg.Loss: -3.028,LR: 1.50E-05]Training epoch 89:  91%|█████████ | 139/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 140,Loss: -2.913,Avg.Loss: -3.027,LR: 1.50E-05]Training epoch 89:  92%|█████████▏| 140/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 141,Loss: -2.999,Avg.Loss: -3.027,LR: 1.50E-05]Training epoch 89:  92%|█████████▏| 141/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 142,Loss: -3.104,Avg.Loss: -3.028,LR: 1.50E-05]Training epoch 89:  93%|█████████▎| 142/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 143,Loss: -3.015,Avg.Loss: -3.028,LR: 1.50E-05]Training epoch 89:  93%|█████████▎| 143/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 144,Loss: -3.511,Avg.Loss: -3.031,LR: 1.49E-05]Training epoch 89:  94%|█████████▍| 144/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 144,Loss: -3.511,Avg.Loss: -3.031,LR: 1.49E-05]Training epoch 89:  94%|█████████▍| 144/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 145,Loss: -3.269,Avg.Loss: -3.033,LR: 1.49E-05]Training epoch 89:  95%|█████████▍| 145/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 146,Loss: -2.717,Avg.Loss: -3.030,LR: 1.49E-05]Training epoch 89:  95%|█████████▌| 146/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 147,Loss: -2.839,Avg.Loss: -3.029,LR: 1.49E-05]Training epoch 89:  96%|█████████▌| 147/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 148,Loss: -2.861,Avg.Loss: -3.028,LR: 1.49E-05]Training epoch 89:  97%|█████████▋| 148/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 149,Loss: -2.923,Avg.Loss: -3.027,LR: 1.48E-05]Training epoch 89:  97%|█████████▋| 149/153 [00:02<00:00, 53.07it/s, Epoch: 89, Batch: 150,Loss: -2.718,Avg.Loss: -3.025,LR: 1.48E-05]Training epoch 89:  98%|█████████▊| 150/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 150,Loss: -2.718,Avg.Loss: -3.025,LR: 1.48E-05]Training epoch 89:  98%|█████████▊| 150/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 151,Loss: -3.344,Avg.Loss: -3.027,LR: 1.48E-05]Training epoch 89:  99%|█████████▊| 151/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 152,Loss: -2.929,Avg.Loss: -3.027,LR: 1.48E-05]Training epoch 89:  99%|█████████▉| 152/153 [00:02<00:00, 53.03it/s, Epoch: 89, Batch: 153,Loss: -2.654,Avg.Loss: -3.024,LR: 1.48E-05]Training epoch 89: 100%|██████████| 153/153 [00:02<00:00, 52.85it/s, Epoch: 89, Batch: 153,Loss: -2.654,Avg.Loss: -3.024,LR: 1.48E-05]
Training epoch 90:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 90:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 90, Batch: 1,Loss: -2.892,Avg.Loss: -2.892,LR: 1.48E-05]Training epoch 90:   1%|          | 1/153 [00:00<00:05, 28.69it/s, Epoch: 90, Batch: 2,Loss: -2.868,Avg.Loss: -2.880,LR: 1.47E-05]Training epoch 90:   1%|▏         | 2/153 [00:00<00:03, 40.51it/s, Epoch: 90, Batch: 3,Loss: -2.864,Avg.Loss: -2.875,LR: 1.47E-05]Training epoch 90:   2%|▏         | 3/153 [00:00<00:03, 47.47it/s, Epoch: 90, Batch: 4,Loss: -3.078,Avg.Loss: -2.926,LR: 1.47E-05]Training epoch 90:   3%|▎         | 4/153 [00:00<00:03, 49.45it/s, Epoch: 90, Batch: 5,Loss: -2.878,Avg.Loss: -2.916,LR: 1.47E-05]Training epoch 90:   3%|▎         | 5/153 [00:00<00:02, 50.95it/s, Epoch: 90, Batch: 6,Loss: -2.660,Avg.Loss: -2.873,LR: 1.47E-05]Training epoch 90:   4%|▍         | 6/153 [00:00<00:02, 51.21it/s, Epoch: 90, Batch: 7,Loss: -2.792,Avg.Loss: -2.862,LR: 1.47E-05]Training epoch 90:   5%|▍         | 7/153 [00:00<00:02, 59.65it/s, Epoch: 90, Batch: 7,Loss: -2.792,Avg.Loss: -2.862,LR: 1.47E-05]Training epoch 90:   5%|▍         | 7/153 [00:00<00:02, 59.65it/s, Epoch: 90, Batch: 8,Loss: -2.775,Avg.Loss: -2.851,LR: 1.46E-05]Training epoch 90:   5%|▌         | 8/153 [00:00<00:02, 59.65it/s, Epoch: 90, Batch: 9,Loss: -3.352,Avg.Loss: -2.907,LR: 1.46E-05]Training epoch 90:   6%|▌         | 9/153 [00:00<00:02, 59.65it/s, Epoch: 90, Batch: 10,Loss: -2.757,Avg.Loss: -2.892,LR: 1.46E-05]Training epoch 90:   7%|▋         | 10/153 [00:00<00:02, 59.65it/s, Epoch: 90, Batch: 11,Loss: -3.080,Avg.Loss: -2.909,LR: 1.46E-05]Training epoch 90:   7%|▋         | 11/153 [00:00<00:02, 59.65it/s, Epoch: 90, Batch: 12,Loss: -3.342,Avg.Loss: -2.945,LR: 1.46E-05]Training epoch 90:   8%|▊         | 12/153 [00:00<00:02, 59.65it/s, Epoch: 90, Batch: 13,Loss: -2.904,Avg.Loss: -2.942,LR: 1.46E-05]Training epoch 90:   8%|▊         | 13/153 [00:00<00:02, 55.58it/s, Epoch: 90, Batch: 13,Loss: -2.904,Avg.Loss: -2.942,LR: 1.46E-05]Training epoch 90:   8%|▊         | 13/153 [00:00<00:02, 55.58it/s, Epoch: 90, Batch: 14,Loss: -2.511,Avg.Loss: -2.911,LR: 1.45E-05]Training epoch 90:   9%|▉         | 14/153 [00:00<00:02, 55.58it/s, Epoch: 90, Batch: 15,Loss: -2.796,Avg.Loss: -2.903,LR: 1.45E-05]Training epoch 90:  10%|▉         | 15/153 [00:00<00:02, 55.58it/s, Epoch: 90, Batch: 16,Loss: -2.654,Avg.Loss: -2.888,LR: 1.45E-05]Training epoch 90:  10%|█         | 16/153 [00:00<00:02, 55.58it/s, Epoch: 90, Batch: 17,Loss: -3.043,Avg.Loss: -2.897,LR: 1.45E-05]Training epoch 90:  11%|█         | 17/153 [00:00<00:02, 55.58it/s, Epoch: 90, Batch: 18,Loss: -2.634,Avg.Loss: -2.882,LR: 1.45E-05]Training epoch 90:  12%|█▏        | 18/153 [00:00<00:02, 55.58it/s, Epoch: 90, Batch: 19,Loss: -2.796,Avg.Loss: -2.878,LR: 1.45E-05]Training epoch 90:  12%|█▏        | 19/153 [00:00<00:02, 54.26it/s, Epoch: 90, Batch: 19,Loss: -2.796,Avg.Loss: -2.878,LR: 1.45E-05]Training epoch 90:  12%|█▏        | 19/153 [00:00<00:02, 54.26it/s, Epoch: 90, Batch: 20,Loss: -3.166,Avg.Loss: -2.892,LR: 1.44E-05]Training epoch 90:  13%|█▎        | 20/153 [00:00<00:02, 54.26it/s, Epoch: 90, Batch: 21,Loss: -3.115,Avg.Loss: -2.903,LR: 1.44E-05]Training epoch 90:  14%|█▎        | 21/153 [00:00<00:02, 54.26it/s, Epoch: 90, Batch: 22,Loss: -2.620,Avg.Loss: -2.890,LR: 1.44E-05]Training epoch 90:  14%|█▍        | 22/153 [00:00<00:02, 54.26it/s, Epoch: 90, Batch: 23,Loss: -3.375,Avg.Loss: -2.911,LR: 1.44E-05]Training epoch 90:  15%|█▌        | 23/153 [00:00<00:02, 54.26it/s, Epoch: 90, Batch: 24,Loss: -3.272,Avg.Loss: -2.926,LR: 1.44E-05]Training epoch 90:  16%|█▌        | 24/153 [00:00<00:02, 54.26it/s, Epoch: 90, Batch: 25,Loss: -3.243,Avg.Loss: -2.939,LR: 1.43E-05]Training epoch 90:  16%|█▋        | 25/153 [00:00<00:02, 52.70it/s, Epoch: 90, Batch: 25,Loss: -3.243,Avg.Loss: -2.939,LR: 1.43E-05]Training epoch 90:  16%|█▋        | 25/153 [00:00<00:02, 52.70it/s, Epoch: 90, Batch: 26,Loss: -3.152,Avg.Loss: -2.947,LR: 1.43E-05]Training epoch 90:  17%|█▋        | 26/153 [00:00<00:02, 52.70it/s, Epoch: 90, Batch: 27,Loss: -3.391,Avg.Loss: -2.963,LR: 1.43E-05]Training epoch 90:  18%|█▊        | 27/153 [00:00<00:02, 52.70it/s, Epoch: 90, Batch: 28,Loss: -3.266,Avg.Loss: -2.974,LR: 1.43E-05]Training epoch 90:  18%|█▊        | 28/153 [00:00<00:02, 52.70it/s, Epoch: 90, Batch: 29,Loss: -3.092,Avg.Loss: -2.978,LR: 1.43E-05]Training epoch 90:  19%|█▉        | 29/153 [00:00<00:02, 52.70it/s, Epoch: 90, Batch: 30,Loss: -2.824,Avg.Loss: -2.973,LR: 1.43E-05]Training epoch 90:  20%|█▉        | 30/153 [00:00<00:02, 52.70it/s, Epoch: 90, Batch: 31,Loss: -2.966,Avg.Loss: -2.973,LR: 1.42E-05]Training epoch 90:  20%|██        | 31/153 [00:00<00:02, 52.48it/s, Epoch: 90, Batch: 31,Loss: -2.966,Avg.Loss: -2.973,LR: 1.42E-05]Training epoch 90:  20%|██        | 31/153 [00:00<00:02, 52.48it/s, Epoch: 90, Batch: 32,Loss: -3.123,Avg.Loss: -2.977,LR: 1.42E-05]Training epoch 90:  21%|██        | 32/153 [00:00<00:02, 52.48it/s, Epoch: 90, Batch: 33,Loss: -3.021,Avg.Loss: -2.979,LR: 1.42E-05]Training epoch 90:  22%|██▏       | 33/153 [00:00<00:02, 52.48it/s, Epoch: 90, Batch: 34,Loss: -2.851,Avg.Loss: -2.975,LR: 1.42E-05]Training epoch 90:  22%|██▏       | 34/153 [00:00<00:02, 52.48it/s, Epoch: 90, Batch: 35,Loss: -2.406,Avg.Loss: -2.959,LR: 1.42E-05]Training epoch 90:  23%|██▎       | 35/153 [00:00<00:02, 52.48it/s, Epoch: 90, Batch: 36,Loss: -2.816,Avg.Loss: -2.955,LR: 1.42E-05]Training epoch 90:  24%|██▎       | 36/153 [00:00<00:02, 52.48it/s, Epoch: 90, Batch: 37,Loss: -2.718,Avg.Loss: -2.948,LR: 1.41E-05]Training epoch 90:  24%|██▍       | 37/153 [00:00<00:02, 52.57it/s, Epoch: 90, Batch: 37,Loss: -2.718,Avg.Loss: -2.948,LR: 1.41E-05]Training epoch 90:  24%|██▍       | 37/153 [00:00<00:02, 52.57it/s, Epoch: 90, Batch: 38,Loss: -2.568,Avg.Loss: -2.938,LR: 1.41E-05]Training epoch 90:  25%|██▍       | 38/153 [00:00<00:02, 52.57it/s, Epoch: 90, Batch: 39,Loss: -3.259,Avg.Loss: -2.947,LR: 1.41E-05]Training epoch 90:  25%|██▌       | 39/153 [00:00<00:02, 52.57it/s, Epoch: 90, Batch: 40,Loss: -3.017,Avg.Loss: -2.948,LR: 1.41E-05]Training epoch 90:  26%|██▌       | 40/153 [00:00<00:02, 52.57it/s, Epoch: 90, Batch: 41,Loss: -3.247,Avg.Loss: -2.956,LR: 1.41E-05]Training epoch 90:  27%|██▋       | 41/153 [00:00<00:02, 52.57it/s, Epoch: 90, Batch: 42,Loss: -2.573,Avg.Loss: -2.947,LR: 1.41E-05]Training epoch 90:  27%|██▋       | 42/153 [00:00<00:02, 52.57it/s, Epoch: 90, Batch: 43,Loss: -3.468,Avg.Loss: -2.959,LR: 1.40E-05]Training epoch 90:  28%|██▊       | 43/153 [00:00<00:02, 52.81it/s, Epoch: 90, Batch: 43,Loss: -3.468,Avg.Loss: -2.959,LR: 1.40E-05]Training epoch 90:  28%|██▊       | 43/153 [00:00<00:02, 52.81it/s, Epoch: 90, Batch: 44,Loss: -3.168,Avg.Loss: -2.963,LR: 1.40E-05]Training epoch 90:  29%|██▉       | 44/153 [00:00<00:02, 52.81it/s, Epoch: 90, Batch: 45,Loss: -3.020,Avg.Loss: -2.965,LR: 1.40E-05]Training epoch 90:  29%|██▉       | 45/153 [00:00<00:02, 52.81it/s, Epoch: 90, Batch: 46,Loss: -3.065,Avg.Loss: -2.967,LR: 1.40E-05]Training epoch 90:  30%|███       | 46/153 [00:00<00:02, 52.81it/s, Epoch: 90, Batch: 47,Loss: -2.403,Avg.Loss: -2.955,LR: 1.40E-05]Training epoch 90:  31%|███       | 47/153 [00:00<00:02, 52.81it/s, Epoch: 90, Batch: 48,Loss: -3.190,Avg.Loss: -2.960,LR: 1.40E-05]Training epoch 90:  31%|███▏      | 48/153 [00:00<00:01, 52.81it/s, Epoch: 90, Batch: 49,Loss: -2.615,Avg.Loss: -2.953,LR: 1.39E-05]Training epoch 90:  32%|███▏      | 49/153 [00:00<00:01, 52.86it/s, Epoch: 90, Batch: 49,Loss: -2.615,Avg.Loss: -2.953,LR: 1.39E-05]Training epoch 90:  32%|███▏      | 49/153 [00:00<00:01, 52.86it/s, Epoch: 90, Batch: 50,Loss: -2.889,Avg.Loss: -2.951,LR: 1.39E-05]Training epoch 90:  33%|███▎      | 50/153 [00:00<00:01, 52.86it/s, Epoch: 90, Batch: 51,Loss: -3.205,Avg.Loss: -2.956,LR: 1.39E-05]Training epoch 90:  33%|███▎      | 51/153 [00:00<00:01, 52.86it/s, Epoch: 90, Batch: 52,Loss: -3.044,Avg.Loss: -2.958,LR: 1.39E-05]Training epoch 90:  34%|███▍      | 52/153 [00:00<00:01, 52.86it/s, Epoch: 90, Batch: 53,Loss: -3.206,Avg.Loss: -2.963,LR: 1.39E-05]Training epoch 90:  35%|███▍      | 53/153 [00:01<00:01, 52.86it/s, Epoch: 90, Batch: 54,Loss: -2.818,Avg.Loss: -2.960,LR: 1.39E-05]Training epoch 90:  35%|███▌      | 54/153 [00:01<00:01, 52.86it/s, Epoch: 90, Batch: 55,Loss: -3.362,Avg.Loss: -2.967,LR: 1.38E-05]Training epoch 90:  36%|███▌      | 55/153 [00:01<00:01, 53.06it/s, Epoch: 90, Batch: 55,Loss: -3.362,Avg.Loss: -2.967,LR: 1.38E-05]Training epoch 90:  36%|███▌      | 55/153 [00:01<00:01, 53.06it/s, Epoch: 90, Batch: 56,Loss: -3.410,Avg.Loss: -2.975,LR: 1.38E-05]Training epoch 90:  37%|███▋      | 56/153 [00:01<00:01, 53.06it/s, Epoch: 90, Batch: 57,Loss: -2.963,Avg.Loss: -2.975,LR: 1.38E-05]Training epoch 90:  37%|███▋      | 57/153 [00:01<00:01, 53.06it/s, Epoch: 90, Batch: 58,Loss: -3.400,Avg.Loss: -2.982,LR: 1.38E-05]Training epoch 90:  38%|███▊      | 58/153 [00:01<00:01, 53.06it/s, Epoch: 90, Batch: 59,Loss: -3.096,Avg.Loss: -2.984,LR: 1.38E-05]Training epoch 90:  39%|███▊      | 59/153 [00:01<00:01, 53.06it/s, Epoch: 90, Batch: 60,Loss: -2.818,Avg.Loss: -2.982,LR: 1.38E-05]Training epoch 90:  39%|███▉      | 60/153 [00:01<00:01, 53.06it/s, Epoch: 90, Batch: 61,Loss: -3.234,Avg.Loss: -2.986,LR: 1.37E-05]Training epoch 90:  40%|███▉      | 61/153 [00:01<00:01, 53.01it/s, Epoch: 90, Batch: 61,Loss: -3.234,Avg.Loss: -2.986,LR: 1.37E-05]Training epoch 90:  40%|███▉      | 61/153 [00:01<00:01, 53.01it/s, Epoch: 90, Batch: 62,Loss: -3.280,Avg.Loss: -2.991,LR: 1.37E-05]Training epoch 90:  41%|████      | 62/153 [00:01<00:01, 53.01it/s, Epoch: 90, Batch: 63,Loss: -3.481,Avg.Loss: -2.998,LR: 1.37E-05]Training epoch 90:  41%|████      | 63/153 [00:01<00:01, 53.01it/s, Epoch: 90, Batch: 64,Loss: -3.119,Avg.Loss: -3.000,LR: 1.37E-05]Training epoch 90:  42%|████▏     | 64/153 [00:01<00:01, 53.01it/s, Epoch: 90, Batch: 65,Loss: -3.016,Avg.Loss: -3.000,LR: 1.37E-05]Training epoch 90:  42%|████▏     | 65/153 [00:01<00:01, 53.01it/s, Epoch: 90, Batch: 66,Loss: -3.470,Avg.Loss: -3.008,LR: 1.37E-05]Training epoch 90:  43%|████▎     | 66/153 [00:01<00:01, 53.01it/s, Epoch: 90, Batch: 67,Loss: -3.024,Avg.Loss: -3.008,LR: 1.36E-05]Training epoch 90:  44%|████▍     | 67/153 [00:01<00:01, 53.09it/s, Epoch: 90, Batch: 67,Loss: -3.024,Avg.Loss: -3.008,LR: 1.36E-05]Training epoch 90:  44%|████▍     | 67/153 [00:01<00:01, 53.09it/s, Epoch: 90, Batch: 68,Loss: -2.543,Avg.Loss: -3.001,LR: 1.36E-05]Training epoch 90:  44%|████▍     | 68/153 [00:01<00:01, 53.09it/s, Epoch: 90, Batch: 69,Loss: -3.050,Avg.Loss: -3.002,LR: 1.36E-05]Training epoch 90:  45%|████▌     | 69/153 [00:01<00:01, 53.09it/s, Epoch: 90, Batch: 70,Loss: -3.223,Avg.Loss: -3.005,LR: 1.36E-05]Training epoch 90:  46%|████▌     | 70/153 [00:01<00:01, 53.09it/s, Epoch: 90, Batch: 71,Loss: -2.812,Avg.Loss: -3.002,LR: 1.36E-05]Training epoch 90:  46%|████▋     | 71/153 [00:01<00:01, 53.09it/s, Epoch: 90, Batch: 72,Loss: -3.119,Avg.Loss: -3.004,LR: 1.36E-05]Training epoch 90:  47%|████▋     | 72/153 [00:01<00:01, 53.09it/s, Epoch: 90, Batch: 73,Loss: -2.708,Avg.Loss: -3.000,LR: 1.35E-05]Training epoch 90:  48%|████▊     | 73/153 [00:01<00:01, 53.25it/s, Epoch: 90, Batch: 73,Loss: -2.708,Avg.Loss: -3.000,LR: 1.35E-05]Training epoch 90:  48%|████▊     | 73/153 [00:01<00:01, 53.25it/s, Epoch: 90, Batch: 74,Loss: -2.898,Avg.Loss: -2.998,LR: 1.35E-05]Training epoch 90:  48%|████▊     | 74/153 [00:01<00:01, 53.25it/s, Epoch: 90, Batch: 75,Loss: -3.287,Avg.Loss: -3.002,LR: 1.35E-05]Training epoch 90:  49%|████▉     | 75/153 [00:01<00:01, 53.25it/s, Epoch: 90, Batch: 76,Loss: -3.193,Avg.Loss: -3.005,LR: 1.35E-05]Training epoch 90:  50%|████▉     | 76/153 [00:01<00:01, 53.25it/s, Epoch: 90, Batch: 77,Loss: -3.123,Avg.Loss: -3.006,LR: 1.35E-05]Training epoch 90:  50%|█████     | 77/153 [00:01<00:01, 53.25it/s, Epoch: 90, Batch: 78,Loss: -3.275,Avg.Loss: -3.010,LR: 1.35E-05]Training epoch 90:  51%|█████     | 78/153 [00:01<00:01, 53.25it/s, Epoch: 90, Batch: 79,Loss: -3.319,Avg.Loss: -3.014,LR: 1.34E-05]Training epoch 90:  52%|█████▏    | 79/153 [00:01<00:01, 53.28it/s, Epoch: 90, Batch: 79,Loss: -3.319,Avg.Loss: -3.014,LR: 1.34E-05]Training epoch 90:  52%|█████▏    | 79/153 [00:01<00:01, 53.28it/s, Epoch: 90, Batch: 80,Loss: -3.015,Avg.Loss: -3.014,LR: 1.34E-05]Training epoch 90:  52%|█████▏    | 80/153 [00:01<00:01, 53.28it/s, Epoch: 90, Batch: 81,Loss: -2.977,Avg.Loss: -3.013,LR: 1.34E-05]Training epoch 90:  53%|█████▎    | 81/153 [00:01<00:01, 53.28it/s, Epoch: 90, Batch: 82,Loss: -3.298,Avg.Loss: -3.017,LR: 1.34E-05]Training epoch 90:  54%|█████▎    | 82/153 [00:01<00:01, 53.28it/s, Epoch: 90, Batch: 83,Loss: -3.210,Avg.Loss: -3.019,LR: 1.34E-05]Training epoch 90:  54%|█████▍    | 83/153 [00:01<00:01, 53.28it/s, Epoch: 90, Batch: 84,Loss: -3.018,Avg.Loss: -3.019,LR: 1.34E-05]Training epoch 90:  55%|█████▍    | 84/153 [00:01<00:01, 53.28it/s, Epoch: 90, Batch: 85,Loss: -2.920,Avg.Loss: -3.018,LR: 1.33E-05]Training epoch 90:  56%|█████▌    | 85/153 [00:01<00:01, 53.23it/s, Epoch: 90, Batch: 85,Loss: -2.920,Avg.Loss: -3.018,LR: 1.33E-05]Training epoch 90:  56%|█████▌    | 85/153 [00:01<00:01, 53.23it/s, Epoch: 90, Batch: 86,Loss: -3.429,Avg.Loss: -3.023,LR: 1.33E-05]Training epoch 90:  56%|█████▌    | 86/153 [00:01<00:01, 53.23it/s, Epoch: 90, Batch: 87,Loss: -2.709,Avg.Loss: -3.019,LR: 1.33E-05]Training epoch 90:  57%|█████▋    | 87/153 [00:01<00:01, 53.23it/s, Epoch: 90, Batch: 88,Loss: -2.761,Avg.Loss: -3.016,LR: 1.33E-05]Training epoch 90:  58%|█████▊    | 88/153 [00:01<00:01, 53.23it/s, Epoch: 90, Batch: 89,Loss: -2.632,Avg.Loss: -3.012,LR: 1.33E-05]Training epoch 90:  58%|█████▊    | 89/153 [00:01<00:01, 53.23it/s, Epoch: 90, Batch: 90,Loss: -2.784,Avg.Loss: -3.009,LR: 1.33E-05]Training epoch 90:  59%|█████▉    | 90/153 [00:01<00:01, 53.23it/s, Epoch: 90, Batch: 91,Loss: -3.368,Avg.Loss: -3.013,LR: 1.32E-05]Training epoch 90:  59%|█████▉    | 91/153 [00:01<00:01, 53.11it/s, Epoch: 90, Batch: 91,Loss: -3.368,Avg.Loss: -3.013,LR: 1.32E-05]Training epoch 90:  59%|█████▉    | 91/153 [00:01<00:01, 53.11it/s, Epoch: 90, Batch: 92,Loss: -2.884,Avg.Loss: -3.012,LR: 1.32E-05]Training epoch 90:  60%|██████    | 92/153 [00:01<00:01, 53.11it/s, Epoch: 90, Batch: 93,Loss: -2.989,Avg.Loss: -3.011,LR: 1.32E-05]Training epoch 90:  61%|██████    | 93/153 [00:01<00:01, 53.11it/s, Epoch: 90, Batch: 94,Loss: -3.427,Avg.Loss: -3.016,LR: 1.32E-05]Training epoch 90:  61%|██████▏   | 94/153 [00:01<00:01, 53.11it/s, Epoch: 90, Batch: 95,Loss: -3.132,Avg.Loss: -3.017,LR: 1.32E-05]Training epoch 90:  62%|██████▏   | 95/153 [00:01<00:01, 53.11it/s, Epoch: 90, Batch: 96,Loss: -3.232,Avg.Loss: -3.019,LR: 1.32E-05]Training epoch 90:  63%|██████▎   | 96/153 [00:01<00:01, 53.11it/s, Epoch: 90, Batch: 97,Loss: -3.166,Avg.Loss: -3.021,LR: 1.31E-05]Training epoch 90:  63%|██████▎   | 97/153 [00:01<00:01, 52.99it/s, Epoch: 90, Batch: 97,Loss: -3.166,Avg.Loss: -3.021,LR: 1.31E-05]Training epoch 90:  63%|██████▎   | 97/153 [00:01<00:01, 52.99it/s, Epoch: 90, Batch: 98,Loss: -3.121,Avg.Loss: -3.022,LR: 1.31E-05]Training epoch 90:  64%|██████▍   | 98/153 [00:01<00:01, 52.99it/s, Epoch: 90, Batch: 99,Loss: -3.254,Avg.Loss: -3.024,LR: 1.31E-05]Training epoch 90:  65%|██████▍   | 99/153 [00:01<00:01, 52.99it/s, Epoch: 90, Batch: 100,Loss: -2.770,Avg.Loss: -3.022,LR: 1.31E-05]Training epoch 90:  65%|██████▌   | 100/153 [00:01<00:01, 52.99it/s, Epoch: 90, Batch: 101,Loss: -3.247,Avg.Loss: -3.024,LR: 1.31E-05]Training epoch 90:  66%|██████▌   | 101/153 [00:01<00:00, 52.99it/s, Epoch: 90, Batch: 102,Loss: -2.935,Avg.Loss: -3.023,LR: 1.31E-05]Training epoch 90:  67%|██████▋   | 102/153 [00:01<00:00, 52.99it/s, Epoch: 90, Batch: 103,Loss: -3.317,Avg.Loss: -3.026,LR: 1.30E-05]Training epoch 90:  67%|██████▋   | 103/153 [00:01<00:00, 53.00it/s, Epoch: 90, Batch: 103,Loss: -3.317,Avg.Loss: -3.026,LR: 1.30E-05]Training epoch 90:  67%|██████▋   | 103/153 [00:01<00:00, 53.00it/s, Epoch: 90, Batch: 104,Loss: -3.280,Avg.Loss: -3.028,LR: 1.30E-05]Training epoch 90:  68%|██████▊   | 104/153 [00:01<00:00, 53.00it/s, Epoch: 90, Batch: 105,Loss: -3.088,Avg.Loss: -3.029,LR: 1.30E-05]Training epoch 90:  69%|██████▊   | 105/153 [00:01<00:00, 53.00it/s, Epoch: 90, Batch: 106,Loss: -2.558,Avg.Loss: -3.024,LR: 1.30E-05]Training epoch 90:  69%|██████▉   | 106/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 107,Loss: -3.382,Avg.Loss: -3.028,LR: 1.30E-05]Training epoch 90:  70%|██████▉   | 107/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 108,Loss: -3.485,Avg.Loss: -3.032,LR: 1.30E-05]Training epoch 90:  71%|███████   | 108/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 109,Loss: -2.987,Avg.Loss: -3.032,LR: 1.29E-05]Training epoch 90:  71%|███████   | 109/153 [00:02<00:00, 52.95it/s, Epoch: 90, Batch: 109,Loss: -2.987,Avg.Loss: -3.032,LR: 1.29E-05]Training epoch 90:  71%|███████   | 109/153 [00:02<00:00, 52.95it/s, Epoch: 90, Batch: 110,Loss: -2.924,Avg.Loss: -3.031,LR: 1.29E-05]Training epoch 90:  72%|███████▏  | 110/153 [00:02<00:00, 52.95it/s, Epoch: 90, Batch: 111,Loss: -2.517,Avg.Loss: -3.026,LR: 1.29E-05]Training epoch 90:  73%|███████▎  | 111/153 [00:02<00:00, 52.95it/s, Epoch: 90, Batch: 112,Loss: -3.061,Avg.Loss: -3.026,LR: 1.29E-05]Training epoch 90:  73%|███████▎  | 112/153 [00:02<00:00, 52.95it/s, Epoch: 90, Batch: 113,Loss: -3.068,Avg.Loss: -3.027,LR: 1.29E-05]Training epoch 90:  74%|███████▍  | 113/153 [00:02<00:00, 52.95it/s, Epoch: 90, Batch: 114,Loss: -3.131,Avg.Loss: -3.028,LR: 1.29E-05]Training epoch 90:  75%|███████▍  | 114/153 [00:02<00:00, 52.95it/s, Epoch: 90, Batch: 115,Loss: -3.051,Avg.Loss: -3.028,LR: 1.28E-05]Training epoch 90:  75%|███████▌  | 115/153 [00:02<00:00, 53.01it/s, Epoch: 90, Batch: 115,Loss: -3.051,Avg.Loss: -3.028,LR: 1.28E-05]Training epoch 90:  75%|███████▌  | 115/153 [00:02<00:00, 53.01it/s, Epoch: 90, Batch: 116,Loss: -3.476,Avg.Loss: -3.032,LR: 1.28E-05]Training epoch 90:  76%|███████▌  | 116/153 [00:02<00:00, 53.01it/s, Epoch: 90, Batch: 117,Loss: -3.151,Avg.Loss: -3.033,LR: 1.28E-05]Training epoch 90:  76%|███████▋  | 117/153 [00:02<00:00, 53.01it/s, Epoch: 90, Batch: 118,Loss: -2.884,Avg.Loss: -3.031,LR: 1.28E-05]Training epoch 90:  77%|███████▋  | 118/153 [00:02<00:00, 53.01it/s, Epoch: 90, Batch: 119,Loss: -3.050,Avg.Loss: -3.032,LR: 1.28E-05]Training epoch 90:  78%|███████▊  | 119/153 [00:02<00:00, 53.01it/s, Epoch: 90, Batch: 120,Loss: -3.286,Avg.Loss: -3.034,LR: 1.28E-05]Training epoch 90:  78%|███████▊  | 120/153 [00:02<00:00, 53.01it/s, Epoch: 90, Batch: 121,Loss: -3.495,Avg.Loss: -3.038,LR: 1.27E-05]Training epoch 90:  79%|███████▉  | 121/153 [00:02<00:00, 53.06it/s, Epoch: 90, Batch: 121,Loss: -3.495,Avg.Loss: -3.038,LR: 1.27E-05]Training epoch 90:  79%|███████▉  | 121/153 [00:02<00:00, 53.06it/s, Epoch: 90, Batch: 122,Loss: -2.980,Avg.Loss: -3.037,LR: 1.27E-05]Training epoch 90:  80%|███████▉  | 122/153 [00:02<00:00, 53.06it/s, Epoch: 90, Batch: 123,Loss: -2.475,Avg.Loss: -3.032,LR: 1.27E-05]Training epoch 90:  80%|████████  | 123/153 [00:02<00:00, 53.06it/s, Epoch: 90, Batch: 124,Loss: -3.396,Avg.Loss: -3.035,LR: 1.27E-05]Training epoch 90:  81%|████████  | 124/153 [00:02<00:00, 53.06it/s, Epoch: 90, Batch: 125,Loss: -2.667,Avg.Loss: -3.032,LR: 1.27E-05]Training epoch 90:  82%|████████▏ | 125/153 [00:02<00:00, 53.06it/s, Epoch: 90, Batch: 126,Loss: -3.173,Avg.Loss: -3.034,LR: 1.27E-05]Training epoch 90:  82%|████████▏ | 126/153 [00:02<00:00, 53.06it/s, Epoch: 90, Batch: 127,Loss: -2.750,Avg.Loss: -3.031,LR: 1.27E-05]Training epoch 90:  83%|████████▎ | 127/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 127,Loss: -2.750,Avg.Loss: -3.031,LR: 1.27E-05]Training epoch 90:  83%|████████▎ | 127/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 128,Loss: -3.077,Avg.Loss: -3.032,LR: 1.26E-05]Training epoch 90:  84%|████████▎ | 128/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 129,Loss: -2.920,Avg.Loss: -3.031,LR: 1.26E-05]Training epoch 90:  84%|████████▍ | 129/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 130,Loss: -2.820,Avg.Loss: -3.029,LR: 1.26E-05]Training epoch 90:  85%|████████▍ | 130/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 131,Loss: -2.840,Avg.Loss: -3.028,LR: 1.26E-05]Training epoch 90:  86%|████████▌ | 131/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 132,Loss: -2.926,Avg.Loss: -3.027,LR: 1.26E-05]Training epoch 90:  86%|████████▋ | 132/153 [00:02<00:00, 53.00it/s, Epoch: 90, Batch: 133,Loss: -2.932,Avg.Loss: -3.026,LR: 1.26E-05]Training epoch 90:  87%|████████▋ | 133/153 [00:02<00:00, 53.15it/s, Epoch: 90, Batch: 133,Loss: -2.932,Avg.Loss: -3.026,LR: 1.26E-05]Training epoch 90:  87%|████████▋ | 133/153 [00:02<00:00, 53.15it/s, Epoch: 90, Batch: 134,Loss: -3.479,Avg.Loss: -3.030,LR: 1.25E-05]Training epoch 90:  88%|████████▊ | 134/153 [00:02<00:00, 53.15it/s, Epoch: 90, Batch: 135,Loss: -3.083,Avg.Loss: -3.030,LR: 1.25E-05]Training epoch 90:  88%|████████▊ | 135/153 [00:02<00:00, 53.15it/s, Epoch: 90, Batch: 136,Loss: -3.156,Avg.Loss: -3.031,LR: 1.25E-05]Training epoch 90:  89%|████████▉ | 136/153 [00:02<00:00, 53.15it/s, Epoch: 90, Batch: 137,Loss: -3.150,Avg.Loss: -3.032,LR: 1.25E-05]Training epoch 90:  90%|████████▉ | 137/153 [00:02<00:00, 53.15it/s, Epoch: 90, Batch: 138,Loss: -3.171,Avg.Loss: -3.033,LR: 1.25E-05]Training epoch 90:  90%|█████████ | 138/153 [00:02<00:00, 53.15it/s, Epoch: 90, Batch: 139,Loss: -3.185,Avg.Loss: -3.034,LR: 1.25E-05]Training epoch 90:  91%|█████████ | 139/153 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 139,Loss: -3.185,Avg.Loss: -3.034,LR: 1.25E-05]Training epoch 90:  91%|█████████ | 139/153 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 140,Loss: -3.001,Avg.Loss: -3.034,LR: 1.24E-05]Training epoch 90:  92%|█████████▏| 140/153 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 141,Loss: -3.001,Avg.Loss: -3.033,LR: 1.24E-05]Training epoch 90:  92%|█████████▏| 141/153 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 142,Loss: -2.546,Avg.Loss: -3.030,LR: 1.24E-05]Training epoch 90:  93%|█████████▎| 142/153 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 143,Loss: -3.073,Avg.Loss: -3.030,LR: 1.24E-05]Training epoch 90:  93%|█████████▎| 143/153 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 144,Loss: -2.943,Avg.Loss: -3.030,LR: 1.24E-05]Training epoch 90:  94%|█████████▍| 144/153 [00:02<00:00, 53.22it/s, Epoch: 90, Batch: 145,Loss: -3.001,Avg.Loss: -3.030,LR: 1.24E-05]Training epoch 90:  95%|█████████▍| 145/153 [00:02<00:00, 53.40it/s, Epoch: 90, Batch: 145,Loss: -3.001,Avg.Loss: -3.030,LR: 1.24E-05]Training epoch 90:  95%|█████████▍| 145/153 [00:02<00:00, 53.40it/s, Epoch: 90, Batch: 146,Loss: -2.990,Avg.Loss: -3.029,LR: 1.23E-05]Training epoch 90:  95%|█████████▌| 146/153 [00:02<00:00, 53.40it/s, Epoch: 90, Batch: 147,Loss: -3.260,Avg.Loss: -3.031,LR: 1.23E-05]Training epoch 90:  96%|█████████▌| 147/153 [00:02<00:00, 53.40it/s, Epoch: 90, Batch: 148,Loss: -3.402,Avg.Loss: -3.033,LR: 1.23E-05]Training epoch 90:  97%|█████████▋| 148/153 [00:02<00:00, 53.40it/s, Epoch: 90, Batch: 149,Loss: -2.677,Avg.Loss: -3.031,LR: 1.23E-05]Training epoch 90:  97%|█████████▋| 149/153 [00:02<00:00, 53.40it/s, Epoch: 90, Batch: 150,Loss: -3.015,Avg.Loss: -3.031,LR: 1.23E-05]Training epoch 90:  98%|█████████▊| 150/153 [00:02<00:00, 53.40it/s, Epoch: 90, Batch: 151,Loss: -3.277,Avg.Loss: -3.032,LR: 1.23E-05]Training epoch 90:  99%|█████████▊| 151/153 [00:02<00:00, 53.39it/s, Epoch: 90, Batch: 151,Loss: -3.277,Avg.Loss: -3.032,LR: 1.23E-05]Training epoch 90:  99%|█████████▊| 151/153 [00:02<00:00, 53.39it/s, Epoch: 90, Batch: 152,Loss: -3.382,Avg.Loss: -3.035,LR: 1.23E-05]Training epoch 90:  99%|█████████▉| 152/153 [00:02<00:00, 53.39it/s, Epoch: 90, Batch: 153,Loss: -2.395,Avg.Loss: -3.031,LR: 1.22E-05]Training epoch 90: 100%|██████████| 153/153 [00:02<00:00, 53.19it/s, Epoch: 90, Batch: 153,Loss: -2.395,Avg.Loss: -3.031,LR: 1.22E-05]
Training epoch 91:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 91:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 91, Batch: 1,Loss: -2.884,Avg.Loss: -2.884,LR: 1.22E-05]Training epoch 91:   1%|          | 1/153 [00:00<00:05, 25.64it/s, Epoch: 91, Batch: 2,Loss: -2.856,Avg.Loss: -2.870,LR: 1.22E-05]Training epoch 91:   1%|▏         | 2/153 [00:00<00:04, 37.38it/s, Epoch: 91, Batch: 3,Loss: -3.186,Avg.Loss: -2.975,LR: 1.22E-05]Training epoch 91:   2%|▏         | 3/153 [00:00<00:03, 42.47it/s, Epoch: 91, Batch: 4,Loss: -2.957,Avg.Loss: -2.971,LR: 1.22E-05]Training epoch 91:   3%|▎         | 4/153 [00:00<00:03, 46.84it/s, Epoch: 91, Batch: 5,Loss: -3.070,Avg.Loss: -2.991,LR: 1.22E-05]Training epoch 91:   3%|▎         | 5/153 [00:00<00:03, 48.36it/s, Epoch: 91, Batch: 6,Loss: -3.062,Avg.Loss: -3.002,LR: 1.21E-05]Training epoch 91:   4%|▍         | 6/153 [00:00<00:02, 57.92it/s, Epoch: 91, Batch: 6,Loss: -3.062,Avg.Loss: -3.002,LR: 1.21E-05]Training epoch 91:   4%|▍         | 6/153 [00:00<00:02, 57.92it/s, Epoch: 91, Batch: 7,Loss: -3.177,Avg.Loss: -3.027,LR: 1.21E-05]Training epoch 91:   5%|▍         | 7/153 [00:00<00:02, 57.92it/s, Epoch: 91, Batch: 8,Loss: -2.997,Avg.Loss: -3.024,LR: 1.21E-05]Training epoch 91:   5%|▌         | 8/153 [00:00<00:02, 57.92it/s, Epoch: 91, Batch: 9,Loss: -3.351,Avg.Loss: -3.060,LR: 1.21E-05]Training epoch 91:   6%|▌         | 9/153 [00:00<00:02, 57.92it/s, Epoch: 91, Batch: 10,Loss: -3.115,Avg.Loss: -3.065,LR: 1.21E-05]Training epoch 91:   7%|▋         | 10/153 [00:00<00:02, 57.92it/s, Epoch: 91, Batch: 11,Loss: -2.478,Avg.Loss: -3.012,LR: 1.21E-05]Training epoch 91:   7%|▋         | 11/153 [00:00<00:02, 57.92it/s, Epoch: 91, Batch: 12,Loss: -2.551,Avg.Loss: -2.974,LR: 1.20E-05]Training epoch 91:   8%|▊         | 12/153 [00:00<00:02, 54.52it/s, Epoch: 91, Batch: 12,Loss: -2.551,Avg.Loss: -2.974,LR: 1.20E-05]Training epoch 91:   8%|▊         | 12/153 [00:00<00:02, 54.52it/s, Epoch: 91, Batch: 13,Loss: -3.359,Avg.Loss: -3.003,LR: 1.20E-05]Training epoch 91:   8%|▊         | 13/153 [00:00<00:02, 54.52it/s, Epoch: 91, Batch: 14,Loss: -3.179,Avg.Loss: -3.016,LR: 1.20E-05]Training epoch 91:   9%|▉         | 14/153 [00:00<00:02, 54.52it/s, Epoch: 91, Batch: 15,Loss: -3.373,Avg.Loss: -3.040,LR: 1.20E-05]Training epoch 91:  10%|▉         | 15/153 [00:00<00:02, 54.52it/s, Epoch: 91, Batch: 16,Loss: -2.690,Avg.Loss: -3.018,LR: 1.20E-05]Training epoch 91:  10%|█         | 16/153 [00:00<00:02, 54.52it/s, Epoch: 91, Batch: 17,Loss: -3.539,Avg.Loss: -3.048,LR: 1.20E-05]Training epoch 91:  11%|█         | 17/153 [00:00<00:02, 54.52it/s, Epoch: 91, Batch: 18,Loss: -3.203,Avg.Loss: -3.057,LR: 1.20E-05]Training epoch 91:  12%|█▏        | 18/153 [00:00<00:02, 53.58it/s, Epoch: 91, Batch: 18,Loss: -3.203,Avg.Loss: -3.057,LR: 1.20E-05]Training epoch 91:  12%|█▏        | 18/153 [00:00<00:02, 53.58it/s, Epoch: 91, Batch: 19,Loss: -2.311,Avg.Loss: -3.018,LR: 1.19E-05]Training epoch 91:  12%|█▏        | 19/153 [00:00<00:02, 53.58it/s, Epoch: 91, Batch: 20,Loss: -3.216,Avg.Loss: -3.028,LR: 1.19E-05]Training epoch 91:  13%|█▎        | 20/153 [00:00<00:02, 53.58it/s, Epoch: 91, Batch: 21,Loss: -2.560,Avg.Loss: -3.005,LR: 1.19E-05]Training epoch 91:  14%|█▎        | 21/153 [00:00<00:02, 53.58it/s, Epoch: 91, Batch: 22,Loss: -3.180,Avg.Loss: -3.013,LR: 1.19E-05]Training epoch 91:  14%|█▍        | 22/153 [00:00<00:02, 53.58it/s, Epoch: 91, Batch: 23,Loss: -2.787,Avg.Loss: -3.004,LR: 1.19E-05]Training epoch 91:  15%|█▌        | 23/153 [00:00<00:02, 53.58it/s, Epoch: 91, Batch: 24,Loss: -2.887,Avg.Loss: -2.999,LR: 1.19E-05]Training epoch 91:  16%|█▌        | 24/153 [00:00<00:02, 52.79it/s, Epoch: 91, Batch: 24,Loss: -2.887,Avg.Loss: -2.999,LR: 1.19E-05]Training epoch 91:  16%|█▌        | 24/153 [00:00<00:02, 52.79it/s, Epoch: 91, Batch: 25,Loss: -3.086,Avg.Loss: -3.002,LR: 1.18E-05]Training epoch 91:  16%|█▋        | 25/153 [00:00<00:02, 52.79it/s, Epoch: 91, Batch: 26,Loss: -2.957,Avg.Loss: -3.000,LR: 1.18E-05]Training epoch 91:  17%|█▋        | 26/153 [00:00<00:02, 52.79it/s, Epoch: 91, Batch: 27,Loss: -3.020,Avg.Loss: -3.001,LR: 1.18E-05]Training epoch 91:  18%|█▊        | 27/153 [00:00<00:02, 52.79it/s, Epoch: 91, Batch: 28,Loss: -3.011,Avg.Loss: -3.001,LR: 1.18E-05]Training epoch 91:  18%|█▊        | 28/153 [00:00<00:02, 52.79it/s, Epoch: 91, Batch: 29,Loss: -2.915,Avg.Loss: -2.999,LR: 1.18E-05]Training epoch 91:  19%|█▉        | 29/153 [00:00<00:02, 52.79it/s, Epoch: 91, Batch: 30,Loss: -3.060,Avg.Loss: -3.001,LR: 1.18E-05]Training epoch 91:  20%|█▉        | 30/153 [00:00<00:02, 52.66it/s, Epoch: 91, Batch: 30,Loss: -3.060,Avg.Loss: -3.001,LR: 1.18E-05]Training epoch 91:  20%|█▉        | 30/153 [00:00<00:02, 52.66it/s, Epoch: 91, Batch: 31,Loss: -3.688,Avg.Loss: -3.023,LR: 1.17E-05]Training epoch 91:  20%|██        | 31/153 [00:00<00:02, 52.66it/s, Epoch: 91, Batch: 32,Loss: -3.111,Avg.Loss: -3.025,LR: 1.17E-05]Training epoch 91:  21%|██        | 32/153 [00:00<00:02, 52.66it/s, Epoch: 91, Batch: 33,Loss: -3.204,Avg.Loss: -3.031,LR: 1.17E-05]Training epoch 91:  22%|██▏       | 33/153 [00:00<00:02, 52.66it/s, Epoch: 91, Batch: 34,Loss: -2.389,Avg.Loss: -3.012,LR: 1.17E-05]Training epoch 91:  22%|██▏       | 34/153 [00:00<00:02, 52.66it/s, Epoch: 91, Batch: 35,Loss: -3.158,Avg.Loss: -3.016,LR: 1.17E-05]Training epoch 91:  23%|██▎       | 35/153 [00:00<00:02, 52.66it/s, Epoch: 91, Batch: 36,Loss: -3.044,Avg.Loss: -3.017,LR: 1.17E-05]Training epoch 91:  24%|██▎       | 36/153 [00:00<00:02, 52.62it/s, Epoch: 91, Batch: 36,Loss: -3.044,Avg.Loss: -3.017,LR: 1.17E-05]Training epoch 91:  24%|██▎       | 36/153 [00:00<00:02, 52.62it/s, Epoch: 91, Batch: 37,Loss: -2.769,Avg.Loss: -3.010,LR: 1.17E-05]Training epoch 91:  24%|██▍       | 37/153 [00:00<00:02, 52.62it/s, Epoch: 91, Batch: 38,Loss: -3.355,Avg.Loss: -3.019,LR: 1.16E-05]Training epoch 91:  25%|██▍       | 38/153 [00:00<00:02, 52.62it/s, Epoch: 91, Batch: 39,Loss: -2.883,Avg.Loss: -3.016,LR: 1.16E-05]Training epoch 91:  25%|██▌       | 39/153 [00:00<00:02, 52.62it/s, Epoch: 91, Batch: 40,Loss: -2.911,Avg.Loss: -3.013,LR: 1.16E-05]Training epoch 91:  26%|██▌       | 40/153 [00:00<00:02, 52.62it/s, Epoch: 91, Batch: 41,Loss: -2.916,Avg.Loss: -3.011,LR: 1.16E-05]Training epoch 91:  27%|██▋       | 41/153 [00:00<00:02, 52.62it/s, Epoch: 91, Batch: 42,Loss: -3.322,Avg.Loss: -3.018,LR: 1.16E-05]Training epoch 91:  27%|██▋       | 42/153 [00:00<00:02, 52.60it/s, Epoch: 91, Batch: 42,Loss: -3.322,Avg.Loss: -3.018,LR: 1.16E-05]Training epoch 91:  27%|██▋       | 42/153 [00:00<00:02, 52.60it/s, Epoch: 91, Batch: 43,Loss: -3.326,Avg.Loss: -3.025,LR: 1.16E-05]Training epoch 91:  28%|██▊       | 43/153 [00:00<00:02, 52.60it/s, Epoch: 91, Batch: 44,Loss: -2.891,Avg.Loss: -3.022,LR: 1.15E-05]Training epoch 91:  29%|██▉       | 44/153 [00:00<00:02, 52.60it/s, Epoch: 91, Batch: 45,Loss: -2.220,Avg.Loss: -3.005,LR: 1.15E-05]Training epoch 91:  29%|██▉       | 45/153 [00:00<00:02, 52.60it/s, Epoch: 91, Batch: 46,Loss: -2.461,Avg.Loss: -2.993,LR: 1.15E-05]Training epoch 91:  30%|███       | 46/153 [00:00<00:02, 52.60it/s, Epoch: 91, Batch: 47,Loss: -3.325,Avg.Loss: -3.000,LR: 1.15E-05]Training epoch 91:  31%|███       | 47/153 [00:00<00:02, 52.60it/s, Epoch: 91, Batch: 48,Loss: -2.422,Avg.Loss: -2.988,LR: 1.15E-05]Training epoch 91:  31%|███▏      | 48/153 [00:00<00:01, 52.52it/s, Epoch: 91, Batch: 48,Loss: -2.422,Avg.Loss: -2.988,LR: 1.15E-05]Training epoch 91:  31%|███▏      | 48/153 [00:00<00:01, 52.52it/s, Epoch: 91, Batch: 49,Loss: -3.196,Avg.Loss: -2.992,LR: 1.15E-05]Training epoch 91:  32%|███▏      | 49/153 [00:00<00:01, 52.52it/s, Epoch: 91, Batch: 50,Loss: -3.112,Avg.Loss: -2.994,LR: 1.15E-05]Training epoch 91:  33%|███▎      | 50/153 [00:00<00:01, 52.52it/s, Epoch: 91, Batch: 51,Loss: -2.299,Avg.Loss: -2.981,LR: 1.14E-05]Training epoch 91:  33%|███▎      | 51/153 [00:00<00:01, 52.52it/s, Epoch: 91, Batch: 52,Loss: -3.371,Avg.Loss: -2.988,LR: 1.14E-05]Training epoch 91:  34%|███▍      | 52/153 [00:01<00:01, 52.52it/s, Epoch: 91, Batch: 53,Loss: -3.389,Avg.Loss: -2.996,LR: 1.14E-05]Training epoch 91:  35%|███▍      | 53/153 [00:01<00:01, 52.52it/s, Epoch: 91, Batch: 54,Loss: -3.119,Avg.Loss: -2.998,LR: 1.14E-05]Training epoch 91:  35%|███▌      | 54/153 [00:01<00:01, 52.50it/s, Epoch: 91, Batch: 54,Loss: -3.119,Avg.Loss: -2.998,LR: 1.14E-05]Training epoch 91:  35%|███▌      | 54/153 [00:01<00:01, 52.50it/s, Epoch: 91, Batch: 55,Loss: -3.321,Avg.Loss: -3.004,LR: 1.14E-05]Training epoch 91:  36%|███▌      | 55/153 [00:01<00:01, 52.50it/s, Epoch: 91, Batch: 56,Loss: -2.491,Avg.Loss: -2.995,LR: 1.14E-05]Training epoch 91:  37%|███▋      | 56/153 [00:01<00:01, 52.50it/s, Epoch: 91, Batch: 57,Loss: -3.275,Avg.Loss: -3.000,LR: 1.13E-05]Training epoch 91:  37%|███▋      | 57/153 [00:01<00:01, 52.50it/s, Epoch: 91, Batch: 58,Loss: -2.729,Avg.Loss: -2.995,LR: 1.13E-05]Training epoch 91:  38%|███▊      | 58/153 [00:01<00:01, 52.50it/s, Epoch: 91, Batch: 59,Loss: -2.704,Avg.Loss: -2.990,LR: 1.13E-05]Training epoch 91:  39%|███▊      | 59/153 [00:01<00:01, 52.50it/s, Epoch: 91, Batch: 60,Loss: -3.075,Avg.Loss: -2.992,LR: 1.13E-05]Training epoch 91:  39%|███▉      | 60/153 [00:01<00:01, 52.51it/s, Epoch: 91, Batch: 60,Loss: -3.075,Avg.Loss: -2.992,LR: 1.13E-05]Training epoch 91:  39%|███▉      | 60/153 [00:01<00:01, 52.51it/s, Epoch: 91, Batch: 61,Loss: -3.379,Avg.Loss: -2.998,LR: 1.13E-05]Training epoch 91:  40%|███▉      | 61/153 [00:01<00:01, 52.51it/s, Epoch: 91, Batch: 62,Loss: -3.283,Avg.Loss: -3.003,LR: 1.13E-05]Training epoch 91:  41%|████      | 62/153 [00:01<00:01, 52.51it/s, Epoch: 91, Batch: 63,Loss: -3.059,Avg.Loss: -3.003,LR: 1.13E-05]Training epoch 91:  41%|████      | 63/153 [00:01<00:01, 52.51it/s, Epoch: 91, Batch: 64,Loss: -2.954,Avg.Loss: -3.003,LR: 1.12E-05]Training epoch 91:  42%|████▏     | 64/153 [00:01<00:01, 52.51it/s, Epoch: 91, Batch: 65,Loss: -3.067,Avg.Loss: -3.004,LR: 1.12E-05]Training epoch 91:  42%|████▏     | 65/153 [00:01<00:01, 52.51it/s, Epoch: 91, Batch: 66,Loss: -2.727,Avg.Loss: -2.999,LR: 1.12E-05]Training epoch 91:  43%|████▎     | 66/153 [00:01<00:01, 52.56it/s, Epoch: 91, Batch: 66,Loss: -2.727,Avg.Loss: -2.999,LR: 1.12E-05]Training epoch 91:  43%|████▎     | 66/153 [00:01<00:01, 52.56it/s, Epoch: 91, Batch: 67,Loss: -2.859,Avg.Loss: -2.997,LR: 1.12E-05]Training epoch 91:  44%|████▍     | 67/153 [00:01<00:01, 52.56it/s, Epoch: 91, Batch: 68,Loss: -3.307,Avg.Loss: -3.002,LR: 1.12E-05]Training epoch 91:  44%|████▍     | 68/153 [00:01<00:01, 52.56it/s, Epoch: 91, Batch: 69,Loss: -3.036,Avg.Loss: -3.002,LR: 1.12E-05]Training epoch 91:  45%|████▌     | 69/153 [00:01<00:01, 52.56it/s, Epoch: 91, Batch: 70,Loss: -2.652,Avg.Loss: -2.997,LR: 1.12E-05]Training epoch 91:  46%|████▌     | 70/153 [00:01<00:01, 52.56it/s, Epoch: 91, Batch: 71,Loss: -2.782,Avg.Loss: -2.994,LR: 1.11E-05]Training epoch 91:  46%|████▋     | 71/153 [00:01<00:01, 52.56it/s, Epoch: 91, Batch: 72,Loss: -2.918,Avg.Loss: -2.993,LR: 1.11E-05]Training epoch 91:  47%|████▋     | 72/153 [00:01<00:01, 52.40it/s, Epoch: 91, Batch: 72,Loss: -2.918,Avg.Loss: -2.993,LR: 1.11E-05]Training epoch 91:  47%|████▋     | 72/153 [00:01<00:01, 52.40it/s, Epoch: 91, Batch: 73,Loss: -3.348,Avg.Loss: -2.998,LR: 1.11E-05]Training epoch 91:  48%|████▊     | 73/153 [00:01<00:01, 52.40it/s, Epoch: 91, Batch: 74,Loss: -2.669,Avg.Loss: -2.994,LR: 1.11E-05]Training epoch 91:  48%|████▊     | 74/153 [00:01<00:01, 52.40it/s, Epoch: 91, Batch: 75,Loss: -2.736,Avg.Loss: -2.990,LR: 1.11E-05]Training epoch 91:  49%|████▉     | 75/153 [00:01<00:01, 52.40it/s, Epoch: 91, Batch: 76,Loss: -3.198,Avg.Loss: -2.993,LR: 1.11E-05]Training epoch 91:  50%|████▉     | 76/153 [00:01<00:01, 52.40it/s, Epoch: 91, Batch: 77,Loss: -3.084,Avg.Loss: -2.994,LR: 1.10E-05]Training epoch 91:  50%|█████     | 77/153 [00:01<00:01, 52.40it/s, Epoch: 91, Batch: 78,Loss: -2.788,Avg.Loss: -2.992,LR: 1.10E-05]Training epoch 91:  51%|█████     | 78/153 [00:01<00:01, 52.46it/s, Epoch: 91, Batch: 78,Loss: -2.788,Avg.Loss: -2.992,LR: 1.10E-05]Training epoch 91:  51%|█████     | 78/153 [00:01<00:01, 52.46it/s, Epoch: 91, Batch: 79,Loss: -3.038,Avg.Loss: -2.992,LR: 1.10E-05]Training epoch 91:  52%|█████▏    | 79/153 [00:01<00:01, 52.46it/s, Epoch: 91, Batch: 80,Loss: -2.957,Avg.Loss: -2.992,LR: 1.10E-05]Training epoch 91:  52%|█████▏    | 80/153 [00:01<00:01, 52.46it/s, Epoch: 91, Batch: 81,Loss: -2.727,Avg.Loss: -2.988,LR: 1.10E-05]Training epoch 91:  53%|█████▎    | 81/153 [00:01<00:01, 52.46it/s, Epoch: 91, Batch: 82,Loss: -2.658,Avg.Loss: -2.984,LR: 1.10E-05]Training epoch 91:  54%|█████▎    | 82/153 [00:01<00:01, 52.46it/s, Epoch: 91, Batch: 83,Loss: -3.073,Avg.Loss: -2.985,LR: 1.10E-05]Training epoch 91:  54%|█████▍    | 83/153 [00:01<00:01, 52.46it/s, Epoch: 91, Batch: 84,Loss: -2.867,Avg.Loss: -2.984,LR: 1.09E-05]Training epoch 91:  55%|█████▍    | 84/153 [00:01<00:01, 52.45it/s, Epoch: 91, Batch: 84,Loss: -2.867,Avg.Loss: -2.984,LR: 1.09E-05]Training epoch 91:  55%|█████▍    | 84/153 [00:01<00:01, 52.45it/s, Epoch: 91, Batch: 85,Loss: -2.509,Avg.Loss: -2.978,LR: 1.09E-05]Training epoch 91:  56%|█████▌    | 85/153 [00:01<00:01, 52.45it/s, Epoch: 91, Batch: 86,Loss: -3.416,Avg.Loss: -2.984,LR: 1.09E-05]Training epoch 91:  56%|█████▌    | 86/153 [00:01<00:01, 52.45it/s, Epoch: 91, Batch: 87,Loss: -3.062,Avg.Loss: -2.984,LR: 1.09E-05]Training epoch 91:  57%|█████▋    | 87/153 [00:01<00:01, 52.45it/s, Epoch: 91, Batch: 88,Loss: -3.121,Avg.Loss: -2.986,LR: 1.09E-05]Training epoch 91:  58%|█████▊    | 88/153 [00:01<00:01, 52.45it/s, Epoch: 91, Batch: 89,Loss: -3.594,Avg.Loss: -2.993,LR: 1.09E-05]Training epoch 91:  58%|█████▊    | 89/153 [00:01<00:01, 52.45it/s, Epoch: 91, Batch: 90,Loss: -3.351,Avg.Loss: -2.997,LR: 1.08E-05]Training epoch 91:  59%|█████▉    | 90/153 [00:01<00:01, 52.41it/s, Epoch: 91, Batch: 90,Loss: -3.351,Avg.Loss: -2.997,LR: 1.08E-05]Training epoch 91:  59%|█████▉    | 90/153 [00:01<00:01, 52.41it/s, Epoch: 91, Batch: 91,Loss: -3.039,Avg.Loss: -2.997,LR: 1.08E-05]Training epoch 91:  59%|█████▉    | 91/153 [00:01<00:01, 52.41it/s, Epoch: 91, Batch: 92,Loss: -3.034,Avg.Loss: -2.998,LR: 1.08E-05]Training epoch 91:  60%|██████    | 92/153 [00:01<00:01, 52.41it/s, Epoch: 91, Batch: 93,Loss: -3.197,Avg.Loss: -3.000,LR: 1.08E-05]Training epoch 91:  61%|██████    | 93/153 [00:01<00:01, 52.41it/s, Epoch: 91, Batch: 94,Loss: -2.668,Avg.Loss: -2.996,LR: 1.08E-05]Training epoch 91:  61%|██████▏   | 94/153 [00:01<00:01, 52.41it/s, Epoch: 91, Batch: 95,Loss: -2.839,Avg.Loss: -2.995,LR: 1.08E-05]Training epoch 91:  62%|██████▏   | 95/153 [00:01<00:01, 52.41it/s, Epoch: 91, Batch: 96,Loss: -3.004,Avg.Loss: -2.995,LR: 1.08E-05]Training epoch 91:  63%|██████▎   | 96/153 [00:01<00:01, 52.53it/s, Epoch: 91, Batch: 96,Loss: -3.004,Avg.Loss: -2.995,LR: 1.08E-05]Training epoch 91:  63%|██████▎   | 96/153 [00:01<00:01, 52.53it/s, Epoch: 91, Batch: 97,Loss: -3.413,Avg.Loss: -2.999,LR: 1.07E-05]Training epoch 91:  63%|██████▎   | 97/153 [00:01<00:01, 52.53it/s, Epoch: 91, Batch: 98,Loss: -3.169,Avg.Loss: -3.001,LR: 1.07E-05]Training epoch 91:  64%|██████▍   | 98/153 [00:01<00:01, 52.53it/s, Epoch: 91, Batch: 99,Loss: -3.454,Avg.Loss: -3.005,LR: 1.07E-05]Training epoch 91:  65%|██████▍   | 99/153 [00:01<00:01, 52.53it/s, Epoch: 91, Batch: 100,Loss: -2.969,Avg.Loss: -3.005,LR: 1.07E-05]Training epoch 91:  65%|██████▌   | 100/153 [00:01<00:01, 52.53it/s, Epoch: 91, Batch: 101,Loss: -2.799,Avg.Loss: -3.003,LR: 1.07E-05]Training epoch 91:  66%|██████▌   | 101/153 [00:01<00:00, 52.53it/s, Epoch: 91, Batch: 102,Loss: -3.092,Avg.Loss: -3.004,LR: 1.07E-05]Training epoch 91:  67%|██████▋   | 102/153 [00:01<00:00, 52.78it/s, Epoch: 91, Batch: 102,Loss: -3.092,Avg.Loss: -3.004,LR: 1.07E-05]Training epoch 91:  67%|██████▋   | 102/153 [00:01<00:00, 52.78it/s, Epoch: 91, Batch: 103,Loss: -2.872,Avg.Loss: -3.003,LR: 1.07E-05]Training epoch 91:  67%|██████▋   | 103/153 [00:01<00:00, 52.78it/s, Epoch: 91, Batch: 104,Loss: -2.989,Avg.Loss: -3.002,LR: 1.06E-05]Training epoch 91:  68%|██████▊   | 104/153 [00:01<00:00, 52.78it/s, Epoch: 91, Batch: 105,Loss: -2.638,Avg.Loss: -2.999,LR: 1.06E-05]Training epoch 91:  69%|██████▊   | 105/153 [00:02<00:00, 52.78it/s, Epoch: 91, Batch: 106,Loss: -2.924,Avg.Loss: -2.998,LR: 1.06E-05]Training epoch 91:  69%|██████▉   | 106/153 [00:02<00:00, 52.78it/s, Epoch: 91, Batch: 107,Loss: -2.982,Avg.Loss: -2.998,LR: 1.06E-05]Training epoch 91:  70%|██████▉   | 107/153 [00:02<00:00, 52.78it/s, Epoch: 91, Batch: 108,Loss: -3.039,Avg.Loss: -2.998,LR: 1.06E-05]Training epoch 91:  71%|███████   | 108/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 108,Loss: -3.039,Avg.Loss: -2.998,LR: 1.06E-05]Training epoch 91:  71%|███████   | 108/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 109,Loss: -2.954,Avg.Loss: -2.998,LR: 1.06E-05]Training epoch 91:  71%|███████   | 109/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 110,Loss: -3.429,Avg.Loss: -3.002,LR: 1.06E-05]Training epoch 91:  72%|███████▏  | 110/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 111,Loss: -3.280,Avg.Loss: -3.004,LR: 1.05E-05]Training epoch 91:  73%|███████▎  | 111/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 112,Loss: -2.850,Avg.Loss: -3.003,LR: 1.05E-05]Training epoch 91:  73%|███████▎  | 112/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 113,Loss: -3.370,Avg.Loss: -3.006,LR: 1.05E-05]Training epoch 91:  74%|███████▍  | 113/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 114,Loss: -3.001,Avg.Loss: -3.006,LR: 1.05E-05]Training epoch 91:  75%|███████▍  | 114/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 114,Loss: -3.001,Avg.Loss: -3.006,LR: 1.05E-05]Training epoch 91:  75%|███████▍  | 114/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 115,Loss: -2.901,Avg.Loss: -3.005,LR: 1.05E-05]Training epoch 91:  75%|███████▌  | 115/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 116,Loss: -3.286,Avg.Loss: -3.008,LR: 1.05E-05]Training epoch 91:  76%|███████▌  | 116/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 117,Loss: -2.778,Avg.Loss: -3.006,LR: 1.04E-05]Training epoch 91:  76%|███████▋  | 117/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 118,Loss: -3.012,Avg.Loss: -3.006,LR: 1.04E-05]Training epoch 91:  77%|███████▋  | 118/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 119,Loss: -3.063,Avg.Loss: -3.006,LR: 1.04E-05]Training epoch 91:  78%|███████▊  | 119/153 [00:02<00:00, 52.71it/s, Epoch: 91, Batch: 120,Loss: -3.157,Avg.Loss: -3.008,LR: 1.04E-05]Training epoch 91:  78%|███████▊  | 120/153 [00:02<00:00, 52.52it/s, Epoch: 91, Batch: 120,Loss: -3.157,Avg.Loss: -3.008,LR: 1.04E-05]Training epoch 91:  78%|███████▊  | 120/153 [00:02<00:00, 52.52it/s, Epoch: 91, Batch: 121,Loss: -3.363,Avg.Loss: -3.011,LR: 1.04E-05]Training epoch 91:  79%|███████▉  | 121/153 [00:02<00:00, 52.52it/s, Epoch: 91, Batch: 122,Loss: -3.019,Avg.Loss: -3.011,LR: 1.04E-05]Training epoch 91:  80%|███████▉  | 122/153 [00:02<00:00, 52.52it/s, Epoch: 91, Batch: 123,Loss: -3.076,Avg.Loss: -3.011,LR: 1.04E-05]Training epoch 91:  80%|████████  | 123/153 [00:02<00:00, 52.52it/s, Epoch: 91, Batch: 124,Loss: -2.794,Avg.Loss: -3.009,LR: 1.03E-05]Training epoch 91:  81%|████████  | 124/153 [00:02<00:00, 52.52it/s, Epoch: 91, Batch: 125,Loss: -3.157,Avg.Loss: -3.011,LR: 1.03E-05]Training epoch 91:  82%|████████▏ | 125/153 [00:02<00:00, 52.52it/s, Epoch: 91, Batch: 126,Loss: -3.445,Avg.Loss: -3.014,LR: 1.03E-05]Training epoch 91:  82%|████████▏ | 126/153 [00:02<00:00, 52.58it/s, Epoch: 91, Batch: 126,Loss: -3.445,Avg.Loss: -3.014,LR: 1.03E-05]Training epoch 91:  82%|████████▏ | 126/153 [00:02<00:00, 52.58it/s, Epoch: 91, Batch: 127,Loss: -3.366,Avg.Loss: -3.017,LR: 1.03E-05]Training epoch 91:  83%|████████▎ | 127/153 [00:02<00:00, 52.58it/s, Epoch: 91, Batch: 128,Loss: -2.932,Avg.Loss: -3.016,LR: 1.03E-05]Training epoch 91:  84%|████████▎ | 128/153 [00:02<00:00, 52.58it/s, Epoch: 91, Batch: 129,Loss: -3.533,Avg.Loss: -3.020,LR: 1.03E-05]Training epoch 91:  84%|████████▍ | 129/153 [00:02<00:00, 52.58it/s, Epoch: 91, Batch: 130,Loss: -3.031,Avg.Loss: -3.020,LR: 1.03E-05]Training epoch 91:  85%|████████▍ | 130/153 [00:02<00:00, 52.58it/s, Epoch: 91, Batch: 131,Loss: -3.032,Avg.Loss: -3.020,LR: 1.02E-05]Training epoch 91:  86%|████████▌ | 131/153 [00:02<00:00, 52.58it/s, Epoch: 91, Batch: 132,Loss: -3.167,Avg.Loss: -3.021,LR: 1.02E-05]Training epoch 91:  86%|████████▋ | 132/153 [00:02<00:00, 52.68it/s, Epoch: 91, Batch: 132,Loss: -3.167,Avg.Loss: -3.021,LR: 1.02E-05]Training epoch 91:  86%|████████▋ | 132/153 [00:02<00:00, 52.68it/s, Epoch: 91, Batch: 133,Loss: -3.255,Avg.Loss: -3.023,LR: 1.02E-05]Training epoch 91:  87%|████████▋ | 133/153 [00:02<00:00, 52.68it/s, Epoch: 91, Batch: 134,Loss: -3.308,Avg.Loss: -3.025,LR: 1.02E-05]Training epoch 91:  88%|████████▊ | 134/153 [00:02<00:00, 52.68it/s, Epoch: 91, Batch: 135,Loss: -2.923,Avg.Loss: -3.025,LR: 1.02E-05]Training epoch 91:  88%|████████▊ | 135/153 [00:02<00:00, 52.68it/s, Epoch: 91, Batch: 136,Loss: -2.837,Avg.Loss: -3.023,LR: 1.02E-05]Training epoch 91:  89%|████████▉ | 136/153 [00:02<00:00, 52.68it/s, Epoch: 91, Batch: 137,Loss: -2.915,Avg.Loss: -3.022,LR: 1.02E-05]Training epoch 91:  90%|████████▉ | 137/153 [00:02<00:00, 52.68it/s, Epoch: 91, Batch: 138,Loss: -3.277,Avg.Loss: -3.024,LR: 1.01E-05]Training epoch 91:  90%|█████████ | 138/153 [00:02<00:00, 52.69it/s, Epoch: 91, Batch: 138,Loss: -3.277,Avg.Loss: -3.024,LR: 1.01E-05]Training epoch 91:  90%|█████████ | 138/153 [00:02<00:00, 52.69it/s, Epoch: 91, Batch: 139,Loss: -2.579,Avg.Loss: -3.021,LR: 1.01E-05]Training epoch 91:  91%|█████████ | 139/153 [00:02<00:00, 52.69it/s, Epoch: 91, Batch: 140,Loss: -3.142,Avg.Loss: -3.022,LR: 1.01E-05]Training epoch 91:  92%|█████████▏| 140/153 [00:02<00:00, 52.69it/s, Epoch: 91, Batch: 141,Loss: -2.971,Avg.Loss: -3.022,LR: 1.01E-05]Training epoch 91:  92%|█████████▏| 141/153 [00:02<00:00, 52.69it/s, Epoch: 91, Batch: 142,Loss: -3.105,Avg.Loss: -3.022,LR: 1.01E-05]Training epoch 91:  93%|█████████▎| 142/153 [00:02<00:00, 52.69it/s, Epoch: 91, Batch: 143,Loss: -3.254,Avg.Loss: -3.024,LR: 1.01E-05]Training epoch 91:  93%|█████████▎| 143/153 [00:02<00:00, 52.69it/s, Epoch: 91, Batch: 144,Loss: -3.014,Avg.Loss: -3.024,LR: 1.01E-05]Training epoch 91:  94%|█████████▍| 144/153 [00:02<00:00, 52.88it/s, Epoch: 91, Batch: 144,Loss: -3.014,Avg.Loss: -3.024,LR: 1.01E-05]Training epoch 91:  94%|█████████▍| 144/153 [00:02<00:00, 52.88it/s, Epoch: 91, Batch: 145,Loss: -3.286,Avg.Loss: -3.025,LR: 1.00E-05]Training epoch 91:  95%|█████████▍| 145/153 [00:02<00:00, 52.88it/s, Epoch: 91, Batch: 146,Loss: -3.168,Avg.Loss: -3.026,LR: 1.00E-05]Training epoch 91:  95%|█████████▌| 146/153 [00:02<00:00, 52.88it/s, Epoch: 91, Batch: 147,Loss: -2.835,Avg.Loss: -3.025,LR: 1.00E-05]Training epoch 91:  96%|█████████▌| 147/153 [00:02<00:00, 52.88it/s, Epoch: 91, Batch: 148,Loss: -3.145,Avg.Loss: -3.026,LR: 1.00E-05]Training epoch 91:  97%|█████████▋| 148/153 [00:02<00:00, 52.88it/s, Epoch: 91, Batch: 149,Loss: -3.130,Avg.Loss: -3.027,LR: 9.98E-06]Training epoch 91:  97%|█████████▋| 149/153 [00:02<00:00, 52.88it/s, Epoch: 91, Batch: 150,Loss: -3.391,Avg.Loss: -3.029,LR: 9.97E-06]Training epoch 91:  98%|█████████▊| 150/153 [00:02<00:00, 52.87it/s, Epoch: 91, Batch: 150,Loss: -3.391,Avg.Loss: -3.029,LR: 9.97E-06]Training epoch 91:  98%|█████████▊| 150/153 [00:02<00:00, 52.87it/s, Epoch: 91, Batch: 151,Loss: -3.061,Avg.Loss: -3.029,LR: 9.96E-06]Training epoch 91:  99%|█████████▊| 151/153 [00:02<00:00, 52.87it/s, Epoch: 91, Batch: 152,Loss: -2.950,Avg.Loss: -3.029,LR: 9.94E-06]Training epoch 91:  99%|█████████▉| 152/153 [00:02<00:00, 52.87it/s, Epoch: 91, Batch: 153,Loss: -3.217,Avg.Loss: -3.030,LR: 9.93E-06]Training epoch 91: 100%|██████████| 153/153 [00:02<00:00, 52.70it/s, Epoch: 91, Batch: 153,Loss: -3.217,Avg.Loss: -3.030,LR: 9.93E-06]
Training epoch 92:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 92:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 92, Batch: 1,Loss: -3.475,Avg.Loss: -3.475,LR: 9.91E-06]Training epoch 92:   1%|          | 1/153 [00:00<00:06, 23.26it/s, Epoch: 92, Batch: 2,Loss: -2.849,Avg.Loss: -3.162,LR: 9.90E-06]Training epoch 92:   1%|▏         | 2/153 [00:00<00:04, 33.50it/s, Epoch: 92, Batch: 3,Loss: -3.363,Avg.Loss: -3.229,LR: 9.88E-06]Training epoch 92:   2%|▏         | 3/153 [00:00<00:03, 39.11it/s, Epoch: 92, Batch: 4,Loss: -2.824,Avg.Loss: -3.128,LR: 9.87E-06]Training epoch 92:   3%|▎         | 4/153 [00:00<00:03, 42.48it/s, Epoch: 92, Batch: 5,Loss: -3.140,Avg.Loss: -3.130,LR: 9.86E-06]Training epoch 92:   3%|▎         | 5/153 [00:00<00:03, 44.33it/s, Epoch: 92, Batch: 6,Loss: -3.424,Avg.Loss: -3.179,LR: 9.84E-06]Training epoch 92:   4%|▍         | 6/153 [00:00<00:02, 53.11it/s, Epoch: 92, Batch: 6,Loss: -3.424,Avg.Loss: -3.179,LR: 9.84E-06]Training epoch 92:   4%|▍         | 6/153 [00:00<00:02, 53.11it/s, Epoch: 92, Batch: 7,Loss: -2.618,Avg.Loss: -3.099,LR: 9.83E-06]Training epoch 92:   5%|▍         | 7/153 [00:00<00:02, 53.11it/s, Epoch: 92, Batch: 8,Loss: -2.666,Avg.Loss: -3.045,LR: 9.81E-06]Training epoch 92:   5%|▌         | 8/153 [00:00<00:02, 53.11it/s, Epoch: 92, Batch: 9,Loss: -3.144,Avg.Loss: -3.056,LR: 9.80E-06]Training epoch 92:   6%|▌         | 9/153 [00:00<00:02, 53.11it/s, Epoch: 92, Batch: 10,Loss: -2.838,Avg.Loss: -3.034,LR: 9.78E-06]Training epoch 92:   7%|▋         | 10/153 [00:00<00:02, 53.11it/s, Epoch: 92, Batch: 11,Loss: -2.977,Avg.Loss: -3.029,LR: 9.77E-06]Training epoch 92:   7%|▋         | 11/153 [00:00<00:02, 53.11it/s, Epoch: 92, Batch: 12,Loss: -2.936,Avg.Loss: -3.021,LR: 9.76E-06]Training epoch 92:   8%|▊         | 12/153 [00:00<00:02, 52.68it/s, Epoch: 92, Batch: 12,Loss: -2.936,Avg.Loss: -3.021,LR: 9.76E-06]Training epoch 92:   8%|▊         | 12/153 [00:00<00:02, 52.68it/s, Epoch: 92, Batch: 13,Loss: -2.743,Avg.Loss: -3.000,LR: 9.74E-06]Training epoch 92:   8%|▊         | 13/153 [00:00<00:02, 52.68it/s, Epoch: 92, Batch: 14,Loss: -3.205,Avg.Loss: -3.014,LR: 9.73E-06]Training epoch 92:   9%|▉         | 14/153 [00:00<00:02, 52.68it/s, Epoch: 92, Batch: 15,Loss: -2.468,Avg.Loss: -2.978,LR: 9.71E-06]Training epoch 92:  10%|▉         | 15/153 [00:00<00:02, 52.68it/s, Epoch: 92, Batch: 16,Loss: -3.457,Avg.Loss: -3.008,LR: 9.70E-06]Training epoch 92:  10%|█         | 16/153 [00:00<00:02, 52.68it/s, Epoch: 92, Batch: 17,Loss: -2.632,Avg.Loss: -2.986,LR: 9.68E-06]Training epoch 92:  11%|█         | 17/153 [00:00<00:02, 52.68it/s, Epoch: 92, Batch: 18,Loss: -2.973,Avg.Loss: -2.985,LR: 9.67E-06]Training epoch 92:  12%|█▏        | 18/153 [00:00<00:02, 53.07it/s, Epoch: 92, Batch: 18,Loss: -2.973,Avg.Loss: -2.985,LR: 9.67E-06]Training epoch 92:  12%|█▏        | 18/153 [00:00<00:02, 53.07it/s, Epoch: 92, Batch: 19,Loss: -2.797,Avg.Loss: -2.975,LR: 9.66E-06]Training epoch 92:  12%|█▏        | 19/153 [00:00<00:02, 53.07it/s, Epoch: 92, Batch: 20,Loss: -2.376,Avg.Loss: -2.945,LR: 9.64E-06]Training epoch 92:  13%|█▎        | 20/153 [00:00<00:02, 53.07it/s, Epoch: 92, Batch: 21,Loss: -2.987,Avg.Loss: -2.947,LR: 9.63E-06]Training epoch 92:  14%|█▎        | 21/153 [00:00<00:02, 53.07it/s, Epoch: 92, Batch: 22,Loss: -3.168,Avg.Loss: -2.957,LR: 9.61E-06]Training epoch 92:  14%|█▍        | 22/153 [00:00<00:02, 53.07it/s, Epoch: 92, Batch: 23,Loss: -3.183,Avg.Loss: -2.967,LR: 9.60E-06]Training epoch 92:  15%|█▌        | 23/153 [00:00<00:02, 53.07it/s, Epoch: 92, Batch: 24,Loss: -3.063,Avg.Loss: -2.971,LR: 9.59E-06]Training epoch 92:  16%|█▌        | 24/153 [00:00<00:02, 52.64it/s, Epoch: 92, Batch: 24,Loss: -3.063,Avg.Loss: -2.971,LR: 9.59E-06]Training epoch 92:  16%|█▌        | 24/153 [00:00<00:02, 52.64it/s, Epoch: 92, Batch: 25,Loss: -3.340,Avg.Loss: -2.986,LR: 9.57E-06]Training epoch 92:  16%|█▋        | 25/153 [00:00<00:02, 52.64it/s, Epoch: 92, Batch: 26,Loss: -3.149,Avg.Loss: -2.992,LR: 9.56E-06]Training epoch 92:  17%|█▋        | 26/153 [00:00<00:02, 52.64it/s, Epoch: 92, Batch: 27,Loss: -2.742,Avg.Loss: -2.983,LR: 9.54E-06]Training epoch 92:  18%|█▊        | 27/153 [00:00<00:02, 52.64it/s, Epoch: 92, Batch: 28,Loss: -2.942,Avg.Loss: -2.981,LR: 9.53E-06]Training epoch 92:  18%|█▊        | 28/153 [00:00<00:02, 52.64it/s, Epoch: 92, Batch: 29,Loss: -3.031,Avg.Loss: -2.983,LR: 9.52E-06]Training epoch 92:  19%|█▉        | 29/153 [00:00<00:02, 52.64it/s, Epoch: 92, Batch: 30,Loss: -2.888,Avg.Loss: -2.980,LR: 9.50E-06]Training epoch 92:  20%|█▉        | 30/153 [00:00<00:02, 52.25it/s, Epoch: 92, Batch: 30,Loss: -2.888,Avg.Loss: -2.980,LR: 9.50E-06]Training epoch 92:  20%|█▉        | 30/153 [00:00<00:02, 52.25it/s, Epoch: 92, Batch: 31,Loss: -2.847,Avg.Loss: -2.976,LR: 9.49E-06]Training epoch 92:  20%|██        | 31/153 [00:00<00:02, 52.25it/s, Epoch: 92, Batch: 32,Loss: -2.959,Avg.Loss: -2.975,LR: 9.47E-06]Training epoch 92:  21%|██        | 32/153 [00:00<00:02, 52.25it/s, Epoch: 92, Batch: 33,Loss: -3.401,Avg.Loss: -2.988,LR: 9.46E-06]Training epoch 92:  22%|██▏       | 33/153 [00:00<00:02, 52.25it/s, Epoch: 92, Batch: 34,Loss: -3.167,Avg.Loss: -2.993,LR: 9.45E-06]Training epoch 92:  22%|██▏       | 34/153 [00:00<00:02, 52.25it/s, Epoch: 92, Batch: 35,Loss: -3.397,Avg.Loss: -3.005,LR: 9.43E-06]Training epoch 92:  23%|██▎       | 35/153 [00:00<00:02, 52.25it/s, Epoch: 92, Batch: 36,Loss: -2.829,Avg.Loss: -3.000,LR: 9.42E-06]Training epoch 92:  24%|██▎       | 36/153 [00:00<00:02, 52.59it/s, Epoch: 92, Batch: 36,Loss: -2.829,Avg.Loss: -3.000,LR: 9.42E-06]Training epoch 92:  24%|██▎       | 36/153 [00:00<00:02, 52.59it/s, Epoch: 92, Batch: 37,Loss: -3.435,Avg.Loss: -3.012,LR: 9.40E-06]Training epoch 92:  24%|██▍       | 37/153 [00:00<00:02, 52.59it/s, Epoch: 92, Batch: 38,Loss: -3.331,Avg.Loss: -3.020,LR: 9.39E-06]Training epoch 92:  25%|██▍       | 38/153 [00:00<00:02, 52.59it/s, Epoch: 92, Batch: 39,Loss: -3.254,Avg.Loss: -3.026,LR: 9.38E-06]Training epoch 92:  25%|██▌       | 39/153 [00:00<00:02, 52.59it/s, Epoch: 92, Batch: 40,Loss: -3.231,Avg.Loss: -3.031,LR: 9.36E-06]Training epoch 92:  26%|██▌       | 40/153 [00:00<00:02, 52.59it/s, Epoch: 92, Batch: 41,Loss: -2.671,Avg.Loss: -3.022,LR: 9.35E-06]Training epoch 92:  27%|██▋       | 41/153 [00:00<00:02, 52.59it/s, Epoch: 92, Batch: 42,Loss: -2.359,Avg.Loss: -3.007,LR: 9.33E-06]Training epoch 92:  27%|██▋       | 42/153 [00:00<00:02, 52.45it/s, Epoch: 92, Batch: 42,Loss: -2.359,Avg.Loss: -3.007,LR: 9.33E-06]Training epoch 92:  27%|██▋       | 42/153 [00:00<00:02, 52.45it/s, Epoch: 92, Batch: 43,Loss: -3.111,Avg.Loss: -3.009,LR: 9.32E-06]Training epoch 92:  28%|██▊       | 43/153 [00:00<00:02, 52.45it/s, Epoch: 92, Batch: 44,Loss: -2.620,Avg.Loss: -3.000,LR: 9.31E-06]Training epoch 92:  29%|██▉       | 44/153 [00:00<00:02, 52.45it/s, Epoch: 92, Batch: 45,Loss: -3.211,Avg.Loss: -3.005,LR: 9.29E-06]Training epoch 92:  29%|██▉       | 45/153 [00:00<00:02, 52.45it/s, Epoch: 92, Batch: 46,Loss: -2.967,Avg.Loss: -3.004,LR: 9.28E-06]Training epoch 92:  30%|███       | 46/153 [00:00<00:02, 52.45it/s, Epoch: 92, Batch: 47,Loss: -3.271,Avg.Loss: -3.010,LR: 9.26E-06]Training epoch 92:  31%|███       | 47/153 [00:00<00:02, 52.45it/s, Epoch: 92, Batch: 48,Loss: -2.999,Avg.Loss: -3.009,LR: 9.25E-06]Training epoch 92:  31%|███▏      | 48/153 [00:00<00:01, 52.69it/s, Epoch: 92, Batch: 48,Loss: -2.999,Avg.Loss: -3.009,LR: 9.25E-06]Training epoch 92:  31%|███▏      | 48/153 [00:00<00:01, 52.69it/s, Epoch: 92, Batch: 49,Loss: -2.971,Avg.Loss: -3.009,LR: 9.24E-06]Training epoch 92:  32%|███▏      | 49/153 [00:00<00:01, 52.69it/s, Epoch: 92, Batch: 50,Loss: -3.449,Avg.Loss: -3.018,LR: 9.22E-06]Training epoch 92:  33%|███▎      | 50/153 [00:00<00:01, 52.69it/s, Epoch: 92, Batch: 51,Loss: -3.157,Avg.Loss: -3.020,LR: 9.21E-06]Training epoch 92:  33%|███▎      | 51/153 [00:00<00:01, 52.69it/s, Epoch: 92, Batch: 52,Loss: -2.604,Avg.Loss: -3.012,LR: 9.20E-06]Training epoch 92:  34%|███▍      | 52/153 [00:01<00:01, 52.69it/s, Epoch: 92, Batch: 53,Loss: -3.028,Avg.Loss: -3.013,LR: 9.18E-06]Training epoch 92:  35%|███▍      | 53/153 [00:01<00:01, 52.69it/s, Epoch: 92, Batch: 54,Loss: -3.080,Avg.Loss: -3.014,LR: 9.17E-06]Training epoch 92:  35%|███▌      | 54/153 [00:01<00:01, 52.74it/s, Epoch: 92, Batch: 54,Loss: -3.080,Avg.Loss: -3.014,LR: 9.17E-06]Training epoch 92:  35%|███▌      | 54/153 [00:01<00:01, 52.74it/s, Epoch: 92, Batch: 55,Loss: -2.967,Avg.Loss: -3.013,LR: 9.15E-06]Training epoch 92:  36%|███▌      | 55/153 [00:01<00:01, 52.74it/s, Epoch: 92, Batch: 56,Loss: -2.883,Avg.Loss: -3.011,LR: 9.14E-06]Training epoch 92:  37%|███▋      | 56/153 [00:01<00:01, 52.74it/s, Epoch: 92, Batch: 57,Loss: -3.256,Avg.Loss: -3.015,LR: 9.13E-06]Training epoch 92:  37%|███▋      | 57/153 [00:01<00:01, 52.74it/s, Epoch: 92, Batch: 58,Loss: -3.205,Avg.Loss: -3.018,LR: 9.11E-06]Training epoch 92:  38%|███▊      | 58/153 [00:01<00:01, 52.74it/s, Epoch: 92, Batch: 59,Loss: -2.980,Avg.Loss: -3.018,LR: 9.10E-06]Training epoch 92:  39%|███▊      | 59/153 [00:01<00:01, 52.74it/s, Epoch: 92, Batch: 60,Loss: -2.918,Avg.Loss: -3.016,LR: 9.09E-06]Training epoch 92:  39%|███▉      | 60/153 [00:01<00:01, 52.71it/s, Epoch: 92, Batch: 60,Loss: -2.918,Avg.Loss: -3.016,LR: 9.09E-06]Training epoch 92:  39%|███▉      | 60/153 [00:01<00:01, 52.71it/s, Epoch: 92, Batch: 61,Loss: -3.077,Avg.Loss: -3.017,LR: 9.07E-06]Training epoch 92:  40%|███▉      | 61/153 [00:01<00:01, 52.71it/s, Epoch: 92, Batch: 62,Loss: -3.272,Avg.Loss: -3.021,LR: 9.06E-06]Training epoch 92:  41%|████      | 62/153 [00:01<00:01, 52.71it/s, Epoch: 92, Batch: 63,Loss: -2.963,Avg.Loss: -3.020,LR: 9.04E-06]Training epoch 92:  41%|████      | 63/153 [00:01<00:01, 52.71it/s, Epoch: 92, Batch: 64,Loss: -3.076,Avg.Loss: -3.021,LR: 9.03E-06]Training epoch 92:  42%|████▏     | 64/153 [00:01<00:01, 52.71it/s, Epoch: 92, Batch: 65,Loss: -2.377,Avg.Loss: -3.011,LR: 9.02E-06]Training epoch 92:  42%|████▏     | 65/153 [00:01<00:01, 52.71it/s, Epoch: 92, Batch: 66,Loss: -2.792,Avg.Loss: -3.008,LR: 9.00E-06]Training epoch 92:  43%|████▎     | 66/153 [00:01<00:01, 52.72it/s, Epoch: 92, Batch: 66,Loss: -2.792,Avg.Loss: -3.008,LR: 9.00E-06]Training epoch 92:  43%|████▎     | 66/153 [00:01<00:01, 52.72it/s, Epoch: 92, Batch: 67,Loss: -3.108,Avg.Loss: -3.009,LR: 8.99E-06]Training epoch 92:  44%|████▍     | 67/153 [00:01<00:01, 52.72it/s, Epoch: 92, Batch: 68,Loss: -2.925,Avg.Loss: -3.008,LR: 8.98E-06]Training epoch 92:  44%|████▍     | 68/153 [00:01<00:01, 52.72it/s, Epoch: 92, Batch: 69,Loss: -2.881,Avg.Loss: -3.006,LR: 8.96E-06]Training epoch 92:  45%|████▌     | 69/153 [00:01<00:01, 52.72it/s, Epoch: 92, Batch: 70,Loss: -3.111,Avg.Loss: -3.008,LR: 8.95E-06]Training epoch 92:  46%|████▌     | 70/153 [00:01<00:01, 52.72it/s, Epoch: 92, Batch: 71,Loss: -2.785,Avg.Loss: -3.004,LR: 8.94E-06]Training epoch 92:  46%|████▋     | 71/153 [00:01<00:01, 52.72it/s, Epoch: 92, Batch: 72,Loss: -3.293,Avg.Loss: -3.008,LR: 8.92E-06]Training epoch 92:  47%|████▋     | 72/153 [00:01<00:01, 52.45it/s, Epoch: 92, Batch: 72,Loss: -3.293,Avg.Loss: -3.008,LR: 8.92E-06]Training epoch 92:  47%|████▋     | 72/153 [00:01<00:01, 52.45it/s, Epoch: 92, Batch: 73,Loss: -3.442,Avg.Loss: -3.014,LR: 8.91E-06]Training epoch 92:  48%|████▊     | 73/153 [00:01<00:01, 52.45it/s, Epoch: 92, Batch: 74,Loss: -2.942,Avg.Loss: -3.013,LR: 8.89E-06]Training epoch 92:  48%|████▊     | 74/153 [00:01<00:01, 52.45it/s, Epoch: 92, Batch: 75,Loss: -2.813,Avg.Loss: -3.011,LR: 8.88E-06]Training epoch 92:  49%|████▉     | 75/153 [00:01<00:01, 52.45it/s, Epoch: 92, Batch: 76,Loss: -3.150,Avg.Loss: -3.013,LR: 8.87E-06]Training epoch 92:  50%|████▉     | 76/153 [00:01<00:01, 52.45it/s, Epoch: 92, Batch: 77,Loss: -2.984,Avg.Loss: -3.012,LR: 8.85E-06]Training epoch 92:  50%|█████     | 77/153 [00:01<00:01, 52.45it/s, Epoch: 92, Batch: 78,Loss: -3.576,Avg.Loss: -3.019,LR: 8.84E-06]Training epoch 92:  51%|█████     | 78/153 [00:01<00:01, 52.21it/s, Epoch: 92, Batch: 78,Loss: -3.576,Avg.Loss: -3.019,LR: 8.84E-06]Training epoch 92:  51%|█████     | 78/153 [00:01<00:01, 52.21it/s, Epoch: 92, Batch: 79,Loss: -2.205,Avg.Loss: -3.009,LR: 8.83E-06]Training epoch 92:  52%|█████▏    | 79/153 [00:01<00:01, 52.21it/s, Epoch: 92, Batch: 80,Loss: -3.001,Avg.Loss: -3.009,LR: 8.81E-06]Training epoch 92:  52%|█████▏    | 80/153 [00:01<00:01, 52.21it/s, Epoch: 92, Batch: 81,Loss: -3.015,Avg.Loss: -3.009,LR: 8.80E-06]Training epoch 92:  53%|█████▎    | 81/153 [00:01<00:01, 52.21it/s, Epoch: 92, Batch: 82,Loss: -3.292,Avg.Loss: -3.013,LR: 8.79E-06]Training epoch 92:  54%|█████▎    | 82/153 [00:01<00:01, 52.21it/s, Epoch: 92, Batch: 83,Loss: -3.144,Avg.Loss: -3.014,LR: 8.77E-06]Training epoch 92:  54%|█████▍    | 83/153 [00:01<00:01, 52.21it/s, Epoch: 92, Batch: 84,Loss: -3.447,Avg.Loss: -3.019,LR: 8.76E-06]Training epoch 92:  55%|█████▍    | 84/153 [00:01<00:01, 52.20it/s, Epoch: 92, Batch: 84,Loss: -3.447,Avg.Loss: -3.019,LR: 8.76E-06]Training epoch 92:  55%|█████▍    | 84/153 [00:01<00:01, 52.20it/s, Epoch: 92, Batch: 85,Loss: -3.260,Avg.Loss: -3.022,LR: 8.75E-06]Training epoch 92:  56%|█████▌    | 85/153 [00:01<00:01, 52.20it/s, Epoch: 92, Batch: 86,Loss: -3.150,Avg.Loss: -3.024,LR: 8.73E-06]Training epoch 92:  56%|█████▌    | 86/153 [00:01<00:01, 52.20it/s, Epoch: 92, Batch: 87,Loss: -2.736,Avg.Loss: -3.020,LR: 8.72E-06]Training epoch 92:  57%|█████▋    | 87/153 [00:01<00:01, 52.20it/s, Epoch: 92, Batch: 88,Loss: -3.028,Avg.Loss: -3.020,LR: 8.71E-06]Training epoch 92:  58%|█████▊    | 88/153 [00:01<00:01, 52.20it/s, Epoch: 92, Batch: 89,Loss: -3.033,Avg.Loss: -3.021,LR: 8.69E-06]Training epoch 92:  58%|█████▊    | 89/153 [00:01<00:01, 52.20it/s, Epoch: 92, Batch: 90,Loss: -3.300,Avg.Loss: -3.024,LR: 8.68E-06]Training epoch 92:  59%|█████▉    | 90/153 [00:01<00:01, 52.28it/s, Epoch: 92, Batch: 90,Loss: -3.300,Avg.Loss: -3.024,LR: 8.68E-06]Training epoch 92:  59%|█████▉    | 90/153 [00:01<00:01, 52.28it/s, Epoch: 92, Batch: 91,Loss: -2.755,Avg.Loss: -3.021,LR: 8.67E-06]Training epoch 92:  59%|█████▉    | 91/153 [00:01<00:01, 52.28it/s, Epoch: 92, Batch: 92,Loss: -3.231,Avg.Loss: -3.023,LR: 8.65E-06]Training epoch 92:  60%|██████    | 92/153 [00:01<00:01, 52.28it/s, Epoch: 92, Batch: 93,Loss: -3.377,Avg.Loss: -3.027,LR: 8.64E-06]Training epoch 92:  61%|██████    | 93/153 [00:01<00:01, 52.28it/s, Epoch: 92, Batch: 94,Loss: -3.157,Avg.Loss: -3.028,LR: 8.63E-06]Training epoch 92:  61%|██████▏   | 94/153 [00:01<00:01, 52.28it/s, Epoch: 92, Batch: 95,Loss: -3.303,Avg.Loss: -3.031,LR: 8.61E-06]Training epoch 92:  62%|██████▏   | 95/153 [00:01<00:01, 52.28it/s, Epoch: 92, Batch: 96,Loss: -2.264,Avg.Loss: -3.023,LR: 8.60E-06]Training epoch 92:  63%|██████▎   | 96/153 [00:01<00:01, 52.11it/s, Epoch: 92, Batch: 96,Loss: -2.264,Avg.Loss: -3.023,LR: 8.60E-06]Training epoch 92:  63%|██████▎   | 96/153 [00:01<00:01, 52.11it/s, Epoch: 92, Batch: 97,Loss: -3.198,Avg.Loss: -3.025,LR: 8.59E-06]Training epoch 92:  63%|██████▎   | 97/153 [00:01<00:01, 52.11it/s, Epoch: 92, Batch: 98,Loss: -2.909,Avg.Loss: -3.024,LR: 8.57E-06]Training epoch 92:  64%|██████▍   | 98/153 [00:01<00:01, 52.11it/s, Epoch: 92, Batch: 99,Loss: -2.902,Avg.Loss: -3.022,LR: 8.56E-06]Training epoch 92:  65%|██████▍   | 99/153 [00:01<00:01, 52.11it/s, Epoch: 92, Batch: 100,Loss: -3.394,Avg.Loss: -3.026,LR: 8.55E-06]Training epoch 92:  65%|██████▌   | 100/153 [00:01<00:01, 52.11it/s, Epoch: 92, Batch: 101,Loss: -3.432,Avg.Loss: -3.030,LR: 8.53E-06]Training epoch 92:  66%|██████▌   | 101/153 [00:01<00:00, 52.11it/s, Epoch: 92, Batch: 102,Loss: -3.583,Avg.Loss: -3.036,LR: 8.52E-06]Training epoch 92:  67%|██████▋   | 102/153 [00:01<00:00, 52.51it/s, Epoch: 92, Batch: 102,Loss: -3.583,Avg.Loss: -3.036,LR: 8.52E-06]Training epoch 92:  67%|██████▋   | 102/153 [00:01<00:00, 52.51it/s, Epoch: 92, Batch: 103,Loss: -2.880,Avg.Loss: -3.034,LR: 8.51E-06]Training epoch 92:  67%|██████▋   | 103/153 [00:01<00:00, 52.51it/s, Epoch: 92, Batch: 104,Loss: -2.815,Avg.Loss: -3.032,LR: 8.49E-06]Training epoch 92:  68%|██████▊   | 104/153 [00:02<00:00, 52.51it/s, Epoch: 92, Batch: 105,Loss: -3.132,Avg.Loss: -3.033,LR: 8.48E-06]Training epoch 92:  69%|██████▊   | 105/153 [00:02<00:00, 52.51it/s, Epoch: 92, Batch: 106,Loss: -3.343,Avg.Loss: -3.036,LR: 8.47E-06]Training epoch 92:  69%|██████▉   | 106/153 [00:02<00:00, 52.51it/s, Epoch: 92, Batch: 107,Loss: -3.007,Avg.Loss: -3.036,LR: 8.45E-06]Training epoch 92:  70%|██████▉   | 107/153 [00:02<00:00, 52.51it/s, Epoch: 92, Batch: 108,Loss: -3.362,Avg.Loss: -3.039,LR: 8.44E-06]Training epoch 92:  71%|███████   | 108/153 [00:02<00:00, 52.36it/s, Epoch: 92, Batch: 108,Loss: -3.362,Avg.Loss: -3.039,LR: 8.44E-06]Training epoch 92:  71%|███████   | 108/153 [00:02<00:00, 52.36it/s, Epoch: 92, Batch: 109,Loss: -3.156,Avg.Loss: -3.040,LR: 8.43E-06]Training epoch 92:  71%|███████   | 109/153 [00:02<00:00, 52.36it/s, Epoch: 92, Batch: 110,Loss: -3.165,Avg.Loss: -3.041,LR: 8.41E-06]Training epoch 92:  72%|███████▏  | 110/153 [00:02<00:00, 52.36it/s, Epoch: 92, Batch: 111,Loss: -3.199,Avg.Loss: -3.042,LR: 8.40E-06]Training epoch 92:  73%|███████▎  | 111/153 [00:02<00:00, 52.36it/s, Epoch: 92, Batch: 112,Loss: -3.121,Avg.Loss: -3.043,LR: 8.39E-06]Training epoch 92:  73%|███████▎  | 112/153 [00:02<00:00, 52.36it/s, Epoch: 92, Batch: 113,Loss: -2.831,Avg.Loss: -3.041,LR: 8.37E-06]Training epoch 92:  74%|███████▍  | 113/153 [00:02<00:00, 52.36it/s, Epoch: 92, Batch: 114,Loss: -3.277,Avg.Loss: -3.043,LR: 8.36E-06]Training epoch 92:  75%|███████▍  | 114/153 [00:02<00:00, 52.21it/s, Epoch: 92, Batch: 114,Loss: -3.277,Avg.Loss: -3.043,LR: 8.36E-06]Training epoch 92:  75%|███████▍  | 114/153 [00:02<00:00, 52.21it/s, Epoch: 92, Batch: 115,Loss: -2.474,Avg.Loss: -3.038,LR: 8.35E-06]Training epoch 92:  75%|███████▌  | 115/153 [00:02<00:00, 52.21it/s, Epoch: 92, Batch: 116,Loss: -2.926,Avg.Loss: -3.037,LR: 8.33E-06]Training epoch 92:  76%|███████▌  | 116/153 [00:02<00:00, 52.21it/s, Epoch: 92, Batch: 117,Loss: -3.369,Avg.Loss: -3.040,LR: 8.32E-06]Training epoch 92:  76%|███████▋  | 117/153 [00:02<00:00, 52.21it/s, Epoch: 92, Batch: 118,Loss: -2.955,Avg.Loss: -3.039,LR: 8.31E-06]Training epoch 92:  77%|███████▋  | 118/153 [00:02<00:00, 52.21it/s, Epoch: 92, Batch: 119,Loss: -3.071,Avg.Loss: -3.040,LR: 8.29E-06]Training epoch 92:  78%|███████▊  | 119/153 [00:02<00:00, 52.21it/s, Epoch: 92, Batch: 120,Loss: -2.706,Avg.Loss: -3.037,LR: 8.28E-06]Training epoch 92:  78%|███████▊  | 120/153 [00:02<00:00, 52.54it/s, Epoch: 92, Batch: 120,Loss: -2.706,Avg.Loss: -3.037,LR: 8.28E-06]Training epoch 92:  78%|███████▊  | 120/153 [00:02<00:00, 52.54it/s, Epoch: 92, Batch: 121,Loss: -3.438,Avg.Loss: -3.040,LR: 8.27E-06]Training epoch 92:  79%|███████▉  | 121/153 [00:02<00:00, 52.54it/s, Epoch: 92, Batch: 122,Loss: -2.997,Avg.Loss: -3.040,LR: 8.25E-06]Training epoch 92:  80%|███████▉  | 122/153 [00:02<00:00, 52.54it/s, Epoch: 92, Batch: 123,Loss: -2.998,Avg.Loss: -3.039,LR: 8.24E-06]Training epoch 92:  80%|████████  | 123/153 [00:02<00:00, 52.54it/s, Epoch: 92, Batch: 124,Loss: -3.170,Avg.Loss: -3.041,LR: 8.23E-06]Training epoch 92:  81%|████████  | 124/153 [00:02<00:00, 52.54it/s, Epoch: 92, Batch: 125,Loss: -3.002,Avg.Loss: -3.040,LR: 8.22E-06]Training epoch 92:  82%|████████▏ | 125/153 [00:02<00:00, 52.54it/s, Epoch: 92, Batch: 126,Loss: -3.169,Avg.Loss: -3.041,LR: 8.20E-06]Training epoch 92:  82%|████████▏ | 126/153 [00:02<00:00, 52.63it/s, Epoch: 92, Batch: 126,Loss: -3.169,Avg.Loss: -3.041,LR: 8.20E-06]Training epoch 92:  82%|████████▏ | 126/153 [00:02<00:00, 52.63it/s, Epoch: 92, Batch: 127,Loss: -3.044,Avg.Loss: -3.041,LR: 8.19E-06]Training epoch 92:  83%|████████▎ | 127/153 [00:02<00:00, 52.63it/s, Epoch: 92, Batch: 128,Loss: -3.055,Avg.Loss: -3.041,LR: 8.18E-06]Training epoch 92:  84%|████████▎ | 128/153 [00:02<00:00, 52.63it/s, Epoch: 92, Batch: 129,Loss: -2.657,Avg.Loss: -3.038,LR: 8.16E-06]Training epoch 92:  84%|████████▍ | 129/153 [00:02<00:00, 52.63it/s, Epoch: 92, Batch: 130,Loss: -2.376,Avg.Loss: -3.033,LR: 8.15E-06]Training epoch 92:  85%|████████▍ | 130/153 [00:02<00:00, 52.63it/s, Epoch: 92, Batch: 131,Loss: -2.941,Avg.Loss: -3.033,LR: 8.14E-06]Training epoch 92:  86%|████████▌ | 131/153 [00:02<00:00, 52.63it/s, Epoch: 92, Batch: 132,Loss: -3.343,Avg.Loss: -3.035,LR: 8.12E-06]Training epoch 92:  86%|████████▋ | 132/153 [00:02<00:00, 52.67it/s, Epoch: 92, Batch: 132,Loss: -3.343,Avg.Loss: -3.035,LR: 8.12E-06]Training epoch 92:  86%|████████▋ | 132/153 [00:02<00:00, 52.67it/s, Epoch: 92, Batch: 133,Loss: -3.281,Avg.Loss: -3.037,LR: 8.11E-06]Training epoch 92:  87%|████████▋ | 133/153 [00:02<00:00, 52.67it/s, Epoch: 92, Batch: 134,Loss: -2.830,Avg.Loss: -3.035,LR: 8.10E-06]Training epoch 92:  88%|████████▊ | 134/153 [00:02<00:00, 52.67it/s, Epoch: 92, Batch: 135,Loss: -3.365,Avg.Loss: -3.038,LR: 8.09E-06]Training epoch 92:  88%|████████▊ | 135/153 [00:02<00:00, 52.67it/s, Epoch: 92, Batch: 136,Loss: -2.850,Avg.Loss: -3.036,LR: 8.07E-06]Training epoch 92:  89%|████████▉ | 136/153 [00:02<00:00, 52.67it/s, Epoch: 92, Batch: 137,Loss: -2.748,Avg.Loss: -3.034,LR: 8.06E-06]Training epoch 92:  90%|████████▉ | 137/153 [00:02<00:00, 52.67it/s, Epoch: 92, Batch: 138,Loss: -3.168,Avg.Loss: -3.035,LR: 8.05E-06]Training epoch 92:  90%|█████████ | 138/153 [00:02<00:00, 52.80it/s, Epoch: 92, Batch: 138,Loss: -3.168,Avg.Loss: -3.035,LR: 8.05E-06]Training epoch 92:  90%|█████████ | 138/153 [00:02<00:00, 52.80it/s, Epoch: 92, Batch: 139,Loss: -3.379,Avg.Loss: -3.038,LR: 8.03E-06]Training epoch 92:  91%|█████████ | 139/153 [00:02<00:00, 52.80it/s, Epoch: 92, Batch: 140,Loss: -3.068,Avg.Loss: -3.038,LR: 8.02E-06]Training epoch 92:  92%|█████████▏| 140/153 [00:02<00:00, 52.80it/s, Epoch: 92, Batch: 141,Loss: -3.052,Avg.Loss: -3.038,LR: 8.01E-06]Training epoch 92:  92%|█████████▏| 141/153 [00:02<00:00, 52.80it/s, Epoch: 92, Batch: 142,Loss: -3.150,Avg.Loss: -3.039,LR: 8.00E-06]Training epoch 92:  93%|█████████▎| 142/153 [00:02<00:00, 52.80it/s, Epoch: 92, Batch: 143,Loss: -3.230,Avg.Loss: -3.040,LR: 7.98E-06]Training epoch 92:  93%|█████████▎| 143/153 [00:02<00:00, 52.80it/s, Epoch: 92, Batch: 144,Loss: -3.405,Avg.Loss: -3.043,LR: 7.97E-06]Training epoch 92:  94%|█████████▍| 144/153 [00:02<00:00, 52.91it/s, Epoch: 92, Batch: 144,Loss: -3.405,Avg.Loss: -3.043,LR: 7.97E-06]Training epoch 92:  94%|█████████▍| 144/153 [00:02<00:00, 52.91it/s, Epoch: 92, Batch: 145,Loss: -2.910,Avg.Loss: -3.042,LR: 7.96E-06]Training epoch 92:  95%|█████████▍| 145/153 [00:02<00:00, 52.91it/s, Epoch: 92, Batch: 146,Loss: -3.193,Avg.Loss: -3.043,LR: 7.94E-06]Training epoch 92:  95%|█████████▌| 146/153 [00:02<00:00, 52.91it/s, Epoch: 92, Batch: 147,Loss: -3.171,Avg.Loss: -3.044,LR: 7.93E-06]Training epoch 92:  96%|█████████▌| 147/153 [00:02<00:00, 52.91it/s, Epoch: 92, Batch: 148,Loss: -2.756,Avg.Loss: -3.042,LR: 7.92E-06]Training epoch 92:  97%|█████████▋| 148/153 [00:02<00:00, 52.91it/s, Epoch: 92, Batch: 149,Loss: -3.129,Avg.Loss: -3.042,LR: 7.91E-06]Training epoch 92:  97%|█████████▋| 149/153 [00:02<00:00, 52.91it/s, Epoch: 92, Batch: 150,Loss: -3.096,Avg.Loss: -3.043,LR: 7.89E-06]Training epoch 92:  98%|█████████▊| 150/153 [00:02<00:00, 52.81it/s, Epoch: 92, Batch: 150,Loss: -3.096,Avg.Loss: -3.043,LR: 7.89E-06]Training epoch 92:  98%|█████████▊| 150/153 [00:02<00:00, 52.81it/s, Epoch: 92, Batch: 151,Loss: -2.957,Avg.Loss: -3.042,LR: 7.88E-06]Training epoch 92:  99%|█████████▊| 151/153 [00:02<00:00, 52.81it/s, Epoch: 92, Batch: 152,Loss: -2.875,Avg.Loss: -3.041,LR: 7.87E-06]Training epoch 92:  99%|█████████▉| 152/153 [00:02<00:00, 52.81it/s, Epoch: 92, Batch: 153,Loss: -3.289,Avg.Loss: -3.043,LR: 7.85E-06]Training epoch 92: 100%|██████████| 153/153 [00:02<00:00, 52.54it/s, Epoch: 92, Batch: 153,Loss: -3.289,Avg.Loss: -3.043,LR: 7.85E-06]
Training epoch 93:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 93:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 93, Batch: 1,Loss: -3.174,Avg.Loss: -3.174,LR: 7.84E-06]Training epoch 93:   1%|          | 1/153 [00:00<00:06, 24.64it/s, Epoch: 93, Batch: 2,Loss: -3.452,Avg.Loss: -3.313,LR: 7.83E-06]Training epoch 93:   1%|▏         | 2/153 [00:00<00:04, 37.13it/s, Epoch: 93, Batch: 3,Loss: -2.941,Avg.Loss: -3.189,LR: 7.82E-06]Training epoch 93:   2%|▏         | 3/153 [00:00<00:03, 41.78it/s, Epoch: 93, Batch: 4,Loss: -3.046,Avg.Loss: -3.153,LR: 7.80E-06]Training epoch 93:   3%|▎         | 4/153 [00:00<00:03, 44.51it/s, Epoch: 93, Batch: 5,Loss: -2.833,Avg.Loss: -3.089,LR: 7.79E-06]Training epoch 93:   3%|▎         | 5/153 [00:00<00:03, 46.17it/s, Epoch: 93, Batch: 6,Loss: -3.078,Avg.Loss: -3.087,LR: 7.78E-06]Training epoch 93:   4%|▍         | 6/153 [00:00<00:02, 55.31it/s, Epoch: 93, Batch: 6,Loss: -3.078,Avg.Loss: -3.087,LR: 7.78E-06]Training epoch 93:   4%|▍         | 6/153 [00:00<00:02, 55.31it/s, Epoch: 93, Batch: 7,Loss: -2.544,Avg.Loss: -3.010,LR: 7.77E-06]Training epoch 93:   5%|▍         | 7/153 [00:00<00:02, 55.31it/s, Epoch: 93, Batch: 8,Loss: -3.193,Avg.Loss: -3.032,LR: 7.75E-06]Training epoch 93:   5%|▌         | 8/153 [00:00<00:02, 55.31it/s, Epoch: 93, Batch: 9,Loss: -3.163,Avg.Loss: -3.047,LR: 7.74E-06]Training epoch 93:   6%|▌         | 9/153 [00:00<00:02, 55.31it/s, Epoch: 93, Batch: 10,Loss: -3.414,Avg.Loss: -3.084,LR: 7.73E-06]Training epoch 93:   7%|▋         | 10/153 [00:00<00:02, 55.31it/s, Epoch: 93, Batch: 11,Loss: -2.757,Avg.Loss: -3.054,LR: 7.71E-06]Training epoch 93:   7%|▋         | 11/153 [00:00<00:02, 55.31it/s, Epoch: 93, Batch: 12,Loss: -3.545,Avg.Loss: -3.095,LR: 7.70E-06]Training epoch 93:   8%|▊         | 12/153 [00:00<00:02, 53.70it/s, Epoch: 93, Batch: 12,Loss: -3.545,Avg.Loss: -3.095,LR: 7.70E-06]Training epoch 93:   8%|▊         | 12/153 [00:00<00:02, 53.70it/s, Epoch: 93, Batch: 13,Loss: -3.610,Avg.Loss: -3.134,LR: 7.69E-06]Training epoch 93:   8%|▊         | 13/153 [00:00<00:02, 53.70it/s, Epoch: 93, Batch: 14,Loss: -2.177,Avg.Loss: -3.066,LR: 7.68E-06]Training epoch 93:   9%|▉         | 14/153 [00:00<00:02, 53.70it/s, Epoch: 93, Batch: 15,Loss: -2.743,Avg.Loss: -3.045,LR: 7.66E-06]Training epoch 93:  10%|▉         | 15/153 [00:00<00:02, 53.70it/s, Epoch: 93, Batch: 16,Loss: -3.388,Avg.Loss: -3.066,LR: 7.65E-06]Training epoch 93:  10%|█         | 16/153 [00:00<00:02, 53.70it/s, Epoch: 93, Batch: 17,Loss: -3.076,Avg.Loss: -3.067,LR: 7.64E-06]Training epoch 93:  11%|█         | 17/153 [00:00<00:02, 53.70it/s, Epoch: 93, Batch: 18,Loss: -2.857,Avg.Loss: -3.055,LR: 7.63E-06]Training epoch 93:  12%|█▏        | 18/153 [00:00<00:02, 53.31it/s, Epoch: 93, Batch: 18,Loss: -2.857,Avg.Loss: -3.055,LR: 7.63E-06]Training epoch 93:  12%|█▏        | 18/153 [00:00<00:02, 53.31it/s, Epoch: 93, Batch: 19,Loss: -2.451,Avg.Loss: -3.023,LR: 7.61E-06]Training epoch 93:  12%|█▏        | 19/153 [00:00<00:02, 53.31it/s, Epoch: 93, Batch: 20,Loss: -2.612,Avg.Loss: -3.003,LR: 7.60E-06]Training epoch 93:  13%|█▎        | 20/153 [00:00<00:02, 53.31it/s, Epoch: 93, Batch: 21,Loss: -3.361,Avg.Loss: -3.020,LR: 7.59E-06]Training epoch 93:  14%|█▎        | 21/153 [00:00<00:02, 53.31it/s, Epoch: 93, Batch: 22,Loss: -2.979,Avg.Loss: -3.018,LR: 7.58E-06]Training epoch 93:  14%|█▍        | 22/153 [00:00<00:02, 53.31it/s, Epoch: 93, Batch: 23,Loss: -2.967,Avg.Loss: -3.016,LR: 7.56E-06]Training epoch 93:  15%|█▌        | 23/153 [00:00<00:02, 53.31it/s, Epoch: 93, Batch: 24,Loss: -3.528,Avg.Loss: -3.037,LR: 7.55E-06]Training epoch 93:  16%|█▌        | 24/153 [00:00<00:02, 51.97it/s, Epoch: 93, Batch: 24,Loss: -3.528,Avg.Loss: -3.037,LR: 7.55E-06]Training epoch 93:  16%|█▌        | 24/153 [00:00<00:02, 51.97it/s, Epoch: 93, Batch: 25,Loss: -2.283,Avg.Loss: -3.007,LR: 7.54E-06]Training epoch 93:  16%|█▋        | 25/153 [00:00<00:02, 51.97it/s, Epoch: 93, Batch: 26,Loss: -3.148,Avg.Loss: -3.012,LR: 7.53E-06]Training epoch 93:  17%|█▋        | 26/153 [00:00<00:02, 51.97it/s, Epoch: 93, Batch: 27,Loss: -3.821,Avg.Loss: -3.042,LR: 7.51E-06]Training epoch 93:  18%|█▊        | 27/153 [00:00<00:02, 51.97it/s, Epoch: 93, Batch: 28,Loss: -2.900,Avg.Loss: -3.037,LR: 7.50E-06]Training epoch 93:  18%|█▊        | 28/153 [00:00<00:02, 51.97it/s, Epoch: 93, Batch: 29,Loss: -3.091,Avg.Loss: -3.039,LR: 7.49E-06]Training epoch 93:  19%|█▉        | 29/153 [00:00<00:02, 51.97it/s, Epoch: 93, Batch: 30,Loss: -3.265,Avg.Loss: -3.046,LR: 7.48E-06]Training epoch 93:  20%|█▉        | 30/153 [00:00<00:02, 51.51it/s, Epoch: 93, Batch: 30,Loss: -3.265,Avg.Loss: -3.046,LR: 7.48E-06]Training epoch 93:  20%|█▉        | 30/153 [00:00<00:02, 51.51it/s, Epoch: 93, Batch: 31,Loss: -2.934,Avg.Loss: -3.043,LR: 7.46E-06]Training epoch 93:  20%|██        | 31/153 [00:00<00:02, 51.51it/s, Epoch: 93, Batch: 32,Loss: -3.038,Avg.Loss: -3.043,LR: 7.45E-06]Training epoch 93:  21%|██        | 32/153 [00:00<00:02, 51.51it/s, Epoch: 93, Batch: 33,Loss: -3.032,Avg.Loss: -3.042,LR: 7.44E-06]Training epoch 93:  22%|██▏       | 33/153 [00:00<00:02, 51.51it/s, Epoch: 93, Batch: 34,Loss: -2.672,Avg.Loss: -3.031,LR: 7.43E-06]Training epoch 93:  22%|██▏       | 34/153 [00:00<00:02, 51.51it/s, Epoch: 93, Batch: 35,Loss: -3.340,Avg.Loss: -3.040,LR: 7.41E-06]Training epoch 93:  23%|██▎       | 35/153 [00:00<00:02, 51.51it/s, Epoch: 93, Batch: 36,Loss: -2.981,Avg.Loss: -3.039,LR: 7.40E-06]Training epoch 93:  24%|██▎       | 36/153 [00:00<00:02, 52.35it/s, Epoch: 93, Batch: 36,Loss: -2.981,Avg.Loss: -3.039,LR: 7.40E-06]Training epoch 93:  24%|██▎       | 36/153 [00:00<00:02, 52.35it/s, Epoch: 93, Batch: 37,Loss: -3.332,Avg.Loss: -3.047,LR: 7.39E-06]Training epoch 93:  24%|██▍       | 37/153 [00:00<00:02, 52.35it/s, Epoch: 93, Batch: 38,Loss: -3.349,Avg.Loss: -3.054,LR: 7.38E-06]Training epoch 93:  25%|██▍       | 38/153 [00:00<00:02, 52.35it/s, Epoch: 93, Batch: 39,Loss: -3.069,Avg.Loss: -3.055,LR: 7.36E-06]Training epoch 93:  25%|██▌       | 39/153 [00:00<00:02, 52.35it/s, Epoch: 93, Batch: 40,Loss: -2.726,Avg.Loss: -3.047,LR: 7.35E-06]Training epoch 93:  26%|██▌       | 40/153 [00:00<00:02, 52.35it/s, Epoch: 93, Batch: 41,Loss: -3.502,Avg.Loss: -3.058,LR: 7.34E-06]Training epoch 93:  27%|██▋       | 41/153 [00:00<00:02, 52.35it/s, Epoch: 93, Batch: 42,Loss: -2.912,Avg.Loss: -3.054,LR: 7.33E-06]Training epoch 93:  27%|██▋       | 42/153 [00:00<00:02, 52.62it/s, Epoch: 93, Batch: 42,Loss: -2.912,Avg.Loss: -3.054,LR: 7.33E-06]Training epoch 93:  27%|██▋       | 42/153 [00:00<00:02, 52.62it/s, Epoch: 93, Batch: 43,Loss: -3.036,Avg.Loss: -3.054,LR: 7.31E-06]Training epoch 93:  28%|██▊       | 43/153 [00:00<00:02, 52.62it/s, Epoch: 93, Batch: 44,Loss: -2.929,Avg.Loss: -3.051,LR: 7.30E-06]Training epoch 93:  29%|██▉       | 44/153 [00:00<00:02, 52.62it/s, Epoch: 93, Batch: 45,Loss: -3.006,Avg.Loss: -3.050,LR: 7.29E-06]Training epoch 93:  29%|██▉       | 45/153 [00:00<00:02, 52.62it/s, Epoch: 93, Batch: 46,Loss: -3.527,Avg.Loss: -3.060,LR: 7.28E-06]Training epoch 93:  30%|███       | 46/153 [00:00<00:02, 52.62it/s, Epoch: 93, Batch: 47,Loss: -3.317,Avg.Loss: -3.066,LR: 7.27E-06]Training epoch 93:  31%|███       | 47/153 [00:00<00:02, 52.62it/s, Epoch: 93, Batch: 48,Loss: -3.151,Avg.Loss: -3.068,LR: 7.25E-06]Training epoch 93:  31%|███▏      | 48/153 [00:00<00:01, 52.83it/s, Epoch: 93, Batch: 48,Loss: -3.151,Avg.Loss: -3.068,LR: 7.25E-06]Training epoch 93:  31%|███▏      | 48/153 [00:00<00:01, 52.83it/s, Epoch: 93, Batch: 49,Loss: -3.108,Avg.Loss: -3.068,LR: 7.24E-06]Training epoch 93:  32%|███▏      | 49/153 [00:00<00:01, 52.83it/s, Epoch: 93, Batch: 50,Loss: -3.303,Avg.Loss: -3.073,LR: 7.23E-06]Training epoch 93:  33%|███▎      | 50/153 [00:00<00:01, 52.83it/s, Epoch: 93, Batch: 51,Loss: -2.563,Avg.Loss: -3.063,LR: 7.22E-06]Training epoch 93:  33%|███▎      | 51/153 [00:00<00:01, 52.83it/s, Epoch: 93, Batch: 52,Loss: -2.783,Avg.Loss: -3.058,LR: 7.20E-06]Training epoch 93:  34%|███▍      | 52/153 [00:01<00:01, 52.83it/s, Epoch: 93, Batch: 53,Loss: -2.514,Avg.Loss: -3.047,LR: 7.19E-06]Training epoch 93:  35%|███▍      | 53/153 [00:01<00:01, 52.83it/s, Epoch: 93, Batch: 54,Loss: -3.197,Avg.Loss: -3.050,LR: 7.18E-06]Training epoch 93:  35%|███▌      | 54/153 [00:01<00:01, 52.92it/s, Epoch: 93, Batch: 54,Loss: -3.197,Avg.Loss: -3.050,LR: 7.18E-06]Training epoch 93:  35%|███▌      | 54/153 [00:01<00:01, 52.92it/s, Epoch: 93, Batch: 55,Loss: -3.155,Avg.Loss: -3.052,LR: 7.17E-06]Training epoch 93:  36%|███▌      | 55/153 [00:01<00:01, 52.92it/s, Epoch: 93, Batch: 56,Loss: -2.918,Avg.Loss: -3.050,LR: 7.16E-06]Training epoch 93:  37%|███▋      | 56/153 [00:01<00:01, 52.92it/s, Epoch: 93, Batch: 57,Loss: -3.039,Avg.Loss: -3.050,LR: 7.14E-06]Training epoch 93:  37%|███▋      | 57/153 [00:01<00:01, 52.92it/s, Epoch: 93, Batch: 58,Loss: -2.831,Avg.Loss: -3.046,LR: 7.13E-06]Training epoch 93:  38%|███▊      | 58/153 [00:01<00:01, 52.92it/s, Epoch: 93, Batch: 59,Loss: -3.057,Avg.Loss: -3.046,LR: 7.12E-06]Training epoch 93:  39%|███▊      | 59/153 [00:01<00:01, 52.92it/s, Epoch: 93, Batch: 60,Loss: -3.118,Avg.Loss: -3.047,LR: 7.11E-06]Training epoch 93:  39%|███▉      | 60/153 [00:01<00:01, 52.86it/s, Epoch: 93, Batch: 60,Loss: -3.118,Avg.Loss: -3.047,LR: 7.11E-06]Training epoch 93:  39%|███▉      | 60/153 [00:01<00:01, 52.86it/s, Epoch: 93, Batch: 61,Loss: -3.247,Avg.Loss: -3.050,LR: 7.09E-06]Training epoch 93:  40%|███▉      | 61/153 [00:01<00:01, 52.86it/s, Epoch: 93, Batch: 62,Loss: -3.473,Avg.Loss: -3.057,LR: 7.08E-06]Training epoch 93:  41%|████      | 62/153 [00:01<00:01, 52.86it/s, Epoch: 93, Batch: 63,Loss: -3.125,Avg.Loss: -3.058,LR: 7.07E-06]Training epoch 93:  41%|████      | 63/153 [00:01<00:01, 52.86it/s, Epoch: 93, Batch: 64,Loss: -2.971,Avg.Loss: -3.057,LR: 7.06E-06]Training epoch 93:  42%|████▏     | 64/153 [00:01<00:01, 52.86it/s, Epoch: 93, Batch: 65,Loss: -3.495,Avg.Loss: -3.064,LR: 7.05E-06]Training epoch 93:  42%|████▏     | 65/153 [00:01<00:01, 52.86it/s, Epoch: 93, Batch: 66,Loss: -3.126,Avg.Loss: -3.065,LR: 7.03E-06]Training epoch 93:  43%|████▎     | 66/153 [00:01<00:01, 52.85it/s, Epoch: 93, Batch: 66,Loss: -3.126,Avg.Loss: -3.065,LR: 7.03E-06]Training epoch 93:  43%|████▎     | 66/153 [00:01<00:01, 52.85it/s, Epoch: 93, Batch: 67,Loss: -2.890,Avg.Loss: -3.062,LR: 7.02E-06]Training epoch 93:  44%|████▍     | 67/153 [00:01<00:01, 52.85it/s, Epoch: 93, Batch: 68,Loss: -2.648,Avg.Loss: -3.056,LR: 7.01E-06]Training epoch 93:  44%|████▍     | 68/153 [00:01<00:01, 52.85it/s, Epoch: 93, Batch: 69,Loss: -2.780,Avg.Loss: -3.052,LR: 7.00E-06]Training epoch 93:  45%|████▌     | 69/153 [00:01<00:01, 52.85it/s, Epoch: 93, Batch: 70,Loss: -3.426,Avg.Loss: -3.057,LR: 6.99E-06]Training epoch 93:  46%|████▌     | 70/153 [00:01<00:01, 52.85it/s, Epoch: 93, Batch: 71,Loss: -2.950,Avg.Loss: -3.056,LR: 6.97E-06]Training epoch 93:  46%|████▋     | 71/153 [00:01<00:01, 52.85it/s, Epoch: 93, Batch: 72,Loss: -2.821,Avg.Loss: -3.053,LR: 6.96E-06]Training epoch 93:  47%|████▋     | 72/153 [00:01<00:01, 52.76it/s, Epoch: 93, Batch: 72,Loss: -2.821,Avg.Loss: -3.053,LR: 6.96E-06]Training epoch 93:  47%|████▋     | 72/153 [00:01<00:01, 52.76it/s, Epoch: 93, Batch: 73,Loss: -2.973,Avg.Loss: -3.051,LR: 6.95E-06]Training epoch 93:  48%|████▊     | 73/153 [00:01<00:01, 52.76it/s, Epoch: 93, Batch: 74,Loss: -3.358,Avg.Loss: -3.056,LR: 6.94E-06]Training epoch 93:  48%|████▊     | 74/153 [00:01<00:01, 52.76it/s, Epoch: 93, Batch: 75,Loss: -3.188,Avg.Loss: -3.057,LR: 6.93E-06]Training epoch 93:  49%|████▉     | 75/153 [00:01<00:01, 52.76it/s, Epoch: 93, Batch: 76,Loss: -3.391,Avg.Loss: -3.062,LR: 6.91E-06]Training epoch 93:  50%|████▉     | 76/153 [00:01<00:01, 52.76it/s, Epoch: 93, Batch: 77,Loss: -3.335,Avg.Loss: -3.065,LR: 6.90E-06]Training epoch 93:  50%|█████     | 77/153 [00:01<00:01, 52.76it/s, Epoch: 93, Batch: 78,Loss: -3.003,Avg.Loss: -3.065,LR: 6.89E-06]Training epoch 93:  51%|█████     | 78/153 [00:01<00:01, 52.72it/s, Epoch: 93, Batch: 78,Loss: -3.003,Avg.Loss: -3.065,LR: 6.89E-06]Training epoch 93:  51%|█████     | 78/153 [00:01<00:01, 52.72it/s, Epoch: 93, Batch: 79,Loss: -2.802,Avg.Loss: -3.061,LR: 6.88E-06]Training epoch 93:  52%|█████▏    | 79/153 [00:01<00:01, 52.72it/s, Epoch: 93, Batch: 80,Loss: -2.806,Avg.Loss: -3.058,LR: 6.87E-06]Training epoch 93:  52%|█████▏    | 80/153 [00:01<00:01, 52.72it/s, Epoch: 93, Batch: 81,Loss: -3.099,Avg.Loss: -3.059,LR: 6.85E-06]Training epoch 93:  53%|█████▎    | 81/153 [00:01<00:01, 52.72it/s, Epoch: 93, Batch: 82,Loss: -2.967,Avg.Loss: -3.057,LR: 6.84E-06]Training epoch 93:  54%|█████▎    | 82/153 [00:01<00:01, 52.72it/s, Epoch: 93, Batch: 83,Loss: -3.246,Avg.Loss: -3.060,LR: 6.83E-06]Training epoch 93:  54%|█████▍    | 83/153 [00:01<00:01, 52.72it/s, Epoch: 93, Batch: 84,Loss: -3.057,Avg.Loss: -3.060,LR: 6.82E-06]Training epoch 93:  55%|█████▍    | 84/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 84,Loss: -3.057,Avg.Loss: -3.060,LR: 6.82E-06]Training epoch 93:  55%|█████▍    | 84/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 85,Loss: -3.024,Avg.Loss: -3.059,LR: 6.81E-06]Training epoch 93:  56%|█████▌    | 85/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 86,Loss: -2.406,Avg.Loss: -3.052,LR: 6.79E-06]Training epoch 93:  56%|█████▌    | 86/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 87,Loss: -2.795,Avg.Loss: -3.049,LR: 6.78E-06]Training epoch 93:  57%|█████▋    | 87/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 88,Loss: -3.028,Avg.Loss: -3.048,LR: 6.77E-06]Training epoch 93:  58%|█████▊    | 88/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 89,Loss: -3.202,Avg.Loss: -3.050,LR: 6.76E-06]Training epoch 93:  58%|█████▊    | 89/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 90,Loss: -3.156,Avg.Loss: -3.051,LR: 6.75E-06]Training epoch 93:  59%|█████▉    | 90/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 90,Loss: -3.156,Avg.Loss: -3.051,LR: 6.75E-06]Training epoch 93:  59%|█████▉    | 90/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 91,Loss: -2.731,Avg.Loss: -3.048,LR: 6.73E-06]Training epoch 93:  59%|█████▉    | 91/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 92,Loss: -2.740,Avg.Loss: -3.044,LR: 6.72E-06]Training epoch 93:  60%|██████    | 92/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 93,Loss: -2.956,Avg.Loss: -3.044,LR: 6.71E-06]Training epoch 93:  61%|██████    | 93/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 94,Loss: -3.014,Avg.Loss: -3.043,LR: 6.70E-06]Training epoch 93:  61%|██████▏   | 94/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 95,Loss: -3.521,Avg.Loss: -3.048,LR: 6.69E-06]Training epoch 93:  62%|██████▏   | 95/153 [00:01<00:01, 52.63it/s, Epoch: 93, Batch: 96,Loss: -3.308,Avg.Loss: -3.051,LR: 6.68E-06]Training epoch 93:  63%|██████▎   | 96/153 [00:01<00:01, 52.81it/s, Epoch: 93, Batch: 96,Loss: -3.308,Avg.Loss: -3.051,LR: 6.68E-06]Training epoch 93:  63%|██████▎   | 96/153 [00:01<00:01, 52.81it/s, Epoch: 93, Batch: 97,Loss: -3.093,Avg.Loss: -3.051,LR: 6.66E-06]Training epoch 93:  63%|██████▎   | 97/153 [00:01<00:01, 52.81it/s, Epoch: 93, Batch: 98,Loss: -2.649,Avg.Loss: -3.047,LR: 6.65E-06]Training epoch 93:  64%|██████▍   | 98/153 [00:01<00:01, 52.81it/s, Epoch: 93, Batch: 99,Loss: -2.799,Avg.Loss: -3.045,LR: 6.64E-06]Training epoch 93:  65%|██████▍   | 99/153 [00:01<00:01, 52.81it/s, Epoch: 93, Batch: 100,Loss: -2.900,Avg.Loss: -3.043,LR: 6.63E-06]Training epoch 93:  65%|██████▌   | 100/153 [00:01<00:01, 52.81it/s, Epoch: 93, Batch: 101,Loss: -2.890,Avg.Loss: -3.042,LR: 6.62E-06]Training epoch 93:  66%|██████▌   | 101/153 [00:01<00:00, 52.81it/s, Epoch: 93, Batch: 102,Loss: -3.099,Avg.Loss: -3.042,LR: 6.61E-06]Training epoch 93:  67%|██████▋   | 102/153 [00:01<00:00, 52.77it/s, Epoch: 93, Batch: 102,Loss: -3.099,Avg.Loss: -3.042,LR: 6.61E-06]Training epoch 93:  67%|██████▋   | 102/153 [00:01<00:00, 52.77it/s, Epoch: 93, Batch: 103,Loss: -2.901,Avg.Loss: -3.041,LR: 6.59E-06]Training epoch 93:  67%|██████▋   | 103/153 [00:01<00:00, 52.77it/s, Epoch: 93, Batch: 104,Loss: -3.375,Avg.Loss: -3.044,LR: 6.58E-06]Training epoch 93:  68%|██████▊   | 104/153 [00:01<00:00, 52.77it/s, Epoch: 93, Batch: 105,Loss: -3.537,Avg.Loss: -3.049,LR: 6.57E-06]Training epoch 93:  69%|██████▊   | 105/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 106,Loss: -2.918,Avg.Loss: -3.048,LR: 6.56E-06]Training epoch 93:  69%|██████▉   | 106/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 107,Loss: -3.026,Avg.Loss: -3.047,LR: 6.55E-06]Training epoch 93:  70%|██████▉   | 107/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 108,Loss: -2.930,Avg.Loss: -3.046,LR: 6.54E-06]Training epoch 93:  71%|███████   | 108/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 108,Loss: -2.930,Avg.Loss: -3.046,LR: 6.54E-06]Training epoch 93:  71%|███████   | 108/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 109,Loss: -2.929,Avg.Loss: -3.045,LR: 6.52E-06]Training epoch 93:  71%|███████   | 109/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 110,Loss: -3.103,Avg.Loss: -3.046,LR: 6.51E-06]Training epoch 93:  72%|███████▏  | 110/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 111,Loss: -3.349,Avg.Loss: -3.049,LR: 6.50E-06]Training epoch 93:  73%|███████▎  | 111/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 112,Loss: -3.298,Avg.Loss: -3.051,LR: 6.49E-06]Training epoch 93:  73%|███████▎  | 112/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 113,Loss: -2.932,Avg.Loss: -3.050,LR: 6.48E-06]Training epoch 93:  74%|███████▍  | 113/153 [00:02<00:00, 52.77it/s, Epoch: 93, Batch: 114,Loss: -2.898,Avg.Loss: -3.048,LR: 6.47E-06]Training epoch 93:  75%|███████▍  | 114/153 [00:02<00:00, 52.76it/s, Epoch: 93, Batch: 114,Loss: -2.898,Avg.Loss: -3.048,LR: 6.47E-06]Training epoch 93:  75%|███████▍  | 114/153 [00:02<00:00, 52.76it/s, Epoch: 93, Batch: 115,Loss: -3.503,Avg.Loss: -3.052,LR: 6.45E-06]Training epoch 93:  75%|███████▌  | 115/153 [00:02<00:00, 52.76it/s, Epoch: 93, Batch: 116,Loss: -2.729,Avg.Loss: -3.050,LR: 6.44E-06]Training epoch 93:  76%|███████▌  | 116/153 [00:02<00:00, 52.76it/s, Epoch: 93, Batch: 117,Loss: -3.632,Avg.Loss: -3.055,LR: 6.43E-06]Training epoch 93:  76%|███████▋  | 117/153 [00:02<00:00, 52.76it/s, Epoch: 93, Batch: 118,Loss: -3.086,Avg.Loss: -3.055,LR: 6.42E-06]Training epoch 93:  77%|███████▋  | 118/153 [00:02<00:00, 52.76it/s, Epoch: 93, Batch: 119,Loss: -2.606,Avg.Loss: -3.051,LR: 6.41E-06]Training epoch 93:  78%|███████▊  | 119/153 [00:02<00:00, 52.76it/s, Epoch: 93, Batch: 120,Loss: -2.677,Avg.Loss: -3.048,LR: 6.40E-06]Training epoch 93:  78%|███████▊  | 120/153 [00:02<00:00, 52.89it/s, Epoch: 93, Batch: 120,Loss: -2.677,Avg.Loss: -3.048,LR: 6.40E-06]Training epoch 93:  78%|███████▊  | 120/153 [00:02<00:00, 52.89it/s, Epoch: 93, Batch: 121,Loss: -3.570,Avg.Loss: -3.052,LR: 6.38E-06]Training epoch 93:  79%|███████▉  | 121/153 [00:02<00:00, 52.89it/s, Epoch: 93, Batch: 122,Loss: -3.028,Avg.Loss: -3.052,LR: 6.37E-06]Training epoch 93:  80%|███████▉  | 122/153 [00:02<00:00, 52.89it/s, Epoch: 93, Batch: 123,Loss: -2.678,Avg.Loss: -3.049,LR: 6.36E-06]Training epoch 93:  80%|████████  | 123/153 [00:02<00:00, 52.89it/s, Epoch: 93, Batch: 124,Loss: -2.991,Avg.Loss: -3.049,LR: 6.35E-06]Training epoch 93:  81%|████████  | 124/153 [00:02<00:00, 52.89it/s, Epoch: 93, Batch: 125,Loss: -3.272,Avg.Loss: -3.050,LR: 6.34E-06]Training epoch 93:  82%|████████▏ | 125/153 [00:02<00:00, 52.89it/s, Epoch: 93, Batch: 126,Loss: -3.116,Avg.Loss: -3.051,LR: 6.33E-06]Training epoch 93:  82%|████████▏ | 126/153 [00:02<00:00, 52.42it/s, Epoch: 93, Batch: 126,Loss: -3.116,Avg.Loss: -3.051,LR: 6.33E-06]Training epoch 93:  82%|████████▏ | 126/153 [00:02<00:00, 52.42it/s, Epoch: 93, Batch: 127,Loss: -2.918,Avg.Loss: -3.050,LR: 6.32E-06]Training epoch 93:  83%|████████▎ | 127/153 [00:02<00:00, 52.42it/s, Epoch: 93, Batch: 128,Loss: -3.277,Avg.Loss: -3.052,LR: 6.30E-06]Training epoch 93:  84%|████████▎ | 128/153 [00:02<00:00, 52.42it/s, Epoch: 93, Batch: 129,Loss: -2.618,Avg.Loss: -3.048,LR: 6.29E-06]Training epoch 93:  84%|████████▍ | 129/153 [00:02<00:00, 52.42it/s, Epoch: 93, Batch: 130,Loss: -3.286,Avg.Loss: -3.050,LR: 6.28E-06]Training epoch 93:  85%|████████▍ | 130/153 [00:02<00:00, 52.42it/s, Epoch: 93, Batch: 131,Loss: -2.999,Avg.Loss: -3.050,LR: 6.27E-06]Training epoch 93:  86%|████████▌ | 131/153 [00:02<00:00, 52.42it/s, Epoch: 93, Batch: 132,Loss: -3.098,Avg.Loss: -3.050,LR: 6.26E-06]Training epoch 93:  86%|████████▋ | 132/153 [00:02<00:00, 52.58it/s, Epoch: 93, Batch: 132,Loss: -3.098,Avg.Loss: -3.050,LR: 6.26E-06]Training epoch 93:  86%|████████▋ | 132/153 [00:02<00:00, 52.58it/s, Epoch: 93, Batch: 133,Loss: -2.972,Avg.Loss: -3.049,LR: 6.25E-06]Training epoch 93:  87%|████████▋ | 133/153 [00:02<00:00, 52.58it/s, Epoch: 93, Batch: 134,Loss: -3.175,Avg.Loss: -3.050,LR: 6.24E-06]Training epoch 93:  88%|████████▊ | 134/153 [00:02<00:00, 52.58it/s, Epoch: 93, Batch: 135,Loss: -3.073,Avg.Loss: -3.051,LR: 6.22E-06]Training epoch 93:  88%|████████▊ | 135/153 [00:02<00:00, 52.58it/s, Epoch: 93, Batch: 136,Loss: -2.992,Avg.Loss: -3.050,LR: 6.21E-06]Training epoch 93:  89%|████████▉ | 136/153 [00:02<00:00, 52.58it/s, Epoch: 93, Batch: 137,Loss: -3.104,Avg.Loss: -3.051,LR: 6.20E-06]Training epoch 93:  90%|████████▉ | 137/153 [00:02<00:00, 52.58it/s, Epoch: 93, Batch: 138,Loss: -3.049,Avg.Loss: -3.051,LR: 6.19E-06]Training epoch 93:  90%|█████████ | 138/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 138,Loss: -3.049,Avg.Loss: -3.051,LR: 6.19E-06]Training epoch 93:  90%|█████████ | 138/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 139,Loss: -2.934,Avg.Loss: -3.050,LR: 6.18E-06]Training epoch 93:  91%|█████████ | 139/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 140,Loss: -3.388,Avg.Loss: -3.052,LR: 6.17E-06]Training epoch 93:  92%|█████████▏| 140/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 141,Loss: -2.822,Avg.Loss: -3.050,LR: 6.16E-06]Training epoch 93:  92%|█████████▏| 141/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 142,Loss: -3.071,Avg.Loss: -3.051,LR: 6.14E-06]Training epoch 93:  93%|█████████▎| 142/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 143,Loss: -3.459,Avg.Loss: -3.053,LR: 6.13E-06]Training epoch 93:  93%|█████████▎| 143/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 144,Loss: -2.639,Avg.Loss: -3.051,LR: 6.12E-06]Training epoch 93:  94%|█████████▍| 144/153 [00:02<00:00, 52.90it/s, Epoch: 93, Batch: 144,Loss: -2.639,Avg.Loss: -3.051,LR: 6.12E-06]Training epoch 93:  94%|█████████▍| 144/153 [00:02<00:00, 52.90it/s, Epoch: 93, Batch: 145,Loss: -2.971,Avg.Loss: -3.050,LR: 6.11E-06]Training epoch 93:  95%|█████████▍| 145/153 [00:02<00:00, 52.90it/s, Epoch: 93, Batch: 146,Loss: -2.694,Avg.Loss: -3.048,LR: 6.10E-06]Training epoch 93:  95%|█████████▌| 146/153 [00:02<00:00, 52.90it/s, Epoch: 93, Batch: 147,Loss: -3.231,Avg.Loss: -3.049,LR: 6.09E-06]Training epoch 93:  96%|█████████▌| 147/153 [00:02<00:00, 52.90it/s, Epoch: 93, Batch: 148,Loss: -2.860,Avg.Loss: -3.048,LR: 6.08E-06]Training epoch 93:  97%|█████████▋| 148/153 [00:02<00:00, 52.90it/s, Epoch: 93, Batch: 149,Loss: -3.038,Avg.Loss: -3.047,LR: 6.07E-06]Training epoch 93:  97%|█████████▋| 149/153 [00:02<00:00, 52.90it/s, Epoch: 93, Batch: 150,Loss: -3.417,Avg.Loss: -3.050,LR: 6.05E-06]Training epoch 93:  98%|█████████▊| 150/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 150,Loss: -3.417,Avg.Loss: -3.050,LR: 6.05E-06]Training epoch 93:  98%|█████████▊| 150/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 151,Loss: -3.343,Avg.Loss: -3.052,LR: 6.04E-06]Training epoch 93:  99%|█████████▊| 151/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 152,Loss: -3.100,Avg.Loss: -3.052,LR: 6.03E-06]Training epoch 93:  99%|█████████▉| 152/153 [00:02<00:00, 52.75it/s, Epoch: 93, Batch: 153,Loss: -3.048,Avg.Loss: -3.052,LR: 6.02E-06]Training epoch 93: 100%|██████████| 153/153 [00:02<00:00, 52.69it/s, Epoch: 93, Batch: 153,Loss: -3.048,Avg.Loss: -3.052,LR: 6.02E-06]
Training epoch 94:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 94:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 94, Batch: 1,Loss: -3.307,Avg.Loss: -3.307,LR: 6.01E-06]Training epoch 94:   1%|          | 1/153 [00:00<00:05, 28.05it/s, Epoch: 94, Batch: 2,Loss: -3.135,Avg.Loss: -3.221,LR: 6.00E-06]Training epoch 94:   1%|▏         | 2/153 [00:00<00:03, 41.07it/s, Epoch: 94, Batch: 3,Loss: -3.084,Avg.Loss: -3.175,LR: 5.99E-06]Training epoch 94:   2%|▏         | 3/153 [00:00<00:03, 49.31it/s, Epoch: 94, Batch: 4,Loss: -2.785,Avg.Loss: -3.078,LR: 5.98E-06]Training epoch 94:   3%|▎         | 4/153 [00:00<00:02, 54.54it/s, Epoch: 94, Batch: 5,Loss: -3.114,Avg.Loss: -3.085,LR: 5.96E-06]Training epoch 94:   3%|▎         | 5/153 [00:00<00:02, 54.41it/s, Epoch: 94, Batch: 6,Loss: -2.594,Avg.Loss: -3.003,LR: 5.95E-06]Training epoch 94:   4%|▍         | 6/153 [00:00<00:02, 54.32it/s, Epoch: 94, Batch: 7,Loss: -2.722,Avg.Loss: -2.963,LR: 5.94E-06]Training epoch 94:   5%|▍         | 7/153 [00:00<00:02, 63.28it/s, Epoch: 94, Batch: 7,Loss: -2.722,Avg.Loss: -2.963,LR: 5.94E-06]Training epoch 94:   5%|▍         | 7/153 [00:00<00:02, 63.28it/s, Epoch: 94, Batch: 8,Loss: -2.466,Avg.Loss: -2.901,LR: 5.93E-06]Training epoch 94:   5%|▌         | 8/153 [00:00<00:02, 63.28it/s, Epoch: 94, Batch: 9,Loss: -3.086,Avg.Loss: -2.921,LR: 5.92E-06]Training epoch 94:   6%|▌         | 9/153 [00:00<00:02, 63.28it/s, Epoch: 94, Batch: 10,Loss: -2.840,Avg.Loss: -2.913,LR: 5.91E-06]Training epoch 94:   7%|▋         | 10/153 [00:00<00:02, 63.28it/s, Epoch: 94, Batch: 11,Loss: -2.976,Avg.Loss: -2.919,LR: 5.90E-06]Training epoch 94:   7%|▋         | 11/153 [00:00<00:02, 63.28it/s, Epoch: 94, Batch: 12,Loss: -3.380,Avg.Loss: -2.957,LR: 5.89E-06]Training epoch 94:   8%|▊         | 12/153 [00:00<00:02, 63.28it/s, Epoch: 94, Batch: 13,Loss: -3.059,Avg.Loss: -2.965,LR: 5.88E-06]Training epoch 94:   8%|▊         | 13/153 [00:00<00:02, 63.28it/s, Epoch: 94, Batch: 14,Loss: -2.676,Avg.Loss: -2.945,LR: 5.87E-06]Training epoch 94:   9%|▉         | 14/153 [00:00<00:02, 57.12it/s, Epoch: 94, Batch: 14,Loss: -2.676,Avg.Loss: -2.945,LR: 5.87E-06]Training epoch 94:   9%|▉         | 14/153 [00:00<00:02, 57.12it/s, Epoch: 94, Batch: 15,Loss: -3.432,Avg.Loss: -2.977,LR: 5.85E-06]Training epoch 94:  10%|▉         | 15/153 [00:00<00:02, 57.12it/s, Epoch: 94, Batch: 16,Loss: -2.788,Avg.Loss: -2.965,LR: 5.84E-06]Training epoch 94:  10%|█         | 16/153 [00:00<00:02, 57.12it/s, Epoch: 94, Batch: 17,Loss: -3.218,Avg.Loss: -2.980,LR: 5.83E-06]Training epoch 94:  11%|█         | 17/153 [00:00<00:02, 57.12it/s, Epoch: 94, Batch: 18,Loss: -3.416,Avg.Loss: -3.004,LR: 5.82E-06]Training epoch 94:  12%|█▏        | 18/153 [00:00<00:02, 57.12it/s, Epoch: 94, Batch: 19,Loss: -2.788,Avg.Loss: -2.993,LR: 5.81E-06]Training epoch 94:  12%|█▏        | 19/153 [00:00<00:02, 57.12it/s, Epoch: 94, Batch: 20,Loss: -3.574,Avg.Loss: -3.022,LR: 5.80E-06]Training epoch 94:  13%|█▎        | 20/153 [00:00<00:02, 55.68it/s, Epoch: 94, Batch: 20,Loss: -3.574,Avg.Loss: -3.022,LR: 5.80E-06]Training epoch 94:  13%|█▎        | 20/153 [00:00<00:02, 55.68it/s, Epoch: 94, Batch: 21,Loss: -2.931,Avg.Loss: -3.018,LR: 5.79E-06]Training epoch 94:  14%|█▎        | 21/153 [00:00<00:02, 55.68it/s, Epoch: 94, Batch: 22,Loss: -2.957,Avg.Loss: -3.015,LR: 5.78E-06]Training epoch 94:  14%|█▍        | 22/153 [00:00<00:02, 55.68it/s, Epoch: 94, Batch: 23,Loss: -3.231,Avg.Loss: -3.024,LR: 5.77E-06]Training epoch 94:  15%|█▌        | 23/153 [00:00<00:02, 55.68it/s, Epoch: 94, Batch: 24,Loss: -3.203,Avg.Loss: -3.032,LR: 5.76E-06]Training epoch 94:  16%|█▌        | 24/153 [00:00<00:02, 55.68it/s, Epoch: 94, Batch: 25,Loss: -3.055,Avg.Loss: -3.033,LR: 5.74E-06]Training epoch 94:  16%|█▋        | 25/153 [00:00<00:02, 55.68it/s, Epoch: 94, Batch: 26,Loss: -3.445,Avg.Loss: -3.049,LR: 5.73E-06]Training epoch 94:  17%|█▋        | 26/153 [00:00<00:02, 51.96it/s, Epoch: 94, Batch: 26,Loss: -3.445,Avg.Loss: -3.049,LR: 5.73E-06]Training epoch 94:  17%|█▋        | 26/153 [00:00<00:02, 51.96it/s, Epoch: 94, Batch: 27,Loss: -3.114,Avg.Loss: -3.051,LR: 5.72E-06]Training epoch 94:  18%|█▊        | 27/153 [00:00<00:02, 51.96it/s, Epoch: 94, Batch: 28,Loss: -2.939,Avg.Loss: -3.047,LR: 5.71E-06]Training epoch 94:  18%|█▊        | 28/153 [00:00<00:02, 51.96it/s, Epoch: 94, Batch: 29,Loss: -3.499,Avg.Loss: -3.063,LR: 5.70E-06]Training epoch 94:  19%|█▉        | 29/153 [00:00<00:02, 51.96it/s, Epoch: 94, Batch: 30,Loss: -3.246,Avg.Loss: -3.069,LR: 5.69E-06]Training epoch 94:  20%|█▉        | 30/153 [00:00<00:02, 51.96it/s, Epoch: 94, Batch: 31,Loss: -3.377,Avg.Loss: -3.079,LR: 5.68E-06]Training epoch 94:  20%|██        | 31/153 [00:00<00:02, 51.96it/s, Epoch: 94, Batch: 32,Loss: -2.846,Avg.Loss: -3.071,LR: 5.67E-06]Training epoch 94:  21%|██        | 32/153 [00:00<00:02, 52.09it/s, Epoch: 94, Batch: 32,Loss: -2.846,Avg.Loss: -3.071,LR: 5.67E-06]Training epoch 94:  21%|██        | 32/153 [00:00<00:02, 52.09it/s, Epoch: 94, Batch: 33,Loss: -3.222,Avg.Loss: -3.076,LR: 5.66E-06]Training epoch 94:  22%|██▏       | 33/153 [00:00<00:02, 52.09it/s, Epoch: 94, Batch: 34,Loss: -2.846,Avg.Loss: -3.069,LR: 5.65E-06]Training epoch 94:  22%|██▏       | 34/153 [00:00<00:02, 52.09it/s, Epoch: 94, Batch: 35,Loss: -2.776,Avg.Loss: -3.061,LR: 5.64E-06]Training epoch 94:  23%|██▎       | 35/153 [00:00<00:02, 52.09it/s, Epoch: 94, Batch: 36,Loss: -3.365,Avg.Loss: -3.069,LR: 5.62E-06]Training epoch 94:  24%|██▎       | 36/153 [00:00<00:02, 52.09it/s, Epoch: 94, Batch: 37,Loss: -2.990,Avg.Loss: -3.067,LR: 5.61E-06]Training epoch 94:  24%|██▍       | 37/153 [00:00<00:02, 52.09it/s, Epoch: 94, Batch: 38,Loss: -3.158,Avg.Loss: -3.069,LR: 5.60E-06]Training epoch 94:  25%|██▍       | 38/153 [00:00<00:02, 52.23it/s, Epoch: 94, Batch: 38,Loss: -3.158,Avg.Loss: -3.069,LR: 5.60E-06]Training epoch 94:  25%|██▍       | 38/153 [00:00<00:02, 52.23it/s, Epoch: 94, Batch: 39,Loss: -2.407,Avg.Loss: -3.052,LR: 5.59E-06]Training epoch 94:  25%|██▌       | 39/153 [00:00<00:02, 52.23it/s, Epoch: 94, Batch: 40,Loss: -3.436,Avg.Loss: -3.062,LR: 5.58E-06]Training epoch 94:  26%|██▌       | 40/153 [00:00<00:02, 52.23it/s, Epoch: 94, Batch: 41,Loss: -2.511,Avg.Loss: -3.049,LR: 5.57E-06]Training epoch 94:  27%|██▋       | 41/153 [00:00<00:02, 52.23it/s, Epoch: 94, Batch: 42,Loss: -3.077,Avg.Loss: -3.049,LR: 5.56E-06]Training epoch 94:  27%|██▋       | 42/153 [00:00<00:02, 52.23it/s, Epoch: 94, Batch: 43,Loss: -2.269,Avg.Loss: -3.031,LR: 5.55E-06]Training epoch 94:  28%|██▊       | 43/153 [00:00<00:02, 52.23it/s, Epoch: 94, Batch: 44,Loss: -2.716,Avg.Loss: -3.024,LR: 5.54E-06]Training epoch 94:  29%|██▉       | 44/153 [00:00<00:02, 52.57it/s, Epoch: 94, Batch: 44,Loss: -2.716,Avg.Loss: -3.024,LR: 5.54E-06]Training epoch 94:  29%|██▉       | 44/153 [00:00<00:02, 52.57it/s, Epoch: 94, Batch: 45,Loss: -3.290,Avg.Loss: -3.030,LR: 5.53E-06]Training epoch 94:  29%|██▉       | 45/153 [00:00<00:02, 52.57it/s, Epoch: 94, Batch: 46,Loss: -3.411,Avg.Loss: -3.038,LR: 5.52E-06]Training epoch 94:  30%|███       | 46/153 [00:00<00:02, 52.57it/s, Epoch: 94, Batch: 47,Loss: -2.957,Avg.Loss: -3.036,LR: 5.51E-06]Training epoch 94:  31%|███       | 47/153 [00:00<00:02, 52.57it/s, Epoch: 94, Batch: 48,Loss: -3.087,Avg.Loss: -3.037,LR: 5.50E-06]Training epoch 94:  31%|███▏      | 48/153 [00:00<00:01, 52.57it/s, Epoch: 94, Batch: 49,Loss: -3.070,Avg.Loss: -3.038,LR: 5.48E-06]Training epoch 94:  32%|███▏      | 49/153 [00:00<00:01, 52.57it/s, Epoch: 94, Batch: 50,Loss: -2.667,Avg.Loss: -3.031,LR: 5.47E-06]Training epoch 94:  33%|███▎      | 50/153 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 50,Loss: -2.667,Avg.Loss: -3.031,LR: 5.47E-06]Training epoch 94:  33%|███▎      | 50/153 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 51,Loss: -3.128,Avg.Loss: -3.033,LR: 5.46E-06]Training epoch 94:  33%|███▎      | 51/153 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 52,Loss: -3.376,Avg.Loss: -3.039,LR: 5.45E-06]Training epoch 94:  34%|███▍      | 52/153 [00:00<00:01, 52.52it/s, Epoch: 94, Batch: 53,Loss: -3.073,Avg.Loss: -3.040,LR: 5.44E-06]Training epoch 94:  35%|███▍      | 53/153 [00:01<00:01, 52.52it/s, Epoch: 94, Batch: 54,Loss: -3.095,Avg.Loss: -3.041,LR: 5.43E-06]Training epoch 94:  35%|███▌      | 54/153 [00:01<00:01, 52.52it/s, Epoch: 94, Batch: 55,Loss: -3.271,Avg.Loss: -3.045,LR: 5.42E-06]Training epoch 94:  36%|███▌      | 55/153 [00:01<00:01, 52.52it/s, Epoch: 94, Batch: 56,Loss: -2.405,Avg.Loss: -3.034,LR: 5.41E-06]Training epoch 94:  37%|███▋      | 56/153 [00:01<00:01, 52.65it/s, Epoch: 94, Batch: 56,Loss: -2.405,Avg.Loss: -3.034,LR: 5.41E-06]Training epoch 94:  37%|███▋      | 56/153 [00:01<00:01, 52.65it/s, Epoch: 94, Batch: 57,Loss: -2.693,Avg.Loss: -3.028,LR: 5.40E-06]Training epoch 94:  37%|███▋      | 57/153 [00:01<00:01, 52.65it/s, Epoch: 94, Batch: 58,Loss: -2.950,Avg.Loss: -3.026,LR: 5.39E-06]Training epoch 94:  38%|███▊      | 58/153 [00:01<00:01, 52.65it/s, Epoch: 94, Batch: 59,Loss: -2.944,Avg.Loss: -3.025,LR: 5.38E-06]Training epoch 94:  39%|███▊      | 59/153 [00:01<00:01, 52.65it/s, Epoch: 94, Batch: 60,Loss: -3.051,Avg.Loss: -3.025,LR: 5.37E-06]Training epoch 94:  39%|███▉      | 60/153 [00:01<00:01, 52.65it/s, Epoch: 94, Batch: 61,Loss: -2.801,Avg.Loss: -3.022,LR: 5.36E-06]Training epoch 94:  40%|███▉      | 61/153 [00:01<00:01, 52.65it/s, Epoch: 94, Batch: 62,Loss: -3.491,Avg.Loss: -3.029,LR: 5.35E-06]Training epoch 94:  41%|████      | 62/153 [00:01<00:01, 52.70it/s, Epoch: 94, Batch: 62,Loss: -3.491,Avg.Loss: -3.029,LR: 5.35E-06]Training epoch 94:  41%|████      | 62/153 [00:01<00:01, 52.70it/s, Epoch: 94, Batch: 63,Loss: -3.371,Avg.Loss: -3.035,LR: 5.34E-06]Training epoch 94:  41%|████      | 63/153 [00:01<00:01, 52.70it/s, Epoch: 94, Batch: 64,Loss: -3.060,Avg.Loss: -3.035,LR: 5.33E-06]Training epoch 94:  42%|████▏     | 64/153 [00:01<00:01, 52.70it/s, Epoch: 94, Batch: 65,Loss: -3.110,Avg.Loss: -3.036,LR: 5.31E-06]Training epoch 94:  42%|████▏     | 65/153 [00:01<00:01, 52.70it/s, Epoch: 94, Batch: 66,Loss: -2.848,Avg.Loss: -3.033,LR: 5.30E-06]Training epoch 94:  43%|████▎     | 66/153 [00:01<00:01, 52.70it/s, Epoch: 94, Batch: 67,Loss: -3.116,Avg.Loss: -3.035,LR: 5.29E-06]Training epoch 94:  44%|████▍     | 67/153 [00:01<00:01, 52.70it/s, Epoch: 94, Batch: 68,Loss: -2.727,Avg.Loss: -3.030,LR: 5.28E-06]Training epoch 94:  44%|████▍     | 68/153 [00:01<00:01, 52.62it/s, Epoch: 94, Batch: 68,Loss: -2.727,Avg.Loss: -3.030,LR: 5.28E-06]Training epoch 94:  44%|████▍     | 68/153 [00:01<00:01, 52.62it/s, Epoch: 94, Batch: 69,Loss: -3.060,Avg.Loss: -3.031,LR: 5.27E-06]Training epoch 94:  45%|████▌     | 69/153 [00:01<00:01, 52.62it/s, Epoch: 94, Batch: 70,Loss: -3.039,Avg.Loss: -3.031,LR: 5.26E-06]Training epoch 94:  46%|████▌     | 70/153 [00:01<00:01, 52.62it/s, Epoch: 94, Batch: 71,Loss: -3.083,Avg.Loss: -3.031,LR: 5.25E-06]Training epoch 94:  46%|████▋     | 71/153 [00:01<00:01, 52.62it/s, Epoch: 94, Batch: 72,Loss: -3.190,Avg.Loss: -3.034,LR: 5.24E-06]Training epoch 94:  47%|████▋     | 72/153 [00:01<00:01, 52.62it/s, Epoch: 94, Batch: 73,Loss: -2.886,Avg.Loss: -3.032,LR: 5.23E-06]Training epoch 94:  48%|████▊     | 73/153 [00:01<00:01, 52.62it/s, Epoch: 94, Batch: 74,Loss: -3.167,Avg.Loss: -3.033,LR: 5.22E-06]Training epoch 94:  48%|████▊     | 74/153 [00:01<00:01, 52.66it/s, Epoch: 94, Batch: 74,Loss: -3.167,Avg.Loss: -3.033,LR: 5.22E-06]Training epoch 94:  48%|████▊     | 74/153 [00:01<00:01, 52.66it/s, Epoch: 94, Batch: 75,Loss: -2.718,Avg.Loss: -3.029,LR: 5.21E-06]Training epoch 94:  49%|████▉     | 75/153 [00:01<00:01, 52.66it/s, Epoch: 94, Batch: 76,Loss: -2.990,Avg.Loss: -3.029,LR: 5.20E-06]Training epoch 94:  50%|████▉     | 76/153 [00:01<00:01, 52.66it/s, Epoch: 94, Batch: 77,Loss: -3.113,Avg.Loss: -3.030,LR: 5.19E-06]Training epoch 94:  50%|█████     | 77/153 [00:01<00:01, 52.66it/s, Epoch: 94, Batch: 78,Loss: -2.933,Avg.Loss: -3.029,LR: 5.18E-06]Training epoch 94:  51%|█████     | 78/153 [00:01<00:01, 52.66it/s, Epoch: 94, Batch: 79,Loss: -3.348,Avg.Loss: -3.033,LR: 5.17E-06]Training epoch 94:  52%|█████▏    | 79/153 [00:01<00:01, 52.66it/s, Epoch: 94, Batch: 80,Loss: -3.653,Avg.Loss: -3.040,LR: 5.16E-06]Training epoch 94:  52%|█████▏    | 80/153 [00:01<00:01, 52.82it/s, Epoch: 94, Batch: 80,Loss: -3.653,Avg.Loss: -3.040,LR: 5.16E-06]Training epoch 94:  52%|█████▏    | 80/153 [00:01<00:01, 52.82it/s, Epoch: 94, Batch: 81,Loss: -2.805,Avg.Loss: -3.037,LR: 5.15E-06]Training epoch 94:  53%|█████▎    | 81/153 [00:01<00:01, 52.82it/s, Epoch: 94, Batch: 82,Loss: -3.269,Avg.Loss: -3.040,LR: 5.14E-06]Training epoch 94:  54%|█████▎    | 82/153 [00:01<00:01, 52.82it/s, Epoch: 94, Batch: 83,Loss: -3.173,Avg.Loss: -3.042,LR: 5.13E-06]Training epoch 94:  54%|█████▍    | 83/153 [00:01<00:01, 52.82it/s, Epoch: 94, Batch: 84,Loss: -3.334,Avg.Loss: -3.045,LR: 5.12E-06]Training epoch 94:  55%|█████▍    | 84/153 [00:01<00:01, 52.82it/s, Epoch: 94, Batch: 85,Loss: -3.029,Avg.Loss: -3.045,LR: 5.11E-06]Training epoch 94:  56%|█████▌    | 85/153 [00:01<00:01, 52.82it/s, Epoch: 94, Batch: 86,Loss: -3.125,Avg.Loss: -3.046,LR: 5.10E-06]Training epoch 94:  56%|█████▌    | 86/153 [00:01<00:01, 52.91it/s, Epoch: 94, Batch: 86,Loss: -3.125,Avg.Loss: -3.046,LR: 5.10E-06]Training epoch 94:  56%|█████▌    | 86/153 [00:01<00:01, 52.91it/s, Epoch: 94, Batch: 87,Loss: -2.745,Avg.Loss: -3.043,LR: 5.09E-06]Training epoch 94:  57%|█████▋    | 87/153 [00:01<00:01, 52.91it/s, Epoch: 94, Batch: 88,Loss: -3.239,Avg.Loss: -3.045,LR: 5.08E-06]Training epoch 94:  58%|█████▊    | 88/153 [00:01<00:01, 52.91it/s, Epoch: 94, Batch: 89,Loss: -3.167,Avg.Loss: -3.046,LR: 5.06E-06]Training epoch 94:  58%|█████▊    | 89/153 [00:01<00:01, 52.91it/s, Epoch: 94, Batch: 90,Loss: -2.676,Avg.Loss: -3.042,LR: 5.05E-06]Training epoch 94:  59%|█████▉    | 90/153 [00:01<00:01, 52.91it/s, Epoch: 94, Batch: 91,Loss: -3.152,Avg.Loss: -3.043,LR: 5.04E-06]Training epoch 94:  59%|█████▉    | 91/153 [00:01<00:01, 52.91it/s, Epoch: 94, Batch: 92,Loss: -3.073,Avg.Loss: -3.044,LR: 5.03E-06]Training epoch 94:  60%|██████    | 92/153 [00:01<00:01, 52.75it/s, Epoch: 94, Batch: 92,Loss: -3.073,Avg.Loss: -3.044,LR: 5.03E-06]Training epoch 94:  60%|██████    | 92/153 [00:01<00:01, 52.75it/s, Epoch: 94, Batch: 93,Loss: -2.917,Avg.Loss: -3.042,LR: 5.02E-06]Training epoch 94:  61%|██████    | 93/153 [00:01<00:01, 52.75it/s, Epoch: 94, Batch: 94,Loss: -2.949,Avg.Loss: -3.041,LR: 5.01E-06]Training epoch 94:  61%|██████▏   | 94/153 [00:01<00:01, 52.75it/s, Epoch: 94, Batch: 95,Loss: -2.847,Avg.Loss: -3.039,LR: 5.00E-06]Training epoch 94:  62%|██████▏   | 95/153 [00:01<00:01, 52.75it/s, Epoch: 94, Batch: 96,Loss: -2.950,Avg.Loss: -3.038,LR: 4.99E-06]Training epoch 94:  63%|██████▎   | 96/153 [00:01<00:01, 52.75it/s, Epoch: 94, Batch: 97,Loss: -3.443,Avg.Loss: -3.042,LR: 4.98E-06]Training epoch 94:  63%|██████▎   | 97/153 [00:01<00:01, 52.75it/s, Epoch: 94, Batch: 98,Loss: -3.269,Avg.Loss: -3.045,LR: 4.97E-06]Training epoch 94:  64%|██████▍   | 98/153 [00:01<00:01, 52.80it/s, Epoch: 94, Batch: 98,Loss: -3.269,Avg.Loss: -3.045,LR: 4.97E-06]Training epoch 94:  64%|██████▍   | 98/153 [00:01<00:01, 52.80it/s, Epoch: 94, Batch: 99,Loss: -2.882,Avg.Loss: -3.043,LR: 4.96E-06]Training epoch 94:  65%|██████▍   | 99/153 [00:01<00:01, 52.80it/s, Epoch: 94, Batch: 100,Loss: -3.603,Avg.Loss: -3.049,LR: 4.95E-06]Training epoch 94:  65%|██████▌   | 100/153 [00:01<00:01, 52.80it/s, Epoch: 94, Batch: 101,Loss: -3.284,Avg.Loss: -3.051,LR: 4.94E-06]Training epoch 94:  66%|██████▌   | 101/153 [00:01<00:00, 52.80it/s, Epoch: 94, Batch: 102,Loss: -3.036,Avg.Loss: -3.051,LR: 4.93E-06]Training epoch 94:  67%|██████▋   | 102/153 [00:01<00:00, 52.80it/s, Epoch: 94, Batch: 103,Loss: -3.303,Avg.Loss: -3.053,LR: 4.92E-06]Training epoch 94:  67%|██████▋   | 103/153 [00:01<00:00, 52.80it/s, Epoch: 94, Batch: 104,Loss: -3.427,Avg.Loss: -3.057,LR: 4.91E-06]Training epoch 94:  68%|██████▊   | 104/153 [00:01<00:00, 52.08it/s, Epoch: 94, Batch: 104,Loss: -3.427,Avg.Loss: -3.057,LR: 4.91E-06]Training epoch 94:  68%|██████▊   | 104/153 [00:01<00:00, 52.08it/s, Epoch: 94, Batch: 105,Loss: -2.660,Avg.Loss: -3.053,LR: 4.90E-06]Training epoch 94:  69%|██████▊   | 105/153 [00:02<00:00, 52.08it/s, Epoch: 94, Batch: 106,Loss: -3.110,Avg.Loss: -3.054,LR: 4.89E-06]Training epoch 94:  69%|██████▉   | 106/153 [00:02<00:00, 52.08it/s, Epoch: 94, Batch: 107,Loss: -3.173,Avg.Loss: -3.055,LR: 4.88E-06]Training epoch 94:  70%|██████▉   | 107/153 [00:02<00:00, 52.08it/s, Epoch: 94, Batch: 108,Loss: -2.994,Avg.Loss: -3.054,LR: 4.87E-06]Training epoch 94:  71%|███████   | 108/153 [00:02<00:00, 52.08it/s, Epoch: 94, Batch: 109,Loss: -3.040,Avg.Loss: -3.054,LR: 4.86E-06]Training epoch 94:  71%|███████   | 109/153 [00:02<00:00, 52.08it/s, Epoch: 94, Batch: 110,Loss: -2.886,Avg.Loss: -3.053,LR: 4.85E-06]Training epoch 94:  72%|███████▏  | 110/153 [00:02<00:00, 52.37it/s, Epoch: 94, Batch: 110,Loss: -2.886,Avg.Loss: -3.053,LR: 4.85E-06]Training epoch 94:  72%|███████▏  | 110/153 [00:02<00:00, 52.37it/s, Epoch: 94, Batch: 111,Loss: -2.617,Avg.Loss: -3.049,LR: 4.84E-06]Training epoch 94:  73%|███████▎  | 111/153 [00:02<00:00, 52.37it/s, Epoch: 94, Batch: 112,Loss: -3.380,Avg.Loss: -3.052,LR: 4.83E-06]Training epoch 94:  73%|███████▎  | 112/153 [00:02<00:00, 52.37it/s, Epoch: 94, Batch: 113,Loss: -3.189,Avg.Loss: -3.053,LR: 4.82E-06]Training epoch 94:  74%|███████▍  | 113/153 [00:02<00:00, 52.37it/s, Epoch: 94, Batch: 114,Loss: -2.824,Avg.Loss: -3.051,LR: 4.81E-06]Training epoch 94:  75%|███████▍  | 114/153 [00:02<00:00, 52.37it/s, Epoch: 94, Batch: 115,Loss: -3.484,Avg.Loss: -3.055,LR: 4.80E-06]Training epoch 94:  75%|███████▌  | 115/153 [00:02<00:00, 52.37it/s, Epoch: 94, Batch: 116,Loss: -3.271,Avg.Loss: -3.057,LR: 4.79E-06]Training epoch 94:  76%|███████▌  | 116/153 [00:02<00:00, 52.47it/s, Epoch: 94, Batch: 116,Loss: -3.271,Avg.Loss: -3.057,LR: 4.79E-06]Training epoch 94:  76%|███████▌  | 116/153 [00:02<00:00, 52.47it/s, Epoch: 94, Batch: 117,Loss: -3.014,Avg.Loss: -3.056,LR: 4.78E-06]Training epoch 94:  76%|███████▋  | 117/153 [00:02<00:00, 52.47it/s, Epoch: 94, Batch: 118,Loss: -3.198,Avg.Loss: -3.057,LR: 4.77E-06]Training epoch 94:  77%|███████▋  | 118/153 [00:02<00:00, 52.47it/s, Epoch: 94, Batch: 119,Loss: -3.323,Avg.Loss: -3.060,LR: 4.76E-06]Training epoch 94:  78%|███████▊  | 119/153 [00:02<00:00, 52.47it/s, Epoch: 94, Batch: 120,Loss: -3.187,Avg.Loss: -3.061,LR: 4.75E-06]Training epoch 94:  78%|███████▊  | 120/153 [00:02<00:00, 52.47it/s, Epoch: 94, Batch: 121,Loss: -3.188,Avg.Loss: -3.062,LR: 4.74E-06]Training epoch 94:  79%|███████▉  | 121/153 [00:02<00:00, 52.47it/s, Epoch: 94, Batch: 122,Loss: -2.963,Avg.Loss: -3.061,LR: 4.73E-06]Training epoch 94:  80%|███████▉  | 122/153 [00:02<00:00, 52.60it/s, Epoch: 94, Batch: 122,Loss: -2.963,Avg.Loss: -3.061,LR: 4.73E-06]Training epoch 94:  80%|███████▉  | 122/153 [00:02<00:00, 52.60it/s, Epoch: 94, Batch: 123,Loss: -3.289,Avg.Loss: -3.063,LR: 4.72E-06]Training epoch 94:  80%|████████  | 123/153 [00:02<00:00, 52.60it/s, Epoch: 94, Batch: 124,Loss: -3.165,Avg.Loss: -3.064,LR: 4.71E-06]Training epoch 94:  81%|████████  | 124/153 [00:02<00:00, 52.60it/s, Epoch: 94, Batch: 125,Loss: -3.306,Avg.Loss: -3.066,LR: 4.70E-06]Training epoch 94:  82%|████████▏ | 125/153 [00:02<00:00, 52.60it/s, Epoch: 94, Batch: 126,Loss: -3.019,Avg.Loss: -3.065,LR: 4.69E-06]Training epoch 94:  82%|████████▏ | 126/153 [00:02<00:00, 52.60it/s, Epoch: 94, Batch: 127,Loss: -3.105,Avg.Loss: -3.065,LR: 4.68E-06]Training epoch 94:  83%|████████▎ | 127/153 [00:02<00:00, 52.60it/s, Epoch: 94, Batch: 128,Loss: -3.010,Avg.Loss: -3.065,LR: 4.67E-06]Training epoch 94:  84%|████████▎ | 128/153 [00:02<00:00, 52.77it/s, Epoch: 94, Batch: 128,Loss: -3.010,Avg.Loss: -3.065,LR: 4.67E-06]Training epoch 94:  84%|████████▎ | 128/153 [00:02<00:00, 52.77it/s, Epoch: 94, Batch: 129,Loss: -2.931,Avg.Loss: -3.064,LR: 4.66E-06]Training epoch 94:  84%|████████▍ | 129/153 [00:02<00:00, 52.77it/s, Epoch: 94, Batch: 130,Loss: -2.831,Avg.Loss: -3.062,LR: 4.65E-06]Training epoch 94:  85%|████████▍ | 130/153 [00:02<00:00, 52.77it/s, Epoch: 94, Batch: 131,Loss: -3.683,Avg.Loss: -3.067,LR: 4.64E-06]Training epoch 94:  86%|████████▌ | 131/153 [00:02<00:00, 52.77it/s, Epoch: 94, Batch: 132,Loss: -2.833,Avg.Loss: -3.065,LR: 4.63E-06]Training epoch 94:  86%|████████▋ | 132/153 [00:02<00:00, 52.77it/s, Epoch: 94, Batch: 133,Loss: -2.428,Avg.Loss: -3.060,LR: 4.62E-06]Training epoch 94:  87%|████████▋ | 133/153 [00:02<00:00, 52.77it/s, Epoch: 94, Batch: 134,Loss: -2.587,Avg.Loss: -3.057,LR: 4.61E-06]Training epoch 94:  88%|████████▊ | 134/153 [00:02<00:00, 52.97it/s, Epoch: 94, Batch: 134,Loss: -2.587,Avg.Loss: -3.057,LR: 4.61E-06]Training epoch 94:  88%|████████▊ | 134/153 [00:02<00:00, 52.97it/s, Epoch: 94, Batch: 135,Loss: -2.848,Avg.Loss: -3.055,LR: 4.60E-06]Training epoch 94:  88%|████████▊ | 135/153 [00:02<00:00, 52.97it/s, Epoch: 94, Batch: 136,Loss: -3.138,Avg.Loss: -3.056,LR: 4.59E-06]Training epoch 94:  89%|████████▉ | 136/153 [00:02<00:00, 52.97it/s, Epoch: 94, Batch: 137,Loss: -2.541,Avg.Loss: -3.052,LR: 4.58E-06]Training epoch 94:  90%|████████▉ | 137/153 [00:02<00:00, 52.97it/s, Epoch: 94, Batch: 138,Loss: -3.066,Avg.Loss: -3.052,LR: 4.57E-06]Training epoch 94:  90%|█████████ | 138/153 [00:02<00:00, 52.97it/s, Epoch: 94, Batch: 139,Loss: -3.221,Avg.Loss: -3.053,LR: 4.56E-06]Training epoch 94:  91%|█████████ | 139/153 [00:02<00:00, 52.97it/s, Epoch: 94, Batch: 140,Loss: -2.969,Avg.Loss: -3.053,LR: 4.55E-06]Training epoch 94:  92%|█████████▏| 140/153 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 140,Loss: -2.969,Avg.Loss: -3.053,LR: 4.55E-06]Training epoch 94:  92%|█████████▏| 140/153 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 141,Loss: -3.118,Avg.Loss: -3.053,LR: 4.54E-06]Training epoch 94:  92%|█████████▏| 141/153 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 142,Loss: -2.257,Avg.Loss: -3.048,LR: 4.53E-06]Training epoch 94:  93%|█████████▎| 142/153 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 143,Loss: -3.183,Avg.Loss: -3.049,LR: 4.52E-06]Training epoch 94:  93%|█████████▎| 143/153 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 144,Loss: -3.039,Avg.Loss: -3.049,LR: 4.52E-06]Training epoch 94:  94%|█████████▍| 144/153 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 145,Loss: -3.310,Avg.Loss: -3.050,LR: 4.51E-06]Training epoch 94:  95%|█████████▍| 145/153 [00:02<00:00, 53.03it/s, Epoch: 94, Batch: 146,Loss: -3.606,Avg.Loss: -3.054,LR: 4.50E-06]Training epoch 94:  95%|█████████▌| 146/153 [00:02<00:00, 53.07it/s, Epoch: 94, Batch: 146,Loss: -3.606,Avg.Loss: -3.054,LR: 4.50E-06]Training epoch 94:  95%|█████████▌| 146/153 [00:02<00:00, 53.07it/s, Epoch: 94, Batch: 147,Loss: -2.757,Avg.Loss: -3.052,LR: 4.49E-06]Training epoch 94:  96%|█████████▌| 147/153 [00:02<00:00, 53.07it/s, Epoch: 94, Batch: 148,Loss: -3.253,Avg.Loss: -3.054,LR: 4.48E-06]Training epoch 94:  97%|█████████▋| 148/153 [00:02<00:00, 53.07it/s, Epoch: 94, Batch: 149,Loss: -2.607,Avg.Loss: -3.051,LR: 4.47E-06]Training epoch 94:  97%|█████████▋| 149/153 [00:02<00:00, 53.07it/s, Epoch: 94, Batch: 150,Loss: -3.233,Avg.Loss: -3.052,LR: 4.46E-06]Training epoch 94:  98%|█████████▊| 150/153 [00:02<00:00, 53.07it/s, Epoch: 94, Batch: 151,Loss: -3.171,Avg.Loss: -3.053,LR: 4.45E-06]Training epoch 94:  99%|█████████▊| 151/153 [00:02<00:00, 53.07it/s, Epoch: 94, Batch: 152,Loss: -3.496,Avg.Loss: -3.055,LR: 4.44E-06]Training epoch 94:  99%|█████████▉| 152/153 [00:02<00:00, 52.80it/s, Epoch: 94, Batch: 152,Loss: -3.496,Avg.Loss: -3.055,LR: 4.44E-06]Training epoch 94:  99%|█████████▉| 152/153 [00:02<00:00, 52.80it/s, Epoch: 94, Batch: 153,Loss: -3.322,Avg.Loss: -3.057,LR: 4.43E-06]Training epoch 94: 100%|██████████| 153/153 [00:02<00:00, 52.88it/s, Epoch: 94, Batch: 153,Loss: -3.322,Avg.Loss: -3.057,LR: 4.43E-06]
Training epoch 95:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 95:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 95, Batch: 1,Loss: -2.485,Avg.Loss: -2.485,LR: 4.42E-06]Training epoch 95:   1%|          | 1/153 [00:00<00:06, 23.96it/s, Epoch: 95, Batch: 2,Loss: -2.685,Avg.Loss: -2.585,LR: 4.41E-06]Training epoch 95:   1%|▏         | 2/153 [00:00<00:04, 34.22it/s, Epoch: 95, Batch: 3,Loss: -3.285,Avg.Loss: -2.818,LR: 4.40E-06]Training epoch 95:   2%|▏         | 3/153 [00:00<00:03, 39.63it/s, Epoch: 95, Batch: 4,Loss: -2.888,Avg.Loss: -2.836,LR: 4.39E-06]Training epoch 95:   3%|▎         | 4/153 [00:00<00:03, 42.90it/s, Epoch: 95, Batch: 5,Loss: -3.657,Avg.Loss: -3.000,LR: 4.38E-06]Training epoch 95:   3%|▎         | 5/153 [00:00<00:03, 45.10it/s, Epoch: 95, Batch: 6,Loss: -3.135,Avg.Loss: -3.023,LR: 4.37E-06]Training epoch 95:   4%|▍         | 6/153 [00:00<00:02, 54.03it/s, Epoch: 95, Batch: 6,Loss: -3.135,Avg.Loss: -3.023,LR: 4.37E-06]Training epoch 95:   4%|▍         | 6/153 [00:00<00:02, 54.03it/s, Epoch: 95, Batch: 7,Loss: -2.981,Avg.Loss: -3.017,LR: 4.36E-06]Training epoch 95:   5%|▍         | 7/153 [00:00<00:02, 54.03it/s, Epoch: 95, Batch: 8,Loss: -3.207,Avg.Loss: -3.040,LR: 4.35E-06]Training epoch 95:   5%|▌         | 8/153 [00:00<00:02, 54.03it/s, Epoch: 95, Batch: 9,Loss: -2.839,Avg.Loss: -3.018,LR: 4.34E-06]Training epoch 95:   6%|▌         | 9/153 [00:00<00:02, 54.03it/s, Epoch: 95, Batch: 10,Loss: -3.130,Avg.Loss: -3.029,LR: 4.33E-06]Training epoch 95:   7%|▋         | 10/153 [00:00<00:02, 54.03it/s, Epoch: 95, Batch: 11,Loss: -2.713,Avg.Loss: -3.001,LR: 4.32E-06]Training epoch 95:   7%|▋         | 11/153 [00:00<00:02, 54.03it/s, Epoch: 95, Batch: 12,Loss: -3.106,Avg.Loss: -3.009,LR: 4.31E-06]Training epoch 95:   8%|▊         | 12/153 [00:00<00:02, 53.12it/s, Epoch: 95, Batch: 12,Loss: -3.106,Avg.Loss: -3.009,LR: 4.31E-06]Training epoch 95:   8%|▊         | 12/153 [00:00<00:02, 53.12it/s, Epoch: 95, Batch: 13,Loss: -3.340,Avg.Loss: -3.035,LR: 4.30E-06]Training epoch 95:   8%|▊         | 13/153 [00:00<00:02, 53.12it/s, Epoch: 95, Batch: 14,Loss: -3.034,Avg.Loss: -3.035,LR: 4.29E-06]Training epoch 95:   9%|▉         | 14/153 [00:00<00:02, 53.12it/s, Epoch: 95, Batch: 15,Loss: -2.876,Avg.Loss: -3.024,LR: 4.29E-06]Training epoch 95:  10%|▉         | 15/153 [00:00<00:02, 53.12it/s, Epoch: 95, Batch: 16,Loss: -3.146,Avg.Loss: -3.032,LR: 4.28E-06]Training epoch 95:  10%|█         | 16/153 [00:00<00:02, 53.12it/s, Epoch: 95, Batch: 17,Loss: -2.982,Avg.Loss: -3.029,LR: 4.27E-06]Training epoch 95:  11%|█         | 17/153 [00:00<00:02, 53.12it/s, Epoch: 95, Batch: 18,Loss: -2.828,Avg.Loss: -3.018,LR: 4.26E-06]Training epoch 95:  12%|█▏        | 18/153 [00:00<00:02, 53.23it/s, Epoch: 95, Batch: 18,Loss: -2.828,Avg.Loss: -3.018,LR: 4.26E-06]Training epoch 95:  12%|█▏        | 18/153 [00:00<00:02, 53.23it/s, Epoch: 95, Batch: 19,Loss: -2.898,Avg.Loss: -3.011,LR: 4.25E-06]Training epoch 95:  12%|█▏        | 19/153 [00:00<00:02, 53.23it/s, Epoch: 95, Batch: 20,Loss: -3.001,Avg.Loss: -3.011,LR: 4.24E-06]Training epoch 95:  13%|█▎        | 20/153 [00:00<00:02, 53.23it/s, Epoch: 95, Batch: 21,Loss: -3.330,Avg.Loss: -3.026,LR: 4.23E-06]Training epoch 95:  14%|█▎        | 21/153 [00:00<00:02, 53.23it/s, Epoch: 95, Batch: 22,Loss: -3.366,Avg.Loss: -3.042,LR: 4.22E-06]Training epoch 95:  14%|█▍        | 22/153 [00:00<00:02, 53.23it/s, Epoch: 95, Batch: 23,Loss: -3.472,Avg.Loss: -3.060,LR: 4.21E-06]Training epoch 95:  15%|█▌        | 23/153 [00:00<00:02, 53.23it/s, Epoch: 95, Batch: 24,Loss: -3.321,Avg.Loss: -3.071,LR: 4.20E-06]Training epoch 95:  16%|█▌        | 24/153 [00:00<00:02, 51.53it/s, Epoch: 95, Batch: 24,Loss: -3.321,Avg.Loss: -3.071,LR: 4.20E-06]Training epoch 95:  16%|█▌        | 24/153 [00:00<00:02, 51.53it/s, Epoch: 95, Batch: 25,Loss: -2.956,Avg.Loss: -3.066,LR: 4.19E-06]Training epoch 95:  16%|█▋        | 25/153 [00:00<00:02, 51.53it/s, Epoch: 95, Batch: 26,Loss: -2.661,Avg.Loss: -3.051,LR: 4.18E-06]Training epoch 95:  17%|█▋        | 26/153 [00:00<00:02, 51.53it/s, Epoch: 95, Batch: 27,Loss: -3.369,Avg.Loss: -3.063,LR: 4.17E-06]Training epoch 95:  18%|█▊        | 27/153 [00:00<00:02, 51.53it/s, Epoch: 95, Batch: 28,Loss: -3.073,Avg.Loss: -3.063,LR: 4.16E-06]Training epoch 95:  18%|█▊        | 28/153 [00:00<00:02, 51.53it/s, Epoch: 95, Batch: 29,Loss: -3.020,Avg.Loss: -3.062,LR: 4.15E-06]Training epoch 95:  19%|█▉        | 29/153 [00:00<00:02, 51.53it/s, Epoch: 95, Batch: 30,Loss: -2.684,Avg.Loss: -3.049,LR: 4.14E-06]Training epoch 95:  20%|█▉        | 30/153 [00:00<00:02, 51.60it/s, Epoch: 95, Batch: 30,Loss: -2.684,Avg.Loss: -3.049,LR: 4.14E-06]Training epoch 95:  20%|█▉        | 30/153 [00:00<00:02, 51.60it/s, Epoch: 95, Batch: 31,Loss: -2.775,Avg.Loss: -3.040,LR: 4.13E-06]Training epoch 95:  20%|██        | 31/153 [00:00<00:02, 51.60it/s, Epoch: 95, Batch: 32,Loss: -2.867,Avg.Loss: -3.035,LR: 4.13E-06]Training epoch 95:  21%|██        | 32/153 [00:00<00:02, 51.60it/s, Epoch: 95, Batch: 33,Loss: -2.517,Avg.Loss: -3.019,LR: 4.12E-06]Training epoch 95:  22%|██▏       | 33/153 [00:00<00:02, 51.60it/s, Epoch: 95, Batch: 34,Loss: -3.147,Avg.Loss: -3.023,LR: 4.11E-06]Training epoch 95:  22%|██▏       | 34/153 [00:00<00:02, 51.60it/s, Epoch: 95, Batch: 35,Loss: -3.148,Avg.Loss: -3.026,LR: 4.10E-06]Training epoch 95:  23%|██▎       | 35/153 [00:00<00:02, 51.60it/s, Epoch: 95, Batch: 36,Loss: -3.030,Avg.Loss: -3.026,LR: 4.09E-06]Training epoch 95:  24%|██▎       | 36/153 [00:00<00:02, 52.07it/s, Epoch: 95, Batch: 36,Loss: -3.030,Avg.Loss: -3.026,LR: 4.09E-06]Training epoch 95:  24%|██▎       | 36/153 [00:00<00:02, 52.07it/s, Epoch: 95, Batch: 37,Loss: -2.868,Avg.Loss: -3.022,LR: 4.08E-06]Training epoch 95:  24%|██▍       | 37/153 [00:00<00:02, 52.07it/s, Epoch: 95, Batch: 38,Loss: -2.955,Avg.Loss: -3.020,LR: 4.07E-06]Training epoch 95:  25%|██▍       | 38/153 [00:00<00:02, 52.07it/s, Epoch: 95, Batch: 39,Loss: -3.412,Avg.Loss: -3.030,LR: 4.06E-06]Training epoch 95:  25%|██▌       | 39/153 [00:00<00:02, 52.07it/s, Epoch: 95, Batch: 40,Loss: -2.864,Avg.Loss: -3.026,LR: 4.05E-06]Training epoch 95:  26%|██▌       | 40/153 [00:00<00:02, 52.07it/s, Epoch: 95, Batch: 41,Loss: -2.354,Avg.Loss: -3.010,LR: 4.04E-06]Training epoch 95:  27%|██▋       | 41/153 [00:00<00:02, 52.07it/s, Epoch: 95, Batch: 42,Loss: -2.702,Avg.Loss: -3.003,LR: 4.03E-06]Training epoch 95:  27%|██▋       | 42/153 [00:00<00:02, 52.22it/s, Epoch: 95, Batch: 42,Loss: -2.702,Avg.Loss: -3.003,LR: 4.03E-06]Training epoch 95:  27%|██▋       | 42/153 [00:00<00:02, 52.22it/s, Epoch: 95, Batch: 43,Loss: -3.184,Avg.Loss: -3.007,LR: 4.02E-06]Training epoch 95:  28%|██▊       | 43/153 [00:00<00:02, 52.22it/s, Epoch: 95, Batch: 44,Loss: -2.881,Avg.Loss: -3.004,LR: 4.01E-06]Training epoch 95:  29%|██▉       | 44/153 [00:00<00:02, 52.22it/s, Epoch: 95, Batch: 45,Loss: -3.355,Avg.Loss: -3.012,LR: 4.01E-06]Training epoch 95:  29%|██▉       | 45/153 [00:00<00:02, 52.22it/s, Epoch: 95, Batch: 46,Loss: -2.401,Avg.Loss: -2.998,LR: 4.00E-06]Training epoch 95:  30%|███       | 46/153 [00:00<00:02, 52.22it/s, Epoch: 95, Batch: 47,Loss: -2.857,Avg.Loss: -2.995,LR: 3.99E-06]Training epoch 95:  31%|███       | 47/153 [00:00<00:02, 52.22it/s, Epoch: 95, Batch: 48,Loss: -3.297,Avg.Loss: -3.002,LR: 3.98E-06]Training epoch 95:  31%|███▏      | 48/153 [00:00<00:01, 52.50it/s, Epoch: 95, Batch: 48,Loss: -3.297,Avg.Loss: -3.002,LR: 3.98E-06]Training epoch 95:  31%|███▏      | 48/153 [00:00<00:01, 52.50it/s, Epoch: 95, Batch: 49,Loss: -3.374,Avg.Loss: -3.009,LR: 3.97E-06]Training epoch 95:  32%|███▏      | 49/153 [00:00<00:01, 52.50it/s, Epoch: 95, Batch: 50,Loss: -2.902,Avg.Loss: -3.007,LR: 3.96E-06]Training epoch 95:  33%|███▎      | 50/153 [00:00<00:01, 52.50it/s, Epoch: 95, Batch: 51,Loss: -3.433,Avg.Loss: -3.016,LR: 3.95E-06]Training epoch 95:  33%|███▎      | 51/153 [00:00<00:01, 52.50it/s, Epoch: 95, Batch: 52,Loss: -2.544,Avg.Loss: -3.006,LR: 3.94E-06]Training epoch 95:  34%|███▍      | 52/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 53,Loss: -3.035,Avg.Loss: -3.007,LR: 3.93E-06]Training epoch 95:  35%|███▍      | 53/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 54,Loss: -3.092,Avg.Loss: -3.009,LR: 3.92E-06]Training epoch 95:  35%|███▌      | 54/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 54,Loss: -3.092,Avg.Loss: -3.009,LR: 3.92E-06]Training epoch 95:  35%|███▌      | 54/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 55,Loss: -3.315,Avg.Loss: -3.014,LR: 3.91E-06]Training epoch 95:  36%|███▌      | 55/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 56,Loss: -2.752,Avg.Loss: -3.010,LR: 3.91E-06]Training epoch 95:  37%|███▋      | 56/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 57,Loss: -3.038,Avg.Loss: -3.010,LR: 3.90E-06]Training epoch 95:  37%|███▋      | 57/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 58,Loss: -3.679,Avg.Loss: -3.022,LR: 3.89E-06]Training epoch 95:  38%|███▊      | 58/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 59,Loss: -2.991,Avg.Loss: -3.021,LR: 3.88E-06]Training epoch 95:  39%|███▊      | 59/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 60,Loss: -2.756,Avg.Loss: -3.017,LR: 3.87E-06]Training epoch 95:  39%|███▉      | 60/153 [00:01<00:01, 52.43it/s, Epoch: 95, Batch: 60,Loss: -2.756,Avg.Loss: -3.017,LR: 3.87E-06]Training epoch 95:  39%|███▉      | 60/153 [00:01<00:01, 52.43it/s, Epoch: 95, Batch: 61,Loss: -3.027,Avg.Loss: -3.017,LR: 3.86E-06]Training epoch 95:  40%|███▉      | 61/153 [00:01<00:01, 52.43it/s, Epoch: 95, Batch: 62,Loss: -2.798,Avg.Loss: -3.013,LR: 3.85E-06]Training epoch 95:  41%|████      | 62/153 [00:01<00:01, 52.43it/s, Epoch: 95, Batch: 63,Loss: -3.175,Avg.Loss: -3.016,LR: 3.84E-06]Training epoch 95:  41%|████      | 63/153 [00:01<00:01, 52.43it/s, Epoch: 95, Batch: 64,Loss: -2.884,Avg.Loss: -3.014,LR: 3.83E-06]Training epoch 95:  42%|████▏     | 64/153 [00:01<00:01, 52.43it/s, Epoch: 95, Batch: 65,Loss: -3.006,Avg.Loss: -3.014,LR: 3.82E-06]Training epoch 95:  42%|████▏     | 65/153 [00:01<00:01, 52.43it/s, Epoch: 95, Batch: 66,Loss: -2.939,Avg.Loss: -3.012,LR: 3.82E-06]Training epoch 95:  43%|████▎     | 66/153 [00:01<00:01, 52.27it/s, Epoch: 95, Batch: 66,Loss: -2.939,Avg.Loss: -3.012,LR: 3.82E-06]Training epoch 95:  43%|████▎     | 66/153 [00:01<00:01, 52.27it/s, Epoch: 95, Batch: 67,Loss: -3.785,Avg.Loss: -3.024,LR: 3.81E-06]Training epoch 95:  44%|████▍     | 67/153 [00:01<00:01, 52.27it/s, Epoch: 95, Batch: 68,Loss: -3.317,Avg.Loss: -3.028,LR: 3.80E-06]Training epoch 95:  44%|████▍     | 68/153 [00:01<00:01, 52.27it/s, Epoch: 95, Batch: 69,Loss: -3.296,Avg.Loss: -3.032,LR: 3.79E-06]Training epoch 95:  45%|████▌     | 69/153 [00:01<00:01, 52.27it/s, Epoch: 95, Batch: 70,Loss: -3.539,Avg.Loss: -3.039,LR: 3.78E-06]Training epoch 95:  46%|████▌     | 70/153 [00:01<00:01, 52.27it/s, Epoch: 95, Batch: 71,Loss: -3.168,Avg.Loss: -3.041,LR: 3.77E-06]Training epoch 95:  46%|████▋     | 71/153 [00:01<00:01, 52.27it/s, Epoch: 95, Batch: 72,Loss: -3.579,Avg.Loss: -3.049,LR: 3.76E-06]Training epoch 95:  47%|████▋     | 72/153 [00:01<00:01, 52.40it/s, Epoch: 95, Batch: 72,Loss: -3.579,Avg.Loss: -3.049,LR: 3.76E-06]Training epoch 95:  47%|████▋     | 72/153 [00:01<00:01, 52.40it/s, Epoch: 95, Batch: 73,Loss: -3.198,Avg.Loss: -3.051,LR: 3.75E-06]Training epoch 95:  48%|████▊     | 73/153 [00:01<00:01, 52.40it/s, Epoch: 95, Batch: 74,Loss: -3.467,Avg.Loss: -3.056,LR: 3.74E-06]Training epoch 95:  48%|████▊     | 74/153 [00:01<00:01, 52.40it/s, Epoch: 95, Batch: 75,Loss: -3.329,Avg.Loss: -3.060,LR: 3.74E-06]Training epoch 95:  49%|████▉     | 75/153 [00:01<00:01, 52.40it/s, Epoch: 95, Batch: 76,Loss: -3.300,Avg.Loss: -3.063,LR: 3.73E-06]Training epoch 95:  50%|████▉     | 76/153 [00:01<00:01, 52.40it/s, Epoch: 95, Batch: 77,Loss: -3.234,Avg.Loss: -3.065,LR: 3.72E-06]Training epoch 95:  50%|█████     | 77/153 [00:01<00:01, 52.40it/s, Epoch: 95, Batch: 78,Loss: -3.336,Avg.Loss: -3.069,LR: 3.71E-06]Training epoch 95:  51%|█████     | 78/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 78,Loss: -3.336,Avg.Loss: -3.069,LR: 3.71E-06]Training epoch 95:  51%|█████     | 78/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 79,Loss: -3.308,Avg.Loss: -3.072,LR: 3.70E-06]Training epoch 95:  52%|█████▏    | 79/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 80,Loss: -2.717,Avg.Loss: -3.067,LR: 3.69E-06]Training epoch 95:  52%|█████▏    | 80/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 81,Loss: -2.811,Avg.Loss: -3.064,LR: 3.68E-06]Training epoch 95:  53%|█████▎    | 81/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 82,Loss: -3.207,Avg.Loss: -3.066,LR: 3.67E-06]Training epoch 95:  54%|█████▎    | 82/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 83,Loss: -3.151,Avg.Loss: -3.067,LR: 3.67E-06]Training epoch 95:  54%|█████▍    | 83/153 [00:01<00:01, 52.50it/s, Epoch: 95, Batch: 84,Loss: -3.081,Avg.Loss: -3.067,LR: 3.66E-06]Training epoch 95:  55%|█████▍    | 84/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 84,Loss: -3.081,Avg.Loss: -3.067,LR: 3.66E-06]Training epoch 95:  55%|█████▍    | 84/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 85,Loss: -3.052,Avg.Loss: -3.067,LR: 3.65E-06]Training epoch 95:  56%|█████▌    | 85/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 86,Loss: -3.223,Avg.Loss: -3.069,LR: 3.64E-06]Training epoch 95:  56%|█████▌    | 86/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 87,Loss: -3.246,Avg.Loss: -3.071,LR: 3.63E-06]Training epoch 95:  57%|█████▋    | 87/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 88,Loss: -2.621,Avg.Loss: -3.066,LR: 3.62E-06]Training epoch 95:  58%|█████▊    | 88/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 89,Loss: -3.140,Avg.Loss: -3.067,LR: 3.61E-06]Training epoch 95:  58%|█████▊    | 89/153 [00:01<00:01, 52.62it/s, Epoch: 95, Batch: 90,Loss: -3.213,Avg.Loss: -3.068,LR: 3.60E-06]Training epoch 95:  59%|█████▉    | 90/153 [00:01<00:01, 52.68it/s, Epoch: 95, Batch: 90,Loss: -3.213,Avg.Loss: -3.068,LR: 3.60E-06]Training epoch 95:  59%|█████▉    | 90/153 [00:01<00:01, 52.68it/s, Epoch: 95, Batch: 91,Loss: -3.188,Avg.Loss: -3.070,LR: 3.60E-06]Training epoch 95:  59%|█████▉    | 91/153 [00:01<00:01, 52.68it/s, Epoch: 95, Batch: 92,Loss: -3.248,Avg.Loss: -3.071,LR: 3.59E-06]Training epoch 95:  60%|██████    | 92/153 [00:01<00:01, 52.68it/s, Epoch: 95, Batch: 93,Loss: -3.359,Avg.Loss: -3.075,LR: 3.58E-06]Training epoch 95:  61%|██████    | 93/153 [00:01<00:01, 52.68it/s, Epoch: 95, Batch: 94,Loss: -2.562,Avg.Loss: -3.069,LR: 3.57E-06]Training epoch 95:  61%|██████▏   | 94/153 [00:01<00:01, 52.68it/s, Epoch: 95, Batch: 95,Loss: -2.819,Avg.Loss: -3.066,LR: 3.56E-06]Training epoch 95:  62%|██████▏   | 95/153 [00:01<00:01, 52.68it/s, Epoch: 95, Batch: 96,Loss: -3.115,Avg.Loss: -3.067,LR: 3.55E-06]Training epoch 95:  63%|██████▎   | 96/153 [00:01<00:01, 52.67it/s, Epoch: 95, Batch: 96,Loss: -3.115,Avg.Loss: -3.067,LR: 3.55E-06]Training epoch 95:  63%|██████▎   | 96/153 [00:01<00:01, 52.67it/s, Epoch: 95, Batch: 97,Loss: -3.155,Avg.Loss: -3.068,LR: 3.54E-06]Training epoch 95:  63%|██████▎   | 97/153 [00:01<00:01, 52.67it/s, Epoch: 95, Batch: 98,Loss: -2.852,Avg.Loss: -3.066,LR: 3.54E-06]Training epoch 95:  64%|██████▍   | 98/153 [00:01<00:01, 52.67it/s, Epoch: 95, Batch: 99,Loss: -3.165,Avg.Loss: -3.067,LR: 3.53E-06]Training epoch 95:  65%|██████▍   | 99/153 [00:01<00:01, 52.67it/s, Epoch: 95, Batch: 100,Loss: -3.162,Avg.Loss: -3.068,LR: 3.52E-06]Training epoch 95:  65%|██████▌   | 100/153 [00:01<00:01, 52.67it/s, Epoch: 95, Batch: 101,Loss: -3.381,Avg.Loss: -3.071,LR: 3.51E-06]Training epoch 95:  66%|██████▌   | 101/153 [00:01<00:00, 52.67it/s, Epoch: 95, Batch: 102,Loss: -3.489,Avg.Loss: -3.075,LR: 3.50E-06]Training epoch 95:  67%|██████▋   | 102/153 [00:01<00:00, 52.72it/s, Epoch: 95, Batch: 102,Loss: -3.489,Avg.Loss: -3.075,LR: 3.50E-06]Training epoch 95:  67%|██████▋   | 102/153 [00:01<00:00, 52.72it/s, Epoch: 95, Batch: 103,Loss: -2.867,Avg.Loss: -3.073,LR: 3.49E-06]Training epoch 95:  67%|██████▋   | 103/153 [00:01<00:00, 52.72it/s, Epoch: 95, Batch: 104,Loss: -3.361,Avg.Loss: -3.076,LR: 3.48E-06]Training epoch 95:  68%|██████▊   | 104/153 [00:01<00:00, 52.72it/s, Epoch: 95, Batch: 105,Loss: -2.771,Avg.Loss: -3.073,LR: 3.48E-06]Training epoch 95:  69%|██████▊   | 105/153 [00:02<00:00, 52.72it/s, Epoch: 95, Batch: 106,Loss: -2.803,Avg.Loss: -3.070,LR: 3.47E-06]Training epoch 95:  69%|██████▉   | 106/153 [00:02<00:00, 52.72it/s, Epoch: 95, Batch: 107,Loss: -3.338,Avg.Loss: -3.073,LR: 3.46E-06]Training epoch 95:  70%|██████▉   | 107/153 [00:02<00:00, 52.72it/s, Epoch: 95, Batch: 108,Loss: -3.172,Avg.Loss: -3.074,LR: 3.45E-06]Training epoch 95:  71%|███████   | 108/153 [00:02<00:00, 52.95it/s, Epoch: 95, Batch: 108,Loss: -3.172,Avg.Loss: -3.074,LR: 3.45E-06]Training epoch 95:  71%|███████   | 108/153 [00:02<00:00, 52.95it/s, Epoch: 95, Batch: 109,Loss: -3.047,Avg.Loss: -3.073,LR: 3.44E-06]Training epoch 95:  71%|███████   | 109/153 [00:02<00:00, 52.95it/s, Epoch: 95, Batch: 110,Loss: -3.000,Avg.Loss: -3.073,LR: 3.43E-06]Training epoch 95:  72%|███████▏  | 110/153 [00:02<00:00, 52.95it/s, Epoch: 95, Batch: 111,Loss: -2.792,Avg.Loss: -3.070,LR: 3.42E-06]Training epoch 95:  73%|███████▎  | 111/153 [00:02<00:00, 52.95it/s, Epoch: 95, Batch: 112,Loss: -3.076,Avg.Loss: -3.070,LR: 3.42E-06]Training epoch 95:  73%|███████▎  | 112/153 [00:02<00:00, 52.95it/s, Epoch: 95, Batch: 113,Loss: -3.472,Avg.Loss: -3.074,LR: 3.41E-06]Training epoch 95:  74%|███████▍  | 113/153 [00:02<00:00, 52.95it/s, Epoch: 95, Batch: 114,Loss: -2.920,Avg.Loss: -3.072,LR: 3.40E-06]Training epoch 95:  75%|███████▍  | 114/153 [00:02<00:00, 53.01it/s, Epoch: 95, Batch: 114,Loss: -2.920,Avg.Loss: -3.072,LR: 3.40E-06]Training epoch 95:  75%|███████▍  | 114/153 [00:02<00:00, 53.01it/s, Epoch: 95, Batch: 115,Loss: -3.253,Avg.Loss: -3.074,LR: 3.39E-06]Training epoch 95:  75%|███████▌  | 115/153 [00:02<00:00, 53.01it/s, Epoch: 95, Batch: 116,Loss: -2.423,Avg.Loss: -3.068,LR: 3.38E-06]Training epoch 95:  76%|███████▌  | 116/153 [00:02<00:00, 53.01it/s, Epoch: 95, Batch: 117,Loss: -2.874,Avg.Loss: -3.067,LR: 3.37E-06]Training epoch 95:  76%|███████▋  | 117/153 [00:02<00:00, 53.01it/s, Epoch: 95, Batch: 118,Loss: -2.783,Avg.Loss: -3.064,LR: 3.37E-06]Training epoch 95:  77%|███████▋  | 118/153 [00:02<00:00, 53.01it/s, Epoch: 95, Batch: 119,Loss: -2.981,Avg.Loss: -3.064,LR: 3.36E-06]Training epoch 95:  78%|███████▊  | 119/153 [00:02<00:00, 53.01it/s, Epoch: 95, Batch: 120,Loss: -3.416,Avg.Loss: -3.067,LR: 3.35E-06]Training epoch 95:  78%|███████▊  | 120/153 [00:02<00:00, 52.84it/s, Epoch: 95, Batch: 120,Loss: -3.416,Avg.Loss: -3.067,LR: 3.35E-06]Training epoch 95:  78%|███████▊  | 120/153 [00:02<00:00, 52.84it/s, Epoch: 95, Batch: 121,Loss: -3.066,Avg.Loss: -3.067,LR: 3.34E-06]Training epoch 95:  79%|███████▉  | 121/153 [00:02<00:00, 52.84it/s, Epoch: 95, Batch: 122,Loss: -2.519,Avg.Loss: -3.062,LR: 3.33E-06]Training epoch 95:  80%|███████▉  | 122/153 [00:02<00:00, 52.84it/s, Epoch: 95, Batch: 123,Loss: -3.389,Avg.Loss: -3.065,LR: 3.32E-06]Training epoch 95:  80%|████████  | 123/153 [00:02<00:00, 52.84it/s, Epoch: 95, Batch: 124,Loss: -2.947,Avg.Loss: -3.064,LR: 3.32E-06]Training epoch 95:  81%|████████  | 124/153 [00:02<00:00, 52.84it/s, Epoch: 95, Batch: 125,Loss: -3.288,Avg.Loss: -3.066,LR: 3.31E-06]Training epoch 95:  82%|████████▏ | 125/153 [00:02<00:00, 52.84it/s, Epoch: 95, Batch: 126,Loss: -2.814,Avg.Loss: -3.064,LR: 3.30E-06]Training epoch 95:  82%|████████▏ | 126/153 [00:02<00:00, 52.83it/s, Epoch: 95, Batch: 126,Loss: -2.814,Avg.Loss: -3.064,LR: 3.30E-06]Training epoch 95:  82%|████████▏ | 126/153 [00:02<00:00, 52.83it/s, Epoch: 95, Batch: 127,Loss: -3.118,Avg.Loss: -3.064,LR: 3.29E-06]Training epoch 95:  83%|████████▎ | 127/153 [00:02<00:00, 52.83it/s, Epoch: 95, Batch: 128,Loss: -3.095,Avg.Loss: -3.064,LR: 3.28E-06]Training epoch 95:  84%|████████▎ | 128/153 [00:02<00:00, 52.83it/s, Epoch: 95, Batch: 129,Loss: -3.080,Avg.Loss: -3.064,LR: 3.27E-06]Training epoch 95:  84%|████████▍ | 129/153 [00:02<00:00, 52.83it/s, Epoch: 95, Batch: 130,Loss: -3.262,Avg.Loss: -3.066,LR: 3.27E-06]Training epoch 95:  85%|████████▍ | 130/153 [00:02<00:00, 52.83it/s, Epoch: 95, Batch: 131,Loss: -3.371,Avg.Loss: -3.068,LR: 3.26E-06]Training epoch 95:  86%|████████▌ | 131/153 [00:02<00:00, 52.83it/s, Epoch: 95, Batch: 132,Loss: -3.489,Avg.Loss: -3.071,LR: 3.25E-06]Training epoch 95:  86%|████████▋ | 132/153 [00:02<00:00, 53.14it/s, Epoch: 95, Batch: 132,Loss: -3.489,Avg.Loss: -3.071,LR: 3.25E-06]Training epoch 95:  86%|████████▋ | 132/153 [00:02<00:00, 53.14it/s, Epoch: 95, Batch: 133,Loss: -3.371,Avg.Loss: -3.074,LR: 3.24E-06]Training epoch 95:  87%|████████▋ | 133/153 [00:02<00:00, 53.14it/s, Epoch: 95, Batch: 134,Loss: -2.912,Avg.Loss: -3.072,LR: 3.23E-06]Training epoch 95:  88%|████████▊ | 134/153 [00:02<00:00, 53.14it/s, Epoch: 95, Batch: 135,Loss: -3.155,Avg.Loss: -3.073,LR: 3.22E-06]Training epoch 95:  88%|████████▊ | 135/153 [00:02<00:00, 53.14it/s, Epoch: 95, Batch: 136,Loss: -3.190,Avg.Loss: -3.074,LR: 3.22E-06]Training epoch 95:  89%|████████▉ | 136/153 [00:02<00:00, 53.14it/s, Epoch: 95, Batch: 137,Loss: -3.008,Avg.Loss: -3.073,LR: 3.21E-06]Training epoch 95:  90%|████████▉ | 137/153 [00:02<00:00, 53.14it/s, Epoch: 95, Batch: 138,Loss: -2.932,Avg.Loss: -3.072,LR: 3.20E-06]Training epoch 95:  90%|█████████ | 138/153 [00:02<00:00, 53.05it/s, Epoch: 95, Batch: 138,Loss: -2.932,Avg.Loss: -3.072,LR: 3.20E-06]Training epoch 95:  90%|█████████ | 138/153 [00:02<00:00, 53.05it/s, Epoch: 95, Batch: 139,Loss: -2.898,Avg.Loss: -3.071,LR: 3.19E-06]Training epoch 95:  91%|█████████ | 139/153 [00:02<00:00, 53.05it/s, Epoch: 95, Batch: 140,Loss: -3.199,Avg.Loss: -3.072,LR: 3.18E-06]Training epoch 95:  92%|█████████▏| 140/153 [00:02<00:00, 53.05it/s, Epoch: 95, Batch: 141,Loss: -2.966,Avg.Loss: -3.071,LR: 3.18E-06]Training epoch 95:  92%|█████████▏| 141/153 [00:02<00:00, 53.05it/s, Epoch: 95, Batch: 142,Loss: -3.164,Avg.Loss: -3.072,LR: 3.17E-06]Training epoch 95:  93%|█████████▎| 142/153 [00:02<00:00, 53.05it/s, Epoch: 95, Batch: 143,Loss: -2.825,Avg.Loss: -3.070,LR: 3.16E-06]Training epoch 95:  93%|█████████▎| 143/153 [00:02<00:00, 53.05it/s, Epoch: 95, Batch: 144,Loss: -3.116,Avg.Loss: -3.071,LR: 3.15E-06]Training epoch 95:  94%|█████████▍| 144/153 [00:02<00:00, 53.16it/s, Epoch: 95, Batch: 144,Loss: -3.116,Avg.Loss: -3.071,LR: 3.15E-06]Training epoch 95:  94%|█████████▍| 144/153 [00:02<00:00, 53.16it/s, Epoch: 95, Batch: 145,Loss: -2.765,Avg.Loss: -3.068,LR: 3.14E-06]Training epoch 95:  95%|█████████▍| 145/153 [00:02<00:00, 53.16it/s, Epoch: 95, Batch: 146,Loss: -3.082,Avg.Loss: -3.069,LR: 3.13E-06]Training epoch 95:  95%|█████████▌| 146/153 [00:02<00:00, 53.16it/s, Epoch: 95, Batch: 147,Loss: -2.514,Avg.Loss: -3.065,LR: 3.13E-06]Training epoch 95:  96%|█████████▌| 147/153 [00:02<00:00, 53.16it/s, Epoch: 95, Batch: 148,Loss: -3.067,Avg.Loss: -3.065,LR: 3.12E-06]Training epoch 95:  97%|█████████▋| 148/153 [00:02<00:00, 53.16it/s, Epoch: 95, Batch: 149,Loss: -3.056,Avg.Loss: -3.065,LR: 3.11E-06]Training epoch 95:  97%|█████████▋| 149/153 [00:02<00:00, 53.16it/s, Epoch: 95, Batch: 150,Loss: -2.944,Avg.Loss: -3.064,LR: 3.10E-06]Training epoch 95:  98%|█████████▊| 150/153 [00:02<00:00, 53.28it/s, Epoch: 95, Batch: 150,Loss: -2.944,Avg.Loss: -3.064,LR: 3.10E-06]Training epoch 95:  98%|█████████▊| 150/153 [00:02<00:00, 53.28it/s, Epoch: 95, Batch: 151,Loss: -3.035,Avg.Loss: -3.064,LR: 3.09E-06]Training epoch 95:  99%|█████████▊| 151/153 [00:02<00:00, 53.28it/s, Epoch: 95, Batch: 152,Loss: -3.029,Avg.Loss: -3.063,LR: 3.09E-06]Training epoch 95:  99%|█████████▉| 152/153 [00:02<00:00, 53.28it/s, Epoch: 95, Batch: 153,Loss: -2.924,Avg.Loss: -3.063,LR: 3.08E-06]Training epoch 95: 100%|██████████| 153/153 [00:02<00:00, 52.68it/s, Epoch: 95, Batch: 153,Loss: -2.924,Avg.Loss: -3.063,LR: 3.08E-06]
Training epoch 96:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 96:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 96, Batch: 1,Loss: -3.047,Avg.Loss: -3.047,LR: 3.07E-06]Training epoch 96:   1%|          | 1/153 [00:00<00:06, 24.41it/s, Epoch: 96, Batch: 2,Loss: -2.833,Avg.Loss: -2.940,LR: 3.06E-06]Training epoch 96:   1%|▏         | 2/153 [00:00<00:04, 34.34it/s, Epoch: 96, Batch: 3,Loss: -2.546,Avg.Loss: -2.809,LR: 3.05E-06]Training epoch 96:   2%|▏         | 3/153 [00:00<00:03, 38.98it/s, Epoch: 96, Batch: 4,Loss: -3.334,Avg.Loss: -2.940,LR: 3.05E-06]Training epoch 96:   3%|▎         | 4/153 [00:00<00:03, 41.62it/s, Epoch: 96, Batch: 5,Loss: -2.715,Avg.Loss: -2.895,LR: 3.04E-06]Training epoch 96:   3%|▎         | 5/153 [00:00<00:03, 43.35it/s, Epoch: 96, Batch: 6,Loss: -2.861,Avg.Loss: -2.889,LR: 3.03E-06]Training epoch 96:   4%|▍         | 6/153 [00:00<00:02, 51.94it/s, Epoch: 96, Batch: 6,Loss: -2.861,Avg.Loss: -2.889,LR: 3.03E-06]Training epoch 96:   4%|▍         | 6/153 [00:00<00:02, 51.94it/s, Epoch: 96, Batch: 7,Loss: -2.774,Avg.Loss: -2.873,LR: 3.02E-06]Training epoch 96:   5%|▍         | 7/153 [00:00<00:02, 51.94it/s, Epoch: 96, Batch: 8,Loss: -3.171,Avg.Loss: -2.910,LR: 3.01E-06]Training epoch 96:   5%|▌         | 8/153 [00:00<00:02, 51.94it/s, Epoch: 96, Batch: 9,Loss: -3.342,Avg.Loss: -2.958,LR: 3.01E-06]Training epoch 96:   6%|▌         | 9/153 [00:00<00:02, 51.94it/s, Epoch: 96, Batch: 10,Loss: -3.220,Avg.Loss: -2.984,LR: 3.00E-06]Training epoch 96:   7%|▋         | 10/153 [00:00<00:02, 51.94it/s, Epoch: 96, Batch: 11,Loss: -3.372,Avg.Loss: -3.020,LR: 2.99E-06]Training epoch 96:   7%|▋         | 11/153 [00:00<00:02, 51.94it/s, Epoch: 96, Batch: 12,Loss: -2.955,Avg.Loss: -3.014,LR: 2.98E-06]Training epoch 96:   8%|▊         | 12/153 [00:00<00:02, 51.85it/s, Epoch: 96, Batch: 12,Loss: -2.955,Avg.Loss: -3.014,LR: 2.98E-06]Training epoch 96:   8%|▊         | 12/153 [00:00<00:02, 51.85it/s, Epoch: 96, Batch: 13,Loss: -3.433,Avg.Loss: -3.046,LR: 2.97E-06]Training epoch 96:   8%|▊         | 13/153 [00:00<00:02, 51.85it/s, Epoch: 96, Batch: 14,Loss: -3.073,Avg.Loss: -3.048,LR: 2.97E-06]Training epoch 96:   9%|▉         | 14/153 [00:00<00:02, 51.85it/s, Epoch: 96, Batch: 15,Loss: -2.904,Avg.Loss: -3.039,LR: 2.96E-06]Training epoch 96:  10%|▉         | 15/153 [00:00<00:02, 51.85it/s, Epoch: 96, Batch: 16,Loss: -2.988,Avg.Loss: -3.036,LR: 2.95E-06]Training epoch 96:  10%|█         | 16/153 [00:00<00:02, 51.85it/s, Epoch: 96, Batch: 17,Loss: -3.382,Avg.Loss: -3.056,LR: 2.94E-06]Training epoch 96:  11%|█         | 17/153 [00:00<00:02, 51.85it/s, Epoch: 96, Batch: 18,Loss: -2.850,Avg.Loss: -3.045,LR: 2.94E-06]Training epoch 96:  12%|█▏        | 18/153 [00:00<00:02, 52.32it/s, Epoch: 96, Batch: 18,Loss: -2.850,Avg.Loss: -3.045,LR: 2.94E-06]Training epoch 96:  12%|█▏        | 18/153 [00:00<00:02, 52.32it/s, Epoch: 96, Batch: 19,Loss: -3.037,Avg.Loss: -3.044,LR: 2.93E-06]Training epoch 96:  12%|█▏        | 19/153 [00:00<00:02, 52.32it/s, Epoch: 96, Batch: 20,Loss: -3.094,Avg.Loss: -3.047,LR: 2.92E-06]Training epoch 96:  13%|█▎        | 20/153 [00:00<00:02, 52.32it/s, Epoch: 96, Batch: 21,Loss: -3.127,Avg.Loss: -3.050,LR: 2.91E-06]Training epoch 96:  14%|█▎        | 21/153 [00:00<00:02, 52.32it/s, Epoch: 96, Batch: 22,Loss: -2.246,Avg.Loss: -3.014,LR: 2.90E-06]Training epoch 96:  14%|█▍        | 22/153 [00:00<00:02, 52.32it/s, Epoch: 96, Batch: 23,Loss: -3.463,Avg.Loss: -3.033,LR: 2.90E-06]Training epoch 96:  15%|█▌        | 23/153 [00:00<00:02, 52.32it/s, Epoch: 96, Batch: 24,Loss: -3.527,Avg.Loss: -3.054,LR: 2.89E-06]Training epoch 96:  16%|█▌        | 24/153 [00:00<00:02, 52.39it/s, Epoch: 96, Batch: 24,Loss: -3.527,Avg.Loss: -3.054,LR: 2.89E-06]Training epoch 96:  16%|█▌        | 24/153 [00:00<00:02, 52.39it/s, Epoch: 96, Batch: 25,Loss: -3.224,Avg.Loss: -3.061,LR: 2.88E-06]Training epoch 96:  16%|█▋        | 25/153 [00:00<00:02, 52.39it/s, Epoch: 96, Batch: 26,Loss: -3.088,Avg.Loss: -3.062,LR: 2.87E-06]Training epoch 96:  17%|█▋        | 26/153 [00:00<00:02, 52.39it/s, Epoch: 96, Batch: 27,Loss: -2.986,Avg.Loss: -3.059,LR: 2.86E-06]Training epoch 96:  18%|█▊        | 27/153 [00:00<00:02, 52.39it/s, Epoch: 96, Batch: 28,Loss: -2.808,Avg.Loss: -3.050,LR: 2.86E-06]Training epoch 96:  18%|█▊        | 28/153 [00:00<00:02, 52.39it/s, Epoch: 96, Batch: 29,Loss: -3.500,Avg.Loss: -3.066,LR: 2.85E-06]Training epoch 96:  19%|█▉        | 29/153 [00:00<00:02, 52.39it/s, Epoch: 96, Batch: 30,Loss: -2.865,Avg.Loss: -3.059,LR: 2.84E-06]Training epoch 96:  20%|█▉        | 30/153 [00:00<00:02, 52.19it/s, Epoch: 96, Batch: 30,Loss: -2.865,Avg.Loss: -3.059,LR: 2.84E-06]Training epoch 96:  20%|█▉        | 30/153 [00:00<00:02, 52.19it/s, Epoch: 96, Batch: 31,Loss: -2.997,Avg.Loss: -3.057,LR: 2.83E-06]Training epoch 96:  20%|██        | 31/153 [00:00<00:02, 52.19it/s, Epoch: 96, Batch: 32,Loss: -3.398,Avg.Loss: -3.068,LR: 2.83E-06]Training epoch 96:  21%|██        | 32/153 [00:00<00:02, 52.19it/s, Epoch: 96, Batch: 33,Loss: -2.992,Avg.Loss: -3.065,LR: 2.82E-06]Training epoch 96:  22%|██▏       | 33/153 [00:00<00:02, 52.19it/s, Epoch: 96, Batch: 34,Loss: -2.909,Avg.Loss: -3.061,LR: 2.81E-06]Training epoch 96:  22%|██▏       | 34/153 [00:00<00:02, 52.19it/s, Epoch: 96, Batch: 35,Loss: -2.940,Avg.Loss: -3.057,LR: 2.80E-06]Training epoch 96:  23%|██▎       | 35/153 [00:00<00:02, 52.19it/s, Epoch: 96, Batch: 36,Loss: -2.979,Avg.Loss: -3.055,LR: 2.80E-06]Training epoch 96:  24%|██▎       | 36/153 [00:00<00:02, 52.25it/s, Epoch: 96, Batch: 36,Loss: -2.979,Avg.Loss: -3.055,LR: 2.80E-06]Training epoch 96:  24%|██▎       | 36/153 [00:00<00:02, 52.25it/s, Epoch: 96, Batch: 37,Loss: -2.878,Avg.Loss: -3.050,LR: 2.79E-06]Training epoch 96:  24%|██▍       | 37/153 [00:00<00:02, 52.25it/s, Epoch: 96, Batch: 38,Loss: -3.109,Avg.Loss: -3.052,LR: 2.78E-06]Training epoch 96:  25%|██▍       | 38/153 [00:00<00:02, 52.25it/s, Epoch: 96, Batch: 39,Loss: -3.089,Avg.Loss: -3.053,LR: 2.77E-06]Training epoch 96:  25%|██▌       | 39/153 [00:00<00:02, 52.25it/s, Epoch: 96, Batch: 40,Loss: -2.434,Avg.Loss: -3.037,LR: 2.77E-06]Training epoch 96:  26%|██▌       | 40/153 [00:00<00:02, 52.25it/s, Epoch: 96, Batch: 41,Loss: -2.902,Avg.Loss: -3.034,LR: 2.76E-06]Training epoch 96:  27%|██▋       | 41/153 [00:00<00:02, 52.25it/s, Epoch: 96, Batch: 42,Loss: -2.982,Avg.Loss: -3.033,LR: 2.75E-06]Training epoch 96:  27%|██▋       | 42/153 [00:00<00:02, 51.64it/s, Epoch: 96, Batch: 42,Loss: -2.982,Avg.Loss: -3.033,LR: 2.75E-06]Training epoch 96:  27%|██▋       | 42/153 [00:00<00:02, 51.64it/s, Epoch: 96, Batch: 43,Loss: -2.795,Avg.Loss: -3.027,LR: 2.74E-06]Training epoch 96:  28%|██▊       | 43/153 [00:00<00:02, 51.64it/s, Epoch: 96, Batch: 44,Loss: -3.084,Avg.Loss: -3.028,LR: 2.73E-06]Training epoch 96:  29%|██▉       | 44/153 [00:00<00:02, 51.64it/s, Epoch: 96, Batch: 45,Loss: -3.759,Avg.Loss: -3.045,LR: 2.73E-06]Training epoch 96:  29%|██▉       | 45/153 [00:00<00:02, 51.64it/s, Epoch: 96, Batch: 46,Loss: -2.964,Avg.Loss: -3.043,LR: 2.72E-06]Training epoch 96:  30%|███       | 46/153 [00:00<00:02, 51.64it/s, Epoch: 96, Batch: 47,Loss: -3.198,Avg.Loss: -3.046,LR: 2.71E-06]Training epoch 96:  31%|███       | 47/153 [00:00<00:02, 51.64it/s, Epoch: 96, Batch: 48,Loss: -3.237,Avg.Loss: -3.050,LR: 2.70E-06]Training epoch 96:  31%|███▏      | 48/153 [00:00<00:02, 52.15it/s, Epoch: 96, Batch: 48,Loss: -3.237,Avg.Loss: -3.050,LR: 2.70E-06]Training epoch 96:  31%|███▏      | 48/153 [00:00<00:02, 52.15it/s, Epoch: 96, Batch: 49,Loss: -2.949,Avg.Loss: -3.048,LR: 2.70E-06]Training epoch 96:  32%|███▏      | 49/153 [00:00<00:01, 52.15it/s, Epoch: 96, Batch: 50,Loss: -2.820,Avg.Loss: -3.044,LR: 2.69E-06]Training epoch 96:  33%|███▎      | 50/153 [00:00<00:01, 52.15it/s, Epoch: 96, Batch: 51,Loss: -3.098,Avg.Loss: -3.045,LR: 2.68E-06]Training epoch 96:  33%|███▎      | 51/153 [00:00<00:01, 52.15it/s, Epoch: 96, Batch: 52,Loss: -2.810,Avg.Loss: -3.040,LR: 2.67E-06]Training epoch 96:  34%|███▍      | 52/153 [00:01<00:01, 52.15it/s, Epoch: 96, Batch: 53,Loss: -3.146,Avg.Loss: -3.042,LR: 2.67E-06]Training epoch 96:  35%|███▍      | 53/153 [00:01<00:01, 52.15it/s, Epoch: 96, Batch: 54,Loss: -2.523,Avg.Loss: -3.033,LR: 2.66E-06]Training epoch 96:  35%|███▌      | 54/153 [00:01<00:01, 52.17it/s, Epoch: 96, Batch: 54,Loss: -2.523,Avg.Loss: -3.033,LR: 2.66E-06]Training epoch 96:  35%|███▌      | 54/153 [00:01<00:01, 52.17it/s, Epoch: 96, Batch: 55,Loss: -3.288,Avg.Loss: -3.037,LR: 2.65E-06]Training epoch 96:  36%|███▌      | 55/153 [00:01<00:01, 52.17it/s, Epoch: 96, Batch: 56,Loss: -3.254,Avg.Loss: -3.041,LR: 2.64E-06]Training epoch 96:  37%|███▋      | 56/153 [00:01<00:01, 52.17it/s, Epoch: 96, Batch: 57,Loss: -3.167,Avg.Loss: -3.043,LR: 2.64E-06]Training epoch 96:  37%|███▋      | 57/153 [00:01<00:01, 52.17it/s, Epoch: 96, Batch: 58,Loss: -2.653,Avg.Loss: -3.037,LR: 2.63E-06]Training epoch 96:  38%|███▊      | 58/153 [00:01<00:01, 52.17it/s, Epoch: 96, Batch: 59,Loss: -3.701,Avg.Loss: -3.048,LR: 2.62E-06]Training epoch 96:  39%|███▊      | 59/153 [00:01<00:01, 52.17it/s, Epoch: 96, Batch: 60,Loss: -2.984,Avg.Loss: -3.047,LR: 2.61E-06]Training epoch 96:  39%|███▉      | 60/153 [00:01<00:01, 52.31it/s, Epoch: 96, Batch: 60,Loss: -2.984,Avg.Loss: -3.047,LR: 2.61E-06]Training epoch 96:  39%|███▉      | 60/153 [00:01<00:01, 52.31it/s, Epoch: 96, Batch: 61,Loss: -2.936,Avg.Loss: -3.045,LR: 2.61E-06]Training epoch 96:  40%|███▉      | 61/153 [00:01<00:01, 52.31it/s, Epoch: 96, Batch: 62,Loss: -3.481,Avg.Loss: -3.052,LR: 2.60E-06]Training epoch 96:  41%|████      | 62/153 [00:01<00:01, 52.31it/s, Epoch: 96, Batch: 63,Loss: -3.209,Avg.Loss: -3.054,LR: 2.59E-06]Training epoch 96:  41%|████      | 63/153 [00:01<00:01, 52.31it/s, Epoch: 96, Batch: 64,Loss: -3.046,Avg.Loss: -3.054,LR: 2.59E-06]Training epoch 96:  42%|████▏     | 64/153 [00:01<00:01, 52.31it/s, Epoch: 96, Batch: 65,Loss: -2.801,Avg.Loss: -3.050,LR: 2.58E-06]Training epoch 96:  42%|████▏     | 65/153 [00:01<00:01, 52.31it/s, Epoch: 96, Batch: 66,Loss: -2.658,Avg.Loss: -3.044,LR: 2.57E-06]Training epoch 96:  43%|████▎     | 66/153 [00:01<00:01, 52.39it/s, Epoch: 96, Batch: 66,Loss: -2.658,Avg.Loss: -3.044,LR: 2.57E-06]Training epoch 96:  43%|████▎     | 66/153 [00:01<00:01, 52.39it/s, Epoch: 96, Batch: 67,Loss: -2.902,Avg.Loss: -3.042,LR: 2.56E-06]Training epoch 96:  44%|████▍     | 67/153 [00:01<00:01, 52.39it/s, Epoch: 96, Batch: 68,Loss: -2.943,Avg.Loss: -3.041,LR: 2.56E-06]Training epoch 96:  44%|████▍     | 68/153 [00:01<00:01, 52.39it/s, Epoch: 96, Batch: 69,Loss: -2.891,Avg.Loss: -3.039,LR: 2.55E-06]Training epoch 96:  45%|████▌     | 69/153 [00:01<00:01, 52.39it/s, Epoch: 96, Batch: 70,Loss: -3.327,Avg.Loss: -3.043,LR: 2.54E-06]Training epoch 96:  46%|████▌     | 70/153 [00:01<00:01, 52.39it/s, Epoch: 96, Batch: 71,Loss: -3.230,Avg.Loss: -3.045,LR: 2.53E-06]Training epoch 96:  46%|████▋     | 71/153 [00:01<00:01, 52.39it/s, Epoch: 96, Batch: 72,Loss: -3.651,Avg.Loss: -3.054,LR: 2.53E-06]Training epoch 96:  47%|████▋     | 72/153 [00:01<00:01, 52.64it/s, Epoch: 96, Batch: 72,Loss: -3.651,Avg.Loss: -3.054,LR: 2.53E-06]Training epoch 96:  47%|████▋     | 72/153 [00:01<00:01, 52.64it/s, Epoch: 96, Batch: 73,Loss: -2.660,Avg.Loss: -3.048,LR: 2.52E-06]Training epoch 96:  48%|████▊     | 73/153 [00:01<00:01, 52.64it/s, Epoch: 96, Batch: 74,Loss: -3.213,Avg.Loss: -3.051,LR: 2.51E-06]Training epoch 96:  48%|████▊     | 74/153 [00:01<00:01, 52.64it/s, Epoch: 96, Batch: 75,Loss: -3.007,Avg.Loss: -3.050,LR: 2.50E-06]Training epoch 96:  49%|████▉     | 75/153 [00:01<00:01, 52.64it/s, Epoch: 96, Batch: 76,Loss: -3.016,Avg.Loss: -3.050,LR: 2.50E-06]Training epoch 96:  50%|████▉     | 76/153 [00:01<00:01, 52.64it/s, Epoch: 96, Batch: 77,Loss: -3.056,Avg.Loss: -3.050,LR: 2.49E-06]Training epoch 96:  50%|█████     | 77/153 [00:01<00:01, 52.64it/s, Epoch: 96, Batch: 78,Loss: -3.197,Avg.Loss: -3.052,LR: 2.48E-06]Training epoch 96:  51%|█████     | 78/153 [00:01<00:01, 52.87it/s, Epoch: 96, Batch: 78,Loss: -3.197,Avg.Loss: -3.052,LR: 2.48E-06]Training epoch 96:  51%|█████     | 78/153 [00:01<00:01, 52.87it/s, Epoch: 96, Batch: 79,Loss: -3.611,Avg.Loss: -3.059,LR: 2.48E-06]Training epoch 96:  52%|█████▏    | 79/153 [00:01<00:01, 52.87it/s, Epoch: 96, Batch: 80,Loss: -3.029,Avg.Loss: -3.058,LR: 2.47E-06]Training epoch 96:  52%|█████▏    | 80/153 [00:01<00:01, 52.87it/s, Epoch: 96, Batch: 81,Loss: -2.739,Avg.Loss: -3.054,LR: 2.46E-06]Training epoch 96:  53%|█████▎    | 81/153 [00:01<00:01, 52.87it/s, Epoch: 96, Batch: 82,Loss: -3.098,Avg.Loss: -3.055,LR: 2.45E-06]Training epoch 96:  54%|█████▎    | 82/153 [00:01<00:01, 52.87it/s, Epoch: 96, Batch: 83,Loss: -2.935,Avg.Loss: -3.053,LR: 2.45E-06]Training epoch 96:  54%|█████▍    | 83/153 [00:01<00:01, 52.87it/s, Epoch: 96, Batch: 84,Loss: -3.128,Avg.Loss: -3.054,LR: 2.44E-06]Training epoch 96:  55%|█████▍    | 84/153 [00:01<00:01, 52.95it/s, Epoch: 96, Batch: 84,Loss: -3.128,Avg.Loss: -3.054,LR: 2.44E-06]Training epoch 96:  55%|█████▍    | 84/153 [00:01<00:01, 52.95it/s, Epoch: 96, Batch: 85,Loss: -3.492,Avg.Loss: -3.059,LR: 2.43E-06]Training epoch 96:  56%|█████▌    | 85/153 [00:01<00:01, 52.95it/s, Epoch: 96, Batch: 86,Loss: -3.077,Avg.Loss: -3.060,LR: 2.43E-06]Training epoch 96:  56%|█████▌    | 86/153 [00:01<00:01, 52.95it/s, Epoch: 96, Batch: 87,Loss: -3.202,Avg.Loss: -3.061,LR: 2.42E-06]Training epoch 96:  57%|█████▋    | 87/153 [00:01<00:01, 52.95it/s, Epoch: 96, Batch: 88,Loss: -3.139,Avg.Loss: -3.062,LR: 2.41E-06]Training epoch 96:  58%|█████▊    | 88/153 [00:01<00:01, 52.95it/s, Epoch: 96, Batch: 89,Loss: -3.024,Avg.Loss: -3.062,LR: 2.40E-06]Training epoch 96:  58%|█████▊    | 89/153 [00:01<00:01, 52.95it/s, Epoch: 96, Batch: 90,Loss: -3.058,Avg.Loss: -3.062,LR: 2.40E-06]Training epoch 96:  59%|█████▉    | 90/153 [00:01<00:01, 52.92it/s, Epoch: 96, Batch: 90,Loss: -3.058,Avg.Loss: -3.062,LR: 2.40E-06]Training epoch 96:  59%|█████▉    | 90/153 [00:01<00:01, 52.92it/s, Epoch: 96, Batch: 91,Loss: -2.554,Avg.Loss: -3.056,LR: 2.39E-06]Training epoch 96:  59%|█████▉    | 91/153 [00:01<00:01, 52.92it/s, Epoch: 96, Batch: 92,Loss: -3.066,Avg.Loss: -3.056,LR: 2.38E-06]Training epoch 96:  60%|██████    | 92/153 [00:01<00:01, 52.92it/s, Epoch: 96, Batch: 93,Loss: -2.738,Avg.Loss: -3.053,LR: 2.38E-06]Training epoch 96:  61%|██████    | 93/153 [00:01<00:01, 52.92it/s, Epoch: 96, Batch: 94,Loss: -3.169,Avg.Loss: -3.054,LR: 2.37E-06]Training epoch 96:  61%|██████▏   | 94/153 [00:01<00:01, 52.92it/s, Epoch: 96, Batch: 95,Loss: -2.678,Avg.Loss: -3.050,LR: 2.36E-06]Training epoch 96:  62%|██████▏   | 95/153 [00:01<00:01, 52.92it/s, Epoch: 96, Batch: 96,Loss: -2.774,Avg.Loss: -3.047,LR: 2.36E-06]Training epoch 96:  63%|██████▎   | 96/153 [00:01<00:01, 52.76it/s, Epoch: 96, Batch: 96,Loss: -2.774,Avg.Loss: -3.047,LR: 2.36E-06]Training epoch 96:  63%|██████▎   | 96/153 [00:01<00:01, 52.76it/s, Epoch: 96, Batch: 97,Loss: -3.176,Avg.Loss: -3.049,LR: 2.35E-06]Training epoch 96:  63%|██████▎   | 97/153 [00:01<00:01, 52.76it/s, Epoch: 96, Batch: 98,Loss: -2.793,Avg.Loss: -3.046,LR: 2.34E-06]Training epoch 96:  64%|██████▍   | 98/153 [00:01<00:01, 52.76it/s, Epoch: 96, Batch: 99,Loss: -3.377,Avg.Loss: -3.049,LR: 2.33E-06]Training epoch 96:  65%|██████▍   | 99/153 [00:01<00:01, 52.76it/s, Epoch: 96, Batch: 100,Loss: -2.690,Avg.Loss: -3.046,LR: 2.33E-06]Training epoch 96:  65%|██████▌   | 100/153 [00:01<00:01, 52.76it/s, Epoch: 96, Batch: 101,Loss: -2.958,Avg.Loss: -3.045,LR: 2.32E-06]Training epoch 96:  66%|██████▌   | 101/153 [00:01<00:00, 52.76it/s, Epoch: 96, Batch: 102,Loss: -3.071,Avg.Loss: -3.045,LR: 2.31E-06]Training epoch 96:  67%|██████▋   | 102/153 [00:01<00:00, 52.82it/s, Epoch: 96, Batch: 102,Loss: -3.071,Avg.Loss: -3.045,LR: 2.31E-06]Training epoch 96:  67%|██████▋   | 102/153 [00:01<00:00, 52.82it/s, Epoch: 96, Batch: 103,Loss: -3.245,Avg.Loss: -3.047,LR: 2.31E-06]Training epoch 96:  67%|██████▋   | 103/153 [00:01<00:00, 52.82it/s, Epoch: 96, Batch: 104,Loss: -3.186,Avg.Loss: -3.048,LR: 2.30E-06]Training epoch 96:  68%|██████▊   | 104/153 [00:01<00:00, 52.82it/s, Epoch: 96, Batch: 105,Loss: -3.110,Avg.Loss: -3.049,LR: 2.29E-06]Training epoch 96:  69%|██████▊   | 105/153 [00:02<00:00, 52.82it/s, Epoch: 96, Batch: 106,Loss: -3.368,Avg.Loss: -3.052,LR: 2.29E-06]Training epoch 96:  69%|██████▉   | 106/153 [00:02<00:00, 52.82it/s, Epoch: 96, Batch: 107,Loss: -3.085,Avg.Loss: -3.052,LR: 2.28E-06]Training epoch 96:  70%|██████▉   | 107/153 [00:02<00:00, 52.82it/s, Epoch: 96, Batch: 108,Loss: -3.426,Avg.Loss: -3.056,LR: 2.27E-06]Training epoch 96:  71%|███████   | 108/153 [00:02<00:00, 52.89it/s, Epoch: 96, Batch: 108,Loss: -3.426,Avg.Loss: -3.056,LR: 2.27E-06]Training epoch 96:  71%|███████   | 108/153 [00:02<00:00, 52.89it/s, Epoch: 96, Batch: 109,Loss: -3.192,Avg.Loss: -3.057,LR: 2.26E-06]Training epoch 96:  71%|███████   | 109/153 [00:02<00:00, 52.89it/s, Epoch: 96, Batch: 110,Loss: -3.463,Avg.Loss: -3.061,LR: 2.26E-06]Training epoch 96:  72%|███████▏  | 110/153 [00:02<00:00, 52.89it/s, Epoch: 96, Batch: 111,Loss: -3.221,Avg.Loss: -3.062,LR: 2.25E-06]Training epoch 96:  73%|███████▎  | 111/153 [00:02<00:00, 52.89it/s, Epoch: 96, Batch: 112,Loss: -3.269,Avg.Loss: -3.064,LR: 2.24E-06]Training epoch 96:  73%|███████▎  | 112/153 [00:02<00:00, 52.89it/s, Epoch: 96, Batch: 113,Loss: -3.085,Avg.Loss: -3.064,LR: 2.24E-06]Training epoch 96:  74%|███████▍  | 113/153 [00:02<00:00, 52.89it/s, Epoch: 96, Batch: 114,Loss: -2.731,Avg.Loss: -3.061,LR: 2.23E-06]Training epoch 96:  75%|███████▍  | 114/153 [00:02<00:00, 53.13it/s, Epoch: 96, Batch: 114,Loss: -2.731,Avg.Loss: -3.061,LR: 2.23E-06]Training epoch 96:  75%|███████▍  | 114/153 [00:02<00:00, 53.13it/s, Epoch: 96, Batch: 115,Loss: -2.715,Avg.Loss: -3.058,LR: 2.22E-06]Training epoch 96:  75%|███████▌  | 115/153 [00:02<00:00, 53.13it/s, Epoch: 96, Batch: 116,Loss: -3.088,Avg.Loss: -3.058,LR: 2.22E-06]Training epoch 96:  76%|███████▌  | 116/153 [00:02<00:00, 53.13it/s, Epoch: 96, Batch: 117,Loss: -3.519,Avg.Loss: -3.062,LR: 2.21E-06]Training epoch 96:  76%|███████▋  | 117/153 [00:02<00:00, 53.13it/s, Epoch: 96, Batch: 118,Loss: -3.219,Avg.Loss: -3.064,LR: 2.20E-06]Training epoch 96:  77%|███████▋  | 118/153 [00:02<00:00, 53.13it/s, Epoch: 96, Batch: 119,Loss: -2.924,Avg.Loss: -3.063,LR: 2.20E-06]Training epoch 96:  78%|███████▊  | 119/153 [00:02<00:00, 53.13it/s, Epoch: 96, Batch: 120,Loss: -3.113,Avg.Loss: -3.063,LR: 2.19E-06]Training epoch 96:  78%|███████▊  | 120/153 [00:02<00:00, 53.22it/s, Epoch: 96, Batch: 120,Loss: -3.113,Avg.Loss: -3.063,LR: 2.19E-06]Training epoch 96:  78%|███████▊  | 120/153 [00:02<00:00, 53.22it/s, Epoch: 96, Batch: 121,Loss: -3.173,Avg.Loss: -3.064,LR: 2.18E-06]Training epoch 96:  79%|███████▉  | 121/153 [00:02<00:00, 53.22it/s, Epoch: 96, Batch: 122,Loss: -3.101,Avg.Loss: -3.064,LR: 2.18E-06]Training epoch 96:  80%|███████▉  | 122/153 [00:02<00:00, 53.22it/s, Epoch: 96, Batch: 123,Loss: -2.771,Avg.Loss: -3.062,LR: 2.17E-06]Training epoch 96:  80%|████████  | 123/153 [00:02<00:00, 53.22it/s, Epoch: 96, Batch: 124,Loss: -3.325,Avg.Loss: -3.064,LR: 2.16E-06]Training epoch 96:  81%|████████  | 124/153 [00:02<00:00, 53.22it/s, Epoch: 96, Batch: 125,Loss: -3.271,Avg.Loss: -3.066,LR: 2.16E-06]Training epoch 96:  82%|████████▏ | 125/153 [00:02<00:00, 53.22it/s, Epoch: 96, Batch: 126,Loss: -3.146,Avg.Loss: -3.066,LR: 2.15E-06]Training epoch 96:  82%|████████▏ | 126/153 [00:02<00:00, 53.45it/s, Epoch: 96, Batch: 126,Loss: -3.146,Avg.Loss: -3.066,LR: 2.15E-06]Training epoch 96:  82%|████████▏ | 126/153 [00:02<00:00, 53.45it/s, Epoch: 96, Batch: 127,Loss: -3.129,Avg.Loss: -3.067,LR: 2.14E-06]Training epoch 96:  83%|████████▎ | 127/153 [00:02<00:00, 53.45it/s, Epoch: 96, Batch: 128,Loss: -3.258,Avg.Loss: -3.068,LR: 2.14E-06]Training epoch 96:  84%|████████▎ | 128/153 [00:02<00:00, 53.45it/s, Epoch: 96, Batch: 129,Loss: -3.207,Avg.Loss: -3.069,LR: 2.13E-06]Training epoch 96:  84%|████████▍ | 129/153 [00:02<00:00, 53.45it/s, Epoch: 96, Batch: 130,Loss: -3.106,Avg.Loss: -3.070,LR: 2.12E-06]Training epoch 96:  85%|████████▍ | 130/153 [00:02<00:00, 53.45it/s, Epoch: 96, Batch: 131,Loss: -3.007,Avg.Loss: -3.069,LR: 2.12E-06]Training epoch 96:  86%|████████▌ | 131/153 [00:02<00:00, 53.45it/s, Epoch: 96, Batch: 132,Loss: -3.203,Avg.Loss: -3.070,LR: 2.11E-06]Training epoch 96:  86%|████████▋ | 132/153 [00:02<00:00, 53.61it/s, Epoch: 96, Batch: 132,Loss: -3.203,Avg.Loss: -3.070,LR: 2.11E-06]Training epoch 96:  86%|████████▋ | 132/153 [00:02<00:00, 53.61it/s, Epoch: 96, Batch: 133,Loss: -3.291,Avg.Loss: -3.072,LR: 2.10E-06]Training epoch 96:  87%|████████▋ | 133/153 [00:02<00:00, 53.61it/s, Epoch: 96, Batch: 134,Loss: -3.187,Avg.Loss: -3.073,LR: 2.10E-06]Training epoch 96:  88%|████████▊ | 134/153 [00:02<00:00, 53.61it/s, Epoch: 96, Batch: 135,Loss: -3.674,Avg.Loss: -3.077,LR: 2.09E-06]Training epoch 96:  88%|████████▊ | 135/153 [00:02<00:00, 53.61it/s, Epoch: 96, Batch: 136,Loss: -3.531,Avg.Loss: -3.080,LR: 2.08E-06]Training epoch 96:  89%|████████▉ | 136/153 [00:02<00:00, 53.61it/s, Epoch: 96, Batch: 137,Loss: -3.294,Avg.Loss: -3.082,LR: 2.08E-06]Training epoch 96:  90%|████████▉ | 137/153 [00:02<00:00, 53.61it/s, Epoch: 96, Batch: 138,Loss: -2.988,Avg.Loss: -3.081,LR: 2.07E-06]Training epoch 96:  90%|█████████ | 138/153 [00:02<00:00, 53.50it/s, Epoch: 96, Batch: 138,Loss: -2.988,Avg.Loss: -3.081,LR: 2.07E-06]Training epoch 96:  90%|█████████ | 138/153 [00:02<00:00, 53.50it/s, Epoch: 96, Batch: 139,Loss: -3.028,Avg.Loss: -3.081,LR: 2.06E-06]Training epoch 96:  91%|█████████ | 139/153 [00:02<00:00, 53.50it/s, Epoch: 96, Batch: 140,Loss: -3.127,Avg.Loss: -3.081,LR: 2.06E-06]Training epoch 96:  92%|█████████▏| 140/153 [00:02<00:00, 53.50it/s, Epoch: 96, Batch: 141,Loss: -3.086,Avg.Loss: -3.081,LR: 2.05E-06]Training epoch 96:  92%|█████████▏| 141/153 [00:02<00:00, 53.50it/s, Epoch: 96, Batch: 142,Loss: -3.580,Avg.Loss: -3.085,LR: 2.04E-06]Training epoch 96:  93%|█████████▎| 142/153 [00:02<00:00, 53.50it/s, Epoch: 96, Batch: 143,Loss: -3.196,Avg.Loss: -3.086,LR: 2.04E-06]Training epoch 96:  93%|█████████▎| 143/153 [00:02<00:00, 53.50it/s, Epoch: 96, Batch: 144,Loss: -2.727,Avg.Loss: -3.083,LR: 2.03E-06]Training epoch 96:  94%|█████████▍| 144/153 [00:02<00:00, 53.43it/s, Epoch: 96, Batch: 144,Loss: -2.727,Avg.Loss: -3.083,LR: 2.03E-06]Training epoch 96:  94%|█████████▍| 144/153 [00:02<00:00, 53.43it/s, Epoch: 96, Batch: 145,Loss: -3.391,Avg.Loss: -3.085,LR: 2.02E-06]Training epoch 96:  95%|█████████▍| 145/153 [00:02<00:00, 53.43it/s, Epoch: 96, Batch: 146,Loss: -2.911,Avg.Loss: -3.084,LR: 2.02E-06]Training epoch 96:  95%|█████████▌| 146/153 [00:02<00:00, 53.43it/s, Epoch: 96, Batch: 147,Loss: -2.865,Avg.Loss: -3.083,LR: 2.01E-06]Training epoch 96:  96%|█████████▌| 147/153 [00:02<00:00, 53.43it/s, Epoch: 96, Batch: 148,Loss: -2.627,Avg.Loss: -3.079,LR: 2.00E-06]Training epoch 96:  97%|█████████▋| 148/153 [00:02<00:00, 53.43it/s, Epoch: 96, Batch: 149,Loss: -2.832,Avg.Loss: -3.078,LR: 2.00E-06]Training epoch 96:  97%|█████████▋| 149/153 [00:02<00:00, 53.43it/s, Epoch: 96, Batch: 150,Loss: -2.727,Avg.Loss: -3.075,LR: 1.99E-06]Training epoch 96:  98%|█████████▊| 150/153 [00:02<00:00, 53.48it/s, Epoch: 96, Batch: 150,Loss: -2.727,Avg.Loss: -3.075,LR: 1.99E-06]Training epoch 96:  98%|█████████▊| 150/153 [00:02<00:00, 53.48it/s, Epoch: 96, Batch: 151,Loss: -2.498,Avg.Loss: -3.072,LR: 1.98E-06]Training epoch 96:  99%|█████████▊| 151/153 [00:02<00:00, 53.48it/s, Epoch: 96, Batch: 152,Loss: -2.869,Avg.Loss: -3.070,LR: 1.98E-06]Training epoch 96:  99%|█████████▉| 152/153 [00:02<00:00, 53.48it/s, Epoch: 96, Batch: 153,Loss: -2.692,Avg.Loss: -3.068,LR: 1.97E-06]Training epoch 96: 100%|██████████| 153/153 [00:02<00:00, 52.77it/s, Epoch: 96, Batch: 153,Loss: -2.692,Avg.Loss: -3.068,LR: 1.97E-06]
Training epoch 97:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 97:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 97, Batch: 1,Loss: -3.307,Avg.Loss: -3.307,LR: 1.96E-06]Training epoch 97:   1%|          | 1/153 [00:00<00:05, 25.35it/s, Epoch: 97, Batch: 2,Loss: -3.202,Avg.Loss: -3.254,LR: 1.96E-06]Training epoch 97:   1%|▏         | 2/153 [00:00<00:04, 35.54it/s, Epoch: 97, Batch: 3,Loss: -2.854,Avg.Loss: -3.121,LR: 1.95E-06]Training epoch 97:   2%|▏         | 3/153 [00:00<00:03, 40.65it/s, Epoch: 97, Batch: 4,Loss: -3.133,Avg.Loss: -3.124,LR: 1.95E-06]Training epoch 97:   3%|▎         | 4/153 [00:00<00:03, 43.53it/s, Epoch: 97, Batch: 5,Loss: -3.168,Avg.Loss: -3.133,LR: 1.94E-06]Training epoch 97:   3%|▎         | 5/153 [00:00<00:03, 44.87it/s, Epoch: 97, Batch: 6,Loss: -3.597,Avg.Loss: -3.210,LR: 1.93E-06]Training epoch 97:   4%|▍         | 6/153 [00:00<00:02, 53.75it/s, Epoch: 97, Batch: 6,Loss: -3.597,Avg.Loss: -3.210,LR: 1.93E-06]Training epoch 97:   4%|▍         | 6/153 [00:00<00:02, 53.75it/s, Epoch: 97, Batch: 7,Loss: -2.852,Avg.Loss: -3.159,LR: 1.93E-06]Training epoch 97:   5%|▍         | 7/153 [00:00<00:02, 53.75it/s, Epoch: 97, Batch: 8,Loss: -3.156,Avg.Loss: -3.159,LR: 1.92E-06]Training epoch 97:   5%|▌         | 8/153 [00:00<00:02, 53.75it/s, Epoch: 97, Batch: 9,Loss: -3.043,Avg.Loss: -3.146,LR: 1.91E-06]Training epoch 97:   6%|▌         | 9/153 [00:00<00:02, 53.75it/s, Epoch: 97, Batch: 10,Loss: -3.064,Avg.Loss: -3.138,LR: 1.91E-06]Training epoch 97:   7%|▋         | 10/153 [00:00<00:02, 53.75it/s, Epoch: 97, Batch: 11,Loss: -2.439,Avg.Loss: -3.074,LR: 1.90E-06]Training epoch 97:   7%|▋         | 11/153 [00:00<00:02, 53.75it/s, Epoch: 97, Batch: 12,Loss: -2.972,Avg.Loss: -3.066,LR: 1.89E-06]Training epoch 97:   8%|▊         | 12/153 [00:00<00:02, 53.26it/s, Epoch: 97, Batch: 12,Loss: -2.972,Avg.Loss: -3.066,LR: 1.89E-06]Training epoch 97:   8%|▊         | 12/153 [00:00<00:02, 53.26it/s, Epoch: 97, Batch: 13,Loss: -3.011,Avg.Loss: -3.061,LR: 1.89E-06]Training epoch 97:   8%|▊         | 13/153 [00:00<00:02, 53.26it/s, Epoch: 97, Batch: 14,Loss: -2.715,Avg.Loss: -3.037,LR: 1.88E-06]Training epoch 97:   9%|▉         | 14/153 [00:00<00:02, 53.26it/s, Epoch: 97, Batch: 15,Loss: -2.999,Avg.Loss: -3.034,LR: 1.88E-06]Training epoch 97:  10%|▉         | 15/153 [00:00<00:02, 53.26it/s, Epoch: 97, Batch: 16,Loss: -2.872,Avg.Loss: -3.024,LR: 1.87E-06]Training epoch 97:  10%|█         | 16/153 [00:00<00:02, 53.26it/s, Epoch: 97, Batch: 17,Loss: -3.298,Avg.Loss: -3.040,LR: 1.86E-06]Training epoch 97:  11%|█         | 17/153 [00:00<00:02, 53.26it/s, Epoch: 97, Batch: 18,Loss: -3.365,Avg.Loss: -3.058,LR: 1.86E-06]Training epoch 97:  12%|█▏        | 18/153 [00:00<00:02, 53.12it/s, Epoch: 97, Batch: 18,Loss: -3.365,Avg.Loss: -3.058,LR: 1.86E-06]Training epoch 97:  12%|█▏        | 18/153 [00:00<00:02, 53.12it/s, Epoch: 97, Batch: 19,Loss: -3.258,Avg.Loss: -3.069,LR: 1.85E-06]Training epoch 97:  12%|█▏        | 19/153 [00:00<00:02, 53.12it/s, Epoch: 97, Batch: 20,Loss: -3.283,Avg.Loss: -3.079,LR: 1.84E-06]Training epoch 97:  13%|█▎        | 20/153 [00:00<00:02, 53.12it/s, Epoch: 97, Batch: 21,Loss: -3.079,Avg.Loss: -3.079,LR: 1.84E-06]Training epoch 97:  14%|█▎        | 21/153 [00:00<00:02, 53.12it/s, Epoch: 97, Batch: 22,Loss: -2.966,Avg.Loss: -3.074,LR: 1.83E-06]Training epoch 97:  14%|█▍        | 22/153 [00:00<00:02, 53.12it/s, Epoch: 97, Batch: 23,Loss: -3.260,Avg.Loss: -3.082,LR: 1.83E-06]Training epoch 97:  15%|█▌        | 23/153 [00:00<00:02, 53.12it/s, Epoch: 97, Batch: 24,Loss: -3.173,Avg.Loss: -3.086,LR: 1.82E-06]Training epoch 97:  16%|█▌        | 24/153 [00:00<00:02, 50.89it/s, Epoch: 97, Batch: 24,Loss: -3.173,Avg.Loss: -3.086,LR: 1.82E-06]Training epoch 97:  16%|█▌        | 24/153 [00:00<00:02, 50.89it/s, Epoch: 97, Batch: 25,Loss: -2.377,Avg.Loss: -3.058,LR: 1.81E-06]Training epoch 97:  16%|█▋        | 25/153 [00:00<00:02, 50.89it/s, Epoch: 97, Batch: 26,Loss: -3.572,Avg.Loss: -3.077,LR: 1.81E-06]Training epoch 97:  17%|█▋        | 26/153 [00:00<00:02, 50.89it/s, Epoch: 97, Batch: 27,Loss: -2.845,Avg.Loss: -3.069,LR: 1.80E-06]Training epoch 97:  18%|█▊        | 27/153 [00:00<00:02, 50.89it/s, Epoch: 97, Batch: 28,Loss: -3.062,Avg.Loss: -3.069,LR: 1.80E-06]Training epoch 97:  18%|█▊        | 28/153 [00:00<00:02, 50.89it/s, Epoch: 97, Batch: 29,Loss: -3.394,Avg.Loss: -3.080,LR: 1.79E-06]Training epoch 97:  19%|█▉        | 29/153 [00:00<00:02, 50.89it/s, Epoch: 97, Batch: 30,Loss: -2.579,Avg.Loss: -3.063,LR: 1.78E-06]Training epoch 97:  20%|█▉        | 30/153 [00:00<00:02, 51.05it/s, Epoch: 97, Batch: 30,Loss: -2.579,Avg.Loss: -3.063,LR: 1.78E-06]Training epoch 97:  20%|█▉        | 30/153 [00:00<00:02, 51.05it/s, Epoch: 97, Batch: 31,Loss: -3.120,Avg.Loss: -3.065,LR: 1.78E-06]Training epoch 97:  20%|██        | 31/153 [00:00<00:02, 51.05it/s, Epoch: 97, Batch: 32,Loss: -3.223,Avg.Loss: -3.070,LR: 1.77E-06]Training epoch 97:  21%|██        | 32/153 [00:00<00:02, 51.05it/s, Epoch: 97, Batch: 33,Loss: -3.517,Avg.Loss: -3.084,LR: 1.76E-06]Training epoch 97:  22%|██▏       | 33/153 [00:00<00:02, 51.05it/s, Epoch: 97, Batch: 34,Loss: -3.114,Avg.Loss: -3.084,LR: 1.76E-06]Training epoch 97:  22%|██▏       | 34/153 [00:00<00:02, 51.05it/s, Epoch: 97, Batch: 35,Loss: -3.291,Avg.Loss: -3.090,LR: 1.75E-06]Training epoch 97:  23%|██▎       | 35/153 [00:00<00:02, 51.05it/s, Epoch: 97, Batch: 36,Loss: -3.183,Avg.Loss: -3.093,LR: 1.75E-06]Training epoch 97:  24%|██▎       | 36/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 36,Loss: -3.183,Avg.Loss: -3.093,LR: 1.75E-06]Training epoch 97:  24%|██▎       | 36/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 37,Loss: -3.205,Avg.Loss: -3.096,LR: 1.74E-06]Training epoch 97:  24%|██▍       | 37/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 38,Loss: -3.135,Avg.Loss: -3.097,LR: 1.73E-06]Training epoch 97:  25%|██▍       | 38/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 39,Loss: -3.358,Avg.Loss: -3.104,LR: 1.73E-06]Training epoch 97:  25%|██▌       | 39/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 40,Loss: -3.337,Avg.Loss: -3.109,LR: 1.72E-06]Training epoch 97:  26%|██▌       | 40/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 41,Loss: -2.241,Avg.Loss: -3.088,LR: 1.72E-06]Training epoch 97:  27%|██▋       | 41/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 42,Loss: -2.821,Avg.Loss: -3.082,LR: 1.71E-06]Training epoch 97:  27%|██▋       | 42/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 42,Loss: -2.821,Avg.Loss: -3.082,LR: 1.71E-06]Training epoch 97:  27%|██▋       | 42/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 43,Loss: -3.325,Avg.Loss: -3.088,LR: 1.70E-06]Training epoch 97:  28%|██▊       | 43/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 44,Loss: -3.171,Avg.Loss: -3.089,LR: 1.70E-06]Training epoch 97:  29%|██▉       | 44/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 45,Loss: -2.952,Avg.Loss: -3.086,LR: 1.69E-06]Training epoch 97:  29%|██▉       | 45/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 46,Loss: -2.954,Avg.Loss: -3.084,LR: 1.69E-06]Training epoch 97:  30%|███       | 46/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 47,Loss: -3.099,Avg.Loss: -3.084,LR: 1.68E-06]Training epoch 97:  31%|███       | 47/153 [00:00<00:02, 50.56it/s, Epoch: 97, Batch: 48,Loss: -2.904,Avg.Loss: -3.080,LR: 1.67E-06]Training epoch 97:  31%|███▏      | 48/153 [00:00<00:02, 51.16it/s, Epoch: 97, Batch: 48,Loss: -2.904,Avg.Loss: -3.080,LR: 1.67E-06]Training epoch 97:  31%|███▏      | 48/153 [00:00<00:02, 51.16it/s, Epoch: 97, Batch: 49,Loss: -2.317,Avg.Loss: -3.065,LR: 1.67E-06]Training epoch 97:  32%|███▏      | 49/153 [00:00<00:02, 51.16it/s, Epoch: 97, Batch: 50,Loss: -3.367,Avg.Loss: -3.071,LR: 1.66E-06]Training epoch 97:  33%|███▎      | 50/153 [00:00<00:02, 51.16it/s, Epoch: 97, Batch: 51,Loss: -2.643,Avg.Loss: -3.062,LR: 1.66E-06]Training epoch 97:  33%|███▎      | 51/153 [00:01<00:01, 51.16it/s, Epoch: 97, Batch: 52,Loss: -2.936,Avg.Loss: -3.060,LR: 1.65E-06]Training epoch 97:  34%|███▍      | 52/153 [00:01<00:01, 51.16it/s, Epoch: 97, Batch: 53,Loss: -3.039,Avg.Loss: -3.059,LR: 1.65E-06]Training epoch 97:  35%|███▍      | 53/153 [00:01<00:01, 51.16it/s, Epoch: 97, Batch: 54,Loss: -3.425,Avg.Loss: -3.066,LR: 1.64E-06]Training epoch 97:  35%|███▌      | 54/153 [00:01<00:01, 51.58it/s, Epoch: 97, Batch: 54,Loss: -3.425,Avg.Loss: -3.066,LR: 1.64E-06]Training epoch 97:  35%|███▌      | 54/153 [00:01<00:01, 51.58it/s, Epoch: 97, Batch: 55,Loss: -3.374,Avg.Loss: -3.072,LR: 1.63E-06]Training epoch 97:  36%|███▌      | 55/153 [00:01<00:01, 51.58it/s, Epoch: 97, Batch: 56,Loss: -3.086,Avg.Loss: -3.072,LR: 1.63E-06]Training epoch 97:  37%|███▋      | 56/153 [00:01<00:01, 51.58it/s, Epoch: 97, Batch: 57,Loss: -3.209,Avg.Loss: -3.074,LR: 1.62E-06]Training epoch 97:  37%|███▋      | 57/153 [00:01<00:01, 51.58it/s, Epoch: 97, Batch: 58,Loss: -3.094,Avg.Loss: -3.075,LR: 1.62E-06]Training epoch 97:  38%|███▊      | 58/153 [00:01<00:01, 51.58it/s, Epoch: 97, Batch: 59,Loss: -2.681,Avg.Loss: -3.068,LR: 1.61E-06]Training epoch 97:  39%|███▊      | 59/153 [00:01<00:01, 51.58it/s, Epoch: 97, Batch: 60,Loss: -3.476,Avg.Loss: -3.075,LR: 1.60E-06]Training epoch 97:  39%|███▉      | 60/153 [00:01<00:01, 51.85it/s, Epoch: 97, Batch: 60,Loss: -3.476,Avg.Loss: -3.075,LR: 1.60E-06]Training epoch 97:  39%|███▉      | 60/153 [00:01<00:01, 51.85it/s, Epoch: 97, Batch: 61,Loss: -2.914,Avg.Loss: -3.072,LR: 1.60E-06]Training epoch 97:  40%|███▉      | 61/153 [00:01<00:01, 51.85it/s, Epoch: 97, Batch: 62,Loss: -2.650,Avg.Loss: -3.065,LR: 1.59E-06]Training epoch 97:  41%|████      | 62/153 [00:01<00:01, 51.85it/s, Epoch: 97, Batch: 63,Loss: -2.830,Avg.Loss: -3.062,LR: 1.59E-06]Training epoch 97:  41%|████      | 63/153 [00:01<00:01, 51.85it/s, Epoch: 97, Batch: 64,Loss: -2.980,Avg.Loss: -3.060,LR: 1.58E-06]Training epoch 97:  42%|████▏     | 64/153 [00:01<00:01, 51.85it/s, Epoch: 97, Batch: 65,Loss: -2.961,Avg.Loss: -3.059,LR: 1.58E-06]Training epoch 97:  42%|████▏     | 65/153 [00:01<00:01, 51.85it/s, Epoch: 97, Batch: 66,Loss: -3.354,Avg.Loss: -3.063,LR: 1.57E-06]Training epoch 97:  43%|████▎     | 66/153 [00:01<00:01, 52.15it/s, Epoch: 97, Batch: 66,Loss: -3.354,Avg.Loss: -3.063,LR: 1.57E-06]Training epoch 97:  43%|████▎     | 66/153 [00:01<00:01, 52.15it/s, Epoch: 97, Batch: 67,Loss: -3.274,Avg.Loss: -3.067,LR: 1.56E-06]Training epoch 97:  44%|████▍     | 67/153 [00:01<00:01, 52.15it/s, Epoch: 97, Batch: 68,Loss: -2.903,Avg.Loss: -3.064,LR: 1.56E-06]Training epoch 97:  44%|████▍     | 68/153 [00:01<00:01, 52.15it/s, Epoch: 97, Batch: 69,Loss: -3.373,Avg.Loss: -3.069,LR: 1.55E-06]Training epoch 97:  45%|████▌     | 69/153 [00:01<00:01, 52.15it/s, Epoch: 97, Batch: 70,Loss: -3.332,Avg.Loss: -3.072,LR: 1.55E-06]Training epoch 97:  46%|████▌     | 70/153 [00:01<00:01, 52.15it/s, Epoch: 97, Batch: 71,Loss: -3.164,Avg.Loss: -3.074,LR: 1.54E-06]Training epoch 97:  46%|████▋     | 71/153 [00:01<00:01, 52.15it/s, Epoch: 97, Batch: 72,Loss: -2.677,Avg.Loss: -3.068,LR: 1.54E-06]Training epoch 97:  47%|████▋     | 72/153 [00:01<00:01, 52.23it/s, Epoch: 97, Batch: 72,Loss: -2.677,Avg.Loss: -3.068,LR: 1.54E-06]Training epoch 97:  47%|████▋     | 72/153 [00:01<00:01, 52.23it/s, Epoch: 97, Batch: 73,Loss: -2.703,Avg.Loss: -3.063,LR: 1.53E-06]Training epoch 97:  48%|████▊     | 73/153 [00:01<00:01, 52.23it/s, Epoch: 97, Batch: 74,Loss: -2.575,Avg.Loss: -3.057,LR: 1.52E-06]Training epoch 97:  48%|████▊     | 74/153 [00:01<00:01, 52.23it/s, Epoch: 97, Batch: 75,Loss: -3.090,Avg.Loss: -3.057,LR: 1.52E-06]Training epoch 97:  49%|████▉     | 75/153 [00:01<00:01, 52.23it/s, Epoch: 97, Batch: 76,Loss: -2.827,Avg.Loss: -3.054,LR: 1.51E-06]Training epoch 97:  50%|████▉     | 76/153 [00:01<00:01, 52.23it/s, Epoch: 97, Batch: 77,Loss: -3.263,Avg.Loss: -3.057,LR: 1.51E-06]Training epoch 97:  50%|█████     | 77/153 [00:01<00:01, 52.23it/s, Epoch: 97, Batch: 78,Loss: -3.542,Avg.Loss: -3.063,LR: 1.50E-06]Training epoch 97:  51%|█████     | 78/153 [00:01<00:01, 52.29it/s, Epoch: 97, Batch: 78,Loss: -3.542,Avg.Loss: -3.063,LR: 1.50E-06]Training epoch 97:  51%|█████     | 78/153 [00:01<00:01, 52.29it/s, Epoch: 97, Batch: 79,Loss: -3.363,Avg.Loss: -3.067,LR: 1.50E-06]Training epoch 97:  52%|█████▏    | 79/153 [00:01<00:01, 52.29it/s, Epoch: 97, Batch: 80,Loss: -2.715,Avg.Loss: -3.062,LR: 1.49E-06]Training epoch 97:  52%|█████▏    | 80/153 [00:01<00:01, 52.29it/s, Epoch: 97, Batch: 81,Loss: -3.426,Avg.Loss: -3.067,LR: 1.48E-06]Training epoch 97:  53%|█████▎    | 81/153 [00:01<00:01, 52.29it/s, Epoch: 97, Batch: 82,Loss: -3.106,Avg.Loss: -3.067,LR: 1.48E-06]Training epoch 97:  54%|█████▎    | 82/153 [00:01<00:01, 52.29it/s, Epoch: 97, Batch: 83,Loss: -2.292,Avg.Loss: -3.058,LR: 1.47E-06]Training epoch 97:  54%|█████▍    | 83/153 [00:01<00:01, 52.29it/s, Epoch: 97, Batch: 84,Loss: -3.090,Avg.Loss: -3.058,LR: 1.47E-06]Training epoch 97:  55%|█████▍    | 84/153 [00:01<00:01, 52.32it/s, Epoch: 97, Batch: 84,Loss: -3.090,Avg.Loss: -3.058,LR: 1.47E-06]Training epoch 97:  55%|█████▍    | 84/153 [00:01<00:01, 52.32it/s, Epoch: 97, Batch: 85,Loss: -3.249,Avg.Loss: -3.061,LR: 1.46E-06]Training epoch 97:  56%|█████▌    | 85/153 [00:01<00:01, 52.32it/s, Epoch: 97, Batch: 86,Loss: -3.049,Avg.Loss: -3.060,LR: 1.46E-06]Training epoch 97:  56%|█████▌    | 86/153 [00:01<00:01, 52.32it/s, Epoch: 97, Batch: 87,Loss: -3.324,Avg.Loss: -3.063,LR: 1.45E-06]Training epoch 97:  57%|█████▋    | 87/153 [00:01<00:01, 52.32it/s, Epoch: 97, Batch: 88,Loss: -3.178,Avg.Loss: -3.065,LR: 1.45E-06]Training epoch 97:  58%|█████▊    | 88/153 [00:01<00:01, 52.32it/s, Epoch: 97, Batch: 89,Loss: -3.361,Avg.Loss: -3.068,LR: 1.44E-06]Training epoch 97:  58%|█████▊    | 89/153 [00:01<00:01, 52.32it/s, Epoch: 97, Batch: 90,Loss: -2.963,Avg.Loss: -3.067,LR: 1.43E-06]Training epoch 97:  59%|█████▉    | 90/153 [00:01<00:01, 51.91it/s, Epoch: 97, Batch: 90,Loss: -2.963,Avg.Loss: -3.067,LR: 1.43E-06]Training epoch 97:  59%|█████▉    | 90/153 [00:01<00:01, 51.91it/s, Epoch: 97, Batch: 91,Loss: -3.281,Avg.Loss: -3.069,LR: 1.43E-06]Training epoch 97:  59%|█████▉    | 91/153 [00:01<00:01, 51.91it/s, Epoch: 97, Batch: 92,Loss: -3.183,Avg.Loss: -3.071,LR: 1.42E-06]Training epoch 97:  60%|██████    | 92/153 [00:01<00:01, 51.91it/s, Epoch: 97, Batch: 93,Loss: -3.146,Avg.Loss: -3.071,LR: 1.42E-06]Training epoch 97:  61%|██████    | 93/153 [00:01<00:01, 51.91it/s, Epoch: 97, Batch: 94,Loss: -3.084,Avg.Loss: -3.071,LR: 1.41E-06]Training epoch 97:  61%|██████▏   | 94/153 [00:01<00:01, 51.91it/s, Epoch: 97, Batch: 95,Loss: -2.266,Avg.Loss: -3.063,LR: 1.41E-06]Training epoch 97:  62%|██████▏   | 95/153 [00:01<00:01, 51.91it/s, Epoch: 97, Batch: 96,Loss: -3.196,Avg.Loss: -3.064,LR: 1.40E-06]Training epoch 97:  63%|██████▎   | 96/153 [00:01<00:01, 52.12it/s, Epoch: 97, Batch: 96,Loss: -3.196,Avg.Loss: -3.064,LR: 1.40E-06]Training epoch 97:  63%|██████▎   | 96/153 [00:01<00:01, 52.12it/s, Epoch: 97, Batch: 97,Loss: -3.053,Avg.Loss: -3.064,LR: 1.40E-06]Training epoch 97:  63%|██████▎   | 97/153 [00:01<00:01, 52.12it/s, Epoch: 97, Batch: 98,Loss: -3.137,Avg.Loss: -3.065,LR: 1.39E-06]Training epoch 97:  64%|██████▍   | 98/153 [00:01<00:01, 52.12it/s, Epoch: 97, Batch: 99,Loss: -3.010,Avg.Loss: -3.064,LR: 1.39E-06]Training epoch 97:  65%|██████▍   | 99/153 [00:01<00:01, 52.12it/s, Epoch: 97, Batch: 100,Loss: -3.200,Avg.Loss: -3.066,LR: 1.38E-06]Training epoch 97:  65%|██████▌   | 100/153 [00:01<00:01, 52.12it/s, Epoch: 97, Batch: 101,Loss: -2.693,Avg.Loss: -3.062,LR: 1.37E-06]Training epoch 97:  66%|██████▌   | 101/153 [00:01<00:00, 52.12it/s, Epoch: 97, Batch: 102,Loss: -3.214,Avg.Loss: -3.064,LR: 1.37E-06]Training epoch 97:  67%|██████▋   | 102/153 [00:01<00:00, 52.12it/s, Epoch: 97, Batch: 102,Loss: -3.214,Avg.Loss: -3.064,LR: 1.37E-06]Training epoch 97:  67%|██████▋   | 102/153 [00:01<00:00, 52.12it/s, Epoch: 97, Batch: 103,Loss: -3.449,Avg.Loss: -3.067,LR: 1.36E-06]Training epoch 97:  67%|██████▋   | 103/153 [00:02<00:00, 52.12it/s, Epoch: 97, Batch: 104,Loss: -2.991,Avg.Loss: -3.067,LR: 1.36E-06]Training epoch 97:  68%|██████▊   | 104/153 [00:02<00:00, 52.12it/s, Epoch: 97, Batch: 105,Loss: -2.997,Avg.Loss: -3.066,LR: 1.35E-06]Training epoch 97:  69%|██████▊   | 105/153 [00:02<00:00, 52.12it/s, Epoch: 97, Batch: 106,Loss: -3.292,Avg.Loss: -3.068,LR: 1.35E-06]Training epoch 97:  69%|██████▉   | 106/153 [00:02<00:00, 52.12it/s, Epoch: 97, Batch: 107,Loss: -3.061,Avg.Loss: -3.068,LR: 1.34E-06]Training epoch 97:  70%|██████▉   | 107/153 [00:02<00:00, 52.12it/s, Epoch: 97, Batch: 108,Loss: -3.196,Avg.Loss: -3.069,LR: 1.34E-06]Training epoch 97:  71%|███████   | 108/153 [00:02<00:00, 52.27it/s, Epoch: 97, Batch: 108,Loss: -3.196,Avg.Loss: -3.069,LR: 1.34E-06]Training epoch 97:  71%|███████   | 108/153 [00:02<00:00, 52.27it/s, Epoch: 97, Batch: 109,Loss: -2.907,Avg.Loss: -3.068,LR: 1.33E-06]Training epoch 97:  71%|███████   | 109/153 [00:02<00:00, 52.27it/s, Epoch: 97, Batch: 110,Loss: -3.204,Avg.Loss: -3.069,LR: 1.33E-06]Training epoch 97:  72%|███████▏  | 110/153 [00:02<00:00, 52.27it/s, Epoch: 97, Batch: 111,Loss: -3.173,Avg.Loss: -3.070,LR: 1.32E-06]Training epoch 97:  73%|███████▎  | 111/153 [00:02<00:00, 52.27it/s, Epoch: 97, Batch: 112,Loss: -3.607,Avg.Loss: -3.075,LR: 1.32E-06]Training epoch 97:  73%|███████▎  | 112/153 [00:02<00:00, 52.27it/s, Epoch: 97, Batch: 113,Loss: -3.102,Avg.Loss: -3.075,LR: 1.31E-06]Training epoch 97:  74%|███████▍  | 113/153 [00:02<00:00, 52.27it/s, Epoch: 97, Batch: 114,Loss: -2.643,Avg.Loss: -3.071,LR: 1.31E-06]Training epoch 97:  75%|███████▍  | 114/153 [00:02<00:00, 52.76it/s, Epoch: 97, Batch: 114,Loss: -2.643,Avg.Loss: -3.071,LR: 1.31E-06]Training epoch 97:  75%|███████▍  | 114/153 [00:02<00:00, 52.76it/s, Epoch: 97, Batch: 115,Loss: -3.101,Avg.Loss: -3.071,LR: 1.30E-06]Training epoch 97:  75%|███████▌  | 115/153 [00:02<00:00, 52.76it/s, Epoch: 97, Batch: 116,Loss: -3.328,Avg.Loss: -3.074,LR: 1.30E-06]Training epoch 97:  76%|███████▌  | 116/153 [00:02<00:00, 52.76it/s, Epoch: 97, Batch: 117,Loss: -3.075,Avg.Loss: -3.074,LR: 1.29E-06]Training epoch 97:  76%|███████▋  | 117/153 [00:02<00:00, 52.76it/s, Epoch: 97, Batch: 118,Loss: -2.520,Avg.Loss: -3.069,LR: 1.29E-06]Training epoch 97:  77%|███████▋  | 118/153 [00:02<00:00, 52.76it/s, Epoch: 97, Batch: 119,Loss: -3.175,Avg.Loss: -3.070,LR: 1.28E-06]Training epoch 97:  78%|███████▊  | 119/153 [00:02<00:00, 52.76it/s, Epoch: 97, Batch: 120,Loss: -2.655,Avg.Loss: -3.066,LR: 1.27E-06]Training epoch 97:  78%|███████▊  | 120/153 [00:02<00:00, 52.87it/s, Epoch: 97, Batch: 120,Loss: -2.655,Avg.Loss: -3.066,LR: 1.27E-06]Training epoch 97:  78%|███████▊  | 120/153 [00:02<00:00, 52.87it/s, Epoch: 97, Batch: 121,Loss: -3.110,Avg.Loss: -3.067,LR: 1.27E-06]Training epoch 97:  79%|███████▉  | 121/153 [00:02<00:00, 52.87it/s, Epoch: 97, Batch: 122,Loss: -3.079,Avg.Loss: -3.067,LR: 1.26E-06]Training epoch 97:  80%|███████▉  | 122/153 [00:02<00:00, 52.87it/s, Epoch: 97, Batch: 123,Loss: -2.665,Avg.Loss: -3.064,LR: 1.26E-06]Training epoch 97:  80%|████████  | 123/153 [00:02<00:00, 52.87it/s, Epoch: 97, Batch: 124,Loss: -3.342,Avg.Loss: -3.066,LR: 1.25E-06]Training epoch 97:  81%|████████  | 124/153 [00:02<00:00, 52.87it/s, Epoch: 97, Batch: 125,Loss: -3.110,Avg.Loss: -3.066,LR: 1.25E-06]Training epoch 97:  82%|████████▏ | 125/153 [00:02<00:00, 52.87it/s, Epoch: 97, Batch: 126,Loss: -3.088,Avg.Loss: -3.066,LR: 1.24E-06]Training epoch 97:  82%|████████▏ | 126/153 [00:02<00:00, 52.95it/s, Epoch: 97, Batch: 126,Loss: -3.088,Avg.Loss: -3.066,LR: 1.24E-06]Training epoch 97:  82%|████████▏ | 126/153 [00:02<00:00, 52.95it/s, Epoch: 97, Batch: 127,Loss: -3.669,Avg.Loss: -3.071,LR: 1.24E-06]Training epoch 97:  83%|████████▎ | 127/153 [00:02<00:00, 52.95it/s, Epoch: 97, Batch: 128,Loss: -3.055,Avg.Loss: -3.071,LR: 1.23E-06]Training epoch 97:  84%|████████▎ | 128/153 [00:02<00:00, 52.95it/s, Epoch: 97, Batch: 129,Loss: -3.117,Avg.Loss: -3.071,LR: 1.23E-06]Training epoch 97:  84%|████████▍ | 129/153 [00:02<00:00, 52.95it/s, Epoch: 97, Batch: 130,Loss: -3.538,Avg.Loss: -3.075,LR: 1.22E-06]Training epoch 97:  85%|████████▍ | 130/153 [00:02<00:00, 52.95it/s, Epoch: 97, Batch: 131,Loss: -2.878,Avg.Loss: -3.073,LR: 1.22E-06]Training epoch 97:  86%|████████▌ | 131/153 [00:02<00:00, 52.95it/s, Epoch: 97, Batch: 132,Loss: -3.217,Avg.Loss: -3.074,LR: 1.21E-06]Training epoch 97:  86%|████████▋ | 132/153 [00:02<00:00, 53.07it/s, Epoch: 97, Batch: 132,Loss: -3.217,Avg.Loss: -3.074,LR: 1.21E-06]Training epoch 97:  86%|████████▋ | 132/153 [00:02<00:00, 53.07it/s, Epoch: 97, Batch: 133,Loss: -2.840,Avg.Loss: -3.073,LR: 1.21E-06]Training epoch 97:  87%|████████▋ | 133/153 [00:02<00:00, 53.07it/s, Epoch: 97, Batch: 134,Loss: -2.839,Avg.Loss: -3.071,LR: 1.20E-06]Training epoch 97:  88%|████████▊ | 134/153 [00:02<00:00, 53.07it/s, Epoch: 97, Batch: 135,Loss: -2.996,Avg.Loss: -3.070,LR: 1.20E-06]Training epoch 97:  88%|████████▊ | 135/153 [00:02<00:00, 53.07it/s, Epoch: 97, Batch: 136,Loss: -3.494,Avg.Loss: -3.074,LR: 1.19E-06]Training epoch 97:  89%|████████▉ | 136/153 [00:02<00:00, 53.07it/s, Epoch: 97, Batch: 137,Loss: -2.966,Avg.Loss: -3.073,LR: 1.19E-06]Training epoch 97:  90%|████████▉ | 137/153 [00:02<00:00, 53.07it/s, Epoch: 97, Batch: 138,Loss: -2.563,Avg.Loss: -3.069,LR: 1.18E-06]Training epoch 97:  90%|█████████ | 138/153 [00:02<00:00, 52.97it/s, Epoch: 97, Batch: 138,Loss: -2.563,Avg.Loss: -3.069,LR: 1.18E-06]Training epoch 97:  90%|█████████ | 138/153 [00:02<00:00, 52.97it/s, Epoch: 97, Batch: 139,Loss: -3.046,Avg.Loss: -3.069,LR: 1.18E-06]Training epoch 97:  91%|█████████ | 139/153 [00:02<00:00, 52.97it/s, Epoch: 97, Batch: 140,Loss: -3.266,Avg.Loss: -3.070,LR: 1.17E-06]Training epoch 97:  92%|█████████▏| 140/153 [00:02<00:00, 52.97it/s, Epoch: 97, Batch: 141,Loss: -3.192,Avg.Loss: -3.071,LR: 1.17E-06]Training epoch 97:  92%|█████████▏| 141/153 [00:02<00:00, 52.97it/s, Epoch: 97, Batch: 142,Loss: -3.306,Avg.Loss: -3.073,LR: 1.16E-06]Training epoch 97:  93%|█████████▎| 142/153 [00:02<00:00, 52.97it/s, Epoch: 97, Batch: 143,Loss: -2.612,Avg.Loss: -3.070,LR: 1.16E-06]Training epoch 97:  93%|█████████▎| 143/153 [00:02<00:00, 52.97it/s, Epoch: 97, Batch: 144,Loss: -2.814,Avg.Loss: -3.068,LR: 1.15E-06]Training epoch 97:  94%|█████████▍| 144/153 [00:02<00:00, 53.00it/s, Epoch: 97, Batch: 144,Loss: -2.814,Avg.Loss: -3.068,LR: 1.15E-06]Training epoch 97:  94%|█████████▍| 144/153 [00:02<00:00, 53.00it/s, Epoch: 97, Batch: 145,Loss: -3.200,Avg.Loss: -3.069,LR: 1.15E-06]Training epoch 97:  95%|█████████▍| 145/153 [00:02<00:00, 53.00it/s, Epoch: 97, Batch: 146,Loss: -3.022,Avg.Loss: -3.068,LR: 1.14E-06]Training epoch 97:  95%|█████████▌| 146/153 [00:02<00:00, 53.00it/s, Epoch: 97, Batch: 147,Loss: -2.885,Avg.Loss: -3.067,LR: 1.14E-06]Training epoch 97:  96%|█████████▌| 147/153 [00:02<00:00, 53.00it/s, Epoch: 97, Batch: 148,Loss: -2.805,Avg.Loss: -3.065,LR: 1.13E-06]Training epoch 97:  97%|█████████▋| 148/153 [00:02<00:00, 53.00it/s, Epoch: 97, Batch: 149,Loss: -3.162,Avg.Loss: -3.066,LR: 1.13E-06]Training epoch 97:  97%|█████████▋| 149/153 [00:02<00:00, 53.00it/s, Epoch: 97, Batch: 150,Loss: -3.436,Avg.Loss: -3.068,LR: 1.12E-06]Training epoch 97:  98%|█████████▊| 150/153 [00:02<00:00, 53.17it/s, Epoch: 97, Batch: 150,Loss: -3.436,Avg.Loss: -3.068,LR: 1.12E-06]Training epoch 97:  98%|█████████▊| 150/153 [00:02<00:00, 53.17it/s, Epoch: 97, Batch: 151,Loss: -3.046,Avg.Loss: -3.068,LR: 1.12E-06]Training epoch 97:  99%|█████████▊| 151/153 [00:02<00:00, 53.17it/s, Epoch: 97, Batch: 152,Loss: -3.358,Avg.Loss: -3.070,LR: 1.11E-06]Training epoch 97:  99%|█████████▉| 152/153 [00:02<00:00, 53.17it/s, Epoch: 97, Batch: 153,Loss: -3.468,Avg.Loss: -3.073,LR: 1.11E-06]Training epoch 97: 100%|██████████| 153/153 [00:02<00:00, 52.23it/s, Epoch: 97, Batch: 153,Loss: -3.468,Avg.Loss: -3.073,LR: 1.11E-06]
Training epoch 98:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 98:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 98, Batch: 1,Loss: -2.878,Avg.Loss: -2.878,LR: 1.10E-06]Training epoch 98:   1%|          | 1/153 [00:00<00:05, 26.40it/s, Epoch: 98, Batch: 2,Loss: -3.252,Avg.Loss: -3.065,LR: 1.10E-06]Training epoch 98:   1%|▏         | 2/153 [00:00<00:03, 39.11it/s, Epoch: 98, Batch: 3,Loss: -2.653,Avg.Loss: -2.927,LR: 1.10E-06]Training epoch 98:   2%|▏         | 3/153 [00:00<00:03, 44.34it/s, Epoch: 98, Batch: 4,Loss: -2.197,Avg.Loss: -2.745,LR: 1.09E-06]Training epoch 98:   3%|▎         | 4/153 [00:00<00:03, 46.87it/s, Epoch: 98, Batch: 5,Loss: -3.002,Avg.Loss: -2.796,LR: 1.09E-06]Training epoch 98:   3%|▎         | 5/153 [00:00<00:03, 48.29it/s, Epoch: 98, Batch: 6,Loss: -3.226,Avg.Loss: -2.868,LR: 1.08E-06]Training epoch 98:   4%|▍         | 6/153 [00:00<00:02, 57.84it/s, Epoch: 98, Batch: 6,Loss: -3.226,Avg.Loss: -2.868,LR: 1.08E-06]Training epoch 98:   4%|▍         | 6/153 [00:00<00:02, 57.84it/s, Epoch: 98, Batch: 7,Loss: -2.822,Avg.Loss: -2.861,LR: 1.08E-06]Training epoch 98:   5%|▍         | 7/153 [00:00<00:02, 57.84it/s, Epoch: 98, Batch: 8,Loss: -2.993,Avg.Loss: -2.878,LR: 1.07E-06]Training epoch 98:   5%|▌         | 8/153 [00:00<00:02, 57.84it/s, Epoch: 98, Batch: 9,Loss: -2.685,Avg.Loss: -2.856,LR: 1.07E-06]Training epoch 98:   6%|▌         | 9/153 [00:00<00:02, 57.84it/s, Epoch: 98, Batch: 10,Loss: -3.314,Avg.Loss: -2.902,LR: 1.06E-06]Training epoch 98:   7%|▋         | 10/153 [00:00<00:02, 57.84it/s, Epoch: 98, Batch: 11,Loss: -2.788,Avg.Loss: -2.892,LR: 1.06E-06]Training epoch 98:   7%|▋         | 11/153 [00:00<00:02, 57.84it/s, Epoch: 98, Batch: 12,Loss: -3.338,Avg.Loss: -2.929,LR: 1.05E-06]Training epoch 98:   8%|▊         | 12/153 [00:00<00:02, 54.96it/s, Epoch: 98, Batch: 12,Loss: -3.338,Avg.Loss: -2.929,LR: 1.05E-06]Training epoch 98:   8%|▊         | 12/153 [00:00<00:02, 54.96it/s, Epoch: 98, Batch: 13,Loss: -3.298,Avg.Loss: -2.957,LR: 1.05E-06]Training epoch 98:   8%|▊         | 13/153 [00:00<00:02, 54.96it/s, Epoch: 98, Batch: 14,Loss: -3.072,Avg.Loss: -2.965,LR: 1.04E-06]Training epoch 98:   9%|▉         | 14/153 [00:00<00:02, 54.96it/s, Epoch: 98, Batch: 15,Loss: -2.864,Avg.Loss: -2.959,LR: 1.04E-06]Training epoch 98:  10%|▉         | 15/153 [00:00<00:02, 54.96it/s, Epoch: 98, Batch: 16,Loss: -2.828,Avg.Loss: -2.951,LR: 1.03E-06]Training epoch 98:  10%|█         | 16/153 [00:00<00:02, 54.96it/s, Epoch: 98, Batch: 17,Loss: -3.119,Avg.Loss: -2.960,LR: 1.03E-06]Training epoch 98:  11%|█         | 17/153 [00:00<00:02, 54.96it/s, Epoch: 98, Batch: 18,Loss: -2.971,Avg.Loss: -2.961,LR: 1.02E-06]Training epoch 98:  12%|█▏        | 18/153 [00:00<00:02, 54.06it/s, Epoch: 98, Batch: 18,Loss: -2.971,Avg.Loss: -2.961,LR: 1.02E-06]Training epoch 98:  12%|█▏        | 18/153 [00:00<00:02, 54.06it/s, Epoch: 98, Batch: 19,Loss: -2.717,Avg.Loss: -2.948,LR: 1.02E-06]Training epoch 98:  12%|█▏        | 19/153 [00:00<00:02, 54.06it/s, Epoch: 98, Batch: 20,Loss: -2.967,Avg.Loss: -2.949,LR: 1.01E-06]Training epoch 98:  13%|█▎        | 20/153 [00:00<00:02, 54.06it/s, Epoch: 98, Batch: 21,Loss: -2.902,Avg.Loss: -2.947,LR: 1.01E-06]Training epoch 98:  14%|█▎        | 21/153 [00:00<00:02, 54.06it/s, Epoch: 98, Batch: 22,Loss: -3.344,Avg.Loss: -2.965,LR: 1.01E-06]Training epoch 98:  14%|█▍        | 22/153 [00:00<00:02, 54.06it/s, Epoch: 98, Batch: 23,Loss: -3.375,Avg.Loss: -2.983,LR: 1.00E-06]Training epoch 98:  15%|█▌        | 23/153 [00:00<00:02, 54.06it/s, Epoch: 98, Batch: 24,Loss: -2.819,Avg.Loss: -2.976,LR: 9.97E-07]Training epoch 98:  16%|█▌        | 24/153 [00:00<00:02, 52.81it/s, Epoch: 98, Batch: 24,Loss: -2.819,Avg.Loss: -2.976,LR: 9.97E-07]Training epoch 98:  16%|█▌        | 24/153 [00:00<00:02, 52.81it/s, Epoch: 98, Batch: 25,Loss: -2.756,Avg.Loss: -2.967,LR: 9.92E-07]Training epoch 98:  16%|█▋        | 25/153 [00:00<00:02, 52.81it/s, Epoch: 98, Batch: 26,Loss: -3.067,Avg.Loss: -2.971,LR: 9.87E-07]Training epoch 98:  17%|█▋        | 26/153 [00:00<00:02, 52.81it/s, Epoch: 98, Batch: 27,Loss: -2.927,Avg.Loss: -2.969,LR: 9.83E-07]Training epoch 98:  18%|█▊        | 27/153 [00:00<00:02, 52.81it/s, Epoch: 98, Batch: 28,Loss: -3.204,Avg.Loss: -2.978,LR: 9.78E-07]Training epoch 98:  18%|█▊        | 28/153 [00:00<00:02, 52.81it/s, Epoch: 98, Batch: 29,Loss: -3.664,Avg.Loss: -3.001,LR: 9.74E-07]Training epoch 98:  19%|█▉        | 29/153 [00:00<00:02, 52.81it/s, Epoch: 98, Batch: 30,Loss: -2.905,Avg.Loss: -2.998,LR: 9.69E-07]Training epoch 98:  20%|█▉        | 30/153 [00:00<00:02, 52.85it/s, Epoch: 98, Batch: 30,Loss: -2.905,Avg.Loss: -2.998,LR: 9.69E-07]Training epoch 98:  20%|█▉        | 30/153 [00:00<00:02, 52.85it/s, Epoch: 98, Batch: 31,Loss: -3.448,Avg.Loss: -3.013,LR: 9.65E-07]Training epoch 98:  20%|██        | 31/153 [00:00<00:02, 52.85it/s, Epoch: 98, Batch: 32,Loss: -2.909,Avg.Loss: -3.009,LR: 9.60E-07]Training epoch 98:  21%|██        | 32/153 [00:00<00:02, 52.85it/s, Epoch: 98, Batch: 33,Loss: -2.762,Avg.Loss: -3.002,LR: 9.56E-07]Training epoch 98:  22%|██▏       | 33/153 [00:00<00:02, 52.85it/s, Epoch: 98, Batch: 34,Loss: -3.254,Avg.Loss: -3.009,LR: 9.51E-07]Training epoch 98:  22%|██▏       | 34/153 [00:00<00:02, 52.85it/s, Epoch: 98, Batch: 35,Loss: -2.944,Avg.Loss: -3.007,LR: 9.47E-07]Training epoch 98:  23%|██▎       | 35/153 [00:00<00:02, 52.85it/s, Epoch: 98, Batch: 36,Loss: -2.752,Avg.Loss: -3.000,LR: 9.42E-07]Training epoch 98:  24%|██▎       | 36/153 [00:00<00:02, 53.24it/s, Epoch: 98, Batch: 36,Loss: -2.752,Avg.Loss: -3.000,LR: 9.42E-07]Training epoch 98:  24%|██▎       | 36/153 [00:00<00:02, 53.24it/s, Epoch: 98, Batch: 37,Loss: -3.027,Avg.Loss: -3.001,LR: 9.38E-07]Training epoch 98:  24%|██▍       | 37/153 [00:00<00:02, 53.24it/s, Epoch: 98, Batch: 38,Loss: -3.414,Avg.Loss: -3.012,LR: 9.34E-07]Training epoch 98:  25%|██▍       | 38/153 [00:00<00:02, 53.24it/s, Epoch: 98, Batch: 39,Loss: -3.035,Avg.Loss: -3.013,LR: 9.29E-07]Training epoch 98:  25%|██▌       | 39/153 [00:00<00:02, 53.24it/s, Epoch: 98, Batch: 40,Loss: -3.125,Avg.Loss: -3.015,LR: 9.25E-07]Training epoch 98:  26%|██▌       | 40/153 [00:00<00:02, 53.24it/s, Epoch: 98, Batch: 41,Loss: -2.837,Avg.Loss: -3.011,LR: 9.20E-07]Training epoch 98:  27%|██▋       | 41/153 [00:00<00:02, 53.24it/s, Epoch: 98, Batch: 42,Loss: -3.256,Avg.Loss: -3.017,LR: 9.16E-07]Training epoch 98:  27%|██▋       | 42/153 [00:00<00:02, 52.89it/s, Epoch: 98, Batch: 42,Loss: -3.256,Avg.Loss: -3.017,LR: 9.16E-07]Training epoch 98:  27%|██▋       | 42/153 [00:00<00:02, 52.89it/s, Epoch: 98, Batch: 43,Loss: -3.073,Avg.Loss: -3.018,LR: 9.11E-07]Training epoch 98:  28%|██▊       | 43/153 [00:00<00:02, 52.89it/s, Epoch: 98, Batch: 44,Loss: -2.934,Avg.Loss: -3.016,LR: 9.07E-07]Training epoch 98:  29%|██▉       | 44/153 [00:00<00:02, 52.89it/s, Epoch: 98, Batch: 45,Loss: -3.052,Avg.Loss: -3.017,LR: 9.03E-07]Training epoch 98:  29%|██▉       | 45/153 [00:00<00:02, 52.89it/s, Epoch: 98, Batch: 46,Loss: -3.109,Avg.Loss: -3.019,LR: 8.98E-07]Training epoch 98:  30%|███       | 46/153 [00:00<00:02, 52.89it/s, Epoch: 98, Batch: 47,Loss: -3.210,Avg.Loss: -3.023,LR: 8.94E-07]Training epoch 98:  31%|███       | 47/153 [00:00<00:02, 52.89it/s, Epoch: 98, Batch: 48,Loss: -3.108,Avg.Loss: -3.025,LR: 8.90E-07]Training epoch 98:  31%|███▏      | 48/153 [00:00<00:01, 53.06it/s, Epoch: 98, Batch: 48,Loss: -3.108,Avg.Loss: -3.025,LR: 8.90E-07]Training epoch 98:  31%|███▏      | 48/153 [00:00<00:01, 53.06it/s, Epoch: 98, Batch: 49,Loss: -3.219,Avg.Loss: -3.029,LR: 8.85E-07]Training epoch 98:  32%|███▏      | 49/153 [00:00<00:01, 53.06it/s, Epoch: 98, Batch: 50,Loss: -3.173,Avg.Loss: -3.032,LR: 8.81E-07]Training epoch 98:  33%|███▎      | 50/153 [00:00<00:01, 53.06it/s, Epoch: 98, Batch: 51,Loss: -3.717,Avg.Loss: -3.045,LR: 8.77E-07]Training epoch 98:  33%|███▎      | 51/153 [00:00<00:01, 53.06it/s, Epoch: 98, Batch: 52,Loss: -2.760,Avg.Loss: -3.040,LR: 8.72E-07]Training epoch 98:  34%|███▍      | 52/153 [00:00<00:01, 53.06it/s, Epoch: 98, Batch: 53,Loss: -3.362,Avg.Loss: -3.046,LR: 8.68E-07]Training epoch 98:  35%|███▍      | 53/153 [00:01<00:01, 53.06it/s, Epoch: 98, Batch: 54,Loss: -3.103,Avg.Loss: -3.047,LR: 8.64E-07]Training epoch 98:  35%|███▌      | 54/153 [00:01<00:01, 53.13it/s, Epoch: 98, Batch: 54,Loss: -3.103,Avg.Loss: -3.047,LR: 8.64E-07]Training epoch 98:  35%|███▌      | 54/153 [00:01<00:01, 53.13it/s, Epoch: 98, Batch: 55,Loss: -3.482,Avg.Loss: -3.055,LR: 8.60E-07]Training epoch 98:  36%|███▌      | 55/153 [00:01<00:01, 53.13it/s, Epoch: 98, Batch: 56,Loss: -3.222,Avg.Loss: -3.058,LR: 8.55E-07]Training epoch 98:  37%|███▋      | 56/153 [00:01<00:01, 53.13it/s, Epoch: 98, Batch: 57,Loss: -3.011,Avg.Loss: -3.057,LR: 8.51E-07]Training epoch 98:  37%|███▋      | 57/153 [00:01<00:01, 53.13it/s, Epoch: 98, Batch: 58,Loss: -3.413,Avg.Loss: -3.063,LR: 8.47E-07]Training epoch 98:  38%|███▊      | 58/153 [00:01<00:01, 53.13it/s, Epoch: 98, Batch: 59,Loss: -3.483,Avg.Loss: -3.070,LR: 8.43E-07]Training epoch 98:  39%|███▊      | 59/153 [00:01<00:01, 53.13it/s, Epoch: 98, Batch: 60,Loss: -3.306,Avg.Loss: -3.074,LR: 8.39E-07]Training epoch 98:  39%|███▉      | 60/153 [00:01<00:01, 53.30it/s, Epoch: 98, Batch: 60,Loss: -3.306,Avg.Loss: -3.074,LR: 8.39E-07]Training epoch 98:  39%|███▉      | 60/153 [00:01<00:01, 53.30it/s, Epoch: 98, Batch: 61,Loss: -3.218,Avg.Loss: -3.076,LR: 8.34E-07]Training epoch 98:  40%|███▉      | 61/153 [00:01<00:01, 53.30it/s, Epoch: 98, Batch: 62,Loss: -2.789,Avg.Loss: -3.072,LR: 8.30E-07]Training epoch 98:  41%|████      | 62/153 [00:01<00:01, 53.30it/s, Epoch: 98, Batch: 63,Loss: -2.951,Avg.Loss: -3.070,LR: 8.26E-07]Training epoch 98:  41%|████      | 63/153 [00:01<00:01, 53.30it/s, Epoch: 98, Batch: 64,Loss: -3.334,Avg.Loss: -3.074,LR: 8.22E-07]Training epoch 98:  42%|████▏     | 64/153 [00:01<00:01, 53.30it/s, Epoch: 98, Batch: 65,Loss: -3.003,Avg.Loss: -3.073,LR: 8.18E-07]Training epoch 98:  42%|████▏     | 65/153 [00:01<00:01, 53.30it/s, Epoch: 98, Batch: 66,Loss: -2.977,Avg.Loss: -3.071,LR: 8.14E-07]Training epoch 98:  43%|████▎     | 66/153 [00:01<00:01, 53.19it/s, Epoch: 98, Batch: 66,Loss: -2.977,Avg.Loss: -3.071,LR: 8.14E-07]Training epoch 98:  43%|████▎     | 66/153 [00:01<00:01, 53.19it/s, Epoch: 98, Batch: 67,Loss: -2.806,Avg.Loss: -3.068,LR: 8.09E-07]Training epoch 98:  44%|████▍     | 67/153 [00:01<00:01, 53.19it/s, Epoch: 98, Batch: 68,Loss: -2.783,Avg.Loss: -3.063,LR: 8.05E-07]Training epoch 98:  44%|████▍     | 68/153 [00:01<00:01, 53.19it/s, Epoch: 98, Batch: 69,Loss: -2.993,Avg.Loss: -3.062,LR: 8.01E-07]Training epoch 98:  45%|████▌     | 69/153 [00:01<00:01, 53.19it/s, Epoch: 98, Batch: 70,Loss: -3.080,Avg.Loss: -3.063,LR: 7.97E-07]Training epoch 98:  46%|████▌     | 70/153 [00:01<00:01, 53.19it/s, Epoch: 98, Batch: 71,Loss: -2.973,Avg.Loss: -3.061,LR: 7.93E-07]Training epoch 98:  46%|████▋     | 71/153 [00:01<00:01, 53.19it/s, Epoch: 98, Batch: 72,Loss: -2.923,Avg.Loss: -3.059,LR: 7.89E-07]Training epoch 98:  47%|████▋     | 72/153 [00:01<00:01, 53.17it/s, Epoch: 98, Batch: 72,Loss: -2.923,Avg.Loss: -3.059,LR: 7.89E-07]Training epoch 98:  47%|████▋     | 72/153 [00:01<00:01, 53.17it/s, Epoch: 98, Batch: 73,Loss: -2.978,Avg.Loss: -3.058,LR: 7.85E-07]Training epoch 98:  48%|████▊     | 73/153 [00:01<00:01, 53.17it/s, Epoch: 98, Batch: 74,Loss: -2.819,Avg.Loss: -3.055,LR: 7.81E-07]Training epoch 98:  48%|████▊     | 74/153 [00:01<00:01, 53.17it/s, Epoch: 98, Batch: 75,Loss: -3.026,Avg.Loss: -3.055,LR: 7.77E-07]Training epoch 98:  49%|████▉     | 75/153 [00:01<00:01, 53.17it/s, Epoch: 98, Batch: 76,Loss: -2.522,Avg.Loss: -3.048,LR: 7.73E-07]Training epoch 98:  50%|████▉     | 76/153 [00:01<00:01, 53.17it/s, Epoch: 98, Batch: 77,Loss: -2.943,Avg.Loss: -3.046,LR: 7.69E-07]Training epoch 98:  50%|█████     | 77/153 [00:01<00:01, 53.17it/s, Epoch: 98, Batch: 78,Loss: -3.145,Avg.Loss: -3.048,LR: 7.65E-07]Training epoch 98:  51%|█████     | 78/153 [00:01<00:01, 53.05it/s, Epoch: 98, Batch: 78,Loss: -3.145,Avg.Loss: -3.048,LR: 7.65E-07]Training epoch 98:  51%|█████     | 78/153 [00:01<00:01, 53.05it/s, Epoch: 98, Batch: 79,Loss: -3.207,Avg.Loss: -3.050,LR: 7.61E-07]Training epoch 98:  52%|█████▏    | 79/153 [00:01<00:01, 53.05it/s, Epoch: 98, Batch: 80,Loss: -2.944,Avg.Loss: -3.048,LR: 7.57E-07]Training epoch 98:  52%|█████▏    | 80/153 [00:01<00:01, 53.05it/s, Epoch: 98, Batch: 81,Loss: -3.200,Avg.Loss: -3.050,LR: 7.53E-07]Training epoch 98:  53%|█████▎    | 81/153 [00:01<00:01, 53.05it/s, Epoch: 98, Batch: 82,Loss: -3.113,Avg.Loss: -3.051,LR: 7.49E-07]Training epoch 98:  54%|█████▎    | 82/153 [00:01<00:01, 53.05it/s, Epoch: 98, Batch: 83,Loss: -2.965,Avg.Loss: -3.050,LR: 7.45E-07]Training epoch 98:  54%|█████▍    | 83/153 [00:01<00:01, 53.05it/s, Epoch: 98, Batch: 84,Loss: -3.367,Avg.Loss: -3.054,LR: 7.41E-07]Training epoch 98:  55%|█████▍    | 84/153 [00:01<00:01, 53.21it/s, Epoch: 98, Batch: 84,Loss: -3.367,Avg.Loss: -3.054,LR: 7.41E-07]Training epoch 98:  55%|█████▍    | 84/153 [00:01<00:01, 53.21it/s, Epoch: 98, Batch: 85,Loss: -3.470,Avg.Loss: -3.059,LR: 7.37E-07]Training epoch 98:  56%|█████▌    | 85/153 [00:01<00:01, 53.21it/s, Epoch: 98, Batch: 86,Loss: -3.303,Avg.Loss: -3.061,LR: 7.33E-07]Training epoch 98:  56%|█████▌    | 86/153 [00:01<00:01, 53.21it/s, Epoch: 98, Batch: 87,Loss: -2.308,Avg.Loss: -3.053,LR: 7.29E-07]Training epoch 98:  57%|█████▋    | 87/153 [00:01<00:01, 53.21it/s, Epoch: 98, Batch: 88,Loss: -3.112,Avg.Loss: -3.053,LR: 7.25E-07]Training epoch 98:  58%|█████▊    | 88/153 [00:01<00:01, 53.21it/s, Epoch: 98, Batch: 89,Loss: -3.224,Avg.Loss: -3.055,LR: 7.21E-07]Training epoch 98:  58%|█████▊    | 89/153 [00:01<00:01, 53.21it/s, Epoch: 98, Batch: 90,Loss: -3.054,Avg.Loss: -3.055,LR: 7.17E-07]Training epoch 98:  59%|█████▉    | 90/153 [00:01<00:01, 53.16it/s, Epoch: 98, Batch: 90,Loss: -3.054,Avg.Loss: -3.055,LR: 7.17E-07]Training epoch 98:  59%|█████▉    | 90/153 [00:01<00:01, 53.16it/s, Epoch: 98, Batch: 91,Loss: -2.799,Avg.Loss: -3.052,LR: 7.13E-07]Training epoch 98:  59%|█████▉    | 91/153 [00:01<00:01, 53.16it/s, Epoch: 98, Batch: 92,Loss: -3.044,Avg.Loss: -3.052,LR: 7.10E-07]Training epoch 98:  60%|██████    | 92/153 [00:01<00:01, 53.16it/s, Epoch: 98, Batch: 93,Loss: -3.044,Avg.Loss: -3.052,LR: 7.06E-07]Training epoch 98:  61%|██████    | 93/153 [00:01<00:01, 53.16it/s, Epoch: 98, Batch: 94,Loss: -2.718,Avg.Loss: -3.049,LR: 7.02E-07]Training epoch 98:  61%|██████▏   | 94/153 [00:01<00:01, 53.16it/s, Epoch: 98, Batch: 95,Loss: -2.798,Avg.Loss: -3.046,LR: 6.98E-07]Training epoch 98:  62%|██████▏   | 95/153 [00:01<00:01, 53.16it/s, Epoch: 98, Batch: 96,Loss: -3.358,Avg.Loss: -3.049,LR: 6.94E-07]Training epoch 98:  63%|██████▎   | 96/153 [00:01<00:01, 53.36it/s, Epoch: 98, Batch: 96,Loss: -3.358,Avg.Loss: -3.049,LR: 6.94E-07]Training epoch 98:  63%|██████▎   | 96/153 [00:01<00:01, 53.36it/s, Epoch: 98, Batch: 97,Loss: -3.413,Avg.Loss: -3.053,LR: 6.90E-07]Training epoch 98:  63%|██████▎   | 97/153 [00:01<00:01, 53.36it/s, Epoch: 98, Batch: 98,Loss: -3.352,Avg.Loss: -3.056,LR: 6.86E-07]Training epoch 98:  64%|██████▍   | 98/153 [00:01<00:01, 53.36it/s, Epoch: 98, Batch: 99,Loss: -3.271,Avg.Loss: -3.058,LR: 6.83E-07]Training epoch 98:  65%|██████▍   | 99/153 [00:01<00:01, 53.36it/s, Epoch: 98, Batch: 100,Loss: -3.464,Avg.Loss: -3.062,LR: 6.79E-07]Training epoch 98:  65%|██████▌   | 100/153 [00:01<00:00, 53.36it/s, Epoch: 98, Batch: 101,Loss: -3.358,Avg.Loss: -3.065,LR: 6.75E-07]Training epoch 98:  66%|██████▌   | 101/153 [00:01<00:00, 53.36it/s, Epoch: 98, Batch: 102,Loss: -3.195,Avg.Loss: -3.067,LR: 6.71E-07]Training epoch 98:  67%|██████▋   | 102/153 [00:01<00:00, 53.52it/s, Epoch: 98, Batch: 102,Loss: -3.195,Avg.Loss: -3.067,LR: 6.71E-07]Training epoch 98:  67%|██████▋   | 102/153 [00:01<00:00, 53.52it/s, Epoch: 98, Batch: 103,Loss: -2.838,Avg.Loss: -3.064,LR: 6.68E-07]Training epoch 98:  67%|██████▋   | 103/153 [00:01<00:00, 53.52it/s, Epoch: 98, Batch: 104,Loss: -2.988,Avg.Loss: -3.064,LR: 6.64E-07]Training epoch 98:  68%|██████▊   | 104/153 [00:01<00:00, 53.52it/s, Epoch: 98, Batch: 105,Loss: -3.027,Avg.Loss: -3.063,LR: 6.60E-07]Training epoch 98:  69%|██████▊   | 105/153 [00:01<00:00, 53.52it/s, Epoch: 98, Batch: 106,Loss: -2.912,Avg.Loss: -3.062,LR: 6.56E-07]Training epoch 98:  69%|██████▉   | 106/153 [00:02<00:00, 53.52it/s, Epoch: 98, Batch: 107,Loss: -3.517,Avg.Loss: -3.066,LR: 6.53E-07]Training epoch 98:  70%|██████▉   | 107/153 [00:02<00:00, 53.52it/s, Epoch: 98, Batch: 108,Loss: -3.304,Avg.Loss: -3.068,LR: 6.49E-07]Training epoch 98:  71%|███████   | 108/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 108,Loss: -3.304,Avg.Loss: -3.068,LR: 6.49E-07]Training epoch 98:  71%|███████   | 108/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 109,Loss: -2.547,Avg.Loss: -3.064,LR: 6.45E-07]Training epoch 98:  71%|███████   | 109/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 110,Loss: -3.619,Avg.Loss: -3.069,LR: 6.42E-07]Training epoch 98:  72%|███████▏  | 110/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 111,Loss: -3.535,Avg.Loss: -3.073,LR: 6.38E-07]Training epoch 98:  73%|███████▎  | 111/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 112,Loss: -2.780,Avg.Loss: -3.070,LR: 6.34E-07]Training epoch 98:  73%|███████▎  | 112/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 113,Loss: -3.191,Avg.Loss: -3.071,LR: 6.31E-07]Training epoch 98:  74%|███████▍  | 113/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 114,Loss: -2.941,Avg.Loss: -3.070,LR: 6.27E-07]Training epoch 98:  75%|███████▍  | 114/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 114,Loss: -2.941,Avg.Loss: -3.070,LR: 6.27E-07]Training epoch 98:  75%|███████▍  | 114/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 115,Loss: -3.504,Avg.Loss: -3.074,LR: 6.23E-07]Training epoch 98:  75%|███████▌  | 115/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 116,Loss: -3.185,Avg.Loss: -3.075,LR: 6.20E-07]Training epoch 98:  76%|███████▌  | 116/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 117,Loss: -2.893,Avg.Loss: -3.073,LR: 6.16E-07]Training epoch 98:  76%|███████▋  | 117/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 118,Loss: -3.054,Avg.Loss: -3.073,LR: 6.13E-07]Training epoch 98:  77%|███████▋  | 118/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 119,Loss: -2.593,Avg.Loss: -3.069,LR: 6.09E-07]Training epoch 98:  78%|███████▊  | 119/153 [00:02<00:00, 53.57it/s, Epoch: 98, Batch: 120,Loss: -2.983,Avg.Loss: -3.068,LR: 6.05E-07]Training epoch 98:  78%|███████▊  | 120/153 [00:02<00:00, 53.51it/s, Epoch: 98, Batch: 120,Loss: -2.983,Avg.Loss: -3.068,LR: 6.05E-07]Training epoch 98:  78%|███████▊  | 120/153 [00:02<00:00, 53.51it/s, Epoch: 98, Batch: 121,Loss: -3.300,Avg.Loss: -3.070,LR: 6.02E-07]Training epoch 98:  79%|███████▉  | 121/153 [00:02<00:00, 53.51it/s, Epoch: 98, Batch: 122,Loss: -2.896,Avg.Loss: -3.069,LR: 5.98E-07]Training epoch 98:  80%|███████▉  | 122/153 [00:02<00:00, 53.51it/s, Epoch: 98, Batch: 123,Loss: -2.902,Avg.Loss: -3.067,LR: 5.95E-07]Training epoch 98:  80%|████████  | 123/153 [00:02<00:00, 53.51it/s, Epoch: 98, Batch: 124,Loss: -2.893,Avg.Loss: -3.066,LR: 5.91E-07]Training epoch 98:  81%|████████  | 124/153 [00:02<00:00, 53.51it/s, Epoch: 98, Batch: 125,Loss: -2.825,Avg.Loss: -3.064,LR: 5.88E-07]Training epoch 98:  82%|████████▏ | 125/153 [00:02<00:00, 53.51it/s, Epoch: 98, Batch: 126,Loss: -2.973,Avg.Loss: -3.063,LR: 5.84E-07]Training epoch 98:  82%|████████▏ | 126/153 [00:02<00:00, 53.50it/s, Epoch: 98, Batch: 126,Loss: -2.973,Avg.Loss: -3.063,LR: 5.84E-07]Training epoch 98:  82%|████████▏ | 126/153 [00:02<00:00, 53.50it/s, Epoch: 98, Batch: 127,Loss: -2.863,Avg.Loss: -3.062,LR: 5.81E-07]Training epoch 98:  83%|████████▎ | 127/153 [00:02<00:00, 53.50it/s, Epoch: 98, Batch: 128,Loss: -3.397,Avg.Loss: -3.064,LR: 5.77E-07]Training epoch 98:  84%|████████▎ | 128/153 [00:02<00:00, 53.50it/s, Epoch: 98, Batch: 129,Loss: -3.459,Avg.Loss: -3.068,LR: 5.74E-07]Training epoch 98:  84%|████████▍ | 129/153 [00:02<00:00, 53.50it/s, Epoch: 98, Batch: 130,Loss: -3.200,Avg.Loss: -3.069,LR: 5.70E-07]Training epoch 98:  85%|████████▍ | 130/153 [00:02<00:00, 53.50it/s, Epoch: 98, Batch: 131,Loss: -2.870,Avg.Loss: -3.067,LR: 5.67E-07]Training epoch 98:  86%|████████▌ | 131/153 [00:02<00:00, 53.50it/s, Epoch: 98, Batch: 132,Loss: -2.919,Avg.Loss: -3.066,LR: 5.63E-07]Training epoch 98:  86%|████████▋ | 132/153 [00:02<00:00, 53.65it/s, Epoch: 98, Batch: 132,Loss: -2.919,Avg.Loss: -3.066,LR: 5.63E-07]Training epoch 98:  86%|████████▋ | 132/153 [00:02<00:00, 53.65it/s, Epoch: 98, Batch: 133,Loss: -3.240,Avg.Loss: -3.067,LR: 5.60E-07]Training epoch 98:  87%|████████▋ | 133/153 [00:02<00:00, 53.65it/s, Epoch: 98, Batch: 134,Loss: -3.169,Avg.Loss: -3.068,LR: 5.56E-07]Training epoch 98:  88%|████████▊ | 134/153 [00:02<00:00, 53.65it/s, Epoch: 98, Batch: 135,Loss: -3.570,Avg.Loss: -3.072,LR: 5.53E-07]Training epoch 98:  88%|████████▊ | 135/153 [00:02<00:00, 53.65it/s, Epoch: 98, Batch: 136,Loss: -3.305,Avg.Loss: -3.073,LR: 5.50E-07]Training epoch 98:  89%|████████▉ | 136/153 [00:02<00:00, 53.65it/s, Epoch: 98, Batch: 137,Loss: -3.261,Avg.Loss: -3.075,LR: 5.46E-07]Training epoch 98:  90%|████████▉ | 137/153 [00:02<00:00, 53.65it/s, Epoch: 98, Batch: 138,Loss: -2.951,Avg.Loss: -3.074,LR: 5.43E-07]Training epoch 98:  90%|█████████ | 138/153 [00:02<00:00, 53.64it/s, Epoch: 98, Batch: 138,Loss: -2.951,Avg.Loss: -3.074,LR: 5.43E-07]Training epoch 98:  90%|█████████ | 138/153 [00:02<00:00, 53.64it/s, Epoch: 98, Batch: 139,Loss: -2.219,Avg.Loss: -3.068,LR: 5.39E-07]Training epoch 98:  91%|█████████ | 139/153 [00:02<00:00, 53.64it/s, Epoch: 98, Batch: 140,Loss: -3.279,Avg.Loss: -3.069,LR: 5.36E-07]Training epoch 98:  92%|█████████▏| 140/153 [00:02<00:00, 53.64it/s, Epoch: 98, Batch: 141,Loss: -3.122,Avg.Loss: -3.070,LR: 5.33E-07]Training epoch 98:  92%|█████████▏| 141/153 [00:02<00:00, 53.64it/s, Epoch: 98, Batch: 142,Loss: -3.112,Avg.Loss: -3.070,LR: 5.29E-07]Training epoch 98:  93%|█████████▎| 142/153 [00:02<00:00, 53.64it/s, Epoch: 98, Batch: 143,Loss: -2.951,Avg.Loss: -3.069,LR: 5.26E-07]Training epoch 98:  93%|█████████▎| 143/153 [00:02<00:00, 53.64it/s, Epoch: 98, Batch: 144,Loss: -3.372,Avg.Loss: -3.071,LR: 5.23E-07]Training epoch 98:  94%|█████████▍| 144/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 144,Loss: -3.372,Avg.Loss: -3.071,LR: 5.23E-07]Training epoch 98:  94%|█████████▍| 144/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 145,Loss: -3.210,Avg.Loss: -3.072,LR: 5.19E-07]Training epoch 98:  95%|█████████▍| 145/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 146,Loss: -3.052,Avg.Loss: -3.072,LR: 5.16E-07]Training epoch 98:  95%|█████████▌| 146/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 147,Loss: -3.433,Avg.Loss: -3.074,LR: 5.13E-07]Training epoch 98:  96%|█████████▌| 147/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 148,Loss: -3.312,Avg.Loss: -3.076,LR: 5.10E-07]Training epoch 98:  97%|█████████▋| 148/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 149,Loss: -2.828,Avg.Loss: -3.074,LR: 5.06E-07]Training epoch 98:  97%|█████████▋| 149/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 150,Loss: -3.375,Avg.Loss: -3.076,LR: 5.03E-07]Training epoch 98:  98%|█████████▊| 150/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 150,Loss: -3.375,Avg.Loss: -3.076,LR: 5.03E-07]Training epoch 98:  98%|█████████▊| 150/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 151,Loss: -2.784,Avg.Loss: -3.074,LR: 5.00E-07]Training epoch 98:  99%|█████████▊| 151/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 152,Loss: -2.985,Avg.Loss: -3.074,LR: 4.97E-07]Training epoch 98:  99%|█████████▉| 152/153 [00:02<00:00, 53.80it/s, Epoch: 98, Batch: 153,Loss: -3.329,Avg.Loss: -3.076,LR: 4.93E-07]Training epoch 98: 100%|██████████| 153/153 [00:02<00:00, 53.41it/s, Epoch: 98, Batch: 153,Loss: -3.329,Avg.Loss: -3.076,LR: 4.93E-07]
Training epoch 99:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 99:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 99, Batch: 1,Loss: -3.213,Avg.Loss: -3.213,LR: 4.90E-07]Training epoch 99:   1%|          | 1/153 [00:00<00:05, 26.41it/s, Epoch: 99, Batch: 2,Loss: -2.934,Avg.Loss: -3.074,LR: 4.87E-07]Training epoch 99:   1%|▏         | 2/153 [00:00<00:04, 37.50it/s, Epoch: 99, Batch: 3,Loss: -2.970,Avg.Loss: -3.039,LR: 4.84E-07]Training epoch 99:   2%|▏         | 3/153 [00:00<00:03, 42.67it/s, Epoch: 99, Batch: 4,Loss: -3.046,Avg.Loss: -3.041,LR: 4.81E-07]Training epoch 99:   3%|▎         | 4/153 [00:00<00:03, 45.65it/s, Epoch: 99, Batch: 5,Loss: -3.008,Avg.Loss: -3.034,LR: 4.77E-07]Training epoch 99:   3%|▎         | 5/153 [00:00<00:03, 47.14it/s, Epoch: 99, Batch: 6,Loss: -3.119,Avg.Loss: -3.048,LR: 4.74E-07]Training epoch 99:   4%|▍         | 6/153 [00:00<00:02, 56.46it/s, Epoch: 99, Batch: 6,Loss: -3.119,Avg.Loss: -3.048,LR: 4.74E-07]Training epoch 99:   4%|▍         | 6/153 [00:00<00:02, 56.46it/s, Epoch: 99, Batch: 7,Loss: -2.760,Avg.Loss: -3.007,LR: 4.71E-07]Training epoch 99:   5%|▍         | 7/153 [00:00<00:02, 56.46it/s, Epoch: 99, Batch: 8,Loss: -3.124,Avg.Loss: -3.022,LR: 4.68E-07]Training epoch 99:   5%|▌         | 8/153 [00:00<00:02, 56.46it/s, Epoch: 99, Batch: 9,Loss: -3.101,Avg.Loss: -3.031,LR: 4.65E-07]Training epoch 99:   6%|▌         | 9/153 [00:00<00:02, 56.46it/s, Epoch: 99, Batch: 10,Loss: -3.122,Avg.Loss: -3.040,LR: 4.62E-07]Training epoch 99:   7%|▋         | 10/153 [00:00<00:02, 56.46it/s, Epoch: 99, Batch: 11,Loss: -3.037,Avg.Loss: -3.040,LR: 4.58E-07]Training epoch 99:   7%|▋         | 11/153 [00:00<00:02, 56.46it/s, Epoch: 99, Batch: 12,Loss: -3.033,Avg.Loss: -3.039,LR: 4.55E-07]Training epoch 99:   8%|▊         | 12/153 [00:00<00:02, 54.32it/s, Epoch: 99, Batch: 12,Loss: -3.033,Avg.Loss: -3.039,LR: 4.55E-07]Training epoch 99:   8%|▊         | 12/153 [00:00<00:02, 54.32it/s, Epoch: 99, Batch: 13,Loss: -3.103,Avg.Loss: -3.044,LR: 4.52E-07]Training epoch 99:   8%|▊         | 13/153 [00:00<00:02, 54.32it/s, Epoch: 99, Batch: 14,Loss: -2.909,Avg.Loss: -3.034,LR: 4.49E-07]Training epoch 99:   9%|▉         | 14/153 [00:00<00:02, 54.32it/s, Epoch: 99, Batch: 15,Loss: -3.167,Avg.Loss: -3.043,LR: 4.46E-07]Training epoch 99:  10%|▉         | 15/153 [00:00<00:02, 54.32it/s, Epoch: 99, Batch: 16,Loss: -2.857,Avg.Loss: -3.032,LR: 4.43E-07]Training epoch 99:  10%|█         | 16/153 [00:00<00:02, 54.32it/s, Epoch: 99, Batch: 17,Loss: -2.855,Avg.Loss: -3.021,LR: 4.40E-07]Training epoch 99:  11%|█         | 17/153 [00:00<00:02, 54.32it/s, Epoch: 99, Batch: 18,Loss: -3.126,Avg.Loss: -3.027,LR: 4.37E-07]Training epoch 99:  12%|█▏        | 18/153 [00:00<00:02, 54.07it/s, Epoch: 99, Batch: 18,Loss: -3.126,Avg.Loss: -3.027,LR: 4.37E-07]Training epoch 99:  12%|█▏        | 18/153 [00:00<00:02, 54.07it/s, Epoch: 99, Batch: 19,Loss: -3.588,Avg.Loss: -3.056,LR: 4.34E-07]Training epoch 99:  12%|█▏        | 19/153 [00:00<00:02, 54.07it/s, Epoch: 99, Batch: 20,Loss: -2.763,Avg.Loss: -3.042,LR: 4.31E-07]Training epoch 99:  13%|█▎        | 20/153 [00:00<00:02, 54.07it/s, Epoch: 99, Batch: 21,Loss: -3.424,Avg.Loss: -3.060,LR: 4.28E-07]Training epoch 99:  14%|█▎        | 21/153 [00:00<00:02, 54.07it/s, Epoch: 99, Batch: 22,Loss: -3.215,Avg.Loss: -3.067,LR: 4.25E-07]Training epoch 99:  14%|█▍        | 22/153 [00:00<00:02, 54.07it/s, Epoch: 99, Batch: 23,Loss: -2.968,Avg.Loss: -3.063,LR: 4.22E-07]Training epoch 99:  15%|█▌        | 23/153 [00:00<00:02, 54.07it/s, Epoch: 99, Batch: 24,Loss: -3.115,Avg.Loss: -3.065,LR: 4.19E-07]Training epoch 99:  16%|█▌        | 24/153 [00:00<00:02, 52.96it/s, Epoch: 99, Batch: 24,Loss: -3.115,Avg.Loss: -3.065,LR: 4.19E-07]Training epoch 99:  16%|█▌        | 24/153 [00:00<00:02, 52.96it/s, Epoch: 99, Batch: 25,Loss: -3.164,Avg.Loss: -3.069,LR: 4.16E-07]Training epoch 99:  16%|█▋        | 25/153 [00:00<00:02, 52.96it/s, Epoch: 99, Batch: 26,Loss: -3.407,Avg.Loss: -3.082,LR: 4.13E-07]Training epoch 99:  17%|█▋        | 26/153 [00:00<00:02, 52.96it/s, Epoch: 99, Batch: 27,Loss: -2.879,Avg.Loss: -3.074,LR: 4.10E-07]Training epoch 99:  18%|█▊        | 27/153 [00:00<00:02, 52.96it/s, Epoch: 99, Batch: 28,Loss: -2.820,Avg.Loss: -3.065,LR: 4.07E-07]Training epoch 99:  18%|█▊        | 28/153 [00:00<00:02, 52.96it/s, Epoch: 99, Batch: 29,Loss: -2.750,Avg.Loss: -3.054,LR: 4.04E-07]Training epoch 99:  19%|█▉        | 29/153 [00:00<00:02, 52.96it/s, Epoch: 99, Batch: 30,Loss: -2.768,Avg.Loss: -3.045,LR: 4.01E-07]Training epoch 99:  20%|█▉        | 30/153 [00:00<00:02, 52.84it/s, Epoch: 99, Batch: 30,Loss: -2.768,Avg.Loss: -3.045,LR: 4.01E-07]Training epoch 99:  20%|█▉        | 30/153 [00:00<00:02, 52.84it/s, Epoch: 99, Batch: 31,Loss: -2.827,Avg.Loss: -3.038,LR: 3.98E-07]Training epoch 99:  20%|██        | 31/153 [00:00<00:02, 52.84it/s, Epoch: 99, Batch: 32,Loss: -3.456,Avg.Loss: -3.051,LR: 3.96E-07]Training epoch 99:  21%|██        | 32/153 [00:00<00:02, 52.84it/s, Epoch: 99, Batch: 33,Loss: -2.836,Avg.Loss: -3.044,LR: 3.93E-07]Training epoch 99:  22%|██▏       | 33/153 [00:00<00:02, 52.84it/s, Epoch: 99, Batch: 34,Loss: -2.939,Avg.Loss: -3.041,LR: 3.90E-07]Training epoch 99:  22%|██▏       | 34/153 [00:00<00:02, 52.84it/s, Epoch: 99, Batch: 35,Loss: -3.241,Avg.Loss: -3.047,LR: 3.87E-07]Training epoch 99:  23%|██▎       | 35/153 [00:00<00:02, 52.84it/s, Epoch: 99, Batch: 36,Loss: -2.713,Avg.Loss: -3.038,LR: 3.84E-07]Training epoch 99:  24%|██▎       | 36/153 [00:00<00:02, 52.93it/s, Epoch: 99, Batch: 36,Loss: -2.713,Avg.Loss: -3.038,LR: 3.84E-07]Training epoch 99:  24%|██▎       | 36/153 [00:00<00:02, 52.93it/s, Epoch: 99, Batch: 37,Loss: -2.814,Avg.Loss: -3.032,LR: 3.81E-07]Training epoch 99:  24%|██▍       | 37/153 [00:00<00:02, 52.93it/s, Epoch: 99, Batch: 38,Loss: -3.197,Avg.Loss: -3.036,LR: 3.78E-07]Training epoch 99:  25%|██▍       | 38/153 [00:00<00:02, 52.93it/s, Epoch: 99, Batch: 39,Loss: -2.883,Avg.Loss: -3.032,LR: 3.76E-07]Training epoch 99:  25%|██▌       | 39/153 [00:00<00:02, 52.93it/s, Epoch: 99, Batch: 40,Loss: -2.662,Avg.Loss: -3.023,LR: 3.73E-07]Training epoch 99:  26%|██▌       | 40/153 [00:00<00:02, 52.93it/s, Epoch: 99, Batch: 41,Loss: -2.951,Avg.Loss: -3.021,LR: 3.70E-07]Training epoch 99:  27%|██▋       | 41/153 [00:00<00:02, 52.93it/s, Epoch: 99, Batch: 42,Loss: -3.080,Avg.Loss: -3.023,LR: 3.67E-07]Training epoch 99:  27%|██▋       | 42/153 [00:00<00:02, 52.52it/s, Epoch: 99, Batch: 42,Loss: -3.080,Avg.Loss: -3.023,LR: 3.67E-07]Training epoch 99:  27%|██▋       | 42/153 [00:00<00:02, 52.52it/s, Epoch: 99, Batch: 43,Loss: -3.205,Avg.Loss: -3.027,LR: 3.64E-07]Training epoch 99:  28%|██▊       | 43/153 [00:00<00:02, 52.52it/s, Epoch: 99, Batch: 44,Loss: -3.156,Avg.Loss: -3.030,LR: 3.62E-07]Training epoch 99:  29%|██▉       | 44/153 [00:00<00:02, 52.52it/s, Epoch: 99, Batch: 45,Loss: -2.965,Avg.Loss: -3.028,LR: 3.59E-07]Training epoch 99:  29%|██▉       | 45/153 [00:00<00:02, 52.52it/s, Epoch: 99, Batch: 46,Loss: -3.106,Avg.Loss: -3.030,LR: 3.56E-07]Training epoch 99:  30%|███       | 46/153 [00:00<00:02, 52.52it/s, Epoch: 99, Batch: 47,Loss: -3.319,Avg.Loss: -3.036,LR: 3.53E-07]Training epoch 99:  31%|███       | 47/153 [00:00<00:02, 52.52it/s, Epoch: 99, Batch: 48,Loss: -2.659,Avg.Loss: -3.028,LR: 3.51E-07]Training epoch 99:  31%|███▏      | 48/153 [00:00<00:01, 52.96it/s, Epoch: 99, Batch: 48,Loss: -2.659,Avg.Loss: -3.028,LR: 3.51E-07]Training epoch 99:  31%|███▏      | 48/153 [00:00<00:01, 52.96it/s, Epoch: 99, Batch: 49,Loss: -3.247,Avg.Loss: -3.033,LR: 3.48E-07]Training epoch 99:  32%|███▏      | 49/153 [00:00<00:01, 52.96it/s, Epoch: 99, Batch: 50,Loss: -2.420,Avg.Loss: -3.020,LR: 3.45E-07]Training epoch 99:  33%|███▎      | 50/153 [00:00<00:01, 52.96it/s, Epoch: 99, Batch: 51,Loss: -2.958,Avg.Loss: -3.019,LR: 3.43E-07]Training epoch 99:  33%|███▎      | 51/153 [00:00<00:01, 52.96it/s, Epoch: 99, Batch: 52,Loss: -3.303,Avg.Loss: -3.025,LR: 3.40E-07]Training epoch 99:  34%|███▍      | 52/153 [00:00<00:01, 52.96it/s, Epoch: 99, Batch: 53,Loss: -3.562,Avg.Loss: -3.035,LR: 3.37E-07]Training epoch 99:  35%|███▍      | 53/153 [00:01<00:01, 52.96it/s, Epoch: 99, Batch: 54,Loss: -3.273,Avg.Loss: -3.039,LR: 3.35E-07]Training epoch 99:  35%|███▌      | 54/153 [00:01<00:01, 53.14it/s, Epoch: 99, Batch: 54,Loss: -3.273,Avg.Loss: -3.039,LR: 3.35E-07]Training epoch 99:  35%|███▌      | 54/153 [00:01<00:01, 53.14it/s, Epoch: 99, Batch: 55,Loss: -3.484,Avg.Loss: -3.047,LR: 3.32E-07]Training epoch 99:  36%|███▌      | 55/153 [00:01<00:01, 53.14it/s, Epoch: 99, Batch: 56,Loss: -3.018,Avg.Loss: -3.047,LR: 3.29E-07]Training epoch 99:  37%|███▋      | 56/153 [00:01<00:01, 53.14it/s, Epoch: 99, Batch: 57,Loss: -2.450,Avg.Loss: -3.036,LR: 3.27E-07]Training epoch 99:  37%|███▋      | 57/153 [00:01<00:01, 53.14it/s, Epoch: 99, Batch: 58,Loss: -3.424,Avg.Loss: -3.043,LR: 3.24E-07]Training epoch 99:  38%|███▊      | 58/153 [00:01<00:01, 53.14it/s, Epoch: 99, Batch: 59,Loss: -3.767,Avg.Loss: -3.055,LR: 3.21E-07]Training epoch 99:  39%|███▊      | 59/153 [00:01<00:01, 53.14it/s, Epoch: 99, Batch: 60,Loss: -2.818,Avg.Loss: -3.051,LR: 3.19E-07]Training epoch 99:  39%|███▉      | 60/153 [00:01<00:01, 53.17it/s, Epoch: 99, Batch: 60,Loss: -2.818,Avg.Loss: -3.051,LR: 3.19E-07]Training epoch 99:  39%|███▉      | 60/153 [00:01<00:01, 53.17it/s, Epoch: 99, Batch: 61,Loss: -2.920,Avg.Loss: -3.049,LR: 3.16E-07]Training epoch 99:  40%|███▉      | 61/153 [00:01<00:01, 53.17it/s, Epoch: 99, Batch: 62,Loss: -2.735,Avg.Loss: -3.044,LR: 3.14E-07]Training epoch 99:  41%|████      | 62/153 [00:01<00:01, 53.17it/s, Epoch: 99, Batch: 63,Loss: -2.926,Avg.Loss: -3.042,LR: 3.11E-07]Training epoch 99:  41%|████      | 63/153 [00:01<00:01, 53.17it/s, Epoch: 99, Batch: 64,Loss: -2.911,Avg.Loss: -3.040,LR: 3.09E-07]Training epoch 99:  42%|████▏     | 64/153 [00:01<00:01, 53.17it/s, Epoch: 99, Batch: 65,Loss: -2.572,Avg.Loss: -3.033,LR: 3.06E-07]Training epoch 99:  42%|████▏     | 65/153 [00:01<00:01, 53.17it/s, Epoch: 99, Batch: 66,Loss: -2.844,Avg.Loss: -3.030,LR: 3.04E-07]Training epoch 99:  43%|████▎     | 66/153 [00:01<00:01, 53.08it/s, Epoch: 99, Batch: 66,Loss: -2.844,Avg.Loss: -3.030,LR: 3.04E-07]Training epoch 99:  43%|████▎     | 66/153 [00:01<00:01, 53.08it/s, Epoch: 99, Batch: 67,Loss: -3.410,Avg.Loss: -3.036,LR: 3.01E-07]Training epoch 99:  44%|████▍     | 67/153 [00:01<00:01, 53.08it/s, Epoch: 99, Batch: 68,Loss: -3.363,Avg.Loss: -3.041,LR: 2.98E-07]Training epoch 99:  44%|████▍     | 68/153 [00:01<00:01, 53.08it/s, Epoch: 99, Batch: 69,Loss: -2.960,Avg.Loss: -3.039,LR: 2.96E-07]Training epoch 99:  45%|████▌     | 69/153 [00:01<00:01, 53.08it/s, Epoch: 99, Batch: 70,Loss: -3.263,Avg.Loss: -3.043,LR: 2.93E-07]Training epoch 99:  46%|████▌     | 70/153 [00:01<00:01, 53.08it/s, Epoch: 99, Batch: 71,Loss: -3.121,Avg.Loss: -3.044,LR: 2.91E-07]Training epoch 99:  46%|████▋     | 71/153 [00:01<00:01, 53.08it/s, Epoch: 99, Batch: 72,Loss: -3.130,Avg.Loss: -3.045,LR: 2.89E-07]Training epoch 99:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 99, Batch: 72,Loss: -3.130,Avg.Loss: -3.045,LR: 2.89E-07]Training epoch 99:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 99, Batch: 73,Loss: -2.942,Avg.Loss: -3.044,LR: 2.86E-07]Training epoch 99:  48%|████▊     | 73/153 [00:01<00:01, 52.96it/s, Epoch: 99, Batch: 74,Loss: -3.103,Avg.Loss: -3.044,LR: 2.84E-07]Training epoch 99:  48%|████▊     | 74/153 [00:01<00:01, 52.96it/s, Epoch: 99, Batch: 75,Loss: -2.930,Avg.Loss: -3.043,LR: 2.81E-07]Training epoch 99:  49%|████▉     | 75/153 [00:01<00:01, 52.96it/s, Epoch: 99, Batch: 76,Loss: -3.325,Avg.Loss: -3.047,LR: 2.79E-07]Training epoch 99:  50%|████▉     | 76/153 [00:01<00:01, 52.96it/s, Epoch: 99, Batch: 77,Loss: -3.601,Avg.Loss: -3.054,LR: 2.76E-07]Training epoch 99:  50%|█████     | 77/153 [00:01<00:01, 52.96it/s, Epoch: 99, Batch: 78,Loss: -2.977,Avg.Loss: -3.053,LR: 2.74E-07]Training epoch 99:  51%|█████     | 78/153 [00:01<00:01, 52.91it/s, Epoch: 99, Batch: 78,Loss: -2.977,Avg.Loss: -3.053,LR: 2.74E-07]Training epoch 99:  51%|█████     | 78/153 [00:01<00:01, 52.91it/s, Epoch: 99, Batch: 79,Loss: -2.622,Avg.Loss: -3.047,LR: 2.72E-07]Training epoch 99:  52%|█████▏    | 79/153 [00:01<00:01, 52.91it/s, Epoch: 99, Batch: 80,Loss: -2.696,Avg.Loss: -3.043,LR: 2.69E-07]Training epoch 99:  52%|█████▏    | 80/153 [00:01<00:01, 52.91it/s, Epoch: 99, Batch: 81,Loss: -2.898,Avg.Loss: -3.041,LR: 2.67E-07]Training epoch 99:  53%|█████▎    | 81/153 [00:01<00:01, 52.91it/s, Epoch: 99, Batch: 82,Loss: -3.396,Avg.Loss: -3.045,LR: 2.64E-07]Training epoch 99:  54%|█████▎    | 82/153 [00:01<00:01, 52.91it/s, Epoch: 99, Batch: 83,Loss: -2.948,Avg.Loss: -3.044,LR: 2.62E-07]Training epoch 99:  54%|█████▍    | 83/153 [00:01<00:01, 52.91it/s, Epoch: 99, Batch: 84,Loss: -3.080,Avg.Loss: -3.045,LR: 2.60E-07]Training epoch 99:  55%|█████▍    | 84/153 [00:01<00:01, 53.03it/s, Epoch: 99, Batch: 84,Loss: -3.080,Avg.Loss: -3.045,LR: 2.60E-07]Training epoch 99:  55%|█████▍    | 84/153 [00:01<00:01, 53.03it/s, Epoch: 99, Batch: 85,Loss: -3.256,Avg.Loss: -3.047,LR: 2.57E-07]Training epoch 99:  56%|█████▌    | 85/153 [00:01<00:01, 53.03it/s, Epoch: 99, Batch: 86,Loss: -3.036,Avg.Loss: -3.047,LR: 2.55E-07]Training epoch 99:  56%|█████▌    | 86/153 [00:01<00:01, 53.03it/s, Epoch: 99, Batch: 87,Loss: -2.924,Avg.Loss: -3.046,LR: 2.53E-07]Training epoch 99:  57%|█████▋    | 87/153 [00:01<00:01, 53.03it/s, Epoch: 99, Batch: 88,Loss: -2.473,Avg.Loss: -3.039,LR: 2.50E-07]Training epoch 99:  58%|█████▊    | 88/153 [00:01<00:01, 53.03it/s, Epoch: 99, Batch: 89,Loss: -3.396,Avg.Loss: -3.043,LR: 2.48E-07]Training epoch 99:  58%|█████▊    | 89/153 [00:01<00:01, 53.03it/s, Epoch: 99, Batch: 90,Loss: -3.526,Avg.Loss: -3.049,LR: 2.46E-07]Training epoch 99:  59%|█████▉    | 90/153 [00:01<00:01, 52.93it/s, Epoch: 99, Batch: 90,Loss: -3.526,Avg.Loss: -3.049,LR: 2.46E-07]Training epoch 99:  59%|█████▉    | 90/153 [00:01<00:01, 52.93it/s, Epoch: 99, Batch: 91,Loss: -3.252,Avg.Loss: -3.051,LR: 2.44E-07]Training epoch 99:  59%|█████▉    | 91/153 [00:01<00:01, 52.93it/s, Epoch: 99, Batch: 92,Loss: -3.182,Avg.Loss: -3.052,LR: 2.41E-07]Training epoch 99:  60%|██████    | 92/153 [00:01<00:01, 52.93it/s, Epoch: 99, Batch: 93,Loss: -3.417,Avg.Loss: -3.056,LR: 2.39E-07]Training epoch 99:  61%|██████    | 93/153 [00:01<00:01, 52.93it/s, Epoch: 99, Batch: 94,Loss: -3.282,Avg.Loss: -3.059,LR: 2.37E-07]Training epoch 99:  61%|██████▏   | 94/153 [00:01<00:01, 52.93it/s, Epoch: 99, Batch: 95,Loss: -3.301,Avg.Loss: -3.061,LR: 2.35E-07]Training epoch 99:  62%|██████▏   | 95/153 [00:01<00:01, 52.93it/s, Epoch: 99, Batch: 96,Loss: -3.167,Avg.Loss: -3.062,LR: 2.32E-07]Training epoch 99:  63%|██████▎   | 96/153 [00:01<00:01, 52.88it/s, Epoch: 99, Batch: 96,Loss: -3.167,Avg.Loss: -3.062,LR: 2.32E-07]Training epoch 99:  63%|██████▎   | 96/153 [00:01<00:01, 52.88it/s, Epoch: 99, Batch: 97,Loss: -2.994,Avg.Loss: -3.061,LR: 2.30E-07]Training epoch 99:  63%|██████▎   | 97/153 [00:01<00:01, 52.88it/s, Epoch: 99, Batch: 98,Loss: -3.324,Avg.Loss: -3.064,LR: 2.28E-07]Training epoch 99:  64%|██████▍   | 98/153 [00:01<00:01, 52.88it/s, Epoch: 99, Batch: 99,Loss: -2.713,Avg.Loss: -3.061,LR: 2.26E-07]Training epoch 99:  65%|██████▍   | 99/153 [00:01<00:01, 52.88it/s, Epoch: 99, Batch: 100,Loss: -3.291,Avg.Loss: -3.063,LR: 2.24E-07]Training epoch 99:  65%|██████▌   | 100/153 [00:01<00:01, 52.88it/s, Epoch: 99, Batch: 101,Loss: -3.027,Avg.Loss: -3.063,LR: 2.21E-07]Training epoch 99:  66%|██████▌   | 101/153 [00:01<00:00, 52.88it/s, Epoch: 99, Batch: 102,Loss: -3.117,Avg.Loss: -3.063,LR: 2.19E-07]Training epoch 99:  67%|██████▋   | 102/153 [00:01<00:00, 52.54it/s, Epoch: 99, Batch: 102,Loss: -3.117,Avg.Loss: -3.063,LR: 2.19E-07]Training epoch 99:  67%|██████▋   | 102/153 [00:01<00:00, 52.54it/s, Epoch: 99, Batch: 103,Loss: -2.758,Avg.Loss: -3.060,LR: 2.17E-07]Training epoch 99:  67%|██████▋   | 103/153 [00:01<00:00, 52.54it/s, Epoch: 99, Batch: 104,Loss: -3.156,Avg.Loss: -3.061,LR: 2.15E-07]Training epoch 99:  68%|██████▊   | 104/153 [00:01<00:00, 52.54it/s, Epoch: 99, Batch: 105,Loss: -3.529,Avg.Loss: -3.065,LR: 2.13E-07]Training epoch 99:  69%|██████▊   | 105/153 [00:02<00:00, 52.54it/s, Epoch: 99, Batch: 106,Loss: -2.851,Avg.Loss: -3.063,LR: 2.11E-07]Training epoch 99:  69%|██████▉   | 106/153 [00:02<00:00, 52.54it/s, Epoch: 99, Batch: 107,Loss: -3.261,Avg.Loss: -3.065,LR: 2.09E-07]Training epoch 99:  70%|██████▉   | 107/153 [00:02<00:00, 52.54it/s, Epoch: 99, Batch: 108,Loss: -2.956,Avg.Loss: -3.064,LR: 2.07E-07]Training epoch 99:  71%|███████   | 108/153 [00:02<00:00, 50.72it/s, Epoch: 99, Batch: 108,Loss: -2.956,Avg.Loss: -3.064,LR: 2.07E-07]Training epoch 99:  71%|███████   | 108/153 [00:02<00:00, 50.72it/s, Epoch: 99, Batch: 109,Loss: -3.635,Avg.Loss: -3.070,LR: 2.05E-07]Training epoch 99:  71%|███████   | 109/153 [00:02<00:00, 50.72it/s, Epoch: 99, Batch: 110,Loss: -2.937,Avg.Loss: -3.068,LR: 2.02E-07]Training epoch 99:  72%|███████▏  | 110/153 [00:02<00:00, 50.72it/s, Epoch: 99, Batch: 111,Loss: -3.102,Avg.Loss: -3.069,LR: 2.00E-07]Training epoch 99:  73%|███████▎  | 111/153 [00:02<00:00, 50.72it/s, Epoch: 99, Batch: 112,Loss: -3.274,Avg.Loss: -3.070,LR: 1.98E-07]Training epoch 99:  73%|███████▎  | 112/153 [00:02<00:00, 50.72it/s, Epoch: 99, Batch: 113,Loss: -2.846,Avg.Loss: -3.068,LR: 1.96E-07]Training epoch 99:  74%|███████▍  | 113/153 [00:02<00:00, 50.72it/s, Epoch: 99, Batch: 114,Loss: -2.741,Avg.Loss: -3.066,LR: 1.94E-07]Training epoch 99:  75%|███████▍  | 114/153 [00:02<00:00, 51.44it/s, Epoch: 99, Batch: 114,Loss: -2.741,Avg.Loss: -3.066,LR: 1.94E-07]Training epoch 99:  75%|███████▍  | 114/153 [00:02<00:00, 51.44it/s, Epoch: 99, Batch: 115,Loss: -2.885,Avg.Loss: -3.064,LR: 1.92E-07]Training epoch 99:  75%|███████▌  | 115/153 [00:02<00:00, 51.44it/s, Epoch: 99, Batch: 116,Loss: -2.745,Avg.Loss: -3.061,LR: 1.90E-07]Training epoch 99:  76%|███████▌  | 116/153 [00:02<00:00, 51.44it/s, Epoch: 99, Batch: 117,Loss: -3.042,Avg.Loss: -3.061,LR: 1.88E-07]Training epoch 99:  76%|███████▋  | 117/153 [00:02<00:00, 51.44it/s, Epoch: 99, Batch: 118,Loss: -3.245,Avg.Loss: -3.063,LR: 1.86E-07]Training epoch 99:  77%|███████▋  | 118/153 [00:02<00:00, 51.44it/s, Epoch: 99, Batch: 119,Loss: -3.287,Avg.Loss: -3.065,LR: 1.84E-07]Training epoch 99:  78%|███████▊  | 119/153 [00:02<00:00, 51.44it/s, Epoch: 99, Batch: 120,Loss: -3.445,Avg.Loss: -3.068,LR: 1.82E-07]Training epoch 99:  78%|███████▊  | 120/153 [00:02<00:00, 51.32it/s, Epoch: 99, Batch: 120,Loss: -3.445,Avg.Loss: -3.068,LR: 1.82E-07]Training epoch 99:  78%|███████▊  | 120/153 [00:02<00:00, 51.32it/s, Epoch: 99, Batch: 121,Loss: -3.173,Avg.Loss: -3.069,LR: 1.80E-07]Training epoch 99:  79%|███████▉  | 121/153 [00:02<00:00, 51.32it/s, Epoch: 99, Batch: 122,Loss: -3.039,Avg.Loss: -3.068,LR: 1.78E-07]Training epoch 99:  80%|███████▉  | 122/153 [00:02<00:00, 51.32it/s, Epoch: 99, Batch: 123,Loss: -3.295,Avg.Loss: -3.070,LR: 1.76E-07]Training epoch 99:  80%|████████  | 123/153 [00:02<00:00, 51.32it/s, Epoch: 99, Batch: 124,Loss: -3.531,Avg.Loss: -3.074,LR: 1.75E-07]Training epoch 99:  81%|████████  | 124/153 [00:02<00:00, 51.32it/s, Epoch: 99, Batch: 125,Loss: -3.158,Avg.Loss: -3.075,LR: 1.73E-07]Training epoch 99:  82%|████████▏ | 125/153 [00:02<00:00, 51.32it/s, Epoch: 99, Batch: 126,Loss: -2.555,Avg.Loss: -3.070,LR: 1.71E-07]Training epoch 99:  82%|████████▏ | 126/153 [00:02<00:00, 51.84it/s, Epoch: 99, Batch: 126,Loss: -2.555,Avg.Loss: -3.070,LR: 1.71E-07]Training epoch 99:  82%|████████▏ | 126/153 [00:02<00:00, 51.84it/s, Epoch: 99, Batch: 127,Loss: -2.871,Avg.Loss: -3.069,LR: 1.69E-07]Training epoch 99:  83%|████████▎ | 127/153 [00:02<00:00, 51.84it/s, Epoch: 99, Batch: 128,Loss: -3.358,Avg.Loss: -3.071,LR: 1.67E-07]Training epoch 99:  84%|████████▎ | 128/153 [00:02<00:00, 51.84it/s, Epoch: 99, Batch: 129,Loss: -3.343,Avg.Loss: -3.073,LR: 1.65E-07]Training epoch 99:  84%|████████▍ | 129/153 [00:02<00:00, 51.84it/s, Epoch: 99, Batch: 130,Loss: -3.145,Avg.Loss: -3.074,LR: 1.63E-07]Training epoch 99:  85%|████████▍ | 130/153 [00:02<00:00, 51.84it/s, Epoch: 99, Batch: 131,Loss: -3.145,Avg.Loss: -3.074,LR: 1.61E-07]Training epoch 99:  86%|████████▌ | 131/153 [00:02<00:00, 51.84it/s, Epoch: 99, Batch: 132,Loss: -2.941,Avg.Loss: -3.073,LR: 1.60E-07]Training epoch 99:  86%|████████▋ | 132/153 [00:02<00:00, 52.21it/s, Epoch: 99, Batch: 132,Loss: -2.941,Avg.Loss: -3.073,LR: 1.60E-07]Training epoch 99:  86%|████████▋ | 132/153 [00:02<00:00, 52.21it/s, Epoch: 99, Batch: 133,Loss: -2.605,Avg.Loss: -3.070,LR: 1.58E-07]Training epoch 99:  87%|████████▋ | 133/153 [00:02<00:00, 52.21it/s, Epoch: 99, Batch: 134,Loss: -3.126,Avg.Loss: -3.070,LR: 1.56E-07]Training epoch 99:  88%|████████▊ | 134/153 [00:02<00:00, 52.21it/s, Epoch: 99, Batch: 135,Loss: -3.004,Avg.Loss: -3.070,LR: 1.54E-07]Training epoch 99:  88%|████████▊ | 135/153 [00:02<00:00, 52.21it/s, Epoch: 99, Batch: 136,Loss: -3.229,Avg.Loss: -3.071,LR: 1.52E-07]Training epoch 99:  89%|████████▉ | 136/153 [00:02<00:00, 52.21it/s, Epoch: 99, Batch: 137,Loss: -3.001,Avg.Loss: -3.070,LR: 1.51E-07]Training epoch 99:  90%|████████▉ | 137/153 [00:02<00:00, 52.21it/s, Epoch: 99, Batch: 138,Loss: -3.031,Avg.Loss: -3.070,LR: 1.49E-07]Training epoch 99:  90%|█████████ | 138/153 [00:02<00:00, 52.70it/s, Epoch: 99, Batch: 138,Loss: -3.031,Avg.Loss: -3.070,LR: 1.49E-07]Training epoch 99:  90%|█████████ | 138/153 [00:02<00:00, 52.70it/s, Epoch: 99, Batch: 139,Loss: -2.708,Avg.Loss: -3.068,LR: 1.47E-07]Training epoch 99:  91%|█████████ | 139/153 [00:02<00:00, 52.70it/s, Epoch: 99, Batch: 140,Loss: -2.887,Avg.Loss: -3.066,LR: 1.45E-07]Training epoch 99:  92%|█████████▏| 140/153 [00:02<00:00, 52.70it/s, Epoch: 99, Batch: 141,Loss: -3.185,Avg.Loss: -3.067,LR: 1.43E-07]Training epoch 99:  92%|█████████▏| 141/153 [00:02<00:00, 52.70it/s, Epoch: 99, Batch: 142,Loss: -3.478,Avg.Loss: -3.070,LR: 1.42E-07]Training epoch 99:  93%|█████████▎| 142/153 [00:02<00:00, 52.70it/s, Epoch: 99, Batch: 143,Loss: -3.039,Avg.Loss: -3.070,LR: 1.40E-07]Training epoch 99:  93%|█████████▎| 143/153 [00:02<00:00, 52.70it/s, Epoch: 99, Batch: 144,Loss: -3.237,Avg.Loss: -3.071,LR: 1.38E-07]Training epoch 99:  94%|█████████▍| 144/153 [00:02<00:00, 52.93it/s, Epoch: 99, Batch: 144,Loss: -3.237,Avg.Loss: -3.071,LR: 1.38E-07]Training epoch 99:  94%|█████████▍| 144/153 [00:02<00:00, 52.93it/s, Epoch: 99, Batch: 145,Loss: -3.487,Avg.Loss: -3.074,LR: 1.37E-07]Training epoch 99:  95%|█████████▍| 145/153 [00:02<00:00, 52.93it/s, Epoch: 99, Batch: 146,Loss: -3.118,Avg.Loss: -3.074,LR: 1.35E-07]Training epoch 99:  95%|█████████▌| 146/153 [00:02<00:00, 52.93it/s, Epoch: 99, Batch: 147,Loss: -2.841,Avg.Loss: -3.073,LR: 1.33E-07]Training epoch 99:  96%|█████████▌| 147/153 [00:02<00:00, 52.93it/s, Epoch: 99, Batch: 148,Loss: -2.740,Avg.Loss: -3.070,LR: 1.32E-07]Training epoch 99:  97%|█████████▋| 148/153 [00:02<00:00, 52.93it/s, Epoch: 99, Batch: 149,Loss: -3.093,Avg.Loss: -3.070,LR: 1.30E-07]Training epoch 99:  97%|█████████▋| 149/153 [00:02<00:00, 52.93it/s, Epoch: 99, Batch: 150,Loss: -3.338,Avg.Loss: -3.072,LR: 1.28E-07]Training epoch 99:  98%|█████████▊| 150/153 [00:02<00:00, 53.09it/s, Epoch: 99, Batch: 150,Loss: -3.338,Avg.Loss: -3.072,LR: 1.28E-07]Training epoch 99:  98%|█████████▊| 150/153 [00:02<00:00, 53.09it/s, Epoch: 99, Batch: 151,Loss: -3.266,Avg.Loss: -3.074,LR: 1.27E-07]Training epoch 99:  99%|█████████▊| 151/153 [00:02<00:00, 53.09it/s, Epoch: 99, Batch: 152,Loss: -3.488,Avg.Loss: -3.076,LR: 1.25E-07]Training epoch 99:  99%|█████████▉| 152/153 [00:02<00:00, 53.09it/s, Epoch: 99, Batch: 153,Loss: -2.920,Avg.Loss: -3.075,LR: 1.23E-07]Training epoch 99: 100%|██████████| 153/153 [00:02<00:00, 52.68it/s, Epoch: 99, Batch: 153,Loss: -2.920,Avg.Loss: -3.075,LR: 1.23E-07]
Training epoch 100:   0%|          | 0/153 [00:00<?, ?it/s]Training epoch 100:   0%|          | 0/153 [00:00<?, ?it/s, Epoch: 100, Batch: 1,Loss: -3.176,Avg.Loss: -3.176,LR: 1.22E-07]Training epoch 100:   1%|          | 1/153 [00:00<00:05, 26.28it/s, Epoch: 100, Batch: 2,Loss: -3.411,Avg.Loss: -3.294,LR: 1.20E-07]Training epoch 100:   1%|▏         | 2/153 [00:00<00:04, 34.88it/s, Epoch: 100, Batch: 3,Loss: -2.703,Avg.Loss: -3.097,LR: 1.19E-07]Training epoch 100:   2%|▏         | 3/153 [00:00<00:03, 39.98it/s, Epoch: 100, Batch: 4,Loss: -2.778,Avg.Loss: -3.017,LR: 1.17E-07]Training epoch 100:   3%|▎         | 4/153 [00:00<00:03, 44.80it/s, Epoch: 100, Batch: 5,Loss: -3.069,Avg.Loss: -3.027,LR: 1.15E-07]Training epoch 100:   3%|▎         | 5/153 [00:00<00:03, 46.57it/s, Epoch: 100, Batch: 6,Loss: -3.156,Avg.Loss: -3.049,LR: 1.14E-07]Training epoch 100:   4%|▍         | 6/153 [00:00<00:02, 55.79it/s, Epoch: 100, Batch: 6,Loss: -3.156,Avg.Loss: -3.049,LR: 1.14E-07]Training epoch 100:   4%|▍         | 6/153 [00:00<00:02, 55.79it/s, Epoch: 100, Batch: 7,Loss: -3.087,Avg.Loss: -3.054,LR: 1.12E-07]Training epoch 100:   5%|▍         | 7/153 [00:00<00:02, 55.79it/s, Epoch: 100, Batch: 8,Loss: -3.228,Avg.Loss: -3.076,LR: 1.11E-07]Training epoch 100:   5%|▌         | 8/153 [00:00<00:02, 55.79it/s, Epoch: 100, Batch: 9,Loss: -2.995,Avg.Loss: -3.067,LR: 1.09E-07]Training epoch 100:   6%|▌         | 9/153 [00:00<00:02, 55.79it/s, Epoch: 100, Batch: 10,Loss: -2.992,Avg.Loss: -3.059,LR: 1.08E-07]Training epoch 100:   7%|▋         | 10/153 [00:00<00:02, 55.79it/s, Epoch: 100, Batch: 11,Loss: -3.322,Avg.Loss: -3.083,LR: 1.06E-07]Training epoch 100:   7%|▋         | 11/153 [00:00<00:02, 55.79it/s, Epoch: 100, Batch: 12,Loss: -3.130,Avg.Loss: -3.087,LR: 1.05E-07]Training epoch 100:   8%|▊         | 12/153 [00:00<00:02, 54.03it/s, Epoch: 100, Batch: 12,Loss: -3.130,Avg.Loss: -3.087,LR: 1.05E-07]Training epoch 100:   8%|▊         | 12/153 [00:00<00:02, 54.03it/s, Epoch: 100, Batch: 13,Loss: -3.421,Avg.Loss: -3.113,LR: 1.03E-07]Training epoch 100:   8%|▊         | 13/153 [00:00<00:02, 54.03it/s, Epoch: 100, Batch: 14,Loss: -2.682,Avg.Loss: -3.082,LR: 1.02E-07]Training epoch 100:   9%|▉         | 14/153 [00:00<00:02, 54.03it/s, Epoch: 100, Batch: 15,Loss: -2.833,Avg.Loss: -3.065,LR: 1.00E-07]Training epoch 100:  10%|▉         | 15/153 [00:00<00:02, 54.03it/s, Epoch: 100, Batch: 16,Loss: -2.821,Avg.Loss: -3.050,LR: 9.89E-08]Training epoch 100:  10%|█         | 16/153 [00:00<00:02, 54.03it/s, Epoch: 100, Batch: 17,Loss: -3.351,Avg.Loss: -3.068,LR: 9.75E-08]Training epoch 100:  11%|█         | 17/153 [00:00<00:02, 54.03it/s, Epoch: 100, Batch: 18,Loss: -2.857,Avg.Loss: -3.056,LR: 9.60E-08]Training epoch 100:  12%|█▏        | 18/153 [00:00<00:02, 53.36it/s, Epoch: 100, Batch: 18,Loss: -2.857,Avg.Loss: -3.056,LR: 9.60E-08]Training epoch 100:  12%|█▏        | 18/153 [00:00<00:02, 53.36it/s, Epoch: 100, Batch: 19,Loss: -2.777,Avg.Loss: -3.041,LR: 9.46E-08]Training epoch 100:  12%|█▏        | 19/153 [00:00<00:02, 53.36it/s, Epoch: 100, Batch: 20,Loss: -3.256,Avg.Loss: -3.052,LR: 9.32E-08]Training epoch 100:  13%|█▎        | 20/153 [00:00<00:02, 53.36it/s, Epoch: 100, Batch: 21,Loss: -3.044,Avg.Loss: -3.052,LR: 9.18E-08]Training epoch 100:  14%|█▎        | 21/153 [00:00<00:02, 53.36it/s, Epoch: 100, Batch: 22,Loss: -2.671,Avg.Loss: -3.034,LR: 9.04E-08]Training epoch 100:  14%|█▍        | 22/153 [00:00<00:02, 53.36it/s, Epoch: 100, Batch: 23,Loss: -3.066,Avg.Loss: -3.036,LR: 8.91E-08]Training epoch 100:  15%|█▌        | 23/153 [00:00<00:02, 53.36it/s, Epoch: 100, Batch: 24,Loss: -2.789,Avg.Loss: -3.026,LR: 8.77E-08]Training epoch 100:  16%|█▌        | 24/153 [00:00<00:02, 52.35it/s, Epoch: 100, Batch: 24,Loss: -2.789,Avg.Loss: -3.026,LR: 8.77E-08]Training epoch 100:  16%|█▌        | 24/153 [00:00<00:02, 52.35it/s, Epoch: 100, Batch: 25,Loss: -3.197,Avg.Loss: -3.032,LR: 8.63E-08]Training epoch 100:  16%|█▋        | 25/153 [00:00<00:02, 52.35it/s, Epoch: 100, Batch: 26,Loss: -3.087,Avg.Loss: -3.035,LR: 8.50E-08]Training epoch 100:  17%|█▋        | 26/153 [00:00<00:02, 52.35it/s, Epoch: 100, Batch: 27,Loss: -3.003,Avg.Loss: -3.033,LR: 8.37E-08]Training epoch 100:  18%|█▊        | 27/153 [00:00<00:02, 52.35it/s, Epoch: 100, Batch: 28,Loss: -3.362,Avg.Loss: -3.045,LR: 8.23E-08]Training epoch 100:  18%|█▊        | 28/153 [00:00<00:02, 52.35it/s, Epoch: 100, Batch: 29,Loss: -3.420,Avg.Loss: -3.058,LR: 8.10E-08]Training epoch 100:  19%|█▉        | 29/153 [00:00<00:02, 52.35it/s, Epoch: 100, Batch: 30,Loss: -2.760,Avg.Loss: -3.048,LR: 7.97E-08]Training epoch 100:  20%|█▉        | 30/153 [00:00<00:02, 52.08it/s, Epoch: 100, Batch: 30,Loss: -2.760,Avg.Loss: -3.048,LR: 7.97E-08]Training epoch 100:  20%|█▉        | 30/153 [00:00<00:02, 52.08it/s, Epoch: 100, Batch: 31,Loss: -2.833,Avg.Loss: -3.041,LR: 7.84E-08]Training epoch 100:  20%|██        | 31/153 [00:00<00:02, 52.08it/s, Epoch: 100, Batch: 32,Loss: -2.883,Avg.Loss: -3.036,LR: 7.72E-08]Training epoch 100:  21%|██        | 32/153 [00:00<00:02, 52.08it/s, Epoch: 100, Batch: 33,Loss: -3.303,Avg.Loss: -3.044,LR: 7.59E-08]Training epoch 100:  22%|██▏       | 33/153 [00:00<00:02, 52.08it/s, Epoch: 100, Batch: 34,Loss: -2.529,Avg.Loss: -3.029,LR: 7.46E-08]Training epoch 100:  22%|██▏       | 34/153 [00:00<00:02, 52.08it/s, Epoch: 100, Batch: 35,Loss: -3.115,Avg.Loss: -3.032,LR: 7.34E-08]Training epoch 100:  23%|██▎       | 35/153 [00:00<00:02, 52.08it/s, Epoch: 100, Batch: 36,Loss: -3.193,Avg.Loss: -3.036,LR: 7.21E-08]Training epoch 100:  24%|██▎       | 36/153 [00:00<00:02, 52.05it/s, Epoch: 100, Batch: 36,Loss: -3.193,Avg.Loss: -3.036,LR: 7.21E-08]Training epoch 100:  24%|██▎       | 36/153 [00:00<00:02, 52.05it/s, Epoch: 100, Batch: 37,Loss: -3.211,Avg.Loss: -3.041,LR: 7.09E-08]Training epoch 100:  24%|██▍       | 37/153 [00:00<00:02, 52.05it/s, Epoch: 100, Batch: 38,Loss: -3.086,Avg.Loss: -3.042,LR: 6.97E-08]Training epoch 100:  25%|██▍       | 38/153 [00:00<00:02, 52.05it/s, Epoch: 100, Batch: 39,Loss: -2.458,Avg.Loss: -3.027,LR: 6.85E-08]Training epoch 100:  25%|██▌       | 39/153 [00:00<00:02, 52.05it/s, Epoch: 100, Batch: 40,Loss: -2.989,Avg.Loss: -3.026,LR: 6.73E-08]Training epoch 100:  26%|██▌       | 40/153 [00:00<00:02, 52.05it/s, Epoch: 100, Batch: 41,Loss: -3.257,Avg.Loss: -3.032,LR: 6.61E-08]Training epoch 100:  27%|██▋       | 41/153 [00:00<00:02, 52.05it/s, Epoch: 100, Batch: 42,Loss: -3.161,Avg.Loss: -3.035,LR: 6.49E-08]Training epoch 100:  27%|██▋       | 42/153 [00:00<00:02, 52.06it/s, Epoch: 100, Batch: 42,Loss: -3.161,Avg.Loss: -3.035,LR: 6.49E-08]Training epoch 100:  27%|██▋       | 42/153 [00:00<00:02, 52.06it/s, Epoch: 100, Batch: 43,Loss: -3.167,Avg.Loss: -3.038,LR: 6.38E-08]Training epoch 100:  28%|██▊       | 43/153 [00:00<00:02, 52.06it/s, Epoch: 100, Batch: 44,Loss: -2.755,Avg.Loss: -3.031,LR: 6.26E-08]Training epoch 100:  29%|██▉       | 44/153 [00:00<00:02, 52.06it/s, Epoch: 100, Batch: 45,Loss: -2.803,Avg.Loss: -3.026,LR: 6.15E-08]Training epoch 100:  29%|██▉       | 45/153 [00:00<00:02, 52.06it/s, Epoch: 100, Batch: 46,Loss: -2.916,Avg.Loss: -3.024,LR: 6.03E-08]Training epoch 100:  30%|███       | 46/153 [00:00<00:02, 52.06it/s, Epoch: 100, Batch: 47,Loss: -3.223,Avg.Loss: -3.028,LR: 5.92E-08]Training epoch 100:  31%|███       | 47/153 [00:00<00:02, 52.06it/s, Epoch: 100, Batch: 48,Loss: -3.295,Avg.Loss: -3.034,LR: 5.81E-08]Training epoch 100:  31%|███▏      | 48/153 [00:00<00:02, 52.43it/s, Epoch: 100, Batch: 48,Loss: -3.295,Avg.Loss: -3.034,LR: 5.81E-08]Training epoch 100:  31%|███▏      | 48/153 [00:00<00:02, 52.43it/s, Epoch: 100, Batch: 49,Loss: -3.068,Avg.Loss: -3.034,LR: 5.70E-08]Training epoch 100:  32%|███▏      | 49/153 [00:00<00:01, 52.43it/s, Epoch: 100, Batch: 50,Loss: -3.094,Avg.Loss: -3.036,LR: 5.59E-08]Training epoch 100:  33%|███▎      | 50/153 [00:00<00:01, 52.43it/s, Epoch: 100, Batch: 51,Loss: -3.420,Avg.Loss: -3.043,LR: 5.48E-08]Training epoch 100:  33%|███▎      | 51/153 [00:00<00:01, 52.43it/s, Epoch: 100, Batch: 52,Loss: -3.165,Avg.Loss: -3.046,LR: 5.38E-08]Training epoch 100:  34%|███▍      | 52/153 [00:01<00:01, 52.43it/s, Epoch: 100, Batch: 53,Loss: -2.992,Avg.Loss: -3.045,LR: 5.27E-08]Training epoch 100:  35%|███▍      | 53/153 [00:01<00:01, 52.43it/s, Epoch: 100, Batch: 54,Loss: -3.025,Avg.Loss: -3.044,LR: 5.16E-08]Training epoch 100:  35%|███▌      | 54/153 [00:01<00:01, 52.97it/s, Epoch: 100, Batch: 54,Loss: -3.025,Avg.Loss: -3.044,LR: 5.16E-08]Training epoch 100:  35%|███▌      | 54/153 [00:01<00:01, 52.97it/s, Epoch: 100, Batch: 55,Loss: -2.768,Avg.Loss: -3.039,LR: 5.06E-08]Training epoch 100:  36%|███▌      | 55/153 [00:01<00:01, 52.97it/s, Epoch: 100, Batch: 56,Loss: -3.268,Avg.Loss: -3.043,LR: 4.96E-08]Training epoch 100:  37%|███▋      | 56/153 [00:01<00:01, 52.97it/s, Epoch: 100, Batch: 57,Loss: -2.963,Avg.Loss: -3.042,LR: 4.86E-08]Training epoch 100:  37%|███▋      | 57/153 [00:01<00:01, 52.97it/s, Epoch: 100, Batch: 58,Loss: -2.703,Avg.Loss: -3.036,LR: 4.76E-08]Training epoch 100:  38%|███▊      | 58/153 [00:01<00:01, 52.97it/s, Epoch: 100, Batch: 59,Loss: -2.977,Avg.Loss: -3.035,LR: 4.66E-08]Training epoch 100:  39%|███▊      | 59/153 [00:01<00:01, 52.97it/s, Epoch: 100, Batch: 60,Loss: -3.252,Avg.Loss: -3.039,LR: 4.56E-08]Training epoch 100:  39%|███▉      | 60/153 [00:01<00:01, 53.17it/s, Epoch: 100, Batch: 60,Loss: -3.252,Avg.Loss: -3.039,LR: 4.56E-08]Training epoch 100:  39%|███▉      | 60/153 [00:01<00:01, 53.17it/s, Epoch: 100, Batch: 61,Loss: -3.201,Avg.Loss: -3.041,LR: 4.46E-08]Training epoch 100:  40%|███▉      | 61/153 [00:01<00:01, 53.17it/s, Epoch: 100, Batch: 62,Loss: -2.592,Avg.Loss: -3.034,LR: 4.36E-08]Training epoch 100:  41%|████      | 62/153 [00:01<00:01, 53.17it/s, Epoch: 100, Batch: 63,Loss: -3.249,Avg.Loss: -3.037,LR: 4.27E-08]Training epoch 100:  41%|████      | 63/153 [00:01<00:01, 53.17it/s, Epoch: 100, Batch: 64,Loss: -3.532,Avg.Loss: -3.045,LR: 4.17E-08]Training epoch 100:  42%|████▏     | 64/153 [00:01<00:01, 53.17it/s, Epoch: 100, Batch: 65,Loss: -3.193,Avg.Loss: -3.047,LR: 4.08E-08]Training epoch 100:  42%|████▏     | 65/153 [00:01<00:01, 53.17it/s, Epoch: 100, Batch: 66,Loss: -3.389,Avg.Loss: -3.053,LR: 3.99E-08]Training epoch 100:  43%|████▎     | 66/153 [00:01<00:01, 53.27it/s, Epoch: 100, Batch: 66,Loss: -3.389,Avg.Loss: -3.053,LR: 3.99E-08]Training epoch 100:  43%|████▎     | 66/153 [00:01<00:01, 53.27it/s, Epoch: 100, Batch: 67,Loss: -3.094,Avg.Loss: -3.053,LR: 3.90E-08]Training epoch 100:  44%|████▍     | 67/153 [00:01<00:01, 53.27it/s, Epoch: 100, Batch: 68,Loss: -3.216,Avg.Loss: -3.056,LR: 3.81E-08]Training epoch 100:  44%|████▍     | 68/153 [00:01<00:01, 53.27it/s, Epoch: 100, Batch: 69,Loss: -3.290,Avg.Loss: -3.059,LR: 3.72E-08]Training epoch 100:  45%|████▌     | 69/153 [00:01<00:01, 53.27it/s, Epoch: 100, Batch: 70,Loss: -3.228,Avg.Loss: -3.061,LR: 3.63E-08]Training epoch 100:  46%|████▌     | 70/153 [00:01<00:01, 53.27it/s, Epoch: 100, Batch: 71,Loss: -2.829,Avg.Loss: -3.058,LR: 3.54E-08]Training epoch 100:  46%|████▋     | 71/153 [00:01<00:01, 53.27it/s, Epoch: 100, Batch: 72,Loss: -2.628,Avg.Loss: -3.052,LR: 3.46E-08]Training epoch 100:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 100, Batch: 72,Loss: -2.628,Avg.Loss: -3.052,LR: 3.46E-08]Training epoch 100:  47%|████▋     | 72/153 [00:01<00:01, 52.96it/s, Epoch: 100, Batch: 73,Loss: -3.104,Avg.Loss: -3.053,LR: 3.37E-08]Training epoch 100:  48%|████▊     | 73/153 [00:01<00:01, 52.96it/s, Epoch: 100, Batch: 74,Loss: -2.990,Avg.Loss: -3.052,LR: 3.29E-08]Training epoch 100:  48%|████▊     | 74/153 [00:01<00:01, 52.96it/s, Epoch: 100, Batch: 75,Loss: -2.894,Avg.Loss: -3.050,LR: 3.21E-08]Training epoch 100:  49%|████▉     | 75/153 [00:01<00:01, 52.96it/s, Epoch: 100, Batch: 76,Loss: -3.212,Avg.Loss: -3.052,LR: 3.12E-08]Training epoch 100:  50%|████▉     | 76/153 [00:01<00:01, 52.96it/s, Epoch: 100, Batch: 77,Loss: -3.286,Avg.Loss: -3.055,LR: 3.04E-08]Training epoch 100:  50%|█████     | 77/153 [00:01<00:01, 52.96it/s, Epoch: 100, Batch: 78,Loss: -3.161,Avg.Loss: -3.056,LR: 2.96E-08]Training epoch 100:  51%|█████     | 78/153 [00:01<00:01, 52.20it/s, Epoch: 100, Batch: 78,Loss: -3.161,Avg.Loss: -3.056,LR: 2.96E-08]Training epoch 100:  51%|█████     | 78/153 [00:01<00:01, 52.20it/s, Epoch: 100, Batch: 79,Loss: -2.930,Avg.Loss: -3.055,LR: 2.89E-08]Training epoch 100:  52%|█████▏    | 79/153 [00:01<00:01, 52.20it/s, Epoch: 100, Batch: 80,Loss: -3.635,Avg.Loss: -3.062,LR: 2.81E-08]Training epoch 100:  52%|█████▏    | 80/153 [00:01<00:01, 52.20it/s, Epoch: 100, Batch: 81,Loss: -2.830,Avg.Loss: -3.059,LR: 2.73E-08]Training epoch 100:  53%|█████▎    | 81/153 [00:01<00:01, 52.20it/s, Epoch: 100, Batch: 82,Loss: -2.976,Avg.Loss: -3.058,LR: 2.66E-08]Training epoch 100:  54%|█████▎    | 82/153 [00:01<00:01, 52.20it/s, Epoch: 100, Batch: 83,Loss: -3.291,Avg.Loss: -3.061,LR: 2.58E-08]Training epoch 100:  54%|█████▍    | 83/153 [00:01<00:01, 52.20it/s, Epoch: 100, Batch: 84,Loss: -2.889,Avg.Loss: -3.059,LR: 2.51E-08]Training epoch 100:  55%|█████▍    | 84/153 [00:01<00:01, 52.51it/s, Epoch: 100, Batch: 84,Loss: -2.889,Avg.Loss: -3.059,LR: 2.51E-08]Training epoch 100:  55%|█████▍    | 84/153 [00:01<00:01, 52.51it/s, Epoch: 100, Batch: 85,Loss: -3.168,Avg.Loss: -3.060,LR: 2.44E-08]Training epoch 100:  56%|█████▌    | 85/153 [00:01<00:01, 52.51it/s, Epoch: 100, Batch: 86,Loss: -3.301,Avg.Loss: -3.063,LR: 2.37E-08]Training epoch 100:  56%|█████▌    | 86/153 [00:01<00:01, 52.51it/s, Epoch: 100, Batch: 87,Loss: -3.722,Avg.Loss: -3.071,LR: 2.30E-08]Training epoch 100:  57%|█████▋    | 87/153 [00:01<00:01, 52.51it/s, Epoch: 100, Batch: 88,Loss: -3.515,Avg.Loss: -3.076,LR: 2.23E-08]Training epoch 100:  58%|█████▊    | 88/153 [00:01<00:01, 52.51it/s, Epoch: 100, Batch: 89,Loss: -2.852,Avg.Loss: -3.073,LR: 2.16E-08]Training epoch 100:  58%|█████▊    | 89/153 [00:01<00:01, 52.51it/s, Epoch: 100, Batch: 90,Loss: -3.234,Avg.Loss: -3.075,LR: 2.09E-08]Training epoch 100:  59%|█████▉    | 90/153 [00:01<00:01, 52.62it/s, Epoch: 100, Batch: 90,Loss: -3.234,Avg.Loss: -3.075,LR: 2.09E-08]Training epoch 100:  59%|█████▉    | 90/153 [00:01<00:01, 52.62it/s, Epoch: 100, Batch: 91,Loss: -2.789,Avg.Loss: -3.072,LR: 2.03E-08]Training epoch 100:  59%|█████▉    | 91/153 [00:01<00:01, 52.62it/s, Epoch: 100, Batch: 92,Loss: -2.960,Avg.Loss: -3.071,LR: 1.96E-08]Training epoch 100:  60%|██████    | 92/153 [00:01<00:01, 52.62it/s, Epoch: 100, Batch: 93,Loss: -3.181,Avg.Loss: -3.072,LR: 1.90E-08]Training epoch 100:  61%|██████    | 93/153 [00:01<00:01, 52.62it/s, Epoch: 100, Batch: 94,Loss: -3.394,Avg.Loss: -3.075,LR: 1.83E-08]Training epoch 100:  61%|██████▏   | 94/153 [00:01<00:01, 52.62it/s, Epoch: 100, Batch: 95,Loss: -3.176,Avg.Loss: -3.076,LR: 1.77E-08]Training epoch 100:  62%|██████▏   | 95/153 [00:01<00:01, 52.62it/s, Epoch: 100, Batch: 96,Loss: -3.310,Avg.Loss: -3.079,LR: 1.71E-08]Training epoch 100:  63%|██████▎   | 96/153 [00:01<00:01, 52.77it/s, Epoch: 100, Batch: 96,Loss: -3.310,Avg.Loss: -3.079,LR: 1.71E-08]Training epoch 100:  63%|██████▎   | 96/153 [00:01<00:01, 52.77it/s, Epoch: 100, Batch: 97,Loss: -3.292,Avg.Loss: -3.081,LR: 1.65E-08]Training epoch 100:  63%|██████▎   | 97/153 [00:01<00:01, 52.77it/s, Epoch: 100, Batch: 98,Loss: -2.856,Avg.Loss: -3.079,LR: 1.59E-08]Training epoch 100:  64%|██████▍   | 98/153 [00:01<00:01, 52.77it/s, Epoch: 100, Batch: 99,Loss: -2.989,Avg.Loss: -3.078,LR: 1.54E-08]Training epoch 100:  65%|██████▍   | 99/153 [00:01<00:01, 52.77it/s, Epoch: 100, Batch: 100,Loss: -2.957,Avg.Loss: -3.076,LR: 1.48E-08]Training epoch 100:  65%|██████▌   | 100/153 [00:01<00:01, 52.77it/s, Epoch: 100, Batch: 101,Loss: -2.953,Avg.Loss: -3.075,LR: 1.42E-08]Training epoch 100:  66%|██████▌   | 101/153 [00:01<00:00, 52.77it/s, Epoch: 100, Batch: 102,Loss: -3.083,Avg.Loss: -3.075,LR: 1.37E-08]Training epoch 100:  67%|██████▋   | 102/153 [00:01<00:00, 52.87it/s, Epoch: 100, Batch: 102,Loss: -3.083,Avg.Loss: -3.075,LR: 1.37E-08]Training epoch 100:  67%|██████▋   | 102/153 [00:01<00:00, 52.87it/s, Epoch: 100, Batch: 103,Loss: -3.320,Avg.Loss: -3.078,LR: 1.32E-08]Training epoch 100:  67%|██████▋   | 103/153 [00:01<00:00, 52.87it/s, Epoch: 100, Batch: 104,Loss: -2.915,Avg.Loss: -3.076,LR: 1.27E-08]Training epoch 100:  68%|██████▊   | 104/153 [00:01<00:00, 52.87it/s, Epoch: 100, Batch: 105,Loss: -2.816,Avg.Loss: -3.074,LR: 1.21E-08]Training epoch 100:  69%|██████▊   | 105/153 [00:02<00:00, 52.87it/s, Epoch: 100, Batch: 106,Loss: -3.505,Avg.Loss: -3.078,LR: 1.16E-08]Training epoch 100:  69%|██████▉   | 106/153 [00:02<00:00, 52.87it/s, Epoch: 100, Batch: 107,Loss: -3.152,Avg.Loss: -3.078,LR: 1.11E-08]Training epoch 100:  70%|██████▉   | 107/153 [00:02<00:00, 52.87it/s, Epoch: 100, Batch: 108,Loss: -2.931,Avg.Loss: -3.077,LR: 1.07E-08]Training epoch 100:  71%|███████   | 108/153 [00:02<00:00, 52.81it/s, Epoch: 100, Batch: 108,Loss: -2.931,Avg.Loss: -3.077,LR: 1.07E-08]Training epoch 100:  71%|███████   | 108/153 [00:02<00:00, 52.81it/s, Epoch: 100, Batch: 109,Loss: -3.284,Avg.Loss: -3.079,LR: 1.02E-08]Training epoch 100:  71%|███████   | 109/153 [00:02<00:00, 52.81it/s, Epoch: 100, Batch: 110,Loss: -3.560,Avg.Loss: -3.083,LR: 9.75E-09]Training epoch 100:  72%|███████▏  | 110/153 [00:02<00:00, 52.81it/s, Epoch: 100, Batch: 111,Loss: -3.195,Avg.Loss: -3.084,LR: 9.30E-09]Training epoch 100:  73%|███████▎  | 111/153 [00:02<00:00, 52.81it/s, Epoch: 100, Batch: 112,Loss: -2.792,Avg.Loss: -3.082,LR: 8.87E-09]Training epoch 100:  73%|███████▎  | 112/153 [00:02<00:00, 52.81it/s, Epoch: 100, Batch: 113,Loss: -2.580,Avg.Loss: -3.077,LR: 8.43E-09]Training epoch 100:  74%|███████▍  | 113/153 [00:02<00:00, 52.81it/s, Epoch: 100, Batch: 114,Loss: -2.768,Avg.Loss: -3.075,LR: 8.02E-09]Training epoch 100:  75%|███████▍  | 114/153 [00:02<00:00, 52.99it/s, Epoch: 100, Batch: 114,Loss: -2.768,Avg.Loss: -3.075,LR: 8.02E-09]Training epoch 100:  75%|███████▍  | 114/153 [00:02<00:00, 52.99it/s, Epoch: 100, Batch: 115,Loss: -3.453,Avg.Loss: -3.078,LR: 7.61E-09]Training epoch 100:  75%|███████▌  | 115/153 [00:02<00:00, 52.99it/s, Epoch: 100, Batch: 116,Loss: -2.851,Avg.Loss: -3.076,LR: 7.21E-09]Training epoch 100:  76%|███████▌  | 116/153 [00:02<00:00, 52.99it/s, Epoch: 100, Batch: 117,Loss: -2.705,Avg.Loss: -3.073,LR: 6.82E-09]Training epoch 100:  76%|███████▋  | 117/153 [00:02<00:00, 52.99it/s, Epoch: 100, Batch: 118,Loss: -3.212,Avg.Loss: -3.074,LR: 6.45E-09]Training epoch 100:  77%|███████▋  | 118/153 [00:02<00:00, 52.99it/s, Epoch: 100, Batch: 119,Loss: -2.935,Avg.Loss: -3.073,LR: 6.09E-09]Training epoch 100:  78%|███████▊  | 119/153 [00:02<00:00, 52.99it/s, Epoch: 100, Batch: 120,Loss: -3.241,Avg.Loss: -3.074,LR: 5.74E-09]Training epoch 100:  78%|███████▊  | 120/153 [00:02<00:00, 53.04it/s, Epoch: 100, Batch: 120,Loss: -3.241,Avg.Loss: -3.074,LR: 5.74E-09]Training epoch 100:  78%|███████▊  | 120/153 [00:02<00:00, 53.04it/s, Epoch: 100, Batch: 121,Loss: -3.232,Avg.Loss: -3.075,LR: 5.39E-09]Training epoch 100:  79%|███████▉  | 121/153 [00:02<00:00, 53.04it/s, Epoch: 100, Batch: 122,Loss: -3.434,Avg.Loss: -3.078,LR: 5.07E-09]Training epoch 100:  80%|███████▉  | 122/153 [00:02<00:00, 53.04it/s, Epoch: 100, Batch: 123,Loss: -3.164,Avg.Loss: -3.079,LR: 4.74E-09]Training epoch 100:  80%|████████  | 123/153 [00:02<00:00, 53.04it/s, Epoch: 100, Batch: 124,Loss: -3.271,Avg.Loss: -3.081,LR: 4.43E-09]Training epoch 100:  81%|████████  | 124/153 [00:02<00:00, 53.04it/s, Epoch: 100, Batch: 125,Loss: -2.848,Avg.Loss: -3.079,LR: 4.13E-09]Training epoch 100:  82%|████████▏ | 125/153 [00:02<00:00, 53.04it/s, Epoch: 100, Batch: 126,Loss: -3.385,Avg.Loss: -3.081,LR: 3.84E-09]Training epoch 100:  82%|████████▏ | 126/153 [00:02<00:00, 53.14it/s, Epoch: 100, Batch: 126,Loss: -3.385,Avg.Loss: -3.081,LR: 3.84E-09]Training epoch 100:  82%|████████▏ | 126/153 [00:02<00:00, 53.14it/s, Epoch: 100, Batch: 127,Loss: -3.300,Avg.Loss: -3.083,LR: 3.56E-09]Training epoch 100:  83%|████████▎ | 127/153 [00:02<00:00, 53.14it/s, Epoch: 100, Batch: 128,Loss: -3.363,Avg.Loss: -3.085,LR: 3.29E-09]Training epoch 100:  84%|████████▎ | 128/153 [00:02<00:00, 53.14it/s, Epoch: 100, Batch: 129,Loss: -3.319,Avg.Loss: -3.087,LR: 3.04E-09]Training epoch 100:  84%|████████▍ | 129/153 [00:02<00:00, 53.14it/s, Epoch: 100, Batch: 130,Loss: -2.944,Avg.Loss: -3.086,LR: 2.79E-09]Training epoch 100:  85%|████████▍ | 130/153 [00:02<00:00, 53.14it/s, Epoch: 100, Batch: 131,Loss: -2.870,Avg.Loss: -3.084,LR: 2.55E-09]Training epoch 100:  86%|████████▌ | 131/153 [00:02<00:00, 53.14it/s, Epoch: 100, Batch: 132,Loss: -3.193,Avg.Loss: -3.085,LR: 2.32E-09]Training epoch 100:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 100, Batch: 132,Loss: -3.193,Avg.Loss: -3.085,LR: 2.32E-09]Training epoch 100:  86%|████████▋ | 132/153 [00:02<00:00, 53.28it/s, Epoch: 100, Batch: 133,Loss: -2.394,Avg.Loss: -3.080,LR: 2.10E-09]Training epoch 100:  87%|████████▋ | 133/153 [00:02<00:00, 53.28it/s, Epoch: 100, Batch: 134,Loss: -2.775,Avg.Loss: -3.078,LR: 1.91E-09]Training epoch 100:  88%|████████▊ | 134/153 [00:02<00:00, 53.28it/s, Epoch: 100, Batch: 135,Loss: -3.389,Avg.Loss: -3.080,LR: 1.71E-09]Training epoch 100:  88%|████████▊ | 135/153 [00:02<00:00, 53.28it/s, Epoch: 100, Batch: 136,Loss: -2.766,Avg.Loss: -3.078,LR: 1.52E-09]Training epoch 100:  89%|████████▉ | 136/153 [00:02<00:00, 53.28it/s, Epoch: 100, Batch: 137,Loss: -3.048,Avg.Loss: -3.077,LR: 1.36E-09]Training epoch 100:  90%|████████▉ | 137/153 [00:02<00:00, 53.28it/s, Epoch: 100, Batch: 138,Loss: -3.138,Avg.Loss: -3.078,LR: 1.19E-09]Training epoch 100:  90%|█████████ | 138/153 [00:02<00:00, 53.48it/s, Epoch: 100, Batch: 138,Loss: -3.138,Avg.Loss: -3.078,LR: 1.19E-09]Training epoch 100:  90%|█████████ | 138/153 [00:02<00:00, 53.48it/s, Epoch: 100, Batch: 139,Loss: -2.932,Avg.Loss: -3.077,LR: 1.03E-09]Training epoch 100:  91%|█████████ | 139/153 [00:02<00:00, 53.48it/s, Epoch: 100, Batch: 140,Loss: -3.500,Avg.Loss: -3.080,LR: 8.94E-10]Training epoch 100:  92%|█████████▏| 140/153 [00:02<00:00, 53.48it/s, Epoch: 100, Batch: 141,Loss: -3.149,Avg.Loss: -3.080,LR: 7.60E-10]Training epoch 100:  92%|█████████▏| 141/153 [00:02<00:00, 53.48it/s, Epoch: 100, Batch: 142,Loss: -2.897,Avg.Loss: -3.079,LR: 6.41E-10]Training epoch 100:  93%|█████████▎| 142/153 [00:02<00:00, 53.48it/s, Epoch: 100, Batch: 143,Loss: -2.978,Avg.Loss: -3.078,LR: 5.22E-10]Training epoch 100:  93%|█████████▎| 143/153 [00:02<00:00, 53.48it/s, Epoch: 100, Batch: 144,Loss: -2.684,Avg.Loss: -3.075,LR: 4.32E-10]Training epoch 100:  94%|█████████▍| 144/153 [00:02<00:00, 53.51it/s, Epoch: 100, Batch: 144,Loss: -2.684,Avg.Loss: -3.075,LR: 4.32E-10]Training epoch 100:  94%|█████████▍| 144/153 [00:02<00:00, 53.51it/s, Epoch: 100, Batch: 145,Loss: -2.879,Avg.Loss: -3.074,LR: 3.43E-10]Training epoch 100:  95%|█████████▍| 145/153 [00:02<00:00, 53.51it/s, Epoch: 100, Batch: 146,Loss: -3.022,Avg.Loss: -3.074,LR: 2.53E-10]Training epoch 100:  95%|█████████▌| 146/153 [00:02<00:00, 53.51it/s, Epoch: 100, Batch: 147,Loss: -3.230,Avg.Loss: -3.075,LR: 1.94E-10]Training epoch 100:  96%|█████████▌| 147/153 [00:02<00:00, 53.51it/s, Epoch: 100, Batch: 148,Loss: -3.215,Avg.Loss: -3.076,LR: 1.34E-10]Training epoch 100:  97%|█████████▋| 148/153 [00:02<00:00, 53.51it/s, Epoch: 100, Batch: 149,Loss: -3.176,Avg.Loss: -3.076,LR: 8.94E-11]Training epoch 100:  97%|█████████▋| 149/153 [00:02<00:00, 53.51it/s, Epoch: 100, Batch: 150,Loss: -3.512,Avg.Loss: -3.079,LR: 4.47E-11]Training epoch 100:  98%|█████████▊| 150/153 [00:02<00:00, 53.34it/s, Epoch: 100, Batch: 150,Loss: -3.512,Avg.Loss: -3.079,LR: 4.47E-11]Training epoch 100:  98%|█████████▊| 150/153 [00:02<00:00, 53.34it/s, Epoch: 100, Batch: 151,Loss: -2.828,Avg.Loss: -3.078,LR: 1.49E-11]Training epoch 100:  99%|█████████▊| 151/153 [00:02<00:00, 53.34it/s, Epoch: 100, Batch: 152,Loss: -3.204,Avg.Loss: -3.079,LR: 0.00E+00]Training epoch 100:  99%|█████████▉| 152/153 [00:02<00:00, 53.34it/s, Epoch: 100, Batch: 153,Loss: -2.922,Avg.Loss: -3.077,LR: 0.00E+00]Training epoch 100: 100%|██████████| 153/153 [00:02<00:00, 52.86it/s, Epoch: 100, Batch: 153,Loss: -2.922,Avg.Loss: -3.077,LR: 0.00E+00]
Finished training
317.4525718688965Plot results
function [run_morpheus] finished in 1295 ms
function [run_morpheus] finished in 1273 ms
function [run_morpheus] finished in 1278 ms
function [run_morpheus] finished in 1288 ms
function [run_morpheus] finished in 1289 ms
function [run_morpheus] finished in 1318 ms
function [run_morpheus] finished in 1270 ms
function [run_morpheus] finished in 1265 ms
function [run_morpheus] finished in 1308 ms
function [run_morpheus] finished in 1353 ms
function [run_morpheus] finished in 1278 ms
function [run_morpheus] finished in 1301 ms
function [run_morpheus] finished in 1351 ms
function [run_morpheus] finished in 1291 ms
function [run_morpheus] finished in 1303 ms
function [run_morpheus] finished in 1259 ms
function [run_morpheus] finished in 1259 ms
function [run_morpheus] finished in 1295 ms
function [run_morpheus] finished in 1298 ms
function [run_morpheus] finished in 1288 ms
function [run_morpheus] finished in 1303 ms
function [run_morpheus] finished in 1281 ms
function [run_morpheus] finished in 1276 ms
function [run_morpheus] finished in 1289 ms
function [run_morpheus] finished in 1281 ms
function [run_morpheus] finished in 1312 ms
function [run_morpheus] finished in 1292 ms
function [run_morpheus] finished in 1295 ms
function [run_morpheus] finished in 1283 ms
function [run_morpheus] finished in 1289 ms
function [run_morpheus] finished in 1304 ms
function [run_morpheus] finished in 1246 ms
function [run_morpheus] finished in 1295 ms
function [run_morpheus] finished in 1276 ms
function [run_morpheus] finished in 1278 ms
function [run_morpheus] finished in 1255 ms
function [run_morpheus] finished in 1317 ms
function [run_morpheus] finished in 1288 ms
function [run_morpheus] finished in 1321 ms
function [run_morpheus] finished in 1320 ms
function [run_morpheus] finished in 1276 ms
function [run_morpheus] finished in 1291 ms
function [run_morpheus] finished in 1293 ms
function [run_morpheus] finished in 1289 ms
function [run_morpheus] finished in 1246 ms
function [run_morpheus] finished in 1280 ms
function [run_morpheus] finished in 1291 ms
function [run_morpheus] finished in 1283 ms
function [run_morpheus] finished in 1285 ms
function [run_morpheus] finished in 1333 ms
function [run_morpheus] finished in 1348 ms
function [run_morpheus] finished in 1266 ms
function [run_morpheus] finished in 1303 ms
function [run_morpheus] finished in 1312 ms
function [run_morpheus] finished in 1264 ms
function [run_morpheus] finished in 1267 ms
function [run_morpheus] finished in 1298 ms
function [run_morpheus] finished in 1337 ms
function [run_morpheus] finished in 1285 ms
function [run_morpheus] finished in 1306 ms
function [run_morpheus] finished in 1289 ms
function [run_morpheus] finished in 1288 ms
function [run_morpheus] finished in 1279 ms
function [run_morpheus] finished in 1315 ms
function [run_morpheus] finished in 1280 ms
function [run_morpheus] finished in 1323 ms
function [run_morpheus] finished in 1252 ms
function [run_morpheus] finished in 1306 ms
function [run_morpheus] finished in 1305 ms
function [run_morpheus] finished in 1284 ms
function [run_morpheus] finished in 1306 ms
function [run_morpheus] finished in 1266 ms
function [run_morpheus] finished in 1313 ms
function [run_morpheus] finished in 1288 ms
function [run_morpheus] finished in 1298 ms
function [run_morpheus] finished in 1348 ms
function [run_morpheus] finished in 1269 ms
function [run_morpheus] finished in 1304 ms
function [run_morpheus] finished in 1271 ms
function [run_morpheus] finished in 1292 ms
function [run_morpheus] finished in 1264 ms
function [run_morpheus] finished in 1285 ms
function [run_morpheus] finished in 1281 ms
function [run_morpheus] finished in 1279 ms
function [run_morpheus] finished in 1295 ms
function [run_morpheus] finished in 1251 ms
function [run_morpheus] finished in 1319 ms
function [run_morpheus] finished in 1291 ms
function [run_morpheus] finished in 1247 ms
function [run_morpheus] finished in 1323 ms
function [run_morpheus] finished in 1293 ms
function [run_morpheus] finished in 1302 ms
function [run_morpheus] finished in 1272 ms
function [run_morpheus] finished in 1316 ms
function [run_morpheus] finished in 1317 ms
function [run_morpheus] finished in 1274 ms
function [run_morpheus] finished in 1266 ms
function [run_morpheus] finished in 1277 ms
function [run_morpheus] finished in 1270 ms
function [run_morpheus] finished in 1256 ms
