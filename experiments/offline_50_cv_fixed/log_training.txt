Initialize priorInitialize generative modelfunction [run_morpheus] finished in 550 ms
function [run_morpheus] finished in 558 ms
Initialize amortizerInitialize trainerfunction [run_morpheus] finished in 535 ms
function [run_morpheus] finished in 563 ms
Initialization finishedStart reading datafunction [read_offline_data] finished in 29291 ms
Finished reading dataStart trainingTraining epoch 1:   0%|          | 0/23 [00:00<?, ?it/s]Training epoch 1:   0%|          | 0/23 [00:01<?, ?it/s, Epoch: 1, Batch: 0,Loss: -3.015,Avg.Loss: -3.015,L.Slope: NA]Training epoch 1:   4%|▍         | 1/23 [00:01<00:33,  1.52s/it, Epoch: 1, Batch: 0,Loss: -3.015,Avg.Loss: -3.015,L.Slope: NA]Training epoch 1:   4%|▍         | 1/23 [00:01<00:33,  1.52s/it, Epoch: 1, Batch: 1,Loss: -2.114,Avg.Loss: -2.565,L.Slope: NA]Training epoch 1:   9%|▊         | 2/23 [00:01<00:16,  1.31it/s, Epoch: 1, Batch: 1,Loss: -2.114,Avg.Loss: -2.565,L.Slope: NA]Training epoch 1:   9%|▊         | 2/23 [00:01<00:16,  1.31it/s, Epoch: 1, Batch: 2,Loss: -2.505,Avg.Loss: -2.545,L.Slope: NA]Training epoch 1:  13%|█▎        | 3/23 [00:01<00:10,  1.93it/s, Epoch: 1, Batch: 2,Loss: -2.505,Avg.Loss: -2.545,L.Slope: NA]Training epoch 1:  13%|█▎        | 3/23 [00:02<00:10,  1.93it/s, Epoch: 1, Batch: 3,Loss: -2.846,Avg.Loss: -2.620,L.Slope: NA]Training epoch 1:  17%|█▋        | 4/23 [00:02<00:07,  2.49it/s, Epoch: 1, Batch: 3,Loss: -2.846,Avg.Loss: -2.620,L.Slope: NA]Training epoch 1:  17%|█▋        | 4/23 [00:02<00:07,  2.49it/s, Epoch: 1, Batch: 4,Loss: -2.912,Avg.Loss: -2.678,L.Slope: NA]Training epoch 1:  22%|██▏       | 5/23 [00:02<00:06,  2.95it/s, Epoch: 1, Batch: 4,Loss: -2.912,Avg.Loss: -2.678,L.Slope: NA]Training epoch 1:  22%|██▏       | 5/23 [00:02<00:06,  2.95it/s, Epoch: 1, Batch: 5,Loss: -3.046,Avg.Loss: -2.740,L.Slope: NA]Training epoch 1:  26%|██▌       | 6/23 [00:02<00:05,  3.33it/s, Epoch: 1, Batch: 5,Loss: -3.046,Avg.Loss: -2.740,L.Slope: NA]Training epoch 1:  26%|██▌       | 6/23 [00:02<00:05,  3.33it/s, Epoch: 1, Batch: 6,Loss: -2.713,Avg.Loss: -2.736,L.Slope: NA]Training epoch 1:  30%|███       | 7/23 [00:02<00:04,  3.63it/s, Epoch: 1, Batch: 6,Loss: -2.713,Avg.Loss: -2.736,L.Slope: NA]Training epoch 1:  30%|███       | 7/23 [00:03<00:04,  3.63it/s, Epoch: 1, Batch: 7,Loss: -2.452,Avg.Loss: -2.700,L.Slope: NA]Training epoch 1:  35%|███▍      | 8/23 [00:03<00:03,  3.85it/s, Epoch: 1, Batch: 7,Loss: -2.452,Avg.Loss: -2.700,L.Slope: NA]Training epoch 1:  35%|███▍      | 8/23 [00:03<00:03,  3.85it/s, Epoch: 1, Batch: 8,Loss: -2.761,Avg.Loss: -2.707,L.Slope: NA]Training epoch 1:  39%|███▉      | 9/23 [00:03<00:03,  4.02it/s, Epoch: 1, Batch: 8,Loss: -2.761,Avg.Loss: -2.707,L.Slope: NA]Training epoch 1:  39%|███▉      | 9/23 [00:03<00:03,  4.02it/s, Epoch: 1, Batch: 9,Loss: -2.762,Avg.Loss: -2.712,L.Slope: NA]Training epoch 1:  43%|████▎     | 10/23 [00:03<00:03,  4.14it/s, Epoch: 1, Batch: 9,Loss: -2.762,Avg.Loss: -2.712,L.Slope: NA]Training epoch 1:  43%|████▎     | 10/23 [00:03<00:03,  4.14it/s, Epoch: 1, Batch: 10,Loss: -2.704,Avg.Loss: -2.712,L.Slope: NA]Training epoch 1:  48%|████▊     | 11/23 [00:03<00:02,  4.22it/s, Epoch: 1, Batch: 10,Loss: -2.704,Avg.Loss: -2.712,L.Slope: NA]Training epoch 1:  48%|████▊     | 11/23 [00:04<00:02,  4.22it/s, Epoch: 1, Batch: 11,Loss: -2.805,Avg.Loss: -2.720,L.Slope: NA]Training epoch 1:  52%|█████▏    | 12/23 [00:04<00:02,  4.28it/s, Epoch: 1, Batch: 11,Loss: -2.805,Avg.Loss: -2.720,L.Slope: NA]Training epoch 1:  52%|█████▏    | 12/23 [00:04<00:02,  4.28it/s, Epoch: 1, Batch: 12,Loss: -2.724,Avg.Loss: -2.720,L.Slope: NA]Training epoch 1:  57%|█████▋    | 13/23 [00:04<00:02,  4.32it/s, Epoch: 1, Batch: 12,Loss: -2.724,Avg.Loss: -2.720,L.Slope: NA]Training epoch 1:  57%|█████▋    | 13/23 [00:04<00:02,  4.32it/s, Epoch: 1, Batch: 13,Loss: -3.082,Avg.Loss: -2.746,L.Slope: NA]Training epoch 1:  61%|██████    | 14/23 [00:04<00:02,  4.36it/s, Epoch: 1, Batch: 13,Loss: -3.082,Avg.Loss: -2.746,L.Slope: NA]Training epoch 1:  61%|██████    | 14/23 [00:04<00:02,  4.36it/s, Epoch: 1, Batch: 14,Loss: -2.665,Avg.Loss: -2.740,L.Slope: NA]Training epoch 1:  65%|██████▌   | 15/23 [00:04<00:01,  4.38it/s, Epoch: 1, Batch: 14,Loss: -2.665,Avg.Loss: -2.740,L.Slope: NA]Training epoch 1:  65%|██████▌   | 15/23 [00:04<00:01,  4.38it/s, Epoch: 1, Batch: 15,Loss: -2.869,Avg.Loss: -2.748,L.Slope: NA]Training epoch 1:  70%|██████▉   | 16/23 [00:04<00:01,  4.39it/s, Epoch: 1, Batch: 15,Loss: -2.869,Avg.Loss: -2.748,L.Slope: NA]Training epoch 1:  70%|██████▉   | 16/23 [00:05<00:01,  4.39it/s, Epoch: 1, Batch: 16,Loss: -2.573,Avg.Loss: -2.738,L.Slope: NA]Training epoch 1:  74%|███████▍  | 17/23 [00:05<00:01,  4.41it/s, Epoch: 1, Batch: 16,Loss: -2.573,Avg.Loss: -2.738,L.Slope: NA]Training epoch 1:  74%|███████▍  | 17/23 [00:05<00:01,  4.41it/s, Epoch: 1, Batch: 17,Loss: -2.805,Avg.Loss: -2.742,L.Slope: NA]Training epoch 1:  78%|███████▊  | 18/23 [00:05<00:01,  4.42it/s, Epoch: 1, Batch: 17,Loss: -2.805,Avg.Loss: -2.742,L.Slope: NA]Training epoch 1:  78%|███████▊  | 18/23 [00:05<00:01,  4.42it/s, Epoch: 1, Batch: 18,Loss: -2.392,Avg.Loss: -2.723,L.Slope: NA]Training epoch 1:  83%|████████▎ | 19/23 [00:05<00:00,  4.42it/s, Epoch: 1, Batch: 18,Loss: -2.392,Avg.Loss: -2.723,L.Slope: NA]Training epoch 1:  83%|████████▎ | 19/23 [00:05<00:00,  4.42it/s, Epoch: 1, Batch: 19,Loss: -2.305,Avg.Loss: -2.703,L.Slope: NA]Training epoch 1:  87%|████████▋ | 20/23 [00:05<00:00,  4.42it/s, Epoch: 1, Batch: 19,Loss: -2.305,Avg.Loss: -2.703,L.Slope: NA]Training epoch 1:  87%|████████▋ | 20/23 [00:06<00:00,  4.42it/s, Epoch: 1, Batch: 20,Loss: -2.780,Avg.Loss: -2.706,L.Slope: NA]Training epoch 1:  91%|█████████▏| 21/23 [00:06<00:00,  4.39it/s, Epoch: 1, Batch: 20,Loss: -2.780,Avg.Loss: -2.706,L.Slope: NA]Training epoch 1:  91%|█████████▏| 21/23 [00:06<00:00,  4.39it/s, Epoch: 1, Batch: 21,Loss: -2.761,Avg.Loss: -2.709,L.Slope: NA]Training epoch 1:  96%|█████████▌| 22/23 [00:06<00:00,  4.38it/s, Epoch: 1, Batch: 21,Loss: -2.761,Avg.Loss: -2.709,L.Slope: NA]Training epoch 1:  96%|█████████▌| 22/23 [00:06<00:00,  4.38it/s, Epoch: 1, Batch: 22,Loss: -2.894,Avg.Loss: -2.717,L.Slope: NA]Training epoch 1: 100%|██████████| 23/23 [00:06<00:00,  4.22it/s, Epoch: 1, Batch: 22,Loss: -2.894,Avg.Loss: -2.717,L.Slope: NA]Training epoch 1: 100%|██████████| 23/23 [00:06<00:00,  3.52it/s, Epoch: 1, Batch: 22,Loss: -2.894,Avg.Loss: -2.717,L.Slope: NA]
Training epoch 2:   0%|          | 0/23 [00:00<?, ?it/s]Training epoch 2:   0%|          | 0/23 [00:00<?, ?it/s, Epoch: 2, Batch: 0,Loss: -1.874,Avg.Loss: -1.874,L.Slope: NA]Training epoch 2:   4%|▍         | 1/23 [00:00<00:05,  4.37it/s, Epoch: 2, Batch: 0,Loss: -1.874,Avg.Loss: -1.874,L.Slope: NA]Training epoch 2:   4%|▍         | 1/23 [00:00<00:05,  4.37it/s, Epoch: 2, Batch: 1,Loss: -2.314,Avg.Loss: -2.094,L.Slope: NA]Training epoch 2:   9%|▊         | 2/23 [00:00<00:04,  4.39it/s, Epoch: 2, Batch: 1,Loss: -2.314,Avg.Loss: -2.094,L.Slope: NA]Training epoch 2:   9%|▊         | 2/23 [00:00<00:04,  4.39it/s, Epoch: 2, Batch: 2,Loss: -2.212,Avg.Loss: -2.133,L.Slope: NA]Training epoch 2:  13%|█▎        | 3/23 [00:00<00:04,  4.38it/s, Epoch: 2, Batch: 2,Loss: -2.212,Avg.Loss: -2.133,L.Slope: NA]Training epoch 2:  13%|█▎        | 3/23 [00:00<00:04,  4.38it/s, Epoch: 2, Batch: 3,Loss: -2.526,Avg.Loss: -2.232,L.Slope: NA]Training epoch 2:  17%|█▋        | 4/23 [00:00<00:04,  4.39it/s, Epoch: 2, Batch: 3,Loss: -2.526,Avg.Loss: -2.232,L.Slope: NA]Training epoch 2:  17%|█▋        | 4/23 [00:01<00:04,  4.39it/s, Epoch: 2, Batch: 4,Loss: -2.799,Avg.Loss: -2.345,L.Slope: NA]Training epoch 2:  22%|██▏       | 5/23 [00:01<00:04,  4.40it/s, Epoch: 2, Batch: 4,Loss: -2.799,Avg.Loss: -2.345,L.Slope: NA]Training epoch 2:  22%|██▏       | 5/23 [00:01<00:04,  4.40it/s, Epoch: 2, Batch: 5,Loss: -1.977,Avg.Loss: -2.284,L.Slope: NA]Training epoch 2:  26%|██▌       | 6/23 [00:01<00:03,  4.41it/s, Epoch: 2, Batch: 5,Loss: -1.977,Avg.Loss: -2.284,L.Slope: NA]Training epoch 2:  26%|██▌       | 6/23 [00:01<00:03,  4.41it/s, Epoch: 2, Batch: 6,Loss: -2.704,Avg.Loss: -2.344,L.Slope: NA]Training epoch 2:  30%|███       | 7/23 [00:01<00:03,  4.41it/s, Epoch: 2, Batch: 6,Loss: -2.704,Avg.Loss: -2.344,L.Slope: NA]Training epoch 2:  30%|███       | 7/23 [00:01<00:03,  4.41it/s, Epoch: 2, Batch: 7,Loss: -2.916,Avg.Loss: -2.415,L.Slope: NA]Training epoch 2:  35%|███▍      | 8/23 [00:01<00:03,  4.42it/s, Epoch: 2, Batch: 7,Loss: -2.916,Avg.Loss: -2.415,L.Slope: NA]Training epoch 2:  35%|███▍      | 8/23 [00:02<00:03,  4.42it/s, Epoch: 2, Batch: 8,Loss: -2.517,Avg.Loss: -2.427,L.Slope: NA]Training epoch 2:  39%|███▉      | 9/23 [00:02<00:03,  4.41it/s, Epoch: 2, Batch: 8,Loss: -2.517,Avg.Loss: -2.427,L.Slope: NA]Training epoch 2:  39%|███▉      | 9/23 [00:02<00:03,  4.41it/s, Epoch: 2, Batch: 9,Loss: -2.615,Avg.Loss: -2.446,L.Slope: NA]Training epoch 2:  43%|████▎     | 10/23 [00:02<00:02,  4.40it/s, Epoch: 2, Batch: 9,Loss: -2.615,Avg.Loss: -2.446,L.Slope: NA]Training epoch 2:  43%|████▎     | 10/23 [00:02<00:02,  4.40it/s, Epoch: 2, Batch: 10,Loss: -2.702,Avg.Loss: -2.469,L.Slope: NA]Training epoch 2:  48%|████▊     | 11/23 [00:02<00:02,  4.40it/s, Epoch: 2, Batch: 10,Loss: -2.702,Avg.Loss: -2.469,L.Slope: NA]Training epoch 2:  48%|████▊     | 11/23 [00:02<00:02,  4.40it/s, Epoch: 2, Batch: 11,Loss: -2.366,Avg.Loss: -2.460,L.Slope: NA]Training epoch 2:  52%|█████▏    | 12/23 [00:02<00:02,  4.38it/s, Epoch: 2, Batch: 11,Loss: -2.366,Avg.Loss: -2.460,L.Slope: NA]Training epoch 2:  52%|█████▏    | 12/23 [00:02<00:02,  4.38it/s, Epoch: 2, Batch: 12,Loss: -2.656,Avg.Loss: -2.475,L.Slope: NA]Training epoch 2:  57%|█████▋    | 13/23 [00:02<00:02,  4.30it/s, Epoch: 2, Batch: 12,Loss: -2.656,Avg.Loss: -2.475,L.Slope: NA]Training epoch 2:  57%|█████▋    | 13/23 [00:03<00:02,  4.30it/s, Epoch: 2, Batch: 13,Loss: -2.649,Avg.Loss: -2.488,L.Slope: NA]Training epoch 2:  61%|██████    | 14/23 [00:03<00:02,  4.32it/s, Epoch: 2, Batch: 13,Loss: -2.649,Avg.Loss: -2.488,L.Slope: NA]Training epoch 2:  61%|██████    | 14/23 [00:03<00:02,  4.32it/s, Epoch: 2, Batch: 14,Loss: -3.071,Avg.Loss: -2.527,L.Slope: NA]Training epoch 2:  65%|██████▌   | 15/23 [00:03<00:01,  4.34it/s, Epoch: 2, Batch: 14,Loss: -3.071,Avg.Loss: -2.527,L.Slope: NA]Training epoch 2:  65%|██████▌   | 15/23 [00:03<00:01,  4.34it/s, Epoch: 2, Batch: 15,Loss: -2.710,Avg.Loss: -2.538,L.Slope: NA]Training epoch 2:  70%|██████▉   | 16/23 [00:03<00:01,  4.28it/s, Epoch: 2, Batch: 15,Loss: -2.710,Avg.Loss: -2.538,L.Slope: NA]Training epoch 2:  70%|██████▉   | 16/23 [00:03<00:01,  4.28it/s, Epoch: 2, Batch: 16,Loss: -2.569,Avg.Loss: -2.540,L.Slope: NA]Training epoch 2:  74%|███████▍  | 17/23 [00:03<00:01,  4.30it/s, Epoch: 2, Batch: 16,Loss: -2.569,Avg.Loss: -2.540,L.Slope: NA]Training epoch 2:  74%|███████▍  | 17/23 [00:04<00:01,  4.30it/s, Epoch: 2, Batch: 17,Loss: -3.168,Avg.Loss: -2.575,L.Slope: NA]Training epoch 2:  78%|███████▊  | 18/23 [00:04<00:01,  4.31it/s, Epoch: 2, Batch: 17,Loss: -3.168,Avg.Loss: -2.575,L.Slope: NA]Training epoch 2:  78%|███████▊  | 18/23 [00:04<00:01,  4.31it/s, Epoch: 2, Batch: 18,Loss: -2.432,Avg.Loss: -2.567,L.Slope: NA]Training epoch 2:  83%|████████▎ | 19/23 [00:04<00:00,  4.31it/s, Epoch: 2, Batch: 18,Loss: -2.432,Avg.Loss: -2.567,L.Slope: NA]Training epoch 2:  83%|████████▎ | 19/23 [00:04<00:00,  4.31it/s, Epoch: 2, Batch: 19,Loss: -3.064,Avg.Loss: -2.592,L.Slope: NA]Training epoch 2:  87%|████████▋ | 20/23 [00:04<00:00,  4.34it/s, Epoch: 2, Batch: 19,Loss: -3.064,Avg.Loss: -2.592,L.Slope: NA]Training epoch 2:  87%|████████▋ | 20/23 [00:04<00:00,  4.34it/s, Epoch: 2, Batch: 20,Loss: -2.518,Avg.Loss: -2.589,L.Slope: NA]Training epoch 2:  91%|█████████▏| 21/23 [00:04<00:00,  4.32it/s, Epoch: 2, Batch: 20,Loss: -2.518,Avg.Loss: -2.589,L.Slope: NA]Training epoch 2:  91%|█████████▏| 21/23 [00:05<00:00,  4.32it/s, Epoch: 2, Batch: 21,Loss: -2.905,Avg.Loss: -2.603,L.Slope: NA]Training epoch 2:  96%|█████████▌| 22/23 [00:05<00:00,  4.29it/s, Epoch: 2, Batch: 21,Loss: -2.905,Avg.Loss: -2.603,L.Slope: NA]Training epoch 2:  96%|█████████▌| 22/23 [00:05<00:00,  4.29it/s, Epoch: 2, Batch: 22,Loss: -3.228,Avg.Loss: -2.630,L.Slope: NA]Training epoch 2: 100%|██████████| 23/23 [00:05<00:00,  4.28it/s, Epoch: 2, Batch: 22,Loss: -3.228,Avg.Loss: -2.630,L.Slope: NA]Training epoch 2: 100%|██████████| 23/23 [00:05<00:00,  4.34it/s, Epoch: 2, Batch: 22,Loss: -3.228,Avg.Loss: -2.630,L.Slope: NA]
Training epoch 3:   0%|          | 0/23 [00:00<?, ?it/s]