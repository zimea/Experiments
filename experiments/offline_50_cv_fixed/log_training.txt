Initialize priorInitialize generative modelfunction [run_morpheus] finished in 542 ms
function [run_morpheus] finished in 506 ms
Initialize amortizerInitialize trainerfunction [run_morpheus] finished in 504 ms
function [run_morpheus] finished in 615 ms
Initialization finishedStart reading datafunction [read_offline_data] finished in 159508 ms
Finished reading dataStart trainingTraining epoch 1:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 1:   0%|          | 0/341 [00:05<?, ?it/s, Epoch: 1, Batch: 1,Loss: 2.986,Avg.Loss: 2.986,LR: 5.00E-04]Training epoch 1:   0%|          | 1/341 [00:05<32:36,  5.75s/it, Epoch: 1, Batch: 1,Loss: 2.986,Avg.Loss: 2.986,LR: 5.00E-04]Training epoch 1:   0%|          | 1/341 [00:05<32:36,  5.75s/it, Epoch: 1, Batch: 2,Loss: 2.759,Avg.Loss: 2.873,LR: 5.00E-04]Training epoch 1:   1%|          | 2/341 [00:05<32:30,  5.75s/it, Epoch: 1, Batch: 3,Loss: 2.802,Avg.Loss: 2.849,LR: 5.00E-04]Training epoch 1:   1%|          | 3/341 [00:05<32:24,  5.75s/it, Epoch: 1, Batch: 4,Loss: 2.833,Avg.Loss: 2.845,LR: 5.00E-04]Training epoch 1:   1%|          | 4/341 [00:05<32:18,  5.75s/it, Epoch: 1, Batch: 5,Loss: 2.735,Avg.Loss: 2.823,LR: 5.00E-04]Training epoch 1:   1%|▏         | 5/341 [00:05<32:13,  5.75s/it, Epoch: 1, Batch: 6,Loss: 2.672,Avg.Loss: 2.798,LR: 5.00E-04]Training epoch 1:   2%|▏         | 6/341 [00:05<32:07,  5.75s/it, Epoch: 1, Batch: 7,Loss: 2.802,Avg.Loss: 2.798,LR: 5.00E-04]Training epoch 1:   2%|▏         | 7/341 [00:05<03:26,  1.62it/s, Epoch: 1, Batch: 7,Loss: 2.802,Avg.Loss: 2.798,LR: 5.00E-04]Training epoch 1:   2%|▏         | 7/341 [00:05<03:26,  1.62it/s, Epoch: 1, Batch: 8,Loss: 2.786,Avg.Loss: 2.797,LR: 5.00E-04]Training epoch 1:   2%|▏         | 8/341 [00:05<03:25,  1.62it/s, Epoch: 1, Batch: 9,Loss: 2.537,Avg.Loss: 2.768,LR: 5.00E-04]Training epoch 1:   3%|▎         | 9/341 [00:05<03:25,  1.62it/s, Epoch: 1, Batch: 10,Loss: 2.707,Avg.Loss: 2.762,LR: 5.00E-04]Training epoch 1:   3%|▎         | 10/341 [00:05<03:24,  1.62it/s, Epoch: 1, Batch: 11,Loss: 2.504,Avg.Loss: 2.738,LR: 5.00E-04]Training epoch 1:   3%|▎         | 11/341 [00:05<03:24,  1.62it/s, Epoch: 1, Batch: 12,Loss: 2.692,Avg.Loss: 2.735,LR: 5.00E-04]Training epoch 1:   4%|▎         | 12/341 [00:05<03:23,  1.62it/s, Epoch: 1, Batch: 13,Loss: 2.717,Avg.Loss: 2.733,LR: 5.00E-04]Training epoch 1:   4%|▍         | 13/341 [00:05<01:32,  3.55it/s, Epoch: 1, Batch: 13,Loss: 2.717,Avg.Loss: 2.733,LR: 5.00E-04]Training epoch 1:   4%|▍         | 13/341 [00:06<01:32,  3.55it/s, Epoch: 1, Batch: 14,Loss: 2.744,Avg.Loss: 2.734,LR: 5.00E-04]Training epoch 1:   4%|▍         | 14/341 [00:06<01:32,  3.55it/s, Epoch: 1, Batch: 15,Loss: 2.368,Avg.Loss: 2.710,LR: 5.00E-04]Training epoch 1:   4%|▍         | 15/341 [00:06<01:31,  3.55it/s, Epoch: 1, Batch: 16,Loss: 2.703,Avg.Loss: 2.709,LR: 5.00E-04]Training epoch 1:   5%|▍         | 16/341 [00:06<01:31,  3.55it/s, Epoch: 1, Batch: 17,Loss: 2.755,Avg.Loss: 2.712,LR: 5.00E-04]Training epoch 1:   5%|▍         | 17/341 [00:06<01:31,  3.55it/s, Epoch: 1, Batch: 18,Loss: 2.768,Avg.Loss: 2.715,LR: 5.00E-04]Training epoch 1:   5%|▌         | 18/341 [00:06<01:31,  3.55it/s, Epoch: 1, Batch: 19,Loss: 2.774,Avg.Loss: 2.718,LR: 5.00E-04]Training epoch 1:   6%|▌         | 19/341 [00:06<00:53,  6.07it/s, Epoch: 1, Batch: 19,Loss: 2.774,Avg.Loss: 2.718,LR: 5.00E-04]Training epoch 1:   6%|▌         | 19/341 [00:06<00:53,  6.07it/s, Epoch: 1, Batch: 20,Loss: 2.610,Avg.Loss: 2.713,LR: 5.00E-04]Training epoch 1:   6%|▌         | 20/341 [00:06<00:52,  6.07it/s, Epoch: 1, Batch: 21,Loss: 2.713,Avg.Loss: 2.713,LR: 5.00E-04]Training epoch 1:   6%|▌         | 21/341 [00:06<00:52,  6.07it/s, Epoch: 1, Batch: 22,Loss: 2.430,Avg.Loss: 2.700,LR: 5.00E-04]Training epoch 1:   6%|▋         | 22/341 [00:06<00:52,  6.07it/s, Epoch: 1, Batch: 23,Loss: 2.616,Avg.Loss: 2.696,LR: 5.00E-04]Training epoch 1:   7%|▋         | 23/341 [00:06<00:52,  6.07it/s, Epoch: 1, Batch: 24,Loss: 2.518,Avg.Loss: 2.689,LR: 5.00E-04]Training epoch 1:   7%|▋         | 24/341 [00:06<00:52,  6.07it/s, Epoch: 1, Batch: 25,Loss: 2.403,Avg.Loss: 2.677,LR: 5.00E-04]Training epoch 1:   7%|▋         | 25/341 [00:06<00:34,  9.29it/s, Epoch: 1, Batch: 25,Loss: 2.403,Avg.Loss: 2.677,LR: 5.00E-04]Training epoch 1:   7%|▋         | 25/341 [00:06<00:34,  9.29it/s, Epoch: 1, Batch: 26,Loss: 2.598,Avg.Loss: 2.674,LR: 5.00E-04]Training epoch 1:   8%|▊         | 26/341 [00:06<00:33,  9.29it/s, Epoch: 1, Batch: 27,Loss: 2.490,Avg.Loss: 2.668,LR: 5.00E-04]Training epoch 1:   8%|▊         | 27/341 [00:06<00:33,  9.29it/s, Epoch: 1, Batch: 28,Loss: 2.416,Avg.Loss: 2.659,LR: 5.00E-04]Training epoch 1:   8%|▊         | 28/341 [00:06<00:33,  9.29it/s, Epoch: 1, Batch: 29,Loss: 2.306,Avg.Loss: 2.646,LR: 5.00E-04]Training epoch 1:   9%|▊         | 29/341 [00:06<00:33,  9.29it/s, Epoch: 1, Batch: 30,Loss: 2.277,Avg.Loss: 2.634,LR: 5.00E-04]Training epoch 1:   9%|▉         | 30/341 [00:06<00:33,  9.29it/s, Epoch: 1, Batch: 31,Loss: 2.105,Avg.Loss: 2.617,LR: 5.00E-04]Training epoch 1:   9%|▉         | 31/341 [00:06<00:23, 13.18it/s, Epoch: 1, Batch: 31,Loss: 2.105,Avg.Loss: 2.617,LR: 5.00E-04]Training epoch 1:   9%|▉         | 31/341 [00:06<00:23, 13.18it/s, Epoch: 1, Batch: 32,Loss: 2.341,Avg.Loss: 2.608,LR: 5.00E-04]Training epoch 1:   9%|▉         | 32/341 [00:06<00:23, 13.18it/s, Epoch: 1, Batch: 33,Loss: 2.152,Avg.Loss: 2.595,LR: 5.00E-04]Training epoch 1:  10%|▉         | 33/341 [00:06<00:23, 13.18it/s, Epoch: 1, Batch: 34,Loss: 2.175,Avg.Loss: 2.582,LR: 5.00E-04]Training epoch 1:  10%|▉         | 34/341 [00:06<00:23, 13.18it/s, Epoch: 1, Batch: 35,Loss: 1.993,Avg.Loss: 2.565,LR: 5.00E-04]Training epoch 1:  10%|█         | 35/341 [00:06<00:23, 13.18it/s, Epoch: 1, Batch: 36,Loss: 1.956,Avg.Loss: 2.548,LR: 5.00E-04]Training epoch 1:  11%|█         | 36/341 [00:06<00:23, 13.18it/s, Epoch: 1, Batch: 37,Loss: 2.011,Avg.Loss: 2.534,LR: 5.00E-04]Training epoch 1:  11%|█         | 37/341 [00:06<00:17, 17.74it/s, Epoch: 1, Batch: 37,Loss: 2.011,Avg.Loss: 2.534,LR: 5.00E-04]Training epoch 1:  11%|█         | 37/341 [00:06<00:17, 17.74it/s, Epoch: 1, Batch: 38,Loss: 1.984,Avg.Loss: 2.519,LR: 5.00E-04]Training epoch 1:  11%|█         | 38/341 [00:06<00:17, 17.74it/s, Epoch: 1, Batch: 39,Loss: 2.139,Avg.Loss: 2.510,LR: 5.00E-04]Training epoch 1:  11%|█▏        | 39/341 [00:06<00:17, 17.74it/s, Epoch: 1, Batch: 40,Loss: 1.905,Avg.Loss: 2.495,LR: 5.00E-04]Training epoch 1:  12%|█▏        | 40/341 [00:06<00:16, 17.74it/s, Epoch: 1, Batch: 41,Loss: 1.802,Avg.Loss: 2.478,LR: 5.00E-04]Training epoch 1:  12%|█▏        | 41/341 [00:06<00:16, 17.74it/s, Epoch: 1, Batch: 42,Loss: 1.773,Avg.Loss: 2.461,LR: 5.00E-04]Training epoch 1:  12%|█▏        | 42/341 [00:06<00:16, 17.74it/s, Epoch: 1, Batch: 43,Loss: 1.987,Avg.Loss: 2.450,LR: 5.00E-04]Training epoch 1:  13%|█▎        | 43/341 [00:06<00:13, 22.53it/s, Epoch: 1, Batch: 43,Loss: 1.987,Avg.Loss: 2.450,LR: 5.00E-04]Training epoch 1:  13%|█▎        | 43/341 [00:06<00:13, 22.53it/s, Epoch: 1, Batch: 44,Loss: 1.816,Avg.Loss: 2.435,LR: 5.00E-04]Training epoch 1:  13%|█▎        | 44/341 [00:06<00:13, 22.53it/s, Epoch: 1, Batch: 45,Loss: 2.175,Avg.Loss: 2.430,LR: 5.00E-04]Training epoch 1:  13%|█▎        | 45/341 [00:06<00:13, 22.53it/s, Epoch: 1, Batch: 46,Loss: 2.075,Avg.Loss: 2.422,LR: 5.00E-04]Training epoch 1:  13%|█▎        | 46/341 [00:06<00:13, 22.53it/s, Epoch: 1, Batch: 47,Loss: 1.904,Avg.Loss: 2.411,LR: 5.00E-04]Training epoch 1:  14%|█▍        | 47/341 [00:06<00:13, 22.53it/s, Epoch: 1, Batch: 48,Loss: 1.861,Avg.Loss: 2.400,LR: 5.00E-04]Training epoch 1:  14%|█▍        | 48/341 [00:06<00:13, 22.53it/s, Epoch: 1, Batch: 49,Loss: 1.865,Avg.Loss: 2.389,LR: 5.00E-04]Training epoch 1:  14%|█▍        | 49/341 [00:06<00:10, 27.37it/s, Epoch: 1, Batch: 49,Loss: 1.865,Avg.Loss: 2.389,LR: 5.00E-04]Training epoch 1:  14%|█▍        | 49/341 [00:06<00:10, 27.37it/s, Epoch: 1, Batch: 50,Loss: 1.651,Avg.Loss: 2.374,LR: 5.00E-04]Training epoch 1:  15%|█▍        | 50/341 [00:06<00:10, 27.37it/s, Epoch: 1, Batch: 51,Loss: 1.828,Avg.Loss: 2.363,LR: 5.00E-04]Training epoch 1:  15%|█▍        | 51/341 [00:06<00:10, 27.37it/s, Epoch: 1, Batch: 52,Loss: 1.978,Avg.Loss: 2.356,LR: 5.00E-04]Training epoch 1:  15%|█▌        | 52/341 [00:06<00:10, 27.37it/s, Epoch: 1, Batch: 53,Loss: 1.871,Avg.Loss: 2.347,LR: 5.00E-04]Training epoch 1:  16%|█▌        | 53/341 [00:06<00:10, 27.37it/s, Epoch: 1, Batch: 54,Loss: 1.970,Avg.Loss: 2.340,LR: 5.00E-04]Training epoch 1:  16%|█▌        | 54/341 [00:06<00:10, 27.37it/s, Epoch: 1, Batch: 55,Loss: 1.998,Avg.Loss: 2.333,LR: 5.00E-04]Training epoch 1:  16%|█▌        | 55/341 [00:06<00:08, 32.06it/s, Epoch: 1, Batch: 55,Loss: 1.998,Avg.Loss: 2.333,LR: 5.00E-04]Training epoch 1:  16%|█▌        | 55/341 [00:06<00:08, 32.06it/s, Epoch: 1, Batch: 56,Loss: 1.978,Avg.Loss: 2.327,LR: 5.00E-04]Training epoch 1:  16%|█▋        | 56/341 [00:06<00:08, 32.06it/s, Epoch: 1, Batch: 57,Loss: 1.843,Avg.Loss: 2.319,LR: 5.00E-04]Training epoch 1:  17%|█▋        | 57/341 [00:06<00:08, 32.06it/s, Epoch: 1, Batch: 58,Loss: 2.104,Avg.Loss: 2.315,LR: 5.00E-04]Training epoch 1:  17%|█▋        | 58/341 [00:06<00:08, 32.06it/s, Epoch: 1, Batch: 59,Loss: 2.025,Avg.Loss: 2.310,LR: 5.00E-04]Training epoch 1:  17%|█▋        | 59/341 [00:06<00:08, 32.06it/s, Epoch: 1, Batch: 60,Loss: 1.482,Avg.Loss: 2.296,LR: 5.00E-04]Training epoch 1:  18%|█▊        | 60/341 [00:06<00:08, 32.06it/s, Epoch: 1, Batch: 61,Loss: 1.896,Avg.Loss: 2.290,LR: 5.00E-04]Training epoch 1:  18%|█▊        | 61/341 [00:06<00:07, 36.42it/s, Epoch: 1, Batch: 61,Loss: 1.896,Avg.Loss: 2.290,LR: 5.00E-04]Training epoch 1:  18%|█▊        | 61/341 [00:06<00:07, 36.42it/s, Epoch: 1, Batch: 62,Loss: 2.028,Avg.Loss: 2.285,LR: 5.00E-04]Training epoch 1:  18%|█▊        | 62/341 [00:06<00:07, 36.42it/s, Epoch: 1, Batch: 63,Loss: 1.802,Avg.Loss: 2.278,LR: 5.00E-04]Training epoch 1:  18%|█▊        | 63/341 [00:06<00:07, 36.42it/s, Epoch: 1, Batch: 64,Loss: 1.498,Avg.Loss: 2.266,LR: 5.00E-04]Training epoch 1:  19%|█▉        | 64/341 [00:06<00:07, 36.42it/s, Epoch: 1, Batch: 65,Loss: 1.548,Avg.Loss: 2.254,LR: 5.00E-04]Training epoch 1:  19%|█▉        | 65/341 [00:06<00:07, 36.42it/s, Epoch: 1, Batch: 66,Loss: 2.043,Avg.Loss: 2.251,LR: 5.00E-04]Training epoch 1:  19%|█▉        | 66/341 [00:06<00:07, 36.42it/s, Epoch: 1, Batch: 67,Loss: 2.186,Avg.Loss: 2.250,LR: 5.00E-04]Training epoch 1:  20%|█▉        | 67/341 [00:06<00:06, 40.52it/s, Epoch: 1, Batch: 67,Loss: 2.186,Avg.Loss: 2.250,LR: 5.00E-04]Training epoch 1:  20%|█▉        | 67/341 [00:07<00:06, 40.52it/s, Epoch: 1, Batch: 68,Loss: 2.079,Avg.Loss: 2.248,LR: 5.00E-04]Training epoch 1:  20%|█▉        | 68/341 [00:07<00:06, 40.52it/s, Epoch: 1, Batch: 69,Loss: 1.758,Avg.Loss: 2.241,LR: 5.00E-04]Training epoch 1:  20%|██        | 69/341 [00:07<00:06, 40.52it/s, Epoch: 1, Batch: 70,Loss: 2.118,Avg.Loss: 2.239,LR: 5.00E-04]Training epoch 1:  21%|██        | 70/341 [00:07<00:06, 40.52it/s, Epoch: 1, Batch: 71,Loss: 1.443,Avg.Loss: 2.228,LR: 5.00E-04]Training epoch 1:  21%|██        | 71/341 [00:07<00:06, 40.52it/s, Epoch: 1, Batch: 72,Loss: 2.100,Avg.Loss: 2.226,LR: 5.00E-04]Training epoch 1:  21%|██        | 72/341 [00:07<00:06, 40.52it/s, Epoch: 1, Batch: 73,Loss: 1.699,Avg.Loss: 2.219,LR: 5.00E-04]Training epoch 1:  21%|██▏       | 73/341 [00:07<00:06, 43.62it/s, Epoch: 1, Batch: 73,Loss: 1.699,Avg.Loss: 2.219,LR: 5.00E-04]Training epoch 1:  21%|██▏       | 73/341 [00:07<00:06, 43.62it/s, Epoch: 1, Batch: 74,Loss: 1.791,Avg.Loss: 2.213,LR: 5.00E-04]Training epoch 1:  22%|██▏       | 74/341 [00:07<00:06, 43.62it/s, Epoch: 1, Batch: 75,Loss: 1.551,Avg.Loss: 2.204,LR: 5.00E-04]Training epoch 1:  22%|██▏       | 75/341 [00:07<00:06, 43.62it/s, Epoch: 1, Batch: 76,Loss: 1.756,Avg.Loss: 2.198,LR: 5.00E-04]Training epoch 1:  22%|██▏       | 76/341 [00:07<00:06, 43.62it/s, Epoch: 1, Batch: 77,Loss: 1.724,Avg.Loss: 2.192,LR: 5.00E-04]Training epoch 1:  23%|██▎       | 77/341 [00:07<00:06, 43.62it/s, Epoch: 1, Batch: 78,Loss: 1.861,Avg.Loss: 2.188,LR: 5.00E-04]Training epoch 1:  23%|██▎       | 78/341 [00:07<00:06, 43.62it/s, Epoch: 1, Batch: 79,Loss: 1.653,Avg.Loss: 2.181,LR: 5.00E-04]Training epoch 1:  23%|██▎       | 79/341 [00:07<00:05, 46.98it/s, Epoch: 1, Batch: 79,Loss: 1.653,Avg.Loss: 2.181,LR: 5.00E-04]Training epoch 1:  23%|██▎       | 79/341 [00:07<00:05, 46.98it/s, Epoch: 1, Batch: 80,Loss: 1.856,Avg.Loss: 2.177,LR: 5.00E-04]Training epoch 1:  23%|██▎       | 80/341 [00:07<00:05, 46.98it/s, Epoch: 1, Batch: 81,Loss: 1.991,Avg.Loss: 2.175,LR: 5.00E-04]Training epoch 1:  24%|██▍       | 81/341 [00:07<00:05, 46.98it/s, Epoch: 1, Batch: 82,Loss: 2.332,Avg.Loss: 2.177,LR: 5.00E-04]Training epoch 1:  24%|██▍       | 82/341 [00:07<00:05, 46.98it/s, Epoch: 1, Batch: 83,Loss: 2.115,Avg.Loss: 2.176,LR: 5.00E-04]Training epoch 1:  24%|██▍       | 83/341 [00:07<00:05, 46.98it/s, Epoch: 1, Batch: 84,Loss: 1.600,Avg.Loss: 2.169,LR: 5.00E-04]Training epoch 1:  25%|██▍       | 84/341 [00:07<00:05, 46.98it/s, Epoch: 1, Batch: 85,Loss: 1.456,Avg.Loss: 2.161,LR: 5.00E-04]Training epoch 1:  25%|██▍       | 85/341 [00:07<00:05, 47.56it/s, Epoch: 1, Batch: 85,Loss: 1.456,Avg.Loss: 2.161,LR: 5.00E-04]Training epoch 1:  25%|██▍       | 85/341 [00:07<00:05, 47.56it/s, Epoch: 1, Batch: 86,Loss: 1.613,Avg.Loss: 2.154,LR: 5.00E-04]Training epoch 1:  25%|██▌       | 86/341 [00:07<00:05, 47.56it/s, Epoch: 1, Batch: 87,Loss: 1.423,Avg.Loss: 2.146,LR: 5.00E-04]Training epoch 1:  26%|██▌       | 87/341 [00:07<00:05, 47.56it/s, Epoch: 1, Batch: 88,Loss: 1.852,Avg.Loss: 2.142,LR: 5.00E-04]Training epoch 1:  26%|██▌       | 88/341 [00:07<00:05, 47.56it/s, Epoch: 1, Batch: 89,Loss: 1.733,Avg.Loss: 2.138,LR: 5.00E-04]Training epoch 1:  26%|██▌       | 89/341 [00:07<00:05, 47.56it/s, Epoch: 1, Batch: 90,Loss: 2.108,Avg.Loss: 2.138,LR: 5.00E-04]Training epoch 1:  26%|██▋       | 90/341 [00:07<00:05, 47.56it/s, Epoch: 1, Batch: 91,Loss: 2.125,Avg.Loss: 2.137,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 91/341 [00:07<00:05, 49.14it/s, Epoch: 1, Batch: 91,Loss: 2.125,Avg.Loss: 2.137,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 91/341 [00:07<00:05, 49.14it/s, Epoch: 1, Batch: 92,Loss: 1.652,Avg.Loss: 2.132,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 92/341 [00:07<00:05, 49.14it/s, Epoch: 1, Batch: 93,Loss: 1.646,Avg.Loss: 2.127,LR: 5.00E-04]Training epoch 1:  27%|██▋       | 93/341 [00:07<00:05, 49.14it/s, Epoch: 1, Batch: 94,Loss: 1.841,Avg.Loss: 2.124,LR: 5.00E-04]Training epoch 1:  28%|██▊       | 94/341 [00:07<00:05, 49.14it/s, Epoch: 1, Batch: 95,Loss: 1.655,Avg.Loss: 2.119,LR: 5.00E-04]Training epoch 1:  28%|██▊       | 95/341 [00:07<00:05, 49.14it/s, Epoch: 1, Batch: 96,Loss: 2.553,Avg.Loss: 2.123,LR: 5.00E-04]Training epoch 1:  28%|██▊       | 96/341 [00:07<00:04, 49.14it/s, Epoch: 1, Batch: 97,Loss: 2.107,Avg.Loss: 2.123,LR: 5.00E-04]Training epoch 1:  28%|██▊       | 97/341 [00:07<00:04, 49.91it/s, Epoch: 1, Batch: 97,Loss: 2.107,Avg.Loss: 2.123,LR: 5.00E-04]Training epoch 1:  28%|██▊       | 97/341 [00:07<00:04, 49.91it/s, Epoch: 1, Batch: 98,Loss: 2.099,Avg.Loss: 2.123,LR: 5.00E-04]Training epoch 1:  29%|██▊       | 98/341 [00:07<00:04, 49.91it/s, Epoch: 1, Batch: 99,Loss: 1.535,Avg.Loss: 2.117,LR: 5.00E-04]Training epoch 1:  29%|██▉       | 99/341 [00:07<00:04, 49.91it/s, Epoch: 1, Batch: 100,Loss: 1.498,Avg.Loss: 2.111,LR: 5.00E-04]Training epoch 1:  29%|██▉       | 100/341 [00:07<00:04, 49.91it/s, Epoch: 1, Batch: 101,Loss: 1.668,Avg.Loss: 2.107,LR: 5.00E-04]Training epoch 1:  30%|██▉       | 101/341 [00:07<00:04, 49.91it/s, Epoch: 1, Batch: 102,Loss: 2.167,Avg.Loss: 2.107,LR: 5.00E-04]Training epoch 1:  30%|██▉       | 102/341 [00:07<00:04, 49.91it/s, Epoch: 1, Batch: 103,Loss: 1.914,Avg.Loss: 2.105,LR: 5.00E-04]Training epoch 1:  30%|███       | 103/341 [00:07<00:04, 51.01it/s, Epoch: 1, Batch: 103,Loss: 1.914,Avg.Loss: 2.105,LR: 5.00E-04]Training epoch 1:  30%|███       | 103/341 [00:07<00:04, 51.01it/s, Epoch: 1, Batch: 104,Loss: 2.428,Avg.Loss: 2.108,LR: 5.00E-04]Training epoch 1:  30%|███       | 104/341 [00:07<00:04, 51.01it/s, Epoch: 1, Batch: 105,Loss: 2.216,Avg.Loss: 2.109,LR: 5.00E-04]Training epoch 1:  31%|███       | 105/341 [00:07<00:04, 51.01it/s, Epoch: 1, Batch: 106,Loss: 1.359,Avg.Loss: 2.102,LR: 5.00E-04]Training epoch 1:  31%|███       | 106/341 [00:07<00:04, 51.01it/s, Epoch: 1, Batch: 107,Loss: 1.721,Avg.Loss: 2.099,LR: 5.00E-04]Training epoch 1:  31%|███▏      | 107/341 [00:07<00:04, 51.01it/s, Epoch: 1, Batch: 108,Loss: 1.778,Avg.Loss: 2.096,LR: 5.00E-04]Training epoch 1:  32%|███▏      | 108/341 [00:07<00:04, 51.01it/s, Epoch: 1, Batch: 109,Loss: 1.744,Avg.Loss: 2.093,LR: 5.00E-04]Training epoch 1:  32%|███▏      | 109/341 [00:07<00:04, 51.91it/s, Epoch: 1, Batch: 109,Loss: 1.744,Avg.Loss: 2.093,LR: 5.00E-04]Training epoch 1:  32%|███▏      | 109/341 [00:07<00:04, 51.91it/s, Epoch: 1, Batch: 110,Loss: 1.939,Avg.Loss: 2.091,LR: 5.00E-04]Training epoch 1:  32%|███▏      | 110/341 [00:07<00:04, 51.91it/s, Epoch: 1, Batch: 111,Loss: 1.506,Avg.Loss: 2.086,LR: 5.00E-04]Training epoch 1:  33%|███▎      | 111/341 [00:07<00:04, 51.91it/s, Epoch: 1, Batch: 112,Loss: 1.761,Avg.Loss: 2.083,LR: 5.00E-04]Training epoch 1:  33%|███▎      | 112/341 [00:07<00:04, 51.91it/s, Epoch: 1, Batch: 113,Loss: 1.928,Avg.Loss: 2.082,LR: 5.00E-04]Training epoch 1:  33%|███▎      | 113/341 [00:07<00:04, 51.91it/s, Epoch: 1, Batch: 114,Loss: 2.162,Avg.Loss: 2.082,LR: 5.00E-04]Training epoch 1:  33%|███▎      | 114/341 [00:07<00:04, 51.91it/s, Epoch: 1, Batch: 115,Loss: 2.030,Avg.Loss: 2.082,LR: 5.00E-04]Training epoch 1:  34%|███▎      | 115/341 [00:07<00:04, 52.27it/s, Epoch: 1, Batch: 115,Loss: 2.030,Avg.Loss: 2.082,LR: 5.00E-04]Training epoch 1:  34%|███▎      | 115/341 [00:07<00:04, 52.27it/s, Epoch: 1, Batch: 116,Loss: 2.140,Avg.Loss: 2.082,LR: 5.00E-04]Training epoch 1:  34%|███▍      | 116/341 [00:07<00:04, 52.27it/s, Epoch: 1, Batch: 117,Loss: 1.774,Avg.Loss: 2.080,LR: 5.00E-04]Training epoch 1:  34%|███▍      | 117/341 [00:07<00:04, 52.27it/s, Epoch: 1, Batch: 118,Loss: 1.497,Avg.Loss: 2.075,LR: 5.00E-04]Training epoch 1:  35%|███▍      | 118/341 [00:07<00:04, 52.27it/s, Epoch: 1, Batch: 119,Loss: 1.484,Avg.Loss: 2.070,LR: 5.00E-04]Training epoch 1:  35%|███▍      | 119/341 [00:07<00:04, 52.27it/s, Epoch: 1, Batch: 120,Loss: 1.731,Avg.Loss: 2.067,LR: 5.00E-04]Training epoch 1:  35%|███▌      | 120/341 [00:08<00:04, 52.27it/s, Epoch: 1, Batch: 121,Loss: 1.394,Avg.Loss: 2.061,LR: 5.00E-04]Training epoch 1:  35%|███▌      | 121/341 [00:08<00:04, 52.52it/s, Epoch: 1, Batch: 121,Loss: 1.394,Avg.Loss: 2.061,LR: 5.00E-04]Training epoch 1:  35%|███▌      | 121/341 [00:08<00:04, 52.52it/s, Epoch: 1, Batch: 122,Loss: 1.614,Avg.Loss: 2.058,LR: 5.00E-04]Training epoch 1:  36%|███▌      | 122/341 [00:08<00:04, 52.52it/s, Epoch: 1, Batch: 123,Loss: 1.464,Avg.Loss: 2.053,LR: 5.00E-04]Training epoch 1:  36%|███▌      | 123/341 [00:08<00:04, 52.52it/s, Epoch: 1, Batch: 124,Loss: 1.300,Avg.Loss: 2.047,LR: 5.00E-04]Training epoch 1:  36%|███▋      | 124/341 [00:08<00:04, 52.52it/s, Epoch: 1, Batch: 125,Loss: 1.523,Avg.Loss: 2.043,LR: 5.00E-04]Training epoch 1:  37%|███▋      | 125/341 [00:08<00:04, 52.52it/s, Epoch: 1, Batch: 126,Loss: 1.507,Avg.Loss: 2.038,LR: 5.00E-04]Training epoch 1:  37%|███▋      | 126/341 [00:08<00:04, 52.52it/s, Epoch: 1, Batch: 127,Loss: 1.703,Avg.Loss: 2.036,LR: 5.00E-04]Training epoch 1:  37%|███▋      | 127/341 [00:08<00:04, 53.48it/s, Epoch: 1, Batch: 127,Loss: 1.703,Avg.Loss: 2.036,LR: 5.00E-04]Training epoch 1:  37%|███▋      | 127/341 [00:08<00:04, 53.48it/s, Epoch: 1, Batch: 128,Loss: 1.652,Avg.Loss: 2.033,LR: 5.00E-04]Training epoch 1:  38%|███▊      | 128/341 [00:08<00:03, 53.48it/s, Epoch: 1, Batch: 129,Loss: 1.759,Avg.Loss: 2.031,LR: 5.00E-04]Training epoch 1:  38%|███▊      | 129/341 [00:08<00:03, 53.48it/s, Epoch: 1, Batch: 130,Loss: 2.027,Avg.Loss: 2.031,LR: 5.00E-04]Training epoch 1:  38%|███▊      | 130/341 [00:08<00:03, 53.48it/s, Epoch: 1, Batch: 131,Loss: 1.743,Avg.Loss: 2.028,LR: 5.00E-04]Training epoch 1:  38%|███▊      | 131/341 [00:08<00:03, 53.48it/s, Epoch: 1, Batch: 132,Loss: 1.761,Avg.Loss: 2.026,LR: 5.00E-04]Training epoch 1:  39%|███▊      | 132/341 [00:08<00:03, 53.48it/s, Epoch: 1, Batch: 133,Loss: 1.554,Avg.Loss: 2.023,LR: 5.00E-04]Training epoch 1:  39%|███▉      | 133/341 [00:08<00:03, 54.13it/s, Epoch: 1, Batch: 133,Loss: 1.554,Avg.Loss: 2.023,LR: 5.00E-04]Training epoch 1:  39%|███▉      | 133/341 [00:08<00:03, 54.13it/s, Epoch: 1, Batch: 134,Loss: 1.929,Avg.Loss: 2.022,LR: 5.00E-04]Training epoch 1:  39%|███▉      | 134/341 [00:08<00:03, 54.13it/s, Epoch: 1, Batch: 135,Loss: 1.510,Avg.Loss: 2.018,LR: 5.00E-04]Training epoch 1:  40%|███▉      | 135/341 [00:08<00:03, 54.13it/s, Epoch: 1, Batch: 136,Loss: 1.241,Avg.Loss: 2.013,LR: 5.00E-04]Training epoch 1:  40%|███▉      | 136/341 [00:08<00:03, 54.13it/s, Epoch: 1, Batch: 137,Loss: 1.633,Avg.Loss: 2.010,LR: 5.00E-04]Training epoch 1:  40%|████      | 137/341 [00:08<00:03, 54.13it/s, Epoch: 1, Batch: 138,Loss: 1.616,Avg.Loss: 2.007,LR: 4.99E-04]Training epoch 1:  40%|████      | 138/341 [00:08<00:03, 54.13it/s, Epoch: 1, Batch: 139,Loss: 2.199,Avg.Loss: 2.008,LR: 4.99E-04]Training epoch 1:  41%|████      | 139/341 [00:08<00:03, 53.87it/s, Epoch: 1, Batch: 139,Loss: 2.199,Avg.Loss: 2.008,LR: 4.99E-04]Training epoch 1:  41%|████      | 139/341 [00:08<00:03, 53.87it/s, Epoch: 1, Batch: 140,Loss: 1.865,Avg.Loss: 2.007,LR: 4.99E-04]Training epoch 1:  41%|████      | 140/341 [00:08<00:03, 53.87it/s, Epoch: 1, Batch: 141,Loss: 1.522,Avg.Loss: 2.004,LR: 4.99E-04]Training epoch 1:  41%|████▏     | 141/341 [00:08<00:03, 53.87it/s, Epoch: 1, Batch: 142,Loss: 1.382,Avg.Loss: 2.000,LR: 4.99E-04]Training epoch 1:  42%|████▏     | 142/341 [00:08<00:03, 53.87it/s, Epoch: 1, Batch: 143,Loss: 1.579,Avg.Loss: 1.997,LR: 4.99E-04]Training epoch 1:  42%|████▏     | 143/341 [00:08<00:03, 53.87it/s, Epoch: 1, Batch: 144,Loss: 1.828,Avg.Loss: 1.995,LR: 4.99E-04]Training epoch 1:  42%|████▏     | 144/341 [00:08<00:03, 53.87it/s, Epoch: 1, Batch: 145,Loss: 1.476,Avg.Loss: 1.992,LR: 4.99E-04]Training epoch 1:  43%|████▎     | 145/341 [00:08<00:03, 53.69it/s, Epoch: 1, Batch: 145,Loss: 1.476,Avg.Loss: 1.992,LR: 4.99E-04]Training epoch 1:  43%|████▎     | 145/341 [00:08<00:03, 53.69it/s, Epoch: 1, Batch: 146,Loss: 1.446,Avg.Loss: 1.988,LR: 4.99E-04]Training epoch 1:  43%|████▎     | 146/341 [00:08<00:03, 53.69it/s, Epoch: 1, Batch: 147,Loss: 1.656,Avg.Loss: 1.986,LR: 4.99E-04]Training epoch 1:  43%|████▎     | 147/341 [00:08<00:03, 53.69it/s, Epoch: 1, Batch: 148,Loss: 1.864,Avg.Loss: 1.985,LR: 4.99E-04]Training epoch 1:  43%|████▎     | 148/341 [00:08<00:03, 53.69it/s, Epoch: 1, Batch: 149,Loss: 1.458,Avg.Loss: 1.981,LR: 4.99E-04]Training epoch 1:  44%|████▎     | 149/341 [00:08<00:03, 53.69it/s, Epoch: 1, Batch: 150,Loss: 1.591,Avg.Loss: 1.979,LR: 4.99E-04]Training epoch 1:  44%|████▍     | 150/341 [00:08<00:03, 53.69it/s, Epoch: 1, Batch: 151,Loss: 1.518,Avg.Loss: 1.976,LR: 4.99E-04]Training epoch 1:  44%|████▍     | 151/341 [00:08<00:03, 53.16it/s, Epoch: 1, Batch: 151,Loss: 1.518,Avg.Loss: 1.976,LR: 4.99E-04]Training epoch 1:  44%|████▍     | 151/341 [00:08<00:03, 53.16it/s, Epoch: 1, Batch: 152,Loss: 1.665,Avg.Loss: 1.974,LR: 4.99E-04]Training epoch 1:  45%|████▍     | 152/341 [00:08<00:03, 53.16it/s, Epoch: 1, Batch: 153,Loss: 1.535,Avg.Loss: 1.971,LR: 4.99E-04]Training epoch 1:  45%|████▍     | 153/341 [00:08<00:03, 53.16it/s, Epoch: 1, Batch: 154,Loss: 1.664,Avg.Loss: 1.969,LR: 4.99E-04]Training epoch 1:  45%|████▌     | 154/341 [00:08<00:03, 53.16it/s, Epoch: 1, Batch: 155,Loss: 1.365,Avg.Loss: 1.965,LR: 4.99E-04]Training epoch 1:  45%|████▌     | 155/341 [00:08<00:03, 53.16it/s, Epoch: 1, Batch: 156,Loss: 1.487,Avg.Loss: 1.962,LR: 4.99E-04]Training epoch 1:  46%|████▌     | 156/341 [00:08<00:03, 53.16it/s, Epoch: 1, Batch: 157,Loss: 1.265,Avg.Loss: 1.958,LR: 4.99E-04]Training epoch 1:  46%|████▌     | 157/341 [00:08<00:03, 52.98it/s, Epoch: 1, Batch: 157,Loss: 1.265,Avg.Loss: 1.958,LR: 4.99E-04]Training epoch 1:  46%|████▌     | 157/341 [00:08<00:03, 52.98it/s, Epoch: 1, Batch: 158,Loss: 1.884,Avg.Loss: 1.957,LR: 4.99E-04]Training epoch 1:  46%|████▋     | 158/341 [00:08<00:03, 52.98it/s, Epoch: 1, Batch: 159,Loss: 1.435,Avg.Loss: 1.954,LR: 4.99E-04]Training epoch 1:  47%|████▋     | 159/341 [00:08<00:03, 52.98it/s, Epoch: 1, Batch: 160,Loss: 1.738,Avg.Loss: 1.952,LR: 4.99E-04]Training epoch 1:  47%|████▋     | 160/341 [00:08<00:03, 52.98it/s, Epoch: 1, Batch: 161,Loss: 1.384,Avg.Loss: 1.949,LR: 4.99E-04]Training epoch 1:  47%|████▋     | 161/341 [00:08<00:03, 52.98it/s, Epoch: 1, Batch: 162,Loss: 1.232,Avg.Loss: 1.944,LR: 4.99E-04]Training epoch 1:  48%|████▊     | 162/341 [00:08<00:03, 52.98it/s, Epoch: 1, Batch: 163,Loss: 1.296,Avg.Loss: 1.940,LR: 4.99E-04]Training epoch 1:  48%|████▊     | 163/341 [00:08<00:03, 53.49it/s, Epoch: 1, Batch: 163,Loss: 1.296,Avg.Loss: 1.940,LR: 4.99E-04]Training epoch 1:  48%|████▊     | 163/341 [00:08<00:03, 53.49it/s, Epoch: 1, Batch: 164,Loss: 1.578,Avg.Loss: 1.938,LR: 4.99E-04]Training epoch 1:  48%|████▊     | 164/341 [00:08<00:03, 53.49it/s, Epoch: 1, Batch: 165,Loss: 1.547,Avg.Loss: 1.936,LR: 4.99E-04]Training epoch 1:  48%|████▊     | 165/341 [00:08<00:03, 53.49it/s, Epoch: 1, Batch: 166,Loss: 1.332,Avg.Loss: 1.932,LR: 4.99E-04]Training epoch 1:  49%|████▊     | 166/341 [00:08<00:03, 53.49it/s, Epoch: 1, Batch: 167,Loss: 2.978,Avg.Loss: 1.939,LR: 4.99E-04]Training epoch 1:  49%|████▉     | 167/341 [00:08<00:03, 53.49it/s, Epoch: 1, Batch: 168,Loss: 1.645,Avg.Loss: 1.937,LR: 4.99E-04]Training epoch 1:  49%|████▉     | 168/341 [00:08<00:03, 53.49it/s, Epoch: 1, Batch: 169,Loss: 2.442,Avg.Loss: 1.940,LR: 4.99E-04]Training epoch 1:  50%|████▉     | 169/341 [00:08<00:03, 53.89it/s, Epoch: 1, Batch: 169,Loss: 2.442,Avg.Loss: 1.940,LR: 4.99E-04]Training epoch 1:  50%|████▉     | 169/341 [00:08<00:03, 53.89it/s, Epoch: 1, Batch: 170,Loss: 1.850,Avg.Loss: 1.939,LR: 4.99E-04]Training epoch 1:  50%|████▉     | 170/341 [00:08<00:03, 53.89it/s, Epoch: 1, Batch: 171,Loss: 1.533,Avg.Loss: 1.937,LR: 4.99E-04]Training epoch 1:  50%|█████     | 171/341 [00:08<00:03, 53.89it/s, Epoch: 1, Batch: 172,Loss: 1.626,Avg.Loss: 1.935,LR: 4.99E-04]Training epoch 1:  50%|█████     | 172/341 [00:08<00:03, 53.89it/s, Epoch: 1, Batch: 173,Loss: 2.030,Avg.Loss: 1.936,LR: 4.99E-04]Training epoch 1:  51%|█████     | 173/341 [00:08<00:03, 53.89it/s, Epoch: 1, Batch: 174,Loss: 2.264,Avg.Loss: 1.938,LR: 4.99E-04]Training epoch 1:  51%|█████     | 174/341 [00:09<00:03, 53.89it/s, Epoch: 1, Batch: 175,Loss: 1.455,Avg.Loss: 1.935,LR: 4.99E-04]Training epoch 1:  51%|█████▏    | 175/341 [00:09<00:03, 54.50it/s, Epoch: 1, Batch: 175,Loss: 1.455,Avg.Loss: 1.935,LR: 4.99E-04]Training epoch 1:  51%|█████▏    | 175/341 [00:09<00:03, 54.50it/s, Epoch: 1, Batch: 176,Loss: 1.438,Avg.Loss: 1.932,LR: 4.99E-04]Training epoch 1:  52%|█████▏    | 176/341 [00:09<00:03, 54.50it/s, Epoch: 1, Batch: 177,Loss: 1.635,Avg.Loss: 1.930,LR: 4.99E-04]Training epoch 1:  52%|█████▏    | 177/341 [00:09<00:03, 54.50it/s, Epoch: 1, Batch: 178,Loss: 1.428,Avg.Loss: 1.927,LR: 4.99E-04]Training epoch 1:  52%|█████▏    | 178/341 [00:09<00:02, 54.50it/s, Epoch: 1, Batch: 179,Loss: 1.948,Avg.Loss: 1.928,LR: 4.99E-04]Training epoch 1:  52%|█████▏    | 179/341 [00:09<00:02, 54.50it/s, Epoch: 1, Batch: 180,Loss: 1.880,Avg.Loss: 1.927,LR: 4.99E-04]Training epoch 1:  53%|█████▎    | 180/341 [00:09<00:02, 54.50it/s, Epoch: 1, Batch: 181,Loss: 1.330,Avg.Loss: 1.924,LR: 4.99E-04]Training epoch 1:  53%|█████▎    | 181/341 [00:09<00:02, 55.22it/s, Epoch: 1, Batch: 181,Loss: 1.330,Avg.Loss: 1.924,LR: 4.99E-04]Training epoch 1:  53%|█████▎    | 181/341 [00:09<00:02, 55.22it/s, Epoch: 1, Batch: 182,Loss: 1.515,Avg.Loss: 1.922,LR: 4.99E-04]Training epoch 1:  53%|█████▎    | 182/341 [00:09<00:02, 55.22it/s, Epoch: 1, Batch: 183,Loss: 2.108,Avg.Loss: 1.923,LR: 4.99E-04]Training epoch 1:  54%|█████▎    | 183/341 [00:09<00:02, 55.22it/s, Epoch: 1, Batch: 184,Loss: 1.949,Avg.Loss: 1.923,LR: 4.99E-04]Training epoch 1:  54%|█████▍    | 184/341 [00:09<00:02, 55.22it/s, Epoch: 1, Batch: 185,Loss: 1.444,Avg.Loss: 1.920,LR: 4.99E-04]Training epoch 1:  54%|█████▍    | 185/341 [00:09<00:02, 55.22it/s, Epoch: 1, Batch: 186,Loss: 1.251,Avg.Loss: 1.917,LR: 4.99E-04]Training epoch 1:  55%|█████▍    | 186/341 [00:09<00:02, 55.22it/s, Epoch: 1, Batch: 187,Loss: 1.317,Avg.Loss: 1.913,LR: 4.99E-04]Training epoch 1:  55%|█████▍    | 187/341 [00:09<00:02, 54.89it/s, Epoch: 1, Batch: 187,Loss: 1.317,Avg.Loss: 1.913,LR: 4.99E-04]Training epoch 1:  55%|█████▍    | 187/341 [00:09<00:02, 54.89it/s, Epoch: 1, Batch: 188,Loss: 1.441,Avg.Loss: 1.911,LR: 4.99E-04]Training epoch 1:  55%|█████▌    | 188/341 [00:09<00:02, 54.89it/s, Epoch: 1, Batch: 189,Loss: 1.757,Avg.Loss: 1.910,LR: 4.99E-04]Training epoch 1:  55%|█████▌    | 189/341 [00:09<00:02, 54.89it/s, Epoch: 1, Batch: 190,Loss: 1.181,Avg.Loss: 1.906,LR: 4.99E-04]Training epoch 1:  56%|█████▌    | 190/341 [00:09<00:02, 54.89it/s, Epoch: 1, Batch: 191,Loss: 1.373,Avg.Loss: 1.904,LR: 4.99E-04]Training epoch 1:  56%|█████▌    | 191/341 [00:09<00:02, 54.89it/s, Epoch: 1, Batch: 192,Loss: 1.484,Avg.Loss: 1.901,LR: 4.99E-04]Training epoch 1:  56%|█████▋    | 192/341 [00:09<00:02, 54.89it/s, Epoch: 1, Batch: 193,Loss: 1.376,Avg.Loss: 1.899,LR: 4.99E-04]Training epoch 1:  57%|█████▋    | 193/341 [00:09<00:02, 53.60it/s, Epoch: 1, Batch: 193,Loss: 1.376,Avg.Loss: 1.899,LR: 4.99E-04]Training epoch 1:  57%|█████▋    | 193/341 [00:09<00:02, 53.60it/s, Epoch: 1, Batch: 194,Loss: 1.133,Avg.Loss: 1.895,LR: 4.99E-04]Training epoch 1:  57%|█████▋    | 194/341 [00:09<00:02, 53.60it/s, Epoch: 1, Batch: 195,Loss: 1.199,Avg.Loss: 1.891,LR: 4.99E-04]Training epoch 1:  57%|█████▋    | 195/341 [00:09<00:02, 53.60it/s, Epoch: 1, Batch: 196,Loss: 1.518,Avg.Loss: 1.889,LR: 4.99E-04]Training epoch 1:  57%|█████▋    | 196/341 [00:09<00:02, 53.60it/s, Epoch: 1, Batch: 197,Loss: 1.418,Avg.Loss: 1.887,LR: 4.99E-04]Training epoch 1:  58%|█████▊    | 197/341 [00:09<00:02, 53.60it/s, Epoch: 1, Batch: 198,Loss: 1.068,Avg.Loss: 1.883,LR: 4.99E-04]Training epoch 1:  58%|█████▊    | 198/341 [00:09<00:02, 53.60it/s, Epoch: 1, Batch: 199,Loss: 1.352,Avg.Loss: 1.880,LR: 4.99E-04]Training epoch 1:  58%|█████▊    | 199/341 [00:09<00:02, 53.90it/s, Epoch: 1, Batch: 199,Loss: 1.352,Avg.Loss: 1.880,LR: 4.99E-04]Training epoch 1:  58%|█████▊    | 199/341 [00:09<00:02, 53.90it/s, Epoch: 1, Batch: 200,Loss: 1.130,Avg.Loss: 1.876,LR: 4.99E-04]Training epoch 1:  59%|█████▊    | 200/341 [00:09<00:02, 53.90it/s, Epoch: 1, Batch: 201,Loss: 1.216,Avg.Loss: 1.873,LR: 4.99E-04]Training epoch 1:  59%|█████▉    | 201/341 [00:09<00:02, 53.90it/s, Epoch: 1, Batch: 202,Loss: 1.225,Avg.Loss: 1.870,LR: 4.99E-04]Training epoch 1:  59%|█████▉    | 202/341 [00:09<00:02, 53.90it/s, Epoch: 1, Batch: 203,Loss: 1.288,Avg.Loss: 1.867,LR: 4.99E-04]Training epoch 1:  60%|█████▉    | 203/341 [00:09<00:02, 53.90it/s, Epoch: 1, Batch: 204,Loss: 1.300,Avg.Loss: 1.864,LR: 4.99E-04]Training epoch 1:  60%|█████▉    | 204/341 [00:09<00:02, 53.90it/s, Epoch: 1, Batch: 205,Loss: 1.387,Avg.Loss: 1.862,LR: 4.99E-04]Training epoch 1:  60%|██████    | 205/341 [00:09<00:02, 53.15it/s, Epoch: 1, Batch: 205,Loss: 1.387,Avg.Loss: 1.862,LR: 4.99E-04]Training epoch 1:  60%|██████    | 205/341 [00:09<00:02, 53.15it/s, Epoch: 1, Batch: 206,Loss: 1.243,Avg.Loss: 1.859,LR: 4.99E-04]Training epoch 1:  60%|██████    | 206/341 [00:09<00:02, 53.15it/s, Epoch: 1, Batch: 207,Loss: 1.560,Avg.Loss: 1.857,LR: 4.99E-04]Training epoch 1:  61%|██████    | 207/341 [00:09<00:02, 53.15it/s, Epoch: 1, Batch: 208,Loss: 1.388,Avg.Loss: 1.855,LR: 4.99E-04]Training epoch 1:  61%|██████    | 208/341 [00:09<00:02, 53.15it/s, Epoch: 1, Batch: 209,Loss: 1.697,Avg.Loss: 1.854,LR: 4.99E-04]Training epoch 1:  61%|██████▏   | 209/341 [00:09<00:02, 53.15it/s, Epoch: 1, Batch: 210,Loss: 1.470,Avg.Loss: 1.853,LR: 4.99E-04]Training epoch 1:  62%|██████▏   | 210/341 [00:09<00:02, 53.15it/s, Epoch: 1, Batch: 211,Loss: 1.138,Avg.Loss: 1.849,LR: 4.99E-04]Training epoch 1:  62%|██████▏   | 211/341 [00:09<00:02, 52.33it/s, Epoch: 1, Batch: 211,Loss: 1.138,Avg.Loss: 1.849,LR: 4.99E-04]Training epoch 1:  62%|██████▏   | 211/341 [00:09<00:02, 52.33it/s, Epoch: 1, Batch: 212,Loss: 1.182,Avg.Loss: 1.846,LR: 4.99E-04]Training epoch 1:  62%|██████▏   | 212/341 [00:09<00:02, 52.33it/s, Epoch: 1, Batch: 213,Loss: 1.363,Avg.Loss: 1.844,LR: 4.99E-04]Training epoch 1:  62%|██████▏   | 213/341 [00:09<00:02, 52.33it/s, Epoch: 1, Batch: 214,Loss: 0.808,Avg.Loss: 1.839,LR: 4.99E-04]Training epoch 1:  63%|██████▎   | 214/341 [00:09<00:02, 52.33it/s, Epoch: 1, Batch: 215,Loss: 1.641,Avg.Loss: 1.838,LR: 4.99E-04]Training epoch 1:  63%|██████▎   | 215/341 [00:09<00:02, 52.33it/s, Epoch: 1, Batch: 216,Loss: 1.537,Avg.Loss: 1.837,LR: 4.99E-04]Training epoch 1:  63%|██████▎   | 216/341 [00:09<00:02, 52.33it/s, Epoch: 1, Batch: 217,Loss: 1.589,Avg.Loss: 1.835,LR: 4.99E-04]Training epoch 1:  64%|██████▎   | 217/341 [00:09<00:02, 51.74it/s, Epoch: 1, Batch: 217,Loss: 1.589,Avg.Loss: 1.835,LR: 4.99E-04]Training epoch 1:  64%|██████▎   | 217/341 [00:09<00:02, 51.74it/s, Epoch: 1, Batch: 218,Loss: 0.748,Avg.Loss: 1.830,LR: 4.99E-04]Training epoch 1:  64%|██████▍   | 218/341 [00:09<00:02, 51.74it/s, Epoch: 1, Batch: 219,Loss: 1.274,Avg.Loss: 1.828,LR: 4.99E-04]Training epoch 1:  64%|██████▍   | 219/341 [00:09<00:02, 51.74it/s, Epoch: 1, Batch: 220,Loss: 1.887,Avg.Loss: 1.828,LR: 4.99E-04]Training epoch 1:  65%|██████▍   | 220/341 [00:09<00:02, 51.74it/s, Epoch: 1, Batch: 221,Loss: 1.746,Avg.Loss: 1.828,LR: 4.99E-04]Training epoch 1:  65%|██████▍   | 221/341 [00:09<00:02, 51.74it/s, Epoch: 1, Batch: 222,Loss: 1.032,Avg.Loss: 1.824,LR: 4.99E-04]Training epoch 1:  65%|██████▌   | 222/341 [00:09<00:02, 51.74it/s, Epoch: 1, Batch: 223,Loss: 0.951,Avg.Loss: 1.820,LR: 4.99E-04]Training epoch 1:  65%|██████▌   | 223/341 [00:09<00:02, 51.80it/s, Epoch: 1, Batch: 223,Loss: 0.951,Avg.Loss: 1.820,LR: 4.99E-04]Training epoch 1:  65%|██████▌   | 223/341 [00:09<00:02, 51.80it/s, Epoch: 1, Batch: 224,Loss: 1.461,Avg.Loss: 1.819,LR: 4.99E-04]Training epoch 1:  66%|██████▌   | 224/341 [00:09<00:02, 51.80it/s, Epoch: 1, Batch: 225,Loss: 1.566,Avg.Loss: 1.818,LR: 4.99E-04]Training epoch 1:  66%|██████▌   | 225/341 [00:09<00:02, 51.80it/s, Epoch: 1, Batch: 226,Loss: 1.241,Avg.Loss: 1.815,LR: 4.99E-04]Training epoch 1:  66%|██████▋   | 226/341 [00:10<00:02, 51.80it/s, Epoch: 1, Batch: 227,Loss: 1.316,Avg.Loss: 1.813,LR: 4.99E-04]Training epoch 1:  67%|██████▋   | 227/341 [00:10<00:02, 51.80it/s, Epoch: 1, Batch: 228,Loss: 1.516,Avg.Loss: 1.812,LR: 4.99E-04]Training epoch 1:  67%|██████▋   | 228/341 [00:10<00:02, 51.80it/s, Epoch: 1, Batch: 229,Loss: 1.366,Avg.Loss: 1.810,LR: 4.99E-04]Training epoch 1:  67%|██████▋   | 229/341 [00:10<00:02, 52.45it/s, Epoch: 1, Batch: 229,Loss: 1.366,Avg.Loss: 1.810,LR: 4.99E-04]Training epoch 1:  67%|██████▋   | 229/341 [00:10<00:02, 52.45it/s, Epoch: 1, Batch: 230,Loss: 0.988,Avg.Loss: 1.806,LR: 4.99E-04]Training epoch 1:  67%|██████▋   | 230/341 [00:10<00:02, 52.45it/s, Epoch: 1, Batch: 231,Loss: 1.715,Avg.Loss: 1.806,LR: 4.99E-04]Training epoch 1:  68%|██████▊   | 231/341 [00:10<00:02, 52.45it/s, Epoch: 1, Batch: 232,Loss: 1.986,Avg.Loss: 1.806,LR: 4.99E-04]Training epoch 1:  68%|██████▊   | 232/341 [00:10<00:02, 52.45it/s, Epoch: 1, Batch: 233,Loss: 1.921,Avg.Loss: 1.807,LR: 4.99E-04]Training epoch 1:  68%|██████▊   | 233/341 [00:10<00:02, 52.45it/s, Epoch: 1, Batch: 234,Loss: 1.207,Avg.Loss: 1.804,LR: 4.99E-04]Training epoch 1:  69%|██████▊   | 234/341 [00:10<00:02, 52.45it/s, Epoch: 1, Batch: 235,Loss: 1.101,Avg.Loss: 1.801,LR: 4.99E-04]Training epoch 1:  69%|██████▉   | 235/341 [00:10<00:02, 52.42it/s, Epoch: 1, Batch: 235,Loss: 1.101,Avg.Loss: 1.801,LR: 4.99E-04]Training epoch 1:  69%|██████▉   | 235/341 [00:10<00:02, 52.42it/s, Epoch: 1, Batch: 236,Loss: 0.967,Avg.Loss: 1.798,LR: 4.99E-04]Training epoch 1:  69%|██████▉   | 236/341 [00:10<00:02, 52.42it/s, Epoch: 1, Batch: 237,Loss: 1.057,Avg.Loss: 1.795,LR: 4.99E-04]Training epoch 1:  70%|██████▉   | 237/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 238,Loss: 0.931,Avg.Loss: 1.791,LR: 4.98E-04]Training epoch 1:  70%|██████▉   | 238/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 239,Loss: 1.121,Avg.Loss: 1.788,LR: 4.98E-04]Training epoch 1:  70%|███████   | 239/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 240,Loss: 0.959,Avg.Loss: 1.785,LR: 4.98E-04]Training epoch 1:  70%|███████   | 240/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 241,Loss: 0.789,Avg.Loss: 1.781,LR: 4.98E-04]Training epoch 1:  71%|███████   | 241/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 241,Loss: 0.789,Avg.Loss: 1.781,LR: 4.98E-04]Training epoch 1:  71%|███████   | 241/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 242,Loss: 0.973,Avg.Loss: 1.777,LR: 4.98E-04]Training epoch 1:  71%|███████   | 242/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 243,Loss: 0.777,Avg.Loss: 1.773,LR: 4.98E-04]Training epoch 1:  71%|███████▏  | 243/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 244,Loss: 1.027,Avg.Loss: 1.770,LR: 4.98E-04]Training epoch 1:  72%|███████▏  | 244/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 245,Loss: 1.109,Avg.Loss: 1.767,LR: 4.98E-04]Training epoch 1:  72%|███████▏  | 245/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 246,Loss: 0.793,Avg.Loss: 1.763,LR: 4.98E-04]Training epoch 1:  72%|███████▏  | 246/341 [00:10<00:01, 52.42it/s, Epoch: 1, Batch: 247,Loss: 1.071,Avg.Loss: 1.761,LR: 4.98E-04]Training epoch 1:  72%|███████▏  | 247/341 [00:10<00:01, 52.83it/s, Epoch: 1, Batch: 247,Loss: 1.071,Avg.Loss: 1.761,LR: 4.98E-04]Training epoch 1:  72%|███████▏  | 247/341 [00:10<00:01, 52.83it/s, Epoch: 1, Batch: 248,Loss: 1.272,Avg.Loss: 1.759,LR: 4.98E-04]Training epoch 1:  73%|███████▎  | 248/341 [00:10<00:01, 52.83it/s, Epoch: 1, Batch: 249,Loss: 1.181,Avg.Loss: 1.756,LR: 4.98E-04]Training epoch 1:  73%|███████▎  | 249/341 [00:10<00:01, 52.83it/s, Epoch: 1, Batch: 250,Loss: 1.203,Avg.Loss: 1.754,LR: 4.98E-04]Training epoch 1:  73%|███████▎  | 250/341 [00:10<00:01, 52.83it/s, Epoch: 1, Batch: 251,Loss: 1.191,Avg.Loss: 1.752,LR: 4.98E-04]Training epoch 1:  74%|███████▎  | 251/341 [00:10<00:01, 52.83it/s, Epoch: 1, Batch: 252,Loss: 1.067,Avg.Loss: 1.749,LR: 4.98E-04]Training epoch 1:  74%|███████▍  | 252/341 [00:10<00:01, 52.83it/s, Epoch: 1, Batch: 253,Loss: 1.339,Avg.Loss: 1.748,LR: 4.98E-04]Training epoch 1:  74%|███████▍  | 253/341 [00:10<00:01, 52.56it/s, Epoch: 1, Batch: 253,Loss: 1.339,Avg.Loss: 1.748,LR: 4.98E-04]Training epoch 1:  74%|███████▍  | 253/341 [00:10<00:01, 52.56it/s, Epoch: 1, Batch: 254,Loss: 1.473,Avg.Loss: 1.746,LR: 4.98E-04]Training epoch 1:  74%|███████▍  | 254/341 [00:10<00:01, 52.56it/s, Epoch: 1, Batch: 255,Loss: 1.065,Avg.Loss: 1.744,LR: 4.98E-04]Training epoch 1:  75%|███████▍  | 255/341 [00:10<00:01, 52.56it/s, Epoch: 1, Batch: 256,Loss: 1.097,Avg.Loss: 1.741,LR: 4.98E-04]Training epoch 1:  75%|███████▌  | 256/341 [00:10<00:01, 52.56it/s, Epoch: 1, Batch: 257,Loss: 1.148,Avg.Loss: 1.739,LR: 4.98E-04]Training epoch 1:  75%|███████▌  | 257/341 [00:10<00:01, 52.56it/s, Epoch: 1, Batch: 258,Loss: 0.833,Avg.Loss: 1.735,LR: 4.98E-04]Training epoch 1:  76%|███████▌  | 258/341 [00:10<00:01, 52.56it/s, Epoch: 1, Batch: 259,Loss: 0.950,Avg.Loss: 1.732,LR: 4.98E-04]Training epoch 1:  76%|███████▌  | 259/341 [00:10<00:01, 52.44it/s, Epoch: 1, Batch: 259,Loss: 0.950,Avg.Loss: 1.732,LR: 4.98E-04]Training epoch 1:  76%|███████▌  | 259/341 [00:10<00:01, 52.44it/s, Epoch: 1, Batch: 260,Loss: 0.971,Avg.Loss: 1.730,LR: 4.98E-04]Training epoch 1:  76%|███████▌  | 260/341 [00:10<00:01, 52.44it/s, Epoch: 1, Batch: 261,Loss: 0.858,Avg.Loss: 1.726,LR: 4.98E-04]Training epoch 1:  77%|███████▋  | 261/341 [00:10<00:01, 52.44it/s, Epoch: 1, Batch: 262,Loss: 0.876,Avg.Loss: 1.723,LR: 4.98E-04]Training epoch 1:  77%|███████▋  | 262/341 [00:10<00:01, 52.44it/s, Epoch: 1, Batch: 263,Loss: 1.081,Avg.Loss: 1.720,LR: 4.98E-04]Training epoch 1:  77%|███████▋  | 263/341 [00:10<00:01, 52.44it/s, Epoch: 1, Batch: 264,Loss: 0.693,Avg.Loss: 1.717,LR: 4.98E-04]Training epoch 1:  77%|███████▋  | 264/341 [00:10<00:01, 52.44it/s, Epoch: 1, Batch: 265,Loss: 0.846,Avg.Loss: 1.713,LR: 4.98E-04]Training epoch 1:  78%|███████▊  | 265/341 [00:10<00:01, 52.39it/s, Epoch: 1, Batch: 265,Loss: 0.846,Avg.Loss: 1.713,LR: 4.98E-04]Training epoch 1:  78%|███████▊  | 265/341 [00:10<00:01, 52.39it/s, Epoch: 1, Batch: 266,Loss: 0.834,Avg.Loss: 1.710,LR: 4.98E-04]Training epoch 1:  78%|███████▊  | 266/341 [00:10<00:01, 52.39it/s, Epoch: 1, Batch: 267,Loss: 0.771,Avg.Loss: 1.706,LR: 4.98E-04]Training epoch 1:  78%|███████▊  | 267/341 [00:10<00:01, 52.39it/s, Epoch: 1, Batch: 268,Loss: 1.163,Avg.Loss: 1.704,LR: 4.98E-04]Training epoch 1:  79%|███████▊  | 268/341 [00:10<00:01, 52.39it/s, Epoch: 1, Batch: 269,Loss: 1.712,Avg.Loss: 1.704,LR: 4.98E-04]Training epoch 1:  79%|███████▉  | 269/341 [00:10<00:01, 52.39it/s, Epoch: 1, Batch: 270,Loss: 0.905,Avg.Loss: 1.702,LR: 4.98E-04]Training epoch 1:  79%|███████▉  | 270/341 [00:10<00:01, 52.39it/s, Epoch: 1, Batch: 271,Loss: 0.852,Avg.Loss: 1.698,LR: 4.98E-04]Training epoch 1:  79%|███████▉  | 271/341 [00:10<00:01, 52.63it/s, Epoch: 1, Batch: 271,Loss: 0.852,Avg.Loss: 1.698,LR: 4.98E-04]Training epoch 1:  79%|███████▉  | 271/341 [00:10<00:01, 52.63it/s, Epoch: 1, Batch: 272,Loss: 0.921,Avg.Loss: 1.696,LR: 4.98E-04]Training epoch 1:  80%|███████▉  | 272/341 [00:10<00:01, 52.63it/s, Epoch: 1, Batch: 273,Loss: 0.868,Avg.Loss: 1.693,LR: 4.98E-04]Training epoch 1:  80%|████████  | 273/341 [00:10<00:01, 52.63it/s, Epoch: 1, Batch: 274,Loss: 0.849,Avg.Loss: 1.689,LR: 4.98E-04]Training epoch 1:  80%|████████  | 274/341 [00:10<00:01, 52.63it/s, Epoch: 1, Batch: 275,Loss: 1.142,Avg.Loss: 1.687,LR: 4.98E-04]Training epoch 1:  81%|████████  | 275/341 [00:10<00:01, 52.63it/s, Epoch: 1, Batch: 276,Loss: 1.198,Avg.Loss: 1.686,LR: 4.98E-04]Training epoch 1:  81%|████████  | 276/341 [00:10<00:01, 52.63it/s, Epoch: 1, Batch: 277,Loss: 1.042,Avg.Loss: 1.683,LR: 4.98E-04]Training epoch 1:  81%|████████  | 277/341 [00:10<00:01, 53.71it/s, Epoch: 1, Batch: 277,Loss: 1.042,Avg.Loss: 1.683,LR: 4.98E-04]Training epoch 1:  81%|████████  | 277/341 [00:10<00:01, 53.71it/s, Epoch: 1, Batch: 278,Loss: 1.277,Avg.Loss: 1.682,LR: 4.98E-04]Training epoch 1:  82%|████████▏ | 278/341 [00:10<00:01, 53.71it/s, Epoch: 1, Batch: 279,Loss: 0.968,Avg.Loss: 1.679,LR: 4.98E-04]Training epoch 1:  82%|████████▏ | 279/341 [00:11<00:01, 53.71it/s, Epoch: 1, Batch: 280,Loss: 0.604,Avg.Loss: 1.675,LR: 4.98E-04]Training epoch 1:  82%|████████▏ | 280/341 [00:11<00:01, 53.71it/s, Epoch: 1, Batch: 281,Loss: 0.888,Avg.Loss: 1.673,LR: 4.98E-04]Training epoch 1:  82%|████████▏ | 281/341 [00:11<00:01, 53.71it/s, Epoch: 1, Batch: 282,Loss: 0.760,Avg.Loss: 1.669,LR: 4.98E-04]Training epoch 1:  83%|████████▎ | 282/341 [00:11<00:01, 53.71it/s, Epoch: 1, Batch: 283,Loss: 0.680,Avg.Loss: 1.666,LR: 4.98E-04]Training epoch 1:  83%|████████▎ | 283/341 [00:11<00:01, 53.49it/s, Epoch: 1, Batch: 283,Loss: 0.680,Avg.Loss: 1.666,LR: 4.98E-04]Training epoch 1:  83%|████████▎ | 283/341 [00:11<00:01, 53.49it/s, Epoch: 1, Batch: 284,Loss: 0.998,Avg.Loss: 1.664,LR: 4.98E-04]Training epoch 1:  83%|████████▎ | 284/341 [00:11<00:01, 53.49it/s, Epoch: 1, Batch: 285,Loss: 0.707,Avg.Loss: 1.660,LR: 4.98E-04]Training epoch 1:  84%|████████▎ | 285/341 [00:11<00:01, 53.49it/s, Epoch: 1, Batch: 286,Loss: 0.645,Avg.Loss: 1.657,LR: 4.98E-04]Training epoch 1:  84%|████████▍ | 286/341 [00:11<00:01, 53.49it/s, Epoch: 1, Batch: 287,Loss: 0.437,Avg.Loss: 1.652,LR: 4.98E-04]Training epoch 1:  84%|████████▍ | 287/341 [00:11<00:01, 53.49it/s, Epoch: 1, Batch: 288,Loss: 0.893,Avg.Loss: 1.650,LR: 4.98E-04]Training epoch 1:  84%|████████▍ | 288/341 [00:11<00:00, 53.49it/s, Epoch: 1, Batch: 289,Loss: 0.830,Avg.Loss: 1.647,LR: 4.98E-04]Training epoch 1:  85%|████████▍ | 289/341 [00:11<00:00, 53.30it/s, Epoch: 1, Batch: 289,Loss: 0.830,Avg.Loss: 1.647,LR: 4.98E-04]Training epoch 1:  85%|████████▍ | 289/341 [00:11<00:00, 53.30it/s, Epoch: 1, Batch: 290,Loss: 0.647,Avg.Loss: 1.644,LR: 4.98E-04]Training epoch 1:  85%|████████▌ | 290/341 [00:11<00:00, 53.30it/s, Epoch: 1, Batch: 291,Loss: 0.671,Avg.Loss: 1.640,LR: 4.98E-04]Training epoch 1:  85%|████████▌ | 291/341 [00:11<00:00, 53.30it/s, Epoch: 1, Batch: 292,Loss: 0.385,Avg.Loss: 1.636,LR: 4.98E-04]Training epoch 1:  86%|████████▌ | 292/341 [00:11<00:00, 53.30it/s, Epoch: 1, Batch: 293,Loss: 0.546,Avg.Loss: 1.632,LR: 4.98E-04]Training epoch 1:  86%|████████▌ | 293/341 [00:11<00:00, 53.30it/s, Epoch: 1, Batch: 294,Loss: 0.807,Avg.Loss: 1.629,LR: 4.98E-04]Training epoch 1:  86%|████████▌ | 294/341 [00:11<00:00, 53.30it/s, Epoch: 1, Batch: 295,Loss: 1.013,Avg.Loss: 1.627,LR: 4.98E-04]Training epoch 1:  87%|████████▋ | 295/341 [00:11<00:00, 53.32it/s, Epoch: 1, Batch: 295,Loss: 1.013,Avg.Loss: 1.627,LR: 4.98E-04]Training epoch 1:  87%|████████▋ | 295/341 [00:11<00:00, 53.32it/s, Epoch: 1, Batch: 296,Loss: 1.136,Avg.Loss: 1.626,LR: 4.98E-04]Training epoch 1:  87%|████████▋ | 296/341 [00:11<00:00, 53.32it/s, Epoch: 1, Batch: 297,Loss: 1.165,Avg.Loss: 1.624,LR: 4.98E-04]Training epoch 1:  87%|████████▋ | 297/341 [00:11<00:00, 53.32it/s, Epoch: 1, Batch: 298,Loss: 0.897,Avg.Loss: 1.622,LR: 4.98E-04]Training epoch 1:  87%|████████▋ | 298/341 [00:11<00:00, 53.32it/s, Epoch: 1, Batch: 299,Loss: 1.554,Avg.Loss: 1.621,LR: 4.98E-04]Training epoch 1:  88%|████████▊ | 299/341 [00:11<00:00, 53.32it/s, Epoch: 1, Batch: 300,Loss: 1.633,Avg.Loss: 1.621,LR: 4.98E-04]Training epoch 1:  88%|████████▊ | 300/341 [00:11<00:00, 53.32it/s, Epoch: 1, Batch: 301,Loss: 2.186,Avg.Loss: 1.623,LR: 4.98E-04]Training epoch 1:  88%|████████▊ | 301/341 [00:11<00:00, 53.01it/s, Epoch: 1, Batch: 301,Loss: 2.186,Avg.Loss: 1.623,LR: 4.98E-04]Training epoch 1:  88%|████████▊ | 301/341 [00:11<00:00, 53.01it/s, Epoch: 1, Batch: 302,Loss: 2.289,Avg.Loss: 1.625,LR: 4.98E-04]Training epoch 1:  89%|████████▊ | 302/341 [00:11<00:00, 53.01it/s, Epoch: 1, Batch: 303,Loss: 0.715,Avg.Loss: 1.622,LR: 4.98E-04]Training epoch 1:  89%|████████▉ | 303/341 [00:11<00:00, 53.01it/s, Epoch: 1, Batch: 304,Loss: 1.615,Avg.Loss: 1.622,LR: 4.98E-04]Training epoch 1:  89%|████████▉ | 304/341 [00:11<00:00, 53.01it/s, Epoch: 1, Batch: 305,Loss: 1.073,Avg.Loss: 1.621,LR: 4.98E-04]Training epoch 1:  89%|████████▉ | 305/341 [00:11<00:00, 53.01it/s, Epoch: 1, Batch: 306,Loss: 0.478,Avg.Loss: 1.617,LR: 4.98E-04]Training epoch 1:  90%|████████▉ | 306/341 [00:11<00:00, 53.01it/s, Epoch: 1, Batch: 307,Loss: 0.806,Avg.Loss: 1.614,LR: 4.98E-04]Training epoch 1:  90%|█████████ | 307/341 [00:11<00:00, 53.05it/s, Epoch: 1, Batch: 307,Loss: 0.806,Avg.Loss: 1.614,LR: 4.98E-04]Training epoch 1:  90%|█████████ | 307/341 [00:11<00:00, 53.05it/s, Epoch: 1, Batch: 308,Loss: 0.744,Avg.Loss: 1.611,LR: 4.97E-04]Training epoch 1:  90%|█████████ | 308/341 [00:11<00:00, 53.05it/s, Epoch: 1, Batch: 309,Loss: 0.561,Avg.Loss: 1.608,LR: 4.97E-04]Training epoch 1:  91%|█████████ | 309/341 [00:11<00:00, 53.05it/s, Epoch: 1, Batch: 310,Loss: 0.476,Avg.Loss: 1.604,LR: 4.97E-04]Training epoch 1:  91%|█████████ | 310/341 [00:11<00:00, 53.05it/s, Epoch: 1, Batch: 311,Loss: 0.466,Avg.Loss: 1.601,LR: 4.97E-04]Training epoch 1:  91%|█████████ | 311/341 [00:11<00:00, 53.05it/s, Epoch: 1, Batch: 312,Loss: 0.542,Avg.Loss: 1.597,LR: 4.97E-04]Training epoch 1:  91%|█████████▏| 312/341 [00:11<00:00, 53.05it/s, Epoch: 1, Batch: 313,Loss: 0.569,Avg.Loss: 1.594,LR: 4.97E-04]Training epoch 1:  92%|█████████▏| 313/341 [00:11<00:00, 52.84it/s, Epoch: 1, Batch: 313,Loss: 0.569,Avg.Loss: 1.594,LR: 4.97E-04]Training epoch 1:  92%|█████████▏| 313/341 [00:11<00:00, 52.84it/s, Epoch: 1, Batch: 314,Loss: 0.390,Avg.Loss: 1.590,LR: 4.97E-04]Training epoch 1:  92%|█████████▏| 314/341 [00:11<00:00, 52.84it/s, Epoch: 1, Batch: 315,Loss: 0.502,Avg.Loss: 1.587,LR: 4.97E-04]Training epoch 1:  92%|█████████▏| 315/341 [00:11<00:00, 52.84it/s, Epoch: 1, Batch: 316,Loss: 0.791,Avg.Loss: 1.584,LR: 4.97E-04]Training epoch 1:  93%|█████████▎| 316/341 [00:11<00:00, 52.84it/s, Epoch: 1, Batch: 317,Loss: 1.285,Avg.Loss: 1.583,LR: 4.97E-04]Training epoch 1:  93%|█████████▎| 317/341 [00:11<00:00, 52.84it/s, Epoch: 1, Batch: 318,Loss: 1.141,Avg.Loss: 1.582,LR: 4.97E-04]Training epoch 1:  93%|█████████▎| 318/341 [00:11<00:00, 52.84it/s, Epoch: 1, Batch: 319,Loss: 1.057,Avg.Loss: 1.580,LR: 4.97E-04]Training epoch 1:  94%|█████████▎| 319/341 [00:11<00:00, 52.47it/s, Epoch: 1, Batch: 319,Loss: 1.057,Avg.Loss: 1.580,LR: 4.97E-04]Training epoch 1:  94%|█████████▎| 319/341 [00:11<00:00, 52.47it/s, Epoch: 1, Batch: 320,Loss: 0.962,Avg.Loss: 1.578,LR: 4.97E-04]Training epoch 1:  94%|█████████▍| 320/341 [00:11<00:00, 52.47it/s, Epoch: 1, Batch: 321,Loss: 0.894,Avg.Loss: 1.576,LR: 4.97E-04]Training epoch 1:  94%|█████████▍| 321/341 [00:11<00:00, 52.47it/s, Epoch: 1, Batch: 322,Loss: 0.520,Avg.Loss: 1.573,LR: 4.97E-04]Training epoch 1:  94%|█████████▍| 322/341 [00:11<00:00, 52.47it/s, Epoch: 1, Batch: 323,Loss: 0.829,Avg.Loss: 1.571,LR: 4.97E-04]Training epoch 1:  95%|█████████▍| 323/341 [00:11<00:00, 52.47it/s, Epoch: 1, Batch: 324,Loss: 0.978,Avg.Loss: 1.569,LR: 4.97E-04]Training epoch 1:  95%|█████████▌| 324/341 [00:11<00:00, 52.47it/s, Epoch: 1, Batch: 325,Loss: 0.995,Avg.Loss: 1.567,LR: 4.97E-04]Training epoch 1:  95%|█████████▌| 325/341 [00:11<00:00, 52.32it/s, Epoch: 1, Batch: 325,Loss: 0.995,Avg.Loss: 1.567,LR: 4.97E-04]Training epoch 1:  95%|█████████▌| 325/341 [00:11<00:00, 52.32it/s, Epoch: 1, Batch: 326,Loss: 0.925,Avg.Loss: 1.565,LR: 4.97E-04]Training epoch 1:  96%|█████████▌| 326/341 [00:11<00:00, 52.32it/s, Epoch: 1, Batch: 327,Loss: 1.269,Avg.Loss: 1.564,LR: 4.97E-04]Training epoch 1:  96%|█████████▌| 327/341 [00:11<00:00, 52.32it/s, Epoch: 1, Batch: 328,Loss: 0.979,Avg.Loss: 1.562,LR: 4.97E-04]Training epoch 1:  96%|█████████▌| 328/341 [00:11<00:00, 52.32it/s, Epoch: 1, Batch: 329,Loss: 0.535,Avg.Loss: 1.559,LR: 4.97E-04]Training epoch 1:  96%|█████████▋| 329/341 [00:11<00:00, 52.32it/s, Epoch: 1, Batch: 330,Loss: 0.526,Avg.Loss: 1.556,LR: 4.97E-04]Training epoch 1:  97%|█████████▋| 330/341 [00:11<00:00, 52.32it/s, Epoch: 1, Batch: 331,Loss: 0.479,Avg.Loss: 1.553,LR: 4.97E-04]Training epoch 1:  97%|█████████▋| 331/341 [00:11<00:00, 52.45it/s, Epoch: 1, Batch: 331,Loss: 0.479,Avg.Loss: 1.553,LR: 4.97E-04]Training epoch 1:  97%|█████████▋| 331/341 [00:11<00:00, 52.45it/s, Epoch: 1, Batch: 332,Loss: 0.619,Avg.Loss: 1.550,LR: 4.97E-04]Training epoch 1:  97%|█████████▋| 332/341 [00:12<00:00, 52.45it/s, Epoch: 1, Batch: 333,Loss: 0.562,Avg.Loss: 1.547,LR: 4.97E-04]Training epoch 1:  98%|█████████▊| 333/341 [00:12<00:00, 52.45it/s, Epoch: 1, Batch: 334,Loss: 0.486,Avg.Loss: 1.544,LR: 4.97E-04]Training epoch 1:  98%|█████████▊| 334/341 [00:12<00:00, 52.45it/s, Epoch: 1, Batch: 335,Loss: 0.901,Avg.Loss: 1.542,LR: 4.97E-04]Training epoch 1:  98%|█████████▊| 335/341 [00:12<00:00, 52.45it/s, Epoch: 1, Batch: 336,Loss: 0.679,Avg.Loss: 1.539,LR: 4.97E-04]Training epoch 1:  99%|█████████▊| 336/341 [00:12<00:00, 52.45it/s, Epoch: 1, Batch: 337,Loss: 0.288,Avg.Loss: 1.536,LR: 4.97E-04]Training epoch 1:  99%|█████████▉| 337/341 [00:12<00:00, 52.83it/s, Epoch: 1, Batch: 337,Loss: 0.288,Avg.Loss: 1.536,LR: 4.97E-04]Training epoch 1:  99%|█████████▉| 337/341 [00:12<00:00, 52.83it/s, Epoch: 1, Batch: 338,Loss: 0.420,Avg.Loss: 1.532,LR: 4.97E-04]Training epoch 1:  99%|█████████▉| 338/341 [00:12<00:00, 52.83it/s, Epoch: 1, Batch: 339,Loss: 0.375,Avg.Loss: 1.529,LR: 4.97E-04]Training epoch 1:  99%|█████████▉| 339/341 [00:12<00:00, 52.83it/s, Epoch: 1, Batch: 340,Loss: 0.588,Avg.Loss: 1.526,LR: 4.97E-04]Training epoch 1: 100%|█████████▉| 340/341 [00:16<00:00, 52.83it/s, Epoch: 1, Batch: 341,Loss: 0.722,Avg.Loss: 1.524,LR: 4.97E-04]Training epoch 1: 100%|██████████| 341/341 [00:16<00:00, 20.24it/s, Epoch: 1, Batch: 341,Loss: 0.722,Avg.Loss: 1.524,LR: 4.97E-04]
Training epoch 2:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 2:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 2, Batch: 1,Loss: 0.685,Avg.Loss: 0.685,LR: 4.97E-04]Training epoch 2:   0%|          | 1/341 [00:00<00:12, 26.20it/s, Epoch: 2, Batch: 2,Loss: 0.720,Avg.Loss: 0.702,LR: 4.97E-04]Training epoch 2:   1%|          | 2/341 [00:00<00:09, 36.56it/s, Epoch: 2, Batch: 3,Loss: 0.331,Avg.Loss: 0.579,LR: 4.97E-04]Training epoch 2:   1%|          | 3/341 [00:00<00:08, 41.17it/s, Epoch: 2, Batch: 4,Loss: 1.084,Avg.Loss: 0.705,LR: 4.97E-04]Training epoch 2:   1%|          | 4/341 [00:00<00:07, 42.72it/s, Epoch: 2, Batch: 5,Loss: 1.031,Avg.Loss: 0.770,LR: 4.97E-04]Training epoch 2:   1%|▏         | 5/341 [00:00<00:07, 43.94it/s, Epoch: 2, Batch: 6,Loss: 0.610,Avg.Loss: 0.744,LR: 4.97E-04]Training epoch 2:   2%|▏         | 6/341 [00:00<00:06, 52.62it/s, Epoch: 2, Batch: 6,Loss: 0.610,Avg.Loss: 0.744,LR: 4.97E-04]Training epoch 2:   2%|▏         | 6/341 [00:00<00:06, 52.62it/s, Epoch: 2, Batch: 7,Loss: 0.675,Avg.Loss: 0.734,LR: 4.97E-04]Training epoch 2:   2%|▏         | 7/341 [00:00<00:06, 52.62it/s, Epoch: 2, Batch: 8,Loss: 0.875,Avg.Loss: 0.751,LR: 4.97E-04]Training epoch 2:   2%|▏         | 8/341 [00:00<00:06, 52.62it/s, Epoch: 2, Batch: 9,Loss: 0.297,Avg.Loss: 0.701,LR: 4.97E-04]Training epoch 2:   3%|▎         | 9/341 [00:00<00:06, 52.62it/s, Epoch: 2, Batch: 10,Loss: 0.219,Avg.Loss: 0.653,LR: 4.97E-04]Training epoch 2:   3%|▎         | 10/341 [00:00<00:06, 52.62it/s, Epoch: 2, Batch: 11,Loss: 0.801,Avg.Loss: 0.666,LR: 4.97E-04]Training epoch 2:   3%|▎         | 11/341 [00:00<00:06, 52.62it/s, Epoch: 2, Batch: 12,Loss: 0.630,Avg.Loss: 0.663,LR: 4.97E-04]Training epoch 2:   4%|▎         | 12/341 [00:00<00:06, 51.09it/s, Epoch: 2, Batch: 12,Loss: 0.630,Avg.Loss: 0.663,LR: 4.97E-04]Training epoch 2:   4%|▎         | 12/341 [00:00<00:06, 51.09it/s, Epoch: 2, Batch: 13,Loss: 0.503,Avg.Loss: 0.651,LR: 4.97E-04]Training epoch 2:   4%|▍         | 13/341 [00:00<00:06, 51.09it/s, Epoch: 2, Batch: 14,Loss: 0.335,Avg.Loss: 0.628,LR: 4.97E-04]Training epoch 2:   4%|▍         | 14/341 [00:00<00:06, 51.09it/s, Epoch: 2, Batch: 15,Loss: 0.159,Avg.Loss: 0.597,LR: 4.97E-04]Training epoch 2:   4%|▍         | 15/341 [00:00<00:06, 51.09it/s, Epoch: 2, Batch: 16,Loss: 0.377,Avg.Loss: 0.583,LR: 4.97E-04]Training epoch 2:   5%|▍         | 16/341 [00:00<00:06, 51.09it/s, Epoch: 2, Batch: 17,Loss: 0.908,Avg.Loss: 0.602,LR: 4.97E-04]Training epoch 2:   5%|▍         | 17/341 [00:00<00:06, 51.09it/s, Epoch: 2, Batch: 18,Loss: 1.046,Avg.Loss: 0.627,LR: 4.97E-04]Training epoch 2:   5%|▌         | 18/341 [00:00<00:06, 49.22it/s, Epoch: 2, Batch: 18,Loss: 1.046,Avg.Loss: 0.627,LR: 4.97E-04]Training epoch 2:   5%|▌         | 18/341 [00:00<00:06, 49.22it/s, Epoch: 2, Batch: 19,Loss: 0.718,Avg.Loss: 0.632,LR: 4.97E-04]Training epoch 2:   6%|▌         | 19/341 [00:00<00:06, 49.22it/s, Epoch: 2, Batch: 20,Loss: 0.909,Avg.Loss: 0.646,LR: 4.97E-04]Training epoch 2:   6%|▌         | 20/341 [00:00<00:06, 49.22it/s, Epoch: 2, Batch: 21,Loss: 0.957,Avg.Loss: 0.660,LR: 4.97E-04]Training epoch 2:   6%|▌         | 21/341 [00:00<00:06, 49.22it/s, Epoch: 2, Batch: 22,Loss: 1.051,Avg.Loss: 0.678,LR: 4.97E-04]Training epoch 2:   6%|▋         | 22/341 [00:00<00:06, 49.22it/s, Epoch: 2, Batch: 23,Loss: 0.546,Avg.Loss: 0.672,LR: 4.96E-04]Training epoch 2:   7%|▋         | 23/341 [00:00<00:06, 48.77it/s, Epoch: 2, Batch: 23,Loss: 0.546,Avg.Loss: 0.672,LR: 4.96E-04]Training epoch 2:   7%|▋         | 23/341 [00:00<00:06, 48.77it/s, Epoch: 2, Batch: 24,Loss: 1.158,Avg.Loss: 0.693,LR: 4.96E-04]Training epoch 2:   7%|▋         | 24/341 [00:00<00:06, 48.77it/s, Epoch: 2, Batch: 25,Loss: 1.441,Avg.Loss: 0.723,LR: 4.96E-04]Training epoch 2:   7%|▋         | 25/341 [00:00<00:06, 48.77it/s, Epoch: 2, Batch: 26,Loss: 1.747,Avg.Loss: 0.762,LR: 4.96E-04]Training epoch 2:   8%|▊         | 26/341 [00:00<00:06, 48.77it/s, Epoch: 2, Batch: 27,Loss: 0.769,Avg.Loss: 0.762,LR: 4.96E-04]Training epoch 2:   8%|▊         | 27/341 [00:00<00:06, 48.77it/s, Epoch: 2, Batch: 28,Loss: 1.573,Avg.Loss: 0.791,LR: 4.96E-04]Training epoch 2:   8%|▊         | 28/341 [00:00<00:06, 47.57it/s, Epoch: 2, Batch: 28,Loss: 1.573,Avg.Loss: 0.791,LR: 4.96E-04]Training epoch 2:   8%|▊         | 28/341 [00:00<00:06, 47.57it/s, Epoch: 2, Batch: 29,Loss: 2.679,Avg.Loss: 0.856,LR: 4.96E-04]Training epoch 2:   9%|▊         | 29/341 [00:00<00:06, 47.57it/s, Epoch: 2, Batch: 30,Loss: 2.122,Avg.Loss: 0.898,LR: 4.96E-04]Training epoch 2:   9%|▉         | 30/341 [00:00<00:06, 47.57it/s, Epoch: 2, Batch: 31,Loss: 1.108,Avg.Loss: 0.905,LR: 4.96E-04]Training epoch 2:   9%|▉         | 31/341 [00:00<00:06, 47.57it/s, Epoch: 2, Batch: 32,Loss: 0.667,Avg.Loss: 0.898,LR: 4.96E-04]Training epoch 2:   9%|▉         | 32/341 [00:00<00:06, 47.57it/s, Epoch: 2, Batch: 33,Loss: 1.141,Avg.Loss: 0.905,LR: 4.96E-04]Training epoch 2:  10%|▉         | 33/341 [00:00<00:06, 47.97it/s, Epoch: 2, Batch: 33,Loss: 1.141,Avg.Loss: 0.905,LR: 4.96E-04]Training epoch 2:  10%|▉         | 33/341 [00:00<00:06, 47.97it/s, Epoch: 2, Batch: 34,Loss: 1.053,Avg.Loss: 0.910,LR: 4.96E-04]Training epoch 2:  10%|▉         | 34/341 [00:00<00:06, 47.97it/s, Epoch: 2, Batch: 35,Loss: 0.734,Avg.Loss: 0.904,LR: 4.96E-04]Training epoch 2:  10%|█         | 35/341 [00:00<00:06, 47.97it/s, Epoch: 2, Batch: 36,Loss: 0.904,Avg.Loss: 0.904,LR: 4.96E-04]Training epoch 2:  11%|█         | 36/341 [00:00<00:06, 47.97it/s, Epoch: 2, Batch: 37,Loss: 1.164,Avg.Loss: 0.911,LR: 4.96E-04]Training epoch 2:  11%|█         | 37/341 [00:00<00:06, 47.97it/s, Epoch: 2, Batch: 38,Loss: 1.139,Avg.Loss: 0.917,LR: 4.96E-04]Training epoch 2:  11%|█         | 38/341 [00:00<00:06, 47.97it/s, Epoch: 2, Batch: 39,Loss: 0.547,Avg.Loss: 0.908,LR: 4.96E-04]Training epoch 2:  11%|█▏        | 39/341 [00:00<00:06, 48.94it/s, Epoch: 2, Batch: 39,Loss: 0.547,Avg.Loss: 0.908,LR: 4.96E-04]Training epoch 2:  11%|█▏        | 39/341 [00:00<00:06, 48.94it/s, Epoch: 2, Batch: 40,Loss: 1.083,Avg.Loss: 0.912,LR: 4.96E-04]Training epoch 2:  12%|█▏        | 40/341 [00:00<00:06, 48.94it/s, Epoch: 2, Batch: 41,Loss: 1.618,Avg.Loss: 0.930,LR: 4.96E-04]Training epoch 2:  12%|█▏        | 41/341 [00:00<00:06, 48.94it/s, Epoch: 2, Batch: 42,Loss: 1.578,Avg.Loss: 0.945,LR: 4.96E-04]Training epoch 2:  12%|█▏        | 42/341 [00:00<00:06, 48.94it/s, Epoch: 2, Batch: 43,Loss: 0.401,Avg.Loss: 0.932,LR: 4.96E-04]Training epoch 2:  13%|█▎        | 43/341 [00:00<00:06, 48.94it/s, Epoch: 2, Batch: 44,Loss: 1.124,Avg.Loss: 0.937,LR: 4.96E-04]Training epoch 2:  13%|█▎        | 44/341 [00:00<00:06, 48.94it/s, Epoch: 2, Batch: 45,Loss: 1.641,Avg.Loss: 0.952,LR: 4.96E-04]Training epoch 2:  13%|█▎        | 45/341 [00:00<00:05, 49.96it/s, Epoch: 2, Batch: 45,Loss: 1.641,Avg.Loss: 0.952,LR: 4.96E-04]Training epoch 2:  13%|█▎        | 45/341 [00:00<00:05, 49.96it/s, Epoch: 2, Batch: 46,Loss: 1.921,Avg.Loss: 0.973,LR: 4.96E-04]Training epoch 2:  13%|█▎        | 46/341 [00:00<00:05, 49.96it/s, Epoch: 2, Batch: 47,Loss: 0.793,Avg.Loss: 0.970,LR: 4.96E-04]Training epoch 2:  14%|█▍        | 47/341 [00:00<00:05, 49.96it/s, Epoch: 2, Batch: 48,Loss: 0.478,Avg.Loss: 0.959,LR: 4.96E-04]Training epoch 2:  14%|█▍        | 48/341 [00:00<00:05, 49.96it/s, Epoch: 2, Batch: 49,Loss: 0.894,Avg.Loss: 0.958,LR: 4.96E-04]Training epoch 2:  14%|█▍        | 49/341 [00:01<00:05, 49.96it/s, Epoch: 2, Batch: 50,Loss: 0.580,Avg.Loss: 0.950,LR: 4.96E-04]Training epoch 2:  15%|█▍        | 50/341 [00:01<00:05, 49.86it/s, Epoch: 2, Batch: 50,Loss: 0.580,Avg.Loss: 0.950,LR: 4.96E-04]Training epoch 2:  15%|█▍        | 50/341 [00:01<00:05, 49.86it/s, Epoch: 2, Batch: 51,Loss: 0.144,Avg.Loss: 0.935,LR: 4.96E-04]Training epoch 2:  15%|█▍        | 51/341 [00:01<00:05, 49.86it/s, Epoch: 2, Batch: 52,Loss: 0.514,Avg.Loss: 0.927,LR: 4.96E-04]Training epoch 2:  15%|█▌        | 52/341 [00:01<00:05, 49.86it/s, Epoch: 2, Batch: 53,Loss: 0.502,Avg.Loss: 0.919,LR: 4.96E-04]Training epoch 2:  16%|█▌        | 53/341 [00:01<00:05, 49.86it/s, Epoch: 2, Batch: 54,Loss: 0.432,Avg.Loss: 0.910,LR: 4.96E-04]Training epoch 2:  16%|█▌        | 54/341 [00:01<00:05, 49.86it/s, Epoch: 2, Batch: 55,Loss: 0.491,Avg.Loss: 0.902,LR: 4.96E-04]Training epoch 2:  16%|█▌        | 55/341 [00:01<00:05, 49.64it/s, Epoch: 2, Batch: 55,Loss: 0.491,Avg.Loss: 0.902,LR: 4.96E-04]Training epoch 2:  16%|█▌        | 55/341 [00:01<00:05, 49.64it/s, Epoch: 2, Batch: 56,Loss: 0.489,Avg.Loss: 0.895,LR: 4.96E-04]Training epoch 2:  16%|█▋        | 56/341 [00:01<00:05, 49.64it/s, Epoch: 2, Batch: 57,Loss: 0.311,Avg.Loss: 0.884,LR: 4.96E-04]Training epoch 2:  17%|█▋        | 57/341 [00:01<00:05, 49.64it/s, Epoch: 2, Batch: 58,Loss: 0.157,Avg.Loss: 0.872,LR: 4.96E-04]Training epoch 2:  17%|█▋        | 58/341 [00:01<00:05, 49.64it/s, Epoch: 2, Batch: 59,Loss: 0.130,Avg.Loss: 0.859,LR: 4.96E-04]Training epoch 2:  17%|█▋        | 59/341 [00:01<00:05, 49.64it/s, Epoch: 2, Batch: 60,Loss: 0.290,Avg.Loss: 0.850,LR: 4.96E-04]Training epoch 2:  18%|█▊        | 60/341 [00:01<00:05, 49.39it/s, Epoch: 2, Batch: 60,Loss: 0.290,Avg.Loss: 0.850,LR: 4.96E-04]Training epoch 2:  18%|█▊        | 60/341 [00:01<00:05, 49.39it/s, Epoch: 2, Batch: 61,Loss: 0.395,Avg.Loss: 0.842,LR: 4.96E-04]Training epoch 2:  18%|█▊        | 61/341 [00:01<00:05, 49.39it/s, Epoch: 2, Batch: 62,Loss: 1.122,Avg.Loss: 0.847,LR: 4.96E-04]Training epoch 2:  18%|█▊        | 62/341 [00:01<00:05, 49.39it/s, Epoch: 2, Batch: 63,Loss: 1.545,Avg.Loss: 0.858,LR: 4.96E-04]Training epoch 2:  18%|█▊        | 63/341 [00:01<00:05, 49.39it/s, Epoch: 2, Batch: 64,Loss: 0.744,Avg.Loss: 0.856,LR: 4.96E-04]Training epoch 2:  19%|█▉        | 64/341 [00:01<00:05, 49.39it/s, Epoch: 2, Batch: 65,Loss: 1.258,Avg.Loss: 0.862,LR: 4.96E-04]Training epoch 2:  19%|█▉        | 65/341 [00:01<00:05, 49.48it/s, Epoch: 2, Batch: 65,Loss: 1.258,Avg.Loss: 0.862,LR: 4.96E-04]Training epoch 2:  19%|█▉        | 65/341 [00:01<00:05, 49.48it/s, Epoch: 2, Batch: 66,Loss: 2.069,Avg.Loss: 0.881,LR: 4.96E-04]Training epoch 2:  19%|█▉        | 66/341 [00:01<00:05, 49.48it/s, Epoch: 2, Batch: 67,Loss: 1.824,Avg.Loss: 0.895,LR: 4.96E-04]Training epoch 2:  20%|█▉        | 67/341 [00:01<00:05, 49.48it/s, Epoch: 2, Batch: 68,Loss: 0.152,Avg.Loss: 0.884,LR: 4.96E-04]Training epoch 2:  20%|█▉        | 68/341 [00:01<00:05, 49.48it/s, Epoch: 2, Batch: 69,Loss: -0.324,Avg.Loss: 0.866,LR: 4.96E-04]Training epoch 2:  20%|██        | 69/341 [00:01<00:05, 49.48it/s, Epoch: 2, Batch: 70,Loss: 0.754,Avg.Loss: 0.865,LR: 4.96E-04] Training epoch 2:  21%|██        | 70/341 [00:01<00:05, 49.48it/s, Epoch: 2, Batch: 71,Loss: 0.138,Avg.Loss: 0.854,LR: 4.96E-04]Training epoch 2:  21%|██        | 71/341 [00:01<00:05, 50.24it/s, Epoch: 2, Batch: 71,Loss: 0.138,Avg.Loss: 0.854,LR: 4.96E-04]Training epoch 2:  21%|██        | 71/341 [00:01<00:05, 50.24it/s, Epoch: 2, Batch: 72,Loss: 0.545,Avg.Loss: 0.850,LR: 4.95E-04]Training epoch 2:  21%|██        | 72/341 [00:01<00:05, 50.24it/s, Epoch: 2, Batch: 73,Loss: 1.230,Avg.Loss: 0.855,LR: 4.95E-04]Training epoch 2:  21%|██▏       | 73/341 [00:01<00:05, 50.24it/s, Epoch: 2, Batch: 74,Loss: 0.856,Avg.Loss: 0.855,LR: 4.95E-04]Training epoch 2:  22%|██▏       | 74/341 [00:01<00:05, 50.24it/s, Epoch: 2, Batch: 75,Loss: 1.038,Avg.Loss: 0.858,LR: 4.95E-04]Training epoch 2:  22%|██▏       | 75/341 [00:01<00:05, 50.24it/s, Epoch: 2, Batch: 76,Loss: 1.026,Avg.Loss: 0.860,LR: 4.95E-04]Training epoch 2:  22%|██▏       | 76/341 [00:01<00:05, 50.24it/s, Epoch: 2, Batch: 77,Loss: 1.147,Avg.Loss: 0.864,LR: 4.95E-04]Training epoch 2:  23%|██▎       | 77/341 [00:01<00:05, 50.74it/s, Epoch: 2, Batch: 77,Loss: 1.147,Avg.Loss: 0.864,LR: 4.95E-04]Training epoch 2:  23%|██▎       | 77/341 [00:01<00:05, 50.74it/s, Epoch: 2, Batch: 78,Loss: 0.509,Avg.Loss: 0.859,LR: 4.95E-04]Training epoch 2:  23%|██▎       | 78/341 [00:01<00:05, 50.74it/s, Epoch: 2, Batch: 79,Loss: 1.414,Avg.Loss: 0.866,LR: 4.95E-04]Training epoch 2:  23%|██▎       | 79/341 [00:01<00:05, 50.74it/s, Epoch: 2, Batch: 80,Loss: 4.258,Avg.Loss: 0.909,LR: 4.95E-04]Training epoch 2:  23%|██▎       | 80/341 [00:01<00:05, 50.74it/s, Epoch: 2, Batch: 81,Loss: 1.866,Avg.Loss: 0.920,LR: 4.95E-04]Training epoch 2:  24%|██▍       | 81/341 [00:01<00:05, 50.74it/s, Epoch: 2, Batch: 82,Loss: 1.029,Avg.Loss: 0.922,LR: 4.95E-04]Training epoch 2:  24%|██▍       | 82/341 [00:01<00:05, 50.74it/s, Epoch: 2, Batch: 83,Loss: 2.385,Avg.Loss: 0.939,LR: 4.95E-04]Training epoch 2:  24%|██▍       | 83/341 [00:01<00:04, 52.83it/s, Epoch: 2, Batch: 83,Loss: 2.385,Avg.Loss: 0.939,LR: 4.95E-04]Training epoch 2:  24%|██▍       | 83/341 [00:01<00:04, 52.83it/s, Epoch: 2, Batch: 84,Loss: 4.095,Avg.Loss: 0.977,LR: 4.95E-04]Training epoch 2:  25%|██▍       | 84/341 [00:01<00:04, 52.83it/s, Epoch: 2, Batch: 85,Loss: 3.559,Avg.Loss: 1.007,LR: 4.95E-04]Training epoch 2:  25%|██▍       | 85/341 [00:01<00:04, 52.83it/s, Epoch: 2, Batch: 86,Loss: 0.943,Avg.Loss: 1.007,LR: 4.95E-04]Training epoch 2:  25%|██▌       | 86/341 [00:01<00:04, 52.83it/s, Epoch: 2, Batch: 87,Loss: 1.309,Avg.Loss: 1.010,LR: 4.95E-04]Training epoch 2:  26%|██▌       | 87/341 [00:01<00:04, 52.83it/s, Epoch: 2, Batch: 88,Loss: 2.214,Avg.Loss: 1.024,LR: 4.95E-04]Training epoch 2:  26%|██▌       | 88/341 [00:01<00:04, 52.83it/s, Epoch: 2, Batch: 89,Loss: 1.755,Avg.Loss: 1.032,LR: 4.95E-04]Training epoch 2:  26%|██▌       | 89/341 [00:01<00:04, 53.25it/s, Epoch: 2, Batch: 89,Loss: 1.755,Avg.Loss: 1.032,LR: 4.95E-04]Training epoch 2:  26%|██▌       | 89/341 [00:01<00:04, 53.25it/s, Epoch: 2, Batch: 90,Loss: 0.487,Avg.Loss: 1.026,LR: 4.95E-04]Training epoch 2:  26%|██▋       | 90/341 [00:01<00:04, 53.25it/s, Epoch: 2, Batch: 91,Loss: 0.774,Avg.Loss: 1.023,LR: 4.95E-04]Training epoch 2:  27%|██▋       | 91/341 [00:01<00:04, 53.25it/s, Epoch: 2, Batch: 92,Loss: 1.224,Avg.Loss: 1.025,LR: 4.95E-04]Training epoch 2:  27%|██▋       | 92/341 [00:01<00:04, 53.25it/s, Epoch: 2, Batch: 93,Loss: 1.075,Avg.Loss: 1.026,LR: 4.95E-04]Training epoch 2:  27%|██▋       | 93/341 [00:01<00:04, 53.25it/s, Epoch: 2, Batch: 94,Loss: 0.003,Avg.Loss: 1.015,LR: 4.95E-04]Training epoch 2:  28%|██▊       | 94/341 [00:01<00:04, 53.25it/s, Epoch: 2, Batch: 95,Loss: 1.737,Avg.Loss: 1.023,LR: 4.95E-04]Training epoch 2:  28%|██▊       | 95/341 [00:01<00:04, 53.07it/s, Epoch: 2, Batch: 95,Loss: 1.737,Avg.Loss: 1.023,LR: 4.95E-04]Training epoch 2:  28%|██▊       | 95/341 [00:01<00:04, 53.07it/s, Epoch: 2, Batch: 96,Loss: 2.406,Avg.Loss: 1.037,LR: 4.95E-04]Training epoch 2:  28%|██▊       | 96/341 [00:01<00:04, 53.07it/s, Epoch: 2, Batch: 97,Loss: 1.659,Avg.Loss: 1.043,LR: 4.95E-04]Training epoch 2:  28%|██▊       | 97/341 [00:01<00:04, 53.07it/s, Epoch: 2, Batch: 98,Loss: 0.664,Avg.Loss: 1.039,LR: 4.95E-04]Training epoch 2:  29%|██▊       | 98/341 [00:01<00:04, 53.07it/s, Epoch: 2, Batch: 99,Loss: 1.376,Avg.Loss: 1.043,LR: 4.95E-04]Training epoch 2:  29%|██▉       | 99/341 [00:01<00:04, 53.07it/s, Epoch: 2, Batch: 100,Loss: 2.144,Avg.Loss: 1.054,LR: 4.95E-04]Training epoch 2:  29%|██▉       | 100/341 [00:01<00:04, 53.07it/s, Epoch: 2, Batch: 101,Loss: 2.230,Avg.Loss: 1.066,LR: 4.95E-04]Training epoch 2:  30%|██▉       | 101/341 [00:01<00:04, 53.42it/s, Epoch: 2, Batch: 101,Loss: 2.230,Avg.Loss: 1.066,LR: 4.95E-04]Training epoch 2:  30%|██▉       | 101/341 [00:02<00:04, 53.42it/s, Epoch: 2, Batch: 102,Loss: 0.908,Avg.Loss: 1.064,LR: 4.95E-04]Training epoch 2:  30%|██▉       | 102/341 [00:02<00:04, 53.42it/s, Epoch: 2, Batch: 103,Loss: 0.216,Avg.Loss: 1.056,LR: 4.95E-04]Training epoch 2:  30%|███       | 103/341 [00:02<00:04, 53.42it/s, Epoch: 2, Batch: 104,Loss: 0.808,Avg.Loss: 1.053,LR: 4.95E-04]Training epoch 2:  30%|███       | 104/341 [00:02<00:04, 53.42it/s, Epoch: 2, Batch: 105,Loss: 0.465,Avg.Loss: 1.048,LR: 4.95E-04]Training epoch 2:  31%|███       | 105/341 [00:02<00:04, 53.42it/s, Epoch: 2, Batch: 106,Loss: 0.316,Avg.Loss: 1.041,LR: 4.95E-04]Training epoch 2:  31%|███       | 106/341 [00:02<00:04, 53.42it/s, Epoch: 2, Batch: 107,Loss: 1.012,Avg.Loss: 1.041,LR: 4.95E-04]Training epoch 2:  31%|███▏      | 107/341 [00:02<00:04, 53.91it/s, Epoch: 2, Batch: 107,Loss: 1.012,Avg.Loss: 1.041,LR: 4.95E-04]Training epoch 2:  31%|███▏      | 107/341 [00:02<00:04, 53.91it/s, Epoch: 2, Batch: 108,Loss: 1.141,Avg.Loss: 1.042,LR: 4.95E-04]Training epoch 2:  32%|███▏      | 108/341 [00:02<00:04, 53.91it/s, Epoch: 2, Batch: 109,Loss: 1.195,Avg.Loss: 1.043,LR: 4.95E-04]Training epoch 2:  32%|███▏      | 109/341 [00:02<00:04, 53.91it/s, Epoch: 2, Batch: 110,Loss: 0.562,Avg.Loss: 1.039,LR: 4.95E-04]Training epoch 2:  32%|███▏      | 110/341 [00:02<00:04, 53.91it/s, Epoch: 2, Batch: 111,Loss: 1.059,Avg.Loss: 1.039,LR: 4.95E-04]Training epoch 2:  33%|███▎      | 111/341 [00:02<00:04, 53.91it/s, Epoch: 2, Batch: 112,Loss: 1.531,Avg.Loss: 1.043,LR: 4.95E-04]Training epoch 2:  33%|███▎      | 112/341 [00:02<00:04, 53.91it/s, Epoch: 2, Batch: 113,Loss: 0.508,Avg.Loss: 1.038,LR: 4.95E-04]Training epoch 2:  33%|███▎      | 113/341 [00:02<00:04, 53.45it/s, Epoch: 2, Batch: 113,Loss: 0.508,Avg.Loss: 1.038,LR: 4.95E-04]Training epoch 2:  33%|███▎      | 113/341 [00:02<00:04, 53.45it/s, Epoch: 2, Batch: 114,Loss: 0.226,Avg.Loss: 1.031,LR: 4.95E-04]Training epoch 2:  33%|███▎      | 114/341 [00:02<00:04, 53.45it/s, Epoch: 2, Batch: 115,Loss: 0.604,Avg.Loss: 1.028,LR: 4.95E-04]Training epoch 2:  34%|███▎      | 115/341 [00:02<00:04, 53.45it/s, Epoch: 2, Batch: 116,Loss: 0.193,Avg.Loss: 1.020,LR: 4.94E-04]Training epoch 2:  34%|███▍      | 116/341 [00:02<00:04, 53.45it/s, Epoch: 2, Batch: 117,Loss: 0.299,Avg.Loss: 1.014,LR: 4.94E-04]Training epoch 2:  34%|███▍      | 117/341 [00:02<00:04, 53.45it/s, Epoch: 2, Batch: 118,Loss: 0.119,Avg.Loss: 1.007,LR: 4.94E-04]Training epoch 2:  35%|███▍      | 118/341 [00:02<00:04, 53.45it/s, Epoch: 2, Batch: 119,Loss: 0.352,Avg.Loss: 1.001,LR: 4.94E-04]Training epoch 2:  35%|███▍      | 119/341 [00:02<00:04, 53.93it/s, Epoch: 2, Batch: 119,Loss: 0.352,Avg.Loss: 1.001,LR: 4.94E-04]Training epoch 2:  35%|███▍      | 119/341 [00:02<00:04, 53.93it/s, Epoch: 2, Batch: 120,Loss: 0.288,Avg.Loss: 0.995,LR: 4.94E-04]Training epoch 2:  35%|███▌      | 120/341 [00:02<00:04, 53.93it/s, Epoch: 2, Batch: 121,Loss: 1.172,Avg.Loss: 0.997,LR: 4.94E-04]Training epoch 2:  35%|███▌      | 121/341 [00:02<00:04, 53.93it/s, Epoch: 2, Batch: 122,Loss: 0.647,Avg.Loss: 0.994,LR: 4.94E-04]Training epoch 2:  36%|███▌      | 122/341 [00:02<00:04, 53.93it/s, Epoch: 2, Batch: 123,Loss: -0.006,Avg.Loss: 0.986,LR: 4.94E-04]Training epoch 2:  36%|███▌      | 123/341 [00:02<00:04, 53.93it/s, Epoch: 2, Batch: 124,Loss: 0.565,Avg.Loss: 0.982,LR: 4.94E-04] Training epoch 2:  36%|███▋      | 124/341 [00:02<00:04, 53.93it/s, Epoch: 2, Batch: 125,Loss: 0.720,Avg.Loss: 0.980,LR: 4.94E-04]Training epoch 2:  37%|███▋      | 125/341 [00:02<00:03, 54.33it/s, Epoch: 2, Batch: 125,Loss: 0.720,Avg.Loss: 0.980,LR: 4.94E-04]Training epoch 2:  37%|███▋      | 125/341 [00:02<00:03, 54.33it/s, Epoch: 2, Batch: 126,Loss: 0.438,Avg.Loss: 0.976,LR: 4.94E-04]Training epoch 2:  37%|███▋      | 126/341 [00:02<00:03, 54.33it/s, Epoch: 2, Batch: 127,Loss: -0.034,Avg.Loss: 0.968,LR: 4.94E-04]Training epoch 2:  37%|███▋      | 127/341 [00:02<00:03, 54.33it/s, Epoch: 2, Batch: 128,Loss: 0.107,Avg.Loss: 0.961,LR: 4.94E-04] Training epoch 2:  38%|███▊      | 128/341 [00:02<00:03, 54.33it/s, Epoch: 2, Batch: 129,Loss: 0.157,Avg.Loss: 0.955,LR: 4.94E-04]Training epoch 2:  38%|███▊      | 129/341 [00:02<00:03, 54.33it/s, Epoch: 2, Batch: 130,Loss: -0.023,Avg.Loss: 0.947,LR: 4.94E-04]Training epoch 2:  38%|███▊      | 130/341 [00:02<00:03, 54.33it/s, Epoch: 2, Batch: 131,Loss: 0.763,Avg.Loss: 0.946,LR: 4.94E-04] Training epoch 2:  38%|███▊      | 131/341 [00:02<00:03, 54.56it/s, Epoch: 2, Batch: 131,Loss: 0.763,Avg.Loss: 0.946,LR: 4.94E-04]Training epoch 2:  38%|███▊      | 131/341 [00:02<00:03, 54.56it/s, Epoch: 2, Batch: 132,Loss: 0.674,Avg.Loss: 0.944,LR: 4.94E-04]Training epoch 2:  39%|███▊      | 132/341 [00:02<00:03, 54.56it/s, Epoch: 2, Batch: 133,Loss: 0.507,Avg.Loss: 0.941,LR: 4.94E-04]Training epoch 2:  39%|███▉      | 133/341 [00:02<00:03, 54.56it/s, Epoch: 2, Batch: 134,Loss: 0.731,Avg.Loss: 0.939,LR: 4.94E-04]Training epoch 2:  39%|███▉      | 134/341 [00:02<00:03, 54.56it/s, Epoch: 2, Batch: 135,Loss: 0.815,Avg.Loss: 0.938,LR: 4.94E-04]Training epoch 2:  40%|███▉      | 135/341 [00:02<00:03, 54.56it/s, Epoch: 2, Batch: 136,Loss: 0.354,Avg.Loss: 0.934,LR: 4.94E-04]Training epoch 2:  40%|███▉      | 136/341 [00:02<00:03, 54.56it/s, Epoch: 2, Batch: 137,Loss: 0.761,Avg.Loss: 0.933,LR: 4.94E-04]Training epoch 2:  40%|████      | 137/341 [00:02<00:03, 54.38it/s, Epoch: 2, Batch: 137,Loss: 0.761,Avg.Loss: 0.933,LR: 4.94E-04]Training epoch 2:  40%|████      | 137/341 [00:02<00:03, 54.38it/s, Epoch: 2, Batch: 138,Loss: 1.308,Avg.Loss: 0.935,LR: 4.94E-04]Training epoch 2:  40%|████      | 138/341 [00:02<00:03, 54.38it/s, Epoch: 2, Batch: 139,Loss: 0.990,Avg.Loss: 0.936,LR: 4.94E-04]Training epoch 2:  41%|████      | 139/341 [00:02<00:03, 54.38it/s, Epoch: 2, Batch: 140,Loss: 0.462,Avg.Loss: 0.932,LR: 4.94E-04]Training epoch 2:  41%|████      | 140/341 [00:02<00:03, 54.38it/s, Epoch: 2, Batch: 141,Loss: 1.797,Avg.Loss: 0.938,LR: 4.94E-04]Training epoch 2:  41%|████▏     | 141/341 [00:02<00:03, 54.38it/s, Epoch: 2, Batch: 142,Loss: 3.480,Avg.Loss: 0.956,LR: 4.94E-04]Training epoch 2:  42%|████▏     | 142/341 [00:02<00:03, 54.38it/s, Epoch: 2, Batch: 143,Loss: 3.407,Avg.Loss: 0.974,LR: 4.94E-04]Training epoch 2:  42%|████▏     | 143/341 [00:02<00:03, 54.46it/s, Epoch: 2, Batch: 143,Loss: 3.407,Avg.Loss: 0.974,LR: 4.94E-04]Training epoch 2:  42%|████▏     | 143/341 [00:02<00:03, 54.46it/s, Epoch: 2, Batch: 144,Loss: 0.922,Avg.Loss: 0.973,LR: 4.94E-04]Training epoch 2:  42%|████▏     | 144/341 [00:02<00:03, 54.46it/s, Epoch: 2, Batch: 145,Loss: 0.190,Avg.Loss: 0.968,LR: 4.94E-04]Training epoch 2:  43%|████▎     | 145/341 [00:02<00:03, 54.46it/s, Epoch: 2, Batch: 146,Loss: 1.827,Avg.Loss: 0.974,LR: 4.94E-04]Training epoch 2:  43%|████▎     | 146/341 [00:02<00:03, 54.46it/s, Epoch: 2, Batch: 147,Loss: 2.668,Avg.Loss: 0.985,LR: 4.94E-04]Training epoch 2:  43%|████▎     | 147/341 [00:02<00:03, 54.46it/s, Epoch: 2, Batch: 148,Loss: 4.245,Avg.Loss: 1.007,LR: 4.94E-04]Training epoch 2:  43%|████▎     | 148/341 [00:02<00:03, 54.46it/s, Epoch: 2, Batch: 149,Loss: 2.473,Avg.Loss: 1.017,LR: 4.94E-04]Training epoch 2:  44%|████▎     | 149/341 [00:02<00:03, 54.74it/s, Epoch: 2, Batch: 149,Loss: 2.473,Avg.Loss: 1.017,LR: 4.94E-04]Training epoch 2:  44%|████▎     | 149/341 [00:02<00:03, 54.74it/s, Epoch: 2, Batch: 150,Loss: 0.536,Avg.Loss: 1.014,LR: 4.94E-04]Training epoch 2:  44%|████▍     | 150/341 [00:02<00:03, 54.74it/s, Epoch: 2, Batch: 151,Loss: 0.518,Avg.Loss: 1.011,LR: 4.94E-04]Training epoch 2:  44%|████▍     | 151/341 [00:02<00:03, 54.74it/s, Epoch: 2, Batch: 152,Loss: 1.129,Avg.Loss: 1.011,LR: 4.94E-04]Training epoch 2:  45%|████▍     | 152/341 [00:02<00:03, 54.74it/s, Epoch: 2, Batch: 153,Loss: 0.982,Avg.Loss: 1.011,LR: 4.94E-04]Training epoch 2:  45%|████▍     | 153/341 [00:02<00:03, 54.74it/s, Epoch: 2, Batch: 154,Loss: 0.352,Avg.Loss: 1.007,LR: 4.94E-04]Training epoch 2:  45%|████▌     | 154/341 [00:02<00:03, 54.74it/s, Epoch: 2, Batch: 155,Loss: 0.439,Avg.Loss: 1.003,LR: 4.94E-04]Training epoch 2:  45%|████▌     | 155/341 [00:02<00:03, 54.40it/s, Epoch: 2, Batch: 155,Loss: 0.439,Avg.Loss: 1.003,LR: 4.94E-04]Training epoch 2:  45%|████▌     | 155/341 [00:02<00:03, 54.40it/s, Epoch: 2, Batch: 156,Loss: 0.816,Avg.Loss: 1.002,LR: 4.93E-04]Training epoch 2:  46%|████▌     | 156/341 [00:03<00:03, 54.40it/s, Epoch: 2, Batch: 157,Loss: 0.519,Avg.Loss: 0.999,LR: 4.93E-04]Training epoch 2:  46%|████▌     | 157/341 [00:03<00:03, 54.40it/s, Epoch: 2, Batch: 158,Loss: 0.236,Avg.Loss: 0.994,LR: 4.93E-04]Training epoch 2:  46%|████▋     | 158/341 [00:03<00:03, 54.40it/s, Epoch: 2, Batch: 159,Loss: 0.147,Avg.Loss: 0.989,LR: 4.93E-04]Training epoch 2:  47%|████▋     | 159/341 [00:03<00:03, 54.40it/s, Epoch: 2, Batch: 160,Loss: 0.014,Avg.Loss: 0.983,LR: 4.93E-04]Training epoch 2:  47%|████▋     | 160/341 [00:03<00:03, 54.40it/s, Epoch: 2, Batch: 161,Loss: -0.017,Avg.Loss: 0.976,LR: 4.93E-04]Training epoch 2:  47%|████▋     | 161/341 [00:03<00:03, 54.14it/s, Epoch: 2, Batch: 161,Loss: -0.017,Avg.Loss: 0.976,LR: 4.93E-04]Training epoch 2:  47%|████▋     | 161/341 [00:03<00:03, 54.14it/s, Epoch: 2, Batch: 162,Loss: 0.098,Avg.Loss: 0.971,LR: 4.93E-04] Training epoch 2:  48%|████▊     | 162/341 [00:03<00:03, 54.14it/s, Epoch: 2, Batch: 163,Loss: 0.212,Avg.Loss: 0.966,LR: 4.93E-04]Training epoch 2:  48%|████▊     | 163/341 [00:03<00:03, 54.14it/s, Epoch: 2, Batch: 164,Loss: -0.219,Avg.Loss: 0.959,LR: 4.93E-04]Training epoch 2:  48%|████▊     | 164/341 [00:03<00:03, 54.14it/s, Epoch: 2, Batch: 165,Loss: 0.057,Avg.Loss: 0.954,LR: 4.93E-04] Training epoch 2:  48%|████▊     | 165/341 [00:03<00:03, 54.14it/s, Epoch: 2, Batch: 166,Loss: 0.517,Avg.Loss: 0.951,LR: 4.93E-04]Training epoch 2:  49%|████▊     | 166/341 [00:03<00:03, 54.14it/s, Epoch: 2, Batch: 167,Loss: 0.128,Avg.Loss: 0.946,LR: 4.93E-04]Training epoch 2:  49%|████▉     | 167/341 [00:03<00:03, 53.93it/s, Epoch: 2, Batch: 167,Loss: 0.128,Avg.Loss: 0.946,LR: 4.93E-04]Training epoch 2:  49%|████▉     | 167/341 [00:03<00:03, 53.93it/s, Epoch: 2, Batch: 168,Loss: 0.040,Avg.Loss: 0.941,LR: 4.93E-04]Training epoch 2:  49%|████▉     | 168/341 [00:03<00:03, 53.93it/s, Epoch: 2, Batch: 169,Loss: -0.098,Avg.Loss: 0.935,LR: 4.93E-04]Training epoch 2:  50%|████▉     | 169/341 [00:03<00:03, 53.93it/s, Epoch: 2, Batch: 170,Loss: -0.013,Avg.Loss: 0.929,LR: 4.93E-04]Training epoch 2:  50%|████▉     | 170/341 [00:03<00:03, 53.93it/s, Epoch: 2, Batch: 171,Loss: -0.142,Avg.Loss: 0.923,LR: 4.93E-04]Training epoch 2:  50%|█████     | 171/341 [00:03<00:03, 53.93it/s, Epoch: 2, Batch: 172,Loss: -0.165,Avg.Loss: 0.916,LR: 4.93E-04]Training epoch 2:  50%|█████     | 172/341 [00:03<00:03, 53.93it/s, Epoch: 2, Batch: 173,Loss: -0.114,Avg.Loss: 0.910,LR: 4.93E-04]Training epoch 2:  51%|█████     | 173/341 [00:03<00:03, 53.75it/s, Epoch: 2, Batch: 173,Loss: -0.114,Avg.Loss: 0.910,LR: 4.93E-04]Training epoch 2:  51%|█████     | 173/341 [00:03<00:03, 53.75it/s, Epoch: 2, Batch: 174,Loss: 0.655,Avg.Loss: 0.909,LR: 4.93E-04] Training epoch 2:  51%|█████     | 174/341 [00:03<00:03, 53.75it/s, Epoch: 2, Batch: 175,Loss: 1.543,Avg.Loss: 0.913,LR: 4.93E-04]Training epoch 2:  51%|█████▏    | 175/341 [00:03<00:03, 53.75it/s, Epoch: 2, Batch: 176,Loss: 1.635,Avg.Loss: 0.917,LR: 4.93E-04]Training epoch 2:  52%|█████▏    | 176/341 [00:03<00:03, 53.75it/s, Epoch: 2, Batch: 177,Loss: 0.587,Avg.Loss: 0.915,LR: 4.93E-04]Training epoch 2:  52%|█████▏    | 177/341 [00:03<00:03, 53.75it/s, Epoch: 2, Batch: 178,Loss: -0.010,Avg.Loss: 0.910,LR: 4.93E-04]Training epoch 2:  52%|█████▏    | 178/341 [00:03<00:03, 53.75it/s, Epoch: 2, Batch: 179,Loss: 0.846,Avg.Loss: 0.909,LR: 4.93E-04] Training epoch 2:  52%|█████▏    | 179/341 [00:03<00:02, 54.30it/s, Epoch: 2, Batch: 179,Loss: 0.846,Avg.Loss: 0.909,LR: 4.93E-04]Training epoch 2:  52%|█████▏    | 179/341 [00:03<00:02, 54.30it/s, Epoch: 2, Batch: 180,Loss: 0.206,Avg.Loss: 0.905,LR: 4.93E-04]Training epoch 2:  53%|█████▎    | 180/341 [00:03<00:02, 54.30it/s, Epoch: 2, Batch: 181,Loss: 1.422,Avg.Loss: 0.908,LR: 4.93E-04]Training epoch 2:  53%|█████▎    | 181/341 [00:03<00:02, 54.30it/s, Epoch: 2, Batch: 182,Loss: 1.127,Avg.Loss: 0.909,LR: 4.93E-04]Training epoch 2:  53%|█████▎    | 182/341 [00:03<00:02, 54.30it/s, Epoch: 2, Batch: 183,Loss: -0.123,Avg.Loss: 0.904,LR: 4.93E-04]Training epoch 2:  54%|█████▎    | 183/341 [00:03<00:02, 54.30it/s, Epoch: 2, Batch: 184,Loss: 0.641,Avg.Loss: 0.902,LR: 4.93E-04] Training epoch 2:  54%|█████▍    | 184/341 [00:03<00:02, 54.30it/s, Epoch: 2, Batch: 185,Loss: 0.815,Avg.Loss: 0.902,LR: 4.93E-04]Training epoch 2:  54%|█████▍    | 185/341 [00:03<00:02, 54.50it/s, Epoch: 2, Batch: 185,Loss: 0.815,Avg.Loss: 0.902,LR: 4.93E-04]Training epoch 2:  54%|█████▍    | 185/341 [00:03<00:02, 54.50it/s, Epoch: 2, Batch: 186,Loss: 0.422,Avg.Loss: 0.899,LR: 4.93E-04]Training epoch 2:  55%|█████▍    | 186/341 [00:03<00:02, 54.50it/s, Epoch: 2, Batch: 187,Loss: 0.065,Avg.Loss: 0.895,LR: 4.93E-04]Training epoch 2:  55%|█████▍    | 187/341 [00:03<00:02, 54.50it/s, Epoch: 2, Batch: 188,Loss: 0.603,Avg.Loss: 0.893,LR: 4.93E-04]Training epoch 2:  55%|█████▌    | 188/341 [00:03<00:02, 54.50it/s, Epoch: 2, Batch: 189,Loss: -0.363,Avg.Loss: 0.887,LR: 4.93E-04]Training epoch 2:  55%|█████▌    | 189/341 [00:03<00:02, 54.50it/s, Epoch: 2, Batch: 190,Loss: 0.387,Avg.Loss: 0.884,LR: 4.93E-04] Training epoch 2:  56%|█████▌    | 190/341 [00:03<00:02, 54.50it/s, Epoch: 2, Batch: 191,Loss: 0.899,Avg.Loss: 0.884,LR: 4.93E-04]Training epoch 2:  56%|█████▌    | 191/341 [00:03<00:02, 54.18it/s, Epoch: 2, Batch: 191,Loss: 0.899,Avg.Loss: 0.884,LR: 4.93E-04]Training epoch 2:  56%|█████▌    | 191/341 [00:03<00:02, 54.18it/s, Epoch: 2, Batch: 192,Loss: 0.022,Avg.Loss: 0.880,LR: 4.93E-04]Training epoch 2:  56%|█████▋    | 192/341 [00:03<00:02, 54.18it/s, Epoch: 2, Batch: 193,Loss: 0.380,Avg.Loss: 0.877,LR: 4.92E-04]Training epoch 2:  57%|█████▋    | 193/341 [00:03<00:02, 54.18it/s, Epoch: 2, Batch: 194,Loss: 0.886,Avg.Loss: 0.877,LR: 4.92E-04]Training epoch 2:  57%|█████▋    | 194/341 [00:03<00:02, 54.18it/s, Epoch: 2, Batch: 195,Loss: -0.041,Avg.Loss: 0.872,LR: 4.92E-04]Training epoch 2:  57%|█████▋    | 195/341 [00:03<00:02, 54.18it/s, Epoch: 2, Batch: 196,Loss: -0.041,Avg.Loss: 0.868,LR: 4.92E-04]Training epoch 2:  57%|█████▋    | 196/341 [00:03<00:02, 54.18it/s, Epoch: 2, Batch: 197,Loss: 0.998,Avg.Loss: 0.868,LR: 4.92E-04] Training epoch 2:  58%|█████▊    | 197/341 [00:03<00:02, 54.01it/s, Epoch: 2, Batch: 197,Loss: 0.998,Avg.Loss: 0.868,LR: 4.92E-04]Training epoch 2:  58%|█████▊    | 197/341 [00:03<00:02, 54.01it/s, Epoch: 2, Batch: 198,Loss: 0.238,Avg.Loss: 0.865,LR: 4.92E-04]Training epoch 2:  58%|█████▊    | 198/341 [00:03<00:02, 54.01it/s, Epoch: 2, Batch: 199,Loss: -0.053,Avg.Loss: 0.861,LR: 4.92E-04]Training epoch 2:  58%|█████▊    | 199/341 [00:03<00:02, 54.01it/s, Epoch: 2, Batch: 200,Loss: 0.142,Avg.Loss: 0.857,LR: 4.92E-04] Training epoch 2:  59%|█████▊    | 200/341 [00:03<00:02, 54.01it/s, Epoch: 2, Batch: 201,Loss: -0.377,Avg.Loss: 0.851,LR: 4.92E-04]Training epoch 2:  59%|█████▉    | 201/341 [00:03<00:02, 54.01it/s, Epoch: 2, Batch: 202,Loss: 0.258,Avg.Loss: 0.848,LR: 4.92E-04] Training epoch 2:  59%|█████▉    | 202/341 [00:03<00:02, 54.01it/s, Epoch: 2, Batch: 203,Loss: 0.699,Avg.Loss: 0.847,LR: 4.92E-04]Training epoch 2:  60%|█████▉    | 203/341 [00:03<00:02, 54.05it/s, Epoch: 2, Batch: 203,Loss: 0.699,Avg.Loss: 0.847,LR: 4.92E-04]Training epoch 2:  60%|█████▉    | 203/341 [00:03<00:02, 54.05it/s, Epoch: 2, Batch: 204,Loss: 0.255,Avg.Loss: 0.844,LR: 4.92E-04]Training epoch 2:  60%|█████▉    | 204/341 [00:03<00:02, 54.05it/s, Epoch: 2, Batch: 205,Loss: -0.261,Avg.Loss: 0.839,LR: 4.92E-04]Training epoch 2:  60%|██████    | 205/341 [00:03<00:02, 54.05it/s, Epoch: 2, Batch: 206,Loss: 0.597,Avg.Loss: 0.838,LR: 4.92E-04] Training epoch 2:  60%|██████    | 206/341 [00:03<00:02, 54.05it/s, Epoch: 2, Batch: 207,Loss: -0.320,Avg.Loss: 0.832,LR: 4.92E-04]Training epoch 2:  61%|██████    | 207/341 [00:03<00:02, 54.05it/s, Epoch: 2, Batch: 208,Loss: 0.482,Avg.Loss: 0.830,LR: 4.92E-04] Training epoch 2:  61%|██████    | 208/341 [00:03<00:02, 54.05it/s, Epoch: 2, Batch: 209,Loss: 0.825,Avg.Loss: 0.830,LR: 4.92E-04]Training epoch 2:  61%|██████▏   | 209/341 [00:03<00:02, 54.26it/s, Epoch: 2, Batch: 209,Loss: 0.825,Avg.Loss: 0.830,LR: 4.92E-04]Training epoch 2:  61%|██████▏   | 209/341 [00:03<00:02, 54.26it/s, Epoch: 2, Batch: 210,Loss: 0.251,Avg.Loss: 0.828,LR: 4.92E-04]Training epoch 2:  62%|██████▏   | 210/341 [00:04<00:02, 54.26it/s, Epoch: 2, Batch: 211,Loss: -0.255,Avg.Loss: 0.823,LR: 4.92E-04]Training epoch 2:  62%|██████▏   | 211/341 [00:04<00:02, 54.26it/s, Epoch: 2, Batch: 212,Loss: 0.119,Avg.Loss: 0.819,LR: 4.92E-04] Training epoch 2:  62%|██████▏   | 212/341 [00:04<00:02, 54.26it/s, Epoch: 2, Batch: 213,Loss: -0.216,Avg.Loss: 0.814,LR: 4.92E-04]Training epoch 2:  62%|██████▏   | 213/341 [00:04<00:02, 54.26it/s, Epoch: 2, Batch: 214,Loss: 0.286,Avg.Loss: 0.812,LR: 4.92E-04] Training epoch 2:  63%|██████▎   | 214/341 [00:04<00:02, 54.26it/s, Epoch: 2, Batch: 215,Loss: 0.968,Avg.Loss: 0.813,LR: 4.92E-04]Training epoch 2:  63%|██████▎   | 215/341 [00:04<00:02, 54.29it/s, Epoch: 2, Batch: 215,Loss: 0.968,Avg.Loss: 0.813,LR: 4.92E-04]Training epoch 2:  63%|██████▎   | 215/341 [00:04<00:02, 54.29it/s, Epoch: 2, Batch: 216,Loss: -0.041,Avg.Loss: 0.809,LR: 4.92E-04]Training epoch 2:  63%|██████▎   | 216/341 [00:04<00:02, 54.29it/s, Epoch: 2, Batch: 217,Loss: -0.202,Avg.Loss: 0.804,LR: 4.92E-04]Training epoch 2:  64%|██████▎   | 217/341 [00:04<00:02, 54.29it/s, Epoch: 2, Batch: 218,Loss: 0.231,Avg.Loss: 0.801,LR: 4.92E-04] Training epoch 2:  64%|██████▍   | 218/341 [00:04<00:02, 54.29it/s, Epoch: 2, Batch: 219,Loss: -0.440,Avg.Loss: 0.796,LR: 4.92E-04]Training epoch 2:  64%|██████▍   | 219/341 [00:04<00:02, 54.29it/s, Epoch: 2, Batch: 220,Loss: 0.490,Avg.Loss: 0.794,LR: 4.92E-04] Training epoch 2:  65%|██████▍   | 220/341 [00:04<00:02, 54.29it/s, Epoch: 2, Batch: 221,Loss: 0.854,Avg.Loss: 0.795,LR: 4.92E-04]Training epoch 2:  65%|██████▍   | 221/341 [00:04<00:02, 54.69it/s, Epoch: 2, Batch: 221,Loss: 0.854,Avg.Loss: 0.795,LR: 4.92E-04]Training epoch 2:  65%|██████▍   | 221/341 [00:04<00:02, 54.69it/s, Epoch: 2, Batch: 222,Loss: -0.107,Avg.Loss: 0.791,LR: 4.92E-04]Training epoch 2:  65%|██████▌   | 222/341 [00:04<00:02, 54.69it/s, Epoch: 2, Batch: 223,Loss: 0.076,Avg.Loss: 0.787,LR: 4.92E-04] Training epoch 2:  65%|██████▌   | 223/341 [00:04<00:02, 54.69it/s, Epoch: 2, Batch: 224,Loss: 0.023,Avg.Loss: 0.784,LR: 4.92E-04]Training epoch 2:  66%|██████▌   | 224/341 [00:04<00:02, 54.69it/s, Epoch: 2, Batch: 225,Loss: -0.662,Avg.Loss: 0.777,LR: 4.92E-04]Training epoch 2:  66%|██████▌   | 225/341 [00:04<00:02, 54.69it/s, Epoch: 2, Batch: 226,Loss: 0.193,Avg.Loss: 0.775,LR: 4.92E-04] Training epoch 2:  66%|██████▋   | 226/341 [00:04<00:02, 54.69it/s, Epoch: 2, Batch: 227,Loss: 1.056,Avg.Loss: 0.776,LR: 4.91E-04]Training epoch 2:  67%|██████▋   | 227/341 [00:04<00:02, 54.63it/s, Epoch: 2, Batch: 227,Loss: 1.056,Avg.Loss: 0.776,LR: 4.91E-04]Training epoch 2:  67%|██████▋   | 227/341 [00:04<00:02, 54.63it/s, Epoch: 2, Batch: 228,Loss: 0.177,Avg.Loss: 0.773,LR: 4.91E-04]Training epoch 2:  67%|██████▋   | 228/341 [00:04<00:02, 54.63it/s, Epoch: 2, Batch: 229,Loss: -0.245,Avg.Loss: 0.769,LR: 4.91E-04]Training epoch 2:  67%|██████▋   | 229/341 [00:04<00:02, 54.63it/s, Epoch: 2, Batch: 230,Loss: 0.134,Avg.Loss: 0.766,LR: 4.91E-04] Training epoch 2:  67%|██████▋   | 230/341 [00:04<00:02, 54.63it/s, Epoch: 2, Batch: 231,Loss: -0.392,Avg.Loss: 0.761,LR: 4.91E-04]Training epoch 2:  68%|██████▊   | 231/341 [00:04<00:02, 54.63it/s, Epoch: 2, Batch: 232,Loss: 0.279,Avg.Loss: 0.759,LR: 4.91E-04] Training epoch 2:  68%|██████▊   | 232/341 [00:04<00:01, 54.63it/s, Epoch: 2, Batch: 233,Loss: 0.588,Avg.Loss: 0.758,LR: 4.91E-04]Training epoch 2:  68%|██████▊   | 233/341 [00:04<00:01, 54.87it/s, Epoch: 2, Batch: 233,Loss: 0.588,Avg.Loss: 0.758,LR: 4.91E-04]Training epoch 2:  68%|██████▊   | 233/341 [00:04<00:01, 54.87it/s, Epoch: 2, Batch: 234,Loss: -0.056,Avg.Loss: 0.755,LR: 4.91E-04]Training epoch 2:  69%|██████▊   | 234/341 [00:04<00:01, 54.87it/s, Epoch: 2, Batch: 235,Loss: -0.369,Avg.Loss: 0.750,LR: 4.91E-04]Training epoch 2:  69%|██████▉   | 235/341 [00:04<00:01, 54.87it/s, Epoch: 2, Batch: 236,Loss: 0.569,Avg.Loss: 0.749,LR: 4.91E-04] Training epoch 2:  69%|██████▉   | 236/341 [00:04<00:01, 54.87it/s, Epoch: 2, Batch: 237,Loss: 0.205,Avg.Loss: 0.747,LR: 4.91E-04]Training epoch 2:  70%|██████▉   | 237/341 [00:04<00:01, 54.87it/s, Epoch: 2, Batch: 238,Loss: 0.115,Avg.Loss: 0.744,LR: 4.91E-04]Training epoch 2:  70%|██████▉   | 238/341 [00:04<00:01, 54.87it/s, Epoch: 2, Batch: 239,Loss: 0.760,Avg.Loss: 0.745,LR: 4.91E-04]Training epoch 2:  70%|███████   | 239/341 [00:04<00:01, 54.66it/s, Epoch: 2, Batch: 239,Loss: 0.760,Avg.Loss: 0.745,LR: 4.91E-04]Training epoch 2:  70%|███████   | 239/341 [00:04<00:01, 54.66it/s, Epoch: 2, Batch: 240,Loss: -0.138,Avg.Loss: 0.741,LR: 4.91E-04]Training epoch 2:  70%|███████   | 240/341 [00:04<00:01, 54.66it/s, Epoch: 2, Batch: 241,Loss: -0.027,Avg.Loss: 0.738,LR: 4.91E-04]Training epoch 2:  71%|███████   | 241/341 [00:04<00:01, 54.66it/s, Epoch: 2, Batch: 242,Loss: 0.777,Avg.Loss: 0.738,LR: 4.91E-04] Training epoch 2:  71%|███████   | 242/341 [00:04<00:01, 54.66it/s, Epoch: 2, Batch: 243,Loss: -0.416,Avg.Loss: 0.733,LR: 4.91E-04]Training epoch 2:  71%|███████▏  | 243/341 [00:04<00:01, 54.66it/s, Epoch: 2, Batch: 244,Loss: -0.024,Avg.Loss: 0.730,LR: 4.91E-04]Training epoch 2:  72%|███████▏  | 244/341 [00:04<00:01, 54.66it/s, Epoch: 2, Batch: 245,Loss: 0.357,Avg.Loss: 0.728,LR: 4.91E-04] Training epoch 2:  72%|███████▏  | 245/341 [00:04<00:01, 53.93it/s, Epoch: 2, Batch: 245,Loss: 0.357,Avg.Loss: 0.728,LR: 4.91E-04]Training epoch 2:  72%|███████▏  | 245/341 [00:04<00:01, 53.93it/s, Epoch: 2, Batch: 246,Loss: -0.449,Avg.Loss: 0.724,LR: 4.91E-04]Training epoch 2:  72%|███████▏  | 246/341 [00:04<00:01, 53.93it/s, Epoch: 2, Batch: 247,Loss: 0.244,Avg.Loss: 0.722,LR: 4.91E-04] Training epoch 2:  72%|███████▏  | 247/341 [00:04<00:01, 53.93it/s, Epoch: 2, Batch: 248,Loss: 0.852,Avg.Loss: 0.722,LR: 4.91E-04]Training epoch 2:  73%|███████▎  | 248/341 [00:04<00:01, 53.93it/s, Epoch: 2, Batch: 249,Loss: -0.022,Avg.Loss: 0.719,LR: 4.91E-04]Training epoch 2:  73%|███████▎  | 249/341 [00:04<00:01, 53.93it/s, Epoch: 2, Batch: 250,Loss: 0.023,Avg.Loss: 0.716,LR: 4.91E-04] Training epoch 2:  73%|███████▎  | 250/341 [00:04<00:01, 53.93it/s, Epoch: 2, Batch: 251,Loss: -0.117,Avg.Loss: 0.713,LR: 4.91E-04]Training epoch 2:  74%|███████▎  | 251/341 [00:04<00:01, 54.43it/s, Epoch: 2, Batch: 251,Loss: -0.117,Avg.Loss: 0.713,LR: 4.91E-04]Training epoch 2:  74%|███████▎  | 251/341 [00:04<00:01, 54.43it/s, Epoch: 2, Batch: 252,Loss: -0.346,Avg.Loss: 0.709,LR: 4.91E-04]Training epoch 2:  74%|███████▍  | 252/341 [00:04<00:01, 54.43it/s, Epoch: 2, Batch: 253,Loss: 0.263,Avg.Loss: 0.707,LR: 4.91E-04] Training epoch 2:  74%|███████▍  | 253/341 [00:04<00:01, 54.43it/s, Epoch: 2, Batch: 254,Loss: 0.721,Avg.Loss: 0.707,LR: 4.91E-04]Training epoch 2:  74%|███████▍  | 254/341 [00:04<00:01, 54.43it/s, Epoch: 2, Batch: 255,Loss: -0.222,Avg.Loss: 0.704,LR: 4.91E-04]Training epoch 2:  75%|███████▍  | 255/341 [00:04<00:01, 54.43it/s, Epoch: 2, Batch: 256,Loss: -0.181,Avg.Loss: 0.700,LR: 4.91E-04]Training epoch 2:  75%|███████▌  | 256/341 [00:04<00:01, 54.43it/s, Epoch: 2, Batch: 257,Loss: 0.411,Avg.Loss: 0.699,LR: 4.91E-04] Training epoch 2:  75%|███████▌  | 257/341 [00:04<00:01, 54.30it/s, Epoch: 2, Batch: 257,Loss: 0.411,Avg.Loss: 0.699,LR: 4.91E-04]Training epoch 2:  75%|███████▌  | 257/341 [00:04<00:01, 54.30it/s, Epoch: 2, Batch: 258,Loss: -0.100,Avg.Loss: 0.696,LR: 4.91E-04]Training epoch 2:  76%|███████▌  | 258/341 [00:04<00:01, 54.30it/s, Epoch: 2, Batch: 259,Loss: -0.026,Avg.Loss: 0.693,LR: 4.91E-04]Training epoch 2:  76%|███████▌  | 259/341 [00:04<00:01, 54.30it/s, Epoch: 2, Batch: 260,Loss: 0.594,Avg.Loss: 0.693,LR: 4.90E-04] Training epoch 2:  76%|███████▌  | 260/341 [00:04<00:01, 54.30it/s, Epoch: 2, Batch: 261,Loss: -0.141,Avg.Loss: 0.690,LR: 4.90E-04]Training epoch 2:  77%|███████▋  | 261/341 [00:04<00:01, 54.30it/s, Epoch: 2, Batch: 262,Loss: -0.183,Avg.Loss: 0.686,LR: 4.90E-04]Training epoch 2:  77%|███████▋  | 262/341 [00:04<00:01, 54.30it/s, Epoch: 2, Batch: 263,Loss: 0.251,Avg.Loss: 0.685,LR: 4.90E-04] Training epoch 2:  77%|███████▋  | 263/341 [00:04<00:01, 54.03it/s, Epoch: 2, Batch: 263,Loss: 0.251,Avg.Loss: 0.685,LR: 4.90E-04]Training epoch 2:  77%|███████▋  | 263/341 [00:04<00:01, 54.03it/s, Epoch: 2, Batch: 264,Loss: -0.195,Avg.Loss: 0.681,LR: 4.90E-04]Training epoch 2:  77%|███████▋  | 264/341 [00:05<00:01, 54.03it/s, Epoch: 2, Batch: 265,Loss: 0.021,Avg.Loss: 0.679,LR: 4.90E-04] Training epoch 2:  78%|███████▊  | 265/341 [00:05<00:01, 54.03it/s, Epoch: 2, Batch: 266,Loss: 0.064,Avg.Loss: 0.676,LR: 4.90E-04]Training epoch 2:  78%|███████▊  | 266/341 [00:05<00:01, 54.03it/s, Epoch: 2, Batch: 267,Loss: -0.230,Avg.Loss: 0.673,LR: 4.90E-04]Training epoch 2:  78%|███████▊  | 267/341 [00:05<00:01, 54.03it/s, Epoch: 2, Batch: 268,Loss: 0.299,Avg.Loss: 0.672,LR: 4.90E-04] Training epoch 2:  79%|███████▊  | 268/341 [00:05<00:01, 54.03it/s, Epoch: 2, Batch: 269,Loss: 0.274,Avg.Loss: 0.670,LR: 4.90E-04]Training epoch 2:  79%|███████▉  | 269/341 [00:05<00:01, 53.67it/s, Epoch: 2, Batch: 269,Loss: 0.274,Avg.Loss: 0.670,LR: 4.90E-04]Training epoch 2:  79%|███████▉  | 269/341 [00:05<00:01, 53.67it/s, Epoch: 2, Batch: 270,Loss: 0.004,Avg.Loss: 0.668,LR: 4.90E-04]Training epoch 2:  79%|███████▉  | 270/341 [00:05<00:01, 53.67it/s, Epoch: 2, Batch: 271,Loss: -0.033,Avg.Loss: 0.665,LR: 4.90E-04]Training epoch 2:  79%|███████▉  | 271/341 [00:05<00:01, 53.67it/s, Epoch: 2, Batch: 272,Loss: 0.187,Avg.Loss: 0.663,LR: 4.90E-04] Training epoch 2:  80%|███████▉  | 272/341 [00:05<00:01, 53.67it/s, Epoch: 2, Batch: 273,Loss: -0.370,Avg.Loss: 0.660,LR: 4.90E-04]Training epoch 2:  80%|████████  | 273/341 [00:05<00:01, 53.67it/s, Epoch: 2, Batch: 274,Loss: -0.009,Avg.Loss: 0.657,LR: 4.90E-04]Training epoch 2:  80%|████████  | 274/341 [00:05<00:01, 53.67it/s, Epoch: 2, Batch: 275,Loss: 0.316,Avg.Loss: 0.656,LR: 4.90E-04] Training epoch 2:  81%|████████  | 275/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 275,Loss: 0.316,Avg.Loss: 0.656,LR: 4.90E-04]Training epoch 2:  81%|████████  | 275/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 276,Loss: -0.376,Avg.Loss: 0.652,LR: 4.90E-04]Training epoch 2:  81%|████████  | 276/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 277,Loss: -0.076,Avg.Loss: 0.650,LR: 4.90E-04]Training epoch 2:  81%|████████  | 277/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 278,Loss: 0.203,Avg.Loss: 0.648,LR: 4.90E-04] Training epoch 2:  82%|████████▏ | 278/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 279,Loss: -0.281,Avg.Loss: 0.645,LR: 4.90E-04]Training epoch 2:  82%|████████▏ | 279/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 280,Loss: 0.168,Avg.Loss: 0.643,LR: 4.90E-04] Training epoch 2:  82%|████████▏ | 280/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 281,Loss: 0.144,Avg.Loss: 0.641,LR: 4.90E-04]Training epoch 2:  82%|████████▏ | 281/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 281,Loss: 0.144,Avg.Loss: 0.641,LR: 4.90E-04]Training epoch 2:  82%|████████▏ | 281/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 282,Loss: -0.329,Avg.Loss: 0.638,LR: 4.90E-04]Training epoch 2:  83%|████████▎ | 282/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 283,Loss: -0.411,Avg.Loss: 0.634,LR: 4.90E-04]Training epoch 2:  83%|████████▎ | 283/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 284,Loss: 0.018,Avg.Loss: 0.632,LR: 4.90E-04] Training epoch 2:  83%|████████▎ | 284/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 285,Loss: -0.150,Avg.Loss: 0.629,LR: 4.90E-04]Training epoch 2:  84%|████████▎ | 285/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 286,Loss: 0.030,Avg.Loss: 0.627,LR: 4.90E-04] Training epoch 2:  84%|████████▍ | 286/341 [00:05<00:01, 53.49it/s, Epoch: 2, Batch: 287,Loss: 0.366,Avg.Loss: 0.626,LR: 4.90E-04]Training epoch 2:  84%|████████▍ | 287/341 [00:05<00:01, 53.66it/s, Epoch: 2, Batch: 287,Loss: 0.366,Avg.Loss: 0.626,LR: 4.90E-04]Training epoch 2:  84%|████████▍ | 287/341 [00:05<00:01, 53.66it/s, Epoch: 2, Batch: 288,Loss: -0.269,Avg.Loss: 0.623,LR: 4.90E-04]Training epoch 2:  84%|████████▍ | 288/341 [00:05<00:00, 53.66it/s, Epoch: 2, Batch: 289,Loss: -0.361,Avg.Loss: 0.620,LR: 4.90E-04]Training epoch 2:  85%|████████▍ | 289/341 [00:05<00:00, 53.66it/s, Epoch: 2, Batch: 290,Loss: -0.005,Avg.Loss: 0.617,LR: 4.90E-04]Training epoch 2:  85%|████████▌ | 290/341 [00:05<00:00, 53.66it/s, Epoch: 2, Batch: 291,Loss: -0.543,Avg.Loss: 0.613,LR: 4.89E-04]Training epoch 2:  85%|████████▌ | 291/341 [00:05<00:00, 53.66it/s, Epoch: 2, Batch: 292,Loss: -0.166,Avg.Loss: 0.611,LR: 4.89E-04]Training epoch 2:  86%|████████▌ | 292/341 [00:05<00:00, 53.66it/s, Epoch: 2, Batch: 293,Loss: 0.427,Avg.Loss: 0.610,LR: 4.89E-04] Training epoch 2:  86%|████████▌ | 293/341 [00:05<00:00, 52.49it/s, Epoch: 2, Batch: 293,Loss: 0.427,Avg.Loss: 0.610,LR: 4.89E-04]Training epoch 2:  86%|████████▌ | 293/341 [00:05<00:00, 52.49it/s, Epoch: 2, Batch: 294,Loss: -0.057,Avg.Loss: 0.608,LR: 4.89E-04]Training epoch 2:  86%|████████▌ | 294/341 [00:05<00:00, 52.49it/s, Epoch: 2, Batch: 295,Loss: -0.259,Avg.Loss: 0.605,LR: 4.89E-04]Training epoch 2:  87%|████████▋ | 295/341 [00:05<00:00, 52.49it/s, Epoch: 2, Batch: 296,Loss: 0.082,Avg.Loss: 0.603,LR: 4.89E-04] Training epoch 2:  87%|████████▋ | 296/341 [00:05<00:00, 52.49it/s, Epoch: 2, Batch: 297,Loss: -0.477,Avg.Loss: 0.599,LR: 4.89E-04]Training epoch 2:  87%|████████▋ | 297/341 [00:05<00:00, 52.49it/s, Epoch: 2, Batch: 298,Loss: 0.056,Avg.Loss: 0.598,LR: 4.89E-04] Training epoch 2:  87%|████████▋ | 298/341 [00:05<00:00, 52.49it/s, Epoch: 2, Batch: 299,Loss: 0.672,Avg.Loss: 0.598,LR: 4.89E-04]Training epoch 2:  88%|████████▊ | 299/341 [00:05<00:00, 52.04it/s, Epoch: 2, Batch: 299,Loss: 0.672,Avg.Loss: 0.598,LR: 4.89E-04]Training epoch 2:  88%|████████▊ | 299/341 [00:05<00:00, 52.04it/s, Epoch: 2, Batch: 300,Loss: 0.136,Avg.Loss: 0.596,LR: 4.89E-04]Training epoch 2:  88%|████████▊ | 300/341 [00:05<00:00, 52.04it/s, Epoch: 2, Batch: 301,Loss: -0.307,Avg.Loss: 0.593,LR: 4.89E-04]Training epoch 2:  88%|████████▊ | 301/341 [00:05<00:00, 52.04it/s, Epoch: 2, Batch: 302,Loss: -0.197,Avg.Loss: 0.591,LR: 4.89E-04]Training epoch 2:  89%|████████▊ | 302/341 [00:05<00:00, 52.04it/s, Epoch: 2, Batch: 303,Loss: -0.513,Avg.Loss: 0.587,LR: 4.89E-04]Training epoch 2:  89%|████████▉ | 303/341 [00:05<00:00, 52.04it/s, Epoch: 2, Batch: 304,Loss: -0.235,Avg.Loss: 0.584,LR: 4.89E-04]Training epoch 2:  89%|████████▉ | 304/341 [00:05<00:00, 52.04it/s, Epoch: 2, Batch: 305,Loss: 0.366,Avg.Loss: 0.584,LR: 4.89E-04] Training epoch 2:  89%|████████▉ | 305/341 [00:05<00:00, 52.16it/s, Epoch: 2, Batch: 305,Loss: 0.366,Avg.Loss: 0.584,LR: 4.89E-04]Training epoch 2:  89%|████████▉ | 305/341 [00:05<00:00, 52.16it/s, Epoch: 2, Batch: 306,Loss: 0.033,Avg.Loss: 0.582,LR: 4.89E-04]Training epoch 2:  90%|████████▉ | 306/341 [00:05<00:00, 52.16it/s, Epoch: 2, Batch: 307,Loss: 0.043,Avg.Loss: 0.580,LR: 4.89E-04]Training epoch 2:  90%|█████████ | 307/341 [00:05<00:00, 52.16it/s, Epoch: 2, Batch: 308,Loss: 0.266,Avg.Loss: 0.579,LR: 4.89E-04]Training epoch 2:  90%|█████████ | 308/341 [00:05<00:00, 52.16it/s, Epoch: 2, Batch: 309,Loss: -0.139,Avg.Loss: 0.577,LR: 4.89E-04]Training epoch 2:  91%|█████████ | 309/341 [00:05<00:00, 52.16it/s, Epoch: 2, Batch: 310,Loss: 0.071,Avg.Loss: 0.575,LR: 4.89E-04] Training epoch 2:  91%|█████████ | 310/341 [00:05<00:00, 52.16it/s, Epoch: 2, Batch: 311,Loss: -0.001,Avg.Loss: 0.573,LR: 4.89E-04]Training epoch 2:  91%|█████████ | 311/341 [00:05<00:00, 52.18it/s, Epoch: 2, Batch: 311,Loss: -0.001,Avg.Loss: 0.573,LR: 4.89E-04]Training epoch 2:  91%|█████████ | 311/341 [00:05<00:00, 52.18it/s, Epoch: 2, Batch: 312,Loss: -0.261,Avg.Loss: 0.571,LR: 4.89E-04]Training epoch 2:  91%|█████████▏| 312/341 [00:05<00:00, 52.18it/s, Epoch: 2, Batch: 313,Loss: -0.214,Avg.Loss: 0.568,LR: 4.89E-04]Training epoch 2:  92%|█████████▏| 313/341 [00:05<00:00, 52.18it/s, Epoch: 2, Batch: 314,Loss: 0.469,Avg.Loss: 0.568,LR: 4.89E-04] Training epoch 2:  92%|█████████▏| 314/341 [00:05<00:00, 52.18it/s, Epoch: 2, Batch: 315,Loss: -0.109,Avg.Loss: 0.566,LR: 4.89E-04]Training epoch 2:  92%|█████████▏| 315/341 [00:05<00:00, 52.18it/s, Epoch: 2, Batch: 316,Loss: -0.478,Avg.Loss: 0.562,LR: 4.89E-04]Training epoch 2:  93%|█████████▎| 316/341 [00:05<00:00, 52.18it/s, Epoch: 2, Batch: 317,Loss: 0.116,Avg.Loss: 0.561,LR: 4.89E-04] Training epoch 2:  93%|█████████▎| 317/341 [00:05<00:00, 52.89it/s, Epoch: 2, Batch: 317,Loss: 0.116,Avg.Loss: 0.561,LR: 4.89E-04]Training epoch 2:  93%|█████████▎| 317/341 [00:06<00:00, 52.89it/s, Epoch: 2, Batch: 318,Loss: -0.413,Avg.Loss: 0.558,LR: 4.89E-04]Training epoch 2:  93%|█████████▎| 318/341 [00:06<00:00, 52.89it/s, Epoch: 2, Batch: 319,Loss: -0.046,Avg.Loss: 0.556,LR: 4.89E-04]Training epoch 2:  94%|█████████▎| 319/341 [00:06<00:00, 52.89it/s, Epoch: 2, Batch: 320,Loss: 0.301,Avg.Loss: 0.555,LR: 4.89E-04] Training epoch 2:  94%|█████████▍| 320/341 [00:06<00:00, 52.89it/s, Epoch: 2, Batch: 321,Loss: -0.141,Avg.Loss: 0.553,LR: 4.88E-04]Training epoch 2:  94%|█████████▍| 321/341 [00:06<00:00, 52.89it/s, Epoch: 2, Batch: 322,Loss: -0.266,Avg.Loss: 0.550,LR: 4.88E-04]Training epoch 2:  94%|█████████▍| 322/341 [00:06<00:00, 52.89it/s, Epoch: 2, Batch: 323,Loss: 0.114,Avg.Loss: 0.549,LR: 4.88E-04] Training epoch 2:  95%|█████████▍| 323/341 [00:06<00:00, 53.13it/s, Epoch: 2, Batch: 323,Loss: 0.114,Avg.Loss: 0.549,LR: 4.88E-04]Training epoch 2:  95%|█████████▍| 323/341 [00:06<00:00, 53.13it/s, Epoch: 2, Batch: 324,Loss: -0.131,Avg.Loss: 0.547,LR: 4.88E-04]Training epoch 2:  95%|█████████▌| 324/341 [00:06<00:00, 53.13it/s, Epoch: 2, Batch: 325,Loss: -0.001,Avg.Loss: 0.545,LR: 4.88E-04]Training epoch 2:  95%|█████████▌| 325/341 [00:06<00:00, 53.13it/s, Epoch: 2, Batch: 326,Loss: 0.459,Avg.Loss: 0.545,LR: 4.88E-04] Training epoch 2:  96%|█████████▌| 326/341 [00:06<00:00, 53.13it/s, Epoch: 2, Batch: 327,Loss: -0.412,Avg.Loss: 0.542,LR: 4.88E-04]Training epoch 2:  96%|█████████▌| 327/341 [00:06<00:00, 53.13it/s, Epoch: 2, Batch: 328,Loss: -0.052,Avg.Loss: 0.540,LR: 4.88E-04]Training epoch 2:  96%|█████████▌| 328/341 [00:06<00:00, 53.13it/s, Epoch: 2, Batch: 329,Loss: 0.342,Avg.Loss: 0.540,LR: 4.88E-04] Training epoch 2:  96%|█████████▋| 329/341 [00:06<00:00, 53.27it/s, Epoch: 2, Batch: 329,Loss: 0.342,Avg.Loss: 0.540,LR: 4.88E-04]Training epoch 2:  96%|█████████▋| 329/341 [00:06<00:00, 53.27it/s, Epoch: 2, Batch: 330,Loss: -0.171,Avg.Loss: 0.538,LR: 4.88E-04]Training epoch 2:  97%|█████████▋| 330/341 [00:06<00:00, 53.27it/s, Epoch: 2, Batch: 331,Loss: -0.106,Avg.Loss: 0.536,LR: 4.88E-04]Training epoch 2:  97%|█████████▋| 331/341 [00:06<00:00, 53.27it/s, Epoch: 2, Batch: 332,Loss: -0.148,Avg.Loss: 0.534,LR: 4.88E-04]Training epoch 2:  97%|█████████▋| 332/341 [00:06<00:00, 53.27it/s, Epoch: 2, Batch: 333,Loss: -0.536,Avg.Loss: 0.530,LR: 4.88E-04]Training epoch 2:  98%|█████████▊| 333/341 [00:06<00:00, 53.27it/s, Epoch: 2, Batch: 334,Loss: -0.080,Avg.Loss: 0.529,LR: 4.88E-04]Training epoch 2:  98%|█████████▊| 334/341 [00:06<00:00, 53.27it/s, Epoch: 2, Batch: 335,Loss: 0.375,Avg.Loss: 0.528,LR: 4.88E-04] Training epoch 2:  98%|█████████▊| 335/341 [00:06<00:00, 52.98it/s, Epoch: 2, Batch: 335,Loss: 0.375,Avg.Loss: 0.528,LR: 4.88E-04]Training epoch 2:  98%|█████████▊| 335/341 [00:06<00:00, 52.98it/s, Epoch: 2, Batch: 336,Loss: 0.039,Avg.Loss: 0.527,LR: 4.88E-04]Training epoch 2:  99%|█████████▊| 336/341 [00:06<00:00, 52.98it/s, Epoch: 2, Batch: 337,Loss: -0.443,Avg.Loss: 0.524,LR: 4.88E-04]Training epoch 2:  99%|█████████▉| 337/341 [00:06<00:00, 52.98it/s, Epoch: 2, Batch: 338,Loss: -0.184,Avg.Loss: 0.522,LR: 4.88E-04]Training epoch 2:  99%|█████████▉| 338/341 [00:06<00:00, 52.98it/s, Epoch: 2, Batch: 339,Loss: -0.718,Avg.Loss: 0.518,LR: 4.88E-04]Training epoch 2:  99%|█████████▉| 339/341 [00:06<00:00, 52.98it/s, Epoch: 2, Batch: 340,Loss: -0.269,Avg.Loss: 0.516,LR: 4.88E-04]Training epoch 2: 100%|█████████▉| 340/341 [00:06<00:00, 52.98it/s, Epoch: 2, Batch: 341,Loss: 0.333,Avg.Loss: 0.515,LR: 4.88E-04] Training epoch 2: 100%|██████████| 341/341 [00:06<00:00, 52.71it/s, Epoch: 2, Batch: 341,Loss: 0.333,Avg.Loss: 0.515,LR: 4.88E-04]Training epoch 2: 100%|██████████| 341/341 [00:06<00:00, 52.86it/s, Epoch: 2, Batch: 341,Loss: 0.333,Avg.Loss: 0.515,LR: 4.88E-04]
Training epoch 3:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 3:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 3, Batch: 1,Loss: -0.389,Avg.Loss: -0.389,LR: 4.88E-04]Training epoch 3:   0%|          | 1/341 [00:00<00:11, 30.72it/s, Epoch: 3, Batch: 2,Loss: -0.162,Avg.Loss: -0.275,LR: 4.88E-04]Training epoch 3:   1%|          | 2/341 [00:00<00:08, 41.09it/s, Epoch: 3, Batch: 3,Loss: 0.033,Avg.Loss: -0.173,LR: 4.88E-04] Training epoch 3:   1%|          | 3/341 [00:00<00:06, 48.71it/s, Epoch: 3, Batch: 4,Loss: -0.275,Avg.Loss: -0.198,LR: 4.88E-04]Training epoch 3:   1%|          | 4/341 [00:00<00:06, 51.20it/s, Epoch: 3, Batch: 5,Loss: 0.256,Avg.Loss: -0.107,LR: 4.88E-04] Training epoch 3:   1%|▏         | 5/341 [00:00<00:06, 51.56it/s, Epoch: 3, Batch: 6,Loss: 0.248,Avg.Loss: -0.048,LR: 4.88E-04]Training epoch 3:   2%|▏         | 6/341 [00:00<00:06, 52.25it/s, Epoch: 3, Batch: 7,Loss: -0.273,Avg.Loss: -0.080,LR: 4.88E-04]Training epoch 3:   2%|▏         | 7/341 [00:00<00:05, 60.86it/s, Epoch: 3, Batch: 7,Loss: -0.273,Avg.Loss: -0.080,LR: 4.88E-04]Training epoch 3:   2%|▏         | 7/341 [00:00<00:05, 60.86it/s, Epoch: 3, Batch: 8,Loss: -0.558,Avg.Loss: -0.140,LR: 4.87E-04]Training epoch 3:   2%|▏         | 8/341 [00:00<00:05, 60.86it/s, Epoch: 3, Batch: 9,Loss: 0.170,Avg.Loss: -0.106,LR: 4.87E-04] Training epoch 3:   3%|▎         | 9/341 [00:00<00:05, 60.86it/s, Epoch: 3, Batch: 10,Loss: -0.362,Avg.Loss: -0.131,LR: 4.87E-04]Training epoch 3:   3%|▎         | 10/341 [00:00<00:05, 60.86it/s, Epoch: 3, Batch: 11,Loss: 0.329,Avg.Loss: -0.089,LR: 4.87E-04]Training epoch 3:   3%|▎         | 11/341 [00:00<00:05, 60.86it/s, Epoch: 3, Batch: 12,Loss: 0.534,Avg.Loss: -0.037,LR: 4.87E-04]Training epoch 3:   4%|▎         | 12/341 [00:00<00:05, 60.86it/s, Epoch: 3, Batch: 13,Loss: 0.408,Avg.Loss: -0.003,LR: 4.87E-04]Training epoch 3:   4%|▍         | 13/341 [00:00<00:05, 60.86it/s, Epoch: 3, Batch: 14,Loss: -0.358,Avg.Loss: -0.028,LR: 4.87E-04]Training epoch 3:   4%|▍         | 14/341 [00:00<00:05, 56.48it/s, Epoch: 3, Batch: 14,Loss: -0.358,Avg.Loss: -0.028,LR: 4.87E-04]Training epoch 3:   4%|▍         | 14/341 [00:00<00:05, 56.48it/s, Epoch: 3, Batch: 15,Loss: -0.062,Avg.Loss: -0.031,LR: 4.87E-04]Training epoch 3:   4%|▍         | 15/341 [00:00<00:05, 56.48it/s, Epoch: 3, Batch: 16,Loss: -0.388,Avg.Loss: -0.053,LR: 4.87E-04]Training epoch 3:   5%|▍         | 16/341 [00:00<00:05, 56.48it/s, Epoch: 3, Batch: 17,Loss: -0.189,Avg.Loss: -0.061,LR: 4.87E-04]Training epoch 3:   5%|▍         | 17/341 [00:00<00:05, 56.48it/s, Epoch: 3, Batch: 18,Loss: -0.182,Avg.Loss: -0.068,LR: 4.87E-04]Training epoch 3:   5%|▌         | 18/341 [00:00<00:05, 56.48it/s, Epoch: 3, Batch: 19,Loss: -0.454,Avg.Loss: -0.088,LR: 4.87E-04]Training epoch 3:   6%|▌         | 19/341 [00:00<00:05, 56.48it/s, Epoch: 3, Batch: 20,Loss: 0.055,Avg.Loss: -0.081,LR: 4.87E-04] Training epoch 3:   6%|▌         | 20/341 [00:00<00:05, 54.85it/s, Epoch: 3, Batch: 20,Loss: 0.055,Avg.Loss: -0.081,LR: 4.87E-04]Training epoch 3:   6%|▌         | 20/341 [00:00<00:05, 54.85it/s, Epoch: 3, Batch: 21,Loss: 0.560,Avg.Loss: -0.050,LR: 4.87E-04]Training epoch 3:   6%|▌         | 21/341 [00:00<00:05, 54.85it/s, Epoch: 3, Batch: 22,Loss: -0.317,Avg.Loss: -0.062,LR: 4.87E-04]Training epoch 3:   6%|▋         | 22/341 [00:00<00:05, 54.85it/s, Epoch: 3, Batch: 23,Loss: -0.243,Avg.Loss: -0.070,LR: 4.87E-04]Training epoch 3:   7%|▋         | 23/341 [00:00<00:05, 54.85it/s, Epoch: 3, Batch: 24,Loss: -0.066,Avg.Loss: -0.070,LR: 4.87E-04]Training epoch 3:   7%|▋         | 24/341 [00:00<00:05, 54.85it/s, Epoch: 3, Batch: 25,Loss: -0.383,Avg.Loss: -0.083,LR: 4.87E-04]Training epoch 3:   7%|▋         | 25/341 [00:00<00:05, 54.85it/s, Epoch: 3, Batch: 26,Loss: -0.217,Avg.Loss: -0.088,LR: 4.87E-04]Training epoch 3:   8%|▊         | 26/341 [00:00<00:05, 54.22it/s, Epoch: 3, Batch: 26,Loss: -0.217,Avg.Loss: -0.088,LR: 4.87E-04]Training epoch 3:   8%|▊         | 26/341 [00:00<00:05, 54.22it/s, Epoch: 3, Batch: 27,Loss: 0.321,Avg.Loss: -0.073,LR: 4.87E-04] Training epoch 3:   8%|▊         | 27/341 [00:00<00:05, 54.22it/s, Epoch: 3, Batch: 28,Loss: -0.351,Avg.Loss: -0.083,LR: 4.87E-04]Training epoch 3:   8%|▊         | 28/341 [00:00<00:05, 54.22it/s, Epoch: 3, Batch: 29,Loss: -0.329,Avg.Loss: -0.091,LR: 4.87E-04]Training epoch 3:   9%|▊         | 29/341 [00:00<00:05, 54.22it/s, Epoch: 3, Batch: 30,Loss: -0.062,Avg.Loss: -0.090,LR: 4.87E-04]Training epoch 3:   9%|▉         | 30/341 [00:00<00:05, 54.22it/s, Epoch: 3, Batch: 31,Loss: -0.598,Avg.Loss: -0.107,LR: 4.87E-04]Training epoch 3:   9%|▉         | 31/341 [00:00<00:05, 54.22it/s, Epoch: 3, Batch: 32,Loss: 0.435,Avg.Loss: -0.090,LR: 4.87E-04] Training epoch 3:   9%|▉         | 32/341 [00:00<00:05, 52.72it/s, Epoch: 3, Batch: 32,Loss: 0.435,Avg.Loss: -0.090,LR: 4.87E-04]Training epoch 3:   9%|▉         | 32/341 [00:00<00:05, 52.72it/s, Epoch: 3, Batch: 33,Loss: 1.284,Avg.Loss: -0.048,LR: 4.87E-04]Training epoch 3:  10%|▉         | 33/341 [00:00<00:05, 52.72it/s, Epoch: 3, Batch: 34,Loss: 0.216,Avg.Loss: -0.040,LR: 4.87E-04]Training epoch 3:  10%|▉         | 34/341 [00:00<00:05, 52.72it/s, Epoch: 3, Batch: 35,Loss: -0.654,Avg.Loss: -0.058,LR: 4.86E-04]Training epoch 3:  10%|█         | 35/341 [00:00<00:05, 52.72it/s, Epoch: 3, Batch: 36,Loss: -0.268,Avg.Loss: -0.064,LR: 4.86E-04]Training epoch 3:  11%|█         | 36/341 [00:00<00:05, 52.72it/s, Epoch: 3, Batch: 37,Loss: -0.759,Avg.Loss: -0.082,LR: 4.86E-04]Training epoch 3:  11%|█         | 37/341 [00:00<00:05, 52.72it/s, Epoch: 3, Batch: 38,Loss: 0.114,Avg.Loss: -0.077,LR: 4.86E-04] Training epoch 3:  11%|█         | 38/341 [00:00<00:05, 52.64it/s, Epoch: 3, Batch: 38,Loss: 0.114,Avg.Loss: -0.077,LR: 4.86E-04]Training epoch 3:  11%|█         | 38/341 [00:00<00:05, 52.64it/s, Epoch: 3, Batch: 39,Loss: 0.616,Avg.Loss: -0.059,LR: 4.86E-04]Training epoch 3:  11%|█▏        | 39/341 [00:00<00:05, 52.64it/s, Epoch: 3, Batch: 40,Loss: -0.359,Avg.Loss: -0.067,LR: 4.86E-04]Training epoch 3:  12%|█▏        | 40/341 [00:00<00:05, 52.64it/s, Epoch: 3, Batch: 41,Loss: -0.315,Avg.Loss: -0.073,LR: 4.86E-04]Training epoch 3:  12%|█▏        | 41/341 [00:00<00:05, 52.64it/s, Epoch: 3, Batch: 42,Loss: 0.120,Avg.Loss: -0.068,LR: 4.86E-04] Training epoch 3:  12%|█▏        | 42/341 [00:00<00:05, 52.64it/s, Epoch: 3, Batch: 43,Loss: -0.507,Avg.Loss: -0.079,LR: 4.86E-04]Training epoch 3:  13%|█▎        | 43/341 [00:00<00:05, 52.64it/s, Epoch: 3, Batch: 44,Loss: -0.538,Avg.Loss: -0.089,LR: 4.86E-04]Training epoch 3:  13%|█▎        | 44/341 [00:00<00:05, 52.52it/s, Epoch: 3, Batch: 44,Loss: -0.538,Avg.Loss: -0.089,LR: 4.86E-04]Training epoch 3:  13%|█▎        | 44/341 [00:00<00:05, 52.52it/s, Epoch: 3, Batch: 45,Loss: 0.088,Avg.Loss: -0.085,LR: 4.86E-04] Training epoch 3:  13%|█▎        | 45/341 [00:00<00:05, 52.52it/s, Epoch: 3, Batch: 46,Loss: -0.390,Avg.Loss: -0.092,LR: 4.86E-04]Training epoch 3:  13%|█▎        | 46/341 [00:00<00:05, 52.52it/s, Epoch: 3, Batch: 47,Loss: -0.470,Avg.Loss: -0.100,LR: 4.86E-04]Training epoch 3:  14%|█▍        | 47/341 [00:00<00:05, 52.52it/s, Epoch: 3, Batch: 48,Loss: -0.371,Avg.Loss: -0.105,LR: 4.86E-04]Training epoch 3:  14%|█▍        | 48/341 [00:00<00:05, 52.52it/s, Epoch: 3, Batch: 49,Loss: -0.625,Avg.Loss: -0.116,LR: 4.86E-04]Training epoch 3:  14%|█▍        | 49/341 [00:00<00:05, 52.52it/s, Epoch: 3, Batch: 50,Loss: -0.396,Avg.Loss: -0.122,LR: 4.86E-04]Training epoch 3:  15%|█▍        | 50/341 [00:00<00:05, 53.16it/s, Epoch: 3, Batch: 50,Loss: -0.396,Avg.Loss: -0.122,LR: 4.86E-04]Training epoch 3:  15%|█▍        | 50/341 [00:00<00:05, 53.16it/s, Epoch: 3, Batch: 51,Loss: 0.233,Avg.Loss: -0.115,LR: 4.86E-04] Training epoch 3:  15%|█▍        | 51/341 [00:00<00:05, 53.16it/s, Epoch: 3, Batch: 52,Loss: -0.457,Avg.Loss: -0.121,LR: 4.86E-04]Training epoch 3:  15%|█▌        | 52/341 [00:00<00:05, 53.16it/s, Epoch: 3, Batch: 53,Loss: -0.171,Avg.Loss: -0.122,LR: 4.86E-04]Training epoch 3:  16%|█▌        | 53/341 [00:01<00:05, 53.16it/s, Epoch: 3, Batch: 54,Loss: 0.380,Avg.Loss: -0.113,LR: 4.86E-04] Training epoch 3:  16%|█▌        | 54/341 [00:01<00:05, 53.16it/s, Epoch: 3, Batch: 55,Loss: -0.216,Avg.Loss: -0.115,LR: 4.86E-04]Training epoch 3:  16%|█▌        | 55/341 [00:01<00:05, 53.16it/s, Epoch: 3, Batch: 56,Loss: -0.216,Avg.Loss: -0.117,LR: 4.86E-04]Training epoch 3:  16%|█▋        | 56/341 [00:01<00:05, 53.95it/s, Epoch: 3, Batch: 56,Loss: -0.216,Avg.Loss: -0.117,LR: 4.86E-04]Training epoch 3:  16%|█▋        | 56/341 [00:01<00:05, 53.95it/s, Epoch: 3, Batch: 57,Loss: 0.030,Avg.Loss: -0.114,LR: 4.86E-04] Training epoch 3:  17%|█▋        | 57/341 [00:01<00:05, 53.95it/s, Epoch: 3, Batch: 58,Loss: -0.747,Avg.Loss: -0.125,LR: 4.86E-04]Training epoch 3:  17%|█▋        | 58/341 [00:01<00:05, 53.95it/s, Epoch: 3, Batch: 59,Loss: -0.278,Avg.Loss: -0.127,LR: 4.86E-04]Training epoch 3:  17%|█▋        | 59/341 [00:01<00:05, 53.95it/s, Epoch: 3, Batch: 60,Loss: 0.299,Avg.Loss: -0.120,LR: 4.86E-04] Training epoch 3:  18%|█▊        | 60/341 [00:01<00:05, 53.95it/s, Epoch: 3, Batch: 61,Loss: -0.199,Avg.Loss: -0.122,LR: 4.85E-04]Training epoch 3:  18%|█▊        | 61/341 [00:01<00:05, 53.95it/s, Epoch: 3, Batch: 62,Loss: -0.382,Avg.Loss: -0.126,LR: 4.85E-04]Training epoch 3:  18%|█▊        | 62/341 [00:01<00:05, 54.09it/s, Epoch: 3, Batch: 62,Loss: -0.382,Avg.Loss: -0.126,LR: 4.85E-04]Training epoch 3:  18%|█▊        | 62/341 [00:01<00:05, 54.09it/s, Epoch: 3, Batch: 63,Loss: -0.175,Avg.Loss: -0.127,LR: 4.85E-04]Training epoch 3:  18%|█▊        | 63/341 [00:01<00:05, 54.09it/s, Epoch: 3, Batch: 64,Loss: -0.671,Avg.Loss: -0.135,LR: 4.85E-04]Training epoch 3:  19%|█▉        | 64/341 [00:01<00:05, 54.09it/s, Epoch: 3, Batch: 65,Loss: 0.262,Avg.Loss: -0.129,LR: 4.85E-04] Training epoch 3:  19%|█▉        | 65/341 [00:01<00:05, 54.09it/s, Epoch: 3, Batch: 66,Loss: 0.389,Avg.Loss: -0.121,LR: 4.85E-04]Training epoch 3:  19%|█▉        | 66/341 [00:01<00:05, 54.09it/s, Epoch: 3, Batch: 67,Loss: -0.157,Avg.Loss: -0.122,LR: 4.85E-04]Training epoch 3:  20%|█▉        | 67/341 [00:01<00:05, 54.09it/s, Epoch: 3, Batch: 68,Loss: -0.653,Avg.Loss: -0.130,LR: 4.85E-04]Training epoch 3:  20%|█▉        | 68/341 [00:01<00:05, 54.01it/s, Epoch: 3, Batch: 68,Loss: -0.653,Avg.Loss: -0.130,LR: 4.85E-04]Training epoch 3:  20%|█▉        | 68/341 [00:01<00:05, 54.01it/s, Epoch: 3, Batch: 69,Loss: -0.302,Avg.Loss: -0.132,LR: 4.85E-04]Training epoch 3:  20%|██        | 69/341 [00:01<00:05, 54.01it/s, Epoch: 3, Batch: 70,Loss: -0.806,Avg.Loss: -0.142,LR: 4.85E-04]Training epoch 3:  21%|██        | 70/341 [00:01<00:05, 54.01it/s, Epoch: 3, Batch: 71,Loss: -0.222,Avg.Loss: -0.143,LR: 4.85E-04]Training epoch 3:  21%|██        | 71/341 [00:01<00:04, 54.01it/s, Epoch: 3, Batch: 72,Loss: 0.042,Avg.Loss: -0.140,LR: 4.85E-04] Training epoch 3:  21%|██        | 72/341 [00:01<00:04, 54.01it/s, Epoch: 3, Batch: 73,Loss: -0.056,Avg.Loss: -0.139,LR: 4.85E-04]Training epoch 3:  21%|██▏       | 73/341 [00:01<00:04, 54.01it/s, Epoch: 3, Batch: 74,Loss: -0.358,Avg.Loss: -0.142,LR: 4.85E-04]Training epoch 3:  22%|██▏       | 74/341 [00:01<00:04, 54.49it/s, Epoch: 3, Batch: 74,Loss: -0.358,Avg.Loss: -0.142,LR: 4.85E-04]Training epoch 3:  22%|██▏       | 74/341 [00:01<00:04, 54.49it/s, Epoch: 3, Batch: 75,Loss: -0.371,Avg.Loss: -0.145,LR: 4.85E-04]Training epoch 3:  22%|██▏       | 75/341 [00:01<00:04, 54.49it/s, Epoch: 3, Batch: 76,Loss: -0.823,Avg.Loss: -0.154,LR: 4.85E-04]Training epoch 3:  22%|██▏       | 76/341 [00:01<00:04, 54.49it/s, Epoch: 3, Batch: 77,Loss: 0.547,Avg.Loss: -0.145,LR: 4.85E-04] Training epoch 3:  23%|██▎       | 77/341 [00:01<00:04, 54.49it/s, Epoch: 3, Batch: 78,Loss: 0.439,Avg.Loss: -0.137,LR: 4.85E-04]Training epoch 3:  23%|██▎       | 78/341 [00:01<00:04, 54.49it/s, Epoch: 3, Batch: 79,Loss: -0.014,Avg.Loss: -0.136,LR: 4.85E-04]Training epoch 3:  23%|██▎       | 79/341 [00:01<00:04, 54.49it/s, Epoch: 3, Batch: 80,Loss: -0.544,Avg.Loss: -0.141,LR: 4.85E-04]Training epoch 3:  23%|██▎       | 80/341 [00:01<00:04, 54.35it/s, Epoch: 3, Batch: 80,Loss: -0.544,Avg.Loss: -0.141,LR: 4.85E-04]Training epoch 3:  23%|██▎       | 80/341 [00:01<00:04, 54.35it/s, Epoch: 3, Batch: 81,Loss: -0.463,Avg.Loss: -0.145,LR: 4.85E-04]Training epoch 3:  24%|██▍       | 81/341 [00:01<00:04, 54.35it/s, Epoch: 3, Batch: 82,Loss: -0.562,Avg.Loss: -0.150,LR: 4.85E-04]Training epoch 3:  24%|██▍       | 82/341 [00:01<00:04, 54.35it/s, Epoch: 3, Batch: 83,Loss: -0.148,Avg.Loss: -0.150,LR: 4.85E-04]Training epoch 3:  24%|██▍       | 83/341 [00:01<00:04, 54.35it/s, Epoch: 3, Batch: 84,Loss: 0.322,Avg.Loss: -0.144,LR: 4.85E-04] Training epoch 3:  25%|██▍       | 84/341 [00:01<00:04, 54.35it/s, Epoch: 3, Batch: 85,Loss: -0.535,Avg.Loss: -0.149,LR: 4.85E-04]Training epoch 3:  25%|██▍       | 85/341 [00:01<00:04, 54.35it/s, Epoch: 3, Batch: 86,Loss: -0.124,Avg.Loss: -0.149,LR: 4.85E-04]Training epoch 3:  25%|██▌       | 86/341 [00:01<00:04, 54.31it/s, Epoch: 3, Batch: 86,Loss: -0.124,Avg.Loss: -0.149,LR: 4.85E-04]Training epoch 3:  25%|██▌       | 86/341 [00:01<00:04, 54.31it/s, Epoch: 3, Batch: 87,Loss: -0.076,Avg.Loss: -0.148,LR: 4.84E-04]Training epoch 3:  26%|██▌       | 87/341 [00:01<00:04, 54.31it/s, Epoch: 3, Batch: 88,Loss: -0.476,Avg.Loss: -0.152,LR: 4.84E-04]Training epoch 3:  26%|██▌       | 88/341 [00:01<00:04, 54.31it/s, Epoch: 3, Batch: 89,Loss: -0.172,Avg.Loss: -0.152,LR: 4.84E-04]Training epoch 3:  26%|██▌       | 89/341 [00:01<00:04, 54.31it/s, Epoch: 3, Batch: 90,Loss: 0.331,Avg.Loss: -0.146,LR: 4.84E-04] Training epoch 3:  26%|██▋       | 90/341 [00:01<00:04, 54.31it/s, Epoch: 3, Batch: 91,Loss: -0.461,Avg.Loss: -0.150,LR: 4.84E-04]Training epoch 3:  27%|██▋       | 91/341 [00:01<00:04, 54.31it/s, Epoch: 3, Batch: 92,Loss: -0.159,Avg.Loss: -0.150,LR: 4.84E-04]Training epoch 3:  27%|██▋       | 92/341 [00:01<00:04, 54.34it/s, Epoch: 3, Batch: 92,Loss: -0.159,Avg.Loss: -0.150,LR: 4.84E-04]Training epoch 3:  27%|██▋       | 92/341 [00:01<00:04, 54.34it/s, Epoch: 3, Batch: 93,Loss: -0.066,Avg.Loss: -0.149,LR: 4.84E-04]Training epoch 3:  27%|██▋       | 93/341 [00:01<00:04, 54.34it/s, Epoch: 3, Batch: 94,Loss: -0.744,Avg.Loss: -0.155,LR: 4.84E-04]Training epoch 3:  28%|██▊       | 94/341 [00:01<00:04, 54.34it/s, Epoch: 3, Batch: 95,Loss: -0.240,Avg.Loss: -0.156,LR: 4.84E-04]Training epoch 3:  28%|██▊       | 95/341 [00:01<00:04, 54.34it/s, Epoch: 3, Batch: 96,Loss: -0.245,Avg.Loss: -0.157,LR: 4.84E-04]Training epoch 3:  28%|██▊       | 96/341 [00:01<00:04, 54.34it/s, Epoch: 3, Batch: 97,Loss: -0.676,Avg.Loss: -0.163,LR: 4.84E-04]Training epoch 3:  28%|██▊       | 97/341 [00:01<00:04, 54.34it/s, Epoch: 3, Batch: 98,Loss: 0.647,Avg.Loss: -0.154,LR: 4.84E-04] Training epoch 3:  29%|██▊       | 98/341 [00:01<00:04, 55.05it/s, Epoch: 3, Batch: 98,Loss: 0.647,Avg.Loss: -0.154,LR: 4.84E-04]Training epoch 3:  29%|██▊       | 98/341 [00:01<00:04, 55.05it/s, Epoch: 3, Batch: 99,Loss: 0.800,Avg.Loss: -0.145,LR: 4.84E-04]Training epoch 3:  29%|██▉       | 99/341 [00:01<00:04, 55.05it/s, Epoch: 3, Batch: 100,Loss: 0.165,Avg.Loss: -0.142,LR: 4.84E-04]Training epoch 3:  29%|██▉       | 100/341 [00:01<00:04, 55.05it/s, Epoch: 3, Batch: 101,Loss: -0.372,Avg.Loss: -0.144,LR: 4.84E-04]Training epoch 3:  30%|██▉       | 101/341 [00:01<00:04, 55.05it/s, Epoch: 3, Batch: 102,Loss: -0.152,Avg.Loss: -0.144,LR: 4.84E-04]Training epoch 3:  30%|██▉       | 102/341 [00:01<00:04, 55.05it/s, Epoch: 3, Batch: 103,Loss: -0.454,Avg.Loss: -0.147,LR: 4.84E-04]Training epoch 3:  30%|███       | 103/341 [00:01<00:04, 55.05it/s, Epoch: 3, Batch: 104,Loss: -0.197,Avg.Loss: -0.147,LR: 4.84E-04]Training epoch 3:  30%|███       | 104/341 [00:01<00:04, 55.04it/s, Epoch: 3, Batch: 104,Loss: -0.197,Avg.Loss: -0.147,LR: 4.84E-04]Training epoch 3:  30%|███       | 104/341 [00:01<00:04, 55.04it/s, Epoch: 3, Batch: 105,Loss: 0.223,Avg.Loss: -0.144,LR: 4.84E-04] Training epoch 3:  31%|███       | 105/341 [00:01<00:04, 55.04it/s, Epoch: 3, Batch: 106,Loss: -0.331,Avg.Loss: -0.146,LR: 4.84E-04]Training epoch 3:  31%|███       | 106/341 [00:01<00:04, 55.04it/s, Epoch: 3, Batch: 107,Loss: -0.282,Avg.Loss: -0.147,LR: 4.84E-04]Training epoch 3:  31%|███▏      | 107/341 [00:01<00:04, 55.04it/s, Epoch: 3, Batch: 108,Loss: -0.258,Avg.Loss: -0.148,LR: 4.84E-04]Training epoch 3:  32%|███▏      | 108/341 [00:02<00:04, 55.04it/s, Epoch: 3, Batch: 109,Loss: -0.255,Avg.Loss: -0.149,LR: 4.84E-04]Training epoch 3:  32%|███▏      | 109/341 [00:02<00:04, 55.04it/s, Epoch: 3, Batch: 110,Loss: -0.524,Avg.Loss: -0.152,LR: 4.84E-04]Training epoch 3:  32%|███▏      | 110/341 [00:02<00:04, 54.64it/s, Epoch: 3, Batch: 110,Loss: -0.524,Avg.Loss: -0.152,LR: 4.84E-04]Training epoch 3:  32%|███▏      | 110/341 [00:02<00:04, 54.64it/s, Epoch: 3, Batch: 111,Loss: -0.363,Avg.Loss: -0.154,LR: 4.84E-04]Training epoch 3:  33%|███▎      | 111/341 [00:02<00:04, 54.64it/s, Epoch: 3, Batch: 112,Loss: -0.628,Avg.Loss: -0.158,LR: 4.83E-04]Training epoch 3:  33%|███▎      | 112/341 [00:02<00:04, 54.64it/s, Epoch: 3, Batch: 113,Loss: -0.639,Avg.Loss: -0.163,LR: 4.83E-04]Training epoch 3:  33%|███▎      | 113/341 [00:02<00:04, 54.64it/s, Epoch: 3, Batch: 114,Loss: -0.616,Avg.Loss: -0.167,LR: 4.83E-04]Training epoch 3:  33%|███▎      | 114/341 [00:02<00:04, 54.64it/s, Epoch: 3, Batch: 115,Loss: -0.733,Avg.Loss: -0.172,LR: 4.83E-04]Training epoch 3:  34%|███▎      | 115/341 [00:02<00:04, 54.64it/s, Epoch: 3, Batch: 116,Loss: -0.123,Avg.Loss: -0.171,LR: 4.83E-04]Training epoch 3:  34%|███▍      | 116/341 [00:02<00:04, 54.78it/s, Epoch: 3, Batch: 116,Loss: -0.123,Avg.Loss: -0.171,LR: 4.83E-04]Training epoch 3:  34%|███▍      | 116/341 [00:02<00:04, 54.78it/s, Epoch: 3, Batch: 117,Loss: 0.277,Avg.Loss: -0.167,LR: 4.83E-04] Training epoch 3:  34%|███▍      | 117/341 [00:02<00:04, 54.78it/s, Epoch: 3, Batch: 118,Loss: -0.608,Avg.Loss: -0.171,LR: 4.83E-04]Training epoch 3:  35%|███▍      | 118/341 [00:02<00:04, 54.78it/s, Epoch: 3, Batch: 119,Loss: -0.269,Avg.Loss: -0.172,LR: 4.83E-04]Training epoch 3:  35%|███▍      | 119/341 [00:02<00:04, 54.78it/s, Epoch: 3, Batch: 120,Loss: 0.120,Avg.Loss: -0.170,LR: 4.83E-04] Training epoch 3:  35%|███▌      | 120/341 [00:02<00:04, 54.78it/s, Epoch: 3, Batch: 121,Loss: -0.577,Avg.Loss: -0.173,LR: 4.83E-04]Training epoch 3:  35%|███▌      | 121/341 [00:02<00:04, 54.78it/s, Epoch: 3, Batch: 122,Loss: -0.266,Avg.Loss: -0.174,LR: 4.83E-04]Training epoch 3:  36%|███▌      | 122/341 [00:02<00:04, 54.48it/s, Epoch: 3, Batch: 122,Loss: -0.266,Avg.Loss: -0.174,LR: 4.83E-04]Training epoch 3:  36%|███▌      | 122/341 [00:02<00:04, 54.48it/s, Epoch: 3, Batch: 123,Loss: -0.014,Avg.Loss: -0.172,LR: 4.83E-04]Training epoch 3:  36%|███▌      | 123/341 [00:02<00:04, 54.48it/s, Epoch: 3, Batch: 124,Loss: -0.698,Avg.Loss: -0.177,LR: 4.83E-04]Training epoch 3:  36%|███▋      | 124/341 [00:02<00:03, 54.48it/s, Epoch: 3, Batch: 125,Loss: -0.028,Avg.Loss: -0.175,LR: 4.83E-04]Training epoch 3:  37%|███▋      | 125/341 [00:02<00:03, 54.48it/s, Epoch: 3, Batch: 126,Loss: 1.008,Avg.Loss: -0.166,LR: 4.83E-04] Training epoch 3:  37%|███▋      | 126/341 [00:02<00:03, 54.48it/s, Epoch: 3, Batch: 127,Loss: 0.323,Avg.Loss: -0.162,LR: 4.83E-04]Training epoch 3:  37%|███▋      | 127/341 [00:02<00:03, 54.48it/s, Epoch: 3, Batch: 128,Loss: -0.545,Avg.Loss: -0.165,LR: 4.83E-04]Training epoch 3:  38%|███▊      | 128/341 [00:02<00:03, 55.16it/s, Epoch: 3, Batch: 128,Loss: -0.545,Avg.Loss: -0.165,LR: 4.83E-04]Training epoch 3:  38%|███▊      | 128/341 [00:02<00:03, 55.16it/s, Epoch: 3, Batch: 129,Loss: -0.230,Avg.Loss: -0.166,LR: 4.83E-04]Training epoch 3:  38%|███▊      | 129/341 [00:02<00:03, 55.16it/s, Epoch: 3, Batch: 130,Loss: 0.215,Avg.Loss: -0.163,LR: 4.83E-04] Training epoch 3:  38%|███▊      | 130/341 [00:02<00:03, 55.16it/s, Epoch: 3, Batch: 131,Loss: -0.393,Avg.Loss: -0.164,LR: 4.83E-04]Training epoch 3:  38%|███▊      | 131/341 [00:02<00:03, 55.16it/s, Epoch: 3, Batch: 132,Loss: -0.265,Avg.Loss: -0.165,LR: 4.83E-04]Training epoch 3:  39%|███▊      | 132/341 [00:02<00:03, 55.16it/s, Epoch: 3, Batch: 133,Loss: -0.829,Avg.Loss: -0.170,LR: 4.83E-04]Training epoch 3:  39%|███▉      | 133/341 [00:02<00:03, 55.16it/s, Epoch: 3, Batch: 134,Loss: -0.338,Avg.Loss: -0.171,LR: 4.83E-04]Training epoch 3:  39%|███▉      | 134/341 [00:02<00:03, 55.12it/s, Epoch: 3, Batch: 134,Loss: -0.338,Avg.Loss: -0.171,LR: 4.83E-04]Training epoch 3:  39%|███▉      | 134/341 [00:02<00:03, 55.12it/s, Epoch: 3, Batch: 135,Loss: 0.009,Avg.Loss: -0.170,LR: 4.83E-04] Training epoch 3:  40%|███▉      | 135/341 [00:02<00:03, 55.12it/s, Epoch: 3, Batch: 136,Loss: 0.131,Avg.Loss: -0.168,LR: 4.82E-04]Training epoch 3:  40%|███▉      | 136/341 [00:02<00:03, 55.12it/s, Epoch: 3, Batch: 137,Loss: -0.018,Avg.Loss: -0.167,LR: 4.82E-04]Training epoch 3:  40%|████      | 137/341 [00:02<00:03, 55.12it/s, Epoch: 3, Batch: 138,Loss: -0.671,Avg.Loss: -0.170,LR: 4.82E-04]Training epoch 3:  40%|████      | 138/341 [00:02<00:03, 55.12it/s, Epoch: 3, Batch: 139,Loss: -0.062,Avg.Loss: -0.170,LR: 4.82E-04]Training epoch 3:  41%|████      | 139/341 [00:02<00:03, 55.12it/s, Epoch: 3, Batch: 140,Loss: -0.063,Avg.Loss: -0.169,LR: 4.82E-04]Training epoch 3:  41%|████      | 140/341 [00:02<00:03, 54.95it/s, Epoch: 3, Batch: 140,Loss: -0.063,Avg.Loss: -0.169,LR: 4.82E-04]Training epoch 3:  41%|████      | 140/341 [00:02<00:03, 54.95it/s, Epoch: 3, Batch: 141,Loss: -0.090,Avg.Loss: -0.168,LR: 4.82E-04]Training epoch 3:  41%|████▏     | 141/341 [00:02<00:03, 54.95it/s, Epoch: 3, Batch: 142,Loss: 0.215,Avg.Loss: -0.166,LR: 4.82E-04] Training epoch 3:  42%|████▏     | 142/341 [00:02<00:03, 54.95it/s, Epoch: 3, Batch: 143,Loss: -0.666,Avg.Loss: -0.169,LR: 4.82E-04]Training epoch 3:  42%|████▏     | 143/341 [00:02<00:03, 54.95it/s, Epoch: 3, Batch: 144,Loss: -0.176,Avg.Loss: -0.169,LR: 4.82E-04]Training epoch 3:  42%|████▏     | 144/341 [00:02<00:03, 54.95it/s, Epoch: 3, Batch: 145,Loss: -0.361,Avg.Loss: -0.171,LR: 4.82E-04]Training epoch 3:  43%|████▎     | 145/341 [00:02<00:03, 54.95it/s, Epoch: 3, Batch: 146,Loss: -0.090,Avg.Loss: -0.170,LR: 4.82E-04]Training epoch 3:  43%|████▎     | 146/341 [00:02<00:03, 54.85it/s, Epoch: 3, Batch: 146,Loss: -0.090,Avg.Loss: -0.170,LR: 4.82E-04]Training epoch 3:  43%|████▎     | 146/341 [00:02<00:03, 54.85it/s, Epoch: 3, Batch: 147,Loss: 0.038,Avg.Loss: -0.169,LR: 4.82E-04] Training epoch 3:  43%|████▎     | 147/341 [00:02<00:03, 54.85it/s, Epoch: 3, Batch: 148,Loss: -0.664,Avg.Loss: -0.172,LR: 4.82E-04]Training epoch 3:  43%|████▎     | 148/341 [00:02<00:03, 54.85it/s, Epoch: 3, Batch: 149,Loss: -0.662,Avg.Loss: -0.175,LR: 4.82E-04]Training epoch 3:  44%|████▎     | 149/341 [00:02<00:03, 54.85it/s, Epoch: 3, Batch: 150,Loss: -0.191,Avg.Loss: -0.175,LR: 4.82E-04]Training epoch 3:  44%|████▍     | 150/341 [00:02<00:03, 54.85it/s, Epoch: 3, Batch: 151,Loss: -0.013,Avg.Loss: -0.174,LR: 4.82E-04]Training epoch 3:  44%|████▍     | 151/341 [00:02<00:03, 54.85it/s, Epoch: 3, Batch: 152,Loss: -0.475,Avg.Loss: -0.176,LR: 4.82E-04]Training epoch 3:  45%|████▍     | 152/341 [00:02<00:03, 54.25it/s, Epoch: 3, Batch: 152,Loss: -0.475,Avg.Loss: -0.176,LR: 4.82E-04]Training epoch 3:  45%|████▍     | 152/341 [00:02<00:03, 54.25it/s, Epoch: 3, Batch: 153,Loss: -0.425,Avg.Loss: -0.178,LR: 4.82E-04]Training epoch 3:  45%|████▍     | 153/341 [00:02<00:03, 54.25it/s, Epoch: 3, Batch: 154,Loss: -0.694,Avg.Loss: -0.181,LR: 4.82E-04]Training epoch 3:  45%|████▌     | 154/341 [00:02<00:03, 54.25it/s, Epoch: 3, Batch: 155,Loss: -0.079,Avg.Loss: -0.181,LR: 4.82E-04]Training epoch 3:  45%|████▌     | 155/341 [00:02<00:03, 54.25it/s, Epoch: 3, Batch: 156,Loss: -0.029,Avg.Loss: -0.180,LR: 4.82E-04]Training epoch 3:  46%|████▌     | 156/341 [00:02<00:03, 54.25it/s, Epoch: 3, Batch: 157,Loss: -0.562,Avg.Loss: -0.182,LR: 4.82E-04]Training epoch 3:  46%|████▌     | 157/341 [00:02<00:03, 54.25it/s, Epoch: 3, Batch: 158,Loss: -0.521,Avg.Loss: -0.184,LR: 4.82E-04]Training epoch 3:  46%|████▋     | 158/341 [00:02<00:03, 54.09it/s, Epoch: 3, Batch: 158,Loss: -0.521,Avg.Loss: -0.184,LR: 4.82E-04]Training epoch 3:  46%|████▋     | 158/341 [00:02<00:03, 54.09it/s, Epoch: 3, Batch: 159,Loss: -0.788,Avg.Loss: -0.188,LR: 4.81E-04]Training epoch 3:  47%|████▋     | 159/341 [00:02<00:03, 54.09it/s, Epoch: 3, Batch: 160,Loss: -0.001,Avg.Loss: -0.187,LR: 4.81E-04]Training epoch 3:  47%|████▋     | 160/341 [00:02<00:03, 54.09it/s, Epoch: 3, Batch: 161,Loss: 0.438,Avg.Loss: -0.183,LR: 4.81E-04] Training epoch 3:  47%|████▋     | 161/341 [00:02<00:03, 54.09it/s, Epoch: 3, Batch: 162,Loss: -0.254,Avg.Loss: -0.183,LR: 4.81E-04]Training epoch 3:  48%|████▊     | 162/341 [00:03<00:03, 54.09it/s, Epoch: 3, Batch: 163,Loss: -0.778,Avg.Loss: -0.187,LR: 4.81E-04]Training epoch 3:  48%|████▊     | 163/341 [00:03<00:03, 54.09it/s, Epoch: 3, Batch: 164,Loss: -0.065,Avg.Loss: -0.186,LR: 4.81E-04]Training epoch 3:  48%|████▊     | 164/341 [00:03<00:03, 53.72it/s, Epoch: 3, Batch: 164,Loss: -0.065,Avg.Loss: -0.186,LR: 4.81E-04]Training epoch 3:  48%|████▊     | 164/341 [00:03<00:03, 53.72it/s, Epoch: 3, Batch: 165,Loss: -0.662,Avg.Loss: -0.189,LR: 4.81E-04]Training epoch 3:  48%|████▊     | 165/341 [00:03<00:03, 53.72it/s, Epoch: 3, Batch: 166,Loss: -0.175,Avg.Loss: -0.189,LR: 4.81E-04]Training epoch 3:  49%|████▊     | 166/341 [00:03<00:03, 53.72it/s, Epoch: 3, Batch: 167,Loss: -0.033,Avg.Loss: -0.188,LR: 4.81E-04]Training epoch 3:  49%|████▉     | 167/341 [00:03<00:03, 53.72it/s, Epoch: 3, Batch: 168,Loss: -0.647,Avg.Loss: -0.191,LR: 4.81E-04]Training epoch 3:  49%|████▉     | 168/341 [00:03<00:03, 53.72it/s, Epoch: 3, Batch: 169,Loss: -0.390,Avg.Loss: -0.192,LR: 4.81E-04]Training epoch 3:  50%|████▉     | 169/341 [00:03<00:03, 53.72it/s, Epoch: 3, Batch: 170,Loss: 0.085,Avg.Loss: -0.190,LR: 4.81E-04] Training epoch 3:  50%|████▉     | 170/341 [00:03<00:03, 53.40it/s, Epoch: 3, Batch: 170,Loss: 0.085,Avg.Loss: -0.190,LR: 4.81E-04]Training epoch 3:  50%|████▉     | 170/341 [00:03<00:03, 53.40it/s, Epoch: 3, Batch: 171,Loss: -0.345,Avg.Loss: -0.191,LR: 4.81E-04]Training epoch 3:  50%|█████     | 171/341 [00:03<00:03, 53.40it/s, Epoch: 3, Batch: 172,Loss: -0.420,Avg.Loss: -0.193,LR: 4.81E-04]Training epoch 3:  50%|█████     | 172/341 [00:03<00:03, 53.40it/s, Epoch: 3, Batch: 173,Loss: -0.600,Avg.Loss: -0.195,LR: 4.81E-04]Training epoch 3:  51%|█████     | 173/341 [00:03<00:03, 53.40it/s, Epoch: 3, Batch: 174,Loss: -0.914,Avg.Loss: -0.199,LR: 4.81E-04]Training epoch 3:  51%|█████     | 174/341 [00:03<00:03, 53.40it/s, Epoch: 3, Batch: 175,Loss: -0.877,Avg.Loss: -0.203,LR: 4.81E-04]Training epoch 3:  51%|█████▏    | 175/341 [00:03<00:03, 53.40it/s, Epoch: 3, Batch: 176,Loss: -0.932,Avg.Loss: -0.207,LR: 4.81E-04]Training epoch 3:  52%|█████▏    | 176/341 [00:03<00:03, 52.46it/s, Epoch: 3, Batch: 176,Loss: -0.932,Avg.Loss: -0.207,LR: 4.81E-04]Training epoch 3:  52%|█████▏    | 176/341 [00:03<00:03, 52.46it/s, Epoch: 3, Batch: 177,Loss: -0.672,Avg.Loss: -0.210,LR: 4.81E-04]Training epoch 3:  52%|█████▏    | 177/341 [00:03<00:03, 52.46it/s, Epoch: 3, Batch: 178,Loss: 0.034,Avg.Loss: -0.208,LR: 4.81E-04] Training epoch 3:  52%|█████▏    | 178/341 [00:03<00:03, 52.46it/s, Epoch: 3, Batch: 179,Loss: -0.142,Avg.Loss: -0.208,LR: 4.81E-04]Training epoch 3:  52%|█████▏    | 179/341 [00:03<00:03, 52.46it/s, Epoch: 3, Batch: 180,Loss: -0.510,Avg.Loss: -0.210,LR: 4.81E-04]Training epoch 3:  53%|█████▎    | 180/341 [00:03<00:03, 52.46it/s, Epoch: 3, Batch: 181,Loss: 0.355,Avg.Loss: -0.207,LR: 4.81E-04] Training epoch 3:  53%|█████▎    | 181/341 [00:03<00:03, 52.46it/s, Epoch: 3, Batch: 182,Loss: 1.852,Avg.Loss: -0.195,LR: 4.80E-04]Training epoch 3:  53%|█████▎    | 182/341 [00:03<00:03, 52.64it/s, Epoch: 3, Batch: 182,Loss: 1.852,Avg.Loss: -0.195,LR: 4.80E-04]Training epoch 3:  53%|█████▎    | 182/341 [00:03<00:03, 52.64it/s, Epoch: 3, Batch: 183,Loss: 0.503,Avg.Loss: -0.191,LR: 4.80E-04]Training epoch 3:  54%|█████▎    | 183/341 [00:03<00:03, 52.64it/s, Epoch: 3, Batch: 184,Loss: -0.563,Avg.Loss: -0.193,LR: 4.80E-04]Training epoch 3:  54%|█████▍    | 184/341 [00:03<00:02, 52.64it/s, Epoch: 3, Batch: 185,Loss: -0.006,Avg.Loss: -0.192,LR: 4.80E-04]Training epoch 3:  54%|█████▍    | 185/341 [00:03<00:02, 52.64it/s, Epoch: 3, Batch: 186,Loss: -0.363,Avg.Loss: -0.193,LR: 4.80E-04]Training epoch 3:  55%|█████▍    | 186/341 [00:03<00:02, 52.64it/s, Epoch: 3, Batch: 187,Loss: -0.631,Avg.Loss: -0.196,LR: 4.80E-04]Training epoch 3:  55%|█████▍    | 187/341 [00:03<00:02, 52.64it/s, Epoch: 3, Batch: 188,Loss: -0.681,Avg.Loss: -0.198,LR: 4.80E-04]Training epoch 3:  55%|█████▌    | 188/341 [00:03<00:02, 53.28it/s, Epoch: 3, Batch: 188,Loss: -0.681,Avg.Loss: -0.198,LR: 4.80E-04]Training epoch 3:  55%|█████▌    | 188/341 [00:03<00:02, 53.28it/s, Epoch: 3, Batch: 189,Loss: -0.186,Avg.Loss: -0.198,LR: 4.80E-04]Training epoch 3:  55%|█████▌    | 189/341 [00:03<00:02, 53.28it/s, Epoch: 3, Batch: 190,Loss: 0.540,Avg.Loss: -0.194,LR: 4.80E-04] Training epoch 3:  56%|█████▌    | 190/341 [00:03<00:02, 53.28it/s, Epoch: 3, Batch: 191,Loss: -0.037,Avg.Loss: -0.194,LR: 4.80E-04]Training epoch 3:  56%|█████▌    | 191/341 [00:03<00:02, 53.28it/s, Epoch: 3, Batch: 192,Loss: -0.325,Avg.Loss: -0.194,LR: 4.80E-04]Training epoch 3:  56%|█████▋    | 192/341 [00:03<00:02, 53.28it/s, Epoch: 3, Batch: 193,Loss: 0.288,Avg.Loss: -0.192,LR: 4.80E-04] Training epoch 3:  57%|█████▋    | 193/341 [00:03<00:02, 53.28it/s, Epoch: 3, Batch: 194,Loss: -0.291,Avg.Loss: -0.192,LR: 4.80E-04]Training epoch 3:  57%|█████▋    | 194/341 [00:03<00:02, 54.38it/s, Epoch: 3, Batch: 194,Loss: -0.291,Avg.Loss: -0.192,LR: 4.80E-04]Training epoch 3:  57%|█████▋    | 194/341 [00:03<00:02, 54.38it/s, Epoch: 3, Batch: 195,Loss: -0.117,Avg.Loss: -0.192,LR: 4.80E-04]Training epoch 3:  57%|█████▋    | 195/341 [00:03<00:02, 54.38it/s, Epoch: 3, Batch: 196,Loss: 0.499,Avg.Loss: -0.188,LR: 4.80E-04] Training epoch 3:  57%|█████▋    | 196/341 [00:03<00:02, 54.38it/s, Epoch: 3, Batch: 197,Loss: -0.254,Avg.Loss: -0.189,LR: 4.80E-04]Training epoch 3:  58%|█████▊    | 197/341 [00:03<00:02, 54.38it/s, Epoch: 3, Batch: 198,Loss: -0.532,Avg.Loss: -0.190,LR: 4.80E-04]Training epoch 3:  58%|█████▊    | 198/341 [00:03<00:02, 54.38it/s, Epoch: 3, Batch: 199,Loss: -0.710,Avg.Loss: -0.193,LR: 4.80E-04]Training epoch 3:  58%|█████▊    | 199/341 [00:03<00:02, 54.38it/s, Epoch: 3, Batch: 200,Loss: -0.117,Avg.Loss: -0.193,LR: 4.80E-04]Training epoch 3:  59%|█████▊    | 200/341 [00:03<00:02, 54.23it/s, Epoch: 3, Batch: 200,Loss: -0.117,Avg.Loss: -0.193,LR: 4.80E-04]Training epoch 3:  59%|█████▊    | 200/341 [00:03<00:02, 54.23it/s, Epoch: 3, Batch: 201,Loss: 0.158,Avg.Loss: -0.191,LR: 4.80E-04] Training epoch 3:  59%|█████▉    | 201/341 [00:03<00:02, 54.23it/s, Epoch: 3, Batch: 202,Loss: -0.373,Avg.Loss: -0.192,LR: 4.80E-04]Training epoch 3:  59%|█████▉    | 202/341 [00:03<00:02, 54.23it/s, Epoch: 3, Batch: 203,Loss: 1.155,Avg.Loss: -0.185,LR: 4.80E-04] Training epoch 3:  60%|█████▉    | 203/341 [00:03<00:02, 54.23it/s, Epoch: 3, Batch: 204,Loss: -0.314,Avg.Loss: -0.186,LR: 4.79E-04]Training epoch 3:  60%|█████▉    | 204/341 [00:03<00:02, 54.23it/s, Epoch: 3, Batch: 205,Loss: 0.127,Avg.Loss: -0.184,LR: 4.79E-04] Training epoch 3:  60%|██████    | 205/341 [00:03<00:02, 54.23it/s, Epoch: 3, Batch: 206,Loss: 0.849,Avg.Loss: -0.179,LR: 4.79E-04]Training epoch 3:  60%|██████    | 206/341 [00:03<00:02, 54.73it/s, Epoch: 3, Batch: 206,Loss: 0.849,Avg.Loss: -0.179,LR: 4.79E-04]Training epoch 3:  60%|██████    | 206/341 [00:03<00:02, 54.73it/s, Epoch: 3, Batch: 207,Loss: -0.233,Avg.Loss: -0.180,LR: 4.79E-04]Training epoch 3:  61%|██████    | 207/341 [00:03<00:02, 54.73it/s, Epoch: 3, Batch: 208,Loss: -0.321,Avg.Loss: -0.180,LR: 4.79E-04]Training epoch 3:  61%|██████    | 208/341 [00:03<00:02, 54.73it/s, Epoch: 3, Batch: 209,Loss: -0.440,Avg.Loss: -0.181,LR: 4.79E-04]Training epoch 3:  61%|██████▏   | 209/341 [00:03<00:02, 54.73it/s, Epoch: 3, Batch: 210,Loss: -0.331,Avg.Loss: -0.182,LR: 4.79E-04]Training epoch 3:  62%|██████▏   | 210/341 [00:03<00:02, 54.73it/s, Epoch: 3, Batch: 211,Loss: -0.855,Avg.Loss: -0.185,LR: 4.79E-04]Training epoch 3:  62%|██████▏   | 211/341 [00:03<00:02, 54.73it/s, Epoch: 3, Batch: 212,Loss: -0.760,Avg.Loss: -0.188,LR: 4.79E-04]Training epoch 3:  62%|██████▏   | 212/341 [00:03<00:02, 54.97it/s, Epoch: 3, Batch: 212,Loss: -0.760,Avg.Loss: -0.188,LR: 4.79E-04]Training epoch 3:  62%|██████▏   | 212/341 [00:03<00:02, 54.97it/s, Epoch: 3, Batch: 213,Loss: -0.554,Avg.Loss: -0.190,LR: 4.79E-04]Training epoch 3:  62%|██████▏   | 213/341 [00:03<00:02, 54.97it/s, Epoch: 3, Batch: 214,Loss: -0.228,Avg.Loss: -0.190,LR: 4.79E-04]Training epoch 3:  63%|██████▎   | 214/341 [00:03<00:02, 54.97it/s, Epoch: 3, Batch: 215,Loss: 0.039,Avg.Loss: -0.189,LR: 4.79E-04] Training epoch 3:  63%|██████▎   | 215/341 [00:03<00:02, 54.97it/s, Epoch: 3, Batch: 216,Loss: -0.126,Avg.Loss: -0.189,LR: 4.79E-04]Training epoch 3:  63%|██████▎   | 216/341 [00:04<00:02, 54.97it/s, Epoch: 3, Batch: 217,Loss: 0.305,Avg.Loss: -0.186,LR: 4.79E-04] Training epoch 3:  64%|██████▎   | 217/341 [00:04<00:02, 54.97it/s, Epoch: 3, Batch: 218,Loss: 0.146,Avg.Loss: -0.185,LR: 4.79E-04]Training epoch 3:  64%|██████▍   | 218/341 [00:04<00:02, 54.09it/s, Epoch: 3, Batch: 218,Loss: 0.146,Avg.Loss: -0.185,LR: 4.79E-04]Training epoch 3:  64%|██████▍   | 218/341 [00:04<00:02, 54.09it/s, Epoch: 3, Batch: 219,Loss: 0.009,Avg.Loss: -0.184,LR: 4.79E-04]Training epoch 3:  64%|██████▍   | 219/341 [00:04<00:02, 54.09it/s, Epoch: 3, Batch: 220,Loss: -0.671,Avg.Loss: -0.186,LR: 4.79E-04]Training epoch 3:  65%|██████▍   | 220/341 [00:04<00:02, 54.09it/s, Epoch: 3, Batch: 221,Loss: 0.152,Avg.Loss: -0.185,LR: 4.79E-04] Training epoch 3:  65%|██████▍   | 221/341 [00:04<00:02, 54.09it/s, Epoch: 3, Batch: 222,Loss: -0.537,Avg.Loss: -0.186,LR: 4.79E-04]Training epoch 3:  65%|██████▌   | 222/341 [00:04<00:02, 54.09it/s, Epoch: 3, Batch: 223,Loss: -0.265,Avg.Loss: -0.187,LR: 4.79E-04]Training epoch 3:  65%|██████▌   | 223/341 [00:04<00:02, 54.09it/s, Epoch: 3, Batch: 224,Loss: 0.458,Avg.Loss: -0.184,LR: 4.79E-04] Training epoch 3:  66%|██████▌   | 224/341 [00:04<00:02, 53.38it/s, Epoch: 3, Batch: 224,Loss: 0.458,Avg.Loss: -0.184,LR: 4.79E-04]Training epoch 3:  66%|██████▌   | 224/341 [00:04<00:02, 53.38it/s, Epoch: 3, Batch: 225,Loss: -0.664,Avg.Loss: -0.186,LR: 4.78E-04]Training epoch 3:  66%|██████▌   | 225/341 [00:04<00:02, 53.38it/s, Epoch: 3, Batch: 226,Loss: -0.664,Avg.Loss: -0.188,LR: 4.78E-04]Training epoch 3:  66%|██████▋   | 226/341 [00:04<00:02, 53.38it/s, Epoch: 3, Batch: 227,Loss: -0.329,Avg.Loss: -0.189,LR: 4.78E-04]Training epoch 3:  67%|██████▋   | 227/341 [00:04<00:02, 53.38it/s, Epoch: 3, Batch: 228,Loss: -0.810,Avg.Loss: -0.191,LR: 4.78E-04]Training epoch 3:  67%|██████▋   | 228/341 [00:04<00:02, 53.38it/s, Epoch: 3, Batch: 229,Loss: -0.881,Avg.Loss: -0.194,LR: 4.78E-04]Training epoch 3:  67%|██████▋   | 229/341 [00:04<00:02, 53.38it/s, Epoch: 3, Batch: 230,Loss: -0.067,Avg.Loss: -0.194,LR: 4.78E-04]Training epoch 3:  67%|██████▋   | 230/341 [00:04<00:02, 53.05it/s, Epoch: 3, Batch: 230,Loss: -0.067,Avg.Loss: -0.194,LR: 4.78E-04]Training epoch 3:  67%|██████▋   | 230/341 [00:04<00:02, 53.05it/s, Epoch: 3, Batch: 231,Loss: -0.637,Avg.Loss: -0.196,LR: 4.78E-04]Training epoch 3:  68%|██████▊   | 231/341 [00:04<00:02, 53.05it/s, Epoch: 3, Batch: 232,Loss: 0.073,Avg.Loss: -0.194,LR: 4.78E-04] Training epoch 3:  68%|██████▊   | 232/341 [00:04<00:02, 53.05it/s, Epoch: 3, Batch: 233,Loss: 0.144,Avg.Loss: -0.193,LR: 4.78E-04]Training epoch 3:  68%|██████▊   | 233/341 [00:04<00:02, 53.05it/s, Epoch: 3, Batch: 234,Loss: -0.252,Avg.Loss: -0.193,LR: 4.78E-04]Training epoch 3:  69%|██████▊   | 234/341 [00:04<00:02, 53.05it/s, Epoch: 3, Batch: 235,Loss: -0.590,Avg.Loss: -0.195,LR: 4.78E-04]Training epoch 3:  69%|██████▉   | 235/341 [00:04<00:01, 53.05it/s, Epoch: 3, Batch: 236,Loss: -0.181,Avg.Loss: -0.195,LR: 4.78E-04]Training epoch 3:  69%|██████▉   | 236/341 [00:04<00:01, 53.05it/s, Epoch: 3, Batch: 236,Loss: -0.181,Avg.Loss: -0.195,LR: 4.78E-04]Training epoch 3:  69%|██████▉   | 236/341 [00:04<00:01, 53.05it/s, Epoch: 3, Batch: 237,Loss: -0.625,Avg.Loss: -0.197,LR: 4.78E-04]Training epoch 3:  70%|██████▉   | 237/341 [00:04<00:01, 53.05it/s, Epoch: 3, Batch: 238,Loss: -0.373,Avg.Loss: -0.197,LR: 4.78E-04]Training epoch 3:  70%|██████▉   | 238/341 [00:04<00:01, 53.05it/s, Epoch: 3, Batch: 239,Loss: -0.092,Avg.Loss: -0.197,LR: 4.78E-04]Training epoch 3:  70%|███████   | 239/341 [00:04<00:01, 53.05it/s, Epoch: 3, Batch: 240,Loss: -0.551,Avg.Loss: -0.198,LR: 4.78E-04]Training epoch 3:  70%|███████   | 240/341 [00:04<00:01, 53.05it/s, Epoch: 3, Batch: 241,Loss: -0.498,Avg.Loss: -0.200,LR: 4.78E-04]Training epoch 3:  71%|███████   | 241/341 [00:04<00:01, 53.05it/s, Epoch: 3, Batch: 242,Loss: -0.188,Avg.Loss: -0.200,LR: 4.78E-04]Training epoch 3:  71%|███████   | 242/341 [00:04<00:01, 52.96it/s, Epoch: 3, Batch: 242,Loss: -0.188,Avg.Loss: -0.200,LR: 4.78E-04]Training epoch 3:  71%|███████   | 242/341 [00:04<00:01, 52.96it/s, Epoch: 3, Batch: 243,Loss: -0.777,Avg.Loss: -0.202,LR: 4.78E-04]Training epoch 3:  71%|███████▏  | 243/341 [00:04<00:01, 52.96it/s, Epoch: 3, Batch: 244,Loss: -0.313,Avg.Loss: -0.203,LR: 4.78E-04]Training epoch 3:  72%|███████▏  | 244/341 [00:04<00:01, 52.96it/s, Epoch: 3, Batch: 245,Loss: 0.249,Avg.Loss: -0.201,LR: 4.78E-04] Training epoch 3:  72%|███████▏  | 245/341 [00:04<00:01, 52.96it/s, Epoch: 3, Batch: 246,Loss: -0.513,Avg.Loss: -0.202,LR: 4.78E-04]Training epoch 3:  72%|███████▏  | 246/341 [00:04<00:01, 52.96it/s, Epoch: 3, Batch: 247,Loss: -0.410,Avg.Loss: -0.203,LR: 4.77E-04]Training epoch 3:  72%|███████▏  | 247/341 [00:04<00:01, 52.96it/s, Epoch: 3, Batch: 248,Loss: -0.155,Avg.Loss: -0.203,LR: 4.77E-04]Training epoch 3:  73%|███████▎  | 248/341 [00:04<00:01, 53.21it/s, Epoch: 3, Batch: 248,Loss: -0.155,Avg.Loss: -0.203,LR: 4.77E-04]Training epoch 3:  73%|███████▎  | 248/341 [00:04<00:01, 53.21it/s, Epoch: 3, Batch: 249,Loss: -0.540,Avg.Loss: -0.204,LR: 4.77E-04]Training epoch 3:  73%|███████▎  | 249/341 [00:04<00:01, 53.21it/s, Epoch: 3, Batch: 250,Loss: -0.614,Avg.Loss: -0.206,LR: 4.77E-04]Training epoch 3:  73%|███████▎  | 250/341 [00:04<00:01, 53.21it/s, Epoch: 3, Batch: 251,Loss: -0.474,Avg.Loss: -0.207,LR: 4.77E-04]Training epoch 3:  74%|███████▎  | 251/341 [00:04<00:01, 53.21it/s, Epoch: 3, Batch: 252,Loss: -0.721,Avg.Loss: -0.209,LR: 4.77E-04]Training epoch 3:  74%|███████▍  | 252/341 [00:04<00:01, 53.21it/s, Epoch: 3, Batch: 253,Loss: -0.701,Avg.Loss: -0.211,LR: 4.77E-04]Training epoch 3:  74%|███████▍  | 253/341 [00:04<00:01, 53.21it/s, Epoch: 3, Batch: 254,Loss: -0.081,Avg.Loss: -0.210,LR: 4.77E-04]Training epoch 3:  74%|███████▍  | 254/341 [00:04<00:01, 52.98it/s, Epoch: 3, Batch: 254,Loss: -0.081,Avg.Loss: -0.210,LR: 4.77E-04]Training epoch 3:  74%|███████▍  | 254/341 [00:04<00:01, 52.98it/s, Epoch: 3, Batch: 255,Loss: -0.836,Avg.Loss: -0.213,LR: 4.77E-04]Training epoch 3:  75%|███████▍  | 255/341 [00:04<00:01, 52.98it/s, Epoch: 3, Batch: 256,Loss: -0.243,Avg.Loss: -0.213,LR: 4.77E-04]Training epoch 3:  75%|███████▌  | 256/341 [00:04<00:01, 52.98it/s, Epoch: 3, Batch: 257,Loss: -0.036,Avg.Loss: -0.212,LR: 4.77E-04]Training epoch 3:  75%|███████▌  | 257/341 [00:04<00:01, 52.98it/s, Epoch: 3, Batch: 258,Loss: -0.461,Avg.Loss: -0.213,LR: 4.77E-04]Training epoch 3:  76%|███████▌  | 258/341 [00:04<00:01, 52.98it/s, Epoch: 3, Batch: 259,Loss: -0.811,Avg.Loss: -0.215,LR: 4.77E-04]Training epoch 3:  76%|███████▌  | 259/341 [00:04<00:01, 52.98it/s, Epoch: 3, Batch: 260,Loss: -0.252,Avg.Loss: -0.215,LR: 4.77E-04]Training epoch 3:  76%|███████▌  | 260/341 [00:04<00:01, 52.41it/s, Epoch: 3, Batch: 260,Loss: -0.252,Avg.Loss: -0.215,LR: 4.77E-04]Training epoch 3:  76%|███████▌  | 260/341 [00:04<00:01, 52.41it/s, Epoch: 3, Batch: 261,Loss: -0.676,Avg.Loss: -0.217,LR: 4.77E-04]Training epoch 3:  77%|███████▋  | 261/341 [00:04<00:01, 52.41it/s, Epoch: 3, Batch: 262,Loss: -0.529,Avg.Loss: -0.218,LR: 4.77E-04]Training epoch 3:  77%|███████▋  | 262/341 [00:04<00:01, 52.41it/s, Epoch: 3, Batch: 263,Loss: -0.285,Avg.Loss: -0.219,LR: 4.77E-04]Training epoch 3:  77%|███████▋  | 263/341 [00:04<00:01, 52.41it/s, Epoch: 3, Batch: 264,Loss: -0.576,Avg.Loss: -0.220,LR: 4.77E-04]Training epoch 3:  77%|███████▋  | 264/341 [00:04<00:01, 52.41it/s, Epoch: 3, Batch: 265,Loss: -0.292,Avg.Loss: -0.220,LR: 4.77E-04]Training epoch 3:  78%|███████▊  | 265/341 [00:04<00:01, 52.41it/s, Epoch: 3, Batch: 266,Loss: -0.569,Avg.Loss: -0.222,LR: 4.77E-04]Training epoch 3:  78%|███████▊  | 266/341 [00:04<00:01, 52.55it/s, Epoch: 3, Batch: 266,Loss: -0.569,Avg.Loss: -0.222,LR: 4.77E-04]Training epoch 3:  78%|███████▊  | 266/341 [00:04<00:01, 52.55it/s, Epoch: 3, Batch: 267,Loss: -0.889,Avg.Loss: -0.224,LR: 4.76E-04]Training epoch 3:  78%|███████▊  | 267/341 [00:04<00:01, 52.55it/s, Epoch: 3, Batch: 268,Loss: -0.104,Avg.Loss: -0.224,LR: 4.76E-04]Training epoch 3:  79%|███████▊  | 268/341 [00:04<00:01, 52.55it/s, Epoch: 3, Batch: 269,Loss: 0.199,Avg.Loss: -0.222,LR: 4.76E-04] Training epoch 3:  79%|███████▉  | 269/341 [00:05<00:01, 52.55it/s, Epoch: 3, Batch: 270,Loss: -0.545,Avg.Loss: -0.223,LR: 4.76E-04]Training epoch 3:  79%|███████▉  | 270/341 [00:05<00:01, 52.55it/s, Epoch: 3, Batch: 271,Loss: -0.815,Avg.Loss: -0.225,LR: 4.76E-04]Training epoch 3:  79%|███████▉  | 271/341 [00:05<00:01, 52.55it/s, Epoch: 3, Batch: 272,Loss: -0.198,Avg.Loss: -0.225,LR: 4.76E-04]Training epoch 3:  80%|███████▉  | 272/341 [00:05<00:01, 52.66it/s, Epoch: 3, Batch: 272,Loss: -0.198,Avg.Loss: -0.225,LR: 4.76E-04]Training epoch 3:  80%|███████▉  | 272/341 [00:05<00:01, 52.66it/s, Epoch: 3, Batch: 273,Loss: -0.832,Avg.Loss: -0.228,LR: 4.76E-04]Training epoch 3:  80%|████████  | 273/341 [00:05<00:01, 52.66it/s, Epoch: 3, Batch: 274,Loss: -0.464,Avg.Loss: -0.228,LR: 4.76E-04]Training epoch 3:  80%|████████  | 274/341 [00:05<00:01, 52.66it/s, Epoch: 3, Batch: 275,Loss: -0.095,Avg.Loss: -0.228,LR: 4.76E-04]Training epoch 3:  81%|████████  | 275/341 [00:05<00:01, 52.66it/s, Epoch: 3, Batch: 276,Loss: -0.600,Avg.Loss: -0.229,LR: 4.76E-04]Training epoch 3:  81%|████████  | 276/341 [00:05<00:01, 52.66it/s, Epoch: 3, Batch: 277,Loss: -0.839,Avg.Loss: -0.231,LR: 4.76E-04]Training epoch 3:  81%|████████  | 277/341 [00:05<00:01, 52.66it/s, Epoch: 3, Batch: 278,Loss: -0.392,Avg.Loss: -0.232,LR: 4.76E-04]Training epoch 3:  82%|████████▏ | 278/341 [00:05<00:01, 52.65it/s, Epoch: 3, Batch: 278,Loss: -0.392,Avg.Loss: -0.232,LR: 4.76E-04]Training epoch 3:  82%|████████▏ | 278/341 [00:05<00:01, 52.65it/s, Epoch: 3, Batch: 279,Loss: -0.808,Avg.Loss: -0.234,LR: 4.76E-04]Training epoch 3:  82%|████████▏ | 279/341 [00:05<00:01, 52.65it/s, Epoch: 3, Batch: 280,Loss: -0.733,Avg.Loss: -0.236,LR: 4.76E-04]Training epoch 3:  82%|████████▏ | 280/341 [00:05<00:01, 52.65it/s, Epoch: 3, Batch: 281,Loss: 0.078,Avg.Loss: -0.235,LR: 4.76E-04] Training epoch 3:  82%|████████▏ | 281/341 [00:05<00:01, 52.65it/s, Epoch: 3, Batch: 282,Loss: -0.595,Avg.Loss: -0.236,LR: 4.76E-04]Training epoch 3:  83%|████████▎ | 282/341 [00:05<00:01, 52.65it/s, Epoch: 3, Batch: 283,Loss: -0.982,Avg.Loss: -0.239,LR: 4.76E-04]Training epoch 3:  83%|████████▎ | 283/341 [00:05<00:01, 52.65it/s, Epoch: 3, Batch: 284,Loss: -0.585,Avg.Loss: -0.240,LR: 4.76E-04]Training epoch 3:  83%|████████▎ | 284/341 [00:05<00:01, 53.30it/s, Epoch: 3, Batch: 284,Loss: -0.585,Avg.Loss: -0.240,LR: 4.76E-04]Training epoch 3:  83%|████████▎ | 284/341 [00:05<00:01, 53.30it/s, Epoch: 3, Batch: 285,Loss: -0.765,Avg.Loss: -0.242,LR: 4.76E-04]Training epoch 3:  84%|████████▎ | 285/341 [00:05<00:01, 53.30it/s, Epoch: 3, Batch: 286,Loss: -0.013,Avg.Loss: -0.241,LR: 4.76E-04]Training epoch 3:  84%|████████▍ | 286/341 [00:05<00:01, 53.30it/s, Epoch: 3, Batch: 287,Loss: 0.225,Avg.Loss: -0.239,LR: 4.76E-04] Training epoch 3:  84%|████████▍ | 287/341 [00:05<00:01, 53.30it/s, Epoch: 3, Batch: 288,Loss: -0.345,Avg.Loss: -0.240,LR: 4.75E-04]Training epoch 3:  84%|████████▍ | 288/341 [00:05<00:00, 53.30it/s, Epoch: 3, Batch: 289,Loss: -0.760,Avg.Loss: -0.242,LR: 4.75E-04]Training epoch 3:  85%|████████▍ | 289/341 [00:05<00:00, 53.30it/s, Epoch: 3, Batch: 290,Loss: -0.400,Avg.Loss: -0.242,LR: 4.75E-04]Training epoch 3:  85%|████████▌ | 290/341 [00:05<00:00, 53.68it/s, Epoch: 3, Batch: 290,Loss: -0.400,Avg.Loss: -0.242,LR: 4.75E-04]Training epoch 3:  85%|████████▌ | 290/341 [00:05<00:00, 53.68it/s, Epoch: 3, Batch: 291,Loss: -0.784,Avg.Loss: -0.244,LR: 4.75E-04]Training epoch 3:  85%|████████▌ | 291/341 [00:05<00:00, 53.68it/s, Epoch: 3, Batch: 292,Loss: -0.732,Avg.Loss: -0.246,LR: 4.75E-04]Training epoch 3:  86%|████████▌ | 292/341 [00:05<00:00, 53.68it/s, Epoch: 3, Batch: 293,Loss: -0.651,Avg.Loss: -0.247,LR: 4.75E-04]Training epoch 3:  86%|████████▌ | 293/341 [00:05<00:00, 53.68it/s, Epoch: 3, Batch: 294,Loss: -1.106,Avg.Loss: -0.250,LR: 4.75E-04]Training epoch 3:  86%|████████▌ | 294/341 [00:05<00:00, 53.68it/s, Epoch: 3, Batch: 295,Loss: -0.439,Avg.Loss: -0.251,LR: 4.75E-04]Training epoch 3:  87%|████████▋ | 295/341 [00:05<00:00, 53.68it/s, Epoch: 3, Batch: 296,Loss: 0.325,Avg.Loss: -0.249,LR: 4.75E-04] Training epoch 3:  87%|████████▋ | 296/341 [00:05<00:00, 53.11it/s, Epoch: 3, Batch: 296,Loss: 0.325,Avg.Loss: -0.249,LR: 4.75E-04]Training epoch 3:  87%|████████▋ | 296/341 [00:05<00:00, 53.11it/s, Epoch: 3, Batch: 297,Loss: -0.292,Avg.Loss: -0.249,LR: 4.75E-04]Training epoch 3:  87%|████████▋ | 297/341 [00:05<00:00, 53.11it/s, Epoch: 3, Batch: 298,Loss: -0.673,Avg.Loss: -0.250,LR: 4.75E-04]Training epoch 3:  87%|████████▋ | 298/341 [00:05<00:00, 53.11it/s, Epoch: 3, Batch: 299,Loss: -0.071,Avg.Loss: -0.250,LR: 4.75E-04]Training epoch 3:  88%|████████▊ | 299/341 [00:05<00:00, 53.11it/s, Epoch: 3, Batch: 300,Loss: -0.823,Avg.Loss: -0.251,LR: 4.75E-04]Training epoch 3:  88%|████████▊ | 300/341 [00:05<00:00, 53.11it/s, Epoch: 3, Batch: 301,Loss: -0.819,Avg.Loss: -0.253,LR: 4.75E-04]Training epoch 3:  88%|████████▊ | 301/341 [00:05<00:00, 53.11it/s, Epoch: 3, Batch: 302,Loss: -0.083,Avg.Loss: -0.253,LR: 4.75E-04]Training epoch 3:  89%|████████▊ | 302/341 [00:05<00:00, 52.50it/s, Epoch: 3, Batch: 302,Loss: -0.083,Avg.Loss: -0.253,LR: 4.75E-04]Training epoch 3:  89%|████████▊ | 302/341 [00:05<00:00, 52.50it/s, Epoch: 3, Batch: 303,Loss: -0.738,Avg.Loss: -0.254,LR: 4.75E-04]Training epoch 3:  89%|████████▉ | 303/341 [00:05<00:00, 52.50it/s, Epoch: 3, Batch: 304,Loss: -0.845,Avg.Loss: -0.256,LR: 4.75E-04]Training epoch 3:  89%|████████▉ | 304/341 [00:05<00:00, 52.50it/s, Epoch: 3, Batch: 305,Loss: -0.063,Avg.Loss: -0.256,LR: 4.75E-04]Training epoch 3:  89%|████████▉ | 305/341 [00:05<00:00, 52.50it/s, Epoch: 3, Batch: 306,Loss: -1.219,Avg.Loss: -0.259,LR: 4.75E-04]Training epoch 3:  90%|████████▉ | 306/341 [00:05<00:00, 52.50it/s, Epoch: 3, Batch: 307,Loss: -0.259,Avg.Loss: -0.259,LR: 4.75E-04]Training epoch 3:  90%|█████████ | 307/341 [00:05<00:00, 52.50it/s, Epoch: 3, Batch: 308,Loss: 0.308,Avg.Loss: -0.257,LR: 4.74E-04] Training epoch 3:  90%|█████████ | 308/341 [00:05<00:00, 52.44it/s, Epoch: 3, Batch: 308,Loss: 0.308,Avg.Loss: -0.257,LR: 4.74E-04]Training epoch 3:  90%|█████████ | 308/341 [00:05<00:00, 52.44it/s, Epoch: 3, Batch: 309,Loss: -0.689,Avg.Loss: -0.258,LR: 4.74E-04]Training epoch 3:  91%|█████████ | 309/341 [00:05<00:00, 52.44it/s, Epoch: 3, Batch: 310,Loss: -0.705,Avg.Loss: -0.260,LR: 4.74E-04]Training epoch 3:  91%|█████████ | 310/341 [00:05<00:00, 52.44it/s, Epoch: 3, Batch: 311,Loss: -0.320,Avg.Loss: -0.260,LR: 4.74E-04]Training epoch 3:  91%|█████████ | 311/341 [00:05<00:00, 52.44it/s, Epoch: 3, Batch: 312,Loss: -1.037,Avg.Loss: -0.263,LR: 4.74E-04]Training epoch 3:  91%|█████████▏| 312/341 [00:05<00:00, 52.44it/s, Epoch: 3, Batch: 313,Loss: -0.448,Avg.Loss: -0.263,LR: 4.74E-04]Training epoch 3:  92%|█████████▏| 313/341 [00:05<00:00, 52.44it/s, Epoch: 3, Batch: 314,Loss: -0.142,Avg.Loss: -0.263,LR: 4.74E-04]Training epoch 3:  92%|█████████▏| 314/341 [00:05<00:00, 52.80it/s, Epoch: 3, Batch: 314,Loss: -0.142,Avg.Loss: -0.263,LR: 4.74E-04]Training epoch 3:  92%|█████████▏| 314/341 [00:05<00:00, 52.80it/s, Epoch: 3, Batch: 315,Loss: -0.727,Avg.Loss: -0.264,LR: 4.74E-04]Training epoch 3:  92%|█████████▏| 315/341 [00:05<00:00, 52.80it/s, Epoch: 3, Batch: 316,Loss: -0.651,Avg.Loss: -0.265,LR: 4.74E-04]Training epoch 3:  93%|█████████▎| 316/341 [00:05<00:00, 52.80it/s, Epoch: 3, Batch: 317,Loss: -0.169,Avg.Loss: -0.265,LR: 4.74E-04]Training epoch 3:  93%|█████████▎| 317/341 [00:05<00:00, 52.80it/s, Epoch: 3, Batch: 318,Loss: -0.892,Avg.Loss: -0.267,LR: 4.74E-04]Training epoch 3:  93%|█████████▎| 318/341 [00:05<00:00, 52.80it/s, Epoch: 3, Batch: 319,Loss: -0.700,Avg.Loss: -0.268,LR: 4.74E-04]Training epoch 3:  94%|█████████▎| 319/341 [00:05<00:00, 52.80it/s, Epoch: 3, Batch: 320,Loss: -0.329,Avg.Loss: -0.269,LR: 4.74E-04]Training epoch 3:  94%|█████████▍| 320/341 [00:05<00:00, 52.91it/s, Epoch: 3, Batch: 320,Loss: -0.329,Avg.Loss: -0.269,LR: 4.74E-04]Training epoch 3:  94%|█████████▍| 320/341 [00:05<00:00, 52.91it/s, Epoch: 3, Batch: 321,Loss: -0.796,Avg.Loss: -0.270,LR: 4.74E-04]Training epoch 3:  94%|█████████▍| 321/341 [00:05<00:00, 52.91it/s, Epoch: 3, Batch: 322,Loss: -0.701,Avg.Loss: -0.272,LR: 4.74E-04]Training epoch 3:  94%|█████████▍| 322/341 [00:06<00:00, 52.91it/s, Epoch: 3, Batch: 323,Loss: -0.273,Avg.Loss: -0.272,LR: 4.74E-04]Training epoch 3:  95%|█████████▍| 323/341 [00:06<00:00, 52.91it/s, Epoch: 3, Batch: 324,Loss: -1.033,Avg.Loss: -0.274,LR: 4.74E-04]Training epoch 3:  95%|█████████▌| 324/341 [00:06<00:00, 52.91it/s, Epoch: 3, Batch: 325,Loss: -0.745,Avg.Loss: -0.275,LR: 4.74E-04]Training epoch 3:  95%|█████████▌| 325/341 [00:06<00:00, 52.91it/s, Epoch: 3, Batch: 326,Loss: -0.291,Avg.Loss: -0.275,LR: 4.74E-04]Training epoch 3:  96%|█████████▌| 326/341 [00:06<00:00, 52.84it/s, Epoch: 3, Batch: 326,Loss: -0.291,Avg.Loss: -0.275,LR: 4.74E-04]Training epoch 3:  96%|█████████▌| 326/341 [00:06<00:00, 52.84it/s, Epoch: 3, Batch: 327,Loss: -1.091,Avg.Loss: -0.278,LR: 4.73E-04]Training epoch 3:  96%|█████████▌| 327/341 [00:06<00:00, 52.84it/s, Epoch: 3, Batch: 328,Loss: -0.506,Avg.Loss: -0.279,LR: 4.73E-04]Training epoch 3:  96%|█████████▌| 328/341 [00:06<00:00, 52.84it/s, Epoch: 3, Batch: 329,Loss: 0.041,Avg.Loss: -0.278,LR: 4.73E-04] Training epoch 3:  96%|█████████▋| 329/341 [00:06<00:00, 52.84it/s, Epoch: 3, Batch: 330,Loss: -0.635,Avg.Loss: -0.279,LR: 4.73E-04]Training epoch 3:  97%|█████████▋| 330/341 [00:06<00:00, 52.84it/s, Epoch: 3, Batch: 331,Loss: -1.065,Avg.Loss: -0.281,LR: 4.73E-04]Training epoch 3:  97%|█████████▋| 331/341 [00:06<00:00, 52.84it/s, Epoch: 3, Batch: 332,Loss: -0.510,Avg.Loss: -0.282,LR: 4.73E-04]Training epoch 3:  97%|█████████▋| 332/341 [00:06<00:00, 53.20it/s, Epoch: 3, Batch: 332,Loss: -0.510,Avg.Loss: -0.282,LR: 4.73E-04]Training epoch 3:  97%|█████████▋| 332/341 [00:06<00:00, 53.20it/s, Epoch: 3, Batch: 333,Loss: -0.842,Avg.Loss: -0.284,LR: 4.73E-04]Training epoch 3:  98%|█████████▊| 333/341 [00:06<00:00, 53.20it/s, Epoch: 3, Batch: 334,Loss: -0.588,Avg.Loss: -0.284,LR: 4.73E-04]Training epoch 3:  98%|█████████▊| 334/341 [00:06<00:00, 53.20it/s, Epoch: 3, Batch: 335,Loss: -0.584,Avg.Loss: -0.285,LR: 4.73E-04]Training epoch 3:  98%|█████████▊| 335/341 [00:06<00:00, 53.20it/s, Epoch: 3, Batch: 336,Loss: -0.715,Avg.Loss: -0.287,LR: 4.73E-04]Training epoch 3:  99%|█████████▊| 336/341 [00:06<00:00, 53.20it/s, Epoch: 3, Batch: 337,Loss: -0.775,Avg.Loss: -0.288,LR: 4.73E-04]Training epoch 3:  99%|█████████▉| 337/341 [00:06<00:00, 53.20it/s, Epoch: 3, Batch: 338,Loss: -0.542,Avg.Loss: -0.289,LR: 4.73E-04]Training epoch 3:  99%|█████████▉| 338/341 [00:06<00:00, 53.41it/s, Epoch: 3, Batch: 338,Loss: -0.542,Avg.Loss: -0.289,LR: 4.73E-04]Training epoch 3:  99%|█████████▉| 338/341 [00:06<00:00, 53.41it/s, Epoch: 3, Batch: 339,Loss: -0.932,Avg.Loss: -0.291,LR: 4.73E-04]Training epoch 3:  99%|█████████▉| 339/341 [00:06<00:00, 53.41it/s, Epoch: 3, Batch: 340,Loss: -0.532,Avg.Loss: -0.291,LR: 4.73E-04]Training epoch 3: 100%|█████████▉| 340/341 [00:06<00:00, 53.41it/s, Epoch: 3, Batch: 341,Loss: 0.643,Avg.Loss: -0.289,LR: 4.73E-04] Training epoch 3: 100%|██████████| 341/341 [00:06<00:00, 53.71it/s, Epoch: 3, Batch: 341,Loss: 0.643,Avg.Loss: -0.289,LR: 4.73E-04]
Training epoch 4:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 4:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 4, Batch: 1,Loss: -0.240,Avg.Loss: -0.240,LR: 4.73E-04]Training epoch 4:   0%|          | 1/341 [00:00<00:11, 30.67it/s, Epoch: 4, Batch: 2,Loss: -1.155,Avg.Loss: -0.697,LR: 4.73E-04]Training epoch 4:   1%|          | 2/341 [00:00<00:08, 40.85it/s, Epoch: 4, Batch: 3,Loss: -0.403,Avg.Loss: -0.599,LR: 4.73E-04]Training epoch 4:   1%|          | 3/341 [00:00<00:07, 46.07it/s, Epoch: 4, Batch: 4,Loss: -0.978,Avg.Loss: -0.694,LR: 4.73E-04]Training epoch 4:   1%|          | 4/341 [00:00<00:06, 48.67it/s, Epoch: 4, Batch: 5,Loss: -0.691,Avg.Loss: -0.693,LR: 4.72E-04]Training epoch 4:   1%|▏         | 5/341 [00:00<00:06, 50.11it/s, Epoch: 4, Batch: 6,Loss: -0.225,Avg.Loss: -0.615,LR: 4.72E-04]Training epoch 4:   2%|▏         | 6/341 [00:00<00:06, 50.90it/s, Epoch: 4, Batch: 7,Loss: -0.274,Avg.Loss: -0.567,LR: 4.72E-04]Training epoch 4:   2%|▏         | 7/341 [00:00<00:05, 59.29it/s, Epoch: 4, Batch: 7,Loss: -0.274,Avg.Loss: -0.567,LR: 4.72E-04]Training epoch 4:   2%|▏         | 7/341 [00:00<00:05, 59.29it/s, Epoch: 4, Batch: 8,Loss: -0.693,Avg.Loss: -0.583,LR: 4.72E-04]Training epoch 4:   2%|▏         | 8/341 [00:00<00:05, 59.29it/s, Epoch: 4, Batch: 9,Loss: -0.681,Avg.Loss: -0.593,LR: 4.72E-04]Training epoch 4:   3%|▎         | 9/341 [00:00<00:05, 59.29it/s, Epoch: 4, Batch: 10,Loss: -0.852,Avg.Loss: -0.619,LR: 4.72E-04]Training epoch 4:   3%|▎         | 10/341 [00:00<00:05, 59.29it/s, Epoch: 4, Batch: 11,Loss: -0.347,Avg.Loss: -0.595,LR: 4.72E-04]Training epoch 4:   3%|▎         | 11/341 [00:00<00:05, 59.29it/s, Epoch: 4, Batch: 12,Loss: 0.392,Avg.Loss: -0.512,LR: 4.72E-04] Training epoch 4:   4%|▎         | 12/341 [00:00<00:05, 59.29it/s, Epoch: 4, Batch: 13,Loss: -0.177,Avg.Loss: -0.487,LR: 4.72E-04]Training epoch 4:   4%|▍         | 13/341 [00:00<00:05, 56.63it/s, Epoch: 4, Batch: 13,Loss: -0.177,Avg.Loss: -0.487,LR: 4.72E-04]Training epoch 4:   4%|▍         | 13/341 [00:00<00:05, 56.63it/s, Epoch: 4, Batch: 14,Loss: -0.862,Avg.Loss: -0.513,LR: 4.72E-04]Training epoch 4:   4%|▍         | 14/341 [00:00<00:05, 56.63it/s, Epoch: 4, Batch: 15,Loss: -0.978,Avg.Loss: -0.544,LR: 4.72E-04]Training epoch 4:   4%|▍         | 15/341 [00:00<00:05, 56.63it/s, Epoch: 4, Batch: 16,Loss: -1.252,Avg.Loss: -0.589,LR: 4.72E-04]Training epoch 4:   5%|▍         | 16/341 [00:00<00:05, 56.63it/s, Epoch: 4, Batch: 17,Loss: -0.523,Avg.Loss: -0.585,LR: 4.72E-04]Training epoch 4:   5%|▍         | 17/341 [00:00<00:05, 56.63it/s, Epoch: 4, Batch: 18,Loss: -0.376,Avg.Loss: -0.573,LR: 4.72E-04]Training epoch 4:   5%|▌         | 18/341 [00:00<00:05, 56.63it/s, Epoch: 4, Batch: 19,Loss: -0.548,Avg.Loss: -0.572,LR: 4.72E-04]Training epoch 4:   6%|▌         | 19/341 [00:00<00:05, 55.32it/s, Epoch: 4, Batch: 19,Loss: -0.548,Avg.Loss: -0.572,LR: 4.72E-04]Training epoch 4:   6%|▌         | 19/341 [00:00<00:05, 55.32it/s, Epoch: 4, Batch: 20,Loss: -0.756,Avg.Loss: -0.581,LR: 4.72E-04]Training epoch 4:   6%|▌         | 20/341 [00:00<00:05, 55.32it/s, Epoch: 4, Batch: 21,Loss: -1.122,Avg.Loss: -0.607,LR: 4.72E-04]Training epoch 4:   6%|▌         | 21/341 [00:00<00:05, 55.32it/s, Epoch: 4, Batch: 22,Loss: -1.156,Avg.Loss: -0.632,LR: 4.72E-04]Training epoch 4:   6%|▋         | 22/341 [00:00<00:05, 55.32it/s, Epoch: 4, Batch: 23,Loss: -0.852,Avg.Loss: -0.641,LR: 4.72E-04]Training epoch 4:   7%|▋         | 23/341 [00:00<00:05, 55.32it/s, Epoch: 4, Batch: 24,Loss: -0.717,Avg.Loss: -0.644,LR: 4.71E-04]Training epoch 4:   7%|▋         | 24/341 [00:00<00:05, 55.32it/s, Epoch: 4, Batch: 25,Loss: -0.083,Avg.Loss: -0.622,LR: 4.71E-04]Training epoch 4:   7%|▋         | 25/341 [00:00<00:05, 53.31it/s, Epoch: 4, Batch: 25,Loss: -0.083,Avg.Loss: -0.622,LR: 4.71E-04]Training epoch 4:   7%|▋         | 25/341 [00:00<00:05, 53.31it/s, Epoch: 4, Batch: 26,Loss: -0.326,Avg.Loss: -0.611,LR: 4.71E-04]Training epoch 4:   8%|▊         | 26/341 [00:00<00:05, 53.31it/s, Epoch: 4, Batch: 27,Loss: 0.242,Avg.Loss: -0.579,LR: 4.71E-04] Training epoch 4:   8%|▊         | 27/341 [00:00<00:05, 53.31it/s, Epoch: 4, Batch: 28,Loss: 0.459,Avg.Loss: -0.542,LR: 4.71E-04]Training epoch 4:   8%|▊         | 28/341 [00:00<00:05, 53.31it/s, Epoch: 4, Batch: 29,Loss: 1.123,Avg.Loss: -0.485,LR: 4.71E-04]Training epoch 4:   9%|▊         | 29/341 [00:00<00:05, 53.31it/s, Epoch: 4, Batch: 30,Loss: -1.177,Avg.Loss: -0.508,LR: 4.71E-04]Training epoch 4:   9%|▉         | 30/341 [00:00<00:05, 53.31it/s, Epoch: 4, Batch: 31,Loss: 0.538,Avg.Loss: -0.474,LR: 4.71E-04] Training epoch 4:   9%|▉         | 31/341 [00:00<00:05, 51.75it/s, Epoch: 4, Batch: 31,Loss: 0.538,Avg.Loss: -0.474,LR: 4.71E-04]Training epoch 4:   9%|▉         | 31/341 [00:00<00:05, 51.75it/s, Epoch: 4, Batch: 32,Loss: 2.146,Avg.Loss: -0.392,LR: 4.71E-04]Training epoch 4:   9%|▉         | 32/341 [00:00<00:05, 51.75it/s, Epoch: 4, Batch: 33,Loss: 1.170,Avg.Loss: -0.345,LR: 4.71E-04]Training epoch 4:  10%|▉         | 33/341 [00:00<00:05, 51.75it/s, Epoch: 4, Batch: 34,Loss: -0.648,Avg.Loss: -0.354,LR: 4.71E-04]Training epoch 4:  10%|▉         | 34/341 [00:00<00:05, 51.75it/s, Epoch: 4, Batch: 35,Loss: 0.346,Avg.Loss: -0.334,LR: 4.71E-04] Training epoch 4:  10%|█         | 35/341 [00:00<00:05, 51.75it/s, Epoch: 4, Batch: 36,Loss: 1.107,Avg.Loss: -0.294,LR: 4.71E-04]Training epoch 4:  11%|█         | 36/341 [00:00<00:05, 51.75it/s, Epoch: 4, Batch: 37,Loss: -0.079,Avg.Loss: -0.288,LR: 4.71E-04]Training epoch 4:  11%|█         | 37/341 [00:00<00:05, 52.06it/s, Epoch: 4, Batch: 37,Loss: -0.079,Avg.Loss: -0.288,LR: 4.71E-04]Training epoch 4:  11%|█         | 37/341 [00:00<00:05, 52.06it/s, Epoch: 4, Batch: 38,Loss: -1.305,Avg.Loss: -0.315,LR: 4.71E-04]Training epoch 4:  11%|█         | 38/341 [00:00<00:05, 52.06it/s, Epoch: 4, Batch: 39,Loss: 1.067,Avg.Loss: -0.279,LR: 4.71E-04] Training epoch 4:  11%|█▏        | 39/341 [00:00<00:05, 52.06it/s, Epoch: 4, Batch: 40,Loss: 3.119,Avg.Loss: -0.194,LR: 4.71E-04]Training epoch 4:  12%|█▏        | 40/341 [00:00<00:05, 52.06it/s, Epoch: 4, Batch: 41,Loss: 2.605,Avg.Loss: -0.126,LR: 4.71E-04]Training epoch 4:  12%|█▏        | 41/341 [00:00<00:05, 52.06it/s, Epoch: 4, Batch: 42,Loss: 1.242,Avg.Loss: -0.093,LR: 4.71E-04]Training epoch 4:  12%|█▏        | 42/341 [00:00<00:05, 52.06it/s, Epoch: 4, Batch: 43,Loss: -0.113,Avg.Loss: -0.094,LR: 4.70E-04]Training epoch 4:  13%|█▎        | 43/341 [00:00<00:05, 52.55it/s, Epoch: 4, Batch: 43,Loss: -0.113,Avg.Loss: -0.094,LR: 4.70E-04]Training epoch 4:  13%|█▎        | 43/341 [00:00<00:05, 52.55it/s, Epoch: 4, Batch: 44,Loss: 0.384,Avg.Loss: -0.083,LR: 4.70E-04] Training epoch 4:  13%|█▎        | 44/341 [00:00<00:05, 52.55it/s, Epoch: 4, Batch: 45,Loss: -0.143,Avg.Loss: -0.084,LR: 4.70E-04]Training epoch 4:  13%|█▎        | 45/341 [00:00<00:05, 52.55it/s, Epoch: 4, Batch: 46,Loss: -0.741,Avg.Loss: -0.099,LR: 4.70E-04]Training epoch 4:  13%|█▎        | 46/341 [00:00<00:05, 52.55it/s, Epoch: 4, Batch: 47,Loss: -0.348,Avg.Loss: -0.104,LR: 4.70E-04]Training epoch 4:  14%|█▍        | 47/341 [00:00<00:05, 52.55it/s, Epoch: 4, Batch: 48,Loss: 0.702,Avg.Loss: -0.087,LR: 4.70E-04] Training epoch 4:  14%|█▍        | 48/341 [00:00<00:05, 52.55it/s, Epoch: 4, Batch: 49,Loss: 0.497,Avg.Loss: -0.075,LR: 4.70E-04]Training epoch 4:  14%|█▍        | 49/341 [00:00<00:05, 52.48it/s, Epoch: 4, Batch: 49,Loss: 0.497,Avg.Loss: -0.075,LR: 4.70E-04]Training epoch 4:  14%|█▍        | 49/341 [00:00<00:05, 52.48it/s, Epoch: 4, Batch: 50,Loss: -0.558,Avg.Loss: -0.085,LR: 4.70E-04]Training epoch 4:  15%|█▍        | 50/341 [00:00<00:05, 52.48it/s, Epoch: 4, Batch: 51,Loss: 0.104,Avg.Loss: -0.081,LR: 4.70E-04] Training epoch 4:  15%|█▍        | 51/341 [00:00<00:05, 52.48it/s, Epoch: 4, Batch: 52,Loss: 0.691,Avg.Loss: -0.066,LR: 4.70E-04]Training epoch 4:  15%|█▌        | 52/341 [00:00<00:05, 52.48it/s, Epoch: 4, Batch: 53,Loss: -0.410,Avg.Loss: -0.073,LR: 4.70E-04]Training epoch 4:  16%|█▌        | 53/341 [00:01<00:05, 52.48it/s, Epoch: 4, Batch: 54,Loss: -0.792,Avg.Loss: -0.086,LR: 4.70E-04]Training epoch 4:  16%|█▌        | 54/341 [00:01<00:05, 52.48it/s, Epoch: 4, Batch: 55,Loss: 0.273,Avg.Loss: -0.080,LR: 4.70E-04] Training epoch 4:  16%|█▌        | 55/341 [00:01<00:05, 52.64it/s, Epoch: 4, Batch: 55,Loss: 0.273,Avg.Loss: -0.080,LR: 4.70E-04]Training epoch 4:  16%|█▌        | 55/341 [00:01<00:05, 52.64it/s, Epoch: 4, Batch: 56,Loss: 1.505,Avg.Loss: -0.051,LR: 4.70E-04]Training epoch 4:  16%|█▋        | 56/341 [00:01<00:05, 52.64it/s, Epoch: 4, Batch: 57,Loss: 0.038,Avg.Loss: -0.050,LR: 4.70E-04]Training epoch 4:  17%|█▋        | 57/341 [00:01<00:05, 52.64it/s, Epoch: 4, Batch: 58,Loss: -0.785,Avg.Loss: -0.062,LR: 4.70E-04]Training epoch 4:  17%|█▋        | 58/341 [00:01<00:05, 52.64it/s, Epoch: 4, Batch: 59,Loss: 0.197,Avg.Loss: -0.058,LR: 4.70E-04] Training epoch 4:  17%|█▋        | 59/341 [00:01<00:05, 52.64it/s, Epoch: 4, Batch: 60,Loss: 0.827,Avg.Loss: -0.043,LR: 4.70E-04]Training epoch 4:  18%|█▊        | 60/341 [00:01<00:05, 52.64it/s, Epoch: 4, Batch: 61,Loss: 0.671,Avg.Loss: -0.031,LR: 4.69E-04]Training epoch 4:  18%|█▊        | 61/341 [00:01<00:05, 52.29it/s, Epoch: 4, Batch: 61,Loss: 0.671,Avg.Loss: -0.031,LR: 4.69E-04]Training epoch 4:  18%|█▊        | 61/341 [00:01<00:05, 52.29it/s, Epoch: 4, Batch: 62,Loss: -0.255,Avg.Loss: -0.035,LR: 4.69E-04]Training epoch 4:  18%|█▊        | 62/341 [00:01<00:05, 52.29it/s, Epoch: 4, Batch: 63,Loss: -0.057,Avg.Loss: -0.035,LR: 4.69E-04]Training epoch 4:  18%|█▊        | 63/341 [00:01<00:05, 52.29it/s, Epoch: 4, Batch: 64,Loss: 2.501,Avg.Loss: 0.004,LR: 4.69E-04]  Training epoch 4:  19%|█▉        | 64/341 [00:01<00:05, 52.29it/s, Epoch: 4, Batch: 65,Loss: 1.913,Avg.Loss: 0.034,LR: 4.69E-04]Training epoch 4:  19%|█▉        | 65/341 [00:01<00:05, 52.29it/s, Epoch: 4, Batch: 66,Loss: 0.461,Avg.Loss: 0.040,LR: 4.69E-04]Training epoch 4:  19%|█▉        | 66/341 [00:01<00:05, 52.29it/s, Epoch: 4, Batch: 67,Loss: -0.633,Avg.Loss: 0.030,LR: 4.69E-04]Training epoch 4:  20%|█▉        | 67/341 [00:01<00:05, 52.45it/s, Epoch: 4, Batch: 67,Loss: -0.633,Avg.Loss: 0.030,LR: 4.69E-04]Training epoch 4:  20%|█▉        | 67/341 [00:01<00:05, 52.45it/s, Epoch: 4, Batch: 68,Loss: -0.194,Avg.Loss: 0.027,LR: 4.69E-04]Training epoch 4:  20%|█▉        | 68/341 [00:01<00:05, 52.45it/s, Epoch: 4, Batch: 69,Loss: -0.777,Avg.Loss: 0.015,LR: 4.69E-04]Training epoch 4:  20%|██        | 69/341 [00:01<00:05, 52.45it/s, Epoch: 4, Batch: 70,Loss: -0.806,Avg.Loss: 0.003,LR: 4.69E-04]Training epoch 4:  21%|██        | 70/341 [00:01<00:05, 52.45it/s, Epoch: 4, Batch: 71,Loss: -0.869,Avg.Loss: -0.009,LR: 4.69E-04]Training epoch 4:  21%|██        | 71/341 [00:01<00:05, 52.45it/s, Epoch: 4, Batch: 72,Loss: -0.834,Avg.Loss: -0.020,LR: 4.69E-04]Training epoch 4:  21%|██        | 72/341 [00:01<00:05, 52.45it/s, Epoch: 4, Batch: 73,Loss: -0.664,Avg.Loss: -0.029,LR: 4.69E-04]Training epoch 4:  21%|██▏       | 73/341 [00:01<00:05, 51.74it/s, Epoch: 4, Batch: 73,Loss: -0.664,Avg.Loss: -0.029,LR: 4.69E-04]Training epoch 4:  21%|██▏       | 73/341 [00:01<00:05, 51.74it/s, Epoch: 4, Batch: 74,Loss: -0.698,Avg.Loss: -0.038,LR: 4.69E-04]Training epoch 4:  22%|██▏       | 74/341 [00:01<00:05, 51.74it/s, Epoch: 4, Batch: 75,Loss: -1.196,Avg.Loss: -0.054,LR: 4.69E-04]Training epoch 4:  22%|██▏       | 75/341 [00:01<00:05, 51.74it/s, Epoch: 4, Batch: 76,Loss: -0.911,Avg.Loss: -0.065,LR: 4.69E-04]Training epoch 4:  22%|██▏       | 76/341 [00:01<00:05, 51.74it/s, Epoch: 4, Batch: 77,Loss: -1.070,Avg.Loss: -0.078,LR: 4.69E-04]Training epoch 4:  23%|██▎       | 77/341 [00:01<00:05, 51.74it/s, Epoch: 4, Batch: 78,Loss: -0.803,Avg.Loss: -0.087,LR: 4.69E-04]Training epoch 4:  23%|██▎       | 78/341 [00:01<00:05, 51.74it/s, Epoch: 4, Batch: 79,Loss: -0.852,Avg.Loss: -0.097,LR: 4.68E-04]Training epoch 4:  23%|██▎       | 79/341 [00:01<00:05, 51.82it/s, Epoch: 4, Batch: 79,Loss: -0.852,Avg.Loss: -0.097,LR: 4.68E-04]Training epoch 4:  23%|██▎       | 79/341 [00:01<00:05, 51.82it/s, Epoch: 4, Batch: 80,Loss: -1.142,Avg.Loss: -0.110,LR: 4.68E-04]Training epoch 4:  23%|██▎       | 80/341 [00:01<00:05, 51.82it/s, Epoch: 4, Batch: 81,Loss: -0.796,Avg.Loss: -0.119,LR: 4.68E-04]Training epoch 4:  24%|██▍       | 81/341 [00:01<00:05, 51.82it/s, Epoch: 4, Batch: 82,Loss: -0.796,Avg.Loss: -0.127,LR: 4.68E-04]Training epoch 4:  24%|██▍       | 82/341 [00:01<00:04, 51.82it/s, Epoch: 4, Batch: 83,Loss: -1.007,Avg.Loss: -0.137,LR: 4.68E-04]Training epoch 4:  24%|██▍       | 83/341 [00:01<00:04, 51.82it/s, Epoch: 4, Batch: 84,Loss: -0.904,Avg.Loss: -0.147,LR: 4.68E-04]Training epoch 4:  25%|██▍       | 84/341 [00:01<00:04, 51.82it/s, Epoch: 4, Batch: 85,Loss: -0.711,Avg.Loss: -0.153,LR: 4.68E-04]Training epoch 4:  25%|██▍       | 85/341 [00:01<00:04, 52.10it/s, Epoch: 4, Batch: 85,Loss: -0.711,Avg.Loss: -0.153,LR: 4.68E-04]Training epoch 4:  25%|██▍       | 85/341 [00:01<00:04, 52.10it/s, Epoch: 4, Batch: 86,Loss: -0.976,Avg.Loss: -0.163,LR: 4.68E-04]Training epoch 4:  25%|██▌       | 86/341 [00:01<00:04, 52.10it/s, Epoch: 4, Batch: 87,Loss: -0.640,Avg.Loss: -0.168,LR: 4.68E-04]Training epoch 4:  26%|██▌       | 87/341 [00:01<00:04, 52.10it/s, Epoch: 4, Batch: 88,Loss: -0.852,Avg.Loss: -0.176,LR: 4.68E-04]Training epoch 4:  26%|██▌       | 88/341 [00:01<00:04, 52.10it/s, Epoch: 4, Batch: 89,Loss: -1.079,Avg.Loss: -0.186,LR: 4.68E-04]Training epoch 4:  26%|██▌       | 89/341 [00:01<00:04, 52.10it/s, Epoch: 4, Batch: 90,Loss: -0.756,Avg.Loss: -0.192,LR: 4.68E-04]Training epoch 4:  26%|██▋       | 90/341 [00:01<00:04, 52.10it/s, Epoch: 4, Batch: 91,Loss: -0.978,Avg.Loss: -0.201,LR: 4.68E-04]Training epoch 4:  27%|██▋       | 91/341 [00:01<00:04, 52.85it/s, Epoch: 4, Batch: 91,Loss: -0.978,Avg.Loss: -0.201,LR: 4.68E-04]Training epoch 4:  27%|██▋       | 91/341 [00:01<00:04, 52.85it/s, Epoch: 4, Batch: 92,Loss: -0.785,Avg.Loss: -0.207,LR: 4.68E-04]Training epoch 4:  27%|██▋       | 92/341 [00:01<00:04, 52.85it/s, Epoch: 4, Batch: 93,Loss: -0.852,Avg.Loss: -0.214,LR: 4.68E-04]Training epoch 4:  27%|██▋       | 93/341 [00:01<00:04, 52.85it/s, Epoch: 4, Batch: 94,Loss: -0.885,Avg.Loss: -0.222,LR: 4.68E-04]Training epoch 4:  28%|██▊       | 94/341 [00:01<00:04, 52.85it/s, Epoch: 4, Batch: 95,Loss: -0.945,Avg.Loss: -0.229,LR: 4.68E-04]Training epoch 4:  28%|██▊       | 95/341 [00:01<00:04, 52.85it/s, Epoch: 4, Batch: 96,Loss: -0.856,Avg.Loss: -0.236,LR: 4.68E-04]Training epoch 4:  28%|██▊       | 96/341 [00:01<00:04, 52.85it/s, Epoch: 4, Batch: 97,Loss: -1.264,Avg.Loss: -0.246,LR: 4.67E-04]Training epoch 4:  28%|██▊       | 97/341 [00:01<00:04, 53.36it/s, Epoch: 4, Batch: 97,Loss: -1.264,Avg.Loss: -0.246,LR: 4.67E-04]Training epoch 4:  28%|██▊       | 97/341 [00:01<00:04, 53.36it/s, Epoch: 4, Batch: 98,Loss: -0.595,Avg.Loss: -0.250,LR: 4.67E-04]Training epoch 4:  29%|██▊       | 98/341 [00:01<00:04, 53.36it/s, Epoch: 4, Batch: 99,Loss: -0.539,Avg.Loss: -0.253,LR: 4.67E-04]Training epoch 4:  29%|██▉       | 99/341 [00:01<00:04, 53.36it/s, Epoch: 4, Batch: 100,Loss: -0.301,Avg.Loss: -0.253,LR: 4.67E-04]Training epoch 4:  29%|██▉       | 100/341 [00:01<00:04, 53.36it/s, Epoch: 4, Batch: 101,Loss: -1.265,Avg.Loss: -0.263,LR: 4.67E-04]Training epoch 4:  30%|██▉       | 101/341 [00:01<00:04, 53.36it/s, Epoch: 4, Batch: 102,Loss: -1.290,Avg.Loss: -0.273,LR: 4.67E-04]Training epoch 4:  30%|██▉       | 102/341 [00:01<00:04, 53.36it/s, Epoch: 4, Batch: 103,Loss: -1.320,Avg.Loss: -0.283,LR: 4.67E-04]Training epoch 4:  30%|███       | 103/341 [00:01<00:04, 53.28it/s, Epoch: 4, Batch: 103,Loss: -1.320,Avg.Loss: -0.283,LR: 4.67E-04]Training epoch 4:  30%|███       | 103/341 [00:01<00:04, 53.28it/s, Epoch: 4, Batch: 104,Loss: -0.748,Avg.Loss: -0.288,LR: 4.67E-04]Training epoch 4:  30%|███       | 104/341 [00:01<00:04, 53.28it/s, Epoch: 4, Batch: 105,Loss: -1.293,Avg.Loss: -0.298,LR: 4.67E-04]Training epoch 4:  31%|███       | 105/341 [00:02<00:04, 53.28it/s, Epoch: 4, Batch: 106,Loss: -0.945,Avg.Loss: -0.304,LR: 4.67E-04]Training epoch 4:  31%|███       | 106/341 [00:02<00:04, 53.28it/s, Epoch: 4, Batch: 107,Loss: -0.578,Avg.Loss: -0.306,LR: 4.67E-04]Training epoch 4:  31%|███▏      | 107/341 [00:02<00:04, 53.28it/s, Epoch: 4, Batch: 108,Loss: -1.049,Avg.Loss: -0.313,LR: 4.67E-04]Training epoch 4:  32%|███▏      | 108/341 [00:02<00:04, 53.28it/s, Epoch: 4, Batch: 109,Loss: 0.033,Avg.Loss: -0.310,LR: 4.67E-04] Training epoch 4:  32%|███▏      | 109/341 [00:02<00:04, 52.85it/s, Epoch: 4, Batch: 109,Loss: 0.033,Avg.Loss: -0.310,LR: 4.67E-04]Training epoch 4:  32%|███▏      | 109/341 [00:02<00:04, 52.85it/s, Epoch: 4, Batch: 110,Loss: 1.125,Avg.Loss: -0.297,LR: 4.67E-04]Training epoch 4:  32%|███▏      | 110/341 [00:02<00:04, 52.85it/s, Epoch: 4, Batch: 111,Loss: 0.451,Avg.Loss: -0.290,LR: 4.67E-04]Training epoch 4:  33%|███▎      | 111/341 [00:02<00:04, 52.85it/s, Epoch: 4, Batch: 112,Loss: -1.196,Avg.Loss: -0.298,LR: 4.67E-04]Training epoch 4:  33%|███▎      | 112/341 [00:02<00:04, 52.85it/s, Epoch: 4, Batch: 113,Loss: 2.005,Avg.Loss: -0.278,LR: 4.67E-04] Training epoch 4:  33%|███▎      | 113/341 [00:02<00:04, 52.85it/s, Epoch: 4, Batch: 114,Loss: 4.761,Avg.Loss: -0.234,LR: 4.66E-04]Training epoch 4:  33%|███▎      | 114/341 [00:02<00:04, 52.85it/s, Epoch: 4, Batch: 115,Loss: 4.948,Avg.Loss: -0.189,LR: 4.66E-04]Training epoch 4:  34%|███▎      | 115/341 [00:02<00:04, 52.83it/s, Epoch: 4, Batch: 115,Loss: 4.948,Avg.Loss: -0.189,LR: 4.66E-04]Training epoch 4:  34%|███▎      | 115/341 [00:02<00:04, 52.83it/s, Epoch: 4, Batch: 116,Loss: 0.151,Avg.Loss: -0.186,LR: 4.66E-04]Training epoch 4:  34%|███▍      | 116/341 [00:02<00:04, 52.83it/s, Epoch: 4, Batch: 117,Loss: -0.836,Avg.Loss: -0.191,LR: 4.66E-04]Training epoch 4:  34%|███▍      | 117/341 [00:02<00:04, 52.83it/s, Epoch: 4, Batch: 118,Loss: -0.005,Avg.Loss: -0.190,LR: 4.66E-04]Training epoch 4:  35%|███▍      | 118/341 [00:02<00:04, 52.83it/s, Epoch: 4, Batch: 119,Loss: -0.496,Avg.Loss: -0.192,LR: 4.66E-04]Training epoch 4:  35%|███▍      | 119/341 [00:02<00:04, 52.83it/s, Epoch: 4, Batch: 120,Loss: -1.162,Avg.Loss: -0.200,LR: 4.66E-04]Training epoch 4:  35%|███▌      | 120/341 [00:02<00:04, 52.83it/s, Epoch: 4, Batch: 121,Loss: -1.340,Avg.Loss: -0.210,LR: 4.66E-04]Training epoch 4:  35%|███▌      | 121/341 [00:02<00:04, 52.52it/s, Epoch: 4, Batch: 121,Loss: -1.340,Avg.Loss: -0.210,LR: 4.66E-04]Training epoch 4:  35%|███▌      | 121/341 [00:02<00:04, 52.52it/s, Epoch: 4, Batch: 122,Loss: -0.929,Avg.Loss: -0.216,LR: 4.66E-04]Training epoch 4:  36%|███▌      | 122/341 [00:02<00:04, 52.52it/s, Epoch: 4, Batch: 123,Loss: -1.103,Avg.Loss: -0.223,LR: 4.66E-04]Training epoch 4:  36%|███▌      | 123/341 [00:02<00:04, 52.52it/s, Epoch: 4, Batch: 124,Loss: -1.246,Avg.Loss: -0.231,LR: 4.66E-04]Training epoch 4:  36%|███▋      | 124/341 [00:02<00:04, 52.52it/s, Epoch: 4, Batch: 125,Loss: -1.101,Avg.Loss: -0.238,LR: 4.66E-04]Training epoch 4:  37%|███▋      | 125/341 [00:02<00:04, 52.52it/s, Epoch: 4, Batch: 126,Loss: -0.724,Avg.Loss: -0.242,LR: 4.66E-04]Training epoch 4:  37%|███▋      | 126/341 [00:02<00:04, 52.52it/s, Epoch: 4, Batch: 127,Loss: -0.853,Avg.Loss: -0.247,LR: 4.66E-04]Training epoch 4:  37%|███▋      | 127/341 [00:02<00:04, 52.38it/s, Epoch: 4, Batch: 127,Loss: -0.853,Avg.Loss: -0.247,LR: 4.66E-04]Training epoch 4:  37%|███▋      | 127/341 [00:02<00:04, 52.38it/s, Epoch: 4, Batch: 128,Loss: -0.901,Avg.Loss: -0.252,LR: 4.66E-04]Training epoch 4:  38%|███▊      | 128/341 [00:02<00:04, 52.38it/s, Epoch: 4, Batch: 129,Loss: -1.248,Avg.Loss: -0.260,LR: 4.66E-04]Training epoch 4:  38%|███▊      | 129/341 [00:02<00:04, 52.38it/s, Epoch: 4, Batch: 130,Loss: -1.257,Avg.Loss: -0.267,LR: 4.66E-04]Training epoch 4:  38%|███▊      | 130/341 [00:02<00:04, 52.38it/s, Epoch: 4, Batch: 131,Loss: -1.044,Avg.Loss: -0.273,LR: 4.66E-04]Training epoch 4:  38%|███▊      | 131/341 [00:02<00:04, 52.38it/s, Epoch: 4, Batch: 132,Loss: -0.874,Avg.Loss: -0.278,LR: 4.65E-04]Training epoch 4:  39%|███▊      | 132/341 [00:02<00:03, 52.38it/s, Epoch: 4, Batch: 133,Loss: -1.182,Avg.Loss: -0.284,LR: 4.65E-04]Training epoch 4:  39%|███▉      | 133/341 [00:02<00:03, 52.69it/s, Epoch: 4, Batch: 133,Loss: -1.182,Avg.Loss: -0.284,LR: 4.65E-04]Training epoch 4:  39%|███▉      | 133/341 [00:02<00:03, 52.69it/s, Epoch: 4, Batch: 134,Loss: -0.877,Avg.Loss: -0.289,LR: 4.65E-04]Training epoch 4:  39%|███▉      | 134/341 [00:02<00:03, 52.69it/s, Epoch: 4, Batch: 135,Loss: -0.554,Avg.Loss: -0.291,LR: 4.65E-04]Training epoch 4:  40%|███▉      | 135/341 [00:02<00:03, 52.69it/s, Epoch: 4, Batch: 136,Loss: -1.183,Avg.Loss: -0.297,LR: 4.65E-04]Training epoch 4:  40%|███▉      | 136/341 [00:02<00:03, 52.69it/s, Epoch: 4, Batch: 137,Loss: -0.927,Avg.Loss: -0.302,LR: 4.65E-04]Training epoch 4:  40%|████      | 137/341 [00:02<00:03, 52.69it/s, Epoch: 4, Batch: 138,Loss: -1.092,Avg.Loss: -0.308,LR: 4.65E-04]Training epoch 4:  40%|████      | 138/341 [00:02<00:03, 52.69it/s, Epoch: 4, Batch: 139,Loss: -0.897,Avg.Loss: -0.312,LR: 4.65E-04]Training epoch 4:  41%|████      | 139/341 [00:02<00:03, 52.15it/s, Epoch: 4, Batch: 139,Loss: -0.897,Avg.Loss: -0.312,LR: 4.65E-04]Training epoch 4:  41%|████      | 139/341 [00:02<00:03, 52.15it/s, Epoch: 4, Batch: 140,Loss: -1.301,Avg.Loss: -0.319,LR: 4.65E-04]Training epoch 4:  41%|████      | 140/341 [00:02<00:03, 52.15it/s, Epoch: 4, Batch: 141,Loss: -1.169,Avg.Loss: -0.325,LR: 4.65E-04]Training epoch 4:  41%|████▏     | 141/341 [00:02<00:03, 52.15it/s, Epoch: 4, Batch: 142,Loss: -0.981,Avg.Loss: -0.330,LR: 4.65E-04]Training epoch 4:  42%|████▏     | 142/341 [00:02<00:03, 52.15it/s, Epoch: 4, Batch: 143,Loss: -1.025,Avg.Loss: -0.335,LR: 4.65E-04]Training epoch 4:  42%|████▏     | 143/341 [00:02<00:03, 52.15it/s, Epoch: 4, Batch: 144,Loss: -1.034,Avg.Loss: -0.339,LR: 4.65E-04]Training epoch 4:  42%|████▏     | 144/341 [00:02<00:03, 52.15it/s, Epoch: 4, Batch: 145,Loss: -0.962,Avg.Loss: -0.344,LR: 4.65E-04]Training epoch 4:  43%|████▎     | 145/341 [00:02<00:03, 51.92it/s, Epoch: 4, Batch: 145,Loss: -0.962,Avg.Loss: -0.344,LR: 4.65E-04]Training epoch 4:  43%|████▎     | 145/341 [00:02<00:03, 51.92it/s, Epoch: 4, Batch: 146,Loss: -1.044,Avg.Loss: -0.348,LR: 4.65E-04]Training epoch 4:  43%|████▎     | 146/341 [00:02<00:03, 51.92it/s, Epoch: 4, Batch: 147,Loss: -1.361,Avg.Loss: -0.355,LR: 4.65E-04]Training epoch 4:  43%|████▎     | 147/341 [00:02<00:03, 51.92it/s, Epoch: 4, Batch: 148,Loss: -0.948,Avg.Loss: -0.359,LR: 4.65E-04]Training epoch 4:  43%|████▎     | 148/341 [00:02<00:03, 51.92it/s, Epoch: 4, Batch: 149,Loss: -1.056,Avg.Loss: -0.364,LR: 4.64E-04]Training epoch 4:  44%|████▎     | 149/341 [00:02<00:03, 51.92it/s, Epoch: 4, Batch: 150,Loss: -1.051,Avg.Loss: -0.369,LR: 4.64E-04]Training epoch 4:  44%|████▍     | 150/341 [00:02<00:03, 51.92it/s, Epoch: 4, Batch: 151,Loss: -1.117,Avg.Loss: -0.374,LR: 4.64E-04]Training epoch 4:  44%|████▍     | 151/341 [00:02<00:03, 51.41it/s, Epoch: 4, Batch: 151,Loss: -1.117,Avg.Loss: -0.374,LR: 4.64E-04]Training epoch 4:  44%|████▍     | 151/341 [00:02<00:03, 51.41it/s, Epoch: 4, Batch: 152,Loss: -0.769,Avg.Loss: -0.376,LR: 4.64E-04]Training epoch 4:  45%|████▍     | 152/341 [00:02<00:03, 51.41it/s, Epoch: 4, Batch: 153,Loss: -0.340,Avg.Loss: -0.376,LR: 4.64E-04]Training epoch 4:  45%|████▍     | 153/341 [00:02<00:03, 51.41it/s, Epoch: 4, Batch: 154,Loss: -0.799,Avg.Loss: -0.379,LR: 4.64E-04]Training epoch 4:  45%|████▌     | 154/341 [00:02<00:03, 51.41it/s, Epoch: 4, Batch: 155,Loss: -0.300,Avg.Loss: -0.378,LR: 4.64E-04]Training epoch 4:  45%|████▌     | 155/341 [00:02<00:03, 51.41it/s, Epoch: 4, Batch: 156,Loss: -0.729,Avg.Loss: -0.380,LR: 4.64E-04]Training epoch 4:  46%|████▌     | 156/341 [00:02<00:03, 51.41it/s, Epoch: 4, Batch: 157,Loss: -1.013,Avg.Loss: -0.384,LR: 4.64E-04]Training epoch 4:  46%|████▌     | 157/341 [00:02<00:03, 51.43it/s, Epoch: 4, Batch: 157,Loss: -1.013,Avg.Loss: -0.384,LR: 4.64E-04]Training epoch 4:  46%|████▌     | 157/341 [00:03<00:03, 51.43it/s, Epoch: 4, Batch: 158,Loss: -0.268,Avg.Loss: -0.384,LR: 4.64E-04]Training epoch 4:  46%|████▋     | 158/341 [00:03<00:03, 51.43it/s, Epoch: 4, Batch: 159,Loss: -1.108,Avg.Loss: -0.388,LR: 4.64E-04]Training epoch 4:  47%|████▋     | 159/341 [00:03<00:03, 51.43it/s, Epoch: 4, Batch: 160,Loss: -0.630,Avg.Loss: -0.390,LR: 4.64E-04]Training epoch 4:  47%|████▋     | 160/341 [00:03<00:03, 51.43it/s, Epoch: 4, Batch: 161,Loss: 0.034,Avg.Loss: -0.387,LR: 4.64E-04] Training epoch 4:  47%|████▋     | 161/341 [00:03<00:03, 51.43it/s, Epoch: 4, Batch: 162,Loss: 0.005,Avg.Loss: -0.385,LR: 4.64E-04]Training epoch 4:  48%|████▊     | 162/341 [00:03<00:03, 51.43it/s, Epoch: 4, Batch: 163,Loss: 0.023,Avg.Loss: -0.382,LR: 4.64E-04]Training epoch 4:  48%|████▊     | 163/341 [00:03<00:03, 51.56it/s, Epoch: 4, Batch: 163,Loss: 0.023,Avg.Loss: -0.382,LR: 4.64E-04]Training epoch 4:  48%|████▊     | 163/341 [00:03<00:03, 51.56it/s, Epoch: 4, Batch: 164,Loss: 0.002,Avg.Loss: -0.380,LR: 4.64E-04]Training epoch 4:  48%|████▊     | 164/341 [00:03<00:03, 51.56it/s, Epoch: 4, Batch: 165,Loss: -0.684,Avg.Loss: -0.382,LR: 4.63E-04]Training epoch 4:  48%|████▊     | 165/341 [00:03<00:03, 51.56it/s, Epoch: 4, Batch: 166,Loss: -0.251,Avg.Loss: -0.381,LR: 4.63E-04]Training epoch 4:  49%|████▊     | 166/341 [00:03<00:03, 51.56it/s, Epoch: 4, Batch: 167,Loss: 1.152,Avg.Loss: -0.372,LR: 4.63E-04] Training epoch 4:  49%|████▉     | 167/341 [00:03<00:03, 51.56it/s, Epoch: 4, Batch: 168,Loss: 0.991,Avg.Loss: -0.364,LR: 4.63E-04]Training epoch 4:  49%|████▉     | 168/341 [00:03<00:03, 51.56it/s, Epoch: 4, Batch: 169,Loss: -0.242,Avg.Loss: -0.363,LR: 4.63E-04]Training epoch 4:  50%|████▉     | 169/341 [00:03<00:03, 51.12it/s, Epoch: 4, Batch: 169,Loss: -0.242,Avg.Loss: -0.363,LR: 4.63E-04]Training epoch 4:  50%|████▉     | 169/341 [00:03<00:03, 51.12it/s, Epoch: 4, Batch: 170,Loss: 1.509,Avg.Loss: -0.352,LR: 4.63E-04] Training epoch 4:  50%|████▉     | 170/341 [00:03<00:03, 51.12it/s, Epoch: 4, Batch: 171,Loss: 4.753,Avg.Loss: -0.322,LR: 4.63E-04]Training epoch 4:  50%|█████     | 171/341 [00:03<00:03, 51.12it/s, Epoch: 4, Batch: 172,Loss: 3.600,Avg.Loss: -0.299,LR: 4.63E-04]Training epoch 4:  50%|█████     | 172/341 [00:03<00:03, 51.12it/s, Epoch: 4, Batch: 173,Loss: 1.270,Avg.Loss: -0.290,LR: 4.63E-04]Training epoch 4:  51%|█████     | 173/341 [00:03<00:03, 51.12it/s, Epoch: 4, Batch: 174,Loss: -0.354,Avg.Loss: -0.291,LR: 4.63E-04]Training epoch 4:  51%|█████     | 174/341 [00:03<00:03, 51.12it/s, Epoch: 4, Batch: 175,Loss: -0.126,Avg.Loss: -0.290,LR: 4.63E-04]Training epoch 4:  51%|█████▏    | 175/341 [00:03<00:03, 50.65it/s, Epoch: 4, Batch: 175,Loss: -0.126,Avg.Loss: -0.290,LR: 4.63E-04]Training epoch 4:  51%|█████▏    | 175/341 [00:03<00:03, 50.65it/s, Epoch: 4, Batch: 176,Loss: 0.868,Avg.Loss: -0.283,LR: 4.63E-04] Training epoch 4:  52%|█████▏    | 176/341 [00:03<00:03, 50.65it/s, Epoch: 4, Batch: 177,Loss: -0.169,Avg.Loss: -0.282,LR: 4.63E-04]Training epoch 4:  52%|█████▏    | 177/341 [00:03<00:03, 50.65it/s, Epoch: 4, Batch: 178,Loss: -0.553,Avg.Loss: -0.284,LR: 4.63E-04]Training epoch 4:  52%|█████▏    | 178/341 [00:03<00:03, 50.65it/s, Epoch: 4, Batch: 179,Loss: -0.503,Avg.Loss: -0.285,LR: 4.63E-04]Training epoch 4:  52%|█████▏    | 179/341 [00:03<00:03, 50.65it/s, Epoch: 4, Batch: 180,Loss: -0.788,Avg.Loss: -0.288,LR: 4.63E-04]Training epoch 4:  53%|█████▎    | 180/341 [00:03<00:03, 50.65it/s, Epoch: 4, Batch: 181,Loss: -1.153,Avg.Loss: -0.293,LR: 4.63E-04]Training epoch 4:  53%|█████▎    | 181/341 [00:03<00:03, 50.85it/s, Epoch: 4, Batch: 181,Loss: -1.153,Avg.Loss: -0.293,LR: 4.63E-04]Training epoch 4:  53%|█████▎    | 181/341 [00:03<00:03, 50.85it/s, Epoch: 4, Batch: 182,Loss: -1.043,Avg.Loss: -0.297,LR: 4.62E-04]Training epoch 4:  53%|█████▎    | 182/341 [00:03<00:03, 50.85it/s, Epoch: 4, Batch: 183,Loss: -1.109,Avg.Loss: -0.301,LR: 4.62E-04]Training epoch 4:  54%|█████▎    | 183/341 [00:03<00:03, 50.85it/s, Epoch: 4, Batch: 184,Loss: -0.722,Avg.Loss: -0.304,LR: 4.62E-04]Training epoch 4:  54%|█████▍    | 184/341 [00:03<00:03, 50.85it/s, Epoch: 4, Batch: 185,Loss: -0.767,Avg.Loss: -0.306,LR: 4.62E-04]Training epoch 4:  54%|█████▍    | 185/341 [00:03<00:03, 50.85it/s, Epoch: 4, Batch: 186,Loss: -0.646,Avg.Loss: -0.308,LR: 4.62E-04]Training epoch 4:  55%|█████▍    | 186/341 [00:03<00:03, 50.85it/s, Epoch: 4, Batch: 187,Loss: -0.996,Avg.Loss: -0.312,LR: 4.62E-04]Training epoch 4:  55%|█████▍    | 187/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 187,Loss: -0.996,Avg.Loss: -0.312,LR: 4.62E-04]Training epoch 4:  55%|█████▍    | 187/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 188,Loss: 0.236,Avg.Loss: -0.309,LR: 4.62E-04] Training epoch 4:  55%|█████▌    | 188/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 189,Loss: 0.575,Avg.Loss: -0.304,LR: 4.62E-04]Training epoch 4:  55%|█████▌    | 189/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 190,Loss: -0.206,Avg.Loss: -0.303,LR: 4.62E-04]Training epoch 4:  56%|█████▌    | 190/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 191,Loss: -0.893,Avg.Loss: -0.307,LR: 4.62E-04]Training epoch 4:  56%|█████▌    | 191/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 192,Loss: -0.850,Avg.Loss: -0.309,LR: 4.62E-04]Training epoch 4:  56%|█████▋    | 192/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 193,Loss: -0.560,Avg.Loss: -0.311,LR: 4.62E-04]Training epoch 4:  57%|█████▋    | 193/341 [00:03<00:02, 51.32it/s, Epoch: 4, Batch: 193,Loss: -0.560,Avg.Loss: -0.311,LR: 4.62E-04]Training epoch 4:  57%|█████▋    | 193/341 [00:03<00:02, 51.32it/s, Epoch: 4, Batch: 194,Loss: -1.090,Avg.Loss: -0.315,LR: 4.62E-04]Training epoch 4:  57%|█████▋    | 194/341 [00:03<00:02, 51.32it/s, Epoch: 4, Batch: 195,Loss: 0.538,Avg.Loss: -0.310,LR: 4.62E-04] Training epoch 4:  57%|█████▋    | 195/341 [00:03<00:02, 51.32it/s, Epoch: 4, Batch: 196,Loss: 1.308,Avg.Loss: -0.302,LR: 4.62E-04]Training epoch 4:  57%|█████▋    | 196/341 [00:03<00:02, 51.32it/s, Epoch: 4, Batch: 197,Loss: -0.727,Avg.Loss: -0.304,LR: 4.62E-04]Training epoch 4:  58%|█████▊    | 197/341 [00:03<00:02, 51.32it/s, Epoch: 4, Batch: 198,Loss: -0.858,Avg.Loss: -0.307,LR: 4.61E-04]Training epoch 4:  58%|█████▊    | 198/341 [00:03<00:02, 51.32it/s, Epoch: 4, Batch: 199,Loss: -0.570,Avg.Loss: -0.308,LR: 4.61E-04]Training epoch 4:  58%|█████▊    | 199/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 199,Loss: -0.570,Avg.Loss: -0.308,LR: 4.61E-04]Training epoch 4:  58%|█████▊    | 199/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 200,Loss: -1.051,Avg.Loss: -0.312,LR: 4.61E-04]Training epoch 4:  59%|█████▊    | 200/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 201,Loss: -0.851,Avg.Loss: -0.315,LR: 4.61E-04]Training epoch 4:  59%|█████▉    | 201/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 202,Loss: -0.380,Avg.Loss: -0.315,LR: 4.61E-04]Training epoch 4:  59%|█████▉    | 202/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 203,Loss: -0.768,Avg.Loss: -0.317,LR: 4.61E-04]Training epoch 4:  60%|█████▉    | 203/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 204,Loss: -0.744,Avg.Loss: -0.319,LR: 4.61E-04]Training epoch 4:  60%|█████▉    | 204/341 [00:03<00:02, 51.44it/s, Epoch: 4, Batch: 205,Loss: -0.604,Avg.Loss: -0.321,LR: 4.61E-04]Training epoch 4:  60%|██████    | 205/341 [00:03<00:02, 51.83it/s, Epoch: 4, Batch: 205,Loss: -0.604,Avg.Loss: -0.321,LR: 4.61E-04]Training epoch 4:  60%|██████    | 205/341 [00:03<00:02, 51.83it/s, Epoch: 4, Batch: 206,Loss: -0.991,Avg.Loss: -0.324,LR: 4.61E-04]Training epoch 4:  60%|██████    | 206/341 [00:03<00:02, 51.83it/s, Epoch: 4, Batch: 207,Loss: -0.294,Avg.Loss: -0.324,LR: 4.61E-04]Training epoch 4:  61%|██████    | 207/341 [00:03<00:02, 51.83it/s, Epoch: 4, Batch: 208,Loss: 0.080,Avg.Loss: -0.322,LR: 4.61E-04] Training epoch 4:  61%|██████    | 208/341 [00:04<00:02, 51.83it/s, Epoch: 4, Batch: 209,Loss: -0.300,Avg.Loss: -0.322,LR: 4.61E-04]Training epoch 4:  61%|██████▏   | 209/341 [00:04<00:02, 51.83it/s, Epoch: 4, Batch: 210,Loss: 0.018,Avg.Loss: -0.320,LR: 4.61E-04] Training epoch 4:  62%|██████▏   | 210/341 [00:04<00:02, 51.83it/s, Epoch: 4, Batch: 211,Loss: -0.178,Avg.Loss: -0.320,LR: 4.61E-04]Training epoch 4:  62%|██████▏   | 211/341 [00:04<00:02, 51.50it/s, Epoch: 4, Batch: 211,Loss: -0.178,Avg.Loss: -0.320,LR: 4.61E-04]Training epoch 4:  62%|██████▏   | 211/341 [00:04<00:02, 51.50it/s, Epoch: 4, Batch: 212,Loss: -0.565,Avg.Loss: -0.321,LR: 4.61E-04]Training epoch 4:  62%|██████▏   | 212/341 [00:04<00:02, 51.50it/s, Epoch: 4, Batch: 213,Loss: -1.021,Avg.Loss: -0.324,LR: 4.61E-04]Training epoch 4:  62%|██████▏   | 213/341 [00:04<00:02, 51.50it/s, Epoch: 4, Batch: 214,Loss: -1.193,Avg.Loss: -0.328,LR: 4.60E-04]Training epoch 4:  63%|██████▎   | 214/341 [00:04<00:02, 51.50it/s, Epoch: 4, Batch: 215,Loss: -1.074,Avg.Loss: -0.332,LR: 4.60E-04]Training epoch 4:  63%|██████▎   | 215/341 [00:04<00:02, 51.50it/s, Epoch: 4, Batch: 216,Loss: -0.850,Avg.Loss: -0.334,LR: 4.60E-04]Training epoch 4:  63%|██████▎   | 216/341 [00:04<00:02, 51.50it/s, Epoch: 4, Batch: 217,Loss: -1.174,Avg.Loss: -0.338,LR: 4.60E-04]Training epoch 4:  64%|██████▎   | 217/341 [00:04<00:02, 51.62it/s, Epoch: 4, Batch: 217,Loss: -1.174,Avg.Loss: -0.338,LR: 4.60E-04]Training epoch 4:  64%|██████▎   | 217/341 [00:04<00:02, 51.62it/s, Epoch: 4, Batch: 218,Loss: -1.030,Avg.Loss: -0.341,LR: 4.60E-04]Training epoch 4:  64%|██████▍   | 218/341 [00:04<00:02, 51.62it/s, Epoch: 4, Batch: 219,Loss: -0.919,Avg.Loss: -0.344,LR: 4.60E-04]Training epoch 4:  64%|██████▍   | 219/341 [00:04<00:02, 51.62it/s, Epoch: 4, Batch: 220,Loss: -0.736,Avg.Loss: -0.345,LR: 4.60E-04]Training epoch 4:  65%|██████▍   | 220/341 [00:04<00:02, 51.62it/s, Epoch: 4, Batch: 221,Loss: -0.530,Avg.Loss: -0.346,LR: 4.60E-04]Training epoch 4:  65%|██████▍   | 221/341 [00:04<00:02, 51.62it/s, Epoch: 4, Batch: 222,Loss: -0.782,Avg.Loss: -0.348,LR: 4.60E-04]Training epoch 4:  65%|██████▌   | 222/341 [00:04<00:02, 51.62it/s, Epoch: 4, Batch: 223,Loss: -1.243,Avg.Loss: -0.352,LR: 4.60E-04]Training epoch 4:  65%|██████▌   | 223/341 [00:04<00:02, 51.40it/s, Epoch: 4, Batch: 223,Loss: -1.243,Avg.Loss: -0.352,LR: 4.60E-04]Training epoch 4:  65%|██████▌   | 223/341 [00:04<00:02, 51.40it/s, Epoch: 4, Batch: 224,Loss: -0.763,Avg.Loss: -0.354,LR: 4.60E-04]Training epoch 4:  66%|██████▌   | 224/341 [00:04<00:02, 51.40it/s, Epoch: 4, Batch: 225,Loss: -0.503,Avg.Loss: -0.355,LR: 4.60E-04]Training epoch 4:  66%|██████▌   | 225/341 [00:04<00:02, 51.40it/s, Epoch: 4, Batch: 226,Loss: -0.496,Avg.Loss: -0.355,LR: 4.60E-04]Training epoch 4:  66%|██████▋   | 226/341 [00:04<00:02, 51.40it/s, Epoch: 4, Batch: 227,Loss: -0.675,Avg.Loss: -0.357,LR: 4.60E-04]Training epoch 4:  67%|██████▋   | 227/341 [00:04<00:02, 51.40it/s, Epoch: 4, Batch: 228,Loss: -0.563,Avg.Loss: -0.358,LR: 4.60E-04]Training epoch 4:  67%|██████▋   | 228/341 [00:04<00:02, 51.40it/s, Epoch: 4, Batch: 229,Loss: -0.882,Avg.Loss: -0.360,LR: 4.60E-04]Training epoch 4:  67%|██████▋   | 229/341 [00:04<00:02, 51.59it/s, Epoch: 4, Batch: 229,Loss: -0.882,Avg.Loss: -0.360,LR: 4.60E-04]Training epoch 4:  67%|██████▋   | 229/341 [00:04<00:02, 51.59it/s, Epoch: 4, Batch: 230,Loss: -0.522,Avg.Loss: -0.361,LR: 4.60E-04]Training epoch 4:  67%|██████▋   | 230/341 [00:04<00:02, 51.59it/s, Epoch: 4, Batch: 231,Loss: -0.068,Avg.Loss: -0.359,LR: 4.59E-04]Training epoch 4:  68%|██████▊   | 231/341 [00:04<00:02, 51.59it/s, Epoch: 4, Batch: 232,Loss: -0.148,Avg.Loss: -0.358,LR: 4.59E-04]Training epoch 4:  68%|██████▊   | 232/341 [00:04<00:02, 51.59it/s, Epoch: 4, Batch: 233,Loss: -0.244,Avg.Loss: -0.358,LR: 4.59E-04]Training epoch 4:  68%|██████▊   | 233/341 [00:04<00:02, 51.59it/s, Epoch: 4, Batch: 234,Loss: -0.451,Avg.Loss: -0.358,LR: 4.59E-04]Training epoch 4:  69%|██████▊   | 234/341 [00:04<00:02, 51.59it/s, Epoch: 4, Batch: 235,Loss: -1.122,Avg.Loss: -0.362,LR: 4.59E-04]Training epoch 4:  69%|██████▉   | 235/341 [00:04<00:02, 51.43it/s, Epoch: 4, Batch: 235,Loss: -1.122,Avg.Loss: -0.362,LR: 4.59E-04]Training epoch 4:  69%|██████▉   | 235/341 [00:04<00:02, 51.43it/s, Epoch: 4, Batch: 236,Loss: -0.621,Avg.Loss: -0.363,LR: 4.59E-04]Training epoch 4:  69%|██████▉   | 236/341 [00:04<00:02, 51.43it/s, Epoch: 4, Batch: 237,Loss: -0.337,Avg.Loss: -0.363,LR: 4.59E-04]Training epoch 4:  70%|██████▉   | 237/341 [00:04<00:02, 51.43it/s, Epoch: 4, Batch: 238,Loss: -0.786,Avg.Loss: -0.364,LR: 4.59E-04]Training epoch 4:  70%|██████▉   | 238/341 [00:04<00:02, 51.43it/s, Epoch: 4, Batch: 239,Loss: -0.846,Avg.Loss: -0.366,LR: 4.59E-04]Training epoch 4:  70%|███████   | 239/341 [00:04<00:01, 51.43it/s, Epoch: 4, Batch: 240,Loss: -0.466,Avg.Loss: -0.367,LR: 4.59E-04]Training epoch 4:  70%|███████   | 240/341 [00:04<00:01, 51.43it/s, Epoch: 4, Batch: 241,Loss: 0.201,Avg.Loss: -0.364,LR: 4.59E-04] Training epoch 4:  71%|███████   | 241/341 [00:04<00:01, 51.53it/s, Epoch: 4, Batch: 241,Loss: 0.201,Avg.Loss: -0.364,LR: 4.59E-04]Training epoch 4:  71%|███████   | 241/341 [00:04<00:01, 51.53it/s, Epoch: 4, Batch: 242,Loss: -0.404,Avg.Loss: -0.365,LR: 4.59E-04]Training epoch 4:  71%|███████   | 242/341 [00:04<00:01, 51.53it/s, Epoch: 4, Batch: 243,Loss: -0.688,Avg.Loss: -0.366,LR: 4.59E-04]Training epoch 4:  71%|███████▏  | 243/341 [00:04<00:01, 51.53it/s, Epoch: 4, Batch: 244,Loss: -0.171,Avg.Loss: -0.365,LR: 4.59E-04]Training epoch 4:  72%|███████▏  | 244/341 [00:04<00:01, 51.53it/s, Epoch: 4, Batch: 245,Loss: -0.434,Avg.Loss: -0.365,LR: 4.59E-04]Training epoch 4:  72%|███████▏  | 245/341 [00:04<00:01, 51.53it/s, Epoch: 4, Batch: 246,Loss: -0.818,Avg.Loss: -0.367,LR: 4.58E-04]Training epoch 4:  72%|███████▏  | 246/341 [00:04<00:01, 51.53it/s, Epoch: 4, Batch: 247,Loss: 0.268,Avg.Loss: -0.365,LR: 4.58E-04] Training epoch 4:  72%|███████▏  | 247/341 [00:04<00:01, 51.36it/s, Epoch: 4, Batch: 247,Loss: 0.268,Avg.Loss: -0.365,LR: 4.58E-04]Training epoch 4:  72%|███████▏  | 247/341 [00:04<00:01, 51.36it/s, Epoch: 4, Batch: 248,Loss: 0.393,Avg.Loss: -0.362,LR: 4.58E-04]Training epoch 4:  73%|███████▎  | 248/341 [00:04<00:01, 51.36it/s, Epoch: 4, Batch: 249,Loss: 0.163,Avg.Loss: -0.360,LR: 4.58E-04]Training epoch 4:  73%|███████▎  | 249/341 [00:04<00:01, 51.36it/s, Epoch: 4, Batch: 250,Loss: -0.490,Avg.Loss: -0.360,LR: 4.58E-04]Training epoch 4:  73%|███████▎  | 250/341 [00:04<00:01, 51.36it/s, Epoch: 4, Batch: 251,Loss: 0.567,Avg.Loss: -0.356,LR: 4.58E-04] Training epoch 4:  74%|███████▎  | 251/341 [00:04<00:01, 51.36it/s, Epoch: 4, Batch: 252,Loss: -0.045,Avg.Loss: -0.355,LR: 4.58E-04]Training epoch 4:  74%|███████▍  | 252/341 [00:04<00:01, 51.36it/s, Epoch: 4, Batch: 253,Loss: -0.534,Avg.Loss: -0.356,LR: 4.58E-04]Training epoch 4:  74%|███████▍  | 253/341 [00:04<00:01, 51.52it/s, Epoch: 4, Batch: 253,Loss: -0.534,Avg.Loss: -0.356,LR: 4.58E-04]Training epoch 4:  74%|███████▍  | 253/341 [00:04<00:01, 51.52it/s, Epoch: 4, Batch: 254,Loss: -0.459,Avg.Loss: -0.356,LR: 4.58E-04]Training epoch 4:  74%|███████▍  | 254/341 [00:04<00:01, 51.52it/s, Epoch: 4, Batch: 255,Loss: -0.836,Avg.Loss: -0.358,LR: 4.58E-04]Training epoch 4:  75%|███████▍  | 255/341 [00:04<00:01, 51.52it/s, Epoch: 4, Batch: 256,Loss: -0.403,Avg.Loss: -0.358,LR: 4.58E-04]Training epoch 4:  75%|███████▌  | 256/341 [00:04<00:01, 51.52it/s, Epoch: 4, Batch: 257,Loss: -0.354,Avg.Loss: -0.358,LR: 4.58E-04]Training epoch 4:  75%|███████▌  | 257/341 [00:04<00:01, 51.52it/s, Epoch: 4, Batch: 258,Loss: -0.589,Avg.Loss: -0.359,LR: 4.58E-04]Training epoch 4:  76%|███████▌  | 258/341 [00:04<00:01, 51.52it/s, Epoch: 4, Batch: 259,Loss: 0.411,Avg.Loss: -0.356,LR: 4.58E-04] Training epoch 4:  76%|███████▌  | 259/341 [00:04<00:01, 51.91it/s, Epoch: 4, Batch: 259,Loss: 0.411,Avg.Loss: -0.356,LR: 4.58E-04]Training epoch 4:  76%|███████▌  | 259/341 [00:04<00:01, 51.91it/s, Epoch: 4, Batch: 260,Loss: 0.291,Avg.Loss: -0.354,LR: 4.58E-04]Training epoch 4:  76%|███████▌  | 260/341 [00:05<00:01, 51.91it/s, Epoch: 4, Batch: 261,Loss: -0.360,Avg.Loss: -0.354,LR: 4.58E-04]Training epoch 4:  77%|███████▋  | 261/341 [00:05<00:01, 51.91it/s, Epoch: 4, Batch: 262,Loss: -0.408,Avg.Loss: -0.354,LR: 4.57E-04]Training epoch 4:  77%|███████▋  | 262/341 [00:05<00:01, 51.91it/s, Epoch: 4, Batch: 263,Loss: -0.280,Avg.Loss: -0.354,LR: 4.57E-04]Training epoch 4:  77%|███████▋  | 263/341 [00:05<00:01, 51.91it/s, Epoch: 4, Batch: 264,Loss: -0.933,Avg.Loss: -0.356,LR: 4.57E-04]Training epoch 4:  77%|███████▋  | 264/341 [00:05<00:01, 51.91it/s, Epoch: 4, Batch: 265,Loss: -0.282,Avg.Loss: -0.356,LR: 4.57E-04]Training epoch 4:  78%|███████▊  | 265/341 [00:05<00:01, 52.53it/s, Epoch: 4, Batch: 265,Loss: -0.282,Avg.Loss: -0.356,LR: 4.57E-04]Training epoch 4:  78%|███████▊  | 265/341 [00:05<00:01, 52.53it/s, Epoch: 4, Batch: 266,Loss: 0.516,Avg.Loss: -0.352,LR: 4.57E-04] Training epoch 4:  78%|███████▊  | 266/341 [00:05<00:01, 52.53it/s, Epoch: 4, Batch: 267,Loss: -0.413,Avg.Loss: -0.353,LR: 4.57E-04]Training epoch 4:  78%|███████▊  | 267/341 [00:05<00:01, 52.53it/s, Epoch: 4, Batch: 268,Loss: -0.928,Avg.Loss: -0.355,LR: 4.57E-04]Training epoch 4:  79%|███████▊  | 268/341 [00:05<00:01, 52.53it/s, Epoch: 4, Batch: 269,Loss: -0.070,Avg.Loss: -0.354,LR: 4.57E-04]Training epoch 4:  79%|███████▉  | 269/341 [00:05<00:01, 52.53it/s, Epoch: 4, Batch: 270,Loss: -1.006,Avg.Loss: -0.356,LR: 4.57E-04]Training epoch 4:  79%|███████▉  | 270/341 [00:05<00:01, 52.53it/s, Epoch: 4, Batch: 271,Loss: -0.800,Avg.Loss: -0.358,LR: 4.57E-04]Training epoch 4:  79%|███████▉  | 271/341 [00:05<00:01, 52.76it/s, Epoch: 4, Batch: 271,Loss: -0.800,Avg.Loss: -0.358,LR: 4.57E-04]Training epoch 4:  79%|███████▉  | 271/341 [00:05<00:01, 52.76it/s, Epoch: 4, Batch: 272,Loss: -0.646,Avg.Loss: -0.359,LR: 4.57E-04]Training epoch 4:  80%|███████▉  | 272/341 [00:05<00:01, 52.76it/s, Epoch: 4, Batch: 273,Loss: -0.623,Avg.Loss: -0.360,LR: 4.57E-04]Training epoch 4:  80%|████████  | 273/341 [00:05<00:01, 52.76it/s, Epoch: 4, Batch: 274,Loss: -0.751,Avg.Loss: -0.361,LR: 4.57E-04]Training epoch 4:  80%|████████  | 274/341 [00:05<00:01, 52.76it/s, Epoch: 4, Batch: 275,Loss: -0.181,Avg.Loss: -0.361,LR: 4.57E-04]Training epoch 4:  81%|████████  | 275/341 [00:05<00:01, 52.76it/s, Epoch: 4, Batch: 276,Loss: -0.780,Avg.Loss: -0.362,LR: 4.57E-04]Training epoch 4:  81%|████████  | 276/341 [00:05<00:01, 52.76it/s, Epoch: 4, Batch: 277,Loss: -1.035,Avg.Loss: -0.364,LR: 4.56E-04]Training epoch 4:  81%|████████  | 277/341 [00:05<00:01, 52.89it/s, Epoch: 4, Batch: 277,Loss: -1.035,Avg.Loss: -0.364,LR: 4.56E-04]Training epoch 4:  81%|████████  | 277/341 [00:05<00:01, 52.89it/s, Epoch: 4, Batch: 278,Loss: -0.688,Avg.Loss: -0.366,LR: 4.56E-04]Training epoch 4:  82%|████████▏ | 278/341 [00:05<00:01, 52.89it/s, Epoch: 4, Batch: 279,Loss: -0.965,Avg.Loss: -0.368,LR: 4.56E-04]Training epoch 4:  82%|████████▏ | 279/341 [00:05<00:01, 52.89it/s, Epoch: 4, Batch: 280,Loss: -0.428,Avg.Loss: -0.368,LR: 4.56E-04]Training epoch 4:  82%|████████▏ | 280/341 [00:05<00:01, 52.89it/s, Epoch: 4, Batch: 281,Loss: 0.022,Avg.Loss: -0.367,LR: 4.56E-04] Training epoch 4:  82%|████████▏ | 281/341 [00:05<00:01, 52.89it/s, Epoch: 4, Batch: 282,Loss: -0.503,Avg.Loss: -0.367,LR: 4.56E-04]Training epoch 4:  83%|████████▎ | 282/341 [00:05<00:01, 52.89it/s, Epoch: 4, Batch: 283,Loss: -0.817,Avg.Loss: -0.369,LR: 4.56E-04]Training epoch 4:  83%|████████▎ | 283/341 [00:05<00:01, 52.59it/s, Epoch: 4, Batch: 283,Loss: -0.817,Avg.Loss: -0.369,LR: 4.56E-04]Training epoch 4:  83%|████████▎ | 283/341 [00:05<00:01, 52.59it/s, Epoch: 4, Batch: 284,Loss: -0.954,Avg.Loss: -0.371,LR: 4.56E-04]Training epoch 4:  83%|████████▎ | 284/341 [00:05<00:01, 52.59it/s, Epoch: 4, Batch: 285,Loss: -1.311,Avg.Loss: -0.374,LR: 4.56E-04]Training epoch 4:  84%|████████▎ | 285/341 [00:05<00:01, 52.59it/s, Epoch: 4, Batch: 286,Loss: -0.454,Avg.Loss: -0.374,LR: 4.56E-04]Training epoch 4:  84%|████████▍ | 286/341 [00:05<00:01, 52.59it/s, Epoch: 4, Batch: 287,Loss: 0.027,Avg.Loss: -0.373,LR: 4.56E-04] Training epoch 4:  84%|████████▍ | 287/341 [00:05<00:01, 52.59it/s, Epoch: 4, Batch: 288,Loss: -0.884,Avg.Loss: -0.375,LR: 4.56E-04]Training epoch 4:  84%|████████▍ | 288/341 [00:05<00:01, 52.59it/s, Epoch: 4, Batch: 289,Loss: -0.697,Avg.Loss: -0.376,LR: 4.56E-04]Training epoch 4:  85%|████████▍ | 289/341 [00:05<00:00, 52.85it/s, Epoch: 4, Batch: 289,Loss: -0.697,Avg.Loss: -0.376,LR: 4.56E-04]Training epoch 4:  85%|████████▍ | 289/341 [00:05<00:00, 52.85it/s, Epoch: 4, Batch: 290,Loss: -0.616,Avg.Loss: -0.377,LR: 4.56E-04]Training epoch 4:  85%|████████▌ | 290/341 [00:05<00:00, 52.85it/s, Epoch: 4, Batch: 291,Loss: -1.071,Avg.Loss: -0.379,LR: 4.56E-04]Training epoch 4:  85%|████████▌ | 291/341 [00:05<00:00, 52.85it/s, Epoch: 4, Batch: 292,Loss: -0.881,Avg.Loss: -0.381,LR: 4.56E-04]Training epoch 4:  86%|████████▌ | 292/341 [00:05<00:00, 52.85it/s, Epoch: 4, Batch: 293,Loss: -0.915,Avg.Loss: -0.383,LR: 4.55E-04]Training epoch 4:  86%|████████▌ | 293/341 [00:05<00:00, 52.85it/s, Epoch: 4, Batch: 294,Loss: -0.936,Avg.Loss: -0.384,LR: 4.55E-04]Training epoch 4:  86%|████████▌ | 294/341 [00:05<00:00, 52.85it/s, Epoch: 4, Batch: 295,Loss: -0.796,Avg.Loss: -0.386,LR: 4.55E-04]Training epoch 4:  87%|████████▋ | 295/341 [00:05<00:00, 52.64it/s, Epoch: 4, Batch: 295,Loss: -0.796,Avg.Loss: -0.386,LR: 4.55E-04]Training epoch 4:  87%|████████▋ | 295/341 [00:05<00:00, 52.64it/s, Epoch: 4, Batch: 296,Loss: -0.331,Avg.Loss: -0.386,LR: 4.55E-04]Training epoch 4:  87%|████████▋ | 296/341 [00:05<00:00, 52.64it/s, Epoch: 4, Batch: 297,Loss: -0.975,Avg.Loss: -0.388,LR: 4.55E-04]Training epoch 4:  87%|████████▋ | 297/341 [00:05<00:00, 52.64it/s, Epoch: 4, Batch: 298,Loss: -0.899,Avg.Loss: -0.389,LR: 4.55E-04]Training epoch 4:  87%|████████▋ | 298/341 [00:05<00:00, 52.64it/s, Epoch: 4, Batch: 299,Loss: -0.780,Avg.Loss: -0.391,LR: 4.55E-04]Training epoch 4:  88%|████████▊ | 299/341 [00:05<00:00, 52.64it/s, Epoch: 4, Batch: 300,Loss: -1.171,Avg.Loss: -0.393,LR: 4.55E-04]Training epoch 4:  88%|████████▊ | 300/341 [00:05<00:00, 52.64it/s, Epoch: 4, Batch: 301,Loss: -0.985,Avg.Loss: -0.395,LR: 4.55E-04]Training epoch 4:  88%|████████▊ | 301/341 [00:05<00:00, 52.08it/s, Epoch: 4, Batch: 301,Loss: -0.985,Avg.Loss: -0.395,LR: 4.55E-04]Training epoch 4:  88%|████████▊ | 301/341 [00:05<00:00, 52.08it/s, Epoch: 4, Batch: 302,Loss: -0.713,Avg.Loss: -0.396,LR: 4.55E-04]Training epoch 4:  89%|████████▊ | 302/341 [00:05<00:00, 52.08it/s, Epoch: 4, Batch: 303,Loss: -1.157,Avg.Loss: -0.399,LR: 4.55E-04]Training epoch 4:  89%|████████▉ | 303/341 [00:05<00:00, 52.08it/s, Epoch: 4, Batch: 304,Loss: -1.002,Avg.Loss: -0.401,LR: 4.55E-04]Training epoch 4:  89%|████████▉ | 304/341 [00:05<00:00, 52.08it/s, Epoch: 4, Batch: 305,Loss: -0.492,Avg.Loss: -0.401,LR: 4.55E-04]Training epoch 4:  89%|████████▉ | 305/341 [00:05<00:00, 52.08it/s, Epoch: 4, Batch: 306,Loss: -0.772,Avg.Loss: -0.402,LR: 4.55E-04]Training epoch 4:  90%|████████▉ | 306/341 [00:05<00:00, 52.08it/s, Epoch: 4, Batch: 307,Loss: -0.792,Avg.Loss: -0.404,LR: 4.55E-04]Training epoch 4:  90%|█████████ | 307/341 [00:05<00:00, 52.16it/s, Epoch: 4, Batch: 307,Loss: -0.792,Avg.Loss: -0.404,LR: 4.55E-04]Training epoch 4:  90%|█████████ | 307/341 [00:05<00:00, 52.16it/s, Epoch: 4, Batch: 308,Loss: -0.657,Avg.Loss: -0.404,LR: 4.54E-04]Training epoch 4:  90%|█████████ | 308/341 [00:05<00:00, 52.16it/s, Epoch: 4, Batch: 309,Loss: -0.857,Avg.Loss: -0.406,LR: 4.54E-04]Training epoch 4:  91%|█████████ | 309/341 [00:05<00:00, 52.16it/s, Epoch: 4, Batch: 310,Loss: -1.262,Avg.Loss: -0.409,LR: 4.54E-04]Training epoch 4:  91%|█████████ | 310/341 [00:05<00:00, 52.16it/s, Epoch: 4, Batch: 311,Loss: -0.543,Avg.Loss: -0.409,LR: 4.54E-04]Training epoch 4:  91%|█████████ | 311/341 [00:05<00:00, 52.16it/s, Epoch: 4, Batch: 312,Loss: -1.031,Avg.Loss: -0.411,LR: 4.54E-04]Training epoch 4:  91%|█████████▏| 312/341 [00:05<00:00, 52.16it/s, Epoch: 4, Batch: 313,Loss: -0.349,Avg.Loss: -0.411,LR: 4.54E-04]Training epoch 4:  92%|█████████▏| 313/341 [00:05<00:00, 53.49it/s, Epoch: 4, Batch: 313,Loss: -0.349,Avg.Loss: -0.411,LR: 4.54E-04]Training epoch 4:  92%|█████████▏| 313/341 [00:06<00:00, 53.49it/s, Epoch: 4, Batch: 314,Loss: -0.664,Avg.Loss: -0.412,LR: 4.54E-04]Training epoch 4:  92%|█████████▏| 314/341 [00:06<00:00, 53.49it/s, Epoch: 4, Batch: 315,Loss: -1.083,Avg.Loss: -0.414,LR: 4.54E-04]Training epoch 4:  92%|█████████▏| 315/341 [00:06<00:00, 53.49it/s, Epoch: 4, Batch: 316,Loss: -0.775,Avg.Loss: -0.415,LR: 4.54E-04]Training epoch 4:  93%|█████████▎| 316/341 [00:06<00:00, 53.49it/s, Epoch: 4, Batch: 317,Loss: -0.097,Avg.Loss: -0.414,LR: 4.54E-04]Training epoch 4:  93%|█████████▎| 317/341 [00:06<00:00, 53.49it/s, Epoch: 4, Batch: 318,Loss: -0.973,Avg.Loss: -0.416,LR: 4.54E-04]Training epoch 4:  93%|█████████▎| 318/341 [00:06<00:00, 53.49it/s, Epoch: 4, Batch: 319,Loss: -1.003,Avg.Loss: -0.418,LR: 4.54E-04]Training epoch 4:  94%|█████████▎| 319/341 [00:06<00:00, 53.26it/s, Epoch: 4, Batch: 319,Loss: -1.003,Avg.Loss: -0.418,LR: 4.54E-04]Training epoch 4:  94%|█████████▎| 319/341 [00:06<00:00, 53.26it/s, Epoch: 4, Batch: 320,Loss: -0.183,Avg.Loss: -0.417,LR: 4.54E-04]Training epoch 4:  94%|█████████▍| 320/341 [00:06<00:00, 53.26it/s, Epoch: 4, Batch: 321,Loss: -0.811,Avg.Loss: -0.418,LR: 4.54E-04]Training epoch 4:  94%|█████████▍| 321/341 [00:06<00:00, 53.26it/s, Epoch: 4, Batch: 322,Loss: -0.804,Avg.Loss: -0.419,LR: 4.54E-04]Training epoch 4:  94%|█████████▍| 322/341 [00:06<00:00, 53.26it/s, Epoch: 4, Batch: 323,Loss: -0.727,Avg.Loss: -0.420,LR: 4.53E-04]Training epoch 4:  95%|█████████▍| 323/341 [00:06<00:00, 53.26it/s, Epoch: 4, Batch: 324,Loss: -0.948,Avg.Loss: -0.422,LR: 4.53E-04]Training epoch 4:  95%|█████████▌| 324/341 [00:06<00:00, 53.26it/s, Epoch: 4, Batch: 325,Loss: -1.123,Avg.Loss: -0.424,LR: 4.53E-04]Training epoch 4:  95%|█████████▌| 325/341 [00:06<00:00, 52.58it/s, Epoch: 4, Batch: 325,Loss: -1.123,Avg.Loss: -0.424,LR: 4.53E-04]Training epoch 4:  95%|█████████▌| 325/341 [00:06<00:00, 52.58it/s, Epoch: 4, Batch: 326,Loss: -0.615,Avg.Loss: -0.425,LR: 4.53E-04]Training epoch 4:  96%|█████████▌| 326/341 [00:06<00:00, 52.58it/s, Epoch: 4, Batch: 327,Loss: -0.874,Avg.Loss: -0.426,LR: 4.53E-04]Training epoch 4:  96%|█████████▌| 327/341 [00:06<00:00, 52.58it/s, Epoch: 4, Batch: 328,Loss: -0.786,Avg.Loss: -0.427,LR: 4.53E-04]Training epoch 4:  96%|█████████▌| 328/341 [00:06<00:00, 52.58it/s, Epoch: 4, Batch: 329,Loss: -0.275,Avg.Loss: -0.427,LR: 4.53E-04]Training epoch 4:  96%|█████████▋| 329/341 [00:06<00:00, 52.58it/s, Epoch: 4, Batch: 330,Loss: -1.167,Avg.Loss: -0.429,LR: 4.53E-04]Training epoch 4:  97%|█████████▋| 330/341 [00:06<00:00, 52.58it/s, Epoch: 4, Batch: 331,Loss: -0.987,Avg.Loss: -0.430,LR: 4.53E-04]Training epoch 4:  97%|█████████▋| 331/341 [00:06<00:00, 52.62it/s, Epoch: 4, Batch: 331,Loss: -0.987,Avg.Loss: -0.430,LR: 4.53E-04]Training epoch 4:  97%|█████████▋| 331/341 [00:06<00:00, 52.62it/s, Epoch: 4, Batch: 332,Loss: -0.855,Avg.Loss: -0.432,LR: 4.53E-04]Training epoch 4:  97%|█████████▋| 332/341 [00:06<00:00, 52.62it/s, Epoch: 4, Batch: 333,Loss: -1.143,Avg.Loss: -0.434,LR: 4.53E-04]Training epoch 4:  98%|█████████▊| 333/341 [00:06<00:00, 52.62it/s, Epoch: 4, Batch: 334,Loss: -0.630,Avg.Loss: -0.434,LR: 4.53E-04]Training epoch 4:  98%|█████████▊| 334/341 [00:06<00:00, 52.62it/s, Epoch: 4, Batch: 335,Loss: -0.590,Avg.Loss: -0.435,LR: 4.53E-04]Training epoch 4:  98%|█████████▊| 335/341 [00:06<00:00, 52.62it/s, Epoch: 4, Batch: 336,Loss: -1.221,Avg.Loss: -0.437,LR: 4.53E-04]Training epoch 4:  99%|█████████▊| 336/341 [00:06<00:00, 52.62it/s, Epoch: 4, Batch: 337,Loss: -0.892,Avg.Loss: -0.439,LR: 4.53E-04]Training epoch 4:  99%|█████████▉| 337/341 [00:06<00:00, 52.72it/s, Epoch: 4, Batch: 337,Loss: -0.892,Avg.Loss: -0.439,LR: 4.53E-04]Training epoch 4:  99%|█████████▉| 337/341 [00:06<00:00, 52.72it/s, Epoch: 4, Batch: 338,Loss: -0.850,Avg.Loss: -0.440,LR: 4.52E-04]Training epoch 4:  99%|█████████▉| 338/341 [00:06<00:00, 52.72it/s, Epoch: 4, Batch: 339,Loss: -1.096,Avg.Loss: -0.442,LR: 4.52E-04]Training epoch 4:  99%|█████████▉| 339/341 [00:06<00:00, 52.72it/s, Epoch: 4, Batch: 340,Loss: -1.069,Avg.Loss: -0.444,LR: 4.52E-04]Training epoch 4: 100%|█████████▉| 340/341 [00:06<00:00, 52.72it/s, Epoch: 4, Batch: 341,Loss: -0.383,Avg.Loss: -0.443,LR: 4.52E-04]Training epoch 4: 100%|██████████| 341/341 [00:06<00:00, 52.25it/s, Epoch: 4, Batch: 341,Loss: -0.383,Avg.Loss: -0.443,LR: 4.52E-04]
Training epoch 5:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 5:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 5, Batch: 1,Loss: -1.116,Avg.Loss: -1.116,LR: 4.52E-04]Training epoch 5:   0%|          | 1/341 [00:00<00:09, 34.05it/s, Epoch: 5, Batch: 2,Loss: -0.827,Avg.Loss: -0.972,LR: 4.52E-04]Training epoch 5:   1%|          | 2/341 [00:00<00:07, 44.05it/s, Epoch: 5, Batch: 3,Loss: -0.635,Avg.Loss: -0.859,LR: 4.52E-04]Training epoch 5:   1%|          | 3/341 [00:00<00:06, 51.71it/s, Epoch: 5, Batch: 4,Loss: -1.003,Avg.Loss: -0.895,LR: 4.52E-04]Training epoch 5:   1%|          | 4/341 [00:00<00:06, 53.32it/s, Epoch: 5, Batch: 5,Loss: -1.282,Avg.Loss: -0.973,LR: 4.52E-04]Training epoch 5:   1%|▏         | 5/341 [00:00<00:06, 53.71it/s, Epoch: 5, Batch: 6,Loss: -0.460,Avg.Loss: -0.887,LR: 4.52E-04]Training epoch 5:   2%|▏         | 6/341 [00:00<00:06, 53.83it/s, Epoch: 5, Batch: 7,Loss: -1.113,Avg.Loss: -0.919,LR: 4.52E-04]Training epoch 5:   2%|▏         | 7/341 [00:00<00:05, 62.68it/s, Epoch: 5, Batch: 7,Loss: -1.113,Avg.Loss: -0.919,LR: 4.52E-04]Training epoch 5:   2%|▏         | 7/341 [00:00<00:05, 62.68it/s, Epoch: 5, Batch: 8,Loss: -0.908,Avg.Loss: -0.918,LR: 4.52E-04]Training epoch 5:   2%|▏         | 8/341 [00:00<00:05, 62.68it/s, Epoch: 5, Batch: 9,Loss: -0.521,Avg.Loss: -0.874,LR: 4.52E-04]Training epoch 5:   3%|▎         | 9/341 [00:00<00:05, 62.68it/s, Epoch: 5, Batch: 10,Loss: -1.315,Avg.Loss: -0.918,LR: 4.52E-04]Training epoch 5:   3%|▎         | 10/341 [00:00<00:05, 62.68it/s, Epoch: 5, Batch: 11,Loss: -0.905,Avg.Loss: -0.917,LR: 4.52E-04]Training epoch 5:   3%|▎         | 11/341 [00:00<00:05, 62.68it/s, Epoch: 5, Batch: 12,Loss: -0.654,Avg.Loss: -0.895,LR: 4.51E-04]Training epoch 5:   4%|▎         | 12/341 [00:00<00:05, 62.68it/s, Epoch: 5, Batch: 13,Loss: -1.156,Avg.Loss: -0.915,LR: 4.51E-04]Training epoch 5:   4%|▍         | 13/341 [00:00<00:05, 62.68it/s, Epoch: 5, Batch: 14,Loss: -0.891,Avg.Loss: -0.913,LR: 4.51E-04]Training epoch 5:   4%|▍         | 14/341 [00:00<00:05, 55.60it/s, Epoch: 5, Batch: 14,Loss: -0.891,Avg.Loss: -0.913,LR: 4.51E-04]Training epoch 5:   4%|▍         | 14/341 [00:00<00:05, 55.60it/s, Epoch: 5, Batch: 15,Loss: -0.234,Avg.Loss: -0.868,LR: 4.51E-04]Training epoch 5:   4%|▍         | 15/341 [00:00<00:05, 55.60it/s, Epoch: 5, Batch: 16,Loss: -0.991,Avg.Loss: -0.876,LR: 4.51E-04]Training epoch 5:   5%|▍         | 16/341 [00:00<00:05, 55.60it/s, Epoch: 5, Batch: 17,Loss: -1.124,Avg.Loss: -0.890,LR: 4.51E-04]Training epoch 5:   5%|▍         | 17/341 [00:00<00:05, 55.60it/s, Epoch: 5, Batch: 18,Loss: -0.857,Avg.Loss: -0.888,LR: 4.51E-04]Training epoch 5:   5%|▌         | 18/341 [00:00<00:05, 55.60it/s, Epoch: 5, Batch: 19,Loss: -1.056,Avg.Loss: -0.897,LR: 4.51E-04]Training epoch 5:   6%|▌         | 19/341 [00:00<00:05, 55.60it/s, Epoch: 5, Batch: 20,Loss: -1.187,Avg.Loss: -0.912,LR: 4.51E-04]Training epoch 5:   6%|▌         | 20/341 [00:00<00:05, 53.82it/s, Epoch: 5, Batch: 20,Loss: -1.187,Avg.Loss: -0.912,LR: 4.51E-04]Training epoch 5:   6%|▌         | 20/341 [00:00<00:05, 53.82it/s, Epoch: 5, Batch: 21,Loss: -0.799,Avg.Loss: -0.906,LR: 4.51E-04]Training epoch 5:   6%|▌         | 21/341 [00:00<00:05, 53.82it/s, Epoch: 5, Batch: 22,Loss: -0.791,Avg.Loss: -0.901,LR: 4.51E-04]Training epoch 5:   6%|▋         | 22/341 [00:00<00:05, 53.82it/s, Epoch: 5, Batch: 23,Loss: -0.561,Avg.Loss: -0.886,LR: 4.51E-04]Training epoch 5:   7%|▋         | 23/341 [00:00<00:05, 53.82it/s, Epoch: 5, Batch: 24,Loss: -0.520,Avg.Loss: -0.871,LR: 4.51E-04]Training epoch 5:   7%|▋         | 24/341 [00:00<00:05, 53.82it/s, Epoch: 5, Batch: 25,Loss: -1.057,Avg.Loss: -0.878,LR: 4.51E-04]Training epoch 5:   7%|▋         | 25/341 [00:00<00:05, 53.82it/s, Epoch: 5, Batch: 26,Loss: -0.726,Avg.Loss: -0.873,LR: 4.50E-04]Training epoch 5:   8%|▊         | 26/341 [00:00<00:06, 52.42it/s, Epoch: 5, Batch: 26,Loss: -0.726,Avg.Loss: -0.873,LR: 4.50E-04]Training epoch 5:   8%|▊         | 26/341 [00:00<00:06, 52.42it/s, Epoch: 5, Batch: 27,Loss: -0.202,Avg.Loss: -0.848,LR: 4.50E-04]Training epoch 5:   8%|▊         | 27/341 [00:00<00:05, 52.42it/s, Epoch: 5, Batch: 28,Loss: -0.528,Avg.Loss: -0.836,LR: 4.50E-04]Training epoch 5:   8%|▊         | 28/341 [00:00<00:05, 52.42it/s, Epoch: 5, Batch: 29,Loss: -1.075,Avg.Loss: -0.845,LR: 4.50E-04]Training epoch 5:   9%|▊         | 29/341 [00:00<00:05, 52.42it/s, Epoch: 5, Batch: 30,Loss: -1.048,Avg.Loss: -0.851,LR: 4.50E-04]Training epoch 5:   9%|▉         | 30/341 [00:00<00:05, 52.42it/s, Epoch: 5, Batch: 31,Loss: -1.343,Avg.Loss: -0.867,LR: 4.50E-04]Training epoch 5:   9%|▉         | 31/341 [00:00<00:05, 52.42it/s, Epoch: 5, Batch: 32,Loss: -0.742,Avg.Loss: -0.863,LR: 4.50E-04]Training epoch 5:   9%|▉         | 32/341 [00:00<00:05, 52.29it/s, Epoch: 5, Batch: 32,Loss: -0.742,Avg.Loss: -0.863,LR: 4.50E-04]Training epoch 5:   9%|▉         | 32/341 [00:00<00:05, 52.29it/s, Epoch: 5, Batch: 33,Loss: -0.807,Avg.Loss: -0.862,LR: 4.50E-04]Training epoch 5:  10%|▉         | 33/341 [00:00<00:05, 52.29it/s, Epoch: 5, Batch: 34,Loss: -0.765,Avg.Loss: -0.859,LR: 4.50E-04]Training epoch 5:  10%|▉         | 34/341 [00:00<00:05, 52.29it/s, Epoch: 5, Batch: 35,Loss: -1.239,Avg.Loss: -0.870,LR: 4.50E-04]Training epoch 5:  10%|█         | 35/341 [00:00<00:05, 52.29it/s, Epoch: 5, Batch: 36,Loss: -0.928,Avg.Loss: -0.871,LR: 4.50E-04]Training epoch 5:  11%|█         | 36/341 [00:00<00:05, 52.29it/s, Epoch: 5, Batch: 37,Loss: 0.455,Avg.Loss: -0.835,LR: 4.50E-04] Training epoch 5:  11%|█         | 37/341 [00:00<00:05, 52.29it/s, Epoch: 5, Batch: 38,Loss: -0.195,Avg.Loss: -0.819,LR: 4.50E-04]Training epoch 5:  11%|█         | 38/341 [00:00<00:05, 52.10it/s, Epoch: 5, Batch: 38,Loss: -0.195,Avg.Loss: -0.819,LR: 4.50E-04]Training epoch 5:  11%|█         | 38/341 [00:00<00:05, 52.10it/s, Epoch: 5, Batch: 39,Loss: 0.057,Avg.Loss: -0.796,LR: 4.50E-04] Training epoch 5:  11%|█▏        | 39/341 [00:00<00:05, 52.10it/s, Epoch: 5, Batch: 40,Loss: -0.073,Avg.Loss: -0.778,LR: 4.50E-04]Training epoch 5:  12%|█▏        | 40/341 [00:00<00:05, 52.10it/s, Epoch: 5, Batch: 41,Loss: -0.264,Avg.Loss: -0.765,LR: 4.49E-04]Training epoch 5:  12%|█▏        | 41/341 [00:00<00:05, 52.10it/s, Epoch: 5, Batch: 42,Loss: 0.134,Avg.Loss: -0.744,LR: 4.49E-04] Training epoch 5:  12%|█▏        | 42/341 [00:00<00:05, 52.10it/s, Epoch: 5, Batch: 43,Loss: 0.530,Avg.Loss: -0.714,LR: 4.49E-04]Training epoch 5:  13%|█▎        | 43/341 [00:00<00:05, 52.10it/s, Epoch: 5, Batch: 44,Loss: 0.549,Avg.Loss: -0.686,LR: 4.49E-04]Training epoch 5:  13%|█▎        | 44/341 [00:00<00:05, 52.22it/s, Epoch: 5, Batch: 44,Loss: 0.549,Avg.Loss: -0.686,LR: 4.49E-04]Training epoch 5:  13%|█▎        | 44/341 [00:00<00:05, 52.22it/s, Epoch: 5, Batch: 45,Loss: -0.657,Avg.Loss: -0.685,LR: 4.49E-04]Training epoch 5:  13%|█▎        | 45/341 [00:00<00:05, 52.22it/s, Epoch: 5, Batch: 46,Loss: -0.028,Avg.Loss: -0.671,LR: 4.49E-04]Training epoch 5:  13%|█▎        | 46/341 [00:00<00:05, 52.22it/s, Epoch: 5, Batch: 47,Loss: -0.415,Avg.Loss: -0.665,LR: 4.49E-04]Training epoch 5:  14%|█▍        | 47/341 [00:00<00:05, 52.22it/s, Epoch: 5, Batch: 48,Loss: -0.514,Avg.Loss: -0.662,LR: 4.49E-04]Training epoch 5:  14%|█▍        | 48/341 [00:00<00:05, 52.22it/s, Epoch: 5, Batch: 49,Loss: -0.996,Avg.Loss: -0.669,LR: 4.49E-04]Training epoch 5:  14%|█▍        | 49/341 [00:00<00:05, 52.22it/s, Epoch: 5, Batch: 50,Loss: -0.892,Avg.Loss: -0.673,LR: 4.49E-04]Training epoch 5:  15%|█▍        | 50/341 [00:00<00:05, 51.44it/s, Epoch: 5, Batch: 50,Loss: -0.892,Avg.Loss: -0.673,LR: 4.49E-04]Training epoch 5:  15%|█▍        | 50/341 [00:00<00:05, 51.44it/s, Epoch: 5, Batch: 51,Loss: -0.530,Avg.Loss: -0.671,LR: 4.49E-04]Training epoch 5:  15%|█▍        | 51/341 [00:00<00:05, 51.44it/s, Epoch: 5, Batch: 52,Loss: -0.471,Avg.Loss: -0.667,LR: 4.49E-04]Training epoch 5:  15%|█▌        | 52/341 [00:01<00:05, 51.44it/s, Epoch: 5, Batch: 53,Loss: -0.897,Avg.Loss: -0.671,LR: 4.49E-04]Training epoch 5:  16%|█▌        | 53/341 [00:01<00:05, 51.44it/s, Epoch: 5, Batch: 54,Loss: -0.645,Avg.Loss: -0.671,LR: 4.49E-04]Training epoch 5:  16%|█▌        | 54/341 [00:01<00:05, 51.44it/s, Epoch: 5, Batch: 55,Loss: -0.368,Avg.Loss: -0.665,LR: 4.48E-04]Training epoch 5:  16%|█▌        | 55/341 [00:01<00:05, 51.44it/s, Epoch: 5, Batch: 56,Loss: -0.211,Avg.Loss: -0.657,LR: 4.48E-04]Training epoch 5:  16%|█▋        | 56/341 [00:01<00:05, 51.65it/s, Epoch: 5, Batch: 56,Loss: -0.211,Avg.Loss: -0.657,LR: 4.48E-04]Training epoch 5:  16%|█▋        | 56/341 [00:01<00:05, 51.65it/s, Epoch: 5, Batch: 57,Loss: -0.519,Avg.Loss: -0.655,LR: 4.48E-04]Training epoch 5:  17%|█▋        | 57/341 [00:01<00:05, 51.65it/s, Epoch: 5, Batch: 58,Loss: -0.135,Avg.Loss: -0.646,LR: 4.48E-04]Training epoch 5:  17%|█▋        | 58/341 [00:01<00:05, 51.65it/s, Epoch: 5, Batch: 59,Loss: -0.083,Avg.Loss: -0.636,LR: 4.48E-04]Training epoch 5:  17%|█▋        | 59/341 [00:01<00:05, 51.65it/s, Epoch: 5, Batch: 60,Loss: -0.575,Avg.Loss: -0.635,LR: 4.48E-04]Training epoch 5:  18%|█▊        | 60/341 [00:01<00:05, 51.65it/s, Epoch: 5, Batch: 61,Loss: -0.911,Avg.Loss: -0.640,LR: 4.48E-04]Training epoch 5:  18%|█▊        | 61/341 [00:01<00:05, 51.65it/s, Epoch: 5, Batch: 62,Loss: -0.599,Avg.Loss: -0.639,LR: 4.48E-04]Training epoch 5:  18%|█▊        | 62/341 [00:01<00:05, 51.93it/s, Epoch: 5, Batch: 62,Loss: -0.599,Avg.Loss: -0.639,LR: 4.48E-04]Training epoch 5:  18%|█▊        | 62/341 [00:01<00:05, 51.93it/s, Epoch: 5, Batch: 63,Loss: 0.117,Avg.Loss: -0.627,LR: 4.48E-04] Training epoch 5:  18%|█▊        | 63/341 [00:01<00:05, 51.93it/s, Epoch: 5, Batch: 64,Loss: 0.588,Avg.Loss: -0.608,LR: 4.48E-04]Training epoch 5:  19%|█▉        | 64/341 [00:01<00:05, 51.93it/s, Epoch: 5, Batch: 65,Loss: 0.566,Avg.Loss: -0.590,LR: 4.48E-04]Training epoch 5:  19%|█▉        | 65/341 [00:01<00:05, 51.93it/s, Epoch: 5, Batch: 66,Loss: -0.308,Avg.Loss: -0.586,LR: 4.48E-04]Training epoch 5:  19%|█▉        | 66/341 [00:01<00:05, 51.93it/s, Epoch: 5, Batch: 67,Loss: -0.237,Avg.Loss: -0.580,LR: 4.48E-04]Training epoch 5:  20%|█▉        | 67/341 [00:01<00:05, 51.93it/s, Epoch: 5, Batch: 68,Loss: -0.718,Avg.Loss: -0.582,LR: 4.48E-04]Training epoch 5:  20%|█▉        | 68/341 [00:01<00:05, 52.85it/s, Epoch: 5, Batch: 68,Loss: -0.718,Avg.Loss: -0.582,LR: 4.48E-04]Training epoch 5:  20%|█▉        | 68/341 [00:01<00:05, 52.85it/s, Epoch: 5, Batch: 69,Loss: -0.269,Avg.Loss: -0.578,LR: 4.47E-04]Training epoch 5:  20%|██        | 69/341 [00:01<00:05, 52.85it/s, Epoch: 5, Batch: 70,Loss: -0.364,Avg.Loss: -0.575,LR: 4.47E-04]Training epoch 5:  21%|██        | 70/341 [00:01<00:05, 52.85it/s, Epoch: 5, Batch: 71,Loss: -0.165,Avg.Loss: -0.569,LR: 4.47E-04]Training epoch 5:  21%|██        | 71/341 [00:01<00:05, 52.85it/s, Epoch: 5, Batch: 72,Loss: -0.465,Avg.Loss: -0.568,LR: 4.47E-04]Training epoch 5:  21%|██        | 72/341 [00:01<00:05, 52.85it/s, Epoch: 5, Batch: 73,Loss: -0.740,Avg.Loss: -0.570,LR: 4.47E-04]Training epoch 5:  21%|██▏       | 73/341 [00:01<00:05, 52.85it/s, Epoch: 5, Batch: 74,Loss: -0.407,Avg.Loss: -0.568,LR: 4.47E-04]Training epoch 5:  22%|██▏       | 74/341 [00:01<00:05, 53.33it/s, Epoch: 5, Batch: 74,Loss: -0.407,Avg.Loss: -0.568,LR: 4.47E-04]Training epoch 5:  22%|██▏       | 74/341 [00:01<00:05, 53.33it/s, Epoch: 5, Batch: 75,Loss: -0.412,Avg.Loss: -0.566,LR: 4.47E-04]Training epoch 5:  22%|██▏       | 75/341 [00:01<00:04, 53.33it/s, Epoch: 5, Batch: 76,Loss: -0.320,Avg.Loss: -0.562,LR: 4.47E-04]Training epoch 5:  22%|██▏       | 76/341 [00:01<00:04, 53.33it/s, Epoch: 5, Batch: 77,Loss: -0.010,Avg.Loss: -0.555,LR: 4.47E-04]Training epoch 5:  23%|██▎       | 77/341 [00:01<00:04, 53.33it/s, Epoch: 5, Batch: 78,Loss: -0.581,Avg.Loss: -0.556,LR: 4.47E-04]Training epoch 5:  23%|██▎       | 78/341 [00:01<00:04, 53.33it/s, Epoch: 5, Batch: 79,Loss: -0.656,Avg.Loss: -0.557,LR: 4.47E-04]Training epoch 5:  23%|██▎       | 79/341 [00:01<00:04, 53.33it/s, Epoch: 5, Batch: 80,Loss: 0.393,Avg.Loss: -0.545,LR: 4.47E-04] Training epoch 5:  23%|██▎       | 80/341 [00:01<00:05, 52.16it/s, Epoch: 5, Batch: 80,Loss: 0.393,Avg.Loss: -0.545,LR: 4.47E-04]Training epoch 5:  23%|██▎       | 80/341 [00:01<00:05, 52.16it/s, Epoch: 5, Batch: 81,Loss: -0.010,Avg.Loss: -0.538,LR: 4.47E-04]Training epoch 5:  24%|██▍       | 81/341 [00:01<00:04, 52.16it/s, Epoch: 5, Batch: 82,Loss: -0.076,Avg.Loss: -0.533,LR: 4.47E-04]Training epoch 5:  24%|██▍       | 82/341 [00:01<00:04, 52.16it/s, Epoch: 5, Batch: 83,Loss: -0.280,Avg.Loss: -0.530,LR: 4.46E-04]Training epoch 5:  24%|██▍       | 83/341 [00:01<00:04, 52.16it/s, Epoch: 5, Batch: 84,Loss: 0.392,Avg.Loss: -0.519,LR: 4.46E-04] Training epoch 5:  25%|██▍       | 84/341 [00:01<00:04, 52.16it/s, Epoch: 5, Batch: 85,Loss: 0.035,Avg.Loss: -0.512,LR: 4.46E-04]Training epoch 5:  25%|██▍       | 85/341 [00:01<00:04, 52.16it/s, Epoch: 5, Batch: 86,Loss: -0.758,Avg.Loss: -0.515,LR: 4.46E-04]Training epoch 5:  25%|██▌       | 86/341 [00:01<00:05, 50.44it/s, Epoch: 5, Batch: 86,Loss: -0.758,Avg.Loss: -0.515,LR: 4.46E-04]Training epoch 5:  25%|██▌       | 86/341 [00:01<00:05, 50.44it/s, Epoch: 5, Batch: 87,Loss: 0.413,Avg.Loss: -0.504,LR: 4.46E-04] Training epoch 5:  26%|██▌       | 87/341 [00:01<00:05, 50.44it/s, Epoch: 5, Batch: 88,Loss: 1.872,Avg.Loss: -0.477,LR: 4.46E-04]Training epoch 5:  26%|██▌       | 88/341 [00:01<00:05, 50.44it/s, Epoch: 5, Batch: 89,Loss: 2.072,Avg.Loss: -0.449,LR: 4.46E-04]Training epoch 5:  26%|██▌       | 89/341 [00:01<00:04, 50.44it/s, Epoch: 5, Batch: 90,Loss: 0.272,Avg.Loss: -0.441,LR: 4.46E-04]Training epoch 5:  26%|██▋       | 90/341 [00:01<00:04, 50.44it/s, Epoch: 5, Batch: 91,Loss: -0.588,Avg.Loss: -0.442,LR: 4.46E-04]Training epoch 5:  27%|██▋       | 91/341 [00:01<00:04, 50.44it/s, Epoch: 5, Batch: 92,Loss: -0.839,Avg.Loss: -0.447,LR: 4.46E-04]Training epoch 5:  27%|██▋       | 92/341 [00:01<00:04, 49.93it/s, Epoch: 5, Batch: 92,Loss: -0.839,Avg.Loss: -0.447,LR: 4.46E-04]Training epoch 5:  27%|██▋       | 92/341 [00:01<00:04, 49.93it/s, Epoch: 5, Batch: 93,Loss: -0.543,Avg.Loss: -0.448,LR: 4.46E-04]Training epoch 5:  27%|██▋       | 93/341 [00:01<00:04, 49.93it/s, Epoch: 5, Batch: 94,Loss: 0.097,Avg.Loss: -0.442,LR: 4.46E-04] Training epoch 5:  28%|██▊       | 94/341 [00:01<00:04, 49.93it/s, Epoch: 5, Batch: 95,Loss: 0.310,Avg.Loss: -0.434,LR: 4.46E-04]Training epoch 5:  28%|██▊       | 95/341 [00:01<00:04, 49.93it/s, Epoch: 5, Batch: 96,Loss: 0.117,Avg.Loss: -0.428,LR: 4.46E-04]Training epoch 5:  28%|██▊       | 96/341 [00:01<00:04, 49.93it/s, Epoch: 5, Batch: 97,Loss: -0.859,Avg.Loss: -0.433,LR: 4.45E-04]Training epoch 5:  28%|██▊       | 97/341 [00:01<00:04, 49.93it/s, Epoch: 5, Batch: 98,Loss: -0.391,Avg.Loss: -0.432,LR: 4.45E-04]Training epoch 5:  29%|██▊       | 98/341 [00:01<00:04, 50.21it/s, Epoch: 5, Batch: 98,Loss: -0.391,Avg.Loss: -0.432,LR: 4.45E-04]Training epoch 5:  29%|██▊       | 98/341 [00:01<00:04, 50.21it/s, Epoch: 5, Batch: 99,Loss: 0.350,Avg.Loss: -0.424,LR: 4.45E-04] Training epoch 5:  29%|██▉       | 99/341 [00:01<00:04, 50.21it/s, Epoch: 5, Batch: 100,Loss: 0.289,Avg.Loss: -0.417,LR: 4.45E-04]Training epoch 5:  29%|██▉       | 100/341 [00:01<00:04, 50.21it/s, Epoch: 5, Batch: 101,Loss: -0.258,Avg.Loss: -0.416,LR: 4.45E-04]Training epoch 5:  30%|██▉       | 101/341 [00:01<00:04, 50.21it/s, Epoch: 5, Batch: 102,Loss: 0.625,Avg.Loss: -0.405,LR: 4.45E-04] Training epoch 5:  30%|██▉       | 102/341 [00:01<00:04, 50.21it/s, Epoch: 5, Batch: 103,Loss: 1.970,Avg.Loss: -0.382,LR: 4.45E-04]Training epoch 5:  30%|███       | 103/341 [00:02<00:04, 50.21it/s, Epoch: 5, Batch: 104,Loss: 1.833,Avg.Loss: -0.361,LR: 4.45E-04]Training epoch 5:  30%|███       | 104/341 [00:02<00:04, 51.04it/s, Epoch: 5, Batch: 104,Loss: 1.833,Avg.Loss: -0.361,LR: 4.45E-04]Training epoch 5:  30%|███       | 104/341 [00:02<00:04, 51.04it/s, Epoch: 5, Batch: 105,Loss: 0.455,Avg.Loss: -0.353,LR: 4.45E-04]Training epoch 5:  31%|███       | 105/341 [00:02<00:04, 51.04it/s, Epoch: 5, Batch: 106,Loss: -0.455,Avg.Loss: -0.354,LR: 4.45E-04]Training epoch 5:  31%|███       | 106/341 [00:02<00:04, 51.04it/s, Epoch: 5, Batch: 107,Loss: -0.590,Avg.Loss: -0.357,LR: 4.45E-04]Training epoch 5:  31%|███▏      | 107/341 [00:02<00:04, 51.04it/s, Epoch: 5, Batch: 108,Loss: -0.630,Avg.Loss: -0.359,LR: 4.45E-04]Training epoch 5:  32%|███▏      | 108/341 [00:02<00:04, 51.04it/s, Epoch: 5, Batch: 109,Loss: -0.372,Avg.Loss: -0.359,LR: 4.45E-04]Training epoch 5:  32%|███▏      | 109/341 [00:02<00:04, 51.04it/s, Epoch: 5, Batch: 110,Loss: -0.249,Avg.Loss: -0.358,LR: 4.45E-04]Training epoch 5:  32%|███▏      | 110/341 [00:02<00:04, 51.28it/s, Epoch: 5, Batch: 110,Loss: -0.249,Avg.Loss: -0.358,LR: 4.45E-04]Training epoch 5:  32%|███▏      | 110/341 [00:02<00:04, 51.28it/s, Epoch: 5, Batch: 111,Loss: -0.202,Avg.Loss: -0.357,LR: 4.44E-04]Training epoch 5:  33%|███▎      | 111/341 [00:02<00:04, 51.28it/s, Epoch: 5, Batch: 112,Loss: -0.780,Avg.Loss: -0.361,LR: 4.44E-04]Training epoch 5:  33%|███▎      | 112/341 [00:02<00:04, 51.28it/s, Epoch: 5, Batch: 113,Loss: -0.540,Avg.Loss: -0.362,LR: 4.44E-04]Training epoch 5:  33%|███▎      | 113/341 [00:02<00:04, 51.28it/s, Epoch: 5, Batch: 114,Loss: 0.471,Avg.Loss: -0.355,LR: 4.44E-04] Training epoch 5:  33%|███▎      | 114/341 [00:02<00:04, 51.28it/s, Epoch: 5, Batch: 115,Loss: 0.398,Avg.Loss: -0.348,LR: 4.44E-04]Training epoch 5:  34%|███▎      | 115/341 [00:02<00:04, 51.28it/s, Epoch: 5, Batch: 116,Loss: 0.981,Avg.Loss: -0.337,LR: 4.44E-04]Training epoch 5:  34%|███▍      | 116/341 [00:02<00:04, 49.71it/s, Epoch: 5, Batch: 116,Loss: 0.981,Avg.Loss: -0.337,LR: 4.44E-04]Training epoch 5:  34%|███▍      | 116/341 [00:02<00:04, 49.71it/s, Epoch: 5, Batch: 117,Loss: -0.070,Avg.Loss: -0.335,LR: 4.44E-04]Training epoch 5:  34%|███▍      | 117/341 [00:02<00:04, 49.71it/s, Epoch: 5, Batch: 118,Loss: -0.795,Avg.Loss: -0.338,LR: 4.44E-04]Training epoch 5:  35%|███▍      | 118/341 [00:02<00:04, 49.71it/s, Epoch: 5, Batch: 119,Loss: -0.401,Avg.Loss: -0.339,LR: 4.44E-04]Training epoch 5:  35%|███▍      | 119/341 [00:02<00:04, 49.71it/s, Epoch: 5, Batch: 120,Loss: -0.231,Avg.Loss: -0.338,LR: 4.44E-04]Training epoch 5:  35%|███▌      | 120/341 [00:02<00:04, 49.71it/s, Epoch: 5, Batch: 121,Loss: 0.288,Avg.Loss: -0.333,LR: 4.44E-04] Training epoch 5:  35%|███▌      | 121/341 [00:02<00:04, 49.34it/s, Epoch: 5, Batch: 121,Loss: 0.288,Avg.Loss: -0.333,LR: 4.44E-04]Training epoch 5:  35%|███▌      | 121/341 [00:02<00:04, 49.34it/s, Epoch: 5, Batch: 122,Loss: -0.143,Avg.Loss: -0.331,LR: 4.44E-04]Training epoch 5:  36%|███▌      | 122/341 [00:02<00:04, 49.34it/s, Epoch: 5, Batch: 123,Loss: -0.608,Avg.Loss: -0.334,LR: 4.44E-04]Training epoch 5:  36%|███▌      | 123/341 [00:02<00:04, 49.34it/s, Epoch: 5, Batch: 124,Loss: -0.774,Avg.Loss: -0.337,LR: 4.44E-04]Training epoch 5:  36%|███▋      | 124/341 [00:02<00:04, 49.34it/s, Epoch: 5, Batch: 125,Loss: -0.622,Avg.Loss: -0.339,LR: 4.43E-04]Training epoch 5:  37%|███▋      | 125/341 [00:02<00:04, 49.34it/s, Epoch: 5, Batch: 126,Loss: -0.177,Avg.Loss: -0.338,LR: 4.43E-04]Training epoch 5:  37%|███▋      | 126/341 [00:02<00:04, 49.34it/s, Epoch: 5, Batch: 127,Loss: -0.336,Avg.Loss: -0.338,LR: 4.43E-04]Training epoch 5:  37%|███▋      | 127/341 [00:02<00:04, 49.68it/s, Epoch: 5, Batch: 127,Loss: -0.336,Avg.Loss: -0.338,LR: 4.43E-04]Training epoch 5:  37%|███▋      | 127/341 [00:02<00:04, 49.68it/s, Epoch: 5, Batch: 128,Loss: -0.176,Avg.Loss: -0.337,LR: 4.43E-04]Training epoch 5:  38%|███▊      | 128/341 [00:02<00:04, 49.68it/s, Epoch: 5, Batch: 129,Loss: -0.180,Avg.Loss: -0.336,LR: 4.43E-04]Training epoch 5:  38%|███▊      | 129/341 [00:02<00:04, 49.68it/s, Epoch: 5, Batch: 130,Loss: -0.010,Avg.Loss: -0.333,LR: 4.43E-04]Training epoch 5:  38%|███▊      | 130/341 [00:02<00:04, 49.68it/s, Epoch: 5, Batch: 131,Loss: -0.369,Avg.Loss: -0.333,LR: 4.43E-04]Training epoch 5:  38%|███▊      | 131/341 [00:02<00:04, 49.68it/s, Epoch: 5, Batch: 132,Loss: -0.140,Avg.Loss: -0.332,LR: 4.43E-04]Training epoch 5:  39%|███▊      | 132/341 [00:02<00:04, 49.68it/s, Epoch: 5, Batch: 133,Loss: 0.348,Avg.Loss: -0.327,LR: 4.43E-04] Training epoch 5:  39%|███▉      | 133/341 [00:02<00:04, 50.31it/s, Epoch: 5, Batch: 133,Loss: 0.348,Avg.Loss: -0.327,LR: 4.43E-04]Training epoch 5:  39%|███▉      | 133/341 [00:02<00:04, 50.31it/s, Epoch: 5, Batch: 134,Loss: 0.311,Avg.Loss: -0.322,LR: 4.43E-04]Training epoch 5:  39%|███▉      | 134/341 [00:02<00:04, 50.31it/s, Epoch: 5, Batch: 135,Loss: -0.028,Avg.Loss: -0.320,LR: 4.43E-04]Training epoch 5:  40%|███▉      | 135/341 [00:02<00:04, 50.31it/s, Epoch: 5, Batch: 136,Loss: -0.040,Avg.Loss: -0.318,LR: 4.43E-04]Training epoch 5:  40%|███▉      | 136/341 [00:02<00:04, 50.31it/s, Epoch: 5, Batch: 137,Loss: -0.057,Avg.Loss: -0.316,LR: 4.43E-04]Training epoch 5:  40%|████      | 137/341 [00:02<00:04, 50.31it/s, Epoch: 5, Batch: 138,Loss: -0.391,Avg.Loss: -0.316,LR: 4.43E-04]Training epoch 5:  40%|████      | 138/341 [00:02<00:04, 50.31it/s, Epoch: 5, Batch: 139,Loss: -0.490,Avg.Loss: -0.318,LR: 4.42E-04]Training epoch 5:  41%|████      | 139/341 [00:02<00:03, 51.45it/s, Epoch: 5, Batch: 139,Loss: -0.490,Avg.Loss: -0.318,LR: 4.42E-04]Training epoch 5:  41%|████      | 139/341 [00:02<00:03, 51.45it/s, Epoch: 5, Batch: 140,Loss: -0.151,Avg.Loss: -0.317,LR: 4.42E-04]Training epoch 5:  41%|████      | 140/341 [00:02<00:03, 51.45it/s, Epoch: 5, Batch: 141,Loss: -0.378,Avg.Loss: -0.317,LR: 4.42E-04]Training epoch 5:  41%|████▏     | 141/341 [00:02<00:03, 51.45it/s, Epoch: 5, Batch: 142,Loss: -0.716,Avg.Loss: -0.320,LR: 4.42E-04]Training epoch 5:  42%|████▏     | 142/341 [00:02<00:03, 51.45it/s, Epoch: 5, Batch: 143,Loss: -0.550,Avg.Loss: -0.321,LR: 4.42E-04]Training epoch 5:  42%|████▏     | 143/341 [00:02<00:03, 51.45it/s, Epoch: 5, Batch: 144,Loss: -0.767,Avg.Loss: -0.324,LR: 4.42E-04]Training epoch 5:  42%|████▏     | 144/341 [00:02<00:03, 51.45it/s, Epoch: 5, Batch: 145,Loss: -1.088,Avg.Loss: -0.330,LR: 4.42E-04]Training epoch 5:  43%|████▎     | 145/341 [00:02<00:03, 51.63it/s, Epoch: 5, Batch: 145,Loss: -1.088,Avg.Loss: -0.330,LR: 4.42E-04]Training epoch 5:  43%|████▎     | 145/341 [00:02<00:03, 51.63it/s, Epoch: 5, Batch: 146,Loss: -0.853,Avg.Loss: -0.333,LR: 4.42E-04]Training epoch 5:  43%|████▎     | 146/341 [00:02<00:03, 51.63it/s, Epoch: 5, Batch: 147,Loss: -0.821,Avg.Loss: -0.337,LR: 4.42E-04]Training epoch 5:  43%|████▎     | 147/341 [00:02<00:03, 51.63it/s, Epoch: 5, Batch: 148,Loss: -0.888,Avg.Loss: -0.340,LR: 4.42E-04]Training epoch 5:  43%|████▎     | 148/341 [00:02<00:03, 51.63it/s, Epoch: 5, Batch: 149,Loss: -0.968,Avg.Loss: -0.345,LR: 4.42E-04]Training epoch 5:  44%|████▎     | 149/341 [00:02<00:03, 51.63it/s, Epoch: 5, Batch: 150,Loss: -0.594,Avg.Loss: -0.346,LR: 4.42E-04]Training epoch 5:  44%|████▍     | 150/341 [00:02<00:03, 51.63it/s, Epoch: 5, Batch: 151,Loss: -1.084,Avg.Loss: -0.351,LR: 4.42E-04]Training epoch 5:  44%|████▍     | 151/341 [00:02<00:03, 51.72it/s, Epoch: 5, Batch: 151,Loss: -1.084,Avg.Loss: -0.351,LR: 4.42E-04]Training epoch 5:  44%|████▍     | 151/341 [00:02<00:03, 51.72it/s, Epoch: 5, Batch: 152,Loss: -1.061,Avg.Loss: -0.356,LR: 4.41E-04]Training epoch 5:  45%|████▍     | 152/341 [00:02<00:03, 51.72it/s, Epoch: 5, Batch: 153,Loss: -1.156,Avg.Loss: -0.361,LR: 4.41E-04]Training epoch 5:  45%|████▍     | 153/341 [00:02<00:03, 51.72it/s, Epoch: 5, Batch: 154,Loss: -1.199,Avg.Loss: -0.366,LR: 4.41E-04]Training epoch 5:  45%|████▌     | 154/341 [00:02<00:03, 51.72it/s, Epoch: 5, Batch: 155,Loss: -1.153,Avg.Loss: -0.372,LR: 4.41E-04]Training epoch 5:  45%|████▌     | 155/341 [00:03<00:03, 51.72it/s, Epoch: 5, Batch: 156,Loss: -1.288,Avg.Loss: -0.377,LR: 4.41E-04]Training epoch 5:  46%|████▌     | 156/341 [00:03<00:03, 51.72it/s, Epoch: 5, Batch: 157,Loss: -0.973,Avg.Loss: -0.381,LR: 4.41E-04]Training epoch 5:  46%|████▌     | 157/341 [00:03<00:03, 52.13it/s, Epoch: 5, Batch: 157,Loss: -0.973,Avg.Loss: -0.381,LR: 4.41E-04]Training epoch 5:  46%|████▌     | 157/341 [00:03<00:03, 52.13it/s, Epoch: 5, Batch: 158,Loss: -0.913,Avg.Loss: -0.385,LR: 4.41E-04]Training epoch 5:  46%|████▋     | 158/341 [00:03<00:03, 52.13it/s, Epoch: 5, Batch: 159,Loss: -0.826,Avg.Loss: -0.387,LR: 4.41E-04]Training epoch 5:  47%|████▋     | 159/341 [00:03<00:03, 52.13it/s, Epoch: 5, Batch: 160,Loss: -1.389,Avg.Loss: -0.394,LR: 4.41E-04]Training epoch 5:  47%|████▋     | 160/341 [00:03<00:03, 52.13it/s, Epoch: 5, Batch: 161,Loss: -1.426,Avg.Loss: -0.400,LR: 4.41E-04]Training epoch 5:  47%|████▋     | 161/341 [00:03<00:03, 52.13it/s, Epoch: 5, Batch: 162,Loss: -1.292,Avg.Loss: -0.406,LR: 4.41E-04]Training epoch 5:  48%|████▊     | 162/341 [00:03<00:03, 52.13it/s, Epoch: 5, Batch: 163,Loss: -1.218,Avg.Loss: -0.411,LR: 4.41E-04]Training epoch 5:  48%|████▊     | 163/341 [00:03<00:03, 52.29it/s, Epoch: 5, Batch: 163,Loss: -1.218,Avg.Loss: -0.411,LR: 4.41E-04]Training epoch 5:  48%|████▊     | 163/341 [00:03<00:03, 52.29it/s, Epoch: 5, Batch: 164,Loss: -1.175,Avg.Loss: -0.415,LR: 4.41E-04]Training epoch 5:  48%|████▊     | 164/341 [00:03<00:03, 52.29it/s, Epoch: 5, Batch: 165,Loss: -1.369,Avg.Loss: -0.421,LR: 4.41E-04]Training epoch 5:  48%|████▊     | 165/341 [00:03<00:03, 52.29it/s, Epoch: 5, Batch: 166,Loss: -0.695,Avg.Loss: -0.423,LR: 4.40E-04]Training epoch 5:  49%|████▊     | 166/341 [00:03<00:03, 52.29it/s, Epoch: 5, Batch: 167,Loss: -0.716,Avg.Loss: -0.424,LR: 4.40E-04]Training epoch 5:  49%|████▉     | 167/341 [00:03<00:03, 52.29it/s, Epoch: 5, Batch: 168,Loss: -0.622,Avg.Loss: -0.426,LR: 4.40E-04]Training epoch 5:  49%|████▉     | 168/341 [00:03<00:03, 52.29it/s, Epoch: 5, Batch: 169,Loss: 0.435,Avg.Loss: -0.420,LR: 4.40E-04] Training epoch 5:  50%|████▉     | 169/341 [00:03<00:03, 51.86it/s, Epoch: 5, Batch: 169,Loss: 0.435,Avg.Loss: -0.420,LR: 4.40E-04]Training epoch 5:  50%|████▉     | 169/341 [00:03<00:03, 51.86it/s, Epoch: 5, Batch: 170,Loss: 0.323,Avg.Loss: -0.416,LR: 4.40E-04]Training epoch 5:  50%|████▉     | 170/341 [00:03<00:03, 51.86it/s, Epoch: 5, Batch: 171,Loss: -0.122,Avg.Loss: -0.414,LR: 4.40E-04]Training epoch 5:  50%|█████     | 171/341 [00:03<00:03, 51.86it/s, Epoch: 5, Batch: 172,Loss: -0.925,Avg.Loss: -0.417,LR: 4.40E-04]Training epoch 5:  50%|█████     | 172/341 [00:03<00:03, 51.86it/s, Epoch: 5, Batch: 173,Loss: -0.157,Avg.Loss: -0.416,LR: 4.40E-04]Training epoch 5:  51%|█████     | 173/341 [00:03<00:03, 51.86it/s, Epoch: 5, Batch: 174,Loss: 0.108,Avg.Loss: -0.413,LR: 4.40E-04] Training epoch 5:  51%|█████     | 174/341 [00:03<00:03, 51.86it/s, Epoch: 5, Batch: 175,Loss: -0.748,Avg.Loss: -0.415,LR: 4.40E-04]Training epoch 5:  51%|█████▏    | 175/341 [00:03<00:03, 51.28it/s, Epoch: 5, Batch: 175,Loss: -0.748,Avg.Loss: -0.415,LR: 4.40E-04]Training epoch 5:  51%|█████▏    | 175/341 [00:03<00:03, 51.28it/s, Epoch: 5, Batch: 176,Loss: -0.112,Avg.Loss: -0.413,LR: 4.40E-04]Training epoch 5:  52%|█████▏    | 176/341 [00:03<00:03, 51.28it/s, Epoch: 5, Batch: 177,Loss: -1.314,Avg.Loss: -0.418,LR: 4.40E-04]Training epoch 5:  52%|█████▏    | 177/341 [00:03<00:03, 51.28it/s, Epoch: 5, Batch: 178,Loss: 0.313,Avg.Loss: -0.414,LR: 4.40E-04] Training epoch 5:  52%|█████▏    | 178/341 [00:03<00:03, 51.28it/s, Epoch: 5, Batch: 179,Loss: 0.378,Avg.Loss: -0.410,LR: 4.39E-04]Training epoch 5:  52%|█████▏    | 179/341 [00:03<00:03, 51.28it/s, Epoch: 5, Batch: 180,Loss: 0.240,Avg.Loss: -0.406,LR: 4.39E-04]Training epoch 5:  53%|█████▎    | 180/341 [00:03<00:03, 51.28it/s, Epoch: 5, Batch: 181,Loss: -0.813,Avg.Loss: -0.408,LR: 4.39E-04]Training epoch 5:  53%|█████▎    | 181/341 [00:03<00:03, 51.10it/s, Epoch: 5, Batch: 181,Loss: -0.813,Avg.Loss: -0.408,LR: 4.39E-04]Training epoch 5:  53%|█████▎    | 181/341 [00:03<00:03, 51.10it/s, Epoch: 5, Batch: 182,Loss: -0.531,Avg.Loss: -0.409,LR: 4.39E-04]Training epoch 5:  53%|█████▎    | 182/341 [00:03<00:03, 51.10it/s, Epoch: 5, Batch: 183,Loss: -1.410,Avg.Loss: -0.414,LR: 4.39E-04]Training epoch 5:  54%|█████▎    | 183/341 [00:03<00:03, 51.10it/s, Epoch: 5, Batch: 184,Loss: -0.291,Avg.Loss: -0.414,LR: 4.39E-04]Training epoch 5:  54%|█████▍    | 184/341 [00:03<00:03, 51.10it/s, Epoch: 5, Batch: 185,Loss: 0.860,Avg.Loss: -0.407,LR: 4.39E-04] Training epoch 5:  54%|█████▍    | 185/341 [00:03<00:03, 51.10it/s, Epoch: 5, Batch: 186,Loss: 0.669,Avg.Loss: -0.401,LR: 4.39E-04]Training epoch 5:  55%|█████▍    | 186/341 [00:03<00:03, 51.10it/s, Epoch: 5, Batch: 187,Loss: 0.297,Avg.Loss: -0.397,LR: 4.39E-04]Training epoch 5:  55%|█████▍    | 187/341 [00:03<00:02, 51.60it/s, Epoch: 5, Batch: 187,Loss: 0.297,Avg.Loss: -0.397,LR: 4.39E-04]Training epoch 5:  55%|█████▍    | 187/341 [00:03<00:02, 51.60it/s, Epoch: 5, Batch: 188,Loss: 0.873,Avg.Loss: -0.391,LR: 4.39E-04]Training epoch 5:  55%|█████▌    | 188/341 [00:03<00:02, 51.60it/s, Epoch: 5, Batch: 189,Loss: -0.113,Avg.Loss: -0.389,LR: 4.39E-04]Training epoch 5:  55%|█████▌    | 189/341 [00:03<00:02, 51.60it/s, Epoch: 5, Batch: 190,Loss: -1.101,Avg.Loss: -0.393,LR: 4.39E-04]Training epoch 5:  56%|█████▌    | 190/341 [00:03<00:02, 51.60it/s, Epoch: 5, Batch: 191,Loss: -0.286,Avg.Loss: -0.392,LR: 4.39E-04]Training epoch 5:  56%|█████▌    | 191/341 [00:03<00:02, 51.60it/s, Epoch: 5, Batch: 192,Loss: 0.065,Avg.Loss: -0.390,LR: 4.38E-04] Training epoch 5:  56%|█████▋    | 192/341 [00:03<00:02, 51.60it/s, Epoch: 5, Batch: 193,Loss: 0.150,Avg.Loss: -0.387,LR: 4.38E-04]Training epoch 5:  57%|█████▋    | 193/341 [00:03<00:02, 51.74it/s, Epoch: 5, Batch: 193,Loss: 0.150,Avg.Loss: -0.387,LR: 4.38E-04]Training epoch 5:  57%|█████▋    | 193/341 [00:03<00:02, 51.74it/s, Epoch: 5, Batch: 194,Loss: -0.305,Avg.Loss: -0.387,LR: 4.38E-04]Training epoch 5:  57%|█████▋    | 194/341 [00:03<00:02, 51.74it/s, Epoch: 5, Batch: 195,Loss: -0.565,Avg.Loss: -0.388,LR: 4.38E-04]Training epoch 5:  57%|█████▋    | 195/341 [00:03<00:02, 51.74it/s, Epoch: 5, Batch: 196,Loss: -0.899,Avg.Loss: -0.390,LR: 4.38E-04]Training epoch 5:  57%|█████▋    | 196/341 [00:03<00:02, 51.74it/s, Epoch: 5, Batch: 197,Loss: -0.282,Avg.Loss: -0.390,LR: 4.38E-04]Training epoch 5:  58%|█████▊    | 197/341 [00:03<00:02, 51.74it/s, Epoch: 5, Batch: 198,Loss: -0.085,Avg.Loss: -0.388,LR: 4.38E-04]Training epoch 5:  58%|█████▊    | 198/341 [00:03<00:02, 51.74it/s, Epoch: 5, Batch: 199,Loss: 0.155,Avg.Loss: -0.385,LR: 4.38E-04] Training epoch 5:  58%|█████▊    | 199/341 [00:03<00:02, 51.89it/s, Epoch: 5, Batch: 199,Loss: 0.155,Avg.Loss: -0.385,LR: 4.38E-04]Training epoch 5:  58%|█████▊    | 199/341 [00:03<00:02, 51.89it/s, Epoch: 5, Batch: 200,Loss: 0.396,Avg.Loss: -0.381,LR: 4.38E-04]Training epoch 5:  59%|█████▊    | 200/341 [00:03<00:02, 51.89it/s, Epoch: 5, Batch: 201,Loss: 0.105,Avg.Loss: -0.379,LR: 4.38E-04]Training epoch 5:  59%|█████▉    | 201/341 [00:03<00:02, 51.89it/s, Epoch: 5, Batch: 202,Loss: -0.342,Avg.Loss: -0.379,LR: 4.38E-04]Training epoch 5:  59%|█████▉    | 202/341 [00:03<00:02, 51.89it/s, Epoch: 5, Batch: 203,Loss: 0.038,Avg.Loss: -0.377,LR: 4.38E-04] Training epoch 5:  60%|█████▉    | 203/341 [00:03<00:02, 51.89it/s, Epoch: 5, Batch: 204,Loss: -0.413,Avg.Loss: -0.377,LR: 4.38E-04]Training epoch 5:  60%|█████▉    | 204/341 [00:03<00:02, 51.89it/s, Epoch: 5, Batch: 205,Loss: -0.820,Avg.Loss: -0.379,LR: 4.37E-04]Training epoch 5:  60%|██████    | 205/341 [00:03<00:02, 51.98it/s, Epoch: 5, Batch: 205,Loss: -0.820,Avg.Loss: -0.379,LR: 4.37E-04]Training epoch 5:  60%|██████    | 205/341 [00:03<00:02, 51.98it/s, Epoch: 5, Batch: 206,Loss: -0.648,Avg.Loss: -0.380,LR: 4.37E-04]Training epoch 5:  60%|██████    | 206/341 [00:04<00:02, 51.98it/s, Epoch: 5, Batch: 207,Loss: -0.123,Avg.Loss: -0.379,LR: 4.37E-04]Training epoch 5:  61%|██████    | 207/341 [00:04<00:02, 51.98it/s, Epoch: 5, Batch: 208,Loss: 0.410,Avg.Loss: -0.375,LR: 4.37E-04] Training epoch 5:  61%|██████    | 208/341 [00:04<00:02, 51.98it/s, Epoch: 5, Batch: 209,Loss: 1.181,Avg.Loss: -0.368,LR: 4.37E-04]Training epoch 5:  61%|██████▏   | 209/341 [00:04<00:02, 51.98it/s, Epoch: 5, Batch: 210,Loss: 0.970,Avg.Loss: -0.362,LR: 4.37E-04]Training epoch 5:  62%|██████▏   | 210/341 [00:04<00:02, 51.98it/s, Epoch: 5, Batch: 211,Loss: 0.431,Avg.Loss: -0.358,LR: 4.37E-04]Training epoch 5:  62%|██████▏   | 211/341 [00:04<00:02, 51.99it/s, Epoch: 5, Batch: 211,Loss: 0.431,Avg.Loss: -0.358,LR: 4.37E-04]Training epoch 5:  62%|██████▏   | 211/341 [00:04<00:02, 51.99it/s, Epoch: 5, Batch: 212,Loss: -0.361,Avg.Loss: -0.358,LR: 4.37E-04]Training epoch 5:  62%|██████▏   | 212/341 [00:04<00:02, 51.99it/s, Epoch: 5, Batch: 213,Loss: -0.806,Avg.Loss: -0.360,LR: 4.37E-04]Training epoch 5:  62%|██████▏   | 213/341 [00:04<00:02, 51.99it/s, Epoch: 5, Batch: 214,Loss: -0.878,Avg.Loss: -0.362,LR: 4.37E-04]Training epoch 5:  63%|██████▎   | 214/341 [00:04<00:02, 51.99it/s, Epoch: 5, Batch: 215,Loss: -0.558,Avg.Loss: -0.363,LR: 4.37E-04]Training epoch 5:  63%|██████▎   | 215/341 [00:04<00:02, 51.99it/s, Epoch: 5, Batch: 216,Loss: -0.601,Avg.Loss: -0.364,LR: 4.37E-04]Training epoch 5:  63%|██████▎   | 216/341 [00:04<00:02, 51.99it/s, Epoch: 5, Batch: 217,Loss: -0.373,Avg.Loss: -0.364,LR: 4.37E-04]Training epoch 5:  64%|██████▎   | 217/341 [00:04<00:02, 52.29it/s, Epoch: 5, Batch: 217,Loss: -0.373,Avg.Loss: -0.364,LR: 4.37E-04]Training epoch 5:  64%|██████▎   | 217/341 [00:04<00:02, 52.29it/s, Epoch: 5, Batch: 218,Loss: -0.077,Avg.Loss: -0.363,LR: 4.37E-04]Training epoch 5:  64%|██████▍   | 218/341 [00:04<00:02, 52.29it/s, Epoch: 5, Batch: 219,Loss: -0.129,Avg.Loss: -0.362,LR: 4.36E-04]Training epoch 5:  64%|██████▍   | 219/341 [00:04<00:02, 52.29it/s, Epoch: 5, Batch: 220,Loss: -0.871,Avg.Loss: -0.364,LR: 4.36E-04]Training epoch 5:  65%|██████▍   | 220/341 [00:04<00:02, 52.29it/s, Epoch: 5, Batch: 221,Loss: -0.646,Avg.Loss: -0.366,LR: 4.36E-04]Training epoch 5:  65%|██████▍   | 221/341 [00:04<00:02, 52.29it/s, Epoch: 5, Batch: 222,Loss: -0.759,Avg.Loss: -0.367,LR: 4.36E-04]Training epoch 5:  65%|██████▌   | 222/341 [00:04<00:02, 52.29it/s, Epoch: 5, Batch: 223,Loss: -0.886,Avg.Loss: -0.370,LR: 4.36E-04]Training epoch 5:  65%|██████▌   | 223/341 [00:04<00:02, 53.06it/s, Epoch: 5, Batch: 223,Loss: -0.886,Avg.Loss: -0.370,LR: 4.36E-04]Training epoch 5:  65%|██████▌   | 223/341 [00:04<00:02, 53.06it/s, Epoch: 5, Batch: 224,Loss: -1.111,Avg.Loss: -0.373,LR: 4.36E-04]Training epoch 5:  66%|██████▌   | 224/341 [00:04<00:02, 53.06it/s, Epoch: 5, Batch: 225,Loss: -0.298,Avg.Loss: -0.373,LR: 4.36E-04]Training epoch 5:  66%|██████▌   | 225/341 [00:04<00:02, 53.06it/s, Epoch: 5, Batch: 226,Loss: 0.018,Avg.Loss: -0.371,LR: 4.36E-04] Training epoch 5:  66%|██████▋   | 226/341 [00:04<00:02, 53.06it/s, Epoch: 5, Batch: 227,Loss: -0.668,Avg.Loss: -0.372,LR: 4.36E-04]Training epoch 5:  67%|██████▋   | 227/341 [00:04<00:02, 53.06it/s, Epoch: 5, Batch: 228,Loss: -0.854,Avg.Loss: -0.374,LR: 4.36E-04]Training epoch 5:  67%|██████▋   | 228/341 [00:04<00:02, 53.06it/s, Epoch: 5, Batch: 229,Loss: -0.678,Avg.Loss: -0.376,LR: 4.36E-04]Training epoch 5:  67%|██████▋   | 229/341 [00:04<00:02, 53.25it/s, Epoch: 5, Batch: 229,Loss: -0.678,Avg.Loss: -0.376,LR: 4.36E-04]Training epoch 5:  67%|██████▋   | 229/341 [00:04<00:02, 53.25it/s, Epoch: 5, Batch: 230,Loss: -0.770,Avg.Loss: -0.377,LR: 4.36E-04]Training epoch 5:  67%|██████▋   | 230/341 [00:04<00:02, 53.25it/s, Epoch: 5, Batch: 231,Loss: -0.591,Avg.Loss: -0.378,LR: 4.36E-04]Training epoch 5:  68%|██████▊   | 231/341 [00:04<00:02, 53.25it/s, Epoch: 5, Batch: 232,Loss: 0.084,Avg.Loss: -0.376,LR: 4.35E-04] Training epoch 5:  68%|██████▊   | 232/341 [00:04<00:02, 53.25it/s, Epoch: 5, Batch: 233,Loss: -0.675,Avg.Loss: -0.378,LR: 4.35E-04]Training epoch 5:  68%|██████▊   | 233/341 [00:04<00:02, 53.25it/s, Epoch: 5, Batch: 234,Loss: -0.405,Avg.Loss: -0.378,LR: 4.35E-04]Training epoch 5:  69%|██████▊   | 234/341 [00:04<00:02, 53.25it/s, Epoch: 5, Batch: 235,Loss: -0.393,Avg.Loss: -0.378,LR: 4.35E-04]Training epoch 5:  69%|██████▉   | 235/341 [00:04<00:01, 53.21it/s, Epoch: 5, Batch: 235,Loss: -0.393,Avg.Loss: -0.378,LR: 4.35E-04]Training epoch 5:  69%|██████▉   | 235/341 [00:04<00:01, 53.21it/s, Epoch: 5, Batch: 236,Loss: -0.589,Avg.Loss: -0.379,LR: 4.35E-04]Training epoch 5:  69%|██████▉   | 236/341 [00:04<00:01, 53.21it/s, Epoch: 5, Batch: 237,Loss: -0.252,Avg.Loss: -0.378,LR: 4.35E-04]Training epoch 5:  70%|██████▉   | 237/341 [00:04<00:01, 53.21it/s, Epoch: 5, Batch: 238,Loss: -0.822,Avg.Loss: -0.380,LR: 4.35E-04]Training epoch 5:  70%|██████▉   | 238/341 [00:04<00:01, 53.21it/s, Epoch: 5, Batch: 239,Loss: -1.016,Avg.Loss: -0.383,LR: 4.35E-04]Training epoch 5:  70%|███████   | 239/341 [00:04<00:01, 53.21it/s, Epoch: 5, Batch: 240,Loss: -1.018,Avg.Loss: -0.385,LR: 4.35E-04]Training epoch 5:  70%|███████   | 240/341 [00:04<00:01, 53.21it/s, Epoch: 5, Batch: 241,Loss: -0.901,Avg.Loss: -0.387,LR: 4.35E-04]Training epoch 5:  71%|███████   | 241/341 [00:04<00:01, 53.34it/s, Epoch: 5, Batch: 241,Loss: -0.901,Avg.Loss: -0.387,LR: 4.35E-04]Training epoch 5:  71%|███████   | 241/341 [00:04<00:01, 53.34it/s, Epoch: 5, Batch: 242,Loss: -1.114,Avg.Loss: -0.390,LR: 4.35E-04]Training epoch 5:  71%|███████   | 242/341 [00:04<00:01, 53.34it/s, Epoch: 5, Batch: 243,Loss: -1.130,Avg.Loss: -0.394,LR: 4.35E-04]Training epoch 5:  71%|███████▏  | 243/341 [00:04<00:01, 53.34it/s, Epoch: 5, Batch: 244,Loss: -1.129,Avg.Loss: -0.397,LR: 4.34E-04]Training epoch 5:  72%|███████▏  | 244/341 [00:04<00:01, 53.34it/s, Epoch: 5, Batch: 245,Loss: -1.223,Avg.Loss: -0.400,LR: 4.34E-04]Training epoch 5:  72%|███████▏  | 245/341 [00:04<00:01, 53.34it/s, Epoch: 5, Batch: 246,Loss: -1.041,Avg.Loss: -0.403,LR: 4.34E-04]Training epoch 5:  72%|███████▏  | 246/341 [00:04<00:01, 53.34it/s, Epoch: 5, Batch: 247,Loss: -0.916,Avg.Loss: -0.405,LR: 4.34E-04]Training epoch 5:  72%|███████▏  | 247/341 [00:04<00:01, 53.27it/s, Epoch: 5, Batch: 247,Loss: -0.916,Avg.Loss: -0.405,LR: 4.34E-04]Training epoch 5:  72%|███████▏  | 247/341 [00:04<00:01, 53.27it/s, Epoch: 5, Batch: 248,Loss: -0.883,Avg.Loss: -0.407,LR: 4.34E-04]Training epoch 5:  73%|███████▎  | 248/341 [00:04<00:01, 53.27it/s, Epoch: 5, Batch: 249,Loss: -1.071,Avg.Loss: -0.409,LR: 4.34E-04]Training epoch 5:  73%|███████▎  | 249/341 [00:04<00:01, 53.27it/s, Epoch: 5, Batch: 250,Loss: -1.351,Avg.Loss: -0.413,LR: 4.34E-04]Training epoch 5:  73%|███████▎  | 250/341 [00:04<00:01, 53.27it/s, Epoch: 5, Batch: 251,Loss: -0.915,Avg.Loss: -0.415,LR: 4.34E-04]Training epoch 5:  74%|███████▎  | 251/341 [00:04<00:01, 53.27it/s, Epoch: 5, Batch: 252,Loss: -1.140,Avg.Loss: -0.418,LR: 4.34E-04]Training epoch 5:  74%|███████▍  | 252/341 [00:04<00:01, 53.27it/s, Epoch: 5, Batch: 253,Loss: -0.442,Avg.Loss: -0.418,LR: 4.34E-04]Training epoch 5:  74%|███████▍  | 253/341 [00:04<00:01, 52.80it/s, Epoch: 5, Batch: 253,Loss: -0.442,Avg.Loss: -0.418,LR: 4.34E-04]Training epoch 5:  74%|███████▍  | 253/341 [00:04<00:01, 52.80it/s, Epoch: 5, Batch: 254,Loss: -0.898,Avg.Loss: -0.420,LR: 4.34E-04]Training epoch 5:  74%|███████▍  | 254/341 [00:04<00:01, 52.80it/s, Epoch: 5, Batch: 255,Loss: -0.805,Avg.Loss: -0.421,LR: 4.34E-04]Training epoch 5:  75%|███████▍  | 255/341 [00:04<00:01, 52.80it/s, Epoch: 5, Batch: 256,Loss: -0.490,Avg.Loss: -0.422,LR: 4.34E-04]Training epoch 5:  75%|███████▌  | 256/341 [00:04<00:01, 52.80it/s, Epoch: 5, Batch: 257,Loss: -0.061,Avg.Loss: -0.420,LR: 4.33E-04]Training epoch 5:  75%|███████▌  | 257/341 [00:04<00:01, 52.80it/s, Epoch: 5, Batch: 258,Loss: -0.854,Avg.Loss: -0.422,LR: 4.33E-04]Training epoch 5:  76%|███████▌  | 258/341 [00:04<00:01, 52.80it/s, Epoch: 5, Batch: 259,Loss: -0.243,Avg.Loss: -0.421,LR: 4.33E-04]Training epoch 5:  76%|███████▌  | 259/341 [00:04<00:01, 52.59it/s, Epoch: 5, Batch: 259,Loss: -0.243,Avg.Loss: -0.421,LR: 4.33E-04]Training epoch 5:  76%|███████▌  | 259/341 [00:05<00:01, 52.59it/s, Epoch: 5, Batch: 260,Loss: 0.632,Avg.Loss: -0.417,LR: 4.33E-04] Training epoch 5:  76%|███████▌  | 260/341 [00:05<00:01, 52.59it/s, Epoch: 5, Batch: 261,Loss: 1.102,Avg.Loss: -0.411,LR: 4.33E-04]Training epoch 5:  77%|███████▋  | 261/341 [00:05<00:01, 52.59it/s, Epoch: 5, Batch: 262,Loss: -0.629,Avg.Loss: -0.412,LR: 4.33E-04]Training epoch 5:  77%|███████▋  | 262/341 [00:05<00:01, 52.59it/s, Epoch: 5, Batch: 263,Loss: -0.061,Avg.Loss: -0.411,LR: 4.33E-04]Training epoch 5:  77%|███████▋  | 263/341 [00:05<00:01, 52.59it/s, Epoch: 5, Batch: 264,Loss: 0.328,Avg.Loss: -0.408,LR: 4.33E-04] Training epoch 5:  77%|███████▋  | 264/341 [00:05<00:01, 52.59it/s, Epoch: 5, Batch: 265,Loss: -0.968,Avg.Loss: -0.410,LR: 4.33E-04]Training epoch 5:  78%|███████▊  | 265/341 [00:05<00:01, 52.63it/s, Epoch: 5, Batch: 265,Loss: -0.968,Avg.Loss: -0.410,LR: 4.33E-04]Training epoch 5:  78%|███████▊  | 265/341 [00:05<00:01, 52.63it/s, Epoch: 5, Batch: 266,Loss: -0.837,Avg.Loss: -0.412,LR: 4.33E-04]Training epoch 5:  78%|███████▊  | 266/341 [00:05<00:01, 52.63it/s, Epoch: 5, Batch: 267,Loss: -0.474,Avg.Loss: -0.412,LR: 4.33E-04]Training epoch 5:  78%|███████▊  | 267/341 [00:05<00:01, 52.63it/s, Epoch: 5, Batch: 268,Loss: -0.670,Avg.Loss: -0.413,LR: 4.33E-04]Training epoch 5:  79%|███████▊  | 268/341 [00:05<00:01, 52.63it/s, Epoch: 5, Batch: 269,Loss: -0.224,Avg.Loss: -0.412,LR: 4.33E-04]Training epoch 5:  79%|███████▉  | 269/341 [00:05<00:01, 52.63it/s, Epoch: 5, Batch: 270,Loss: 0.307,Avg.Loss: -0.410,LR: 4.32E-04] Training epoch 5:  79%|███████▉  | 270/341 [00:05<00:01, 52.63it/s, Epoch: 5, Batch: 271,Loss: -0.880,Avg.Loss: -0.411,LR: 4.32E-04]Training epoch 5:  79%|███████▉  | 271/341 [00:05<00:01, 52.14it/s, Epoch: 5, Batch: 271,Loss: -0.880,Avg.Loss: -0.411,LR: 4.32E-04]Training epoch 5:  79%|███████▉  | 271/341 [00:05<00:01, 52.14it/s, Epoch: 5, Batch: 272,Loss: -1.270,Avg.Loss: -0.414,LR: 4.32E-04]Training epoch 5:  80%|███████▉  | 272/341 [00:05<00:01, 52.14it/s, Epoch: 5, Batch: 273,Loss: -0.591,Avg.Loss: -0.415,LR: 4.32E-04]Training epoch 5:  80%|████████  | 273/341 [00:05<00:01, 52.14it/s, Epoch: 5, Batch: 274,Loss: -0.776,Avg.Loss: -0.416,LR: 4.32E-04]Training epoch 5:  80%|████████  | 274/341 [00:05<00:01, 52.14it/s, Epoch: 5, Batch: 275,Loss: -0.346,Avg.Loss: -0.416,LR: 4.32E-04]Training epoch 5:  81%|████████  | 275/341 [00:05<00:01, 52.14it/s, Epoch: 5, Batch: 276,Loss: 1.478,Avg.Loss: -0.409,LR: 4.32E-04] Training epoch 5:  81%|████████  | 276/341 [00:05<00:01, 52.14it/s, Epoch: 5, Batch: 277,Loss: -0.486,Avg.Loss: -0.410,LR: 4.32E-04]Training epoch 5:  81%|████████  | 277/341 [00:05<00:01, 52.11it/s, Epoch: 5, Batch: 277,Loss: -0.486,Avg.Loss: -0.410,LR: 4.32E-04]Training epoch 5:  81%|████████  | 277/341 [00:05<00:01, 52.11it/s, Epoch: 5, Batch: 278,Loss: -1.024,Avg.Loss: -0.412,LR: 4.32E-04]Training epoch 5:  82%|████████▏ | 278/341 [00:05<00:01, 52.11it/s, Epoch: 5, Batch: 279,Loss: -1.140,Avg.Loss: -0.414,LR: 4.32E-04]Training epoch 5:  82%|████████▏ | 279/341 [00:05<00:01, 52.11it/s, Epoch: 5, Batch: 280,Loss: -0.851,Avg.Loss: -0.416,LR: 4.32E-04]Training epoch 5:  82%|████████▏ | 280/341 [00:05<00:01, 52.11it/s, Epoch: 5, Batch: 281,Loss: -0.989,Avg.Loss: -0.418,LR: 4.32E-04]Training epoch 5:  82%|████████▏ | 281/341 [00:05<00:01, 52.11it/s, Epoch: 5, Batch: 282,Loss: -1.327,Avg.Loss: -0.421,LR: 4.32E-04]Training epoch 5:  83%|████████▎ | 282/341 [00:05<00:01, 52.11it/s, Epoch: 5, Batch: 283,Loss: -1.246,Avg.Loss: -0.424,LR: 4.31E-04]Training epoch 5:  83%|████████▎ | 283/341 [00:05<00:01, 51.01it/s, Epoch: 5, Batch: 283,Loss: -1.246,Avg.Loss: -0.424,LR: 4.31E-04]Training epoch 5:  83%|████████▎ | 283/341 [00:05<00:01, 51.01it/s, Epoch: 5, Batch: 284,Loss: -0.855,Avg.Loss: -0.426,LR: 4.31E-04]Training epoch 5:  83%|████████▎ | 284/341 [00:05<00:01, 51.01it/s, Epoch: 5, Batch: 285,Loss: -0.611,Avg.Loss: -0.426,LR: 4.31E-04]Training epoch 5:  84%|████████▎ | 285/341 [00:05<00:01, 51.01it/s, Epoch: 5, Batch: 286,Loss: -0.538,Avg.Loss: -0.427,LR: 4.31E-04]Training epoch 5:  84%|████████▍ | 286/341 [00:05<00:01, 51.01it/s, Epoch: 5, Batch: 287,Loss: 0.417,Avg.Loss: -0.424,LR: 4.31E-04] Training epoch 5:  84%|████████▍ | 287/341 [00:05<00:01, 51.01it/s, Epoch: 5, Batch: 288,Loss: -0.533,Avg.Loss: -0.424,LR: 4.31E-04]Training epoch 5:  84%|████████▍ | 288/341 [00:05<00:01, 51.01it/s, Epoch: 5, Batch: 289,Loss: -0.731,Avg.Loss: -0.425,LR: 4.31E-04]Training epoch 5:  85%|████████▍ | 289/341 [00:05<00:00, 52.01it/s, Epoch: 5, Batch: 289,Loss: -0.731,Avg.Loss: -0.425,LR: 4.31E-04]Training epoch 5:  85%|████████▍ | 289/341 [00:05<00:00, 52.01it/s, Epoch: 5, Batch: 290,Loss: -0.516,Avg.Loss: -0.426,LR: 4.31E-04]Training epoch 5:  85%|████████▌ | 290/341 [00:05<00:00, 52.01it/s, Epoch: 5, Batch: 291,Loss: -1.046,Avg.Loss: -0.428,LR: 4.31E-04]Training epoch 5:  85%|████████▌ | 291/341 [00:05<00:00, 52.01it/s, Epoch: 5, Batch: 292,Loss: -0.716,Avg.Loss: -0.429,LR: 4.31E-04]Training epoch 5:  86%|████████▌ | 292/341 [00:05<00:00, 52.01it/s, Epoch: 5, Batch: 293,Loss: -0.241,Avg.Loss: -0.428,LR: 4.31E-04]Training epoch 5:  86%|████████▌ | 293/341 [00:05<00:00, 52.01it/s, Epoch: 5, Batch: 294,Loss: -1.009,Avg.Loss: -0.430,LR: 4.31E-04]Training epoch 5:  86%|████████▌ | 294/341 [00:05<00:00, 52.01it/s, Epoch: 5, Batch: 295,Loss: -0.647,Avg.Loss: -0.431,LR: 4.30E-04]Training epoch 5:  87%|████████▋ | 295/341 [00:05<00:00, 52.03it/s, Epoch: 5, Batch: 295,Loss: -0.647,Avg.Loss: -0.431,LR: 4.30E-04]Training epoch 5:  87%|████████▋ | 295/341 [00:05<00:00, 52.03it/s, Epoch: 5, Batch: 296,Loss: -0.110,Avg.Loss: -0.430,LR: 4.30E-04]Training epoch 5:  87%|████████▋ | 296/341 [00:05<00:00, 52.03it/s, Epoch: 5, Batch: 297,Loss: -0.998,Avg.Loss: -0.432,LR: 4.30E-04]Training epoch 5:  87%|████████▋ | 297/341 [00:05<00:00, 52.03it/s, Epoch: 5, Batch: 298,Loss: -1.119,Avg.Loss: -0.434,LR: 4.30E-04]Training epoch 5:  87%|████████▋ | 298/341 [00:05<00:00, 52.03it/s, Epoch: 5, Batch: 299,Loss: -0.906,Avg.Loss: -0.435,LR: 4.30E-04]Training epoch 5:  88%|████████▊ | 299/341 [00:05<00:00, 52.03it/s, Epoch: 5, Batch: 300,Loss: -1.146,Avg.Loss: -0.438,LR: 4.30E-04]Training epoch 5:  88%|████████▊ | 300/341 [00:05<00:00, 52.03it/s, Epoch: 5, Batch: 301,Loss: -0.595,Avg.Loss: -0.438,LR: 4.30E-04]Training epoch 5:  88%|████████▊ | 301/341 [00:05<00:00, 53.40it/s, Epoch: 5, Batch: 301,Loss: -0.595,Avg.Loss: -0.438,LR: 4.30E-04]Training epoch 5:  88%|████████▊ | 301/341 [00:05<00:00, 53.40it/s, Epoch: 5, Batch: 302,Loss: -0.518,Avg.Loss: -0.439,LR: 4.30E-04]Training epoch 5:  89%|████████▊ | 302/341 [00:05<00:00, 53.40it/s, Epoch: 5, Batch: 303,Loss: -0.663,Avg.Loss: -0.439,LR: 4.30E-04]Training epoch 5:  89%|████████▉ | 303/341 [00:05<00:00, 53.40it/s, Epoch: 5, Batch: 304,Loss: -1.212,Avg.Loss: -0.442,LR: 4.30E-04]Training epoch 5:  89%|████████▉ | 304/341 [00:05<00:00, 53.40it/s, Epoch: 5, Batch: 305,Loss: -0.359,Avg.Loss: -0.442,LR: 4.30E-04]Training epoch 5:  89%|████████▉ | 305/341 [00:05<00:00, 53.40it/s, Epoch: 5, Batch: 306,Loss: -1.070,Avg.Loss: -0.444,LR: 4.30E-04]Training epoch 5:  90%|████████▉ | 306/341 [00:05<00:00, 53.40it/s, Epoch: 5, Batch: 307,Loss: -0.956,Avg.Loss: -0.445,LR: 4.30E-04]Training epoch 5:  90%|█████████ | 307/341 [00:05<00:00, 54.27it/s, Epoch: 5, Batch: 307,Loss: -0.956,Avg.Loss: -0.445,LR: 4.30E-04]Training epoch 5:  90%|█████████ | 307/341 [00:05<00:00, 54.27it/s, Epoch: 5, Batch: 308,Loss: -0.717,Avg.Loss: -0.446,LR: 4.29E-04]Training epoch 5:  90%|█████████ | 308/341 [00:05<00:00, 54.27it/s, Epoch: 5, Batch: 309,Loss: -1.117,Avg.Loss: -0.448,LR: 4.29E-04]Training epoch 5:  91%|█████████ | 309/341 [00:05<00:00, 54.27it/s, Epoch: 5, Batch: 310,Loss: -1.103,Avg.Loss: -0.450,LR: 4.29E-04]Training epoch 5:  91%|█████████ | 310/341 [00:05<00:00, 54.27it/s, Epoch: 5, Batch: 311,Loss: -0.795,Avg.Loss: -0.452,LR: 4.29E-04]Training epoch 5:  91%|█████████ | 311/341 [00:05<00:00, 54.27it/s, Epoch: 5, Batch: 312,Loss: -1.242,Avg.Loss: -0.454,LR: 4.29E-04]Training epoch 5:  91%|█████████▏| 312/341 [00:06<00:00, 54.27it/s, Epoch: 5, Batch: 313,Loss: -0.932,Avg.Loss: -0.456,LR: 4.29E-04]Training epoch 5:  92%|█████████▏| 313/341 [00:06<00:00, 52.55it/s, Epoch: 5, Batch: 313,Loss: -0.932,Avg.Loss: -0.456,LR: 4.29E-04]Training epoch 5:  92%|█████████▏| 313/341 [00:06<00:00, 52.55it/s, Epoch: 5, Batch: 314,Loss: -0.206,Avg.Loss: -0.455,LR: 4.29E-04]Training epoch 5:  92%|█████████▏| 314/341 [00:06<00:00, 52.55it/s, Epoch: 5, Batch: 315,Loss: -1.068,Avg.Loss: -0.457,LR: 4.29E-04]Training epoch 5:  92%|█████████▏| 315/341 [00:06<00:00, 52.55it/s, Epoch: 5, Batch: 316,Loss: -1.374,Avg.Loss: -0.460,LR: 4.29E-04]Training epoch 5:  93%|█████████▎| 316/341 [00:06<00:00, 52.55it/s, Epoch: 5, Batch: 317,Loss: -0.827,Avg.Loss: -0.461,LR: 4.29E-04]Training epoch 5:  93%|█████████▎| 317/341 [00:06<00:00, 52.55it/s, Epoch: 5, Batch: 318,Loss: -1.041,Avg.Loss: -0.463,LR: 4.29E-04]Training epoch 5:  93%|█████████▎| 318/341 [00:06<00:00, 52.55it/s, Epoch: 5, Batch: 319,Loss: -0.929,Avg.Loss: -0.464,LR: 4.29E-04]Training epoch 5:  94%|█████████▎| 319/341 [00:06<00:00, 51.84it/s, Epoch: 5, Batch: 319,Loss: -0.929,Avg.Loss: -0.464,LR: 4.29E-04]Training epoch 5:  94%|█████████▎| 319/341 [00:06<00:00, 51.84it/s, Epoch: 5, Batch: 320,Loss: -0.221,Avg.Loss: -0.463,LR: 4.28E-04]Training epoch 5:  94%|█████████▍| 320/341 [00:06<00:00, 51.84it/s, Epoch: 5, Batch: 321,Loss: -1.158,Avg.Loss: -0.466,LR: 4.28E-04]Training epoch 5:  94%|█████████▍| 321/341 [00:06<00:00, 51.84it/s, Epoch: 5, Batch: 322,Loss: -1.422,Avg.Loss: -0.469,LR: 4.28E-04]Training epoch 5:  94%|█████████▍| 322/341 [00:06<00:00, 51.84it/s, Epoch: 5, Batch: 323,Loss: -0.989,Avg.Loss: -0.470,LR: 4.28E-04]Training epoch 5:  95%|█████████▍| 323/341 [00:06<00:00, 51.84it/s, Epoch: 5, Batch: 324,Loss: -1.383,Avg.Loss: -0.473,LR: 4.28E-04]Training epoch 5:  95%|█████████▌| 324/341 [00:06<00:00, 51.84it/s, Epoch: 5, Batch: 325,Loss: -1.024,Avg.Loss: -0.475,LR: 4.28E-04]Training epoch 5:  95%|█████████▌| 325/341 [00:06<00:00, 51.91it/s, Epoch: 5, Batch: 325,Loss: -1.024,Avg.Loss: -0.475,LR: 4.28E-04]Training epoch 5:  95%|█████████▌| 325/341 [00:06<00:00, 51.91it/s, Epoch: 5, Batch: 326,Loss: -0.464,Avg.Loss: -0.475,LR: 4.28E-04]Training epoch 5:  96%|█████████▌| 326/341 [00:06<00:00, 51.91it/s, Epoch: 5, Batch: 327,Loss: -0.919,Avg.Loss: -0.476,LR: 4.28E-04]Training epoch 5:  96%|█████████▌| 327/341 [00:06<00:00, 51.91it/s, Epoch: 5, Batch: 328,Loss: -1.547,Avg.Loss: -0.479,LR: 4.28E-04]Training epoch 5:  96%|█████████▌| 328/341 [00:06<00:00, 51.91it/s, Epoch: 5, Batch: 329,Loss: -1.177,Avg.Loss: -0.481,LR: 4.28E-04]Training epoch 5:  96%|█████████▋| 329/341 [00:06<00:00, 51.91it/s, Epoch: 5, Batch: 330,Loss: -1.210,Avg.Loss: -0.484,LR: 4.28E-04]Training epoch 5:  97%|█████████▋| 330/341 [00:06<00:00, 51.91it/s, Epoch: 5, Batch: 331,Loss: -0.851,Avg.Loss: -0.485,LR: 4.28E-04]Training epoch 5:  97%|█████████▋| 331/341 [00:06<00:00, 51.18it/s, Epoch: 5, Batch: 331,Loss: -0.851,Avg.Loss: -0.485,LR: 4.28E-04]Training epoch 5:  97%|█████████▋| 331/341 [00:06<00:00, 51.18it/s, Epoch: 5, Batch: 332,Loss: -0.249,Avg.Loss: -0.484,LR: 4.28E-04]Training epoch 5:  97%|█████████▋| 332/341 [00:06<00:00, 51.18it/s, Epoch: 5, Batch: 333,Loss: -1.207,Avg.Loss: -0.486,LR: 4.27E-04]Training epoch 5:  98%|█████████▊| 333/341 [00:06<00:00, 51.18it/s, Epoch: 5, Batch: 334,Loss: -1.239,Avg.Loss: -0.488,LR: 4.27E-04]Training epoch 5:  98%|█████████▊| 334/341 [00:06<00:00, 51.18it/s, Epoch: 5, Batch: 335,Loss: -0.905,Avg.Loss: -0.490,LR: 4.27E-04]Training epoch 5:  98%|█████████▊| 335/341 [00:06<00:00, 51.18it/s, Epoch: 5, Batch: 336,Loss: -1.112,Avg.Loss: -0.491,LR: 4.27E-04]Training epoch 5:  99%|█████████▊| 336/341 [00:06<00:00, 51.18it/s, Epoch: 5, Batch: 337,Loss: -0.991,Avg.Loss: -0.493,LR: 4.27E-04]Training epoch 5:  99%|█████████▉| 337/341 [00:06<00:00, 51.73it/s, Epoch: 5, Batch: 337,Loss: -0.991,Avg.Loss: -0.493,LR: 4.27E-04]Training epoch 5:  99%|█████████▉| 337/341 [00:06<00:00, 51.73it/s, Epoch: 5, Batch: 338,Loss: -0.471,Avg.Loss: -0.493,LR: 4.27E-04]Training epoch 5:  99%|█████████▉| 338/341 [00:06<00:00, 51.73it/s, Epoch: 5, Batch: 339,Loss: -1.274,Avg.Loss: -0.495,LR: 4.27E-04]Training epoch 5:  99%|█████████▉| 339/341 [00:06<00:00, 51.73it/s, Epoch: 5, Batch: 340,Loss: -0.958,Avg.Loss: -0.497,LR: 4.27E-04]Training epoch 5: 100%|█████████▉| 340/341 [00:06<00:00, 51.73it/s, Epoch: 5, Batch: 341,Loss: -0.254,Avg.Loss: -0.496,LR: 4.27E-04]Training epoch 5: 100%|██████████| 341/341 [00:06<00:00, 51.94it/s, Epoch: 5, Batch: 341,Loss: -0.254,Avg.Loss: -0.496,LR: 4.27E-04]
Training epoch 6:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 6:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 6, Batch: 1,Loss: -1.292,Avg.Loss: -1.292,LR: 4.27E-04]Training epoch 6:   0%|          | 1/341 [00:00<00:13, 25.24it/s, Epoch: 6, Batch: 2,Loss: -1.153,Avg.Loss: -1.223,LR: 4.27E-04]Training epoch 6:   1%|          | 2/341 [00:00<00:09, 35.01it/s, Epoch: 6, Batch: 3,Loss: -0.733,Avg.Loss: -1.059,LR: 4.27E-04]Training epoch 6:   1%|          | 3/341 [00:00<00:09, 36.76it/s, Epoch: 6, Batch: 4,Loss: -1.510,Avg.Loss: -1.172,LR: 4.26E-04]Training epoch 6:   1%|          | 4/341 [00:00<00:08, 38.87it/s, Epoch: 6, Batch: 5,Loss: -0.964,Avg.Loss: -1.130,LR: 4.26E-04]Training epoch 6:   1%|▏         | 5/341 [00:00<00:06, 48.49it/s, Epoch: 6, Batch: 5,Loss: -0.964,Avg.Loss: -1.130,LR: 4.26E-04]Training epoch 6:   1%|▏         | 5/341 [00:00<00:06, 48.49it/s, Epoch: 6, Batch: 6,Loss: -0.407,Avg.Loss: -1.010,LR: 4.26E-04]Training epoch 6:   2%|▏         | 6/341 [00:00<00:06, 48.49it/s, Epoch: 6, Batch: 7,Loss: -1.392,Avg.Loss: -1.065,LR: 4.26E-04]Training epoch 6:   2%|▏         | 7/341 [00:00<00:06, 48.49it/s, Epoch: 6, Batch: 8,Loss: -0.948,Avg.Loss: -1.050,LR: 4.26E-04]Training epoch 6:   2%|▏         | 8/341 [00:00<00:06, 48.49it/s, Epoch: 6, Batch: 9,Loss: -1.104,Avg.Loss: -1.056,LR: 4.26E-04]Training epoch 6:   3%|▎         | 9/341 [00:00<00:06, 48.49it/s, Epoch: 6, Batch: 10,Loss: -1.374,Avg.Loss: -1.088,LR: 4.26E-04]Training epoch 6:   3%|▎         | 10/341 [00:00<00:06, 48.49it/s, Epoch: 6, Batch: 11,Loss: -1.078,Avg.Loss: -1.087,LR: 4.26E-04]Training epoch 6:   3%|▎         | 11/341 [00:00<00:06, 50.02it/s, Epoch: 6, Batch: 11,Loss: -1.078,Avg.Loss: -1.087,LR: 4.26E-04]Training epoch 6:   3%|▎         | 11/341 [00:00<00:06, 50.02it/s, Epoch: 6, Batch: 12,Loss: -0.888,Avg.Loss: -1.070,LR: 4.26E-04]Training epoch 6:   4%|▎         | 12/341 [00:00<00:06, 50.02it/s, Epoch: 6, Batch: 13,Loss: -1.401,Avg.Loss: -1.096,LR: 4.26E-04]Training epoch 6:   4%|▍         | 13/341 [00:00<00:06, 50.02it/s, Epoch: 6, Batch: 14,Loss: -1.133,Avg.Loss: -1.098,LR: 4.26E-04]Training epoch 6:   4%|▍         | 14/341 [00:00<00:06, 50.02it/s, Epoch: 6, Batch: 15,Loss: -0.001,Avg.Loss: -1.025,LR: 4.26E-04]Training epoch 6:   4%|▍         | 15/341 [00:00<00:06, 50.02it/s, Epoch: 6, Batch: 16,Loss: -1.222,Avg.Loss: -1.038,LR: 4.25E-04]Training epoch 6:   5%|▍         | 16/341 [00:00<00:06, 50.02it/s, Epoch: 6, Batch: 17,Loss: -1.363,Avg.Loss: -1.057,LR: 4.25E-04]Training epoch 6:   5%|▍         | 17/341 [00:00<00:06, 51.91it/s, Epoch: 6, Batch: 17,Loss: -1.363,Avg.Loss: -1.057,LR: 4.25E-04]Training epoch 6:   5%|▍         | 17/341 [00:00<00:06, 51.91it/s, Epoch: 6, Batch: 18,Loss: -0.896,Avg.Loss: -1.048,LR: 4.25E-04]Training epoch 6:   5%|▌         | 18/341 [00:00<00:06, 51.91it/s, Epoch: 6, Batch: 19,Loss: -1.165,Avg.Loss: -1.054,LR: 4.25E-04]Training epoch 6:   6%|▌         | 19/341 [00:00<00:06, 51.91it/s, Epoch: 6, Batch: 20,Loss: -0.841,Avg.Loss: -1.043,LR: 4.25E-04]Training epoch 6:   6%|▌         | 20/341 [00:00<00:06, 51.91it/s, Epoch: 6, Batch: 21,Loss: -0.395,Avg.Loss: -1.012,LR: 4.25E-04]Training epoch 6:   6%|▌         | 21/341 [00:00<00:06, 51.91it/s, Epoch: 6, Batch: 22,Loss: -0.951,Avg.Loss: -1.010,LR: 4.25E-04]Training epoch 6:   6%|▋         | 22/341 [00:00<00:06, 51.91it/s, Epoch: 6, Batch: 23,Loss: -1.403,Avg.Loss: -1.027,LR: 4.25E-04]Training epoch 6:   7%|▋         | 23/341 [00:00<00:06, 51.28it/s, Epoch: 6, Batch: 23,Loss: -1.403,Avg.Loss: -1.027,LR: 4.25E-04]Training epoch 6:   7%|▋         | 23/341 [00:00<00:06, 51.28it/s, Epoch: 6, Batch: 24,Loss: -0.754,Avg.Loss: -1.015,LR: 4.25E-04]Training epoch 6:   7%|▋         | 24/341 [00:00<00:06, 51.28it/s, Epoch: 6, Batch: 25,Loss: -1.487,Avg.Loss: -1.034,LR: 4.25E-04]Training epoch 6:   7%|▋         | 25/341 [00:00<00:06, 51.28it/s, Epoch: 6, Batch: 26,Loss: -1.107,Avg.Loss: -1.037,LR: 4.25E-04]Training epoch 6:   8%|▊         | 26/341 [00:00<00:06, 51.28it/s, Epoch: 6, Batch: 27,Loss: -1.346,Avg.Loss: -1.048,LR: 4.25E-04]Training epoch 6:   8%|▊         | 27/341 [00:00<00:06, 51.28it/s, Epoch: 6, Batch: 28,Loss: -0.944,Avg.Loss: -1.045,LR: 4.24E-04]Training epoch 6:   8%|▊         | 28/341 [00:00<00:06, 51.28it/s, Epoch: 6, Batch: 29,Loss: -1.250,Avg.Loss: -1.052,LR: 4.24E-04]Training epoch 6:   9%|▊         | 29/341 [00:00<00:06, 50.82it/s, Epoch: 6, Batch: 29,Loss: -1.250,Avg.Loss: -1.052,LR: 4.24E-04]Training epoch 6:   9%|▊         | 29/341 [00:00<00:06, 50.82it/s, Epoch: 6, Batch: 30,Loss: -1.249,Avg.Loss: -1.058,LR: 4.24E-04]Training epoch 6:   9%|▉         | 30/341 [00:00<00:06, 50.82it/s, Epoch: 6, Batch: 31,Loss: -0.926,Avg.Loss: -1.054,LR: 4.24E-04]Training epoch 6:   9%|▉         | 31/341 [00:00<00:06, 50.82it/s, Epoch: 6, Batch: 32,Loss: -0.141,Avg.Loss: -1.026,LR: 4.24E-04]Training epoch 6:   9%|▉         | 32/341 [00:00<00:06, 50.82it/s, Epoch: 6, Batch: 33,Loss: -0.932,Avg.Loss: -1.023,LR: 4.24E-04]Training epoch 6:  10%|▉         | 33/341 [00:00<00:06, 50.82it/s, Epoch: 6, Batch: 34,Loss: -1.006,Avg.Loss: -1.022,LR: 4.24E-04]Training epoch 6:  10%|▉         | 34/341 [00:00<00:06, 50.82it/s, Epoch: 6, Batch: 35,Loss: -1.498,Avg.Loss: -1.036,LR: 4.24E-04]Training epoch 6:  10%|█         | 35/341 [00:00<00:06, 49.81it/s, Epoch: 6, Batch: 35,Loss: -1.498,Avg.Loss: -1.036,LR: 4.24E-04]Training epoch 6:  10%|█         | 35/341 [00:00<00:06, 49.81it/s, Epoch: 6, Batch: 36,Loss: -0.989,Avg.Loss: -1.035,LR: 4.24E-04]Training epoch 6:  11%|█         | 36/341 [00:00<00:06, 49.81it/s, Epoch: 6, Batch: 37,Loss: -0.933,Avg.Loss: -1.032,LR: 4.24E-04]Training epoch 6:  11%|█         | 37/341 [00:00<00:06, 49.81it/s, Epoch: 6, Batch: 38,Loss: -0.042,Avg.Loss: -1.006,LR: 4.24E-04]Training epoch 6:  11%|█         | 38/341 [00:00<00:06, 49.81it/s, Epoch: 6, Batch: 39,Loss: -1.316,Avg.Loss: -1.014,LR: 4.24E-04]Training epoch 6:  11%|█▏        | 39/341 [00:00<00:06, 49.81it/s, Epoch: 6, Batch: 40,Loss: -1.316,Avg.Loss: -1.021,LR: 4.23E-04]Training epoch 6:  12%|█▏        | 40/341 [00:00<00:06, 49.81it/s, Epoch: 6, Batch: 41,Loss: -0.911,Avg.Loss: -1.019,LR: 4.23E-04]Training epoch 6:  12%|█▏        | 41/341 [00:00<00:05, 50.27it/s, Epoch: 6, Batch: 41,Loss: -0.911,Avg.Loss: -1.019,LR: 4.23E-04]Training epoch 6:  12%|█▏        | 41/341 [00:00<00:05, 50.27it/s, Epoch: 6, Batch: 42,Loss: -0.577,Avg.Loss: -1.008,LR: 4.23E-04]Training epoch 6:  12%|█▏        | 42/341 [00:00<00:05, 50.27it/s, Epoch: 6, Batch: 43,Loss: -0.530,Avg.Loss: -0.997,LR: 4.23E-04]Training epoch 6:  13%|█▎        | 43/341 [00:00<00:05, 50.27it/s, Epoch: 6, Batch: 44,Loss: -0.831,Avg.Loss: -0.993,LR: 4.23E-04]Training epoch 6:  13%|█▎        | 44/341 [00:00<00:05, 50.27it/s, Epoch: 6, Batch: 45,Loss: -1.002,Avg.Loss: -0.993,LR: 4.23E-04]Training epoch 6:  13%|█▎        | 45/341 [00:00<00:05, 50.27it/s, Epoch: 6, Batch: 46,Loss: 0.208,Avg.Loss: -0.967,LR: 4.23E-04] Training epoch 6:  13%|█▎        | 46/341 [00:00<00:05, 50.27it/s, Epoch: 6, Batch: 47,Loss: 1.068,Avg.Loss: -0.924,LR: 4.23E-04]Training epoch 6:  14%|█▍        | 47/341 [00:00<00:05, 50.91it/s, Epoch: 6, Batch: 47,Loss: 1.068,Avg.Loss: -0.924,LR: 4.23E-04]Training epoch 6:  14%|█▍        | 47/341 [00:00<00:05, 50.91it/s, Epoch: 6, Batch: 48,Loss: -0.491,Avg.Loss: -0.915,LR: 4.23E-04]Training epoch 6:  14%|█▍        | 48/341 [00:00<00:05, 50.91it/s, Epoch: 6, Batch: 49,Loss: -1.081,Avg.Loss: -0.918,LR: 4.23E-04]Training epoch 6:  14%|█▍        | 49/341 [00:00<00:05, 50.91it/s, Epoch: 6, Batch: 50,Loss: -0.666,Avg.Loss: -0.913,LR: 4.23E-04]Training epoch 6:  15%|█▍        | 50/341 [00:01<00:05, 50.91it/s, Epoch: 6, Batch: 51,Loss: -0.623,Avg.Loss: -0.908,LR: 4.23E-04]Training epoch 6:  15%|█▍        | 51/341 [00:01<00:05, 50.91it/s, Epoch: 6, Batch: 52,Loss: -0.040,Avg.Loss: -0.891,LR: 4.22E-04]Training epoch 6:  15%|█▌        | 52/341 [00:01<00:05, 50.91it/s, Epoch: 6, Batch: 53,Loss: -0.353,Avg.Loss: -0.881,LR: 4.22E-04]Training epoch 6:  16%|█▌        | 53/341 [00:01<00:05, 50.49it/s, Epoch: 6, Batch: 53,Loss: -0.353,Avg.Loss: -0.881,LR: 4.22E-04]Training epoch 6:  16%|█▌        | 53/341 [00:01<00:05, 50.49it/s, Epoch: 6, Batch: 54,Loss: -1.081,Avg.Loss: -0.884,LR: 4.22E-04]Training epoch 6:  16%|█▌        | 54/341 [00:01<00:05, 50.49it/s, Epoch: 6, Batch: 55,Loss: -0.549,Avg.Loss: -0.878,LR: 4.22E-04]Training epoch 6:  16%|█▌        | 55/341 [00:01<00:05, 50.49it/s, Epoch: 6, Batch: 56,Loss: 0.542,Avg.Loss: -0.853,LR: 4.22E-04] Training epoch 6:  16%|█▋        | 56/341 [00:01<00:05, 50.49it/s, Epoch: 6, Batch: 57,Loss: 1.598,Avg.Loss: -0.810,LR: 4.22E-04]Training epoch 6:  17%|█▋        | 57/341 [00:01<00:05, 50.49it/s, Epoch: 6, Batch: 58,Loss: 1.374,Avg.Loss: -0.772,LR: 4.22E-04]Training epoch 6:  17%|█▋        | 58/341 [00:01<00:05, 50.49it/s, Epoch: 6, Batch: 59,Loss: 0.188,Avg.Loss: -0.756,LR: 4.22E-04]Training epoch 6:  17%|█▋        | 59/341 [00:01<00:05, 50.08it/s, Epoch: 6, Batch: 59,Loss: 0.188,Avg.Loss: -0.756,LR: 4.22E-04]Training epoch 6:  17%|█▋        | 59/341 [00:01<00:05, 50.08it/s, Epoch: 6, Batch: 60,Loss: -0.876,Avg.Loss: -0.758,LR: 4.22E-04]Training epoch 6:  18%|█▊        | 60/341 [00:01<00:05, 50.08it/s, Epoch: 6, Batch: 61,Loss: -0.947,Avg.Loss: -0.761,LR: 4.22E-04]Training epoch 6:  18%|█▊        | 61/341 [00:01<00:05, 50.08it/s, Epoch: 6, Batch: 62,Loss: -0.847,Avg.Loss: -0.762,LR: 4.22E-04]Training epoch 6:  18%|█▊        | 62/341 [00:01<00:05, 50.08it/s, Epoch: 6, Batch: 63,Loss: -0.772,Avg.Loss: -0.763,LR: 4.22E-04]Training epoch 6:  18%|█▊        | 63/341 [00:01<00:05, 50.08it/s, Epoch: 6, Batch: 64,Loss: -0.670,Avg.Loss: -0.761,LR: 4.21E-04]Training epoch 6:  19%|█▉        | 64/341 [00:01<00:05, 50.08it/s, Epoch: 6, Batch: 65,Loss: -0.293,Avg.Loss: -0.754,LR: 4.21E-04]Training epoch 6:  19%|█▉        | 65/341 [00:01<00:05, 49.62it/s, Epoch: 6, Batch: 65,Loss: -0.293,Avg.Loss: -0.754,LR: 4.21E-04]Training epoch 6:  19%|█▉        | 65/341 [00:01<00:05, 49.62it/s, Epoch: 6, Batch: 66,Loss: -0.292,Avg.Loss: -0.747,LR: 4.21E-04]Training epoch 6:  19%|█▉        | 66/341 [00:01<00:05, 49.62it/s, Epoch: 6, Batch: 67,Loss: -0.815,Avg.Loss: -0.748,LR: 4.21E-04]Training epoch 6:  20%|█▉        | 67/341 [00:01<00:05, 49.62it/s, Epoch: 6, Batch: 68,Loss: -1.070,Avg.Loss: -0.753,LR: 4.21E-04]Training epoch 6:  20%|█▉        | 68/341 [00:01<00:05, 49.62it/s, Epoch: 6, Batch: 69,Loss: -0.919,Avg.Loss: -0.755,LR: 4.21E-04]Training epoch 6:  20%|██        | 69/341 [00:01<00:05, 49.62it/s, Epoch: 6, Batch: 70,Loss: -0.373,Avg.Loss: -0.750,LR: 4.21E-04]Training epoch 6:  21%|██        | 70/341 [00:01<00:05, 49.62it/s, Epoch: 6, Batch: 71,Loss: 0.000,Avg.Loss: -0.739,LR: 4.21E-04] Training epoch 6:  21%|██        | 71/341 [00:01<00:05, 50.05it/s, Epoch: 6, Batch: 71,Loss: 0.000,Avg.Loss: -0.739,LR: 4.21E-04]Training epoch 6:  21%|██        | 71/341 [00:01<00:05, 50.05it/s, Epoch: 6, Batch: 72,Loss: 0.112,Avg.Loss: -0.727,LR: 4.21E-04]Training epoch 6:  21%|██        | 72/341 [00:01<00:05, 50.05it/s, Epoch: 6, Batch: 73,Loss: 0.290,Avg.Loss: -0.713,LR: 4.21E-04]Training epoch 6:  21%|██▏       | 73/341 [00:01<00:05, 50.05it/s, Epoch: 6, Batch: 74,Loss: 0.652,Avg.Loss: -0.695,LR: 4.21E-04]Training epoch 6:  22%|██▏       | 74/341 [00:01<00:05, 50.05it/s, Epoch: 6, Batch: 75,Loss: -0.039,Avg.Loss: -0.686,LR: 4.21E-04]Training epoch 6:  22%|██▏       | 75/341 [00:01<00:05, 50.05it/s, Epoch: 6, Batch: 76,Loss: -0.290,Avg.Loss: -0.681,LR: 4.20E-04]Training epoch 6:  22%|██▏       | 76/341 [00:01<00:05, 50.05it/s, Epoch: 6, Batch: 77,Loss: -0.444,Avg.Loss: -0.678,LR: 4.20E-04]Training epoch 6:  23%|██▎       | 77/341 [00:01<00:05, 51.27it/s, Epoch: 6, Batch: 77,Loss: -0.444,Avg.Loss: -0.678,LR: 4.20E-04]Training epoch 6:  23%|██▎       | 77/341 [00:01<00:05, 51.27it/s, Epoch: 6, Batch: 78,Loss: 0.405,Avg.Loss: -0.664,LR: 4.20E-04] Training epoch 6:  23%|██▎       | 78/341 [00:01<00:05, 51.27it/s, Epoch: 6, Batch: 79,Loss: -0.625,Avg.Loss: -0.664,LR: 4.20E-04]Training epoch 6:  23%|██▎       | 79/341 [00:01<00:05, 51.27it/s, Epoch: 6, Batch: 80,Loss: -0.984,Avg.Loss: -0.668,LR: 4.20E-04]Training epoch 6:  23%|██▎       | 80/341 [00:01<00:05, 51.27it/s, Epoch: 6, Batch: 81,Loss: 0.197,Avg.Loss: -0.657,LR: 4.20E-04] Training epoch 6:  24%|██▍       | 81/341 [00:01<00:05, 51.27it/s, Epoch: 6, Batch: 82,Loss: 0.811,Avg.Loss: -0.639,LR: 4.20E-04]Training epoch 6:  24%|██▍       | 82/341 [00:01<00:05, 51.27it/s, Epoch: 6, Batch: 83,Loss: 0.902,Avg.Loss: -0.620,LR: 4.20E-04]Training epoch 6:  24%|██▍       | 83/341 [00:01<00:04, 51.86it/s, Epoch: 6, Batch: 83,Loss: 0.902,Avg.Loss: -0.620,LR: 4.20E-04]Training epoch 6:  24%|██▍       | 83/341 [00:01<00:04, 51.86it/s, Epoch: 6, Batch: 84,Loss: -0.543,Avg.Loss: -0.619,LR: 4.20E-04]Training epoch 6:  25%|██▍       | 84/341 [00:01<00:04, 51.86it/s, Epoch: 6, Batch: 85,Loss: -0.824,Avg.Loss: -0.622,LR: 4.20E-04]Training epoch 6:  25%|██▍       | 85/341 [00:01<00:04, 51.86it/s, Epoch: 6, Batch: 86,Loss: -0.131,Avg.Loss: -0.616,LR: 4.20E-04]Training epoch 6:  25%|██▌       | 86/341 [00:01<00:04, 51.86it/s, Epoch: 6, Batch: 87,Loss: -0.484,Avg.Loss: -0.615,LR: 4.20E-04]Training epoch 6:  26%|██▌       | 87/341 [00:01<00:04, 51.86it/s, Epoch: 6, Batch: 88,Loss: -0.796,Avg.Loss: -0.617,LR: 4.19E-04]Training epoch 6:  26%|██▌       | 88/341 [00:01<00:04, 51.86it/s, Epoch: 6, Batch: 89,Loss: -0.858,Avg.Loss: -0.619,LR: 4.19E-04]Training epoch 6:  26%|██▌       | 89/341 [00:01<00:04, 52.69it/s, Epoch: 6, Batch: 89,Loss: -0.858,Avg.Loss: -0.619,LR: 4.19E-04]Training epoch 6:  26%|██▌       | 89/341 [00:01<00:04, 52.69it/s, Epoch: 6, Batch: 90,Loss: 0.435,Avg.Loss: -0.608,LR: 4.19E-04] Training epoch 6:  26%|██▋       | 90/341 [00:01<00:04, 52.69it/s, Epoch: 6, Batch: 91,Loss: 0.030,Avg.Loss: -0.601,LR: 4.19E-04]Training epoch 6:  27%|██▋       | 91/341 [00:01<00:04, 52.69it/s, Epoch: 6, Batch: 92,Loss: -0.354,Avg.Loss: -0.598,LR: 4.19E-04]Training epoch 6:  27%|██▋       | 92/341 [00:01<00:04, 52.69it/s, Epoch: 6, Batch: 93,Loss: -0.669,Avg.Loss: -0.599,LR: 4.19E-04]Training epoch 6:  27%|██▋       | 93/341 [00:01<00:04, 52.69it/s, Epoch: 6, Batch: 94,Loss: -0.311,Avg.Loss: -0.596,LR: 4.19E-04]Training epoch 6:  28%|██▊       | 94/341 [00:01<00:04, 52.69it/s, Epoch: 6, Batch: 95,Loss: -0.318,Avg.Loss: -0.593,LR: 4.19E-04]Training epoch 6:  28%|██▊       | 95/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 95,Loss: -0.318,Avg.Loss: -0.593,LR: 4.19E-04]Training epoch 6:  28%|██▊       | 95/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 96,Loss: -0.839,Avg.Loss: -0.595,LR: 4.19E-04]Training epoch 6:  28%|██▊       | 96/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 97,Loss: -0.666,Avg.Loss: -0.596,LR: 4.19E-04]Training epoch 6:  28%|██▊       | 97/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 98,Loss: 0.325,Avg.Loss: -0.587,LR: 4.19E-04] Training epoch 6:  29%|██▊       | 98/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 99,Loss: -0.086,Avg.Loss: -0.582,LR: 4.19E-04]Training epoch 6:  29%|██▉       | 99/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 100,Loss: -0.753,Avg.Loss: -0.583,LR: 4.18E-04]Training epoch 6:  29%|██▉       | 100/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 101,Loss: -0.798,Avg.Loss: -0.585,LR: 4.18E-04]Training epoch 6:  30%|██▉       | 101/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 101,Loss: -0.798,Avg.Loss: -0.585,LR: 4.18E-04]Training epoch 6:  30%|██▉       | 101/341 [00:01<00:04, 52.66it/s, Epoch: 6, Batch: 102,Loss: -0.383,Avg.Loss: -0.583,LR: 4.18E-04]Training epoch 6:  30%|██▉       | 102/341 [00:02<00:04, 52.66it/s, Epoch: 6, Batch: 103,Loss: -0.712,Avg.Loss: -0.585,LR: 4.18E-04]Training epoch 6:  30%|███       | 103/341 [00:02<00:04, 52.66it/s, Epoch: 6, Batch: 104,Loss: -0.733,Avg.Loss: -0.586,LR: 4.18E-04]Training epoch 6:  30%|███       | 104/341 [00:02<00:04, 52.66it/s, Epoch: 6, Batch: 105,Loss: -0.450,Avg.Loss: -0.585,LR: 4.18E-04]Training epoch 6:  31%|███       | 105/341 [00:02<00:04, 52.66it/s, Epoch: 6, Batch: 106,Loss: 0.129,Avg.Loss: -0.578,LR: 4.18E-04] Training epoch 6:  31%|███       | 106/341 [00:02<00:04, 52.66it/s, Epoch: 6, Batch: 107,Loss: -0.225,Avg.Loss: -0.575,LR: 4.18E-04]Training epoch 6:  31%|███▏      | 107/341 [00:02<00:04, 52.92it/s, Epoch: 6, Batch: 107,Loss: -0.225,Avg.Loss: -0.575,LR: 4.18E-04]Training epoch 6:  31%|███▏      | 107/341 [00:02<00:04, 52.92it/s, Epoch: 6, Batch: 108,Loss: -0.888,Avg.Loss: -0.578,LR: 4.18E-04]Training epoch 6:  32%|███▏      | 108/341 [00:02<00:04, 52.92it/s, Epoch: 6, Batch: 109,Loss: -0.529,Avg.Loss: -0.577,LR: 4.18E-04]Training epoch 6:  32%|███▏      | 109/341 [00:02<00:04, 52.92it/s, Epoch: 6, Batch: 110,Loss: -0.066,Avg.Loss: -0.573,LR: 4.18E-04]Training epoch 6:  32%|███▏      | 110/341 [00:02<00:04, 52.92it/s, Epoch: 6, Batch: 111,Loss: -0.255,Avg.Loss: -0.570,LR: 4.18E-04]Training epoch 6:  33%|███▎      | 111/341 [00:02<00:04, 52.92it/s, Epoch: 6, Batch: 112,Loss: -0.786,Avg.Loss: -0.572,LR: 4.17E-04]Training epoch 6:  33%|███▎      | 112/341 [00:02<00:04, 52.92it/s, Epoch: 6, Batch: 113,Loss: -0.794,Avg.Loss: -0.574,LR: 4.17E-04]Training epoch 6:  33%|███▎      | 113/341 [00:02<00:04, 52.98it/s, Epoch: 6, Batch: 113,Loss: -0.794,Avg.Loss: -0.574,LR: 4.17E-04]Training epoch 6:  33%|███▎      | 113/341 [00:02<00:04, 52.98it/s, Epoch: 6, Batch: 114,Loss: -0.341,Avg.Loss: -0.572,LR: 4.17E-04]Training epoch 6:  33%|███▎      | 114/341 [00:02<00:04, 52.98it/s, Epoch: 6, Batch: 115,Loss: -0.475,Avg.Loss: -0.571,LR: 4.17E-04]Training epoch 6:  34%|███▎      | 115/341 [00:02<00:04, 52.98it/s, Epoch: 6, Batch: 116,Loss: -0.943,Avg.Loss: -0.574,LR: 4.17E-04]Training epoch 6:  34%|███▍      | 116/341 [00:02<00:04, 52.98it/s, Epoch: 6, Batch: 117,Loss: -0.645,Avg.Loss: -0.575,LR: 4.17E-04]Training epoch 6:  34%|███▍      | 117/341 [00:02<00:04, 52.98it/s, Epoch: 6, Batch: 118,Loss: 0.400,Avg.Loss: -0.566,LR: 4.17E-04] Training epoch 6:  35%|███▍      | 118/341 [00:02<00:04, 52.98it/s, Epoch: 6, Batch: 119,Loss: -0.336,Avg.Loss: -0.564,LR: 4.17E-04]Training epoch 6:  35%|███▍      | 119/341 [00:02<00:04, 53.34it/s, Epoch: 6, Batch: 119,Loss: -0.336,Avg.Loss: -0.564,LR: 4.17E-04]Training epoch 6:  35%|███▍      | 119/341 [00:02<00:04, 53.34it/s, Epoch: 6, Batch: 120,Loss: -0.801,Avg.Loss: -0.566,LR: 4.17E-04]Training epoch 6:  35%|███▌      | 120/341 [00:02<00:04, 53.34it/s, Epoch: 6, Batch: 121,Loss: -0.883,Avg.Loss: -0.569,LR: 4.17E-04]Training epoch 6:  35%|███▌      | 121/341 [00:02<00:04, 53.34it/s, Epoch: 6, Batch: 122,Loss: -0.378,Avg.Loss: -0.567,LR: 4.17E-04]Training epoch 6:  36%|███▌      | 122/341 [00:02<00:04, 53.34it/s, Epoch: 6, Batch: 123,Loss: -0.231,Avg.Loss: -0.565,LR: 4.16E-04]Training epoch 6:  36%|███▌      | 123/341 [00:02<00:04, 53.34it/s, Epoch: 6, Batch: 124,Loss: -0.911,Avg.Loss: -0.568,LR: 4.16E-04]Training epoch 6:  36%|███▋      | 124/341 [00:02<00:04, 53.34it/s, Epoch: 6, Batch: 125,Loss: -0.664,Avg.Loss: -0.568,LR: 4.16E-04]Training epoch 6:  37%|███▋      | 125/341 [00:02<00:04, 52.97it/s, Epoch: 6, Batch: 125,Loss: -0.664,Avg.Loss: -0.568,LR: 4.16E-04]Training epoch 6:  37%|███▋      | 125/341 [00:02<00:04, 52.97it/s, Epoch: 6, Batch: 126,Loss: -0.207,Avg.Loss: -0.565,LR: 4.16E-04]Training epoch 6:  37%|███▋      | 126/341 [00:02<00:04, 52.97it/s, Epoch: 6, Batch: 127,Loss: -0.084,Avg.Loss: -0.562,LR: 4.16E-04]Training epoch 6:  37%|███▋      | 127/341 [00:02<00:04, 52.97it/s, Epoch: 6, Batch: 128,Loss: -1.165,Avg.Loss: -0.566,LR: 4.16E-04]Training epoch 6:  38%|███▊      | 128/341 [00:02<00:04, 52.97it/s, Epoch: 6, Batch: 129,Loss: -0.605,Avg.Loss: -0.567,LR: 4.16E-04]Training epoch 6:  38%|███▊      | 129/341 [00:02<00:04, 52.97it/s, Epoch: 6, Batch: 130,Loss: -0.247,Avg.Loss: -0.564,LR: 4.16E-04]Training epoch 6:  38%|███▊      | 130/341 [00:02<00:03, 52.97it/s, Epoch: 6, Batch: 131,Loss: -0.323,Avg.Loss: -0.562,LR: 4.16E-04]Training epoch 6:  38%|███▊      | 131/341 [00:02<00:03, 52.72it/s, Epoch: 6, Batch: 131,Loss: -0.323,Avg.Loss: -0.562,LR: 4.16E-04]Training epoch 6:  38%|███▊      | 131/341 [00:02<00:03, 52.72it/s, Epoch: 6, Batch: 132,Loss: -1.108,Avg.Loss: -0.566,LR: 4.16E-04]Training epoch 6:  39%|███▊      | 132/341 [00:02<00:03, 52.72it/s, Epoch: 6, Batch: 133,Loss: -0.678,Avg.Loss: -0.567,LR: 4.16E-04]Training epoch 6:  39%|███▉      | 133/341 [00:02<00:03, 52.72it/s, Epoch: 6, Batch: 134,Loss: -0.126,Avg.Loss: -0.564,LR: 4.16E-04]Training epoch 6:  39%|███▉      | 134/341 [00:02<00:03, 52.72it/s, Epoch: 6, Batch: 135,Loss: -0.014,Avg.Loss: -0.560,LR: 4.15E-04]Training epoch 6:  40%|███▉      | 135/341 [00:02<00:03, 52.72it/s, Epoch: 6, Batch: 136,Loss: -1.148,Avg.Loss: -0.564,LR: 4.15E-04]Training epoch 6:  40%|███▉      | 136/341 [00:02<00:03, 52.72it/s, Epoch: 6, Batch: 137,Loss: -1.209,Avg.Loss: -0.569,LR: 4.15E-04]Training epoch 6:  40%|████      | 137/341 [00:02<00:03, 53.77it/s, Epoch: 6, Batch: 137,Loss: -1.209,Avg.Loss: -0.569,LR: 4.15E-04]Training epoch 6:  40%|████      | 137/341 [00:02<00:03, 53.77it/s, Epoch: 6, Batch: 138,Loss: -0.740,Avg.Loss: -0.570,LR: 4.15E-04]Training epoch 6:  40%|████      | 138/341 [00:02<00:03, 53.77it/s, Epoch: 6, Batch: 139,Loss: -0.408,Avg.Loss: -0.569,LR: 4.15E-04]Training epoch 6:  41%|████      | 139/341 [00:02<00:03, 53.77it/s, Epoch: 6, Batch: 140,Loss: -1.135,Avg.Loss: -0.573,LR: 4.15E-04]Training epoch 6:  41%|████      | 140/341 [00:02<00:03, 53.77it/s, Epoch: 6, Batch: 141,Loss: -0.818,Avg.Loss: -0.575,LR: 4.15E-04]Training epoch 6:  41%|████▏     | 141/341 [00:02<00:03, 53.77it/s, Epoch: 6, Batch: 142,Loss: -0.844,Avg.Loss: -0.577,LR: 4.15E-04]Training epoch 6:  42%|████▏     | 142/341 [00:02<00:03, 53.77it/s, Epoch: 6, Batch: 143,Loss: -0.221,Avg.Loss: -0.574,LR: 4.15E-04]Training epoch 6:  42%|████▏     | 143/341 [00:02<00:03, 54.21it/s, Epoch: 6, Batch: 143,Loss: -0.221,Avg.Loss: -0.574,LR: 4.15E-04]Training epoch 6:  42%|████▏     | 143/341 [00:02<00:03, 54.21it/s, Epoch: 6, Batch: 144,Loss: -0.765,Avg.Loss: -0.576,LR: 4.15E-04]Training epoch 6:  42%|████▏     | 144/341 [00:02<00:03, 54.21it/s, Epoch: 6, Batch: 145,Loss: -1.052,Avg.Loss: -0.579,LR: 4.15E-04]Training epoch 6:  43%|████▎     | 145/341 [00:02<00:03, 54.21it/s, Epoch: 6, Batch: 146,Loss: -1.035,Avg.Loss: -0.582,LR: 4.14E-04]Training epoch 6:  43%|████▎     | 146/341 [00:02<00:03, 54.21it/s, Epoch: 6, Batch: 147,Loss: -1.003,Avg.Loss: -0.585,LR: 4.14E-04]Training epoch 6:  43%|████▎     | 147/341 [00:02<00:03, 54.21it/s, Epoch: 6, Batch: 148,Loss: -1.104,Avg.Loss: -0.588,LR: 4.14E-04]Training epoch 6:  43%|████▎     | 148/341 [00:02<00:03, 54.21it/s, Epoch: 6, Batch: 149,Loss: -1.168,Avg.Loss: -0.592,LR: 4.14E-04]Training epoch 6:  44%|████▎     | 149/341 [00:02<00:03, 54.57it/s, Epoch: 6, Batch: 149,Loss: -1.168,Avg.Loss: -0.592,LR: 4.14E-04]Training epoch 6:  44%|████▎     | 149/341 [00:02<00:03, 54.57it/s, Epoch: 6, Batch: 150,Loss: -1.291,Avg.Loss: -0.597,LR: 4.14E-04]Training epoch 6:  44%|████▍     | 150/341 [00:02<00:03, 54.57it/s, Epoch: 6, Batch: 151,Loss: -1.100,Avg.Loss: -0.600,LR: 4.14E-04]Training epoch 6:  44%|████▍     | 151/341 [00:02<00:03, 54.57it/s, Epoch: 6, Batch: 152,Loss: -1.476,Avg.Loss: -0.606,LR: 4.14E-04]Training epoch 6:  45%|████▍     | 152/341 [00:02<00:03, 54.57it/s, Epoch: 6, Batch: 153,Loss: -1.392,Avg.Loss: -0.611,LR: 4.14E-04]Training epoch 6:  45%|████▍     | 153/341 [00:02<00:03, 54.57it/s, Epoch: 6, Batch: 154,Loss: -1.165,Avg.Loss: -0.615,LR: 4.14E-04]Training epoch 6:  45%|████▌     | 154/341 [00:02<00:03, 54.57it/s, Epoch: 6, Batch: 155,Loss: -1.021,Avg.Loss: -0.617,LR: 4.14E-04]Training epoch 6:  45%|████▌     | 155/341 [00:02<00:03, 53.92it/s, Epoch: 6, Batch: 155,Loss: -1.021,Avg.Loss: -0.617,LR: 4.14E-04]Training epoch 6:  45%|████▌     | 155/341 [00:02<00:03, 53.92it/s, Epoch: 6, Batch: 156,Loss: -1.140,Avg.Loss: -0.621,LR: 4.14E-04]Training epoch 6:  46%|████▌     | 156/341 [00:03<00:03, 53.92it/s, Epoch: 6, Batch: 157,Loss: -1.604,Avg.Loss: -0.627,LR: 4.14E-04]Training epoch 6:  46%|████▌     | 157/341 [00:03<00:03, 53.92it/s, Epoch: 6, Batch: 158,Loss: -1.058,Avg.Loss: -0.630,LR: 4.13E-04]Training epoch 6:  46%|████▋     | 158/341 [00:03<00:03, 53.92it/s, Epoch: 6, Batch: 159,Loss: 0.003,Avg.Loss: -0.626,LR: 4.13E-04] Training epoch 6:  47%|████▋     | 159/341 [00:03<00:03, 53.92it/s, Epoch: 6, Batch: 160,Loss: 0.600,Avg.Loss: -0.618,LR: 4.13E-04]Training epoch 6:  47%|████▋     | 160/341 [00:03<00:03, 53.92it/s, Epoch: 6, Batch: 161,Loss: -0.070,Avg.Loss: -0.615,LR: 4.13E-04]Training epoch 6:  47%|████▋     | 161/341 [00:03<00:03, 53.26it/s, Epoch: 6, Batch: 161,Loss: -0.070,Avg.Loss: -0.615,LR: 4.13E-04]Training epoch 6:  47%|████▋     | 161/341 [00:03<00:03, 53.26it/s, Epoch: 6, Batch: 162,Loss: -0.889,Avg.Loss: -0.616,LR: 4.13E-04]Training epoch 6:  48%|████▊     | 162/341 [00:03<00:03, 53.26it/s, Epoch: 6, Batch: 163,Loss: -1.448,Avg.Loss: -0.621,LR: 4.13E-04]Training epoch 6:  48%|████▊     | 163/341 [00:03<00:03, 53.26it/s, Epoch: 6, Batch: 164,Loss: -1.071,Avg.Loss: -0.624,LR: 4.13E-04]Training epoch 6:  48%|████▊     | 164/341 [00:03<00:03, 53.26it/s, Epoch: 6, Batch: 165,Loss: -0.261,Avg.Loss: -0.622,LR: 4.13E-04]Training epoch 6:  48%|████▊     | 165/341 [00:03<00:03, 53.26it/s, Epoch: 6, Batch: 166,Loss: 0.208,Avg.Loss: -0.617,LR: 4.13E-04] Training epoch 6:  49%|████▊     | 166/341 [00:03<00:03, 53.26it/s, Epoch: 6, Batch: 167,Loss: 0.354,Avg.Loss: -0.611,LR: 4.13E-04]Training epoch 6:  49%|████▉     | 167/341 [00:03<00:03, 53.77it/s, Epoch: 6, Batch: 167,Loss: 0.354,Avg.Loss: -0.611,LR: 4.13E-04]Training epoch 6:  49%|████▉     | 167/341 [00:03<00:03, 53.77it/s, Epoch: 6, Batch: 168,Loss: -0.295,Avg.Loss: -0.609,LR: 4.13E-04]Training epoch 6:  49%|████▉     | 168/341 [00:03<00:03, 53.77it/s, Epoch: 6, Batch: 169,Loss: -0.945,Avg.Loss: -0.611,LR: 4.12E-04]Training epoch 6:  50%|████▉     | 169/341 [00:03<00:03, 53.77it/s, Epoch: 6, Batch: 170,Loss: -0.692,Avg.Loss: -0.612,LR: 4.12E-04]Training epoch 6:  50%|████▉     | 170/341 [00:03<00:03, 53.77it/s, Epoch: 6, Batch: 171,Loss: -0.696,Avg.Loss: -0.612,LR: 4.12E-04]Training epoch 6:  50%|█████     | 171/341 [00:03<00:03, 53.77it/s, Epoch: 6, Batch: 172,Loss: -0.672,Avg.Loss: -0.613,LR: 4.12E-04]Training epoch 6:  50%|█████     | 172/341 [00:03<00:03, 53.77it/s, Epoch: 6, Batch: 173,Loss: 0.624,Avg.Loss: -0.605,LR: 4.12E-04] Training epoch 6:  51%|█████     | 173/341 [00:03<00:03, 53.58it/s, Epoch: 6, Batch: 173,Loss: 0.624,Avg.Loss: -0.605,LR: 4.12E-04]Training epoch 6:  51%|█████     | 173/341 [00:03<00:03, 53.58it/s, Epoch: 6, Batch: 174,Loss: -0.584,Avg.Loss: -0.605,LR: 4.12E-04]Training epoch 6:  51%|█████     | 174/341 [00:03<00:03, 53.58it/s, Epoch: 6, Batch: 175,Loss: -0.671,Avg.Loss: -0.606,LR: 4.12E-04]Training epoch 6:  51%|█████▏    | 175/341 [00:03<00:03, 53.58it/s, Epoch: 6, Batch: 176,Loss: -1.005,Avg.Loss: -0.608,LR: 4.12E-04]Training epoch 6:  52%|█████▏    | 176/341 [00:03<00:03, 53.58it/s, Epoch: 6, Batch: 177,Loss: -0.947,Avg.Loss: -0.610,LR: 4.12E-04]Training epoch 6:  52%|█████▏    | 177/341 [00:03<00:03, 53.58it/s, Epoch: 6, Batch: 178,Loss: -0.964,Avg.Loss: -0.612,LR: 4.12E-04]Training epoch 6:  52%|█████▏    | 178/341 [00:03<00:03, 53.58it/s, Epoch: 6, Batch: 179,Loss: -0.780,Avg.Loss: -0.613,LR: 4.12E-04]Training epoch 6:  52%|█████▏    | 179/341 [00:03<00:03, 53.32it/s, Epoch: 6, Batch: 179,Loss: -0.780,Avg.Loss: -0.613,LR: 4.12E-04]Training epoch 6:  52%|█████▏    | 179/341 [00:03<00:03, 53.32it/s, Epoch: 6, Batch: 180,Loss: -0.868,Avg.Loss: -0.614,LR: 4.12E-04]Training epoch 6:  53%|█████▎    | 180/341 [00:03<00:03, 53.32it/s, Epoch: 6, Batch: 181,Loss: -0.650,Avg.Loss: -0.614,LR: 4.11E-04]Training epoch 6:  53%|█████▎    | 181/341 [00:03<00:03, 53.32it/s, Epoch: 6, Batch: 182,Loss: -1.179,Avg.Loss: -0.618,LR: 4.11E-04]Training epoch 6:  53%|█████▎    | 182/341 [00:03<00:02, 53.32it/s, Epoch: 6, Batch: 183,Loss: -0.716,Avg.Loss: -0.618,LR: 4.11E-04]Training epoch 6:  54%|█████▎    | 183/341 [00:03<00:02, 53.32it/s, Epoch: 6, Batch: 184,Loss: -1.424,Avg.Loss: -0.622,LR: 4.11E-04]Training epoch 6:  54%|█████▍    | 184/341 [00:03<00:02, 53.32it/s, Epoch: 6, Batch: 185,Loss: -1.171,Avg.Loss: -0.625,LR: 4.11E-04]Training epoch 6:  54%|█████▍    | 185/341 [00:03<00:02, 52.97it/s, Epoch: 6, Batch: 185,Loss: -1.171,Avg.Loss: -0.625,LR: 4.11E-04]Training epoch 6:  54%|█████▍    | 185/341 [00:03<00:02, 52.97it/s, Epoch: 6, Batch: 186,Loss: -0.810,Avg.Loss: -0.626,LR: 4.11E-04]Training epoch 6:  55%|█████▍    | 186/341 [00:03<00:02, 52.97it/s, Epoch: 6, Batch: 187,Loss: -1.428,Avg.Loss: -0.631,LR: 4.11E-04]Training epoch 6:  55%|█████▍    | 187/341 [00:03<00:02, 52.97it/s, Epoch: 6, Batch: 188,Loss: -0.629,Avg.Loss: -0.631,LR: 4.11E-04]Training epoch 6:  55%|█████▌    | 188/341 [00:03<00:02, 52.97it/s, Epoch: 6, Batch: 189,Loss: 0.363,Avg.Loss: -0.625,LR: 4.11E-04] Training epoch 6:  55%|█████▌    | 189/341 [00:03<00:02, 52.97it/s, Epoch: 6, Batch: 190,Loss: -0.967,Avg.Loss: -0.627,LR: 4.11E-04]Training epoch 6:  56%|█████▌    | 190/341 [00:03<00:02, 52.97it/s, Epoch: 6, Batch: 191,Loss: -1.114,Avg.Loss: -0.630,LR: 4.11E-04]Training epoch 6:  56%|█████▌    | 191/341 [00:03<00:02, 53.00it/s, Epoch: 6, Batch: 191,Loss: -1.114,Avg.Loss: -0.630,LR: 4.11E-04]Training epoch 6:  56%|█████▌    | 191/341 [00:03<00:02, 53.00it/s, Epoch: 6, Batch: 192,Loss: -1.033,Avg.Loss: -0.632,LR: 4.10E-04]Training epoch 6:  56%|█████▋    | 192/341 [00:03<00:02, 53.00it/s, Epoch: 6, Batch: 193,Loss: -1.218,Avg.Loss: -0.635,LR: 4.10E-04]Training epoch 6:  57%|█████▋    | 193/341 [00:03<00:02, 53.00it/s, Epoch: 6, Batch: 194,Loss: -0.230,Avg.Loss: -0.633,LR: 4.10E-04]Training epoch 6:  57%|█████▋    | 194/341 [00:03<00:02, 53.00it/s, Epoch: 6, Batch: 195,Loss: 0.728,Avg.Loss: -0.626,LR: 4.10E-04] Training epoch 6:  57%|█████▋    | 195/341 [00:03<00:02, 53.00it/s, Epoch: 6, Batch: 196,Loss: -0.608,Avg.Loss: -0.626,LR: 4.10E-04]Training epoch 6:  57%|█████▋    | 196/341 [00:03<00:02, 53.00it/s, Epoch: 6, Batch: 197,Loss: -1.444,Avg.Loss: -0.630,LR: 4.10E-04]Training epoch 6:  58%|█████▊    | 197/341 [00:03<00:02, 53.92it/s, Epoch: 6, Batch: 197,Loss: -1.444,Avg.Loss: -0.630,LR: 4.10E-04]Training epoch 6:  58%|█████▊    | 197/341 [00:03<00:02, 53.92it/s, Epoch: 6, Batch: 198,Loss: -1.199,Avg.Loss: -0.633,LR: 4.10E-04]Training epoch 6:  58%|█████▊    | 198/341 [00:03<00:02, 53.92it/s, Epoch: 6, Batch: 199,Loss: -1.368,Avg.Loss: -0.636,LR: 4.10E-04]Training epoch 6:  58%|█████▊    | 199/341 [00:03<00:02, 53.92it/s, Epoch: 6, Batch: 200,Loss: -0.679,Avg.Loss: -0.637,LR: 4.10E-04]Training epoch 6:  59%|█████▊    | 200/341 [00:03<00:02, 53.92it/s, Epoch: 6, Batch: 201,Loss: -0.114,Avg.Loss: -0.634,LR: 4.10E-04]Training epoch 6:  59%|█████▉    | 201/341 [00:03<00:02, 53.92it/s, Epoch: 6, Batch: 202,Loss: -1.098,Avg.Loss: -0.636,LR: 4.10E-04]Training epoch 6:  59%|█████▉    | 202/341 [00:03<00:02, 53.92it/s, Epoch: 6, Batch: 203,Loss: -0.941,Avg.Loss: -0.638,LR: 4.09E-04]Training epoch 6:  60%|█████▉    | 203/341 [00:03<00:02, 53.73it/s, Epoch: 6, Batch: 203,Loss: -0.941,Avg.Loss: -0.638,LR: 4.09E-04]Training epoch 6:  60%|█████▉    | 203/341 [00:03<00:02, 53.73it/s, Epoch: 6, Batch: 204,Loss: -0.525,Avg.Loss: -0.637,LR: 4.09E-04]Training epoch 6:  60%|█████▉    | 204/341 [00:03<00:02, 53.73it/s, Epoch: 6, Batch: 205,Loss: -0.478,Avg.Loss: -0.637,LR: 4.09E-04]Training epoch 6:  60%|██████    | 205/341 [00:03<00:02, 53.73it/s, Epoch: 6, Batch: 206,Loss: -1.495,Avg.Loss: -0.641,LR: 4.09E-04]Training epoch 6:  60%|██████    | 206/341 [00:03<00:02, 53.73it/s, Epoch: 6, Batch: 207,Loss: -1.388,Avg.Loss: -0.644,LR: 4.09E-04]Training epoch 6:  61%|██████    | 207/341 [00:03<00:02, 53.73it/s, Epoch: 6, Batch: 208,Loss: -1.489,Avg.Loss: -0.648,LR: 4.09E-04]Training epoch 6:  61%|██████    | 208/341 [00:03<00:02, 53.73it/s, Epoch: 6, Batch: 209,Loss: -1.620,Avg.Loss: -0.653,LR: 4.09E-04]Training epoch 6:  61%|██████▏   | 209/341 [00:03<00:02, 52.09it/s, Epoch: 6, Batch: 209,Loss: -1.620,Avg.Loss: -0.653,LR: 4.09E-04]Training epoch 6:  61%|██████▏   | 209/341 [00:04<00:02, 52.09it/s, Epoch: 6, Batch: 210,Loss: -1.542,Avg.Loss: -0.657,LR: 4.09E-04]Training epoch 6:  62%|██████▏   | 210/341 [00:04<00:02, 52.09it/s, Epoch: 6, Batch: 211,Loss: -1.526,Avg.Loss: -0.661,LR: 4.09E-04]Training epoch 6:  62%|██████▏   | 211/341 [00:04<00:02, 52.09it/s, Epoch: 6, Batch: 212,Loss: -1.430,Avg.Loss: -0.665,LR: 4.09E-04]Training epoch 6:  62%|██████▏   | 212/341 [00:04<00:02, 52.09it/s, Epoch: 6, Batch: 213,Loss: -1.137,Avg.Loss: -0.667,LR: 4.09E-04]Training epoch 6:  62%|██████▏   | 213/341 [00:04<00:02, 52.09it/s, Epoch: 6, Batch: 214,Loss: -1.294,Avg.Loss: -0.670,LR: 4.09E-04]Training epoch 6:  63%|██████▎   | 214/341 [00:04<00:02, 52.09it/s, Epoch: 6, Batch: 215,Loss: -0.846,Avg.Loss: -0.671,LR: 4.08E-04]Training epoch 6:  63%|██████▎   | 215/341 [00:04<00:02, 51.57it/s, Epoch: 6, Batch: 215,Loss: -0.846,Avg.Loss: -0.671,LR: 4.08E-04]Training epoch 6:  63%|██████▎   | 215/341 [00:04<00:02, 51.57it/s, Epoch: 6, Batch: 216,Loss: -0.924,Avg.Loss: -0.672,LR: 4.08E-04]Training epoch 6:  63%|██████▎   | 216/341 [00:04<00:02, 51.57it/s, Epoch: 6, Batch: 217,Loss: -1.305,Avg.Loss: -0.675,LR: 4.08E-04]Training epoch 6:  64%|██████▎   | 217/341 [00:04<00:02, 51.57it/s, Epoch: 6, Batch: 218,Loss: -0.910,Avg.Loss: -0.676,LR: 4.08E-04]Training epoch 6:  64%|██████▍   | 218/341 [00:04<00:02, 51.57it/s, Epoch: 6, Batch: 219,Loss: -1.250,Avg.Loss: -0.679,LR: 4.08E-04]Training epoch 6:  64%|██████▍   | 219/341 [00:04<00:02, 51.57it/s, Epoch: 6, Batch: 220,Loss: -1.290,Avg.Loss: -0.682,LR: 4.08E-04]Training epoch 6:  65%|██████▍   | 220/341 [00:04<00:02, 51.57it/s, Epoch: 6, Batch: 221,Loss: -0.447,Avg.Loss: -0.680,LR: 4.08E-04]Training epoch 6:  65%|██████▍   | 221/341 [00:04<00:02, 51.39it/s, Epoch: 6, Batch: 221,Loss: -0.447,Avg.Loss: -0.680,LR: 4.08E-04]Training epoch 6:  65%|██████▍   | 221/341 [00:04<00:02, 51.39it/s, Epoch: 6, Batch: 222,Loss: -0.671,Avg.Loss: -0.680,LR: 4.08E-04]Training epoch 6:  65%|██████▌   | 222/341 [00:04<00:02, 51.39it/s, Epoch: 6, Batch: 223,Loss: -0.587,Avg.Loss: -0.680,LR: 4.08E-04]Training epoch 6:  65%|██████▌   | 223/341 [00:04<00:02, 51.39it/s, Epoch: 6, Batch: 224,Loss: -0.853,Avg.Loss: -0.681,LR: 4.08E-04]Training epoch 6:  66%|██████▌   | 224/341 [00:04<00:02, 51.39it/s, Epoch: 6, Batch: 225,Loss: -1.604,Avg.Loss: -0.685,LR: 4.08E-04]Training epoch 6:  66%|██████▌   | 225/341 [00:04<00:02, 51.39it/s, Epoch: 6, Batch: 226,Loss: -1.343,Avg.Loss: -0.688,LR: 4.07E-04]Training epoch 6:  66%|██████▋   | 226/341 [00:04<00:02, 51.39it/s, Epoch: 6, Batch: 227,Loss: -0.754,Avg.Loss: -0.688,LR: 4.07E-04]Training epoch 6:  67%|██████▋   | 227/341 [00:04<00:02, 51.26it/s, Epoch: 6, Batch: 227,Loss: -0.754,Avg.Loss: -0.688,LR: 4.07E-04]Training epoch 6:  67%|██████▋   | 227/341 [00:04<00:02, 51.26it/s, Epoch: 6, Batch: 228,Loss: -1.530,Avg.Loss: -0.692,LR: 4.07E-04]Training epoch 6:  67%|██████▋   | 228/341 [00:04<00:02, 51.26it/s, Epoch: 6, Batch: 229,Loss: -1.160,Avg.Loss: -0.694,LR: 4.07E-04]Training epoch 6:  67%|██████▋   | 229/341 [00:04<00:02, 51.26it/s, Epoch: 6, Batch: 230,Loss: -0.821,Avg.Loss: -0.694,LR: 4.07E-04]Training epoch 6:  67%|██████▋   | 230/341 [00:04<00:02, 51.26it/s, Epoch: 6, Batch: 231,Loss: -1.234,Avg.Loss: -0.697,LR: 4.07E-04]Training epoch 6:  68%|██████▊   | 231/341 [00:04<00:02, 51.26it/s, Epoch: 6, Batch: 232,Loss: -0.813,Avg.Loss: -0.697,LR: 4.07E-04]Training epoch 6:  68%|██████▊   | 232/341 [00:04<00:02, 51.26it/s, Epoch: 6, Batch: 233,Loss: -1.181,Avg.Loss: -0.699,LR: 4.07E-04]Training epoch 6:  68%|██████▊   | 233/341 [00:04<00:02, 51.78it/s, Epoch: 6, Batch: 233,Loss: -1.181,Avg.Loss: -0.699,LR: 4.07E-04]Training epoch 6:  68%|██████▊   | 233/341 [00:04<00:02, 51.78it/s, Epoch: 6, Batch: 234,Loss: -1.617,Avg.Loss: -0.703,LR: 4.07E-04]Training epoch 6:  69%|██████▊   | 234/341 [00:04<00:02, 51.78it/s, Epoch: 6, Batch: 235,Loss: -1.396,Avg.Loss: -0.706,LR: 4.07E-04]Training epoch 6:  69%|██████▉   | 235/341 [00:04<00:02, 51.78it/s, Epoch: 6, Batch: 236,Loss: -1.292,Avg.Loss: -0.709,LR: 4.07E-04]Training epoch 6:  69%|██████▉   | 236/341 [00:04<00:02, 51.78it/s, Epoch: 6, Batch: 237,Loss: -1.459,Avg.Loss: -0.712,LR: 4.06E-04]Training epoch 6:  70%|██████▉   | 237/341 [00:04<00:02, 51.78it/s, Epoch: 6, Batch: 238,Loss: -0.951,Avg.Loss: -0.713,LR: 4.06E-04]Training epoch 6:  70%|██████▉   | 238/341 [00:04<00:01, 51.78it/s, Epoch: 6, Batch: 239,Loss: -0.974,Avg.Loss: -0.714,LR: 4.06E-04]Training epoch 6:  70%|███████   | 239/341 [00:04<00:01, 51.67it/s, Epoch: 6, Batch: 239,Loss: -0.974,Avg.Loss: -0.714,LR: 4.06E-04]Training epoch 6:  70%|███████   | 239/341 [00:04<00:01, 51.67it/s, Epoch: 6, Batch: 240,Loss: -1.294,Avg.Loss: -0.716,LR: 4.06E-04]Training epoch 6:  70%|███████   | 240/341 [00:04<00:01, 51.67it/s, Epoch: 6, Batch: 241,Loss: 0.675,Avg.Loss: -0.711,LR: 4.06E-04] Training epoch 6:  71%|███████   | 241/341 [00:04<00:01, 51.67it/s, Epoch: 6, Batch: 242,Loss: 1.867,Avg.Loss: -0.700,LR: 4.06E-04]Training epoch 6:  71%|███████   | 242/341 [00:04<00:01, 51.67it/s, Epoch: 6, Batch: 243,Loss: 1.645,Avg.Loss: -0.690,LR: 4.06E-04]Training epoch 6:  71%|███████▏  | 243/341 [00:04<00:01, 51.67it/s, Epoch: 6, Batch: 244,Loss: 1.788,Avg.Loss: -0.680,LR: 4.06E-04]Training epoch 6:  72%|███████▏  | 244/341 [00:04<00:01, 51.67it/s, Epoch: 6, Batch: 245,Loss: 2.420,Avg.Loss: -0.667,LR: 4.06E-04]Training epoch 6:  72%|███████▏  | 245/341 [00:04<00:01, 51.59it/s, Epoch: 6, Batch: 245,Loss: 2.420,Avg.Loss: -0.667,LR: 4.06E-04]Training epoch 6:  72%|███████▏  | 245/341 [00:04<00:01, 51.59it/s, Epoch: 6, Batch: 246,Loss: 0.898,Avg.Loss: -0.661,LR: 4.06E-04]Training epoch 6:  72%|███████▏  | 246/341 [00:04<00:01, 51.59it/s, Epoch: 6, Batch: 247,Loss: -0.406,Avg.Loss: -0.660,LR: 4.06E-04]Training epoch 6:  72%|███████▏  | 247/341 [00:04<00:01, 51.59it/s, Epoch: 6, Batch: 248,Loss: -1.289,Avg.Loss: -0.663,LR: 4.05E-04]Training epoch 6:  73%|███████▎  | 248/341 [00:04<00:01, 51.59it/s, Epoch: 6, Batch: 249,Loss: -0.189,Avg.Loss: -0.661,LR: 4.05E-04]Training epoch 6:  73%|███████▎  | 249/341 [00:04<00:01, 51.59it/s, Epoch: 6, Batch: 250,Loss: -0.630,Avg.Loss: -0.661,LR: 4.05E-04]Training epoch 6:  73%|███████▎  | 250/341 [00:04<00:01, 51.59it/s, Epoch: 6, Batch: 251,Loss: -1.080,Avg.Loss: -0.662,LR: 4.05E-04]Training epoch 6:  74%|███████▎  | 251/341 [00:04<00:01, 51.79it/s, Epoch: 6, Batch: 251,Loss: -1.080,Avg.Loss: -0.662,LR: 4.05E-04]Training epoch 6:  74%|███████▎  | 251/341 [00:04<00:01, 51.79it/s, Epoch: 6, Batch: 252,Loss: -0.949,Avg.Loss: -0.663,LR: 4.05E-04]Training epoch 6:  74%|███████▍  | 252/341 [00:04<00:01, 51.79it/s, Epoch: 6, Batch: 253,Loss: -1.582,Avg.Loss: -0.667,LR: 4.05E-04]Training epoch 6:  74%|███████▍  | 253/341 [00:04<00:01, 51.79it/s, Epoch: 6, Batch: 254,Loss: -1.478,Avg.Loss: -0.670,LR: 4.05E-04]Training epoch 6:  74%|███████▍  | 254/341 [00:04<00:01, 51.79it/s, Epoch: 6, Batch: 255,Loss: -1.006,Avg.Loss: -0.672,LR: 4.05E-04]Training epoch 6:  75%|███████▍  | 255/341 [00:04<00:01, 51.79it/s, Epoch: 6, Batch: 256,Loss: -1.247,Avg.Loss: -0.674,LR: 4.05E-04]Training epoch 6:  75%|███████▌  | 256/341 [00:04<00:01, 51.79it/s, Epoch: 6, Batch: 257,Loss: -1.510,Avg.Loss: -0.677,LR: 4.05E-04]Training epoch 6:  75%|███████▌  | 257/341 [00:04<00:01, 51.96it/s, Epoch: 6, Batch: 257,Loss: -1.510,Avg.Loss: -0.677,LR: 4.05E-04]Training epoch 6:  75%|███████▌  | 257/341 [00:04<00:01, 51.96it/s, Epoch: 6, Batch: 258,Loss: -0.912,Avg.Loss: -0.678,LR: 4.05E-04]Training epoch 6:  76%|███████▌  | 258/341 [00:04<00:01, 51.96it/s, Epoch: 6, Batch: 259,Loss: -0.992,Avg.Loss: -0.679,LR: 4.04E-04]Training epoch 6:  76%|███████▌  | 259/341 [00:04<00:01, 51.96it/s, Epoch: 6, Batch: 260,Loss: 0.244,Avg.Loss: -0.676,LR: 4.04E-04] Training epoch 6:  76%|███████▌  | 260/341 [00:05<00:01, 51.96it/s, Epoch: 6, Batch: 261,Loss: 0.828,Avg.Loss: -0.670,LR: 4.04E-04]Training epoch 6:  77%|███████▋  | 261/341 [00:05<00:01, 51.96it/s, Epoch: 6, Batch: 262,Loss: 0.080,Avg.Loss: -0.667,LR: 4.04E-04]Training epoch 6:  77%|███████▋  | 262/341 [00:05<00:01, 51.96it/s, Epoch: 6, Batch: 263,Loss: -0.806,Avg.Loss: -0.667,LR: 4.04E-04]Training epoch 6:  77%|███████▋  | 263/341 [00:05<00:01, 52.39it/s, Epoch: 6, Batch: 263,Loss: -0.806,Avg.Loss: -0.667,LR: 4.04E-04]Training epoch 6:  77%|███████▋  | 263/341 [00:05<00:01, 52.39it/s, Epoch: 6, Batch: 264,Loss: -0.925,Avg.Loss: -0.668,LR: 4.04E-04]Training epoch 6:  77%|███████▋  | 264/341 [00:05<00:01, 52.39it/s, Epoch: 6, Batch: 265,Loss: -1.337,Avg.Loss: -0.671,LR: 4.04E-04]Training epoch 6:  78%|███████▊  | 265/341 [00:05<00:01, 52.39it/s, Epoch: 6, Batch: 266,Loss: -1.115,Avg.Loss: -0.673,LR: 4.04E-04]Training epoch 6:  78%|███████▊  | 266/341 [00:05<00:01, 52.39it/s, Epoch: 6, Batch: 267,Loss: -1.037,Avg.Loss: -0.674,LR: 4.04E-04]Training epoch 6:  78%|███████▊  | 267/341 [00:05<00:01, 52.39it/s, Epoch: 6, Batch: 268,Loss: -1.373,Avg.Loss: -0.677,LR: 4.04E-04]Training epoch 6:  79%|███████▊  | 268/341 [00:05<00:01, 52.39it/s, Epoch: 6, Batch: 269,Loss: -0.737,Avg.Loss: -0.677,LR: 4.04E-04]Training epoch 6:  79%|███████▉  | 269/341 [00:05<00:01, 51.46it/s, Epoch: 6, Batch: 269,Loss: -0.737,Avg.Loss: -0.677,LR: 4.04E-04]Training epoch 6:  79%|███████▉  | 269/341 [00:05<00:01, 51.46it/s, Epoch: 6, Batch: 270,Loss: 0.193,Avg.Loss: -0.674,LR: 4.03E-04] Training epoch 6:  79%|███████▉  | 270/341 [00:05<00:01, 51.46it/s, Epoch: 6, Batch: 271,Loss: 2.098,Avg.Loss: -0.663,LR: 4.03E-04]Training epoch 6:  79%|███████▉  | 271/341 [00:05<00:01, 51.46it/s, Epoch: 6, Batch: 272,Loss: 0.709,Avg.Loss: -0.658,LR: 4.03E-04]Training epoch 6:  80%|███████▉  | 272/341 [00:05<00:01, 51.46it/s, Epoch: 6, Batch: 273,Loss: 0.688,Avg.Loss: -0.653,LR: 4.03E-04]Training epoch 6:  80%|████████  | 273/341 [00:05<00:01, 51.46it/s, Epoch: 6, Batch: 274,Loss: -0.195,Avg.Loss: -0.652,LR: 4.03E-04]Training epoch 6:  80%|████████  | 274/341 [00:05<00:01, 51.46it/s, Epoch: 6, Batch: 275,Loss: -0.785,Avg.Loss: -0.652,LR: 4.03E-04]Training epoch 6:  81%|████████  | 275/341 [00:05<00:01, 51.42it/s, Epoch: 6, Batch: 275,Loss: -0.785,Avg.Loss: -0.652,LR: 4.03E-04]Training epoch 6:  81%|████████  | 275/341 [00:05<00:01, 51.42it/s, Epoch: 6, Batch: 276,Loss: -0.769,Avg.Loss: -0.653,LR: 4.03E-04]Training epoch 6:  81%|████████  | 276/341 [00:05<00:01, 51.42it/s, Epoch: 6, Batch: 277,Loss: 0.211,Avg.Loss: -0.650,LR: 4.03E-04] Training epoch 6:  81%|████████  | 277/341 [00:05<00:01, 51.42it/s, Epoch: 6, Batch: 278,Loss: -0.346,Avg.Loss: -0.648,LR: 4.03E-04]Training epoch 6:  82%|████████▏ | 278/341 [00:05<00:01, 51.42it/s, Epoch: 6, Batch: 279,Loss: -0.966,Avg.Loss: -0.650,LR: 4.03E-04]Training epoch 6:  82%|████████▏ | 279/341 [00:05<00:01, 51.42it/s, Epoch: 6, Batch: 280,Loss: -0.280,Avg.Loss: -0.648,LR: 4.03E-04]Training epoch 6:  82%|████████▏ | 280/341 [00:05<00:01, 51.42it/s, Epoch: 6, Batch: 281,Loss: 0.491,Avg.Loss: -0.644,LR: 4.02E-04] Training epoch 6:  82%|████████▏ | 281/341 [00:05<00:01, 51.76it/s, Epoch: 6, Batch: 281,Loss: 0.491,Avg.Loss: -0.644,LR: 4.02E-04]Training epoch 6:  82%|████████▏ | 281/341 [00:05<00:01, 51.76it/s, Epoch: 6, Batch: 282,Loss: 0.696,Avg.Loss: -0.639,LR: 4.02E-04]Training epoch 6:  83%|████████▎ | 282/341 [00:05<00:01, 51.76it/s, Epoch: 6, Batch: 283,Loss: -0.749,Avg.Loss: -0.640,LR: 4.02E-04]Training epoch 6:  83%|████████▎ | 283/341 [00:05<00:01, 51.76it/s, Epoch: 6, Batch: 284,Loss: 0.494,Avg.Loss: -0.636,LR: 4.02E-04] Training epoch 6:  83%|████████▎ | 284/341 [00:05<00:01, 51.76it/s, Epoch: 6, Batch: 285,Loss: 0.174,Avg.Loss: -0.633,LR: 4.02E-04]Training epoch 6:  84%|████████▎ | 285/341 [00:05<00:01, 51.76it/s, Epoch: 6, Batch: 286,Loss: -0.425,Avg.Loss: -0.632,LR: 4.02E-04]Training epoch 6:  84%|████████▍ | 286/341 [00:05<00:01, 51.76it/s, Epoch: 6, Batch: 287,Loss: -0.843,Avg.Loss: -0.633,LR: 4.02E-04]Training epoch 6:  84%|████████▍ | 287/341 [00:05<00:01, 52.32it/s, Epoch: 6, Batch: 287,Loss: -0.843,Avg.Loss: -0.633,LR: 4.02E-04]Training epoch 6:  84%|████████▍ | 287/341 [00:05<00:01, 52.32it/s, Epoch: 6, Batch: 288,Loss: -0.068,Avg.Loss: -0.631,LR: 4.02E-04]Training epoch 6:  84%|████████▍ | 288/341 [00:05<00:01, 52.32it/s, Epoch: 6, Batch: 289,Loss: 1.195,Avg.Loss: -0.625,LR: 4.02E-04] Training epoch 6:  85%|████████▍ | 289/341 [00:05<00:00, 52.32it/s, Epoch: 6, Batch: 290,Loss: 1.146,Avg.Loss: -0.619,LR: 4.02E-04]Training epoch 6:  85%|████████▌ | 290/341 [00:05<00:00, 52.32it/s, Epoch: 6, Batch: 291,Loss: -0.060,Avg.Loss: -0.617,LR: 4.02E-04]Training epoch 6:  85%|████████▌ | 291/341 [00:05<00:00, 52.32it/s, Epoch: 6, Batch: 292,Loss: -0.876,Avg.Loss: -0.618,LR: 4.01E-04]Training epoch 6:  86%|████████▌ | 292/341 [00:05<00:00, 52.32it/s, Epoch: 6, Batch: 293,Loss: -0.492,Avg.Loss: -0.617,LR: 4.01E-04]Training epoch 6:  86%|████████▌ | 293/341 [00:05<00:00, 52.62it/s, Epoch: 6, Batch: 293,Loss: -0.492,Avg.Loss: -0.617,LR: 4.01E-04]Training epoch 6:  86%|████████▌ | 293/341 [00:05<00:00, 52.62it/s, Epoch: 6, Batch: 294,Loss: -0.456,Avg.Loss: -0.617,LR: 4.01E-04]Training epoch 6:  86%|████████▌ | 294/341 [00:05<00:00, 52.62it/s, Epoch: 6, Batch: 295,Loss: -0.634,Avg.Loss: -0.617,LR: 4.01E-04]Training epoch 6:  87%|████████▋ | 295/341 [00:05<00:00, 52.62it/s, Epoch: 6, Batch: 296,Loss: -1.039,Avg.Loss: -0.618,LR: 4.01E-04]Training epoch 6:  87%|████████▋ | 296/341 [00:05<00:00, 52.62it/s, Epoch: 6, Batch: 297,Loss: -0.822,Avg.Loss: -0.619,LR: 4.01E-04]Training epoch 6:  87%|████████▋ | 297/341 [00:05<00:00, 52.62it/s, Epoch: 6, Batch: 298,Loss: -1.105,Avg.Loss: -0.620,LR: 4.01E-04]Training epoch 6:  87%|████████▋ | 298/341 [00:05<00:00, 52.62it/s, Epoch: 6, Batch: 299,Loss: -0.936,Avg.Loss: -0.621,LR: 4.01E-04]Training epoch 6:  88%|████████▊ | 299/341 [00:05<00:00, 53.19it/s, Epoch: 6, Batch: 299,Loss: -0.936,Avg.Loss: -0.621,LR: 4.01E-04]Training epoch 6:  88%|████████▊ | 299/341 [00:05<00:00, 53.19it/s, Epoch: 6, Batch: 300,Loss: -0.682,Avg.Loss: -0.622,LR: 4.01E-04]Training epoch 6:  88%|████████▊ | 300/341 [00:05<00:00, 53.19it/s, Epoch: 6, Batch: 301,Loss: -1.081,Avg.Loss: -0.623,LR: 4.01E-04]Training epoch 6:  88%|████████▊ | 301/341 [00:05<00:00, 53.19it/s, Epoch: 6, Batch: 302,Loss: -0.919,Avg.Loss: -0.624,LR: 4.01E-04]Training epoch 6:  89%|████████▊ | 302/341 [00:05<00:00, 53.19it/s, Epoch: 6, Batch: 303,Loss: -0.361,Avg.Loss: -0.623,LR: 4.00E-04]Training epoch 6:  89%|████████▉ | 303/341 [00:05<00:00, 53.19it/s, Epoch: 6, Batch: 304,Loss: -0.933,Avg.Loss: -0.624,LR: 4.00E-04]Training epoch 6:  89%|████████▉ | 304/341 [00:05<00:00, 53.19it/s, Epoch: 6, Batch: 305,Loss: -1.009,Avg.Loss: -0.626,LR: 4.00E-04]Training epoch 6:  89%|████████▉ | 305/341 [00:05<00:00, 52.96it/s, Epoch: 6, Batch: 305,Loss: -1.009,Avg.Loss: -0.626,LR: 4.00E-04]Training epoch 6:  89%|████████▉ | 305/341 [00:05<00:00, 52.96it/s, Epoch: 6, Batch: 306,Loss: -0.556,Avg.Loss: -0.625,LR: 4.00E-04]Training epoch 6:  90%|████████▉ | 306/341 [00:05<00:00, 52.96it/s, Epoch: 6, Batch: 307,Loss: -0.770,Avg.Loss: -0.626,LR: 4.00E-04]Training epoch 6:  90%|█████████ | 307/341 [00:05<00:00, 52.96it/s, Epoch: 6, Batch: 308,Loss: -1.168,Avg.Loss: -0.628,LR: 4.00E-04]Training epoch 6:  90%|█████████ | 308/341 [00:05<00:00, 52.96it/s, Epoch: 6, Batch: 309,Loss: -1.175,Avg.Loss: -0.629,LR: 4.00E-04]Training epoch 6:  91%|█████████ | 309/341 [00:05<00:00, 52.96it/s, Epoch: 6, Batch: 310,Loss: -1.020,Avg.Loss: -0.631,LR: 4.00E-04]Training epoch 6:  91%|█████████ | 310/341 [00:05<00:00, 52.96it/s, Epoch: 6, Batch: 311,Loss: -1.258,Avg.Loss: -0.633,LR: 4.00E-04]Training epoch 6:  91%|█████████ | 311/341 [00:05<00:00, 52.83it/s, Epoch: 6, Batch: 311,Loss: -1.258,Avg.Loss: -0.633,LR: 4.00E-04]Training epoch 6:  91%|█████████ | 311/341 [00:05<00:00, 52.83it/s, Epoch: 6, Batch: 312,Loss: -1.314,Avg.Loss: -0.635,LR: 4.00E-04]Training epoch 6:  91%|█████████▏| 312/341 [00:05<00:00, 52.83it/s, Epoch: 6, Batch: 313,Loss: -1.380,Avg.Loss: -0.637,LR: 4.00E-04]Training epoch 6:  92%|█████████▏| 313/341 [00:06<00:00, 52.83it/s, Epoch: 6, Batch: 314,Loss: -1.223,Avg.Loss: -0.639,LR: 3.99E-04]Training epoch 6:  92%|█████████▏| 314/341 [00:06<00:00, 52.83it/s, Epoch: 6, Batch: 315,Loss: -1.479,Avg.Loss: -0.642,LR: 3.99E-04]Training epoch 6:  92%|█████████▏| 315/341 [00:06<00:00, 52.83it/s, Epoch: 6, Batch: 316,Loss: -1.384,Avg.Loss: -0.644,LR: 3.99E-04]Training epoch 6:  93%|█████████▎| 316/341 [00:06<00:00, 52.83it/s, Epoch: 6, Batch: 317,Loss: -1.214,Avg.Loss: -0.646,LR: 3.99E-04]Training epoch 6:  93%|█████████▎| 317/341 [00:06<00:00, 52.80it/s, Epoch: 6, Batch: 317,Loss: -1.214,Avg.Loss: -0.646,LR: 3.99E-04]Training epoch 6:  93%|█████████▎| 317/341 [00:06<00:00, 52.80it/s, Epoch: 6, Batch: 318,Loss: -1.266,Avg.Loss: -0.648,LR: 3.99E-04]Training epoch 6:  93%|█████████▎| 318/341 [00:06<00:00, 52.80it/s, Epoch: 6, Batch: 319,Loss: -0.961,Avg.Loss: -0.649,LR: 3.99E-04]Training epoch 6:  94%|█████████▎| 319/341 [00:06<00:00, 52.80it/s, Epoch: 6, Batch: 320,Loss: -1.196,Avg.Loss: -0.651,LR: 3.99E-04]Training epoch 6:  94%|█████████▍| 320/341 [00:06<00:00, 52.80it/s, Epoch: 6, Batch: 321,Loss: -1.168,Avg.Loss: -0.652,LR: 3.99E-04]Training epoch 6:  94%|█████████▍| 321/341 [00:06<00:00, 52.80it/s, Epoch: 6, Batch: 322,Loss: -0.757,Avg.Loss: -0.652,LR: 3.99E-04]Training epoch 6:  94%|█████████▍| 322/341 [00:06<00:00, 52.80it/s, Epoch: 6, Batch: 323,Loss: 0.648,Avg.Loss: -0.648,LR: 3.99E-04] Training epoch 6:  95%|█████████▍| 323/341 [00:06<00:00, 53.39it/s, Epoch: 6, Batch: 323,Loss: 0.648,Avg.Loss: -0.648,LR: 3.99E-04]Training epoch 6:  95%|█████████▍| 323/341 [00:06<00:00, 53.39it/s, Epoch: 6, Batch: 324,Loss: -1.158,Avg.Loss: -0.650,LR: 3.99E-04]Training epoch 6:  95%|█████████▌| 324/341 [00:06<00:00, 53.39it/s, Epoch: 6, Batch: 325,Loss: -1.355,Avg.Loss: -0.652,LR: 3.98E-04]Training epoch 6:  95%|█████████▌| 325/341 [00:06<00:00, 53.39it/s, Epoch: 6, Batch: 326,Loss: 0.615,Avg.Loss: -0.648,LR: 3.98E-04] Training epoch 6:  96%|█████████▌| 326/341 [00:06<00:00, 53.39it/s, Epoch: 6, Batch: 327,Loss: 1.217,Avg.Loss: -0.643,LR: 3.98E-04]Training epoch 6:  96%|█████████▌| 327/341 [00:06<00:00, 53.39it/s, Epoch: 6, Batch: 328,Loss: 2.377,Avg.Loss: -0.633,LR: 3.98E-04]Training epoch 6:  96%|█████████▌| 328/341 [00:06<00:00, 53.39it/s, Epoch: 6, Batch: 329,Loss: -1.031,Avg.Loss: -0.635,LR: 3.98E-04]Training epoch 6:  96%|█████████▋| 329/341 [00:06<00:00, 54.14it/s, Epoch: 6, Batch: 329,Loss: -1.031,Avg.Loss: -0.635,LR: 3.98E-04]Training epoch 6:  96%|█████████▋| 329/341 [00:06<00:00, 54.14it/s, Epoch: 6, Batch: 330,Loss: -1.197,Avg.Loss: -0.636,LR: 3.98E-04]Training epoch 6:  97%|█████████▋| 330/341 [00:06<00:00, 54.14it/s, Epoch: 6, Batch: 331,Loss: -0.924,Avg.Loss: -0.637,LR: 3.98E-04]Training epoch 6:  97%|█████████▋| 331/341 [00:06<00:00, 54.14it/s, Epoch: 6, Batch: 332,Loss: -1.179,Avg.Loss: -0.639,LR: 3.98E-04]Training epoch 6:  97%|█████████▋| 332/341 [00:06<00:00, 54.14it/s, Epoch: 6, Batch: 333,Loss: -1.383,Avg.Loss: -0.641,LR: 3.98E-04]Training epoch 6:  98%|█████████▊| 333/341 [00:06<00:00, 54.14it/s, Epoch: 6, Batch: 334,Loss: -1.290,Avg.Loss: -0.643,LR: 3.98E-04]Training epoch 6:  98%|█████████▊| 334/341 [00:06<00:00, 54.14it/s, Epoch: 6, Batch: 335,Loss: -0.978,Avg.Loss: -0.644,LR: 3.98E-04]Training epoch 6:  98%|█████████▊| 335/341 [00:06<00:00, 53.46it/s, Epoch: 6, Batch: 335,Loss: -0.978,Avg.Loss: -0.644,LR: 3.98E-04]Training epoch 6:  98%|█████████▊| 335/341 [00:06<00:00, 53.46it/s, Epoch: 6, Batch: 336,Loss: -1.465,Avg.Loss: -0.646,LR: 3.97E-04]Training epoch 6:  99%|█████████▊| 336/341 [00:06<00:00, 53.46it/s, Epoch: 6, Batch: 337,Loss: -1.518,Avg.Loss: -0.649,LR: 3.97E-04]Training epoch 6:  99%|█████████▉| 337/341 [00:06<00:00, 53.46it/s, Epoch: 6, Batch: 338,Loss: -1.581,Avg.Loss: -0.652,LR: 3.97E-04]Training epoch 6:  99%|█████████▉| 338/341 [00:06<00:00, 53.46it/s, Epoch: 6, Batch: 339,Loss: -1.101,Avg.Loss: -0.653,LR: 3.97E-04]Training epoch 6:  99%|█████████▉| 339/341 [00:06<00:00, 53.46it/s, Epoch: 6, Batch: 340,Loss: -1.475,Avg.Loss: -0.656,LR: 3.97E-04]Training epoch 6: 100%|█████████▉| 340/341 [00:06<00:00, 53.46it/s, Epoch: 6, Batch: 341,Loss: -1.380,Avg.Loss: -0.658,LR: 3.97E-04]Training epoch 6: 100%|██████████| 341/341 [00:06<00:00, 53.78it/s, Epoch: 6, Batch: 341,Loss: -1.380,Avg.Loss: -0.658,LR: 3.97E-04]Training epoch 6: 100%|██████████| 341/341 [00:06<00:00, 52.35it/s, Epoch: 6, Batch: 341,Loss: -1.380,Avg.Loss: -0.658,LR: 3.97E-04]
Training epoch 7:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 7:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 7, Batch: 1,Loss: -0.983,Avg.Loss: -0.983,LR: 3.97E-04]Training epoch 7:   0%|          | 1/341 [00:00<00:09, 34.12it/s, Epoch: 7, Batch: 2,Loss: -1.836,Avg.Loss: -1.410,LR: 3.97E-04]Training epoch 7:   1%|          | 2/341 [00:00<00:07, 42.59it/s, Epoch: 7, Batch: 3,Loss: -0.057,Avg.Loss: -0.959,LR: 3.97E-04]Training epoch 7:   1%|          | 3/341 [00:00<00:07, 46.36it/s, Epoch: 7, Batch: 4,Loss: 0.517,Avg.Loss: -0.590,LR: 3.97E-04] Training epoch 7:   1%|          | 4/341 [00:00<00:07, 47.79it/s, Epoch: 7, Batch: 5,Loss: 1.682,Avg.Loss: -0.136,LR: 3.96E-04]Training epoch 7:   1%|▏         | 5/341 [00:00<00:06, 49.21it/s, Epoch: 7, Batch: 6,Loss: -1.013,Avg.Loss: -0.282,LR: 3.96E-04]Training epoch 7:   2%|▏         | 6/341 [00:00<00:05, 58.93it/s, Epoch: 7, Batch: 6,Loss: -1.013,Avg.Loss: -0.282,LR: 3.96E-04]Training epoch 7:   2%|▏         | 6/341 [00:00<00:05, 58.93it/s, Epoch: 7, Batch: 7,Loss: -0.759,Avg.Loss: -0.350,LR: 3.96E-04]Training epoch 7:   2%|▏         | 7/341 [00:00<00:05, 58.93it/s, Epoch: 7, Batch: 8,Loss: 1.256,Avg.Loss: -0.149,LR: 3.96E-04] Training epoch 7:   2%|▏         | 8/341 [00:00<00:05, 58.93it/s, Epoch: 7, Batch: 9,Loss: 0.208,Avg.Loss: -0.110,LR: 3.96E-04]Training epoch 7:   3%|▎         | 9/341 [00:00<00:05, 58.93it/s, Epoch: 7, Batch: 10,Loss: -0.989,Avg.Loss: -0.197,LR: 3.96E-04]Training epoch 7:   3%|▎         | 10/341 [00:00<00:05, 58.93it/s, Epoch: 7, Batch: 11,Loss: -0.896,Avg.Loss: -0.261,LR: 3.96E-04]Training epoch 7:   3%|▎         | 11/341 [00:00<00:05, 58.93it/s, Epoch: 7, Batch: 12,Loss: 0.173,Avg.Loss: -0.225,LR: 3.96E-04] Training epoch 7:   4%|▎         | 12/341 [00:00<00:06, 54.29it/s, Epoch: 7, Batch: 12,Loss: 0.173,Avg.Loss: -0.225,LR: 3.96E-04]Training epoch 7:   4%|▎         | 12/341 [00:00<00:06, 54.29it/s, Epoch: 7, Batch: 13,Loss: 0.389,Avg.Loss: -0.178,LR: 3.96E-04]Training epoch 7:   4%|▍         | 13/341 [00:00<00:06, 54.29it/s, Epoch: 7, Batch: 14,Loss: -1.539,Avg.Loss: -0.275,LR: 3.96E-04]Training epoch 7:   4%|▍         | 14/341 [00:00<00:06, 54.29it/s, Epoch: 7, Batch: 15,Loss: -0.262,Avg.Loss: -0.274,LR: 3.96E-04]Training epoch 7:   4%|▍         | 15/341 [00:00<00:06, 54.29it/s, Epoch: 7, Batch: 16,Loss: 1.920,Avg.Loss: -0.137,LR: 3.95E-04] Training epoch 7:   5%|▍         | 16/341 [00:00<00:05, 54.29it/s, Epoch: 7, Batch: 17,Loss: 1.320,Avg.Loss: -0.051,LR: 3.95E-04]Training epoch 7:   5%|▍         | 17/341 [00:00<00:05, 54.29it/s, Epoch: 7, Batch: 18,Loss: -0.753,Avg.Loss: -0.090,LR: 3.95E-04]Training epoch 7:   5%|▌         | 18/341 [00:00<00:05, 53.85it/s, Epoch: 7, Batch: 18,Loss: -0.753,Avg.Loss: -0.090,LR: 3.95E-04]Training epoch 7:   5%|▌         | 18/341 [00:00<00:05, 53.85it/s, Epoch: 7, Batch: 19,Loss: -1.471,Avg.Loss: -0.163,LR: 3.95E-04]Training epoch 7:   6%|▌         | 19/341 [00:00<00:05, 53.85it/s, Epoch: 7, Batch: 20,Loss: -0.014,Avg.Loss: -0.155,LR: 3.95E-04]Training epoch 7:   6%|▌         | 20/341 [00:00<00:05, 53.85it/s, Epoch: 7, Batch: 21,Loss: -0.455,Avg.Loss: -0.170,LR: 3.95E-04]Training epoch 7:   6%|▌         | 21/341 [00:00<00:05, 53.85it/s, Epoch: 7, Batch: 22,Loss: -1.725,Avg.Loss: -0.240,LR: 3.95E-04]Training epoch 7:   6%|▋         | 22/341 [00:00<00:05, 53.85it/s, Epoch: 7, Batch: 23,Loss: -0.489,Avg.Loss: -0.251,LR: 3.95E-04]Training epoch 7:   7%|▋         | 23/341 [00:00<00:05, 53.85it/s, Epoch: 7, Batch: 24,Loss: 2.560,Avg.Loss: -0.134,LR: 3.95E-04] Training epoch 7:   7%|▋         | 24/341 [00:00<00:05, 53.39it/s, Epoch: 7, Batch: 24,Loss: 2.560,Avg.Loss: -0.134,LR: 3.95E-04]Training epoch 7:   7%|▋         | 24/341 [00:00<00:05, 53.39it/s, Epoch: 7, Batch: 25,Loss: 0.934,Avg.Loss: -0.091,LR: 3.95E-04]Training epoch 7:   7%|▋         | 25/341 [00:00<00:05, 53.39it/s, Epoch: 7, Batch: 26,Loss: -1.117,Avg.Loss: -0.131,LR: 3.95E-04]Training epoch 7:   8%|▊         | 26/341 [00:00<00:05, 53.39it/s, Epoch: 7, Batch: 27,Loss: -1.107,Avg.Loss: -0.167,LR: 3.94E-04]Training epoch 7:   8%|▊         | 27/341 [00:00<00:05, 53.39it/s, Epoch: 7, Batch: 28,Loss: -0.213,Avg.Loss: -0.169,LR: 3.94E-04]Training epoch 7:   8%|▊         | 28/341 [00:00<00:05, 53.39it/s, Epoch: 7, Batch: 29,Loss: -0.531,Avg.Loss: -0.181,LR: 3.94E-04]Training epoch 7:   9%|▊         | 29/341 [00:00<00:05, 53.39it/s, Epoch: 7, Batch: 30,Loss: -1.391,Avg.Loss: -0.221,LR: 3.94E-04]Training epoch 7:   9%|▉         | 30/341 [00:00<00:05, 53.19it/s, Epoch: 7, Batch: 30,Loss: -1.391,Avg.Loss: -0.221,LR: 3.94E-04]Training epoch 7:   9%|▉         | 30/341 [00:00<00:05, 53.19it/s, Epoch: 7, Batch: 31,Loss: -0.607,Avg.Loss: -0.234,LR: 3.94E-04]Training epoch 7:   9%|▉         | 31/341 [00:00<00:05, 53.19it/s, Epoch: 7, Batch: 32,Loss: 0.852,Avg.Loss: -0.200,LR: 3.94E-04] Training epoch 7:   9%|▉         | 32/341 [00:00<00:05, 53.19it/s, Epoch: 7, Batch: 33,Loss: 0.743,Avg.Loss: -0.171,LR: 3.94E-04]Training epoch 7:  10%|▉         | 33/341 [00:00<00:05, 53.19it/s, Epoch: 7, Batch: 34,Loss: -1.190,Avg.Loss: -0.201,LR: 3.94E-04]Training epoch 7:  10%|▉         | 34/341 [00:00<00:05, 53.19it/s, Epoch: 7, Batch: 35,Loss: -1.145,Avg.Loss: -0.228,LR: 3.94E-04]Training epoch 7:  10%|█         | 35/341 [00:00<00:05, 53.19it/s, Epoch: 7, Batch: 36,Loss: -0.134,Avg.Loss: -0.226,LR: 3.94E-04]Training epoch 7:  11%|█         | 36/341 [00:00<00:05, 53.72it/s, Epoch: 7, Batch: 36,Loss: -0.134,Avg.Loss: -0.226,LR: 3.94E-04]Training epoch 7:  11%|█         | 36/341 [00:00<00:05, 53.72it/s, Epoch: 7, Batch: 37,Loss: -0.365,Avg.Loss: -0.229,LR: 3.93E-04]Training epoch 7:  11%|█         | 37/341 [00:00<00:05, 53.72it/s, Epoch: 7, Batch: 38,Loss: -1.357,Avg.Loss: -0.259,LR: 3.93E-04]Training epoch 7:  11%|█         | 38/341 [00:00<00:05, 53.72it/s, Epoch: 7, Batch: 39,Loss: -0.683,Avg.Loss: -0.270,LR: 3.93E-04]Training epoch 7:  11%|█▏        | 39/341 [00:00<00:05, 53.72it/s, Epoch: 7, Batch: 40,Loss: 0.730,Avg.Loss: -0.245,LR: 3.93E-04] Training epoch 7:  12%|█▏        | 40/341 [00:00<00:05, 53.72it/s, Epoch: 7, Batch: 41,Loss: 0.382,Avg.Loss: -0.230,LR: 3.93E-04]Training epoch 7:  12%|█▏        | 41/341 [00:00<00:05, 53.72it/s, Epoch: 7, Batch: 42,Loss: -1.291,Avg.Loss: -0.255,LR: 3.93E-04]Training epoch 7:  12%|█▏        | 42/341 [00:00<00:05, 53.66it/s, Epoch: 7, Batch: 42,Loss: -1.291,Avg.Loss: -0.255,LR: 3.93E-04]Training epoch 7:  12%|█▏        | 42/341 [00:00<00:05, 53.66it/s, Epoch: 7, Batch: 43,Loss: -0.838,Avg.Loss: -0.268,LR: 3.93E-04]Training epoch 7:  13%|█▎        | 43/341 [00:00<00:05, 53.66it/s, Epoch: 7, Batch: 44,Loss: 0.367,Avg.Loss: -0.254,LR: 3.93E-04] Training epoch 7:  13%|█▎        | 44/341 [00:00<00:05, 53.66it/s, Epoch: 7, Batch: 45,Loss: -0.115,Avg.Loss: -0.251,LR: 3.93E-04]Training epoch 7:  13%|█▎        | 45/341 [00:00<00:05, 53.66it/s, Epoch: 7, Batch: 46,Loss: -1.175,Avg.Loss: -0.271,LR: 3.93E-04]Training epoch 7:  13%|█▎        | 46/341 [00:00<00:05, 53.66it/s, Epoch: 7, Batch: 47,Loss: -1.334,Avg.Loss: -0.294,LR: 3.93E-04]Training epoch 7:  14%|█▍        | 47/341 [00:00<00:05, 53.66it/s, Epoch: 7, Batch: 48,Loss: -0.048,Avg.Loss: -0.289,LR: 3.92E-04]Training epoch 7:  14%|█▍        | 48/341 [00:00<00:05, 54.03it/s, Epoch: 7, Batch: 48,Loss: -0.048,Avg.Loss: -0.289,LR: 3.92E-04]Training epoch 7:  14%|█▍        | 48/341 [00:00<00:05, 54.03it/s, Epoch: 7, Batch: 49,Loss: -0.526,Avg.Loss: -0.293,LR: 3.92E-04]Training epoch 7:  14%|█▍        | 49/341 [00:00<00:05, 54.03it/s, Epoch: 7, Batch: 50,Loss: -1.083,Avg.Loss: -0.309,LR: 3.92E-04]Training epoch 7:  15%|█▍        | 50/341 [00:00<00:05, 54.03it/s, Epoch: 7, Batch: 51,Loss: -0.774,Avg.Loss: -0.318,LR: 3.92E-04]Training epoch 7:  15%|█▍        | 51/341 [00:00<00:05, 54.03it/s, Epoch: 7, Batch: 52,Loss: -0.145,Avg.Loss: -0.315,LR: 3.92E-04]Training epoch 7:  15%|█▌        | 52/341 [00:00<00:05, 54.03it/s, Epoch: 7, Batch: 53,Loss: -0.329,Avg.Loss: -0.315,LR: 3.92E-04]Training epoch 7:  16%|█▌        | 53/341 [00:01<00:05, 54.03it/s, Epoch: 7, Batch: 54,Loss: -1.544,Avg.Loss: -0.338,LR: 3.92E-04]Training epoch 7:  16%|█▌        | 54/341 [00:01<00:05, 53.77it/s, Epoch: 7, Batch: 54,Loss: -1.544,Avg.Loss: -0.338,LR: 3.92E-04]Training epoch 7:  16%|█▌        | 54/341 [00:01<00:05, 53.77it/s, Epoch: 7, Batch: 55,Loss: -0.875,Avg.Loss: -0.348,LR: 3.92E-04]Training epoch 7:  16%|█▌        | 55/341 [00:01<00:05, 53.77it/s, Epoch: 7, Batch: 56,Loss: -0.136,Avg.Loss: -0.344,LR: 3.92E-04]Training epoch 7:  16%|█▋        | 56/341 [00:01<00:05, 53.77it/s, Epoch: 7, Batch: 57,Loss: -0.380,Avg.Loss: -0.345,LR: 3.92E-04]Training epoch 7:  17%|█▋        | 57/341 [00:01<00:05, 53.77it/s, Epoch: 7, Batch: 58,Loss: -1.315,Avg.Loss: -0.361,LR: 3.91E-04]Training epoch 7:  17%|█▋        | 58/341 [00:01<00:05, 53.77it/s, Epoch: 7, Batch: 59,Loss: -0.728,Avg.Loss: -0.368,LR: 3.91E-04]Training epoch 7:  17%|█▋        | 59/341 [00:01<00:05, 53.77it/s, Epoch: 7, Batch: 60,Loss: -0.062,Avg.Loss: -0.362,LR: 3.91E-04]Training epoch 7:  18%|█▊        | 60/341 [00:01<00:05, 52.17it/s, Epoch: 7, Batch: 60,Loss: -0.062,Avg.Loss: -0.362,LR: 3.91E-04]Training epoch 7:  18%|█▊        | 60/341 [00:01<00:05, 52.17it/s, Epoch: 7, Batch: 61,Loss: -0.461,Avg.Loss: -0.364,LR: 3.91E-04]Training epoch 7:  18%|█▊        | 61/341 [00:01<00:05, 52.17it/s, Epoch: 7, Batch: 62,Loss: -1.183,Avg.Loss: -0.377,LR: 3.91E-04]Training epoch 7:  18%|█▊        | 62/341 [00:01<00:05, 52.17it/s, Epoch: 7, Batch: 63,Loss: -0.947,Avg.Loss: -0.386,LR: 3.91E-04]Training epoch 7:  18%|█▊        | 63/341 [00:01<00:05, 52.17it/s, Epoch: 7, Batch: 64,Loss: 0.118,Avg.Loss: -0.378,LR: 3.91E-04] Training epoch 7:  19%|█▉        | 64/341 [00:01<00:05, 52.17it/s, Epoch: 7, Batch: 65,Loss: -0.014,Avg.Loss: -0.373,LR: 3.91E-04]Training epoch 7:  19%|█▉        | 65/341 [00:01<00:05, 52.17it/s, Epoch: 7, Batch: 66,Loss: -1.217,Avg.Loss: -0.386,LR: 3.91E-04]Training epoch 7:  19%|█▉        | 66/341 [00:01<00:05, 50.80it/s, Epoch: 7, Batch: 66,Loss: -1.217,Avg.Loss: -0.386,LR: 3.91E-04]Training epoch 7:  19%|█▉        | 66/341 [00:01<00:05, 50.80it/s, Epoch: 7, Batch: 67,Loss: -1.039,Avg.Loss: -0.395,LR: 3.91E-04]Training epoch 7:  20%|█▉        | 67/341 [00:01<00:05, 50.80it/s, Epoch: 7, Batch: 68,Loss: -0.535,Avg.Loss: -0.397,LR: 3.91E-04]Training epoch 7:  20%|█▉        | 68/341 [00:01<00:05, 50.80it/s, Epoch: 7, Batch: 69,Loss: -0.083,Avg.Loss: -0.393,LR: 3.90E-04]Training epoch 7:  20%|██        | 69/341 [00:01<00:05, 50.80it/s, Epoch: 7, Batch: 70,Loss: -1.341,Avg.Loss: -0.406,LR: 3.90E-04]Training epoch 7:  21%|██        | 70/341 [00:01<00:05, 50.80it/s, Epoch: 7, Batch: 71,Loss: -1.195,Avg.Loss: -0.418,LR: 3.90E-04]Training epoch 7:  21%|██        | 71/341 [00:01<00:05, 50.80it/s, Epoch: 7, Batch: 72,Loss: 0.091,Avg.Loss: -0.410,LR: 3.90E-04] Training epoch 7:  21%|██        | 72/341 [00:01<00:05, 50.47it/s, Epoch: 7, Batch: 72,Loss: 0.091,Avg.Loss: -0.410,LR: 3.90E-04]Training epoch 7:  21%|██        | 72/341 [00:01<00:05, 50.47it/s, Epoch: 7, Batch: 73,Loss: -0.547,Avg.Loss: -0.412,LR: 3.90E-04]Training epoch 7:  21%|██▏       | 73/341 [00:01<00:05, 50.47it/s, Epoch: 7, Batch: 74,Loss: -1.428,Avg.Loss: -0.426,LR: 3.90E-04]Training epoch 7:  22%|██▏       | 74/341 [00:01<00:05, 50.47it/s, Epoch: 7, Batch: 75,Loss: -0.936,Avg.Loss: -0.433,LR: 3.90E-04]Training epoch 7:  22%|██▏       | 75/341 [00:01<00:05, 50.47it/s, Epoch: 7, Batch: 76,Loss: 0.629,Avg.Loss: -0.419,LR: 3.90E-04] Training epoch 7:  22%|██▏       | 76/341 [00:01<00:05, 50.47it/s, Epoch: 7, Batch: 77,Loss: -0.106,Avg.Loss: -0.415,LR: 3.90E-04]Training epoch 7:  23%|██▎       | 77/341 [00:01<00:05, 50.47it/s, Epoch: 7, Batch: 78,Loss: -1.142,Avg.Loss: -0.424,LR: 3.90E-04]Training epoch 7:  23%|██▎       | 78/341 [00:01<00:05, 50.73it/s, Epoch: 7, Batch: 78,Loss: -1.142,Avg.Loss: -0.424,LR: 3.90E-04]Training epoch 7:  23%|██▎       | 78/341 [00:01<00:05, 50.73it/s, Epoch: 7, Batch: 79,Loss: -1.073,Avg.Loss: -0.432,LR: 3.89E-04]Training epoch 7:  23%|██▎       | 79/341 [00:01<00:05, 50.73it/s, Epoch: 7, Batch: 80,Loss: -0.644,Avg.Loss: -0.435,LR: 3.89E-04]Training epoch 7:  23%|██▎       | 80/341 [00:01<00:05, 50.73it/s, Epoch: 7, Batch: 81,Loss: -0.706,Avg.Loss: -0.438,LR: 3.89E-04]Training epoch 7:  24%|██▍       | 81/341 [00:01<00:05, 50.73it/s, Epoch: 7, Batch: 82,Loss: -1.476,Avg.Loss: -0.451,LR: 3.89E-04]Training epoch 7:  24%|██▍       | 82/341 [00:01<00:05, 50.73it/s, Epoch: 7, Batch: 83,Loss: -1.084,Avg.Loss: -0.459,LR: 3.89E-04]Training epoch 7:  24%|██▍       | 83/341 [00:01<00:05, 50.73it/s, Epoch: 7, Batch: 84,Loss: 0.255,Avg.Loss: -0.450,LR: 3.89E-04] Training epoch 7:  25%|██▍       | 84/341 [00:01<00:05, 50.40it/s, Epoch: 7, Batch: 84,Loss: 0.255,Avg.Loss: -0.450,LR: 3.89E-04]Training epoch 7:  25%|██▍       | 84/341 [00:01<00:05, 50.40it/s, Epoch: 7, Batch: 85,Loss: -0.554,Avg.Loss: -0.451,LR: 3.89E-04]Training epoch 7:  25%|██▍       | 85/341 [00:01<00:05, 50.40it/s, Epoch: 7, Batch: 86,Loss: -1.284,Avg.Loss: -0.461,LR: 3.89E-04]Training epoch 7:  25%|██▌       | 86/341 [00:01<00:05, 50.40it/s, Epoch: 7, Batch: 87,Loss: -0.917,Avg.Loss: -0.466,LR: 3.89E-04]Training epoch 7:  26%|██▌       | 87/341 [00:01<00:05, 50.40it/s, Epoch: 7, Batch: 88,Loss: -0.441,Avg.Loss: -0.466,LR: 3.89E-04]Training epoch 7:  26%|██▌       | 88/341 [00:01<00:05, 50.40it/s, Epoch: 7, Batch: 89,Loss: -0.781,Avg.Loss: -0.470,LR: 3.89E-04]Training epoch 7:  26%|██▌       | 89/341 [00:01<00:04, 50.40it/s, Epoch: 7, Batch: 90,Loss: -0.866,Avg.Loss: -0.474,LR: 3.88E-04]Training epoch 7:  26%|██▋       | 90/341 [00:01<00:04, 50.52it/s, Epoch: 7, Batch: 90,Loss: -0.866,Avg.Loss: -0.474,LR: 3.88E-04]Training epoch 7:  26%|██▋       | 90/341 [00:01<00:04, 50.52it/s, Epoch: 7, Batch: 91,Loss: -0.242,Avg.Loss: -0.471,LR: 3.88E-04]Training epoch 7:  27%|██▋       | 91/341 [00:01<00:04, 50.52it/s, Epoch: 7, Batch: 92,Loss: 0.676,Avg.Loss: -0.459,LR: 3.88E-04] Training epoch 7:  27%|██▋       | 92/341 [00:01<00:04, 50.52it/s, Epoch: 7, Batch: 93,Loss: 0.670,Avg.Loss: -0.447,LR: 3.88E-04]Training epoch 7:  27%|██▋       | 93/341 [00:01<00:04, 50.52it/s, Epoch: 7, Batch: 94,Loss: -0.885,Avg.Loss: -0.451,LR: 3.88E-04]Training epoch 7:  28%|██▊       | 94/341 [00:01<00:04, 50.52it/s, Epoch: 7, Batch: 95,Loss: -1.213,Avg.Loss: -0.459,LR: 3.88E-04]Training epoch 7:  28%|██▊       | 95/341 [00:01<00:04, 50.52it/s, Epoch: 7, Batch: 96,Loss: -0.760,Avg.Loss: -0.463,LR: 3.88E-04]Training epoch 7:  28%|██▊       | 96/341 [00:01<00:04, 50.51it/s, Epoch: 7, Batch: 96,Loss: -0.760,Avg.Loss: -0.463,LR: 3.88E-04]Training epoch 7:  28%|██▊       | 96/341 [00:01<00:04, 50.51it/s, Epoch: 7, Batch: 97,Loss: -0.999,Avg.Loss: -0.468,LR: 3.88E-04]Training epoch 7:  28%|██▊       | 97/341 [00:01<00:04, 50.51it/s, Epoch: 7, Batch: 98,Loss: -1.616,Avg.Loss: -0.480,LR: 3.88E-04]Training epoch 7:  29%|██▊       | 98/341 [00:01<00:04, 50.51it/s, Epoch: 7, Batch: 99,Loss: -1.227,Avg.Loss: -0.487,LR: 3.88E-04]Training epoch 7:  29%|██▉       | 99/341 [00:01<00:04, 50.51it/s, Epoch: 7, Batch: 100,Loss: -1.066,Avg.Loss: -0.493,LR: 3.87E-04]Training epoch 7:  29%|██▉       | 100/341 [00:01<00:04, 50.51it/s, Epoch: 7, Batch: 101,Loss: -1.075,Avg.Loss: -0.499,LR: 3.87E-04]Training epoch 7:  30%|██▉       | 101/341 [00:01<00:04, 50.51it/s, Epoch: 7, Batch: 102,Loss: -0.436,Avg.Loss: -0.498,LR: 3.87E-04]Training epoch 7:  30%|██▉       | 102/341 [00:01<00:04, 50.54it/s, Epoch: 7, Batch: 102,Loss: -0.436,Avg.Loss: -0.498,LR: 3.87E-04]Training epoch 7:  30%|██▉       | 102/341 [00:01<00:04, 50.54it/s, Epoch: 7, Batch: 103,Loss: -0.073,Avg.Loss: -0.494,LR: 3.87E-04]Training epoch 7:  30%|███       | 103/341 [00:02<00:04, 50.54it/s, Epoch: 7, Batch: 104,Loss: -1.217,Avg.Loss: -0.501,LR: 3.87E-04]Training epoch 7:  30%|███       | 104/341 [00:02<00:04, 50.54it/s, Epoch: 7, Batch: 105,Loss: -1.308,Avg.Loss: -0.509,LR: 3.87E-04]Training epoch 7:  31%|███       | 105/341 [00:02<00:04, 50.54it/s, Epoch: 7, Batch: 106,Loss: -1.066,Avg.Loss: -0.514,LR: 3.87E-04]Training epoch 7:  31%|███       | 106/341 [00:02<00:04, 50.54it/s, Epoch: 7, Batch: 107,Loss: -0.921,Avg.Loss: -0.518,LR: 3.87E-04]Training epoch 7:  31%|███▏      | 107/341 [00:02<00:04, 50.54it/s, Epoch: 7, Batch: 108,Loss: -1.176,Avg.Loss: -0.524,LR: 3.87E-04]Training epoch 7:  32%|███▏      | 108/341 [00:02<00:04, 50.64it/s, Epoch: 7, Batch: 108,Loss: -1.176,Avg.Loss: -0.524,LR: 3.87E-04]Training epoch 7:  32%|███▏      | 108/341 [00:02<00:04, 50.64it/s, Epoch: 7, Batch: 109,Loss: -1.352,Avg.Loss: -0.532,LR: 3.87E-04]Training epoch 7:  32%|███▏      | 109/341 [00:02<00:04, 50.64it/s, Epoch: 7, Batch: 110,Loss: -1.420,Avg.Loss: -0.540,LR: 3.87E-04]Training epoch 7:  32%|███▏      | 110/341 [00:02<00:04, 50.64it/s, Epoch: 7, Batch: 111,Loss: -1.275,Avg.Loss: -0.546,LR: 3.86E-04]Training epoch 7:  33%|███▎      | 111/341 [00:02<00:04, 50.64it/s, Epoch: 7, Batch: 112,Loss: -1.275,Avg.Loss: -0.553,LR: 3.86E-04]Training epoch 7:  33%|███▎      | 112/341 [00:02<00:04, 50.64it/s, Epoch: 7, Batch: 113,Loss: -1.317,Avg.Loss: -0.560,LR: 3.86E-04]Training epoch 7:  33%|███▎      | 113/341 [00:02<00:04, 50.64it/s, Epoch: 7, Batch: 114,Loss: -1.506,Avg.Loss: -0.568,LR: 3.86E-04]Training epoch 7:  33%|███▎      | 114/341 [00:02<00:04, 50.98it/s, Epoch: 7, Batch: 114,Loss: -1.506,Avg.Loss: -0.568,LR: 3.86E-04]Training epoch 7:  33%|███▎      | 114/341 [00:02<00:04, 50.98it/s, Epoch: 7, Batch: 115,Loss: -0.966,Avg.Loss: -0.571,LR: 3.86E-04]Training epoch 7:  34%|███▎      | 115/341 [00:02<00:04, 50.98it/s, Epoch: 7, Batch: 116,Loss: -1.553,Avg.Loss: -0.580,LR: 3.86E-04]Training epoch 7:  34%|███▍      | 116/341 [00:02<00:04, 50.98it/s, Epoch: 7, Batch: 117,Loss: -1.284,Avg.Loss: -0.586,LR: 3.86E-04]Training epoch 7:  34%|███▍      | 117/341 [00:02<00:04, 50.98it/s, Epoch: 7, Batch: 118,Loss: -1.078,Avg.Loss: -0.590,LR: 3.86E-04]Training epoch 7:  35%|███▍      | 118/341 [00:02<00:04, 50.98it/s, Epoch: 7, Batch: 119,Loss: -1.123,Avg.Loss: -0.594,LR: 3.86E-04]Training epoch 7:  35%|███▍      | 119/341 [00:02<00:04, 50.98it/s, Epoch: 7, Batch: 120,Loss: -0.968,Avg.Loss: -0.598,LR: 3.86E-04]Training epoch 7:  35%|███▌      | 120/341 [00:02<00:04, 50.69it/s, Epoch: 7, Batch: 120,Loss: -0.968,Avg.Loss: -0.598,LR: 3.86E-04]Training epoch 7:  35%|███▌      | 120/341 [00:02<00:04, 50.69it/s, Epoch: 7, Batch: 121,Loss: -0.784,Avg.Loss: -0.599,LR: 3.85E-04]Training epoch 7:  35%|███▌      | 121/341 [00:02<00:04, 50.69it/s, Epoch: 7, Batch: 122,Loss: -0.582,Avg.Loss: -0.599,LR: 3.85E-04]Training epoch 7:  36%|███▌      | 122/341 [00:02<00:04, 50.69it/s, Epoch: 7, Batch: 123,Loss: 0.325,Avg.Loss: -0.591,LR: 3.85E-04] Training epoch 7:  36%|███▌      | 123/341 [00:02<00:04, 50.69it/s, Epoch: 7, Batch: 124,Loss: -0.821,Avg.Loss: -0.593,LR: 3.85E-04]Training epoch 7:  36%|███▋      | 124/341 [00:02<00:04, 50.69it/s, Epoch: 7, Batch: 125,Loss: -1.595,Avg.Loss: -0.601,LR: 3.85E-04]Training epoch 7:  37%|███▋      | 125/341 [00:02<00:04, 50.69it/s, Epoch: 7, Batch: 126,Loss: -1.205,Avg.Loss: -0.606,LR: 3.85E-04]Training epoch 7:  37%|███▋      | 126/341 [00:02<00:04, 50.70it/s, Epoch: 7, Batch: 126,Loss: -1.205,Avg.Loss: -0.606,LR: 3.85E-04]Training epoch 7:  37%|███▋      | 126/341 [00:02<00:04, 50.70it/s, Epoch: 7, Batch: 127,Loss: -1.417,Avg.Loss: -0.612,LR: 3.85E-04]Training epoch 7:  37%|███▋      | 127/341 [00:02<00:04, 50.70it/s, Epoch: 7, Batch: 128,Loss: -0.589,Avg.Loss: -0.612,LR: 3.85E-04]Training epoch 7:  38%|███▊      | 128/341 [00:02<00:04, 50.70it/s, Epoch: 7, Batch: 129,Loss: -0.200,Avg.Loss: -0.609,LR: 3.85E-04]Training epoch 7:  38%|███▊      | 129/341 [00:02<00:04, 50.70it/s, Epoch: 7, Batch: 130,Loss: -1.518,Avg.Loss: -0.616,LR: 3.85E-04]Training epoch 7:  38%|███▊      | 130/341 [00:02<00:04, 50.70it/s, Epoch: 7, Batch: 131,Loss: -1.350,Avg.Loss: -0.622,LR: 3.84E-04]Training epoch 7:  38%|███▊      | 131/341 [00:02<00:04, 50.70it/s, Epoch: 7, Batch: 132,Loss: -1.149,Avg.Loss: -0.626,LR: 3.84E-04]Training epoch 7:  39%|███▊      | 132/341 [00:02<00:04, 50.63it/s, Epoch: 7, Batch: 132,Loss: -1.149,Avg.Loss: -0.626,LR: 3.84E-04]Training epoch 7:  39%|███▊      | 132/341 [00:02<00:04, 50.63it/s, Epoch: 7, Batch: 133,Loss: -1.428,Avg.Loss: -0.632,LR: 3.84E-04]Training epoch 7:  39%|███▉      | 133/341 [00:02<00:04, 50.63it/s, Epoch: 7, Batch: 134,Loss: -1.214,Avg.Loss: -0.636,LR: 3.84E-04]Training epoch 7:  39%|███▉      | 134/341 [00:02<00:04, 50.63it/s, Epoch: 7, Batch: 135,Loss: -1.007,Avg.Loss: -0.639,LR: 3.84E-04]Training epoch 7:  40%|███▉      | 135/341 [00:02<00:04, 50.63it/s, Epoch: 7, Batch: 136,Loss: -1.595,Avg.Loss: -0.646,LR: 3.84E-04]Training epoch 7:  40%|███▉      | 136/341 [00:02<00:04, 50.63it/s, Epoch: 7, Batch: 137,Loss: -0.577,Avg.Loss: -0.645,LR: 3.84E-04]Training epoch 7:  40%|████      | 137/341 [00:02<00:04, 50.63it/s, Epoch: 7, Batch: 138,Loss: -0.329,Avg.Loss: -0.643,LR: 3.84E-04]Training epoch 7:  40%|████      | 138/341 [00:02<00:03, 51.89it/s, Epoch: 7, Batch: 138,Loss: -0.329,Avg.Loss: -0.643,LR: 3.84E-04]Training epoch 7:  40%|████      | 138/341 [00:02<00:03, 51.89it/s, Epoch: 7, Batch: 139,Loss: -1.519,Avg.Loss: -0.649,LR: 3.84E-04]Training epoch 7:  41%|████      | 139/341 [00:02<00:03, 51.89it/s, Epoch: 7, Batch: 140,Loss: -1.059,Avg.Loss: -0.652,LR: 3.84E-04]Training epoch 7:  41%|████      | 140/341 [00:02<00:03, 51.89it/s, Epoch: 7, Batch: 141,Loss: -1.283,Avg.Loss: -0.657,LR: 3.84E-04]Training epoch 7:  41%|████▏     | 141/341 [00:02<00:03, 51.89it/s, Epoch: 7, Batch: 142,Loss: -1.356,Avg.Loss: -0.662,LR: 3.83E-04]Training epoch 7:  42%|████▏     | 142/341 [00:02<00:03, 51.89it/s, Epoch: 7, Batch: 143,Loss: -0.681,Avg.Loss: -0.662,LR: 3.83E-04]Training epoch 7:  42%|████▏     | 143/341 [00:02<00:03, 51.89it/s, Epoch: 7, Batch: 144,Loss: -0.476,Avg.Loss: -0.660,LR: 3.83E-04]Training epoch 7:  42%|████▏     | 144/341 [00:02<00:03, 51.86it/s, Epoch: 7, Batch: 144,Loss: -0.476,Avg.Loss: -0.660,LR: 3.83E-04]Training epoch 7:  42%|████▏     | 144/341 [00:02<00:03, 51.86it/s, Epoch: 7, Batch: 145,Loss: -0.862,Avg.Loss: -0.662,LR: 3.83E-04]Training epoch 7:  43%|████▎     | 145/341 [00:02<00:03, 51.86it/s, Epoch: 7, Batch: 146,Loss: -1.436,Avg.Loss: -0.667,LR: 3.83E-04]Training epoch 7:  43%|████▎     | 146/341 [00:02<00:03, 51.86it/s, Epoch: 7, Batch: 147,Loss: -1.324,Avg.Loss: -0.672,LR: 3.83E-04]Training epoch 7:  43%|████▎     | 147/341 [00:02<00:03, 51.86it/s, Epoch: 7, Batch: 148,Loss: -1.292,Avg.Loss: -0.676,LR: 3.83E-04]Training epoch 7:  43%|████▎     | 148/341 [00:02<00:03, 51.86it/s, Epoch: 7, Batch: 149,Loss: -1.034,Avg.Loss: -0.678,LR: 3.83E-04]Training epoch 7:  44%|████▎     | 149/341 [00:02<00:03, 51.86it/s, Epoch: 7, Batch: 150,Loss: -1.183,Avg.Loss: -0.682,LR: 3.83E-04]Training epoch 7:  44%|████▍     | 150/341 [00:02<00:03, 52.21it/s, Epoch: 7, Batch: 150,Loss: -1.183,Avg.Loss: -0.682,LR: 3.83E-04]Training epoch 7:  44%|████▍     | 150/341 [00:02<00:03, 52.21it/s, Epoch: 7, Batch: 151,Loss: -1.585,Avg.Loss: -0.688,LR: 3.83E-04]Training epoch 7:  44%|████▍     | 151/341 [00:02<00:03, 52.21it/s, Epoch: 7, Batch: 152,Loss: -0.725,Avg.Loss: -0.688,LR: 3.82E-04]Training epoch 7:  45%|████▍     | 152/341 [00:02<00:03, 52.21it/s, Epoch: 7, Batch: 153,Loss: -0.291,Avg.Loss: -0.685,LR: 3.82E-04]Training epoch 7:  45%|████▍     | 153/341 [00:02<00:03, 52.21it/s, Epoch: 7, Batch: 154,Loss: -1.223,Avg.Loss: -0.689,LR: 3.82E-04]Training epoch 7:  45%|████▌     | 154/341 [00:02<00:03, 52.21it/s, Epoch: 7, Batch: 155,Loss: -1.848,Avg.Loss: -0.696,LR: 3.82E-04]Training epoch 7:  45%|████▌     | 155/341 [00:03<00:03, 52.21it/s, Epoch: 7, Batch: 156,Loss: -1.080,Avg.Loss: -0.699,LR: 3.82E-04]Training epoch 7:  46%|████▌     | 156/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 156,Loss: -1.080,Avg.Loss: -0.699,LR: 3.82E-04]Training epoch 7:  46%|████▌     | 156/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 157,Loss: -1.694,Avg.Loss: -0.705,LR: 3.82E-04]Training epoch 7:  46%|████▌     | 157/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 158,Loss: -1.339,Avg.Loss: -0.709,LR: 3.82E-04]Training epoch 7:  46%|████▋     | 158/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 159,Loss: -0.850,Avg.Loss: -0.710,LR: 3.82E-04]Training epoch 7:  47%|████▋     | 159/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 160,Loss: -1.522,Avg.Loss: -0.715,LR: 3.82E-04]Training epoch 7:  47%|████▋     | 160/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 161,Loss: -1.641,Avg.Loss: -0.721,LR: 3.82E-04]Training epoch 7:  47%|████▋     | 161/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 162,Loss: -1.396,Avg.Loss: -0.725,LR: 3.81E-04]Training epoch 7:  48%|████▊     | 162/341 [00:03<00:03, 51.10it/s, Epoch: 7, Batch: 162,Loss: -1.396,Avg.Loss: -0.725,LR: 3.81E-04]Training epoch 7:  48%|████▊     | 162/341 [00:03<00:03, 51.10it/s, Epoch: 7, Batch: 163,Loss: -1.435,Avg.Loss: -0.729,LR: 3.81E-04]Training epoch 7:  48%|████▊     | 163/341 [00:03<00:03, 51.10it/s, Epoch: 7, Batch: 164,Loss: -1.376,Avg.Loss: -0.733,LR: 3.81E-04]Training epoch 7:  48%|████▊     | 164/341 [00:03<00:03, 51.10it/s, Epoch: 7, Batch: 165,Loss: -0.867,Avg.Loss: -0.734,LR: 3.81E-04]Training epoch 7:  48%|████▊     | 165/341 [00:03<00:03, 51.10it/s, Epoch: 7, Batch: 166,Loss: -1.603,Avg.Loss: -0.739,LR: 3.81E-04]Training epoch 7:  49%|████▊     | 166/341 [00:03<00:03, 51.10it/s, Epoch: 7, Batch: 167,Loss: -1.583,Avg.Loss: -0.744,LR: 3.81E-04]Training epoch 7:  49%|████▉     | 167/341 [00:03<00:03, 51.10it/s, Epoch: 7, Batch: 168,Loss: -0.832,Avg.Loss: -0.745,LR: 3.81E-04]Training epoch 7:  49%|████▉     | 168/341 [00:03<00:03, 51.28it/s, Epoch: 7, Batch: 168,Loss: -0.832,Avg.Loss: -0.745,LR: 3.81E-04]Training epoch 7:  49%|████▉     | 168/341 [00:03<00:03, 51.28it/s, Epoch: 7, Batch: 169,Loss: -1.370,Avg.Loss: -0.749,LR: 3.81E-04]Training epoch 7:  50%|████▉     | 169/341 [00:03<00:03, 51.28it/s, Epoch: 7, Batch: 170,Loss: -1.369,Avg.Loss: -0.752,LR: 3.81E-04]Training epoch 7:  50%|████▉     | 170/341 [00:03<00:03, 51.28it/s, Epoch: 7, Batch: 171,Loss: -1.189,Avg.Loss: -0.755,LR: 3.81E-04]Training epoch 7:  50%|█████     | 171/341 [00:03<00:03, 51.28it/s, Epoch: 7, Batch: 172,Loss: -1.225,Avg.Loss: -0.757,LR: 3.80E-04]Training epoch 7:  50%|█████     | 172/341 [00:03<00:03, 51.28it/s, Epoch: 7, Batch: 173,Loss: -1.408,Avg.Loss: -0.761,LR: 3.80E-04]Training epoch 7:  51%|█████     | 173/341 [00:03<00:03, 51.28it/s, Epoch: 7, Batch: 174,Loss: -0.579,Avg.Loss: -0.760,LR: 3.80E-04]Training epoch 7:  51%|█████     | 174/341 [00:03<00:03, 51.58it/s, Epoch: 7, Batch: 174,Loss: -0.579,Avg.Loss: -0.760,LR: 3.80E-04]Training epoch 7:  51%|█████     | 174/341 [00:03<00:03, 51.58it/s, Epoch: 7, Batch: 175,Loss: -1.297,Avg.Loss: -0.763,LR: 3.80E-04]Training epoch 7:  51%|█████▏    | 175/341 [00:03<00:03, 51.58it/s, Epoch: 7, Batch: 176,Loss: -1.284,Avg.Loss: -0.766,LR: 3.80E-04]Training epoch 7:  52%|█████▏    | 176/341 [00:03<00:03, 51.58it/s, Epoch: 7, Batch: 177,Loss: -0.992,Avg.Loss: -0.767,LR: 3.80E-04]Training epoch 7:  52%|█████▏    | 177/341 [00:03<00:03, 51.58it/s, Epoch: 7, Batch: 178,Loss: -1.834,Avg.Loss: -0.773,LR: 3.80E-04]Training epoch 7:  52%|█████▏    | 178/341 [00:03<00:03, 51.58it/s, Epoch: 7, Batch: 179,Loss: -1.161,Avg.Loss: -0.776,LR: 3.80E-04]Training epoch 7:  52%|█████▏    | 179/341 [00:03<00:03, 51.58it/s, Epoch: 7, Batch: 180,Loss: -0.969,Avg.Loss: -0.777,LR: 3.80E-04]Training epoch 7:  53%|█████▎    | 180/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 180,Loss: -0.969,Avg.Loss: -0.777,LR: 3.80E-04]Training epoch 7:  53%|█████▎    | 180/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 181,Loss: -1.597,Avg.Loss: -0.781,LR: 3.80E-04]Training epoch 7:  53%|█████▎    | 181/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 182,Loss: -1.275,Avg.Loss: -0.784,LR: 3.79E-04]Training epoch 7:  53%|█████▎    | 182/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 183,Loss: -0.600,Avg.Loss: -0.783,LR: 3.79E-04]Training epoch 7:  54%|█████▎    | 183/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 184,Loss: -1.402,Avg.Loss: -0.786,LR: 3.79E-04]Training epoch 7:  54%|█████▍    | 184/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 185,Loss: -1.407,Avg.Loss: -0.790,LR: 3.79E-04]Training epoch 7:  54%|█████▍    | 185/341 [00:03<00:03, 51.51it/s, Epoch: 7, Batch: 186,Loss: -1.109,Avg.Loss: -0.791,LR: 3.79E-04]Training epoch 7:  55%|█████▍    | 186/341 [00:03<00:02, 51.92it/s, Epoch: 7, Batch: 186,Loss: -1.109,Avg.Loss: -0.791,LR: 3.79E-04]Training epoch 7:  55%|█████▍    | 186/341 [00:03<00:02, 51.92it/s, Epoch: 7, Batch: 187,Loss: -1.419,Avg.Loss: -0.795,LR: 3.79E-04]Training epoch 7:  55%|█████▍    | 187/341 [00:03<00:02, 51.92it/s, Epoch: 7, Batch: 188,Loss: -1.521,Avg.Loss: -0.799,LR: 3.79E-04]Training epoch 7:  55%|█████▌    | 188/341 [00:03<00:02, 51.92it/s, Epoch: 7, Batch: 189,Loss: -0.997,Avg.Loss: -0.800,LR: 3.79E-04]Training epoch 7:  55%|█████▌    | 189/341 [00:03<00:02, 51.92it/s, Epoch: 7, Batch: 190,Loss: -1.226,Avg.Loss: -0.802,LR: 3.79E-04]Training epoch 7:  56%|█████▌    | 190/341 [00:03<00:02, 51.92it/s, Epoch: 7, Batch: 191,Loss: -1.315,Avg.Loss: -0.805,LR: 3.79E-04]Training epoch 7:  56%|█████▌    | 191/341 [00:03<00:02, 51.92it/s, Epoch: 7, Batch: 192,Loss: -0.801,Avg.Loss: -0.805,LR: 3.79E-04]Training epoch 7:  56%|█████▋    | 192/341 [00:03<00:02, 51.65it/s, Epoch: 7, Batch: 192,Loss: -0.801,Avg.Loss: -0.805,LR: 3.79E-04]Training epoch 7:  56%|█████▋    | 192/341 [00:03<00:02, 51.65it/s, Epoch: 7, Batch: 193,Loss: -1.229,Avg.Loss: -0.807,LR: 3.78E-04]Training epoch 7:  57%|█████▋    | 193/341 [00:03<00:02, 51.65it/s, Epoch: 7, Batch: 194,Loss: -1.213,Avg.Loss: -0.809,LR: 3.78E-04]Training epoch 7:  57%|█████▋    | 194/341 [00:03<00:02, 51.65it/s, Epoch: 7, Batch: 195,Loss: -0.896,Avg.Loss: -0.809,LR: 3.78E-04]Training epoch 7:  57%|█████▋    | 195/341 [00:03<00:02, 51.65it/s, Epoch: 7, Batch: 196,Loss: -1.445,Avg.Loss: -0.813,LR: 3.78E-04]Training epoch 7:  57%|█████▋    | 196/341 [00:03<00:02, 51.65it/s, Epoch: 7, Batch: 197,Loss: -1.290,Avg.Loss: -0.815,LR: 3.78E-04]Training epoch 7:  58%|█████▊    | 197/341 [00:03<00:02, 51.65it/s, Epoch: 7, Batch: 198,Loss: -0.583,Avg.Loss: -0.814,LR: 3.78E-04]Training epoch 7:  58%|█████▊    | 198/341 [00:03<00:02, 51.61it/s, Epoch: 7, Batch: 198,Loss: -0.583,Avg.Loss: -0.814,LR: 3.78E-04]Training epoch 7:  58%|█████▊    | 198/341 [00:03<00:02, 51.61it/s, Epoch: 7, Batch: 199,Loss: -1.143,Avg.Loss: -0.815,LR: 3.78E-04]Training epoch 7:  58%|█████▊    | 199/341 [00:03<00:02, 51.61it/s, Epoch: 7, Batch: 200,Loss: -1.511,Avg.Loss: -0.819,LR: 3.78E-04]Training epoch 7:  59%|█████▊    | 200/341 [00:03<00:02, 51.61it/s, Epoch: 7, Batch: 201,Loss: -1.494,Avg.Loss: -0.822,LR: 3.78E-04]Training epoch 7:  59%|█████▉    | 201/341 [00:03<00:02, 51.61it/s, Epoch: 7, Batch: 202,Loss: -1.521,Avg.Loss: -0.826,LR: 3.78E-04]Training epoch 7:  59%|█████▉    | 202/341 [00:03<00:02, 51.61it/s, Epoch: 7, Batch: 203,Loss: -1.187,Avg.Loss: -0.828,LR: 3.77E-04]Training epoch 7:  60%|█████▉    | 203/341 [00:03<00:02, 51.61it/s, Epoch: 7, Batch: 204,Loss: -0.638,Avg.Loss: -0.827,LR: 3.77E-04]Training epoch 7:  60%|█████▉    | 204/341 [00:03<00:02, 52.26it/s, Epoch: 7, Batch: 204,Loss: -0.638,Avg.Loss: -0.827,LR: 3.77E-04]Training epoch 7:  60%|█████▉    | 204/341 [00:03<00:02, 52.26it/s, Epoch: 7, Batch: 205,Loss: -1.628,Avg.Loss: -0.831,LR: 3.77E-04]Training epoch 7:  60%|██████    | 205/341 [00:03<00:02, 52.26it/s, Epoch: 7, Batch: 206,Loss: -1.316,Avg.Loss: -0.833,LR: 3.77E-04]Training epoch 7:  60%|██████    | 206/341 [00:03<00:02, 52.26it/s, Epoch: 7, Batch: 207,Loss: -0.907,Avg.Loss: -0.833,LR: 3.77E-04]Training epoch 7:  61%|██████    | 207/341 [00:04<00:02, 52.26it/s, Epoch: 7, Batch: 208,Loss: -1.515,Avg.Loss: -0.837,LR: 3.77E-04]Training epoch 7:  61%|██████    | 208/341 [00:04<00:02, 52.26it/s, Epoch: 7, Batch: 209,Loss: -1.265,Avg.Loss: -0.839,LR: 3.77E-04]Training epoch 7:  61%|██████▏   | 209/341 [00:04<00:02, 52.26it/s, Epoch: 7, Batch: 210,Loss: -0.611,Avg.Loss: -0.837,LR: 3.77E-04]Training epoch 7:  62%|██████▏   | 210/341 [00:04<00:02, 52.41it/s, Epoch: 7, Batch: 210,Loss: -0.611,Avg.Loss: -0.837,LR: 3.77E-04]Training epoch 7:  62%|██████▏   | 210/341 [00:04<00:02, 52.41it/s, Epoch: 7, Batch: 211,Loss: -1.334,Avg.Loss: -0.840,LR: 3.77E-04]Training epoch 7:  62%|██████▏   | 211/341 [00:04<00:02, 52.41it/s, Epoch: 7, Batch: 212,Loss: -1.432,Avg.Loss: -0.843,LR: 3.77E-04]Training epoch 7:  62%|██████▏   | 212/341 [00:04<00:02, 52.41it/s, Epoch: 7, Batch: 213,Loss: -1.147,Avg.Loss: -0.844,LR: 3.76E-04]Training epoch 7:  62%|██████▏   | 213/341 [00:04<00:02, 52.41it/s, Epoch: 7, Batch: 214,Loss: -1.639,Avg.Loss: -0.848,LR: 3.76E-04]Training epoch 7:  63%|██████▎   | 214/341 [00:04<00:02, 52.41it/s, Epoch: 7, Batch: 215,Loss: -1.236,Avg.Loss: -0.850,LR: 3.76E-04]Training epoch 7:  63%|██████▎   | 215/341 [00:04<00:02, 52.41it/s, Epoch: 7, Batch: 216,Loss: -1.337,Avg.Loss: -0.852,LR: 3.76E-04]Training epoch 7:  63%|██████▎   | 216/341 [00:04<00:02, 52.51it/s, Epoch: 7, Batch: 216,Loss: -1.337,Avg.Loss: -0.852,LR: 3.76E-04]Training epoch 7:  63%|██████▎   | 216/341 [00:04<00:02, 52.51it/s, Epoch: 7, Batch: 217,Loss: -1.619,Avg.Loss: -0.855,LR: 3.76E-04]Training epoch 7:  64%|██████▎   | 217/341 [00:04<00:02, 52.51it/s, Epoch: 7, Batch: 218,Loss: -1.097,Avg.Loss: -0.856,LR: 3.76E-04]Training epoch 7:  64%|██████▍   | 218/341 [00:04<00:02, 52.51it/s, Epoch: 7, Batch: 219,Loss: -0.402,Avg.Loss: -0.854,LR: 3.76E-04]Training epoch 7:  64%|██████▍   | 219/341 [00:04<00:02, 52.51it/s, Epoch: 7, Batch: 220,Loss: -1.245,Avg.Loss: -0.856,LR: 3.76E-04]Training epoch 7:  65%|██████▍   | 220/341 [00:04<00:02, 52.51it/s, Epoch: 7, Batch: 221,Loss: -0.932,Avg.Loss: -0.857,LR: 3.76E-04]Training epoch 7:  65%|██████▍   | 221/341 [00:04<00:02, 52.51it/s, Epoch: 7, Batch: 222,Loss: -1.607,Avg.Loss: -0.860,LR: 3.76E-04]Training epoch 7:  65%|██████▌   | 222/341 [00:04<00:02, 52.89it/s, Epoch: 7, Batch: 222,Loss: -1.607,Avg.Loss: -0.860,LR: 3.76E-04]Training epoch 7:  65%|██████▌   | 222/341 [00:04<00:02, 52.89it/s, Epoch: 7, Batch: 223,Loss: -1.572,Avg.Loss: -0.863,LR: 3.75E-04]Training epoch 7:  65%|██████▌   | 223/341 [00:04<00:02, 52.89it/s, Epoch: 7, Batch: 224,Loss: -0.963,Avg.Loss: -0.864,LR: 3.75E-04]Training epoch 7:  66%|██████▌   | 224/341 [00:04<00:02, 52.89it/s, Epoch: 7, Batch: 225,Loss: -0.508,Avg.Loss: -0.862,LR: 3.75E-04]Training epoch 7:  66%|██████▌   | 225/341 [00:04<00:02, 52.89it/s, Epoch: 7, Batch: 226,Loss: -1.425,Avg.Loss: -0.864,LR: 3.75E-04]Training epoch 7:  66%|██████▋   | 226/341 [00:04<00:02, 52.89it/s, Epoch: 7, Batch: 227,Loss: -1.360,Avg.Loss: -0.867,LR: 3.75E-04]Training epoch 7:  67%|██████▋   | 227/341 [00:04<00:02, 52.89it/s, Epoch: 7, Batch: 228,Loss: -1.155,Avg.Loss: -0.868,LR: 3.75E-04]Training epoch 7:  67%|██████▋   | 228/341 [00:04<00:02, 52.39it/s, Epoch: 7, Batch: 228,Loss: -1.155,Avg.Loss: -0.868,LR: 3.75E-04]Training epoch 7:  67%|██████▋   | 228/341 [00:04<00:02, 52.39it/s, Epoch: 7, Batch: 229,Loss: -1.360,Avg.Loss: -0.870,LR: 3.75E-04]Training epoch 7:  67%|██████▋   | 229/341 [00:04<00:02, 52.39it/s, Epoch: 7, Batch: 230,Loss: -1.156,Avg.Loss: -0.871,LR: 3.75E-04]Training epoch 7:  67%|██████▋   | 230/341 [00:04<00:02, 52.39it/s, Epoch: 7, Batch: 231,Loss: -1.013,Avg.Loss: -0.872,LR: 3.75E-04]Training epoch 7:  68%|██████▊   | 231/341 [00:04<00:02, 52.39it/s, Epoch: 7, Batch: 232,Loss: -1.282,Avg.Loss: -0.874,LR: 3.75E-04]Training epoch 7:  68%|██████▊   | 232/341 [00:04<00:02, 52.39it/s, Epoch: 7, Batch: 233,Loss: -1.544,Avg.Loss: -0.877,LR: 3.74E-04]Training epoch 7:  68%|██████▊   | 233/341 [00:04<00:02, 52.39it/s, Epoch: 7, Batch: 234,Loss: -0.774,Avg.Loss: -0.876,LR: 3.74E-04]Training epoch 7:  69%|██████▊   | 234/341 [00:04<00:02, 52.34it/s, Epoch: 7, Batch: 234,Loss: -0.774,Avg.Loss: -0.876,LR: 3.74E-04]Training epoch 7:  69%|██████▊   | 234/341 [00:04<00:02, 52.34it/s, Epoch: 7, Batch: 235,Loss: -1.830,Avg.Loss: -0.880,LR: 3.74E-04]Training epoch 7:  69%|██████▉   | 235/341 [00:04<00:02, 52.34it/s, Epoch: 7, Batch: 236,Loss: -1.071,Avg.Loss: -0.881,LR: 3.74E-04]Training epoch 7:  69%|██████▉   | 236/341 [00:04<00:02, 52.34it/s, Epoch: 7, Batch: 237,Loss: -0.901,Avg.Loss: -0.881,LR: 3.74E-04]Training epoch 7:  70%|██████▉   | 237/341 [00:04<00:01, 52.34it/s, Epoch: 7, Batch: 238,Loss: -1.520,Avg.Loss: -0.884,LR: 3.74E-04]Training epoch 7:  70%|██████▉   | 238/341 [00:04<00:01, 52.34it/s, Epoch: 7, Batch: 239,Loss: -1.347,Avg.Loss: -0.886,LR: 3.74E-04]Training epoch 7:  70%|███████   | 239/341 [00:04<00:01, 52.34it/s, Epoch: 7, Batch: 240,Loss: -1.139,Avg.Loss: -0.887,LR: 3.74E-04]Training epoch 7:  70%|███████   | 240/341 [00:04<00:01, 52.41it/s, Epoch: 7, Batch: 240,Loss: -1.139,Avg.Loss: -0.887,LR: 3.74E-04]Training epoch 7:  70%|███████   | 240/341 [00:04<00:01, 52.41it/s, Epoch: 7, Batch: 241,Loss: -1.359,Avg.Loss: -0.889,LR: 3.74E-04]Training epoch 7:  71%|███████   | 241/341 [00:04<00:01, 52.41it/s, Epoch: 7, Batch: 242,Loss: -1.599,Avg.Loss: -0.892,LR: 3.74E-04]Training epoch 7:  71%|███████   | 242/341 [00:04<00:01, 52.41it/s, Epoch: 7, Batch: 243,Loss: -0.756,Avg.Loss: -0.891,LR: 3.73E-04]Training epoch 7:  71%|███████▏  | 243/341 [00:04<00:01, 52.41it/s, Epoch: 7, Batch: 244,Loss: -1.771,Avg.Loss: -0.895,LR: 3.73E-04]Training epoch 7:  72%|███████▏  | 244/341 [00:04<00:01, 52.41it/s, Epoch: 7, Batch: 245,Loss: -1.414,Avg.Loss: -0.897,LR: 3.73E-04]Training epoch 7:  72%|███████▏  | 245/341 [00:04<00:01, 52.41it/s, Epoch: 7, Batch: 246,Loss: -0.942,Avg.Loss: -0.897,LR: 3.73E-04]Training epoch 7:  72%|███████▏  | 246/341 [00:04<00:01, 50.83it/s, Epoch: 7, Batch: 246,Loss: -0.942,Avg.Loss: -0.897,LR: 3.73E-04]Training epoch 7:  72%|███████▏  | 246/341 [00:04<00:01, 50.83it/s, Epoch: 7, Batch: 247,Loss: -1.054,Avg.Loss: -0.898,LR: 3.73E-04]Training epoch 7:  72%|███████▏  | 247/341 [00:04<00:01, 50.83it/s, Epoch: 7, Batch: 248,Loss: -1.235,Avg.Loss: -0.899,LR: 3.73E-04]Training epoch 7:  73%|███████▎  | 248/341 [00:04<00:01, 50.83it/s, Epoch: 7, Batch: 249,Loss: -0.524,Avg.Loss: -0.897,LR: 3.73E-04]Training epoch 7:  73%|███████▎  | 249/341 [00:04<00:01, 50.83it/s, Epoch: 7, Batch: 250,Loss: -1.330,Avg.Loss: -0.899,LR: 3.73E-04]Training epoch 7:  73%|███████▎  | 250/341 [00:04<00:01, 50.83it/s, Epoch: 7, Batch: 251,Loss: -1.560,Avg.Loss: -0.902,LR: 3.73E-04]Training epoch 7:  74%|███████▎  | 251/341 [00:04<00:01, 50.83it/s, Epoch: 7, Batch: 252,Loss: -1.256,Avg.Loss: -0.903,LR: 3.73E-04]Training epoch 7:  74%|███████▍  | 252/341 [00:04<00:01, 51.21it/s, Epoch: 7, Batch: 252,Loss: -1.256,Avg.Loss: -0.903,LR: 3.73E-04]Training epoch 7:  74%|███████▍  | 252/341 [00:04<00:01, 51.21it/s, Epoch: 7, Batch: 253,Loss: -1.598,Avg.Loss: -0.906,LR: 3.72E-04]Training epoch 7:  74%|███████▍  | 253/341 [00:04<00:01, 51.21it/s, Epoch: 7, Batch: 254,Loss: -1.138,Avg.Loss: -0.907,LR: 3.72E-04]Training epoch 7:  74%|███████▍  | 254/341 [00:04<00:01, 51.21it/s, Epoch: 7, Batch: 255,Loss: -0.975,Avg.Loss: -0.907,LR: 3.72E-04]Training epoch 7:  75%|███████▍  | 255/341 [00:04<00:01, 51.21it/s, Epoch: 7, Batch: 256,Loss: -1.461,Avg.Loss: -0.909,LR: 3.72E-04]Training epoch 7:  75%|███████▌  | 256/341 [00:04<00:01, 51.21it/s, Epoch: 7, Batch: 257,Loss: -1.171,Avg.Loss: -0.910,LR: 3.72E-04]Training epoch 7:  75%|███████▌  | 257/341 [00:04<00:01, 51.21it/s, Epoch: 7, Batch: 258,Loss: -1.217,Avg.Loss: -0.912,LR: 3.72E-04]Training epoch 7:  76%|███████▌  | 258/341 [00:04<00:01, 51.81it/s, Epoch: 7, Batch: 258,Loss: -1.217,Avg.Loss: -0.912,LR: 3.72E-04]Training epoch 7:  76%|███████▌  | 258/341 [00:04<00:01, 51.81it/s, Epoch: 7, Batch: 259,Loss: -1.251,Avg.Loss: -0.913,LR: 3.72E-04]Training epoch 7:  76%|███████▌  | 259/341 [00:05<00:01, 51.81it/s, Epoch: 7, Batch: 260,Loss: -1.337,Avg.Loss: -0.914,LR: 3.72E-04]Training epoch 7:  76%|███████▌  | 260/341 [00:05<00:01, 51.81it/s, Epoch: 7, Batch: 261,Loss: -1.049,Avg.Loss: -0.915,LR: 3.72E-04]Training epoch 7:  77%|███████▋  | 261/341 [00:05<00:01, 51.81it/s, Epoch: 7, Batch: 262,Loss: -0.967,Avg.Loss: -0.915,LR: 3.72E-04]Training epoch 7:  77%|███████▋  | 262/341 [00:05<00:01, 51.81it/s, Epoch: 7, Batch: 263,Loss: -1.383,Avg.Loss: -0.917,LR: 3.71E-04]Training epoch 7:  77%|███████▋  | 263/341 [00:05<00:01, 51.81it/s, Epoch: 7, Batch: 264,Loss: -1.261,Avg.Loss: -0.918,LR: 3.71E-04]Training epoch 7:  77%|███████▋  | 264/341 [00:05<00:01, 51.89it/s, Epoch: 7, Batch: 264,Loss: -1.261,Avg.Loss: -0.918,LR: 3.71E-04]Training epoch 7:  77%|███████▋  | 264/341 [00:05<00:01, 51.89it/s, Epoch: 7, Batch: 265,Loss: -1.443,Avg.Loss: -0.920,LR: 3.71E-04]Training epoch 7:  78%|███████▊  | 265/341 [00:05<00:01, 51.89it/s, Epoch: 7, Batch: 266,Loss: -1.232,Avg.Loss: -0.921,LR: 3.71E-04]Training epoch 7:  78%|███████▊  | 266/341 [00:05<00:01, 51.89it/s, Epoch: 7, Batch: 267,Loss: -0.753,Avg.Loss: -0.921,LR: 3.71E-04]Training epoch 7:  78%|███████▊  | 267/341 [00:05<00:01, 51.89it/s, Epoch: 7, Batch: 268,Loss: -1.702,Avg.Loss: -0.924,LR: 3.71E-04]Training epoch 7:  79%|███████▊  | 268/341 [00:05<00:01, 51.89it/s, Epoch: 7, Batch: 269,Loss: -0.667,Avg.Loss: -0.923,LR: 3.71E-04]Training epoch 7:  79%|███████▉  | 269/341 [00:05<00:01, 51.89it/s, Epoch: 7, Batch: 270,Loss: -0.327,Avg.Loss: -0.921,LR: 3.71E-04]Training epoch 7:  79%|███████▉  | 270/341 [00:05<00:01, 51.90it/s, Epoch: 7, Batch: 270,Loss: -0.327,Avg.Loss: -0.921,LR: 3.71E-04]Training epoch 7:  79%|███████▉  | 270/341 [00:05<00:01, 51.90it/s, Epoch: 7, Batch: 271,Loss: -1.068,Avg.Loss: -0.921,LR: 3.71E-04]Training epoch 7:  79%|███████▉  | 271/341 [00:05<00:01, 51.90it/s, Epoch: 7, Batch: 272,Loss: -1.769,Avg.Loss: -0.924,LR: 3.71E-04]Training epoch 7:  80%|███████▉  | 272/341 [00:05<00:01, 51.90it/s, Epoch: 7, Batch: 273,Loss: -1.456,Avg.Loss: -0.926,LR: 3.70E-04]Training epoch 7:  80%|████████  | 273/341 [00:05<00:01, 51.90it/s, Epoch: 7, Batch: 274,Loss: -1.545,Avg.Loss: -0.928,LR: 3.70E-04]Training epoch 7:  80%|████████  | 274/341 [00:05<00:01, 51.90it/s, Epoch: 7, Batch: 275,Loss: -1.247,Avg.Loss: -0.930,LR: 3.70E-04]Training epoch 7:  81%|████████  | 275/341 [00:05<00:01, 51.90it/s, Epoch: 7, Batch: 276,Loss: -0.718,Avg.Loss: -0.929,LR: 3.70E-04]Training epoch 7:  81%|████████  | 276/341 [00:05<00:01, 52.09it/s, Epoch: 7, Batch: 276,Loss: -0.718,Avg.Loss: -0.929,LR: 3.70E-04]Training epoch 7:  81%|████████  | 276/341 [00:05<00:01, 52.09it/s, Epoch: 7, Batch: 277,Loss: -1.209,Avg.Loss: -0.930,LR: 3.70E-04]Training epoch 7:  81%|████████  | 277/341 [00:05<00:01, 52.09it/s, Epoch: 7, Batch: 278,Loss: -1.329,Avg.Loss: -0.931,LR: 3.70E-04]Training epoch 7:  82%|████████▏ | 278/341 [00:05<00:01, 52.09it/s, Epoch: 7, Batch: 279,Loss: -1.019,Avg.Loss: -0.932,LR: 3.70E-04]Training epoch 7:  82%|████████▏ | 279/341 [00:05<00:01, 52.09it/s, Epoch: 7, Batch: 280,Loss: -1.637,Avg.Loss: -0.934,LR: 3.70E-04]Training epoch 7:  82%|████████▏ | 280/341 [00:05<00:01, 52.09it/s, Epoch: 7, Batch: 281,Loss: -0.891,Avg.Loss: -0.934,LR: 3.70E-04]Training epoch 7:  82%|████████▏ | 281/341 [00:05<00:01, 52.09it/s, Epoch: 7, Batch: 282,Loss: -0.880,Avg.Loss: -0.934,LR: 3.70E-04]Training epoch 7:  83%|████████▎ | 282/341 [00:05<00:01, 52.51it/s, Epoch: 7, Batch: 282,Loss: -0.880,Avg.Loss: -0.934,LR: 3.70E-04]Training epoch 7:  83%|████████▎ | 282/341 [00:05<00:01, 52.51it/s, Epoch: 7, Batch: 283,Loss: -1.429,Avg.Loss: -0.935,LR: 3.69E-04]Training epoch 7:  83%|████████▎ | 283/341 [00:05<00:01, 52.51it/s, Epoch: 7, Batch: 284,Loss: -1.443,Avg.Loss: -0.937,LR: 3.69E-04]Training epoch 7:  83%|████████▎ | 284/341 [00:05<00:01, 52.51it/s, Epoch: 7, Batch: 285,Loss: -1.034,Avg.Loss: -0.938,LR: 3.69E-04]Training epoch 7:  84%|████████▎ | 285/341 [00:05<00:01, 52.51it/s, Epoch: 7, Batch: 286,Loss: -1.547,Avg.Loss: -0.940,LR: 3.69E-04]Training epoch 7:  84%|████████▍ | 286/341 [00:05<00:01, 52.51it/s, Epoch: 7, Batch: 287,Loss: -1.394,Avg.Loss: -0.941,LR: 3.69E-04]Training epoch 7:  84%|████████▍ | 287/341 [00:05<00:01, 52.51it/s, Epoch: 7, Batch: 288,Loss: -0.878,Avg.Loss: -0.941,LR: 3.69E-04]Training epoch 7:  84%|████████▍ | 288/341 [00:05<00:01, 52.48it/s, Epoch: 7, Batch: 288,Loss: -0.878,Avg.Loss: -0.941,LR: 3.69E-04]Training epoch 7:  84%|████████▍ | 288/341 [00:05<00:01, 52.48it/s, Epoch: 7, Batch: 289,Loss: -1.513,Avg.Loss: -0.943,LR: 3.69E-04]Training epoch 7:  85%|████████▍ | 289/341 [00:05<00:00, 52.48it/s, Epoch: 7, Batch: 290,Loss: -1.393,Avg.Loss: -0.945,LR: 3.69E-04]Training epoch 7:  85%|████████▌ | 290/341 [00:05<00:00, 52.48it/s, Epoch: 7, Batch: 291,Loss: -0.920,Avg.Loss: -0.945,LR: 3.69E-04]Training epoch 7:  85%|████████▌ | 291/341 [00:05<00:00, 52.48it/s, Epoch: 7, Batch: 292,Loss: -1.534,Avg.Loss: -0.947,LR: 3.68E-04]Training epoch 7:  86%|████████▌ | 292/341 [00:05<00:00, 52.48it/s, Epoch: 7, Batch: 293,Loss: -1.258,Avg.Loss: -0.948,LR: 3.68E-04]Training epoch 7:  86%|████████▌ | 293/341 [00:05<00:00, 52.48it/s, Epoch: 7, Batch: 294,Loss: -1.227,Avg.Loss: -0.949,LR: 3.68E-04]Training epoch 7:  86%|████████▌ | 294/341 [00:05<00:00, 52.81it/s, Epoch: 7, Batch: 294,Loss: -1.227,Avg.Loss: -0.949,LR: 3.68E-04]Training epoch 7:  86%|████████▌ | 294/341 [00:05<00:00, 52.81it/s, Epoch: 7, Batch: 295,Loss: -1.644,Avg.Loss: -0.951,LR: 3.68E-04]Training epoch 7:  87%|████████▋ | 295/341 [00:05<00:00, 52.81it/s, Epoch: 7, Batch: 296,Loss: -1.362,Avg.Loss: -0.952,LR: 3.68E-04]Training epoch 7:  87%|████████▋ | 296/341 [00:05<00:00, 52.81it/s, Epoch: 7, Batch: 297,Loss: -0.848,Avg.Loss: -0.952,LR: 3.68E-04]Training epoch 7:  87%|████████▋ | 297/341 [00:05<00:00, 52.81it/s, Epoch: 7, Batch: 298,Loss: -1.313,Avg.Loss: -0.953,LR: 3.68E-04]Training epoch 7:  87%|████████▋ | 298/341 [00:05<00:00, 52.81it/s, Epoch: 7, Batch: 299,Loss: -1.380,Avg.Loss: -0.955,LR: 3.68E-04]Training epoch 7:  88%|████████▊ | 299/341 [00:05<00:00, 52.81it/s, Epoch: 7, Batch: 300,Loss: -1.315,Avg.Loss: -0.956,LR: 3.68E-04]Training epoch 7:  88%|████████▊ | 300/341 [00:05<00:00, 52.88it/s, Epoch: 7, Batch: 300,Loss: -1.315,Avg.Loss: -0.956,LR: 3.68E-04]Training epoch 7:  88%|████████▊ | 300/341 [00:05<00:00, 52.88it/s, Epoch: 7, Batch: 301,Loss: -1.582,Avg.Loss: -0.958,LR: 3.68E-04]Training epoch 7:  88%|████████▊ | 301/341 [00:05<00:00, 52.88it/s, Epoch: 7, Batch: 302,Loss: -1.290,Avg.Loss: -0.959,LR: 3.67E-04]Training epoch 7:  89%|████████▊ | 302/341 [00:05<00:00, 52.88it/s, Epoch: 7, Batch: 303,Loss: -1.224,Avg.Loss: -0.960,LR: 3.67E-04]Training epoch 7:  89%|████████▉ | 303/341 [00:05<00:00, 52.88it/s, Epoch: 7, Batch: 304,Loss: -1.763,Avg.Loss: -0.963,LR: 3.67E-04]Training epoch 7:  89%|████████▉ | 304/341 [00:05<00:00, 52.88it/s, Epoch: 7, Batch: 305,Loss: -1.137,Avg.Loss: -0.963,LR: 3.67E-04]Training epoch 7:  89%|████████▉ | 305/341 [00:05<00:00, 52.88it/s, Epoch: 7, Batch: 306,Loss: -0.613,Avg.Loss: -0.962,LR: 3.67E-04]Training epoch 7:  90%|████████▉ | 306/341 [00:05<00:00, 53.10it/s, Epoch: 7, Batch: 306,Loss: -0.613,Avg.Loss: -0.962,LR: 3.67E-04]Training epoch 7:  90%|████████▉ | 306/341 [00:05<00:00, 53.10it/s, Epoch: 7, Batch: 307,Loss: -1.510,Avg.Loss: -0.964,LR: 3.67E-04]Training epoch 7:  90%|█████████ | 307/341 [00:05<00:00, 53.10it/s, Epoch: 7, Batch: 308,Loss: -1.528,Avg.Loss: -0.966,LR: 3.67E-04]Training epoch 7:  90%|█████████ | 308/341 [00:05<00:00, 53.10it/s, Epoch: 7, Batch: 309,Loss: -1.196,Avg.Loss: -0.966,LR: 3.67E-04]Training epoch 7:  91%|█████████ | 309/341 [00:05<00:00, 53.10it/s, Epoch: 7, Batch: 310,Loss: -1.674,Avg.Loss: -0.969,LR: 3.67E-04]Training epoch 7:  91%|█████████ | 310/341 [00:05<00:00, 53.10it/s, Epoch: 7, Batch: 311,Loss: -1.382,Avg.Loss: -0.970,LR: 3.67E-04]Training epoch 7:  91%|█████████ | 311/341 [00:05<00:00, 53.10it/s, Epoch: 7, Batch: 312,Loss: -1.195,Avg.Loss: -0.971,LR: 3.66E-04]Training epoch 7:  91%|█████████▏| 312/341 [00:05<00:00, 53.49it/s, Epoch: 7, Batch: 312,Loss: -1.195,Avg.Loss: -0.971,LR: 3.66E-04]Training epoch 7:  91%|█████████▏| 312/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 313,Loss: -1.818,Avg.Loss: -0.973,LR: 3.66E-04]Training epoch 7:  92%|█████████▏| 313/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 314,Loss: -1.337,Avg.Loss: -0.975,LR: 3.66E-04]Training epoch 7:  92%|█████████▏| 314/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 315,Loss: -0.993,Avg.Loss: -0.975,LR: 3.66E-04]Training epoch 7:  92%|█████████▏| 315/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 316,Loss: -1.419,Avg.Loss: -0.976,LR: 3.66E-04]Training epoch 7:  93%|█████████▎| 316/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 317,Loss: -1.629,Avg.Loss: -0.978,LR: 3.66E-04]Training epoch 7:  93%|█████████▎| 317/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 318,Loss: -0.939,Avg.Loss: -0.978,LR: 3.66E-04]Training epoch 7:  93%|█████████▎| 318/341 [00:06<00:00, 53.70it/s, Epoch: 7, Batch: 318,Loss: -0.939,Avg.Loss: -0.978,LR: 3.66E-04]Training epoch 7:  93%|█████████▎| 318/341 [00:06<00:00, 53.70it/s, Epoch: 7, Batch: 319,Loss: -1.459,Avg.Loss: -0.979,LR: 3.66E-04]Training epoch 7:  94%|█████████▎| 319/341 [00:06<00:00, 53.70it/s, Epoch: 7, Batch: 320,Loss: -1.375,Avg.Loss: -0.981,LR: 3.66E-04]Training epoch 7:  94%|█████████▍| 320/341 [00:06<00:00, 53.70it/s, Epoch: 7, Batch: 321,Loss: -0.954,Avg.Loss: -0.981,LR: 3.66E-04]Training epoch 7:  94%|█████████▍| 321/341 [00:06<00:00, 53.70it/s, Epoch: 7, Batch: 322,Loss: -1.704,Avg.Loss: -0.983,LR: 3.65E-04]Training epoch 7:  94%|█████████▍| 322/341 [00:06<00:00, 53.70it/s, Epoch: 7, Batch: 323,Loss: -1.667,Avg.Loss: -0.985,LR: 3.65E-04]Training epoch 7:  95%|█████████▍| 323/341 [00:06<00:00, 53.70it/s, Epoch: 7, Batch: 324,Loss: -0.951,Avg.Loss: -0.985,LR: 3.65E-04]Training epoch 7:  95%|█████████▌| 324/341 [00:06<00:00, 54.22it/s, Epoch: 7, Batch: 324,Loss: -0.951,Avg.Loss: -0.985,LR: 3.65E-04]Training epoch 7:  95%|█████████▌| 324/341 [00:06<00:00, 54.22it/s, Epoch: 7, Batch: 325,Loss: -1.676,Avg.Loss: -0.987,LR: 3.65E-04]Training epoch 7:  95%|█████████▌| 325/341 [00:06<00:00, 54.22it/s, Epoch: 7, Batch: 326,Loss: -1.039,Avg.Loss: -0.987,LR: 3.65E-04]Training epoch 7:  96%|█████████▌| 326/341 [00:06<00:00, 54.22it/s, Epoch: 7, Batch: 327,Loss: -0.806,Avg.Loss: -0.987,LR: 3.65E-04]Training epoch 7:  96%|█████████▌| 327/341 [00:06<00:00, 54.22it/s, Epoch: 7, Batch: 328,Loss: -1.640,Avg.Loss: -0.989,LR: 3.65E-04]Training epoch 7:  96%|█████████▌| 328/341 [00:06<00:00, 54.22it/s, Epoch: 7, Batch: 329,Loss: -1.577,Avg.Loss: -0.990,LR: 3.65E-04]Training epoch 7:  96%|█████████▋| 329/341 [00:06<00:00, 54.22it/s, Epoch: 7, Batch: 330,Loss: -0.829,Avg.Loss: -0.990,LR: 3.65E-04]Training epoch 7:  97%|█████████▋| 330/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 330,Loss: -0.829,Avg.Loss: -0.990,LR: 3.65E-04]Training epoch 7:  97%|█████████▋| 330/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 331,Loss: -1.124,Avg.Loss: -0.990,LR: 3.65E-04]Training epoch 7:  97%|█████████▋| 331/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 332,Loss: -1.341,Avg.Loss: -0.991,LR: 3.64E-04]Training epoch 7:  97%|█████████▋| 332/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 333,Loss: -1.365,Avg.Loss: -0.992,LR: 3.64E-04]Training epoch 7:  98%|█████████▊| 333/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 334,Loss: -1.644,Avg.Loss: -0.994,LR: 3.64E-04]Training epoch 7:  98%|█████████▊| 334/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 335,Loss: -1.604,Avg.Loss: -0.996,LR: 3.64E-04]Training epoch 7:  98%|█████████▊| 335/341 [00:06<00:00, 53.49it/s, Epoch: 7, Batch: 336,Loss: -1.318,Avg.Loss: -0.997,LR: 3.64E-04]Training epoch 7:  99%|█████████▊| 336/341 [00:06<00:00, 53.67it/s, Epoch: 7, Batch: 336,Loss: -1.318,Avg.Loss: -0.997,LR: 3.64E-04]Training epoch 7:  99%|█████████▊| 336/341 [00:06<00:00, 53.67it/s, Epoch: 7, Batch: 337,Loss: -1.448,Avg.Loss: -0.999,LR: 3.64E-04]Training epoch 7:  99%|█████████▉| 337/341 [00:06<00:00, 53.67it/s, Epoch: 7, Batch: 338,Loss: -1.435,Avg.Loss: -1.000,LR: 3.64E-04]Training epoch 7:  99%|█████████▉| 338/341 [00:06<00:00, 53.67it/s, Epoch: 7, Batch: 339,Loss: -0.962,Avg.Loss: -1.000,LR: 3.64E-04]Training epoch 7:  99%|█████████▉| 339/341 [00:06<00:00, 53.67it/s, Epoch: 7, Batch: 340,Loss: -1.462,Avg.Loss: -1.001,LR: 3.64E-04]Training epoch 7: 100%|█████████▉| 340/341 [00:06<00:00, 53.67it/s, Epoch: 7, Batch: 341,Loss: -1.776,Avg.Loss: -1.003,LR: 3.63E-04]Training epoch 7: 100%|██████████| 341/341 [00:06<00:00, 52.19it/s, Epoch: 7, Batch: 341,Loss: -1.776,Avg.Loss: -1.003,LR: 3.63E-04]
Training epoch 8:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 8:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 8, Batch: 1,Loss: -1.194,Avg.Loss: -1.194,LR: 3.63E-04]Training epoch 8:   0%|          | 1/341 [00:00<00:12, 27.22it/s, Epoch: 8, Batch: 2,Loss: -1.280,Avg.Loss: -1.237,LR: 3.63E-04]Training epoch 8:   1%|          | 2/341 [00:00<00:08, 39.48it/s, Epoch: 8, Batch: 3,Loss: -1.179,Avg.Loss: -1.218,LR: 3.63E-04]Training epoch 8:   1%|          | 3/341 [00:00<00:07, 44.18it/s, Epoch: 8, Batch: 4,Loss: -1.316,Avg.Loss: -1.242,LR: 3.63E-04]Training epoch 8:   1%|          | 4/341 [00:00<00:07, 46.23it/s, Epoch: 8, Batch: 5,Loss: -1.918,Avg.Loss: -1.377,LR: 3.63E-04]Training epoch 8:   1%|▏         | 5/341 [00:00<00:07, 47.86it/s, Epoch: 8, Batch: 6,Loss: -1.206,Avg.Loss: -1.349,LR: 3.63E-04]Training epoch 8:   2%|▏         | 6/341 [00:00<00:05, 57.32it/s, Epoch: 8, Batch: 6,Loss: -1.206,Avg.Loss: -1.349,LR: 3.63E-04]Training epoch 8:   2%|▏         | 6/341 [00:00<00:05, 57.32it/s, Epoch: 8, Batch: 7,Loss: -0.914,Avg.Loss: -1.287,LR: 3.63E-04]Training epoch 8:   2%|▏         | 7/341 [00:00<00:05, 57.32it/s, Epoch: 8, Batch: 8,Loss: -1.316,Avg.Loss: -1.291,LR: 3.63E-04]Training epoch 8:   2%|▏         | 8/341 [00:00<00:05, 57.32it/s, Epoch: 8, Batch: 9,Loss: -1.360,Avg.Loss: -1.298,LR: 3.63E-04]Training epoch 8:   3%|▎         | 9/341 [00:00<00:05, 57.32it/s, Epoch: 8, Batch: 10,Loss: -0.842,Avg.Loss: -1.253,LR: 3.62E-04]Training epoch 8:   3%|▎         | 10/341 [00:00<00:05, 57.32it/s, Epoch: 8, Batch: 11,Loss: -1.533,Avg.Loss: -1.278,LR: 3.62E-04]Training epoch 8:   3%|▎         | 11/341 [00:00<00:05, 57.32it/s, Epoch: 8, Batch: 12,Loss: -1.300,Avg.Loss: -1.280,LR: 3.62E-04]Training epoch 8:   4%|▎         | 12/341 [00:00<00:05, 55.16it/s, Epoch: 8, Batch: 12,Loss: -1.300,Avg.Loss: -1.280,LR: 3.62E-04]Training epoch 8:   4%|▎         | 12/341 [00:00<00:05, 55.16it/s, Epoch: 8, Batch: 13,Loss: -0.742,Avg.Loss: -1.239,LR: 3.62E-04]Training epoch 8:   4%|▍         | 13/341 [00:00<00:05, 55.16it/s, Epoch: 8, Batch: 14,Loss: -1.510,Avg.Loss: -1.258,LR: 3.62E-04]Training epoch 8:   4%|▍         | 14/341 [00:00<00:05, 55.16it/s, Epoch: 8, Batch: 15,Loss: -1.394,Avg.Loss: -1.267,LR: 3.62E-04]Training epoch 8:   4%|▍         | 15/341 [00:00<00:05, 55.16it/s, Epoch: 8, Batch: 16,Loss: -1.208,Avg.Loss: -1.263,LR: 3.62E-04]Training epoch 8:   5%|▍         | 16/341 [00:00<00:05, 55.16it/s, Epoch: 8, Batch: 17,Loss: -1.647,Avg.Loss: -1.286,LR: 3.62E-04]Training epoch 8:   5%|▍         | 17/341 [00:00<00:05, 55.16it/s, Epoch: 8, Batch: 18,Loss: -1.517,Avg.Loss: -1.299,LR: 3.62E-04]Training epoch 8:   5%|▌         | 18/341 [00:00<00:05, 55.24it/s, Epoch: 8, Batch: 18,Loss: -1.517,Avg.Loss: -1.299,LR: 3.62E-04]Training epoch 8:   5%|▌         | 18/341 [00:00<00:05, 55.24it/s, Epoch: 8, Batch: 19,Loss: -0.979,Avg.Loss: -1.282,LR: 3.62E-04]Training epoch 8:   6%|▌         | 19/341 [00:00<00:05, 55.24it/s, Epoch: 8, Batch: 20,Loss: -1.452,Avg.Loss: -1.290,LR: 3.61E-04]Training epoch 8:   6%|▌         | 20/341 [00:00<00:05, 55.24it/s, Epoch: 8, Batch: 21,Loss: -1.461,Avg.Loss: -1.298,LR: 3.61E-04]Training epoch 8:   6%|▌         | 21/341 [00:00<00:05, 55.24it/s, Epoch: 8, Batch: 22,Loss: -1.376,Avg.Loss: -1.302,LR: 3.61E-04]Training epoch 8:   6%|▋         | 22/341 [00:00<00:05, 55.24it/s, Epoch: 8, Batch: 23,Loss: -1.720,Avg.Loss: -1.320,LR: 3.61E-04]Training epoch 8:   7%|▋         | 23/341 [00:00<00:05, 55.24it/s, Epoch: 8, Batch: 24,Loss: -1.351,Avg.Loss: -1.321,LR: 3.61E-04]Training epoch 8:   7%|▋         | 24/341 [00:00<00:05, 54.63it/s, Epoch: 8, Batch: 24,Loss: -1.351,Avg.Loss: -1.321,LR: 3.61E-04]Training epoch 8:   7%|▋         | 24/341 [00:00<00:05, 54.63it/s, Epoch: 8, Batch: 25,Loss: -1.059,Avg.Loss: -1.311,LR: 3.61E-04]Training epoch 8:   7%|▋         | 25/341 [00:00<00:05, 54.63it/s, Epoch: 8, Batch: 26,Loss: -1.607,Avg.Loss: -1.322,LR: 3.61E-04]Training epoch 8:   8%|▊         | 26/341 [00:00<00:05, 54.63it/s, Epoch: 8, Batch: 27,Loss: -1.656,Avg.Loss: -1.335,LR: 3.61E-04]Training epoch 8:   8%|▊         | 27/341 [00:00<00:05, 54.63it/s, Epoch: 8, Batch: 28,Loss: -1.419,Avg.Loss: -1.338,LR: 3.61E-04]Training epoch 8:   8%|▊         | 28/341 [00:00<00:05, 54.63it/s, Epoch: 8, Batch: 29,Loss: -1.930,Avg.Loss: -1.358,LR: 3.61E-04]Training epoch 8:   9%|▊         | 29/341 [00:00<00:05, 54.63it/s, Epoch: 8, Batch: 30,Loss: -0.987,Avg.Loss: -1.346,LR: 3.60E-04]Training epoch 8:   9%|▉         | 30/341 [00:00<00:05, 52.73it/s, Epoch: 8, Batch: 30,Loss: -0.987,Avg.Loss: -1.346,LR: 3.60E-04]Training epoch 8:   9%|▉         | 30/341 [00:00<00:05, 52.73it/s, Epoch: 8, Batch: 31,Loss: -1.008,Avg.Loss: -1.335,LR: 3.60E-04]Training epoch 8:   9%|▉         | 31/341 [00:00<00:05, 52.73it/s, Epoch: 8, Batch: 32,Loss: -1.144,Avg.Loss: -1.329,LR: 3.60E-04]Training epoch 8:   9%|▉         | 32/341 [00:00<00:05, 52.73it/s, Epoch: 8, Batch: 33,Loss: -1.457,Avg.Loss: -1.333,LR: 3.60E-04]Training epoch 8:  10%|▉         | 33/341 [00:00<00:05, 52.73it/s, Epoch: 8, Batch: 34,Loss: -1.019,Avg.Loss: -1.324,LR: 3.60E-04]Training epoch 8:  10%|▉         | 34/341 [00:00<00:05, 52.73it/s, Epoch: 8, Batch: 35,Loss: -1.760,Avg.Loss: -1.336,LR: 3.60E-04]Training epoch 8:  10%|█         | 35/341 [00:00<00:05, 52.73it/s, Epoch: 8, Batch: 36,Loss: -1.160,Avg.Loss: -1.331,LR: 3.60E-04]Training epoch 8:  11%|█         | 36/341 [00:00<00:05, 53.60it/s, Epoch: 8, Batch: 36,Loss: -1.160,Avg.Loss: -1.331,LR: 3.60E-04]Training epoch 8:  11%|█         | 36/341 [00:00<00:05, 53.60it/s, Epoch: 8, Batch: 37,Loss: -1.078,Avg.Loss: -1.324,LR: 3.60E-04]Training epoch 8:  11%|█         | 37/341 [00:00<00:05, 53.60it/s, Epoch: 8, Batch: 38,Loss: -1.149,Avg.Loss: -1.320,LR: 3.60E-04]Training epoch 8:  11%|█         | 38/341 [00:00<00:05, 53.60it/s, Epoch: 8, Batch: 39,Loss: -1.712,Avg.Loss: -1.330,LR: 3.59E-04]Training epoch 8:  11%|█▏        | 39/341 [00:00<00:05, 53.60it/s, Epoch: 8, Batch: 40,Loss: -1.349,Avg.Loss: -1.330,LR: 3.59E-04]Training epoch 8:  12%|█▏        | 40/341 [00:00<00:05, 53.60it/s, Epoch: 8, Batch: 41,Loss: -1.718,Avg.Loss: -1.340,LR: 3.59E-04]Training epoch 8:  12%|█▏        | 41/341 [00:00<00:05, 53.60it/s, Epoch: 8, Batch: 42,Loss: -1.272,Avg.Loss: -1.338,LR: 3.59E-04]Training epoch 8:  12%|█▏        | 42/341 [00:00<00:05, 53.56it/s, Epoch: 8, Batch: 42,Loss: -1.272,Avg.Loss: -1.338,LR: 3.59E-04]Training epoch 8:  12%|█▏        | 42/341 [00:00<00:05, 53.56it/s, Epoch: 8, Batch: 43,Loss: -0.999,Avg.Loss: -1.330,LR: 3.59E-04]Training epoch 8:  13%|█▎        | 43/341 [00:00<00:05, 53.56it/s, Epoch: 8, Batch: 44,Loss: -1.617,Avg.Loss: -1.337,LR: 3.59E-04]Training epoch 8:  13%|█▎        | 44/341 [00:00<00:05, 53.56it/s, Epoch: 8, Batch: 45,Loss: -1.150,Avg.Loss: -1.333,LR: 3.59E-04]Training epoch 8:  13%|█▎        | 45/341 [00:00<00:05, 53.56it/s, Epoch: 8, Batch: 46,Loss: -0.844,Avg.Loss: -1.322,LR: 3.59E-04]Training epoch 8:  13%|█▎        | 46/341 [00:00<00:05, 53.56it/s, Epoch: 8, Batch: 47,Loss: -1.414,Avg.Loss: -1.324,LR: 3.59E-04]Training epoch 8:  14%|█▍        | 47/341 [00:00<00:05, 53.56it/s, Epoch: 8, Batch: 48,Loss: -1.801,Avg.Loss: -1.334,LR: 3.59E-04]Training epoch 8:  14%|█▍        | 48/341 [00:00<00:05, 54.56it/s, Epoch: 8, Batch: 48,Loss: -1.801,Avg.Loss: -1.334,LR: 3.59E-04]Training epoch 8:  14%|█▍        | 48/341 [00:00<00:05, 54.56it/s, Epoch: 8, Batch: 49,Loss: -1.351,Avg.Loss: -1.334,LR: 3.58E-04]Training epoch 8:  14%|█▍        | 49/341 [00:00<00:05, 54.56it/s, Epoch: 8, Batch: 50,Loss: -1.510,Avg.Loss: -1.338,LR: 3.58E-04]Training epoch 8:  15%|█▍        | 50/341 [00:00<00:05, 54.56it/s, Epoch: 8, Batch: 51,Loss: -1.430,Avg.Loss: -1.340,LR: 3.58E-04]Training epoch 8:  15%|█▍        | 51/341 [00:00<00:05, 54.56it/s, Epoch: 8, Batch: 52,Loss: -0.725,Avg.Loss: -1.328,LR: 3.58E-04]Training epoch 8:  15%|█▌        | 52/341 [00:00<00:05, 54.56it/s, Epoch: 8, Batch: 53,Loss: -1.102,Avg.Loss: -1.323,LR: 3.58E-04]Training epoch 8:  16%|█▌        | 53/341 [00:00<00:05, 54.56it/s, Epoch: 8, Batch: 54,Loss: -1.783,Avg.Loss: -1.332,LR: 3.58E-04]Training epoch 8:  16%|█▌        | 54/341 [00:00<00:05, 54.63it/s, Epoch: 8, Batch: 54,Loss: -1.783,Avg.Loss: -1.332,LR: 3.58E-04]Training epoch 8:  16%|█▌        | 54/341 [00:01<00:05, 54.63it/s, Epoch: 8, Batch: 55,Loss: -1.329,Avg.Loss: -1.332,LR: 3.58E-04]Training epoch 8:  16%|█▌        | 55/341 [00:01<00:05, 54.63it/s, Epoch: 8, Batch: 56,Loss: -1.445,Avg.Loss: -1.334,LR: 3.58E-04]Training epoch 8:  16%|█▋        | 56/341 [00:01<00:05, 54.63it/s, Epoch: 8, Batch: 57,Loss: -1.488,Avg.Loss: -1.337,LR: 3.58E-04]Training epoch 8:  17%|█▋        | 57/341 [00:01<00:05, 54.63it/s, Epoch: 8, Batch: 58,Loss: -1.634,Avg.Loss: -1.342,LR: 3.58E-04]Training epoch 8:  17%|█▋        | 58/341 [00:01<00:05, 54.63it/s, Epoch: 8, Batch: 59,Loss: -1.891,Avg.Loss: -1.351,LR: 3.57E-04]Training epoch 8:  17%|█▋        | 59/341 [00:01<00:05, 54.63it/s, Epoch: 8, Batch: 60,Loss: -0.957,Avg.Loss: -1.344,LR: 3.57E-04]Training epoch 8:  18%|█▊        | 60/341 [00:01<00:05, 55.07it/s, Epoch: 8, Batch: 60,Loss: -0.957,Avg.Loss: -1.344,LR: 3.57E-04]Training epoch 8:  18%|█▊        | 60/341 [00:01<00:05, 55.07it/s, Epoch: 8, Batch: 61,Loss: -0.099,Avg.Loss: -1.324,LR: 3.57E-04]Training epoch 8:  18%|█▊        | 61/341 [00:01<00:05, 55.07it/s, Epoch: 8, Batch: 62,Loss: -1.160,Avg.Loss: -1.321,LR: 3.57E-04]Training epoch 8:  18%|█▊        | 62/341 [00:01<00:05, 55.07it/s, Epoch: 8, Batch: 63,Loss: -0.879,Avg.Loss: -1.314,LR: 3.57E-04]Training epoch 8:  18%|█▊        | 63/341 [00:01<00:05, 55.07it/s, Epoch: 8, Batch: 64,Loss: -1.372,Avg.Loss: -1.315,LR: 3.57E-04]Training epoch 8:  19%|█▉        | 64/341 [00:01<00:05, 55.07it/s, Epoch: 8, Batch: 65,Loss: -1.671,Avg.Loss: -1.321,LR: 3.57E-04]Training epoch 8:  19%|█▉        | 65/341 [00:01<00:05, 55.07it/s, Epoch: 8, Batch: 66,Loss: -1.326,Avg.Loss: -1.321,LR: 3.57E-04]Training epoch 8:  19%|█▉        | 66/341 [00:01<00:04, 55.26it/s, Epoch: 8, Batch: 66,Loss: -1.326,Avg.Loss: -1.321,LR: 3.57E-04]Training epoch 8:  19%|█▉        | 66/341 [00:01<00:04, 55.26it/s, Epoch: 8, Batch: 67,Loss: -0.417,Avg.Loss: -1.307,LR: 3.57E-04]Training epoch 8:  20%|█▉        | 67/341 [00:01<00:04, 55.26it/s, Epoch: 8, Batch: 68,Loss: -1.154,Avg.Loss: -1.305,LR: 3.56E-04]Training epoch 8:  20%|█▉        | 68/341 [00:01<00:04, 55.26it/s, Epoch: 8, Batch: 69,Loss: -1.178,Avg.Loss: -1.303,LR: 3.56E-04]Training epoch 8:  20%|██        | 69/341 [00:01<00:04, 55.26it/s, Epoch: 8, Batch: 70,Loss: -0.588,Avg.Loss: -1.293,LR: 3.56E-04]Training epoch 8:  21%|██        | 70/341 [00:01<00:04, 55.26it/s, Epoch: 8, Batch: 71,Loss: -1.549,Avg.Loss: -1.297,LR: 3.56E-04]Training epoch 8:  21%|██        | 71/341 [00:01<00:04, 55.26it/s, Epoch: 8, Batch: 72,Loss: -1.648,Avg.Loss: -1.302,LR: 3.56E-04]Training epoch 8:  21%|██        | 72/341 [00:01<00:04, 55.41it/s, Epoch: 8, Batch: 72,Loss: -1.648,Avg.Loss: -1.302,LR: 3.56E-04]Training epoch 8:  21%|██        | 72/341 [00:01<00:04, 55.41it/s, Epoch: 8, Batch: 73,Loss: -1.110,Avg.Loss: -1.299,LR: 3.56E-04]Training epoch 8:  21%|██▏       | 73/341 [00:01<00:04, 55.41it/s, Epoch: 8, Batch: 74,Loss: -1.385,Avg.Loss: -1.300,LR: 3.56E-04]Training epoch 8:  22%|██▏       | 74/341 [00:01<00:04, 55.41it/s, Epoch: 8, Batch: 75,Loss: -1.153,Avg.Loss: -1.298,LR: 3.56E-04]Training epoch 8:  22%|██▏       | 75/341 [00:01<00:04, 55.41it/s, Epoch: 8, Batch: 76,Loss: -1.096,Avg.Loss: -1.295,LR: 3.56E-04]Training epoch 8:  22%|██▏       | 76/341 [00:01<00:04, 55.41it/s, Epoch: 8, Batch: 77,Loss: -1.631,Avg.Loss: -1.300,LR: 3.56E-04]Training epoch 8:  23%|██▎       | 77/341 [00:01<00:04, 55.41it/s, Epoch: 8, Batch: 78,Loss: -1.186,Avg.Loss: -1.298,LR: 3.55E-04]Training epoch 8:  23%|██▎       | 78/341 [00:01<00:04, 55.65it/s, Epoch: 8, Batch: 78,Loss: -1.186,Avg.Loss: -1.298,LR: 3.55E-04]Training epoch 8:  23%|██▎       | 78/341 [00:01<00:04, 55.65it/s, Epoch: 8, Batch: 79,Loss: -0.915,Avg.Loss: -1.293,LR: 3.55E-04]Training epoch 8:  23%|██▎       | 79/341 [00:01<00:04, 55.65it/s, Epoch: 8, Batch: 80,Loss: -1.449,Avg.Loss: -1.295,LR: 3.55E-04]Training epoch 8:  23%|██▎       | 80/341 [00:01<00:04, 55.65it/s, Epoch: 8, Batch: 81,Loss: -1.731,Avg.Loss: -1.301,LR: 3.55E-04]Training epoch 8:  24%|██▍       | 81/341 [00:01<00:04, 55.65it/s, Epoch: 8, Batch: 82,Loss: -1.428,Avg.Loss: -1.302,LR: 3.55E-04]Training epoch 8:  24%|██▍       | 82/341 [00:01<00:04, 55.65it/s, Epoch: 8, Batch: 83,Loss: -1.539,Avg.Loss: -1.305,LR: 3.55E-04]Training epoch 8:  24%|██▍       | 83/341 [00:01<00:04, 55.65it/s, Epoch: 8, Batch: 84,Loss: -0.548,Avg.Loss: -1.296,LR: 3.55E-04]Training epoch 8:  25%|██▍       | 84/341 [00:01<00:04, 55.57it/s, Epoch: 8, Batch: 84,Loss: -0.548,Avg.Loss: -1.296,LR: 3.55E-04]Training epoch 8:  25%|██▍       | 84/341 [00:01<00:04, 55.57it/s, Epoch: 8, Batch: 85,Loss: -0.069,Avg.Loss: -1.282,LR: 3.55E-04]Training epoch 8:  25%|██▍       | 85/341 [00:01<00:04, 55.57it/s, Epoch: 8, Batch: 86,Loss: -0.907,Avg.Loss: -1.277,LR: 3.55E-04]Training epoch 8:  25%|██▌       | 86/341 [00:01<00:04, 55.57it/s, Epoch: 8, Batch: 87,Loss: -1.392,Avg.Loss: -1.279,LR: 3.54E-04]Training epoch 8:  26%|██▌       | 87/341 [00:01<00:04, 55.57it/s, Epoch: 8, Batch: 88,Loss: -0.987,Avg.Loss: -1.275,LR: 3.54E-04]Training epoch 8:  26%|██▌       | 88/341 [00:01<00:04, 55.57it/s, Epoch: 8, Batch: 89,Loss: -1.424,Avg.Loss: -1.277,LR: 3.54E-04]Training epoch 8:  26%|██▌       | 89/341 [00:01<00:04, 55.57it/s, Epoch: 8, Batch: 90,Loss: -1.505,Avg.Loss: -1.280,LR: 3.54E-04]Training epoch 8:  26%|██▋       | 90/341 [00:01<00:04, 55.43it/s, Epoch: 8, Batch: 90,Loss: -1.505,Avg.Loss: -1.280,LR: 3.54E-04]Training epoch 8:  26%|██▋       | 90/341 [00:01<00:04, 55.43it/s, Epoch: 8, Batch: 91,Loss: -1.015,Avg.Loss: -1.277,LR: 3.54E-04]Training epoch 8:  27%|██▋       | 91/341 [00:01<00:04, 55.43it/s, Epoch: 8, Batch: 92,Loss: -1.625,Avg.Loss: -1.281,LR: 3.54E-04]Training epoch 8:  27%|██▋       | 92/341 [00:01<00:04, 55.43it/s, Epoch: 8, Batch: 93,Loss: -0.740,Avg.Loss: -1.275,LR: 3.54E-04]Training epoch 8:  27%|██▋       | 93/341 [00:01<00:04, 55.43it/s, Epoch: 8, Batch: 94,Loss: 0.552,Avg.Loss: -1.255,LR: 3.54E-04] Training epoch 8:  28%|██▊       | 94/341 [00:01<00:04, 55.43it/s, Epoch: 8, Batch: 95,Loss: -0.078,Avg.Loss: -1.243,LR: 3.54E-04]Training epoch 8:  28%|██▊       | 95/341 [00:01<00:04, 55.43it/s, Epoch: 8, Batch: 96,Loss: -1.337,Avg.Loss: -1.244,LR: 3.54E-04]Training epoch 8:  28%|██▊       | 96/341 [00:01<00:04, 55.48it/s, Epoch: 8, Batch: 96,Loss: -1.337,Avg.Loss: -1.244,LR: 3.54E-04]Training epoch 8:  28%|██▊       | 96/341 [00:01<00:04, 55.48it/s, Epoch: 8, Batch: 97,Loss: -1.476,Avg.Loss: -1.246,LR: 3.53E-04]Training epoch 8:  28%|██▊       | 97/341 [00:01<00:04, 55.48it/s, Epoch: 8, Batch: 98,Loss: -1.542,Avg.Loss: -1.249,LR: 3.53E-04]Training epoch 8:  29%|██▊       | 98/341 [00:01<00:04, 55.48it/s, Epoch: 8, Batch: 99,Loss: -1.021,Avg.Loss: -1.247,LR: 3.53E-04]Training epoch 8:  29%|██▉       | 99/341 [00:01<00:04, 55.48it/s, Epoch: 8, Batch: 100,Loss: -0.374,Avg.Loss: -1.238,LR: 3.53E-04]Training epoch 8:  29%|██▉       | 100/341 [00:01<00:04, 55.48it/s, Epoch: 8, Batch: 101,Loss: -1.434,Avg.Loss: -1.240,LR: 3.53E-04]Training epoch 8:  30%|██▉       | 101/341 [00:01<00:04, 55.48it/s, Epoch: 8, Batch: 102,Loss: -0.691,Avg.Loss: -1.235,LR: 3.53E-04]Training epoch 8:  30%|██▉       | 102/341 [00:01<00:04, 55.05it/s, Epoch: 8, Batch: 102,Loss: -0.691,Avg.Loss: -1.235,LR: 3.53E-04]Training epoch 8:  30%|██▉       | 102/341 [00:01<00:04, 55.05it/s, Epoch: 8, Batch: 103,Loss: -0.939,Avg.Loss: -1.232,LR: 3.53E-04]Training epoch 8:  30%|███       | 103/341 [00:01<00:04, 55.05it/s, Epoch: 8, Batch: 104,Loss: -1.610,Avg.Loss: -1.236,LR: 3.53E-04]Training epoch 8:  30%|███       | 104/341 [00:01<00:04, 55.05it/s, Epoch: 8, Batch: 105,Loss: -1.136,Avg.Loss: -1.235,LR: 3.53E-04]Training epoch 8:  31%|███       | 105/341 [00:01<00:04, 55.05it/s, Epoch: 8, Batch: 106,Loss: -0.317,Avg.Loss: -1.226,LR: 3.52E-04]Training epoch 8:  31%|███       | 106/341 [00:01<00:04, 55.05it/s, Epoch: 8, Batch: 107,Loss: -1.200,Avg.Loss: -1.226,LR: 3.52E-04]Training epoch 8:  31%|███▏      | 107/341 [00:01<00:04, 55.05it/s, Epoch: 8, Batch: 108,Loss: -1.150,Avg.Loss: -1.225,LR: 3.52E-04]Training epoch 8:  32%|███▏      | 108/341 [00:01<00:04, 54.83it/s, Epoch: 8, Batch: 108,Loss: -1.150,Avg.Loss: -1.225,LR: 3.52E-04]Training epoch 8:  32%|███▏      | 108/341 [00:01<00:04, 54.83it/s, Epoch: 8, Batch: 109,Loss: -1.122,Avg.Loss: -1.224,LR: 3.52E-04]Training epoch 8:  32%|███▏      | 109/341 [00:02<00:04, 54.83it/s, Epoch: 8, Batch: 110,Loss: -1.291,Avg.Loss: -1.225,LR: 3.52E-04]Training epoch 8:  32%|███▏      | 110/341 [00:02<00:04, 54.83it/s, Epoch: 8, Batch: 111,Loss: -1.439,Avg.Loss: -1.227,LR: 3.52E-04]Training epoch 8:  33%|███▎      | 111/341 [00:02<00:04, 54.83it/s, Epoch: 8, Batch: 112,Loss: -1.582,Avg.Loss: -1.230,LR: 3.52E-04]Training epoch 8:  33%|███▎      | 112/341 [00:02<00:04, 54.83it/s, Epoch: 8, Batch: 113,Loss: -1.657,Avg.Loss: -1.234,LR: 3.52E-04]Training epoch 8:  33%|███▎      | 113/341 [00:02<00:04, 54.83it/s, Epoch: 8, Batch: 114,Loss: -1.738,Avg.Loss: -1.238,LR: 3.52E-04]Training epoch 8:  33%|███▎      | 114/341 [00:02<00:04, 54.54it/s, Epoch: 8, Batch: 114,Loss: -1.738,Avg.Loss: -1.238,LR: 3.52E-04]Training epoch 8:  33%|███▎      | 114/341 [00:02<00:04, 54.54it/s, Epoch: 8, Batch: 115,Loss: -1.452,Avg.Loss: -1.240,LR: 3.52E-04]Training epoch 8:  34%|███▎      | 115/341 [00:02<00:04, 54.54it/s, Epoch: 8, Batch: 116,Loss: -1.330,Avg.Loss: -1.241,LR: 3.51E-04]Training epoch 8:  34%|███▍      | 116/341 [00:02<00:04, 54.54it/s, Epoch: 8, Batch: 117,Loss: -1.289,Avg.Loss: -1.241,LR: 3.51E-04]Training epoch 8:  34%|███▍      | 117/341 [00:02<00:04, 54.54it/s, Epoch: 8, Batch: 118,Loss: -1.373,Avg.Loss: -1.242,LR: 3.51E-04]Training epoch 8:  35%|███▍      | 118/341 [00:02<00:04, 54.54it/s, Epoch: 8, Batch: 119,Loss: -1.880,Avg.Loss: -1.248,LR: 3.51E-04]Training epoch 8:  35%|███▍      | 119/341 [00:02<00:04, 54.54it/s, Epoch: 8, Batch: 120,Loss: -0.848,Avg.Loss: -1.244,LR: 3.51E-04]Training epoch 8:  35%|███▌      | 120/341 [00:02<00:04, 54.34it/s, Epoch: 8, Batch: 120,Loss: -0.848,Avg.Loss: -1.244,LR: 3.51E-04]Training epoch 8:  35%|███▌      | 120/341 [00:02<00:04, 54.34it/s, Epoch: 8, Batch: 121,Loss: -0.883,Avg.Loss: -1.241,LR: 3.51E-04]Training epoch 8:  35%|███▌      | 121/341 [00:02<00:04, 54.34it/s, Epoch: 8, Batch: 122,Loss: -1.435,Avg.Loss: -1.243,LR: 3.51E-04]Training epoch 8:  36%|███▌      | 122/341 [00:02<00:04, 54.34it/s, Epoch: 8, Batch: 123,Loss: -1.308,Avg.Loss: -1.243,LR: 3.51E-04]Training epoch 8:  36%|███▌      | 123/341 [00:02<00:04, 54.34it/s, Epoch: 8, Batch: 124,Loss: -0.966,Avg.Loss: -1.241,LR: 3.51E-04]Training epoch 8:  36%|███▋      | 124/341 [00:02<00:03, 54.34it/s, Epoch: 8, Batch: 125,Loss: -1.546,Avg.Loss: -1.244,LR: 3.50E-04]Training epoch 8:  37%|███▋      | 125/341 [00:02<00:03, 54.34it/s, Epoch: 8, Batch: 126,Loss: -1.204,Avg.Loss: -1.243,LR: 3.50E-04]Training epoch 8:  37%|███▋      | 126/341 [00:02<00:03, 54.54it/s, Epoch: 8, Batch: 126,Loss: -1.204,Avg.Loss: -1.243,LR: 3.50E-04]Training epoch 8:  37%|███▋      | 126/341 [00:02<00:03, 54.54it/s, Epoch: 8, Batch: 127,Loss: -0.478,Avg.Loss: -1.237,LR: 3.50E-04]Training epoch 8:  37%|███▋      | 127/341 [00:02<00:03, 54.54it/s, Epoch: 8, Batch: 128,Loss: -0.921,Avg.Loss: -1.235,LR: 3.50E-04]Training epoch 8:  38%|███▊      | 128/341 [00:02<00:03, 54.54it/s, Epoch: 8, Batch: 129,Loss: -1.438,Avg.Loss: -1.236,LR: 3.50E-04]Training epoch 8:  38%|███▊      | 129/341 [00:02<00:03, 54.54it/s, Epoch: 8, Batch: 130,Loss: -1.552,Avg.Loss: -1.239,LR: 3.50E-04]Training epoch 8:  38%|███▊      | 130/341 [00:02<00:03, 54.54it/s, Epoch: 8, Batch: 131,Loss: -1.723,Avg.Loss: -1.242,LR: 3.50E-04]Training epoch 8:  38%|███▊      | 131/341 [00:02<00:03, 54.54it/s, Epoch: 8, Batch: 132,Loss: -1.394,Avg.Loss: -1.244,LR: 3.50E-04]Training epoch 8:  39%|███▊      | 132/341 [00:02<00:03, 54.60it/s, Epoch: 8, Batch: 132,Loss: -1.394,Avg.Loss: -1.244,LR: 3.50E-04]Training epoch 8:  39%|███▊      | 132/341 [00:02<00:03, 54.60it/s, Epoch: 8, Batch: 133,Loss: -1.219,Avg.Loss: -1.243,LR: 3.50E-04]Training epoch 8:  39%|███▉      | 133/341 [00:02<00:03, 54.60it/s, Epoch: 8, Batch: 134,Loss: -1.798,Avg.Loss: -1.248,LR: 3.50E-04]Training epoch 8:  39%|███▉      | 134/341 [00:02<00:03, 54.60it/s, Epoch: 8, Batch: 135,Loss: -0.862,Avg.Loss: -1.245,LR: 3.49E-04]Training epoch 8:  40%|███▉      | 135/341 [00:02<00:03, 54.60it/s, Epoch: 8, Batch: 136,Loss: -0.924,Avg.Loss: -1.242,LR: 3.49E-04]Training epoch 8:  40%|███▉      | 136/341 [00:02<00:03, 54.60it/s, Epoch: 8, Batch: 137,Loss: -1.343,Avg.Loss: -1.243,LR: 3.49E-04]Training epoch 8:  40%|████      | 137/341 [00:02<00:03, 54.60it/s, Epoch: 8, Batch: 138,Loss: -0.913,Avg.Loss: -1.241,LR: 3.49E-04]Training epoch 8:  40%|████      | 138/341 [00:02<00:03, 53.69it/s, Epoch: 8, Batch: 138,Loss: -0.913,Avg.Loss: -1.241,LR: 3.49E-04]Training epoch 8:  40%|████      | 138/341 [00:02<00:03, 53.69it/s, Epoch: 8, Batch: 139,Loss: -1.021,Avg.Loss: -1.239,LR: 3.49E-04]Training epoch 8:  41%|████      | 139/341 [00:02<00:03, 53.69it/s, Epoch: 8, Batch: 140,Loss: -1.471,Avg.Loss: -1.241,LR: 3.49E-04]Training epoch 8:  41%|████      | 140/341 [00:02<00:03, 53.69it/s, Epoch: 8, Batch: 141,Loss: -1.641,Avg.Loss: -1.244,LR: 3.49E-04]Training epoch 8:  41%|████▏     | 141/341 [00:02<00:03, 53.69it/s, Epoch: 8, Batch: 142,Loss: -1.284,Avg.Loss: -1.244,LR: 3.49E-04]Training epoch 8:  42%|████▏     | 142/341 [00:02<00:03, 53.69it/s, Epoch: 8, Batch: 143,Loss: -1.714,Avg.Loss: -1.247,LR: 3.49E-04]Training epoch 8:  42%|████▏     | 143/341 [00:02<00:03, 53.69it/s, Epoch: 8, Batch: 144,Loss: -1.460,Avg.Loss: -1.249,LR: 3.48E-04]Training epoch 8:  42%|████▏     | 144/341 [00:02<00:03, 53.71it/s, Epoch: 8, Batch: 144,Loss: -1.460,Avg.Loss: -1.249,LR: 3.48E-04]Training epoch 8:  42%|████▏     | 144/341 [00:02<00:03, 53.71it/s, Epoch: 8, Batch: 145,Loss: -0.918,Avg.Loss: -1.246,LR: 3.48E-04]Training epoch 8:  43%|████▎     | 145/341 [00:02<00:03, 53.71it/s, Epoch: 8, Batch: 146,Loss: -1.629,Avg.Loss: -1.249,LR: 3.48E-04]Training epoch 8:  43%|████▎     | 146/341 [00:02<00:03, 53.71it/s, Epoch: 8, Batch: 147,Loss: -1.230,Avg.Loss: -1.249,LR: 3.48E-04]Training epoch 8:  43%|████▎     | 147/341 [00:02<00:03, 53.71it/s, Epoch: 8, Batch: 148,Loss: -1.007,Avg.Loss: -1.247,LR: 3.48E-04]Training epoch 8:  43%|████▎     | 148/341 [00:02<00:03, 53.71it/s, Epoch: 8, Batch: 149,Loss: -1.712,Avg.Loss: -1.250,LR: 3.48E-04]Training epoch 8:  44%|████▎     | 149/341 [00:02<00:03, 53.71it/s, Epoch: 8, Batch: 150,Loss: -1.575,Avg.Loss: -1.252,LR: 3.48E-04]Training epoch 8:  44%|████▍     | 150/341 [00:02<00:03, 53.18it/s, Epoch: 8, Batch: 150,Loss: -1.575,Avg.Loss: -1.252,LR: 3.48E-04]Training epoch 8:  44%|████▍     | 150/341 [00:02<00:03, 53.18it/s, Epoch: 8, Batch: 151,Loss: -0.856,Avg.Loss: -1.250,LR: 3.48E-04]Training epoch 8:  44%|████▍     | 151/341 [00:02<00:03, 53.18it/s, Epoch: 8, Batch: 152,Loss: -1.412,Avg.Loss: -1.251,LR: 3.48E-04]Training epoch 8:  45%|████▍     | 152/341 [00:02<00:03, 53.18it/s, Epoch: 8, Batch: 153,Loss: -1.510,Avg.Loss: -1.253,LR: 3.48E-04]Training epoch 8:  45%|████▍     | 153/341 [00:02<00:03, 53.18it/s, Epoch: 8, Batch: 154,Loss: -1.342,Avg.Loss: -1.253,LR: 3.47E-04]Training epoch 8:  45%|████▌     | 154/341 [00:02<00:03, 53.18it/s, Epoch: 8, Batch: 155,Loss: -1.943,Avg.Loss: -1.258,LR: 3.47E-04]Training epoch 8:  45%|████▌     | 155/341 [00:02<00:03, 53.18it/s, Epoch: 8, Batch: 156,Loss: -1.470,Avg.Loss: -1.259,LR: 3.47E-04]Training epoch 8:  46%|████▌     | 156/341 [00:02<00:03, 53.51it/s, Epoch: 8, Batch: 156,Loss: -1.470,Avg.Loss: -1.259,LR: 3.47E-04]Training epoch 8:  46%|████▌     | 156/341 [00:02<00:03, 53.51it/s, Epoch: 8, Batch: 157,Loss: -1.010,Avg.Loss: -1.257,LR: 3.47E-04]Training epoch 8:  46%|████▌     | 157/341 [00:02<00:03, 53.51it/s, Epoch: 8, Batch: 158,Loss: -1.354,Avg.Loss: -1.258,LR: 3.47E-04]Training epoch 8:  46%|████▋     | 158/341 [00:02<00:03, 53.51it/s, Epoch: 8, Batch: 159,Loss: -1.586,Avg.Loss: -1.260,LR: 3.47E-04]Training epoch 8:  47%|████▋     | 159/341 [00:02<00:03, 53.51it/s, Epoch: 8, Batch: 160,Loss: -0.900,Avg.Loss: -1.258,LR: 3.47E-04]Training epoch 8:  47%|████▋     | 160/341 [00:02<00:03, 53.51it/s, Epoch: 8, Batch: 161,Loss: -1.488,Avg.Loss: -1.259,LR: 3.47E-04]Training epoch 8:  47%|████▋     | 161/341 [00:02<00:03, 53.51it/s, Epoch: 8, Batch: 162,Loss: -1.115,Avg.Loss: -1.258,LR: 3.47E-04]Training epoch 8:  48%|████▊     | 162/341 [00:02<00:03, 53.56it/s, Epoch: 8, Batch: 162,Loss: -1.115,Avg.Loss: -1.258,LR: 3.47E-04]Training epoch 8:  48%|████▊     | 162/341 [00:02<00:03, 53.56it/s, Epoch: 8, Batch: 163,Loss: -1.540,Avg.Loss: -1.260,LR: 3.46E-04]Training epoch 8:  48%|████▊     | 163/341 [00:03<00:03, 53.56it/s, Epoch: 8, Batch: 164,Loss: -1.903,Avg.Loss: -1.264,LR: 3.46E-04]Training epoch 8:  48%|████▊     | 164/341 [00:03<00:03, 53.56it/s, Epoch: 8, Batch: 165,Loss: -1.316,Avg.Loss: -1.264,LR: 3.46E-04]Training epoch 8:  48%|████▊     | 165/341 [00:03<00:03, 53.56it/s, Epoch: 8, Batch: 166,Loss: -0.559,Avg.Loss: -1.260,LR: 3.46E-04]Training epoch 8:  49%|████▊     | 166/341 [00:03<00:03, 53.56it/s, Epoch: 8, Batch: 167,Loss: -1.150,Avg.Loss: -1.259,LR: 3.46E-04]Training epoch 8:  49%|████▉     | 167/341 [00:03<00:03, 53.56it/s, Epoch: 8, Batch: 168,Loss: -1.367,Avg.Loss: -1.260,LR: 3.46E-04]Training epoch 8:  49%|████▉     | 168/341 [00:03<00:03, 53.79it/s, Epoch: 8, Batch: 168,Loss: -1.367,Avg.Loss: -1.260,LR: 3.46E-04]Training epoch 8:  49%|████▉     | 168/341 [00:03<00:03, 53.79it/s, Epoch: 8, Batch: 169,Loss: -1.531,Avg.Loss: -1.262,LR: 3.46E-04]Training epoch 8:  50%|████▉     | 169/341 [00:03<00:03, 53.79it/s, Epoch: 8, Batch: 170,Loss: -1.976,Avg.Loss: -1.266,LR: 3.46E-04]Training epoch 8:  50%|████▉     | 170/341 [00:03<00:03, 53.79it/s, Epoch: 8, Batch: 171,Loss: -1.519,Avg.Loss: -1.267,LR: 3.46E-04]Training epoch 8:  50%|█████     | 171/341 [00:03<00:03, 53.79it/s, Epoch: 8, Batch: 172,Loss: -1.343,Avg.Loss: -1.268,LR: 3.46E-04]Training epoch 8:  50%|█████     | 172/341 [00:03<00:03, 53.79it/s, Epoch: 8, Batch: 173,Loss: -1.752,Avg.Loss: -1.271,LR: 3.45E-04]Training epoch 8:  51%|█████     | 173/341 [00:03<00:03, 53.79it/s, Epoch: 8, Batch: 174,Loss: -1.709,Avg.Loss: -1.273,LR: 3.45E-04]Training epoch 8:  51%|█████     | 174/341 [00:03<00:03, 53.75it/s, Epoch: 8, Batch: 174,Loss: -1.709,Avg.Loss: -1.273,LR: 3.45E-04]Training epoch 8:  51%|█████     | 174/341 [00:03<00:03, 53.75it/s, Epoch: 8, Batch: 175,Loss: -1.174,Avg.Loss: -1.273,LR: 3.45E-04]Training epoch 8:  51%|█████▏    | 175/341 [00:03<00:03, 53.75it/s, Epoch: 8, Batch: 176,Loss: -0.286,Avg.Loss: -1.267,LR: 3.45E-04]Training epoch 8:  52%|█████▏    | 176/341 [00:03<00:03, 53.75it/s, Epoch: 8, Batch: 177,Loss: -0.812,Avg.Loss: -1.264,LR: 3.45E-04]Training epoch 8:  52%|█████▏    | 177/341 [00:03<00:03, 53.75it/s, Epoch: 8, Batch: 178,Loss: -0.151,Avg.Loss: -1.258,LR: 3.45E-04]Training epoch 8:  52%|█████▏    | 178/341 [00:03<00:03, 53.75it/s, Epoch: 8, Batch: 179,Loss: -0.733,Avg.Loss: -1.255,LR: 3.45E-04]Training epoch 8:  52%|█████▏    | 179/341 [00:03<00:03, 53.75it/s, Epoch: 8, Batch: 180,Loss: -0.564,Avg.Loss: -1.251,LR: 3.45E-04]Training epoch 8:  53%|█████▎    | 180/341 [00:03<00:02, 54.79it/s, Epoch: 8, Batch: 180,Loss: -0.564,Avg.Loss: -1.251,LR: 3.45E-04]Training epoch 8:  53%|█████▎    | 180/341 [00:03<00:02, 54.79it/s, Epoch: 8, Batch: 181,Loss: -0.674,Avg.Loss: -1.248,LR: 3.45E-04]Training epoch 8:  53%|█████▎    | 181/341 [00:03<00:02, 54.79it/s, Epoch: 8, Batch: 182,Loss: -1.451,Avg.Loss: -1.249,LR: 3.44E-04]Training epoch 8:  53%|█████▎    | 182/341 [00:03<00:02, 54.79it/s, Epoch: 8, Batch: 183,Loss: 0.001,Avg.Loss: -1.242,LR: 3.44E-04] Training epoch 8:  54%|█████▎    | 183/341 [00:03<00:02, 54.79it/s, Epoch: 8, Batch: 184,Loss: -0.766,Avg.Loss: -1.240,LR: 3.44E-04]Training epoch 8:  54%|█████▍    | 184/341 [00:03<00:02, 54.79it/s, Epoch: 8, Batch: 185,Loss: -1.060,Avg.Loss: -1.239,LR: 3.44E-04]Training epoch 8:  54%|█████▍    | 185/341 [00:03<00:02, 54.79it/s, Epoch: 8, Batch: 186,Loss: -0.627,Avg.Loss: -1.236,LR: 3.44E-04]Training epoch 8:  55%|█████▍    | 186/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 186,Loss: -0.627,Avg.Loss: -1.236,LR: 3.44E-04]Training epoch 8:  55%|█████▍    | 186/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 187,Loss: -0.647,Avg.Loss: -1.232,LR: 3.44E-04]Training epoch 8:  55%|█████▍    | 187/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 188,Loss: -1.119,Avg.Loss: -1.232,LR: 3.44E-04]Training epoch 8:  55%|█████▌    | 188/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 189,Loss: -1.232,Avg.Loss: -1.232,LR: 3.44E-04]Training epoch 8:  55%|█████▌    | 189/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 190,Loss: -1.212,Avg.Loss: -1.232,LR: 3.44E-04]Training epoch 8:  56%|█████▌    | 190/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 191,Loss: -1.336,Avg.Loss: -1.232,LR: 3.43E-04]Training epoch 8:  56%|█████▌    | 191/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 192,Loss: -1.667,Avg.Loss: -1.235,LR: 3.43E-04]Training epoch 8:  56%|█████▋    | 192/341 [00:03<00:02, 55.15it/s, Epoch: 8, Batch: 192,Loss: -1.667,Avg.Loss: -1.235,LR: 3.43E-04]Training epoch 8:  56%|█████▋    | 192/341 [00:03<00:02, 55.15it/s, Epoch: 8, Batch: 193,Loss: -1.205,Avg.Loss: -1.234,LR: 3.43E-04]Training epoch 8:  57%|█████▋    | 193/341 [00:03<00:02, 55.15it/s, Epoch: 8, Batch: 194,Loss: -1.339,Avg.Loss: -1.235,LR: 3.43E-04]Training epoch 8:  57%|█████▋    | 194/341 [00:03<00:02, 55.15it/s, Epoch: 8, Batch: 195,Loss: -1.142,Avg.Loss: -1.234,LR: 3.43E-04]Training epoch 8:  57%|█████▋    | 195/341 [00:03<00:02, 55.15it/s, Epoch: 8, Batch: 196,Loss: -0.748,Avg.Loss: -1.232,LR: 3.43E-04]Training epoch 8:  57%|█████▋    | 196/341 [00:03<00:02, 55.15it/s, Epoch: 8, Batch: 197,Loss: -1.332,Avg.Loss: -1.232,LR: 3.43E-04]Training epoch 8:  58%|█████▊    | 197/341 [00:03<00:02, 55.15it/s, Epoch: 8, Batch: 198,Loss: -1.399,Avg.Loss: -1.233,LR: 3.43E-04]Training epoch 8:  58%|█████▊    | 198/341 [00:03<00:02, 55.10it/s, Epoch: 8, Batch: 198,Loss: -1.399,Avg.Loss: -1.233,LR: 3.43E-04]Training epoch 8:  58%|█████▊    | 198/341 [00:03<00:02, 55.10it/s, Epoch: 8, Batch: 199,Loss: -1.452,Avg.Loss: -1.234,LR: 3.43E-04]Training epoch 8:  58%|█████▊    | 199/341 [00:03<00:02, 55.10it/s, Epoch: 8, Batch: 200,Loss: -1.366,Avg.Loss: -1.235,LR: 3.43E-04]Training epoch 8:  59%|█████▊    | 200/341 [00:03<00:02, 55.10it/s, Epoch: 8, Batch: 201,Loss: -1.536,Avg.Loss: -1.237,LR: 3.42E-04]Training epoch 8:  59%|█████▉    | 201/341 [00:03<00:02, 55.10it/s, Epoch: 8, Batch: 202,Loss: -1.458,Avg.Loss: -1.238,LR: 3.42E-04]Training epoch 8:  59%|█████▉    | 202/341 [00:03<00:02, 55.10it/s, Epoch: 8, Batch: 203,Loss: -1.582,Avg.Loss: -1.239,LR: 3.42E-04]Training epoch 8:  60%|█████▉    | 203/341 [00:03<00:02, 55.10it/s, Epoch: 8, Batch: 204,Loss: -1.287,Avg.Loss: -1.240,LR: 3.42E-04]Training epoch 8:  60%|█████▉    | 204/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 204,Loss: -1.287,Avg.Loss: -1.240,LR: 3.42E-04]Training epoch 8:  60%|█████▉    | 204/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 205,Loss: -0.929,Avg.Loss: -1.238,LR: 3.42E-04]Training epoch 8:  60%|██████    | 205/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 206,Loss: -1.428,Avg.Loss: -1.239,LR: 3.42E-04]Training epoch 8:  60%|██████    | 206/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 207,Loss: -1.490,Avg.Loss: -1.240,LR: 3.42E-04]Training epoch 8:  61%|██████    | 207/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 208,Loss: -1.311,Avg.Loss: -1.241,LR: 3.42E-04]Training epoch 8:  61%|██████    | 208/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 209,Loss: -0.675,Avg.Loss: -1.238,LR: 3.42E-04]Training epoch 8:  61%|██████▏   | 209/341 [00:03<00:02, 54.83it/s, Epoch: 8, Batch: 210,Loss: -1.038,Avg.Loss: -1.237,LR: 3.41E-04]Training epoch 8:  62%|██████▏   | 210/341 [00:03<00:02, 54.38it/s, Epoch: 8, Batch: 210,Loss: -1.038,Avg.Loss: -1.237,LR: 3.41E-04]Training epoch 8:  62%|██████▏   | 210/341 [00:03<00:02, 54.38it/s, Epoch: 8, Batch: 211,Loss: -1.685,Avg.Loss: -1.239,LR: 3.41E-04]Training epoch 8:  62%|██████▏   | 211/341 [00:03<00:02, 54.38it/s, Epoch: 8, Batch: 212,Loss: -1.200,Avg.Loss: -1.239,LR: 3.41E-04]Training epoch 8:  62%|██████▏   | 212/341 [00:03<00:02, 54.38it/s, Epoch: 8, Batch: 213,Loss: -0.383,Avg.Loss: -1.235,LR: 3.41E-04]Training epoch 8:  62%|██████▏   | 213/341 [00:03<00:02, 54.38it/s, Epoch: 8, Batch: 214,Loss: -0.781,Avg.Loss: -1.233,LR: 3.41E-04]Training epoch 8:  63%|██████▎   | 214/341 [00:03<00:02, 54.38it/s, Epoch: 8, Batch: 215,Loss: -0.816,Avg.Loss: -1.231,LR: 3.41E-04]Training epoch 8:  63%|██████▎   | 215/341 [00:03<00:02, 54.38it/s, Epoch: 8, Batch: 216,Loss: -0.300,Avg.Loss: -1.226,LR: 3.41E-04]Training epoch 8:  63%|██████▎   | 216/341 [00:03<00:02, 54.48it/s, Epoch: 8, Batch: 216,Loss: -0.300,Avg.Loss: -1.226,LR: 3.41E-04]Training epoch 8:  63%|██████▎   | 216/341 [00:03<00:02, 54.48it/s, Epoch: 8, Batch: 217,Loss: -1.355,Avg.Loss: -1.227,LR: 3.41E-04]Training epoch 8:  64%|██████▎   | 217/341 [00:03<00:02, 54.48it/s, Epoch: 8, Batch: 218,Loss: -1.209,Avg.Loss: -1.227,LR: 3.41E-04]Training epoch 8:  64%|██████▍   | 218/341 [00:04<00:02, 54.48it/s, Epoch: 8, Batch: 219,Loss: -1.379,Avg.Loss: -1.228,LR: 3.40E-04]Training epoch 8:  64%|██████▍   | 219/341 [00:04<00:02, 54.48it/s, Epoch: 8, Batch: 220,Loss: -1.120,Avg.Loss: -1.227,LR: 3.40E-04]Training epoch 8:  65%|██████▍   | 220/341 [00:04<00:02, 54.48it/s, Epoch: 8, Batch: 221,Loss: -0.293,Avg.Loss: -1.223,LR: 3.40E-04]Training epoch 8:  65%|██████▍   | 221/341 [00:04<00:02, 54.48it/s, Epoch: 8, Batch: 222,Loss: 0.128,Avg.Loss: -1.217,LR: 3.40E-04] Training epoch 8:  65%|██████▌   | 222/341 [00:04<00:02, 54.34it/s, Epoch: 8, Batch: 222,Loss: 0.128,Avg.Loss: -1.217,LR: 3.40E-04]Training epoch 8:  65%|██████▌   | 222/341 [00:04<00:02, 54.34it/s, Epoch: 8, Batch: 223,Loss: -0.012,Avg.Loss: -1.211,LR: 3.40E-04]Training epoch 8:  65%|██████▌   | 223/341 [00:04<00:02, 54.34it/s, Epoch: 8, Batch: 224,Loss: -0.950,Avg.Loss: -1.210,LR: 3.40E-04]Training epoch 8:  66%|██████▌   | 224/341 [00:04<00:02, 54.34it/s, Epoch: 8, Batch: 225,Loss: -1.656,Avg.Loss: -1.212,LR: 3.40E-04]Training epoch 8:  66%|██████▌   | 225/341 [00:04<00:02, 54.34it/s, Epoch: 8, Batch: 226,Loss: -1.035,Avg.Loss: -1.211,LR: 3.40E-04]Training epoch 8:  66%|██████▋   | 226/341 [00:04<00:02, 54.34it/s, Epoch: 8, Batch: 227,Loss: 0.104,Avg.Loss: -1.206,LR: 3.40E-04] Training epoch 8:  67%|██████▋   | 227/341 [00:04<00:02, 54.34it/s, Epoch: 8, Batch: 228,Loss: 1.155,Avg.Loss: -1.195,LR: 3.40E-04]Training epoch 8:  67%|██████▋   | 228/341 [00:04<00:02, 55.17it/s, Epoch: 8, Batch: 228,Loss: 1.155,Avg.Loss: -1.195,LR: 3.40E-04]Training epoch 8:  67%|██████▋   | 228/341 [00:04<00:02, 55.17it/s, Epoch: 8, Batch: 229,Loss: 0.481,Avg.Loss: -1.188,LR: 3.39E-04]Training epoch 8:  67%|██████▋   | 229/341 [00:04<00:02, 55.17it/s, Epoch: 8, Batch: 230,Loss: -0.740,Avg.Loss: -1.186,LR: 3.39E-04]Training epoch 8:  67%|██████▋   | 230/341 [00:04<00:02, 55.17it/s, Epoch: 8, Batch: 231,Loss: -0.386,Avg.Loss: -1.183,LR: 3.39E-04]Training epoch 8:  68%|██████▊   | 231/341 [00:04<00:01, 55.17it/s, Epoch: 8, Batch: 232,Loss: 0.517,Avg.Loss: -1.175,LR: 3.39E-04] Training epoch 8:  68%|██████▊   | 232/341 [00:04<00:01, 55.17it/s, Epoch: 8, Batch: 233,Loss: -0.688,Avg.Loss: -1.173,LR: 3.39E-04]Training epoch 8:  68%|██████▊   | 233/341 [00:04<00:01, 55.17it/s, Epoch: 8, Batch: 234,Loss: 0.070,Avg.Loss: -1.168,LR: 3.39E-04] Training epoch 8:  69%|██████▊   | 234/341 [00:04<00:01, 55.96it/s, Epoch: 8, Batch: 234,Loss: 0.070,Avg.Loss: -1.168,LR: 3.39E-04]Training epoch 8:  69%|██████▊   | 234/341 [00:04<00:01, 55.96it/s, Epoch: 8, Batch: 235,Loss: -0.672,Avg.Loss: -1.166,LR: 3.39E-04]Training epoch 8:  69%|██████▉   | 235/341 [00:04<00:01, 55.96it/s, Epoch: 8, Batch: 236,Loss: -0.948,Avg.Loss: -1.165,LR: 3.39E-04]Training epoch 8:  69%|██████▉   | 236/341 [00:04<00:01, 55.96it/s, Epoch: 8, Batch: 237,Loss: -1.450,Avg.Loss: -1.166,LR: 3.39E-04]Training epoch 8:  70%|██████▉   | 237/341 [00:04<00:01, 55.96it/s, Epoch: 8, Batch: 238,Loss: -1.196,Avg.Loss: -1.166,LR: 3.38E-04]Training epoch 8:  70%|██████▉   | 238/341 [00:04<00:01, 55.96it/s, Epoch: 8, Batch: 239,Loss: -1.061,Avg.Loss: -1.166,LR: 3.38E-04]Training epoch 8:  70%|███████   | 239/341 [00:04<00:01, 55.96it/s, Epoch: 8, Batch: 240,Loss: -0.755,Avg.Loss: -1.164,LR: 3.38E-04]Training epoch 8:  70%|███████   | 240/341 [00:04<00:01, 56.12it/s, Epoch: 8, Batch: 240,Loss: -0.755,Avg.Loss: -1.164,LR: 3.38E-04]Training epoch 8:  70%|███████   | 240/341 [00:04<00:01, 56.12it/s, Epoch: 8, Batch: 241,Loss: -0.554,Avg.Loss: -1.161,LR: 3.38E-04]Training epoch 8:  71%|███████   | 241/341 [00:04<00:01, 56.12it/s, Epoch: 8, Batch: 242,Loss: -1.139,Avg.Loss: -1.161,LR: 3.38E-04]Training epoch 8:  71%|███████   | 242/341 [00:04<00:01, 56.12it/s, Epoch: 8, Batch: 243,Loss: -1.046,Avg.Loss: -1.161,LR: 3.38E-04]Training epoch 8:  71%|███████▏  | 243/341 [00:04<00:01, 56.12it/s, Epoch: 8, Batch: 244,Loss: -0.423,Avg.Loss: -1.158,LR: 3.38E-04]Training epoch 8:  72%|███████▏  | 244/341 [00:04<00:01, 56.12it/s, Epoch: 8, Batch: 245,Loss: -1.016,Avg.Loss: -1.157,LR: 3.38E-04]Training epoch 8:  72%|███████▏  | 245/341 [00:04<00:01, 56.12it/s, Epoch: 8, Batch: 246,Loss: -1.087,Avg.Loss: -1.157,LR: 3.38E-04]Training epoch 8:  72%|███████▏  | 246/341 [00:04<00:01, 55.61it/s, Epoch: 8, Batch: 246,Loss: -1.087,Avg.Loss: -1.157,LR: 3.38E-04]Training epoch 8:  72%|███████▏  | 246/341 [00:04<00:01, 55.61it/s, Epoch: 8, Batch: 247,Loss: -1.077,Avg.Loss: -1.157,LR: 3.37E-04]Training epoch 8:  72%|███████▏  | 247/341 [00:04<00:01, 55.61it/s, Epoch: 8, Batch: 248,Loss: -1.189,Avg.Loss: -1.157,LR: 3.37E-04]Training epoch 8:  73%|███████▎  | 248/341 [00:04<00:01, 55.61it/s, Epoch: 8, Batch: 249,Loss: -1.177,Avg.Loss: -1.157,LR: 3.37E-04]Training epoch 8:  73%|███████▎  | 249/341 [00:04<00:01, 55.61it/s, Epoch: 8, Batch: 250,Loss: -1.077,Avg.Loss: -1.157,LR: 3.37E-04]Training epoch 8:  73%|███████▎  | 250/341 [00:04<00:01, 55.61it/s, Epoch: 8, Batch: 251,Loss: -1.073,Avg.Loss: -1.156,LR: 3.37E-04]Training epoch 8:  74%|███████▎  | 251/341 [00:04<00:01, 55.61it/s, Epoch: 8, Batch: 252,Loss: -1.242,Avg.Loss: -1.157,LR: 3.37E-04]Training epoch 8:  74%|███████▍  | 252/341 [00:04<00:01, 55.70it/s, Epoch: 8, Batch: 252,Loss: -1.242,Avg.Loss: -1.157,LR: 3.37E-04]Training epoch 8:  74%|███████▍  | 252/341 [00:04<00:01, 55.70it/s, Epoch: 8, Batch: 253,Loss: -1.040,Avg.Loss: -1.156,LR: 3.37E-04]Training epoch 8:  74%|███████▍  | 253/341 [00:04<00:01, 55.70it/s, Epoch: 8, Batch: 254,Loss: -1.562,Avg.Loss: -1.158,LR: 3.37E-04]Training epoch 8:  74%|███████▍  | 254/341 [00:04<00:01, 55.70it/s, Epoch: 8, Batch: 255,Loss: -1.187,Avg.Loss: -1.158,LR: 3.37E-04]Training epoch 8:  75%|███████▍  | 255/341 [00:04<00:01, 55.70it/s, Epoch: 8, Batch: 256,Loss: -1.351,Avg.Loss: -1.159,LR: 3.37E-04]Training epoch 8:  75%|███████▌  | 256/341 [00:04<00:01, 55.70it/s, Epoch: 8, Batch: 257,Loss: -1.333,Avg.Loss: -1.159,LR: 3.36E-04]Training epoch 8:  75%|███████▌  | 257/341 [00:04<00:01, 55.70it/s, Epoch: 8, Batch: 258,Loss: -1.004,Avg.Loss: -1.159,LR: 3.36E-04]Training epoch 8:  76%|███████▌  | 258/341 [00:04<00:01, 55.21it/s, Epoch: 8, Batch: 258,Loss: -1.004,Avg.Loss: -1.159,LR: 3.36E-04]Training epoch 8:  76%|███████▌  | 258/341 [00:04<00:01, 55.21it/s, Epoch: 8, Batch: 259,Loss: -1.273,Avg.Loss: -1.159,LR: 3.36E-04]Training epoch 8:  76%|███████▌  | 259/341 [00:04<00:01, 55.21it/s, Epoch: 8, Batch: 260,Loss: -1.436,Avg.Loss: -1.160,LR: 3.36E-04]Training epoch 8:  76%|███████▌  | 260/341 [00:04<00:01, 55.21it/s, Epoch: 8, Batch: 261,Loss: -0.930,Avg.Loss: -1.159,LR: 3.36E-04]Training epoch 8:  77%|███████▋  | 261/341 [00:04<00:01, 55.21it/s, Epoch: 8, Batch: 262,Loss: -0.836,Avg.Loss: -1.158,LR: 3.36E-04]Training epoch 8:  77%|███████▋  | 262/341 [00:04<00:01, 55.21it/s, Epoch: 8, Batch: 263,Loss: -1.147,Avg.Loss: -1.158,LR: 3.36E-04]Training epoch 8:  77%|███████▋  | 263/341 [00:04<00:01, 55.21it/s, Epoch: 8, Batch: 264,Loss: -1.157,Avg.Loss: -1.158,LR: 3.36E-04]Training epoch 8:  77%|███████▋  | 264/341 [00:04<00:01, 54.93it/s, Epoch: 8, Batch: 264,Loss: -1.157,Avg.Loss: -1.158,LR: 3.36E-04]Training epoch 8:  77%|███████▋  | 264/341 [00:04<00:01, 54.93it/s, Epoch: 8, Batch: 265,Loss: -1.312,Avg.Loss: -1.159,LR: 3.36E-04]Training epoch 8:  78%|███████▊  | 265/341 [00:04<00:01, 54.93it/s, Epoch: 8, Batch: 266,Loss: -1.661,Avg.Loss: -1.160,LR: 3.35E-04]Training epoch 8:  78%|███████▊  | 266/341 [00:04<00:01, 54.93it/s, Epoch: 8, Batch: 267,Loss: -1.110,Avg.Loss: -1.160,LR: 3.35E-04]Training epoch 8:  78%|███████▊  | 267/341 [00:04<00:01, 54.93it/s, Epoch: 8, Batch: 268,Loss: -0.818,Avg.Loss: -1.159,LR: 3.35E-04]Training epoch 8:  79%|███████▊  | 268/341 [00:04<00:01, 54.93it/s, Epoch: 8, Batch: 269,Loss: -1.282,Avg.Loss: -1.159,LR: 3.35E-04]Training epoch 8:  79%|███████▉  | 269/341 [00:04<00:01, 54.93it/s, Epoch: 8, Batch: 270,Loss: -1.367,Avg.Loss: -1.160,LR: 3.35E-04]Training epoch 8:  79%|███████▉  | 270/341 [00:04<00:01, 54.12it/s, Epoch: 8, Batch: 270,Loss: -1.367,Avg.Loss: -1.160,LR: 3.35E-04]Training epoch 8:  79%|███████▉  | 270/341 [00:04<00:01, 54.12it/s, Epoch: 8, Batch: 271,Loss: -1.473,Avg.Loss: -1.161,LR: 3.35E-04]Training epoch 8:  79%|███████▉  | 271/341 [00:04<00:01, 54.12it/s, Epoch: 8, Batch: 272,Loss: -1.581,Avg.Loss: -1.163,LR: 3.35E-04]Training epoch 8:  80%|███████▉  | 272/341 [00:04<00:01, 54.12it/s, Epoch: 8, Batch: 273,Loss: -1.161,Avg.Loss: -1.163,LR: 3.35E-04]Training epoch 8:  80%|████████  | 273/341 [00:05<00:01, 54.12it/s, Epoch: 8, Batch: 274,Loss: -0.851,Avg.Loss: -1.162,LR: 3.35E-04]Training epoch 8:  80%|████████  | 274/341 [00:05<00:01, 54.12it/s, Epoch: 8, Batch: 275,Loss: -1.337,Avg.Loss: -1.162,LR: 3.34E-04]Training epoch 8:  81%|████████  | 275/341 [00:05<00:01, 54.12it/s, Epoch: 8, Batch: 276,Loss: -1.524,Avg.Loss: -1.164,LR: 3.34E-04]Training epoch 8:  81%|████████  | 276/341 [00:05<00:01, 53.93it/s, Epoch: 8, Batch: 276,Loss: -1.524,Avg.Loss: -1.164,LR: 3.34E-04]Training epoch 8:  81%|████████  | 276/341 [00:05<00:01, 53.93it/s, Epoch: 8, Batch: 277,Loss: -1.261,Avg.Loss: -1.164,LR: 3.34E-04]Training epoch 8:  81%|████████  | 277/341 [00:05<00:01, 53.93it/s, Epoch: 8, Batch: 278,Loss: -1.460,Avg.Loss: -1.165,LR: 3.34E-04]Training epoch 8:  82%|████████▏ | 278/341 [00:05<00:01, 53.93it/s, Epoch: 8, Batch: 279,Loss: -1.372,Avg.Loss: -1.166,LR: 3.34E-04]Training epoch 8:  82%|████████▏ | 279/341 [00:05<00:01, 53.93it/s, Epoch: 8, Batch: 280,Loss: -0.868,Avg.Loss: -1.165,LR: 3.34E-04]Training epoch 8:  82%|████████▏ | 280/341 [00:05<00:01, 53.93it/s, Epoch: 8, Batch: 281,Loss: -1.483,Avg.Loss: -1.166,LR: 3.34E-04]Training epoch 8:  82%|████████▏ | 281/341 [00:05<00:01, 53.93it/s, Epoch: 8, Batch: 282,Loss: -1.727,Avg.Loss: -1.168,LR: 3.34E-04]Training epoch 8:  83%|████████▎ | 282/341 [00:05<00:01, 53.76it/s, Epoch: 8, Batch: 282,Loss: -1.727,Avg.Loss: -1.168,LR: 3.34E-04]Training epoch 8:  83%|████████▎ | 282/341 [00:05<00:01, 53.76it/s, Epoch: 8, Batch: 283,Loss: -1.531,Avg.Loss: -1.169,LR: 3.34E-04]Training epoch 8:  83%|████████▎ | 283/341 [00:05<00:01, 53.76it/s, Epoch: 8, Batch: 284,Loss: -1.657,Avg.Loss: -1.171,LR: 3.33E-04]Training epoch 8:  83%|████████▎ | 284/341 [00:05<00:01, 53.76it/s, Epoch: 8, Batch: 285,Loss: -1.274,Avg.Loss: -1.171,LR: 3.33E-04]Training epoch 8:  84%|████████▎ | 285/341 [00:05<00:01, 53.76it/s, Epoch: 8, Batch: 286,Loss: -0.835,Avg.Loss: -1.170,LR: 3.33E-04]Training epoch 8:  84%|████████▍ | 286/341 [00:05<00:01, 53.76it/s, Epoch: 8, Batch: 287,Loss: -1.146,Avg.Loss: -1.170,LR: 3.33E-04]Training epoch 8:  84%|████████▍ | 287/341 [00:05<00:01, 53.76it/s, Epoch: 8, Batch: 288,Loss: -1.425,Avg.Loss: -1.171,LR: 3.33E-04]Training epoch 8:  84%|████████▍ | 288/341 [00:05<00:00, 53.68it/s, Epoch: 8, Batch: 288,Loss: -1.425,Avg.Loss: -1.171,LR: 3.33E-04]Training epoch 8:  84%|████████▍ | 288/341 [00:05<00:00, 53.68it/s, Epoch: 8, Batch: 289,Loss: -1.001,Avg.Loss: -1.170,LR: 3.33E-04]Training epoch 8:  85%|████████▍ | 289/341 [00:05<00:00, 53.68it/s, Epoch: 8, Batch: 290,Loss: -1.775,Avg.Loss: -1.172,LR: 3.33E-04]Training epoch 8:  85%|████████▌ | 290/341 [00:05<00:00, 53.68it/s, Epoch: 8, Batch: 291,Loss: -1.511,Avg.Loss: -1.174,LR: 3.33E-04]Training epoch 8:  85%|████████▌ | 291/341 [00:05<00:00, 53.68it/s, Epoch: 8, Batch: 292,Loss: -1.050,Avg.Loss: -1.173,LR: 3.33E-04]Training epoch 8:  86%|████████▌ | 292/341 [00:05<00:00, 53.68it/s, Epoch: 8, Batch: 293,Loss: -1.519,Avg.Loss: -1.174,LR: 3.32E-04]Training epoch 8:  86%|████████▌ | 293/341 [00:05<00:00, 53.68it/s, Epoch: 8, Batch: 294,Loss: -1.582,Avg.Loss: -1.176,LR: 3.32E-04]Training epoch 8:  86%|████████▌ | 294/341 [00:05<00:00, 53.53it/s, Epoch: 8, Batch: 294,Loss: -1.582,Avg.Loss: -1.176,LR: 3.32E-04]Training epoch 8:  86%|████████▌ | 294/341 [00:05<00:00, 53.53it/s, Epoch: 8, Batch: 295,Loss: -1.330,Avg.Loss: -1.176,LR: 3.32E-04]Training epoch 8:  87%|████████▋ | 295/341 [00:05<00:00, 53.53it/s, Epoch: 8, Batch: 296,Loss: -1.386,Avg.Loss: -1.177,LR: 3.32E-04]Training epoch 8:  87%|████████▋ | 296/341 [00:05<00:00, 53.53it/s, Epoch: 8, Batch: 297,Loss: -1.549,Avg.Loss: -1.178,LR: 3.32E-04]Training epoch 8:  87%|████████▋ | 297/341 [00:05<00:00, 53.53it/s, Epoch: 8, Batch: 298,Loss: -1.003,Avg.Loss: -1.178,LR: 3.32E-04]Training epoch 8:  87%|████████▋ | 298/341 [00:05<00:00, 53.53it/s, Epoch: 8, Batch: 299,Loss: -1.548,Avg.Loss: -1.179,LR: 3.32E-04]Training epoch 8:  88%|████████▊ | 299/341 [00:05<00:00, 53.53it/s, Epoch: 8, Batch: 300,Loss: -1.513,Avg.Loss: -1.180,LR: 3.32E-04]Training epoch 8:  88%|████████▊ | 300/341 [00:05<00:00, 53.75it/s, Epoch: 8, Batch: 300,Loss: -1.513,Avg.Loss: -1.180,LR: 3.32E-04]Training epoch 8:  88%|████████▊ | 300/341 [00:05<00:00, 53.75it/s, Epoch: 8, Batch: 301,Loss: -1.298,Avg.Loss: -1.180,LR: 3.32E-04]Training epoch 8:  88%|████████▊ | 301/341 [00:05<00:00, 53.75it/s, Epoch: 8, Batch: 302,Loss: -1.660,Avg.Loss: -1.182,LR: 3.32E-04]Training epoch 8:  89%|████████▊ | 302/341 [00:05<00:00, 53.75it/s, Epoch: 8, Batch: 303,Loss: -1.470,Avg.Loss: -1.183,LR: 3.31E-04]Training epoch 8:  89%|████████▉ | 303/341 [00:05<00:00, 53.75it/s, Epoch: 8, Batch: 304,Loss: -1.110,Avg.Loss: -1.183,LR: 3.31E-04]Training epoch 8:  89%|████████▉ | 304/341 [00:05<00:00, 53.75it/s, Epoch: 8, Batch: 305,Loss: -1.425,Avg.Loss: -1.183,LR: 3.31E-04]Training epoch 8:  89%|████████▉ | 305/341 [00:05<00:00, 53.75it/s, Epoch: 8, Batch: 306,Loss: -1.265,Avg.Loss: -1.184,LR: 3.31E-04]Training epoch 8:  90%|████████▉ | 306/341 [00:05<00:00, 53.62it/s, Epoch: 8, Batch: 306,Loss: -1.265,Avg.Loss: -1.184,LR: 3.31E-04]Training epoch 8:  90%|████████▉ | 306/341 [00:05<00:00, 53.62it/s, Epoch: 8, Batch: 307,Loss: -1.405,Avg.Loss: -1.184,LR: 3.31E-04]Training epoch 8:  90%|█████████ | 307/341 [00:05<00:00, 53.62it/s, Epoch: 8, Batch: 308,Loss: -1.864,Avg.Loss: -1.187,LR: 3.31E-04]Training epoch 8:  90%|█████████ | 308/341 [00:05<00:00, 53.62it/s, Epoch: 8, Batch: 309,Loss: -1.663,Avg.Loss: -1.188,LR: 3.31E-04]Training epoch 8:  91%|█████████ | 309/341 [00:05<00:00, 53.62it/s, Epoch: 8, Batch: 310,Loss: -1.144,Avg.Loss: -1.188,LR: 3.31E-04]Training epoch 8:  91%|█████████ | 310/341 [00:05<00:00, 53.62it/s, Epoch: 8, Batch: 311,Loss: -1.714,Avg.Loss: -1.190,LR: 3.31E-04]Training epoch 8:  91%|█████████ | 311/341 [00:05<00:00, 53.62it/s, Epoch: 8, Batch: 312,Loss: -1.542,Avg.Loss: -1.191,LR: 3.30E-04]Training epoch 8:  91%|█████████▏| 312/341 [00:05<00:00, 53.55it/s, Epoch: 8, Batch: 312,Loss: -1.542,Avg.Loss: -1.191,LR: 3.30E-04]Training epoch 8:  91%|█████████▏| 312/341 [00:05<00:00, 53.55it/s, Epoch: 8, Batch: 313,Loss: -1.462,Avg.Loss: -1.192,LR: 3.30E-04]Training epoch 8:  92%|█████████▏| 313/341 [00:05<00:00, 53.55it/s, Epoch: 8, Batch: 314,Loss: -1.350,Avg.Loss: -1.192,LR: 3.30E-04]Training epoch 8:  92%|█████████▏| 314/341 [00:05<00:00, 53.55it/s, Epoch: 8, Batch: 315,Loss: -1.406,Avg.Loss: -1.193,LR: 3.30E-04]Training epoch 8:  92%|█████████▏| 315/341 [00:05<00:00, 53.55it/s, Epoch: 8, Batch: 316,Loss: -1.515,Avg.Loss: -1.194,LR: 3.30E-04]Training epoch 8:  93%|█████████▎| 316/341 [00:05<00:00, 53.55it/s, Epoch: 8, Batch: 317,Loss: -1.755,Avg.Loss: -1.196,LR: 3.30E-04]Training epoch 8:  93%|█████████▎| 317/341 [00:05<00:00, 53.55it/s, Epoch: 8, Batch: 318,Loss: -1.253,Avg.Loss: -1.196,LR: 3.30E-04]Training epoch 8:  93%|█████████▎| 318/341 [00:05<00:00, 53.49it/s, Epoch: 8, Batch: 318,Loss: -1.253,Avg.Loss: -1.196,LR: 3.30E-04]Training epoch 8:  93%|█████████▎| 318/341 [00:05<00:00, 53.49it/s, Epoch: 8, Batch: 319,Loss: -1.143,Avg.Loss: -1.196,LR: 3.30E-04]Training epoch 8:  94%|█████████▎| 319/341 [00:05<00:00, 53.49it/s, Epoch: 8, Batch: 320,Loss: -1.631,Avg.Loss: -1.197,LR: 3.30E-04]Training epoch 8:  94%|█████████▍| 320/341 [00:05<00:00, 53.49it/s, Epoch: 8, Batch: 321,Loss: -1.772,Avg.Loss: -1.199,LR: 3.29E-04]Training epoch 8:  94%|█████████▍| 321/341 [00:05<00:00, 53.49it/s, Epoch: 8, Batch: 322,Loss: -1.295,Avg.Loss: -1.199,LR: 3.29E-04]Training epoch 8:  94%|█████████▍| 322/341 [00:05<00:00, 53.49it/s, Epoch: 8, Batch: 323,Loss: -1.920,Avg.Loss: -1.201,LR: 3.29E-04]Training epoch 8:  95%|█████████▍| 323/341 [00:05<00:00, 53.49it/s, Epoch: 8, Batch: 324,Loss: -1.560,Avg.Loss: -1.203,LR: 3.29E-04]Training epoch 8:  95%|█████████▌| 324/341 [00:05<00:00, 53.89it/s, Epoch: 8, Batch: 324,Loss: -1.560,Avg.Loss: -1.203,LR: 3.29E-04]Training epoch 8:  95%|█████████▌| 324/341 [00:05<00:00, 53.89it/s, Epoch: 8, Batch: 325,Loss: -1.421,Avg.Loss: -1.203,LR: 3.29E-04]Training epoch 8:  95%|█████████▌| 325/341 [00:05<00:00, 53.89it/s, Epoch: 8, Batch: 326,Loss: -1.552,Avg.Loss: -1.204,LR: 3.29E-04]Training epoch 8:  96%|█████████▌| 326/341 [00:06<00:00, 53.89it/s, Epoch: 8, Batch: 327,Loss: -1.288,Avg.Loss: -1.205,LR: 3.29E-04]Training epoch 8:  96%|█████████▌| 327/341 [00:06<00:00, 53.89it/s, Epoch: 8, Batch: 328,Loss: -0.729,Avg.Loss: -1.203,LR: 3.29E-04]Training epoch 8:  96%|█████████▌| 328/341 [00:06<00:00, 53.89it/s, Epoch: 8, Batch: 329,Loss: -1.508,Avg.Loss: -1.204,LR: 3.29E-04]Training epoch 8:  96%|█████████▋| 329/341 [00:06<00:00, 53.89it/s, Epoch: 8, Batch: 330,Loss: -1.781,Avg.Loss: -1.206,LR: 3.28E-04]Training epoch 8:  97%|█████████▋| 330/341 [00:06<00:00, 53.49it/s, Epoch: 8, Batch: 330,Loss: -1.781,Avg.Loss: -1.206,LR: 3.28E-04]Training epoch 8:  97%|█████████▋| 330/341 [00:06<00:00, 53.49it/s, Epoch: 8, Batch: 331,Loss: -1.041,Avg.Loss: -1.205,LR: 3.28E-04]Training epoch 8:  97%|█████████▋| 331/341 [00:06<00:00, 53.49it/s, Epoch: 8, Batch: 332,Loss: -1.681,Avg.Loss: -1.207,LR: 3.28E-04]Training epoch 8:  97%|█████████▋| 332/341 [00:06<00:00, 53.49it/s, Epoch: 8, Batch: 333,Loss: -1.344,Avg.Loss: -1.207,LR: 3.28E-04]Training epoch 8:  98%|█████████▊| 333/341 [00:06<00:00, 53.49it/s, Epoch: 8, Batch: 334,Loss: -1.383,Avg.Loss: -1.208,LR: 3.28E-04]Training epoch 8:  98%|█████████▊| 334/341 [00:06<00:00, 53.49it/s, Epoch: 8, Batch: 335,Loss: -1.855,Avg.Loss: -1.210,LR: 3.28E-04]Training epoch 8:  98%|█████████▊| 335/341 [00:06<00:00, 53.49it/s, Epoch: 8, Batch: 336,Loss: -1.681,Avg.Loss: -1.211,LR: 3.28E-04]Training epoch 8:  99%|█████████▊| 336/341 [00:06<00:00, 53.83it/s, Epoch: 8, Batch: 336,Loss: -1.681,Avg.Loss: -1.211,LR: 3.28E-04]Training epoch 8:  99%|█████████▊| 336/341 [00:06<00:00, 53.83it/s, Epoch: 8, Batch: 337,Loss: -1.272,Avg.Loss: -1.211,LR: 3.28E-04]Training epoch 8:  99%|█████████▉| 337/341 [00:06<00:00, 53.83it/s, Epoch: 8, Batch: 338,Loss: -1.752,Avg.Loss: -1.213,LR: 3.28E-04]Training epoch 8:  99%|█████████▉| 338/341 [00:06<00:00, 53.83it/s, Epoch: 8, Batch: 339,Loss: -1.390,Avg.Loss: -1.213,LR: 3.27E-04]Training epoch 8:  99%|█████████▉| 339/341 [00:06<00:00, 53.83it/s, Epoch: 8, Batch: 340,Loss: -1.307,Avg.Loss: -1.214,LR: 3.27E-04]Training epoch 8: 100%|█████████▉| 340/341 [00:06<00:00, 53.83it/s, Epoch: 8, Batch: 341,Loss: -1.936,Avg.Loss: -1.216,LR: 3.27E-04]Training epoch 8: 100%|██████████| 341/341 [00:06<00:00, 54.40it/s, Epoch: 8, Batch: 341,Loss: -1.936,Avg.Loss: -1.216,LR: 3.27E-04]
Training epoch 9:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 9:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 9, Batch: 1,Loss: -1.420,Avg.Loss: -1.420,LR: 3.27E-04]Training epoch 9:   0%|          | 1/341 [00:00<00:10, 31.20it/s, Epoch: 9, Batch: 2,Loss: -1.235,Avg.Loss: -1.328,LR: 3.27E-04]Training epoch 9:   1%|          | 2/341 [00:00<00:07, 44.66it/s, Epoch: 9, Batch: 3,Loss: -1.837,Avg.Loss: -1.498,LR: 3.27E-04]Training epoch 9:   1%|          | 3/341 [00:00<00:06, 48.59it/s, Epoch: 9, Batch: 4,Loss: -1.688,Avg.Loss: -1.545,LR: 3.27E-04]Training epoch 9:   1%|          | 4/341 [00:00<00:06, 49.44it/s, Epoch: 9, Batch: 5,Loss: -1.003,Avg.Loss: -1.437,LR: 3.27E-04]Training epoch 9:   1%|▏         | 5/341 [00:00<00:06, 50.21it/s, Epoch: 9, Batch: 6,Loss: -1.787,Avg.Loss: -1.495,LR: 3.27E-04]Training epoch 9:   2%|▏         | 6/341 [00:00<00:06, 50.67it/s, Epoch: 9, Batch: 7,Loss: -1.320,Avg.Loss: -1.470,LR: 3.26E-04]Training epoch 9:   2%|▏         | 7/341 [00:00<00:05, 59.01it/s, Epoch: 9, Batch: 7,Loss: -1.320,Avg.Loss: -1.470,LR: 3.26E-04]Training epoch 9:   2%|▏         | 7/341 [00:00<00:05, 59.01it/s, Epoch: 9, Batch: 8,Loss: -1.126,Avg.Loss: -1.427,LR: 3.26E-04]Training epoch 9:   2%|▏         | 8/341 [00:00<00:05, 59.01it/s, Epoch: 9, Batch: 9,Loss: -1.786,Avg.Loss: -1.467,LR: 3.26E-04]Training epoch 9:   3%|▎         | 9/341 [00:00<00:05, 59.01it/s, Epoch: 9, Batch: 10,Loss: -1.211,Avg.Loss: -1.441,LR: 3.26E-04]Training epoch 9:   3%|▎         | 10/341 [00:00<00:05, 59.01it/s, Epoch: 9, Batch: 11,Loss: -0.834,Avg.Loss: -1.386,LR: 3.26E-04]Training epoch 9:   3%|▎         | 11/341 [00:00<00:05, 59.01it/s, Epoch: 9, Batch: 12,Loss: -1.373,Avg.Loss: -1.385,LR: 3.26E-04]Training epoch 9:   4%|▎         | 12/341 [00:00<00:05, 59.01it/s, Epoch: 9, Batch: 13,Loss: -1.449,Avg.Loss: -1.390,LR: 3.26E-04]Training epoch 9:   4%|▍         | 13/341 [00:00<00:05, 55.86it/s, Epoch: 9, Batch: 13,Loss: -1.449,Avg.Loss: -1.390,LR: 3.26E-04]Training epoch 9:   4%|▍         | 13/341 [00:00<00:05, 55.86it/s, Epoch: 9, Batch: 14,Loss: -1.122,Avg.Loss: -1.371,LR: 3.26E-04]Training epoch 9:   4%|▍         | 14/341 [00:00<00:05, 55.86it/s, Epoch: 9, Batch: 15,Loss: -1.597,Avg.Loss: -1.386,LR: 3.26E-04]Training epoch 9:   4%|▍         | 15/341 [00:00<00:05, 55.86it/s, Epoch: 9, Batch: 16,Loss: -0.989,Avg.Loss: -1.361,LR: 3.25E-04]Training epoch 9:   5%|▍         | 16/341 [00:00<00:05, 55.86it/s, Epoch: 9, Batch: 17,Loss: -1.154,Avg.Loss: -1.349,LR: 3.25E-04]Training epoch 9:   5%|▍         | 17/341 [00:00<00:05, 55.86it/s, Epoch: 9, Batch: 18,Loss: -1.640,Avg.Loss: -1.365,LR: 3.25E-04]Training epoch 9:   5%|▌         | 18/341 [00:00<00:05, 55.86it/s, Epoch: 9, Batch: 19,Loss: -1.696,Avg.Loss: -1.383,LR: 3.25E-04]Training epoch 9:   6%|▌         | 19/341 [00:00<00:05, 54.95it/s, Epoch: 9, Batch: 19,Loss: -1.696,Avg.Loss: -1.383,LR: 3.25E-04]Training epoch 9:   6%|▌         | 19/341 [00:00<00:05, 54.95it/s, Epoch: 9, Batch: 20,Loss: -1.409,Avg.Loss: -1.384,LR: 3.25E-04]Training epoch 9:   6%|▌         | 20/341 [00:00<00:05, 54.95it/s, Epoch: 9, Batch: 21,Loss: -1.586,Avg.Loss: -1.393,LR: 3.25E-04]Training epoch 9:   6%|▌         | 21/341 [00:00<00:05, 54.95it/s, Epoch: 9, Batch: 22,Loss: -1.501,Avg.Loss: -1.398,LR: 3.25E-04]Training epoch 9:   6%|▋         | 22/341 [00:00<00:05, 54.95it/s, Epoch: 9, Batch: 23,Loss: -1.192,Avg.Loss: -1.389,LR: 3.25E-04]Training epoch 9:   7%|▋         | 23/341 [00:00<00:05, 54.95it/s, Epoch: 9, Batch: 24,Loss: -1.842,Avg.Loss: -1.408,LR: 3.25E-04]Training epoch 9:   7%|▋         | 24/341 [00:00<00:05, 54.95it/s, Epoch: 9, Batch: 25,Loss: -1.368,Avg.Loss: -1.407,LR: 3.25E-04]Training epoch 9:   7%|▋         | 25/341 [00:00<00:05, 53.52it/s, Epoch: 9, Batch: 25,Loss: -1.368,Avg.Loss: -1.407,LR: 3.25E-04]Training epoch 9:   7%|▋         | 25/341 [00:00<00:05, 53.52it/s, Epoch: 9, Batch: 26,Loss: -0.738,Avg.Loss: -1.381,LR: 3.24E-04]Training epoch 9:   8%|▊         | 26/341 [00:00<00:05, 53.52it/s, Epoch: 9, Batch: 27,Loss: -1.276,Avg.Loss: -1.377,LR: 3.24E-04]Training epoch 9:   8%|▊         | 27/341 [00:00<00:05, 53.52it/s, Epoch: 9, Batch: 28,Loss: -1.603,Avg.Loss: -1.385,LR: 3.24E-04]Training epoch 9:   8%|▊         | 28/341 [00:00<00:05, 53.52it/s, Epoch: 9, Batch: 29,Loss: -1.538,Avg.Loss: -1.390,LR: 3.24E-04]Training epoch 9:   9%|▊         | 29/341 [00:00<00:05, 53.52it/s, Epoch: 9, Batch: 30,Loss: -1.757,Avg.Loss: -1.403,LR: 3.24E-04]Training epoch 9:   9%|▉         | 30/341 [00:00<00:05, 53.52it/s, Epoch: 9, Batch: 31,Loss: -1.578,Avg.Loss: -1.408,LR: 3.24E-04]Training epoch 9:   9%|▉         | 31/341 [00:00<00:05, 52.97it/s, Epoch: 9, Batch: 31,Loss: -1.578,Avg.Loss: -1.408,LR: 3.24E-04]Training epoch 9:   9%|▉         | 31/341 [00:00<00:05, 52.97it/s, Epoch: 9, Batch: 32,Loss: -1.088,Avg.Loss: -1.398,LR: 3.24E-04]Training epoch 9:   9%|▉         | 32/341 [00:00<00:05, 52.97it/s, Epoch: 9, Batch: 33,Loss: -1.712,Avg.Loss: -1.408,LR: 3.24E-04]Training epoch 9:  10%|▉         | 33/341 [00:00<00:05, 52.97it/s, Epoch: 9, Batch: 34,Loss: -1.696,Avg.Loss: -1.416,LR: 3.24E-04]Training epoch 9:  10%|▉         | 34/341 [00:00<00:05, 52.97it/s, Epoch: 9, Batch: 35,Loss: -1.241,Avg.Loss: -1.411,LR: 3.23E-04]Training epoch 9:  10%|█         | 35/341 [00:00<00:05, 52.97it/s, Epoch: 9, Batch: 36,Loss: -1.897,Avg.Loss: -1.425,LR: 3.23E-04]Training epoch 9:  11%|█         | 36/341 [00:00<00:05, 52.97it/s, Epoch: 9, Batch: 37,Loss: -1.488,Avg.Loss: -1.426,LR: 3.23E-04]Training epoch 9:  11%|█         | 37/341 [00:00<00:05, 53.62it/s, Epoch: 9, Batch: 37,Loss: -1.488,Avg.Loss: -1.426,LR: 3.23E-04]Training epoch 9:  11%|█         | 37/341 [00:00<00:05, 53.62it/s, Epoch: 9, Batch: 38,Loss: -0.858,Avg.Loss: -1.411,LR: 3.23E-04]Training epoch 9:  11%|█         | 38/341 [00:00<00:05, 53.62it/s, Epoch: 9, Batch: 39,Loss: -1.624,Avg.Loss: -1.417,LR: 3.23E-04]Training epoch 9:  11%|█▏        | 39/341 [00:00<00:05, 53.62it/s, Epoch: 9, Batch: 40,Loss: -1.563,Avg.Loss: -1.420,LR: 3.23E-04]Training epoch 9:  12%|█▏        | 40/341 [00:00<00:05, 53.62it/s, Epoch: 9, Batch: 41,Loss: -1.603,Avg.Loss: -1.425,LR: 3.23E-04]Training epoch 9:  12%|█▏        | 41/341 [00:00<00:05, 53.62it/s, Epoch: 9, Batch: 42,Loss: -2.055,Avg.Loss: -1.440,LR: 3.23E-04]Training epoch 9:  12%|█▏        | 42/341 [00:00<00:05, 53.62it/s, Epoch: 9, Batch: 43,Loss: -1.727,Avg.Loss: -1.447,LR: 3.23E-04]Training epoch 9:  13%|█▎        | 43/341 [00:00<00:05, 54.24it/s, Epoch: 9, Batch: 43,Loss: -1.727,Avg.Loss: -1.447,LR: 3.23E-04]Training epoch 9:  13%|█▎        | 43/341 [00:00<00:05, 54.24it/s, Epoch: 9, Batch: 44,Loss: -1.357,Avg.Loss: -1.445,LR: 3.22E-04]Training epoch 9:  13%|█▎        | 44/341 [00:00<00:05, 54.24it/s, Epoch: 9, Batch: 45,Loss: -1.507,Avg.Loss: -1.446,LR: 3.22E-04]Training epoch 9:  13%|█▎        | 45/341 [00:00<00:05, 54.24it/s, Epoch: 9, Batch: 46,Loss: -1.507,Avg.Loss: -1.447,LR: 3.22E-04]Training epoch 9:  13%|█▎        | 46/341 [00:00<00:05, 54.24it/s, Epoch: 9, Batch: 47,Loss: -1.201,Avg.Loss: -1.442,LR: 3.22E-04]Training epoch 9:  14%|█▍        | 47/341 [00:00<00:05, 54.24it/s, Epoch: 9, Batch: 48,Loss: -1.862,Avg.Loss: -1.451,LR: 3.22E-04]Training epoch 9:  14%|█▍        | 48/341 [00:00<00:05, 54.24it/s, Epoch: 9, Batch: 49,Loss: -1.318,Avg.Loss: -1.448,LR: 3.22E-04]Training epoch 9:  14%|█▍        | 49/341 [00:00<00:05, 54.13it/s, Epoch: 9, Batch: 49,Loss: -1.318,Avg.Loss: -1.448,LR: 3.22E-04]Training epoch 9:  14%|█▍        | 49/341 [00:00<00:05, 54.13it/s, Epoch: 9, Batch: 50,Loss: -1.398,Avg.Loss: -1.447,LR: 3.22E-04]Training epoch 9:  15%|█▍        | 50/341 [00:00<00:05, 54.13it/s, Epoch: 9, Batch: 51,Loss: -1.969,Avg.Loss: -1.457,LR: 3.22E-04]Training epoch 9:  15%|█▍        | 51/341 [00:00<00:05, 54.13it/s, Epoch: 9, Batch: 52,Loss: -1.349,Avg.Loss: -1.455,LR: 3.22E-04]Training epoch 9:  15%|█▌        | 52/341 [00:00<00:05, 54.13it/s, Epoch: 9, Batch: 53,Loss: -0.801,Avg.Loss: -1.443,LR: 3.21E-04]Training epoch 9:  16%|█▌        | 53/341 [00:00<00:05, 54.13it/s, Epoch: 9, Batch: 54,Loss: -1.212,Avg.Loss: -1.439,LR: 3.21E-04]Training epoch 9:  16%|█▌        | 54/341 [00:01<00:05, 54.13it/s, Epoch: 9, Batch: 55,Loss: -1.819,Avg.Loss: -1.446,LR: 3.21E-04]Training epoch 9:  16%|█▌        | 55/341 [00:01<00:05, 54.48it/s, Epoch: 9, Batch: 55,Loss: -1.819,Avg.Loss: -1.446,LR: 3.21E-04]Training epoch 9:  16%|█▌        | 55/341 [00:01<00:05, 54.48it/s, Epoch: 9, Batch: 56,Loss: -1.230,Avg.Loss: -1.442,LR: 3.21E-04]Training epoch 9:  16%|█▋        | 56/341 [00:01<00:05, 54.48it/s, Epoch: 9, Batch: 57,Loss: -1.701,Avg.Loss: -1.446,LR: 3.21E-04]Training epoch 9:  17%|█▋        | 57/341 [00:01<00:05, 54.48it/s, Epoch: 9, Batch: 58,Loss: -1.241,Avg.Loss: -1.443,LR: 3.21E-04]Training epoch 9:  17%|█▋        | 58/341 [00:01<00:05, 54.48it/s, Epoch: 9, Batch: 59,Loss: -1.005,Avg.Loss: -1.435,LR: 3.21E-04]Training epoch 9:  17%|█▋        | 59/341 [00:01<00:05, 54.48it/s, Epoch: 9, Batch: 60,Loss: -1.780,Avg.Loss: -1.441,LR: 3.21E-04]Training epoch 9:  18%|█▊        | 60/341 [00:01<00:05, 54.48it/s, Epoch: 9, Batch: 61,Loss: -1.199,Avg.Loss: -1.437,LR: 3.21E-04]Training epoch 9:  18%|█▊        | 61/341 [00:01<00:05, 54.37it/s, Epoch: 9, Batch: 61,Loss: -1.199,Avg.Loss: -1.437,LR: 3.21E-04]Training epoch 9:  18%|█▊        | 61/341 [00:01<00:05, 54.37it/s, Epoch: 9, Batch: 62,Loss: -0.991,Avg.Loss: -1.430,LR: 3.20E-04]Training epoch 9:  18%|█▊        | 62/341 [00:01<00:05, 54.37it/s, Epoch: 9, Batch: 63,Loss: -1.501,Avg.Loss: -1.431,LR: 3.20E-04]Training epoch 9:  18%|█▊        | 63/341 [00:01<00:05, 54.37it/s, Epoch: 9, Batch: 64,Loss: -1.933,Avg.Loss: -1.439,LR: 3.20E-04]Training epoch 9:  19%|█▉        | 64/341 [00:01<00:05, 54.37it/s, Epoch: 9, Batch: 65,Loss: -1.404,Avg.Loss: -1.438,LR: 3.20E-04]Training epoch 9:  19%|█▉        | 65/341 [00:01<00:05, 54.37it/s, Epoch: 9, Batch: 66,Loss: -1.776,Avg.Loss: -1.443,LR: 3.20E-04]Training epoch 9:  19%|█▉        | 66/341 [00:01<00:05, 54.37it/s, Epoch: 9, Batch: 67,Loss: -1.680,Avg.Loss: -1.447,LR: 3.20E-04]Training epoch 9:  20%|█▉        | 67/341 [00:01<00:04, 54.93it/s, Epoch: 9, Batch: 67,Loss: -1.680,Avg.Loss: -1.447,LR: 3.20E-04]Training epoch 9:  20%|█▉        | 67/341 [00:01<00:04, 54.93it/s, Epoch: 9, Batch: 68,Loss: -1.129,Avg.Loss: -1.442,LR: 3.20E-04]Training epoch 9:  20%|█▉        | 68/341 [00:01<00:04, 54.93it/s, Epoch: 9, Batch: 69,Loss: -1.933,Avg.Loss: -1.449,LR: 3.20E-04]Training epoch 9:  20%|██        | 69/341 [00:01<00:04, 54.93it/s, Epoch: 9, Batch: 70,Loss: -1.716,Avg.Loss: -1.453,LR: 3.20E-04]Training epoch 9:  21%|██        | 70/341 [00:01<00:04, 54.93it/s, Epoch: 9, Batch: 71,Loss: -1.183,Avg.Loss: -1.449,LR: 3.19E-04]Training epoch 9:  21%|██        | 71/341 [00:01<00:04, 54.93it/s, Epoch: 9, Batch: 72,Loss: -1.587,Avg.Loss: -1.451,LR: 3.19E-04]Training epoch 9:  21%|██        | 72/341 [00:01<00:04, 54.93it/s, Epoch: 9, Batch: 73,Loss: -1.606,Avg.Loss: -1.453,LR: 3.19E-04]Training epoch 9:  21%|██▏       | 73/341 [00:01<00:04, 54.87it/s, Epoch: 9, Batch: 73,Loss: -1.606,Avg.Loss: -1.453,LR: 3.19E-04]Training epoch 9:  21%|██▏       | 73/341 [00:01<00:04, 54.87it/s, Epoch: 9, Batch: 74,Loss: -0.939,Avg.Loss: -1.446,LR: 3.19E-04]Training epoch 9:  22%|██▏       | 74/341 [00:01<00:04, 54.87it/s, Epoch: 9, Batch: 75,Loss: -1.514,Avg.Loss: -1.447,LR: 3.19E-04]Training epoch 9:  22%|██▏       | 75/341 [00:01<00:04, 54.87it/s, Epoch: 9, Batch: 76,Loss: -1.538,Avg.Loss: -1.449,LR: 3.19E-04]Training epoch 9:  22%|██▏       | 76/341 [00:01<00:04, 54.87it/s, Epoch: 9, Batch: 77,Loss: -1.153,Avg.Loss: -1.445,LR: 3.19E-04]Training epoch 9:  23%|██▎       | 77/341 [00:01<00:04, 54.87it/s, Epoch: 9, Batch: 78,Loss: -1.909,Avg.Loss: -1.451,LR: 3.19E-04]Training epoch 9:  23%|██▎       | 78/341 [00:01<00:04, 54.87it/s, Epoch: 9, Batch: 79,Loss: -1.235,Avg.Loss: -1.448,LR: 3.19E-04]Training epoch 9:  23%|██▎       | 79/341 [00:01<00:04, 54.76it/s, Epoch: 9, Batch: 79,Loss: -1.235,Avg.Loss: -1.448,LR: 3.19E-04]Training epoch 9:  23%|██▎       | 79/341 [00:01<00:04, 54.76it/s, Epoch: 9, Batch: 80,Loss: -1.590,Avg.Loss: -1.450,LR: 3.18E-04]Training epoch 9:  23%|██▎       | 80/341 [00:01<00:04, 54.76it/s, Epoch: 9, Batch: 81,Loss: -1.797,Avg.Loss: -1.454,LR: 3.18E-04]Training epoch 9:  24%|██▍       | 81/341 [00:01<00:04, 54.76it/s, Epoch: 9, Batch: 82,Loss: -0.937,Avg.Loss: -1.448,LR: 3.18E-04]Training epoch 9:  24%|██▍       | 82/341 [00:01<00:04, 54.76it/s, Epoch: 9, Batch: 83,Loss: -1.086,Avg.Loss: -1.443,LR: 3.18E-04]Training epoch 9:  24%|██▍       | 83/341 [00:01<00:04, 54.76it/s, Epoch: 9, Batch: 84,Loss: -1.318,Avg.Loss: -1.442,LR: 3.18E-04]Training epoch 9:  25%|██▍       | 84/341 [00:01<00:04, 54.76it/s, Epoch: 9, Batch: 85,Loss: -1.734,Avg.Loss: -1.445,LR: 3.18E-04]Training epoch 9:  25%|██▍       | 85/341 [00:01<00:04, 55.09it/s, Epoch: 9, Batch: 85,Loss: -1.734,Avg.Loss: -1.445,LR: 3.18E-04]Training epoch 9:  25%|██▍       | 85/341 [00:01<00:04, 55.09it/s, Epoch: 9, Batch: 86,Loss: -1.319,Avg.Loss: -1.444,LR: 3.18E-04]Training epoch 9:  25%|██▌       | 86/341 [00:01<00:04, 55.09it/s, Epoch: 9, Batch: 87,Loss: -1.869,Avg.Loss: -1.449,LR: 3.18E-04]Training epoch 9:  26%|██▌       | 87/341 [00:01<00:04, 55.09it/s, Epoch: 9, Batch: 88,Loss: -1.498,Avg.Loss: -1.449,LR: 3.18E-04]Training epoch 9:  26%|██▌       | 88/341 [00:01<00:04, 55.09it/s, Epoch: 9, Batch: 89,Loss: -0.777,Avg.Loss: -1.442,LR: 3.17E-04]Training epoch 9:  26%|██▌       | 89/341 [00:01<00:04, 55.09it/s, Epoch: 9, Batch: 90,Loss: -1.379,Avg.Loss: -1.441,LR: 3.17E-04]Training epoch 9:  26%|██▋       | 90/341 [00:01<00:04, 55.09it/s, Epoch: 9, Batch: 91,Loss: -1.813,Avg.Loss: -1.445,LR: 3.17E-04]Training epoch 9:  27%|██▋       | 91/341 [00:01<00:04, 54.41it/s, Epoch: 9, Batch: 91,Loss: -1.813,Avg.Loss: -1.445,LR: 3.17E-04]Training epoch 9:  27%|██▋       | 91/341 [00:01<00:04, 54.41it/s, Epoch: 9, Batch: 92,Loss: -1.128,Avg.Loss: -1.442,LR: 3.17E-04]Training epoch 9:  27%|██▋       | 92/341 [00:01<00:04, 54.41it/s, Epoch: 9, Batch: 93,Loss: -1.858,Avg.Loss: -1.446,LR: 3.17E-04]Training epoch 9:  27%|██▋       | 93/341 [00:01<00:04, 54.41it/s, Epoch: 9, Batch: 94,Loss: -1.418,Avg.Loss: -1.446,LR: 3.17E-04]Training epoch 9:  28%|██▊       | 94/341 [00:01<00:04, 54.41it/s, Epoch: 9, Batch: 95,Loss: -1.103,Avg.Loss: -1.442,LR: 3.17E-04]Training epoch 9:  28%|██▊       | 95/341 [00:01<00:04, 54.41it/s, Epoch: 9, Batch: 96,Loss: -1.429,Avg.Loss: -1.442,LR: 3.17E-04]Training epoch 9:  28%|██▊       | 96/341 [00:01<00:04, 54.41it/s, Epoch: 9, Batch: 97,Loss: -1.589,Avg.Loss: -1.444,LR: 3.17E-04]Training epoch 9:  28%|██▊       | 97/341 [00:01<00:04, 52.68it/s, Epoch: 9, Batch: 97,Loss: -1.589,Avg.Loss: -1.444,LR: 3.17E-04]Training epoch 9:  28%|██▊       | 97/341 [00:01<00:04, 52.68it/s, Epoch: 9, Batch: 98,Loss: -1.477,Avg.Loss: -1.444,LR: 3.16E-04]Training epoch 9:  29%|██▊       | 98/341 [00:01<00:04, 52.68it/s, Epoch: 9, Batch: 99,Loss: -1.717,Avg.Loss: -1.447,LR: 3.16E-04]Training epoch 9:  29%|██▉       | 99/341 [00:01<00:04, 52.68it/s, Epoch: 9, Batch: 100,Loss: -1.314,Avg.Loss: -1.445,LR: 3.16E-04]Training epoch 9:  29%|██▉       | 100/341 [00:01<00:04, 52.68it/s, Epoch: 9, Batch: 101,Loss: -1.184,Avg.Loss: -1.443,LR: 3.16E-04]Training epoch 9:  30%|██▉       | 101/341 [00:01<00:04, 52.68it/s, Epoch: 9, Batch: 102,Loss: -1.596,Avg.Loss: -1.444,LR: 3.16E-04]Training epoch 9:  30%|██▉       | 102/341 [00:01<00:04, 52.68it/s, Epoch: 9, Batch: 103,Loss: -1.555,Avg.Loss: -1.445,LR: 3.16E-04]Training epoch 9:  30%|███       | 103/341 [00:01<00:04, 52.99it/s, Epoch: 9, Batch: 103,Loss: -1.555,Avg.Loss: -1.445,LR: 3.16E-04]Training epoch 9:  30%|███       | 103/341 [00:01<00:04, 52.99it/s, Epoch: 9, Batch: 104,Loss: -0.713,Avg.Loss: -1.438,LR: 3.16E-04]Training epoch 9:  30%|███       | 104/341 [00:01<00:04, 52.99it/s, Epoch: 9, Batch: 105,Loss: -1.242,Avg.Loss: -1.436,LR: 3.16E-04]Training epoch 9:  31%|███       | 105/341 [00:01<00:04, 52.99it/s, Epoch: 9, Batch: 106,Loss: -1.548,Avg.Loss: -1.437,LR: 3.16E-04]Training epoch 9:  31%|███       | 106/341 [00:01<00:04, 52.99it/s, Epoch: 9, Batch: 107,Loss: -1.592,Avg.Loss: -1.439,LR: 3.15E-04]Training epoch 9:  31%|███▏      | 107/341 [00:01<00:04, 52.99it/s, Epoch: 9, Batch: 108,Loss: -2.040,Avg.Loss: -1.445,LR: 3.15E-04]Training epoch 9:  32%|███▏      | 108/341 [00:02<00:04, 52.99it/s, Epoch: 9, Batch: 109,Loss: -1.565,Avg.Loss: -1.446,LR: 3.15E-04]Training epoch 9:  32%|███▏      | 109/341 [00:02<00:04, 53.74it/s, Epoch: 9, Batch: 109,Loss: -1.565,Avg.Loss: -1.446,LR: 3.15E-04]Training epoch 9:  32%|███▏      | 109/341 [00:02<00:04, 53.74it/s, Epoch: 9, Batch: 110,Loss: -1.154,Avg.Loss: -1.443,LR: 3.15E-04]Training epoch 9:  32%|███▏      | 110/341 [00:02<00:04, 53.74it/s, Epoch: 9, Batch: 111,Loss: -1.510,Avg.Loss: -1.444,LR: 3.15E-04]Training epoch 9:  33%|███▎      | 111/341 [00:02<00:04, 53.74it/s, Epoch: 9, Batch: 112,Loss: -1.692,Avg.Loss: -1.446,LR: 3.15E-04]Training epoch 9:  33%|███▎      | 112/341 [00:02<00:04, 53.74it/s, Epoch: 9, Batch: 113,Loss: -1.497,Avg.Loss: -1.446,LR: 3.15E-04]Training epoch 9:  33%|███▎      | 113/341 [00:02<00:04, 53.74it/s, Epoch: 9, Batch: 114,Loss: -1.884,Avg.Loss: -1.450,LR: 3.15E-04]Training epoch 9:  33%|███▎      | 114/341 [00:02<00:04, 53.74it/s, Epoch: 9, Batch: 115,Loss: -1.680,Avg.Loss: -1.452,LR: 3.15E-04]Training epoch 9:  34%|███▎      | 115/341 [00:02<00:04, 54.01it/s, Epoch: 9, Batch: 115,Loss: -1.680,Avg.Loss: -1.452,LR: 3.15E-04]Training epoch 9:  34%|███▎      | 115/341 [00:02<00:04, 54.01it/s, Epoch: 9, Batch: 116,Loss: -0.771,Avg.Loss: -1.446,LR: 3.14E-04]Training epoch 9:  34%|███▍      | 116/341 [00:02<00:04, 54.01it/s, Epoch: 9, Batch: 117,Loss: -1.641,Avg.Loss: -1.448,LR: 3.14E-04]Training epoch 9:  34%|███▍      | 117/341 [00:02<00:04, 54.01it/s, Epoch: 9, Batch: 118,Loss: -2.048,Avg.Loss: -1.453,LR: 3.14E-04]Training epoch 9:  35%|███▍      | 118/341 [00:02<00:04, 54.01it/s, Epoch: 9, Batch: 119,Loss: -1.263,Avg.Loss: -1.451,LR: 3.14E-04]Training epoch 9:  35%|███▍      | 119/341 [00:02<00:04, 54.01it/s, Epoch: 9, Batch: 120,Loss: -1.892,Avg.Loss: -1.455,LR: 3.14E-04]Training epoch 9:  35%|███▌      | 120/341 [00:02<00:04, 54.01it/s, Epoch: 9, Batch: 121,Loss: -1.814,Avg.Loss: -1.458,LR: 3.14E-04]Training epoch 9:  35%|███▌      | 121/341 [00:02<00:04, 54.12it/s, Epoch: 9, Batch: 121,Loss: -1.814,Avg.Loss: -1.458,LR: 3.14E-04]Training epoch 9:  35%|███▌      | 121/341 [00:02<00:04, 54.12it/s, Epoch: 9, Batch: 122,Loss: -1.620,Avg.Loss: -1.459,LR: 3.14E-04]Training epoch 9:  36%|███▌      | 122/341 [00:02<00:04, 54.12it/s, Epoch: 9, Batch: 123,Loss: -1.766,Avg.Loss: -1.462,LR: 3.14E-04]Training epoch 9:  36%|███▌      | 123/341 [00:02<00:04, 54.12it/s, Epoch: 9, Batch: 124,Loss: -1.677,Avg.Loss: -1.464,LR: 3.14E-04]Training epoch 9:  36%|███▋      | 124/341 [00:02<00:04, 54.12it/s, Epoch: 9, Batch: 125,Loss: -0.962,Avg.Loss: -1.460,LR: 3.13E-04]Training epoch 9:  37%|███▋      | 125/341 [00:02<00:03, 54.12it/s, Epoch: 9, Batch: 126,Loss: -1.667,Avg.Loss: -1.461,LR: 3.13E-04]Training epoch 9:  37%|███▋      | 126/341 [00:02<00:03, 54.12it/s, Epoch: 9, Batch: 127,Loss: -1.715,Avg.Loss: -1.463,LR: 3.13E-04]Training epoch 9:  37%|███▋      | 127/341 [00:02<00:03, 54.33it/s, Epoch: 9, Batch: 127,Loss: -1.715,Avg.Loss: -1.463,LR: 3.13E-04]Training epoch 9:  37%|███▋      | 127/341 [00:02<00:03, 54.33it/s, Epoch: 9, Batch: 128,Loss: -1.295,Avg.Loss: -1.462,LR: 3.13E-04]Training epoch 9:  38%|███▊      | 128/341 [00:02<00:03, 54.33it/s, Epoch: 9, Batch: 129,Loss: -1.681,Avg.Loss: -1.464,LR: 3.13E-04]Training epoch 9:  38%|███▊      | 129/341 [00:02<00:03, 54.33it/s, Epoch: 9, Batch: 130,Loss: -1.588,Avg.Loss: -1.465,LR: 3.13E-04]Training epoch 9:  38%|███▊      | 130/341 [00:02<00:03, 54.33it/s, Epoch: 9, Batch: 131,Loss: -1.492,Avg.Loss: -1.465,LR: 3.13E-04]Training epoch 9:  38%|███▊      | 131/341 [00:02<00:03, 54.33it/s, Epoch: 9, Batch: 132,Loss: -1.872,Avg.Loss: -1.468,LR: 3.13E-04]Training epoch 9:  39%|███▊      | 132/341 [00:02<00:03, 54.33it/s, Epoch: 9, Batch: 133,Loss: -1.421,Avg.Loss: -1.467,LR: 3.13E-04]Training epoch 9:  39%|███▉      | 133/341 [00:02<00:03, 54.43it/s, Epoch: 9, Batch: 133,Loss: -1.421,Avg.Loss: -1.467,LR: 3.13E-04]Training epoch 9:  39%|███▉      | 133/341 [00:02<00:03, 54.43it/s, Epoch: 9, Batch: 134,Loss: -0.854,Avg.Loss: -1.463,LR: 3.12E-04]Training epoch 9:  39%|███▉      | 134/341 [00:02<00:03, 54.43it/s, Epoch: 9, Batch: 135,Loss: -1.724,Avg.Loss: -1.465,LR: 3.12E-04]Training epoch 9:  40%|███▉      | 135/341 [00:02<00:03, 54.43it/s, Epoch: 9, Batch: 136,Loss: -1.543,Avg.Loss: -1.465,LR: 3.12E-04]Training epoch 9:  40%|███▉      | 136/341 [00:02<00:03, 54.43it/s, Epoch: 9, Batch: 137,Loss: -1.458,Avg.Loss: -1.465,LR: 3.12E-04]Training epoch 9:  40%|████      | 137/341 [00:02<00:03, 54.43it/s, Epoch: 9, Batch: 138,Loss: -1.523,Avg.Loss: -1.466,LR: 3.12E-04]Training epoch 9:  40%|████      | 138/341 [00:02<00:03, 54.43it/s, Epoch: 9, Batch: 139,Loss: -2.034,Avg.Loss: -1.470,LR: 3.12E-04]Training epoch 9:  41%|████      | 139/341 [00:02<00:03, 54.41it/s, Epoch: 9, Batch: 139,Loss: -2.034,Avg.Loss: -1.470,LR: 3.12E-04]Training epoch 9:  41%|████      | 139/341 [00:02<00:03, 54.41it/s, Epoch: 9, Batch: 140,Loss: -1.145,Avg.Loss: -1.468,LR: 3.12E-04]Training epoch 9:  41%|████      | 140/341 [00:02<00:03, 54.41it/s, Epoch: 9, Batch: 141,Loss: -1.516,Avg.Loss: -1.468,LR: 3.12E-04]Training epoch 9:  41%|████▏     | 141/341 [00:02<00:03, 54.41it/s, Epoch: 9, Batch: 142,Loss: -1.765,Avg.Loss: -1.470,LR: 3.12E-04]Training epoch 9:  42%|████▏     | 142/341 [00:02<00:03, 54.41it/s, Epoch: 9, Batch: 143,Loss: -1.392,Avg.Loss: -1.469,LR: 3.11E-04]Training epoch 9:  42%|████▏     | 143/341 [00:02<00:03, 54.41it/s, Epoch: 9, Batch: 144,Loss: -1.666,Avg.Loss: -1.471,LR: 3.11E-04]Training epoch 9:  42%|████▏     | 144/341 [00:02<00:03, 54.41it/s, Epoch: 9, Batch: 145,Loss: -1.137,Avg.Loss: -1.468,LR: 3.11E-04]Training epoch 9:  43%|████▎     | 145/341 [00:02<00:03, 54.35it/s, Epoch: 9, Batch: 145,Loss: -1.137,Avg.Loss: -1.468,LR: 3.11E-04]Training epoch 9:  43%|████▎     | 145/341 [00:02<00:03, 54.35it/s, Epoch: 9, Batch: 146,Loss: -0.917,Avg.Loss: -1.465,LR: 3.11E-04]Training epoch 9:  43%|████▎     | 146/341 [00:02<00:03, 54.35it/s, Epoch: 9, Batch: 147,Loss: -1.716,Avg.Loss: -1.466,LR: 3.11E-04]Training epoch 9:  43%|████▎     | 147/341 [00:02<00:03, 54.35it/s, Epoch: 9, Batch: 148,Loss: -1.609,Avg.Loss: -1.467,LR: 3.11E-04]Training epoch 9:  43%|████▎     | 148/341 [00:02<00:03, 54.35it/s, Epoch: 9, Batch: 149,Loss: -0.999,Avg.Loss: -1.464,LR: 3.11E-04]Training epoch 9:  44%|████▎     | 149/341 [00:02<00:03, 54.35it/s, Epoch: 9, Batch: 150,Loss: -1.716,Avg.Loss: -1.466,LR: 3.11E-04]Training epoch 9:  44%|████▍     | 150/341 [00:02<00:03, 54.35it/s, Epoch: 9, Batch: 151,Loss: -1.808,Avg.Loss: -1.468,LR: 3.11E-04]Training epoch 9:  44%|████▍     | 151/341 [00:02<00:03, 54.32it/s, Epoch: 9, Batch: 151,Loss: -1.808,Avg.Loss: -1.468,LR: 3.11E-04]Training epoch 9:  44%|████▍     | 151/341 [00:02<00:03, 54.32it/s, Epoch: 9, Batch: 152,Loss: -1.146,Avg.Loss: -1.466,LR: 3.10E-04]Training epoch 9:  45%|████▍     | 152/341 [00:02<00:03, 54.32it/s, Epoch: 9, Batch: 153,Loss: -1.909,Avg.Loss: -1.469,LR: 3.10E-04]Training epoch 9:  45%|████▍     | 153/341 [00:02<00:03, 54.32it/s, Epoch: 9, Batch: 154,Loss: -1.674,Avg.Loss: -1.470,LR: 3.10E-04]Training epoch 9:  45%|████▌     | 154/341 [00:02<00:03, 54.32it/s, Epoch: 9, Batch: 155,Loss: -0.742,Avg.Loss: -1.466,LR: 3.10E-04]Training epoch 9:  45%|████▌     | 155/341 [00:02<00:03, 54.32it/s, Epoch: 9, Batch: 156,Loss: -1.584,Avg.Loss: -1.466,LR: 3.10E-04]Training epoch 9:  46%|████▌     | 156/341 [00:02<00:03, 54.32it/s, Epoch: 9, Batch: 157,Loss: -1.332,Avg.Loss: -1.465,LR: 3.10E-04]Training epoch 9:  46%|████▌     | 157/341 [00:02<00:03, 54.45it/s, Epoch: 9, Batch: 157,Loss: -1.332,Avg.Loss: -1.465,LR: 3.10E-04]Training epoch 9:  46%|████▌     | 157/341 [00:02<00:03, 54.45it/s, Epoch: 9, Batch: 158,Loss: -1.424,Avg.Loss: -1.465,LR: 3.10E-04]Training epoch 9:  46%|████▋     | 158/341 [00:02<00:03, 54.45it/s, Epoch: 9, Batch: 159,Loss: -1.858,Avg.Loss: -1.468,LR: 3.10E-04]Training epoch 9:  47%|████▋     | 159/341 [00:02<00:03, 54.45it/s, Epoch: 9, Batch: 160,Loss: -1.708,Avg.Loss: -1.469,LR: 3.10E-04]Training epoch 9:  47%|████▋     | 160/341 [00:02<00:03, 54.45it/s, Epoch: 9, Batch: 161,Loss: -1.050,Avg.Loss: -1.467,LR: 3.09E-04]Training epoch 9:  47%|████▋     | 161/341 [00:02<00:03, 54.45it/s, Epoch: 9, Batch: 162,Loss: -1.499,Avg.Loss: -1.467,LR: 3.09E-04]Training epoch 9:  48%|████▊     | 162/341 [00:02<00:03, 54.45it/s, Epoch: 9, Batch: 163,Loss: -1.670,Avg.Loss: -1.468,LR: 3.09E-04]Training epoch 9:  48%|████▊     | 163/341 [00:02<00:03, 54.87it/s, Epoch: 9, Batch: 163,Loss: -1.670,Avg.Loss: -1.468,LR: 3.09E-04]Training epoch 9:  48%|████▊     | 163/341 [00:03<00:03, 54.87it/s, Epoch: 9, Batch: 164,Loss: -1.002,Avg.Loss: -1.465,LR: 3.09E-04]Training epoch 9:  48%|████▊     | 164/341 [00:03<00:03, 54.87it/s, Epoch: 9, Batch: 165,Loss: -1.592,Avg.Loss: -1.466,LR: 3.09E-04]Training epoch 9:  48%|████▊     | 165/341 [00:03<00:03, 54.87it/s, Epoch: 9, Batch: 166,Loss: -1.641,Avg.Loss: -1.467,LR: 3.09E-04]Training epoch 9:  49%|████▊     | 166/341 [00:03<00:03, 54.87it/s, Epoch: 9, Batch: 167,Loss: -1.017,Avg.Loss: -1.464,LR: 3.09E-04]Training epoch 9:  49%|████▉     | 167/341 [00:03<00:03, 54.87it/s, Epoch: 9, Batch: 168,Loss: -1.572,Avg.Loss: -1.465,LR: 3.09E-04]Training epoch 9:  49%|████▉     | 168/341 [00:03<00:03, 54.87it/s, Epoch: 9, Batch: 169,Loss: -1.649,Avg.Loss: -1.466,LR: 3.09E-04]Training epoch 9:  50%|████▉     | 169/341 [00:03<00:03, 54.61it/s, Epoch: 9, Batch: 169,Loss: -1.649,Avg.Loss: -1.466,LR: 3.09E-04]Training epoch 9:  50%|████▉     | 169/341 [00:03<00:03, 54.61it/s, Epoch: 9, Batch: 170,Loss: -1.476,Avg.Loss: -1.466,LR: 3.08E-04]Training epoch 9:  50%|████▉     | 170/341 [00:03<00:03, 54.61it/s, Epoch: 9, Batch: 171,Loss: -1.757,Avg.Loss: -1.468,LR: 3.08E-04]Training epoch 9:  50%|█████     | 171/341 [00:03<00:03, 54.61it/s, Epoch: 9, Batch: 172,Loss: -1.572,Avg.Loss: -1.468,LR: 3.08E-04]Training epoch 9:  50%|█████     | 172/341 [00:03<00:03, 54.61it/s, Epoch: 9, Batch: 173,Loss: -1.357,Avg.Loss: -1.468,LR: 3.08E-04]Training epoch 9:  51%|█████     | 173/341 [00:03<00:03, 54.61it/s, Epoch: 9, Batch: 174,Loss: -1.801,Avg.Loss: -1.470,LR: 3.08E-04]Training epoch 9:  51%|█████     | 174/341 [00:03<00:03, 54.61it/s, Epoch: 9, Batch: 175,Loss: -1.553,Avg.Loss: -1.470,LR: 3.08E-04]Training epoch 9:  51%|█████▏    | 175/341 [00:03<00:03, 54.56it/s, Epoch: 9, Batch: 175,Loss: -1.553,Avg.Loss: -1.470,LR: 3.08E-04]Training epoch 9:  51%|█████▏    | 175/341 [00:03<00:03, 54.56it/s, Epoch: 9, Batch: 176,Loss: -1.157,Avg.Loss: -1.468,LR: 3.08E-04]Training epoch 9:  52%|█████▏    | 176/341 [00:03<00:03, 54.56it/s, Epoch: 9, Batch: 177,Loss: -1.523,Avg.Loss: -1.469,LR: 3.08E-04]Training epoch 9:  52%|█████▏    | 177/341 [00:03<00:03, 54.56it/s, Epoch: 9, Batch: 178,Loss: -1.760,Avg.Loss: -1.470,LR: 3.08E-04]Training epoch 9:  52%|█████▏    | 178/341 [00:03<00:02, 54.56it/s, Epoch: 9, Batch: 179,Loss: -1.479,Avg.Loss: -1.470,LR: 3.07E-04]Training epoch 9:  52%|█████▏    | 179/341 [00:03<00:02, 54.56it/s, Epoch: 9, Batch: 180,Loss: -1.747,Avg.Loss: -1.472,LR: 3.07E-04]Training epoch 9:  53%|█████▎    | 180/341 [00:03<00:02, 54.56it/s, Epoch: 9, Batch: 181,Loss: -1.688,Avg.Loss: -1.473,LR: 3.07E-04]Training epoch 9:  53%|█████▎    | 181/341 [00:03<00:02, 54.66it/s, Epoch: 9, Batch: 181,Loss: -1.688,Avg.Loss: -1.473,LR: 3.07E-04]Training epoch 9:  53%|█████▎    | 181/341 [00:03<00:02, 54.66it/s, Epoch: 9, Batch: 182,Loss: -1.373,Avg.Loss: -1.473,LR: 3.07E-04]Training epoch 9:  53%|█████▎    | 182/341 [00:03<00:02, 54.66it/s, Epoch: 9, Batch: 183,Loss: -1.735,Avg.Loss: -1.474,LR: 3.07E-04]Training epoch 9:  54%|█████▎    | 183/341 [00:03<00:02, 54.66it/s, Epoch: 9, Batch: 184,Loss: -1.613,Avg.Loss: -1.475,LR: 3.07E-04]Training epoch 9:  54%|█████▍    | 184/341 [00:03<00:02, 54.66it/s, Epoch: 9, Batch: 185,Loss: -1.611,Avg.Loss: -1.475,LR: 3.07E-04]Training epoch 9:  54%|█████▍    | 185/341 [00:03<00:02, 54.66it/s, Epoch: 9, Batch: 186,Loss: -1.473,Avg.Loss: -1.475,LR: 3.07E-04]Training epoch 9:  55%|█████▍    | 186/341 [00:03<00:02, 54.66it/s, Epoch: 9, Batch: 187,Loss: -1.302,Avg.Loss: -1.475,LR: 3.07E-04]Training epoch 9:  55%|█████▍    | 187/341 [00:03<00:02, 54.85it/s, Epoch: 9, Batch: 187,Loss: -1.302,Avg.Loss: -1.475,LR: 3.07E-04]Training epoch 9:  55%|█████▍    | 187/341 [00:03<00:02, 54.85it/s, Epoch: 9, Batch: 188,Loss: -1.313,Avg.Loss: -1.474,LR: 3.06E-04]Training epoch 9:  55%|█████▌    | 188/341 [00:03<00:02, 54.85it/s, Epoch: 9, Batch: 189,Loss: -1.703,Avg.Loss: -1.475,LR: 3.06E-04]Training epoch 9:  55%|█████▌    | 189/341 [00:03<00:02, 54.85it/s, Epoch: 9, Batch: 190,Loss: -1.782,Avg.Loss: -1.477,LR: 3.06E-04]Training epoch 9:  56%|█████▌    | 190/341 [00:03<00:02, 54.85it/s, Epoch: 9, Batch: 191,Loss: -1.568,Avg.Loss: -1.477,LR: 3.06E-04]Training epoch 9:  56%|█████▌    | 191/341 [00:03<00:02, 54.85it/s, Epoch: 9, Batch: 192,Loss: -1.536,Avg.Loss: -1.477,LR: 3.06E-04]Training epoch 9:  56%|█████▋    | 192/341 [00:03<00:02, 54.85it/s, Epoch: 9, Batch: 193,Loss: -1.836,Avg.Loss: -1.479,LR: 3.06E-04]Training epoch 9:  57%|█████▋    | 193/341 [00:03<00:02, 54.57it/s, Epoch: 9, Batch: 193,Loss: -1.836,Avg.Loss: -1.479,LR: 3.06E-04]Training epoch 9:  57%|█████▋    | 193/341 [00:03<00:02, 54.57it/s, Epoch: 9, Batch: 194,Loss: -1.567,Avg.Loss: -1.480,LR: 3.06E-04]Training epoch 9:  57%|█████▋    | 194/341 [00:03<00:02, 54.57it/s, Epoch: 9, Batch: 195,Loss: -1.742,Avg.Loss: -1.481,LR: 3.06E-04]Training epoch 9:  57%|█████▋    | 195/341 [00:03<00:02, 54.57it/s, Epoch: 9, Batch: 196,Loss: -1.051,Avg.Loss: -1.479,LR: 3.06E-04]Training epoch 9:  57%|█████▋    | 196/341 [00:03<00:02, 54.57it/s, Epoch: 9, Batch: 197,Loss: -0.676,Avg.Loss: -1.475,LR: 3.05E-04]Training epoch 9:  58%|█████▊    | 197/341 [00:03<00:02, 54.57it/s, Epoch: 9, Batch: 198,Loss: -1.176,Avg.Loss: -1.473,LR: 3.05E-04]Training epoch 9:  58%|█████▊    | 198/341 [00:03<00:02, 54.57it/s, Epoch: 9, Batch: 199,Loss: -1.871,Avg.Loss: -1.475,LR: 3.05E-04]Training epoch 9:  58%|█████▊    | 199/341 [00:03<00:02, 53.99it/s, Epoch: 9, Batch: 199,Loss: -1.871,Avg.Loss: -1.475,LR: 3.05E-04]Training epoch 9:  58%|█████▊    | 199/341 [00:03<00:02, 53.99it/s, Epoch: 9, Batch: 200,Loss: -1.528,Avg.Loss: -1.475,LR: 3.05E-04]Training epoch 9:  59%|█████▊    | 200/341 [00:03<00:02, 53.99it/s, Epoch: 9, Batch: 201,Loss: -1.368,Avg.Loss: -1.475,LR: 3.05E-04]Training epoch 9:  59%|█████▉    | 201/341 [00:03<00:02, 53.99it/s, Epoch: 9, Batch: 202,Loss: -1.365,Avg.Loss: -1.474,LR: 3.05E-04]Training epoch 9:  59%|█████▉    | 202/341 [00:03<00:02, 53.99it/s, Epoch: 9, Batch: 203,Loss: -0.821,Avg.Loss: -1.471,LR: 3.05E-04]Training epoch 9:  60%|█████▉    | 203/341 [00:03<00:02, 53.99it/s, Epoch: 9, Batch: 204,Loss: -1.910,Avg.Loss: -1.473,LR: 3.05E-04]Training epoch 9:  60%|█████▉    | 204/341 [00:03<00:02, 53.99it/s, Epoch: 9, Batch: 205,Loss: -1.369,Avg.Loss: -1.473,LR: 3.04E-04]Training epoch 9:  60%|██████    | 205/341 [00:03<00:02, 54.61it/s, Epoch: 9, Batch: 205,Loss: -1.369,Avg.Loss: -1.473,LR: 3.04E-04]Training epoch 9:  60%|██████    | 205/341 [00:03<00:02, 54.61it/s, Epoch: 9, Batch: 206,Loss: -0.961,Avg.Loss: -1.470,LR: 3.04E-04]Training epoch 9:  60%|██████    | 206/341 [00:03<00:02, 54.61it/s, Epoch: 9, Batch: 207,Loss: -1.541,Avg.Loss: -1.471,LR: 3.04E-04]Training epoch 9:  61%|██████    | 207/341 [00:03<00:02, 54.61it/s, Epoch: 9, Batch: 208,Loss: -1.553,Avg.Loss: -1.471,LR: 3.04E-04]Training epoch 9:  61%|██████    | 208/341 [00:03<00:02, 54.61it/s, Epoch: 9, Batch: 209,Loss: -1.124,Avg.Loss: -1.469,LR: 3.04E-04]Training epoch 9:  61%|██████▏   | 209/341 [00:03<00:02, 54.61it/s, Epoch: 9, Batch: 210,Loss: -1.259,Avg.Loss: -1.468,LR: 3.04E-04]Training epoch 9:  62%|██████▏   | 210/341 [00:03<00:02, 54.61it/s, Epoch: 9, Batch: 211,Loss: -0.999,Avg.Loss: -1.466,LR: 3.04E-04]Training epoch 9:  62%|██████▏   | 211/341 [00:03<00:02, 54.80it/s, Epoch: 9, Batch: 211,Loss: -0.999,Avg.Loss: -1.466,LR: 3.04E-04]Training epoch 9:  62%|██████▏   | 211/341 [00:03<00:02, 54.80it/s, Epoch: 9, Batch: 212,Loss: -0.734,Avg.Loss: -1.463,LR: 3.04E-04]Training epoch 9:  62%|██████▏   | 212/341 [00:03<00:02, 54.80it/s, Epoch: 9, Batch: 213,Loss: -1.056,Avg.Loss: -1.461,LR: 3.04E-04]Training epoch 9:  62%|██████▏   | 213/341 [00:03<00:02, 54.80it/s, Epoch: 9, Batch: 214,Loss: -1.855,Avg.Loss: -1.463,LR: 3.03E-04]Training epoch 9:  63%|██████▎   | 214/341 [00:03<00:02, 54.80it/s, Epoch: 9, Batch: 215,Loss: -1.552,Avg.Loss: -1.463,LR: 3.03E-04]Training epoch 9:  63%|██████▎   | 215/341 [00:03<00:02, 54.80it/s, Epoch: 9, Batch: 216,Loss: -1.798,Avg.Loss: -1.465,LR: 3.03E-04]Training epoch 9:  63%|██████▎   | 216/341 [00:03<00:02, 54.80it/s, Epoch: 9, Batch: 217,Loss: -1.761,Avg.Loss: -1.466,LR: 3.03E-04]Training epoch 9:  64%|██████▎   | 217/341 [00:03<00:02, 54.50it/s, Epoch: 9, Batch: 217,Loss: -1.761,Avg.Loss: -1.466,LR: 3.03E-04]Training epoch 9:  64%|██████▎   | 217/341 [00:04<00:02, 54.50it/s, Epoch: 9, Batch: 218,Loss: -1.627,Avg.Loss: -1.467,LR: 3.03E-04]Training epoch 9:  64%|██████▍   | 218/341 [00:04<00:02, 54.50it/s, Epoch: 9, Batch: 219,Loss: -1.666,Avg.Loss: -1.468,LR: 3.03E-04]Training epoch 9:  64%|██████▍   | 219/341 [00:04<00:02, 54.50it/s, Epoch: 9, Batch: 220,Loss: -1.756,Avg.Loss: -1.469,LR: 3.03E-04]Training epoch 9:  65%|██████▍   | 220/341 [00:04<00:02, 54.50it/s, Epoch: 9, Batch: 221,Loss: -1.679,Avg.Loss: -1.470,LR: 3.03E-04]Training epoch 9:  65%|██████▍   | 221/341 [00:04<00:02, 54.50it/s, Epoch: 9, Batch: 222,Loss: -2.000,Avg.Loss: -1.472,LR: 3.03E-04]Training epoch 9:  65%|██████▌   | 222/341 [00:04<00:02, 54.50it/s, Epoch: 9, Batch: 223,Loss: -1.807,Avg.Loss: -1.474,LR: 3.02E-04]Training epoch 9:  65%|██████▌   | 223/341 [00:04<00:02, 54.84it/s, Epoch: 9, Batch: 223,Loss: -1.807,Avg.Loss: -1.474,LR: 3.02E-04]Training epoch 9:  65%|██████▌   | 223/341 [00:04<00:02, 54.84it/s, Epoch: 9, Batch: 224,Loss: -1.154,Avg.Loss: -1.472,LR: 3.02E-04]Training epoch 9:  66%|██████▌   | 224/341 [00:04<00:02, 54.84it/s, Epoch: 9, Batch: 225,Loss: -1.231,Avg.Loss: -1.471,LR: 3.02E-04]Training epoch 9:  66%|██████▌   | 225/341 [00:04<00:02, 54.84it/s, Epoch: 9, Batch: 226,Loss: -1.301,Avg.Loss: -1.471,LR: 3.02E-04]Training epoch 9:  66%|██████▋   | 226/341 [00:04<00:02, 54.84it/s, Epoch: 9, Batch: 227,Loss: -1.763,Avg.Loss: -1.472,LR: 3.02E-04]Training epoch 9:  67%|██████▋   | 227/341 [00:04<00:02, 54.84it/s, Epoch: 9, Batch: 228,Loss: -1.186,Avg.Loss: -1.471,LR: 3.02E-04]Training epoch 9:  67%|██████▋   | 228/341 [00:04<00:02, 54.84it/s, Epoch: 9, Batch: 229,Loss: -1.423,Avg.Loss: -1.470,LR: 3.02E-04]Training epoch 9:  67%|██████▋   | 229/341 [00:04<00:02, 54.86it/s, Epoch: 9, Batch: 229,Loss: -1.423,Avg.Loss: -1.470,LR: 3.02E-04]Training epoch 9:  67%|██████▋   | 229/341 [00:04<00:02, 54.86it/s, Epoch: 9, Batch: 230,Loss: -1.254,Avg.Loss: -1.469,LR: 3.02E-04]Training epoch 9:  67%|██████▋   | 230/341 [00:04<00:02, 54.86it/s, Epoch: 9, Batch: 231,Loss: -1.472,Avg.Loss: -1.469,LR: 3.02E-04]Training epoch 9:  68%|██████▊   | 231/341 [00:04<00:02, 54.86it/s, Epoch: 9, Batch: 232,Loss: -1.981,Avg.Loss: -1.472,LR: 3.01E-04]Training epoch 9:  68%|██████▊   | 232/341 [00:04<00:01, 54.86it/s, Epoch: 9, Batch: 233,Loss: -0.336,Avg.Loss: -1.467,LR: 3.01E-04]Training epoch 9:  68%|██████▊   | 233/341 [00:04<00:01, 54.86it/s, Epoch: 9, Batch: 234,Loss: 1.146,Avg.Loss: -1.456,LR: 3.01E-04] Training epoch 9:  69%|██████▊   | 234/341 [00:04<00:01, 54.86it/s, Epoch: 9, Batch: 235,Loss: 0.649,Avg.Loss: -1.447,LR: 3.01E-04]Training epoch 9:  69%|██████▉   | 235/341 [00:04<00:01, 56.18it/s, Epoch: 9, Batch: 235,Loss: 0.649,Avg.Loss: -1.447,LR: 3.01E-04]Training epoch 9:  69%|██████▉   | 235/341 [00:04<00:01, 56.18it/s, Epoch: 9, Batch: 236,Loss: 2.476,Avg.Loss: -1.430,LR: 3.01E-04]Training epoch 9:  69%|██████▉   | 236/341 [00:04<00:01, 56.18it/s, Epoch: 9, Batch: 237,Loss: 0.320,Avg.Loss: -1.423,LR: 3.01E-04]Training epoch 9:  70%|██████▉   | 237/341 [00:04<00:01, 56.18it/s, Epoch: 9, Batch: 238,Loss: 0.657,Avg.Loss: -1.414,LR: 3.01E-04]Training epoch 9:  70%|██████▉   | 238/341 [00:04<00:01, 56.18it/s, Epoch: 9, Batch: 239,Loss: 0.905,Avg.Loss: -1.404,LR: 3.01E-04]Training epoch 9:  70%|███████   | 239/341 [00:04<00:01, 56.18it/s, Epoch: 9, Batch: 240,Loss: -1.377,Avg.Loss: -1.404,LR: 3.01E-04]Training epoch 9:  70%|███████   | 240/341 [00:04<00:01, 56.18it/s, Epoch: 9, Batch: 241,Loss: -0.681,Avg.Loss: -1.401,LR: 3.00E-04]Training epoch 9:  71%|███████   | 241/341 [00:04<00:01, 55.53it/s, Epoch: 9, Batch: 241,Loss: -0.681,Avg.Loss: -1.401,LR: 3.00E-04]Training epoch 9:  71%|███████   | 241/341 [00:04<00:01, 55.53it/s, Epoch: 9, Batch: 242,Loss: 1.458,Avg.Loss: -1.389,LR: 3.00E-04] Training epoch 9:  71%|███████   | 242/341 [00:04<00:01, 55.53it/s, Epoch: 9, Batch: 243,Loss: 3.112,Avg.Loss: -1.371,LR: 3.00E-04]Training epoch 9:  71%|███████▏  | 243/341 [00:04<00:01, 55.53it/s, Epoch: 9, Batch: 244,Loss: 0.595,Avg.Loss: -1.363,LR: 3.00E-04]Training epoch 9:  72%|███████▏  | 244/341 [00:04<00:01, 55.53it/s, Epoch: 9, Batch: 245,Loss: -0.683,Avg.Loss: -1.360,LR: 3.00E-04]Training epoch 9:  72%|███████▏  | 245/341 [00:04<00:01, 55.53it/s, Epoch: 9, Batch: 246,Loss: -0.976,Avg.Loss: -1.358,LR: 3.00E-04]Training epoch 9:  72%|███████▏  | 246/341 [00:04<00:01, 55.53it/s, Epoch: 9, Batch: 247,Loss: -1.395,Avg.Loss: -1.358,LR: 3.00E-04]Training epoch 9:  72%|███████▏  | 247/341 [00:04<00:01, 54.53it/s, Epoch: 9, Batch: 247,Loss: -1.395,Avg.Loss: -1.358,LR: 3.00E-04]Training epoch 9:  72%|███████▏  | 247/341 [00:04<00:01, 54.53it/s, Epoch: 9, Batch: 248,Loss: -1.062,Avg.Loss: -1.357,LR: 3.00E-04]Training epoch 9:  73%|███████▎  | 248/341 [00:04<00:01, 54.53it/s, Epoch: 9, Batch: 249,Loss: -1.011,Avg.Loss: -1.356,LR: 3.00E-04]Training epoch 9:  73%|███████▎  | 249/341 [00:04<00:01, 54.53it/s, Epoch: 9, Batch: 250,Loss: -0.966,Avg.Loss: -1.354,LR: 2.99E-04]Training epoch 9:  73%|███████▎  | 250/341 [00:04<00:01, 54.53it/s, Epoch: 9, Batch: 251,Loss: -0.980,Avg.Loss: -1.353,LR: 2.99E-04]Training epoch 9:  74%|███████▎  | 251/341 [00:04<00:01, 54.53it/s, Epoch: 9, Batch: 252,Loss: 0.761,Avg.Loss: -1.344,LR: 2.99E-04] Training epoch 9:  74%|███████▍  | 252/341 [00:04<00:01, 54.53it/s, Epoch: 9, Batch: 253,Loss: -0.877,Avg.Loss: -1.343,LR: 2.99E-04]Training epoch 9:  74%|███████▍  | 253/341 [00:04<00:01, 54.10it/s, Epoch: 9, Batch: 253,Loss: -0.877,Avg.Loss: -1.343,LR: 2.99E-04]Training epoch 9:  74%|███████▍  | 253/341 [00:04<00:01, 54.10it/s, Epoch: 9, Batch: 254,Loss: -0.545,Avg.Loss: -1.339,LR: 2.99E-04]Training epoch 9:  74%|███████▍  | 254/341 [00:04<00:01, 54.10it/s, Epoch: 9, Batch: 255,Loss: -0.418,Avg.Loss: -1.336,LR: 2.99E-04]Training epoch 9:  75%|███████▍  | 255/341 [00:04<00:01, 54.10it/s, Epoch: 9, Batch: 256,Loss: -0.746,Avg.Loss: -1.334,LR: 2.99E-04]Training epoch 9:  75%|███████▌  | 256/341 [00:04<00:01, 54.10it/s, Epoch: 9, Batch: 257,Loss: -1.667,Avg.Loss: -1.335,LR: 2.99E-04]Training epoch 9:  75%|███████▌  | 257/341 [00:04<00:01, 54.10it/s, Epoch: 9, Batch: 258,Loss: -0.909,Avg.Loss: -1.333,LR: 2.99E-04]Training epoch 9:  76%|███████▌  | 258/341 [00:04<00:01, 54.10it/s, Epoch: 9, Batch: 259,Loss: -0.427,Avg.Loss: -1.330,LR: 2.98E-04]Training epoch 9:  76%|███████▌  | 259/341 [00:04<00:01, 53.82it/s, Epoch: 9, Batch: 259,Loss: -0.427,Avg.Loss: -1.330,LR: 2.98E-04]Training epoch 9:  76%|███████▌  | 259/341 [00:04<00:01, 53.82it/s, Epoch: 9, Batch: 260,Loss: -0.283,Avg.Loss: -1.326,LR: 2.98E-04]Training epoch 9:  76%|███████▌  | 260/341 [00:04<00:01, 53.82it/s, Epoch: 9, Batch: 261,Loss: -0.494,Avg.Loss: -1.322,LR: 2.98E-04]Training epoch 9:  77%|███████▋  | 261/341 [00:04<00:01, 53.82it/s, Epoch: 9, Batch: 262,Loss: -0.852,Avg.Loss: -1.321,LR: 2.98E-04]Training epoch 9:  77%|███████▋  | 262/341 [00:04<00:01, 53.82it/s, Epoch: 9, Batch: 263,Loss: -0.116,Avg.Loss: -1.316,LR: 2.98E-04]Training epoch 9:  77%|███████▋  | 263/341 [00:04<00:01, 53.82it/s, Epoch: 9, Batch: 264,Loss: -0.986,Avg.Loss: -1.315,LR: 2.98E-04]Training epoch 9:  77%|███████▋  | 264/341 [00:04<00:01, 53.82it/s, Epoch: 9, Batch: 265,Loss: -1.359,Avg.Loss: -1.315,LR: 2.98E-04]Training epoch 9:  78%|███████▊  | 265/341 [00:04<00:01, 53.51it/s, Epoch: 9, Batch: 265,Loss: -1.359,Avg.Loss: -1.315,LR: 2.98E-04]Training epoch 9:  78%|███████▊  | 265/341 [00:04<00:01, 53.51it/s, Epoch: 9, Batch: 266,Loss: -0.868,Avg.Loss: -1.313,LR: 2.98E-04]Training epoch 9:  78%|███████▊  | 266/341 [00:04<00:01, 53.51it/s, Epoch: 9, Batch: 267,Loss: 0.424,Avg.Loss: -1.307,LR: 2.98E-04] Training epoch 9:  78%|███████▊  | 267/341 [00:04<00:01, 53.51it/s, Epoch: 9, Batch: 268,Loss: 0.091,Avg.Loss: -1.302,LR: 2.97E-04]Training epoch 9:  79%|███████▊  | 268/341 [00:04<00:01, 53.51it/s, Epoch: 9, Batch: 269,Loss: -1.364,Avg.Loss: -1.302,LR: 2.97E-04]Training epoch 9:  79%|███████▉  | 269/341 [00:04<00:01, 53.51it/s, Epoch: 9, Batch: 270,Loss: -1.206,Avg.Loss: -1.302,LR: 2.97E-04]Training epoch 9:  79%|███████▉  | 270/341 [00:04<00:01, 53.51it/s, Epoch: 9, Batch: 271,Loss: -0.708,Avg.Loss: -1.299,LR: 2.97E-04]Training epoch 9:  79%|███████▉  | 271/341 [00:04<00:01, 53.66it/s, Epoch: 9, Batch: 271,Loss: -0.708,Avg.Loss: -1.299,LR: 2.97E-04]Training epoch 9:  79%|███████▉  | 271/341 [00:05<00:01, 53.66it/s, Epoch: 9, Batch: 272,Loss: -0.774,Avg.Loss: -1.297,LR: 2.97E-04]Training epoch 9:  80%|███████▉  | 272/341 [00:05<00:01, 53.66it/s, Epoch: 9, Batch: 273,Loss: -1.640,Avg.Loss: -1.299,LR: 2.97E-04]Training epoch 9:  80%|████████  | 273/341 [00:05<00:01, 53.66it/s, Epoch: 9, Batch: 274,Loss: -1.118,Avg.Loss: -1.298,LR: 2.97E-04]Training epoch 9:  80%|████████  | 274/341 [00:05<00:01, 53.66it/s, Epoch: 9, Batch: 275,Loss: -0.602,Avg.Loss: -1.295,LR: 2.97E-04]Training epoch 9:  81%|████████  | 275/341 [00:05<00:01, 53.66it/s, Epoch: 9, Batch: 276,Loss: -0.548,Avg.Loss: -1.293,LR: 2.96E-04]Training epoch 9:  81%|████████  | 276/341 [00:05<00:01, 53.66it/s, Epoch: 9, Batch: 277,Loss: -1.741,Avg.Loss: -1.294,LR: 2.96E-04]Training epoch 9:  81%|████████  | 277/341 [00:05<00:01, 53.78it/s, Epoch: 9, Batch: 277,Loss: -1.741,Avg.Loss: -1.294,LR: 2.96E-04]Training epoch 9:  81%|████████  | 277/341 [00:05<00:01, 53.78it/s, Epoch: 9, Batch: 278,Loss: -1.123,Avg.Loss: -1.294,LR: 2.96E-04]Training epoch 9:  82%|████████▏ | 278/341 [00:05<00:01, 53.78it/s, Epoch: 9, Batch: 279,Loss: -0.361,Avg.Loss: -1.290,LR: 2.96E-04]Training epoch 9:  82%|████████▏ | 279/341 [00:05<00:01, 53.78it/s, Epoch: 9, Batch: 280,Loss: -0.905,Avg.Loss: -1.289,LR: 2.96E-04]Training epoch 9:  82%|████████▏ | 280/341 [00:05<00:01, 53.78it/s, Epoch: 9, Batch: 281,Loss: -1.484,Avg.Loss: -1.290,LR: 2.96E-04]Training epoch 9:  82%|████████▏ | 281/341 [00:05<00:01, 53.78it/s, Epoch: 9, Batch: 282,Loss: -1.114,Avg.Loss: -1.289,LR: 2.96E-04]Training epoch 9:  83%|████████▎ | 282/341 [00:05<00:01, 53.78it/s, Epoch: 9, Batch: 283,Loss: -0.043,Avg.Loss: -1.285,LR: 2.96E-04]Training epoch 9:  83%|████████▎ | 283/341 [00:05<00:01, 54.33it/s, Epoch: 9, Batch: 283,Loss: -0.043,Avg.Loss: -1.285,LR: 2.96E-04]Training epoch 9:  83%|████████▎ | 283/341 [00:05<00:01, 54.33it/s, Epoch: 9, Batch: 284,Loss: -0.390,Avg.Loss: -1.282,LR: 2.96E-04]Training epoch 9:  83%|████████▎ | 284/341 [00:05<00:01, 54.33it/s, Epoch: 9, Batch: 285,Loss: -0.995,Avg.Loss: -1.281,LR: 2.95E-04]Training epoch 9:  84%|████████▎ | 285/341 [00:05<00:01, 54.33it/s, Epoch: 9, Batch: 286,Loss: -1.390,Avg.Loss: -1.281,LR: 2.95E-04]Training epoch 9:  84%|████████▍ | 286/341 [00:05<00:01, 54.33it/s, Epoch: 9, Batch: 287,Loss: -1.143,Avg.Loss: -1.280,LR: 2.95E-04]Training epoch 9:  84%|████████▍ | 287/341 [00:05<00:00, 54.33it/s, Epoch: 9, Batch: 288,Loss: -1.440,Avg.Loss: -1.281,LR: 2.95E-04]Training epoch 9:  84%|████████▍ | 288/341 [00:05<00:00, 54.33it/s, Epoch: 9, Batch: 289,Loss: -1.691,Avg.Loss: -1.282,LR: 2.95E-04]Training epoch 9:  85%|████████▍ | 289/341 [00:05<00:00, 54.46it/s, Epoch: 9, Batch: 289,Loss: -1.691,Avg.Loss: -1.282,LR: 2.95E-04]Training epoch 9:  85%|████████▍ | 289/341 [00:05<00:00, 54.46it/s, Epoch: 9, Batch: 290,Loss: -1.119,Avg.Loss: -1.282,LR: 2.95E-04]Training epoch 9:  85%|████████▌ | 290/341 [00:05<00:00, 54.46it/s, Epoch: 9, Batch: 291,Loss: -1.317,Avg.Loss: -1.282,LR: 2.95E-04]Training epoch 9:  85%|████████▌ | 291/341 [00:05<00:00, 54.46it/s, Epoch: 9, Batch: 292,Loss: -1.197,Avg.Loss: -1.282,LR: 2.95E-04]Training epoch 9:  86%|████████▌ | 292/341 [00:05<00:00, 54.46it/s, Epoch: 9, Batch: 293,Loss: -1.542,Avg.Loss: -1.283,LR: 2.95E-04]Training epoch 9:  86%|████████▌ | 293/341 [00:05<00:00, 54.46it/s, Epoch: 9, Batch: 294,Loss: -1.237,Avg.Loss: -1.282,LR: 2.94E-04]Training epoch 9:  86%|████████▌ | 294/341 [00:05<00:00, 54.46it/s, Epoch: 9, Batch: 295,Loss: -0.102,Avg.Loss: -1.278,LR: 2.94E-04]Training epoch 9:  87%|████████▋ | 295/341 [00:05<00:00, 54.84it/s, Epoch: 9, Batch: 295,Loss: -0.102,Avg.Loss: -1.278,LR: 2.94E-04]Training epoch 9:  87%|████████▋ | 295/341 [00:05<00:00, 54.84it/s, Epoch: 9, Batch: 296,Loss: -0.567,Avg.Loss: -1.276,LR: 2.94E-04]Training epoch 9:  87%|████████▋ | 296/341 [00:05<00:00, 54.84it/s, Epoch: 9, Batch: 297,Loss: -1.310,Avg.Loss: -1.276,LR: 2.94E-04]Training epoch 9:  87%|████████▋ | 297/341 [00:05<00:00, 54.84it/s, Epoch: 9, Batch: 298,Loss: -0.652,Avg.Loss: -1.274,LR: 2.94E-04]Training epoch 9:  87%|████████▋ | 298/341 [00:05<00:00, 54.84it/s, Epoch: 9, Batch: 299,Loss: -0.373,Avg.Loss: -1.271,LR: 2.94E-04]Training epoch 9:  88%|████████▊ | 299/341 [00:05<00:00, 54.84it/s, Epoch: 9, Batch: 300,Loss: -0.789,Avg.Loss: -1.269,LR: 2.94E-04]Training epoch 9:  88%|████████▊ | 300/341 [00:05<00:00, 54.84it/s, Epoch: 9, Batch: 301,Loss: -1.411,Avg.Loss: -1.270,LR: 2.94E-04]Training epoch 9:  88%|████████▊ | 301/341 [00:05<00:00, 54.68it/s, Epoch: 9, Batch: 301,Loss: -1.411,Avg.Loss: -1.270,LR: 2.94E-04]Training epoch 9:  88%|████████▊ | 301/341 [00:05<00:00, 54.68it/s, Epoch: 9, Batch: 302,Loss: -1.558,Avg.Loss: -1.271,LR: 2.94E-04]Training epoch 9:  89%|████████▊ | 302/341 [00:05<00:00, 54.68it/s, Epoch: 9, Batch: 303,Loss: -0.943,Avg.Loss: -1.270,LR: 2.93E-04]Training epoch 9:  89%|████████▉ | 303/341 [00:05<00:00, 54.68it/s, Epoch: 9, Batch: 304,Loss: -1.229,Avg.Loss: -1.270,LR: 2.93E-04]Training epoch 9:  89%|████████▉ | 304/341 [00:05<00:00, 54.68it/s, Epoch: 9, Batch: 305,Loss: -1.694,Avg.Loss: -1.271,LR: 2.93E-04]Training epoch 9:  89%|████████▉ | 305/341 [00:05<00:00, 54.68it/s, Epoch: 9, Batch: 306,Loss: -1.501,Avg.Loss: -1.272,LR: 2.93E-04]Training epoch 9:  90%|████████▉ | 306/341 [00:05<00:00, 54.68it/s, Epoch: 9, Batch: 307,Loss: 0.012,Avg.Loss: -1.268,LR: 2.93E-04] Training epoch 9:  90%|█████████ | 307/341 [00:05<00:00, 54.48it/s, Epoch: 9, Batch: 307,Loss: 0.012,Avg.Loss: -1.268,LR: 2.93E-04]Training epoch 9:  90%|█████████ | 307/341 [00:05<00:00, 54.48it/s, Epoch: 9, Batch: 308,Loss: -0.499,Avg.Loss: -1.265,LR: 2.93E-04]Training epoch 9:  90%|█████████ | 308/341 [00:05<00:00, 54.48it/s, Epoch: 9, Batch: 309,Loss: -1.226,Avg.Loss: -1.265,LR: 2.93E-04]Training epoch 9:  91%|█████████ | 309/341 [00:05<00:00, 54.48it/s, Epoch: 9, Batch: 310,Loss: -1.444,Avg.Loss: -1.266,LR: 2.93E-04]Training epoch 9:  91%|█████████ | 310/341 [00:05<00:00, 54.48it/s, Epoch: 9, Batch: 311,Loss: -1.056,Avg.Loss: -1.265,LR: 2.93E-04]Training epoch 9:  91%|█████████ | 311/341 [00:05<00:00, 54.48it/s, Epoch: 9, Batch: 312,Loss: -1.279,Avg.Loss: -1.265,LR: 2.92E-04]Training epoch 9:  91%|█████████▏| 312/341 [00:05<00:00, 54.48it/s, Epoch: 9, Batch: 313,Loss: -1.670,Avg.Loss: -1.266,LR: 2.92E-04]Training epoch 9:  92%|█████████▏| 313/341 [00:05<00:00, 54.06it/s, Epoch: 9, Batch: 313,Loss: -1.670,Avg.Loss: -1.266,LR: 2.92E-04]Training epoch 9:  92%|█████████▏| 313/341 [00:05<00:00, 54.06it/s, Epoch: 9, Batch: 314,Loss: -1.068,Avg.Loss: -1.266,LR: 2.92E-04]Training epoch 9:  92%|█████████▏| 314/341 [00:05<00:00, 54.06it/s, Epoch: 9, Batch: 315,Loss: -0.518,Avg.Loss: -1.263,LR: 2.92E-04]Training epoch 9:  92%|█████████▏| 315/341 [00:05<00:00, 54.06it/s, Epoch: 9, Batch: 316,Loss: -1.126,Avg.Loss: -1.263,LR: 2.92E-04]Training epoch 9:  93%|█████████▎| 316/341 [00:05<00:00, 54.06it/s, Epoch: 9, Batch: 317,Loss: -1.699,Avg.Loss: -1.264,LR: 2.92E-04]Training epoch 9:  93%|█████████▎| 317/341 [00:05<00:00, 54.06it/s, Epoch: 9, Batch: 318,Loss: -0.832,Avg.Loss: -1.263,LR: 2.92E-04]Training epoch 9:  93%|█████████▎| 318/341 [00:05<00:00, 54.06it/s, Epoch: 9, Batch: 319,Loss: -0.675,Avg.Loss: -1.261,LR: 2.92E-04]Training epoch 9:  94%|█████████▎| 319/341 [00:05<00:00, 53.64it/s, Epoch: 9, Batch: 319,Loss: -0.675,Avg.Loss: -1.261,LR: 2.92E-04]Training epoch 9:  94%|█████████▎| 319/341 [00:05<00:00, 53.64it/s, Epoch: 9, Batch: 320,Loss: -0.810,Avg.Loss: -1.260,LR: 2.91E-04]Training epoch 9:  94%|█████████▍| 320/341 [00:05<00:00, 53.64it/s, Epoch: 9, Batch: 321,Loss: -1.646,Avg.Loss: -1.261,LR: 2.91E-04]Training epoch 9:  94%|█████████▍| 321/341 [00:05<00:00, 53.64it/s, Epoch: 9, Batch: 322,Loss: -1.112,Avg.Loss: -1.260,LR: 2.91E-04]Training epoch 9:  94%|█████████▍| 322/341 [00:05<00:00, 53.64it/s, Epoch: 9, Batch: 323,Loss: -0.609,Avg.Loss: -1.258,LR: 2.91E-04]Training epoch 9:  95%|█████████▍| 323/341 [00:05<00:00, 53.64it/s, Epoch: 9, Batch: 324,Loss: -0.700,Avg.Loss: -1.257,LR: 2.91E-04]Training epoch 9:  95%|█████████▌| 324/341 [00:05<00:00, 53.64it/s, Epoch: 9, Batch: 325,Loss: -1.777,Avg.Loss: -1.258,LR: 2.91E-04]Training epoch 9:  95%|█████████▌| 325/341 [00:05<00:00, 53.65it/s, Epoch: 9, Batch: 325,Loss: -1.777,Avg.Loss: -1.258,LR: 2.91E-04]Training epoch 9:  95%|█████████▌| 325/341 [00:05<00:00, 53.65it/s, Epoch: 9, Batch: 326,Loss: -1.454,Avg.Loss: -1.259,LR: 2.91E-04]Training epoch 9:  96%|█████████▌| 326/341 [00:06<00:00, 53.65it/s, Epoch: 9, Batch: 327,Loss: -0.876,Avg.Loss: -1.258,LR: 2.91E-04]Training epoch 9:  96%|█████████▌| 327/341 [00:06<00:00, 53.65it/s, Epoch: 9, Batch: 328,Loss: -0.460,Avg.Loss: -1.255,LR: 2.91E-04]Training epoch 9:  96%|█████████▌| 328/341 [00:06<00:00, 53.65it/s, Epoch: 9, Batch: 329,Loss: -1.388,Avg.Loss: -1.256,LR: 2.90E-04]Training epoch 9:  96%|█████████▋| 329/341 [00:06<00:00, 53.65it/s, Epoch: 9, Batch: 330,Loss: -1.782,Avg.Loss: -1.257,LR: 2.90E-04]Training epoch 9:  97%|█████████▋| 330/341 [00:06<00:00, 53.65it/s, Epoch: 9, Batch: 331,Loss: -1.256,Avg.Loss: -1.257,LR: 2.90E-04]Training epoch 9:  97%|█████████▋| 331/341 [00:06<00:00, 54.07it/s, Epoch: 9, Batch: 331,Loss: -1.256,Avg.Loss: -1.257,LR: 2.90E-04]Training epoch 9:  97%|█████████▋| 331/341 [00:06<00:00, 54.07it/s, Epoch: 9, Batch: 332,Loss: -1.178,Avg.Loss: -1.257,LR: 2.90E-04]Training epoch 9:  97%|█████████▋| 332/341 [00:06<00:00, 54.07it/s, Epoch: 9, Batch: 333,Loss: -1.524,Avg.Loss: -1.258,LR: 2.90E-04]Training epoch 9:  98%|█████████▊| 333/341 [00:06<00:00, 54.07it/s, Epoch: 9, Batch: 334,Loss: -1.226,Avg.Loss: -1.258,LR: 2.90E-04]Training epoch 9:  98%|█████████▊| 334/341 [00:06<00:00, 54.07it/s, Epoch: 9, Batch: 335,Loss: -0.744,Avg.Loss: -1.256,LR: 2.90E-04]Training epoch 9:  98%|█████████▊| 335/341 [00:06<00:00, 54.07it/s, Epoch: 9, Batch: 336,Loss: -0.674,Avg.Loss: -1.254,LR: 2.90E-04]Training epoch 9:  99%|█████████▊| 336/341 [00:06<00:00, 54.07it/s, Epoch: 9, Batch: 337,Loss: -1.528,Avg.Loss: -1.255,LR: 2.90E-04]Training epoch 9:  99%|█████████▉| 337/341 [00:06<00:00, 54.22it/s, Epoch: 9, Batch: 337,Loss: -1.528,Avg.Loss: -1.255,LR: 2.90E-04]Training epoch 9:  99%|█████████▉| 337/341 [00:06<00:00, 54.22it/s, Epoch: 9, Batch: 338,Loss: -1.704,Avg.Loss: -1.256,LR: 2.89E-04]Training epoch 9:  99%|█████████▉| 338/341 [00:06<00:00, 54.22it/s, Epoch: 9, Batch: 339,Loss: -1.145,Avg.Loss: -1.256,LR: 2.89E-04]Training epoch 9:  99%|█████████▉| 339/341 [00:06<00:00, 54.22it/s, Epoch: 9, Batch: 340,Loss: -1.235,Avg.Loss: -1.256,LR: 2.89E-04]Training epoch 9: 100%|█████████▉| 340/341 [00:06<00:00, 54.22it/s, Epoch: 9, Batch: 341,Loss: -1.258,Avg.Loss: -1.256,LR: 2.89E-04]Training epoch 9: 100%|██████████| 341/341 [00:06<00:00, 54.34it/s, Epoch: 9, Batch: 341,Loss: -1.258,Avg.Loss: -1.256,LR: 2.89E-04]
Training epoch 10:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 10:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 10, Batch: 1,Loss: -1.415,Avg.Loss: -1.415,LR: 2.89E-04]Training epoch 10:   0%|          | 1/341 [00:00<00:11, 30.06it/s, Epoch: 10, Batch: 2,Loss: -0.542,Avg.Loss: -0.979,LR: 2.89E-04]Training epoch 10:   1%|          | 2/341 [00:00<00:08, 41.17it/s, Epoch: 10, Batch: 3,Loss: -0.912,Avg.Loss: -0.956,LR: 2.89E-04]Training epoch 10:   1%|          | 3/341 [00:00<00:07, 45.05it/s, Epoch: 10, Batch: 4,Loss: -1.745,Avg.Loss: -1.154,LR: 2.89E-04]Training epoch 10:   1%|          | 4/341 [00:00<00:07, 46.85it/s, Epoch: 10, Batch: 5,Loss: -1.316,Avg.Loss: -1.186,LR: 2.89E-04]Training epoch 10:   1%|▏         | 5/341 [00:00<00:06, 48.34it/s, Epoch: 10, Batch: 6,Loss: -0.496,Avg.Loss: -1.071,LR: 2.88E-04]Training epoch 10:   2%|▏         | 6/341 [00:00<00:05, 57.91it/s, Epoch: 10, Batch: 6,Loss: -0.496,Avg.Loss: -1.071,LR: 2.88E-04]Training epoch 10:   2%|▏         | 6/341 [00:00<00:05, 57.91it/s, Epoch: 10, Batch: 7,Loss: -0.909,Avg.Loss: -1.048,LR: 2.88E-04]Training epoch 10:   2%|▏         | 7/341 [00:00<00:05, 57.91it/s, Epoch: 10, Batch: 8,Loss: -1.786,Avg.Loss: -1.140,LR: 2.88E-04]Training epoch 10:   2%|▏         | 8/341 [00:00<00:05, 57.91it/s, Epoch: 10, Batch: 9,Loss: -1.434,Avg.Loss: -1.173,LR: 2.88E-04]Training epoch 10:   3%|▎         | 9/341 [00:00<00:05, 57.91it/s, Epoch: 10, Batch: 10,Loss: -1.070,Avg.Loss: -1.163,LR: 2.88E-04]Training epoch 10:   3%|▎         | 10/341 [00:00<00:05, 57.91it/s, Epoch: 10, Batch: 11,Loss: -1.301,Avg.Loss: -1.175,LR: 2.88E-04]Training epoch 10:   3%|▎         | 11/341 [00:00<00:05, 57.91it/s, Epoch: 10, Batch: 12,Loss: -1.676,Avg.Loss: -1.217,LR: 2.88E-04]Training epoch 10:   4%|▎         | 12/341 [00:00<00:05, 55.80it/s, Epoch: 10, Batch: 12,Loss: -1.676,Avg.Loss: -1.217,LR: 2.88E-04]Training epoch 10:   4%|▎         | 12/341 [00:00<00:05, 55.80it/s, Epoch: 10, Batch: 13,Loss: -1.029,Avg.Loss: -1.202,LR: 2.88E-04]Training epoch 10:   4%|▍         | 13/341 [00:00<00:05, 55.80it/s, Epoch: 10, Batch: 14,Loss: -0.655,Avg.Loss: -1.163,LR: 2.88E-04]Training epoch 10:   4%|▍         | 14/341 [00:00<00:05, 55.80it/s, Epoch: 10, Batch: 15,Loss: -0.810,Avg.Loss: -1.140,LR: 2.87E-04]Training epoch 10:   4%|▍         | 15/341 [00:00<00:05, 55.80it/s, Epoch: 10, Batch: 16,Loss: -1.455,Avg.Loss: -1.159,LR: 2.87E-04]Training epoch 10:   5%|▍         | 16/341 [00:00<00:05, 55.80it/s, Epoch: 10, Batch: 17,Loss: -1.509,Avg.Loss: -1.180,LR: 2.87E-04]Training epoch 10:   5%|▍         | 17/341 [00:00<00:05, 55.80it/s, Epoch: 10, Batch: 18,Loss: -1.190,Avg.Loss: -1.181,LR: 2.87E-04]Training epoch 10:   5%|▌         | 18/341 [00:00<00:05, 54.01it/s, Epoch: 10, Batch: 18,Loss: -1.190,Avg.Loss: -1.181,LR: 2.87E-04]Training epoch 10:   5%|▌         | 18/341 [00:00<00:05, 54.01it/s, Epoch: 10, Batch: 19,Loss: -0.874,Avg.Loss: -1.164,LR: 2.87E-04]Training epoch 10:   6%|▌         | 19/341 [00:00<00:05, 54.01it/s, Epoch: 10, Batch: 20,Loss: -1.508,Avg.Loss: -1.182,LR: 2.87E-04]Training epoch 10:   6%|▌         | 20/341 [00:00<00:05, 54.01it/s, Epoch: 10, Batch: 21,Loss: -1.218,Avg.Loss: -1.183,LR: 2.87E-04]Training epoch 10:   6%|▌         | 21/341 [00:00<00:05, 54.01it/s, Epoch: 10, Batch: 22,Loss: -0.751,Avg.Loss: -1.164,LR: 2.87E-04]Training epoch 10:   6%|▋         | 22/341 [00:00<00:05, 54.01it/s, Epoch: 10, Batch: 23,Loss: -0.700,Avg.Loss: -1.143,LR: 2.86E-04]Training epoch 10:   7%|▋         | 23/341 [00:00<00:05, 54.01it/s, Epoch: 10, Batch: 24,Loss: -1.668,Avg.Loss: -1.165,LR: 2.86E-04]Training epoch 10:   7%|▋         | 24/341 [00:00<00:05, 54.05it/s, Epoch: 10, Batch: 24,Loss: -1.668,Avg.Loss: -1.165,LR: 2.86E-04]Training epoch 10:   7%|▋         | 24/341 [00:00<00:05, 54.05it/s, Epoch: 10, Batch: 25,Loss: -1.667,Avg.Loss: -1.185,LR: 2.86E-04]Training epoch 10:   7%|▋         | 25/341 [00:00<00:05, 54.05it/s, Epoch: 10, Batch: 26,Loss: -1.147,Avg.Loss: -1.184,LR: 2.86E-04]Training epoch 10:   8%|▊         | 26/341 [00:00<00:05, 54.05it/s, Epoch: 10, Batch: 27,Loss: -1.359,Avg.Loss: -1.190,LR: 2.86E-04]Training epoch 10:   8%|▊         | 27/341 [00:00<00:05, 54.05it/s, Epoch: 10, Batch: 28,Loss: -1.741,Avg.Loss: -1.210,LR: 2.86E-04]Training epoch 10:   8%|▊         | 28/341 [00:00<00:05, 54.05it/s, Epoch: 10, Batch: 29,Loss: -0.856,Avg.Loss: -1.198,LR: 2.86E-04]Training epoch 10:   9%|▊         | 29/341 [00:00<00:05, 54.05it/s, Epoch: 10, Batch: 30,Loss: -0.627,Avg.Loss: -1.179,LR: 2.86E-04]Training epoch 10:   9%|▉         | 30/341 [00:00<00:05, 54.30it/s, Epoch: 10, Batch: 30,Loss: -0.627,Avg.Loss: -1.179,LR: 2.86E-04]Training epoch 10:   9%|▉         | 30/341 [00:00<00:05, 54.30it/s, Epoch: 10, Batch: 31,Loss: -0.971,Avg.Loss: -1.172,LR: 2.86E-04]Training epoch 10:   9%|▉         | 31/341 [00:00<00:05, 54.30it/s, Epoch: 10, Batch: 32,Loss: -1.942,Avg.Loss: -1.196,LR: 2.85E-04]Training epoch 10:   9%|▉         | 32/341 [00:00<00:05, 54.30it/s, Epoch: 10, Batch: 33,Loss: -1.295,Avg.Loss: -1.199,LR: 2.85E-04]Training epoch 10:  10%|▉         | 33/341 [00:00<00:05, 54.30it/s, Epoch: 10, Batch: 34,Loss: -0.993,Avg.Loss: -1.193,LR: 2.85E-04]Training epoch 10:  10%|▉         | 34/341 [00:00<00:05, 54.30it/s, Epoch: 10, Batch: 35,Loss: -0.858,Avg.Loss: -1.184,LR: 2.85E-04]Training epoch 10:  10%|█         | 35/341 [00:00<00:05, 54.30it/s, Epoch: 10, Batch: 36,Loss: -1.920,Avg.Loss: -1.204,LR: 2.85E-04]Training epoch 10:  11%|█         | 36/341 [00:00<00:05, 53.65it/s, Epoch: 10, Batch: 36,Loss: -1.920,Avg.Loss: -1.204,LR: 2.85E-04]Training epoch 10:  11%|█         | 36/341 [00:00<00:05, 53.65it/s, Epoch: 10, Batch: 37,Loss: -1.365,Avg.Loss: -1.208,LR: 2.85E-04]Training epoch 10:  11%|█         | 37/341 [00:00<00:05, 53.65it/s, Epoch: 10, Batch: 38,Loss: -0.672,Avg.Loss: -1.194,LR: 2.85E-04]Training epoch 10:  11%|█         | 38/341 [00:00<00:05, 53.65it/s, Epoch: 10, Batch: 39,Loss: -0.555,Avg.Loss: -1.178,LR: 2.85E-04]Training epoch 10:  11%|█▏        | 39/341 [00:00<00:05, 53.65it/s, Epoch: 10, Batch: 40,Loss: -1.648,Avg.Loss: -1.190,LR: 2.85E-04]Training epoch 10:  12%|█▏        | 40/341 [00:00<00:05, 53.65it/s, Epoch: 10, Batch: 41,Loss: -1.347,Avg.Loss: -1.193,LR: 2.84E-04]Training epoch 10:  12%|█▏        | 41/341 [00:00<00:05, 53.65it/s, Epoch: 10, Batch: 42,Loss: -1.222,Avg.Loss: -1.194,LR: 2.84E-04]Training epoch 10:  12%|█▏        | 42/341 [00:00<00:05, 53.62it/s, Epoch: 10, Batch: 42,Loss: -1.222,Avg.Loss: -1.194,LR: 2.84E-04]Training epoch 10:  12%|█▏        | 42/341 [00:00<00:05, 53.62it/s, Epoch: 10, Batch: 43,Loss: -1.127,Avg.Loss: -1.193,LR: 2.84E-04]Training epoch 10:  13%|█▎        | 43/341 [00:00<00:05, 53.62it/s, Epoch: 10, Batch: 44,Loss: -1.740,Avg.Loss: -1.205,LR: 2.84E-04]Training epoch 10:  13%|█▎        | 44/341 [00:00<00:05, 53.62it/s, Epoch: 10, Batch: 45,Loss: -1.516,Avg.Loss: -1.212,LR: 2.84E-04]Training epoch 10:  13%|█▎        | 45/341 [00:00<00:05, 53.62it/s, Epoch: 10, Batch: 46,Loss: -0.241,Avg.Loss: -1.191,LR: 2.84E-04]Training epoch 10:  13%|█▎        | 46/341 [00:00<00:05, 53.62it/s, Epoch: 10, Batch: 47,Loss: -0.977,Avg.Loss: -1.186,LR: 2.84E-04]Training epoch 10:  14%|█▍        | 47/341 [00:00<00:05, 53.62it/s, Epoch: 10, Batch: 48,Loss: -1.609,Avg.Loss: -1.195,LR: 2.84E-04]Training epoch 10:  14%|█▍        | 48/341 [00:00<00:05, 53.43it/s, Epoch: 10, Batch: 48,Loss: -1.609,Avg.Loss: -1.195,LR: 2.84E-04]Training epoch 10:  14%|█▍        | 48/341 [00:00<00:05, 53.43it/s, Epoch: 10, Batch: 49,Loss: -1.453,Avg.Loss: -1.200,LR: 2.84E-04]Training epoch 10:  14%|█▍        | 49/341 [00:00<00:05, 53.43it/s, Epoch: 10, Batch: 50,Loss: -0.256,Avg.Loss: -1.181,LR: 2.83E-04]Training epoch 10:  15%|█▍        | 50/341 [00:00<00:05, 53.43it/s, Epoch: 10, Batch: 51,Loss: -0.657,Avg.Loss: -1.171,LR: 2.83E-04]Training epoch 10:  15%|█▍        | 51/341 [00:00<00:05, 53.43it/s, Epoch: 10, Batch: 52,Loss: -1.405,Avg.Loss: -1.176,LR: 2.83E-04]Training epoch 10:  15%|█▌        | 52/341 [00:00<00:05, 53.43it/s, Epoch: 10, Batch: 53,Loss: -1.472,Avg.Loss: -1.181,LR: 2.83E-04]Training epoch 10:  16%|█▌        | 53/341 [00:01<00:05, 53.43it/s, Epoch: 10, Batch: 54,Loss: -0.551,Avg.Loss: -1.170,LR: 2.83E-04]Training epoch 10:  16%|█▌        | 54/341 [00:01<00:05, 53.32it/s, Epoch: 10, Batch: 54,Loss: -0.551,Avg.Loss: -1.170,LR: 2.83E-04]Training epoch 10:  16%|█▌        | 54/341 [00:01<00:05, 53.32it/s, Epoch: 10, Batch: 55,Loss: -0.961,Avg.Loss: -1.166,LR: 2.83E-04]Training epoch 10:  16%|█▌        | 55/341 [00:01<00:05, 53.32it/s, Epoch: 10, Batch: 56,Loss: -1.759,Avg.Loss: -1.176,LR: 2.83E-04]Training epoch 10:  16%|█▋        | 56/341 [00:01<00:05, 53.32it/s, Epoch: 10, Batch: 57,Loss: -1.206,Avg.Loss: -1.177,LR: 2.83E-04]Training epoch 10:  17%|█▋        | 57/341 [00:01<00:05, 53.32it/s, Epoch: 10, Batch: 58,Loss: -0.840,Avg.Loss: -1.171,LR: 2.82E-04]Training epoch 10:  17%|█▋        | 58/341 [00:01<00:05, 53.32it/s, Epoch: 10, Batch: 59,Loss: -1.130,Avg.Loss: -1.170,LR: 2.82E-04]Training epoch 10:  17%|█▋        | 59/341 [00:01<00:05, 53.32it/s, Epoch: 10, Batch: 60,Loss: -1.816,Avg.Loss: -1.181,LR: 2.82E-04]Training epoch 10:  18%|█▊        | 60/341 [00:01<00:05, 53.09it/s, Epoch: 10, Batch: 60,Loss: -1.816,Avg.Loss: -1.181,LR: 2.82E-04]Training epoch 10:  18%|█▊        | 60/341 [00:01<00:05, 53.09it/s, Epoch: 10, Batch: 61,Loss: -1.434,Avg.Loss: -1.185,LR: 2.82E-04]Training epoch 10:  18%|█▊        | 61/341 [00:01<00:05, 53.09it/s, Epoch: 10, Batch: 62,Loss: -0.492,Avg.Loss: -1.174,LR: 2.82E-04]Training epoch 10:  18%|█▊        | 62/341 [00:01<00:05, 53.09it/s, Epoch: 10, Batch: 63,Loss: -0.793,Avg.Loss: -1.168,LR: 2.82E-04]Training epoch 10:  18%|█▊        | 63/341 [00:01<00:05, 53.09it/s, Epoch: 10, Batch: 64,Loss: -1.455,Avg.Loss: -1.173,LR: 2.82E-04]Training epoch 10:  19%|█▉        | 64/341 [00:01<00:05, 53.09it/s, Epoch: 10, Batch: 65,Loss: -1.505,Avg.Loss: -1.178,LR: 2.82E-04]Training epoch 10:  19%|█▉        | 65/341 [00:01<00:05, 53.09it/s, Epoch: 10, Batch: 66,Loss: -0.603,Avg.Loss: -1.169,LR: 2.82E-04]Training epoch 10:  19%|█▉        | 66/341 [00:01<00:05, 53.18it/s, Epoch: 10, Batch: 66,Loss: -0.603,Avg.Loss: -1.169,LR: 2.82E-04]Training epoch 10:  19%|█▉        | 66/341 [00:01<00:05, 53.18it/s, Epoch: 10, Batch: 67,Loss: -0.594,Avg.Loss: -1.160,LR: 2.81E-04]Training epoch 10:  20%|█▉        | 67/341 [00:01<00:05, 53.18it/s, Epoch: 10, Batch: 68,Loss: -1.580,Avg.Loss: -1.167,LR: 2.81E-04]Training epoch 10:  20%|█▉        | 68/341 [00:01<00:05, 53.18it/s, Epoch: 10, Batch: 69,Loss: -1.853,Avg.Loss: -1.176,LR: 2.81E-04]Training epoch 10:  20%|██        | 69/341 [00:01<00:05, 53.18it/s, Epoch: 10, Batch: 70,Loss: -1.260,Avg.Loss: -1.178,LR: 2.81E-04]Training epoch 10:  21%|██        | 70/341 [00:01<00:05, 53.18it/s, Epoch: 10, Batch: 71,Loss: -1.444,Avg.Loss: -1.181,LR: 2.81E-04]Training epoch 10:  21%|██        | 71/341 [00:01<00:05, 53.18it/s, Epoch: 10, Batch: 72,Loss: -1.621,Avg.Loss: -1.188,LR: 2.81E-04]Training epoch 10:  21%|██        | 72/341 [00:01<00:05, 53.17it/s, Epoch: 10, Batch: 72,Loss: -1.621,Avg.Loss: -1.188,LR: 2.81E-04]Training epoch 10:  21%|██        | 72/341 [00:01<00:05, 53.17it/s, Epoch: 10, Batch: 73,Loss: -1.380,Avg.Loss: -1.190,LR: 2.81E-04]Training epoch 10:  21%|██▏       | 73/341 [00:01<00:05, 53.17it/s, Epoch: 10, Batch: 74,Loss: -0.952,Avg.Loss: -1.187,LR: 2.81E-04]Training epoch 10:  22%|██▏       | 74/341 [00:01<00:05, 53.17it/s, Epoch: 10, Batch: 75,Loss: -1.526,Avg.Loss: -1.191,LR: 2.81E-04]Training epoch 10:  22%|██▏       | 75/341 [00:01<00:05, 53.17it/s, Epoch: 10, Batch: 76,Loss: -1.754,Avg.Loss: -1.199,LR: 2.80E-04]Training epoch 10:  22%|██▏       | 76/341 [00:01<00:04, 53.17it/s, Epoch: 10, Batch: 77,Loss: -1.208,Avg.Loss: -1.199,LR: 2.80E-04]Training epoch 10:  23%|██▎       | 77/341 [00:01<00:04, 53.17it/s, Epoch: 10, Batch: 78,Loss: -1.769,Avg.Loss: -1.206,LR: 2.80E-04]Training epoch 10:  23%|██▎       | 78/341 [00:01<00:04, 52.98it/s, Epoch: 10, Batch: 78,Loss: -1.769,Avg.Loss: -1.206,LR: 2.80E-04]Training epoch 10:  23%|██▎       | 78/341 [00:01<00:04, 52.98it/s, Epoch: 10, Batch: 79,Loss: -1.644,Avg.Loss: -1.212,LR: 2.80E-04]Training epoch 10:  23%|██▎       | 79/341 [00:01<00:04, 52.98it/s, Epoch: 10, Batch: 80,Loss: -1.413,Avg.Loss: -1.214,LR: 2.80E-04]Training epoch 10:  23%|██▎       | 80/341 [00:01<00:04, 52.98it/s, Epoch: 10, Batch: 81,Loss: -1.551,Avg.Loss: -1.219,LR: 2.80E-04]Training epoch 10:  24%|██▍       | 81/341 [00:01<00:04, 52.98it/s, Epoch: 10, Batch: 82,Loss: -1.923,Avg.Loss: -1.227,LR: 2.80E-04]Training epoch 10:  24%|██▍       | 82/341 [00:01<00:04, 52.98it/s, Epoch: 10, Batch: 83,Loss: -1.967,Avg.Loss: -1.236,LR: 2.80E-04]Training epoch 10:  24%|██▍       | 83/341 [00:01<00:04, 52.98it/s, Epoch: 10, Batch: 84,Loss: -1.414,Avg.Loss: -1.238,LR: 2.80E-04]Training epoch 10:  25%|██▍       | 84/341 [00:01<00:04, 53.75it/s, Epoch: 10, Batch: 84,Loss: -1.414,Avg.Loss: -1.238,LR: 2.80E-04]Training epoch 10:  25%|██▍       | 84/341 [00:01<00:04, 53.75it/s, Epoch: 10, Batch: 85,Loss: -1.240,Avg.Loss: -1.238,LR: 2.79E-04]Training epoch 10:  25%|██▍       | 85/341 [00:01<00:04, 53.75it/s, Epoch: 10, Batch: 86,Loss: -1.354,Avg.Loss: -1.240,LR: 2.79E-04]Training epoch 10:  25%|██▌       | 86/341 [00:01<00:04, 53.75it/s, Epoch: 10, Batch: 87,Loss: -0.465,Avg.Loss: -1.231,LR: 2.79E-04]Training epoch 10:  26%|██▌       | 87/341 [00:01<00:04, 53.75it/s, Epoch: 10, Batch: 88,Loss: -0.945,Avg.Loss: -1.227,LR: 2.79E-04]Training epoch 10:  26%|██▌       | 88/341 [00:01<00:04, 53.75it/s, Epoch: 10, Batch: 89,Loss: -1.514,Avg.Loss: -1.231,LR: 2.79E-04]Training epoch 10:  26%|██▌       | 89/341 [00:01<00:04, 53.75it/s, Epoch: 10, Batch: 90,Loss: -1.254,Avg.Loss: -1.231,LR: 2.79E-04]Training epoch 10:  26%|██▋       | 90/341 [00:01<00:04, 53.64it/s, Epoch: 10, Batch: 90,Loss: -1.254,Avg.Loss: -1.231,LR: 2.79E-04]Training epoch 10:  26%|██▋       | 90/341 [00:01<00:04, 53.64it/s, Epoch: 10, Batch: 91,Loss: -0.854,Avg.Loss: -1.227,LR: 2.79E-04]Training epoch 10:  27%|██▋       | 91/341 [00:01<00:04, 53.64it/s, Epoch: 10, Batch: 92,Loss: -0.945,Avg.Loss: -1.224,LR: 2.79E-04]Training epoch 10:  27%|██▋       | 92/341 [00:01<00:04, 53.64it/s, Epoch: 10, Batch: 93,Loss: -1.003,Avg.Loss: -1.221,LR: 2.78E-04]Training epoch 10:  27%|██▋       | 93/341 [00:01<00:04, 53.64it/s, Epoch: 10, Batch: 94,Loss: -0.860,Avg.Loss: -1.217,LR: 2.78E-04]Training epoch 10:  28%|██▊       | 94/341 [00:01<00:04, 53.64it/s, Epoch: 10, Batch: 95,Loss: -1.309,Avg.Loss: -1.218,LR: 2.78E-04]Training epoch 10:  28%|██▊       | 95/341 [00:01<00:04, 53.64it/s, Epoch: 10, Batch: 96,Loss: -1.461,Avg.Loss: -1.221,LR: 2.78E-04]Training epoch 10:  28%|██▊       | 96/341 [00:01<00:04, 53.65it/s, Epoch: 10, Batch: 96,Loss: -1.461,Avg.Loss: -1.221,LR: 2.78E-04]Training epoch 10:  28%|██▊       | 96/341 [00:01<00:04, 53.65it/s, Epoch: 10, Batch: 97,Loss: -1.341,Avg.Loss: -1.222,LR: 2.78E-04]Training epoch 10:  28%|██▊       | 97/341 [00:01<00:04, 53.65it/s, Epoch: 10, Batch: 98,Loss: 0.234,Avg.Loss: -1.207,LR: 2.78E-04] Training epoch 10:  29%|██▊       | 98/341 [00:01<00:04, 53.65it/s, Epoch: 10, Batch: 99,Loss: -0.051,Avg.Loss: -1.196,LR: 2.78E-04]Training epoch 10:  29%|██▉       | 99/341 [00:01<00:04, 53.65it/s, Epoch: 10, Batch: 100,Loss: -1.172,Avg.Loss: -1.195,LR: 2.78E-04]Training epoch 10:  29%|██▉       | 100/341 [00:01<00:04, 53.65it/s, Epoch: 10, Batch: 101,Loss: -1.196,Avg.Loss: -1.195,LR: 2.78E-04]Training epoch 10:  30%|██▉       | 101/341 [00:01<00:04, 53.65it/s, Epoch: 10, Batch: 102,Loss: -1.352,Avg.Loss: -1.197,LR: 2.77E-04]Training epoch 10:  30%|██▉       | 102/341 [00:01<00:04, 54.02it/s, Epoch: 10, Batch: 102,Loss: -1.352,Avg.Loss: -1.197,LR: 2.77E-04]Training epoch 10:  30%|██▉       | 102/341 [00:01<00:04, 54.02it/s, Epoch: 10, Batch: 103,Loss: -1.721,Avg.Loss: -1.202,LR: 2.77E-04]Training epoch 10:  30%|███       | 103/341 [00:01<00:04, 54.02it/s, Epoch: 10, Batch: 104,Loss: -1.078,Avg.Loss: -1.201,LR: 2.77E-04]Training epoch 10:  30%|███       | 104/341 [00:01<00:04, 54.02it/s, Epoch: 10, Batch: 105,Loss: -0.322,Avg.Loss: -1.192,LR: 2.77E-04]Training epoch 10:  31%|███       | 105/341 [00:01<00:04, 54.02it/s, Epoch: 10, Batch: 106,Loss: -0.379,Avg.Loss: -1.185,LR: 2.77E-04]Training epoch 10:  31%|███       | 106/341 [00:01<00:04, 54.02it/s, Epoch: 10, Batch: 107,Loss: -1.068,Avg.Loss: -1.184,LR: 2.77E-04]Training epoch 10:  31%|███▏      | 107/341 [00:02<00:04, 54.02it/s, Epoch: 10, Batch: 108,Loss: -1.126,Avg.Loss: -1.183,LR: 2.77E-04]Training epoch 10:  32%|███▏      | 108/341 [00:02<00:04, 54.30it/s, Epoch: 10, Batch: 108,Loss: -1.126,Avg.Loss: -1.183,LR: 2.77E-04]Training epoch 10:  32%|███▏      | 108/341 [00:02<00:04, 54.30it/s, Epoch: 10, Batch: 109,Loss: -0.519,Avg.Loss: -1.177,LR: 2.77E-04]Training epoch 10:  32%|███▏      | 109/341 [00:02<00:04, 54.30it/s, Epoch: 10, Batch: 110,Loss: -0.565,Avg.Loss: -1.171,LR: 2.77E-04]Training epoch 10:  32%|███▏      | 110/341 [00:02<00:04, 54.30it/s, Epoch: 10, Batch: 111,Loss: -1.675,Avg.Loss: -1.176,LR: 2.76E-04]Training epoch 10:  33%|███▎      | 111/341 [00:02<00:04, 54.30it/s, Epoch: 10, Batch: 112,Loss: -1.163,Avg.Loss: -1.176,LR: 2.76E-04]Training epoch 10:  33%|███▎      | 112/341 [00:02<00:04, 54.30it/s, Epoch: 10, Batch: 113,Loss: -0.243,Avg.Loss: -1.168,LR: 2.76E-04]Training epoch 10:  33%|███▎      | 113/341 [00:02<00:04, 54.30it/s, Epoch: 10, Batch: 114,Loss: -0.082,Avg.Loss: -1.158,LR: 2.76E-04]Training epoch 10:  33%|███▎      | 114/341 [00:02<00:04, 54.55it/s, Epoch: 10, Batch: 114,Loss: -0.082,Avg.Loss: -1.158,LR: 2.76E-04]Training epoch 10:  33%|███▎      | 114/341 [00:02<00:04, 54.55it/s, Epoch: 10, Batch: 115,Loss: -1.051,Avg.Loss: -1.157,LR: 2.76E-04]Training epoch 10:  34%|███▎      | 115/341 [00:02<00:04, 54.55it/s, Epoch: 10, Batch: 116,Loss: -1.268,Avg.Loss: -1.158,LR: 2.76E-04]Training epoch 10:  34%|███▍      | 116/341 [00:02<00:04, 54.55it/s, Epoch: 10, Batch: 117,Loss: -0.973,Avg.Loss: -1.157,LR: 2.76E-04]Training epoch 10:  34%|███▍      | 117/341 [00:02<00:04, 54.55it/s, Epoch: 10, Batch: 118,Loss: -1.076,Avg.Loss: -1.156,LR: 2.76E-04]Training epoch 10:  35%|███▍      | 118/341 [00:02<00:04, 54.55it/s, Epoch: 10, Batch: 119,Loss: -1.510,Avg.Loss: -1.159,LR: 2.76E-04]Training epoch 10:  35%|███▍      | 119/341 [00:02<00:04, 54.55it/s, Epoch: 10, Batch: 120,Loss: -1.574,Avg.Loss: -1.162,LR: 2.75E-04]Training epoch 10:  35%|███▌      | 120/341 [00:02<00:04, 54.56it/s, Epoch: 10, Batch: 120,Loss: -1.574,Avg.Loss: -1.162,LR: 2.75E-04]Training epoch 10:  35%|███▌      | 120/341 [00:02<00:04, 54.56it/s, Epoch: 10, Batch: 121,Loss: -0.516,Avg.Loss: -1.157,LR: 2.75E-04]Training epoch 10:  35%|███▌      | 121/341 [00:02<00:04, 54.56it/s, Epoch: 10, Batch: 122,Loss: -1.218,Avg.Loss: -1.157,LR: 2.75E-04]Training epoch 10:  36%|███▌      | 122/341 [00:02<00:04, 54.56it/s, Epoch: 10, Batch: 123,Loss: -1.880,Avg.Loss: -1.163,LR: 2.75E-04]Training epoch 10:  36%|███▌      | 123/341 [00:02<00:03, 54.56it/s, Epoch: 10, Batch: 124,Loss: -0.653,Avg.Loss: -1.159,LR: 2.75E-04]Training epoch 10:  36%|███▋      | 124/341 [00:02<00:03, 54.56it/s, Epoch: 10, Batch: 125,Loss: -0.222,Avg.Loss: -1.152,LR: 2.75E-04]Training epoch 10:  37%|███▋      | 125/341 [00:02<00:03, 54.56it/s, Epoch: 10, Batch: 126,Loss: -0.373,Avg.Loss: -1.146,LR: 2.75E-04]Training epoch 10:  37%|███▋      | 126/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 126,Loss: -0.373,Avg.Loss: -1.146,LR: 2.75E-04]Training epoch 10:  37%|███▋      | 126/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 127,Loss: -1.284,Avg.Loss: -1.147,LR: 2.75E-04]Training epoch 10:  37%|███▋      | 127/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 128,Loss: -1.723,Avg.Loss: -1.151,LR: 2.74E-04]Training epoch 10:  38%|███▊      | 128/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 129,Loss: -1.437,Avg.Loss: -1.153,LR: 2.74E-04]Training epoch 10:  38%|███▊      | 129/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 130,Loss: -1.202,Avg.Loss: -1.154,LR: 2.74E-04]Training epoch 10:  38%|███▊      | 130/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 131,Loss: -1.662,Avg.Loss: -1.158,LR: 2.74E-04]Training epoch 10:  38%|███▊      | 131/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 132,Loss: -1.060,Avg.Loss: -1.157,LR: 2.74E-04]Training epoch 10:  39%|███▊      | 132/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 132,Loss: -1.060,Avg.Loss: -1.157,LR: 2.74E-04]Training epoch 10:  39%|███▊      | 132/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 133,Loss: -0.207,Avg.Loss: -1.150,LR: 2.74E-04]Training epoch 10:  39%|███▉      | 133/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 134,Loss: -0.426,Avg.Loss: -1.144,LR: 2.74E-04]Training epoch 10:  39%|███▉      | 134/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 135,Loss: -1.874,Avg.Loss: -1.150,LR: 2.74E-04]Training epoch 10:  40%|███▉      | 135/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 136,Loss: -1.442,Avg.Loss: -1.152,LR: 2.74E-04]Training epoch 10:  40%|███▉      | 136/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 137,Loss: -0.779,Avg.Loss: -1.149,LR: 2.73E-04]Training epoch 10:  40%|████      | 137/341 [00:02<00:03, 54.36it/s, Epoch: 10, Batch: 138,Loss: -0.606,Avg.Loss: -1.145,LR: 2.73E-04]Training epoch 10:  40%|████      | 138/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 138,Loss: -0.606,Avg.Loss: -1.145,LR: 2.73E-04]Training epoch 10:  40%|████      | 138/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 139,Loss: -1.424,Avg.Loss: -1.147,LR: 2.73E-04]Training epoch 10:  41%|████      | 139/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 140,Loss: -1.508,Avg.Loss: -1.150,LR: 2.73E-04]Training epoch 10:  41%|████      | 140/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 141,Loss: -1.301,Avg.Loss: -1.151,LR: 2.73E-04]Training epoch 10:  41%|████▏     | 141/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 142,Loss: -1.209,Avg.Loss: -1.151,LR: 2.73E-04]Training epoch 10:  42%|████▏     | 142/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 143,Loss: -1.790,Avg.Loss: -1.156,LR: 2.73E-04]Training epoch 10:  42%|████▏     | 143/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 144,Loss: -0.704,Avg.Loss: -1.153,LR: 2.73E-04]Training epoch 10:  42%|████▏     | 144/341 [00:02<00:03, 53.85it/s, Epoch: 10, Batch: 144,Loss: -0.704,Avg.Loss: -1.153,LR: 2.73E-04]Training epoch 10:  42%|████▏     | 144/341 [00:02<00:03, 53.85it/s, Epoch: 10, Batch: 145,Loss: -0.109,Avg.Loss: -1.145,LR: 2.73E-04]Training epoch 10:  43%|████▎     | 145/341 [00:02<00:03, 53.85it/s, Epoch: 10, Batch: 146,Loss: -0.098,Avg.Loss: -1.138,LR: 2.72E-04]Training epoch 10:  43%|████▎     | 146/341 [00:02<00:03, 53.85it/s, Epoch: 10, Batch: 147,Loss: -1.503,Avg.Loss: -1.141,LR: 2.72E-04]Training epoch 10:  43%|████▎     | 147/341 [00:02<00:03, 53.85it/s, Epoch: 10, Batch: 148,Loss: -1.731,Avg.Loss: -1.145,LR: 2.72E-04]Training epoch 10:  43%|████▎     | 148/341 [00:02<00:03, 53.85it/s, Epoch: 10, Batch: 149,Loss: -1.194,Avg.Loss: -1.145,LR: 2.72E-04]Training epoch 10:  44%|████▎     | 149/341 [00:02<00:03, 53.85it/s, Epoch: 10, Batch: 150,Loss: -1.356,Avg.Loss: -1.146,LR: 2.72E-04]Training epoch 10:  44%|████▍     | 150/341 [00:02<00:03, 53.89it/s, Epoch: 10, Batch: 150,Loss: -1.356,Avg.Loss: -1.146,LR: 2.72E-04]Training epoch 10:  44%|████▍     | 150/341 [00:02<00:03, 53.89it/s, Epoch: 10, Batch: 151,Loss: -1.774,Avg.Loss: -1.151,LR: 2.72E-04]Training epoch 10:  44%|████▍     | 151/341 [00:02<00:03, 53.89it/s, Epoch: 10, Batch: 152,Loss: -1.117,Avg.Loss: -1.150,LR: 2.72E-04]Training epoch 10:  45%|████▍     | 152/341 [00:02<00:03, 53.89it/s, Epoch: 10, Batch: 153,Loss: -0.505,Avg.Loss: -1.146,LR: 2.72E-04]Training epoch 10:  45%|████▍     | 153/341 [00:02<00:03, 53.89it/s, Epoch: 10, Batch: 154,Loss: -0.443,Avg.Loss: -1.142,LR: 2.72E-04]Training epoch 10:  45%|████▌     | 154/341 [00:02<00:03, 53.89it/s, Epoch: 10, Batch: 155,Loss: -1.643,Avg.Loss: -1.145,LR: 2.71E-04]Training epoch 10:  45%|████▌     | 155/341 [00:02<00:03, 53.89it/s, Epoch: 10, Batch: 156,Loss: -1.102,Avg.Loss: -1.145,LR: 2.71E-04]Training epoch 10:  46%|████▌     | 156/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 156,Loss: -1.102,Avg.Loss: -1.145,LR: 2.71E-04]Training epoch 10:  46%|████▌     | 156/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 157,Loss: -0.212,Avg.Loss: -1.139,LR: 2.71E-04]Training epoch 10:  46%|████▌     | 157/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 158,Loss: -0.259,Avg.Loss: -1.133,LR: 2.71E-04]Training epoch 10:  46%|████▋     | 158/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 159,Loss: -1.203,Avg.Loss: -1.133,LR: 2.71E-04]Training epoch 10:  47%|████▋     | 159/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 160,Loss: -1.720,Avg.Loss: -1.137,LR: 2.71E-04]Training epoch 10:  47%|████▋     | 160/341 [00:02<00:03, 53.71it/s, Epoch: 10, Batch: 161,Loss: -1.006,Avg.Loss: -1.136,LR: 2.71E-04]Training epoch 10:  47%|████▋     | 161/341 [00:03<00:03, 53.71it/s, Epoch: 10, Batch: 162,Loss: -1.661,Avg.Loss: -1.140,LR: 2.71E-04]Training epoch 10:  48%|████▊     | 162/341 [00:03<00:03, 52.03it/s, Epoch: 10, Batch: 162,Loss: -1.661,Avg.Loss: -1.140,LR: 2.71E-04]Training epoch 10:  48%|████▊     | 162/341 [00:03<00:03, 52.03it/s, Epoch: 10, Batch: 163,Loss: -1.873,Avg.Loss: -1.144,LR: 2.70E-04]Training epoch 10:  48%|████▊     | 163/341 [00:03<00:03, 52.03it/s, Epoch: 10, Batch: 164,Loss: -1.892,Avg.Loss: -1.149,LR: 2.70E-04]Training epoch 10:  48%|████▊     | 164/341 [00:03<00:03, 52.03it/s, Epoch: 10, Batch: 165,Loss: -1.264,Avg.Loss: -1.149,LR: 2.70E-04]Training epoch 10:  48%|████▊     | 165/341 [00:03<00:03, 52.03it/s, Epoch: 10, Batch: 166,Loss: -1.357,Avg.Loss: -1.151,LR: 2.70E-04]Training epoch 10:  49%|████▊     | 166/341 [00:03<00:03, 52.03it/s, Epoch: 10, Batch: 167,Loss: -1.756,Avg.Loss: -1.154,LR: 2.70E-04]Training epoch 10:  49%|████▉     | 167/341 [00:03<00:03, 52.03it/s, Epoch: 10, Batch: 168,Loss: -1.206,Avg.Loss: -1.155,LR: 2.70E-04]Training epoch 10:  49%|████▉     | 168/341 [00:03<00:03, 53.02it/s, Epoch: 10, Batch: 168,Loss: -1.206,Avg.Loss: -1.155,LR: 2.70E-04]Training epoch 10:  49%|████▉     | 168/341 [00:03<00:03, 53.02it/s, Epoch: 10, Batch: 169,Loss: -0.711,Avg.Loss: -1.152,LR: 2.70E-04]Training epoch 10:  50%|████▉     | 169/341 [00:03<00:03, 53.02it/s, Epoch: 10, Batch: 170,Loss: -0.477,Avg.Loss: -1.148,LR: 2.70E-04]Training epoch 10:  50%|████▉     | 170/341 [00:03<00:03, 53.02it/s, Epoch: 10, Batch: 171,Loss: -0.380,Avg.Loss: -1.143,LR: 2.70E-04]Training epoch 10:  50%|█████     | 171/341 [00:03<00:03, 53.02it/s, Epoch: 10, Batch: 172,Loss: 1.187,Avg.Loss: -1.130,LR: 2.69E-04] Training epoch 10:  50%|█████     | 172/341 [00:03<00:03, 53.02it/s, Epoch: 10, Batch: 173,Loss: -0.096,Avg.Loss: -1.124,LR: 2.69E-04]Training epoch 10:  51%|█████     | 173/341 [00:03<00:03, 53.02it/s, Epoch: 10, Batch: 174,Loss: -1.276,Avg.Loss: -1.125,LR: 2.69E-04]Training epoch 10:  51%|█████     | 174/341 [00:03<00:03, 53.00it/s, Epoch: 10, Batch: 174,Loss: -1.276,Avg.Loss: -1.125,LR: 2.69E-04]Training epoch 10:  51%|█████     | 174/341 [00:03<00:03, 53.00it/s, Epoch: 10, Batch: 175,Loss: -1.721,Avg.Loss: -1.128,LR: 2.69E-04]Training epoch 10:  51%|█████▏    | 175/341 [00:03<00:03, 53.00it/s, Epoch: 10, Batch: 176,Loss: -1.635,Avg.Loss: -1.131,LR: 2.69E-04]Training epoch 10:  52%|█████▏    | 176/341 [00:03<00:03, 53.00it/s, Epoch: 10, Batch: 177,Loss: -1.254,Avg.Loss: -1.132,LR: 2.69E-04]Training epoch 10:  52%|█████▏    | 177/341 [00:03<00:03, 53.00it/s, Epoch: 10, Batch: 178,Loss: -1.471,Avg.Loss: -1.134,LR: 2.69E-04]Training epoch 10:  52%|█████▏    | 178/341 [00:03<00:03, 53.00it/s, Epoch: 10, Batch: 179,Loss: -1.739,Avg.Loss: -1.137,LR: 2.69E-04]Training epoch 10:  52%|█████▏    | 179/341 [00:03<00:03, 53.00it/s, Epoch: 10, Batch: 180,Loss: -1.413,Avg.Loss: -1.139,LR: 2.69E-04]Training epoch 10:  53%|█████▎    | 180/341 [00:03<00:03, 52.33it/s, Epoch: 10, Batch: 180,Loss: -1.413,Avg.Loss: -1.139,LR: 2.69E-04]Training epoch 10:  53%|█████▎    | 180/341 [00:03<00:03, 52.33it/s, Epoch: 10, Batch: 181,Loss: -1.618,Avg.Loss: -1.141,LR: 2.68E-04]Training epoch 10:  53%|█████▎    | 181/341 [00:03<00:03, 52.33it/s, Epoch: 10, Batch: 182,Loss: -1.545,Avg.Loss: -1.143,LR: 2.68E-04]Training epoch 10:  53%|█████▎    | 182/341 [00:03<00:03, 52.33it/s, Epoch: 10, Batch: 183,Loss: -1.464,Avg.Loss: -1.145,LR: 2.68E-04]Training epoch 10:  54%|█████▎    | 183/341 [00:03<00:03, 52.33it/s, Epoch: 10, Batch: 184,Loss: -1.397,Avg.Loss: -1.147,LR: 2.68E-04]Training epoch 10:  54%|█████▍    | 184/341 [00:03<00:02, 52.33it/s, Epoch: 10, Batch: 185,Loss: -1.825,Avg.Loss: -1.150,LR: 2.68E-04]Training epoch 10:  54%|█████▍    | 185/341 [00:03<00:02, 52.33it/s, Epoch: 10, Batch: 186,Loss: -1.537,Avg.Loss: -1.152,LR: 2.68E-04]Training epoch 10:  55%|█████▍    | 186/341 [00:03<00:02, 52.47it/s, Epoch: 10, Batch: 186,Loss: -1.537,Avg.Loss: -1.152,LR: 2.68E-04]Training epoch 10:  55%|█████▍    | 186/341 [00:03<00:02, 52.47it/s, Epoch: 10, Batch: 187,Loss: -1.648,Avg.Loss: -1.155,LR: 2.68E-04]Training epoch 10:  55%|█████▍    | 187/341 [00:03<00:02, 52.47it/s, Epoch: 10, Batch: 188,Loss: -1.492,Avg.Loss: -1.157,LR: 2.68E-04]Training epoch 10:  55%|█████▌    | 188/341 [00:03<00:02, 52.47it/s, Epoch: 10, Batch: 189,Loss: -1.744,Avg.Loss: -1.160,LR: 2.67E-04]Training epoch 10:  55%|█████▌    | 189/341 [00:03<00:02, 52.47it/s, Epoch: 10, Batch: 190,Loss: -1.601,Avg.Loss: -1.162,LR: 2.67E-04]Training epoch 10:  56%|█████▌    | 190/341 [00:03<00:02, 52.47it/s, Epoch: 10, Batch: 191,Loss: -1.257,Avg.Loss: -1.163,LR: 2.67E-04]Training epoch 10:  56%|█████▌    | 191/341 [00:03<00:02, 52.47it/s, Epoch: 10, Batch: 192,Loss: -1.446,Avg.Loss: -1.164,LR: 2.67E-04]Training epoch 10:  56%|█████▋    | 192/341 [00:03<00:02, 52.58it/s, Epoch: 10, Batch: 192,Loss: -1.446,Avg.Loss: -1.164,LR: 2.67E-04]Training epoch 10:  56%|█████▋    | 192/341 [00:03<00:02, 52.58it/s, Epoch: 10, Batch: 193,Loss: -1.436,Avg.Loss: -1.166,LR: 2.67E-04]Training epoch 10:  57%|█████▋    | 193/341 [00:03<00:02, 52.58it/s, Epoch: 10, Batch: 194,Loss: -1.875,Avg.Loss: -1.169,LR: 2.67E-04]Training epoch 10:  57%|█████▋    | 194/341 [00:03<00:02, 52.58it/s, Epoch: 10, Batch: 195,Loss: -1.570,Avg.Loss: -1.171,LR: 2.67E-04]Training epoch 10:  57%|█████▋    | 195/341 [00:03<00:02, 52.58it/s, Epoch: 10, Batch: 196,Loss: -1.653,Avg.Loss: -1.174,LR: 2.67E-04]Training epoch 10:  57%|█████▋    | 196/341 [00:03<00:02, 52.58it/s, Epoch: 10, Batch: 197,Loss: -1.787,Avg.Loss: -1.177,LR: 2.67E-04]Training epoch 10:  58%|█████▊    | 197/341 [00:03<00:02, 52.58it/s, Epoch: 10, Batch: 198,Loss: -1.601,Avg.Loss: -1.179,LR: 2.66E-04]Training epoch 10:  58%|█████▊    | 198/341 [00:03<00:02, 52.25it/s, Epoch: 10, Batch: 198,Loss: -1.601,Avg.Loss: -1.179,LR: 2.66E-04]Training epoch 10:  58%|█████▊    | 198/341 [00:03<00:02, 52.25it/s, Epoch: 10, Batch: 199,Loss: -1.345,Avg.Loss: -1.180,LR: 2.66E-04]Training epoch 10:  58%|█████▊    | 199/341 [00:03<00:02, 52.25it/s, Epoch: 10, Batch: 200,Loss: -2.109,Avg.Loss: -1.184,LR: 2.66E-04]Training epoch 10:  59%|█████▊    | 200/341 [00:03<00:02, 52.25it/s, Epoch: 10, Batch: 201,Loss: -1.879,Avg.Loss: -1.188,LR: 2.66E-04]Training epoch 10:  59%|█████▉    | 201/341 [00:03<00:02, 52.25it/s, Epoch: 10, Batch: 202,Loss: -1.421,Avg.Loss: -1.189,LR: 2.66E-04]Training epoch 10:  59%|█████▉    | 202/341 [00:03<00:02, 52.25it/s, Epoch: 10, Batch: 203,Loss: -1.654,Avg.Loss: -1.191,LR: 2.66E-04]Training epoch 10:  60%|█████▉    | 203/341 [00:03<00:02, 52.25it/s, Epoch: 10, Batch: 204,Loss: -1.421,Avg.Loss: -1.192,LR: 2.66E-04]Training epoch 10:  60%|█████▉    | 204/341 [00:03<00:02, 51.83it/s, Epoch: 10, Batch: 204,Loss: -1.421,Avg.Loss: -1.192,LR: 2.66E-04]Training epoch 10:  60%|█████▉    | 204/341 [00:03<00:02, 51.83it/s, Epoch: 10, Batch: 205,Loss: -1.711,Avg.Loss: -1.195,LR: 2.66E-04]Training epoch 10:  60%|██████    | 205/341 [00:03<00:02, 51.83it/s, Epoch: 10, Batch: 206,Loss: -1.509,Avg.Loss: -1.197,LR: 2.66E-04]Training epoch 10:  60%|██████    | 206/341 [00:03<00:02, 51.83it/s, Epoch: 10, Batch: 207,Loss: -1.762,Avg.Loss: -1.199,LR: 2.65E-04]Training epoch 10:  61%|██████    | 207/341 [00:03<00:02, 51.83it/s, Epoch: 10, Batch: 208,Loss: -1.450,Avg.Loss: -1.200,LR: 2.65E-04]Training epoch 10:  61%|██████    | 208/341 [00:03<00:02, 51.83it/s, Epoch: 10, Batch: 209,Loss: -1.284,Avg.Loss: -1.201,LR: 2.65E-04]Training epoch 10:  61%|██████▏   | 209/341 [00:03<00:02, 51.83it/s, Epoch: 10, Batch: 210,Loss: -1.750,Avg.Loss: -1.203,LR: 2.65E-04]Training epoch 10:  62%|██████▏   | 210/341 [00:03<00:02, 51.84it/s, Epoch: 10, Batch: 210,Loss: -1.750,Avg.Loss: -1.203,LR: 2.65E-04]Training epoch 10:  62%|██████▏   | 210/341 [00:03<00:02, 51.84it/s, Epoch: 10, Batch: 211,Loss: -1.771,Avg.Loss: -1.206,LR: 2.65E-04]Training epoch 10:  62%|██████▏   | 211/341 [00:03<00:02, 51.84it/s, Epoch: 10, Batch: 212,Loss: -1.780,Avg.Loss: -1.209,LR: 2.65E-04]Training epoch 10:  62%|██████▏   | 212/341 [00:03<00:02, 51.84it/s, Epoch: 10, Batch: 213,Loss: -2.209,Avg.Loss: -1.214,LR: 2.65E-04]Training epoch 10:  62%|██████▏   | 213/341 [00:04<00:02, 51.84it/s, Epoch: 10, Batch: 214,Loss: -1.414,Avg.Loss: -1.215,LR: 2.65E-04]Training epoch 10:  63%|██████▎   | 214/341 [00:04<00:02, 51.84it/s, Epoch: 10, Batch: 215,Loss: -1.363,Avg.Loss: -1.215,LR: 2.65E-04]Training epoch 10:  63%|██████▎   | 215/341 [00:04<00:02, 51.84it/s, Epoch: 10, Batch: 216,Loss: -1.100,Avg.Loss: -1.215,LR: 2.64E-04]Training epoch 10:  63%|██████▎   | 216/341 [00:04<00:02, 53.09it/s, Epoch: 10, Batch: 216,Loss: -1.100,Avg.Loss: -1.215,LR: 2.64E-04]Training epoch 10:  63%|██████▎   | 216/341 [00:04<00:02, 53.09it/s, Epoch: 10, Batch: 217,Loss: -1.271,Avg.Loss: -1.215,LR: 2.64E-04]Training epoch 10:  64%|██████▎   | 217/341 [00:04<00:02, 53.09it/s, Epoch: 10, Batch: 218,Loss: -1.479,Avg.Loss: -1.216,LR: 2.64E-04]Training epoch 10:  64%|██████▍   | 218/341 [00:04<00:02, 53.09it/s, Epoch: 10, Batch: 219,Loss: -1.005,Avg.Loss: -1.215,LR: 2.64E-04]Training epoch 10:  64%|██████▍   | 219/341 [00:04<00:02, 53.09it/s, Epoch: 10, Batch: 220,Loss: -0.568,Avg.Loss: -1.212,LR: 2.64E-04]Training epoch 10:  65%|██████▍   | 220/341 [00:04<00:02, 53.09it/s, Epoch: 10, Batch: 221,Loss: -1.384,Avg.Loss: -1.213,LR: 2.64E-04]Training epoch 10:  65%|██████▍   | 221/341 [00:04<00:02, 53.09it/s, Epoch: 10, Batch: 222,Loss: -1.516,Avg.Loss: -1.214,LR: 2.64E-04]Training epoch 10:  65%|██████▌   | 222/341 [00:04<00:02, 52.86it/s, Epoch: 10, Batch: 222,Loss: -1.516,Avg.Loss: -1.214,LR: 2.64E-04]Training epoch 10:  65%|██████▌   | 222/341 [00:04<00:02, 52.86it/s, Epoch: 10, Batch: 223,Loss: -1.663,Avg.Loss: -1.216,LR: 2.64E-04]Training epoch 10:  65%|██████▌   | 223/341 [00:04<00:02, 52.86it/s, Epoch: 10, Batch: 224,Loss: -1.584,Avg.Loss: -1.218,LR: 2.63E-04]Training epoch 10:  66%|██████▌   | 224/341 [00:04<00:02, 52.86it/s, Epoch: 10, Batch: 225,Loss: -1.520,Avg.Loss: -1.219,LR: 2.63E-04]Training epoch 10:  66%|██████▌   | 225/341 [00:04<00:02, 52.86it/s, Epoch: 10, Batch: 226,Loss: -1.448,Avg.Loss: -1.220,LR: 2.63E-04]Training epoch 10:  66%|██████▋   | 226/341 [00:04<00:02, 52.86it/s, Epoch: 10, Batch: 227,Loss: -1.201,Avg.Loss: -1.220,LR: 2.63E-04]Training epoch 10:  67%|██████▋   | 227/341 [00:04<00:02, 52.86it/s, Epoch: 10, Batch: 228,Loss: -1.590,Avg.Loss: -1.222,LR: 2.63E-04]Training epoch 10:  67%|██████▋   | 228/341 [00:04<00:02, 52.91it/s, Epoch: 10, Batch: 228,Loss: -1.590,Avg.Loss: -1.222,LR: 2.63E-04]Training epoch 10:  67%|██████▋   | 228/341 [00:04<00:02, 52.91it/s, Epoch: 10, Batch: 229,Loss: -1.764,Avg.Loss: -1.224,LR: 2.63E-04]Training epoch 10:  67%|██████▋   | 229/341 [00:04<00:02, 52.91it/s, Epoch: 10, Batch: 230,Loss: -1.161,Avg.Loss: -1.224,LR: 2.63E-04]Training epoch 10:  67%|██████▋   | 230/341 [00:04<00:02, 52.91it/s, Epoch: 10, Batch: 231,Loss: -1.129,Avg.Loss: -1.224,LR: 2.63E-04]Training epoch 10:  68%|██████▊   | 231/341 [00:04<00:02, 52.91it/s, Epoch: 10, Batch: 232,Loss: -1.459,Avg.Loss: -1.225,LR: 2.63E-04]Training epoch 10:  68%|██████▊   | 232/341 [00:04<00:02, 52.91it/s, Epoch: 10, Batch: 233,Loss: -1.925,Avg.Loss: -1.228,LR: 2.62E-04]Training epoch 10:  68%|██████▊   | 233/341 [00:04<00:02, 52.91it/s, Epoch: 10, Batch: 234,Loss: -1.659,Avg.Loss: -1.229,LR: 2.62E-04]Training epoch 10:  69%|██████▊   | 234/341 [00:04<00:02, 52.82it/s, Epoch: 10, Batch: 234,Loss: -1.659,Avg.Loss: -1.229,LR: 2.62E-04]Training epoch 10:  69%|██████▊   | 234/341 [00:04<00:02, 52.82it/s, Epoch: 10, Batch: 235,Loss: -1.268,Avg.Loss: -1.230,LR: 2.62E-04]Training epoch 10:  69%|██████▉   | 235/341 [00:04<00:02, 52.82it/s, Epoch: 10, Batch: 236,Loss: -0.802,Avg.Loss: -1.228,LR: 2.62E-04]Training epoch 10:  69%|██████▉   | 236/341 [00:04<00:01, 52.82it/s, Epoch: 10, Batch: 237,Loss: -0.662,Avg.Loss: -1.225,LR: 2.62E-04]Training epoch 10:  70%|██████▉   | 237/341 [00:04<00:01, 52.82it/s, Epoch: 10, Batch: 238,Loss: -1.359,Avg.Loss: -1.226,LR: 2.62E-04]Training epoch 10:  70%|██████▉   | 238/341 [00:04<00:01, 52.82it/s, Epoch: 10, Batch: 239,Loss: -1.523,Avg.Loss: -1.227,LR: 2.62E-04]Training epoch 10:  70%|███████   | 239/341 [00:04<00:01, 52.82it/s, Epoch: 10, Batch: 240,Loss: -0.903,Avg.Loss: -1.226,LR: 2.62E-04]Training epoch 10:  70%|███████   | 240/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 240,Loss: -0.903,Avg.Loss: -1.226,LR: 2.62E-04]Training epoch 10:  70%|███████   | 240/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 241,Loss: -0.389,Avg.Loss: -1.222,LR: 2.62E-04]Training epoch 10:  71%|███████   | 241/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 242,Loss: 0.619,Avg.Loss: -1.215,LR: 2.61E-04] Training epoch 10:  71%|███████   | 242/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 243,Loss: 0.135,Avg.Loss: -1.209,LR: 2.61E-04]Training epoch 10:  71%|███████▏  | 243/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 244,Loss: -1.394,Avg.Loss: -1.210,LR: 2.61E-04]Training epoch 10:  72%|███████▏  | 244/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 245,Loss: -1.578,Avg.Loss: -1.212,LR: 2.61E-04]Training epoch 10:  72%|███████▏  | 245/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 246,Loss: -1.346,Avg.Loss: -1.212,LR: 2.61E-04]Training epoch 10:  72%|███████▏  | 246/341 [00:04<00:01, 53.20it/s, Epoch: 10, Batch: 246,Loss: -1.346,Avg.Loss: -1.212,LR: 2.61E-04]Training epoch 10:  72%|███████▏  | 246/341 [00:04<00:01, 53.20it/s, Epoch: 10, Batch: 247,Loss: -1.176,Avg.Loss: -1.212,LR: 2.61E-04]Training epoch 10:  72%|███████▏  | 247/341 [00:04<00:01, 53.20it/s, Epoch: 10, Batch: 248,Loss: -0.635,Avg.Loss: -1.210,LR: 2.61E-04]Training epoch 10:  73%|███████▎  | 248/341 [00:04<00:01, 53.20it/s, Epoch: 10, Batch: 249,Loss: -0.901,Avg.Loss: -1.208,LR: 2.61E-04]Training epoch 10:  73%|███████▎  | 249/341 [00:04<00:01, 53.20it/s, Epoch: 10, Batch: 250,Loss: -1.240,Avg.Loss: -1.208,LR: 2.60E-04]Training epoch 10:  73%|███████▎  | 250/341 [00:04<00:01, 53.20it/s, Epoch: 10, Batch: 251,Loss: -1.229,Avg.Loss: -1.209,LR: 2.60E-04]Training epoch 10:  74%|███████▎  | 251/341 [00:04<00:01, 53.20it/s, Epoch: 10, Batch: 252,Loss: -1.813,Avg.Loss: -1.211,LR: 2.60E-04]Training epoch 10:  74%|███████▍  | 252/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 252,Loss: -1.813,Avg.Loss: -1.211,LR: 2.60E-04]Training epoch 10:  74%|███████▍  | 252/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 253,Loss: -1.670,Avg.Loss: -1.213,LR: 2.60E-04]Training epoch 10:  74%|███████▍  | 253/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 254,Loss: -1.302,Avg.Loss: -1.213,LR: 2.60E-04]Training epoch 10:  74%|███████▍  | 254/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 255,Loss: -1.287,Avg.Loss: -1.213,LR: 2.60E-04]Training epoch 10:  75%|███████▍  | 255/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 256,Loss: -1.863,Avg.Loss: -1.216,LR: 2.60E-04]Training epoch 10:  75%|███████▌  | 256/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 257,Loss: -1.259,Avg.Loss: -1.216,LR: 2.60E-04]Training epoch 10:  75%|███████▌  | 257/341 [00:04<00:01, 53.24it/s, Epoch: 10, Batch: 258,Loss: -0.270,Avg.Loss: -1.212,LR: 2.60E-04]Training epoch 10:  76%|███████▌  | 258/341 [00:04<00:01, 53.25it/s, Epoch: 10, Batch: 258,Loss: -0.270,Avg.Loss: -1.212,LR: 2.60E-04]Training epoch 10:  76%|███████▌  | 258/341 [00:04<00:01, 53.25it/s, Epoch: 10, Batch: 259,Loss: -1.049,Avg.Loss: -1.212,LR: 2.59E-04]Training epoch 10:  76%|███████▌  | 259/341 [00:04<00:01, 53.25it/s, Epoch: 10, Batch: 260,Loss: -1.656,Avg.Loss: -1.214,LR: 2.59E-04]Training epoch 10:  76%|███████▌  | 260/341 [00:04<00:01, 53.25it/s, Epoch: 10, Batch: 261,Loss: -1.110,Avg.Loss: -1.213,LR: 2.59E-04]Training epoch 10:  77%|███████▋  | 261/341 [00:04<00:01, 53.25it/s, Epoch: 10, Batch: 262,Loss: -0.092,Avg.Loss: -1.209,LR: 2.59E-04]Training epoch 10:  77%|███████▋  | 262/341 [00:04<00:01, 53.25it/s, Epoch: 10, Batch: 263,Loss: 0.518,Avg.Loss: -1.202,LR: 2.59E-04] Training epoch 10:  77%|███████▋  | 263/341 [00:04<00:01, 53.25it/s, Epoch: 10, Batch: 264,Loss: -0.703,Avg.Loss: -1.200,LR: 2.59E-04]Training epoch 10:  77%|███████▋  | 264/341 [00:04<00:01, 53.21it/s, Epoch: 10, Batch: 264,Loss: -0.703,Avg.Loss: -1.200,LR: 2.59E-04]Training epoch 10:  77%|███████▋  | 264/341 [00:04<00:01, 53.21it/s, Epoch: 10, Batch: 265,Loss: -2.113,Avg.Loss: -1.204,LR: 2.59E-04]Training epoch 10:  78%|███████▊  | 265/341 [00:04<00:01, 53.21it/s, Epoch: 10, Batch: 266,Loss: 0.158,Avg.Loss: -1.199,LR: 2.59E-04] Training epoch 10:  78%|███████▊  | 266/341 [00:05<00:01, 53.21it/s, Epoch: 10, Batch: 267,Loss: 2.291,Avg.Loss: -1.186,LR: 2.59E-04]Training epoch 10:  78%|███████▊  | 267/341 [00:05<00:01, 53.21it/s, Epoch: 10, Batch: 268,Loss: 2.469,Avg.Loss: -1.172,LR: 2.58E-04]Training epoch 10:  79%|███████▊  | 268/341 [00:05<00:01, 53.21it/s, Epoch: 10, Batch: 269,Loss: 1.806,Avg.Loss: -1.161,LR: 2.58E-04]Training epoch 10:  79%|███████▉  | 269/341 [00:05<00:01, 53.21it/s, Epoch: 10, Batch: 270,Loss: -0.769,Avg.Loss: -1.159,LR: 2.58E-04]Training epoch 10:  79%|███████▉  | 270/341 [00:05<00:01, 53.29it/s, Epoch: 10, Batch: 270,Loss: -0.769,Avg.Loss: -1.159,LR: 2.58E-04]Training epoch 10:  79%|███████▉  | 270/341 [00:05<00:01, 53.29it/s, Epoch: 10, Batch: 271,Loss: -1.690,Avg.Loss: -1.161,LR: 2.58E-04]Training epoch 10:  79%|███████▉  | 271/341 [00:05<00:01, 53.29it/s, Epoch: 10, Batch: 272,Loss: -1.044,Avg.Loss: -1.161,LR: 2.58E-04]Training epoch 10:  80%|███████▉  | 272/341 [00:05<00:01, 53.29it/s, Epoch: 10, Batch: 273,Loss: -0.488,Avg.Loss: -1.159,LR: 2.58E-04]Training epoch 10:  80%|████████  | 273/341 [00:05<00:01, 53.29it/s, Epoch: 10, Batch: 274,Loss: -1.429,Avg.Loss: -1.160,LR: 2.58E-04]Training epoch 10:  80%|████████  | 274/341 [00:05<00:01, 53.29it/s, Epoch: 10, Batch: 275,Loss: -1.801,Avg.Loss: -1.162,LR: 2.58E-04]Training epoch 10:  81%|████████  | 275/341 [00:05<00:01, 53.29it/s, Epoch: 10, Batch: 276,Loss: -1.549,Avg.Loss: -1.163,LR: 2.57E-04]Training epoch 10:  81%|████████  | 276/341 [00:05<00:01, 53.64it/s, Epoch: 10, Batch: 276,Loss: -1.549,Avg.Loss: -1.163,LR: 2.57E-04]Training epoch 10:  81%|████████  | 276/341 [00:05<00:01, 53.64it/s, Epoch: 10, Batch: 277,Loss: -1.489,Avg.Loss: -1.164,LR: 2.57E-04]Training epoch 10:  81%|████████  | 277/341 [00:05<00:01, 53.64it/s, Epoch: 10, Batch: 278,Loss: -1.786,Avg.Loss: -1.167,LR: 2.57E-04]Training epoch 10:  82%|████████▏ | 278/341 [00:05<00:01, 53.64it/s, Epoch: 10, Batch: 279,Loss: -1.696,Avg.Loss: -1.169,LR: 2.57E-04]Training epoch 10:  82%|████████▏ | 279/341 [00:05<00:01, 53.64it/s, Epoch: 10, Batch: 280,Loss: -1.499,Avg.Loss: -1.170,LR: 2.57E-04]Training epoch 10:  82%|████████▏ | 280/341 [00:05<00:01, 53.64it/s, Epoch: 10, Batch: 281,Loss: -1.190,Avg.Loss: -1.170,LR: 2.57E-04]Training epoch 10:  82%|████████▏ | 281/341 [00:05<00:01, 53.64it/s, Epoch: 10, Batch: 282,Loss: -1.026,Avg.Loss: -1.169,LR: 2.57E-04]Training epoch 10:  83%|████████▎ | 282/341 [00:05<00:01, 53.47it/s, Epoch: 10, Batch: 282,Loss: -1.026,Avg.Loss: -1.169,LR: 2.57E-04]Training epoch 10:  83%|████████▎ | 282/341 [00:05<00:01, 53.47it/s, Epoch: 10, Batch: 283,Loss: -1.155,Avg.Loss: -1.169,LR: 2.57E-04]Training epoch 10:  83%|████████▎ | 283/341 [00:05<00:01, 53.47it/s, Epoch: 10, Batch: 284,Loss: -1.943,Avg.Loss: -1.172,LR: 2.57E-04]Training epoch 10:  83%|████████▎ | 284/341 [00:05<00:01, 53.47it/s, Epoch: 10, Batch: 285,Loss: -1.316,Avg.Loss: -1.173,LR: 2.56E-04]Training epoch 10:  84%|████████▎ | 285/341 [00:05<00:01, 53.47it/s, Epoch: 10, Batch: 286,Loss: -0.792,Avg.Loss: -1.171,LR: 2.56E-04]Training epoch 10:  84%|████████▍ | 286/341 [00:05<00:01, 53.47it/s, Epoch: 10, Batch: 287,Loss: -0.839,Avg.Loss: -1.170,LR: 2.56E-04]Training epoch 10:  84%|████████▍ | 287/341 [00:05<00:01, 53.47it/s, Epoch: 10, Batch: 288,Loss: -1.165,Avg.Loss: -1.170,LR: 2.56E-04]Training epoch 10:  84%|████████▍ | 288/341 [00:05<00:00, 53.47it/s, Epoch: 10, Batch: 288,Loss: -1.165,Avg.Loss: -1.170,LR: 2.56E-04]Training epoch 10:  84%|████████▍ | 288/341 [00:05<00:00, 53.47it/s, Epoch: 10, Batch: 289,Loss: -1.205,Avg.Loss: -1.170,LR: 2.56E-04]Training epoch 10:  85%|████████▍ | 289/341 [00:05<00:00, 53.47it/s, Epoch: 10, Batch: 290,Loss: 0.817,Avg.Loss: -1.163,LR: 2.56E-04] Training epoch 10:  85%|████████▌ | 290/341 [00:05<00:00, 53.47it/s, Epoch: 10, Batch: 291,Loss: -0.833,Avg.Loss: -1.162,LR: 2.56E-04]Training epoch 10:  85%|████████▌ | 291/341 [00:05<00:00, 53.47it/s, Epoch: 10, Batch: 292,Loss: -1.029,Avg.Loss: -1.162,LR: 2.56E-04]Training epoch 10:  86%|████████▌ | 292/341 [00:05<00:00, 53.47it/s, Epoch: 10, Batch: 293,Loss: -0.351,Avg.Loss: -1.159,LR: 2.56E-04]Training epoch 10:  86%|████████▌ | 293/341 [00:05<00:00, 53.47it/s, Epoch: 10, Batch: 294,Loss: 1.851,Avg.Loss: -1.149,LR: 2.55E-04] Training epoch 10:  86%|████████▌ | 294/341 [00:05<00:00, 53.02it/s, Epoch: 10, Batch: 294,Loss: 1.851,Avg.Loss: -1.149,LR: 2.55E-04]Training epoch 10:  86%|████████▌ | 294/341 [00:05<00:00, 53.02it/s, Epoch: 10, Batch: 295,Loss: 0.600,Avg.Loss: -1.143,LR: 2.55E-04]Training epoch 10:  87%|████████▋ | 295/341 [00:05<00:00, 53.02it/s, Epoch: 10, Batch: 296,Loss: -0.292,Avg.Loss: -1.140,LR: 2.55E-04]Training epoch 10:  87%|████████▋ | 296/341 [00:05<00:00, 53.02it/s, Epoch: 10, Batch: 297,Loss: -1.642,Avg.Loss: -1.142,LR: 2.55E-04]Training epoch 10:  87%|████████▋ | 297/341 [00:05<00:00, 53.02it/s, Epoch: 10, Batch: 298,Loss: -1.304,Avg.Loss: -1.142,LR: 2.55E-04]Training epoch 10:  87%|████████▋ | 298/341 [00:05<00:00, 53.02it/s, Epoch: 10, Batch: 299,Loss: 0.288,Avg.Loss: -1.137,LR: 2.55E-04] Training epoch 10:  88%|████████▊ | 299/341 [00:05<00:00, 53.02it/s, Epoch: 10, Batch: 300,Loss: -0.468,Avg.Loss: -1.135,LR: 2.55E-04]Training epoch 10:  88%|████████▊ | 300/341 [00:05<00:00, 52.60it/s, Epoch: 10, Batch: 300,Loss: -0.468,Avg.Loss: -1.135,LR: 2.55E-04]Training epoch 10:  88%|████████▊ | 300/341 [00:05<00:00, 52.60it/s, Epoch: 10, Batch: 301,Loss: -0.877,Avg.Loss: -1.134,LR: 2.55E-04]Training epoch 10:  88%|████████▊ | 301/341 [00:05<00:00, 52.60it/s, Epoch: 10, Batch: 302,Loss: -1.595,Avg.Loss: -1.136,LR: 2.54E-04]Training epoch 10:  89%|████████▊ | 302/341 [00:05<00:00, 52.60it/s, Epoch: 10, Batch: 303,Loss: -0.607,Avg.Loss: -1.134,LR: 2.54E-04]Training epoch 10:  89%|████████▉ | 303/341 [00:05<00:00, 52.60it/s, Epoch: 10, Batch: 304,Loss: 0.290,Avg.Loss: -1.129,LR: 2.54E-04] Training epoch 10:  89%|████████▉ | 304/341 [00:05<00:00, 52.60it/s, Epoch: 10, Batch: 305,Loss: 1.115,Avg.Loss: -1.122,LR: 2.54E-04]Training epoch 10:  89%|████████▉ | 305/341 [00:05<00:00, 52.60it/s, Epoch: 10, Batch: 306,Loss: 0.015,Avg.Loss: -1.118,LR: 2.54E-04]Training epoch 10:  90%|████████▉ | 306/341 [00:05<00:00, 54.26it/s, Epoch: 10, Batch: 306,Loss: 0.015,Avg.Loss: -1.118,LR: 2.54E-04]Training epoch 10:  90%|████████▉ | 306/341 [00:05<00:00, 54.26it/s, Epoch: 10, Batch: 307,Loss: -1.769,Avg.Loss: -1.120,LR: 2.54E-04]Training epoch 10:  90%|█████████ | 307/341 [00:05<00:00, 54.26it/s, Epoch: 10, Batch: 308,Loss: -1.243,Avg.Loss: -1.121,LR: 2.54E-04]Training epoch 10:  90%|█████████ | 308/341 [00:05<00:00, 54.26it/s, Epoch: 10, Batch: 309,Loss: -0.649,Avg.Loss: -1.119,LR: 2.54E-04]Training epoch 10:  91%|█████████ | 309/341 [00:05<00:00, 54.26it/s, Epoch: 10, Batch: 310,Loss: -0.303,Avg.Loss: -1.117,LR: 2.54E-04]Training epoch 10:  91%|█████████ | 310/341 [00:05<00:00, 54.26it/s, Epoch: 10, Batch: 311,Loss: -1.061,Avg.Loss: -1.116,LR: 2.53E-04]Training epoch 10:  91%|█████████ | 311/341 [00:05<00:00, 54.26it/s, Epoch: 10, Batch: 312,Loss: -1.507,Avg.Loss: -1.118,LR: 2.53E-04]Training epoch 10:  91%|█████████▏| 312/341 [00:05<00:00, 53.80it/s, Epoch: 10, Batch: 312,Loss: -1.507,Avg.Loss: -1.118,LR: 2.53E-04]Training epoch 10:  91%|█████████▏| 312/341 [00:05<00:00, 53.80it/s, Epoch: 10, Batch: 313,Loss: -1.042,Avg.Loss: -1.117,LR: 2.53E-04]Training epoch 10:  92%|█████████▏| 313/341 [00:05<00:00, 53.80it/s, Epoch: 10, Batch: 314,Loss: -0.394,Avg.Loss: -1.115,LR: 2.53E-04]Training epoch 10:  92%|█████████▏| 314/341 [00:05<00:00, 53.80it/s, Epoch: 10, Batch: 315,Loss: -0.510,Avg.Loss: -1.113,LR: 2.53E-04]Training epoch 10:  92%|█████████▏| 315/341 [00:05<00:00, 53.80it/s, Epoch: 10, Batch: 316,Loss: -0.329,Avg.Loss: -1.111,LR: 2.53E-04]Training epoch 10:  93%|█████████▎| 316/341 [00:05<00:00, 53.80it/s, Epoch: 10, Batch: 317,Loss: -0.595,Avg.Loss: -1.109,LR: 2.53E-04]Training epoch 10:  93%|█████████▎| 317/341 [00:05<00:00, 53.80it/s, Epoch: 10, Batch: 318,Loss: -0.417,Avg.Loss: -1.107,LR: 2.53E-04]Training epoch 10:  93%|█████████▎| 318/341 [00:05<00:00, 53.72it/s, Epoch: 10, Batch: 318,Loss: -0.417,Avg.Loss: -1.107,LR: 2.53E-04]Training epoch 10:  93%|█████████▎| 318/341 [00:05<00:00, 53.72it/s, Epoch: 10, Batch: 319,Loss: 0.193,Avg.Loss: -1.103,LR: 2.53E-04] Training epoch 10:  94%|█████████▎| 319/341 [00:05<00:00, 53.72it/s, Epoch: 10, Batch: 320,Loss: -1.396,Avg.Loss: -1.104,LR: 2.52E-04]Training epoch 10:  94%|█████████▍| 320/341 [00:06<00:00, 53.72it/s, Epoch: 10, Batch: 321,Loss: -1.597,Avg.Loss: -1.105,LR: 2.52E-04]Training epoch 10:  94%|█████████▍| 321/341 [00:06<00:00, 53.72it/s, Epoch: 10, Batch: 322,Loss: -1.191,Avg.Loss: -1.106,LR: 2.52E-04]Training epoch 10:  94%|█████████▍| 322/341 [00:06<00:00, 53.72it/s, Epoch: 10, Batch: 323,Loss: -1.470,Avg.Loss: -1.107,LR: 2.52E-04]Training epoch 10:  95%|█████████▍| 323/341 [00:06<00:00, 53.72it/s, Epoch: 10, Batch: 324,Loss: -1.418,Avg.Loss: -1.108,LR: 2.52E-04]Training epoch 10:  95%|█████████▌| 324/341 [00:06<00:00, 53.26it/s, Epoch: 10, Batch: 324,Loss: -1.418,Avg.Loss: -1.108,LR: 2.52E-04]Training epoch 10:  95%|█████████▌| 324/341 [00:06<00:00, 53.26it/s, Epoch: 10, Batch: 325,Loss: -0.922,Avg.Loss: -1.107,LR: 2.52E-04]Training epoch 10:  95%|█████████▌| 325/341 [00:06<00:00, 53.26it/s, Epoch: 10, Batch: 326,Loss: -1.894,Avg.Loss: -1.110,LR: 2.52E-04]Training epoch 10:  96%|█████████▌| 326/341 [00:06<00:00, 53.26it/s, Epoch: 10, Batch: 327,Loss: -1.769,Avg.Loss: -1.112,LR: 2.52E-04]Training epoch 10:  96%|█████████▌| 327/341 [00:06<00:00, 53.26it/s, Epoch: 10, Batch: 328,Loss: -0.947,Avg.Loss: -1.111,LR: 2.51E-04]Training epoch 10:  96%|█████████▌| 328/341 [00:06<00:00, 53.26it/s, Epoch: 10, Batch: 329,Loss: -0.837,Avg.Loss: -1.110,LR: 2.51E-04]Training epoch 10:  96%|█████████▋| 329/341 [00:06<00:00, 53.26it/s, Epoch: 10, Batch: 330,Loss: -1.048,Avg.Loss: -1.110,LR: 2.51E-04]Training epoch 10:  97%|█████████▋| 330/341 [00:06<00:00, 52.50it/s, Epoch: 10, Batch: 330,Loss: -1.048,Avg.Loss: -1.110,LR: 2.51E-04]Training epoch 10:  97%|█████████▋| 330/341 [00:06<00:00, 52.50it/s, Epoch: 10, Batch: 331,Loss: -1.462,Avg.Loss: -1.111,LR: 2.51E-04]Training epoch 10:  97%|█████████▋| 331/341 [00:06<00:00, 52.50it/s, Epoch: 10, Batch: 332,Loss: -1.524,Avg.Loss: -1.112,LR: 2.51E-04]Training epoch 10:  97%|█████████▋| 332/341 [00:06<00:00, 52.50it/s, Epoch: 10, Batch: 333,Loss: -1.439,Avg.Loss: -1.113,LR: 2.51E-04]Training epoch 10:  98%|█████████▊| 333/341 [00:06<00:00, 52.50it/s, Epoch: 10, Batch: 334,Loss: -1.271,Avg.Loss: -1.114,LR: 2.51E-04]Training epoch 10:  98%|█████████▊| 334/341 [00:06<00:00, 52.50it/s, Epoch: 10, Batch: 335,Loss: -1.549,Avg.Loss: -1.115,LR: 2.51E-04]Training epoch 10:  98%|█████████▊| 335/341 [00:06<00:00, 52.50it/s, Epoch: 10, Batch: 336,Loss: -1.713,Avg.Loss: -1.117,LR: 2.51E-04]Training epoch 10:  99%|█████████▊| 336/341 [00:06<00:00, 51.66it/s, Epoch: 10, Batch: 336,Loss: -1.713,Avg.Loss: -1.117,LR: 2.51E-04]Training epoch 10:  99%|█████████▊| 336/341 [00:06<00:00, 51.66it/s, Epoch: 10, Batch: 337,Loss: -1.876,Avg.Loss: -1.119,LR: 2.50E-04]Training epoch 10:  99%|█████████▉| 337/341 [00:06<00:00, 51.66it/s, Epoch: 10, Batch: 338,Loss: -1.210,Avg.Loss: -1.119,LR: 2.50E-04]Training epoch 10:  99%|█████████▉| 338/341 [00:06<00:00, 51.66it/s, Epoch: 10, Batch: 339,Loss: -1.419,Avg.Loss: -1.120,LR: 2.50E-04]Training epoch 10:  99%|█████████▉| 339/341 [00:06<00:00, 51.66it/s, Epoch: 10, Batch: 340,Loss: -1.814,Avg.Loss: -1.122,LR: 2.50E-04]Training epoch 10: 100%|█████████▉| 340/341 [00:06<00:00, 51.66it/s, Epoch: 10, Batch: 341,Loss: -1.572,Avg.Loss: -1.124,LR: 2.50E-04]Training epoch 10: 100%|██████████| 341/341 [00:06<00:00, 53.25it/s, Epoch: 10, Batch: 341,Loss: -1.572,Avg.Loss: -1.124,LR: 2.50E-04]
Training epoch 11:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 11:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 11, Batch: 1,Loss: -1.118,Avg.Loss: -1.118,LR: 2.50E-04]Training epoch 11:   0%|          | 1/341 [00:00<00:12, 28.05it/s, Epoch: 11, Batch: 2,Loss: -0.383,Avg.Loss: -0.751,LR: 2.50E-04]Training epoch 11:   1%|          | 2/341 [00:00<00:08, 38.49it/s, Epoch: 11, Batch: 3,Loss: -1.322,Avg.Loss: -0.941,LR: 2.50E-04]Training epoch 11:   1%|          | 3/341 [00:00<00:07, 42.63it/s, Epoch: 11, Batch: 4,Loss: -1.250,Avg.Loss: -1.019,LR: 2.50E-04]Training epoch 11:   1%|          | 4/341 [00:00<00:07, 44.71it/s, Epoch: 11, Batch: 5,Loss: -1.432,Avg.Loss: -1.101,LR: 2.49E-04]Training epoch 11:   1%|▏         | 5/341 [00:00<00:07, 46.22it/s, Epoch: 11, Batch: 6,Loss: -1.950,Avg.Loss: -1.243,LR: 2.49E-04]Training epoch 11:   2%|▏         | 6/341 [00:00<00:06, 55.35it/s, Epoch: 11, Batch: 6,Loss: -1.950,Avg.Loss: -1.243,LR: 2.49E-04]Training epoch 11:   2%|▏         | 6/341 [00:00<00:06, 55.35it/s, Epoch: 11, Batch: 7,Loss: -1.806,Avg.Loss: -1.323,LR: 2.49E-04]Training epoch 11:   2%|▏         | 7/341 [00:00<00:06, 55.35it/s, Epoch: 11, Batch: 8,Loss: -1.426,Avg.Loss: -1.336,LR: 2.49E-04]Training epoch 11:   2%|▏         | 8/341 [00:00<00:06, 55.35it/s, Epoch: 11, Batch: 9,Loss: -1.603,Avg.Loss: -1.366,LR: 2.49E-04]Training epoch 11:   3%|▎         | 9/341 [00:00<00:05, 55.35it/s, Epoch: 11, Batch: 10,Loss: -1.579,Avg.Loss: -1.387,LR: 2.49E-04]Training epoch 11:   3%|▎         | 10/341 [00:00<00:05, 55.35it/s, Epoch: 11, Batch: 11,Loss: -1.550,Avg.Loss: -1.402,LR: 2.49E-04]Training epoch 11:   3%|▎         | 11/341 [00:00<00:05, 55.35it/s, Epoch: 11, Batch: 12,Loss: -1.771,Avg.Loss: -1.433,LR: 2.49E-04]Training epoch 11:   4%|▎         | 12/341 [00:00<00:06, 53.79it/s, Epoch: 11, Batch: 12,Loss: -1.771,Avg.Loss: -1.433,LR: 2.49E-04]Training epoch 11:   4%|▎         | 12/341 [00:00<00:06, 53.79it/s, Epoch: 11, Batch: 13,Loss: -2.048,Avg.Loss: -1.480,LR: 2.49E-04]Training epoch 11:   4%|▍         | 13/341 [00:00<00:06, 53.79it/s, Epoch: 11, Batch: 14,Loss: -1.708,Avg.Loss: -1.496,LR: 2.48E-04]Training epoch 11:   4%|▍         | 14/341 [00:00<00:06, 53.79it/s, Epoch: 11, Batch: 15,Loss: -1.417,Avg.Loss: -1.491,LR: 2.48E-04]Training epoch 11:   4%|▍         | 15/341 [00:00<00:06, 53.79it/s, Epoch: 11, Batch: 16,Loss: -2.019,Avg.Loss: -1.524,LR: 2.48E-04]Training epoch 11:   5%|▍         | 16/341 [00:00<00:06, 53.79it/s, Epoch: 11, Batch: 17,Loss: -2.079,Avg.Loss: -1.557,LR: 2.48E-04]Training epoch 11:   5%|▍         | 17/341 [00:00<00:06, 53.79it/s, Epoch: 11, Batch: 18,Loss: -2.084,Avg.Loss: -1.586,LR: 2.48E-04]Training epoch 11:   5%|▌         | 18/341 [00:00<00:06, 53.69it/s, Epoch: 11, Batch: 18,Loss: -2.084,Avg.Loss: -1.586,LR: 2.48E-04]Training epoch 11:   5%|▌         | 18/341 [00:00<00:06, 53.69it/s, Epoch: 11, Batch: 19,Loss: -1.945,Avg.Loss: -1.605,LR: 2.48E-04]Training epoch 11:   6%|▌         | 19/341 [00:00<00:05, 53.69it/s, Epoch: 11, Batch: 20,Loss: -2.071,Avg.Loss: -1.628,LR: 2.48E-04]Training epoch 11:   6%|▌         | 20/341 [00:00<00:05, 53.69it/s, Epoch: 11, Batch: 21,Loss: -1.830,Avg.Loss: -1.638,LR: 2.48E-04]Training epoch 11:   6%|▌         | 21/341 [00:00<00:05, 53.69it/s, Epoch: 11, Batch: 22,Loss: -1.248,Avg.Loss: -1.620,LR: 2.47E-04]Training epoch 11:   6%|▋         | 22/341 [00:00<00:05, 53.69it/s, Epoch: 11, Batch: 23,Loss: -1.460,Avg.Loss: -1.613,LR: 2.47E-04]Training epoch 11:   7%|▋         | 23/341 [00:00<00:05, 53.69it/s, Epoch: 11, Batch: 24,Loss: -1.700,Avg.Loss: -1.617,LR: 2.47E-04]Training epoch 11:   7%|▋         | 24/341 [00:00<00:05, 53.15it/s, Epoch: 11, Batch: 24,Loss: -1.700,Avg.Loss: -1.617,LR: 2.47E-04]Training epoch 11:   7%|▋         | 24/341 [00:00<00:05, 53.15it/s, Epoch: 11, Batch: 25,Loss: -1.542,Avg.Loss: -1.614,LR: 2.47E-04]Training epoch 11:   7%|▋         | 25/341 [00:00<00:05, 53.15it/s, Epoch: 11, Batch: 26,Loss: -1.506,Avg.Loss: -1.610,LR: 2.47E-04]Training epoch 11:   8%|▊         | 26/341 [00:00<00:05, 53.15it/s, Epoch: 11, Batch: 27,Loss: -1.922,Avg.Loss: -1.621,LR: 2.47E-04]Training epoch 11:   8%|▊         | 27/341 [00:00<00:05, 53.15it/s, Epoch: 11, Batch: 28,Loss: -1.355,Avg.Loss: -1.612,LR: 2.47E-04]Training epoch 11:   8%|▊         | 28/341 [00:00<00:05, 53.15it/s, Epoch: 11, Batch: 29,Loss: -0.994,Avg.Loss: -1.590,LR: 2.47E-04]Training epoch 11:   9%|▊         | 29/341 [00:00<00:05, 53.15it/s, Epoch: 11, Batch: 30,Loss: -1.473,Avg.Loss: -1.586,LR: 2.47E-04]Training epoch 11:   9%|▉         | 30/341 [00:00<00:05, 53.87it/s, Epoch: 11, Batch: 30,Loss: -1.473,Avg.Loss: -1.586,LR: 2.47E-04]Training epoch 11:   9%|▉         | 30/341 [00:00<00:05, 53.87it/s, Epoch: 11, Batch: 31,Loss: -1.518,Avg.Loss: -1.584,LR: 2.46E-04]Training epoch 11:   9%|▉         | 31/341 [00:00<00:05, 53.87it/s, Epoch: 11, Batch: 32,Loss: -0.961,Avg.Loss: -1.565,LR: 2.46E-04]Training epoch 11:   9%|▉         | 32/341 [00:00<00:05, 53.87it/s, Epoch: 11, Batch: 33,Loss: -1.781,Avg.Loss: -1.571,LR: 2.46E-04]Training epoch 11:  10%|▉         | 33/341 [00:00<00:05, 53.87it/s, Epoch: 11, Batch: 34,Loss: -2.247,Avg.Loss: -1.591,LR: 2.46E-04]Training epoch 11:  10%|▉         | 34/341 [00:00<00:05, 53.87it/s, Epoch: 11, Batch: 35,Loss: -1.842,Avg.Loss: -1.598,LR: 2.46E-04]Training epoch 11:  10%|█         | 35/341 [00:00<00:05, 53.87it/s, Epoch: 11, Batch: 36,Loss: -2.224,Avg.Loss: -1.616,LR: 2.46E-04]Training epoch 11:  11%|█         | 36/341 [00:00<00:05, 55.05it/s, Epoch: 11, Batch: 36,Loss: -2.224,Avg.Loss: -1.616,LR: 2.46E-04]Training epoch 11:  11%|█         | 36/341 [00:00<00:05, 55.05it/s, Epoch: 11, Batch: 37,Loss: -1.813,Avg.Loss: -1.621,LR: 2.46E-04]Training epoch 11:  11%|█         | 37/341 [00:00<00:05, 55.05it/s, Epoch: 11, Batch: 38,Loss: -1.651,Avg.Loss: -1.622,LR: 2.46E-04]Training epoch 11:  11%|█         | 38/341 [00:00<00:05, 55.05it/s, Epoch: 11, Batch: 39,Loss: -1.788,Avg.Loss: -1.626,LR: 2.46E-04]Training epoch 11:  11%|█▏        | 39/341 [00:00<00:05, 55.05it/s, Epoch: 11, Batch: 40,Loss: -1.614,Avg.Loss: -1.626,LR: 2.45E-04]Training epoch 11:  12%|█▏        | 40/341 [00:00<00:05, 55.05it/s, Epoch: 11, Batch: 41,Loss: -0.973,Avg.Loss: -1.610,LR: 2.45E-04]Training epoch 11:  12%|█▏        | 41/341 [00:00<00:05, 55.05it/s, Epoch: 11, Batch: 42,Loss: -1.805,Avg.Loss: -1.615,LR: 2.45E-04]Training epoch 11:  12%|█▏        | 42/341 [00:00<00:05, 55.65it/s, Epoch: 11, Batch: 42,Loss: -1.805,Avg.Loss: -1.615,LR: 2.45E-04]Training epoch 11:  12%|█▏        | 42/341 [00:00<00:05, 55.65it/s, Epoch: 11, Batch: 43,Loss: -1.653,Avg.Loss: -1.615,LR: 2.45E-04]Training epoch 11:  13%|█▎        | 43/341 [00:00<00:05, 55.65it/s, Epoch: 11, Batch: 44,Loss: -1.427,Avg.Loss: -1.611,LR: 2.45E-04]Training epoch 11:  13%|█▎        | 44/341 [00:00<00:05, 55.65it/s, Epoch: 11, Batch: 45,Loss: -1.763,Avg.Loss: -1.615,LR: 2.45E-04]Training epoch 11:  13%|█▎        | 45/341 [00:00<00:05, 55.65it/s, Epoch: 11, Batch: 46,Loss: -1.767,Avg.Loss: -1.618,LR: 2.45E-04]Training epoch 11:  13%|█▎        | 46/341 [00:00<00:05, 55.65it/s, Epoch: 11, Batch: 47,Loss: -1.117,Avg.Loss: -1.607,LR: 2.45E-04]Training epoch 11:  14%|█▍        | 47/341 [00:00<00:05, 55.65it/s, Epoch: 11, Batch: 48,Loss: -2.068,Avg.Loss: -1.617,LR: 2.44E-04]Training epoch 11:  14%|█▍        | 48/341 [00:00<00:05, 55.01it/s, Epoch: 11, Batch: 48,Loss: -2.068,Avg.Loss: -1.617,LR: 2.44E-04]Training epoch 11:  14%|█▍        | 48/341 [00:00<00:05, 55.01it/s, Epoch: 11, Batch: 49,Loss: -1.469,Avg.Loss: -1.614,LR: 2.44E-04]Training epoch 11:  14%|█▍        | 49/341 [00:00<00:05, 55.01it/s, Epoch: 11, Batch: 50,Loss: -0.650,Avg.Loss: -1.595,LR: 2.44E-04]Training epoch 11:  15%|█▍        | 50/341 [00:00<00:05, 55.01it/s, Epoch: 11, Batch: 51,Loss: -1.723,Avg.Loss: -1.597,LR: 2.44E-04]Training epoch 11:  15%|█▍        | 51/341 [00:00<00:05, 55.01it/s, Epoch: 11, Batch: 52,Loss: -2.035,Avg.Loss: -1.605,LR: 2.44E-04]Training epoch 11:  15%|█▌        | 52/341 [00:00<00:05, 55.01it/s, Epoch: 11, Batch: 53,Loss: -1.859,Avg.Loss: -1.610,LR: 2.44E-04]Training epoch 11:  16%|█▌        | 53/341 [00:00<00:05, 55.01it/s, Epoch: 11, Batch: 54,Loss: -2.315,Avg.Loss: -1.623,LR: 2.44E-04]Training epoch 11:  16%|█▌        | 54/341 [00:00<00:05, 53.97it/s, Epoch: 11, Batch: 54,Loss: -2.315,Avg.Loss: -1.623,LR: 2.44E-04]Training epoch 11:  16%|█▌        | 54/341 [00:01<00:05, 53.97it/s, Epoch: 11, Batch: 55,Loss: -1.932,Avg.Loss: -1.629,LR: 2.44E-04]Training epoch 11:  16%|█▌        | 55/341 [00:01<00:05, 53.97it/s, Epoch: 11, Batch: 56,Loss: -1.689,Avg.Loss: -1.630,LR: 2.44E-04]Training epoch 11:  16%|█▋        | 56/341 [00:01<00:05, 53.97it/s, Epoch: 11, Batch: 57,Loss: -2.203,Avg.Loss: -1.640,LR: 2.43E-04]Training epoch 11:  17%|█▋        | 57/341 [00:01<00:05, 53.97it/s, Epoch: 11, Batch: 58,Loss: -1.373,Avg.Loss: -1.635,LR: 2.43E-04]Training epoch 11:  17%|█▋        | 58/341 [00:01<00:05, 53.97it/s, Epoch: 11, Batch: 59,Loss: -1.039,Avg.Loss: -1.625,LR: 2.43E-04]Training epoch 11:  17%|█▋        | 59/341 [00:01<00:05, 53.97it/s, Epoch: 11, Batch: 60,Loss: -1.675,Avg.Loss: -1.626,LR: 2.43E-04]Training epoch 11:  18%|█▊        | 60/341 [00:01<00:05, 54.18it/s, Epoch: 11, Batch: 60,Loss: -1.675,Avg.Loss: -1.626,LR: 2.43E-04]Training epoch 11:  18%|█▊        | 60/341 [00:01<00:05, 54.18it/s, Epoch: 11, Batch: 61,Loss: -1.701,Avg.Loss: -1.627,LR: 2.43E-04]Training epoch 11:  18%|█▊        | 61/341 [00:01<00:05, 54.18it/s, Epoch: 11, Batch: 62,Loss: -1.478,Avg.Loss: -1.625,LR: 2.43E-04]Training epoch 11:  18%|█▊        | 62/341 [00:01<00:05, 54.18it/s, Epoch: 11, Batch: 63,Loss: -1.817,Avg.Loss: -1.628,LR: 2.43E-04]Training epoch 11:  18%|█▊        | 63/341 [00:01<00:05, 54.18it/s, Epoch: 11, Batch: 64,Loss: -1.237,Avg.Loss: -1.622,LR: 2.43E-04]Training epoch 11:  19%|█▉        | 64/341 [00:01<00:05, 54.18it/s, Epoch: 11, Batch: 65,Loss: -0.200,Avg.Loss: -1.600,LR: 2.43E-04]Training epoch 11:  19%|█▉        | 65/341 [00:01<00:05, 54.18it/s, Epoch: 11, Batch: 66,Loss: -1.373,Avg.Loss: -1.597,LR: 2.42E-04]Training epoch 11:  19%|█▉        | 66/341 [00:01<00:05, 54.48it/s, Epoch: 11, Batch: 66,Loss: -1.373,Avg.Loss: -1.597,LR: 2.42E-04]Training epoch 11:  19%|█▉        | 66/341 [00:01<00:05, 54.48it/s, Epoch: 11, Batch: 67,Loss: -2.404,Avg.Loss: -1.609,LR: 2.42E-04]Training epoch 11:  20%|█▉        | 67/341 [00:01<00:05, 54.48it/s, Epoch: 11, Batch: 68,Loss: 0.445,Avg.Loss: -1.578,LR: 2.42E-04] Training epoch 11:  20%|█▉        | 68/341 [00:01<00:05, 54.48it/s, Epoch: 11, Batch: 69,Loss: 1.756,Avg.Loss: -1.530,LR: 2.42E-04]Training epoch 11:  20%|██        | 69/341 [00:01<00:04, 54.48it/s, Epoch: 11, Batch: 70,Loss: 1.056,Avg.Loss: -1.493,LR: 2.42E-04]Training epoch 11:  21%|██        | 70/341 [00:01<00:04, 54.48it/s, Epoch: 11, Batch: 71,Loss: 0.609,Avg.Loss: -1.464,LR: 2.42E-04]Training epoch 11:  21%|██        | 71/341 [00:01<00:04, 54.48it/s, Epoch: 11, Batch: 72,Loss: -1.381,Avg.Loss: -1.462,LR: 2.42E-04]Training epoch 11:  21%|██        | 72/341 [00:01<00:04, 54.49it/s, Epoch: 11, Batch: 72,Loss: -1.381,Avg.Loss: -1.462,LR: 2.42E-04]Training epoch 11:  21%|██        | 72/341 [00:01<00:04, 54.49it/s, Epoch: 11, Batch: 73,Loss: -0.369,Avg.Loss: -1.447,LR: 2.42E-04]Training epoch 11:  21%|██▏       | 73/341 [00:01<00:04, 54.49it/s, Epoch: 11, Batch: 74,Loss: 1.306,Avg.Loss: -1.410,LR: 2.41E-04] Training epoch 11:  22%|██▏       | 74/341 [00:01<00:04, 54.49it/s, Epoch: 11, Batch: 75,Loss: 1.384,Avg.Loss: -1.373,LR: 2.41E-04]Training epoch 11:  22%|██▏       | 75/341 [00:01<00:04, 54.49it/s, Epoch: 11, Batch: 76,Loss: 0.107,Avg.Loss: -1.354,LR: 2.41E-04]Training epoch 11:  22%|██▏       | 76/341 [00:01<00:04, 54.49it/s, Epoch: 11, Batch: 77,Loss: -2.057,Avg.Loss: -1.363,LR: 2.41E-04]Training epoch 11:  23%|██▎       | 77/341 [00:01<00:04, 54.49it/s, Epoch: 11, Batch: 78,Loss: -0.777,Avg.Loss: -1.355,LR: 2.41E-04]Training epoch 11:  23%|██▎       | 78/341 [00:01<00:04, 55.28it/s, Epoch: 11, Batch: 78,Loss: -0.777,Avg.Loss: -1.355,LR: 2.41E-04]Training epoch 11:  23%|██▎       | 78/341 [00:01<00:04, 55.28it/s, Epoch: 11, Batch: 79,Loss: 0.433,Avg.Loss: -1.333,LR: 2.41E-04] Training epoch 11:  23%|██▎       | 79/341 [00:01<00:04, 55.28it/s, Epoch: 11, Batch: 80,Loss: 1.664,Avg.Loss: -1.295,LR: 2.41E-04]Training epoch 11:  23%|██▎       | 80/341 [00:01<00:04, 55.28it/s, Epoch: 11, Batch: 81,Loss: -0.965,Avg.Loss: -1.291,LR: 2.41E-04]Training epoch 11:  24%|██▍       | 81/341 [00:01<00:04, 55.28it/s, Epoch: 11, Batch: 82,Loss: -1.923,Avg.Loss: -1.299,LR: 2.41E-04]Training epoch 11:  24%|██▍       | 82/341 [00:01<00:04, 55.28it/s, Epoch: 11, Batch: 83,Loss: -1.065,Avg.Loss: -1.296,LR: 2.40E-04]Training epoch 11:  24%|██▍       | 83/341 [00:01<00:04, 55.28it/s, Epoch: 11, Batch: 84,Loss: 1.869,Avg.Loss: -1.258,LR: 2.40E-04] Training epoch 11:  25%|██▍       | 84/341 [00:01<00:04, 54.03it/s, Epoch: 11, Batch: 84,Loss: 1.869,Avg.Loss: -1.258,LR: 2.40E-04]Training epoch 11:  25%|██▍       | 84/341 [00:01<00:04, 54.03it/s, Epoch: 11, Batch: 85,Loss: 1.507,Avg.Loss: -1.226,LR: 2.40E-04]Training epoch 11:  25%|██▍       | 85/341 [00:01<00:04, 54.03it/s, Epoch: 11, Batch: 86,Loss: 0.526,Avg.Loss: -1.205,LR: 2.40E-04]Training epoch 11:  25%|██▌       | 86/341 [00:01<00:04, 54.03it/s, Epoch: 11, Batch: 87,Loss: -1.495,Avg.Loss: -1.209,LR: 2.40E-04]Training epoch 11:  26%|██▌       | 87/341 [00:01<00:04, 54.03it/s, Epoch: 11, Batch: 88,Loss: -0.766,Avg.Loss: -1.204,LR: 2.40E-04]Training epoch 11:  26%|██▌       | 88/341 [00:01<00:04, 54.03it/s, Epoch: 11, Batch: 89,Loss: 0.254,Avg.Loss: -1.187,LR: 2.40E-04] Training epoch 11:  26%|██▌       | 89/341 [00:01<00:04, 54.03it/s, Epoch: 11, Batch: 90,Loss: 1.384,Avg.Loss: -1.159,LR: 2.40E-04]Training epoch 11:  26%|██▋       | 90/341 [00:01<00:04, 54.29it/s, Epoch: 11, Batch: 90,Loss: 1.384,Avg.Loss: -1.159,LR: 2.40E-04]Training epoch 11:  26%|██▋       | 90/341 [00:01<00:04, 54.29it/s, Epoch: 11, Batch: 91,Loss: 0.308,Avg.Loss: -1.143,LR: 2.40E-04]Training epoch 11:  27%|██▋       | 91/341 [00:01<00:04, 54.29it/s, Epoch: 11, Batch: 92,Loss: -1.714,Avg.Loss: -1.149,LR: 2.39E-04]Training epoch 11:  27%|██▋       | 92/341 [00:01<00:04, 54.29it/s, Epoch: 11, Batch: 93,Loss: -1.464,Avg.Loss: -1.152,LR: 2.39E-04]Training epoch 11:  27%|██▋       | 93/341 [00:01<00:04, 54.29it/s, Epoch: 11, Batch: 94,Loss: 0.312,Avg.Loss: -1.137,LR: 2.39E-04] Training epoch 11:  28%|██▊       | 94/341 [00:01<00:04, 54.29it/s, Epoch: 11, Batch: 95,Loss: 0.757,Avg.Loss: -1.117,LR: 2.39E-04]Training epoch 11:  28%|██▊       | 95/341 [00:01<00:04, 54.29it/s, Epoch: 11, Batch: 96,Loss: -0.976,Avg.Loss: -1.115,LR: 2.39E-04]Training epoch 11:  28%|██▊       | 96/341 [00:01<00:04, 54.15it/s, Epoch: 11, Batch: 96,Loss: -0.976,Avg.Loss: -1.115,LR: 2.39E-04]Training epoch 11:  28%|██▊       | 96/341 [00:01<00:04, 54.15it/s, Epoch: 11, Batch: 97,Loss: -2.097,Avg.Loss: -1.125,LR: 2.39E-04]Training epoch 11:  28%|██▊       | 97/341 [00:01<00:04, 54.15it/s, Epoch: 11, Batch: 98,Loss: -0.358,Avg.Loss: -1.117,LR: 2.39E-04]Training epoch 11:  29%|██▊       | 98/341 [00:01<00:04, 54.15it/s, Epoch: 11, Batch: 99,Loss: 1.328,Avg.Loss: -1.093,LR: 2.39E-04] Training epoch 11:  29%|██▉       | 99/341 [00:01<00:04, 54.15it/s, Epoch: 11, Batch: 100,Loss: 1.310,Avg.Loss: -1.069,LR: 2.38E-04]Training epoch 11:  29%|██▉       | 100/341 [00:01<00:04, 54.15it/s, Epoch: 11, Batch: 101,Loss: -0.166,Avg.Loss: -1.060,LR: 2.38E-04]Training epoch 11:  30%|██▉       | 101/341 [00:01<00:04, 54.15it/s, Epoch: 11, Batch: 102,Loss: -1.484,Avg.Loss: -1.064,LR: 2.38E-04]Training epoch 11:  30%|██▉       | 102/341 [00:01<00:04, 53.65it/s, Epoch: 11, Batch: 102,Loss: -1.484,Avg.Loss: -1.064,LR: 2.38E-04]Training epoch 11:  30%|██▉       | 102/341 [00:01<00:04, 53.65it/s, Epoch: 11, Batch: 103,Loss: -1.072,Avg.Loss: -1.064,LR: 2.38E-04]Training epoch 11:  30%|███       | 103/341 [00:01<00:04, 53.65it/s, Epoch: 11, Batch: 104,Loss: 0.769,Avg.Loss: -1.046,LR: 2.38E-04] Training epoch 11:  30%|███       | 104/341 [00:01<00:04, 53.65it/s, Epoch: 11, Batch: 105,Loss: 0.880,Avg.Loss: -1.028,LR: 2.38E-04]Training epoch 11:  31%|███       | 105/341 [00:01<00:04, 53.65it/s, Epoch: 11, Batch: 106,Loss: -0.435,Avg.Loss: -1.022,LR: 2.38E-04]Training epoch 11:  31%|███       | 106/341 [00:01<00:04, 53.65it/s, Epoch: 11, Batch: 107,Loss: -1.828,Avg.Loss: -1.030,LR: 2.38E-04]Training epoch 11:  31%|███▏      | 107/341 [00:01<00:04, 53.65it/s, Epoch: 11, Batch: 108,Loss: -0.951,Avg.Loss: -1.029,LR: 2.38E-04]Training epoch 11:  32%|███▏      | 108/341 [00:01<00:04, 54.06it/s, Epoch: 11, Batch: 108,Loss: -0.951,Avg.Loss: -1.029,LR: 2.38E-04]Training epoch 11:  32%|███▏      | 108/341 [00:02<00:04, 54.06it/s, Epoch: 11, Batch: 109,Loss: 0.427,Avg.Loss: -1.016,LR: 2.37E-04] Training epoch 11:  32%|███▏      | 109/341 [00:02<00:04, 54.06it/s, Epoch: 11, Batch: 110,Loss: 0.753,Avg.Loss: -1.000,LR: 2.37E-04]Training epoch 11:  32%|███▏      | 110/341 [00:02<00:04, 54.06it/s, Epoch: 11, Batch: 111,Loss: 0.212,Avg.Loss: -0.989,LR: 2.37E-04]Training epoch 11:  33%|███▎      | 111/341 [00:02<00:04, 54.06it/s, Epoch: 11, Batch: 112,Loss: -1.854,Avg.Loss: -0.997,LR: 2.37E-04]Training epoch 11:  33%|███▎      | 112/341 [00:02<00:04, 54.06it/s, Epoch: 11, Batch: 113,Loss: -1.678,Avg.Loss: -1.003,LR: 2.37E-04]Training epoch 11:  33%|███▎      | 113/341 [00:02<00:04, 54.06it/s, Epoch: 11, Batch: 114,Loss: -0.444,Avg.Loss: -0.998,LR: 2.37E-04]Training epoch 11:  33%|███▎      | 114/341 [00:02<00:04, 54.11it/s, Epoch: 11, Batch: 114,Loss: -0.444,Avg.Loss: -0.998,LR: 2.37E-04]Training epoch 11:  33%|███▎      | 114/341 [00:02<00:04, 54.11it/s, Epoch: 11, Batch: 115,Loss: 0.334,Avg.Loss: -0.986,LR: 2.37E-04] Training epoch 11:  34%|███▎      | 115/341 [00:02<00:04, 54.11it/s, Epoch: 11, Batch: 116,Loss: -0.942,Avg.Loss: -0.986,LR: 2.37E-04]Training epoch 11:  34%|███▍      | 116/341 [00:02<00:04, 54.11it/s, Epoch: 11, Batch: 117,Loss: -1.920,Avg.Loss: -0.994,LR: 2.37E-04]Training epoch 11:  34%|███▍      | 117/341 [00:02<00:04, 54.11it/s, Epoch: 11, Batch: 118,Loss: -1.127,Avg.Loss: -0.995,LR: 2.36E-04]Training epoch 11:  35%|███▍      | 118/341 [00:02<00:04, 54.11it/s, Epoch: 11, Batch: 119,Loss: 0.232,Avg.Loss: -0.985,LR: 2.36E-04] Training epoch 11:  35%|███▍      | 119/341 [00:02<00:04, 54.11it/s, Epoch: 11, Batch: 120,Loss: 0.992,Avg.Loss: -0.968,LR: 2.36E-04]Training epoch 11:  35%|███▌      | 120/341 [00:02<00:04, 54.07it/s, Epoch: 11, Batch: 120,Loss: 0.992,Avg.Loss: -0.968,LR: 2.36E-04]Training epoch 11:  35%|███▌      | 120/341 [00:02<00:04, 54.07it/s, Epoch: 11, Batch: 121,Loss: -0.150,Avg.Loss: -0.961,LR: 2.36E-04]Training epoch 11:  35%|███▌      | 121/341 [00:02<00:04, 54.07it/s, Epoch: 11, Batch: 122,Loss: -1.641,Avg.Loss: -0.967,LR: 2.36E-04]Training epoch 11:  36%|███▌      | 122/341 [00:02<00:04, 54.07it/s, Epoch: 11, Batch: 123,Loss: -1.620,Avg.Loss: -0.972,LR: 2.36E-04]Training epoch 11:  36%|███▌      | 123/341 [00:02<00:04, 54.07it/s, Epoch: 11, Batch: 124,Loss: 0.102,Avg.Loss: -0.964,LR: 2.36E-04] Training epoch 11:  36%|███▋      | 124/341 [00:02<00:04, 54.07it/s, Epoch: 11, Batch: 125,Loss: -0.337,Avg.Loss: -0.959,LR: 2.36E-04]Training epoch 11:  37%|███▋      | 125/341 [00:02<00:03, 54.07it/s, Epoch: 11, Batch: 126,Loss: -0.887,Avg.Loss: -0.958,LR: 2.35E-04]Training epoch 11:  37%|███▋      | 126/341 [00:02<00:03, 53.77it/s, Epoch: 11, Batch: 126,Loss: -0.887,Avg.Loss: -0.958,LR: 2.35E-04]Training epoch 11:  37%|███▋      | 126/341 [00:02<00:03, 53.77it/s, Epoch: 11, Batch: 127,Loss: -2.023,Avg.Loss: -0.966,LR: 2.35E-04]Training epoch 11:  37%|███▋      | 127/341 [00:02<00:03, 53.77it/s, Epoch: 11, Batch: 128,Loss: -1.055,Avg.Loss: -0.967,LR: 2.35E-04]Training epoch 11:  38%|███▊      | 128/341 [00:02<00:03, 53.77it/s, Epoch: 11, Batch: 129,Loss: 0.983,Avg.Loss: -0.952,LR: 2.35E-04] Training epoch 11:  38%|███▊      | 129/341 [00:02<00:03, 53.77it/s, Epoch: 11, Batch: 130,Loss: 1.268,Avg.Loss: -0.935,LR: 2.35E-04]Training epoch 11:  38%|███▊      | 130/341 [00:02<00:03, 53.77it/s, Epoch: 11, Batch: 131,Loss: 0.710,Avg.Loss: -0.922,LR: 2.35E-04]Training epoch 11:  38%|███▊      | 131/341 [00:02<00:03, 53.77it/s, Epoch: 11, Batch: 132,Loss: -1.123,Avg.Loss: -0.924,LR: 2.35E-04]Training epoch 11:  39%|███▊      | 132/341 [00:02<00:03, 54.23it/s, Epoch: 11, Batch: 132,Loss: -1.123,Avg.Loss: -0.924,LR: 2.35E-04]Training epoch 11:  39%|███▊      | 132/341 [00:02<00:03, 54.23it/s, Epoch: 11, Batch: 133,Loss: -1.282,Avg.Loss: -0.927,LR: 2.35E-04]Training epoch 11:  39%|███▉      | 133/341 [00:02<00:03, 54.23it/s, Epoch: 11, Batch: 134,Loss: -0.458,Avg.Loss: -0.923,LR: 2.35E-04]Training epoch 11:  39%|███▉      | 134/341 [00:02<00:03, 54.23it/s, Epoch: 11, Batch: 135,Loss: -0.744,Avg.Loss: -0.922,LR: 2.34E-04]Training epoch 11:  40%|███▉      | 135/341 [00:02<00:03, 54.23it/s, Epoch: 11, Batch: 136,Loss: -1.327,Avg.Loss: -0.925,LR: 2.34E-04]Training epoch 11:  40%|███▉      | 136/341 [00:02<00:03, 54.23it/s, Epoch: 11, Batch: 137,Loss: -1.996,Avg.Loss: -0.932,LR: 2.34E-04]Training epoch 11:  40%|████      | 137/341 [00:02<00:03, 54.23it/s, Epoch: 11, Batch: 138,Loss: -1.082,Avg.Loss: -0.934,LR: 2.34E-04]Training epoch 11:  40%|████      | 138/341 [00:02<00:03, 53.79it/s, Epoch: 11, Batch: 138,Loss: -1.082,Avg.Loss: -0.934,LR: 2.34E-04]Training epoch 11:  40%|████      | 138/341 [00:02<00:03, 53.79it/s, Epoch: 11, Batch: 139,Loss: 0.823,Avg.Loss: -0.921,LR: 2.34E-04] Training epoch 11:  41%|████      | 139/341 [00:02<00:03, 53.79it/s, Epoch: 11, Batch: 140,Loss: 0.600,Avg.Loss: -0.910,LR: 2.34E-04]Training epoch 11:  41%|████      | 140/341 [00:02<00:03, 53.79it/s, Epoch: 11, Batch: 141,Loss: -0.276,Avg.Loss: -0.906,LR: 2.34E-04]Training epoch 11:  41%|████▏     | 141/341 [00:02<00:03, 53.79it/s, Epoch: 11, Batch: 142,Loss: -1.924,Avg.Loss: -0.913,LR: 2.34E-04]Training epoch 11:  42%|████▏     | 142/341 [00:02<00:03, 53.79it/s, Epoch: 11, Batch: 143,Loss: -1.759,Avg.Loss: -0.919,LR: 2.34E-04]Training epoch 11:  42%|████▏     | 143/341 [00:02<00:03, 53.79it/s, Epoch: 11, Batch: 144,Loss: 0.106,Avg.Loss: -0.912,LR: 2.33E-04] Training epoch 11:  42%|████▏     | 144/341 [00:02<00:03, 53.57it/s, Epoch: 11, Batch: 144,Loss: 0.106,Avg.Loss: -0.912,LR: 2.33E-04]Training epoch 11:  42%|████▏     | 144/341 [00:02<00:03, 53.57it/s, Epoch: 11, Batch: 145,Loss: -0.319,Avg.Loss: -0.907,LR: 2.33E-04]Training epoch 11:  43%|████▎     | 145/341 [00:02<00:03, 53.57it/s, Epoch: 11, Batch: 146,Loss: -0.720,Avg.Loss: -0.906,LR: 2.33E-04]Training epoch 11:  43%|████▎     | 146/341 [00:02<00:03, 53.57it/s, Epoch: 11, Batch: 147,Loss: -1.810,Avg.Loss: -0.912,LR: 2.33E-04]Training epoch 11:  43%|████▎     | 147/341 [00:02<00:03, 53.57it/s, Epoch: 11, Batch: 148,Loss: -1.267,Avg.Loss: -0.915,LR: 2.33E-04]Training epoch 11:  43%|████▎     | 148/341 [00:02<00:03, 53.57it/s, Epoch: 11, Batch: 149,Loss: -0.368,Avg.Loss: -0.911,LR: 2.33E-04]Training epoch 11:  44%|████▎     | 149/341 [00:02<00:03, 53.57it/s, Epoch: 11, Batch: 150,Loss: 0.045,Avg.Loss: -0.905,LR: 2.33E-04] Training epoch 11:  44%|████▍     | 150/341 [00:02<00:03, 52.74it/s, Epoch: 11, Batch: 150,Loss: 0.045,Avg.Loss: -0.905,LR: 2.33E-04]Training epoch 11:  44%|████▍     | 150/341 [00:02<00:03, 52.74it/s, Epoch: 11, Batch: 151,Loss: -1.449,Avg.Loss: -0.908,LR: 2.33E-04]Training epoch 11:  44%|████▍     | 151/341 [00:02<00:03, 52.74it/s, Epoch: 11, Batch: 152,Loss: -2.032,Avg.Loss: -0.916,LR: 2.33E-04]Training epoch 11:  45%|████▍     | 152/341 [00:02<00:03, 52.74it/s, Epoch: 11, Batch: 153,Loss: -1.147,Avg.Loss: -0.917,LR: 2.32E-04]Training epoch 11:  45%|████▍     | 153/341 [00:02<00:03, 52.74it/s, Epoch: 11, Batch: 154,Loss: 0.379,Avg.Loss: -0.909,LR: 2.32E-04] Training epoch 11:  45%|████▌     | 154/341 [00:02<00:03, 52.74it/s, Epoch: 11, Batch: 155,Loss: 0.086,Avg.Loss: -0.902,LR: 2.32E-04]Training epoch 11:  45%|████▌     | 155/341 [00:02<00:03, 52.74it/s, Epoch: 11, Batch: 156,Loss: -0.911,Avg.Loss: -0.902,LR: 2.32E-04]Training epoch 11:  46%|████▌     | 156/341 [00:02<00:03, 52.94it/s, Epoch: 11, Batch: 156,Loss: -0.911,Avg.Loss: -0.902,LR: 2.32E-04]Training epoch 11:  46%|████▌     | 156/341 [00:02<00:03, 52.94it/s, Epoch: 11, Batch: 157,Loss: -1.661,Avg.Loss: -0.907,LR: 2.32E-04]Training epoch 11:  46%|████▌     | 157/341 [00:02<00:03, 52.94it/s, Epoch: 11, Batch: 158,Loss: -1.362,Avg.Loss: -0.910,LR: 2.32E-04]Training epoch 11:  46%|████▋     | 158/341 [00:02<00:03, 52.94it/s, Epoch: 11, Batch: 159,Loss: -0.280,Avg.Loss: -0.906,LR: 2.32E-04]Training epoch 11:  47%|████▋     | 159/341 [00:02<00:03, 52.94it/s, Epoch: 11, Batch: 160,Loss: 0.106,Avg.Loss: -0.900,LR: 2.32E-04] Training epoch 11:  47%|████▋     | 160/341 [00:02<00:03, 52.94it/s, Epoch: 11, Batch: 161,Loss: -0.830,Avg.Loss: -0.899,LR: 2.31E-04]Training epoch 11:  47%|████▋     | 161/341 [00:03<00:03, 52.94it/s, Epoch: 11, Batch: 162,Loss: -1.489,Avg.Loss: -0.903,LR: 2.31E-04]Training epoch 11:  48%|████▊     | 162/341 [00:03<00:03, 52.82it/s, Epoch: 11, Batch: 162,Loss: -1.489,Avg.Loss: -0.903,LR: 2.31E-04]Training epoch 11:  48%|████▊     | 162/341 [00:03<00:03, 52.82it/s, Epoch: 11, Batch: 163,Loss: -1.347,Avg.Loss: -0.906,LR: 2.31E-04]Training epoch 11:  48%|████▊     | 163/341 [00:03<00:03, 52.82it/s, Epoch: 11, Batch: 164,Loss: -0.164,Avg.Loss: -0.901,LR: 2.31E-04]Training epoch 11:  48%|████▊     | 164/341 [00:03<00:03, 52.82it/s, Epoch: 11, Batch: 165,Loss: -0.369,Avg.Loss: -0.898,LR: 2.31E-04]Training epoch 11:  48%|████▊     | 165/341 [00:03<00:03, 52.82it/s, Epoch: 11, Batch: 166,Loss: -0.894,Avg.Loss: -0.898,LR: 2.31E-04]Training epoch 11:  49%|████▊     | 166/341 [00:03<00:03, 52.82it/s, Epoch: 11, Batch: 167,Loss: -1.731,Avg.Loss: -0.903,LR: 2.31E-04]Training epoch 11:  49%|████▉     | 167/341 [00:03<00:03, 52.82it/s, Epoch: 11, Batch: 168,Loss: -1.074,Avg.Loss: -0.904,LR: 2.31E-04]Training epoch 11:  49%|████▉     | 168/341 [00:03<00:03, 53.97it/s, Epoch: 11, Batch: 168,Loss: -1.074,Avg.Loss: -0.904,LR: 2.31E-04]Training epoch 11:  49%|████▉     | 168/341 [00:03<00:03, 53.97it/s, Epoch: 11, Batch: 169,Loss: 0.291,Avg.Loss: -0.897,LR: 2.31E-04] Training epoch 11:  50%|████▉     | 169/341 [00:03<00:03, 53.97it/s, Epoch: 11, Batch: 170,Loss: 0.207,Avg.Loss: -0.890,LR: 2.30E-04]Training epoch 11:  50%|████▉     | 170/341 [00:03<00:03, 53.97it/s, Epoch: 11, Batch: 171,Loss: -0.770,Avg.Loss: -0.890,LR: 2.30E-04]Training epoch 11:  50%|█████     | 171/341 [00:03<00:03, 53.97it/s, Epoch: 11, Batch: 172,Loss: -1.640,Avg.Loss: -0.894,LR: 2.30E-04]Training epoch 11:  50%|█████     | 172/341 [00:03<00:03, 53.97it/s, Epoch: 11, Batch: 173,Loss: -1.665,Avg.Loss: -0.899,LR: 2.30E-04]Training epoch 11:  51%|█████     | 173/341 [00:03<00:03, 53.97it/s, Epoch: 11, Batch: 174,Loss: -1.143,Avg.Loss: -0.900,LR: 2.30E-04]Training epoch 11:  51%|█████     | 174/341 [00:03<00:03, 53.75it/s, Epoch: 11, Batch: 174,Loss: -1.143,Avg.Loss: -0.900,LR: 2.30E-04]Training epoch 11:  51%|█████     | 174/341 [00:03<00:03, 53.75it/s, Epoch: 11, Batch: 175,Loss: -0.676,Avg.Loss: -0.899,LR: 2.30E-04]Training epoch 11:  51%|█████▏    | 175/341 [00:03<00:03, 53.75it/s, Epoch: 11, Batch: 176,Loss: -1.335,Avg.Loss: -0.901,LR: 2.30E-04]Training epoch 11:  52%|█████▏    | 176/341 [00:03<00:03, 53.75it/s, Epoch: 11, Batch: 177,Loss: -1.651,Avg.Loss: -0.905,LR: 2.30E-04]Training epoch 11:  52%|█████▏    | 177/341 [00:03<00:03, 53.75it/s, Epoch: 11, Batch: 178,Loss: -1.360,Avg.Loss: -0.908,LR: 2.30E-04]Training epoch 11:  52%|█████▏    | 178/341 [00:03<00:03, 53.75it/s, Epoch: 11, Batch: 179,Loss: -0.544,Avg.Loss: -0.906,LR: 2.29E-04]Training epoch 11:  52%|█████▏    | 179/341 [00:03<00:03, 53.75it/s, Epoch: 11, Batch: 180,Loss: -0.726,Avg.Loss: -0.905,LR: 2.29E-04]Training epoch 11:  53%|█████▎    | 180/341 [00:03<00:02, 54.05it/s, Epoch: 11, Batch: 180,Loss: -0.726,Avg.Loss: -0.905,LR: 2.29E-04]Training epoch 11:  53%|█████▎    | 180/341 [00:03<00:02, 54.05it/s, Epoch: 11, Batch: 181,Loss: -1.291,Avg.Loss: -0.907,LR: 2.29E-04]Training epoch 11:  53%|█████▎    | 181/341 [00:03<00:02, 54.05it/s, Epoch: 11, Batch: 182,Loss: -1.507,Avg.Loss: -0.910,LR: 2.29E-04]Training epoch 11:  53%|█████▎    | 182/341 [00:03<00:02, 54.05it/s, Epoch: 11, Batch: 183,Loss: -1.162,Avg.Loss: -0.912,LR: 2.29E-04]Training epoch 11:  54%|█████▎    | 183/341 [00:03<00:02, 54.05it/s, Epoch: 11, Batch: 184,Loss: -1.362,Avg.Loss: -0.914,LR: 2.29E-04]Training epoch 11:  54%|█████▍    | 184/341 [00:03<00:02, 54.05it/s, Epoch: 11, Batch: 185,Loss: -1.831,Avg.Loss: -0.919,LR: 2.29E-04]Training epoch 11:  54%|█████▍    | 185/341 [00:03<00:02, 54.05it/s, Epoch: 11, Batch: 186,Loss: -1.271,Avg.Loss: -0.921,LR: 2.29E-04]Training epoch 11:  55%|█████▍    | 186/341 [00:03<00:02, 54.12it/s, Epoch: 11, Batch: 186,Loss: -1.271,Avg.Loss: -0.921,LR: 2.29E-04]Training epoch 11:  55%|█████▍    | 186/341 [00:03<00:02, 54.12it/s, Epoch: 11, Batch: 187,Loss: -0.999,Avg.Loss: -0.921,LR: 2.28E-04]Training epoch 11:  55%|█████▍    | 187/341 [00:03<00:02, 54.12it/s, Epoch: 11, Batch: 188,Loss: -0.842,Avg.Loss: -0.921,LR: 2.28E-04]Training epoch 11:  55%|█████▌    | 188/341 [00:03<00:02, 54.12it/s, Epoch: 11, Batch: 189,Loss: -1.563,Avg.Loss: -0.924,LR: 2.28E-04]Training epoch 11:  55%|█████▌    | 189/341 [00:03<00:02, 54.12it/s, Epoch: 11, Batch: 190,Loss: -1.511,Avg.Loss: -0.927,LR: 2.28E-04]Training epoch 11:  56%|█████▌    | 190/341 [00:03<00:02, 54.12it/s, Epoch: 11, Batch: 191,Loss: -1.393,Avg.Loss: -0.930,LR: 2.28E-04]Training epoch 11:  56%|█████▌    | 191/341 [00:03<00:02, 54.12it/s, Epoch: 11, Batch: 192,Loss: -1.019,Avg.Loss: -0.930,LR: 2.28E-04]Training epoch 11:  56%|█████▋    | 192/341 [00:03<00:02, 53.83it/s, Epoch: 11, Batch: 192,Loss: -1.019,Avg.Loss: -0.930,LR: 2.28E-04]Training epoch 11:  56%|█████▋    | 192/341 [00:03<00:02, 53.83it/s, Epoch: 11, Batch: 193,Loss: -1.583,Avg.Loss: -0.934,LR: 2.28E-04]Training epoch 11:  57%|█████▋    | 193/341 [00:03<00:02, 53.83it/s, Epoch: 11, Batch: 194,Loss: -1.790,Avg.Loss: -0.938,LR: 2.28E-04]Training epoch 11:  57%|█████▋    | 194/341 [00:03<00:02, 53.83it/s, Epoch: 11, Batch: 195,Loss: -1.343,Avg.Loss: -0.940,LR: 2.28E-04]Training epoch 11:  57%|█████▋    | 195/341 [00:03<00:02, 53.83it/s, Epoch: 11, Batch: 196,Loss: -1.110,Avg.Loss: -0.941,LR: 2.27E-04]Training epoch 11:  57%|█████▋    | 196/341 [00:03<00:02, 53.83it/s, Epoch: 11, Batch: 197,Loss: -1.781,Avg.Loss: -0.945,LR: 2.27E-04]Training epoch 11:  58%|█████▊    | 197/341 [00:03<00:02, 53.83it/s, Epoch: 11, Batch: 198,Loss: -1.435,Avg.Loss: -0.948,LR: 2.27E-04]Training epoch 11:  58%|█████▊    | 198/341 [00:03<00:02, 54.14it/s, Epoch: 11, Batch: 198,Loss: -1.435,Avg.Loss: -0.948,LR: 2.27E-04]Training epoch 11:  58%|█████▊    | 198/341 [00:03<00:02, 54.14it/s, Epoch: 11, Batch: 199,Loss: -1.187,Avg.Loss: -0.949,LR: 2.27E-04]Training epoch 11:  58%|█████▊    | 199/341 [00:03<00:02, 54.14it/s, Epoch: 11, Batch: 200,Loss: -1.570,Avg.Loss: -0.952,LR: 2.27E-04]Training epoch 11:  59%|█████▊    | 200/341 [00:03<00:02, 54.14it/s, Epoch: 11, Batch: 201,Loss: -1.688,Avg.Loss: -0.956,LR: 2.27E-04]Training epoch 11:  59%|█████▉    | 201/341 [00:03<00:02, 54.14it/s, Epoch: 11, Batch: 202,Loss: -1.227,Avg.Loss: -0.957,LR: 2.27E-04]Training epoch 11:  59%|█████▉    | 202/341 [00:03<00:02, 54.14it/s, Epoch: 11, Batch: 203,Loss: -0.417,Avg.Loss: -0.955,LR: 2.27E-04]Training epoch 11:  60%|█████▉    | 203/341 [00:03<00:02, 54.14it/s, Epoch: 11, Batch: 204,Loss: -0.652,Avg.Loss: -0.953,LR: 2.27E-04]Training epoch 11:  60%|█████▉    | 204/341 [00:03<00:02, 54.03it/s, Epoch: 11, Batch: 204,Loss: -0.652,Avg.Loss: -0.953,LR: 2.27E-04]Training epoch 11:  60%|█████▉    | 204/341 [00:03<00:02, 54.03it/s, Epoch: 11, Batch: 205,Loss: -1.465,Avg.Loss: -0.956,LR: 2.26E-04]Training epoch 11:  60%|██████    | 205/341 [00:03<00:02, 54.03it/s, Epoch: 11, Batch: 206,Loss: -1.738,Avg.Loss: -0.959,LR: 2.26E-04]Training epoch 11:  60%|██████    | 206/341 [00:03<00:02, 54.03it/s, Epoch: 11, Batch: 207,Loss: -1.638,Avg.Loss: -0.963,LR: 2.26E-04]Training epoch 11:  61%|██████    | 207/341 [00:03<00:02, 54.03it/s, Epoch: 11, Batch: 208,Loss: -1.306,Avg.Loss: -0.964,LR: 2.26E-04]Training epoch 11:  61%|██████    | 208/341 [00:03<00:02, 54.03it/s, Epoch: 11, Batch: 209,Loss: -1.946,Avg.Loss: -0.969,LR: 2.26E-04]Training epoch 11:  61%|██████▏   | 209/341 [00:03<00:02, 54.03it/s, Epoch: 11, Batch: 210,Loss: -1.597,Avg.Loss: -0.972,LR: 2.26E-04]Training epoch 11:  62%|██████▏   | 210/341 [00:03<00:02, 53.99it/s, Epoch: 11, Batch: 210,Loss: -1.597,Avg.Loss: -0.972,LR: 2.26E-04]Training epoch 11:  62%|██████▏   | 210/341 [00:03<00:02, 53.99it/s, Epoch: 11, Batch: 211,Loss: -0.809,Avg.Loss: -0.971,LR: 2.26E-04]Training epoch 11:  62%|██████▏   | 211/341 [00:03<00:02, 53.99it/s, Epoch: 11, Batch: 212,Loss: -1.252,Avg.Loss: -0.973,LR: 2.26E-04]Training epoch 11:  62%|██████▏   | 212/341 [00:03<00:02, 53.99it/s, Epoch: 11, Batch: 213,Loss: -1.439,Avg.Loss: -0.975,LR: 2.26E-04]Training epoch 11:  62%|██████▏   | 213/341 [00:03<00:02, 53.99it/s, Epoch: 11, Batch: 214,Loss: -1.778,Avg.Loss: -0.978,LR: 2.25E-04]Training epoch 11:  63%|██████▎   | 214/341 [00:03<00:02, 53.99it/s, Epoch: 11, Batch: 215,Loss: -1.495,Avg.Loss: -0.981,LR: 2.25E-04]Training epoch 11:  63%|██████▎   | 215/341 [00:03<00:02, 53.99it/s, Epoch: 11, Batch: 216,Loss: -1.869,Avg.Loss: -0.985,LR: 2.25E-04]Training epoch 11:  63%|██████▎   | 216/341 [00:03<00:02, 54.02it/s, Epoch: 11, Batch: 216,Loss: -1.869,Avg.Loss: -0.985,LR: 2.25E-04]Training epoch 11:  63%|██████▎   | 216/341 [00:04<00:02, 54.02it/s, Epoch: 11, Batch: 217,Loss: -1.630,Avg.Loss: -0.988,LR: 2.25E-04]Training epoch 11:  64%|██████▎   | 217/341 [00:04<00:02, 54.02it/s, Epoch: 11, Batch: 218,Loss: -1.715,Avg.Loss: -0.991,LR: 2.25E-04]Training epoch 11:  64%|██████▍   | 218/341 [00:04<00:02, 54.02it/s, Epoch: 11, Batch: 219,Loss: -1.633,Avg.Loss: -0.994,LR: 2.25E-04]Training epoch 11:  64%|██████▍   | 219/341 [00:04<00:02, 54.02it/s, Epoch: 11, Batch: 220,Loss: -1.382,Avg.Loss: -0.996,LR: 2.25E-04]Training epoch 11:  65%|██████▍   | 220/341 [00:04<00:02, 54.02it/s, Epoch: 11, Batch: 221,Loss: -1.046,Avg.Loss: -0.996,LR: 2.25E-04]Training epoch 11:  65%|██████▍   | 221/341 [00:04<00:02, 54.02it/s, Epoch: 11, Batch: 222,Loss: -1.236,Avg.Loss: -0.997,LR: 2.24E-04]Training epoch 11:  65%|██████▌   | 222/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 222,Loss: -1.236,Avg.Loss: -0.997,LR: 2.24E-04]Training epoch 11:  65%|██████▌   | 222/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 223,Loss: -1.934,Avg.Loss: -1.001,LR: 2.24E-04]Training epoch 11:  65%|██████▌   | 223/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 224,Loss: -1.088,Avg.Loss: -1.002,LR: 2.24E-04]Training epoch 11:  66%|██████▌   | 224/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 225,Loss: -0.620,Avg.Loss: -1.000,LR: 2.24E-04]Training epoch 11:  66%|██████▌   | 225/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 226,Loss: -0.688,Avg.Loss: -0.999,LR: 2.24E-04]Training epoch 11:  66%|██████▋   | 226/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 227,Loss: -1.269,Avg.Loss: -1.000,LR: 2.24E-04]Training epoch 11:  67%|██████▋   | 227/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 228,Loss: -2.052,Avg.Loss: -1.005,LR: 2.24E-04]Training epoch 11:  67%|██████▋   | 228/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 228,Loss: -2.052,Avg.Loss: -1.005,LR: 2.24E-04]Training epoch 11:  67%|██████▋   | 228/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 229,Loss: -1.238,Avg.Loss: -1.006,LR: 2.24E-04]Training epoch 11:  67%|██████▋   | 229/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 230,Loss: 0.348,Avg.Loss: -1.000,LR: 2.24E-04] Training epoch 11:  67%|██████▋   | 230/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 231,Loss: 0.232,Avg.Loss: -0.994,LR: 2.23E-04]Training epoch 11:  68%|██████▊   | 231/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 232,Loss: -0.175,Avg.Loss: -0.991,LR: 2.23E-04]Training epoch 11:  68%|██████▊   | 232/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 233,Loss: -1.516,Avg.Loss: -0.993,LR: 2.23E-04]Training epoch 11:  68%|██████▊   | 233/341 [00:04<00:02, 53.95it/s, Epoch: 11, Batch: 234,Loss: -1.368,Avg.Loss: -0.995,LR: 2.23E-04]Training epoch 11:  69%|██████▊   | 234/341 [00:04<00:01, 53.97it/s, Epoch: 11, Batch: 234,Loss: -1.368,Avg.Loss: -0.995,LR: 2.23E-04]Training epoch 11:  69%|██████▊   | 234/341 [00:04<00:01, 53.97it/s, Epoch: 11, Batch: 235,Loss: -0.125,Avg.Loss: -0.991,LR: 2.23E-04]Training epoch 11:  69%|██████▉   | 235/341 [00:04<00:01, 53.97it/s, Epoch: 11, Batch: 236,Loss: -0.031,Avg.Loss: -0.987,LR: 2.23E-04]Training epoch 11:  69%|██████▉   | 236/341 [00:04<00:01, 53.97it/s, Epoch: 11, Batch: 237,Loss: -0.824,Avg.Loss: -0.986,LR: 2.23E-04]Training epoch 11:  70%|██████▉   | 237/341 [00:04<00:01, 53.97it/s, Epoch: 11, Batch: 238,Loss: -1.538,Avg.Loss: -0.989,LR: 2.23E-04]Training epoch 11:  70%|██████▉   | 238/341 [00:04<00:01, 53.97it/s, Epoch: 11, Batch: 239,Loss: -1.583,Avg.Loss: -0.991,LR: 2.23E-04]Training epoch 11:  70%|███████   | 239/341 [00:04<00:01, 53.97it/s, Epoch: 11, Batch: 240,Loss: -0.706,Avg.Loss: -0.990,LR: 2.22E-04]Training epoch 11:  70%|███████   | 240/341 [00:04<00:01, 54.90it/s, Epoch: 11, Batch: 240,Loss: -0.706,Avg.Loss: -0.990,LR: 2.22E-04]Training epoch 11:  70%|███████   | 240/341 [00:04<00:01, 54.90it/s, Epoch: 11, Batch: 241,Loss: -0.444,Avg.Loss: -0.988,LR: 2.22E-04]Training epoch 11:  71%|███████   | 241/341 [00:04<00:01, 54.90it/s, Epoch: 11, Batch: 242,Loss: -1.024,Avg.Loss: -0.988,LR: 2.22E-04]Training epoch 11:  71%|███████   | 242/341 [00:04<00:01, 54.90it/s, Epoch: 11, Batch: 243,Loss: -1.608,Avg.Loss: -0.990,LR: 2.22E-04]Training epoch 11:  71%|███████▏  | 243/341 [00:04<00:01, 54.90it/s, Epoch: 11, Batch: 244,Loss: -1.697,Avg.Loss: -0.993,LR: 2.22E-04]Training epoch 11:  72%|███████▏  | 244/341 [00:04<00:01, 54.90it/s, Epoch: 11, Batch: 245,Loss: -1.513,Avg.Loss: -0.995,LR: 2.22E-04]Training epoch 11:  72%|███████▏  | 245/341 [00:04<00:01, 54.90it/s, Epoch: 11, Batch: 246,Loss: -1.588,Avg.Loss: -0.998,LR: 2.22E-04]Training epoch 11:  72%|███████▏  | 246/341 [00:04<00:01, 54.47it/s, Epoch: 11, Batch: 246,Loss: -1.588,Avg.Loss: -0.998,LR: 2.22E-04]Training epoch 11:  72%|███████▏  | 246/341 [00:04<00:01, 54.47it/s, Epoch: 11, Batch: 247,Loss: -1.219,Avg.Loss: -0.999,LR: 2.22E-04]Training epoch 11:  72%|███████▏  | 247/341 [00:04<00:01, 54.47it/s, Epoch: 11, Batch: 248,Loss: -1.690,Avg.Loss: -1.001,LR: 2.22E-04]Training epoch 11:  73%|███████▎  | 248/341 [00:04<00:01, 54.47it/s, Epoch: 11, Batch: 249,Loss: -1.752,Avg.Loss: -1.004,LR: 2.21E-04]Training epoch 11:  73%|███████▎  | 249/341 [00:04<00:01, 54.47it/s, Epoch: 11, Batch: 250,Loss: -1.855,Avg.Loss: -1.008,LR: 2.21E-04]Training epoch 11:  73%|███████▎  | 250/341 [00:04<00:01, 54.47it/s, Epoch: 11, Batch: 251,Loss: -1.564,Avg.Loss: -1.010,LR: 2.21E-04]Training epoch 11:  74%|███████▎  | 251/341 [00:04<00:01, 54.47it/s, Epoch: 11, Batch: 252,Loss: -1.410,Avg.Loss: -1.012,LR: 2.21E-04]Training epoch 11:  74%|███████▍  | 252/341 [00:04<00:01, 54.28it/s, Epoch: 11, Batch: 252,Loss: -1.410,Avg.Loss: -1.012,LR: 2.21E-04]Training epoch 11:  74%|███████▍  | 252/341 [00:04<00:01, 54.28it/s, Epoch: 11, Batch: 253,Loss: -1.254,Avg.Loss: -1.013,LR: 2.21E-04]Training epoch 11:  74%|███████▍  | 253/341 [00:04<00:01, 54.28it/s, Epoch: 11, Batch: 254,Loss: -1.932,Avg.Loss: -1.016,LR: 2.21E-04]Training epoch 11:  74%|███████▍  | 254/341 [00:04<00:01, 54.28it/s, Epoch: 11, Batch: 255,Loss: -1.686,Avg.Loss: -1.019,LR: 2.21E-04]Training epoch 11:  75%|███████▍  | 255/341 [00:04<00:01, 54.28it/s, Epoch: 11, Batch: 256,Loss: -1.626,Avg.Loss: -1.021,LR: 2.21E-04]Training epoch 11:  75%|███████▌  | 256/341 [00:04<00:01, 54.28it/s, Epoch: 11, Batch: 257,Loss: -1.716,Avg.Loss: -1.024,LR: 2.20E-04]Training epoch 11:  75%|███████▌  | 257/341 [00:04<00:01, 54.28it/s, Epoch: 11, Batch: 258,Loss: -1.783,Avg.Loss: -1.027,LR: 2.20E-04]Training epoch 11:  76%|███████▌  | 258/341 [00:04<00:01, 53.85it/s, Epoch: 11, Batch: 258,Loss: -1.783,Avg.Loss: -1.027,LR: 2.20E-04]Training epoch 11:  76%|███████▌  | 258/341 [00:04<00:01, 53.85it/s, Epoch: 11, Batch: 259,Loss: -1.756,Avg.Loss: -1.030,LR: 2.20E-04]Training epoch 11:  76%|███████▌  | 259/341 [00:04<00:01, 53.85it/s, Epoch: 11, Batch: 260,Loss: -1.705,Avg.Loss: -1.032,LR: 2.20E-04]Training epoch 11:  76%|███████▌  | 260/341 [00:04<00:01, 53.85it/s, Epoch: 11, Batch: 261,Loss: -1.852,Avg.Loss: -1.035,LR: 2.20E-04]Training epoch 11:  77%|███████▋  | 261/341 [00:04<00:01, 53.85it/s, Epoch: 11, Batch: 262,Loss: -2.062,Avg.Loss: -1.039,LR: 2.20E-04]Training epoch 11:  77%|███████▋  | 262/341 [00:04<00:01, 53.85it/s, Epoch: 11, Batch: 263,Loss: -1.549,Avg.Loss: -1.041,LR: 2.20E-04]Training epoch 11:  77%|███████▋  | 263/341 [00:04<00:01, 53.85it/s, Epoch: 11, Batch: 264,Loss: -1.547,Avg.Loss: -1.043,LR: 2.20E-04]Training epoch 11:  77%|███████▋  | 264/341 [00:04<00:01, 54.06it/s, Epoch: 11, Batch: 264,Loss: -1.547,Avg.Loss: -1.043,LR: 2.20E-04]Training epoch 11:  77%|███████▋  | 264/341 [00:04<00:01, 54.06it/s, Epoch: 11, Batch: 265,Loss: -1.578,Avg.Loss: -1.045,LR: 2.20E-04]Training epoch 11:  78%|███████▊  | 265/341 [00:04<00:01, 54.06it/s, Epoch: 11, Batch: 266,Loss: -1.479,Avg.Loss: -1.047,LR: 2.19E-04]Training epoch 11:  78%|███████▊  | 266/341 [00:04<00:01, 54.06it/s, Epoch: 11, Batch: 267,Loss: -1.467,Avg.Loss: -1.048,LR: 2.19E-04]Training epoch 11:  78%|███████▊  | 267/341 [00:04<00:01, 54.06it/s, Epoch: 11, Batch: 268,Loss: -1.706,Avg.Loss: -1.051,LR: 2.19E-04]Training epoch 11:  79%|███████▊  | 268/341 [00:04<00:01, 54.06it/s, Epoch: 11, Batch: 269,Loss: -1.583,Avg.Loss: -1.053,LR: 2.19E-04]Training epoch 11:  79%|███████▉  | 269/341 [00:04<00:01, 54.06it/s, Epoch: 11, Batch: 270,Loss: -1.740,Avg.Loss: -1.055,LR: 2.19E-04]Training epoch 11:  79%|███████▉  | 270/341 [00:04<00:01, 53.98it/s, Epoch: 11, Batch: 270,Loss: -1.740,Avg.Loss: -1.055,LR: 2.19E-04]Training epoch 11:  79%|███████▉  | 270/341 [00:05<00:01, 53.98it/s, Epoch: 11, Batch: 271,Loss: -1.837,Avg.Loss: -1.058,LR: 2.19E-04]Training epoch 11:  79%|███████▉  | 271/341 [00:05<00:01, 53.98it/s, Epoch: 11, Batch: 272,Loss: -2.196,Avg.Loss: -1.062,LR: 2.19E-04]Training epoch 11:  80%|███████▉  | 272/341 [00:05<00:01, 53.98it/s, Epoch: 11, Batch: 273,Loss: -1.654,Avg.Loss: -1.065,LR: 2.19E-04]Training epoch 11:  80%|████████  | 273/341 [00:05<00:01, 53.98it/s, Epoch: 11, Batch: 274,Loss: -1.802,Avg.Loss: -1.067,LR: 2.19E-04]Training epoch 11:  80%|████████  | 274/341 [00:05<00:01, 53.98it/s, Epoch: 11, Batch: 275,Loss: -1.642,Avg.Loss: -1.069,LR: 2.18E-04]Training epoch 11:  81%|████████  | 275/341 [00:05<00:01, 53.98it/s, Epoch: 11, Batch: 276,Loss: -1.532,Avg.Loss: -1.071,LR: 2.18E-04]Training epoch 11:  81%|████████  | 276/341 [00:05<00:01, 53.59it/s, Epoch: 11, Batch: 276,Loss: -1.532,Avg.Loss: -1.071,LR: 2.18E-04]Training epoch 11:  81%|████████  | 276/341 [00:05<00:01, 53.59it/s, Epoch: 11, Batch: 277,Loss: -1.739,Avg.Loss: -1.074,LR: 2.18E-04]Training epoch 11:  81%|████████  | 277/341 [00:05<00:01, 53.59it/s, Epoch: 11, Batch: 278,Loss: -1.395,Avg.Loss: -1.075,LR: 2.18E-04]Training epoch 11:  82%|████████▏ | 278/341 [00:05<00:01, 53.59it/s, Epoch: 11, Batch: 279,Loss: -1.107,Avg.Loss: -1.075,LR: 2.18E-04]Training epoch 11:  82%|████████▏ | 279/341 [00:05<00:01, 53.59it/s, Epoch: 11, Batch: 280,Loss: -1.185,Avg.Loss: -1.075,LR: 2.18E-04]Training epoch 11:  82%|████████▏ | 280/341 [00:05<00:01, 53.59it/s, Epoch: 11, Batch: 281,Loss: -1.651,Avg.Loss: -1.077,LR: 2.18E-04]Training epoch 11:  82%|████████▏ | 281/341 [00:05<00:01, 53.59it/s, Epoch: 11, Batch: 282,Loss: -1.562,Avg.Loss: -1.079,LR: 2.18E-04]Training epoch 11:  83%|████████▎ | 282/341 [00:05<00:01, 53.85it/s, Epoch: 11, Batch: 282,Loss: -1.562,Avg.Loss: -1.079,LR: 2.18E-04]Training epoch 11:  83%|████████▎ | 282/341 [00:05<00:01, 53.85it/s, Epoch: 11, Batch: 283,Loss: -2.171,Avg.Loss: -1.083,LR: 2.18E-04]Training epoch 11:  83%|████████▎ | 283/341 [00:05<00:01, 53.85it/s, Epoch: 11, Batch: 284,Loss: -2.141,Avg.Loss: -1.087,LR: 2.17E-04]Training epoch 11:  83%|████████▎ | 284/341 [00:05<00:01, 53.85it/s, Epoch: 11, Batch: 285,Loss: -1.319,Avg.Loss: -1.087,LR: 2.17E-04]Training epoch 11:  84%|████████▎ | 285/341 [00:05<00:01, 53.85it/s, Epoch: 11, Batch: 286,Loss: -1.988,Avg.Loss: -1.090,LR: 2.17E-04]Training epoch 11:  84%|████████▍ | 286/341 [00:05<00:01, 53.85it/s, Epoch: 11, Batch: 287,Loss: -1.622,Avg.Loss: -1.092,LR: 2.17E-04]Training epoch 11:  84%|████████▍ | 287/341 [00:05<00:01, 53.85it/s, Epoch: 11, Batch: 288,Loss: -1.851,Avg.Loss: -1.095,LR: 2.17E-04]Training epoch 11:  84%|████████▍ | 288/341 [00:05<00:00, 53.92it/s, Epoch: 11, Batch: 288,Loss: -1.851,Avg.Loss: -1.095,LR: 2.17E-04]Training epoch 11:  84%|████████▍ | 288/341 [00:05<00:00, 53.92it/s, Epoch: 11, Batch: 289,Loss: -1.775,Avg.Loss: -1.097,LR: 2.17E-04]Training epoch 11:  85%|████████▍ | 289/341 [00:05<00:00, 53.92it/s, Epoch: 11, Batch: 290,Loss: -1.605,Avg.Loss: -1.099,LR: 2.17E-04]Training epoch 11:  85%|████████▌ | 290/341 [00:05<00:00, 53.92it/s, Epoch: 11, Batch: 291,Loss: -2.196,Avg.Loss: -1.103,LR: 2.17E-04]Training epoch 11:  85%|████████▌ | 291/341 [00:05<00:00, 53.92it/s, Epoch: 11, Batch: 292,Loss: -1.546,Avg.Loss: -1.104,LR: 2.16E-04]Training epoch 11:  86%|████████▌ | 292/341 [00:05<00:00, 53.92it/s, Epoch: 11, Batch: 293,Loss: -0.892,Avg.Loss: -1.104,LR: 2.16E-04]Training epoch 11:  86%|████████▌ | 293/341 [00:05<00:00, 53.92it/s, Epoch: 11, Batch: 294,Loss: -1.430,Avg.Loss: -1.105,LR: 2.16E-04]Training epoch 11:  86%|████████▌ | 294/341 [00:05<00:00, 54.62it/s, Epoch: 11, Batch: 294,Loss: -1.430,Avg.Loss: -1.105,LR: 2.16E-04]Training epoch 11:  86%|████████▌ | 294/341 [00:05<00:00, 54.62it/s, Epoch: 11, Batch: 295,Loss: -1.802,Avg.Loss: -1.107,LR: 2.16E-04]Training epoch 11:  87%|████████▋ | 295/341 [00:05<00:00, 54.62it/s, Epoch: 11, Batch: 296,Loss: -1.442,Avg.Loss: -1.108,LR: 2.16E-04]Training epoch 11:  87%|████████▋ | 296/341 [00:05<00:00, 54.62it/s, Epoch: 11, Batch: 297,Loss: 0.443,Avg.Loss: -1.103,LR: 2.16E-04] Training epoch 11:  87%|████████▋ | 297/341 [00:05<00:00, 54.62it/s, Epoch: 11, Batch: 298,Loss: 0.112,Avg.Loss: -1.099,LR: 2.16E-04]Training epoch 11:  87%|████████▋ | 298/341 [00:05<00:00, 54.62it/s, Epoch: 11, Batch: 299,Loss: -1.418,Avg.Loss: -1.100,LR: 2.16E-04]Training epoch 11:  88%|████████▊ | 299/341 [00:05<00:00, 54.62it/s, Epoch: 11, Batch: 300,Loss: -1.734,Avg.Loss: -1.102,LR: 2.16E-04]Training epoch 11:  88%|████████▊ | 300/341 [00:05<00:00, 52.17it/s, Epoch: 11, Batch: 300,Loss: -1.734,Avg.Loss: -1.102,LR: 2.16E-04]Training epoch 11:  88%|████████▊ | 300/341 [00:05<00:00, 52.17it/s, Epoch: 11, Batch: 301,Loss: -1.318,Avg.Loss: -1.103,LR: 2.15E-04]Training epoch 11:  88%|████████▊ | 301/341 [00:05<00:00, 52.17it/s, Epoch: 11, Batch: 302,Loss: -1.757,Avg.Loss: -1.105,LR: 2.15E-04]Training epoch 11:  89%|████████▊ | 302/341 [00:05<00:00, 52.17it/s, Epoch: 11, Batch: 303,Loss: -1.886,Avg.Loss: -1.108,LR: 2.15E-04]Training epoch 11:  89%|████████▉ | 303/341 [00:05<00:00, 52.17it/s, Epoch: 11, Batch: 304,Loss: -1.456,Avg.Loss: -1.109,LR: 2.15E-04]Training epoch 11:  89%|████████▉ | 304/341 [00:05<00:00, 52.17it/s, Epoch: 11, Batch: 305,Loss: -1.424,Avg.Loss: -1.110,LR: 2.15E-04]Training epoch 11:  89%|████████▉ | 305/341 [00:05<00:00, 52.17it/s, Epoch: 11, Batch: 306,Loss: -1.870,Avg.Loss: -1.112,LR: 2.15E-04]Training epoch 11:  90%|████████▉ | 306/341 [00:05<00:00, 51.54it/s, Epoch: 11, Batch: 306,Loss: -1.870,Avg.Loss: -1.112,LR: 2.15E-04]Training epoch 11:  90%|████████▉ | 306/341 [00:05<00:00, 51.54it/s, Epoch: 11, Batch: 307,Loss: -1.517,Avg.Loss: -1.114,LR: 2.15E-04]Training epoch 11:  90%|█████████ | 307/341 [00:05<00:00, 51.54it/s, Epoch: 11, Batch: 308,Loss: -0.965,Avg.Loss: -1.113,LR: 2.15E-04]Training epoch 11:  90%|█████████ | 308/341 [00:05<00:00, 51.54it/s, Epoch: 11, Batch: 309,Loss: -1.757,Avg.Loss: -1.115,LR: 2.15E-04]Training epoch 11:  91%|█████████ | 309/341 [00:05<00:00, 51.54it/s, Epoch: 11, Batch: 310,Loss: -1.703,Avg.Loss: -1.117,LR: 2.14E-04]Training epoch 11:  91%|█████████ | 310/341 [00:05<00:00, 51.54it/s, Epoch: 11, Batch: 311,Loss: -1.530,Avg.Loss: -1.118,LR: 2.14E-04]Training epoch 11:  91%|█████████ | 311/341 [00:05<00:00, 51.54it/s, Epoch: 11, Batch: 312,Loss: -0.974,Avg.Loss: -1.118,LR: 2.14E-04]Training epoch 11:  91%|█████████▏| 312/341 [00:05<00:00, 51.62it/s, Epoch: 11, Batch: 312,Loss: -0.974,Avg.Loss: -1.118,LR: 2.14E-04]Training epoch 11:  91%|█████████▏| 312/341 [00:05<00:00, 51.62it/s, Epoch: 11, Batch: 313,Loss: -0.633,Avg.Loss: -1.116,LR: 2.14E-04]Training epoch 11:  92%|█████████▏| 313/341 [00:05<00:00, 51.62it/s, Epoch: 11, Batch: 314,Loss: -0.794,Avg.Loss: -1.115,LR: 2.14E-04]Training epoch 11:  92%|█████████▏| 314/341 [00:05<00:00, 51.62it/s, Epoch: 11, Batch: 315,Loss: -1.176,Avg.Loss: -1.116,LR: 2.14E-04]Training epoch 11:  92%|█████████▏| 315/341 [00:05<00:00, 51.62it/s, Epoch: 11, Batch: 316,Loss: -0.300,Avg.Loss: -1.113,LR: 2.14E-04]Training epoch 11:  93%|█████████▎| 316/341 [00:05<00:00, 51.62it/s, Epoch: 11, Batch: 317,Loss: -1.025,Avg.Loss: -1.113,LR: 2.14E-04]Training epoch 11:  93%|█████████▎| 317/341 [00:05<00:00, 51.62it/s, Epoch: 11, Batch: 318,Loss: -1.453,Avg.Loss: -1.114,LR: 2.14E-04]Training epoch 11:  93%|█████████▎| 318/341 [00:05<00:00, 52.23it/s, Epoch: 11, Batch: 318,Loss: -1.453,Avg.Loss: -1.114,LR: 2.14E-04]Training epoch 11:  93%|█████████▎| 318/341 [00:05<00:00, 52.23it/s, Epoch: 11, Batch: 319,Loss: -1.528,Avg.Loss: -1.115,LR: 2.13E-04]Training epoch 11:  94%|█████████▎| 319/341 [00:05<00:00, 52.23it/s, Epoch: 11, Batch: 320,Loss: -0.209,Avg.Loss: -1.112,LR: 2.13E-04]Training epoch 11:  94%|█████████▍| 320/341 [00:05<00:00, 52.23it/s, Epoch: 11, Batch: 321,Loss: -0.102,Avg.Loss: -1.109,LR: 2.13E-04]Training epoch 11:  94%|█████████▍| 321/341 [00:05<00:00, 52.23it/s, Epoch: 11, Batch: 322,Loss: -1.366,Avg.Loss: -1.110,LR: 2.13E-04]Training epoch 11:  94%|█████████▍| 322/341 [00:06<00:00, 52.23it/s, Epoch: 11, Batch: 323,Loss: -1.634,Avg.Loss: -1.112,LR: 2.13E-04]Training epoch 11:  95%|█████████▍| 323/341 [00:06<00:00, 52.23it/s, Epoch: 11, Batch: 324,Loss: -1.412,Avg.Loss: -1.112,LR: 2.13E-04]Training epoch 11:  95%|█████████▌| 324/341 [00:06<00:00, 52.31it/s, Epoch: 11, Batch: 324,Loss: -1.412,Avg.Loss: -1.112,LR: 2.13E-04]Training epoch 11:  95%|█████████▌| 324/341 [00:06<00:00, 52.31it/s, Epoch: 11, Batch: 325,Loss: -0.072,Avg.Loss: -1.109,LR: 2.13E-04]Training epoch 11:  95%|█████████▌| 325/341 [00:06<00:00, 52.31it/s, Epoch: 11, Batch: 326,Loss: -0.178,Avg.Loss: -1.106,LR: 2.13E-04]Training epoch 11:  96%|█████████▌| 326/341 [00:06<00:00, 52.31it/s, Epoch: 11, Batch: 327,Loss: 0.079,Avg.Loss: -1.103,LR: 2.12E-04] Training epoch 11:  96%|█████████▌| 327/341 [00:06<00:00, 52.31it/s, Epoch: 11, Batch: 328,Loss: -0.942,Avg.Loss: -1.102,LR: 2.12E-04]Training epoch 11:  96%|█████████▌| 328/341 [00:06<00:00, 52.31it/s, Epoch: 11, Batch: 329,Loss: -1.729,Avg.Loss: -1.104,LR: 2.12E-04]Training epoch 11:  96%|█████████▋| 329/341 [00:06<00:00, 52.31it/s, Epoch: 11, Batch: 330,Loss: -1.728,Avg.Loss: -1.106,LR: 2.12E-04]Training epoch 11:  97%|█████████▋| 330/341 [00:06<00:00, 53.12it/s, Epoch: 11, Batch: 330,Loss: -1.728,Avg.Loss: -1.106,LR: 2.12E-04]Training epoch 11:  97%|█████████▋| 330/341 [00:06<00:00, 53.12it/s, Epoch: 11, Batch: 331,Loss: -1.922,Avg.Loss: -1.109,LR: 2.12E-04]Training epoch 11:  97%|█████████▋| 331/341 [00:06<00:00, 53.12it/s, Epoch: 11, Batch: 332,Loss: -1.673,Avg.Loss: -1.110,LR: 2.12E-04]Training epoch 11:  97%|█████████▋| 332/341 [00:06<00:00, 53.12it/s, Epoch: 11, Batch: 333,Loss: -1.563,Avg.Loss: -1.112,LR: 2.12E-04]Training epoch 11:  98%|█████████▊| 333/341 [00:06<00:00, 53.12it/s, Epoch: 11, Batch: 334,Loss: -1.726,Avg.Loss: -1.113,LR: 2.12E-04]Training epoch 11:  98%|█████████▊| 334/341 [00:06<00:00, 53.12it/s, Epoch: 11, Batch: 335,Loss: -1.694,Avg.Loss: -1.115,LR: 2.12E-04]Training epoch 11:  98%|█████████▊| 335/341 [00:06<00:00, 53.12it/s, Epoch: 11, Batch: 336,Loss: -1.401,Avg.Loss: -1.116,LR: 2.11E-04]Training epoch 11:  99%|█████████▊| 336/341 [00:06<00:00, 53.60it/s, Epoch: 11, Batch: 336,Loss: -1.401,Avg.Loss: -1.116,LR: 2.11E-04]Training epoch 11:  99%|█████████▊| 336/341 [00:06<00:00, 53.60it/s, Epoch: 11, Batch: 337,Loss: -1.413,Avg.Loss: -1.117,LR: 2.11E-04]Training epoch 11:  99%|█████████▉| 337/341 [00:06<00:00, 53.60it/s, Epoch: 11, Batch: 338,Loss: -1.650,Avg.Loss: -1.118,LR: 2.11E-04]Training epoch 11:  99%|█████████▉| 338/341 [00:06<00:00, 53.60it/s, Epoch: 11, Batch: 339,Loss: -1.557,Avg.Loss: -1.120,LR: 2.11E-04]Training epoch 11:  99%|█████████▉| 339/341 [00:06<00:00, 53.60it/s, Epoch: 11, Batch: 340,Loss: -1.928,Avg.Loss: -1.122,LR: 2.11E-04]Training epoch 11: 100%|█████████▉| 340/341 [00:06<00:00, 53.60it/s, Epoch: 11, Batch: 341,Loss: -1.504,Avg.Loss: -1.123,LR: 2.11E-04]Training epoch 11: 100%|██████████| 341/341 [00:06<00:00, 53.81it/s, Epoch: 11, Batch: 341,Loss: -1.504,Avg.Loss: -1.123,LR: 2.11E-04]
Training epoch 12:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 12:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 12, Batch: 1,Loss: -1.850,Avg.Loss: -1.850,LR: 2.11E-04]Training epoch 12:   0%|          | 1/341 [00:00<00:12, 28.23it/s, Epoch: 12, Batch: 2,Loss: -1.885,Avg.Loss: -1.867,LR: 2.11E-04]Training epoch 12:   1%|          | 2/341 [00:00<00:08, 38.78it/s, Epoch: 12, Batch: 3,Loss: -1.884,Avg.Loss: -1.873,LR: 2.11E-04]Training epoch 12:   1%|          | 3/341 [00:00<00:07, 43.45it/s, Epoch: 12, Batch: 4,Loss: -1.767,Avg.Loss: -1.846,LR: 2.10E-04]Training epoch 12:   1%|          | 4/341 [00:00<00:07, 45.90it/s, Epoch: 12, Batch: 5,Loss: -1.634,Avg.Loss: -1.804,LR: 2.10E-04]Training epoch 12:   1%|▏         | 5/341 [00:00<00:07, 47.27it/s, Epoch: 12, Batch: 6,Loss: -1.128,Avg.Loss: -1.691,LR: 2.10E-04]Training epoch 12:   2%|▏         | 6/341 [00:00<00:05, 56.61it/s, Epoch: 12, Batch: 6,Loss: -1.128,Avg.Loss: -1.691,LR: 2.10E-04]Training epoch 12:   2%|▏         | 6/341 [00:00<00:05, 56.61it/s, Epoch: 12, Batch: 7,Loss: -1.298,Avg.Loss: -1.635,LR: 2.10E-04]Training epoch 12:   2%|▏         | 7/341 [00:00<00:05, 56.61it/s, Epoch: 12, Batch: 8,Loss: -1.611,Avg.Loss: -1.632,LR: 2.10E-04]Training epoch 12:   2%|▏         | 8/341 [00:00<00:05, 56.61it/s, Epoch: 12, Batch: 9,Loss: -1.536,Avg.Loss: -1.621,LR: 2.10E-04]Training epoch 12:   3%|▎         | 9/341 [00:00<00:05, 56.61it/s, Epoch: 12, Batch: 10,Loss: -1.377,Avg.Loss: -1.597,LR: 2.10E-04]Training epoch 12:   3%|▎         | 10/341 [00:00<00:05, 56.61it/s, Epoch: 12, Batch: 11,Loss: -2.000,Avg.Loss: -1.634,LR: 2.10E-04]Training epoch 12:   3%|▎         | 11/341 [00:00<00:05, 56.61it/s, Epoch: 12, Batch: 12,Loss: -1.941,Avg.Loss: -1.659,LR: 2.10E-04]Training epoch 12:   4%|▎         | 12/341 [00:00<00:05, 55.23it/s, Epoch: 12, Batch: 12,Loss: -1.941,Avg.Loss: -1.659,LR: 2.10E-04]Training epoch 12:   4%|▎         | 12/341 [00:00<00:05, 55.23it/s, Epoch: 12, Batch: 13,Loss: -1.750,Avg.Loss: -1.666,LR: 2.09E-04]Training epoch 12:   4%|▍         | 13/341 [00:00<00:05, 55.23it/s, Epoch: 12, Batch: 14,Loss: -1.944,Avg.Loss: -1.686,LR: 2.09E-04]Training epoch 12:   4%|▍         | 14/341 [00:00<00:05, 55.23it/s, Epoch: 12, Batch: 15,Loss: -1.683,Avg.Loss: -1.686,LR: 2.09E-04]Training epoch 12:   4%|▍         | 15/341 [00:00<00:05, 55.23it/s, Epoch: 12, Batch: 16,Loss: -1.199,Avg.Loss: -1.656,LR: 2.09E-04]Training epoch 12:   5%|▍         | 16/341 [00:00<00:05, 55.23it/s, Epoch: 12, Batch: 17,Loss: -1.569,Avg.Loss: -1.650,LR: 2.09E-04]Training epoch 12:   5%|▍         | 17/341 [00:00<00:05, 55.23it/s, Epoch: 12, Batch: 18,Loss: -1.984,Avg.Loss: -1.669,LR: 2.09E-04]Training epoch 12:   5%|▌         | 18/341 [00:00<00:05, 54.08it/s, Epoch: 12, Batch: 18,Loss: -1.984,Avg.Loss: -1.669,LR: 2.09E-04]Training epoch 12:   5%|▌         | 18/341 [00:00<00:05, 54.08it/s, Epoch: 12, Batch: 19,Loss: -1.766,Avg.Loss: -1.674,LR: 2.09E-04]Training epoch 12:   6%|▌         | 19/341 [00:00<00:05, 54.08it/s, Epoch: 12, Batch: 20,Loss: -2.270,Avg.Loss: -1.704,LR: 2.09E-04]Training epoch 12:   6%|▌         | 20/341 [00:00<00:05, 54.08it/s, Epoch: 12, Batch: 21,Loss: -1.821,Avg.Loss: -1.709,LR: 2.09E-04]Training epoch 12:   6%|▌         | 21/341 [00:00<00:05, 54.08it/s, Epoch: 12, Batch: 22,Loss: -1.599,Avg.Loss: -1.704,LR: 2.08E-04]Training epoch 12:   6%|▋         | 22/341 [00:00<00:05, 54.08it/s, Epoch: 12, Batch: 23,Loss: -1.770,Avg.Loss: -1.707,LR: 2.08E-04]Training epoch 12:   7%|▋         | 23/341 [00:00<00:05, 54.08it/s, Epoch: 12, Batch: 24,Loss: -1.875,Avg.Loss: -1.714,LR: 2.08E-04]Training epoch 12:   7%|▋         | 24/341 [00:00<00:05, 52.87it/s, Epoch: 12, Batch: 24,Loss: -1.875,Avg.Loss: -1.714,LR: 2.08E-04]Training epoch 12:   7%|▋         | 24/341 [00:00<00:05, 52.87it/s, Epoch: 12, Batch: 25,Loss: -1.643,Avg.Loss: -1.711,LR: 2.08E-04]Training epoch 12:   7%|▋         | 25/341 [00:00<00:05, 52.87it/s, Epoch: 12, Batch: 26,Loss: -1.969,Avg.Loss: -1.721,LR: 2.08E-04]Training epoch 12:   8%|▊         | 26/341 [00:00<00:05, 52.87it/s, Epoch: 12, Batch: 27,Loss: -1.656,Avg.Loss: -1.719,LR: 2.08E-04]Training epoch 12:   8%|▊         | 27/341 [00:00<00:05, 52.87it/s, Epoch: 12, Batch: 28,Loss: -1.424,Avg.Loss: -1.708,LR: 2.08E-04]Training epoch 12:   8%|▊         | 28/341 [00:00<00:05, 52.87it/s, Epoch: 12, Batch: 29,Loss: -1.967,Avg.Loss: -1.717,LR: 2.08E-04]Training epoch 12:   9%|▊         | 29/341 [00:00<00:05, 52.87it/s, Epoch: 12, Batch: 30,Loss: -2.056,Avg.Loss: -1.729,LR: 2.07E-04]Training epoch 12:   9%|▉         | 30/341 [00:00<00:05, 52.20it/s, Epoch: 12, Batch: 30,Loss: -2.056,Avg.Loss: -1.729,LR: 2.07E-04]Training epoch 12:   9%|▉         | 30/341 [00:00<00:05, 52.20it/s, Epoch: 12, Batch: 31,Loss: -1.760,Avg.Loss: -1.730,LR: 2.07E-04]Training epoch 12:   9%|▉         | 31/341 [00:00<00:05, 52.20it/s, Epoch: 12, Batch: 32,Loss: -1.987,Avg.Loss: -1.738,LR: 2.07E-04]Training epoch 12:   9%|▉         | 32/341 [00:00<00:05, 52.20it/s, Epoch: 12, Batch: 33,Loss: -1.727,Avg.Loss: -1.737,LR: 2.07E-04]Training epoch 12:  10%|▉         | 33/341 [00:00<00:05, 52.20it/s, Epoch: 12, Batch: 34,Loss: -1.963,Avg.Loss: -1.744,LR: 2.07E-04]Training epoch 12:  10%|▉         | 34/341 [00:00<00:05, 52.20it/s, Epoch: 12, Batch: 35,Loss: -1.910,Avg.Loss: -1.749,LR: 2.07E-04]Training epoch 12:  10%|█         | 35/341 [00:00<00:05, 52.20it/s, Epoch: 12, Batch: 36,Loss: -1.765,Avg.Loss: -1.749,LR: 2.07E-04]Training epoch 12:  11%|█         | 36/341 [00:00<00:05, 52.64it/s, Epoch: 12, Batch: 36,Loss: -1.765,Avg.Loss: -1.749,LR: 2.07E-04]Training epoch 12:  11%|█         | 36/341 [00:00<00:05, 52.64it/s, Epoch: 12, Batch: 37,Loss: -1.459,Avg.Loss: -1.741,LR: 2.07E-04]Training epoch 12:  11%|█         | 37/341 [00:00<00:05, 52.64it/s, Epoch: 12, Batch: 38,Loss: -2.011,Avg.Loss: -1.748,LR: 2.07E-04]Training epoch 12:  11%|█         | 38/341 [00:00<00:05, 52.64it/s, Epoch: 12, Batch: 39,Loss: -1.579,Avg.Loss: -1.744,LR: 2.06E-04]Training epoch 12:  11%|█▏        | 39/341 [00:00<00:05, 52.64it/s, Epoch: 12, Batch: 40,Loss: -1.004,Avg.Loss: -1.726,LR: 2.06E-04]Training epoch 12:  12%|█▏        | 40/341 [00:00<00:05, 52.64it/s, Epoch: 12, Batch: 41,Loss: -1.523,Avg.Loss: -1.721,LR: 2.06E-04]Training epoch 12:  12%|█▏        | 41/341 [00:00<00:05, 52.64it/s, Epoch: 12, Batch: 42,Loss: -2.161,Avg.Loss: -1.731,LR: 2.06E-04]Training epoch 12:  12%|█▏        | 42/341 [00:00<00:05, 52.83it/s, Epoch: 12, Batch: 42,Loss: -2.161,Avg.Loss: -1.731,LR: 2.06E-04]Training epoch 12:  12%|█▏        | 42/341 [00:00<00:05, 52.83it/s, Epoch: 12, Batch: 43,Loss: -2.268,Avg.Loss: -1.744,LR: 2.06E-04]Training epoch 12:  13%|█▎        | 43/341 [00:00<00:05, 52.83it/s, Epoch: 12, Batch: 44,Loss: -2.381,Avg.Loss: -1.758,LR: 2.06E-04]Training epoch 12:  13%|█▎        | 44/341 [00:00<00:05, 52.83it/s, Epoch: 12, Batch: 45,Loss: -1.735,Avg.Loss: -1.758,LR: 2.06E-04]Training epoch 12:  13%|█▎        | 45/341 [00:00<00:05, 52.83it/s, Epoch: 12, Batch: 46,Loss: -1.814,Avg.Loss: -1.759,LR: 2.06E-04]Training epoch 12:  13%|█▎        | 46/341 [00:00<00:05, 52.83it/s, Epoch: 12, Batch: 47,Loss: -1.835,Avg.Loss: -1.760,LR: 2.06E-04]Training epoch 12:  14%|█▍        | 47/341 [00:00<00:05, 52.83it/s, Epoch: 12, Batch: 48,Loss: -1.787,Avg.Loss: -1.761,LR: 2.05E-04]Training epoch 12:  14%|█▍        | 48/341 [00:00<00:05, 52.85it/s, Epoch: 12, Batch: 48,Loss: -1.787,Avg.Loss: -1.761,LR: 2.05E-04]Training epoch 12:  14%|█▍        | 48/341 [00:00<00:05, 52.85it/s, Epoch: 12, Batch: 49,Loss: -1.473,Avg.Loss: -1.755,LR: 2.05E-04]Training epoch 12:  14%|█▍        | 49/341 [00:00<00:05, 52.85it/s, Epoch: 12, Batch: 50,Loss: -1.480,Avg.Loss: -1.750,LR: 2.05E-04]Training epoch 12:  15%|█▍        | 50/341 [00:00<00:05, 52.85it/s, Epoch: 12, Batch: 51,Loss: -1.977,Avg.Loss: -1.754,LR: 2.05E-04]Training epoch 12:  15%|█▍        | 51/341 [00:00<00:05, 52.85it/s, Epoch: 12, Batch: 52,Loss: -1.653,Avg.Loss: -1.752,LR: 2.05E-04]Training epoch 12:  15%|█▌        | 52/341 [00:00<00:05, 52.85it/s, Epoch: 12, Batch: 53,Loss: -1.770,Avg.Loss: -1.752,LR: 2.05E-04]Training epoch 12:  16%|█▌        | 53/341 [00:01<00:05, 52.85it/s, Epoch: 12, Batch: 54,Loss: -1.889,Avg.Loss: -1.755,LR: 2.05E-04]Training epoch 12:  16%|█▌        | 54/341 [00:01<00:05, 53.25it/s, Epoch: 12, Batch: 54,Loss: -1.889,Avg.Loss: -1.755,LR: 2.05E-04]Training epoch 12:  16%|█▌        | 54/341 [00:01<00:05, 53.25it/s, Epoch: 12, Batch: 55,Loss: -2.015,Avg.Loss: -1.760,LR: 2.05E-04]Training epoch 12:  16%|█▌        | 55/341 [00:01<00:05, 53.25it/s, Epoch: 12, Batch: 56,Loss: -2.260,Avg.Loss: -1.769,LR: 2.05E-04]Training epoch 12:  16%|█▋        | 56/341 [00:01<00:05, 53.25it/s, Epoch: 12, Batch: 57,Loss: -1.800,Avg.Loss: -1.769,LR: 2.04E-04]Training epoch 12:  17%|█▋        | 57/341 [00:01<00:05, 53.25it/s, Epoch: 12, Batch: 58,Loss: -1.518,Avg.Loss: -1.765,LR: 2.04E-04]Training epoch 12:  17%|█▋        | 58/341 [00:01<00:05, 53.25it/s, Epoch: 12, Batch: 59,Loss: -1.973,Avg.Loss: -1.768,LR: 2.04E-04]Training epoch 12:  17%|█▋        | 59/341 [00:01<00:05, 53.25it/s, Epoch: 12, Batch: 60,Loss: -2.219,Avg.Loss: -1.776,LR: 2.04E-04]Training epoch 12:  18%|█▊        | 60/341 [00:01<00:05, 53.37it/s, Epoch: 12, Batch: 60,Loss: -2.219,Avg.Loss: -1.776,LR: 2.04E-04]Training epoch 12:  18%|█▊        | 60/341 [00:01<00:05, 53.37it/s, Epoch: 12, Batch: 61,Loss: -1.922,Avg.Loss: -1.778,LR: 2.04E-04]Training epoch 12:  18%|█▊        | 61/341 [00:01<00:05, 53.37it/s, Epoch: 12, Batch: 62,Loss: -2.184,Avg.Loss: -1.785,LR: 2.04E-04]Training epoch 12:  18%|█▊        | 62/341 [00:01<00:05, 53.37it/s, Epoch: 12, Batch: 63,Loss: -1.565,Avg.Loss: -1.781,LR: 2.04E-04]Training epoch 12:  18%|█▊        | 63/341 [00:01<00:05, 53.37it/s, Epoch: 12, Batch: 64,Loss: -1.284,Avg.Loss: -1.774,LR: 2.04E-04]Training epoch 12:  19%|█▉        | 64/341 [00:01<00:05, 53.37it/s, Epoch: 12, Batch: 65,Loss: -1.973,Avg.Loss: -1.777,LR: 2.04E-04]Training epoch 12:  19%|█▉        | 65/341 [00:01<00:05, 53.37it/s, Epoch: 12, Batch: 66,Loss: -1.947,Avg.Loss: -1.779,LR: 2.03E-04]Training epoch 12:  19%|█▉        | 66/341 [00:01<00:05, 54.11it/s, Epoch: 12, Batch: 66,Loss: -1.947,Avg.Loss: -1.779,LR: 2.03E-04]Training epoch 12:  19%|█▉        | 66/341 [00:01<00:05, 54.11it/s, Epoch: 12, Batch: 67,Loss: -1.557,Avg.Loss: -1.776,LR: 2.03E-04]Training epoch 12:  20%|█▉        | 67/341 [00:01<00:05, 54.11it/s, Epoch: 12, Batch: 68,Loss: -2.132,Avg.Loss: -1.781,LR: 2.03E-04]Training epoch 12:  20%|█▉        | 68/341 [00:01<00:05, 54.11it/s, Epoch: 12, Batch: 69,Loss: -2.273,Avg.Loss: -1.788,LR: 2.03E-04]Training epoch 12:  20%|██        | 69/341 [00:01<00:05, 54.11it/s, Epoch: 12, Batch: 70,Loss: -1.931,Avg.Loss: -1.790,LR: 2.03E-04]Training epoch 12:  21%|██        | 70/341 [00:01<00:05, 54.11it/s, Epoch: 12, Batch: 71,Loss: -2.024,Avg.Loss: -1.794,LR: 2.03E-04]Training epoch 12:  21%|██        | 71/341 [00:01<00:04, 54.11it/s, Epoch: 12, Batch: 72,Loss: -1.764,Avg.Loss: -1.793,LR: 2.03E-04]Training epoch 12:  21%|██        | 72/341 [00:01<00:04, 54.25it/s, Epoch: 12, Batch: 72,Loss: -1.764,Avg.Loss: -1.793,LR: 2.03E-04]Training epoch 12:  21%|██        | 72/341 [00:01<00:04, 54.25it/s, Epoch: 12, Batch: 73,Loss: -1.597,Avg.Loss: -1.791,LR: 2.03E-04]Training epoch 12:  21%|██▏       | 73/341 [00:01<00:04, 54.25it/s, Epoch: 12, Batch: 74,Loss: -1.988,Avg.Loss: -1.793,LR: 2.02E-04]Training epoch 12:  22%|██▏       | 74/341 [00:01<00:04, 54.25it/s, Epoch: 12, Batch: 75,Loss: -1.897,Avg.Loss: -1.795,LR: 2.02E-04]Training epoch 12:  22%|██▏       | 75/341 [00:01<00:04, 54.25it/s, Epoch: 12, Batch: 76,Loss: -1.277,Avg.Loss: -1.788,LR: 2.02E-04]Training epoch 12:  22%|██▏       | 76/341 [00:01<00:04, 54.25it/s, Epoch: 12, Batch: 77,Loss: -1.765,Avg.Loss: -1.787,LR: 2.02E-04]Training epoch 12:  23%|██▎       | 77/341 [00:01<00:04, 54.25it/s, Epoch: 12, Batch: 78,Loss: -1.989,Avg.Loss: -1.790,LR: 2.02E-04]Training epoch 12:  23%|██▎       | 78/341 [00:01<00:04, 54.24it/s, Epoch: 12, Batch: 78,Loss: -1.989,Avg.Loss: -1.790,LR: 2.02E-04]Training epoch 12:  23%|██▎       | 78/341 [00:01<00:04, 54.24it/s, Epoch: 12, Batch: 79,Loss: -1.692,Avg.Loss: -1.789,LR: 2.02E-04]Training epoch 12:  23%|██▎       | 79/341 [00:01<00:04, 54.24it/s, Epoch: 12, Batch: 80,Loss: -1.904,Avg.Loss: -1.790,LR: 2.02E-04]Training epoch 12:  23%|██▎       | 80/341 [00:01<00:04, 54.24it/s, Epoch: 12, Batch: 81,Loss: -1.745,Avg.Loss: -1.790,LR: 2.02E-04]Training epoch 12:  24%|██▍       | 81/341 [00:01<00:04, 54.24it/s, Epoch: 12, Batch: 82,Loss: -1.696,Avg.Loss: -1.789,LR: 2.02E-04]Training epoch 12:  24%|██▍       | 82/341 [00:01<00:04, 54.24it/s, Epoch: 12, Batch: 83,Loss: -2.014,Avg.Loss: -1.791,LR: 2.01E-04]Training epoch 12:  24%|██▍       | 83/341 [00:01<00:04, 54.24it/s, Epoch: 12, Batch: 84,Loss: -2.005,Avg.Loss: -1.794,LR: 2.01E-04]Training epoch 12:  25%|██▍       | 84/341 [00:01<00:04, 54.29it/s, Epoch: 12, Batch: 84,Loss: -2.005,Avg.Loss: -1.794,LR: 2.01E-04]Training epoch 12:  25%|██▍       | 84/341 [00:01<00:04, 54.29it/s, Epoch: 12, Batch: 85,Loss: -2.013,Avg.Loss: -1.796,LR: 2.01E-04]Training epoch 12:  25%|██▍       | 85/341 [00:01<00:04, 54.29it/s, Epoch: 12, Batch: 86,Loss: -2.174,Avg.Loss: -1.801,LR: 2.01E-04]Training epoch 12:  25%|██▌       | 86/341 [00:01<00:04, 54.29it/s, Epoch: 12, Batch: 87,Loss: -1.742,Avg.Loss: -1.800,LR: 2.01E-04]Training epoch 12:  26%|██▌       | 87/341 [00:01<00:04, 54.29it/s, Epoch: 12, Batch: 88,Loss: -2.109,Avg.Loss: -1.804,LR: 2.01E-04]Training epoch 12:  26%|██▌       | 88/341 [00:01<00:04, 54.29it/s, Epoch: 12, Batch: 89,Loss: -1.794,Avg.Loss: -1.804,LR: 2.01E-04]Training epoch 12:  26%|██▌       | 89/341 [00:01<00:04, 54.29it/s, Epoch: 12, Batch: 90,Loss: -1.685,Avg.Loss: -1.802,LR: 2.01E-04]Training epoch 12:  26%|██▋       | 90/341 [00:01<00:04, 54.30it/s, Epoch: 12, Batch: 90,Loss: -1.685,Avg.Loss: -1.802,LR: 2.01E-04]Training epoch 12:  26%|██▋       | 90/341 [00:01<00:04, 54.30it/s, Epoch: 12, Batch: 91,Loss: -1.654,Avg.Loss: -1.801,LR: 2.01E-04]Training epoch 12:  27%|██▋       | 91/341 [00:01<00:04, 54.30it/s, Epoch: 12, Batch: 92,Loss: -1.088,Avg.Loss: -1.793,LR: 2.00E-04]Training epoch 12:  27%|██▋       | 92/341 [00:01<00:04, 54.30it/s, Epoch: 12, Batch: 93,Loss: -1.513,Avg.Loss: -1.790,LR: 2.00E-04]Training epoch 12:  27%|██▋       | 93/341 [00:01<00:04, 54.30it/s, Epoch: 12, Batch: 94,Loss: -1.490,Avg.Loss: -1.787,LR: 2.00E-04]Training epoch 12:  28%|██▊       | 94/341 [00:01<00:04, 54.30it/s, Epoch: 12, Batch: 95,Loss: -2.269,Avg.Loss: -1.792,LR: 2.00E-04]Training epoch 12:  28%|██▊       | 95/341 [00:01<00:04, 54.30it/s, Epoch: 12, Batch: 96,Loss: -1.632,Avg.Loss: -1.790,LR: 2.00E-04]Training epoch 12:  28%|██▊       | 96/341 [00:01<00:04, 54.21it/s, Epoch: 12, Batch: 96,Loss: -1.632,Avg.Loss: -1.790,LR: 2.00E-04]Training epoch 12:  28%|██▊       | 96/341 [00:01<00:04, 54.21it/s, Epoch: 12, Batch: 97,Loss: -2.091,Avg.Loss: -1.793,LR: 2.00E-04]Training epoch 12:  28%|██▊       | 97/341 [00:01<00:04, 54.21it/s, Epoch: 12, Batch: 98,Loss: -1.552,Avg.Loss: -1.791,LR: 2.00E-04]Training epoch 12:  29%|██▊       | 98/341 [00:01<00:04, 54.21it/s, Epoch: 12, Batch: 99,Loss: -2.102,Avg.Loss: -1.794,LR: 2.00E-04]Training epoch 12:  29%|██▉       | 99/341 [00:01<00:04, 54.21it/s, Epoch: 12, Batch: 100,Loss: -1.688,Avg.Loss: -1.793,LR: 2.00E-04]Training epoch 12:  29%|██▉       | 100/341 [00:01<00:04, 54.21it/s, Epoch: 12, Batch: 101,Loss: -1.415,Avg.Loss: -1.789,LR: 1.99E-04]Training epoch 12:  30%|██▉       | 101/341 [00:01<00:04, 54.21it/s, Epoch: 12, Batch: 102,Loss: -1.841,Avg.Loss: -1.790,LR: 1.99E-04]Training epoch 12:  30%|██▉       | 102/341 [00:01<00:04, 54.45it/s, Epoch: 12, Batch: 102,Loss: -1.841,Avg.Loss: -1.790,LR: 1.99E-04]Training epoch 12:  30%|██▉       | 102/341 [00:01<00:04, 54.45it/s, Epoch: 12, Batch: 103,Loss: -2.142,Avg.Loss: -1.793,LR: 1.99E-04]Training epoch 12:  30%|███       | 103/341 [00:01<00:04, 54.45it/s, Epoch: 12, Batch: 104,Loss: -1.940,Avg.Loss: -1.794,LR: 1.99E-04]Training epoch 12:  30%|███       | 104/341 [00:01<00:04, 54.45it/s, Epoch: 12, Batch: 105,Loss: -2.117,Avg.Loss: -1.797,LR: 1.99E-04]Training epoch 12:  31%|███       | 105/341 [00:01<00:04, 54.45it/s, Epoch: 12, Batch: 106,Loss: -2.110,Avg.Loss: -1.800,LR: 1.99E-04]Training epoch 12:  31%|███       | 106/341 [00:01<00:04, 54.45it/s, Epoch: 12, Batch: 107,Loss: -1.672,Avg.Loss: -1.799,LR: 1.99E-04]Training epoch 12:  31%|███▏      | 107/341 [00:02<00:04, 54.45it/s, Epoch: 12, Batch: 108,Loss: -1.991,Avg.Loss: -1.801,LR: 1.99E-04]Training epoch 12:  32%|███▏      | 108/341 [00:02<00:04, 54.83it/s, Epoch: 12, Batch: 108,Loss: -1.991,Avg.Loss: -1.801,LR: 1.99E-04]Training epoch 12:  32%|███▏      | 108/341 [00:02<00:04, 54.83it/s, Epoch: 12, Batch: 109,Loss: -1.929,Avg.Loss: -1.802,LR: 1.99E-04]Training epoch 12:  32%|███▏      | 109/341 [00:02<00:04, 54.83it/s, Epoch: 12, Batch: 110,Loss: -1.993,Avg.Loss: -1.804,LR: 1.98E-04]Training epoch 12:  32%|███▏      | 110/341 [00:02<00:04, 54.83it/s, Epoch: 12, Batch: 111,Loss: -1.842,Avg.Loss: -1.804,LR: 1.98E-04]Training epoch 12:  33%|███▎      | 111/341 [00:02<00:04, 54.83it/s, Epoch: 12, Batch: 112,Loss: -1.391,Avg.Loss: -1.801,LR: 1.98E-04]Training epoch 12:  33%|███▎      | 112/341 [00:02<00:04, 54.83it/s, Epoch: 12, Batch: 113,Loss: -1.508,Avg.Loss: -1.798,LR: 1.98E-04]Training epoch 12:  33%|███▎      | 113/341 [00:02<00:04, 54.83it/s, Epoch: 12, Batch: 114,Loss: -1.513,Avg.Loss: -1.795,LR: 1.98E-04]Training epoch 12:  33%|███▎      | 114/341 [00:02<00:04, 54.52it/s, Epoch: 12, Batch: 114,Loss: -1.513,Avg.Loss: -1.795,LR: 1.98E-04]Training epoch 12:  33%|███▎      | 114/341 [00:02<00:04, 54.52it/s, Epoch: 12, Batch: 115,Loss: -1.683,Avg.Loss: -1.794,LR: 1.98E-04]Training epoch 12:  34%|███▎      | 115/341 [00:02<00:04, 54.52it/s, Epoch: 12, Batch: 116,Loss: -1.449,Avg.Loss: -1.791,LR: 1.98E-04]Training epoch 12:  34%|███▍      | 116/341 [00:02<00:04, 54.52it/s, Epoch: 12, Batch: 117,Loss: -1.840,Avg.Loss: -1.792,LR: 1.98E-04]Training epoch 12:  34%|███▍      | 117/341 [00:02<00:04, 54.52it/s, Epoch: 12, Batch: 118,Loss: -1.115,Avg.Loss: -1.786,LR: 1.98E-04]Training epoch 12:  35%|███▍      | 118/341 [00:02<00:04, 54.52it/s, Epoch: 12, Batch: 119,Loss: -1.297,Avg.Loss: -1.782,LR: 1.97E-04]Training epoch 12:  35%|███▍      | 119/341 [00:02<00:04, 54.52it/s, Epoch: 12, Batch: 120,Loss: -1.208,Avg.Loss: -1.777,LR: 1.97E-04]Training epoch 12:  35%|███▌      | 120/341 [00:02<00:04, 54.00it/s, Epoch: 12, Batch: 120,Loss: -1.208,Avg.Loss: -1.777,LR: 1.97E-04]Training epoch 12:  35%|███▌      | 120/341 [00:02<00:04, 54.00it/s, Epoch: 12, Batch: 121,Loss: -1.942,Avg.Loss: -1.779,LR: 1.97E-04]Training epoch 12:  35%|███▌      | 121/341 [00:02<00:04, 54.00it/s, Epoch: 12, Batch: 122,Loss: -1.510,Avg.Loss: -1.776,LR: 1.97E-04]Training epoch 12:  36%|███▌      | 122/341 [00:02<00:04, 54.00it/s, Epoch: 12, Batch: 123,Loss: -2.217,Avg.Loss: -1.780,LR: 1.97E-04]Training epoch 12:  36%|███▌      | 123/341 [00:02<00:04, 54.00it/s, Epoch: 12, Batch: 124,Loss: -2.266,Avg.Loss: -1.784,LR: 1.97E-04]Training epoch 12:  36%|███▋      | 124/341 [00:02<00:04, 54.00it/s, Epoch: 12, Batch: 125,Loss: -1.753,Avg.Loss: -1.784,LR: 1.97E-04]Training epoch 12:  37%|███▋      | 125/341 [00:02<00:03, 54.00it/s, Epoch: 12, Batch: 126,Loss: -2.078,Avg.Loss: -1.786,LR: 1.97E-04]Training epoch 12:  37%|███▋      | 126/341 [00:02<00:04, 53.75it/s, Epoch: 12, Batch: 126,Loss: -2.078,Avg.Loss: -1.786,LR: 1.97E-04]Training epoch 12:  37%|███▋      | 126/341 [00:02<00:04, 53.75it/s, Epoch: 12, Batch: 127,Loss: -2.143,Avg.Loss: -1.789,LR: 1.97E-04]Training epoch 12:  37%|███▋      | 127/341 [00:02<00:03, 53.75it/s, Epoch: 12, Batch: 128,Loss: -1.901,Avg.Loss: -1.790,LR: 1.96E-04]Training epoch 12:  38%|███▊      | 128/341 [00:02<00:03, 53.75it/s, Epoch: 12, Batch: 129,Loss: -1.755,Avg.Loss: -1.789,LR: 1.96E-04]Training epoch 12:  38%|███▊      | 129/341 [00:02<00:03, 53.75it/s, Epoch: 12, Batch: 130,Loss: -1.707,Avg.Loss: -1.789,LR: 1.96E-04]Training epoch 12:  38%|███▊      | 130/341 [00:02<00:03, 53.75it/s, Epoch: 12, Batch: 131,Loss: -1.678,Avg.Loss: -1.788,LR: 1.96E-04]Training epoch 12:  38%|███▊      | 131/341 [00:02<00:03, 53.75it/s, Epoch: 12, Batch: 132,Loss: -1.770,Avg.Loss: -1.788,LR: 1.96E-04]Training epoch 12:  39%|███▊      | 132/341 [00:02<00:03, 53.82it/s, Epoch: 12, Batch: 132,Loss: -1.770,Avg.Loss: -1.788,LR: 1.96E-04]Training epoch 12:  39%|███▊      | 132/341 [00:02<00:03, 53.82it/s, Epoch: 12, Batch: 133,Loss: -1.671,Avg.Loss: -1.787,LR: 1.96E-04]Training epoch 12:  39%|███▉      | 133/341 [00:02<00:03, 53.82it/s, Epoch: 12, Batch: 134,Loss: -1.932,Avg.Loss: -1.788,LR: 1.96E-04]Training epoch 12:  39%|███▉      | 134/341 [00:02<00:03, 53.82it/s, Epoch: 12, Batch: 135,Loss: -1.520,Avg.Loss: -1.786,LR: 1.96E-04]Training epoch 12:  40%|███▉      | 135/341 [00:02<00:03, 53.82it/s, Epoch: 12, Batch: 136,Loss: -1.124,Avg.Loss: -1.781,LR: 1.96E-04]Training epoch 12:  40%|███▉      | 136/341 [00:02<00:03, 53.82it/s, Epoch: 12, Batch: 137,Loss: -1.576,Avg.Loss: -1.780,LR: 1.95E-04]Training epoch 12:  40%|████      | 137/341 [00:02<00:03, 53.82it/s, Epoch: 12, Batch: 138,Loss: -1.993,Avg.Loss: -1.781,LR: 1.95E-04]Training epoch 12:  40%|████      | 138/341 [00:02<00:03, 53.74it/s, Epoch: 12, Batch: 138,Loss: -1.993,Avg.Loss: -1.781,LR: 1.95E-04]Training epoch 12:  40%|████      | 138/341 [00:02<00:03, 53.74it/s, Epoch: 12, Batch: 139,Loss: -1.054,Avg.Loss: -1.776,LR: 1.95E-04]Training epoch 12:  41%|████      | 139/341 [00:02<00:03, 53.74it/s, Epoch: 12, Batch: 140,Loss: -1.855,Avg.Loss: -1.777,LR: 1.95E-04]Training epoch 12:  41%|████      | 140/341 [00:02<00:03, 53.74it/s, Epoch: 12, Batch: 141,Loss: -1.671,Avg.Loss: -1.776,LR: 1.95E-04]Training epoch 12:  41%|████▏     | 141/341 [00:02<00:03, 53.74it/s, Epoch: 12, Batch: 142,Loss: -1.828,Avg.Loss: -1.776,LR: 1.95E-04]Training epoch 12:  42%|████▏     | 142/341 [00:02<00:03, 53.74it/s, Epoch: 12, Batch: 143,Loss: -1.579,Avg.Loss: -1.775,LR: 1.95E-04]Training epoch 12:  42%|████▏     | 143/341 [00:02<00:03, 53.74it/s, Epoch: 12, Batch: 144,Loss: -2.220,Avg.Loss: -1.778,LR: 1.95E-04]Training epoch 12:  42%|████▏     | 144/341 [00:02<00:03, 53.71it/s, Epoch: 12, Batch: 144,Loss: -2.220,Avg.Loss: -1.778,LR: 1.95E-04]Training epoch 12:  42%|████▏     | 144/341 [00:02<00:03, 53.71it/s, Epoch: 12, Batch: 145,Loss: -1.981,Avg.Loss: -1.779,LR: 1.94E-04]Training epoch 12:  43%|████▎     | 145/341 [00:02<00:03, 53.71it/s, Epoch: 12, Batch: 146,Loss: -2.276,Avg.Loss: -1.783,LR: 1.94E-04]Training epoch 12:  43%|████▎     | 146/341 [00:02<00:03, 53.71it/s, Epoch: 12, Batch: 147,Loss: -2.108,Avg.Loss: -1.785,LR: 1.94E-04]Training epoch 12:  43%|████▎     | 147/341 [00:02<00:03, 53.71it/s, Epoch: 12, Batch: 148,Loss: -1.706,Avg.Loss: -1.784,LR: 1.94E-04]Training epoch 12:  43%|████▎     | 148/341 [00:02<00:03, 53.71it/s, Epoch: 12, Batch: 149,Loss: -1.447,Avg.Loss: -1.782,LR: 1.94E-04]Training epoch 12:  44%|████▎     | 149/341 [00:02<00:03, 53.71it/s, Epoch: 12, Batch: 150,Loss: -2.061,Avg.Loss: -1.784,LR: 1.94E-04]Training epoch 12:  44%|████▍     | 150/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 150,Loss: -2.061,Avg.Loss: -1.784,LR: 1.94E-04]Training epoch 12:  44%|████▍     | 150/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 151,Loss: -1.843,Avg.Loss: -1.784,LR: 1.94E-04]Training epoch 12:  44%|████▍     | 151/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 152,Loss: -0.984,Avg.Loss: -1.779,LR: 1.94E-04]Training epoch 12:  45%|████▍     | 152/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 153,Loss: -1.390,Avg.Loss: -1.777,LR: 1.94E-04]Training epoch 12:  45%|████▍     | 153/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 154,Loss: -2.042,Avg.Loss: -1.778,LR: 1.93E-04]Training epoch 12:  45%|████▌     | 154/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 155,Loss: -1.372,Avg.Loss: -1.776,LR: 1.93E-04]Training epoch 12:  45%|████▌     | 155/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 156,Loss: -0.015,Avg.Loss: -1.764,LR: 1.93E-04]Training epoch 12:  46%|████▌     | 156/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 156,Loss: -0.015,Avg.Loss: -1.764,LR: 1.93E-04]Training epoch 12:  46%|████▌     | 156/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 157,Loss: 0.318,Avg.Loss: -1.751,LR: 1.93E-04] Training epoch 12:  46%|████▌     | 157/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 158,Loss: -1.286,Avg.Loss: -1.748,LR: 1.93E-04]Training epoch 12:  46%|████▋     | 158/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 159,Loss: -2.107,Avg.Loss: -1.750,LR: 1.93E-04]Training epoch 12:  47%|████▋     | 159/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 160,Loss: -2.044,Avg.Loss: -1.752,LR: 1.93E-04]Training epoch 12:  47%|████▋     | 160/341 [00:02<00:03, 53.90it/s, Epoch: 12, Batch: 161,Loss: -1.881,Avg.Loss: -1.753,LR: 1.93E-04]Training epoch 12:  47%|████▋     | 161/341 [00:03<00:03, 53.90it/s, Epoch: 12, Batch: 162,Loss: -2.188,Avg.Loss: -1.756,LR: 1.93E-04]Training epoch 12:  48%|████▊     | 162/341 [00:03<00:03, 53.56it/s, Epoch: 12, Batch: 162,Loss: -2.188,Avg.Loss: -1.756,LR: 1.93E-04]Training epoch 12:  48%|████▊     | 162/341 [00:03<00:03, 53.56it/s, Epoch: 12, Batch: 163,Loss: -2.127,Avg.Loss: -1.758,LR: 1.92E-04]Training epoch 12:  48%|████▊     | 163/341 [00:03<00:03, 53.56it/s, Epoch: 12, Batch: 164,Loss: -1.927,Avg.Loss: -1.759,LR: 1.92E-04]Training epoch 12:  48%|████▊     | 164/341 [00:03<00:03, 53.56it/s, Epoch: 12, Batch: 165,Loss: -2.020,Avg.Loss: -1.761,LR: 1.92E-04]Training epoch 12:  48%|████▊     | 165/341 [00:03<00:03, 53.56it/s, Epoch: 12, Batch: 166,Loss: -2.152,Avg.Loss: -1.763,LR: 1.92E-04]Training epoch 12:  49%|████▊     | 166/341 [00:03<00:03, 53.56it/s, Epoch: 12, Batch: 167,Loss: -1.911,Avg.Loss: -1.764,LR: 1.92E-04]Training epoch 12:  49%|████▉     | 167/341 [00:03<00:03, 53.56it/s, Epoch: 12, Batch: 168,Loss: -2.069,Avg.Loss: -1.766,LR: 1.92E-04]Training epoch 12:  49%|████▉     | 168/341 [00:03<00:03, 53.24it/s, Epoch: 12, Batch: 168,Loss: -2.069,Avg.Loss: -1.766,LR: 1.92E-04]Training epoch 12:  49%|████▉     | 168/341 [00:03<00:03, 53.24it/s, Epoch: 12, Batch: 169,Loss: -1.784,Avg.Loss: -1.766,LR: 1.92E-04]Training epoch 12:  50%|████▉     | 169/341 [00:03<00:03, 53.24it/s, Epoch: 12, Batch: 170,Loss: -0.880,Avg.Loss: -1.761,LR: 1.92E-04]Training epoch 12:  50%|████▉     | 170/341 [00:03<00:03, 53.24it/s, Epoch: 12, Batch: 171,Loss: -1.595,Avg.Loss: -1.760,LR: 1.92E-04]Training epoch 12:  50%|█████     | 171/341 [00:03<00:03, 53.24it/s, Epoch: 12, Batch: 172,Loss: -2.238,Avg.Loss: -1.762,LR: 1.91E-04]Training epoch 12:  50%|█████     | 172/341 [00:03<00:03, 53.24it/s, Epoch: 12, Batch: 173,Loss: -2.232,Avg.Loss: -1.765,LR: 1.91E-04]Training epoch 12:  51%|█████     | 173/341 [00:03<00:03, 53.24it/s, Epoch: 12, Batch: 174,Loss: -2.225,Avg.Loss: -1.768,LR: 1.91E-04]Training epoch 12:  51%|█████     | 174/341 [00:03<00:03, 54.06it/s, Epoch: 12, Batch: 174,Loss: -2.225,Avg.Loss: -1.768,LR: 1.91E-04]Training epoch 12:  51%|█████     | 174/341 [00:03<00:03, 54.06it/s, Epoch: 12, Batch: 175,Loss: -2.205,Avg.Loss: -1.770,LR: 1.91E-04]Training epoch 12:  51%|█████▏    | 175/341 [00:03<00:03, 54.06it/s, Epoch: 12, Batch: 176,Loss: -1.822,Avg.Loss: -1.771,LR: 1.91E-04]Training epoch 12:  52%|█████▏    | 176/341 [00:03<00:03, 54.06it/s, Epoch: 12, Batch: 177,Loss: -1.650,Avg.Loss: -1.770,LR: 1.91E-04]Training epoch 12:  52%|█████▏    | 177/341 [00:03<00:03, 54.06it/s, Epoch: 12, Batch: 178,Loss: -2.066,Avg.Loss: -1.772,LR: 1.91E-04]Training epoch 12:  52%|█████▏    | 178/341 [00:03<00:03, 54.06it/s, Epoch: 12, Batch: 179,Loss: -1.479,Avg.Loss: -1.770,LR: 1.91E-04]Training epoch 12:  52%|█████▏    | 179/341 [00:03<00:02, 54.06it/s, Epoch: 12, Batch: 180,Loss: -0.710,Avg.Loss: -1.764,LR: 1.91E-04]Training epoch 12:  53%|█████▎    | 180/341 [00:03<00:02, 53.92it/s, Epoch: 12, Batch: 180,Loss: -0.710,Avg.Loss: -1.764,LR: 1.91E-04]Training epoch 12:  53%|█████▎    | 180/341 [00:03<00:02, 53.92it/s, Epoch: 12, Batch: 181,Loss: -0.833,Avg.Loss: -1.759,LR: 1.90E-04]Training epoch 12:  53%|█████▎    | 181/341 [00:03<00:02, 53.92it/s, Epoch: 12, Batch: 182,Loss: -1.903,Avg.Loss: -1.760,LR: 1.90E-04]Training epoch 12:  53%|█████▎    | 182/341 [00:03<00:02, 53.92it/s, Epoch: 12, Batch: 183,Loss: -0.985,Avg.Loss: -1.755,LR: 1.90E-04]Training epoch 12:  54%|█████▎    | 183/341 [00:03<00:02, 53.92it/s, Epoch: 12, Batch: 184,Loss: -0.676,Avg.Loss: -1.750,LR: 1.90E-04]Training epoch 12:  54%|█████▍    | 184/341 [00:03<00:02, 53.92it/s, Epoch: 12, Batch: 185,Loss: -0.370,Avg.Loss: -1.742,LR: 1.90E-04]Training epoch 12:  54%|█████▍    | 185/341 [00:03<00:02, 53.92it/s, Epoch: 12, Batch: 186,Loss: -1.410,Avg.Loss: -1.740,LR: 1.90E-04]Training epoch 12:  55%|█████▍    | 186/341 [00:03<00:02, 54.28it/s, Epoch: 12, Batch: 186,Loss: -1.410,Avg.Loss: -1.740,LR: 1.90E-04]Training epoch 12:  55%|█████▍    | 186/341 [00:03<00:02, 54.28it/s, Epoch: 12, Batch: 187,Loss: -1.517,Avg.Loss: -1.739,LR: 1.90E-04]Training epoch 12:  55%|█████▍    | 187/341 [00:03<00:02, 54.28it/s, Epoch: 12, Batch: 188,Loss: -1.444,Avg.Loss: -1.738,LR: 1.90E-04]Training epoch 12:  55%|█████▌    | 188/341 [00:03<00:02, 54.28it/s, Epoch: 12, Batch: 189,Loss: -1.465,Avg.Loss: -1.736,LR: 1.90E-04]Training epoch 12:  55%|█████▌    | 189/341 [00:03<00:02, 54.28it/s, Epoch: 12, Batch: 190,Loss: -2.011,Avg.Loss: -1.738,LR: 1.89E-04]Training epoch 12:  56%|█████▌    | 190/341 [00:03<00:02, 54.28it/s, Epoch: 12, Batch: 191,Loss: -1.546,Avg.Loss: -1.737,LR: 1.89E-04]Training epoch 12:  56%|█████▌    | 191/341 [00:03<00:02, 54.28it/s, Epoch: 12, Batch: 192,Loss: -1.559,Avg.Loss: -1.736,LR: 1.89E-04]Training epoch 12:  56%|█████▋    | 192/341 [00:03<00:02, 54.36it/s, Epoch: 12, Batch: 192,Loss: -1.559,Avg.Loss: -1.736,LR: 1.89E-04]Training epoch 12:  56%|█████▋    | 192/341 [00:03<00:02, 54.36it/s, Epoch: 12, Batch: 193,Loss: -2.059,Avg.Loss: -1.737,LR: 1.89E-04]Training epoch 12:  57%|█████▋    | 193/341 [00:03<00:02, 54.36it/s, Epoch: 12, Batch: 194,Loss: -2.259,Avg.Loss: -1.740,LR: 1.89E-04]Training epoch 12:  57%|█████▋    | 194/341 [00:03<00:02, 54.36it/s, Epoch: 12, Batch: 195,Loss: -1.682,Avg.Loss: -1.740,LR: 1.89E-04]Training epoch 12:  57%|█████▋    | 195/341 [00:03<00:02, 54.36it/s, Epoch: 12, Batch: 196,Loss: -2.071,Avg.Loss: -1.741,LR: 1.89E-04]Training epoch 12:  57%|█████▋    | 196/341 [00:03<00:02, 54.36it/s, Epoch: 12, Batch: 197,Loss: -1.763,Avg.Loss: -1.741,LR: 1.89E-04]Training epoch 12:  58%|█████▊    | 197/341 [00:03<00:02, 54.36it/s, Epoch: 12, Batch: 198,Loss: -1.775,Avg.Loss: -1.742,LR: 1.89E-04]Training epoch 12:  58%|█████▊    | 198/341 [00:03<00:02, 54.88it/s, Epoch: 12, Batch: 198,Loss: -1.775,Avg.Loss: -1.742,LR: 1.89E-04]Training epoch 12:  58%|█████▊    | 198/341 [00:03<00:02, 54.88it/s, Epoch: 12, Batch: 199,Loss: -2.398,Avg.Loss: -1.745,LR: 1.88E-04]Training epoch 12:  58%|█████▊    | 199/341 [00:03<00:02, 54.88it/s, Epoch: 12, Batch: 200,Loss: -2.105,Avg.Loss: -1.747,LR: 1.88E-04]Training epoch 12:  59%|█████▊    | 200/341 [00:03<00:02, 54.88it/s, Epoch: 12, Batch: 201,Loss: -1.589,Avg.Loss: -1.746,LR: 1.88E-04]Training epoch 12:  59%|█████▉    | 201/341 [00:03<00:02, 54.88it/s, Epoch: 12, Batch: 202,Loss: -2.338,Avg.Loss: -1.749,LR: 1.88E-04]Training epoch 12:  59%|█████▉    | 202/341 [00:03<00:02, 54.88it/s, Epoch: 12, Batch: 203,Loss: -1.998,Avg.Loss: -1.750,LR: 1.88E-04]Training epoch 12:  60%|█████▉    | 203/341 [00:03<00:02, 54.88it/s, Epoch: 12, Batch: 204,Loss: -1.906,Avg.Loss: -1.751,LR: 1.88E-04]Training epoch 12:  60%|█████▉    | 204/341 [00:03<00:02, 54.41it/s, Epoch: 12, Batch: 204,Loss: -1.906,Avg.Loss: -1.751,LR: 1.88E-04]Training epoch 12:  60%|█████▉    | 204/341 [00:03<00:02, 54.41it/s, Epoch: 12, Batch: 205,Loss: -2.517,Avg.Loss: -1.755,LR: 1.88E-04]Training epoch 12:  60%|██████    | 205/341 [00:03<00:02, 54.41it/s, Epoch: 12, Batch: 206,Loss: -1.543,Avg.Loss: -1.754,LR: 1.88E-04]Training epoch 12:  60%|██████    | 206/341 [00:03<00:02, 54.41it/s, Epoch: 12, Batch: 207,Loss: -1.240,Avg.Loss: -1.751,LR: 1.88E-04]Training epoch 12:  61%|██████    | 207/341 [00:03<00:02, 54.41it/s, Epoch: 12, Batch: 208,Loss: -1.700,Avg.Loss: -1.751,LR: 1.87E-04]Training epoch 12:  61%|██████    | 208/341 [00:03<00:02, 54.41it/s, Epoch: 12, Batch: 209,Loss: -2.062,Avg.Loss: -1.752,LR: 1.87E-04]Training epoch 12:  61%|██████▏   | 209/341 [00:03<00:02, 54.41it/s, Epoch: 12, Batch: 210,Loss: -0.698,Avg.Loss: -1.747,LR: 1.87E-04]Training epoch 12:  62%|██████▏   | 210/341 [00:03<00:02, 54.35it/s, Epoch: 12, Batch: 210,Loss: -0.698,Avg.Loss: -1.747,LR: 1.87E-04]Training epoch 12:  62%|██████▏   | 210/341 [00:03<00:02, 54.35it/s, Epoch: 12, Batch: 211,Loss: 0.717,Avg.Loss: -1.736,LR: 1.87E-04] Training epoch 12:  62%|██████▏   | 211/341 [00:03<00:02, 54.35it/s, Epoch: 12, Batch: 212,Loss: 1.039,Avg.Loss: -1.723,LR: 1.87E-04]Training epoch 12:  62%|██████▏   | 212/341 [00:03<00:02, 54.35it/s, Epoch: 12, Batch: 213,Loss: -0.028,Avg.Loss: -1.715,LR: 1.87E-04]Training epoch 12:  62%|██████▏   | 213/341 [00:03<00:02, 54.35it/s, Epoch: 12, Batch: 214,Loss: -2.260,Avg.Loss: -1.717,LR: 1.87E-04]Training epoch 12:  63%|██████▎   | 214/341 [00:03<00:02, 54.35it/s, Epoch: 12, Batch: 215,Loss: -0.891,Avg.Loss: -1.713,LR: 1.87E-04]Training epoch 12:  63%|██████▎   | 215/341 [00:04<00:02, 54.35it/s, Epoch: 12, Batch: 216,Loss: 1.556,Avg.Loss: -1.698,LR: 1.87E-04] Training epoch 12:  63%|██████▎   | 216/341 [00:04<00:02, 54.47it/s, Epoch: 12, Batch: 216,Loss: 1.556,Avg.Loss: -1.698,LR: 1.87E-04]Training epoch 12:  63%|██████▎   | 216/341 [00:04<00:02, 54.47it/s, Epoch: 12, Batch: 217,Loss: 2.105,Avg.Loss: -1.681,LR: 1.86E-04]Training epoch 12:  64%|██████▎   | 217/341 [00:04<00:02, 54.47it/s, Epoch: 12, Batch: 218,Loss: 0.419,Avg.Loss: -1.671,LR: 1.86E-04]Training epoch 12:  64%|██████▍   | 218/341 [00:04<00:02, 54.47it/s, Epoch: 12, Batch: 219,Loss: -1.328,Avg.Loss: -1.669,LR: 1.86E-04]Training epoch 12:  64%|██████▍   | 219/341 [00:04<00:02, 54.47it/s, Epoch: 12, Batch: 220,Loss: -2.065,Avg.Loss: -1.671,LR: 1.86E-04]Training epoch 12:  65%|██████▍   | 220/341 [00:04<00:02, 54.47it/s, Epoch: 12, Batch: 221,Loss: -1.211,Avg.Loss: -1.669,LR: 1.86E-04]Training epoch 12:  65%|██████▍   | 221/341 [00:04<00:02, 54.47it/s, Epoch: 12, Batch: 222,Loss: -0.877,Avg.Loss: -1.666,LR: 1.86E-04]Training epoch 12:  65%|██████▌   | 222/341 [00:04<00:02, 54.60it/s, Epoch: 12, Batch: 222,Loss: -0.877,Avg.Loss: -1.666,LR: 1.86E-04]Training epoch 12:  65%|██████▌   | 222/341 [00:04<00:02, 54.60it/s, Epoch: 12, Batch: 223,Loss: -0.832,Avg.Loss: -1.662,LR: 1.86E-04]Training epoch 12:  65%|██████▌   | 223/341 [00:04<00:02, 54.60it/s, Epoch: 12, Batch: 224,Loss: -2.198,Avg.Loss: -1.664,LR: 1.86E-04]Training epoch 12:  66%|██████▌   | 224/341 [00:04<00:02, 54.60it/s, Epoch: 12, Batch: 225,Loss: -1.905,Avg.Loss: -1.665,LR: 1.86E-04]Training epoch 12:  66%|██████▌   | 225/341 [00:04<00:02, 54.60it/s, Epoch: 12, Batch: 226,Loss: -2.236,Avg.Loss: -1.668,LR: 1.85E-04]Training epoch 12:  66%|██████▋   | 226/341 [00:04<00:02, 54.60it/s, Epoch: 12, Batch: 227,Loss: -2.141,Avg.Loss: -1.670,LR: 1.85E-04]Training epoch 12:  67%|██████▋   | 227/341 [00:04<00:02, 54.60it/s, Epoch: 12, Batch: 228,Loss: -1.713,Avg.Loss: -1.670,LR: 1.85E-04]Training epoch 12:  67%|██████▋   | 228/341 [00:04<00:02, 54.94it/s, Epoch: 12, Batch: 228,Loss: -1.713,Avg.Loss: -1.670,LR: 1.85E-04]Training epoch 12:  67%|██████▋   | 228/341 [00:04<00:02, 54.94it/s, Epoch: 12, Batch: 229,Loss: -2.107,Avg.Loss: -1.672,LR: 1.85E-04]Training epoch 12:  67%|██████▋   | 229/341 [00:04<00:02, 54.94it/s, Epoch: 12, Batch: 230,Loss: -1.838,Avg.Loss: -1.673,LR: 1.85E-04]Training epoch 12:  67%|██████▋   | 230/341 [00:04<00:02, 54.94it/s, Epoch: 12, Batch: 231,Loss: -1.367,Avg.Loss: -1.671,LR: 1.85E-04]Training epoch 12:  68%|██████▊   | 231/341 [00:04<00:02, 54.94it/s, Epoch: 12, Batch: 232,Loss: -1.411,Avg.Loss: -1.670,LR: 1.85E-04]Training epoch 12:  68%|██████▊   | 232/341 [00:04<00:01, 54.94it/s, Epoch: 12, Batch: 233,Loss: -2.075,Avg.Loss: -1.672,LR: 1.85E-04]Training epoch 12:  68%|██████▊   | 233/341 [00:04<00:01, 54.94it/s, Epoch: 12, Batch: 234,Loss: -1.454,Avg.Loss: -1.671,LR: 1.85E-04]Training epoch 12:  69%|██████▊   | 234/341 [00:04<00:01, 54.78it/s, Epoch: 12, Batch: 234,Loss: -1.454,Avg.Loss: -1.671,LR: 1.85E-04]Training epoch 12:  69%|██████▊   | 234/341 [00:04<00:01, 54.78it/s, Epoch: 12, Batch: 235,Loss: -0.352,Avg.Loss: -1.666,LR: 1.84E-04]Training epoch 12:  69%|██████▉   | 235/341 [00:04<00:01, 54.78it/s, Epoch: 12, Batch: 236,Loss: -1.202,Avg.Loss: -1.664,LR: 1.84E-04]Training epoch 12:  69%|██████▉   | 236/341 [00:04<00:01, 54.78it/s, Epoch: 12, Batch: 237,Loss: -1.902,Avg.Loss: -1.665,LR: 1.84E-04]Training epoch 12:  70%|██████▉   | 237/341 [00:04<00:01, 54.78it/s, Epoch: 12, Batch: 238,Loss: -1.288,Avg.Loss: -1.663,LR: 1.84E-04]Training epoch 12:  70%|██████▉   | 238/341 [00:04<00:01, 54.78it/s, Epoch: 12, Batch: 239,Loss: 0.226,Avg.Loss: -1.655,LR: 1.84E-04] Training epoch 12:  70%|███████   | 239/341 [00:04<00:01, 54.78it/s, Epoch: 12, Batch: 240,Loss: -0.587,Avg.Loss: -1.651,LR: 1.84E-04]Training epoch 12:  70%|███████   | 240/341 [00:04<00:01, 54.42it/s, Epoch: 12, Batch: 240,Loss: -0.587,Avg.Loss: -1.651,LR: 1.84E-04]Training epoch 12:  70%|███████   | 240/341 [00:04<00:01, 54.42it/s, Epoch: 12, Batch: 241,Loss: -1.664,Avg.Loss: -1.651,LR: 1.84E-04]Training epoch 12:  71%|███████   | 241/341 [00:04<00:01, 54.42it/s, Epoch: 12, Batch: 242,Loss: -1.307,Avg.Loss: -1.649,LR: 1.84E-04]Training epoch 12:  71%|███████   | 242/341 [00:04<00:01, 54.42it/s, Epoch: 12, Batch: 243,Loss: -0.463,Avg.Loss: -1.644,LR: 1.84E-04]Training epoch 12:  71%|███████▏  | 243/341 [00:04<00:01, 54.42it/s, Epoch: 12, Batch: 244,Loss: -0.939,Avg.Loss: -1.641,LR: 1.83E-04]Training epoch 12:  72%|███████▏  | 244/341 [00:04<00:01, 54.42it/s, Epoch: 12, Batch: 245,Loss: -1.315,Avg.Loss: -1.640,LR: 1.83E-04]Training epoch 12:  72%|███████▏  | 245/341 [00:04<00:01, 54.42it/s, Epoch: 12, Batch: 246,Loss: -1.994,Avg.Loss: -1.642,LR: 1.83E-04]Training epoch 12:  72%|███████▏  | 246/341 [00:04<00:01, 54.75it/s, Epoch: 12, Batch: 246,Loss: -1.994,Avg.Loss: -1.642,LR: 1.83E-04]Training epoch 12:  72%|███████▏  | 246/341 [00:04<00:01, 54.75it/s, Epoch: 12, Batch: 247,Loss: -1.939,Avg.Loss: -1.643,LR: 1.83E-04]Training epoch 12:  72%|███████▏  | 247/341 [00:04<00:01, 54.75it/s, Epoch: 12, Batch: 248,Loss: -1.695,Avg.Loss: -1.643,LR: 1.83E-04]Training epoch 12:  73%|███████▎  | 248/341 [00:04<00:01, 54.75it/s, Epoch: 12, Batch: 249,Loss: -2.100,Avg.Loss: -1.645,LR: 1.83E-04]Training epoch 12:  73%|███████▎  | 249/341 [00:04<00:01, 54.75it/s, Epoch: 12, Batch: 250,Loss: -1.818,Avg.Loss: -1.646,LR: 1.83E-04]Training epoch 12:  73%|███████▎  | 250/341 [00:04<00:01, 54.75it/s, Epoch: 12, Batch: 251,Loss: -1.982,Avg.Loss: -1.647,LR: 1.83E-04]Training epoch 12:  74%|███████▎  | 251/341 [00:04<00:01, 54.75it/s, Epoch: 12, Batch: 252,Loss: -1.761,Avg.Loss: -1.647,LR: 1.83E-04]Training epoch 12:  74%|███████▍  | 252/341 [00:04<00:01, 54.92it/s, Epoch: 12, Batch: 252,Loss: -1.761,Avg.Loss: -1.647,LR: 1.83E-04]Training epoch 12:  74%|███████▍  | 252/341 [00:04<00:01, 54.92it/s, Epoch: 12, Batch: 253,Loss: -2.082,Avg.Loss: -1.649,LR: 1.82E-04]Training epoch 12:  74%|███████▍  | 253/341 [00:04<00:01, 54.92it/s, Epoch: 12, Batch: 254,Loss: -2.015,Avg.Loss: -1.650,LR: 1.82E-04]Training epoch 12:  74%|███████▍  | 254/341 [00:04<00:01, 54.92it/s, Epoch: 12, Batch: 255,Loss: -1.886,Avg.Loss: -1.651,LR: 1.82E-04]Training epoch 12:  75%|███████▍  | 255/341 [00:04<00:01, 54.92it/s, Epoch: 12, Batch: 256,Loss: -1.438,Avg.Loss: -1.651,LR: 1.82E-04]Training epoch 12:  75%|███████▌  | 256/341 [00:04<00:01, 54.92it/s, Epoch: 12, Batch: 257,Loss: -2.257,Avg.Loss: -1.653,LR: 1.82E-04]Training epoch 12:  75%|███████▌  | 257/341 [00:04<00:01, 54.92it/s, Epoch: 12, Batch: 258,Loss: -2.056,Avg.Loss: -1.654,LR: 1.82E-04]Training epoch 12:  76%|███████▌  | 258/341 [00:04<00:01, 54.79it/s, Epoch: 12, Batch: 258,Loss: -2.056,Avg.Loss: -1.654,LR: 1.82E-04]Training epoch 12:  76%|███████▌  | 258/341 [00:04<00:01, 54.79it/s, Epoch: 12, Batch: 259,Loss: -1.853,Avg.Loss: -1.655,LR: 1.82E-04]Training epoch 12:  76%|███████▌  | 259/341 [00:04<00:01, 54.79it/s, Epoch: 12, Batch: 260,Loss: -1.612,Avg.Loss: -1.655,LR: 1.82E-04]Training epoch 12:  76%|███████▌  | 260/341 [00:04<00:01, 54.79it/s, Epoch: 12, Batch: 261,Loss: -1.300,Avg.Loss: -1.654,LR: 1.82E-04]Training epoch 12:  77%|███████▋  | 261/341 [00:04<00:01, 54.79it/s, Epoch: 12, Batch: 262,Loss: -2.058,Avg.Loss: -1.655,LR: 1.81E-04]Training epoch 12:  77%|███████▋  | 262/341 [00:04<00:01, 54.79it/s, Epoch: 12, Batch: 263,Loss: -2.306,Avg.Loss: -1.658,LR: 1.81E-04]Training epoch 12:  77%|███████▋  | 263/341 [00:04<00:01, 54.79it/s, Epoch: 12, Batch: 264,Loss: -1.932,Avg.Loss: -1.659,LR: 1.81E-04]Training epoch 12:  77%|███████▋  | 264/341 [00:04<00:01, 54.49it/s, Epoch: 12, Batch: 264,Loss: -1.932,Avg.Loss: -1.659,LR: 1.81E-04]Training epoch 12:  77%|███████▋  | 264/341 [00:04<00:01, 54.49it/s, Epoch: 12, Batch: 265,Loss: -2.124,Avg.Loss: -1.661,LR: 1.81E-04]Training epoch 12:  78%|███████▊  | 265/341 [00:04<00:01, 54.49it/s, Epoch: 12, Batch: 266,Loss: -2.381,Avg.Loss: -1.663,LR: 1.81E-04]Training epoch 12:  78%|███████▊  | 266/341 [00:04<00:01, 54.49it/s, Epoch: 12, Batch: 267,Loss: -2.002,Avg.Loss: -1.665,LR: 1.81E-04]Training epoch 12:  78%|███████▊  | 267/341 [00:04<00:01, 54.49it/s, Epoch: 12, Batch: 268,Loss: -1.487,Avg.Loss: -1.664,LR: 1.81E-04]Training epoch 12:  79%|███████▊  | 268/341 [00:04<00:01, 54.49it/s, Epoch: 12, Batch: 269,Loss: -1.865,Avg.Loss: -1.665,LR: 1.81E-04]Training epoch 12:  79%|███████▉  | 269/341 [00:04<00:01, 54.49it/s, Epoch: 12, Batch: 270,Loss: -2.232,Avg.Loss: -1.667,LR: 1.81E-04]Training epoch 12:  79%|███████▉  | 270/341 [00:04<00:01, 54.44it/s, Epoch: 12, Batch: 270,Loss: -2.232,Avg.Loss: -1.667,LR: 1.81E-04]Training epoch 12:  79%|███████▉  | 270/341 [00:05<00:01, 54.44it/s, Epoch: 12, Batch: 271,Loss: -2.137,Avg.Loss: -1.668,LR: 1.80E-04]Training epoch 12:  79%|███████▉  | 271/341 [00:05<00:01, 54.44it/s, Epoch: 12, Batch: 272,Loss: -1.428,Avg.Loss: -1.668,LR: 1.80E-04]Training epoch 12:  80%|███████▉  | 272/341 [00:05<00:01, 54.44it/s, Epoch: 12, Batch: 273,Loss: -1.473,Avg.Loss: -1.667,LR: 1.80E-04]Training epoch 12:  80%|████████  | 273/341 [00:05<00:01, 54.44it/s, Epoch: 12, Batch: 274,Loss: -1.595,Avg.Loss: -1.667,LR: 1.80E-04]Training epoch 12:  80%|████████  | 274/341 [00:05<00:01, 54.44it/s, Epoch: 12, Batch: 275,Loss: -2.062,Avg.Loss: -1.668,LR: 1.80E-04]Training epoch 12:  81%|████████  | 275/341 [00:05<00:01, 54.44it/s, Epoch: 12, Batch: 276,Loss: -2.081,Avg.Loss: -1.670,LR: 1.80E-04]Training epoch 12:  81%|████████  | 276/341 [00:05<00:01, 55.35it/s, Epoch: 12, Batch: 276,Loss: -2.081,Avg.Loss: -1.670,LR: 1.80E-04]Training epoch 12:  81%|████████  | 276/341 [00:05<00:01, 55.35it/s, Epoch: 12, Batch: 277,Loss: -1.979,Avg.Loss: -1.671,LR: 1.80E-04]Training epoch 12:  81%|████████  | 277/341 [00:05<00:01, 55.35it/s, Epoch: 12, Batch: 278,Loss: -0.861,Avg.Loss: -1.668,LR: 1.80E-04]Training epoch 12:  82%|████████▏ | 278/341 [00:05<00:01, 55.35it/s, Epoch: 12, Batch: 279,Loss: -0.970,Avg.Loss: -1.665,LR: 1.80E-04]Training epoch 12:  82%|████████▏ | 279/341 [00:05<00:01, 55.35it/s, Epoch: 12, Batch: 280,Loss: -2.067,Avg.Loss: -1.667,LR: 1.79E-04]Training epoch 12:  82%|████████▏ | 280/341 [00:05<00:01, 55.35it/s, Epoch: 12, Batch: 281,Loss: -2.371,Avg.Loss: -1.669,LR: 1.79E-04]Training epoch 12:  82%|████████▏ | 281/341 [00:05<00:01, 55.35it/s, Epoch: 12, Batch: 282,Loss: -1.530,Avg.Loss: -1.669,LR: 1.79E-04]Training epoch 12:  83%|████████▎ | 282/341 [00:05<00:01, 55.98it/s, Epoch: 12, Batch: 282,Loss: -1.530,Avg.Loss: -1.669,LR: 1.79E-04]Training epoch 12:  83%|████████▎ | 282/341 [00:05<00:01, 55.98it/s, Epoch: 12, Batch: 283,Loss: -1.123,Avg.Loss: -1.667,LR: 1.79E-04]Training epoch 12:  83%|████████▎ | 283/341 [00:05<00:01, 55.98it/s, Epoch: 12, Batch: 284,Loss: -1.386,Avg.Loss: -1.666,LR: 1.79E-04]Training epoch 12:  83%|████████▎ | 284/341 [00:05<00:01, 55.98it/s, Epoch: 12, Batch: 285,Loss: -1.875,Avg.Loss: -1.666,LR: 1.79E-04]Training epoch 12:  84%|████████▎ | 285/341 [00:05<00:01, 55.98it/s, Epoch: 12, Batch: 286,Loss: -2.177,Avg.Loss: -1.668,LR: 1.79E-04]Training epoch 12:  84%|████████▍ | 286/341 [00:05<00:00, 55.98it/s, Epoch: 12, Batch: 287,Loss: -1.851,Avg.Loss: -1.669,LR: 1.79E-04]Training epoch 12:  84%|████████▍ | 287/341 [00:05<00:00, 55.98it/s, Epoch: 12, Batch: 288,Loss: -1.966,Avg.Loss: -1.670,LR: 1.79E-04]Training epoch 12:  84%|████████▍ | 288/341 [00:05<00:00, 55.22it/s, Epoch: 12, Batch: 288,Loss: -1.966,Avg.Loss: -1.670,LR: 1.79E-04]Training epoch 12:  84%|████████▍ | 288/341 [00:05<00:00, 55.22it/s, Epoch: 12, Batch: 289,Loss: -2.100,Avg.Loss: -1.671,LR: 1.78E-04]Training epoch 12:  85%|████████▍ | 289/341 [00:05<00:00, 55.22it/s, Epoch: 12, Batch: 290,Loss: -2.199,Avg.Loss: -1.673,LR: 1.78E-04]Training epoch 12:  85%|████████▌ | 290/341 [00:05<00:00, 55.22it/s, Epoch: 12, Batch: 291,Loss: -2.177,Avg.Loss: -1.675,LR: 1.78E-04]Training epoch 12:  85%|████████▌ | 291/341 [00:05<00:00, 55.22it/s, Epoch: 12, Batch: 292,Loss: -1.625,Avg.Loss: -1.675,LR: 1.78E-04]Training epoch 12:  86%|████████▌ | 292/341 [00:05<00:00, 55.22it/s, Epoch: 12, Batch: 293,Loss: -1.973,Avg.Loss: -1.676,LR: 1.78E-04]Training epoch 12:  86%|████████▌ | 293/341 [00:05<00:00, 55.22it/s, Epoch: 12, Batch: 294,Loss: -2.189,Avg.Loss: -1.678,LR: 1.78E-04]Training epoch 12:  86%|████████▌ | 294/341 [00:05<00:00, 56.15it/s, Epoch: 12, Batch: 294,Loss: -2.189,Avg.Loss: -1.678,LR: 1.78E-04]Training epoch 12:  86%|████████▌ | 294/341 [00:05<00:00, 56.15it/s, Epoch: 12, Batch: 295,Loss: -2.133,Avg.Loss: -1.679,LR: 1.78E-04]Training epoch 12:  87%|████████▋ | 295/341 [00:05<00:00, 56.15it/s, Epoch: 12, Batch: 296,Loss: -2.320,Avg.Loss: -1.681,LR: 1.78E-04]Training epoch 12:  87%|████████▋ | 296/341 [00:05<00:00, 56.15it/s, Epoch: 12, Batch: 297,Loss: -2.280,Avg.Loss: -1.683,LR: 1.78E-04]Training epoch 12:  87%|████████▋ | 297/341 [00:05<00:00, 56.15it/s, Epoch: 12, Batch: 298,Loss: -2.180,Avg.Loss: -1.685,LR: 1.77E-04]Training epoch 12:  87%|████████▋ | 298/341 [00:05<00:00, 56.15it/s, Epoch: 12, Batch: 299,Loss: -0.632,Avg.Loss: -1.681,LR: 1.77E-04]Training epoch 12:  88%|████████▊ | 299/341 [00:05<00:00, 56.15it/s, Epoch: 12, Batch: 300,Loss: -1.258,Avg.Loss: -1.680,LR: 1.77E-04]Training epoch 12:  88%|████████▊ | 300/341 [00:05<00:00, 55.29it/s, Epoch: 12, Batch: 300,Loss: -1.258,Avg.Loss: -1.680,LR: 1.77E-04]Training epoch 12:  88%|████████▊ | 300/341 [00:05<00:00, 55.29it/s, Epoch: 12, Batch: 301,Loss: -1.199,Avg.Loss: -1.678,LR: 1.77E-04]Training epoch 12:  88%|████████▊ | 301/341 [00:05<00:00, 55.29it/s, Epoch: 12, Batch: 302,Loss: -1.767,Avg.Loss: -1.679,LR: 1.77E-04]Training epoch 12:  89%|████████▊ | 302/341 [00:05<00:00, 55.29it/s, Epoch: 12, Batch: 303,Loss: -2.326,Avg.Loss: -1.681,LR: 1.77E-04]Training epoch 12:  89%|████████▉ | 303/341 [00:05<00:00, 55.29it/s, Epoch: 12, Batch: 304,Loss: -2.289,Avg.Loss: -1.683,LR: 1.77E-04]Training epoch 12:  89%|████████▉ | 304/341 [00:05<00:00, 55.29it/s, Epoch: 12, Batch: 305,Loss: -2.261,Avg.Loss: -1.685,LR: 1.77E-04]Training epoch 12:  89%|████████▉ | 305/341 [00:05<00:00, 55.29it/s, Epoch: 12, Batch: 306,Loss: -2.041,Avg.Loss: -1.686,LR: 1.77E-04]Training epoch 12:  90%|████████▉ | 306/341 [00:05<00:00, 54.92it/s, Epoch: 12, Batch: 306,Loss: -2.041,Avg.Loss: -1.686,LR: 1.77E-04]Training epoch 12:  90%|████████▉ | 306/341 [00:05<00:00, 54.92it/s, Epoch: 12, Batch: 307,Loss: -2.188,Avg.Loss: -1.688,LR: 1.76E-04]Training epoch 12:  90%|█████████ | 307/341 [00:05<00:00, 54.92it/s, Epoch: 12, Batch: 308,Loss: -2.171,Avg.Loss: -1.689,LR: 1.76E-04]Training epoch 12:  90%|█████████ | 308/341 [00:05<00:00, 54.92it/s, Epoch: 12, Batch: 309,Loss: -1.966,Avg.Loss: -1.690,LR: 1.76E-04]Training epoch 12:  91%|█████████ | 309/341 [00:05<00:00, 54.92it/s, Epoch: 12, Batch: 310,Loss: -2.022,Avg.Loss: -1.691,LR: 1.76E-04]Training epoch 12:  91%|█████████ | 310/341 [00:05<00:00, 54.92it/s, Epoch: 12, Batch: 311,Loss: -2.413,Avg.Loss: -1.693,LR: 1.76E-04]Training epoch 12:  91%|█████████ | 311/341 [00:05<00:00, 54.92it/s, Epoch: 12, Batch: 312,Loss: -1.670,Avg.Loss: -1.693,LR: 1.76E-04]Training epoch 12:  91%|█████████▏| 312/341 [00:05<00:00, 54.92it/s, Epoch: 12, Batch: 313,Loss: -1.554,Avg.Loss: -1.693,LR: 1.76E-04]Training epoch 12:  92%|█████████▏| 313/341 [00:05<00:00, 57.19it/s, Epoch: 12, Batch: 313,Loss: -1.554,Avg.Loss: -1.693,LR: 1.76E-04]Training epoch 12:  92%|█████████▏| 313/341 [00:05<00:00, 57.19it/s, Epoch: 12, Batch: 314,Loss: -1.885,Avg.Loss: -1.694,LR: 1.76E-04]Training epoch 12:  92%|█████████▏| 314/341 [00:05<00:00, 57.19it/s, Epoch: 12, Batch: 315,Loss: -1.710,Avg.Loss: -1.694,LR: 1.76E-04]Training epoch 12:  92%|█████████▏| 315/341 [00:05<00:00, 57.19it/s, Epoch: 12, Batch: 316,Loss: -1.282,Avg.Loss: -1.692,LR: 1.75E-04]Training epoch 12:  93%|█████████▎| 316/341 [00:05<00:00, 57.19it/s, Epoch: 12, Batch: 317,Loss: -1.819,Avg.Loss: -1.693,LR: 1.75E-04]Training epoch 12:  93%|█████████▎| 317/341 [00:05<00:00, 57.19it/s, Epoch: 12, Batch: 318,Loss: -1.573,Avg.Loss: -1.692,LR: 1.75E-04]Training epoch 12:  93%|█████████▎| 318/341 [00:05<00:00, 57.19it/s, Epoch: 12, Batch: 319,Loss: -1.638,Avg.Loss: -1.692,LR: 1.75E-04]Training epoch 12:  94%|█████████▎| 319/341 [00:05<00:00, 56.37it/s, Epoch: 12, Batch: 319,Loss: -1.638,Avg.Loss: -1.692,LR: 1.75E-04]Training epoch 12:  94%|█████████▎| 319/341 [00:05<00:00, 56.37it/s, Epoch: 12, Batch: 320,Loss: -1.848,Avg.Loss: -1.693,LR: 1.75E-04]Training epoch 12:  94%|█████████▍| 320/341 [00:05<00:00, 56.37it/s, Epoch: 12, Batch: 321,Loss: -1.802,Avg.Loss: -1.693,LR: 1.75E-04]Training epoch 12:  94%|█████████▍| 321/341 [00:05<00:00, 56.37it/s, Epoch: 12, Batch: 322,Loss: -2.315,Avg.Loss: -1.695,LR: 1.75E-04]Training epoch 12:  94%|█████████▍| 322/341 [00:05<00:00, 56.37it/s, Epoch: 12, Batch: 323,Loss: -1.773,Avg.Loss: -1.695,LR: 1.75E-04]Training epoch 12:  95%|█████████▍| 323/341 [00:05<00:00, 56.37it/s, Epoch: 12, Batch: 324,Loss: -2.406,Avg.Loss: -1.697,LR: 1.75E-04]Training epoch 12:  95%|█████████▌| 324/341 [00:05<00:00, 56.37it/s, Epoch: 12, Batch: 325,Loss: -1.866,Avg.Loss: -1.698,LR: 1.75E-04]Training epoch 12:  95%|█████████▌| 325/341 [00:05<00:00, 55.51it/s, Epoch: 12, Batch: 325,Loss: -1.866,Avg.Loss: -1.698,LR: 1.75E-04]Training epoch 12:  95%|█████████▌| 325/341 [00:05<00:00, 55.51it/s, Epoch: 12, Batch: 326,Loss: -2.028,Avg.Loss: -1.699,LR: 1.74E-04]Training epoch 12:  96%|█████████▌| 326/341 [00:06<00:00, 55.51it/s, Epoch: 12, Batch: 327,Loss: -2.119,Avg.Loss: -1.700,LR: 1.74E-04]Training epoch 12:  96%|█████████▌| 327/341 [00:06<00:00, 55.51it/s, Epoch: 12, Batch: 328,Loss: -2.028,Avg.Loss: -1.701,LR: 1.74E-04]Training epoch 12:  96%|█████████▌| 328/341 [00:06<00:00, 55.51it/s, Epoch: 12, Batch: 329,Loss: -1.555,Avg.Loss: -1.701,LR: 1.74E-04]Training epoch 12:  96%|█████████▋| 329/341 [00:06<00:00, 55.51it/s, Epoch: 12, Batch: 330,Loss: -2.008,Avg.Loss: -1.702,LR: 1.74E-04]Training epoch 12:  97%|█████████▋| 330/341 [00:06<00:00, 55.51it/s, Epoch: 12, Batch: 331,Loss: -1.817,Avg.Loss: -1.702,LR: 1.74E-04]Training epoch 12:  97%|█████████▋| 331/341 [00:06<00:00, 55.23it/s, Epoch: 12, Batch: 331,Loss: -1.817,Avg.Loss: -1.702,LR: 1.74E-04]Training epoch 12:  97%|█████████▋| 331/341 [00:06<00:00, 55.23it/s, Epoch: 12, Batch: 332,Loss: -2.206,Avg.Loss: -1.703,LR: 1.74E-04]Training epoch 12:  97%|█████████▋| 332/341 [00:06<00:00, 55.23it/s, Epoch: 12, Batch: 333,Loss: -1.712,Avg.Loss: -1.703,LR: 1.74E-04]Training epoch 12:  98%|█████████▊| 333/341 [00:06<00:00, 55.23it/s, Epoch: 12, Batch: 334,Loss: -1.620,Avg.Loss: -1.703,LR: 1.74E-04]Training epoch 12:  98%|█████████▊| 334/341 [00:06<00:00, 55.23it/s, Epoch: 12, Batch: 335,Loss: -2.347,Avg.Loss: -1.705,LR: 1.73E-04]Training epoch 12:  98%|█████████▊| 335/341 [00:06<00:00, 55.23it/s, Epoch: 12, Batch: 336,Loss: -2.033,Avg.Loss: -1.706,LR: 1.73E-04]Training epoch 12:  99%|█████████▊| 336/341 [00:06<00:00, 55.23it/s, Epoch: 12, Batch: 337,Loss: -2.215,Avg.Loss: -1.708,LR: 1.73E-04]Training epoch 12:  99%|█████████▉| 337/341 [00:06<00:00, 54.76it/s, Epoch: 12, Batch: 337,Loss: -2.215,Avg.Loss: -1.708,LR: 1.73E-04]Training epoch 12:  99%|█████████▉| 337/341 [00:06<00:00, 54.76it/s, Epoch: 12, Batch: 338,Loss: -1.670,Avg.Loss: -1.708,LR: 1.73E-04]Training epoch 12:  99%|█████████▉| 338/341 [00:06<00:00, 54.76it/s, Epoch: 12, Batch: 339,Loss: -1.290,Avg.Loss: -1.706,LR: 1.73E-04]Training epoch 12:  99%|█████████▉| 339/341 [00:06<00:00, 54.76it/s, Epoch: 12, Batch: 340,Loss: -2.233,Avg.Loss: -1.708,LR: 1.73E-04]Training epoch 12: 100%|█████████▉| 340/341 [00:06<00:00, 54.76it/s, Epoch: 12, Batch: 341,Loss: -1.483,Avg.Loss: -1.707,LR: 1.73E-04]Training epoch 12: 100%|██████████| 341/341 [00:06<00:00, 54.40it/s, Epoch: 12, Batch: 341,Loss: -1.483,Avg.Loss: -1.707,LR: 1.73E-04]
Training epoch 13:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 13:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 13, Batch: 1,Loss: -1.656,Avg.Loss: -1.656,LR: 1.73E-04]Training epoch 13:   0%|          | 1/341 [00:00<00:11, 29.94it/s, Epoch: 13, Batch: 2,Loss: -1.173,Avg.Loss: -1.414,LR: 1.73E-04]Training epoch 13:   1%|          | 2/341 [00:00<00:08, 40.81it/s, Epoch: 13, Batch: 3,Loss: -1.072,Avg.Loss: -1.300,LR: 1.72E-04]Training epoch 13:   1%|          | 3/341 [00:00<00:07, 44.39it/s, Epoch: 13, Batch: 4,Loss: -1.606,Avg.Loss: -1.377,LR: 1.72E-04]Training epoch 13:   1%|          | 4/341 [00:00<00:07, 46.52it/s, Epoch: 13, Batch: 5,Loss: -1.751,Avg.Loss: -1.451,LR: 1.72E-04]Training epoch 13:   1%|▏         | 5/341 [00:00<00:07, 47.87it/s, Epoch: 13, Batch: 6,Loss: -1.835,Avg.Loss: -1.515,LR: 1.72E-04]Training epoch 13:   2%|▏         | 6/341 [00:00<00:05, 57.34it/s, Epoch: 13, Batch: 6,Loss: -1.835,Avg.Loss: -1.515,LR: 1.72E-04]Training epoch 13:   2%|▏         | 6/341 [00:00<00:05, 57.34it/s, Epoch: 13, Batch: 7,Loss: -1.870,Avg.Loss: -1.566,LR: 1.72E-04]Training epoch 13:   2%|▏         | 7/341 [00:00<00:05, 57.34it/s, Epoch: 13, Batch: 8,Loss: -2.015,Avg.Loss: -1.622,LR: 1.72E-04]Training epoch 13:   2%|▏         | 8/341 [00:00<00:05, 57.34it/s, Epoch: 13, Batch: 9,Loss: -2.515,Avg.Loss: -1.721,LR: 1.72E-04]Training epoch 13:   3%|▎         | 9/341 [00:00<00:05, 57.34it/s, Epoch: 13, Batch: 10,Loss: -2.234,Avg.Loss: -1.773,LR: 1.72E-04]Training epoch 13:   3%|▎         | 10/341 [00:00<00:05, 57.34it/s, Epoch: 13, Batch: 11,Loss: -2.207,Avg.Loss: -1.812,LR: 1.72E-04]Training epoch 13:   3%|▎         | 11/341 [00:00<00:05, 57.34it/s, Epoch: 13, Batch: 12,Loss: -2.164,Avg.Loss: -1.841,LR: 1.71E-04]Training epoch 13:   4%|▎         | 12/341 [00:00<00:05, 56.29it/s, Epoch: 13, Batch: 12,Loss: -2.164,Avg.Loss: -1.841,LR: 1.71E-04]Training epoch 13:   4%|▎         | 12/341 [00:00<00:05, 56.29it/s, Epoch: 13, Batch: 13,Loss: -1.980,Avg.Loss: -1.852,LR: 1.71E-04]Training epoch 13:   4%|▍         | 13/341 [00:00<00:05, 56.29it/s, Epoch: 13, Batch: 14,Loss: -2.207,Avg.Loss: -1.877,LR: 1.71E-04]Training epoch 13:   4%|▍         | 14/341 [00:00<00:05, 56.29it/s, Epoch: 13, Batch: 15,Loss: -2.175,Avg.Loss: -1.897,LR: 1.71E-04]Training epoch 13:   4%|▍         | 15/341 [00:00<00:05, 56.29it/s, Epoch: 13, Batch: 16,Loss: -2.382,Avg.Loss: -1.928,LR: 1.71E-04]Training epoch 13:   5%|▍         | 16/341 [00:00<00:05, 56.29it/s, Epoch: 13, Batch: 17,Loss: -1.895,Avg.Loss: -1.926,LR: 1.71E-04]Training epoch 13:   5%|▍         | 17/341 [00:00<00:05, 56.29it/s, Epoch: 13, Batch: 18,Loss: -1.955,Avg.Loss: -1.927,LR: 1.71E-04]Training epoch 13:   5%|▌         | 18/341 [00:00<00:05, 55.07it/s, Epoch: 13, Batch: 18,Loss: -1.955,Avg.Loss: -1.927,LR: 1.71E-04]Training epoch 13:   5%|▌         | 18/341 [00:00<00:05, 55.07it/s, Epoch: 13, Batch: 19,Loss: -1.768,Avg.Loss: -1.919,LR: 1.71E-04]Training epoch 13:   6%|▌         | 19/341 [00:00<00:05, 55.07it/s, Epoch: 13, Batch: 20,Loss: -1.200,Avg.Loss: -1.883,LR: 1.71E-04]Training epoch 13:   6%|▌         | 20/341 [00:00<00:05, 55.07it/s, Epoch: 13, Batch: 21,Loss: -1.979,Avg.Loss: -1.888,LR: 1.70E-04]Training epoch 13:   6%|▌         | 21/341 [00:00<00:05, 55.07it/s, Epoch: 13, Batch: 22,Loss: -2.208,Avg.Loss: -1.902,LR: 1.70E-04]Training epoch 13:   6%|▋         | 22/341 [00:00<00:05, 55.07it/s, Epoch: 13, Batch: 23,Loss: -2.345,Avg.Loss: -1.921,LR: 1.70E-04]Training epoch 13:   7%|▋         | 23/341 [00:00<00:05, 55.07it/s, Epoch: 13, Batch: 24,Loss: -2.376,Avg.Loss: -1.940,LR: 1.70E-04]Training epoch 13:   7%|▋         | 24/341 [00:00<00:05, 54.90it/s, Epoch: 13, Batch: 24,Loss: -2.376,Avg.Loss: -1.940,LR: 1.70E-04]Training epoch 13:   7%|▋         | 24/341 [00:00<00:05, 54.90it/s, Epoch: 13, Batch: 25,Loss: -2.081,Avg.Loss: -1.946,LR: 1.70E-04]Training epoch 13:   7%|▋         | 25/341 [00:00<00:05, 54.90it/s, Epoch: 13, Batch: 26,Loss: -1.983,Avg.Loss: -1.947,LR: 1.70E-04]Training epoch 13:   8%|▊         | 26/341 [00:00<00:05, 54.90it/s, Epoch: 13, Batch: 27,Loss: -1.864,Avg.Loss: -1.944,LR: 1.70E-04]Training epoch 13:   8%|▊         | 27/341 [00:00<00:05, 54.90it/s, Epoch: 13, Batch: 28,Loss: -1.897,Avg.Loss: -1.943,LR: 1.70E-04]Training epoch 13:   8%|▊         | 28/341 [00:00<00:05, 54.90it/s, Epoch: 13, Batch: 29,Loss: -2.196,Avg.Loss: -1.951,LR: 1.70E-04]Training epoch 13:   9%|▊         | 29/341 [00:00<00:05, 54.90it/s, Epoch: 13, Batch: 30,Loss: -2.548,Avg.Loss: -1.971,LR: 1.69E-04]Training epoch 13:   9%|▉         | 30/341 [00:00<00:05, 53.69it/s, Epoch: 13, Batch: 30,Loss: -2.548,Avg.Loss: -1.971,LR: 1.69E-04]Training epoch 13:   9%|▉         | 30/341 [00:00<00:05, 53.69it/s, Epoch: 13, Batch: 31,Loss: -2.316,Avg.Loss: -1.982,LR: 1.69E-04]Training epoch 13:   9%|▉         | 31/341 [00:00<00:05, 53.69it/s, Epoch: 13, Batch: 32,Loss: -2.143,Avg.Loss: -1.987,LR: 1.69E-04]Training epoch 13:   9%|▉         | 32/341 [00:00<00:05, 53.69it/s, Epoch: 13, Batch: 33,Loss: -2.080,Avg.Loss: -1.990,LR: 1.69E-04]Training epoch 13:  10%|▉         | 33/341 [00:00<00:05, 53.69it/s, Epoch: 13, Batch: 34,Loss: -2.515,Avg.Loss: -2.006,LR: 1.69E-04]Training epoch 13:  10%|▉         | 34/341 [00:00<00:05, 53.69it/s, Epoch: 13, Batch: 35,Loss: -2.329,Avg.Loss: -2.015,LR: 1.69E-04]Training epoch 13:  10%|█         | 35/341 [00:00<00:05, 53.69it/s, Epoch: 13, Batch: 36,Loss: -2.279,Avg.Loss: -2.022,LR: 1.69E-04]Training epoch 13:  11%|█         | 36/341 [00:00<00:05, 53.94it/s, Epoch: 13, Batch: 36,Loss: -2.279,Avg.Loss: -2.022,LR: 1.69E-04]Training epoch 13:  11%|█         | 36/341 [00:00<00:05, 53.94it/s, Epoch: 13, Batch: 37,Loss: -1.992,Avg.Loss: -2.021,LR: 1.69E-04]Training epoch 13:  11%|█         | 37/341 [00:00<00:05, 53.94it/s, Epoch: 13, Batch: 38,Loss: -2.163,Avg.Loss: -2.025,LR: 1.69E-04]Training epoch 13:  11%|█         | 38/341 [00:00<00:05, 53.94it/s, Epoch: 13, Batch: 39,Loss: -2.556,Avg.Loss: -2.039,LR: 1.68E-04]Training epoch 13:  11%|█▏        | 39/341 [00:00<00:05, 53.94it/s, Epoch: 13, Batch: 40,Loss: -2.235,Avg.Loss: -2.044,LR: 1.68E-04]Training epoch 13:  12%|█▏        | 40/341 [00:00<00:05, 53.94it/s, Epoch: 13, Batch: 41,Loss: -2.481,Avg.Loss: -2.054,LR: 1.68E-04]Training epoch 13:  12%|█▏        | 41/341 [00:00<00:05, 53.94it/s, Epoch: 13, Batch: 42,Loss: -2.165,Avg.Loss: -2.057,LR: 1.68E-04]Training epoch 13:  12%|█▏        | 42/341 [00:00<00:05, 53.88it/s, Epoch: 13, Batch: 42,Loss: -2.165,Avg.Loss: -2.057,LR: 1.68E-04]Training epoch 13:  12%|█▏        | 42/341 [00:00<00:05, 53.88it/s, Epoch: 13, Batch: 43,Loss: -2.240,Avg.Loss: -2.061,LR: 1.68E-04]Training epoch 13:  13%|█▎        | 43/341 [00:00<00:05, 53.88it/s, Epoch: 13, Batch: 44,Loss: -2.071,Avg.Loss: -2.061,LR: 1.68E-04]Training epoch 13:  13%|█▎        | 44/341 [00:00<00:05, 53.88it/s, Epoch: 13, Batch: 45,Loss: -2.016,Avg.Loss: -2.060,LR: 1.68E-04]Training epoch 13:  13%|█▎        | 45/341 [00:00<00:05, 53.88it/s, Epoch: 13, Batch: 46,Loss: -1.795,Avg.Loss: -2.055,LR: 1.68E-04]Training epoch 13:  13%|█▎        | 46/341 [00:00<00:05, 53.88it/s, Epoch: 13, Batch: 47,Loss: -2.028,Avg.Loss: -2.054,LR: 1.68E-04]Training epoch 13:  14%|█▍        | 47/341 [00:00<00:05, 53.88it/s, Epoch: 13, Batch: 48,Loss: -1.562,Avg.Loss: -2.044,LR: 1.68E-04]Training epoch 13:  14%|█▍        | 48/341 [00:00<00:05, 53.64it/s, Epoch: 13, Batch: 48,Loss: -1.562,Avg.Loss: -2.044,LR: 1.68E-04]Training epoch 13:  14%|█▍        | 48/341 [00:00<00:05, 53.64it/s, Epoch: 13, Batch: 49,Loss: -2.482,Avg.Loss: -2.053,LR: 1.67E-04]Training epoch 13:  14%|█▍        | 49/341 [00:00<00:05, 53.64it/s, Epoch: 13, Batch: 50,Loss: -1.551,Avg.Loss: -2.043,LR: 1.67E-04]Training epoch 13:  15%|█▍        | 50/341 [00:00<00:05, 53.64it/s, Epoch: 13, Batch: 51,Loss: -1.695,Avg.Loss: -2.036,LR: 1.67E-04]Training epoch 13:  15%|█▍        | 51/341 [00:00<00:05, 53.64it/s, Epoch: 13, Batch: 52,Loss: -2.409,Avg.Loss: -2.043,LR: 1.67E-04]Training epoch 13:  15%|█▌        | 52/341 [00:00<00:05, 53.64it/s, Epoch: 13, Batch: 53,Loss: -2.040,Avg.Loss: -2.043,LR: 1.67E-04]Training epoch 13:  16%|█▌        | 53/341 [00:01<00:05, 53.64it/s, Epoch: 13, Batch: 54,Loss: -0.823,Avg.Loss: -2.020,LR: 1.67E-04]Training epoch 13:  16%|█▌        | 54/341 [00:01<00:05, 52.63it/s, Epoch: 13, Batch: 54,Loss: -0.823,Avg.Loss: -2.020,LR: 1.67E-04]Training epoch 13:  16%|█▌        | 54/341 [00:01<00:05, 52.63it/s, Epoch: 13, Batch: 55,Loss: -1.507,Avg.Loss: -2.011,LR: 1.67E-04]Training epoch 13:  16%|█▌        | 55/341 [00:01<00:05, 52.63it/s, Epoch: 13, Batch: 56,Loss: -2.592,Avg.Loss: -2.021,LR: 1.67E-04]Training epoch 13:  16%|█▋        | 56/341 [00:01<00:05, 52.63it/s, Epoch: 13, Batch: 57,Loss: -1.560,Avg.Loss: -2.013,LR: 1.67E-04]Training epoch 13:  17%|█▋        | 57/341 [00:01<00:05, 52.63it/s, Epoch: 13, Batch: 58,Loss: 0.189,Avg.Loss: -1.975,LR: 1.66E-04] Training epoch 13:  17%|█▋        | 58/341 [00:01<00:05, 52.63it/s, Epoch: 13, Batch: 59,Loss: 0.550,Avg.Loss: -1.933,LR: 1.66E-04]Training epoch 13:  17%|█▋        | 59/341 [00:01<00:05, 52.63it/s, Epoch: 13, Batch: 60,Loss: -1.171,Avg.Loss: -1.920,LR: 1.66E-04]Training epoch 13:  18%|█▊        | 60/341 [00:01<00:05, 52.65it/s, Epoch: 13, Batch: 60,Loss: -1.171,Avg.Loss: -1.920,LR: 1.66E-04]Training epoch 13:  18%|█▊        | 60/341 [00:01<00:05, 52.65it/s, Epoch: 13, Batch: 61,Loss: -1.920,Avg.Loss: -1.920,LR: 1.66E-04]Training epoch 13:  18%|█▊        | 61/341 [00:01<00:05, 52.65it/s, Epoch: 13, Batch: 62,Loss: -1.822,Avg.Loss: -1.918,LR: 1.66E-04]Training epoch 13:  18%|█▊        | 62/341 [00:01<00:05, 52.65it/s, Epoch: 13, Batch: 63,Loss: -0.920,Avg.Loss: -1.902,LR: 1.66E-04]Training epoch 13:  18%|█▊        | 63/341 [00:01<00:05, 52.65it/s, Epoch: 13, Batch: 64,Loss: -1.505,Avg.Loss: -1.896,LR: 1.66E-04]Training epoch 13:  19%|█▉        | 64/341 [00:01<00:05, 52.65it/s, Epoch: 13, Batch: 65,Loss: -1.812,Avg.Loss: -1.895,LR: 1.66E-04]Training epoch 13:  19%|█▉        | 65/341 [00:01<00:05, 52.65it/s, Epoch: 13, Batch: 66,Loss: -0.534,Avg.Loss: -1.874,LR: 1.66E-04]Training epoch 13:  19%|█▉        | 66/341 [00:01<00:05, 52.40it/s, Epoch: 13, Batch: 66,Loss: -0.534,Avg.Loss: -1.874,LR: 1.66E-04]Training epoch 13:  19%|█▉        | 66/341 [00:01<00:05, 52.40it/s, Epoch: 13, Batch: 67,Loss: -1.264,Avg.Loss: -1.865,LR: 1.65E-04]Training epoch 13:  20%|█▉        | 67/341 [00:01<00:05, 52.40it/s, Epoch: 13, Batch: 68,Loss: -1.721,Avg.Loss: -1.863,LR: 1.65E-04]Training epoch 13:  20%|█▉        | 68/341 [00:01<00:05, 52.40it/s, Epoch: 13, Batch: 69,Loss: -1.103,Avg.Loss: -1.852,LR: 1.65E-04]Training epoch 13:  20%|██        | 69/341 [00:01<00:05, 52.40it/s, Epoch: 13, Batch: 70,Loss: -0.942,Avg.Loss: -1.839,LR: 1.65E-04]Training epoch 13:  21%|██        | 70/341 [00:01<00:05, 52.40it/s, Epoch: 13, Batch: 71,Loss: -0.323,Avg.Loss: -1.818,LR: 1.65E-04]Training epoch 13:  21%|██        | 71/341 [00:01<00:05, 52.40it/s, Epoch: 13, Batch: 72,Loss: -1.268,Avg.Loss: -1.810,LR: 1.65E-04]Training epoch 13:  21%|██        | 72/341 [00:01<00:04, 54.01it/s, Epoch: 13, Batch: 72,Loss: -1.268,Avg.Loss: -1.810,LR: 1.65E-04]Training epoch 13:  21%|██        | 72/341 [00:01<00:04, 54.01it/s, Epoch: 13, Batch: 73,Loss: -1.532,Avg.Loss: -1.806,LR: 1.65E-04]Training epoch 13:  21%|██▏       | 73/341 [00:01<00:04, 54.01it/s, Epoch: 13, Batch: 74,Loss: -1.750,Avg.Loss: -1.806,LR: 1.65E-04]Training epoch 13:  22%|██▏       | 74/341 [00:01<00:04, 54.01it/s, Epoch: 13, Batch: 75,Loss: -1.412,Avg.Loss: -1.800,LR: 1.65E-04]Training epoch 13:  22%|██▏       | 75/341 [00:01<00:04, 54.01it/s, Epoch: 13, Batch: 76,Loss: -2.152,Avg.Loss: -1.805,LR: 1.64E-04]Training epoch 13:  22%|██▏       | 76/341 [00:01<00:04, 54.01it/s, Epoch: 13, Batch: 77,Loss: -1.391,Avg.Loss: -1.800,LR: 1.64E-04]Training epoch 13:  23%|██▎       | 77/341 [00:01<00:04, 54.01it/s, Epoch: 13, Batch: 78,Loss: 0.201,Avg.Loss: -1.774,LR: 1.64E-04] Training epoch 13:  23%|██▎       | 78/341 [00:01<00:04, 53.29it/s, Epoch: 13, Batch: 78,Loss: 0.201,Avg.Loss: -1.774,LR: 1.64E-04]Training epoch 13:  23%|██▎       | 78/341 [00:01<00:04, 53.29it/s, Epoch: 13, Batch: 79,Loss: -0.450,Avg.Loss: -1.757,LR: 1.64E-04]Training epoch 13:  23%|██▎       | 79/341 [00:01<00:04, 53.29it/s, Epoch: 13, Batch: 80,Loss: -1.815,Avg.Loss: -1.758,LR: 1.64E-04]Training epoch 13:  23%|██▎       | 80/341 [00:01<00:04, 53.29it/s, Epoch: 13, Batch: 81,Loss: -2.129,Avg.Loss: -1.762,LR: 1.64E-04]Training epoch 13:  24%|██▍       | 81/341 [00:01<00:04, 53.29it/s, Epoch: 13, Batch: 82,Loss: -1.389,Avg.Loss: -1.758,LR: 1.64E-04]Training epoch 13:  24%|██▍       | 82/341 [00:01<00:04, 53.29it/s, Epoch: 13, Batch: 83,Loss: -1.619,Avg.Loss: -1.756,LR: 1.64E-04]Training epoch 13:  24%|██▍       | 83/341 [00:01<00:04, 53.29it/s, Epoch: 13, Batch: 84,Loss: -2.386,Avg.Loss: -1.764,LR: 1.64E-04]Training epoch 13:  25%|██▍       | 84/341 [00:01<00:04, 52.55it/s, Epoch: 13, Batch: 84,Loss: -2.386,Avg.Loss: -1.764,LR: 1.64E-04]Training epoch 13:  25%|██▍       | 84/341 [00:01<00:04, 52.55it/s, Epoch: 13, Batch: 85,Loss: -1.764,Avg.Loss: -1.764,LR: 1.63E-04]Training epoch 13:  25%|██▍       | 85/341 [00:01<00:04, 52.55it/s, Epoch: 13, Batch: 86,Loss: -0.915,Avg.Loss: -1.754,LR: 1.63E-04]Training epoch 13:  25%|██▌       | 86/341 [00:01<00:04, 52.55it/s, Epoch: 13, Batch: 87,Loss: -1.212,Avg.Loss: -1.748,LR: 1.63E-04]Training epoch 13:  26%|██▌       | 87/341 [00:01<00:04, 52.55it/s, Epoch: 13, Batch: 88,Loss: -2.181,Avg.Loss: -1.753,LR: 1.63E-04]Training epoch 13:  26%|██▌       | 88/341 [00:01<00:04, 52.55it/s, Epoch: 13, Batch: 89,Loss: -2.085,Avg.Loss: -1.756,LR: 1.63E-04]Training epoch 13:  26%|██▌       | 89/341 [00:01<00:04, 52.55it/s, Epoch: 13, Batch: 90,Loss: -0.928,Avg.Loss: -1.747,LR: 1.63E-04]Training epoch 13:  26%|██▋       | 90/341 [00:01<00:04, 51.75it/s, Epoch: 13, Batch: 90,Loss: -0.928,Avg.Loss: -1.747,LR: 1.63E-04]Training epoch 13:  26%|██▋       | 90/341 [00:01<00:04, 51.75it/s, Epoch: 13, Batch: 91,Loss: -0.682,Avg.Loss: -1.735,LR: 1.63E-04]Training epoch 13:  27%|██▋       | 91/341 [00:01<00:04, 51.75it/s, Epoch: 13, Batch: 92,Loss: -1.931,Avg.Loss: -1.738,LR: 1.63E-04]Training epoch 13:  27%|██▋       | 92/341 [00:01<00:04, 51.75it/s, Epoch: 13, Batch: 93,Loss: -2.160,Avg.Loss: -1.742,LR: 1.63E-04]Training epoch 13:  27%|██▋       | 93/341 [00:01<00:04, 51.75it/s, Epoch: 13, Batch: 94,Loss: -1.457,Avg.Loss: -1.739,LR: 1.63E-04]Training epoch 13:  28%|██▊       | 94/341 [00:01<00:04, 51.75it/s, Epoch: 13, Batch: 95,Loss: -1.401,Avg.Loss: -1.735,LR: 1.62E-04]Training epoch 13:  28%|██▊       | 95/341 [00:01<00:04, 51.75it/s, Epoch: 13, Batch: 96,Loss: -1.832,Avg.Loss: -1.736,LR: 1.62E-04]Training epoch 13:  28%|██▊       | 96/341 [00:01<00:04, 52.61it/s, Epoch: 13, Batch: 96,Loss: -1.832,Avg.Loss: -1.736,LR: 1.62E-04]Training epoch 13:  28%|██▊       | 96/341 [00:01<00:04, 52.61it/s, Epoch: 13, Batch: 97,Loss: -1.750,Avg.Loss: -1.737,LR: 1.62E-04]Training epoch 13:  28%|██▊       | 97/341 [00:01<00:04, 52.61it/s, Epoch: 13, Batch: 98,Loss: -0.773,Avg.Loss: -1.727,LR: 1.62E-04]Training epoch 13:  29%|██▊       | 98/341 [00:01<00:04, 52.61it/s, Epoch: 13, Batch: 99,Loss: -1.160,Avg.Loss: -1.721,LR: 1.62E-04]Training epoch 13:  29%|██▉       | 99/341 [00:01<00:04, 52.61it/s, Epoch: 13, Batch: 100,Loss: -2.145,Avg.Loss: -1.725,LR: 1.62E-04]Training epoch 13:  29%|██▉       | 100/341 [00:01<00:04, 52.61it/s, Epoch: 13, Batch: 101,Loss: -1.777,Avg.Loss: -1.726,LR: 1.62E-04]Training epoch 13:  30%|██▉       | 101/341 [00:01<00:04, 52.61it/s, Epoch: 13, Batch: 102,Loss: -1.082,Avg.Loss: -1.719,LR: 1.62E-04]Training epoch 13:  30%|██▉       | 102/341 [00:01<00:04, 51.38it/s, Epoch: 13, Batch: 102,Loss: -1.082,Avg.Loss: -1.719,LR: 1.62E-04]Training epoch 13:  30%|██▉       | 102/341 [00:01<00:04, 51.38it/s, Epoch: 13, Batch: 103,Loss: -1.718,Avg.Loss: -1.719,LR: 1.62E-04]Training epoch 13:  30%|███       | 103/341 [00:01<00:04, 51.38it/s, Epoch: 13, Batch: 104,Loss: -2.317,Avg.Loss: -1.725,LR: 1.61E-04]Training epoch 13:  30%|███       | 104/341 [00:01<00:04, 51.38it/s, Epoch: 13, Batch: 105,Loss: -1.480,Avg.Loss: -1.723,LR: 1.61E-04]Training epoch 13:  31%|███       | 105/341 [00:01<00:04, 51.38it/s, Epoch: 13, Batch: 106,Loss: -1.455,Avg.Loss: -1.720,LR: 1.61E-04]Training epoch 13:  31%|███       | 106/341 [00:02<00:04, 51.38it/s, Epoch: 13, Batch: 107,Loss: -0.693,Avg.Loss: -1.711,LR: 1.61E-04]Training epoch 13:  31%|███▏      | 107/341 [00:02<00:04, 51.38it/s, Epoch: 13, Batch: 108,Loss: -2.286,Avg.Loss: -1.716,LR: 1.61E-04]Training epoch 13:  32%|███▏      | 108/341 [00:02<00:04, 52.57it/s, Epoch: 13, Batch: 108,Loss: -2.286,Avg.Loss: -1.716,LR: 1.61E-04]Training epoch 13:  32%|███▏      | 108/341 [00:02<00:04, 52.57it/s, Epoch: 13, Batch: 109,Loss: -1.203,Avg.Loss: -1.711,LR: 1.61E-04]Training epoch 13:  32%|███▏      | 109/341 [00:02<00:04, 52.57it/s, Epoch: 13, Batch: 110,Loss: -0.590,Avg.Loss: -1.701,LR: 1.61E-04]Training epoch 13:  32%|███▏      | 110/341 [00:02<00:04, 52.57it/s, Epoch: 13, Batch: 111,Loss: -0.668,Avg.Loss: -1.692,LR: 1.61E-04]Training epoch 13:  33%|███▎      | 111/341 [00:02<00:04, 52.57it/s, Epoch: 13, Batch: 112,Loss: -1.926,Avg.Loss: -1.694,LR: 1.61E-04]Training epoch 13:  33%|███▎      | 112/341 [00:02<00:04, 52.57it/s, Epoch: 13, Batch: 113,Loss: -1.803,Avg.Loss: -1.695,LR: 1.60E-04]Training epoch 13:  33%|███▎      | 113/341 [00:02<00:04, 52.57it/s, Epoch: 13, Batch: 114,Loss: -1.284,Avg.Loss: -1.691,LR: 1.60E-04]Training epoch 13:  33%|███▎      | 114/341 [00:02<00:04, 52.55it/s, Epoch: 13, Batch: 114,Loss: -1.284,Avg.Loss: -1.691,LR: 1.60E-04]Training epoch 13:  33%|███▎      | 114/341 [00:02<00:04, 52.55it/s, Epoch: 13, Batch: 115,Loss: -1.801,Avg.Loss: -1.692,LR: 1.60E-04]Training epoch 13:  34%|███▎      | 115/341 [00:02<00:04, 52.55it/s, Epoch: 13, Batch: 116,Loss: -2.376,Avg.Loss: -1.698,LR: 1.60E-04]Training epoch 13:  34%|███▍      | 116/341 [00:02<00:04, 52.55it/s, Epoch: 13, Batch: 117,Loss: -1.920,Avg.Loss: -1.700,LR: 1.60E-04]Training epoch 13:  34%|███▍      | 117/341 [00:02<00:04, 52.55it/s, Epoch: 13, Batch: 118,Loss: -1.523,Avg.Loss: -1.699,LR: 1.60E-04]Training epoch 13:  35%|███▍      | 118/341 [00:02<00:04, 52.55it/s, Epoch: 13, Batch: 119,Loss: -1.502,Avg.Loss: -1.697,LR: 1.60E-04]Training epoch 13:  35%|███▍      | 119/341 [00:02<00:04, 52.55it/s, Epoch: 13, Batch: 120,Loss: -1.820,Avg.Loss: -1.698,LR: 1.60E-04]Training epoch 13:  35%|███▌      | 120/341 [00:02<00:04, 53.33it/s, Epoch: 13, Batch: 120,Loss: -1.820,Avg.Loss: -1.698,LR: 1.60E-04]Training epoch 13:  35%|███▌      | 120/341 [00:02<00:04, 53.33it/s, Epoch: 13, Batch: 121,Loss: -2.406,Avg.Loss: -1.704,LR: 1.60E-04]Training epoch 13:  35%|███▌      | 121/341 [00:02<00:04, 53.33it/s, Epoch: 13, Batch: 122,Loss: -2.433,Avg.Loss: -1.710,LR: 1.60E-04]Training epoch 13:  36%|███▌      | 122/341 [00:02<00:04, 53.33it/s, Epoch: 13, Batch: 123,Loss: -2.397,Avg.Loss: -1.715,LR: 1.59E-04]Training epoch 13:  36%|███▌      | 123/341 [00:02<00:04, 53.33it/s, Epoch: 13, Batch: 124,Loss: -2.169,Avg.Loss: -1.719,LR: 1.59E-04]Training epoch 13:  36%|███▋      | 124/341 [00:02<00:04, 53.33it/s, Epoch: 13, Batch: 125,Loss: -2.162,Avg.Loss: -1.723,LR: 1.59E-04]Training epoch 13:  37%|███▋      | 125/341 [00:02<00:04, 53.33it/s, Epoch: 13, Batch: 126,Loss: -1.882,Avg.Loss: -1.724,LR: 1.59E-04]Training epoch 13:  37%|███▋      | 126/341 [00:02<00:03, 53.89it/s, Epoch: 13, Batch: 126,Loss: -1.882,Avg.Loss: -1.724,LR: 1.59E-04]Training epoch 13:  37%|███▋      | 126/341 [00:02<00:03, 53.89it/s, Epoch: 13, Batch: 127,Loss: -1.975,Avg.Loss: -1.726,LR: 1.59E-04]Training epoch 13:  37%|███▋      | 127/341 [00:02<00:03, 53.89it/s, Epoch: 13, Batch: 128,Loss: -2.029,Avg.Loss: -1.728,LR: 1.59E-04]Training epoch 13:  38%|███▊      | 128/341 [00:02<00:03, 53.89it/s, Epoch: 13, Batch: 129,Loss: -2.373,Avg.Loss: -1.733,LR: 1.59E-04]Training epoch 13:  38%|███▊      | 129/341 [00:02<00:03, 53.89it/s, Epoch: 13, Batch: 130,Loss: -2.320,Avg.Loss: -1.738,LR: 1.59E-04]Training epoch 13:  38%|███▊      | 130/341 [00:02<00:03, 53.89it/s, Epoch: 13, Batch: 131,Loss: -1.953,Avg.Loss: -1.739,LR: 1.59E-04]Training epoch 13:  38%|███▊      | 131/341 [00:02<00:03, 53.89it/s, Epoch: 13, Batch: 132,Loss: -1.287,Avg.Loss: -1.736,LR: 1.58E-04]Training epoch 13:  39%|███▊      | 132/341 [00:02<00:03, 54.08it/s, Epoch: 13, Batch: 132,Loss: -1.287,Avg.Loss: -1.736,LR: 1.58E-04]Training epoch 13:  39%|███▊      | 132/341 [00:02<00:03, 54.08it/s, Epoch: 13, Batch: 133,Loss: -1.867,Avg.Loss: -1.737,LR: 1.58E-04]Training epoch 13:  39%|███▉      | 133/341 [00:02<00:03, 54.08it/s, Epoch: 13, Batch: 134,Loss: -2.364,Avg.Loss: -1.742,LR: 1.58E-04]Training epoch 13:  39%|███▉      | 134/341 [00:02<00:03, 54.08it/s, Epoch: 13, Batch: 135,Loss: -1.995,Avg.Loss: -1.743,LR: 1.58E-04]Training epoch 13:  40%|███▉      | 135/341 [00:02<00:03, 54.08it/s, Epoch: 13, Batch: 136,Loss: -1.482,Avg.Loss: -1.742,LR: 1.58E-04]Training epoch 13:  40%|███▉      | 136/341 [00:02<00:03, 54.08it/s, Epoch: 13, Batch: 137,Loss: -1.626,Avg.Loss: -1.741,LR: 1.58E-04]Training epoch 13:  40%|████      | 137/341 [00:02<00:03, 54.08it/s, Epoch: 13, Batch: 138,Loss: -2.154,Avg.Loss: -1.744,LR: 1.58E-04]Training epoch 13:  40%|████      | 138/341 [00:02<00:03, 54.65it/s, Epoch: 13, Batch: 138,Loss: -2.154,Avg.Loss: -1.744,LR: 1.58E-04]Training epoch 13:  40%|████      | 138/341 [00:02<00:03, 54.65it/s, Epoch: 13, Batch: 139,Loss: -1.947,Avg.Loss: -1.745,LR: 1.58E-04]Training epoch 13:  41%|████      | 139/341 [00:02<00:03, 54.65it/s, Epoch: 13, Batch: 140,Loss: -2.552,Avg.Loss: -1.751,LR: 1.58E-04]Training epoch 13:  41%|████      | 140/341 [00:02<00:03, 54.65it/s, Epoch: 13, Batch: 141,Loss: -2.411,Avg.Loss: -1.756,LR: 1.57E-04]Training epoch 13:  41%|████▏     | 141/341 [00:02<00:03, 54.65it/s, Epoch: 13, Batch: 142,Loss: -2.079,Avg.Loss: -1.758,LR: 1.57E-04]Training epoch 13:  42%|████▏     | 142/341 [00:02<00:03, 54.65it/s, Epoch: 13, Batch: 143,Loss: -1.896,Avg.Loss: -1.759,LR: 1.57E-04]Training epoch 13:  42%|████▏     | 143/341 [00:02<00:03, 54.65it/s, Epoch: 13, Batch: 144,Loss: -2.191,Avg.Loss: -1.762,LR: 1.57E-04]Training epoch 13:  42%|████▏     | 144/341 [00:02<00:03, 54.36it/s, Epoch: 13, Batch: 144,Loss: -2.191,Avg.Loss: -1.762,LR: 1.57E-04]Training epoch 13:  42%|████▏     | 144/341 [00:02<00:03, 54.36it/s, Epoch: 13, Batch: 145,Loss: -1.875,Avg.Loss: -1.763,LR: 1.57E-04]Training epoch 13:  43%|████▎     | 145/341 [00:02<00:03, 54.36it/s, Epoch: 13, Batch: 146,Loss: -1.929,Avg.Loss: -1.764,LR: 1.57E-04]Training epoch 13:  43%|████▎     | 146/341 [00:02<00:03, 54.36it/s, Epoch: 13, Batch: 147,Loss: -2.299,Avg.Loss: -1.767,LR: 1.57E-04]Training epoch 13:  43%|████▎     | 147/341 [00:02<00:03, 54.36it/s, Epoch: 13, Batch: 148,Loss: -2.464,Avg.Loss: -1.772,LR: 1.57E-04]Training epoch 13:  43%|████▎     | 148/341 [00:02<00:03, 54.36it/s, Epoch: 13, Batch: 149,Loss: -1.651,Avg.Loss: -1.771,LR: 1.57E-04]Training epoch 13:  44%|████▎     | 149/341 [00:02<00:03, 54.36it/s, Epoch: 13, Batch: 150,Loss: -1.884,Avg.Loss: -1.772,LR: 1.57E-04]Training epoch 13:  44%|████▍     | 150/341 [00:02<00:03, 53.98it/s, Epoch: 13, Batch: 150,Loss: -1.884,Avg.Loss: -1.772,LR: 1.57E-04]Training epoch 13:  44%|████▍     | 150/341 [00:02<00:03, 53.98it/s, Epoch: 13, Batch: 151,Loss: -1.460,Avg.Loss: -1.770,LR: 1.56E-04]Training epoch 13:  44%|████▍     | 151/341 [00:02<00:03, 53.98it/s, Epoch: 13, Batch: 152,Loss: -0.428,Avg.Loss: -1.761,LR: 1.56E-04]Training epoch 13:  45%|████▍     | 152/341 [00:02<00:03, 53.98it/s, Epoch: 13, Batch: 153,Loss: -0.319,Avg.Loss: -1.752,LR: 1.56E-04]Training epoch 13:  45%|████▍     | 153/341 [00:02<00:03, 53.98it/s, Epoch: 13, Batch: 154,Loss: -1.315,Avg.Loss: -1.749,LR: 1.56E-04]Training epoch 13:  45%|████▌     | 154/341 [00:02<00:03, 53.98it/s, Epoch: 13, Batch: 155,Loss: -0.445,Avg.Loss: -1.740,LR: 1.56E-04]Training epoch 13:  45%|████▌     | 155/341 [00:02<00:03, 53.98it/s, Epoch: 13, Batch: 156,Loss: -0.636,Avg.Loss: -1.733,LR: 1.56E-04]Training epoch 13:  46%|████▌     | 156/341 [00:02<00:03, 53.79it/s, Epoch: 13, Batch: 156,Loss: -0.636,Avg.Loss: -1.733,LR: 1.56E-04]Training epoch 13:  46%|████▌     | 156/341 [00:02<00:03, 53.79it/s, Epoch: 13, Batch: 157,Loss: -0.977,Avg.Loss: -1.729,LR: 1.56E-04]Training epoch 13:  46%|████▌     | 157/341 [00:02<00:03, 53.79it/s, Epoch: 13, Batch: 158,Loss: -1.692,Avg.Loss: -1.728,LR: 1.56E-04]Training epoch 13:  46%|████▋     | 158/341 [00:02<00:03, 53.79it/s, Epoch: 13, Batch: 159,Loss: -0.908,Avg.Loss: -1.723,LR: 1.56E-04]Training epoch 13:  47%|████▋     | 159/341 [00:02<00:03, 53.79it/s, Epoch: 13, Batch: 160,Loss: 0.093,Avg.Loss: -1.712,LR: 1.55E-04] Training epoch 13:  47%|████▋     | 160/341 [00:03<00:03, 53.79it/s, Epoch: 13, Batch: 161,Loss: -0.367,Avg.Loss: -1.703,LR: 1.55E-04]Training epoch 13:  47%|████▋     | 161/341 [00:03<00:03, 53.79it/s, Epoch: 13, Batch: 162,Loss: -0.834,Avg.Loss: -1.698,LR: 1.55E-04]Training epoch 13:  48%|████▊     | 162/341 [00:03<00:03, 53.35it/s, Epoch: 13, Batch: 162,Loss: -0.834,Avg.Loss: -1.698,LR: 1.55E-04]Training epoch 13:  48%|████▊     | 162/341 [00:03<00:03, 53.35it/s, Epoch: 13, Batch: 163,Loss: -1.688,Avg.Loss: -1.698,LR: 1.55E-04]Training epoch 13:  48%|████▊     | 163/341 [00:03<00:03, 53.35it/s, Epoch: 13, Batch: 164,Loss: -0.956,Avg.Loss: -1.694,LR: 1.55E-04]Training epoch 13:  48%|████▊     | 164/341 [00:03<00:03, 53.35it/s, Epoch: 13, Batch: 165,Loss: 1.690,Avg.Loss: -1.673,LR: 1.55E-04] Training epoch 13:  48%|████▊     | 165/341 [00:03<00:03, 53.35it/s, Epoch: 13, Batch: 166,Loss: 1.992,Avg.Loss: -1.651,LR: 1.55E-04]Training epoch 13:  49%|████▊     | 166/341 [00:03<00:03, 53.35it/s, Epoch: 13, Batch: 167,Loss: 0.548,Avg.Loss: -1.638,LR: 1.55E-04]Training epoch 13:  49%|████▉     | 167/341 [00:03<00:03, 53.35it/s, Epoch: 13, Batch: 168,Loss: -1.484,Avg.Loss: -1.637,LR: 1.55E-04]Training epoch 13:  49%|████▉     | 168/341 [00:03<00:03, 54.00it/s, Epoch: 13, Batch: 168,Loss: -1.484,Avg.Loss: -1.637,LR: 1.55E-04]Training epoch 13:  49%|████▉     | 168/341 [00:03<00:03, 54.00it/s, Epoch: 13, Batch: 169,Loss: -1.401,Avg.Loss: -1.635,LR: 1.54E-04]Training epoch 13:  50%|████▉     | 169/341 [00:03<00:03, 54.00it/s, Epoch: 13, Batch: 170,Loss: -0.866,Avg.Loss: -1.631,LR: 1.54E-04]Training epoch 13:  50%|████▉     | 170/341 [00:03<00:03, 54.00it/s, Epoch: 13, Batch: 171,Loss: -0.511,Avg.Loss: -1.624,LR: 1.54E-04]Training epoch 13:  50%|█████     | 171/341 [00:03<00:03, 54.00it/s, Epoch: 13, Batch: 172,Loss: -1.277,Avg.Loss: -1.622,LR: 1.54E-04]Training epoch 13:  50%|█████     | 172/341 [00:03<00:03, 54.00it/s, Epoch: 13, Batch: 173,Loss: -2.083,Avg.Loss: -1.625,LR: 1.54E-04]Training epoch 13:  51%|█████     | 173/341 [00:03<00:03, 54.00it/s, Epoch: 13, Batch: 174,Loss: -1.489,Avg.Loss: -1.624,LR: 1.54E-04]Training epoch 13:  51%|█████     | 174/341 [00:03<00:03, 54.53it/s, Epoch: 13, Batch: 174,Loss: -1.489,Avg.Loss: -1.624,LR: 1.54E-04]Training epoch 13:  51%|█████     | 174/341 [00:03<00:03, 54.53it/s, Epoch: 13, Batch: 175,Loss: -0.574,Avg.Loss: -1.618,LR: 1.54E-04]Training epoch 13:  51%|█████▏    | 175/341 [00:03<00:03, 54.53it/s, Epoch: 13, Batch: 176,Loss: -0.838,Avg.Loss: -1.614,LR: 1.54E-04]Training epoch 13:  52%|█████▏    | 176/341 [00:03<00:03, 54.53it/s, Epoch: 13, Batch: 177,Loss: -0.794,Avg.Loss: -1.609,LR: 1.54E-04]Training epoch 13:  52%|█████▏    | 177/341 [00:03<00:03, 54.53it/s, Epoch: 13, Batch: 178,Loss: -2.197,Avg.Loss: -1.612,LR: 1.54E-04]Training epoch 13:  52%|█████▏    | 178/341 [00:03<00:02, 54.53it/s, Epoch: 13, Batch: 179,Loss: -1.498,Avg.Loss: -1.612,LR: 1.53E-04]Training epoch 13:  52%|█████▏    | 179/341 [00:03<00:02, 54.53it/s, Epoch: 13, Batch: 180,Loss: -0.239,Avg.Loss: -1.604,LR: 1.53E-04]Training epoch 13:  53%|█████▎    | 180/341 [00:03<00:02, 54.95it/s, Epoch: 13, Batch: 180,Loss: -0.239,Avg.Loss: -1.604,LR: 1.53E-04]Training epoch 13:  53%|█████▎    | 180/341 [00:03<00:02, 54.95it/s, Epoch: 13, Batch: 181,Loss: -0.496,Avg.Loss: -1.598,LR: 1.53E-04]Training epoch 13:  53%|█████▎    | 181/341 [00:03<00:02, 54.95it/s, Epoch: 13, Batch: 182,Loss: -1.004,Avg.Loss: -1.595,LR: 1.53E-04]Training epoch 13:  53%|█████▎    | 182/341 [00:03<00:02, 54.95it/s, Epoch: 13, Batch: 183,Loss: -2.007,Avg.Loss: -1.597,LR: 1.53E-04]Training epoch 13:  54%|█████▎    | 183/341 [00:03<00:02, 54.95it/s, Epoch: 13, Batch: 184,Loss: -1.465,Avg.Loss: -1.596,LR: 1.53E-04]Training epoch 13:  54%|█████▍    | 184/341 [00:03<00:02, 54.95it/s, Epoch: 13, Batch: 185,Loss: 0.362,Avg.Loss: -1.586,LR: 1.53E-04] Training epoch 13:  54%|█████▍    | 185/341 [00:03<00:02, 54.95it/s, Epoch: 13, Batch: 186,Loss: 0.048,Avg.Loss: -1.577,LR: 1.53E-04]Training epoch 13:  55%|█████▍    | 186/341 [00:03<00:02, 54.98it/s, Epoch: 13, Batch: 186,Loss: 0.048,Avg.Loss: -1.577,LR: 1.53E-04]Training epoch 13:  55%|█████▍    | 186/341 [00:03<00:02, 54.98it/s, Epoch: 13, Batch: 187,Loss: -1.013,Avg.Loss: -1.574,LR: 1.53E-04]Training epoch 13:  55%|█████▍    | 187/341 [00:03<00:02, 54.98it/s, Epoch: 13, Batch: 188,Loss: -1.884,Avg.Loss: -1.576,LR: 1.52E-04]Training epoch 13:  55%|█████▌    | 188/341 [00:03<00:02, 54.98it/s, Epoch: 13, Batch: 189,Loss: -1.790,Avg.Loss: -1.577,LR: 1.52E-04]Training epoch 13:  55%|█████▌    | 189/341 [00:03<00:02, 54.98it/s, Epoch: 13, Batch: 190,Loss: -1.065,Avg.Loss: -1.574,LR: 1.52E-04]Training epoch 13:  56%|█████▌    | 190/341 [00:03<00:02, 54.98it/s, Epoch: 13, Batch: 191,Loss: -0.338,Avg.Loss: -1.568,LR: 1.52E-04]Training epoch 13:  56%|█████▌    | 191/341 [00:03<00:02, 54.98it/s, Epoch: 13, Batch: 192,Loss: -0.724,Avg.Loss: -1.563,LR: 1.52E-04]Training epoch 13:  56%|█████▋    | 192/341 [00:03<00:02, 55.25it/s, Epoch: 13, Batch: 192,Loss: -0.724,Avg.Loss: -1.563,LR: 1.52E-04]Training epoch 13:  56%|█████▋    | 192/341 [00:03<00:02, 55.25it/s, Epoch: 13, Batch: 193,Loss: -1.992,Avg.Loss: -1.565,LR: 1.52E-04]Training epoch 13:  57%|█████▋    | 193/341 [00:03<00:02, 55.25it/s, Epoch: 13, Batch: 194,Loss: -1.564,Avg.Loss: -1.565,LR: 1.52E-04]Training epoch 13:  57%|█████▋    | 194/341 [00:03<00:02, 55.25it/s, Epoch: 13, Batch: 195,Loss: -0.325,Avg.Loss: -1.559,LR: 1.52E-04]Training epoch 13:  57%|█████▋    | 195/341 [00:03<00:02, 55.25it/s, Epoch: 13, Batch: 196,Loss: -0.959,Avg.Loss: -1.556,LR: 1.52E-04]Training epoch 13:  57%|█████▋    | 196/341 [00:03<00:02, 55.25it/s, Epoch: 13, Batch: 197,Loss: -1.637,Avg.Loss: -1.556,LR: 1.52E-04]Training epoch 13:  58%|█████▊    | 197/341 [00:03<00:02, 55.25it/s, Epoch: 13, Batch: 198,Loss: -2.438,Avg.Loss: -1.561,LR: 1.51E-04]Training epoch 13:  58%|█████▊    | 198/341 [00:03<00:02, 54.78it/s, Epoch: 13, Batch: 198,Loss: -2.438,Avg.Loss: -1.561,LR: 1.51E-04]Training epoch 13:  58%|█████▊    | 198/341 [00:03<00:02, 54.78it/s, Epoch: 13, Batch: 199,Loss: -1.426,Avg.Loss: -1.560,LR: 1.51E-04]Training epoch 13:  58%|█████▊    | 199/341 [00:03<00:02, 54.78it/s, Epoch: 13, Batch: 200,Loss: -0.352,Avg.Loss: -1.554,LR: 1.51E-04]Training epoch 13:  59%|█████▊    | 200/341 [00:03<00:02, 54.78it/s, Epoch: 13, Batch: 201,Loss: -0.231,Avg.Loss: -1.548,LR: 1.51E-04]Training epoch 13:  59%|█████▉    | 201/341 [00:03<00:02, 54.78it/s, Epoch: 13, Batch: 202,Loss: -0.874,Avg.Loss: -1.544,LR: 1.51E-04]Training epoch 13:  59%|█████▉    | 202/341 [00:03<00:02, 54.78it/s, Epoch: 13, Batch: 203,Loss: -2.107,Avg.Loss: -1.547,LR: 1.51E-04]Training epoch 13:  60%|█████▉    | 203/341 [00:03<00:02, 54.78it/s, Epoch: 13, Batch: 204,Loss: -1.929,Avg.Loss: -1.549,LR: 1.51E-04]Training epoch 13:  60%|█████▉    | 204/341 [00:03<00:02, 53.59it/s, Epoch: 13, Batch: 204,Loss: -1.929,Avg.Loss: -1.549,LR: 1.51E-04]Training epoch 13:  60%|█████▉    | 204/341 [00:03<00:02, 53.59it/s, Epoch: 13, Batch: 205,Loss: -0.438,Avg.Loss: -1.543,LR: 1.51E-04]Training epoch 13:  60%|██████    | 205/341 [00:03<00:02, 53.59it/s, Epoch: 13, Batch: 206,Loss: -0.939,Avg.Loss: -1.540,LR: 1.51E-04]Training epoch 13:  60%|██████    | 206/341 [00:03<00:02, 53.59it/s, Epoch: 13, Batch: 207,Loss: -1.081,Avg.Loss: -1.538,LR: 1.50E-04]Training epoch 13:  61%|██████    | 207/341 [00:03<00:02, 53.59it/s, Epoch: 13, Batch: 208,Loss: -2.398,Avg.Loss: -1.542,LR: 1.50E-04]Training epoch 13:  61%|██████    | 208/341 [00:03<00:02, 53.59it/s, Epoch: 13, Batch: 209,Loss: -1.678,Avg.Loss: -1.543,LR: 1.50E-04]Training epoch 13:  61%|██████▏   | 209/341 [00:03<00:02, 53.59it/s, Epoch: 13, Batch: 210,Loss: -0.297,Avg.Loss: -1.537,LR: 1.50E-04]Training epoch 13:  62%|██████▏   | 210/341 [00:03<00:02, 53.63it/s, Epoch: 13, Batch: 210,Loss: -0.297,Avg.Loss: -1.537,LR: 1.50E-04]Training epoch 13:  62%|██████▏   | 210/341 [00:03<00:02, 53.63it/s, Epoch: 13, Batch: 211,Loss: -0.132,Avg.Loss: -1.530,LR: 1.50E-04]Training epoch 13:  62%|██████▏   | 211/341 [00:03<00:02, 53.63it/s, Epoch: 13, Batch: 212,Loss: -1.323,Avg.Loss: -1.529,LR: 1.50E-04]Training epoch 13:  62%|██████▏   | 212/341 [00:03<00:02, 53.63it/s, Epoch: 13, Batch: 213,Loss: -1.997,Avg.Loss: -1.532,LR: 1.50E-04]Training epoch 13:  62%|██████▏   | 213/341 [00:03<00:02, 53.63it/s, Epoch: 13, Batch: 214,Loss: -1.629,Avg.Loss: -1.532,LR: 1.50E-04]Training epoch 13:  63%|██████▎   | 214/341 [00:04<00:02, 53.63it/s, Epoch: 13, Batch: 215,Loss: -0.735,Avg.Loss: -1.528,LR: 1.50E-04]Training epoch 13:  63%|██████▎   | 215/341 [00:04<00:02, 53.63it/s, Epoch: 13, Batch: 216,Loss: -0.580,Avg.Loss: -1.524,LR: 1.50E-04]Training epoch 13:  63%|██████▎   | 216/341 [00:04<00:02, 53.32it/s, Epoch: 13, Batch: 216,Loss: -0.580,Avg.Loss: -1.524,LR: 1.50E-04]Training epoch 13:  63%|██████▎   | 216/341 [00:04<00:02, 53.32it/s, Epoch: 13, Batch: 217,Loss: -1.005,Avg.Loss: -1.522,LR: 1.49E-04]Training epoch 13:  64%|██████▎   | 217/341 [00:04<00:02, 53.32it/s, Epoch: 13, Batch: 218,Loss: -2.038,Avg.Loss: -1.524,LR: 1.49E-04]Training epoch 13:  64%|██████▍   | 218/341 [00:04<00:02, 53.32it/s, Epoch: 13, Batch: 219,Loss: -1.758,Avg.Loss: -1.525,LR: 1.49E-04]Training epoch 13:  64%|██████▍   | 219/341 [00:04<00:02, 53.32it/s, Epoch: 13, Batch: 220,Loss: -0.681,Avg.Loss: -1.521,LR: 1.49E-04]Training epoch 13:  65%|██████▍   | 220/341 [00:04<00:02, 53.32it/s, Epoch: 13, Batch: 221,Loss: -0.932,Avg.Loss: -1.519,LR: 1.49E-04]Training epoch 13:  65%|██████▍   | 221/341 [00:04<00:02, 53.32it/s, Epoch: 13, Batch: 222,Loss: -1.185,Avg.Loss: -1.517,LR: 1.49E-04]Training epoch 13:  65%|██████▌   | 222/341 [00:04<00:02, 54.23it/s, Epoch: 13, Batch: 222,Loss: -1.185,Avg.Loss: -1.517,LR: 1.49E-04]Training epoch 13:  65%|██████▌   | 222/341 [00:04<00:02, 54.23it/s, Epoch: 13, Batch: 223,Loss: -2.177,Avg.Loss: -1.520,LR: 1.49E-04]Training epoch 13:  65%|██████▌   | 223/341 [00:04<00:02, 54.23it/s, Epoch: 13, Batch: 224,Loss: -1.411,Avg.Loss: -1.520,LR: 1.49E-04]Training epoch 13:  66%|██████▌   | 224/341 [00:04<00:02, 54.23it/s, Epoch: 13, Batch: 225,Loss: -0.618,Avg.Loss: -1.516,LR: 1.49E-04]Training epoch 13:  66%|██████▌   | 225/341 [00:04<00:02, 54.23it/s, Epoch: 13, Batch: 226,Loss: -0.820,Avg.Loss: -1.512,LR: 1.48E-04]Training epoch 13:  66%|██████▋   | 226/341 [00:04<00:02, 54.23it/s, Epoch: 13, Batch: 227,Loss: -1.320,Avg.Loss: -1.512,LR: 1.48E-04]Training epoch 13:  67%|██████▋   | 227/341 [00:04<00:02, 54.23it/s, Epoch: 13, Batch: 228,Loss: -1.975,Avg.Loss: -1.514,LR: 1.48E-04]Training epoch 13:  67%|██████▋   | 228/341 [00:04<00:02, 54.03it/s, Epoch: 13, Batch: 228,Loss: -1.975,Avg.Loss: -1.514,LR: 1.48E-04]Training epoch 13:  67%|██████▋   | 228/341 [00:04<00:02, 54.03it/s, Epoch: 13, Batch: 229,Loss: -1.516,Avg.Loss: -1.514,LR: 1.48E-04]Training epoch 13:  67%|██████▋   | 229/341 [00:04<00:02, 54.03it/s, Epoch: 13, Batch: 230,Loss: -0.674,Avg.Loss: -1.510,LR: 1.48E-04]Training epoch 13:  67%|██████▋   | 230/341 [00:04<00:02, 54.03it/s, Epoch: 13, Batch: 231,Loss: -0.565,Avg.Loss: -1.506,LR: 1.48E-04]Training epoch 13:  68%|██████▊   | 231/341 [00:04<00:02, 54.03it/s, Epoch: 13, Batch: 232,Loss: -0.776,Avg.Loss: -1.503,LR: 1.48E-04]Training epoch 13:  68%|██████▊   | 232/341 [00:04<00:02, 54.03it/s, Epoch: 13, Batch: 233,Loss: -2.154,Avg.Loss: -1.506,LR: 1.48E-04]Training epoch 13:  68%|██████▊   | 233/341 [00:04<00:01, 54.03it/s, Epoch: 13, Batch: 234,Loss: -1.559,Avg.Loss: -1.506,LR: 1.48E-04]Training epoch 13:  69%|██████▊   | 234/341 [00:04<00:01, 54.69it/s, Epoch: 13, Batch: 234,Loss: -1.559,Avg.Loss: -1.506,LR: 1.48E-04]Training epoch 13:  69%|██████▊   | 234/341 [00:04<00:01, 54.69it/s, Epoch: 13, Batch: 235,Loss: -0.969,Avg.Loss: -1.504,LR: 1.48E-04]Training epoch 13:  69%|██████▉   | 235/341 [00:04<00:01, 54.69it/s, Epoch: 13, Batch: 236,Loss: -1.013,Avg.Loss: -1.501,LR: 1.47E-04]Training epoch 13:  69%|██████▉   | 236/341 [00:04<00:01, 54.69it/s, Epoch: 13, Batch: 237,Loss: -1.524,Avg.Loss: -1.502,LR: 1.47E-04]Training epoch 13:  70%|██████▉   | 237/341 [00:04<00:01, 54.69it/s, Epoch: 13, Batch: 238,Loss: -2.228,Avg.Loss: -1.505,LR: 1.47E-04]Training epoch 13:  70%|██████▉   | 238/341 [00:04<00:01, 54.69it/s, Epoch: 13, Batch: 239,Loss: -1.584,Avg.Loss: -1.505,LR: 1.47E-04]Training epoch 13:  70%|███████   | 239/341 [00:04<00:01, 54.69it/s, Epoch: 13, Batch: 240,Loss: -0.737,Avg.Loss: -1.502,LR: 1.47E-04]Training epoch 13:  70%|███████   | 240/341 [00:04<00:01, 54.14it/s, Epoch: 13, Batch: 240,Loss: -0.737,Avg.Loss: -1.502,LR: 1.47E-04]Training epoch 13:  70%|███████   | 240/341 [00:04<00:01, 54.14it/s, Epoch: 13, Batch: 241,Loss: -0.803,Avg.Loss: -1.499,LR: 1.47E-04]Training epoch 13:  71%|███████   | 241/341 [00:04<00:01, 54.14it/s, Epoch: 13, Batch: 242,Loss: -1.286,Avg.Loss: -1.498,LR: 1.47E-04]Training epoch 13:  71%|███████   | 242/341 [00:04<00:01, 54.14it/s, Epoch: 13, Batch: 243,Loss: -1.876,Avg.Loss: -1.500,LR: 1.47E-04]Training epoch 13:  71%|███████▏  | 243/341 [00:04<00:01, 54.14it/s, Epoch: 13, Batch: 244,Loss: -1.569,Avg.Loss: -1.500,LR: 1.47E-04]Training epoch 13:  72%|███████▏  | 244/341 [00:04<00:01, 54.14it/s, Epoch: 13, Batch: 245,Loss: -0.481,Avg.Loss: -1.496,LR: 1.46E-04]Training epoch 13:  72%|███████▏  | 245/341 [00:04<00:01, 54.14it/s, Epoch: 13, Batch: 246,Loss: -0.391,Avg.Loss: -1.491,LR: 1.46E-04]Training epoch 13:  72%|███████▏  | 246/341 [00:04<00:01, 53.71it/s, Epoch: 13, Batch: 246,Loss: -0.391,Avg.Loss: -1.491,LR: 1.46E-04]Training epoch 13:  72%|███████▏  | 246/341 [00:04<00:01, 53.71it/s, Epoch: 13, Batch: 247,Loss: -1.343,Avg.Loss: -1.491,LR: 1.46E-04]Training epoch 13:  72%|███████▏  | 247/341 [00:04<00:01, 53.71it/s, Epoch: 13, Batch: 248,Loss: -1.845,Avg.Loss: -1.492,LR: 1.46E-04]Training epoch 13:  73%|███████▎  | 248/341 [00:04<00:01, 53.71it/s, Epoch: 13, Batch: 249,Loss: -1.823,Avg.Loss: -1.493,LR: 1.46E-04]Training epoch 13:  73%|███████▎  | 249/341 [00:04<00:01, 53.71it/s, Epoch: 13, Batch: 250,Loss: -1.458,Avg.Loss: -1.493,LR: 1.46E-04]Training epoch 13:  73%|███████▎  | 250/341 [00:04<00:01, 53.71it/s, Epoch: 13, Batch: 251,Loss: -1.311,Avg.Loss: -1.492,LR: 1.46E-04]Training epoch 13:  74%|███████▎  | 251/341 [00:04<00:01, 53.71it/s, Epoch: 13, Batch: 252,Loss: -1.605,Avg.Loss: -1.493,LR: 1.46E-04]Training epoch 13:  74%|███████▍  | 252/341 [00:04<00:01, 53.28it/s, Epoch: 13, Batch: 252,Loss: -1.605,Avg.Loss: -1.493,LR: 1.46E-04]Training epoch 13:  74%|███████▍  | 252/341 [00:04<00:01, 53.28it/s, Epoch: 13, Batch: 253,Loss: -2.410,Avg.Loss: -1.497,LR: 1.46E-04]Training epoch 13:  74%|███████▍  | 253/341 [00:04<00:01, 53.28it/s, Epoch: 13, Batch: 254,Loss: -1.280,Avg.Loss: -1.496,LR: 1.46E-04]Training epoch 13:  74%|███████▍  | 254/341 [00:04<00:01, 53.28it/s, Epoch: 13, Batch: 255,Loss: -0.415,Avg.Loss: -1.491,LR: 1.45E-04]Training epoch 13:  75%|███████▍  | 255/341 [00:04<00:01, 53.28it/s, Epoch: 13, Batch: 256,Loss: -0.708,Avg.Loss: -1.488,LR: 1.45E-04]Training epoch 13:  75%|███████▌  | 256/341 [00:04<00:01, 53.28it/s, Epoch: 13, Batch: 257,Loss: -1.097,Avg.Loss: -1.487,LR: 1.45E-04]Training epoch 13:  75%|███████▌  | 257/341 [00:04<00:01, 53.28it/s, Epoch: 13, Batch: 258,Loss: -2.149,Avg.Loss: -1.489,LR: 1.45E-04]Training epoch 13:  76%|███████▌  | 258/341 [00:04<00:01, 53.90it/s, Epoch: 13, Batch: 258,Loss: -2.149,Avg.Loss: -1.489,LR: 1.45E-04]Training epoch 13:  76%|███████▌  | 258/341 [00:04<00:01, 53.90it/s, Epoch: 13, Batch: 259,Loss: -1.938,Avg.Loss: -1.491,LR: 1.45E-04]Training epoch 13:  76%|███████▌  | 259/341 [00:04<00:01, 53.90it/s, Epoch: 13, Batch: 260,Loss: -0.572,Avg.Loss: -1.488,LR: 1.45E-04]Training epoch 13:  76%|███████▌  | 260/341 [00:04<00:01, 53.90it/s, Epoch: 13, Batch: 261,Loss: -0.797,Avg.Loss: -1.485,LR: 1.45E-04]Training epoch 13:  77%|███████▋  | 261/341 [00:04<00:01, 53.90it/s, Epoch: 13, Batch: 262,Loss: -1.412,Avg.Loss: -1.485,LR: 1.45E-04]Training epoch 13:  77%|███████▋  | 262/341 [00:04<00:01, 53.90it/s, Epoch: 13, Batch: 263,Loss: -2.350,Avg.Loss: -1.488,LR: 1.45E-04]Training epoch 13:  77%|███████▋  | 263/341 [00:04<00:01, 53.90it/s, Epoch: 13, Batch: 264,Loss: -1.799,Avg.Loss: -1.489,LR: 1.44E-04]Training epoch 13:  77%|███████▋  | 264/341 [00:04<00:01, 53.58it/s, Epoch: 13, Batch: 264,Loss: -1.799,Avg.Loss: -1.489,LR: 1.44E-04]Training epoch 13:  77%|███████▋  | 264/341 [00:04<00:01, 53.58it/s, Epoch: 13, Batch: 265,Loss: -0.876,Avg.Loss: -1.487,LR: 1.44E-04]Training epoch 13:  78%|███████▊  | 265/341 [00:04<00:01, 53.58it/s, Epoch: 13, Batch: 266,Loss: -0.822,Avg.Loss: -1.484,LR: 1.44E-04]Training epoch 13:  78%|███████▊  | 266/341 [00:04<00:01, 53.58it/s, Epoch: 13, Batch: 267,Loss: -1.211,Avg.Loss: -1.483,LR: 1.44E-04]Training epoch 13:  78%|███████▊  | 267/341 [00:04<00:01, 53.58it/s, Epoch: 13, Batch: 268,Loss: -1.965,Avg.Loss: -1.485,LR: 1.44E-04]Training epoch 13:  79%|███████▊  | 268/341 [00:05<00:01, 53.58it/s, Epoch: 13, Batch: 269,Loss: -2.007,Avg.Loss: -1.487,LR: 1.44E-04]Training epoch 13:  79%|███████▉  | 269/341 [00:05<00:01, 53.58it/s, Epoch: 13, Batch: 270,Loss: -0.807,Avg.Loss: -1.485,LR: 1.44E-04]Training epoch 13:  79%|███████▉  | 270/341 [00:05<00:01, 53.17it/s, Epoch: 13, Batch: 270,Loss: -0.807,Avg.Loss: -1.485,LR: 1.44E-04]Training epoch 13:  79%|███████▉  | 270/341 [00:05<00:01, 53.17it/s, Epoch: 13, Batch: 271,Loss: -0.695,Avg.Loss: -1.482,LR: 1.44E-04]Training epoch 13:  79%|███████▉  | 271/341 [00:05<00:01, 53.17it/s, Epoch: 13, Batch: 272,Loss: -1.701,Avg.Loss: -1.482,LR: 1.44E-04]Training epoch 13:  80%|███████▉  | 272/341 [00:05<00:01, 53.17it/s, Epoch: 13, Batch: 273,Loss: -2.093,Avg.Loss: -1.485,LR: 1.44E-04]Training epoch 13:  80%|████████  | 273/341 [00:05<00:01, 53.17it/s, Epoch: 13, Batch: 274,Loss: -1.754,Avg.Loss: -1.486,LR: 1.43E-04]Training epoch 13:  80%|████████  | 274/341 [00:05<00:01, 53.17it/s, Epoch: 13, Batch: 275,Loss: -0.839,Avg.Loss: -1.483,LR: 1.43E-04]Training epoch 13:  81%|████████  | 275/341 [00:05<00:01, 53.17it/s, Epoch: 13, Batch: 276,Loss: -1.022,Avg.Loss: -1.482,LR: 1.43E-04]Training epoch 13:  81%|████████  | 276/341 [00:05<00:01, 52.63it/s, Epoch: 13, Batch: 276,Loss: -1.022,Avg.Loss: -1.482,LR: 1.43E-04]Training epoch 13:  81%|████████  | 276/341 [00:05<00:01, 52.63it/s, Epoch: 13, Batch: 277,Loss: -1.608,Avg.Loss: -1.482,LR: 1.43E-04]Training epoch 13:  81%|████████  | 277/341 [00:05<00:01, 52.63it/s, Epoch: 13, Batch: 278,Loss: -1.988,Avg.Loss: -1.484,LR: 1.43E-04]Training epoch 13:  82%|████████▏ | 278/341 [00:05<00:01, 52.63it/s, Epoch: 13, Batch: 279,Loss: -1.871,Avg.Loss: -1.485,LR: 1.43E-04]Training epoch 13:  82%|████████▏ | 279/341 [00:05<00:01, 52.63it/s, Epoch: 13, Batch: 280,Loss: -0.659,Avg.Loss: -1.482,LR: 1.43E-04]Training epoch 13:  82%|████████▏ | 280/341 [00:05<00:01, 52.63it/s, Epoch: 13, Batch: 281,Loss: -0.920,Avg.Loss: -1.480,LR: 1.43E-04]Training epoch 13:  82%|████████▏ | 281/341 [00:05<00:01, 52.63it/s, Epoch: 13, Batch: 282,Loss: -1.526,Avg.Loss: -1.480,LR: 1.43E-04]Training epoch 13:  83%|████████▎ | 282/341 [00:05<00:01, 52.51it/s, Epoch: 13, Batch: 282,Loss: -1.526,Avg.Loss: -1.480,LR: 1.43E-04]Training epoch 13:  83%|████████▎ | 282/341 [00:05<00:01, 52.51it/s, Epoch: 13, Batch: 283,Loss: -2.355,Avg.Loss: -1.484,LR: 1.42E-04]Training epoch 13:  83%|████████▎ | 283/341 [00:05<00:01, 52.51it/s, Epoch: 13, Batch: 284,Loss: -1.746,Avg.Loss: -1.485,LR: 1.42E-04]Training epoch 13:  83%|████████▎ | 284/341 [00:05<00:01, 52.51it/s, Epoch: 13, Batch: 285,Loss: -0.652,Avg.Loss: -1.482,LR: 1.42E-04]Training epoch 13:  84%|████████▎ | 285/341 [00:05<00:01, 52.51it/s, Epoch: 13, Batch: 286,Loss: -0.930,Avg.Loss: -1.480,LR: 1.42E-04]Training epoch 13:  84%|████████▍ | 286/341 [00:05<00:01, 52.51it/s, Epoch: 13, Batch: 287,Loss: -1.228,Avg.Loss: -1.479,LR: 1.42E-04]Training epoch 13:  84%|████████▍ | 287/341 [00:05<00:01, 52.51it/s, Epoch: 13, Batch: 288,Loss: -1.893,Avg.Loss: -1.480,LR: 1.42E-04]Training epoch 13:  84%|████████▍ | 288/341 [00:05<00:01, 52.53it/s, Epoch: 13, Batch: 288,Loss: -1.893,Avg.Loss: -1.480,LR: 1.42E-04]Training epoch 13:  84%|████████▍ | 288/341 [00:05<00:01, 52.53it/s, Epoch: 13, Batch: 289,Loss: -1.831,Avg.Loss: -1.481,LR: 1.42E-04]Training epoch 13:  85%|████████▍ | 289/341 [00:05<00:00, 52.53it/s, Epoch: 13, Batch: 290,Loss: -1.608,Avg.Loss: -1.482,LR: 1.42E-04]Training epoch 13:  85%|████████▌ | 290/341 [00:05<00:00, 52.53it/s, Epoch: 13, Batch: 291,Loss: -1.192,Avg.Loss: -1.481,LR: 1.42E-04]Training epoch 13:  85%|████████▌ | 291/341 [00:05<00:00, 52.53it/s, Epoch: 13, Batch: 292,Loss: -1.999,Avg.Loss: -1.483,LR: 1.42E-04]Training epoch 13:  86%|████████▌ | 292/341 [00:05<00:00, 52.53it/s, Epoch: 13, Batch: 293,Loss: -2.358,Avg.Loss: -1.486,LR: 1.41E-04]Training epoch 13:  86%|████████▌ | 293/341 [00:05<00:00, 52.53it/s, Epoch: 13, Batch: 294,Loss: -1.688,Avg.Loss: -1.486,LR: 1.41E-04]Training epoch 13:  86%|████████▌ | 294/341 [00:05<00:00, 53.00it/s, Epoch: 13, Batch: 294,Loss: -1.688,Avg.Loss: -1.486,LR: 1.41E-04]Training epoch 13:  86%|████████▌ | 294/341 [00:05<00:00, 53.00it/s, Epoch: 13, Batch: 295,Loss: -1.013,Avg.Loss: -1.485,LR: 1.41E-04]Training epoch 13:  87%|████████▋ | 295/341 [00:05<00:00, 53.00it/s, Epoch: 13, Batch: 296,Loss: -0.807,Avg.Loss: -1.482,LR: 1.41E-04]Training epoch 13:  87%|████████▋ | 296/341 [00:05<00:00, 53.00it/s, Epoch: 13, Batch: 297,Loss: -1.731,Avg.Loss: -1.483,LR: 1.41E-04]Training epoch 13:  87%|████████▋ | 297/341 [00:05<00:00, 53.00it/s, Epoch: 13, Batch: 298,Loss: -2.032,Avg.Loss: -1.485,LR: 1.41E-04]Training epoch 13:  87%|████████▋ | 298/341 [00:05<00:00, 53.00it/s, Epoch: 13, Batch: 299,Loss: -2.080,Avg.Loss: -1.487,LR: 1.41E-04]Training epoch 13:  88%|████████▊ | 299/341 [00:05<00:00, 53.00it/s, Epoch: 13, Batch: 300,Loss: -1.844,Avg.Loss: -1.488,LR: 1.41E-04]Training epoch 13:  88%|████████▊ | 300/341 [00:05<00:00, 53.24it/s, Epoch: 13, Batch: 300,Loss: -1.844,Avg.Loss: -1.488,LR: 1.41E-04]Training epoch 13:  88%|████████▊ | 300/341 [00:05<00:00, 53.24it/s, Epoch: 13, Batch: 301,Loss: -2.229,Avg.Loss: -1.491,LR: 1.41E-04]Training epoch 13:  88%|████████▊ | 301/341 [00:05<00:00, 53.24it/s, Epoch: 13, Batch: 302,Loss: -2.075,Avg.Loss: -1.493,LR: 1.41E-04]Training epoch 13:  89%|████████▊ | 302/341 [00:05<00:00, 53.24it/s, Epoch: 13, Batch: 303,Loss: -1.762,Avg.Loss: -1.494,LR: 1.40E-04]Training epoch 13:  89%|████████▉ | 303/341 [00:05<00:00, 53.24it/s, Epoch: 13, Batch: 304,Loss: -1.781,Avg.Loss: -1.495,LR: 1.40E-04]Training epoch 13:  89%|████████▉ | 304/341 [00:05<00:00, 53.24it/s, Epoch: 13, Batch: 305,Loss: -2.457,Avg.Loss: -1.498,LR: 1.40E-04]Training epoch 13:  89%|████████▉ | 305/341 [00:05<00:00, 53.24it/s, Epoch: 13, Batch: 306,Loss: -2.190,Avg.Loss: -1.500,LR: 1.40E-04]Training epoch 13:  90%|████████▉ | 306/341 [00:05<00:00, 53.11it/s, Epoch: 13, Batch: 306,Loss: -2.190,Avg.Loss: -1.500,LR: 1.40E-04]Training epoch 13:  90%|████████▉ | 306/341 [00:05<00:00, 53.11it/s, Epoch: 13, Batch: 307,Loss: -2.185,Avg.Loss: -1.502,LR: 1.40E-04]Training epoch 13:  90%|█████████ | 307/341 [00:05<00:00, 53.11it/s, Epoch: 13, Batch: 308,Loss: -1.784,Avg.Loss: -1.503,LR: 1.40E-04]Training epoch 13:  90%|█████████ | 308/341 [00:05<00:00, 53.11it/s, Epoch: 13, Batch: 309,Loss: -1.510,Avg.Loss: -1.503,LR: 1.40E-04]Training epoch 13:  91%|█████████ | 309/341 [00:05<00:00, 53.11it/s, Epoch: 13, Batch: 310,Loss: -1.343,Avg.Loss: -1.503,LR: 1.40E-04]Training epoch 13:  91%|█████████ | 310/341 [00:05<00:00, 53.11it/s, Epoch: 13, Batch: 311,Loss: -1.817,Avg.Loss: -1.504,LR: 1.40E-04]Training epoch 13:  91%|█████████ | 311/341 [00:05<00:00, 53.11it/s, Epoch: 13, Batch: 312,Loss: -2.386,Avg.Loss: -1.506,LR: 1.39E-04]Training epoch 13:  91%|█████████▏| 312/341 [00:05<00:00, 53.90it/s, Epoch: 13, Batch: 312,Loss: -2.386,Avg.Loss: -1.506,LR: 1.39E-04]Training epoch 13:  91%|█████████▏| 312/341 [00:05<00:00, 53.90it/s, Epoch: 13, Batch: 313,Loss: -1.634,Avg.Loss: -1.507,LR: 1.39E-04]Training epoch 13:  92%|█████████▏| 313/341 [00:05<00:00, 53.90it/s, Epoch: 13, Batch: 314,Loss: -1.584,Avg.Loss: -1.507,LR: 1.39E-04]Training epoch 13:  92%|█████████▏| 314/341 [00:05<00:00, 53.90it/s, Epoch: 13, Batch: 315,Loss: -1.046,Avg.Loss: -1.506,LR: 1.39E-04]Training epoch 13:  92%|█████████▏| 315/341 [00:05<00:00, 53.90it/s, Epoch: 13, Batch: 316,Loss: -1.168,Avg.Loss: -1.505,LR: 1.39E-04]Training epoch 13:  93%|█████████▎| 316/341 [00:05<00:00, 53.90it/s, Epoch: 13, Batch: 317,Loss: -1.457,Avg.Loss: -1.504,LR: 1.39E-04]Training epoch 13:  93%|█████████▎| 317/341 [00:05<00:00, 53.90it/s, Epoch: 13, Batch: 318,Loss: -1.488,Avg.Loss: -1.504,LR: 1.39E-04]Training epoch 13:  93%|█████████▎| 318/341 [00:05<00:00, 54.61it/s, Epoch: 13, Batch: 318,Loss: -1.488,Avg.Loss: -1.504,LR: 1.39E-04]Training epoch 13:  93%|█████████▎| 318/341 [00:05<00:00, 54.61it/s, Epoch: 13, Batch: 319,Loss: -1.931,Avg.Loss: -1.506,LR: 1.39E-04]Training epoch 13:  94%|█████████▎| 319/341 [00:05<00:00, 54.61it/s, Epoch: 13, Batch: 320,Loss: -1.997,Avg.Loss: -1.507,LR: 1.39E-04]Training epoch 13:  94%|█████████▍| 320/341 [00:05<00:00, 54.61it/s, Epoch: 13, Batch: 321,Loss: -1.687,Avg.Loss: -1.508,LR: 1.39E-04]Training epoch 13:  94%|█████████▍| 321/341 [00:05<00:00, 54.61it/s, Epoch: 13, Batch: 322,Loss: -2.003,Avg.Loss: -1.509,LR: 1.38E-04]Training epoch 13:  94%|█████████▍| 322/341 [00:06<00:00, 54.61it/s, Epoch: 13, Batch: 323,Loss: -2.298,Avg.Loss: -1.512,LR: 1.38E-04]Training epoch 13:  95%|█████████▍| 323/341 [00:06<00:00, 54.61it/s, Epoch: 13, Batch: 324,Loss: -1.248,Avg.Loss: -1.511,LR: 1.38E-04]Training epoch 13:  95%|█████████▌| 324/341 [00:06<00:00, 54.46it/s, Epoch: 13, Batch: 324,Loss: -1.248,Avg.Loss: -1.511,LR: 1.38E-04]Training epoch 13:  95%|█████████▌| 324/341 [00:06<00:00, 54.46it/s, Epoch: 13, Batch: 325,Loss: -1.291,Avg.Loss: -1.510,LR: 1.38E-04]Training epoch 13:  95%|█████████▌| 325/341 [00:06<00:00, 54.46it/s, Epoch: 13, Batch: 326,Loss: -1.720,Avg.Loss: -1.511,LR: 1.38E-04]Training epoch 13:  96%|█████████▌| 326/341 [00:06<00:00, 54.46it/s, Epoch: 13, Batch: 327,Loss: -1.926,Avg.Loss: -1.512,LR: 1.38E-04]Training epoch 13:  96%|█████████▌| 327/341 [00:06<00:00, 54.46it/s, Epoch: 13, Batch: 328,Loss: -1.762,Avg.Loss: -1.513,LR: 1.38E-04]Training epoch 13:  96%|█████████▌| 328/341 [00:06<00:00, 54.46it/s, Epoch: 13, Batch: 329,Loss: -1.528,Avg.Loss: -1.513,LR: 1.38E-04]Training epoch 13:  96%|█████████▋| 329/341 [00:06<00:00, 54.46it/s, Epoch: 13, Batch: 330,Loss: -1.974,Avg.Loss: -1.514,LR: 1.38E-04]Training epoch 13:  97%|█████████▋| 330/341 [00:06<00:00, 54.62it/s, Epoch: 13, Batch: 330,Loss: -1.974,Avg.Loss: -1.514,LR: 1.38E-04]Training epoch 13:  97%|█████████▋| 330/341 [00:06<00:00, 54.62it/s, Epoch: 13, Batch: 331,Loss: -2.332,Avg.Loss: -1.517,LR: 1.38E-04]Training epoch 13:  97%|█████████▋| 331/341 [00:06<00:00, 54.62it/s, Epoch: 13, Batch: 332,Loss: -1.808,Avg.Loss: -1.518,LR: 1.37E-04]Training epoch 13:  97%|█████████▋| 332/341 [00:06<00:00, 54.62it/s, Epoch: 13, Batch: 333,Loss: -1.500,Avg.Loss: -1.518,LR: 1.37E-04]Training epoch 13:  98%|█████████▊| 333/341 [00:06<00:00, 54.62it/s, Epoch: 13, Batch: 334,Loss: -0.896,Avg.Loss: -1.516,LR: 1.37E-04]Training epoch 13:  98%|█████████▊| 334/341 [00:06<00:00, 54.62it/s, Epoch: 13, Batch: 335,Loss: -2.215,Avg.Loss: -1.518,LR: 1.37E-04]Training epoch 13:  98%|█████████▊| 335/341 [00:06<00:00, 54.62it/s, Epoch: 13, Batch: 336,Loss: -2.144,Avg.Loss: -1.520,LR: 1.37E-04]Training epoch 13:  99%|█████████▊| 336/341 [00:06<00:00, 54.36it/s, Epoch: 13, Batch: 336,Loss: -2.144,Avg.Loss: -1.520,LR: 1.37E-04]Training epoch 13:  99%|█████████▊| 336/341 [00:06<00:00, 54.36it/s, Epoch: 13, Batch: 337,Loss: -1.893,Avg.Loss: -1.521,LR: 1.37E-04]Training epoch 13:  99%|█████████▉| 337/341 [00:06<00:00, 54.36it/s, Epoch: 13, Batch: 338,Loss: -1.832,Avg.Loss: -1.522,LR: 1.37E-04]Training epoch 13:  99%|█████████▉| 338/341 [00:06<00:00, 54.36it/s, Epoch: 13, Batch: 339,Loss: -2.023,Avg.Loss: -1.523,LR: 1.37E-04]Training epoch 13:  99%|█████████▉| 339/341 [00:06<00:00, 54.36it/s, Epoch: 13, Batch: 340,Loss: -2.100,Avg.Loss: -1.525,LR: 1.37E-04]Training epoch 13: 100%|█████████▉| 340/341 [00:06<00:00, 54.36it/s, Epoch: 13, Batch: 341,Loss: -2.170,Avg.Loss: -1.527,LR: 1.37E-04]Training epoch 13: 100%|██████████| 341/341 [00:06<00:00, 53.66it/s, Epoch: 13, Batch: 341,Loss: -2.170,Avg.Loss: -1.527,LR: 1.37E-04]
Training epoch 14:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 14:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 14, Batch: 1,Loss: -2.270,Avg.Loss: -2.270,LR: 1.36E-04]Training epoch 14:   0%|          | 1/341 [00:00<00:09, 35.24it/s, Epoch: 14, Batch: 2,Loss: -2.356,Avg.Loss: -2.313,LR: 1.36E-04]Training epoch 14:   1%|          | 2/341 [00:00<00:07, 46.82it/s, Epoch: 14, Batch: 3,Loss: -2.384,Avg.Loss: -2.337,LR: 1.36E-04]Training epoch 14:   1%|          | 3/341 [00:00<00:06, 49.06it/s, Epoch: 14, Batch: 4,Loss: -2.503,Avg.Loss: -2.378,LR: 1.36E-04]Training epoch 14:   1%|          | 4/341 [00:00<00:06, 49.91it/s, Epoch: 14, Batch: 5,Loss: -2.062,Avg.Loss: -2.315,LR: 1.36E-04]Training epoch 14:   1%|▏         | 5/341 [00:00<00:06, 50.28it/s, Epoch: 14, Batch: 6,Loss: -2.385,Avg.Loss: -2.327,LR: 1.36E-04]Training epoch 14:   2%|▏         | 6/341 [00:00<00:06, 50.86it/s, Epoch: 14, Batch: 7,Loss: -2.327,Avg.Loss: -2.327,LR: 1.36E-04]Training epoch 14:   2%|▏         | 7/341 [00:00<00:05, 59.23it/s, Epoch: 14, Batch: 7,Loss: -2.327,Avg.Loss: -2.327,LR: 1.36E-04]Training epoch 14:   2%|▏         | 7/341 [00:00<00:05, 59.23it/s, Epoch: 14, Batch: 8,Loss: -1.979,Avg.Loss: -2.283,LR: 1.36E-04]Training epoch 14:   2%|▏         | 8/341 [00:00<00:05, 59.23it/s, Epoch: 14, Batch: 9,Loss: -1.481,Avg.Loss: -2.194,LR: 1.36E-04]Training epoch 14:   3%|▎         | 9/341 [00:00<00:05, 59.23it/s, Epoch: 14, Batch: 10,Loss: -1.591,Avg.Loss: -2.134,LR: 1.35E-04]Training epoch 14:   3%|▎         | 10/341 [00:00<00:05, 59.23it/s, Epoch: 14, Batch: 11,Loss: -1.877,Avg.Loss: -2.110,LR: 1.35E-04]Training epoch 14:   3%|▎         | 11/341 [00:00<00:05, 59.23it/s, Epoch: 14, Batch: 12,Loss: -1.717,Avg.Loss: -2.078,LR: 1.35E-04]Training epoch 14:   4%|▎         | 12/341 [00:00<00:05, 59.23it/s, Epoch: 14, Batch: 13,Loss: -1.845,Avg.Loss: -2.060,LR: 1.35E-04]Training epoch 14:   4%|▍         | 13/341 [00:00<00:05, 55.86it/s, Epoch: 14, Batch: 13,Loss: -1.845,Avg.Loss: -2.060,LR: 1.35E-04]Training epoch 14:   4%|▍         | 13/341 [00:00<00:05, 55.86it/s, Epoch: 14, Batch: 14,Loss: -2.065,Avg.Loss: -2.060,LR: 1.35E-04]Training epoch 14:   4%|▍         | 14/341 [00:00<00:05, 55.86it/s, Epoch: 14, Batch: 15,Loss: -2.331,Avg.Loss: -2.078,LR: 1.35E-04]Training epoch 14:   4%|▍         | 15/341 [00:00<00:05, 55.86it/s, Epoch: 14, Batch: 16,Loss: -2.026,Avg.Loss: -2.075,LR: 1.35E-04]Training epoch 14:   5%|▍         | 16/341 [00:00<00:05, 55.86it/s, Epoch: 14, Batch: 17,Loss: -1.889,Avg.Loss: -2.064,LR: 1.35E-04]Training epoch 14:   5%|▍         | 17/341 [00:00<00:05, 55.86it/s, Epoch: 14, Batch: 18,Loss: -1.953,Avg.Loss: -2.058,LR: 1.35E-04]Training epoch 14:   5%|▌         | 18/341 [00:00<00:05, 55.86it/s, Epoch: 14, Batch: 19,Loss: -1.997,Avg.Loss: -2.055,LR: 1.35E-04]Training epoch 14:   6%|▌         | 19/341 [00:00<00:05, 54.81it/s, Epoch: 14, Batch: 19,Loss: -1.997,Avg.Loss: -2.055,LR: 1.35E-04]Training epoch 14:   6%|▌         | 19/341 [00:00<00:05, 54.81it/s, Epoch: 14, Batch: 20,Loss: -1.543,Avg.Loss: -2.029,LR: 1.34E-04]Training epoch 14:   6%|▌         | 20/341 [00:00<00:05, 54.81it/s, Epoch: 14, Batch: 21,Loss: -0.837,Avg.Loss: -1.972,LR: 1.34E-04]Training epoch 14:   6%|▌         | 21/341 [00:00<00:05, 54.81it/s, Epoch: 14, Batch: 22,Loss: -1.812,Avg.Loss: -1.965,LR: 1.34E-04]Training epoch 14:   6%|▋         | 22/341 [00:00<00:05, 54.81it/s, Epoch: 14, Batch: 23,Loss: -2.217,Avg.Loss: -1.976,LR: 1.34E-04]Training epoch 14:   7%|▋         | 23/341 [00:00<00:05, 54.81it/s, Epoch: 14, Batch: 24,Loss: -1.350,Avg.Loss: -1.950,LR: 1.34E-04]Training epoch 14:   7%|▋         | 24/341 [00:00<00:05, 54.81it/s, Epoch: 14, Batch: 25,Loss: -0.225,Avg.Loss: -1.881,LR: 1.34E-04]Training epoch 14:   7%|▋         | 25/341 [00:00<00:05, 54.65it/s, Epoch: 14, Batch: 25,Loss: -0.225,Avg.Loss: -1.881,LR: 1.34E-04]Training epoch 14:   7%|▋         | 25/341 [00:00<00:05, 54.65it/s, Epoch: 14, Batch: 26,Loss: -0.291,Avg.Loss: -1.820,LR: 1.34E-04]Training epoch 14:   8%|▊         | 26/341 [00:00<00:05, 54.65it/s, Epoch: 14, Batch: 27,Loss: -1.792,Avg.Loss: -1.819,LR: 1.34E-04]Training epoch 14:   8%|▊         | 27/341 [00:00<00:05, 54.65it/s, Epoch: 14, Batch: 28,Loss: -2.023,Avg.Loss: -1.826,LR: 1.34E-04]Training epoch 14:   8%|▊         | 28/341 [00:00<00:05, 54.65it/s, Epoch: 14, Batch: 29,Loss: -1.759,Avg.Loss: -1.824,LR: 1.34E-04]Training epoch 14:   9%|▊         | 29/341 [00:00<00:05, 54.65it/s, Epoch: 14, Batch: 30,Loss: -0.543,Avg.Loss: -1.781,LR: 1.33E-04]Training epoch 14:   9%|▉         | 30/341 [00:00<00:05, 54.65it/s, Epoch: 14, Batch: 31,Loss: 0.093,Avg.Loss: -1.721,LR: 1.33E-04] Training epoch 14:   9%|▉         | 31/341 [00:00<00:05, 55.00it/s, Epoch: 14, Batch: 31,Loss: 0.093,Avg.Loss: -1.721,LR: 1.33E-04]Training epoch 14:   9%|▉         | 31/341 [00:00<00:05, 55.00it/s, Epoch: 14, Batch: 32,Loss: -0.606,Avg.Loss: -1.686,LR: 1.33E-04]Training epoch 14:   9%|▉         | 32/341 [00:00<00:05, 55.00it/s, Epoch: 14, Batch: 33,Loss: -2.096,Avg.Loss: -1.698,LR: 1.33E-04]Training epoch 14:  10%|▉         | 33/341 [00:00<00:05, 55.00it/s, Epoch: 14, Batch: 34,Loss: -1.986,Avg.Loss: -1.707,LR: 1.33E-04]Training epoch 14:  10%|▉         | 34/341 [00:00<00:05, 55.00it/s, Epoch: 14, Batch: 35,Loss: -1.651,Avg.Loss: -1.705,LR: 1.33E-04]Training epoch 14:  10%|█         | 35/341 [00:00<00:05, 55.00it/s, Epoch: 14, Batch: 36,Loss: -1.408,Avg.Loss: -1.697,LR: 1.33E-04]Training epoch 14:  11%|█         | 36/341 [00:00<00:05, 55.00it/s, Epoch: 14, Batch: 37,Loss: -2.059,Avg.Loss: -1.707,LR: 1.33E-04]Training epoch 14:  11%|█         | 37/341 [00:00<00:05, 55.08it/s, Epoch: 14, Batch: 37,Loss: -2.059,Avg.Loss: -1.707,LR: 1.33E-04]Training epoch 14:  11%|█         | 37/341 [00:00<00:05, 55.08it/s, Epoch: 14, Batch: 38,Loss: -2.360,Avg.Loss: -1.724,LR: 1.33E-04]Training epoch 14:  11%|█         | 38/341 [00:00<00:05, 55.08it/s, Epoch: 14, Batch: 39,Loss: -2.089,Avg.Loss: -1.733,LR: 1.33E-04]Training epoch 14:  11%|█▏        | 39/341 [00:00<00:05, 55.08it/s, Epoch: 14, Batch: 40,Loss: -1.976,Avg.Loss: -1.739,LR: 1.32E-04]Training epoch 14:  12%|█▏        | 40/341 [00:00<00:05, 55.08it/s, Epoch: 14, Batch: 41,Loss: -2.094,Avg.Loss: -1.748,LR: 1.32E-04]Training epoch 14:  12%|█▏        | 41/341 [00:00<00:05, 55.08it/s, Epoch: 14, Batch: 42,Loss: -1.984,Avg.Loss: -1.753,LR: 1.32E-04]Training epoch 14:  12%|█▏        | 42/341 [00:00<00:05, 55.08it/s, Epoch: 14, Batch: 43,Loss: -2.263,Avg.Loss: -1.765,LR: 1.32E-04]Training epoch 14:  13%|█▎        | 43/341 [00:00<00:05, 53.87it/s, Epoch: 14, Batch: 43,Loss: -2.263,Avg.Loss: -1.765,LR: 1.32E-04]Training epoch 14:  13%|█▎        | 43/341 [00:00<00:05, 53.87it/s, Epoch: 14, Batch: 44,Loss: -2.080,Avg.Loss: -1.772,LR: 1.32E-04]Training epoch 14:  13%|█▎        | 44/341 [00:00<00:05, 53.87it/s, Epoch: 14, Batch: 45,Loss: -2.386,Avg.Loss: -1.786,LR: 1.32E-04]Training epoch 14:  13%|█▎        | 45/341 [00:00<00:05, 53.87it/s, Epoch: 14, Batch: 46,Loss: -2.320,Avg.Loss: -1.798,LR: 1.32E-04]Training epoch 14:  13%|█▎        | 46/341 [00:00<00:05, 53.87it/s, Epoch: 14, Batch: 47,Loss: -2.140,Avg.Loss: -1.805,LR: 1.32E-04]Training epoch 14:  14%|█▍        | 47/341 [00:00<00:05, 53.87it/s, Epoch: 14, Batch: 48,Loss: -2.143,Avg.Loss: -1.812,LR: 1.32E-04]Training epoch 14:  14%|█▍        | 48/341 [00:00<00:05, 53.87it/s, Epoch: 14, Batch: 49,Loss: -2.312,Avg.Loss: -1.822,LR: 1.32E-04]Training epoch 14:  14%|█▍        | 49/341 [00:00<00:05, 53.43it/s, Epoch: 14, Batch: 49,Loss: -2.312,Avg.Loss: -1.822,LR: 1.32E-04]Training epoch 14:  14%|█▍        | 49/341 [00:00<00:05, 53.43it/s, Epoch: 14, Batch: 50,Loss: -2.196,Avg.Loss: -1.830,LR: 1.31E-04]Training epoch 14:  15%|█▍        | 50/341 [00:00<00:05, 53.43it/s, Epoch: 14, Batch: 51,Loss: -1.978,Avg.Loss: -1.833,LR: 1.31E-04]Training epoch 14:  15%|█▍        | 51/341 [00:00<00:05, 53.43it/s, Epoch: 14, Batch: 52,Loss: -1.677,Avg.Loss: -1.830,LR: 1.31E-04]Training epoch 14:  15%|█▌        | 52/341 [00:00<00:05, 53.43it/s, Epoch: 14, Batch: 53,Loss: -1.420,Avg.Loss: -1.822,LR: 1.31E-04]Training epoch 14:  16%|█▌        | 53/341 [00:00<00:05, 53.43it/s, Epoch: 14, Batch: 54,Loss: -1.531,Avg.Loss: -1.816,LR: 1.31E-04]Training epoch 14:  16%|█▌        | 54/341 [00:01<00:05, 53.43it/s, Epoch: 14, Batch: 55,Loss: -2.197,Avg.Loss: -1.823,LR: 1.31E-04]Training epoch 14:  16%|█▌        | 55/341 [00:01<00:05, 53.17it/s, Epoch: 14, Batch: 55,Loss: -2.197,Avg.Loss: -1.823,LR: 1.31E-04]Training epoch 14:  16%|█▌        | 55/341 [00:01<00:05, 53.17it/s, Epoch: 14, Batch: 56,Loss: -2.193,Avg.Loss: -1.830,LR: 1.31E-04]Training epoch 14:  16%|█▋        | 56/341 [00:01<00:05, 53.17it/s, Epoch: 14, Batch: 57,Loss: -1.796,Avg.Loss: -1.829,LR: 1.31E-04]Training epoch 14:  17%|█▋        | 57/341 [00:01<00:05, 53.17it/s, Epoch: 14, Batch: 58,Loss: -1.106,Avg.Loss: -1.817,LR: 1.31E-04]Training epoch 14:  17%|█▋        | 58/341 [00:01<00:05, 53.17it/s, Epoch: 14, Batch: 59,Loss: -1.412,Avg.Loss: -1.810,LR: 1.30E-04]Training epoch 14:  17%|█▋        | 59/341 [00:01<00:05, 53.17it/s, Epoch: 14, Batch: 60,Loss: -1.791,Avg.Loss: -1.810,LR: 1.30E-04]Training epoch 14:  18%|█▊        | 60/341 [00:01<00:05, 53.17it/s, Epoch: 14, Batch: 61,Loss: -2.120,Avg.Loss: -1.815,LR: 1.30E-04]Training epoch 14:  18%|█▊        | 61/341 [00:01<00:05, 53.02it/s, Epoch: 14, Batch: 61,Loss: -2.120,Avg.Loss: -1.815,LR: 1.30E-04]Training epoch 14:  18%|█▊        | 61/341 [00:01<00:05, 53.02it/s, Epoch: 14, Batch: 62,Loss: -1.356,Avg.Loss: -1.807,LR: 1.30E-04]Training epoch 14:  18%|█▊        | 62/341 [00:01<00:05, 53.02it/s, Epoch: 14, Batch: 63,Loss: -2.108,Avg.Loss: -1.812,LR: 1.30E-04]Training epoch 14:  18%|█▊        | 63/341 [00:01<00:05, 53.02it/s, Epoch: 14, Batch: 64,Loss: -2.236,Avg.Loss: -1.819,LR: 1.30E-04]Training epoch 14:  19%|█▉        | 64/341 [00:01<00:05, 53.02it/s, Epoch: 14, Batch: 65,Loss: -0.824,Avg.Loss: -1.804,LR: 1.30E-04]Training epoch 14:  19%|█▉        | 65/341 [00:01<00:05, 53.02it/s, Epoch: 14, Batch: 66,Loss: -0.214,Avg.Loss: -1.779,LR: 1.30E-04]Training epoch 14:  19%|█▉        | 66/341 [00:01<00:05, 53.02it/s, Epoch: 14, Batch: 67,Loss: 0.011,Avg.Loss: -1.753,LR: 1.30E-04] Training epoch 14:  20%|█▉        | 67/341 [00:01<00:05, 52.78it/s, Epoch: 14, Batch: 67,Loss: 0.011,Avg.Loss: -1.753,LR: 1.30E-04]Training epoch 14:  20%|█▉        | 67/341 [00:01<00:05, 52.78it/s, Epoch: 14, Batch: 68,Loss: -1.480,Avg.Loss: -1.749,LR: 1.30E-04]Training epoch 14:  20%|█▉        | 68/341 [00:01<00:05, 52.78it/s, Epoch: 14, Batch: 69,Loss: -1.815,Avg.Loss: -1.750,LR: 1.29E-04]Training epoch 14:  20%|██        | 69/341 [00:01<00:05, 52.78it/s, Epoch: 14, Batch: 70,Loss: -1.360,Avg.Loss: -1.744,LR: 1.29E-04]Training epoch 14:  21%|██        | 70/341 [00:01<00:05, 52.78it/s, Epoch: 14, Batch: 71,Loss: -0.528,Avg.Loss: -1.727,LR: 1.29E-04]Training epoch 14:  21%|██        | 71/341 [00:01<00:05, 52.78it/s, Epoch: 14, Batch: 72,Loss: 0.024,Avg.Loss: -1.703,LR: 1.29E-04] Training epoch 14:  21%|██        | 72/341 [00:01<00:05, 52.78it/s, Epoch: 14, Batch: 73,Loss: -0.917,Avg.Loss: -1.692,LR: 1.29E-04]Training epoch 14:  21%|██▏       | 73/341 [00:01<00:05, 52.67it/s, Epoch: 14, Batch: 73,Loss: -0.917,Avg.Loss: -1.692,LR: 1.29E-04]Training epoch 14:  21%|██▏       | 73/341 [00:01<00:05, 52.67it/s, Epoch: 14, Batch: 74,Loss: -1.705,Avg.Loss: -1.692,LR: 1.29E-04]Training epoch 14:  22%|██▏       | 74/341 [00:01<00:05, 52.67it/s, Epoch: 14, Batch: 75,Loss: -0.942,Avg.Loss: -1.682,LR: 1.29E-04]Training epoch 14:  22%|██▏       | 75/341 [00:01<00:05, 52.67it/s, Epoch: 14, Batch: 76,Loss: -0.697,Avg.Loss: -1.669,LR: 1.29E-04]Training epoch 14:  22%|██▏       | 76/341 [00:01<00:05, 52.67it/s, Epoch: 14, Batch: 77,Loss: 0.343,Avg.Loss: -1.643,LR: 1.29E-04] Training epoch 14:  23%|██▎       | 77/341 [00:01<00:05, 52.67it/s, Epoch: 14, Batch: 78,Loss: -0.817,Avg.Loss: -1.632,LR: 1.29E-04]Training epoch 14:  23%|██▎       | 78/341 [00:01<00:04, 52.67it/s, Epoch: 14, Batch: 79,Loss: -1.300,Avg.Loss: -1.628,LR: 1.28E-04]Training epoch 14:  23%|██▎       | 79/341 [00:01<00:04, 52.91it/s, Epoch: 14, Batch: 79,Loss: -1.300,Avg.Loss: -1.628,LR: 1.28E-04]Training epoch 14:  23%|██▎       | 79/341 [00:01<00:04, 52.91it/s, Epoch: 14, Batch: 80,Loss: -2.053,Avg.Loss: -1.634,LR: 1.28E-04]Training epoch 14:  23%|██▎       | 80/341 [00:01<00:04, 52.91it/s, Epoch: 14, Batch: 81,Loss: -1.967,Avg.Loss: -1.638,LR: 1.28E-04]Training epoch 14:  24%|██▍       | 81/341 [00:01<00:04, 52.91it/s, Epoch: 14, Batch: 82,Loss: -1.896,Avg.Loss: -1.641,LR: 1.28E-04]Training epoch 14:  24%|██▍       | 82/341 [00:01<00:04, 52.91it/s, Epoch: 14, Batch: 83,Loss: -1.853,Avg.Loss: -1.643,LR: 1.28E-04]Training epoch 14:  24%|██▍       | 83/341 [00:01<00:04, 52.91it/s, Epoch: 14, Batch: 84,Loss: -2.006,Avg.Loss: -1.648,LR: 1.28E-04]Training epoch 14:  25%|██▍       | 84/341 [00:01<00:04, 52.91it/s, Epoch: 14, Batch: 85,Loss: -2.045,Avg.Loss: -1.652,LR: 1.28E-04]Training epoch 14:  25%|██▍       | 85/341 [00:01<00:04, 53.05it/s, Epoch: 14, Batch: 85,Loss: -2.045,Avg.Loss: -1.652,LR: 1.28E-04]Training epoch 14:  25%|██▍       | 85/341 [00:01<00:04, 53.05it/s, Epoch: 14, Batch: 86,Loss: -1.937,Avg.Loss: -1.656,LR: 1.28E-04]Training epoch 14:  25%|██▌       | 86/341 [00:01<00:04, 53.05it/s, Epoch: 14, Batch: 87,Loss: -1.920,Avg.Loss: -1.659,LR: 1.28E-04]Training epoch 14:  26%|██▌       | 87/341 [00:01<00:04, 53.05it/s, Epoch: 14, Batch: 88,Loss: -1.842,Avg.Loss: -1.661,LR: 1.28E-04]Training epoch 14:  26%|██▌       | 88/341 [00:01<00:04, 53.05it/s, Epoch: 14, Batch: 89,Loss: -2.140,Avg.Loss: -1.666,LR: 1.27E-04]Training epoch 14:  26%|██▌       | 89/341 [00:01<00:04, 53.05it/s, Epoch: 14, Batch: 90,Loss: -1.655,Avg.Loss: -1.666,LR: 1.27E-04]Training epoch 14:  26%|██▋       | 90/341 [00:01<00:04, 53.05it/s, Epoch: 14, Batch: 91,Loss: -2.175,Avg.Loss: -1.672,LR: 1.27E-04]Training epoch 14:  27%|██▋       | 91/341 [00:01<00:04, 52.88it/s, Epoch: 14, Batch: 91,Loss: -2.175,Avg.Loss: -1.672,LR: 1.27E-04]Training epoch 14:  27%|██▋       | 91/341 [00:01<00:04, 52.88it/s, Epoch: 14, Batch: 92,Loss: -1.805,Avg.Loss: -1.673,LR: 1.27E-04]Training epoch 14:  27%|██▋       | 92/341 [00:01<00:04, 52.88it/s, Epoch: 14, Batch: 93,Loss: -2.329,Avg.Loss: -1.680,LR: 1.27E-04]Training epoch 14:  27%|██▋       | 93/341 [00:01<00:04, 52.88it/s, Epoch: 14, Batch: 94,Loss: -2.520,Avg.Loss: -1.689,LR: 1.27E-04]Training epoch 14:  28%|██▊       | 94/341 [00:01<00:04, 52.88it/s, Epoch: 14, Batch: 95,Loss: -2.437,Avg.Loss: -1.697,LR: 1.27E-04]Training epoch 14:  28%|██▊       | 95/341 [00:01<00:04, 52.88it/s, Epoch: 14, Batch: 96,Loss: -2.233,Avg.Loss: -1.703,LR: 1.27E-04]Training epoch 14:  28%|██▊       | 96/341 [00:01<00:04, 52.88it/s, Epoch: 14, Batch: 97,Loss: -2.099,Avg.Loss: -1.707,LR: 1.27E-04]Training epoch 14:  28%|██▊       | 97/341 [00:01<00:04, 53.09it/s, Epoch: 14, Batch: 97,Loss: -2.099,Avg.Loss: -1.707,LR: 1.27E-04]Training epoch 14:  28%|██▊       | 97/341 [00:01<00:04, 53.09it/s, Epoch: 14, Batch: 98,Loss: -2.405,Avg.Loss: -1.714,LR: 1.27E-04]Training epoch 14:  29%|██▊       | 98/341 [00:01<00:04, 53.09it/s, Epoch: 14, Batch: 99,Loss: -1.923,Avg.Loss: -1.716,LR: 1.26E-04]Training epoch 14:  29%|██▉       | 99/341 [00:01<00:04, 53.09it/s, Epoch: 14, Batch: 100,Loss: -2.066,Avg.Loss: -1.719,LR: 1.26E-04]Training epoch 14:  29%|██▉       | 100/341 [00:01<00:04, 53.09it/s, Epoch: 14, Batch: 101,Loss: -2.611,Avg.Loss: -1.728,LR: 1.26E-04]Training epoch 14:  30%|██▉       | 101/341 [00:01<00:04, 53.09it/s, Epoch: 14, Batch: 102,Loss: -2.254,Avg.Loss: -1.733,LR: 1.26E-04]Training epoch 14:  30%|██▉       | 102/341 [00:01<00:04, 53.09it/s, Epoch: 14, Batch: 103,Loss: -1.827,Avg.Loss: -1.734,LR: 1.26E-04]Training epoch 14:  30%|███       | 103/341 [00:01<00:04, 52.31it/s, Epoch: 14, Batch: 103,Loss: -1.827,Avg.Loss: -1.734,LR: 1.26E-04]Training epoch 14:  30%|███       | 103/341 [00:01<00:04, 52.31it/s, Epoch: 14, Batch: 104,Loss: -2.074,Avg.Loss: -1.738,LR: 1.26E-04]Training epoch 14:  30%|███       | 104/341 [00:01<00:04, 52.31it/s, Epoch: 14, Batch: 105,Loss: -1.754,Avg.Loss: -1.738,LR: 1.26E-04]Training epoch 14:  31%|███       | 105/341 [00:01<00:04, 52.31it/s, Epoch: 14, Batch: 106,Loss: -2.307,Avg.Loss: -1.743,LR: 1.26E-04]Training epoch 14:  31%|███       | 106/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 107,Loss: -2.153,Avg.Loss: -1.747,LR: 1.26E-04]Training epoch 14:  31%|███▏      | 107/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 108,Loss: -2.135,Avg.Loss: -1.750,LR: 1.26E-04]Training epoch 14:  32%|███▏      | 108/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 109,Loss: -1.934,Avg.Loss: -1.752,LR: 1.25E-04]Training epoch 14:  32%|███▏      | 109/341 [00:02<00:04, 52.40it/s, Epoch: 14, Batch: 109,Loss: -1.934,Avg.Loss: -1.752,LR: 1.25E-04]Training epoch 14:  32%|███▏      | 109/341 [00:02<00:04, 52.40it/s, Epoch: 14, Batch: 110,Loss: -1.807,Avg.Loss: -1.753,LR: 1.25E-04]Training epoch 14:  32%|███▏      | 110/341 [00:02<00:04, 52.40it/s, Epoch: 14, Batch: 111,Loss: -2.057,Avg.Loss: -1.755,LR: 1.25E-04]Training epoch 14:  33%|███▎      | 111/341 [00:02<00:04, 52.40it/s, Epoch: 14, Batch: 112,Loss: -2.294,Avg.Loss: -1.760,LR: 1.25E-04]Training epoch 14:  33%|███▎      | 112/341 [00:02<00:04, 52.40it/s, Epoch: 14, Batch: 113,Loss: -2.272,Avg.Loss: -1.765,LR: 1.25E-04]Training epoch 14:  33%|███▎      | 113/341 [00:02<00:04, 52.40it/s, Epoch: 14, Batch: 114,Loss: -1.890,Avg.Loss: -1.766,LR: 1.25E-04]Training epoch 14:  33%|███▎      | 114/341 [00:02<00:04, 52.40it/s, Epoch: 14, Batch: 115,Loss: -2.233,Avg.Loss: -1.770,LR: 1.25E-04]Training epoch 14:  34%|███▎      | 115/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 115,Loss: -2.233,Avg.Loss: -1.770,LR: 1.25E-04]Training epoch 14:  34%|███▎      | 115/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 116,Loss: -2.064,Avg.Loss: -1.772,LR: 1.25E-04]Training epoch 14:  34%|███▍      | 116/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 117,Loss: -2.319,Avg.Loss: -1.777,LR: 1.25E-04]Training epoch 14:  34%|███▍      | 117/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 118,Loss: -2.303,Avg.Loss: -1.782,LR: 1.25E-04]Training epoch 14:  35%|███▍      | 118/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 119,Loss: -2.342,Avg.Loss: -1.786,LR: 1.24E-04]Training epoch 14:  35%|███▍      | 119/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 120,Loss: -2.189,Avg.Loss: -1.790,LR: 1.24E-04]Training epoch 14:  35%|███▌      | 120/341 [00:02<00:04, 52.31it/s, Epoch: 14, Batch: 121,Loss: -2.226,Avg.Loss: -1.793,LR: 1.24E-04]Training epoch 14:  35%|███▌      | 121/341 [00:02<00:04, 52.06it/s, Epoch: 14, Batch: 121,Loss: -2.226,Avg.Loss: -1.793,LR: 1.24E-04]Training epoch 14:  35%|███▌      | 121/341 [00:02<00:04, 52.06it/s, Epoch: 14, Batch: 122,Loss: -2.481,Avg.Loss: -1.799,LR: 1.24E-04]Training epoch 14:  36%|███▌      | 122/341 [00:02<00:04, 52.06it/s, Epoch: 14, Batch: 123,Loss: -2.181,Avg.Loss: -1.802,LR: 1.24E-04]Training epoch 14:  36%|███▌      | 123/341 [00:02<00:04, 52.06it/s, Epoch: 14, Batch: 124,Loss: -1.690,Avg.Loss: -1.801,LR: 1.24E-04]Training epoch 14:  36%|███▋      | 124/341 [00:02<00:04, 52.06it/s, Epoch: 14, Batch: 125,Loss: -2.351,Avg.Loss: -1.805,LR: 1.24E-04]Training epoch 14:  37%|███▋      | 125/341 [00:02<00:04, 52.06it/s, Epoch: 14, Batch: 126,Loss: -2.088,Avg.Loss: -1.808,LR: 1.24E-04]Training epoch 14:  37%|███▋      | 126/341 [00:02<00:04, 52.06it/s, Epoch: 14, Batch: 127,Loss: -2.266,Avg.Loss: -1.811,LR: 1.24E-04]Training epoch 14:  37%|███▋      | 127/341 [00:02<00:04, 52.54it/s, Epoch: 14, Batch: 127,Loss: -2.266,Avg.Loss: -1.811,LR: 1.24E-04]Training epoch 14:  37%|███▋      | 127/341 [00:02<00:04, 52.54it/s, Epoch: 14, Batch: 128,Loss: -2.005,Avg.Loss: -1.813,LR: 1.24E-04]Training epoch 14:  38%|███▊      | 128/341 [00:02<00:04, 52.54it/s, Epoch: 14, Batch: 129,Loss: -2.162,Avg.Loss: -1.816,LR: 1.23E-04]Training epoch 14:  38%|███▊      | 129/341 [00:02<00:04, 52.54it/s, Epoch: 14, Batch: 130,Loss: -2.180,Avg.Loss: -1.818,LR: 1.23E-04]Training epoch 14:  38%|███▊      | 130/341 [00:02<00:04, 52.54it/s, Epoch: 14, Batch: 131,Loss: -2.249,Avg.Loss: -1.822,LR: 1.23E-04]Training epoch 14:  38%|███▊      | 131/341 [00:02<00:03, 52.54it/s, Epoch: 14, Batch: 132,Loss: -2.021,Avg.Loss: -1.823,LR: 1.23E-04]Training epoch 14:  39%|███▊      | 132/341 [00:02<00:03, 52.54it/s, Epoch: 14, Batch: 133,Loss: -2.089,Avg.Loss: -1.825,LR: 1.23E-04]Training epoch 14:  39%|███▉      | 133/341 [00:02<00:03, 53.45it/s, Epoch: 14, Batch: 133,Loss: -2.089,Avg.Loss: -1.825,LR: 1.23E-04]Training epoch 14:  39%|███▉      | 133/341 [00:02<00:03, 53.45it/s, Epoch: 14, Batch: 134,Loss: -1.962,Avg.Loss: -1.826,LR: 1.23E-04]Training epoch 14:  39%|███▉      | 134/341 [00:02<00:03, 53.45it/s, Epoch: 14, Batch: 135,Loss: -2.182,Avg.Loss: -1.829,LR: 1.23E-04]Training epoch 14:  40%|███▉      | 135/341 [00:02<00:03, 53.45it/s, Epoch: 14, Batch: 136,Loss: -2.070,Avg.Loss: -1.831,LR: 1.23E-04]Training epoch 14:  40%|███▉      | 136/341 [00:02<00:03, 53.45it/s, Epoch: 14, Batch: 137,Loss: -2.071,Avg.Loss: -1.832,LR: 1.23E-04]Training epoch 14:  40%|████      | 137/341 [00:02<00:03, 53.45it/s, Epoch: 14, Batch: 138,Loss: -1.970,Avg.Loss: -1.833,LR: 1.23E-04]Training epoch 14:  40%|████      | 138/341 [00:02<00:03, 53.45it/s, Epoch: 14, Batch: 139,Loss: -2.444,Avg.Loss: -1.838,LR: 1.22E-04]Training epoch 14:  41%|████      | 139/341 [00:02<00:03, 53.57it/s, Epoch: 14, Batch: 139,Loss: -2.444,Avg.Loss: -1.838,LR: 1.22E-04]Training epoch 14:  41%|████      | 139/341 [00:02<00:03, 53.57it/s, Epoch: 14, Batch: 140,Loss: -2.175,Avg.Loss: -1.840,LR: 1.22E-04]Training epoch 14:  41%|████      | 140/341 [00:02<00:03, 53.57it/s, Epoch: 14, Batch: 141,Loss: -1.777,Avg.Loss: -1.840,LR: 1.22E-04]Training epoch 14:  41%|████▏     | 141/341 [00:02<00:03, 53.57it/s, Epoch: 14, Batch: 142,Loss: -1.934,Avg.Loss: -1.840,LR: 1.22E-04]Training epoch 14:  42%|████▏     | 142/341 [00:02<00:03, 53.57it/s, Epoch: 14, Batch: 143,Loss: -2.338,Avg.Loss: -1.844,LR: 1.22E-04]Training epoch 14:  42%|████▏     | 143/341 [00:02<00:03, 53.57it/s, Epoch: 14, Batch: 144,Loss: -2.257,Avg.Loss: -1.847,LR: 1.22E-04]Training epoch 14:  42%|████▏     | 144/341 [00:02<00:03, 53.57it/s, Epoch: 14, Batch: 145,Loss: -2.101,Avg.Loss: -1.848,LR: 1.22E-04]Training epoch 14:  43%|████▎     | 145/341 [00:02<00:03, 52.72it/s, Epoch: 14, Batch: 145,Loss: -2.101,Avg.Loss: -1.848,LR: 1.22E-04]Training epoch 14:  43%|████▎     | 145/341 [00:02<00:03, 52.72it/s, Epoch: 14, Batch: 146,Loss: -1.618,Avg.Loss: -1.847,LR: 1.22E-04]Training epoch 14:  43%|████▎     | 146/341 [00:02<00:03, 52.72it/s, Epoch: 14, Batch: 147,Loss: -2.085,Avg.Loss: -1.848,LR: 1.22E-04]Training epoch 14:  43%|████▎     | 147/341 [00:02<00:03, 52.72it/s, Epoch: 14, Batch: 148,Loss: -2.009,Avg.Loss: -1.850,LR: 1.22E-04]Training epoch 14:  43%|████▎     | 148/341 [00:02<00:03, 52.72it/s, Epoch: 14, Batch: 149,Loss: -2.411,Avg.Loss: -1.853,LR: 1.21E-04]Training epoch 14:  44%|████▎     | 149/341 [00:02<00:03, 52.72it/s, Epoch: 14, Batch: 150,Loss: -1.816,Avg.Loss: -1.853,LR: 1.21E-04]Training epoch 14:  44%|████▍     | 150/341 [00:02<00:03, 52.72it/s, Epoch: 14, Batch: 151,Loss: -1.395,Avg.Loss: -1.850,LR: 1.21E-04]Training epoch 14:  44%|████▍     | 151/341 [00:02<00:03, 52.35it/s, Epoch: 14, Batch: 151,Loss: -1.395,Avg.Loss: -1.850,LR: 1.21E-04]Training epoch 14:  44%|████▍     | 151/341 [00:02<00:03, 52.35it/s, Epoch: 14, Batch: 152,Loss: -1.464,Avg.Loss: -1.848,LR: 1.21E-04]Training epoch 14:  45%|████▍     | 152/341 [00:02<00:03, 52.35it/s, Epoch: 14, Batch: 153,Loss: -1.508,Avg.Loss: -1.845,LR: 1.21E-04]Training epoch 14:  45%|████▍     | 153/341 [00:02<00:03, 52.35it/s, Epoch: 14, Batch: 154,Loss: -1.159,Avg.Loss: -1.841,LR: 1.21E-04]Training epoch 14:  45%|████▌     | 154/341 [00:02<00:03, 52.35it/s, Epoch: 14, Batch: 155,Loss: -0.382,Avg.Loss: -1.831,LR: 1.21E-04]Training epoch 14:  45%|████▌     | 155/341 [00:02<00:03, 52.35it/s, Epoch: 14, Batch: 156,Loss: -0.362,Avg.Loss: -1.822,LR: 1.21E-04]Training epoch 14:  46%|████▌     | 156/341 [00:02<00:03, 52.35it/s, Epoch: 14, Batch: 157,Loss: -1.893,Avg.Loss: -1.822,LR: 1.21E-04]Training epoch 14:  46%|████▌     | 157/341 [00:02<00:03, 52.23it/s, Epoch: 14, Batch: 157,Loss: -1.893,Avg.Loss: -1.822,LR: 1.21E-04]Training epoch 14:  46%|████▌     | 157/341 [00:02<00:03, 52.23it/s, Epoch: 14, Batch: 158,Loss: -2.345,Avg.Loss: -1.826,LR: 1.21E-04]Training epoch 14:  46%|████▋     | 158/341 [00:02<00:03, 52.23it/s, Epoch: 14, Batch: 159,Loss: -1.705,Avg.Loss: -1.825,LR: 1.21E-04]Training epoch 14:  47%|████▋     | 159/341 [00:03<00:03, 52.23it/s, Epoch: 14, Batch: 160,Loss: -0.623,Avg.Loss: -1.817,LR: 1.20E-04]Training epoch 14:  47%|████▋     | 160/341 [00:03<00:03, 52.23it/s, Epoch: 14, Batch: 161,Loss: 0.128,Avg.Loss: -1.805,LR: 1.20E-04] Training epoch 14:  47%|████▋     | 161/341 [00:03<00:03, 52.23it/s, Epoch: 14, Batch: 162,Loss: -0.329,Avg.Loss: -1.796,LR: 1.20E-04]Training epoch 14:  48%|████▊     | 162/341 [00:03<00:03, 52.23it/s, Epoch: 14, Batch: 163,Loss: -1.368,Avg.Loss: -1.794,LR: 1.20E-04]Training epoch 14:  48%|████▊     | 163/341 [00:03<00:03, 52.15it/s, Epoch: 14, Batch: 163,Loss: -1.368,Avg.Loss: -1.794,LR: 1.20E-04]Training epoch 14:  48%|████▊     | 163/341 [00:03<00:03, 52.15it/s, Epoch: 14, Batch: 164,Loss: -1.491,Avg.Loss: -1.792,LR: 1.20E-04]Training epoch 14:  48%|████▊     | 164/341 [00:03<00:03, 52.15it/s, Epoch: 14, Batch: 165,Loss: -0.879,Avg.Loss: -1.786,LR: 1.20E-04]Training epoch 14:  48%|████▊     | 165/341 [00:03<00:03, 52.15it/s, Epoch: 14, Batch: 166,Loss: -1.570,Avg.Loss: -1.785,LR: 1.20E-04]Training epoch 14:  49%|████▊     | 166/341 [00:03<00:03, 52.15it/s, Epoch: 14, Batch: 167,Loss: -2.038,Avg.Loss: -1.786,LR: 1.20E-04]Training epoch 14:  49%|████▉     | 167/341 [00:03<00:03, 52.15it/s, Epoch: 14, Batch: 168,Loss: -2.380,Avg.Loss: -1.790,LR: 1.20E-04]Training epoch 14:  49%|████▉     | 168/341 [00:03<00:03, 52.15it/s, Epoch: 14, Batch: 169,Loss: -1.580,Avg.Loss: -1.789,LR: 1.20E-04]Training epoch 14:  50%|████▉     | 169/341 [00:03<00:03, 51.70it/s, Epoch: 14, Batch: 169,Loss: -1.580,Avg.Loss: -1.789,LR: 1.20E-04]Training epoch 14:  50%|████▉     | 169/341 [00:03<00:03, 51.70it/s, Epoch: 14, Batch: 170,Loss: -1.869,Avg.Loss: -1.789,LR: 1.19E-04]Training epoch 14:  50%|████▉     | 170/341 [00:03<00:03, 51.70it/s, Epoch: 14, Batch: 171,Loss: -2.148,Avg.Loss: -1.791,LR: 1.19E-04]Training epoch 14:  50%|█████     | 171/341 [00:03<00:03, 51.70it/s, Epoch: 14, Batch: 172,Loss: -1.749,Avg.Loss: -1.791,LR: 1.19E-04]Training epoch 14:  50%|█████     | 172/341 [00:03<00:03, 51.70it/s, Epoch: 14, Batch: 173,Loss: -1.906,Avg.Loss: -1.792,LR: 1.19E-04]Training epoch 14:  51%|█████     | 173/341 [00:03<00:03, 51.70it/s, Epoch: 14, Batch: 174,Loss: -1.461,Avg.Loss: -1.790,LR: 1.19E-04]Training epoch 14:  51%|█████     | 174/341 [00:03<00:03, 51.70it/s, Epoch: 14, Batch: 175,Loss: -2.007,Avg.Loss: -1.791,LR: 1.19E-04]Training epoch 14:  51%|█████▏    | 175/341 [00:03<00:03, 51.63it/s, Epoch: 14, Batch: 175,Loss: -2.007,Avg.Loss: -1.791,LR: 1.19E-04]Training epoch 14:  51%|█████▏    | 175/341 [00:03<00:03, 51.63it/s, Epoch: 14, Batch: 176,Loss: -2.459,Avg.Loss: -1.795,LR: 1.19E-04]Training epoch 14:  52%|█████▏    | 176/341 [00:03<00:03, 51.63it/s, Epoch: 14, Batch: 177,Loss: -2.306,Avg.Loss: -1.798,LR: 1.19E-04]Training epoch 14:  52%|█████▏    | 177/341 [00:03<00:03, 51.63it/s, Epoch: 14, Batch: 178,Loss: -1.871,Avg.Loss: -1.798,LR: 1.19E-04]Training epoch 14:  52%|█████▏    | 178/341 [00:03<00:03, 51.63it/s, Epoch: 14, Batch: 179,Loss: -2.217,Avg.Loss: -1.801,LR: 1.19E-04]Training epoch 14:  52%|█████▏    | 179/341 [00:03<00:03, 51.63it/s, Epoch: 14, Batch: 180,Loss: -2.360,Avg.Loss: -1.804,LR: 1.18E-04]Training epoch 14:  53%|█████▎    | 180/341 [00:03<00:03, 51.63it/s, Epoch: 14, Batch: 181,Loss: -2.386,Avg.Loss: -1.807,LR: 1.18E-04]Training epoch 14:  53%|█████▎    | 181/341 [00:03<00:03, 50.59it/s, Epoch: 14, Batch: 181,Loss: -2.386,Avg.Loss: -1.807,LR: 1.18E-04]Training epoch 14:  53%|█████▎    | 181/341 [00:03<00:03, 50.59it/s, Epoch: 14, Batch: 182,Loss: -2.238,Avg.Loss: -1.809,LR: 1.18E-04]Training epoch 14:  53%|█████▎    | 182/341 [00:03<00:03, 50.59it/s, Epoch: 14, Batch: 183,Loss: -2.562,Avg.Loss: -1.813,LR: 1.18E-04]Training epoch 14:  54%|█████▎    | 183/341 [00:03<00:03, 50.59it/s, Epoch: 14, Batch: 184,Loss: -2.554,Avg.Loss: -1.817,LR: 1.18E-04]Training epoch 14:  54%|█████▍    | 184/341 [00:03<00:03, 50.59it/s, Epoch: 14, Batch: 185,Loss: -2.177,Avg.Loss: -1.819,LR: 1.18E-04]Training epoch 14:  54%|█████▍    | 185/341 [00:03<00:03, 50.59it/s, Epoch: 14, Batch: 186,Loss: -2.178,Avg.Loss: -1.821,LR: 1.18E-04]Training epoch 14:  55%|█████▍    | 186/341 [00:03<00:03, 50.59it/s, Epoch: 14, Batch: 187,Loss: -2.773,Avg.Loss: -1.826,LR: 1.18E-04]Training epoch 14:  55%|█████▍    | 187/341 [00:03<00:03, 50.56it/s, Epoch: 14, Batch: 187,Loss: -2.773,Avg.Loss: -1.826,LR: 1.18E-04]Training epoch 14:  55%|█████▍    | 187/341 [00:03<00:03, 50.56it/s, Epoch: 14, Batch: 188,Loss: -2.445,Avg.Loss: -1.830,LR: 1.18E-04]Training epoch 14:  55%|█████▌    | 188/341 [00:03<00:03, 50.56it/s, Epoch: 14, Batch: 189,Loss: -1.931,Avg.Loss: -1.830,LR: 1.18E-04]Training epoch 14:  55%|█████▌    | 189/341 [00:03<00:03, 50.56it/s, Epoch: 14, Batch: 190,Loss: -2.009,Avg.Loss: -1.831,LR: 1.17E-04]Training epoch 14:  56%|█████▌    | 190/341 [00:03<00:02, 50.56it/s, Epoch: 14, Batch: 191,Loss: -2.256,Avg.Loss: -1.833,LR: 1.17E-04]Training epoch 14:  56%|█████▌    | 191/341 [00:03<00:02, 50.56it/s, Epoch: 14, Batch: 192,Loss: -1.564,Avg.Loss: -1.832,LR: 1.17E-04]Training epoch 14:  56%|█████▋    | 192/341 [00:03<00:02, 50.56it/s, Epoch: 14, Batch: 193,Loss: -1.027,Avg.Loss: -1.828,LR: 1.17E-04]Training epoch 14:  57%|█████▋    | 193/341 [00:03<00:02, 50.87it/s, Epoch: 14, Batch: 193,Loss: -1.027,Avg.Loss: -1.828,LR: 1.17E-04]Training epoch 14:  57%|█████▋    | 193/341 [00:03<00:02, 50.87it/s, Epoch: 14, Batch: 194,Loss: -0.762,Avg.Loss: -1.822,LR: 1.17E-04]Training epoch 14:  57%|█████▋    | 194/341 [00:03<00:02, 50.87it/s, Epoch: 14, Batch: 195,Loss: -1.485,Avg.Loss: -1.821,LR: 1.17E-04]Training epoch 14:  57%|█████▋    | 195/341 [00:03<00:02, 50.87it/s, Epoch: 14, Batch: 196,Loss: -1.908,Avg.Loss: -1.821,LR: 1.17E-04]Training epoch 14:  57%|█████▋    | 196/341 [00:03<00:02, 50.87it/s, Epoch: 14, Batch: 197,Loss: -0.790,Avg.Loss: -1.816,LR: 1.17E-04]Training epoch 14:  58%|█████▊    | 197/341 [00:03<00:02, 50.87it/s, Epoch: 14, Batch: 198,Loss: -1.746,Avg.Loss: -1.815,LR: 1.17E-04]Training epoch 14:  58%|█████▊    | 198/341 [00:03<00:02, 50.87it/s, Epoch: 14, Batch: 199,Loss: -2.414,Avg.Loss: -1.818,LR: 1.17E-04]Training epoch 14:  58%|█████▊    | 199/341 [00:03<00:02, 51.09it/s, Epoch: 14, Batch: 199,Loss: -2.414,Avg.Loss: -1.818,LR: 1.17E-04]Training epoch 14:  58%|█████▊    | 199/341 [00:03<00:02, 51.09it/s, Epoch: 14, Batch: 200,Loss: -1.948,Avg.Loss: -1.819,LR: 1.16E-04]Training epoch 14:  59%|█████▊    | 200/341 [00:03<00:02, 51.09it/s, Epoch: 14, Batch: 201,Loss: -1.957,Avg.Loss: -1.820,LR: 1.16E-04]Training epoch 14:  59%|█████▉    | 201/341 [00:03<00:02, 51.09it/s, Epoch: 14, Batch: 202,Loss: -2.261,Avg.Loss: -1.822,LR: 1.16E-04]Training epoch 14:  59%|█████▉    | 202/341 [00:03<00:02, 51.09it/s, Epoch: 14, Batch: 203,Loss: -2.418,Avg.Loss: -1.825,LR: 1.16E-04]Training epoch 14:  60%|█████▉    | 203/341 [00:03<00:02, 51.09it/s, Epoch: 14, Batch: 204,Loss: -2.521,Avg.Loss: -1.828,LR: 1.16E-04]Training epoch 14:  60%|█████▉    | 204/341 [00:03<00:02, 51.09it/s, Epoch: 14, Batch: 205,Loss: -2.216,Avg.Loss: -1.830,LR: 1.16E-04]Training epoch 14:  60%|██████    | 205/341 [00:03<00:02, 51.46it/s, Epoch: 14, Batch: 205,Loss: -2.216,Avg.Loss: -1.830,LR: 1.16E-04]Training epoch 14:  60%|██████    | 205/341 [00:03<00:02, 51.46it/s, Epoch: 14, Batch: 206,Loss: -2.533,Avg.Loss: -1.834,LR: 1.16E-04]Training epoch 14:  60%|██████    | 206/341 [00:03<00:02, 51.46it/s, Epoch: 14, Batch: 207,Loss: -1.990,Avg.Loss: -1.834,LR: 1.16E-04]Training epoch 14:  61%|██████    | 207/341 [00:03<00:02, 51.46it/s, Epoch: 14, Batch: 208,Loss: -2.454,Avg.Loss: -1.837,LR: 1.16E-04]Training epoch 14:  61%|██████    | 208/341 [00:03<00:02, 51.46it/s, Epoch: 14, Batch: 209,Loss: -2.049,Avg.Loss: -1.838,LR: 1.16E-04]Training epoch 14:  61%|██████▏   | 209/341 [00:03<00:02, 51.46it/s, Epoch: 14, Batch: 210,Loss: -1.991,Avg.Loss: -1.839,LR: 1.16E-04]Training epoch 14:  62%|██████▏   | 210/341 [00:04<00:02, 51.46it/s, Epoch: 14, Batch: 211,Loss: -2.719,Avg.Loss: -1.843,LR: 1.15E-04]Training epoch 14:  62%|██████▏   | 211/341 [00:04<00:02, 51.74it/s, Epoch: 14, Batch: 211,Loss: -2.719,Avg.Loss: -1.843,LR: 1.15E-04]Training epoch 14:  62%|██████▏   | 211/341 [00:04<00:02, 51.74it/s, Epoch: 14, Batch: 212,Loss: -2.441,Avg.Loss: -1.846,LR: 1.15E-04]Training epoch 14:  62%|██████▏   | 212/341 [00:04<00:02, 51.74it/s, Epoch: 14, Batch: 213,Loss: -2.083,Avg.Loss: -1.847,LR: 1.15E-04]Training epoch 14:  62%|██████▏   | 213/341 [00:04<00:02, 51.74it/s, Epoch: 14, Batch: 214,Loss: -1.961,Avg.Loss: -1.848,LR: 1.15E-04]Training epoch 14:  63%|██████▎   | 214/341 [00:04<00:02, 51.74it/s, Epoch: 14, Batch: 215,Loss: -2.435,Avg.Loss: -1.850,LR: 1.15E-04]Training epoch 14:  63%|██████▎   | 215/341 [00:04<00:02, 51.74it/s, Epoch: 14, Batch: 216,Loss: -2.415,Avg.Loss: -1.853,LR: 1.15E-04]Training epoch 14:  63%|██████▎   | 216/341 [00:04<00:02, 51.74it/s, Epoch: 14, Batch: 217,Loss: -2.485,Avg.Loss: -1.856,LR: 1.15E-04]Training epoch 14:  64%|██████▎   | 217/341 [00:04<00:02, 51.55it/s, Epoch: 14, Batch: 217,Loss: -2.485,Avg.Loss: -1.856,LR: 1.15E-04]Training epoch 14:  64%|██████▎   | 217/341 [00:04<00:02, 51.55it/s, Epoch: 14, Batch: 218,Loss: -2.060,Avg.Loss: -1.857,LR: 1.15E-04]Training epoch 14:  64%|██████▍   | 218/341 [00:04<00:02, 51.55it/s, Epoch: 14, Batch: 219,Loss: -1.350,Avg.Loss: -1.855,LR: 1.15E-04]Training epoch 14:  64%|██████▍   | 219/341 [00:04<00:02, 51.55it/s, Epoch: 14, Batch: 220,Loss: -2.090,Avg.Loss: -1.856,LR: 1.15E-04]Training epoch 14:  65%|██████▍   | 220/341 [00:04<00:02, 51.55it/s, Epoch: 14, Batch: 221,Loss: -1.893,Avg.Loss: -1.856,LR: 1.14E-04]Training epoch 14:  65%|██████▍   | 221/341 [00:04<00:02, 51.55it/s, Epoch: 14, Batch: 222,Loss: -1.663,Avg.Loss: -1.855,LR: 1.14E-04]Training epoch 14:  65%|██████▌   | 222/341 [00:04<00:02, 51.55it/s, Epoch: 14, Batch: 223,Loss: -0.800,Avg.Loss: -1.850,LR: 1.14E-04]Training epoch 14:  65%|██████▌   | 223/341 [00:04<00:02, 51.79it/s, Epoch: 14, Batch: 223,Loss: -0.800,Avg.Loss: -1.850,LR: 1.14E-04]Training epoch 14:  65%|██████▌   | 223/341 [00:04<00:02, 51.79it/s, Epoch: 14, Batch: 224,Loss: -0.349,Avg.Loss: -1.843,LR: 1.14E-04]Training epoch 14:  66%|██████▌   | 224/341 [00:04<00:02, 51.79it/s, Epoch: 14, Batch: 225,Loss: -1.725,Avg.Loss: -1.843,LR: 1.14E-04]Training epoch 14:  66%|██████▌   | 225/341 [00:04<00:02, 51.79it/s, Epoch: 14, Batch: 226,Loss: -2.161,Avg.Loss: -1.844,LR: 1.14E-04]Training epoch 14:  66%|██████▋   | 226/341 [00:04<00:02, 51.79it/s, Epoch: 14, Batch: 227,Loss: -1.760,Avg.Loss: -1.844,LR: 1.14E-04]Training epoch 14:  67%|██████▋   | 227/341 [00:04<00:02, 51.79it/s, Epoch: 14, Batch: 228,Loss: -0.605,Avg.Loss: -1.839,LR: 1.14E-04]Training epoch 14:  67%|██████▋   | 228/341 [00:04<00:02, 51.79it/s, Epoch: 14, Batch: 229,Loss: -0.600,Avg.Loss: -1.833,LR: 1.14E-04]Training epoch 14:  67%|██████▋   | 229/341 [00:04<00:02, 52.01it/s, Epoch: 14, Batch: 229,Loss: -0.600,Avg.Loss: -1.833,LR: 1.14E-04]Training epoch 14:  67%|██████▋   | 229/341 [00:04<00:02, 52.01it/s, Epoch: 14, Batch: 230,Loss: -0.960,Avg.Loss: -1.829,LR: 1.14E-04]Training epoch 14:  67%|██████▋   | 230/341 [00:04<00:02, 52.01it/s, Epoch: 14, Batch: 231,Loss: -1.493,Avg.Loss: -1.828,LR: 1.13E-04]Training epoch 14:  68%|██████▊   | 231/341 [00:04<00:02, 52.01it/s, Epoch: 14, Batch: 232,Loss: -1.771,Avg.Loss: -1.828,LR: 1.13E-04]Training epoch 14:  68%|██████▊   | 232/341 [00:04<00:02, 52.01it/s, Epoch: 14, Batch: 233,Loss: -1.154,Avg.Loss: -1.825,LR: 1.13E-04]Training epoch 14:  68%|██████▊   | 233/341 [00:04<00:02, 52.01it/s, Epoch: 14, Batch: 234,Loss: -2.272,Avg.Loss: -1.827,LR: 1.13E-04]Training epoch 14:  69%|██████▊   | 234/341 [00:04<00:02, 52.01it/s, Epoch: 14, Batch: 235,Loss: -2.473,Avg.Loss: -1.829,LR: 1.13E-04]Training epoch 14:  69%|██████▉   | 235/341 [00:04<00:02, 51.81it/s, Epoch: 14, Batch: 235,Loss: -2.473,Avg.Loss: -1.829,LR: 1.13E-04]Training epoch 14:  69%|██████▉   | 235/341 [00:04<00:02, 51.81it/s, Epoch: 14, Batch: 236,Loss: -2.178,Avg.Loss: -1.831,LR: 1.13E-04]Training epoch 14:  69%|██████▉   | 236/341 [00:04<00:02, 51.81it/s, Epoch: 14, Batch: 237,Loss: -2.034,Avg.Loss: -1.832,LR: 1.13E-04]Training epoch 14:  70%|██████▉   | 237/341 [00:04<00:02, 51.81it/s, Epoch: 14, Batch: 238,Loss: -1.911,Avg.Loss: -1.832,LR: 1.13E-04]Training epoch 14:  70%|██████▉   | 238/341 [00:04<00:01, 51.81it/s, Epoch: 14, Batch: 239,Loss: -2.314,Avg.Loss: -1.834,LR: 1.13E-04]Training epoch 14:  70%|███████   | 239/341 [00:04<00:01, 51.81it/s, Epoch: 14, Batch: 240,Loss: -2.432,Avg.Loss: -1.837,LR: 1.13E-04]Training epoch 14:  70%|███████   | 240/341 [00:04<00:01, 51.81it/s, Epoch: 14, Batch: 241,Loss: -2.257,Avg.Loss: -1.838,LR: 1.13E-04]Training epoch 14:  71%|███████   | 241/341 [00:04<00:01, 52.02it/s, Epoch: 14, Batch: 241,Loss: -2.257,Avg.Loss: -1.838,LR: 1.13E-04]Training epoch 14:  71%|███████   | 241/341 [00:04<00:01, 52.02it/s, Epoch: 14, Batch: 242,Loss: -1.839,Avg.Loss: -1.838,LR: 1.12E-04]Training epoch 14:  71%|███████   | 242/341 [00:04<00:01, 52.02it/s, Epoch: 14, Batch: 243,Loss: -2.136,Avg.Loss: -1.840,LR: 1.12E-04]Training epoch 14:  71%|███████▏  | 243/341 [00:04<00:01, 52.02it/s, Epoch: 14, Batch: 244,Loss: -2.058,Avg.Loss: -1.840,LR: 1.12E-04]Training epoch 14:  72%|███████▏  | 244/341 [00:04<00:01, 52.02it/s, Epoch: 14, Batch: 245,Loss: -1.933,Avg.Loss: -1.841,LR: 1.12E-04]Training epoch 14:  72%|███████▏  | 245/341 [00:04<00:01, 52.02it/s, Epoch: 14, Batch: 246,Loss: -2.052,Avg.Loss: -1.842,LR: 1.12E-04]Training epoch 14:  72%|███████▏  | 246/341 [00:04<00:01, 52.02it/s, Epoch: 14, Batch: 247,Loss: -2.330,Avg.Loss: -1.844,LR: 1.12E-04]Training epoch 14:  72%|███████▏  | 247/341 [00:04<00:01, 51.80it/s, Epoch: 14, Batch: 247,Loss: -2.330,Avg.Loss: -1.844,LR: 1.12E-04]Training epoch 14:  72%|███████▏  | 247/341 [00:04<00:01, 51.80it/s, Epoch: 14, Batch: 248,Loss: -2.237,Avg.Loss: -1.845,LR: 1.12E-04]Training epoch 14:  73%|███████▎  | 248/341 [00:04<00:01, 51.80it/s, Epoch: 14, Batch: 249,Loss: -2.442,Avg.Loss: -1.848,LR: 1.12E-04]Training epoch 14:  73%|███████▎  | 249/341 [00:04<00:01, 51.80it/s, Epoch: 14, Batch: 250,Loss: -2.130,Avg.Loss: -1.849,LR: 1.12E-04]Training epoch 14:  73%|███████▎  | 250/341 [00:04<00:01, 51.80it/s, Epoch: 14, Batch: 251,Loss: -2.257,Avg.Loss: -1.850,LR: 1.12E-04]Training epoch 14:  74%|███████▎  | 251/341 [00:04<00:01, 51.80it/s, Epoch: 14, Batch: 252,Loss: -2.248,Avg.Loss: -1.852,LR: 1.11E-04]Training epoch 14:  74%|███████▍  | 252/341 [00:04<00:01, 51.80it/s, Epoch: 14, Batch: 253,Loss: -2.276,Avg.Loss: -1.854,LR: 1.11E-04]Training epoch 14:  74%|███████▍  | 253/341 [00:04<00:01, 51.78it/s, Epoch: 14, Batch: 253,Loss: -2.276,Avg.Loss: -1.854,LR: 1.11E-04]Training epoch 14:  74%|███████▍  | 253/341 [00:04<00:01, 51.78it/s, Epoch: 14, Batch: 254,Loss: -1.891,Avg.Loss: -1.854,LR: 1.11E-04]Training epoch 14:  74%|███████▍  | 254/341 [00:04<00:01, 51.78it/s, Epoch: 14, Batch: 255,Loss: -1.725,Avg.Loss: -1.853,LR: 1.11E-04]Training epoch 14:  75%|███████▍  | 255/341 [00:04<00:01, 51.78it/s, Epoch: 14, Batch: 256,Loss: -2.346,Avg.Loss: -1.855,LR: 1.11E-04]Training epoch 14:  75%|███████▌  | 256/341 [00:04<00:01, 51.78it/s, Epoch: 14, Batch: 257,Loss: -2.117,Avg.Loss: -1.856,LR: 1.11E-04]Training epoch 14:  75%|███████▌  | 257/341 [00:04<00:01, 51.78it/s, Epoch: 14, Batch: 258,Loss: -1.845,Avg.Loss: -1.856,LR: 1.11E-04]Training epoch 14:  76%|███████▌  | 258/341 [00:04<00:01, 51.78it/s, Epoch: 14, Batch: 259,Loss: -1.719,Avg.Loss: -1.856,LR: 1.11E-04]Training epoch 14:  76%|███████▌  | 259/341 [00:04<00:01, 52.11it/s, Epoch: 14, Batch: 259,Loss: -1.719,Avg.Loss: -1.856,LR: 1.11E-04]Training epoch 14:  76%|███████▌  | 259/341 [00:04<00:01, 52.11it/s, Epoch: 14, Batch: 260,Loss: -1.875,Avg.Loss: -1.856,LR: 1.11E-04]Training epoch 14:  76%|███████▌  | 260/341 [00:04<00:01, 52.11it/s, Epoch: 14, Batch: 261,Loss: -2.061,Avg.Loss: -1.857,LR: 1.11E-04]Training epoch 14:  77%|███████▋  | 261/341 [00:04<00:01, 52.11it/s, Epoch: 14, Batch: 262,Loss: -2.166,Avg.Loss: -1.858,LR: 1.11E-04]Training epoch 14:  77%|███████▋  | 262/341 [00:05<00:01, 52.11it/s, Epoch: 14, Batch: 263,Loss: -1.980,Avg.Loss: -1.858,LR: 1.10E-04]Training epoch 14:  77%|███████▋  | 263/341 [00:05<00:01, 52.11it/s, Epoch: 14, Batch: 264,Loss: -2.453,Avg.Loss: -1.860,LR: 1.10E-04]Training epoch 14:  77%|███████▋  | 264/341 [00:05<00:01, 52.11it/s, Epoch: 14, Batch: 265,Loss: -2.331,Avg.Loss: -1.862,LR: 1.10E-04]Training epoch 14:  78%|███████▊  | 265/341 [00:05<00:01, 52.28it/s, Epoch: 14, Batch: 265,Loss: -2.331,Avg.Loss: -1.862,LR: 1.10E-04]Training epoch 14:  78%|███████▊  | 265/341 [00:05<00:01, 52.28it/s, Epoch: 14, Batch: 266,Loss: -2.487,Avg.Loss: -1.865,LR: 1.10E-04]Training epoch 14:  78%|███████▊  | 266/341 [00:05<00:01, 52.28it/s, Epoch: 14, Batch: 267,Loss: -2.215,Avg.Loss: -1.866,LR: 1.10E-04]Training epoch 14:  78%|███████▊  | 267/341 [00:05<00:01, 52.28it/s, Epoch: 14, Batch: 268,Loss: -2.474,Avg.Loss: -1.868,LR: 1.10E-04]Training epoch 14:  79%|███████▊  | 268/341 [00:05<00:01, 52.28it/s, Epoch: 14, Batch: 269,Loss: -2.013,Avg.Loss: -1.869,LR: 1.10E-04]Training epoch 14:  79%|███████▉  | 269/341 [00:05<00:01, 52.28it/s, Epoch: 14, Batch: 270,Loss: -2.386,Avg.Loss: -1.871,LR: 1.10E-04]Training epoch 14:  79%|███████▉  | 270/341 [00:05<00:01, 52.28it/s, Epoch: 14, Batch: 271,Loss: -2.497,Avg.Loss: -1.873,LR: 1.10E-04]Training epoch 14:  79%|███████▉  | 271/341 [00:05<00:01, 52.05it/s, Epoch: 14, Batch: 271,Loss: -2.497,Avg.Loss: -1.873,LR: 1.10E-04]Training epoch 14:  79%|███████▉  | 271/341 [00:05<00:01, 52.05it/s, Epoch: 14, Batch: 272,Loss: -1.712,Avg.Loss: -1.872,LR: 1.10E-04]Training epoch 14:  80%|███████▉  | 272/341 [00:05<00:01, 52.05it/s, Epoch: 14, Batch: 273,Loss: -2.231,Avg.Loss: -1.874,LR: 1.09E-04]Training epoch 14:  80%|████████  | 273/341 [00:05<00:01, 52.05it/s, Epoch: 14, Batch: 274,Loss: -2.545,Avg.Loss: -1.876,LR: 1.09E-04]Training epoch 14:  80%|████████  | 274/341 [00:05<00:01, 52.05it/s, Epoch: 14, Batch: 275,Loss: -2.601,Avg.Loss: -1.879,LR: 1.09E-04]Training epoch 14:  81%|████████  | 275/341 [00:05<00:01, 52.05it/s, Epoch: 14, Batch: 276,Loss: -2.021,Avg.Loss: -1.879,LR: 1.09E-04]Training epoch 14:  81%|████████  | 276/341 [00:05<00:01, 52.05it/s, Epoch: 14, Batch: 277,Loss: -2.177,Avg.Loss: -1.880,LR: 1.09E-04]Training epoch 14:  81%|████████  | 277/341 [00:05<00:01, 51.76it/s, Epoch: 14, Batch: 277,Loss: -2.177,Avg.Loss: -1.880,LR: 1.09E-04]Training epoch 14:  81%|████████  | 277/341 [00:05<00:01, 51.76it/s, Epoch: 14, Batch: 278,Loss: -2.011,Avg.Loss: -1.881,LR: 1.09E-04]Training epoch 14:  82%|████████▏ | 278/341 [00:05<00:01, 51.76it/s, Epoch: 14, Batch: 279,Loss: -2.118,Avg.Loss: -1.882,LR: 1.09E-04]Training epoch 14:  82%|████████▏ | 279/341 [00:05<00:01, 51.76it/s, Epoch: 14, Batch: 280,Loss: -2.448,Avg.Loss: -1.884,LR: 1.09E-04]Training epoch 14:  82%|████████▏ | 280/341 [00:05<00:01, 51.76it/s, Epoch: 14, Batch: 281,Loss: -1.923,Avg.Loss: -1.884,LR: 1.09E-04]Training epoch 14:  82%|████████▏ | 281/341 [00:05<00:01, 51.76it/s, Epoch: 14, Batch: 282,Loss: -2.000,Avg.Loss: -1.884,LR: 1.09E-04]Training epoch 14:  83%|████████▎ | 282/341 [00:05<00:01, 51.76it/s, Epoch: 14, Batch: 283,Loss: -2.209,Avg.Loss: -1.885,LR: 1.09E-04]Training epoch 14:  83%|████████▎ | 283/341 [00:05<00:01, 52.15it/s, Epoch: 14, Batch: 283,Loss: -2.209,Avg.Loss: -1.885,LR: 1.09E-04]Training epoch 14:  83%|████████▎ | 283/341 [00:05<00:01, 52.15it/s, Epoch: 14, Batch: 284,Loss: -2.157,Avg.Loss: -1.886,LR: 1.08E-04]Training epoch 14:  83%|████████▎ | 284/341 [00:05<00:01, 52.15it/s, Epoch: 14, Batch: 285,Loss: -2.490,Avg.Loss: -1.888,LR: 1.08E-04]Training epoch 14:  84%|████████▎ | 285/341 [00:05<00:01, 52.15it/s, Epoch: 14, Batch: 286,Loss: -2.574,Avg.Loss: -1.891,LR: 1.08E-04]Training epoch 14:  84%|████████▍ | 286/341 [00:05<00:01, 52.15it/s, Epoch: 14, Batch: 287,Loss: -2.438,Avg.Loss: -1.893,LR: 1.08E-04]Training epoch 14:  84%|████████▍ | 287/341 [00:05<00:01, 52.15it/s, Epoch: 14, Batch: 288,Loss: -2.437,Avg.Loss: -1.895,LR: 1.08E-04]Training epoch 14:  84%|████████▍ | 288/341 [00:05<00:01, 52.15it/s, Epoch: 14, Batch: 289,Loss: -1.695,Avg.Loss: -1.894,LR: 1.08E-04]Training epoch 14:  85%|████████▍ | 289/341 [00:05<00:00, 52.45it/s, Epoch: 14, Batch: 289,Loss: -1.695,Avg.Loss: -1.894,LR: 1.08E-04]Training epoch 14:  85%|████████▍ | 289/341 [00:05<00:00, 52.45it/s, Epoch: 14, Batch: 290,Loss: -2.568,Avg.Loss: -1.896,LR: 1.08E-04]Training epoch 14:  85%|████████▌ | 290/341 [00:05<00:00, 52.45it/s, Epoch: 14, Batch: 291,Loss: -2.440,Avg.Loss: -1.898,LR: 1.08E-04]Training epoch 14:  85%|████████▌ | 291/341 [00:05<00:00, 52.45it/s, Epoch: 14, Batch: 292,Loss: -1.962,Avg.Loss: -1.898,LR: 1.08E-04]Training epoch 14:  86%|████████▌ | 292/341 [00:05<00:00, 52.45it/s, Epoch: 14, Batch: 293,Loss: -2.169,Avg.Loss: -1.899,LR: 1.08E-04]Training epoch 14:  86%|████████▌ | 293/341 [00:05<00:00, 52.45it/s, Epoch: 14, Batch: 294,Loss: -2.264,Avg.Loss: -1.901,LR: 1.07E-04]Training epoch 14:  86%|████████▌ | 294/341 [00:05<00:00, 52.45it/s, Epoch: 14, Batch: 295,Loss: -2.013,Avg.Loss: -1.901,LR: 1.07E-04]Training epoch 14:  87%|████████▋ | 295/341 [00:05<00:00, 53.36it/s, Epoch: 14, Batch: 295,Loss: -2.013,Avg.Loss: -1.901,LR: 1.07E-04]Training epoch 14:  87%|████████▋ | 295/341 [00:05<00:00, 53.36it/s, Epoch: 14, Batch: 296,Loss: -2.001,Avg.Loss: -1.901,LR: 1.07E-04]Training epoch 14:  87%|████████▋ | 296/341 [00:05<00:00, 53.36it/s, Epoch: 14, Batch: 297,Loss: -2.293,Avg.Loss: -1.903,LR: 1.07E-04]Training epoch 14:  87%|████████▋ | 297/341 [00:05<00:00, 53.36it/s, Epoch: 14, Batch: 298,Loss: -1.982,Avg.Loss: -1.903,LR: 1.07E-04]Training epoch 14:  87%|████████▋ | 298/341 [00:05<00:00, 53.36it/s, Epoch: 14, Batch: 299,Loss: -1.542,Avg.Loss: -1.902,LR: 1.07E-04]Training epoch 14:  88%|████████▊ | 299/341 [00:05<00:00, 53.36it/s, Epoch: 14, Batch: 300,Loss: -1.743,Avg.Loss: -1.901,LR: 1.07E-04]Training epoch 14:  88%|████████▊ | 300/341 [00:05<00:00, 53.36it/s, Epoch: 14, Batch: 301,Loss: -2.417,Avg.Loss: -1.903,LR: 1.07E-04]Training epoch 14:  88%|████████▊ | 301/341 [00:05<00:00, 54.00it/s, Epoch: 14, Batch: 301,Loss: -2.417,Avg.Loss: -1.903,LR: 1.07E-04]Training epoch 14:  88%|████████▊ | 301/341 [00:05<00:00, 54.00it/s, Epoch: 14, Batch: 302,Loss: -1.910,Avg.Loss: -1.903,LR: 1.07E-04]Training epoch 14:  89%|████████▊ | 302/341 [00:05<00:00, 54.00it/s, Epoch: 14, Batch: 303,Loss: -1.398,Avg.Loss: -1.901,LR: 1.07E-04]Training epoch 14:  89%|████████▉ | 303/341 [00:05<00:00, 54.00it/s, Epoch: 14, Batch: 304,Loss: -0.923,Avg.Loss: -1.898,LR: 1.07E-04]Training epoch 14:  89%|████████▉ | 304/341 [00:05<00:00, 54.00it/s, Epoch: 14, Batch: 305,Loss: -1.811,Avg.Loss: -1.898,LR: 1.06E-04]Training epoch 14:  89%|████████▉ | 305/341 [00:05<00:00, 54.00it/s, Epoch: 14, Batch: 306,Loss: -2.211,Avg.Loss: -1.899,LR: 1.06E-04]Training epoch 14:  90%|████████▉ | 306/341 [00:05<00:00, 54.00it/s, Epoch: 14, Batch: 307,Loss: -2.394,Avg.Loss: -1.900,LR: 1.06E-04]Training epoch 14:  90%|█████████ | 307/341 [00:05<00:00, 54.19it/s, Epoch: 14, Batch: 307,Loss: -2.394,Avg.Loss: -1.900,LR: 1.06E-04]Training epoch 14:  90%|█████████ | 307/341 [00:05<00:00, 54.19it/s, Epoch: 14, Batch: 308,Loss: -2.464,Avg.Loss: -1.902,LR: 1.06E-04]Training epoch 14:  90%|█████████ | 308/341 [00:05<00:00, 54.19it/s, Epoch: 14, Batch: 309,Loss: -2.654,Avg.Loss: -1.905,LR: 1.06E-04]Training epoch 14:  91%|█████████ | 309/341 [00:05<00:00, 54.19it/s, Epoch: 14, Batch: 310,Loss: -2.091,Avg.Loss: -1.905,LR: 1.06E-04]Training epoch 14:  91%|█████████ | 310/341 [00:05<00:00, 54.19it/s, Epoch: 14, Batch: 311,Loss: -1.732,Avg.Loss: -1.905,LR: 1.06E-04]Training epoch 14:  91%|█████████ | 311/341 [00:05<00:00, 54.19it/s, Epoch: 14, Batch: 312,Loss: -2.178,Avg.Loss: -1.905,LR: 1.06E-04]Training epoch 14:  91%|█████████▏| 312/341 [00:05<00:00, 54.19it/s, Epoch: 14, Batch: 313,Loss: -1.965,Avg.Loss: -1.906,LR: 1.06E-04]Training epoch 14:  92%|█████████▏| 313/341 [00:05<00:00, 54.51it/s, Epoch: 14, Batch: 313,Loss: -1.965,Avg.Loss: -1.906,LR: 1.06E-04]Training epoch 14:  92%|█████████▏| 313/341 [00:05<00:00, 54.51it/s, Epoch: 14, Batch: 314,Loss: -2.006,Avg.Loss: -1.906,LR: 1.06E-04]Training epoch 14:  92%|█████████▏| 314/341 [00:05<00:00, 54.51it/s, Epoch: 14, Batch: 315,Loss: -2.460,Avg.Loss: -1.908,LR: 1.05E-04]Training epoch 14:  92%|█████████▏| 315/341 [00:06<00:00, 54.51it/s, Epoch: 14, Batch: 316,Loss: -2.190,Avg.Loss: -1.909,LR: 1.05E-04]Training epoch 14:  93%|█████████▎| 316/341 [00:06<00:00, 54.51it/s, Epoch: 14, Batch: 317,Loss: -1.905,Avg.Loss: -1.909,LR: 1.05E-04]Training epoch 14:  93%|█████████▎| 317/341 [00:06<00:00, 54.51it/s, Epoch: 14, Batch: 318,Loss: -2.257,Avg.Loss: -1.910,LR: 1.05E-04]Training epoch 14:  93%|█████████▎| 318/341 [00:06<00:00, 54.51it/s, Epoch: 14, Batch: 319,Loss: -2.410,Avg.Loss: -1.911,LR: 1.05E-04]Training epoch 14:  94%|█████████▎| 319/341 [00:06<00:00, 52.55it/s, Epoch: 14, Batch: 319,Loss: -2.410,Avg.Loss: -1.911,LR: 1.05E-04]Training epoch 14:  94%|█████████▎| 319/341 [00:06<00:00, 52.55it/s, Epoch: 14, Batch: 320,Loss: -2.636,Avg.Loss: -1.914,LR: 1.05E-04]Training epoch 14:  94%|█████████▍| 320/341 [00:06<00:00, 52.55it/s, Epoch: 14, Batch: 321,Loss: -2.677,Avg.Loss: -1.916,LR: 1.05E-04]Training epoch 14:  94%|█████████▍| 321/341 [00:06<00:00, 52.55it/s, Epoch: 14, Batch: 322,Loss: -2.304,Avg.Loss: -1.917,LR: 1.05E-04]Training epoch 14:  94%|█████████▍| 322/341 [00:06<00:00, 52.55it/s, Epoch: 14, Batch: 323,Loss: -2.261,Avg.Loss: -1.918,LR: 1.05E-04]Training epoch 14:  95%|█████████▍| 323/341 [00:06<00:00, 52.55it/s, Epoch: 14, Batch: 324,Loss: -1.207,Avg.Loss: -1.916,LR: 1.05E-04]Training epoch 14:  95%|█████████▌| 324/341 [00:06<00:00, 52.55it/s, Epoch: 14, Batch: 325,Loss: -1.829,Avg.Loss: -1.916,LR: 1.05E-04]Training epoch 14:  95%|█████████▌| 325/341 [00:06<00:00, 53.96it/s, Epoch: 14, Batch: 325,Loss: -1.829,Avg.Loss: -1.916,LR: 1.05E-04]Training epoch 14:  95%|█████████▌| 325/341 [00:06<00:00, 53.96it/s, Epoch: 14, Batch: 326,Loss: -1.698,Avg.Loss: -1.915,LR: 1.04E-04]Training epoch 14:  96%|█████████▌| 326/341 [00:06<00:00, 53.96it/s, Epoch: 14, Batch: 327,Loss: -1.729,Avg.Loss: -1.915,LR: 1.04E-04]Training epoch 14:  96%|█████████▌| 327/341 [00:06<00:00, 53.96it/s, Epoch: 14, Batch: 328,Loss: -1.825,Avg.Loss: -1.914,LR: 1.04E-04]Training epoch 14:  96%|█████████▌| 328/341 [00:06<00:00, 53.96it/s, Epoch: 14, Batch: 329,Loss: -1.529,Avg.Loss: -1.913,LR: 1.04E-04]Training epoch 14:  96%|█████████▋| 329/341 [00:06<00:00, 53.96it/s, Epoch: 14, Batch: 330,Loss: -2.422,Avg.Loss: -1.915,LR: 1.04E-04]Training epoch 14:  97%|█████████▋| 330/341 [00:06<00:00, 53.96it/s, Epoch: 14, Batch: 331,Loss: -2.289,Avg.Loss: -1.916,LR: 1.04E-04]Training epoch 14:  97%|█████████▋| 331/341 [00:06<00:00, 53.99it/s, Epoch: 14, Batch: 331,Loss: -2.289,Avg.Loss: -1.916,LR: 1.04E-04]Training epoch 14:  97%|█████████▋| 331/341 [00:06<00:00, 53.99it/s, Epoch: 14, Batch: 332,Loss: -1.890,Avg.Loss: -1.916,LR: 1.04E-04]Training epoch 14:  97%|█████████▋| 332/341 [00:06<00:00, 53.99it/s, Epoch: 14, Batch: 333,Loss: -2.118,Avg.Loss: -1.916,LR: 1.04E-04]Training epoch 14:  98%|█████████▊| 333/341 [00:06<00:00, 53.99it/s, Epoch: 14, Batch: 334,Loss: -1.911,Avg.Loss: -1.916,LR: 1.04E-04]Training epoch 14:  98%|█████████▊| 334/341 [00:06<00:00, 53.99it/s, Epoch: 14, Batch: 335,Loss: -1.966,Avg.Loss: -1.916,LR: 1.04E-04]Training epoch 14:  98%|█████████▊| 335/341 [00:06<00:00, 53.99it/s, Epoch: 14, Batch: 336,Loss: -1.768,Avg.Loss: -1.916,LR: 1.04E-04]Training epoch 14:  99%|█████████▊| 336/341 [00:06<00:00, 53.99it/s, Epoch: 14, Batch: 337,Loss: -2.464,Avg.Loss: -1.918,LR: 1.03E-04]Training epoch 14:  99%|█████████▉| 337/341 [00:06<00:00, 54.03it/s, Epoch: 14, Batch: 337,Loss: -2.464,Avg.Loss: -1.918,LR: 1.03E-04]Training epoch 14:  99%|█████████▉| 337/341 [00:06<00:00, 54.03it/s, Epoch: 14, Batch: 338,Loss: -2.137,Avg.Loss: -1.918,LR: 1.03E-04]Training epoch 14:  99%|█████████▉| 338/341 [00:06<00:00, 54.03it/s, Epoch: 14, Batch: 339,Loss: -2.107,Avg.Loss: -1.919,LR: 1.03E-04]Training epoch 14:  99%|█████████▉| 339/341 [00:06<00:00, 54.03it/s, Epoch: 14, Batch: 340,Loss: -1.472,Avg.Loss: -1.917,LR: 1.03E-04]Training epoch 14: 100%|█████████▉| 340/341 [00:06<00:00, 54.03it/s, Epoch: 14, Batch: 341,Loss: -1.876,Avg.Loss: -1.917,LR: 1.03E-04]Training epoch 14: 100%|██████████| 341/341 [00:06<00:00, 52.72it/s, Epoch: 14, Batch: 341,Loss: -1.876,Avg.Loss: -1.917,LR: 1.03E-04]
Training epoch 15:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 15:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 15, Batch: 1,Loss: -1.581,Avg.Loss: -1.581,LR: 1.03E-04]Training epoch 15:   0%|          | 1/341 [00:00<00:12, 26.92it/s, Epoch: 15, Batch: 2,Loss: -1.401,Avg.Loss: -1.491,LR: 1.03E-04]Training epoch 15:   1%|          | 2/341 [00:00<00:09, 35.57it/s, Epoch: 15, Batch: 3,Loss: -2.052,Avg.Loss: -1.678,LR: 1.03E-04]Training epoch 15:   1%|          | 3/341 [00:00<00:08, 37.84it/s, Epoch: 15, Batch: 4,Loss: -2.705,Avg.Loss: -1.935,LR: 1.03E-04]Training epoch 15:   1%|          | 4/341 [00:00<00:08, 39.69it/s, Epoch: 15, Batch: 5,Loss: -2.324,Avg.Loss: -2.013,LR: 1.03E-04]Training epoch 15:   1%|▏         | 5/341 [00:00<00:06, 49.51it/s, Epoch: 15, Batch: 5,Loss: -2.324,Avg.Loss: -2.013,LR: 1.03E-04]Training epoch 15:   1%|▏         | 5/341 [00:00<00:06, 49.51it/s, Epoch: 15, Batch: 6,Loss: -2.586,Avg.Loss: -2.108,LR: 1.02E-04]Training epoch 15:   2%|▏         | 6/341 [00:00<00:06, 49.51it/s, Epoch: 15, Batch: 7,Loss: -2.663,Avg.Loss: -2.187,LR: 1.02E-04]Training epoch 15:   2%|▏         | 7/341 [00:00<00:06, 49.51it/s, Epoch: 15, Batch: 8,Loss: -2.410,Avg.Loss: -2.215,LR: 1.02E-04]Training epoch 15:   2%|▏         | 8/341 [00:00<00:06, 49.51it/s, Epoch: 15, Batch: 9,Loss: -2.479,Avg.Loss: -2.245,LR: 1.02E-04]Training epoch 15:   3%|▎         | 9/341 [00:00<00:06, 49.51it/s, Epoch: 15, Batch: 10,Loss: -2.073,Avg.Loss: -2.227,LR: 1.02E-04]Training epoch 15:   3%|▎         | 10/341 [00:00<00:06, 49.61it/s, Epoch: 15, Batch: 10,Loss: -2.073,Avg.Loss: -2.227,LR: 1.02E-04]Training epoch 15:   3%|▎         | 10/341 [00:00<00:06, 49.61it/s, Epoch: 15, Batch: 11,Loss: -2.181,Avg.Loss: -2.223,LR: 1.02E-04]Training epoch 15:   3%|▎         | 11/341 [00:00<00:06, 49.61it/s, Epoch: 15, Batch: 12,Loss: -2.279,Avg.Loss: -2.228,LR: 1.02E-04]Training epoch 15:   4%|▎         | 12/341 [00:00<00:06, 49.61it/s, Epoch: 15, Batch: 13,Loss: -2.374,Avg.Loss: -2.239,LR: 1.02E-04]Training epoch 15:   4%|▍         | 13/341 [00:00<00:06, 49.61it/s, Epoch: 15, Batch: 14,Loss: -2.406,Avg.Loss: -2.251,LR: 1.02E-04]Training epoch 15:   4%|▍         | 14/341 [00:00<00:06, 49.61it/s, Epoch: 15, Batch: 15,Loss: -2.400,Avg.Loss: -2.261,LR: 1.02E-04]Training epoch 15:   4%|▍         | 15/341 [00:00<00:06, 49.61it/s, Epoch: 15, Batch: 16,Loss: -2.229,Avg.Loss: -2.259,LR: 1.02E-04]Training epoch 15:   5%|▍         | 16/341 [00:00<00:06, 50.65it/s, Epoch: 15, Batch: 16,Loss: -2.229,Avg.Loss: -2.259,LR: 1.02E-04]Training epoch 15:   5%|▍         | 16/341 [00:00<00:06, 50.65it/s, Epoch: 15, Batch: 17,Loss: -2.445,Avg.Loss: -2.270,LR: 1.01E-04]Training epoch 15:   5%|▍         | 17/341 [00:00<00:06, 50.65it/s, Epoch: 15, Batch: 18,Loss: -2.290,Avg.Loss: -2.271,LR: 1.01E-04]Training epoch 15:   5%|▌         | 18/341 [00:00<00:06, 50.65it/s, Epoch: 15, Batch: 19,Loss: -2.235,Avg.Loss: -2.269,LR: 1.01E-04]Training epoch 15:   6%|▌         | 19/341 [00:00<00:06, 50.65it/s, Epoch: 15, Batch: 20,Loss: -2.030,Avg.Loss: -2.257,LR: 1.01E-04]Training epoch 15:   6%|▌         | 20/341 [00:00<00:06, 50.65it/s, Epoch: 15, Batch: 21,Loss: -2.521,Avg.Loss: -2.270,LR: 1.01E-04]Training epoch 15:   6%|▌         | 21/341 [00:00<00:06, 50.65it/s, Epoch: 15, Batch: 22,Loss: -2.056,Avg.Loss: -2.260,LR: 1.01E-04]Training epoch 15:   6%|▋         | 22/341 [00:00<00:06, 49.49it/s, Epoch: 15, Batch: 22,Loss: -2.056,Avg.Loss: -2.260,LR: 1.01E-04]Training epoch 15:   6%|▋         | 22/341 [00:00<00:06, 49.49it/s, Epoch: 15, Batch: 23,Loss: -2.762,Avg.Loss: -2.282,LR: 1.01E-04]Training epoch 15:   7%|▋         | 23/341 [00:00<00:06, 49.49it/s, Epoch: 15, Batch: 24,Loss: -2.176,Avg.Loss: -2.277,LR: 1.01E-04]Training epoch 15:   7%|▋         | 24/341 [00:00<00:06, 49.49it/s, Epoch: 15, Batch: 25,Loss: -2.011,Avg.Loss: -2.267,LR: 1.01E-04]Training epoch 15:   7%|▋         | 25/341 [00:00<00:06, 49.49it/s, Epoch: 15, Batch: 26,Loss: -2.265,Avg.Loss: -2.267,LR: 1.01E-04]Training epoch 15:   8%|▊         | 26/341 [00:00<00:06, 49.49it/s, Epoch: 15, Batch: 27,Loss: -2.549,Avg.Loss: -2.277,LR: 1.01E-04]Training epoch 15:   8%|▊         | 27/341 [00:00<00:06, 49.49it/s, Epoch: 15, Batch: 28,Loss: -1.978,Avg.Loss: -2.267,LR: 1.00E-04]Training epoch 15:   8%|▊         | 28/341 [00:00<00:05, 52.43it/s, Epoch: 15, Batch: 28,Loss: -1.978,Avg.Loss: -2.267,LR: 1.00E-04]Training epoch 15:   8%|▊         | 28/341 [00:00<00:05, 52.43it/s, Epoch: 15, Batch: 29,Loss: -2.519,Avg.Loss: -2.275,LR: 1.00E-04]Training epoch 15:   9%|▊         | 29/341 [00:00<00:05, 52.43it/s, Epoch: 15, Batch: 30,Loss: -2.608,Avg.Loss: -2.286,LR: 1.00E-04]Training epoch 15:   9%|▉         | 30/341 [00:00<00:05, 52.43it/s, Epoch: 15, Batch: 31,Loss: -2.104,Avg.Loss: -2.280,LR: 1.00E-04]Training epoch 15:   9%|▉         | 31/341 [00:00<00:05, 52.43it/s, Epoch: 15, Batch: 32,Loss: -2.473,Avg.Loss: -2.286,LR: 1.00E-04]Training epoch 15:   9%|▉         | 32/341 [00:00<00:05, 52.43it/s, Epoch: 15, Batch: 33,Loss: -2.663,Avg.Loss: -2.298,LR: 1.00E-04]Training epoch 15:  10%|▉         | 33/341 [00:00<00:05, 52.43it/s, Epoch: 15, Batch: 34,Loss: -2.074,Avg.Loss: -2.291,LR: 9.99E-05]Training epoch 15:  10%|▉         | 34/341 [00:00<00:05, 53.26it/s, Epoch: 15, Batch: 34,Loss: -2.074,Avg.Loss: -2.291,LR: 9.99E-05]Training epoch 15:  10%|▉         | 34/341 [00:00<00:05, 53.26it/s, Epoch: 15, Batch: 35,Loss: -2.402,Avg.Loss: -2.294,LR: 9.98E-05]Training epoch 15:  10%|█         | 35/341 [00:00<00:05, 53.26it/s, Epoch: 15, Batch: 36,Loss: -2.295,Avg.Loss: -2.294,LR: 9.97E-05]Training epoch 15:  11%|█         | 36/341 [00:00<00:05, 53.26it/s, Epoch: 15, Batch: 37,Loss: -2.444,Avg.Loss: -2.299,LR: 9.96E-05]Training epoch 15:  11%|█         | 37/341 [00:00<00:05, 53.26it/s, Epoch: 15, Batch: 38,Loss: -2.262,Avg.Loss: -2.298,LR: 9.95E-05]Training epoch 15:  11%|█         | 38/341 [00:00<00:05, 53.26it/s, Epoch: 15, Batch: 39,Loss: -2.137,Avg.Loss: -2.293,LR: 9.94E-05]Training epoch 15:  11%|█▏        | 39/341 [00:00<00:05, 53.26it/s, Epoch: 15, Batch: 40,Loss: -1.837,Avg.Loss: -2.282,LR: 9.94E-05]Training epoch 15:  12%|█▏        | 40/341 [00:00<00:05, 52.28it/s, Epoch: 15, Batch: 40,Loss: -1.837,Avg.Loss: -2.282,LR: 9.94E-05]Training epoch 15:  12%|█▏        | 40/341 [00:00<00:05, 52.28it/s, Epoch: 15, Batch: 41,Loss: -2.364,Avg.Loss: -2.284,LR: 9.93E-05]Training epoch 15:  12%|█▏        | 41/341 [00:00<00:05, 52.28it/s, Epoch: 15, Batch: 42,Loss: -2.522,Avg.Loss: -2.290,LR: 9.92E-05]Training epoch 15:  12%|█▏        | 42/341 [00:00<00:05, 52.28it/s, Epoch: 15, Batch: 43,Loss: -2.704,Avg.Loss: -2.299,LR: 9.91E-05]Training epoch 15:  13%|█▎        | 43/341 [00:00<00:05, 52.28it/s, Epoch: 15, Batch: 44,Loss: -2.523,Avg.Loss: -2.304,LR: 9.90E-05]Training epoch 15:  13%|█▎        | 44/341 [00:00<00:05, 52.28it/s, Epoch: 15, Batch: 45,Loss: -2.605,Avg.Loss: -2.311,LR: 9.89E-05]Training epoch 15:  13%|█▎        | 45/341 [00:00<00:05, 52.28it/s, Epoch: 15, Batch: 46,Loss: -2.038,Avg.Loss: -2.305,LR: 9.88E-05]Training epoch 15:  13%|█▎        | 46/341 [00:00<00:05, 53.19it/s, Epoch: 15, Batch: 46,Loss: -2.038,Avg.Loss: -2.305,LR: 9.88E-05]Training epoch 15:  13%|█▎        | 46/341 [00:00<00:05, 53.19it/s, Epoch: 15, Batch: 47,Loss: -2.302,Avg.Loss: -2.305,LR: 9.87E-05]Training epoch 15:  14%|█▍        | 47/341 [00:00<00:05, 53.19it/s, Epoch: 15, Batch: 48,Loss: -2.207,Avg.Loss: -2.303,LR: 9.86E-05]Training epoch 15:  14%|█▍        | 48/341 [00:00<00:05, 53.19it/s, Epoch: 15, Batch: 49,Loss: -1.805,Avg.Loss: -2.293,LR: 9.85E-05]Training epoch 15:  14%|█▍        | 49/341 [00:00<00:05, 53.19it/s, Epoch: 15, Batch: 50,Loss: -2.570,Avg.Loss: -2.298,LR: 9.84E-05]Training epoch 15:  15%|█▍        | 50/341 [00:00<00:05, 53.19it/s, Epoch: 15, Batch: 51,Loss: -2.650,Avg.Loss: -2.305,LR: 9.83E-05]Training epoch 15:  15%|█▍        | 51/341 [00:00<00:05, 53.19it/s, Epoch: 15, Batch: 52,Loss: -1.990,Avg.Loss: -2.299,LR: 9.83E-05]Training epoch 15:  15%|█▌        | 52/341 [00:00<00:05, 53.43it/s, Epoch: 15, Batch: 52,Loss: -1.990,Avg.Loss: -2.299,LR: 9.83E-05]Training epoch 15:  15%|█▌        | 52/341 [00:01<00:05, 53.43it/s, Epoch: 15, Batch: 53,Loss: -2.474,Avg.Loss: -2.303,LR: 9.82E-05]Training epoch 15:  16%|█▌        | 53/341 [00:01<00:05, 53.43it/s, Epoch: 15, Batch: 54,Loss: -2.168,Avg.Loss: -2.300,LR: 9.81E-05]Training epoch 15:  16%|█▌        | 54/341 [00:01<00:05, 53.43it/s, Epoch: 15, Batch: 55,Loss: -2.054,Avg.Loss: -2.296,LR: 9.80E-05]Training epoch 15:  16%|█▌        | 55/341 [00:01<00:05, 53.43it/s, Epoch: 15, Batch: 56,Loss: -2.381,Avg.Loss: -2.297,LR: 9.79E-05]Training epoch 15:  16%|█▋        | 56/341 [00:01<00:05, 53.43it/s, Epoch: 15, Batch: 57,Loss: -2.554,Avg.Loss: -2.302,LR: 9.78E-05]Training epoch 15:  17%|█▋        | 57/341 [00:01<00:05, 53.43it/s, Epoch: 15, Batch: 58,Loss: -2.259,Avg.Loss: -2.301,LR: 9.77E-05]Training epoch 15:  17%|█▋        | 58/341 [00:01<00:05, 53.61it/s, Epoch: 15, Batch: 58,Loss: -2.259,Avg.Loss: -2.301,LR: 9.77E-05]Training epoch 15:  17%|█▋        | 58/341 [00:01<00:05, 53.61it/s, Epoch: 15, Batch: 59,Loss: -2.422,Avg.Loss: -2.303,LR: 9.76E-05]Training epoch 15:  17%|█▋        | 59/341 [00:01<00:05, 53.61it/s, Epoch: 15, Batch: 60,Loss: -2.208,Avg.Loss: -2.301,LR: 9.75E-05]Training epoch 15:  18%|█▊        | 60/341 [00:01<00:05, 53.61it/s, Epoch: 15, Batch: 61,Loss: -2.003,Avg.Loss: -2.296,LR: 9.74E-05]Training epoch 15:  18%|█▊        | 61/341 [00:01<00:05, 53.61it/s, Epoch: 15, Batch: 62,Loss: -2.236,Avg.Loss: -2.296,LR: 9.73E-05]Training epoch 15:  18%|█▊        | 62/341 [00:01<00:05, 53.61it/s, Epoch: 15, Batch: 63,Loss: -2.172,Avg.Loss: -2.294,LR: 9.72E-05]Training epoch 15:  18%|█▊        | 63/341 [00:01<00:05, 53.61it/s, Epoch: 15, Batch: 64,Loss: -2.121,Avg.Loss: -2.291,LR: 9.72E-05]Training epoch 15:  19%|█▉        | 64/341 [00:01<00:05, 53.67it/s, Epoch: 15, Batch: 64,Loss: -2.121,Avg.Loss: -2.291,LR: 9.72E-05]Training epoch 15:  19%|█▉        | 64/341 [00:01<00:05, 53.67it/s, Epoch: 15, Batch: 65,Loss: -2.364,Avg.Loss: -2.292,LR: 9.71E-05]Training epoch 15:  19%|█▉        | 65/341 [00:01<00:05, 53.67it/s, Epoch: 15, Batch: 66,Loss: -1.949,Avg.Loss: -2.287,LR: 9.70E-05]Training epoch 15:  19%|█▉        | 66/341 [00:01<00:05, 53.67it/s, Epoch: 15, Batch: 67,Loss: -2.315,Avg.Loss: -2.287,LR: 9.69E-05]Training epoch 15:  20%|█▉        | 67/341 [00:01<00:05, 53.67it/s, Epoch: 15, Batch: 68,Loss: -2.722,Avg.Loss: -2.294,LR: 9.68E-05]Training epoch 15:  20%|█▉        | 68/341 [00:01<00:05, 53.67it/s, Epoch: 15, Batch: 69,Loss: -2.287,Avg.Loss: -2.294,LR: 9.67E-05]Training epoch 15:  20%|██        | 69/341 [00:01<00:05, 53.67it/s, Epoch: 15, Batch: 70,Loss: -2.004,Avg.Loss: -2.289,LR: 9.66E-05]Training epoch 15:  21%|██        | 70/341 [00:01<00:05, 53.79it/s, Epoch: 15, Batch: 70,Loss: -2.004,Avg.Loss: -2.289,LR: 9.66E-05]Training epoch 15:  21%|██        | 70/341 [00:01<00:05, 53.79it/s, Epoch: 15, Batch: 71,Loss: -2.123,Avg.Loss: -2.287,LR: 9.65E-05]Training epoch 15:  21%|██        | 71/341 [00:01<00:05, 53.79it/s, Epoch: 15, Batch: 72,Loss: -2.305,Avg.Loss: -2.287,LR: 9.64E-05]Training epoch 15:  21%|██        | 72/341 [00:01<00:05, 53.79it/s, Epoch: 15, Batch: 73,Loss: -2.204,Avg.Loss: -2.286,LR: 9.63E-05]Training epoch 15:  21%|██▏       | 73/341 [00:01<00:04, 53.79it/s, Epoch: 15, Batch: 74,Loss: -2.483,Avg.Loss: -2.289,LR: 9.62E-05]Training epoch 15:  22%|██▏       | 74/341 [00:01<00:04, 53.79it/s, Epoch: 15, Batch: 75,Loss: -2.275,Avg.Loss: -2.289,LR: 9.62E-05]Training epoch 15:  22%|██▏       | 75/341 [00:01<00:04, 53.79it/s, Epoch: 15, Batch: 76,Loss: -2.430,Avg.Loss: -2.290,LR: 9.61E-05]Training epoch 15:  22%|██▏       | 76/341 [00:01<00:04, 53.89it/s, Epoch: 15, Batch: 76,Loss: -2.430,Avg.Loss: -2.290,LR: 9.61E-05]Training epoch 15:  22%|██▏       | 76/341 [00:01<00:04, 53.89it/s, Epoch: 15, Batch: 77,Loss: -2.339,Avg.Loss: -2.291,LR: 9.60E-05]Training epoch 15:  23%|██▎       | 77/341 [00:01<00:04, 53.89it/s, Epoch: 15, Batch: 78,Loss: -2.446,Avg.Loss: -2.293,LR: 9.59E-05]Training epoch 15:  23%|██▎       | 78/341 [00:01<00:04, 53.89it/s, Epoch: 15, Batch: 79,Loss: -1.733,Avg.Loss: -2.286,LR: 9.58E-05]Training epoch 15:  23%|██▎       | 79/341 [00:01<00:04, 53.89it/s, Epoch: 15, Batch: 80,Loss: -2.436,Avg.Loss: -2.288,LR: 9.57E-05]Training epoch 15:  23%|██▎       | 80/341 [00:01<00:04, 53.89it/s, Epoch: 15, Batch: 81,Loss: -2.623,Avg.Loss: -2.292,LR: 9.56E-05]Training epoch 15:  24%|██▍       | 81/341 [00:01<00:04, 53.89it/s, Epoch: 15, Batch: 82,Loss: -2.130,Avg.Loss: -2.290,LR: 9.55E-05]Training epoch 15:  24%|██▍       | 82/341 [00:01<00:04, 53.06it/s, Epoch: 15, Batch: 82,Loss: -2.130,Avg.Loss: -2.290,LR: 9.55E-05]Training epoch 15:  24%|██▍       | 82/341 [00:01<00:04, 53.06it/s, Epoch: 15, Batch: 83,Loss: -2.724,Avg.Loss: -2.295,LR: 9.54E-05]Training epoch 15:  24%|██▍       | 83/341 [00:01<00:04, 53.06it/s, Epoch: 15, Batch: 84,Loss: -2.274,Avg.Loss: -2.295,LR: 9.53E-05]Training epoch 15:  25%|██▍       | 84/341 [00:01<00:04, 53.06it/s, Epoch: 15, Batch: 85,Loss: -1.731,Avg.Loss: -2.288,LR: 9.52E-05]Training epoch 15:  25%|██▍       | 85/341 [00:01<00:04, 53.06it/s, Epoch: 15, Batch: 86,Loss: -2.506,Avg.Loss: -2.291,LR: 9.52E-05]Training epoch 15:  25%|██▌       | 86/341 [00:01<00:04, 53.06it/s, Epoch: 15, Batch: 87,Loss: -2.536,Avg.Loss: -2.294,LR: 9.51E-05]Training epoch 15:  26%|██▌       | 87/341 [00:01<00:04, 53.06it/s, Epoch: 15, Batch: 88,Loss: -2.028,Avg.Loss: -2.291,LR: 9.50E-05]Training epoch 15:  26%|██▌       | 88/341 [00:01<00:04, 52.44it/s, Epoch: 15, Batch: 88,Loss: -2.028,Avg.Loss: -2.291,LR: 9.50E-05]Training epoch 15:  26%|██▌       | 88/341 [00:01<00:04, 52.44it/s, Epoch: 15, Batch: 89,Loss: -1.708,Avg.Loss: -2.284,LR: 9.49E-05]Training epoch 15:  26%|██▌       | 89/341 [00:01<00:04, 52.44it/s, Epoch: 15, Batch: 90,Loss: -2.279,Avg.Loss: -2.284,LR: 9.48E-05]Training epoch 15:  26%|██▋       | 90/341 [00:01<00:04, 52.44it/s, Epoch: 15, Batch: 91,Loss: -2.269,Avg.Loss: -2.284,LR: 9.47E-05]Training epoch 15:  27%|██▋       | 91/341 [00:01<00:04, 52.44it/s, Epoch: 15, Batch: 92,Loss: -1.699,Avg.Loss: -2.278,LR: 9.46E-05]Training epoch 15:  27%|██▋       | 92/341 [00:01<00:04, 52.44it/s, Epoch: 15, Batch: 93,Loss: -1.756,Avg.Loss: -2.272,LR: 9.45E-05]Training epoch 15:  27%|██▋       | 93/341 [00:01<00:04, 52.44it/s, Epoch: 15, Batch: 94,Loss: -2.481,Avg.Loss: -2.274,LR: 9.44E-05]Training epoch 15:  28%|██▊       | 94/341 [00:01<00:04, 51.95it/s, Epoch: 15, Batch: 94,Loss: -2.481,Avg.Loss: -2.274,LR: 9.44E-05]Training epoch 15:  28%|██▊       | 94/341 [00:01<00:04, 51.95it/s, Epoch: 15, Batch: 95,Loss: -2.069,Avg.Loss: -2.272,LR: 9.43E-05]Training epoch 15:  28%|██▊       | 95/341 [00:01<00:04, 51.95it/s, Epoch: 15, Batch: 96,Loss: -1.670,Avg.Loss: -2.266,LR: 9.43E-05]Training epoch 15:  28%|██▊       | 96/341 [00:01<00:04, 51.95it/s, Epoch: 15, Batch: 97,Loss: -2.471,Avg.Loss: -2.268,LR: 9.42E-05]Training epoch 15:  28%|██▊       | 97/341 [00:01<00:04, 51.95it/s, Epoch: 15, Batch: 98,Loss: -2.111,Avg.Loss: -2.266,LR: 9.41E-05]Training epoch 15:  29%|██▊       | 98/341 [00:01<00:04, 51.95it/s, Epoch: 15, Batch: 99,Loss: -2.415,Avg.Loss: -2.268,LR: 9.40E-05]Training epoch 15:  29%|██▉       | 99/341 [00:01<00:04, 51.95it/s, Epoch: 15, Batch: 100,Loss: -2.110,Avg.Loss: -2.266,LR: 9.39E-05]Training epoch 15:  29%|██▉       | 100/341 [00:01<00:04, 51.68it/s, Epoch: 15, Batch: 100,Loss: -2.110,Avg.Loss: -2.266,LR: 9.39E-05]Training epoch 15:  29%|██▉       | 100/341 [00:01<00:04, 51.68it/s, Epoch: 15, Batch: 101,Loss: -2.169,Avg.Loss: -2.265,LR: 9.38E-05]Training epoch 15:  30%|██▉       | 101/341 [00:01<00:04, 51.68it/s, Epoch: 15, Batch: 102,Loss: -2.317,Avg.Loss: -2.266,LR: 9.37E-05]Training epoch 15:  30%|██▉       | 102/341 [00:01<00:04, 51.68it/s, Epoch: 15, Batch: 103,Loss: -2.457,Avg.Loss: -2.268,LR: 9.36E-05]Training epoch 15:  30%|███       | 103/341 [00:01<00:04, 51.68it/s, Epoch: 15, Batch: 104,Loss: -2.283,Avg.Loss: -2.268,LR: 9.35E-05]Training epoch 15:  30%|███       | 104/341 [00:02<00:04, 51.68it/s, Epoch: 15, Batch: 105,Loss: -1.668,Avg.Loss: -2.262,LR: 9.34E-05]Training epoch 15:  31%|███       | 105/341 [00:02<00:04, 51.68it/s, Epoch: 15, Batch: 106,Loss: -2.026,Avg.Loss: -2.260,LR: 9.34E-05]Training epoch 15:  31%|███       | 106/341 [00:02<00:04, 51.54it/s, Epoch: 15, Batch: 106,Loss: -2.026,Avg.Loss: -2.260,LR: 9.34E-05]Training epoch 15:  31%|███       | 106/341 [00:02<00:04, 51.54it/s, Epoch: 15, Batch: 107,Loss: -2.376,Avg.Loss: -2.261,LR: 9.33E-05]Training epoch 15:  31%|███▏      | 107/341 [00:02<00:04, 51.54it/s, Epoch: 15, Batch: 108,Loss: -1.685,Avg.Loss: -2.256,LR: 9.32E-05]Training epoch 15:  32%|███▏      | 108/341 [00:02<00:04, 51.54it/s, Epoch: 15, Batch: 109,Loss: -1.753,Avg.Loss: -2.251,LR: 9.31E-05]Training epoch 15:  32%|███▏      | 109/341 [00:02<00:04, 51.54it/s, Epoch: 15, Batch: 110,Loss: -2.267,Avg.Loss: -2.251,LR: 9.30E-05]Training epoch 15:  32%|███▏      | 110/341 [00:02<00:04, 51.54it/s, Epoch: 15, Batch: 111,Loss: -2.515,Avg.Loss: -2.253,LR: 9.29E-05]Training epoch 15:  33%|███▎      | 111/341 [00:02<00:04, 51.54it/s, Epoch: 15, Batch: 112,Loss: -1.853,Avg.Loss: -2.250,LR: 9.28E-05]Training epoch 15:  33%|███▎      | 112/341 [00:02<00:04, 51.81it/s, Epoch: 15, Batch: 112,Loss: -1.853,Avg.Loss: -2.250,LR: 9.28E-05]Training epoch 15:  33%|███▎      | 112/341 [00:02<00:04, 51.81it/s, Epoch: 15, Batch: 113,Loss: -1.053,Avg.Loss: -2.239,LR: 9.27E-05]Training epoch 15:  33%|███▎      | 113/341 [00:02<00:04, 51.81it/s, Epoch: 15, Batch: 114,Loss: -1.058,Avg.Loss: -2.229,LR: 9.26E-05]Training epoch 15:  33%|███▎      | 114/341 [00:02<00:04, 51.81it/s, Epoch: 15, Batch: 115,Loss: -1.336,Avg.Loss: -2.221,LR: 9.26E-05]Training epoch 15:  34%|███▎      | 115/341 [00:02<00:04, 51.81it/s, Epoch: 15, Batch: 116,Loss: -2.331,Avg.Loss: -2.222,LR: 9.25E-05]Training epoch 15:  34%|███▍      | 116/341 [00:02<00:04, 51.81it/s, Epoch: 15, Batch: 117,Loss: -2.081,Avg.Loss: -2.221,LR: 9.24E-05]Training epoch 15:  34%|███▍      | 117/341 [00:02<00:04, 51.81it/s, Epoch: 15, Batch: 118,Loss: -2.208,Avg.Loss: -2.221,LR: 9.23E-05]Training epoch 15:  35%|███▍      | 118/341 [00:02<00:04, 52.65it/s, Epoch: 15, Batch: 118,Loss: -2.208,Avg.Loss: -2.221,LR: 9.23E-05]Training epoch 15:  35%|███▍      | 118/341 [00:02<00:04, 52.65it/s, Epoch: 15, Batch: 119,Loss: -2.573,Avg.Loss: -2.224,LR: 9.22E-05]Training epoch 15:  35%|███▍      | 119/341 [00:02<00:04, 52.65it/s, Epoch: 15, Batch: 120,Loss: -2.475,Avg.Loss: -2.226,LR: 9.21E-05]Training epoch 15:  35%|███▌      | 120/341 [00:02<00:04, 52.65it/s, Epoch: 15, Batch: 121,Loss: -2.460,Avg.Loss: -2.228,LR: 9.20E-05]Training epoch 15:  35%|███▌      | 121/341 [00:02<00:04, 52.65it/s, Epoch: 15, Batch: 122,Loss: -2.715,Avg.Loss: -2.232,LR: 9.19E-05]Training epoch 15:  36%|███▌      | 122/341 [00:02<00:04, 52.65it/s, Epoch: 15, Batch: 123,Loss: -2.181,Avg.Loss: -2.231,LR: 9.18E-05]Training epoch 15:  36%|███▌      | 123/341 [00:02<00:04, 52.65it/s, Epoch: 15, Batch: 124,Loss: -1.546,Avg.Loss: -2.226,LR: 9.17E-05]Training epoch 15:  36%|███▋      | 124/341 [00:02<00:04, 52.43it/s, Epoch: 15, Batch: 124,Loss: -1.546,Avg.Loss: -2.226,LR: 9.17E-05]Training epoch 15:  36%|███▋      | 124/341 [00:02<00:04, 52.43it/s, Epoch: 15, Batch: 125,Loss: -2.069,Avg.Loss: -2.225,LR: 9.17E-05]Training epoch 15:  37%|███▋      | 125/341 [00:02<00:04, 52.43it/s, Epoch: 15, Batch: 126,Loss: -2.124,Avg.Loss: -2.224,LR: 9.16E-05]Training epoch 15:  37%|███▋      | 126/341 [00:02<00:04, 52.43it/s, Epoch: 15, Batch: 127,Loss: -2.903,Avg.Loss: -2.229,LR: 9.15E-05]Training epoch 15:  37%|███▋      | 127/341 [00:02<00:04, 52.43it/s, Epoch: 15, Batch: 128,Loss: -2.745,Avg.Loss: -2.233,LR: 9.14E-05]Training epoch 15:  38%|███▊      | 128/341 [00:02<00:04, 52.43it/s, Epoch: 15, Batch: 129,Loss: -2.233,Avg.Loss: -2.233,LR: 9.13E-05]Training epoch 15:  38%|███▊      | 129/341 [00:02<00:04, 52.43it/s, Epoch: 15, Batch: 130,Loss: -2.263,Avg.Loss: -2.233,LR: 9.12E-05]Training epoch 15:  38%|███▊      | 130/341 [00:02<00:04, 52.39it/s, Epoch: 15, Batch: 130,Loss: -2.263,Avg.Loss: -2.233,LR: 9.12E-05]Training epoch 15:  38%|███▊      | 130/341 [00:02<00:04, 52.39it/s, Epoch: 15, Batch: 131,Loss: -2.333,Avg.Loss: -2.234,LR: 9.11E-05]Training epoch 15:  38%|███▊      | 131/341 [00:02<00:04, 52.39it/s, Epoch: 15, Batch: 132,Loss: -2.530,Avg.Loss: -2.236,LR: 9.10E-05]Training epoch 15:  39%|███▊      | 132/341 [00:02<00:03, 52.39it/s, Epoch: 15, Batch: 133,Loss: -2.108,Avg.Loss: -2.235,LR: 9.09E-05]Training epoch 15:  39%|███▉      | 133/341 [00:02<00:03, 52.39it/s, Epoch: 15, Batch: 134,Loss: -1.967,Avg.Loss: -2.233,LR: 9.09E-05]Training epoch 15:  39%|███▉      | 134/341 [00:02<00:03, 52.39it/s, Epoch: 15, Batch: 135,Loss: -2.424,Avg.Loss: -2.235,LR: 9.08E-05]Training epoch 15:  40%|███▉      | 135/341 [00:02<00:03, 52.39it/s, Epoch: 15, Batch: 136,Loss: -1.991,Avg.Loss: -2.233,LR: 9.07E-05]Training epoch 15:  40%|███▉      | 136/341 [00:02<00:03, 52.06it/s, Epoch: 15, Batch: 136,Loss: -1.991,Avg.Loss: -2.233,LR: 9.07E-05]Training epoch 15:  40%|███▉      | 136/341 [00:02<00:03, 52.06it/s, Epoch: 15, Batch: 137,Loss: -2.211,Avg.Loss: -2.233,LR: 9.06E-05]Training epoch 15:  40%|████      | 137/341 [00:02<00:03, 52.06it/s, Epoch: 15, Batch: 138,Loss: -2.190,Avg.Loss: -2.233,LR: 9.05E-05]Training epoch 15:  40%|████      | 138/341 [00:02<00:03, 52.06it/s, Epoch: 15, Batch: 139,Loss: -2.479,Avg.Loss: -2.234,LR: 9.04E-05]Training epoch 15:  41%|████      | 139/341 [00:02<00:03, 52.06it/s, Epoch: 15, Batch: 140,Loss: -1.818,Avg.Loss: -2.231,LR: 9.03E-05]Training epoch 15:  41%|████      | 140/341 [00:02<00:03, 52.06it/s, Epoch: 15, Batch: 141,Loss: -2.208,Avg.Loss: -2.231,LR: 9.02E-05]Training epoch 15:  41%|████▏     | 141/341 [00:02<00:03, 52.06it/s, Epoch: 15, Batch: 142,Loss: -2.404,Avg.Loss: -2.232,LR: 9.01E-05]Training epoch 15:  42%|████▏     | 142/341 [00:02<00:03, 52.23it/s, Epoch: 15, Batch: 142,Loss: -2.404,Avg.Loss: -2.232,LR: 9.01E-05]Training epoch 15:  42%|████▏     | 142/341 [00:02<00:03, 52.23it/s, Epoch: 15, Batch: 143,Loss: -1.804,Avg.Loss: -2.229,LR: 9.01E-05]Training epoch 15:  42%|████▏     | 143/341 [00:02<00:03, 52.23it/s, Epoch: 15, Batch: 144,Loss: -2.100,Avg.Loss: -2.229,LR: 9.00E-05]Training epoch 15:  42%|████▏     | 144/341 [00:02<00:03, 52.23it/s, Epoch: 15, Batch: 145,Loss: -2.542,Avg.Loss: -2.231,LR: 8.99E-05]Training epoch 15:  43%|████▎     | 145/341 [00:02<00:03, 52.23it/s, Epoch: 15, Batch: 146,Loss: -2.344,Avg.Loss: -2.231,LR: 8.98E-05]Training epoch 15:  43%|████▎     | 146/341 [00:02<00:03, 52.23it/s, Epoch: 15, Batch: 147,Loss: -2.282,Avg.Loss: -2.232,LR: 8.97E-05]Training epoch 15:  43%|████▎     | 147/341 [00:02<00:03, 52.23it/s, Epoch: 15, Batch: 148,Loss: -2.855,Avg.Loss: -2.236,LR: 8.96E-05]Training epoch 15:  43%|████▎     | 148/341 [00:02<00:03, 52.54it/s, Epoch: 15, Batch: 148,Loss: -2.855,Avg.Loss: -2.236,LR: 8.96E-05]Training epoch 15:  43%|████▎     | 148/341 [00:02<00:03, 52.54it/s, Epoch: 15, Batch: 149,Loss: -2.453,Avg.Loss: -2.237,LR: 8.95E-05]Training epoch 15:  44%|████▎     | 149/341 [00:02<00:03, 52.54it/s, Epoch: 15, Batch: 150,Loss: -1.954,Avg.Loss: -2.236,LR: 8.94E-05]Training epoch 15:  44%|████▍     | 150/341 [00:02<00:03, 52.54it/s, Epoch: 15, Batch: 151,Loss: -2.574,Avg.Loss: -2.238,LR: 8.94E-05]Training epoch 15:  44%|████▍     | 151/341 [00:02<00:03, 52.54it/s, Epoch: 15, Batch: 152,Loss: -2.454,Avg.Loss: -2.239,LR: 8.93E-05]Training epoch 15:  45%|████▍     | 152/341 [00:02<00:03, 52.54it/s, Epoch: 15, Batch: 153,Loss: -2.511,Avg.Loss: -2.241,LR: 8.92E-05]Training epoch 15:  45%|████▍     | 153/341 [00:02<00:03, 52.54it/s, Epoch: 15, Batch: 154,Loss: -2.139,Avg.Loss: -2.240,LR: 8.91E-05]Training epoch 15:  45%|████▌     | 154/341 [00:02<00:03, 53.20it/s, Epoch: 15, Batch: 154,Loss: -2.139,Avg.Loss: -2.240,LR: 8.91E-05]Training epoch 15:  45%|████▌     | 154/341 [00:02<00:03, 53.20it/s, Epoch: 15, Batch: 155,Loss: -2.670,Avg.Loss: -2.243,LR: 8.90E-05]Training epoch 15:  45%|████▌     | 155/341 [00:02<00:03, 53.20it/s, Epoch: 15, Batch: 156,Loss: -2.407,Avg.Loss: -2.244,LR: 8.89E-05]Training epoch 15:  46%|████▌     | 156/341 [00:02<00:03, 53.20it/s, Epoch: 15, Batch: 157,Loss: -1.654,Avg.Loss: -2.240,LR: 8.88E-05]Training epoch 15:  46%|████▌     | 157/341 [00:03<00:03, 53.20it/s, Epoch: 15, Batch: 158,Loss: -2.371,Avg.Loss: -2.241,LR: 8.87E-05]Training epoch 15:  46%|████▋     | 158/341 [00:03<00:03, 53.20it/s, Epoch: 15, Batch: 159,Loss: -1.856,Avg.Loss: -2.239,LR: 8.86E-05]Training epoch 15:  47%|████▋     | 159/341 [00:03<00:03, 53.20it/s, Epoch: 15, Batch: 160,Loss: -2.458,Avg.Loss: -2.240,LR: 8.86E-05]Training epoch 15:  47%|████▋     | 160/341 [00:03<00:03, 53.32it/s, Epoch: 15, Batch: 160,Loss: -2.458,Avg.Loss: -2.240,LR: 8.86E-05]Training epoch 15:  47%|████▋     | 160/341 [00:03<00:03, 53.32it/s, Epoch: 15, Batch: 161,Loss: -2.250,Avg.Loss: -2.240,LR: 8.85E-05]Training epoch 15:  47%|████▋     | 161/341 [00:03<00:03, 53.32it/s, Epoch: 15, Batch: 162,Loss: -2.162,Avg.Loss: -2.240,LR: 8.84E-05]Training epoch 15:  48%|████▊     | 162/341 [00:03<00:03, 53.32it/s, Epoch: 15, Batch: 163,Loss: -1.391,Avg.Loss: -2.235,LR: 8.83E-05]Training epoch 15:  48%|████▊     | 163/341 [00:03<00:03, 53.32it/s, Epoch: 15, Batch: 164,Loss: -2.073,Avg.Loss: -2.234,LR: 8.82E-05]Training epoch 15:  48%|████▊     | 164/341 [00:03<00:03, 53.32it/s, Epoch: 15, Batch: 165,Loss: -2.189,Avg.Loss: -2.233,LR: 8.81E-05]Training epoch 15:  48%|████▊     | 165/341 [00:03<00:03, 53.32it/s, Epoch: 15, Batch: 166,Loss: -2.248,Avg.Loss: -2.233,LR: 8.80E-05]Training epoch 15:  49%|████▊     | 166/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 166,Loss: -2.248,Avg.Loss: -2.233,LR: 8.80E-05]Training epoch 15:  49%|████▊     | 166/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 167,Loss: -2.264,Avg.Loss: -2.234,LR: 8.79E-05]Training epoch 15:  49%|████▉     | 167/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 168,Loss: -2.342,Avg.Loss: -2.234,LR: 8.79E-05]Training epoch 15:  49%|████▉     | 168/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 169,Loss: -1.985,Avg.Loss: -2.233,LR: 8.78E-05]Training epoch 15:  50%|████▉     | 169/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 170,Loss: -2.306,Avg.Loss: -2.233,LR: 8.77E-05]Training epoch 15:  50%|████▉     | 170/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 171,Loss: -2.418,Avg.Loss: -2.234,LR: 8.76E-05]Training epoch 15:  50%|█████     | 171/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 172,Loss: -2.554,Avg.Loss: -2.236,LR: 8.75E-05]Training epoch 15:  50%|█████     | 172/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 172,Loss: -2.554,Avg.Loss: -2.236,LR: 8.75E-05]Training epoch 15:  50%|█████     | 172/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 173,Loss: -2.412,Avg.Loss: -2.237,LR: 8.74E-05]Training epoch 15:  51%|█████     | 173/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 174,Loss: -2.581,Avg.Loss: -2.239,LR: 8.73E-05]Training epoch 15:  51%|█████     | 174/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 175,Loss: -2.291,Avg.Loss: -2.239,LR: 8.72E-05]Training epoch 15:  51%|█████▏    | 175/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 176,Loss: -2.535,Avg.Loss: -2.241,LR: 8.72E-05]Training epoch 15:  52%|█████▏    | 176/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 177,Loss: -2.399,Avg.Loss: -2.242,LR: 8.71E-05]Training epoch 15:  52%|█████▏    | 177/341 [00:03<00:03, 53.72it/s, Epoch: 15, Batch: 178,Loss: -2.324,Avg.Loss: -2.242,LR: 8.70E-05]Training epoch 15:  52%|█████▏    | 178/341 [00:03<00:03, 53.46it/s, Epoch: 15, Batch: 178,Loss: -2.324,Avg.Loss: -2.242,LR: 8.70E-05]Training epoch 15:  52%|█████▏    | 178/341 [00:03<00:03, 53.46it/s, Epoch: 15, Batch: 179,Loss: -2.323,Avg.Loss: -2.243,LR: 8.69E-05]Training epoch 15:  52%|█████▏    | 179/341 [00:03<00:03, 53.46it/s, Epoch: 15, Batch: 180,Loss: -1.845,Avg.Loss: -2.241,LR: 8.68E-05]Training epoch 15:  53%|█████▎    | 180/341 [00:03<00:03, 53.46it/s, Epoch: 15, Batch: 181,Loss: -2.062,Avg.Loss: -2.240,LR: 8.67E-05]Training epoch 15:  53%|█████▎    | 181/341 [00:03<00:02, 53.46it/s, Epoch: 15, Batch: 182,Loss: -1.343,Avg.Loss: -2.235,LR: 8.66E-05]Training epoch 15:  53%|█████▎    | 182/341 [00:03<00:02, 53.46it/s, Epoch: 15, Batch: 183,Loss: -1.779,Avg.Loss: -2.232,LR: 8.65E-05]Training epoch 15:  54%|█████▎    | 183/341 [00:03<00:02, 53.46it/s, Epoch: 15, Batch: 184,Loss: -2.056,Avg.Loss: -2.231,LR: 8.65E-05]Training epoch 15:  54%|█████▍    | 184/341 [00:03<00:02, 53.58it/s, Epoch: 15, Batch: 184,Loss: -2.056,Avg.Loss: -2.231,LR: 8.65E-05]Training epoch 15:  54%|█████▍    | 184/341 [00:03<00:02, 53.58it/s, Epoch: 15, Batch: 185,Loss: -1.653,Avg.Loss: -2.228,LR: 8.64E-05]Training epoch 15:  54%|█████▍    | 185/341 [00:03<00:02, 53.58it/s, Epoch: 15, Batch: 186,Loss: -2.428,Avg.Loss: -2.229,LR: 8.63E-05]Training epoch 15:  55%|█████▍    | 186/341 [00:03<00:02, 53.58it/s, Epoch: 15, Batch: 187,Loss: -2.113,Avg.Loss: -2.229,LR: 8.62E-05]Training epoch 15:  55%|█████▍    | 187/341 [00:03<00:02, 53.58it/s, Epoch: 15, Batch: 188,Loss: -2.528,Avg.Loss: -2.230,LR: 8.61E-05]Training epoch 15:  55%|█████▌    | 188/341 [00:03<00:02, 53.58it/s, Epoch: 15, Batch: 189,Loss: -2.208,Avg.Loss: -2.230,LR: 8.60E-05]Training epoch 15:  55%|█████▌    | 189/341 [00:03<00:02, 53.58it/s, Epoch: 15, Batch: 190,Loss: -2.229,Avg.Loss: -2.230,LR: 8.59E-05]Training epoch 15:  56%|█████▌    | 190/341 [00:03<00:02, 53.26it/s, Epoch: 15, Batch: 190,Loss: -2.229,Avg.Loss: -2.230,LR: 8.59E-05]Training epoch 15:  56%|█████▌    | 190/341 [00:03<00:02, 53.26it/s, Epoch: 15, Batch: 191,Loss: -2.699,Avg.Loss: -2.233,LR: 8.59E-05]Training epoch 15:  56%|█████▌    | 191/341 [00:03<00:02, 53.26it/s, Epoch: 15, Batch: 192,Loss: -2.529,Avg.Loss: -2.234,LR: 8.58E-05]Training epoch 15:  56%|█████▋    | 192/341 [00:03<00:02, 53.26it/s, Epoch: 15, Batch: 193,Loss: -2.318,Avg.Loss: -2.235,LR: 8.57E-05]Training epoch 15:  57%|█████▋    | 193/341 [00:03<00:02, 53.26it/s, Epoch: 15, Batch: 194,Loss: -2.455,Avg.Loss: -2.236,LR: 8.56E-05]Training epoch 15:  57%|█████▋    | 194/341 [00:03<00:02, 53.26it/s, Epoch: 15, Batch: 195,Loss: -2.701,Avg.Loss: -2.238,LR: 8.55E-05]Training epoch 15:  57%|█████▋    | 195/341 [00:03<00:02, 53.26it/s, Epoch: 15, Batch: 196,Loss: -2.232,Avg.Loss: -2.238,LR: 8.54E-05]Training epoch 15:  57%|█████▋    | 196/341 [00:03<00:02, 53.33it/s, Epoch: 15, Batch: 196,Loss: -2.232,Avg.Loss: -2.238,LR: 8.54E-05]Training epoch 15:  57%|█████▋    | 196/341 [00:03<00:02, 53.33it/s, Epoch: 15, Batch: 197,Loss: -2.541,Avg.Loss: -2.240,LR: 8.53E-05]Training epoch 15:  58%|█████▊    | 197/341 [00:03<00:02, 53.33it/s, Epoch: 15, Batch: 198,Loss: -1.982,Avg.Loss: -2.238,LR: 8.52E-05]Training epoch 15:  58%|█████▊    | 198/341 [00:03<00:02, 53.33it/s, Epoch: 15, Batch: 199,Loss: -2.281,Avg.Loss: -2.239,LR: 8.52E-05]Training epoch 15:  58%|█████▊    | 199/341 [00:03<00:02, 53.33it/s, Epoch: 15, Batch: 200,Loss: -2.480,Avg.Loss: -2.240,LR: 8.51E-05]Training epoch 15:  59%|█████▊    | 200/341 [00:03<00:02, 53.33it/s, Epoch: 15, Batch: 201,Loss: -2.246,Avg.Loss: -2.240,LR: 8.50E-05]Training epoch 15:  59%|█████▉    | 201/341 [00:03<00:02, 53.33it/s, Epoch: 15, Batch: 202,Loss: -2.683,Avg.Loss: -2.242,LR: 8.49E-05]Training epoch 15:  59%|█████▉    | 202/341 [00:03<00:02, 53.64it/s, Epoch: 15, Batch: 202,Loss: -2.683,Avg.Loss: -2.242,LR: 8.49E-05]Training epoch 15:  59%|█████▉    | 202/341 [00:03<00:02, 53.64it/s, Epoch: 15, Batch: 203,Loss: -2.813,Avg.Loss: -2.245,LR: 8.48E-05]Training epoch 15:  60%|█████▉    | 203/341 [00:03<00:02, 53.64it/s, Epoch: 15, Batch: 204,Loss: -2.402,Avg.Loss: -2.246,LR: 8.47E-05]Training epoch 15:  60%|█████▉    | 204/341 [00:03<00:02, 53.64it/s, Epoch: 15, Batch: 205,Loss: -2.324,Avg.Loss: -2.246,LR: 8.46E-05]Training epoch 15:  60%|██████    | 205/341 [00:03<00:02, 53.64it/s, Epoch: 15, Batch: 206,Loss: -2.548,Avg.Loss: -2.247,LR: 8.46E-05]Training epoch 15:  60%|██████    | 206/341 [00:03<00:02, 53.64it/s, Epoch: 15, Batch: 207,Loss: -2.222,Avg.Loss: -2.247,LR: 8.45E-05]Training epoch 15:  61%|██████    | 207/341 [00:03<00:02, 53.64it/s, Epoch: 15, Batch: 208,Loss: -2.167,Avg.Loss: -2.247,LR: 8.44E-05]Training epoch 15:  61%|██████    | 208/341 [00:03<00:02, 53.40it/s, Epoch: 15, Batch: 208,Loss: -2.167,Avg.Loss: -2.247,LR: 8.44E-05]Training epoch 15:  61%|██████    | 208/341 [00:03<00:02, 53.40it/s, Epoch: 15, Batch: 209,Loss: -2.156,Avg.Loss: -2.246,LR: 8.43E-05]Training epoch 15:  61%|██████▏   | 209/341 [00:03<00:02, 53.40it/s, Epoch: 15, Batch: 210,Loss: -2.671,Avg.Loss: -2.248,LR: 8.42E-05]Training epoch 15:  62%|██████▏   | 210/341 [00:03<00:02, 53.40it/s, Epoch: 15, Batch: 211,Loss: -2.634,Avg.Loss: -2.250,LR: 8.41E-05]Training epoch 15:  62%|██████▏   | 211/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 212,Loss: -2.401,Avg.Loss: -2.251,LR: 8.40E-05]Training epoch 15:  62%|██████▏   | 212/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 213,Loss: -2.335,Avg.Loss: -2.251,LR: 8.39E-05]Training epoch 15:  62%|██████▏   | 213/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 214,Loss: -2.393,Avg.Loss: -2.252,LR: 8.39E-05]Training epoch 15:  63%|██████▎   | 214/341 [00:04<00:02, 53.44it/s, Epoch: 15, Batch: 214,Loss: -2.393,Avg.Loss: -2.252,LR: 8.39E-05]Training epoch 15:  63%|██████▎   | 214/341 [00:04<00:02, 53.44it/s, Epoch: 15, Batch: 215,Loss: -2.743,Avg.Loss: -2.254,LR: 8.38E-05]Training epoch 15:  63%|██████▎   | 215/341 [00:04<00:02, 53.44it/s, Epoch: 15, Batch: 216,Loss: -1.938,Avg.Loss: -2.253,LR: 8.37E-05]Training epoch 15:  63%|██████▎   | 216/341 [00:04<00:02, 53.44it/s, Epoch: 15, Batch: 217,Loss: -2.364,Avg.Loss: -2.253,LR: 8.36E-05]Training epoch 15:  64%|██████▎   | 217/341 [00:04<00:02, 53.44it/s, Epoch: 15, Batch: 218,Loss: -2.483,Avg.Loss: -2.254,LR: 8.35E-05]Training epoch 15:  64%|██████▍   | 218/341 [00:04<00:02, 53.44it/s, Epoch: 15, Batch: 219,Loss: -2.870,Avg.Loss: -2.257,LR: 8.34E-05]Training epoch 15:  64%|██████▍   | 219/341 [00:04<00:02, 53.44it/s, Epoch: 15, Batch: 220,Loss: -2.850,Avg.Loss: -2.260,LR: 8.33E-05]Training epoch 15:  65%|██████▍   | 220/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 220,Loss: -2.850,Avg.Loss: -2.260,LR: 8.33E-05]Training epoch 15:  65%|██████▍   | 220/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 221,Loss: -2.618,Avg.Loss: -2.262,LR: 8.33E-05]Training epoch 15:  65%|██████▍   | 221/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 222,Loss: -2.604,Avg.Loss: -2.263,LR: 8.32E-05]Training epoch 15:  65%|██████▌   | 222/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 223,Loss: -2.225,Avg.Loss: -2.263,LR: 8.31E-05]Training epoch 15:  65%|██████▌   | 223/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 224,Loss: -2.361,Avg.Loss: -2.263,LR: 8.30E-05]Training epoch 15:  66%|██████▌   | 224/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 225,Loss: -2.563,Avg.Loss: -2.265,LR: 8.29E-05]Training epoch 15:  66%|██████▌   | 225/341 [00:04<00:02, 53.40it/s, Epoch: 15, Batch: 226,Loss: -2.660,Avg.Loss: -2.266,LR: 8.28E-05]Training epoch 15:  66%|██████▋   | 226/341 [00:04<00:02, 53.23it/s, Epoch: 15, Batch: 226,Loss: -2.660,Avg.Loss: -2.266,LR: 8.28E-05]Training epoch 15:  66%|██████▋   | 226/341 [00:04<00:02, 53.23it/s, Epoch: 15, Batch: 227,Loss: -2.640,Avg.Loss: -2.268,LR: 8.27E-05]Training epoch 15:  67%|██████▋   | 227/341 [00:04<00:02, 53.23it/s, Epoch: 15, Batch: 228,Loss: -2.630,Avg.Loss: -2.270,LR: 8.27E-05]Training epoch 15:  67%|██████▋   | 228/341 [00:04<00:02, 53.23it/s, Epoch: 15, Batch: 229,Loss: -2.420,Avg.Loss: -2.270,LR: 8.26E-05]Training epoch 15:  67%|██████▋   | 229/341 [00:04<00:02, 53.23it/s, Epoch: 15, Batch: 230,Loss: -2.772,Avg.Loss: -2.273,LR: 8.25E-05]Training epoch 15:  67%|██████▋   | 230/341 [00:04<00:02, 53.23it/s, Epoch: 15, Batch: 231,Loss: -2.047,Avg.Loss: -2.272,LR: 8.24E-05]Training epoch 15:  68%|██████▊   | 231/341 [00:04<00:02, 53.23it/s, Epoch: 15, Batch: 232,Loss: -2.241,Avg.Loss: -2.271,LR: 8.23E-05]Training epoch 15:  68%|██████▊   | 232/341 [00:04<00:02, 53.32it/s, Epoch: 15, Batch: 232,Loss: -2.241,Avg.Loss: -2.271,LR: 8.23E-05]Training epoch 15:  68%|██████▊   | 232/341 [00:04<00:02, 53.32it/s, Epoch: 15, Batch: 233,Loss: -2.225,Avg.Loss: -2.271,LR: 8.22E-05]Training epoch 15:  68%|██████▊   | 233/341 [00:04<00:02, 53.32it/s, Epoch: 15, Batch: 234,Loss: -1.880,Avg.Loss: -2.270,LR: 8.21E-05]Training epoch 15:  69%|██████▊   | 234/341 [00:04<00:02, 53.32it/s, Epoch: 15, Batch: 235,Loss: -1.996,Avg.Loss: -2.268,LR: 8.21E-05]Training epoch 15:  69%|██████▉   | 235/341 [00:04<00:01, 53.32it/s, Epoch: 15, Batch: 236,Loss: -1.862,Avg.Loss: -2.267,LR: 8.20E-05]Training epoch 15:  69%|██████▉   | 236/341 [00:04<00:01, 53.32it/s, Epoch: 15, Batch: 237,Loss: -2.383,Avg.Loss: -2.267,LR: 8.19E-05]Training epoch 15:  70%|██████▉   | 237/341 [00:04<00:01, 53.32it/s, Epoch: 15, Batch: 238,Loss: -1.917,Avg.Loss: -2.266,LR: 8.18E-05]Training epoch 15:  70%|██████▉   | 238/341 [00:04<00:01, 53.36it/s, Epoch: 15, Batch: 238,Loss: -1.917,Avg.Loss: -2.266,LR: 8.18E-05]Training epoch 15:  70%|██████▉   | 238/341 [00:04<00:01, 53.36it/s, Epoch: 15, Batch: 239,Loss: -1.488,Avg.Loss: -2.262,LR: 8.17E-05]Training epoch 15:  70%|███████   | 239/341 [00:04<00:01, 53.36it/s, Epoch: 15, Batch: 240,Loss: -1.012,Avg.Loss: -2.257,LR: 8.16E-05]Training epoch 15:  70%|███████   | 240/341 [00:04<00:01, 53.36it/s, Epoch: 15, Batch: 241,Loss: -1.681,Avg.Loss: -2.255,LR: 8.16E-05]Training epoch 15:  71%|███████   | 241/341 [00:04<00:01, 53.36it/s, Epoch: 15, Batch: 242,Loss: -2.524,Avg.Loss: -2.256,LR: 8.15E-05]Training epoch 15:  71%|███████   | 242/341 [00:04<00:01, 53.36it/s, Epoch: 15, Batch: 243,Loss: -2.212,Avg.Loss: -2.256,LR: 8.14E-05]Training epoch 15:  71%|███████▏  | 243/341 [00:04<00:01, 53.36it/s, Epoch: 15, Batch: 244,Loss: -0.354,Avg.Loss: -2.248,LR: 8.13E-05]Training epoch 15:  72%|███████▏  | 244/341 [00:04<00:01, 52.60it/s, Epoch: 15, Batch: 244,Loss: -0.354,Avg.Loss: -2.248,LR: 8.13E-05]Training epoch 15:  72%|███████▏  | 244/341 [00:04<00:01, 52.60it/s, Epoch: 15, Batch: 245,Loss: -1.340,Avg.Loss: -2.244,LR: 8.12E-05]Training epoch 15:  72%|███████▏  | 245/341 [00:04<00:01, 52.60it/s, Epoch: 15, Batch: 246,Loss: -1.394,Avg.Loss: -2.241,LR: 8.11E-05]Training epoch 15:  72%|███████▏  | 246/341 [00:04<00:01, 52.60it/s, Epoch: 15, Batch: 247,Loss: -2.324,Avg.Loss: -2.241,LR: 8.10E-05]Training epoch 15:  72%|███████▏  | 247/341 [00:04<00:01, 52.60it/s, Epoch: 15, Batch: 248,Loss: -2.054,Avg.Loss: -2.240,LR: 8.10E-05]Training epoch 15:  73%|███████▎  | 248/341 [00:04<00:01, 52.60it/s, Epoch: 15, Batch: 249,Loss: -1.616,Avg.Loss: -2.238,LR: 8.09E-05]Training epoch 15:  73%|███████▎  | 249/341 [00:04<00:01, 52.60it/s, Epoch: 15, Batch: 250,Loss: -1.490,Avg.Loss: -2.235,LR: 8.08E-05]Training epoch 15:  73%|███████▎  | 250/341 [00:04<00:01, 52.86it/s, Epoch: 15, Batch: 250,Loss: -1.490,Avg.Loss: -2.235,LR: 8.08E-05]Training epoch 15:  73%|███████▎  | 250/341 [00:04<00:01, 52.86it/s, Epoch: 15, Batch: 251,Loss: -2.262,Avg.Loss: -2.235,LR: 8.07E-05]Training epoch 15:  74%|███████▎  | 251/341 [00:04<00:01, 52.86it/s, Epoch: 15, Batch: 252,Loss: -2.422,Avg.Loss: -2.236,LR: 8.06E-05]Training epoch 15:  74%|███████▍  | 252/341 [00:04<00:01, 52.86it/s, Epoch: 15, Batch: 253,Loss: -1.785,Avg.Loss: -2.234,LR: 8.05E-05]Training epoch 15:  74%|███████▍  | 253/341 [00:04<00:01, 52.86it/s, Epoch: 15, Batch: 254,Loss: -0.954,Avg.Loss: -2.229,LR: 8.04E-05]Training epoch 15:  74%|███████▍  | 254/341 [00:04<00:01, 52.86it/s, Epoch: 15, Batch: 255,Loss: -0.975,Avg.Loss: -2.224,LR: 8.04E-05]Training epoch 15:  75%|███████▍  | 255/341 [00:04<00:01, 52.86it/s, Epoch: 15, Batch: 256,Loss: -1.063,Avg.Loss: -2.219,LR: 8.03E-05]Training epoch 15:  75%|███████▌  | 256/341 [00:04<00:01, 51.86it/s, Epoch: 15, Batch: 256,Loss: -1.063,Avg.Loss: -2.219,LR: 8.03E-05]Training epoch 15:  75%|███████▌  | 256/341 [00:04<00:01, 51.86it/s, Epoch: 15, Batch: 257,Loss: -2.407,Avg.Loss: -2.220,LR: 8.02E-05]Training epoch 15:  75%|███████▌  | 257/341 [00:04<00:01, 51.86it/s, Epoch: 15, Batch: 258,Loss: -2.248,Avg.Loss: -2.220,LR: 8.01E-05]Training epoch 15:  76%|███████▌  | 258/341 [00:04<00:01, 51.86it/s, Epoch: 15, Batch: 259,Loss: -1.883,Avg.Loss: -2.219,LR: 8.00E-05]Training epoch 15:  76%|███████▌  | 259/341 [00:04<00:01, 51.86it/s, Epoch: 15, Batch: 260,Loss: -1.841,Avg.Loss: -2.218,LR: 7.99E-05]Training epoch 15:  76%|███████▌  | 260/341 [00:04<00:01, 51.86it/s, Epoch: 15, Batch: 261,Loss: -1.790,Avg.Loss: -2.216,LR: 7.99E-05]Training epoch 15:  77%|███████▋  | 261/341 [00:04<00:01, 51.86it/s, Epoch: 15, Batch: 262,Loss: -2.316,Avg.Loss: -2.216,LR: 7.98E-05]Training epoch 15:  77%|███████▋  | 262/341 [00:04<00:01, 51.89it/s, Epoch: 15, Batch: 262,Loss: -2.316,Avg.Loss: -2.216,LR: 7.98E-05]Training epoch 15:  77%|███████▋  | 262/341 [00:04<00:01, 51.89it/s, Epoch: 15, Batch: 263,Loss: -1.885,Avg.Loss: -2.215,LR: 7.97E-05]Training epoch 15:  77%|███████▋  | 263/341 [00:05<00:01, 51.89it/s, Epoch: 15, Batch: 264,Loss: -1.084,Avg.Loss: -2.211,LR: 7.96E-05]Training epoch 15:  77%|███████▋  | 264/341 [00:05<00:01, 51.89it/s, Epoch: 15, Batch: 265,Loss: -1.639,Avg.Loss: -2.209,LR: 7.95E-05]Training epoch 15:  78%|███████▊  | 265/341 [00:05<00:01, 51.89it/s, Epoch: 15, Batch: 266,Loss: -2.153,Avg.Loss: -2.208,LR: 7.94E-05]Training epoch 15:  78%|███████▊  | 266/341 [00:05<00:01, 51.89it/s, Epoch: 15, Batch: 267,Loss: -2.685,Avg.Loss: -2.210,LR: 7.94E-05]Training epoch 15:  78%|███████▊  | 267/341 [00:05<00:01, 51.89it/s, Epoch: 15, Batch: 268,Loss: -2.045,Avg.Loss: -2.210,LR: 7.93E-05]Training epoch 15:  79%|███████▊  | 268/341 [00:05<00:01, 52.59it/s, Epoch: 15, Batch: 268,Loss: -2.045,Avg.Loss: -2.210,LR: 7.93E-05]Training epoch 15:  79%|███████▊  | 268/341 [00:05<00:01, 52.59it/s, Epoch: 15, Batch: 269,Loss: -1.881,Avg.Loss: -2.208,LR: 7.92E-05]Training epoch 15:  79%|███████▉  | 269/341 [00:05<00:01, 52.59it/s, Epoch: 15, Batch: 270,Loss: -0.581,Avg.Loss: -2.202,LR: 7.91E-05]Training epoch 15:  79%|███████▉  | 270/341 [00:05<00:01, 52.59it/s, Epoch: 15, Batch: 271,Loss: -1.836,Avg.Loss: -2.201,LR: 7.90E-05]Training epoch 15:  79%|███████▉  | 271/341 [00:05<00:01, 52.59it/s, Epoch: 15, Batch: 272,Loss: -2.194,Avg.Loss: -2.201,LR: 7.89E-05]Training epoch 15:  80%|███████▉  | 272/341 [00:05<00:01, 52.59it/s, Epoch: 15, Batch: 273,Loss: -2.477,Avg.Loss: -2.202,LR: 7.88E-05]Training epoch 15:  80%|████████  | 273/341 [00:05<00:01, 52.59it/s, Epoch: 15, Batch: 274,Loss: -1.842,Avg.Loss: -2.201,LR: 7.88E-05]Training epoch 15:  80%|████████  | 274/341 [00:05<00:01, 52.32it/s, Epoch: 15, Batch: 274,Loss: -1.842,Avg.Loss: -2.201,LR: 7.88E-05]Training epoch 15:  80%|████████  | 274/341 [00:05<00:01, 52.32it/s, Epoch: 15, Batch: 275,Loss: -1.777,Avg.Loss: -2.199,LR: 7.87E-05]Training epoch 15:  81%|████████  | 275/341 [00:05<00:01, 52.32it/s, Epoch: 15, Batch: 276,Loss: -2.315,Avg.Loss: -2.199,LR: 7.86E-05]Training epoch 15:  81%|████████  | 276/341 [00:05<00:01, 52.32it/s, Epoch: 15, Batch: 277,Loss: -2.730,Avg.Loss: -2.201,LR: 7.85E-05]Training epoch 15:  81%|████████  | 277/341 [00:05<00:01, 52.32it/s, Epoch: 15, Batch: 278,Loss: -2.098,Avg.Loss: -2.201,LR: 7.84E-05]Training epoch 15:  82%|████████▏ | 278/341 [00:05<00:01, 52.32it/s, Epoch: 15, Batch: 279,Loss: -1.408,Avg.Loss: -2.198,LR: 7.83E-05]Training epoch 15:  82%|████████▏ | 279/341 [00:05<00:01, 52.32it/s, Epoch: 15, Batch: 280,Loss: -1.115,Avg.Loss: -2.194,LR: 7.83E-05]Training epoch 15:  82%|████████▏ | 280/341 [00:05<00:01, 52.72it/s, Epoch: 15, Batch: 280,Loss: -1.115,Avg.Loss: -2.194,LR: 7.83E-05]Training epoch 15:  82%|████████▏ | 280/341 [00:05<00:01, 52.72it/s, Epoch: 15, Batch: 281,Loss: -1.286,Avg.Loss: -2.191,LR: 7.82E-05]Training epoch 15:  82%|████████▏ | 281/341 [00:05<00:01, 52.72it/s, Epoch: 15, Batch: 282,Loss: -2.686,Avg.Loss: -2.193,LR: 7.81E-05]Training epoch 15:  83%|████████▎ | 282/341 [00:05<00:01, 52.72it/s, Epoch: 15, Batch: 283,Loss: -2.098,Avg.Loss: -2.193,LR: 7.80E-05]Training epoch 15:  83%|████████▎ | 283/341 [00:05<00:01, 52.72it/s, Epoch: 15, Batch: 284,Loss: -1.900,Avg.Loss: -2.191,LR: 7.79E-05]Training epoch 15:  83%|████████▎ | 284/341 [00:05<00:01, 52.72it/s, Epoch: 15, Batch: 285,Loss: -1.806,Avg.Loss: -2.190,LR: 7.78E-05]Training epoch 15:  84%|████████▎ | 285/341 [00:05<00:01, 52.72it/s, Epoch: 15, Batch: 286,Loss: -2.305,Avg.Loss: -2.191,LR: 7.78E-05]Training epoch 15:  84%|████████▍ | 286/341 [00:05<00:01, 53.01it/s, Epoch: 15, Batch: 286,Loss: -2.305,Avg.Loss: -2.191,LR: 7.78E-05]Training epoch 15:  84%|████████▍ | 286/341 [00:05<00:01, 53.01it/s, Epoch: 15, Batch: 287,Loss: -2.611,Avg.Loss: -2.192,LR: 7.77E-05]Training epoch 15:  84%|████████▍ | 287/341 [00:05<00:01, 53.01it/s, Epoch: 15, Batch: 288,Loss: -1.412,Avg.Loss: -2.189,LR: 7.76E-05]Training epoch 15:  84%|████████▍ | 288/341 [00:05<00:00, 53.01it/s, Epoch: 15, Batch: 289,Loss: -0.980,Avg.Loss: -2.185,LR: 7.75E-05]Training epoch 15:  85%|████████▍ | 289/341 [00:05<00:00, 53.01it/s, Epoch: 15, Batch: 290,Loss: -0.927,Avg.Loss: -2.181,LR: 7.74E-05]Training epoch 15:  85%|████████▌ | 290/341 [00:05<00:00, 53.01it/s, Epoch: 15, Batch: 291,Loss: -1.792,Avg.Loss: -2.179,LR: 7.73E-05]Training epoch 15:  85%|████████▌ | 291/341 [00:05<00:00, 53.01it/s, Epoch: 15, Batch: 292,Loss: -2.012,Avg.Loss: -2.179,LR: 7.73E-05]Training epoch 15:  86%|████████▌ | 292/341 [00:05<00:00, 53.31it/s, Epoch: 15, Batch: 292,Loss: -2.012,Avg.Loss: -2.179,LR: 7.73E-05]Training epoch 15:  86%|████████▌ | 292/341 [00:05<00:00, 53.31it/s, Epoch: 15, Batch: 293,Loss: -2.237,Avg.Loss: -2.179,LR: 7.72E-05]Training epoch 15:  86%|████████▌ | 293/341 [00:05<00:00, 53.31it/s, Epoch: 15, Batch: 294,Loss: -1.469,Avg.Loss: -2.177,LR: 7.71E-05]Training epoch 15:  86%|████████▌ | 294/341 [00:05<00:00, 53.31it/s, Epoch: 15, Batch: 295,Loss: -1.462,Avg.Loss: -2.174,LR: 7.70E-05]Training epoch 15:  87%|████████▋ | 295/341 [00:05<00:00, 53.31it/s, Epoch: 15, Batch: 296,Loss: -2.148,Avg.Loss: -2.174,LR: 7.69E-05]Training epoch 15:  87%|████████▋ | 296/341 [00:05<00:00, 53.31it/s, Epoch: 15, Batch: 297,Loss: -2.267,Avg.Loss: -2.174,LR: 7.68E-05]Training epoch 15:  87%|████████▋ | 297/341 [00:05<00:00, 53.31it/s, Epoch: 15, Batch: 298,Loss: -2.092,Avg.Loss: -2.174,LR: 7.68E-05]Training epoch 15:  87%|████████▋ | 298/341 [00:05<00:00, 53.43it/s, Epoch: 15, Batch: 298,Loss: -2.092,Avg.Loss: -2.174,LR: 7.68E-05]Training epoch 15:  87%|████████▋ | 298/341 [00:05<00:00, 53.43it/s, Epoch: 15, Batch: 299,Loss: -1.436,Avg.Loss: -2.172,LR: 7.67E-05]Training epoch 15:  88%|████████▊ | 299/341 [00:05<00:00, 53.43it/s, Epoch: 15, Batch: 300,Loss: -1.135,Avg.Loss: -2.168,LR: 7.66E-05]Training epoch 15:  88%|████████▊ | 300/341 [00:05<00:00, 53.43it/s, Epoch: 15, Batch: 301,Loss: -1.934,Avg.Loss: -2.167,LR: 7.65E-05]Training epoch 15:  88%|████████▊ | 301/341 [00:05<00:00, 53.43it/s, Epoch: 15, Batch: 302,Loss: -2.721,Avg.Loss: -2.169,LR: 7.64E-05]Training epoch 15:  89%|████████▊ | 302/341 [00:05<00:00, 53.43it/s, Epoch: 15, Batch: 303,Loss: -2.321,Avg.Loss: -2.170,LR: 7.63E-05]Training epoch 15:  89%|████████▉ | 303/341 [00:05<00:00, 53.43it/s, Epoch: 15, Batch: 304,Loss: -1.685,Avg.Loss: -2.168,LR: 7.63E-05]Training epoch 15:  89%|████████▉ | 304/341 [00:05<00:00, 54.43it/s, Epoch: 15, Batch: 304,Loss: -1.685,Avg.Loss: -2.168,LR: 7.63E-05]Training epoch 15:  89%|████████▉ | 304/341 [00:05<00:00, 54.43it/s, Epoch: 15, Batch: 305,Loss: -1.597,Avg.Loss: -2.166,LR: 7.62E-05]Training epoch 15:  89%|████████▉ | 305/341 [00:05<00:00, 54.43it/s, Epoch: 15, Batch: 306,Loss: -2.073,Avg.Loss: -2.166,LR: 7.61E-05]Training epoch 15:  90%|████████▉ | 306/341 [00:05<00:00, 54.43it/s, Epoch: 15, Batch: 307,Loss: -2.908,Avg.Loss: -2.168,LR: 7.60E-05]Training epoch 15:  90%|█████████ | 307/341 [00:05<00:00, 54.43it/s, Epoch: 15, Batch: 308,Loss: -2.103,Avg.Loss: -2.168,LR: 7.59E-05]Training epoch 15:  90%|█████████ | 308/341 [00:05<00:00, 54.43it/s, Epoch: 15, Batch: 309,Loss: -1.597,Avg.Loss: -2.166,LR: 7.58E-05]Training epoch 15:  91%|█████████ | 309/341 [00:05<00:00, 54.43it/s, Epoch: 15, Batch: 310,Loss: -2.232,Avg.Loss: -2.167,LR: 7.58E-05]Training epoch 15:  91%|█████████ | 310/341 [00:05<00:00, 54.36it/s, Epoch: 15, Batch: 310,Loss: -2.232,Avg.Loss: -2.167,LR: 7.58E-05]Training epoch 15:  91%|█████████ | 310/341 [00:05<00:00, 54.36it/s, Epoch: 15, Batch: 311,Loss: -2.425,Avg.Loss: -2.167,LR: 7.57E-05]Training epoch 15:  91%|█████████ | 311/341 [00:05<00:00, 54.36it/s, Epoch: 15, Batch: 312,Loss: -2.884,Avg.Loss: -2.170,LR: 7.56E-05]Training epoch 15:  91%|█████████▏| 312/341 [00:05<00:00, 54.36it/s, Epoch: 15, Batch: 313,Loss: -2.289,Avg.Loss: -2.170,LR: 7.55E-05]Training epoch 15:  92%|█████████▏| 313/341 [00:05<00:00, 54.36it/s, Epoch: 15, Batch: 314,Loss: -1.187,Avg.Loss: -2.167,LR: 7.54E-05]Training epoch 15:  92%|█████████▏| 314/341 [00:05<00:00, 54.36it/s, Epoch: 15, Batch: 315,Loss: -1.908,Avg.Loss: -2.166,LR: 7.54E-05]Training epoch 15:  92%|█████████▏| 315/341 [00:05<00:00, 54.36it/s, Epoch: 15, Batch: 316,Loss: -1.944,Avg.Loss: -2.165,LR: 7.53E-05]Training epoch 15:  93%|█████████▎| 316/341 [00:05<00:00, 54.04it/s, Epoch: 15, Batch: 316,Loss: -1.944,Avg.Loss: -2.165,LR: 7.53E-05]Training epoch 15:  93%|█████████▎| 316/341 [00:05<00:00, 54.04it/s, Epoch: 15, Batch: 317,Loss: -2.730,Avg.Loss: -2.167,LR: 7.52E-05]Training epoch 15:  93%|█████████▎| 317/341 [00:06<00:00, 54.04it/s, Epoch: 15, Batch: 318,Loss: -2.261,Avg.Loss: -2.168,LR: 7.51E-05]Training epoch 15:  93%|█████████▎| 318/341 [00:06<00:00, 54.04it/s, Epoch: 15, Batch: 319,Loss: -2.089,Avg.Loss: -2.167,LR: 7.50E-05]Training epoch 15:  94%|█████████▎| 319/341 [00:06<00:00, 54.04it/s, Epoch: 15, Batch: 320,Loss: -2.184,Avg.Loss: -2.167,LR: 7.49E-05]Training epoch 15:  94%|█████████▍| 320/341 [00:06<00:00, 54.04it/s, Epoch: 15, Batch: 321,Loss: -2.282,Avg.Loss: -2.168,LR: 7.49E-05]Training epoch 15:  94%|█████████▍| 321/341 [00:06<00:00, 54.04it/s, Epoch: 15, Batch: 322,Loss: -1.580,Avg.Loss: -2.166,LR: 7.48E-05]Training epoch 15:  94%|█████████▍| 322/341 [00:06<00:00, 54.54it/s, Epoch: 15, Batch: 322,Loss: -1.580,Avg.Loss: -2.166,LR: 7.48E-05]Training epoch 15:  94%|█████████▍| 322/341 [00:06<00:00, 54.54it/s, Epoch: 15, Batch: 323,Loss: -1.800,Avg.Loss: -2.165,LR: 7.47E-05]Training epoch 15:  95%|█████████▍| 323/341 [00:06<00:00, 54.54it/s, Epoch: 15, Batch: 324,Loss: -1.771,Avg.Loss: -2.164,LR: 7.46E-05]Training epoch 15:  95%|█████████▌| 324/341 [00:06<00:00, 54.54it/s, Epoch: 15, Batch: 325,Loss: -2.159,Avg.Loss: -2.163,LR: 7.45E-05]Training epoch 15:  95%|█████████▌| 325/341 [00:06<00:00, 54.54it/s, Epoch: 15, Batch: 326,Loss: -1.641,Avg.Loss: -2.162,LR: 7.44E-05]Training epoch 15:  96%|█████████▌| 326/341 [00:06<00:00, 54.54it/s, Epoch: 15, Batch: 327,Loss: -1.690,Avg.Loss: -2.160,LR: 7.44E-05]Training epoch 15:  96%|█████████▌| 327/341 [00:06<00:00, 54.54it/s, Epoch: 15, Batch: 328,Loss: -1.556,Avg.Loss: -2.159,LR: 7.43E-05]Training epoch 15:  96%|█████████▌| 328/341 [00:06<00:00, 55.14it/s, Epoch: 15, Batch: 328,Loss: -1.556,Avg.Loss: -2.159,LR: 7.43E-05]Training epoch 15:  96%|█████████▌| 328/341 [00:06<00:00, 55.14it/s, Epoch: 15, Batch: 329,Loss: -1.688,Avg.Loss: -2.157,LR: 7.42E-05]Training epoch 15:  96%|█████████▋| 329/341 [00:06<00:00, 55.14it/s, Epoch: 15, Batch: 330,Loss: -2.360,Avg.Loss: -2.158,LR: 7.41E-05]Training epoch 15:  97%|█████████▋| 330/341 [00:06<00:00, 55.14it/s, Epoch: 15, Batch: 331,Loss: -2.187,Avg.Loss: -2.158,LR: 7.40E-05]Training epoch 15:  97%|█████████▋| 331/341 [00:06<00:00, 55.14it/s, Epoch: 15, Batch: 332,Loss: -1.098,Avg.Loss: -2.155,LR: 7.40E-05]Training epoch 15:  97%|█████████▋| 332/341 [00:06<00:00, 55.14it/s, Epoch: 15, Batch: 333,Loss: -0.074,Avg.Loss: -2.148,LR: 7.39E-05]Training epoch 15:  98%|█████████▊| 333/341 [00:06<00:00, 55.14it/s, Epoch: 15, Batch: 334,Loss: -1.258,Avg.Loss: -2.146,LR: 7.38E-05]Training epoch 15:  98%|█████████▊| 334/341 [00:06<00:00, 55.40it/s, Epoch: 15, Batch: 334,Loss: -1.258,Avg.Loss: -2.146,LR: 7.38E-05]Training epoch 15:  98%|█████████▊| 334/341 [00:06<00:00, 55.40it/s, Epoch: 15, Batch: 335,Loss: -2.079,Avg.Loss: -2.146,LR: 7.37E-05]Training epoch 15:  98%|█████████▊| 335/341 [00:06<00:00, 55.40it/s, Epoch: 15, Batch: 336,Loss: -2.290,Avg.Loss: -2.146,LR: 7.36E-05]Training epoch 15:  99%|█████████▊| 336/341 [00:06<00:00, 55.40it/s, Epoch: 15, Batch: 337,Loss: -2.207,Avg.Loss: -2.146,LR: 7.35E-05]Training epoch 15:  99%|█████████▉| 337/341 [00:06<00:00, 55.40it/s, Epoch: 15, Batch: 338,Loss: -1.903,Avg.Loss: -2.145,LR: 7.35E-05]Training epoch 15:  99%|█████████▉| 338/341 [00:06<00:00, 55.40it/s, Epoch: 15, Batch: 339,Loss: -2.335,Avg.Loss: -2.146,LR: 7.34E-05]Training epoch 15:  99%|█████████▉| 339/341 [00:06<00:00, 55.40it/s, Epoch: 15, Batch: 340,Loss: -2.302,Avg.Loss: -2.146,LR: 7.33E-05]Training epoch 15: 100%|█████████▉| 340/341 [00:06<00:00, 54.98it/s, Epoch: 15, Batch: 340,Loss: -2.302,Avg.Loss: -2.146,LR: 7.33E-05]Training epoch 15: 100%|█████████▉| 340/341 [00:06<00:00, 54.98it/s, Epoch: 15, Batch: 341,Loss: -2.803,Avg.Loss: -2.148,LR: 7.32E-05]Training epoch 15: 100%|██████████| 341/341 [00:06<00:00, 53.07it/s, Epoch: 15, Batch: 341,Loss: -2.803,Avg.Loss: -2.148,LR: 7.32E-05]
Training epoch 16:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 16:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 16, Batch: 1,Loss: -2.022,Avg.Loss: -2.022,LR: 7.31E-05]Training epoch 16:   0%|          | 1/341 [00:00<00:12, 27.74it/s, Epoch: 16, Batch: 2,Loss: -2.236,Avg.Loss: -2.129,LR: 7.31E-05]Training epoch 16:   1%|          | 2/341 [00:00<00:09, 37.35it/s, Epoch: 16, Batch: 3,Loss: -2.522,Avg.Loss: -2.260,LR: 7.30E-05]Training epoch 16:   1%|          | 3/341 [00:00<00:08, 41.62it/s, Epoch: 16, Batch: 4,Loss: -2.524,Avg.Loss: -2.326,LR: 7.29E-05]Training epoch 16:   1%|          | 4/341 [00:00<00:07, 44.11it/s, Epoch: 16, Batch: 5,Loss: -2.313,Avg.Loss: -2.323,LR: 7.28E-05]Training epoch 16:   1%|▏         | 5/341 [00:00<00:07, 45.71it/s, Epoch: 16, Batch: 6,Loss: -2.729,Avg.Loss: -2.391,LR: 7.27E-05]Training epoch 16:   2%|▏         | 6/341 [00:00<00:06, 54.75it/s, Epoch: 16, Batch: 6,Loss: -2.729,Avg.Loss: -2.391,LR: 7.27E-05]Training epoch 16:   2%|▏         | 6/341 [00:00<00:06, 54.75it/s, Epoch: 16, Batch: 7,Loss: -2.378,Avg.Loss: -2.389,LR: 7.27E-05]Training epoch 16:   2%|▏         | 7/341 [00:00<00:06, 54.75it/s, Epoch: 16, Batch: 8,Loss: -2.632,Avg.Loss: -2.420,LR: 7.26E-05]Training epoch 16:   2%|▏         | 8/341 [00:00<00:06, 54.75it/s, Epoch: 16, Batch: 9,Loss: -2.669,Avg.Loss: -2.447,LR: 7.25E-05]Training epoch 16:   3%|▎         | 9/341 [00:00<00:06, 54.75it/s, Epoch: 16, Batch: 10,Loss: -2.639,Avg.Loss: -2.466,LR: 7.24E-05]Training epoch 16:   3%|▎         | 10/341 [00:00<00:06, 54.75it/s, Epoch: 16, Batch: 11,Loss: -2.357,Avg.Loss: -2.457,LR: 7.23E-05]Training epoch 16:   3%|▎         | 11/341 [00:00<00:06, 54.75it/s, Epoch: 16, Batch: 12,Loss: -2.529,Avg.Loss: -2.463,LR: 7.22E-05]Training epoch 16:   4%|▎         | 12/341 [00:00<00:06, 54.48it/s, Epoch: 16, Batch: 12,Loss: -2.529,Avg.Loss: -2.463,LR: 7.22E-05]Training epoch 16:   4%|▎         | 12/341 [00:00<00:06, 54.48it/s, Epoch: 16, Batch: 13,Loss: -2.386,Avg.Loss: -2.457,LR: 7.22E-05]Training epoch 16:   4%|▍         | 13/341 [00:00<00:06, 54.48it/s, Epoch: 16, Batch: 14,Loss: -2.665,Avg.Loss: -2.472,LR: 7.21E-05]Training epoch 16:   4%|▍         | 14/341 [00:00<00:06, 54.48it/s, Epoch: 16, Batch: 15,Loss: -2.846,Avg.Loss: -2.497,LR: 7.20E-05]Training epoch 16:   4%|▍         | 15/341 [00:00<00:05, 54.48it/s, Epoch: 16, Batch: 16,Loss: -2.659,Avg.Loss: -2.507,LR: 7.19E-05]Training epoch 16:   5%|▍         | 16/341 [00:00<00:05, 54.48it/s, Epoch: 16, Batch: 17,Loss: -2.622,Avg.Loss: -2.513,LR: 7.18E-05]Training epoch 16:   5%|▍         | 17/341 [00:00<00:05, 54.48it/s, Epoch: 16, Batch: 18,Loss: -2.584,Avg.Loss: -2.517,LR: 7.18E-05]Training epoch 16:   5%|▌         | 18/341 [00:00<00:05, 53.90it/s, Epoch: 16, Batch: 18,Loss: -2.584,Avg.Loss: -2.517,LR: 7.18E-05]Training epoch 16:   5%|▌         | 18/341 [00:00<00:05, 53.90it/s, Epoch: 16, Batch: 19,Loss: -2.761,Avg.Loss: -2.530,LR: 7.17E-05]Training epoch 16:   6%|▌         | 19/341 [00:00<00:05, 53.90it/s, Epoch: 16, Batch: 20,Loss: -2.268,Avg.Loss: -2.517,LR: 7.16E-05]Training epoch 16:   6%|▌         | 20/341 [00:00<00:05, 53.90it/s, Epoch: 16, Batch: 21,Loss: -2.522,Avg.Loss: -2.517,LR: 7.15E-05]Training epoch 16:   6%|▌         | 21/341 [00:00<00:05, 53.90it/s, Epoch: 16, Batch: 22,Loss: -2.491,Avg.Loss: -2.516,LR: 7.14E-05]Training epoch 16:   6%|▋         | 22/341 [00:00<00:05, 53.90it/s, Epoch: 16, Batch: 23,Loss: -2.196,Avg.Loss: -2.502,LR: 7.14E-05]Training epoch 16:   7%|▋         | 23/341 [00:00<00:05, 53.90it/s, Epoch: 16, Batch: 24,Loss: -2.634,Avg.Loss: -2.508,LR: 7.13E-05]Training epoch 16:   7%|▋         | 24/341 [00:00<00:05, 54.22it/s, Epoch: 16, Batch: 24,Loss: -2.634,Avg.Loss: -2.508,LR: 7.13E-05]Training epoch 16:   7%|▋         | 24/341 [00:00<00:05, 54.22it/s, Epoch: 16, Batch: 25,Loss: -2.465,Avg.Loss: -2.506,LR: 7.12E-05]Training epoch 16:   7%|▋         | 25/341 [00:00<00:05, 54.22it/s, Epoch: 16, Batch: 26,Loss: -2.542,Avg.Loss: -2.507,LR: 7.11E-05]Training epoch 16:   8%|▊         | 26/341 [00:00<00:05, 54.22it/s, Epoch: 16, Batch: 27,Loss: -2.509,Avg.Loss: -2.507,LR: 7.10E-05]Training epoch 16:   8%|▊         | 27/341 [00:00<00:05, 54.22it/s, Epoch: 16, Batch: 28,Loss: -2.249,Avg.Loss: -2.498,LR: 7.10E-05]Training epoch 16:   8%|▊         | 28/341 [00:00<00:05, 54.22it/s, Epoch: 16, Batch: 29,Loss: -2.724,Avg.Loss: -2.506,LR: 7.09E-05]Training epoch 16:   9%|▊         | 29/341 [00:00<00:05, 54.22it/s, Epoch: 16, Batch: 30,Loss: -2.258,Avg.Loss: -2.498,LR: 7.08E-05]Training epoch 16:   9%|▉         | 30/341 [00:00<00:05, 53.15it/s, Epoch: 16, Batch: 30,Loss: -2.258,Avg.Loss: -2.498,LR: 7.08E-05]Training epoch 16:   9%|▉         | 30/341 [00:00<00:05, 53.15it/s, Epoch: 16, Batch: 31,Loss: -2.342,Avg.Loss: -2.493,LR: 7.07E-05]Training epoch 16:   9%|▉         | 31/341 [00:00<00:05, 53.15it/s, Epoch: 16, Batch: 32,Loss: -2.468,Avg.Loss: -2.492,LR: 7.06E-05]Training epoch 16:   9%|▉         | 32/341 [00:00<00:05, 53.15it/s, Epoch: 16, Batch: 33,Loss: -1.938,Avg.Loss: -2.475,LR: 7.06E-05]Training epoch 16:  10%|▉         | 33/341 [00:00<00:05, 53.15it/s, Epoch: 16, Batch: 34,Loss: -2.369,Avg.Loss: -2.472,LR: 7.05E-05]Training epoch 16:  10%|▉         | 34/341 [00:00<00:05, 53.15it/s, Epoch: 16, Batch: 35,Loss: -2.074,Avg.Loss: -2.461,LR: 7.04E-05]Training epoch 16:  10%|█         | 35/341 [00:00<00:05, 53.15it/s, Epoch: 16, Batch: 36,Loss: -2.201,Avg.Loss: -2.453,LR: 7.03E-05]Training epoch 16:  11%|█         | 36/341 [00:00<00:05, 53.43it/s, Epoch: 16, Batch: 36,Loss: -2.201,Avg.Loss: -2.453,LR: 7.03E-05]Training epoch 16:  11%|█         | 36/341 [00:00<00:05, 53.43it/s, Epoch: 16, Batch: 37,Loss: -2.459,Avg.Loss: -2.454,LR: 7.02E-05]Training epoch 16:  11%|█         | 37/341 [00:00<00:05, 53.43it/s, Epoch: 16, Batch: 38,Loss: -2.334,Avg.Loss: -2.450,LR: 7.02E-05]Training epoch 16:  11%|█         | 38/341 [00:00<00:05, 53.43it/s, Epoch: 16, Batch: 39,Loss: -2.032,Avg.Loss: -2.440,LR: 7.01E-05]Training epoch 16:  11%|█▏        | 39/341 [00:00<00:05, 53.43it/s, Epoch: 16, Batch: 40,Loss: -2.250,Avg.Loss: -2.435,LR: 7.00E-05]Training epoch 16:  12%|█▏        | 40/341 [00:00<00:05, 53.43it/s, Epoch: 16, Batch: 41,Loss: -2.371,Avg.Loss: -2.433,LR: 6.99E-05]Training epoch 16:  12%|█▏        | 41/341 [00:00<00:05, 53.43it/s, Epoch: 16, Batch: 42,Loss: -1.780,Avg.Loss: -2.418,LR: 6.98E-05]Training epoch 16:  12%|█▏        | 42/341 [00:00<00:05, 54.28it/s, Epoch: 16, Batch: 42,Loss: -1.780,Avg.Loss: -2.418,LR: 6.98E-05]Training epoch 16:  12%|█▏        | 42/341 [00:00<00:05, 54.28it/s, Epoch: 16, Batch: 43,Loss: -2.163,Avg.Loss: -2.412,LR: 6.98E-05]Training epoch 16:  13%|█▎        | 43/341 [00:00<00:05, 54.28it/s, Epoch: 16, Batch: 44,Loss: -2.415,Avg.Loss: -2.412,LR: 6.97E-05]Training epoch 16:  13%|█▎        | 44/341 [00:00<00:05, 54.28it/s, Epoch: 16, Batch: 45,Loss: -2.457,Avg.Loss: -2.413,LR: 6.96E-05]Training epoch 16:  13%|█▎        | 45/341 [00:00<00:05, 54.28it/s, Epoch: 16, Batch: 46,Loss: -2.434,Avg.Loss: -2.413,LR: 6.95E-05]Training epoch 16:  13%|█▎        | 46/341 [00:00<00:05, 54.28it/s, Epoch: 16, Batch: 47,Loss: -2.110,Avg.Loss: -2.407,LR: 6.94E-05]Training epoch 16:  14%|█▍        | 47/341 [00:00<00:05, 54.28it/s, Epoch: 16, Batch: 48,Loss: -2.031,Avg.Loss: -2.399,LR: 6.94E-05]Training epoch 16:  14%|█▍        | 48/341 [00:00<00:05, 54.25it/s, Epoch: 16, Batch: 48,Loss: -2.031,Avg.Loss: -2.399,LR: 6.94E-05]Training epoch 16:  14%|█▍        | 48/341 [00:00<00:05, 54.25it/s, Epoch: 16, Batch: 49,Loss: -2.560,Avg.Loss: -2.402,LR: 6.93E-05]Training epoch 16:  14%|█▍        | 49/341 [00:00<00:05, 54.25it/s, Epoch: 16, Batch: 50,Loss: -2.038,Avg.Loss: -2.395,LR: 6.92E-05]Training epoch 16:  15%|█▍        | 50/341 [00:00<00:05, 54.25it/s, Epoch: 16, Batch: 51,Loss: -2.636,Avg.Loss: -2.400,LR: 6.91E-05]Training epoch 16:  15%|█▍        | 51/341 [00:00<00:05, 54.25it/s, Epoch: 16, Batch: 52,Loss: -2.558,Avg.Loss: -2.403,LR: 6.90E-05]Training epoch 16:  15%|█▌        | 52/341 [00:00<00:05, 54.25it/s, Epoch: 16, Batch: 53,Loss: -2.362,Avg.Loss: -2.402,LR: 6.90E-05]Training epoch 16:  16%|█▌        | 53/341 [00:00<00:05, 54.25it/s, Epoch: 16, Batch: 54,Loss: -2.218,Avg.Loss: -2.399,LR: 6.89E-05]Training epoch 16:  16%|█▌        | 54/341 [00:00<00:05, 54.67it/s, Epoch: 16, Batch: 54,Loss: -2.218,Avg.Loss: -2.399,LR: 6.89E-05]Training epoch 16:  16%|█▌        | 54/341 [00:01<00:05, 54.67it/s, Epoch: 16, Batch: 55,Loss: -2.017,Avg.Loss: -2.392,LR: 6.88E-05]Training epoch 16:  16%|█▌        | 55/341 [00:01<00:05, 54.67it/s, Epoch: 16, Batch: 56,Loss: -2.279,Avg.Loss: -2.390,LR: 6.87E-05]Training epoch 16:  16%|█▋        | 56/341 [00:01<00:05, 54.67it/s, Epoch: 16, Batch: 57,Loss: -2.513,Avg.Loss: -2.392,LR: 6.86E-05]Training epoch 16:  17%|█▋        | 57/341 [00:01<00:05, 54.67it/s, Epoch: 16, Batch: 58,Loss: -2.316,Avg.Loss: -2.391,LR: 6.86E-05]Training epoch 16:  17%|█▋        | 58/341 [00:01<00:05, 54.67it/s, Epoch: 16, Batch: 59,Loss: -1.854,Avg.Loss: -2.382,LR: 6.85E-05]Training epoch 16:  17%|█▋        | 59/341 [00:01<00:05, 54.67it/s, Epoch: 16, Batch: 60,Loss: -1.984,Avg.Loss: -2.375,LR: 6.84E-05]Training epoch 16:  18%|█▊        | 60/341 [00:01<00:05, 54.61it/s, Epoch: 16, Batch: 60,Loss: -1.984,Avg.Loss: -2.375,LR: 6.84E-05]Training epoch 16:  18%|█▊        | 60/341 [00:01<00:05, 54.61it/s, Epoch: 16, Batch: 61,Loss: -2.308,Avg.Loss: -2.374,LR: 6.83E-05]Training epoch 16:  18%|█▊        | 61/341 [00:01<00:05, 54.61it/s, Epoch: 16, Batch: 62,Loss: -2.445,Avg.Loss: -2.375,LR: 6.82E-05]Training epoch 16:  18%|█▊        | 62/341 [00:01<00:05, 54.61it/s, Epoch: 16, Batch: 63,Loss: -2.186,Avg.Loss: -2.372,LR: 6.82E-05]Training epoch 16:  18%|█▊        | 63/341 [00:01<00:05, 54.61it/s, Epoch: 16, Batch: 64,Loss: -2.340,Avg.Loss: -2.371,LR: 6.81E-05]Training epoch 16:  19%|█▉        | 64/341 [00:01<00:05, 54.61it/s, Epoch: 16, Batch: 65,Loss: -2.519,Avg.Loss: -2.374,LR: 6.80E-05]Training epoch 16:  19%|█▉        | 65/341 [00:01<00:05, 54.61it/s, Epoch: 16, Batch: 66,Loss: -2.416,Avg.Loss: -2.374,LR: 6.79E-05]Training epoch 16:  19%|█▉        | 66/341 [00:01<00:05, 54.27it/s, Epoch: 16, Batch: 66,Loss: -2.416,Avg.Loss: -2.374,LR: 6.79E-05]Training epoch 16:  19%|█▉        | 66/341 [00:01<00:05, 54.27it/s, Epoch: 16, Batch: 67,Loss: -2.219,Avg.Loss: -2.372,LR: 6.79E-05]Training epoch 16:  20%|█▉        | 67/341 [00:01<00:05, 54.27it/s, Epoch: 16, Batch: 68,Loss: -2.458,Avg.Loss: -2.373,LR: 6.78E-05]Training epoch 16:  20%|█▉        | 68/341 [00:01<00:05, 54.27it/s, Epoch: 16, Batch: 69,Loss: -2.207,Avg.Loss: -2.371,LR: 6.77E-05]Training epoch 16:  20%|██        | 69/341 [00:01<00:05, 54.27it/s, Epoch: 16, Batch: 70,Loss: -2.564,Avg.Loss: -2.374,LR: 6.76E-05]Training epoch 16:  21%|██        | 70/341 [00:01<00:04, 54.27it/s, Epoch: 16, Batch: 71,Loss: -2.359,Avg.Loss: -2.373,LR: 6.75E-05]Training epoch 16:  21%|██        | 71/341 [00:01<00:04, 54.27it/s, Epoch: 16, Batch: 72,Loss: -2.134,Avg.Loss: -2.370,LR: 6.75E-05]Training epoch 16:  21%|██        | 72/341 [00:01<00:04, 54.15it/s, Epoch: 16, Batch: 72,Loss: -2.134,Avg.Loss: -2.370,LR: 6.75E-05]Training epoch 16:  21%|██        | 72/341 [00:01<00:04, 54.15it/s, Epoch: 16, Batch: 73,Loss: -2.484,Avg.Loss: -2.372,LR: 6.74E-05]Training epoch 16:  21%|██▏       | 73/341 [00:01<00:04, 54.15it/s, Epoch: 16, Batch: 74,Loss: -2.342,Avg.Loss: -2.371,LR: 6.73E-05]Training epoch 16:  22%|██▏       | 74/341 [00:01<00:04, 54.15it/s, Epoch: 16, Batch: 75,Loss: -1.997,Avg.Loss: -2.366,LR: 6.72E-05]Training epoch 16:  22%|██▏       | 75/341 [00:01<00:04, 54.15it/s, Epoch: 16, Batch: 76,Loss: -2.196,Avg.Loss: -2.364,LR: 6.71E-05]Training epoch 16:  22%|██▏       | 76/341 [00:01<00:04, 54.15it/s, Epoch: 16, Batch: 77,Loss: -2.412,Avg.Loss: -2.365,LR: 6.71E-05]Training epoch 16:  23%|██▎       | 77/341 [00:01<00:04, 54.15it/s, Epoch: 16, Batch: 78,Loss: -2.180,Avg.Loss: -2.362,LR: 6.70E-05]Training epoch 16:  23%|██▎       | 78/341 [00:01<00:04, 54.52it/s, Epoch: 16, Batch: 78,Loss: -2.180,Avg.Loss: -2.362,LR: 6.70E-05]Training epoch 16:  23%|██▎       | 78/341 [00:01<00:04, 54.52it/s, Epoch: 16, Batch: 79,Loss: -2.258,Avg.Loss: -2.361,LR: 6.69E-05]Training epoch 16:  23%|██▎       | 79/341 [00:01<00:04, 54.52it/s, Epoch: 16, Batch: 80,Loss: -1.843,Avg.Loss: -2.355,LR: 6.68E-05]Training epoch 16:  23%|██▎       | 80/341 [00:01<00:04, 54.52it/s, Epoch: 16, Batch: 81,Loss: -2.466,Avg.Loss: -2.356,LR: 6.68E-05]Training epoch 16:  24%|██▍       | 81/341 [00:01<00:04, 54.52it/s, Epoch: 16, Batch: 82,Loss: -2.665,Avg.Loss: -2.360,LR: 6.67E-05]Training epoch 16:  24%|██▍       | 82/341 [00:01<00:04, 54.52it/s, Epoch: 16, Batch: 83,Loss: -2.643,Avg.Loss: -2.363,LR: 6.66E-05]Training epoch 16:  24%|██▍       | 83/341 [00:01<00:04, 54.52it/s, Epoch: 16, Batch: 84,Loss: -2.489,Avg.Loss: -2.365,LR: 6.65E-05]Training epoch 16:  25%|██▍       | 84/341 [00:01<00:04, 55.06it/s, Epoch: 16, Batch: 84,Loss: -2.489,Avg.Loss: -2.365,LR: 6.65E-05]Training epoch 16:  25%|██▍       | 84/341 [00:01<00:04, 55.06it/s, Epoch: 16, Batch: 85,Loss: -2.328,Avg.Loss: -2.364,LR: 6.64E-05]Training epoch 16:  25%|██▍       | 85/341 [00:01<00:04, 55.06it/s, Epoch: 16, Batch: 86,Loss: -2.350,Avg.Loss: -2.364,LR: 6.64E-05]Training epoch 16:  25%|██▌       | 86/341 [00:01<00:04, 55.06it/s, Epoch: 16, Batch: 87,Loss: -1.651,Avg.Loss: -2.356,LR: 6.63E-05]Training epoch 16:  26%|██▌       | 87/341 [00:01<00:04, 55.06it/s, Epoch: 16, Batch: 88,Loss: -2.156,Avg.Loss: -2.354,LR: 6.62E-05]Training epoch 16:  26%|██▌       | 88/341 [00:01<00:04, 55.06it/s, Epoch: 16, Batch: 89,Loss: -1.822,Avg.Loss: -2.348,LR: 6.61E-05]Training epoch 16:  26%|██▌       | 89/341 [00:01<00:04, 55.06it/s, Epoch: 16, Batch: 90,Loss: -2.383,Avg.Loss: -2.348,LR: 6.60E-05]Training epoch 16:  26%|██▋       | 90/341 [00:01<00:04, 54.93it/s, Epoch: 16, Batch: 90,Loss: -2.383,Avg.Loss: -2.348,LR: 6.60E-05]Training epoch 16:  26%|██▋       | 90/341 [00:01<00:04, 54.93it/s, Epoch: 16, Batch: 91,Loss: -2.359,Avg.Loss: -2.348,LR: 6.60E-05]Training epoch 16:  27%|██▋       | 91/341 [00:01<00:04, 54.93it/s, Epoch: 16, Batch: 92,Loss: -2.663,Avg.Loss: -2.351,LR: 6.59E-05]Training epoch 16:  27%|██▋       | 92/341 [00:01<00:04, 54.93it/s, Epoch: 16, Batch: 93,Loss: -2.690,Avg.Loss: -2.355,LR: 6.58E-05]Training epoch 16:  27%|██▋       | 93/341 [00:01<00:04, 54.93it/s, Epoch: 16, Batch: 94,Loss: -2.483,Avg.Loss: -2.356,LR: 6.57E-05]Training epoch 16:  28%|██▊       | 94/341 [00:01<00:04, 54.93it/s, Epoch: 16, Batch: 95,Loss: -2.417,Avg.Loss: -2.357,LR: 6.57E-05]Training epoch 16:  28%|██▊       | 95/341 [00:01<00:04, 54.93it/s, Epoch: 16, Batch: 96,Loss: -2.388,Avg.Loss: -2.357,LR: 6.56E-05]Training epoch 16:  28%|██▊       | 96/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 96,Loss: -2.388,Avg.Loss: -2.357,LR: 6.56E-05]Training epoch 16:  28%|██▊       | 96/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 97,Loss: -2.098,Avg.Loss: -2.355,LR: 6.55E-05]Training epoch 16:  28%|██▊       | 97/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 98,Loss: -2.789,Avg.Loss: -2.359,LR: 6.54E-05]Training epoch 16:  29%|██▊       | 98/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 99,Loss: -2.235,Avg.Loss: -2.358,LR: 6.53E-05]Training epoch 16:  29%|██▉       | 99/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 100,Loss: -2.631,Avg.Loss: -2.361,LR: 6.53E-05]Training epoch 16:  29%|██▉       | 100/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 101,Loss: -2.707,Avg.Loss: -2.364,LR: 6.52E-05]Training epoch 16:  30%|██▉       | 101/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 102,Loss: -2.334,Avg.Loss: -2.364,LR: 6.51E-05]Training epoch 16:  30%|██▉       | 102/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 102,Loss: -2.334,Avg.Loss: -2.364,LR: 6.51E-05]Training epoch 16:  30%|██▉       | 102/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 103,Loss: -2.568,Avg.Loss: -2.366,LR: 6.50E-05]Training epoch 16:  30%|███       | 103/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 104,Loss: -2.655,Avg.Loss: -2.369,LR: 6.50E-05]Training epoch 16:  30%|███       | 104/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 105,Loss: -2.337,Avg.Loss: -2.368,LR: 6.49E-05]Training epoch 16:  31%|███       | 105/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 106,Loss: -2.212,Avg.Loss: -2.367,LR: 6.48E-05]Training epoch 16:  31%|███       | 106/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 107,Loss: -2.030,Avg.Loss: -2.364,LR: 6.47E-05]Training epoch 16:  31%|███▏      | 107/341 [00:01<00:04, 54.70it/s, Epoch: 16, Batch: 108,Loss: -2.699,Avg.Loss: -2.367,LR: 6.47E-05]Training epoch 16:  32%|███▏      | 108/341 [00:02<00:04, 52.46it/s, Epoch: 16, Batch: 108,Loss: -2.699,Avg.Loss: -2.367,LR: 6.47E-05]Training epoch 16:  32%|███▏      | 108/341 [00:02<00:04, 52.46it/s, Epoch: 16, Batch: 109,Loss: -2.634,Avg.Loss: -2.369,LR: 6.46E-05]Training epoch 16:  32%|███▏      | 109/341 [00:02<00:04, 52.46it/s, Epoch: 16, Batch: 110,Loss: -2.776,Avg.Loss: -2.373,LR: 6.45E-05]Training epoch 16:  32%|███▏      | 110/341 [00:02<00:04, 52.46it/s, Epoch: 16, Batch: 111,Loss: -2.309,Avg.Loss: -2.372,LR: 6.44E-05]Training epoch 16:  33%|███▎      | 111/341 [00:02<00:04, 52.46it/s, Epoch: 16, Batch: 112,Loss: -2.762,Avg.Loss: -2.376,LR: 6.43E-05]Training epoch 16:  33%|███▎      | 112/341 [00:02<00:04, 52.46it/s, Epoch: 16, Batch: 113,Loss: -2.589,Avg.Loss: -2.378,LR: 6.43E-05]Training epoch 16:  33%|███▎      | 113/341 [00:02<00:04, 52.46it/s, Epoch: 16, Batch: 114,Loss: -2.502,Avg.Loss: -2.379,LR: 6.42E-05]Training epoch 16:  33%|███▎      | 114/341 [00:02<00:04, 51.91it/s, Epoch: 16, Batch: 114,Loss: -2.502,Avg.Loss: -2.379,LR: 6.42E-05]Training epoch 16:  33%|███▎      | 114/341 [00:02<00:04, 51.91it/s, Epoch: 16, Batch: 115,Loss: -2.356,Avg.Loss: -2.379,LR: 6.41E-05]Training epoch 16:  34%|███▎      | 115/341 [00:02<00:04, 51.91it/s, Epoch: 16, Batch: 116,Loss: -2.326,Avg.Loss: -2.378,LR: 6.40E-05]Training epoch 16:  34%|███▍      | 116/341 [00:02<00:04, 51.91it/s, Epoch: 16, Batch: 117,Loss: -2.118,Avg.Loss: -2.376,LR: 6.40E-05]Training epoch 16:  34%|███▍      | 117/341 [00:02<00:04, 51.91it/s, Epoch: 16, Batch: 118,Loss: -1.865,Avg.Loss: -2.372,LR: 6.39E-05]Training epoch 16:  35%|███▍      | 118/341 [00:02<00:04, 51.91it/s, Epoch: 16, Batch: 119,Loss: -2.056,Avg.Loss: -2.369,LR: 6.38E-05]Training epoch 16:  35%|███▍      | 119/341 [00:02<00:04, 51.91it/s, Epoch: 16, Batch: 120,Loss: -2.562,Avg.Loss: -2.371,LR: 6.37E-05]Training epoch 16:  35%|███▌      | 120/341 [00:02<00:04, 51.22it/s, Epoch: 16, Batch: 120,Loss: -2.562,Avg.Loss: -2.371,LR: 6.37E-05]Training epoch 16:  35%|███▌      | 120/341 [00:02<00:04, 51.22it/s, Epoch: 16, Batch: 121,Loss: -2.032,Avg.Loss: -2.368,LR: 6.36E-05]Training epoch 16:  35%|███▌      | 121/341 [00:02<00:04, 51.22it/s, Epoch: 16, Batch: 122,Loss: -1.914,Avg.Loss: -2.364,LR: 6.36E-05]Training epoch 16:  36%|███▌      | 122/341 [00:02<00:04, 51.22it/s, Epoch: 16, Batch: 123,Loss: -2.206,Avg.Loss: -2.363,LR: 6.35E-05]Training epoch 16:  36%|███▌      | 123/341 [00:02<00:04, 51.22it/s, Epoch: 16, Batch: 124,Loss: -2.426,Avg.Loss: -2.363,LR: 6.34E-05]Training epoch 16:  36%|███▋      | 124/341 [00:02<00:04, 51.22it/s, Epoch: 16, Batch: 125,Loss: -2.325,Avg.Loss: -2.363,LR: 6.33E-05]Training epoch 16:  37%|███▋      | 125/341 [00:02<00:04, 51.22it/s, Epoch: 16, Batch: 126,Loss: -2.427,Avg.Loss: -2.363,LR: 6.33E-05]Training epoch 16:  37%|███▋      | 126/341 [00:02<00:04, 52.10it/s, Epoch: 16, Batch: 126,Loss: -2.427,Avg.Loss: -2.363,LR: 6.33E-05]Training epoch 16:  37%|███▋      | 126/341 [00:02<00:04, 52.10it/s, Epoch: 16, Batch: 127,Loss: -2.375,Avg.Loss: -2.364,LR: 6.32E-05]Training epoch 16:  37%|███▋      | 127/341 [00:02<00:04, 52.10it/s, Epoch: 16, Batch: 128,Loss: -2.346,Avg.Loss: -2.363,LR: 6.31E-05]Training epoch 16:  38%|███▊      | 128/341 [00:02<00:04, 52.10it/s, Epoch: 16, Batch: 129,Loss: -2.706,Avg.Loss: -2.366,LR: 6.30E-05]Training epoch 16:  38%|███▊      | 129/341 [00:02<00:04, 52.10it/s, Epoch: 16, Batch: 130,Loss: -2.347,Avg.Loss: -2.366,LR: 6.30E-05]Training epoch 16:  38%|███▊      | 130/341 [00:02<00:04, 52.10it/s, Epoch: 16, Batch: 131,Loss: -2.602,Avg.Loss: -2.368,LR: 6.29E-05]Training epoch 16:  38%|███▊      | 131/341 [00:02<00:04, 52.10it/s, Epoch: 16, Batch: 132,Loss: -2.333,Avg.Loss: -2.367,LR: 6.28E-05]Training epoch 16:  39%|███▊      | 132/341 [00:02<00:03, 52.62it/s, Epoch: 16, Batch: 132,Loss: -2.333,Avg.Loss: -2.367,LR: 6.28E-05]Training epoch 16:  39%|███▊      | 132/341 [00:02<00:03, 52.62it/s, Epoch: 16, Batch: 133,Loss: -2.617,Avg.Loss: -2.369,LR: 6.27E-05]Training epoch 16:  39%|███▉      | 133/341 [00:02<00:03, 52.62it/s, Epoch: 16, Batch: 134,Loss: -2.307,Avg.Loss: -2.369,LR: 6.27E-05]Training epoch 16:  39%|███▉      | 134/341 [00:02<00:03, 52.62it/s, Epoch: 16, Batch: 135,Loss: -2.372,Avg.Loss: -2.369,LR: 6.26E-05]Training epoch 16:  40%|███▉      | 135/341 [00:02<00:03, 52.62it/s, Epoch: 16, Batch: 136,Loss: -2.631,Avg.Loss: -2.371,LR: 6.25E-05]Training epoch 16:  40%|███▉      | 136/341 [00:02<00:03, 52.62it/s, Epoch: 16, Batch: 137,Loss: -2.711,Avg.Loss: -2.373,LR: 6.24E-05]Training epoch 16:  40%|████      | 137/341 [00:02<00:03, 52.62it/s, Epoch: 16, Batch: 138,Loss: -2.476,Avg.Loss: -2.374,LR: 6.24E-05]Training epoch 16:  40%|████      | 138/341 [00:02<00:03, 53.53it/s, Epoch: 16, Batch: 138,Loss: -2.476,Avg.Loss: -2.374,LR: 6.24E-05]Training epoch 16:  40%|████      | 138/341 [00:02<00:03, 53.53it/s, Epoch: 16, Batch: 139,Loss: -2.121,Avg.Loss: -2.372,LR: 6.23E-05]Training epoch 16:  41%|████      | 139/341 [00:02<00:03, 53.53it/s, Epoch: 16, Batch: 140,Loss: -1.743,Avg.Loss: -2.368,LR: 6.22E-05]Training epoch 16:  41%|████      | 140/341 [00:02<00:03, 53.53it/s, Epoch: 16, Batch: 141,Loss: -2.162,Avg.Loss: -2.366,LR: 6.21E-05]Training epoch 16:  41%|████▏     | 141/341 [00:02<00:03, 53.53it/s, Epoch: 16, Batch: 142,Loss: -2.416,Avg.Loss: -2.367,LR: 6.20E-05]Training epoch 16:  42%|████▏     | 142/341 [00:02<00:03, 53.53it/s, Epoch: 16, Batch: 143,Loss: -2.261,Avg.Loss: -2.366,LR: 6.20E-05]Training epoch 16:  42%|████▏     | 143/341 [00:02<00:03, 53.53it/s, Epoch: 16, Batch: 144,Loss: -1.895,Avg.Loss: -2.363,LR: 6.19E-05]Training epoch 16:  42%|████▏     | 144/341 [00:02<00:03, 51.73it/s, Epoch: 16, Batch: 144,Loss: -1.895,Avg.Loss: -2.363,LR: 6.19E-05]Training epoch 16:  42%|████▏     | 144/341 [00:02<00:03, 51.73it/s, Epoch: 16, Batch: 145,Loss: -2.443,Avg.Loss: -2.363,LR: 6.18E-05]Training epoch 16:  43%|████▎     | 145/341 [00:02<00:03, 51.73it/s, Epoch: 16, Batch: 146,Loss: -2.426,Avg.Loss: -2.364,LR: 6.17E-05]Training epoch 16:  43%|████▎     | 146/341 [00:02<00:03, 51.73it/s, Epoch: 16, Batch: 147,Loss: -2.229,Avg.Loss: -2.363,LR: 6.17E-05]Training epoch 16:  43%|████▎     | 147/341 [00:02<00:03, 51.73it/s, Epoch: 16, Batch: 148,Loss: -1.966,Avg.Loss: -2.360,LR: 6.16E-05]Training epoch 16:  43%|████▎     | 148/341 [00:02<00:03, 51.73it/s, Epoch: 16, Batch: 149,Loss: -2.447,Avg.Loss: -2.361,LR: 6.15E-05]Training epoch 16:  44%|████▎     | 149/341 [00:02<00:03, 51.73it/s, Epoch: 16, Batch: 150,Loss: -2.573,Avg.Loss: -2.362,LR: 6.14E-05]Training epoch 16:  44%|████▍     | 150/341 [00:02<00:03, 52.68it/s, Epoch: 16, Batch: 150,Loss: -2.573,Avg.Loss: -2.362,LR: 6.14E-05]Training epoch 16:  44%|████▍     | 150/341 [00:02<00:03, 52.68it/s, Epoch: 16, Batch: 151,Loss: -1.992,Avg.Loss: -2.360,LR: 6.14E-05]Training epoch 16:  44%|████▍     | 151/341 [00:02<00:03, 52.68it/s, Epoch: 16, Batch: 152,Loss: -2.618,Avg.Loss: -2.361,LR: 6.13E-05]Training epoch 16:  45%|████▍     | 152/341 [00:02<00:03, 52.68it/s, Epoch: 16, Batch: 153,Loss: -2.209,Avg.Loss: -2.360,LR: 6.12E-05]Training epoch 16:  45%|████▍     | 153/341 [00:02<00:03, 52.68it/s, Epoch: 16, Batch: 154,Loss: -1.849,Avg.Loss: -2.357,LR: 6.11E-05]Training epoch 16:  45%|████▌     | 154/341 [00:02<00:03, 52.68it/s, Epoch: 16, Batch: 155,Loss: -1.420,Avg.Loss: -2.351,LR: 6.11E-05]Training epoch 16:  45%|████▌     | 155/341 [00:02<00:03, 52.68it/s, Epoch: 16, Batch: 156,Loss: -2.330,Avg.Loss: -2.351,LR: 6.10E-05]Training epoch 16:  46%|████▌     | 156/341 [00:02<00:03, 52.76it/s, Epoch: 16, Batch: 156,Loss: -2.330,Avg.Loss: -2.351,LR: 6.10E-05]Training epoch 16:  46%|████▌     | 156/341 [00:02<00:03, 52.76it/s, Epoch: 16, Batch: 157,Loss: -2.634,Avg.Loss: -2.353,LR: 6.09E-05]Training epoch 16:  46%|████▌     | 157/341 [00:02<00:03, 52.76it/s, Epoch: 16, Batch: 158,Loss: -2.630,Avg.Loss: -2.354,LR: 6.08E-05]Training epoch 16:  46%|████▋     | 158/341 [00:02<00:03, 52.76it/s, Epoch: 16, Batch: 159,Loss: -2.326,Avg.Loss: -2.354,LR: 6.08E-05]Training epoch 16:  47%|████▋     | 159/341 [00:02<00:03, 52.76it/s, Epoch: 16, Batch: 160,Loss: -2.478,Avg.Loss: -2.355,LR: 6.07E-05]Training epoch 16:  47%|████▋     | 160/341 [00:03<00:03, 52.76it/s, Epoch: 16, Batch: 161,Loss: -1.903,Avg.Loss: -2.352,LR: 6.06E-05]Training epoch 16:  47%|████▋     | 161/341 [00:03<00:03, 52.76it/s, Epoch: 16, Batch: 162,Loss: -2.373,Avg.Loss: -2.352,LR: 6.05E-05]Training epoch 16:  48%|████▊     | 162/341 [00:03<00:03, 53.04it/s, Epoch: 16, Batch: 162,Loss: -2.373,Avg.Loss: -2.352,LR: 6.05E-05]Training epoch 16:  48%|████▊     | 162/341 [00:03<00:03, 53.04it/s, Epoch: 16, Batch: 163,Loss: -2.421,Avg.Loss: -2.353,LR: 6.05E-05]Training epoch 16:  48%|████▊     | 163/341 [00:03<00:03, 53.04it/s, Epoch: 16, Batch: 164,Loss: -2.319,Avg.Loss: -2.352,LR: 6.04E-05]Training epoch 16:  48%|████▊     | 164/341 [00:03<00:03, 53.04it/s, Epoch: 16, Batch: 165,Loss: -2.274,Avg.Loss: -2.352,LR: 6.03E-05]Training epoch 16:  48%|████▊     | 165/341 [00:03<00:03, 53.04it/s, Epoch: 16, Batch: 166,Loss: -2.582,Avg.Loss: -2.353,LR: 6.02E-05]Training epoch 16:  49%|████▊     | 166/341 [00:03<00:03, 53.04it/s, Epoch: 16, Batch: 167,Loss: -2.874,Avg.Loss: -2.356,LR: 6.02E-05]Training epoch 16:  49%|████▉     | 167/341 [00:03<00:03, 53.04it/s, Epoch: 16, Batch: 168,Loss: -2.102,Avg.Loss: -2.355,LR: 6.01E-05]Training epoch 16:  49%|████▉     | 168/341 [00:03<00:03, 53.36it/s, Epoch: 16, Batch: 168,Loss: -2.102,Avg.Loss: -2.355,LR: 6.01E-05]Training epoch 16:  49%|████▉     | 168/341 [00:03<00:03, 53.36it/s, Epoch: 16, Batch: 169,Loss: -2.795,Avg.Loss: -2.358,LR: 6.00E-05]Training epoch 16:  50%|████▉     | 169/341 [00:03<00:03, 53.36it/s, Epoch: 16, Batch: 170,Loss: -2.671,Avg.Loss: -2.359,LR: 5.99E-05]Training epoch 16:  50%|████▉     | 170/341 [00:03<00:03, 53.36it/s, Epoch: 16, Batch: 171,Loss: -2.430,Avg.Loss: -2.360,LR: 5.99E-05]Training epoch 16:  50%|█████     | 171/341 [00:03<00:03, 53.36it/s, Epoch: 16, Batch: 172,Loss: -2.713,Avg.Loss: -2.362,LR: 5.98E-05]Training epoch 16:  50%|█████     | 172/341 [00:03<00:03, 53.36it/s, Epoch: 16, Batch: 173,Loss: -2.561,Avg.Loss: -2.363,LR: 5.97E-05]Training epoch 16:  51%|█████     | 173/341 [00:03<00:03, 53.36it/s, Epoch: 16, Batch: 174,Loss: -2.521,Avg.Loss: -2.364,LR: 5.96E-05]Training epoch 16:  51%|█████     | 174/341 [00:03<00:03, 54.05it/s, Epoch: 16, Batch: 174,Loss: -2.521,Avg.Loss: -2.364,LR: 5.96E-05]Training epoch 16:  51%|█████     | 174/341 [00:03<00:03, 54.05it/s, Epoch: 16, Batch: 175,Loss: -2.576,Avg.Loss: -2.365,LR: 5.96E-05]Training epoch 16:  51%|█████▏    | 175/341 [00:03<00:03, 54.05it/s, Epoch: 16, Batch: 176,Loss: -2.346,Avg.Loss: -2.365,LR: 5.95E-05]Training epoch 16:  52%|█████▏    | 176/341 [00:03<00:03, 54.05it/s, Epoch: 16, Batch: 177,Loss: -2.315,Avg.Loss: -2.365,LR: 5.94E-05]Training epoch 16:  52%|█████▏    | 177/341 [00:03<00:03, 54.05it/s, Epoch: 16, Batch: 178,Loss: -2.571,Avg.Loss: -2.366,LR: 5.93E-05]Training epoch 16:  52%|█████▏    | 178/341 [00:03<00:03, 54.05it/s, Epoch: 16, Batch: 179,Loss: -2.435,Avg.Loss: -2.366,LR: 5.93E-05]Training epoch 16:  52%|█████▏    | 179/341 [00:03<00:02, 54.05it/s, Epoch: 16, Batch: 180,Loss: -2.035,Avg.Loss: -2.364,LR: 5.92E-05]Training epoch 16:  53%|█████▎    | 180/341 [00:03<00:03, 52.76it/s, Epoch: 16, Batch: 180,Loss: -2.035,Avg.Loss: -2.364,LR: 5.92E-05]Training epoch 16:  53%|█████▎    | 180/341 [00:03<00:03, 52.76it/s, Epoch: 16, Batch: 181,Loss: -2.176,Avg.Loss: -2.363,LR: 5.91E-05]Training epoch 16:  53%|█████▎    | 181/341 [00:03<00:03, 52.76it/s, Epoch: 16, Batch: 182,Loss: -2.169,Avg.Loss: -2.362,LR: 5.90E-05]Training epoch 16:  53%|█████▎    | 182/341 [00:03<00:03, 52.76it/s, Epoch: 16, Batch: 183,Loss: -2.710,Avg.Loss: -2.364,LR: 5.90E-05]Training epoch 16:  54%|█████▎    | 183/341 [00:03<00:02, 52.76it/s, Epoch: 16, Batch: 184,Loss: -2.180,Avg.Loss: -2.363,LR: 5.89E-05]Training epoch 16:  54%|█████▍    | 184/341 [00:03<00:02, 52.76it/s, Epoch: 16, Batch: 185,Loss: -2.264,Avg.Loss: -2.363,LR: 5.88E-05]Training epoch 16:  54%|█████▍    | 185/341 [00:03<00:02, 52.76it/s, Epoch: 16, Batch: 186,Loss: -1.999,Avg.Loss: -2.361,LR: 5.87E-05]Training epoch 16:  55%|█████▍    | 186/341 [00:03<00:02, 54.55it/s, Epoch: 16, Batch: 186,Loss: -1.999,Avg.Loss: -2.361,LR: 5.87E-05]Training epoch 16:  55%|█████▍    | 186/341 [00:03<00:02, 54.55it/s, Epoch: 16, Batch: 187,Loss: -2.758,Avg.Loss: -2.363,LR: 5.87E-05]Training epoch 16:  55%|█████▍    | 187/341 [00:03<00:02, 54.55it/s, Epoch: 16, Batch: 188,Loss: -2.677,Avg.Loss: -2.365,LR: 5.86E-05]Training epoch 16:  55%|█████▌    | 188/341 [00:03<00:02, 54.55it/s, Epoch: 16, Batch: 189,Loss: -2.207,Avg.Loss: -2.364,LR: 5.85E-05]Training epoch 16:  55%|█████▌    | 189/341 [00:03<00:02, 54.55it/s, Epoch: 16, Batch: 190,Loss: -2.292,Avg.Loss: -2.363,LR: 5.84E-05]Training epoch 16:  56%|█████▌    | 190/341 [00:03<00:02, 54.55it/s, Epoch: 16, Batch: 191,Loss: -2.465,Avg.Loss: -2.364,LR: 5.84E-05]Training epoch 16:  56%|█████▌    | 191/341 [00:03<00:02, 54.55it/s, Epoch: 16, Batch: 192,Loss: -2.606,Avg.Loss: -2.365,LR: 5.83E-05]Training epoch 16:  56%|█████▋    | 192/341 [00:03<00:02, 54.93it/s, Epoch: 16, Batch: 192,Loss: -2.606,Avg.Loss: -2.365,LR: 5.83E-05]Training epoch 16:  56%|█████▋    | 192/341 [00:03<00:02, 54.93it/s, Epoch: 16, Batch: 193,Loss: -1.797,Avg.Loss: -2.362,LR: 5.82E-05]Training epoch 16:  57%|█████▋    | 193/341 [00:03<00:02, 54.93it/s, Epoch: 16, Batch: 194,Loss: -2.597,Avg.Loss: -2.363,LR: 5.82E-05]Training epoch 16:  57%|█████▋    | 194/341 [00:03<00:02, 54.93it/s, Epoch: 16, Batch: 195,Loss: -2.505,Avg.Loss: -2.364,LR: 5.81E-05]Training epoch 16:  57%|█████▋    | 195/341 [00:03<00:02, 54.93it/s, Epoch: 16, Batch: 196,Loss: -2.611,Avg.Loss: -2.365,LR: 5.80E-05]Training epoch 16:  57%|█████▋    | 196/341 [00:03<00:02, 54.93it/s, Epoch: 16, Batch: 197,Loss: -1.951,Avg.Loss: -2.363,LR: 5.79E-05]Training epoch 16:  58%|█████▊    | 197/341 [00:03<00:02, 54.93it/s, Epoch: 16, Batch: 198,Loss: -2.381,Avg.Loss: -2.363,LR: 5.79E-05]Training epoch 16:  58%|█████▊    | 198/341 [00:03<00:02, 54.88it/s, Epoch: 16, Batch: 198,Loss: -2.381,Avg.Loss: -2.363,LR: 5.79E-05]Training epoch 16:  58%|█████▊    | 198/341 [00:03<00:02, 54.88it/s, Epoch: 16, Batch: 199,Loss: -2.965,Avg.Loss: -2.366,LR: 5.78E-05]Training epoch 16:  58%|█████▊    | 199/341 [00:03<00:02, 54.88it/s, Epoch: 16, Batch: 200,Loss: -2.394,Avg.Loss: -2.367,LR: 5.77E-05]Training epoch 16:  59%|█████▊    | 200/341 [00:03<00:02, 54.88it/s, Epoch: 16, Batch: 201,Loss: -2.534,Avg.Loss: -2.367,LR: 5.76E-05]Training epoch 16:  59%|█████▉    | 201/341 [00:03<00:02, 54.88it/s, Epoch: 16, Batch: 202,Loss: -2.555,Avg.Loss: -2.368,LR: 5.76E-05]Training epoch 16:  59%|█████▉    | 202/341 [00:03<00:02, 54.88it/s, Epoch: 16, Batch: 203,Loss: -2.795,Avg.Loss: -2.370,LR: 5.75E-05]Training epoch 16:  60%|█████▉    | 203/341 [00:03<00:02, 54.88it/s, Epoch: 16, Batch: 204,Loss: -2.496,Avg.Loss: -2.371,LR: 5.74E-05]Training epoch 16:  60%|█████▉    | 204/341 [00:03<00:02, 54.31it/s, Epoch: 16, Batch: 204,Loss: -2.496,Avg.Loss: -2.371,LR: 5.74E-05]Training epoch 16:  60%|█████▉    | 204/341 [00:03<00:02, 54.31it/s, Epoch: 16, Batch: 205,Loss: -2.603,Avg.Loss: -2.372,LR: 5.73E-05]Training epoch 16:  60%|██████    | 205/341 [00:03<00:02, 54.31it/s, Epoch: 16, Batch: 206,Loss: -2.349,Avg.Loss: -2.372,LR: 5.73E-05]Training epoch 16:  60%|██████    | 206/341 [00:03<00:02, 54.31it/s, Epoch: 16, Batch: 207,Loss: -2.439,Avg.Loss: -2.372,LR: 5.72E-05]Training epoch 16:  61%|██████    | 207/341 [00:03<00:02, 54.31it/s, Epoch: 16, Batch: 208,Loss: -2.295,Avg.Loss: -2.372,LR: 5.71E-05]Training epoch 16:  61%|██████    | 208/341 [00:03<00:02, 54.31it/s, Epoch: 16, Batch: 209,Loss: -2.000,Avg.Loss: -2.370,LR: 5.70E-05]Training epoch 16:  61%|██████▏   | 209/341 [00:03<00:02, 54.31it/s, Epoch: 16, Batch: 210,Loss: -2.324,Avg.Loss: -2.370,LR: 5.70E-05]Training epoch 16:  62%|██████▏   | 210/341 [00:03<00:02, 54.56it/s, Epoch: 16, Batch: 210,Loss: -2.324,Avg.Loss: -2.370,LR: 5.70E-05]Training epoch 16:  62%|██████▏   | 210/341 [00:03<00:02, 54.56it/s, Epoch: 16, Batch: 211,Loss: -2.123,Avg.Loss: -2.369,LR: 5.69E-05]Training epoch 16:  62%|██████▏   | 211/341 [00:03<00:02, 54.56it/s, Epoch: 16, Batch: 212,Loss: -2.656,Avg.Loss: -2.370,LR: 5.68E-05]Training epoch 16:  62%|██████▏   | 212/341 [00:03<00:02, 54.56it/s, Epoch: 16, Batch: 213,Loss: -2.117,Avg.Loss: -2.369,LR: 5.68E-05]Training epoch 16:  62%|██████▏   | 213/341 [00:03<00:02, 54.56it/s, Epoch: 16, Batch: 214,Loss: -2.067,Avg.Loss: -2.368,LR: 5.67E-05]Training epoch 16:  63%|██████▎   | 214/341 [00:04<00:02, 54.56it/s, Epoch: 16, Batch: 215,Loss: -1.721,Avg.Loss: -2.365,LR: 5.66E-05]Training epoch 16:  63%|██████▎   | 215/341 [00:04<00:02, 54.56it/s, Epoch: 16, Batch: 216,Loss: -2.385,Avg.Loss: -2.365,LR: 5.65E-05]Training epoch 16:  63%|██████▎   | 216/341 [00:04<00:02, 53.88it/s, Epoch: 16, Batch: 216,Loss: -2.385,Avg.Loss: -2.365,LR: 5.65E-05]Training epoch 16:  63%|██████▎   | 216/341 [00:04<00:02, 53.88it/s, Epoch: 16, Batch: 217,Loss: -2.766,Avg.Loss: -2.366,LR: 5.65E-05]Training epoch 16:  64%|██████▎   | 217/341 [00:04<00:02, 53.88it/s, Epoch: 16, Batch: 218,Loss: -1.879,Avg.Loss: -2.364,LR: 5.64E-05]Training epoch 16:  64%|██████▍   | 218/341 [00:04<00:02, 53.88it/s, Epoch: 16, Batch: 219,Loss: -1.507,Avg.Loss: -2.360,LR: 5.63E-05]Training epoch 16:  64%|██████▍   | 219/341 [00:04<00:02, 53.88it/s, Epoch: 16, Batch: 220,Loss: -1.596,Avg.Loss: -2.357,LR: 5.62E-05]Training epoch 16:  65%|██████▍   | 220/341 [00:04<00:02, 53.88it/s, Epoch: 16, Batch: 221,Loss: -1.926,Avg.Loss: -2.355,LR: 5.62E-05]Training epoch 16:  65%|██████▍   | 221/341 [00:04<00:02, 53.88it/s, Epoch: 16, Batch: 222,Loss: -2.673,Avg.Loss: -2.356,LR: 5.61E-05]Training epoch 16:  65%|██████▌   | 222/341 [00:04<00:02, 54.08it/s, Epoch: 16, Batch: 222,Loss: -2.673,Avg.Loss: -2.356,LR: 5.61E-05]Training epoch 16:  65%|██████▌   | 222/341 [00:04<00:02, 54.08it/s, Epoch: 16, Batch: 223,Loss: -2.357,Avg.Loss: -2.356,LR: 5.60E-05]Training epoch 16:  65%|██████▌   | 223/341 [00:04<00:02, 54.08it/s, Epoch: 16, Batch: 224,Loss: -2.186,Avg.Loss: -2.356,LR: 5.60E-05]Training epoch 16:  66%|██████▌   | 224/341 [00:04<00:02, 54.08it/s, Epoch: 16, Batch: 225,Loss: -1.625,Avg.Loss: -2.352,LR: 5.59E-05]Training epoch 16:  66%|██████▌   | 225/341 [00:04<00:02, 54.08it/s, Epoch: 16, Batch: 226,Loss: -2.194,Avg.Loss: -2.352,LR: 5.58E-05]Training epoch 16:  66%|██████▋   | 226/341 [00:04<00:02, 54.08it/s, Epoch: 16, Batch: 227,Loss: -2.469,Avg.Loss: -2.352,LR: 5.57E-05]Training epoch 16:  67%|██████▋   | 227/341 [00:04<00:02, 54.08it/s, Epoch: 16, Batch: 228,Loss: -2.278,Avg.Loss: -2.352,LR: 5.57E-05]Training epoch 16:  67%|██████▋   | 228/341 [00:04<00:02, 53.82it/s, Epoch: 16, Batch: 228,Loss: -2.278,Avg.Loss: -2.352,LR: 5.57E-05]Training epoch 16:  67%|██████▋   | 228/341 [00:04<00:02, 53.82it/s, Epoch: 16, Batch: 229,Loss: -2.274,Avg.Loss: -2.351,LR: 5.56E-05]Training epoch 16:  67%|██████▋   | 229/341 [00:04<00:02, 53.82it/s, Epoch: 16, Batch: 230,Loss: -1.828,Avg.Loss: -2.349,LR: 5.55E-05]Training epoch 16:  67%|██████▋   | 230/341 [00:04<00:02, 53.82it/s, Epoch: 16, Batch: 231,Loss: -2.314,Avg.Loss: -2.349,LR: 5.54E-05]Training epoch 16:  68%|██████▊   | 231/341 [00:04<00:02, 53.82it/s, Epoch: 16, Batch: 232,Loss: -2.388,Avg.Loss: -2.349,LR: 5.54E-05]Training epoch 16:  68%|██████▊   | 232/341 [00:04<00:02, 53.82it/s, Epoch: 16, Batch: 233,Loss: -2.586,Avg.Loss: -2.350,LR: 5.53E-05]Training epoch 16:  68%|██████▊   | 233/341 [00:04<00:02, 53.82it/s, Epoch: 16, Batch: 234,Loss: -1.954,Avg.Loss: -2.349,LR: 5.52E-05]Training epoch 16:  69%|██████▊   | 234/341 [00:04<00:01, 53.82it/s, Epoch: 16, Batch: 234,Loss: -1.954,Avg.Loss: -2.349,LR: 5.52E-05]Training epoch 16:  69%|██████▊   | 234/341 [00:04<00:01, 53.82it/s, Epoch: 16, Batch: 235,Loss: -2.037,Avg.Loss: -2.347,LR: 5.52E-05]Training epoch 16:  69%|██████▉   | 235/341 [00:04<00:01, 53.82it/s, Epoch: 16, Batch: 236,Loss: -2.102,Avg.Loss: -2.346,LR: 5.51E-05]Training epoch 16:  69%|██████▉   | 236/341 [00:04<00:01, 53.82it/s, Epoch: 16, Batch: 237,Loss: -2.442,Avg.Loss: -2.347,LR: 5.50E-05]Training epoch 16:  70%|██████▉   | 237/341 [00:04<00:01, 53.82it/s, Epoch: 16, Batch: 238,Loss: -2.429,Avg.Loss: -2.347,LR: 5.49E-05]Training epoch 16:  70%|██████▉   | 238/341 [00:04<00:01, 53.82it/s, Epoch: 16, Batch: 239,Loss: -2.155,Avg.Loss: -2.346,LR: 5.49E-05]Training epoch 16:  70%|███████   | 239/341 [00:04<00:01, 53.82it/s, Epoch: 16, Batch: 240,Loss: -2.067,Avg.Loss: -2.345,LR: 5.48E-05]Training epoch 16:  70%|███████   | 240/341 [00:04<00:01, 54.00it/s, Epoch: 16, Batch: 240,Loss: -2.067,Avg.Loss: -2.345,LR: 5.48E-05]Training epoch 16:  70%|███████   | 240/341 [00:04<00:01, 54.00it/s, Epoch: 16, Batch: 241,Loss: -2.293,Avg.Loss: -2.345,LR: 5.47E-05]Training epoch 16:  71%|███████   | 241/341 [00:04<00:01, 54.00it/s, Epoch: 16, Batch: 242,Loss: -2.438,Avg.Loss: -2.345,LR: 5.47E-05]Training epoch 16:  71%|███████   | 242/341 [00:04<00:01, 54.00it/s, Epoch: 16, Batch: 243,Loss: -2.524,Avg.Loss: -2.346,LR: 5.46E-05]Training epoch 16:  71%|███████▏  | 243/341 [00:04<00:01, 54.00it/s, Epoch: 16, Batch: 244,Loss: -2.048,Avg.Loss: -2.345,LR: 5.45E-05]Training epoch 16:  72%|███████▏  | 244/341 [00:04<00:01, 54.00it/s, Epoch: 16, Batch: 245,Loss: -2.254,Avg.Loss: -2.344,LR: 5.44E-05]Training epoch 16:  72%|███████▏  | 245/341 [00:04<00:01, 54.00it/s, Epoch: 16, Batch: 246,Loss: -2.055,Avg.Loss: -2.343,LR: 5.44E-05]Training epoch 16:  72%|███████▏  | 246/341 [00:04<00:01, 54.18it/s, Epoch: 16, Batch: 246,Loss: -2.055,Avg.Loss: -2.343,LR: 5.44E-05]Training epoch 16:  72%|███████▏  | 246/341 [00:04<00:01, 54.18it/s, Epoch: 16, Batch: 247,Loss: -2.291,Avg.Loss: -2.343,LR: 5.43E-05]Training epoch 16:  72%|███████▏  | 247/341 [00:04<00:01, 54.18it/s, Epoch: 16, Batch: 248,Loss: -2.349,Avg.Loss: -2.343,LR: 5.42E-05]Training epoch 16:  73%|███████▎  | 248/341 [00:04<00:01, 54.18it/s, Epoch: 16, Batch: 249,Loss: -1.519,Avg.Loss: -2.340,LR: 5.42E-05]Training epoch 16:  73%|███████▎  | 249/341 [00:04<00:01, 54.18it/s, Epoch: 16, Batch: 250,Loss: -1.507,Avg.Loss: -2.336,LR: 5.41E-05]Training epoch 16:  73%|███████▎  | 250/341 [00:04<00:01, 54.18it/s, Epoch: 16, Batch: 251,Loss: -1.953,Avg.Loss: -2.335,LR: 5.40E-05]Training epoch 16:  74%|███████▎  | 251/341 [00:04<00:01, 54.18it/s, Epoch: 16, Batch: 252,Loss: -2.343,Avg.Loss: -2.335,LR: 5.39E-05]Training epoch 16:  74%|███████▍  | 252/341 [00:04<00:01, 54.87it/s, Epoch: 16, Batch: 252,Loss: -2.343,Avg.Loss: -2.335,LR: 5.39E-05]Training epoch 16:  74%|███████▍  | 252/341 [00:04<00:01, 54.87it/s, Epoch: 16, Batch: 253,Loss: -2.610,Avg.Loss: -2.336,LR: 5.39E-05]Training epoch 16:  74%|███████▍  | 253/341 [00:04<00:01, 54.87it/s, Epoch: 16, Batch: 254,Loss: -1.742,Avg.Loss: -2.334,LR: 5.38E-05]Training epoch 16:  74%|███████▍  | 254/341 [00:04<00:01, 54.87it/s, Epoch: 16, Batch: 255,Loss: -1.707,Avg.Loss: -2.331,LR: 5.37E-05]Training epoch 16:  75%|███████▍  | 255/341 [00:04<00:01, 54.87it/s, Epoch: 16, Batch: 256,Loss: -2.111,Avg.Loss: -2.330,LR: 5.37E-05]Training epoch 16:  75%|███████▌  | 256/341 [00:04<00:01, 54.87it/s, Epoch: 16, Batch: 257,Loss: -1.750,Avg.Loss: -2.328,LR: 5.36E-05]Training epoch 16:  75%|███████▌  | 257/341 [00:04<00:01, 54.87it/s, Epoch: 16, Batch: 258,Loss: -2.325,Avg.Loss: -2.328,LR: 5.35E-05]Training epoch 16:  76%|███████▌  | 258/341 [00:04<00:01, 54.41it/s, Epoch: 16, Batch: 258,Loss: -2.325,Avg.Loss: -2.328,LR: 5.35E-05]Training epoch 16:  76%|███████▌  | 258/341 [00:04<00:01, 54.41it/s, Epoch: 16, Batch: 259,Loss: -2.426,Avg.Loss: -2.328,LR: 5.34E-05]Training epoch 16:  76%|███████▌  | 259/341 [00:04<00:01, 54.41it/s, Epoch: 16, Batch: 260,Loss: -1.917,Avg.Loss: -2.327,LR: 5.34E-05]Training epoch 16:  76%|███████▌  | 260/341 [00:04<00:01, 54.41it/s, Epoch: 16, Batch: 261,Loss: -1.753,Avg.Loss: -2.325,LR: 5.33E-05]Training epoch 16:  77%|███████▋  | 261/341 [00:04<00:01, 54.41it/s, Epoch: 16, Batch: 262,Loss: -2.630,Avg.Loss: -2.326,LR: 5.32E-05]Training epoch 16:  77%|███████▋  | 262/341 [00:04<00:01, 54.41it/s, Epoch: 16, Batch: 263,Loss: -2.874,Avg.Loss: -2.328,LR: 5.32E-05]Training epoch 16:  77%|███████▋  | 263/341 [00:04<00:01, 54.41it/s, Epoch: 16, Batch: 264,Loss: -2.376,Avg.Loss: -2.328,LR: 5.31E-05]Training epoch 16:  77%|███████▋  | 264/341 [00:04<00:01, 54.23it/s, Epoch: 16, Batch: 264,Loss: -2.376,Avg.Loss: -2.328,LR: 5.31E-05]Training epoch 16:  77%|███████▋  | 264/341 [00:04<00:01, 54.23it/s, Epoch: 16, Batch: 265,Loss: -2.677,Avg.Loss: -2.329,LR: 5.30E-05]Training epoch 16:  78%|███████▊  | 265/341 [00:04<00:01, 54.23it/s, Epoch: 16, Batch: 266,Loss: -2.554,Avg.Loss: -2.330,LR: 5.29E-05]Training epoch 16:  78%|███████▊  | 266/341 [00:04<00:01, 54.23it/s, Epoch: 16, Batch: 267,Loss: -2.913,Avg.Loss: -2.332,LR: 5.29E-05]Training epoch 16:  78%|███████▊  | 267/341 [00:04<00:01, 54.23it/s, Epoch: 16, Batch: 268,Loss: -2.348,Avg.Loss: -2.332,LR: 5.28E-05]Training epoch 16:  79%|███████▊  | 268/341 [00:04<00:01, 54.23it/s, Epoch: 16, Batch: 269,Loss: -2.419,Avg.Loss: -2.333,LR: 5.27E-05]Training epoch 16:  79%|███████▉  | 269/341 [00:05<00:01, 54.23it/s, Epoch: 16, Batch: 270,Loss: -2.741,Avg.Loss: -2.334,LR: 5.27E-05]Training epoch 16:  79%|███████▉  | 270/341 [00:05<00:01, 54.25it/s, Epoch: 16, Batch: 270,Loss: -2.741,Avg.Loss: -2.334,LR: 5.27E-05]Training epoch 16:  79%|███████▉  | 270/341 [00:05<00:01, 54.25it/s, Epoch: 16, Batch: 271,Loss: -2.189,Avg.Loss: -2.334,LR: 5.26E-05]Training epoch 16:  79%|███████▉  | 271/341 [00:05<00:01, 54.25it/s, Epoch: 16, Batch: 272,Loss: -2.182,Avg.Loss: -2.333,LR: 5.25E-05]Training epoch 16:  80%|███████▉  | 272/341 [00:05<00:01, 54.25it/s, Epoch: 16, Batch: 273,Loss: -2.433,Avg.Loss: -2.333,LR: 5.24E-05]Training epoch 16:  80%|████████  | 273/341 [00:05<00:01, 54.25it/s, Epoch: 16, Batch: 274,Loss: -2.610,Avg.Loss: -2.335,LR: 5.24E-05]Training epoch 16:  80%|████████  | 274/341 [00:05<00:01, 54.25it/s, Epoch: 16, Batch: 275,Loss: -2.196,Avg.Loss: -2.334,LR: 5.23E-05]Training epoch 16:  81%|████████  | 275/341 [00:05<00:01, 54.25it/s, Epoch: 16, Batch: 276,Loss: -2.084,Avg.Loss: -2.333,LR: 5.22E-05]Training epoch 16:  81%|████████  | 276/341 [00:05<00:01, 54.03it/s, Epoch: 16, Batch: 276,Loss: -2.084,Avg.Loss: -2.333,LR: 5.22E-05]Training epoch 16:  81%|████████  | 276/341 [00:05<00:01, 54.03it/s, Epoch: 16, Batch: 277,Loss: -1.814,Avg.Loss: -2.331,LR: 5.22E-05]Training epoch 16:  81%|████████  | 277/341 [00:05<00:01, 54.03it/s, Epoch: 16, Batch: 278,Loss: -2.549,Avg.Loss: -2.332,LR: 5.21E-05]Training epoch 16:  82%|████████▏ | 278/341 [00:05<00:01, 54.03it/s, Epoch: 16, Batch: 279,Loss: -2.234,Avg.Loss: -2.332,LR: 5.20E-05]Training epoch 16:  82%|████████▏ | 279/341 [00:05<00:01, 54.03it/s, Epoch: 16, Batch: 280,Loss: -2.564,Avg.Loss: -2.332,LR: 5.20E-05]Training epoch 16:  82%|████████▏ | 280/341 [00:05<00:01, 54.03it/s, Epoch: 16, Batch: 281,Loss: -2.718,Avg.Loss: -2.334,LR: 5.19E-05]Training epoch 16:  82%|████████▏ | 281/341 [00:05<00:01, 54.03it/s, Epoch: 16, Batch: 282,Loss: -2.298,Avg.Loss: -2.334,LR: 5.18E-05]Training epoch 16:  83%|████████▎ | 282/341 [00:05<00:01, 53.78it/s, Epoch: 16, Batch: 282,Loss: -2.298,Avg.Loss: -2.334,LR: 5.18E-05]Training epoch 16:  83%|████████▎ | 282/341 [00:05<00:01, 53.78it/s, Epoch: 16, Batch: 283,Loss: -2.201,Avg.Loss: -2.333,LR: 5.17E-05]Training epoch 16:  83%|████████▎ | 283/341 [00:05<00:01, 53.78it/s, Epoch: 16, Batch: 284,Loss: -2.356,Avg.Loss: -2.333,LR: 5.17E-05]Training epoch 16:  83%|████████▎ | 284/341 [00:05<00:01, 53.78it/s, Epoch: 16, Batch: 285,Loss: -2.454,Avg.Loss: -2.334,LR: 5.16E-05]Training epoch 16:  84%|████████▎ | 285/341 [00:05<00:01, 53.78it/s, Epoch: 16, Batch: 286,Loss: -2.335,Avg.Loss: -2.334,LR: 5.15E-05]Training epoch 16:  84%|████████▍ | 286/341 [00:05<00:01, 53.78it/s, Epoch: 16, Batch: 287,Loss: -2.672,Avg.Loss: -2.335,LR: 5.15E-05]Training epoch 16:  84%|████████▍ | 287/341 [00:05<00:01, 53.78it/s, Epoch: 16, Batch: 288,Loss: -2.661,Avg.Loss: -2.336,LR: 5.14E-05]Training epoch 16:  84%|████████▍ | 288/341 [00:05<00:00, 53.71it/s, Epoch: 16, Batch: 288,Loss: -2.661,Avg.Loss: -2.336,LR: 5.14E-05]Training epoch 16:  84%|████████▍ | 288/341 [00:05<00:00, 53.71it/s, Epoch: 16, Batch: 289,Loss: -2.695,Avg.Loss: -2.337,LR: 5.13E-05]Training epoch 16:  85%|████████▍ | 289/341 [00:05<00:00, 53.71it/s, Epoch: 16, Batch: 290,Loss: -2.278,Avg.Loss: -2.337,LR: 5.13E-05]Training epoch 16:  85%|████████▌ | 290/341 [00:05<00:00, 53.71it/s, Epoch: 16, Batch: 291,Loss: -2.128,Avg.Loss: -2.336,LR: 5.12E-05]Training epoch 16:  85%|████████▌ | 291/341 [00:05<00:00, 53.71it/s, Epoch: 16, Batch: 292,Loss: -2.197,Avg.Loss: -2.336,LR: 5.11E-05]Training epoch 16:  86%|████████▌ | 292/341 [00:05<00:00, 53.71it/s, Epoch: 16, Batch: 293,Loss: -2.313,Avg.Loss: -2.336,LR: 5.10E-05]Training epoch 16:  86%|████████▌ | 293/341 [00:05<00:00, 53.71it/s, Epoch: 16, Batch: 294,Loss: -2.554,Avg.Loss: -2.337,LR: 5.10E-05]Training epoch 16:  86%|████████▌ | 294/341 [00:05<00:00, 53.73it/s, Epoch: 16, Batch: 294,Loss: -2.554,Avg.Loss: -2.337,LR: 5.10E-05]Training epoch 16:  86%|████████▌ | 294/341 [00:05<00:00, 53.73it/s, Epoch: 16, Batch: 295,Loss: -2.409,Avg.Loss: -2.337,LR: 5.09E-05]Training epoch 16:  87%|████████▋ | 295/341 [00:05<00:00, 53.73it/s, Epoch: 16, Batch: 296,Loss: -2.098,Avg.Loss: -2.336,LR: 5.08E-05]Training epoch 16:  87%|████████▋ | 296/341 [00:05<00:00, 53.73it/s, Epoch: 16, Batch: 297,Loss: -2.366,Avg.Loss: -2.336,LR: 5.08E-05]Training epoch 16:  87%|████████▋ | 297/341 [00:05<00:00, 53.73it/s, Epoch: 16, Batch: 298,Loss: -2.439,Avg.Loss: -2.336,LR: 5.07E-05]Training epoch 16:  87%|████████▋ | 298/341 [00:05<00:00, 53.73it/s, Epoch: 16, Batch: 299,Loss: -2.755,Avg.Loss: -2.338,LR: 5.06E-05]Training epoch 16:  88%|████████▊ | 299/341 [00:05<00:00, 53.73it/s, Epoch: 16, Batch: 300,Loss: -2.320,Avg.Loss: -2.338,LR: 5.06E-05]Training epoch 16:  88%|████████▊ | 300/341 [00:05<00:00, 53.78it/s, Epoch: 16, Batch: 300,Loss: -2.320,Avg.Loss: -2.338,LR: 5.06E-05]Training epoch 16:  88%|████████▊ | 300/341 [00:05<00:00, 53.78it/s, Epoch: 16, Batch: 301,Loss: -2.059,Avg.Loss: -2.337,LR: 5.05E-05]Training epoch 16:  88%|████████▊ | 301/341 [00:05<00:00, 53.78it/s, Epoch: 16, Batch: 302,Loss: -2.546,Avg.Loss: -2.338,LR: 5.04E-05]Training epoch 16:  89%|████████▊ | 302/341 [00:05<00:00, 53.78it/s, Epoch: 16, Batch: 303,Loss: -2.648,Avg.Loss: -2.339,LR: 5.03E-05]Training epoch 16:  89%|████████▉ | 303/341 [00:05<00:00, 53.78it/s, Epoch: 16, Batch: 304,Loss: -2.655,Avg.Loss: -2.340,LR: 5.03E-05]Training epoch 16:  89%|████████▉ | 304/341 [00:05<00:00, 53.78it/s, Epoch: 16, Batch: 305,Loss: -2.643,Avg.Loss: -2.341,LR: 5.02E-05]Training epoch 16:  89%|████████▉ | 305/341 [00:05<00:00, 53.78it/s, Epoch: 16, Batch: 306,Loss: -2.369,Avg.Loss: -2.341,LR: 5.01E-05]Training epoch 16:  90%|████████▉ | 306/341 [00:05<00:00, 53.88it/s, Epoch: 16, Batch: 306,Loss: -2.369,Avg.Loss: -2.341,LR: 5.01E-05]Training epoch 16:  90%|████████▉ | 306/341 [00:05<00:00, 53.88it/s, Epoch: 16, Batch: 307,Loss: -2.480,Avg.Loss: -2.341,LR: 5.01E-05]Training epoch 16:  90%|█████████ | 307/341 [00:05<00:00, 53.88it/s, Epoch: 16, Batch: 308,Loss: -2.753,Avg.Loss: -2.343,LR: 5.00E-05]Training epoch 16:  90%|█████████ | 308/341 [00:05<00:00, 53.88it/s, Epoch: 16, Batch: 309,Loss: -2.743,Avg.Loss: -2.344,LR: 4.99E-05]Training epoch 16:  91%|█████████ | 309/341 [00:05<00:00, 53.88it/s, Epoch: 16, Batch: 310,Loss: -2.101,Avg.Loss: -2.343,LR: 4.99E-05]Training epoch 16:  91%|█████████ | 310/341 [00:05<00:00, 53.88it/s, Epoch: 16, Batch: 311,Loss: -2.240,Avg.Loss: -2.343,LR: 4.98E-05]Training epoch 16:  91%|█████████ | 311/341 [00:05<00:00, 53.88it/s, Epoch: 16, Batch: 312,Loss: -2.714,Avg.Loss: -2.344,LR: 4.97E-05]Training epoch 16:  91%|█████████▏| 312/341 [00:05<00:00, 54.33it/s, Epoch: 16, Batch: 312,Loss: -2.714,Avg.Loss: -2.344,LR: 4.97E-05]Training epoch 16:  91%|█████████▏| 312/341 [00:05<00:00, 54.33it/s, Epoch: 16, Batch: 313,Loss: -2.545,Avg.Loss: -2.345,LR: 4.97E-05]Training epoch 16:  92%|█████████▏| 313/341 [00:05<00:00, 54.33it/s, Epoch: 16, Batch: 314,Loss: -2.282,Avg.Loss: -2.344,LR: 4.96E-05]Training epoch 16:  92%|█████████▏| 314/341 [00:05<00:00, 54.33it/s, Epoch: 16, Batch: 315,Loss: -2.357,Avg.Loss: -2.344,LR: 4.95E-05]Training epoch 16:  92%|█████████▏| 315/341 [00:05<00:00, 54.33it/s, Epoch: 16, Batch: 316,Loss: -2.655,Avg.Loss: -2.345,LR: 4.95E-05]Training epoch 16:  93%|█████████▎| 316/341 [00:05<00:00, 54.33it/s, Epoch: 16, Batch: 317,Loss: -2.131,Avg.Loss: -2.345,LR: 4.94E-05]Training epoch 16:  93%|█████████▎| 317/341 [00:05<00:00, 54.33it/s, Epoch: 16, Batch: 318,Loss: -2.455,Avg.Loss: -2.345,LR: 4.93E-05]Training epoch 16:  93%|█████████▎| 318/341 [00:05<00:00, 55.80it/s, Epoch: 16, Batch: 318,Loss: -2.455,Avg.Loss: -2.345,LR: 4.93E-05]Training epoch 16:  93%|█████████▎| 318/341 [00:05<00:00, 55.80it/s, Epoch: 16, Batch: 319,Loss: -2.393,Avg.Loss: -2.345,LR: 4.92E-05]Training epoch 16:  94%|█████████▎| 319/341 [00:05<00:00, 55.80it/s, Epoch: 16, Batch: 320,Loss: -2.507,Avg.Loss: -2.346,LR: 4.92E-05]Training epoch 16:  94%|█████████▍| 320/341 [00:05<00:00, 55.80it/s, Epoch: 16, Batch: 321,Loss: -2.741,Avg.Loss: -2.347,LR: 4.91E-05]Training epoch 16:  94%|█████████▍| 321/341 [00:05<00:00, 55.80it/s, Epoch: 16, Batch: 322,Loss: -2.698,Avg.Loss: -2.348,LR: 4.90E-05]Training epoch 16:  94%|█████████▍| 322/341 [00:05<00:00, 55.80it/s, Epoch: 16, Batch: 323,Loss: -2.408,Avg.Loss: -2.348,LR: 4.90E-05]Training epoch 16:  95%|█████████▍| 323/341 [00:06<00:00, 55.80it/s, Epoch: 16, Batch: 324,Loss: -2.444,Avg.Loss: -2.348,LR: 4.89E-05]Training epoch 16:  95%|█████████▌| 324/341 [00:06<00:00, 54.99it/s, Epoch: 16, Batch: 324,Loss: -2.444,Avg.Loss: -2.348,LR: 4.89E-05]Training epoch 16:  95%|█████████▌| 324/341 [00:06<00:00, 54.99it/s, Epoch: 16, Batch: 325,Loss: -2.887,Avg.Loss: -2.350,LR: 4.88E-05]Training epoch 16:  95%|█████████▌| 325/341 [00:06<00:00, 54.99it/s, Epoch: 16, Batch: 326,Loss: -2.679,Avg.Loss: -2.351,LR: 4.88E-05]Training epoch 16:  96%|█████████▌| 326/341 [00:06<00:00, 54.99it/s, Epoch: 16, Batch: 327,Loss: -2.413,Avg.Loss: -2.351,LR: 4.87E-05]Training epoch 16:  96%|█████████▌| 327/341 [00:06<00:00, 54.99it/s, Epoch: 16, Batch: 328,Loss: -2.565,Avg.Loss: -2.352,LR: 4.86E-05]Training epoch 16:  96%|█████████▌| 328/341 [00:06<00:00, 54.99it/s, Epoch: 16, Batch: 329,Loss: -2.655,Avg.Loss: -2.353,LR: 4.86E-05]Training epoch 16:  96%|█████████▋| 329/341 [00:06<00:00, 54.99it/s, Epoch: 16, Batch: 330,Loss: -2.750,Avg.Loss: -2.354,LR: 4.85E-05]Training epoch 16:  97%|█████████▋| 330/341 [00:06<00:00, 55.50it/s, Epoch: 16, Batch: 330,Loss: -2.750,Avg.Loss: -2.354,LR: 4.85E-05]Training epoch 16:  97%|█████████▋| 330/341 [00:06<00:00, 55.50it/s, Epoch: 16, Batch: 331,Loss: -2.688,Avg.Loss: -2.355,LR: 4.84E-05]Training epoch 16:  97%|█████████▋| 331/341 [00:06<00:00, 55.50it/s, Epoch: 16, Batch: 332,Loss: -2.732,Avg.Loss: -2.356,LR: 4.84E-05]Training epoch 16:  97%|█████████▋| 332/341 [00:06<00:00, 55.50it/s, Epoch: 16, Batch: 333,Loss: -2.457,Avg.Loss: -2.357,LR: 4.83E-05]Training epoch 16:  98%|█████████▊| 333/341 [00:06<00:00, 55.50it/s, Epoch: 16, Batch: 334,Loss: -2.474,Avg.Loss: -2.357,LR: 4.82E-05]Training epoch 16:  98%|█████████▊| 334/341 [00:06<00:00, 55.50it/s, Epoch: 16, Batch: 335,Loss: -2.497,Avg.Loss: -2.357,LR: 4.82E-05]Training epoch 16:  98%|█████████▊| 335/341 [00:06<00:00, 55.50it/s, Epoch: 16, Batch: 336,Loss: -2.610,Avg.Loss: -2.358,LR: 4.81E-05]Training epoch 16:  99%|█████████▊| 336/341 [00:06<00:00, 55.25it/s, Epoch: 16, Batch: 336,Loss: -2.610,Avg.Loss: -2.358,LR: 4.81E-05]Training epoch 16:  99%|█████████▊| 336/341 [00:06<00:00, 55.25it/s, Epoch: 16, Batch: 337,Loss: -1.482,Avg.Loss: -2.355,LR: 4.80E-05]Training epoch 16:  99%|█████████▉| 337/341 [00:06<00:00, 55.25it/s, Epoch: 16, Batch: 338,Loss: -2.480,Avg.Loss: -2.356,LR: 4.79E-05]Training epoch 16:  99%|█████████▉| 338/341 [00:06<00:00, 55.25it/s, Epoch: 16, Batch: 339,Loss: -2.503,Avg.Loss: -2.356,LR: 4.79E-05]Training epoch 16:  99%|█████████▉| 339/341 [00:06<00:00, 55.25it/s, Epoch: 16, Batch: 340,Loss: -2.850,Avg.Loss: -2.358,LR: 4.78E-05]Training epoch 16: 100%|█████████▉| 340/341 [00:06<00:00, 55.25it/s, Epoch: 16, Batch: 341,Loss: -2.609,Avg.Loss: -2.358,LR: 4.77E-05]Training epoch 16: 100%|██████████| 341/341 [00:06<00:00, 53.93it/s, Epoch: 16, Batch: 341,Loss: -2.609,Avg.Loss: -2.358,LR: 4.77E-05]
Training epoch 17:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 17:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 17, Batch: 1,Loss: -2.986,Avg.Loss: -2.986,LR: 4.77E-05]Training epoch 17:   0%|          | 1/341 [00:00<00:11, 30.03it/s, Epoch: 17, Batch: 2,Loss: -2.394,Avg.Loss: -2.690,LR: 4.76E-05]Training epoch 17:   1%|          | 2/341 [00:00<00:08, 40.97it/s, Epoch: 17, Batch: 3,Loss: -2.831,Avg.Loss: -2.737,LR: 4.75E-05]Training epoch 17:   1%|          | 3/341 [00:00<00:07, 45.41it/s, Epoch: 17, Batch: 4,Loss: -2.429,Avg.Loss: -2.660,LR: 4.75E-05]Training epoch 17:   1%|          | 4/341 [00:00<00:06, 50.04it/s, Epoch: 17, Batch: 5,Loss: -1.661,Avg.Loss: -2.460,LR: 4.74E-05]Training epoch 17:   1%|▏         | 5/341 [00:00<00:06, 51.18it/s, Epoch: 17, Batch: 6,Loss: -2.560,Avg.Loss: -2.477,LR: 4.73E-05]Training epoch 17:   2%|▏         | 6/341 [00:00<00:06, 52.64it/s, Epoch: 17, Batch: 7,Loss: -2.883,Avg.Loss: -2.535,LR: 4.73E-05]Training epoch 17:   2%|▏         | 7/341 [00:00<00:05, 61.33it/s, Epoch: 17, Batch: 7,Loss: -2.883,Avg.Loss: -2.535,LR: 4.73E-05]Training epoch 17:   2%|▏         | 7/341 [00:00<00:05, 61.33it/s, Epoch: 17, Batch: 8,Loss: -2.412,Avg.Loss: -2.519,LR: 4.72E-05]Training epoch 17:   2%|▏         | 8/341 [00:00<00:05, 61.33it/s, Epoch: 17, Batch: 9,Loss: -2.433,Avg.Loss: -2.510,LR: 4.71E-05]Training epoch 17:   3%|▎         | 9/341 [00:00<00:05, 61.33it/s, Epoch: 17, Batch: 10,Loss: -2.817,Avg.Loss: -2.541,LR: 4.71E-05]Training epoch 17:   3%|▎         | 10/341 [00:00<00:05, 61.33it/s, Epoch: 17, Batch: 11,Loss: -2.211,Avg.Loss: -2.511,LR: 4.70E-05]Training epoch 17:   3%|▎         | 11/341 [00:00<00:05, 61.33it/s, Epoch: 17, Batch: 12,Loss: -2.341,Avg.Loss: -2.496,LR: 4.69E-05]Training epoch 17:   4%|▎         | 12/341 [00:00<00:05, 61.33it/s, Epoch: 17, Batch: 13,Loss: -2.386,Avg.Loss: -2.488,LR: 4.69E-05]Training epoch 17:   4%|▍         | 13/341 [00:00<00:05, 61.33it/s, Epoch: 17, Batch: 14,Loss: -2.709,Avg.Loss: -2.504,LR: 4.68E-05]Training epoch 17:   4%|▍         | 14/341 [00:00<00:05, 58.32it/s, Epoch: 17, Batch: 14,Loss: -2.709,Avg.Loss: -2.504,LR: 4.68E-05]Training epoch 17:   4%|▍         | 14/341 [00:00<00:05, 58.32it/s, Epoch: 17, Batch: 15,Loss: -2.103,Avg.Loss: -2.477,LR: 4.67E-05]Training epoch 17:   4%|▍         | 15/341 [00:00<00:05, 58.32it/s, Epoch: 17, Batch: 16,Loss: -2.631,Avg.Loss: -2.487,LR: 4.67E-05]Training epoch 17:   5%|▍         | 16/341 [00:00<00:05, 58.32it/s, Epoch: 17, Batch: 17,Loss: -2.391,Avg.Loss: -2.481,LR: 4.66E-05]Training epoch 17:   5%|▍         | 17/341 [00:00<00:05, 58.32it/s, Epoch: 17, Batch: 18,Loss: -2.531,Avg.Loss: -2.484,LR: 4.65E-05]Training epoch 17:   5%|▌         | 18/341 [00:00<00:05, 58.32it/s, Epoch: 17, Batch: 19,Loss: -2.417,Avg.Loss: -2.480,LR: 4.65E-05]Training epoch 17:   6%|▌         | 19/341 [00:00<00:05, 58.32it/s, Epoch: 17, Batch: 20,Loss: -2.164,Avg.Loss: -2.464,LR: 4.64E-05]Training epoch 17:   6%|▌         | 20/341 [00:00<00:05, 57.20it/s, Epoch: 17, Batch: 20,Loss: -2.164,Avg.Loss: -2.464,LR: 4.64E-05]Training epoch 17:   6%|▌         | 20/341 [00:00<00:05, 57.20it/s, Epoch: 17, Batch: 21,Loss: -2.660,Avg.Loss: -2.474,LR: 4.63E-05]Training epoch 17:   6%|▌         | 21/341 [00:00<00:05, 57.20it/s, Epoch: 17, Batch: 22,Loss: -2.542,Avg.Loss: -2.477,LR: 4.63E-05]Training epoch 17:   6%|▋         | 22/341 [00:00<00:05, 57.20it/s, Epoch: 17, Batch: 23,Loss: -2.534,Avg.Loss: -2.479,LR: 4.62E-05]Training epoch 17:   7%|▋         | 23/341 [00:00<00:05, 57.20it/s, Epoch: 17, Batch: 24,Loss: -2.563,Avg.Loss: -2.483,LR: 4.61E-05]Training epoch 17:   7%|▋         | 24/341 [00:00<00:05, 57.20it/s, Epoch: 17, Batch: 25,Loss: -2.596,Avg.Loss: -2.487,LR: 4.61E-05]Training epoch 17:   7%|▋         | 25/341 [00:00<00:05, 57.20it/s, Epoch: 17, Batch: 26,Loss: -1.878,Avg.Loss: -2.464,LR: 4.60E-05]Training epoch 17:   8%|▊         | 26/341 [00:00<00:05, 56.47it/s, Epoch: 17, Batch: 26,Loss: -1.878,Avg.Loss: -2.464,LR: 4.60E-05]Training epoch 17:   8%|▊         | 26/341 [00:00<00:05, 56.47it/s, Epoch: 17, Batch: 27,Loss: -2.561,Avg.Loss: -2.468,LR: 4.59E-05]Training epoch 17:   8%|▊         | 27/341 [00:00<00:05, 56.47it/s, Epoch: 17, Batch: 28,Loss: -2.595,Avg.Loss: -2.472,LR: 4.59E-05]Training epoch 17:   8%|▊         | 28/341 [00:00<00:05, 56.47it/s, Epoch: 17, Batch: 29,Loss: -2.155,Avg.Loss: -2.461,LR: 4.58E-05]Training epoch 17:   9%|▊         | 29/341 [00:00<00:05, 56.47it/s, Epoch: 17, Batch: 30,Loss: -2.356,Avg.Loss: -2.458,LR: 4.57E-05]Training epoch 17:   9%|▉         | 30/341 [00:00<00:05, 56.47it/s, Epoch: 17, Batch: 31,Loss: -2.363,Avg.Loss: -2.455,LR: 4.57E-05]Training epoch 17:   9%|▉         | 31/341 [00:00<00:05, 56.47it/s, Epoch: 17, Batch: 32,Loss: -2.347,Avg.Loss: -2.451,LR: 4.56E-05]Training epoch 17:   9%|▉         | 32/341 [00:00<00:05, 54.74it/s, Epoch: 17, Batch: 32,Loss: -2.347,Avg.Loss: -2.451,LR: 4.56E-05]Training epoch 17:   9%|▉         | 32/341 [00:00<00:05, 54.74it/s, Epoch: 17, Batch: 33,Loss: -2.580,Avg.Loss: -2.455,LR: 4.55E-05]Training epoch 17:  10%|▉         | 33/341 [00:00<00:05, 54.74it/s, Epoch: 17, Batch: 34,Loss: -2.835,Avg.Loss: -2.466,LR: 4.55E-05]Training epoch 17:  10%|▉         | 34/341 [00:00<00:05, 54.74it/s, Epoch: 17, Batch: 35,Loss: -2.650,Avg.Loss: -2.472,LR: 4.54E-05]Training epoch 17:  10%|█         | 35/341 [00:00<00:05, 54.74it/s, Epoch: 17, Batch: 36,Loss: -2.613,Avg.Loss: -2.476,LR: 4.53E-05]Training epoch 17:  11%|█         | 36/341 [00:00<00:05, 54.74it/s, Epoch: 17, Batch: 37,Loss: -2.756,Avg.Loss: -2.483,LR: 4.53E-05]Training epoch 17:  11%|█         | 37/341 [00:00<00:05, 54.74it/s, Epoch: 17, Batch: 38,Loss: -2.585,Avg.Loss: -2.486,LR: 4.52E-05]Training epoch 17:  11%|█         | 38/341 [00:00<00:05, 54.53it/s, Epoch: 17, Batch: 38,Loss: -2.585,Avg.Loss: -2.486,LR: 4.52E-05]Training epoch 17:  11%|█         | 38/341 [00:00<00:05, 54.53it/s, Epoch: 17, Batch: 39,Loss: -2.566,Avg.Loss: -2.488,LR: 4.51E-05]Training epoch 17:  11%|█▏        | 39/341 [00:00<00:05, 54.53it/s, Epoch: 17, Batch: 40,Loss: -2.324,Avg.Loss: -2.484,LR: 4.51E-05]Training epoch 17:  12%|█▏        | 40/341 [00:00<00:05, 54.53it/s, Epoch: 17, Batch: 41,Loss: -2.365,Avg.Loss: -2.481,LR: 4.50E-05]Training epoch 17:  12%|█▏        | 41/341 [00:00<00:05, 54.53it/s, Epoch: 17, Batch: 42,Loss: -2.520,Avg.Loss: -2.482,LR: 4.49E-05]Training epoch 17:  12%|█▏        | 42/341 [00:00<00:05, 54.53it/s, Epoch: 17, Batch: 43,Loss: -2.468,Avg.Loss: -2.481,LR: 4.49E-05]Training epoch 17:  13%|█▎        | 43/341 [00:00<00:05, 54.53it/s, Epoch: 17, Batch: 44,Loss: -2.688,Avg.Loss: -2.486,LR: 4.48E-05]Training epoch 17:  13%|█▎        | 44/341 [00:00<00:05, 53.81it/s, Epoch: 17, Batch: 44,Loss: -2.688,Avg.Loss: -2.486,LR: 4.48E-05]Training epoch 17:  13%|█▎        | 44/341 [00:00<00:05, 53.81it/s, Epoch: 17, Batch: 45,Loss: -2.746,Avg.Loss: -2.492,LR: 4.47E-05]Training epoch 17:  13%|█▎        | 45/341 [00:00<00:05, 53.81it/s, Epoch: 17, Batch: 46,Loss: -3.012,Avg.Loss: -2.503,LR: 4.47E-05]Training epoch 17:  13%|█▎        | 46/341 [00:00<00:05, 53.81it/s, Epoch: 17, Batch: 47,Loss: -2.537,Avg.Loss: -2.504,LR: 4.46E-05]Training epoch 17:  14%|█▍        | 47/341 [00:00<00:05, 53.81it/s, Epoch: 17, Batch: 48,Loss: -2.434,Avg.Loss: -2.502,LR: 4.45E-05]Training epoch 17:  14%|█▍        | 48/341 [00:00<00:05, 53.81it/s, Epoch: 17, Batch: 49,Loss: -2.364,Avg.Loss: -2.500,LR: 4.45E-05]Training epoch 17:  14%|█▍        | 49/341 [00:00<00:05, 53.81it/s, Epoch: 17, Batch: 50,Loss: -2.651,Avg.Loss: -2.503,LR: 4.44E-05]Training epoch 17:  15%|█▍        | 50/341 [00:00<00:05, 53.68it/s, Epoch: 17, Batch: 50,Loss: -2.651,Avg.Loss: -2.503,LR: 4.44E-05]Training epoch 17:  15%|█▍        | 50/341 [00:00<00:05, 53.68it/s, Epoch: 17, Batch: 51,Loss: -2.916,Avg.Loss: -2.511,LR: 4.43E-05]Training epoch 17:  15%|█▍        | 51/341 [00:00<00:05, 53.68it/s, Epoch: 17, Batch: 52,Loss: -2.307,Avg.Loss: -2.507,LR: 4.43E-05]Training epoch 17:  15%|█▌        | 52/341 [00:00<00:05, 53.68it/s, Epoch: 17, Batch: 53,Loss: -2.685,Avg.Loss: -2.510,LR: 4.42E-05]Training epoch 17:  16%|█▌        | 53/341 [00:00<00:05, 53.68it/s, Epoch: 17, Batch: 54,Loss: -2.211,Avg.Loss: -2.505,LR: 4.42E-05]Training epoch 17:  16%|█▌        | 54/341 [00:01<00:05, 53.68it/s, Epoch: 17, Batch: 55,Loss: -2.630,Avg.Loss: -2.507,LR: 4.41E-05]Training epoch 17:  16%|█▌        | 55/341 [00:01<00:05, 53.68it/s, Epoch: 17, Batch: 56,Loss: -2.744,Avg.Loss: -2.511,LR: 4.40E-05]Training epoch 17:  16%|█▋        | 56/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 56,Loss: -2.744,Avg.Loss: -2.511,LR: 4.40E-05]Training epoch 17:  16%|█▋        | 56/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 57,Loss: -2.642,Avg.Loss: -2.514,LR: 4.40E-05]Training epoch 17:  17%|█▋        | 57/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 58,Loss: -2.692,Avg.Loss: -2.517,LR: 4.39E-05]Training epoch 17:  17%|█▋        | 58/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 59,Loss: -2.779,Avg.Loss: -2.521,LR: 4.38E-05]Training epoch 17:  17%|█▋        | 59/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 60,Loss: -2.499,Avg.Loss: -2.521,LR: 4.38E-05]Training epoch 17:  18%|█▊        | 60/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 61,Loss: -2.306,Avg.Loss: -2.517,LR: 4.37E-05]Training epoch 17:  18%|█▊        | 61/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 62,Loss: -2.576,Avg.Loss: -2.518,LR: 4.36E-05]Training epoch 17:  18%|█▊        | 62/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 62,Loss: -2.576,Avg.Loss: -2.518,LR: 4.36E-05]Training epoch 17:  18%|█▊        | 62/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 63,Loss: -2.097,Avg.Loss: -2.511,LR: 4.36E-05]Training epoch 17:  18%|█▊        | 63/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 64,Loss: -2.716,Avg.Loss: -2.515,LR: 4.35E-05]Training epoch 17:  19%|█▉        | 64/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 65,Loss: -2.332,Avg.Loss: -2.512,LR: 4.34E-05]Training epoch 17:  19%|█▉        | 65/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 66,Loss: -2.538,Avg.Loss: -2.512,LR: 4.34E-05]Training epoch 17:  19%|█▉        | 66/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 67,Loss: -2.519,Avg.Loss: -2.512,LR: 4.33E-05]Training epoch 17:  20%|█▉        | 67/341 [00:01<00:05, 53.89it/s, Epoch: 17, Batch: 68,Loss: -2.200,Avg.Loss: -2.508,LR: 4.32E-05]Training epoch 17:  20%|█▉        | 68/341 [00:01<00:05, 54.28it/s, Epoch: 17, Batch: 68,Loss: -2.200,Avg.Loss: -2.508,LR: 4.32E-05]Training epoch 17:  20%|█▉        | 68/341 [00:01<00:05, 54.28it/s, Epoch: 17, Batch: 69,Loss: -2.803,Avg.Loss: -2.512,LR: 4.32E-05]Training epoch 17:  20%|██        | 69/341 [00:01<00:05, 54.28it/s, Epoch: 17, Batch: 70,Loss: -2.290,Avg.Loss: -2.509,LR: 4.31E-05]Training epoch 17:  21%|██        | 70/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 71,Loss: -2.770,Avg.Loss: -2.513,LR: 4.30E-05]Training epoch 17:  21%|██        | 71/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 72,Loss: -2.770,Avg.Loss: -2.516,LR: 4.30E-05]Training epoch 17:  21%|██        | 72/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 73,Loss: -2.540,Avg.Loss: -2.516,LR: 4.29E-05]Training epoch 17:  21%|██▏       | 73/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 74,Loss: -2.928,Avg.Loss: -2.522,LR: 4.29E-05]Training epoch 17:  22%|██▏       | 74/341 [00:01<00:04, 54.21it/s, Epoch: 17, Batch: 74,Loss: -2.928,Avg.Loss: -2.522,LR: 4.29E-05]Training epoch 17:  22%|██▏       | 74/341 [00:01<00:04, 54.21it/s, Epoch: 17, Batch: 75,Loss: -2.648,Avg.Loss: -2.524,LR: 4.28E-05]Training epoch 17:  22%|██▏       | 75/341 [00:01<00:04, 54.21it/s, Epoch: 17, Batch: 76,Loss: -2.637,Avg.Loss: -2.525,LR: 4.27E-05]Training epoch 17:  22%|██▏       | 76/341 [00:01<00:04, 54.21it/s, Epoch: 17, Batch: 77,Loss: -2.975,Avg.Loss: -2.531,LR: 4.27E-05]Training epoch 17:  23%|██▎       | 77/341 [00:01<00:04, 54.21it/s, Epoch: 17, Batch: 78,Loss: -2.552,Avg.Loss: -2.531,LR: 4.26E-05]Training epoch 17:  23%|██▎       | 78/341 [00:01<00:04, 54.21it/s, Epoch: 17, Batch: 79,Loss: -2.501,Avg.Loss: -2.531,LR: 4.25E-05]Training epoch 17:  23%|██▎       | 79/341 [00:01<00:04, 54.21it/s, Epoch: 17, Batch: 80,Loss: -2.616,Avg.Loss: -2.532,LR: 4.25E-05]Training epoch 17:  23%|██▎       | 80/341 [00:01<00:04, 54.53it/s, Epoch: 17, Batch: 80,Loss: -2.616,Avg.Loss: -2.532,LR: 4.25E-05]Training epoch 17:  23%|██▎       | 80/341 [00:01<00:04, 54.53it/s, Epoch: 17, Batch: 81,Loss: -2.544,Avg.Loss: -2.532,LR: 4.24E-05]Training epoch 17:  24%|██▍       | 81/341 [00:01<00:04, 54.53it/s, Epoch: 17, Batch: 82,Loss: -2.499,Avg.Loss: -2.532,LR: 4.23E-05]Training epoch 17:  24%|██▍       | 82/341 [00:01<00:04, 54.53it/s, Epoch: 17, Batch: 83,Loss: -2.698,Avg.Loss: -2.534,LR: 4.23E-05]Training epoch 17:  24%|██▍       | 83/341 [00:01<00:04, 54.53it/s, Epoch: 17, Batch: 84,Loss: -2.316,Avg.Loss: -2.531,LR: 4.22E-05]Training epoch 17:  25%|██▍       | 84/341 [00:01<00:04, 54.53it/s, Epoch: 17, Batch: 85,Loss: -2.619,Avg.Loss: -2.532,LR: 4.21E-05]Training epoch 17:  25%|██▍       | 85/341 [00:01<00:04, 54.53it/s, Epoch: 17, Batch: 86,Loss: -2.608,Avg.Loss: -2.533,LR: 4.21E-05]Training epoch 17:  25%|██▌       | 86/341 [00:01<00:04, 54.38it/s, Epoch: 17, Batch: 86,Loss: -2.608,Avg.Loss: -2.533,LR: 4.21E-05]Training epoch 17:  25%|██▌       | 86/341 [00:01<00:04, 54.38it/s, Epoch: 17, Batch: 87,Loss: -2.648,Avg.Loss: -2.534,LR: 4.20E-05]Training epoch 17:  26%|██▌       | 87/341 [00:01<00:04, 54.38it/s, Epoch: 17, Batch: 88,Loss: -2.331,Avg.Loss: -2.532,LR: 4.20E-05]Training epoch 17:  26%|██▌       | 88/341 [00:01<00:04, 54.38it/s, Epoch: 17, Batch: 89,Loss: -2.314,Avg.Loss: -2.530,LR: 4.19E-05]Training epoch 17:  26%|██▌       | 89/341 [00:01<00:04, 54.38it/s, Epoch: 17, Batch: 90,Loss: -2.824,Avg.Loss: -2.533,LR: 4.18E-05]Training epoch 17:  26%|██▋       | 90/341 [00:01<00:04, 54.38it/s, Epoch: 17, Batch: 91,Loss: -2.505,Avg.Loss: -2.533,LR: 4.18E-05]Training epoch 17:  27%|██▋       | 91/341 [00:01<00:04, 54.38it/s, Epoch: 17, Batch: 92,Loss: -2.390,Avg.Loss: -2.531,LR: 4.17E-05]Training epoch 17:  27%|██▋       | 92/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 92,Loss: -2.390,Avg.Loss: -2.531,LR: 4.17E-05]Training epoch 17:  27%|██▋       | 92/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 93,Loss: -2.380,Avg.Loss: -2.529,LR: 4.16E-05]Training epoch 17:  27%|██▋       | 93/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 94,Loss: -2.546,Avg.Loss: -2.530,LR: 4.16E-05]Training epoch 17:  28%|██▊       | 94/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 95,Loss: -2.261,Avg.Loss: -2.527,LR: 4.15E-05]Training epoch 17:  28%|██▊       | 95/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 96,Loss: -2.621,Avg.Loss: -2.528,LR: 4.14E-05]Training epoch 17:  28%|██▊       | 96/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 97,Loss: -2.335,Avg.Loss: -2.526,LR: 4.14E-05]Training epoch 17:  28%|██▊       | 97/341 [00:01<00:04, 54.28it/s, Epoch: 17, Batch: 98,Loss: -2.350,Avg.Loss: -2.524,LR: 4.13E-05]Training epoch 17:  29%|██▊       | 98/341 [00:01<00:04, 54.25it/s, Epoch: 17, Batch: 98,Loss: -2.350,Avg.Loss: -2.524,LR: 4.13E-05]Training epoch 17:  29%|██▊       | 98/341 [00:01<00:04, 54.25it/s, Epoch: 17, Batch: 99,Loss: -2.778,Avg.Loss: -2.526,LR: 4.13E-05]Training epoch 17:  29%|██▉       | 99/341 [00:01<00:04, 54.25it/s, Epoch: 17, Batch: 100,Loss: -2.749,Avg.Loss: -2.529,LR: 4.12E-05]Training epoch 17:  29%|██▉       | 100/341 [00:01<00:04, 54.25it/s, Epoch: 17, Batch: 101,Loss: -2.824,Avg.Loss: -2.532,LR: 4.11E-05]Training epoch 17:  30%|██▉       | 101/341 [00:01<00:04, 54.25it/s, Epoch: 17, Batch: 102,Loss: -2.627,Avg.Loss: -2.533,LR: 4.11E-05]Training epoch 17:  30%|██▉       | 102/341 [00:01<00:04, 54.25it/s, Epoch: 17, Batch: 103,Loss: -2.225,Avg.Loss: -2.530,LR: 4.10E-05]Training epoch 17:  30%|███       | 103/341 [00:01<00:04, 54.25it/s, Epoch: 17, Batch: 104,Loss: -2.226,Avg.Loss: -2.527,LR: 4.09E-05]Training epoch 17:  30%|███       | 104/341 [00:01<00:04, 54.12it/s, Epoch: 17, Batch: 104,Loss: -2.226,Avg.Loss: -2.527,LR: 4.09E-05]Training epoch 17:  30%|███       | 104/341 [00:01<00:04, 54.12it/s, Epoch: 17, Batch: 105,Loss: -1.853,Avg.Loss: -2.520,LR: 4.09E-05]Training epoch 17:  31%|███       | 105/341 [00:01<00:04, 54.12it/s, Epoch: 17, Batch: 106,Loss: -2.721,Avg.Loss: -2.522,LR: 4.08E-05]Training epoch 17:  31%|███       | 106/341 [00:01<00:04, 54.12it/s, Epoch: 17, Batch: 107,Loss: -2.244,Avg.Loss: -2.520,LR: 4.08E-05]Training epoch 17:  31%|███▏      | 107/341 [00:01<00:04, 54.12it/s, Epoch: 17, Batch: 108,Loss: -2.456,Avg.Loss: -2.519,LR: 4.07E-05]Training epoch 17:  32%|███▏      | 108/341 [00:01<00:04, 54.12it/s, Epoch: 17, Batch: 109,Loss: -2.578,Avg.Loss: -2.520,LR: 4.06E-05]Training epoch 17:  32%|███▏      | 109/341 [00:02<00:04, 54.12it/s, Epoch: 17, Batch: 110,Loss: -2.733,Avg.Loss: -2.521,LR: 4.06E-05]Training epoch 17:  32%|███▏      | 110/341 [00:02<00:04, 54.43it/s, Epoch: 17, Batch: 110,Loss: -2.733,Avg.Loss: -2.521,LR: 4.06E-05]Training epoch 17:  32%|███▏      | 110/341 [00:02<00:04, 54.43it/s, Epoch: 17, Batch: 111,Loss: -2.964,Avg.Loss: -2.525,LR: 4.05E-05]Training epoch 17:  33%|███▎      | 111/341 [00:02<00:04, 54.43it/s, Epoch: 17, Batch: 112,Loss: -2.969,Avg.Loss: -2.529,LR: 4.04E-05]Training epoch 17:  33%|███▎      | 112/341 [00:02<00:04, 54.43it/s, Epoch: 17, Batch: 113,Loss: -2.410,Avg.Loss: -2.528,LR: 4.04E-05]Training epoch 17:  33%|███▎      | 113/341 [00:02<00:04, 54.43it/s, Epoch: 17, Batch: 114,Loss: -2.326,Avg.Loss: -2.527,LR: 4.03E-05]Training epoch 17:  33%|███▎      | 114/341 [00:02<00:04, 54.43it/s, Epoch: 17, Batch: 115,Loss: -2.475,Avg.Loss: -2.526,LR: 4.02E-05]Training epoch 17:  34%|███▎      | 115/341 [00:02<00:04, 54.43it/s, Epoch: 17, Batch: 116,Loss: -2.386,Avg.Loss: -2.525,LR: 4.02E-05]Training epoch 17:  34%|███▍      | 116/341 [00:02<00:04, 54.46it/s, Epoch: 17, Batch: 116,Loss: -2.386,Avg.Loss: -2.525,LR: 4.02E-05]Training epoch 17:  34%|███▍      | 116/341 [00:02<00:04, 54.46it/s, Epoch: 17, Batch: 117,Loss: -2.156,Avg.Loss: -2.522,LR: 4.01E-05]Training epoch 17:  34%|███▍      | 117/341 [00:02<00:04, 54.46it/s, Epoch: 17, Batch: 118,Loss: -2.094,Avg.Loss: -2.518,LR: 4.01E-05]Training epoch 17:  35%|███▍      | 118/341 [00:02<00:04, 54.46it/s, Epoch: 17, Batch: 119,Loss: -2.565,Avg.Loss: -2.519,LR: 4.00E-05]Training epoch 17:  35%|███▍      | 119/341 [00:02<00:04, 54.46it/s, Epoch: 17, Batch: 120,Loss: -1.943,Avg.Loss: -2.514,LR: 3.99E-05]Training epoch 17:  35%|███▌      | 120/341 [00:02<00:04, 54.46it/s, Epoch: 17, Batch: 121,Loss: -2.522,Avg.Loss: -2.514,LR: 3.99E-05]Training epoch 17:  35%|███▌      | 121/341 [00:02<00:04, 54.46it/s, Epoch: 17, Batch: 122,Loss: -2.743,Avg.Loss: -2.516,LR: 3.98E-05]Training epoch 17:  36%|███▌      | 122/341 [00:02<00:04, 54.38it/s, Epoch: 17, Batch: 122,Loss: -2.743,Avg.Loss: -2.516,LR: 3.98E-05]Training epoch 17:  36%|███▌      | 122/341 [00:02<00:04, 54.38it/s, Epoch: 17, Batch: 123,Loss: -2.604,Avg.Loss: -2.516,LR: 3.97E-05]Training epoch 17:  36%|███▌      | 123/341 [00:02<00:04, 54.38it/s, Epoch: 17, Batch: 124,Loss: -2.652,Avg.Loss: -2.517,LR: 3.97E-05]Training epoch 17:  36%|███▋      | 124/341 [00:02<00:03, 54.38it/s, Epoch: 17, Batch: 125,Loss: -2.660,Avg.Loss: -2.519,LR: 3.96E-05]Training epoch 17:  37%|███▋      | 125/341 [00:02<00:03, 54.38it/s, Epoch: 17, Batch: 126,Loss: -2.614,Avg.Loss: -2.519,LR: 3.96E-05]Training epoch 17:  37%|███▋      | 126/341 [00:02<00:03, 54.38it/s, Epoch: 17, Batch: 127,Loss: -2.532,Avg.Loss: -2.519,LR: 3.95E-05]Training epoch 17:  37%|███▋      | 127/341 [00:02<00:03, 54.38it/s, Epoch: 17, Batch: 128,Loss: -2.642,Avg.Loss: -2.520,LR: 3.94E-05]Training epoch 17:  38%|███▊      | 128/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 128,Loss: -2.642,Avg.Loss: -2.520,LR: 3.94E-05]Training epoch 17:  38%|███▊      | 128/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 129,Loss: -2.322,Avg.Loss: -2.519,LR: 3.94E-05]Training epoch 17:  38%|███▊      | 129/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 130,Loss: -2.587,Avg.Loss: -2.519,LR: 3.93E-05]Training epoch 17:  38%|███▊      | 130/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 131,Loss: -2.508,Avg.Loss: -2.519,LR: 3.93E-05]Training epoch 17:  38%|███▊      | 131/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 132,Loss: -2.763,Avg.Loss: -2.521,LR: 3.92E-05]Training epoch 17:  39%|███▊      | 132/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 133,Loss: -2.540,Avg.Loss: -2.521,LR: 3.91E-05]Training epoch 17:  39%|███▉      | 133/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 134,Loss: -2.195,Avg.Loss: -2.519,LR: 3.91E-05]Training epoch 17:  39%|███▉      | 134/341 [00:02<00:03, 54.90it/s, Epoch: 17, Batch: 134,Loss: -2.195,Avg.Loss: -2.519,LR: 3.91E-05]Training epoch 17:  39%|███▉      | 134/341 [00:02<00:03, 54.90it/s, Epoch: 17, Batch: 135,Loss: -2.463,Avg.Loss: -2.518,LR: 3.90E-05]Training epoch 17:  40%|███▉      | 135/341 [00:02<00:03, 54.90it/s, Epoch: 17, Batch: 136,Loss: -2.747,Avg.Loss: -2.520,LR: 3.89E-05]Training epoch 17:  40%|███▉      | 136/341 [00:02<00:03, 54.90it/s, Epoch: 17, Batch: 137,Loss: -2.170,Avg.Loss: -2.518,LR: 3.89E-05]Training epoch 17:  40%|████      | 137/341 [00:02<00:03, 54.90it/s, Epoch: 17, Batch: 138,Loss: -2.367,Avg.Loss: -2.517,LR: 3.88E-05]Training epoch 17:  40%|████      | 138/341 [00:02<00:03, 54.90it/s, Epoch: 17, Batch: 139,Loss: -2.491,Avg.Loss: -2.516,LR: 3.88E-05]Training epoch 17:  41%|████      | 139/341 [00:02<00:03, 54.90it/s, Epoch: 17, Batch: 140,Loss: -2.845,Avg.Loss: -2.519,LR: 3.87E-05]Training epoch 17:  41%|████      | 140/341 [00:02<00:03, 54.77it/s, Epoch: 17, Batch: 140,Loss: -2.845,Avg.Loss: -2.519,LR: 3.87E-05]Training epoch 17:  41%|████      | 140/341 [00:02<00:03, 54.77it/s, Epoch: 17, Batch: 141,Loss: -2.539,Avg.Loss: -2.519,LR: 3.86E-05]Training epoch 17:  41%|████▏     | 141/341 [00:02<00:03, 54.77it/s, Epoch: 17, Batch: 142,Loss: -2.573,Avg.Loss: -2.519,LR: 3.86E-05]Training epoch 17:  42%|████▏     | 142/341 [00:02<00:03, 54.77it/s, Epoch: 17, Batch: 143,Loss: -2.614,Avg.Loss: -2.520,LR: 3.85E-05]Training epoch 17:  42%|████▏     | 143/341 [00:02<00:03, 54.77it/s, Epoch: 17, Batch: 144,Loss: -2.761,Avg.Loss: -2.522,LR: 3.85E-05]Training epoch 17:  42%|████▏     | 144/341 [00:02<00:03, 54.77it/s, Epoch: 17, Batch: 145,Loss: -1.860,Avg.Loss: -2.517,LR: 3.84E-05]Training epoch 17:  43%|████▎     | 145/341 [00:02<00:03, 54.77it/s, Epoch: 17, Batch: 146,Loss: -2.632,Avg.Loss: -2.518,LR: 3.83E-05]Training epoch 17:  43%|████▎     | 146/341 [00:02<00:03, 54.49it/s, Epoch: 17, Batch: 146,Loss: -2.632,Avg.Loss: -2.518,LR: 3.83E-05]Training epoch 17:  43%|████▎     | 146/341 [00:02<00:03, 54.49it/s, Epoch: 17, Batch: 147,Loss: -2.485,Avg.Loss: -2.518,LR: 3.83E-05]Training epoch 17:  43%|████▎     | 147/341 [00:02<00:03, 54.49it/s, Epoch: 17, Batch: 148,Loss: -2.773,Avg.Loss: -2.519,LR: 3.82E-05]Training epoch 17:  43%|████▎     | 148/341 [00:02<00:03, 54.49it/s, Epoch: 17, Batch: 149,Loss: -2.425,Avg.Loss: -2.519,LR: 3.81E-05]Training epoch 17:  44%|████▎     | 149/341 [00:02<00:03, 54.49it/s, Epoch: 17, Batch: 150,Loss: -2.856,Avg.Loss: -2.521,LR: 3.81E-05]Training epoch 17:  44%|████▍     | 150/341 [00:02<00:03, 54.49it/s, Epoch: 17, Batch: 151,Loss: -2.859,Avg.Loss: -2.523,LR: 3.80E-05]Training epoch 17:  44%|████▍     | 151/341 [00:02<00:03, 54.49it/s, Epoch: 17, Batch: 152,Loss: -2.609,Avg.Loss: -2.524,LR: 3.80E-05]Training epoch 17:  45%|████▍     | 152/341 [00:02<00:03, 54.81it/s, Epoch: 17, Batch: 152,Loss: -2.609,Avg.Loss: -2.524,LR: 3.80E-05]Training epoch 17:  45%|████▍     | 152/341 [00:02<00:03, 54.81it/s, Epoch: 17, Batch: 153,Loss: -2.868,Avg.Loss: -2.526,LR: 3.79E-05]Training epoch 17:  45%|████▍     | 153/341 [00:02<00:03, 54.81it/s, Epoch: 17, Batch: 154,Loss: -2.931,Avg.Loss: -2.529,LR: 3.78E-05]Training epoch 17:  45%|████▌     | 154/341 [00:02<00:03, 54.81it/s, Epoch: 17, Batch: 155,Loss: -2.965,Avg.Loss: -2.531,LR: 3.78E-05]Training epoch 17:  45%|████▌     | 155/341 [00:02<00:03, 54.81it/s, Epoch: 17, Batch: 156,Loss: -2.735,Avg.Loss: -2.533,LR: 3.77E-05]Training epoch 17:  46%|████▌     | 156/341 [00:02<00:03, 54.81it/s, Epoch: 17, Batch: 157,Loss: -2.400,Avg.Loss: -2.532,LR: 3.77E-05]Training epoch 17:  46%|████▌     | 157/341 [00:02<00:03, 54.81it/s, Epoch: 17, Batch: 158,Loss: -2.295,Avg.Loss: -2.530,LR: 3.76E-05]Training epoch 17:  46%|████▋     | 158/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 158,Loss: -2.295,Avg.Loss: -2.530,LR: 3.76E-05]Training epoch 17:  46%|████▋     | 158/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 159,Loss: -2.869,Avg.Loss: -2.532,LR: 3.75E-05]Training epoch 17:  47%|████▋     | 159/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 160,Loss: -2.823,Avg.Loss: -2.534,LR: 3.75E-05]Training epoch 17:  47%|████▋     | 160/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 161,Loss: -2.561,Avg.Loss: -2.534,LR: 3.74E-05]Training epoch 17:  47%|████▋     | 161/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 162,Loss: -2.571,Avg.Loss: -2.535,LR: 3.74E-05]Training epoch 17:  48%|████▊     | 162/341 [00:02<00:03, 54.40it/s, Epoch: 17, Batch: 163,Loss: -2.760,Avg.Loss: -2.536,LR: 3.73E-05]Training epoch 17:  48%|████▊     | 163/341 [00:03<00:03, 54.40it/s, Epoch: 17, Batch: 164,Loss: -2.431,Avg.Loss: -2.535,LR: 3.72E-05]Training epoch 17:  48%|████▊     | 164/341 [00:03<00:03, 54.33it/s, Epoch: 17, Batch: 164,Loss: -2.431,Avg.Loss: -2.535,LR: 3.72E-05]Training epoch 17:  48%|████▊     | 164/341 [00:03<00:03, 54.33it/s, Epoch: 17, Batch: 165,Loss: -2.415,Avg.Loss: -2.535,LR: 3.72E-05]Training epoch 17:  48%|████▊     | 165/341 [00:03<00:03, 54.33it/s, Epoch: 17, Batch: 166,Loss: -2.372,Avg.Loss: -2.534,LR: 3.71E-05]Training epoch 17:  49%|████▊     | 166/341 [00:03<00:03, 54.33it/s, Epoch: 17, Batch: 167,Loss: -2.362,Avg.Loss: -2.533,LR: 3.71E-05]Training epoch 17:  49%|████▉     | 167/341 [00:03<00:03, 54.33it/s, Epoch: 17, Batch: 168,Loss: -3.064,Avg.Loss: -2.536,LR: 3.70E-05]Training epoch 17:  49%|████▉     | 168/341 [00:03<00:03, 54.33it/s, Epoch: 17, Batch: 169,Loss: -2.304,Avg.Loss: -2.534,LR: 3.69E-05]Training epoch 17:  50%|████▉     | 169/341 [00:03<00:03, 54.33it/s, Epoch: 17, Batch: 170,Loss: -2.522,Avg.Loss: -2.534,LR: 3.69E-05]Training epoch 17:  50%|████▉     | 170/341 [00:03<00:03, 54.24it/s, Epoch: 17, Batch: 170,Loss: -2.522,Avg.Loss: -2.534,LR: 3.69E-05]Training epoch 17:  50%|████▉     | 170/341 [00:03<00:03, 54.24it/s, Epoch: 17, Batch: 171,Loss: -2.564,Avg.Loss: -2.535,LR: 3.68E-05]Training epoch 17:  50%|█████     | 171/341 [00:03<00:03, 54.24it/s, Epoch: 17, Batch: 172,Loss: -2.311,Avg.Loss: -2.533,LR: 3.67E-05]Training epoch 17:  50%|█████     | 172/341 [00:03<00:03, 54.24it/s, Epoch: 17, Batch: 173,Loss: -2.517,Avg.Loss: -2.533,LR: 3.67E-05]Training epoch 17:  51%|█████     | 173/341 [00:03<00:03, 54.24it/s, Epoch: 17, Batch: 174,Loss: -2.807,Avg.Loss: -2.535,LR: 3.66E-05]Training epoch 17:  51%|█████     | 174/341 [00:03<00:03, 54.24it/s, Epoch: 17, Batch: 175,Loss: -2.774,Avg.Loss: -2.536,LR: 3.66E-05]Training epoch 17:  51%|█████▏    | 175/341 [00:03<00:03, 54.24it/s, Epoch: 17, Batch: 176,Loss: -2.554,Avg.Loss: -2.536,LR: 3.65E-05]Training epoch 17:  52%|█████▏    | 176/341 [00:03<00:03, 54.21it/s, Epoch: 17, Batch: 176,Loss: -2.554,Avg.Loss: -2.536,LR: 3.65E-05]Training epoch 17:  52%|█████▏    | 176/341 [00:03<00:03, 54.21it/s, Epoch: 17, Batch: 177,Loss: -2.682,Avg.Loss: -2.537,LR: 3.64E-05]Training epoch 17:  52%|█████▏    | 177/341 [00:03<00:03, 54.21it/s, Epoch: 17, Batch: 178,Loss: -2.543,Avg.Loss: -2.537,LR: 3.64E-05]Training epoch 17:  52%|█████▏    | 178/341 [00:03<00:03, 54.21it/s, Epoch: 17, Batch: 179,Loss: -2.565,Avg.Loss: -2.537,LR: 3.63E-05]Training epoch 17:  52%|█████▏    | 179/341 [00:03<00:02, 54.21it/s, Epoch: 17, Batch: 180,Loss: -2.605,Avg.Loss: -2.538,LR: 3.63E-05]Training epoch 17:  53%|█████▎    | 180/341 [00:03<00:02, 54.21it/s, Epoch: 17, Batch: 181,Loss: -2.693,Avg.Loss: -2.538,LR: 3.62E-05]Training epoch 17:  53%|█████▎    | 181/341 [00:03<00:02, 54.21it/s, Epoch: 17, Batch: 182,Loss: -2.642,Avg.Loss: -2.539,LR: 3.62E-05]Training epoch 17:  53%|█████▎    | 182/341 [00:03<00:02, 54.12it/s, Epoch: 17, Batch: 182,Loss: -2.642,Avg.Loss: -2.539,LR: 3.62E-05]Training epoch 17:  53%|█████▎    | 182/341 [00:03<00:02, 54.12it/s, Epoch: 17, Batch: 183,Loss: -2.512,Avg.Loss: -2.539,LR: 3.61E-05]Training epoch 17:  54%|█████▎    | 183/341 [00:03<00:02, 54.12it/s, Epoch: 17, Batch: 184,Loss: -2.772,Avg.Loss: -2.540,LR: 3.60E-05]Training epoch 17:  54%|█████▍    | 184/341 [00:03<00:02, 54.12it/s, Epoch: 17, Batch: 185,Loss: -1.757,Avg.Loss: -2.536,LR: 3.60E-05]Training epoch 17:  54%|█████▍    | 185/341 [00:03<00:02, 54.12it/s, Epoch: 17, Batch: 186,Loss: -2.636,Avg.Loss: -2.536,LR: 3.59E-05]Training epoch 17:  55%|█████▍    | 186/341 [00:03<00:02, 54.12it/s, Epoch: 17, Batch: 187,Loss: -2.157,Avg.Loss: -2.534,LR: 3.59E-05]Training epoch 17:  55%|█████▍    | 187/341 [00:03<00:02, 54.12it/s, Epoch: 17, Batch: 188,Loss: -2.654,Avg.Loss: -2.535,LR: 3.58E-05]Training epoch 17:  55%|█████▌    | 188/341 [00:03<00:02, 54.23it/s, Epoch: 17, Batch: 188,Loss: -2.654,Avg.Loss: -2.535,LR: 3.58E-05]Training epoch 17:  55%|█████▌    | 188/341 [00:03<00:02, 54.23it/s, Epoch: 17, Batch: 189,Loss: -2.515,Avg.Loss: -2.535,LR: 3.57E-05]Training epoch 17:  55%|█████▌    | 189/341 [00:03<00:02, 54.23it/s, Epoch: 17, Batch: 190,Loss: -2.892,Avg.Loss: -2.537,LR: 3.57E-05]Training epoch 17:  56%|█████▌    | 190/341 [00:03<00:02, 54.23it/s, Epoch: 17, Batch: 191,Loss: -2.989,Avg.Loss: -2.539,LR: 3.56E-05]Training epoch 17:  56%|█████▌    | 191/341 [00:03<00:02, 54.23it/s, Epoch: 17, Batch: 192,Loss: -2.580,Avg.Loss: -2.539,LR: 3.56E-05]Training epoch 17:  56%|█████▋    | 192/341 [00:03<00:02, 54.23it/s, Epoch: 17, Batch: 193,Loss: -2.521,Avg.Loss: -2.539,LR: 3.55E-05]Training epoch 17:  57%|█████▋    | 193/341 [00:03<00:02, 54.23it/s, Epoch: 17, Batch: 194,Loss: -2.817,Avg.Loss: -2.541,LR: 3.54E-05]Training epoch 17:  57%|█████▋    | 194/341 [00:03<00:02, 54.26it/s, Epoch: 17, Batch: 194,Loss: -2.817,Avg.Loss: -2.541,LR: 3.54E-05]Training epoch 17:  57%|█████▋    | 194/341 [00:03<00:02, 54.26it/s, Epoch: 17, Batch: 195,Loss: -2.907,Avg.Loss: -2.543,LR: 3.54E-05]Training epoch 17:  57%|█████▋    | 195/341 [00:03<00:02, 54.26it/s, Epoch: 17, Batch: 196,Loss: -2.619,Avg.Loss: -2.543,LR: 3.53E-05]Training epoch 17:  57%|█████▋    | 196/341 [00:03<00:02, 54.26it/s, Epoch: 17, Batch: 197,Loss: -2.664,Avg.Loss: -2.544,LR: 3.53E-05]Training epoch 17:  58%|█████▊    | 197/341 [00:03<00:02, 54.26it/s, Epoch: 17, Batch: 198,Loss: -2.389,Avg.Loss: -2.543,LR: 3.52E-05]Training epoch 17:  58%|█████▊    | 198/341 [00:03<00:02, 54.26it/s, Epoch: 17, Batch: 199,Loss: -2.666,Avg.Loss: -2.543,LR: 3.51E-05]Training epoch 17:  58%|█████▊    | 199/341 [00:03<00:02, 54.26it/s, Epoch: 17, Batch: 200,Loss: -2.824,Avg.Loss: -2.545,LR: 3.51E-05]Training epoch 17:  59%|█████▊    | 200/341 [00:03<00:02, 54.20it/s, Epoch: 17, Batch: 200,Loss: -2.824,Avg.Loss: -2.545,LR: 3.51E-05]Training epoch 17:  59%|█████▊    | 200/341 [00:03<00:02, 54.20it/s, Epoch: 17, Batch: 201,Loss: -2.652,Avg.Loss: -2.545,LR: 3.50E-05]Training epoch 17:  59%|█████▉    | 201/341 [00:03<00:02, 54.20it/s, Epoch: 17, Batch: 202,Loss: -2.273,Avg.Loss: -2.544,LR: 3.50E-05]Training epoch 17:  59%|█████▉    | 202/341 [00:03<00:02, 54.20it/s, Epoch: 17, Batch: 203,Loss: -2.216,Avg.Loss: -2.542,LR: 3.49E-05]Training epoch 17:  60%|█████▉    | 203/341 [00:03<00:02, 54.20it/s, Epoch: 17, Batch: 204,Loss: -2.465,Avg.Loss: -2.542,LR: 3.48E-05]Training epoch 17:  60%|█████▉    | 204/341 [00:03<00:02, 54.20it/s, Epoch: 17, Batch: 205,Loss: -2.633,Avg.Loss: -2.543,LR: 3.48E-05]Training epoch 17:  60%|██████    | 205/341 [00:03<00:02, 54.20it/s, Epoch: 17, Batch: 206,Loss: -2.448,Avg.Loss: -2.542,LR: 3.47E-05]Training epoch 17:  60%|██████    | 206/341 [00:03<00:02, 54.11it/s, Epoch: 17, Batch: 206,Loss: -2.448,Avg.Loss: -2.542,LR: 3.47E-05]Training epoch 17:  60%|██████    | 206/341 [00:03<00:02, 54.11it/s, Epoch: 17, Batch: 207,Loss: -2.699,Avg.Loss: -2.543,LR: 3.47E-05]Training epoch 17:  61%|██████    | 207/341 [00:03<00:02, 54.11it/s, Epoch: 17, Batch: 208,Loss: -2.669,Avg.Loss: -2.543,LR: 3.46E-05]Training epoch 17:  61%|██████    | 208/341 [00:03<00:02, 54.11it/s, Epoch: 17, Batch: 209,Loss: -3.028,Avg.Loss: -2.546,LR: 3.46E-05]Training epoch 17:  61%|██████▏   | 209/341 [00:03<00:02, 54.11it/s, Epoch: 17, Batch: 210,Loss: -2.478,Avg.Loss: -2.545,LR: 3.45E-05]Training epoch 17:  62%|██████▏   | 210/341 [00:03<00:02, 54.11it/s, Epoch: 17, Batch: 211,Loss: -2.784,Avg.Loss: -2.547,LR: 3.44E-05]Training epoch 17:  62%|██████▏   | 211/341 [00:03<00:02, 54.11it/s, Epoch: 17, Batch: 212,Loss: -2.438,Avg.Loss: -2.546,LR: 3.44E-05]Training epoch 17:  62%|██████▏   | 212/341 [00:03<00:02, 53.93it/s, Epoch: 17, Batch: 212,Loss: -2.438,Avg.Loss: -2.546,LR: 3.44E-05]Training epoch 17:  62%|██████▏   | 212/341 [00:03<00:02, 53.93it/s, Epoch: 17, Batch: 213,Loss: -2.610,Avg.Loss: -2.546,LR: 3.43E-05]Training epoch 17:  62%|██████▏   | 213/341 [00:03<00:02, 53.93it/s, Epoch: 17, Batch: 214,Loss: -2.361,Avg.Loss: -2.545,LR: 3.43E-05]Training epoch 17:  63%|██████▎   | 214/341 [00:03<00:02, 53.93it/s, Epoch: 17, Batch: 215,Loss: -2.992,Avg.Loss: -2.548,LR: 3.42E-05]Training epoch 17:  63%|██████▎   | 215/341 [00:03<00:02, 53.93it/s, Epoch: 17, Batch: 216,Loss: -2.934,Avg.Loss: -2.549,LR: 3.41E-05]Training epoch 17:  63%|██████▎   | 216/341 [00:03<00:02, 53.93it/s, Epoch: 17, Batch: 217,Loss: -2.593,Avg.Loss: -2.550,LR: 3.41E-05]Training epoch 17:  64%|██████▎   | 217/341 [00:03<00:02, 53.93it/s, Epoch: 17, Batch: 218,Loss: -2.040,Avg.Loss: -2.547,LR: 3.40E-05]Training epoch 17:  64%|██████▍   | 218/341 [00:03<00:02, 54.36it/s, Epoch: 17, Batch: 218,Loss: -2.040,Avg.Loss: -2.547,LR: 3.40E-05]Training epoch 17:  64%|██████▍   | 218/341 [00:04<00:02, 54.36it/s, Epoch: 17, Batch: 219,Loss: -2.557,Avg.Loss: -2.547,LR: 3.40E-05]Training epoch 17:  64%|██████▍   | 219/341 [00:04<00:02, 54.36it/s, Epoch: 17, Batch: 220,Loss: -2.837,Avg.Loss: -2.549,LR: 3.39E-05]Training epoch 17:  65%|██████▍   | 220/341 [00:04<00:02, 54.36it/s, Epoch: 17, Batch: 221,Loss: -2.798,Avg.Loss: -2.550,LR: 3.39E-05]Training epoch 17:  65%|██████▍   | 221/341 [00:04<00:02, 54.36it/s, Epoch: 17, Batch: 222,Loss: -2.440,Avg.Loss: -2.549,LR: 3.38E-05]Training epoch 17:  65%|██████▌   | 222/341 [00:04<00:02, 54.36it/s, Epoch: 17, Batch: 223,Loss: -2.745,Avg.Loss: -2.550,LR: 3.37E-05]Training epoch 17:  65%|██████▌   | 223/341 [00:04<00:02, 54.36it/s, Epoch: 17, Batch: 224,Loss: -2.496,Avg.Loss: -2.550,LR: 3.37E-05]Training epoch 17:  66%|██████▌   | 224/341 [00:04<00:02, 54.37it/s, Epoch: 17, Batch: 224,Loss: -2.496,Avg.Loss: -2.550,LR: 3.37E-05]Training epoch 17:  66%|██████▌   | 224/341 [00:04<00:02, 54.37it/s, Epoch: 17, Batch: 225,Loss: -2.511,Avg.Loss: -2.550,LR: 3.36E-05]Training epoch 17:  66%|██████▌   | 225/341 [00:04<00:02, 54.37it/s, Epoch: 17, Batch: 226,Loss: -2.890,Avg.Loss: -2.551,LR: 3.36E-05]Training epoch 17:  66%|██████▋   | 226/341 [00:04<00:02, 54.37it/s, Epoch: 17, Batch: 227,Loss: -2.718,Avg.Loss: -2.552,LR: 3.35E-05]Training epoch 17:  67%|██████▋   | 227/341 [00:04<00:02, 54.37it/s, Epoch: 17, Batch: 228,Loss: -2.648,Avg.Loss: -2.552,LR: 3.35E-05]Training epoch 17:  67%|██████▋   | 228/341 [00:04<00:02, 54.37it/s, Epoch: 17, Batch: 229,Loss: -2.347,Avg.Loss: -2.551,LR: 3.34E-05]Training epoch 17:  67%|██████▋   | 229/341 [00:04<00:02, 54.37it/s, Epoch: 17, Batch: 230,Loss: -2.820,Avg.Loss: -2.553,LR: 3.33E-05]Training epoch 17:  67%|██████▋   | 230/341 [00:04<00:02, 54.28it/s, Epoch: 17, Batch: 230,Loss: -2.820,Avg.Loss: -2.553,LR: 3.33E-05]Training epoch 17:  67%|██████▋   | 230/341 [00:04<00:02, 54.28it/s, Epoch: 17, Batch: 231,Loss: -2.503,Avg.Loss: -2.552,LR: 3.33E-05]Training epoch 17:  68%|██████▊   | 231/341 [00:04<00:02, 54.28it/s, Epoch: 17, Batch: 232,Loss: -2.508,Avg.Loss: -2.552,LR: 3.32E-05]Training epoch 17:  68%|██████▊   | 232/341 [00:04<00:02, 54.28it/s, Epoch: 17, Batch: 233,Loss: -2.919,Avg.Loss: -2.554,LR: 3.32E-05]Training epoch 17:  68%|██████▊   | 233/341 [00:04<00:01, 54.28it/s, Epoch: 17, Batch: 234,Loss: -2.432,Avg.Loss: -2.553,LR: 3.31E-05]Training epoch 17:  69%|██████▊   | 234/341 [00:04<00:01, 54.28it/s, Epoch: 17, Batch: 235,Loss: -2.500,Avg.Loss: -2.553,LR: 3.31E-05]Training epoch 17:  69%|██████▉   | 235/341 [00:04<00:01, 54.28it/s, Epoch: 17, Batch: 236,Loss: -2.801,Avg.Loss: -2.554,LR: 3.30E-05]Training epoch 17:  69%|██████▉   | 236/341 [00:04<00:01, 54.15it/s, Epoch: 17, Batch: 236,Loss: -2.801,Avg.Loss: -2.554,LR: 3.30E-05]Training epoch 17:  69%|██████▉   | 236/341 [00:04<00:01, 54.15it/s, Epoch: 17, Batch: 237,Loss: -2.557,Avg.Loss: -2.554,LR: 3.29E-05]Training epoch 17:  70%|██████▉   | 237/341 [00:04<00:01, 54.15it/s, Epoch: 17, Batch: 238,Loss: -1.817,Avg.Loss: -2.551,LR: 3.29E-05]Training epoch 17:  70%|██████▉   | 238/341 [00:04<00:01, 54.15it/s, Epoch: 17, Batch: 239,Loss: -2.577,Avg.Loss: -2.551,LR: 3.28E-05]Training epoch 17:  70%|███████   | 239/341 [00:04<00:01, 54.15it/s, Epoch: 17, Batch: 240,Loss: -2.662,Avg.Loss: -2.552,LR: 3.28E-05]Training epoch 17:  70%|███████   | 240/341 [00:04<00:01, 54.15it/s, Epoch: 17, Batch: 241,Loss: -2.310,Avg.Loss: -2.551,LR: 3.27E-05]Training epoch 17:  71%|███████   | 241/341 [00:04<00:01, 54.15it/s, Epoch: 17, Batch: 242,Loss: -2.578,Avg.Loss: -2.551,LR: 3.27E-05]Training epoch 17:  71%|███████   | 242/341 [00:04<00:01, 54.16it/s, Epoch: 17, Batch: 242,Loss: -2.578,Avg.Loss: -2.551,LR: 3.27E-05]Training epoch 17:  71%|███████   | 242/341 [00:04<00:01, 54.16it/s, Epoch: 17, Batch: 243,Loss: -2.442,Avg.Loss: -2.550,LR: 3.26E-05]Training epoch 17:  71%|███████▏  | 243/341 [00:04<00:01, 54.16it/s, Epoch: 17, Batch: 244,Loss: -2.699,Avg.Loss: -2.551,LR: 3.25E-05]Training epoch 17:  72%|███████▏  | 244/341 [00:04<00:01, 54.16it/s, Epoch: 17, Batch: 245,Loss: -2.912,Avg.Loss: -2.552,LR: 3.25E-05]Training epoch 17:  72%|███████▏  | 245/341 [00:04<00:01, 54.16it/s, Epoch: 17, Batch: 246,Loss: -2.902,Avg.Loss: -2.554,LR: 3.24E-05]Training epoch 17:  72%|███████▏  | 246/341 [00:04<00:01, 54.16it/s, Epoch: 17, Batch: 247,Loss: -2.758,Avg.Loss: -2.555,LR: 3.24E-05]Training epoch 17:  72%|███████▏  | 247/341 [00:04<00:01, 54.16it/s, Epoch: 17, Batch: 248,Loss: -3.133,Avg.Loss: -2.557,LR: 3.23E-05]Training epoch 17:  73%|███████▎  | 248/341 [00:04<00:01, 54.13it/s, Epoch: 17, Batch: 248,Loss: -3.133,Avg.Loss: -2.557,LR: 3.23E-05]Training epoch 17:  73%|███████▎  | 248/341 [00:04<00:01, 54.13it/s, Epoch: 17, Batch: 249,Loss: -2.457,Avg.Loss: -2.556,LR: 3.23E-05]Training epoch 17:  73%|███████▎  | 249/341 [00:04<00:01, 54.13it/s, Epoch: 17, Batch: 250,Loss: -2.347,Avg.Loss: -2.556,LR: 3.22E-05]Training epoch 17:  73%|███████▎  | 250/341 [00:04<00:01, 54.13it/s, Epoch: 17, Batch: 251,Loss: -2.620,Avg.Loss: -2.556,LR: 3.21E-05]Training epoch 17:  74%|███████▎  | 251/341 [00:04<00:01, 54.13it/s, Epoch: 17, Batch: 252,Loss: -2.727,Avg.Loss: -2.557,LR: 3.21E-05]Training epoch 17:  74%|███████▍  | 252/341 [00:04<00:01, 54.13it/s, Epoch: 17, Batch: 253,Loss: -2.332,Avg.Loss: -2.556,LR: 3.20E-05]Training epoch 17:  74%|███████▍  | 253/341 [00:04<00:01, 54.13it/s, Epoch: 17, Batch: 254,Loss: -2.511,Avg.Loss: -2.556,LR: 3.20E-05]Training epoch 17:  74%|███████▍  | 254/341 [00:04<00:01, 54.19it/s, Epoch: 17, Batch: 254,Loss: -2.511,Avg.Loss: -2.556,LR: 3.20E-05]Training epoch 17:  74%|███████▍  | 254/341 [00:04<00:01, 54.19it/s, Epoch: 17, Batch: 255,Loss: -2.804,Avg.Loss: -2.556,LR: 3.19E-05]Training epoch 17:  75%|███████▍  | 255/341 [00:04<00:01, 54.19it/s, Epoch: 17, Batch: 256,Loss: -2.497,Avg.Loss: -2.556,LR: 3.19E-05]Training epoch 17:  75%|███████▌  | 256/341 [00:04<00:01, 54.19it/s, Epoch: 17, Batch: 257,Loss: -2.602,Avg.Loss: -2.556,LR: 3.18E-05]Training epoch 17:  75%|███████▌  | 257/341 [00:04<00:01, 54.19it/s, Epoch: 17, Batch: 258,Loss: -1.832,Avg.Loss: -2.554,LR: 3.17E-05]Training epoch 17:  76%|███████▌  | 258/341 [00:04<00:01, 54.19it/s, Epoch: 17, Batch: 259,Loss: -3.131,Avg.Loss: -2.556,LR: 3.17E-05]Training epoch 17:  76%|███████▌  | 259/341 [00:04<00:01, 54.19it/s, Epoch: 17, Batch: 260,Loss: -2.607,Avg.Loss: -2.556,LR: 3.16E-05]Training epoch 17:  76%|███████▌  | 260/341 [00:04<00:01, 53.92it/s, Epoch: 17, Batch: 260,Loss: -2.607,Avg.Loss: -2.556,LR: 3.16E-05]Training epoch 17:  76%|███████▌  | 260/341 [00:04<00:01, 53.92it/s, Epoch: 17, Batch: 261,Loss: -2.852,Avg.Loss: -2.557,LR: 3.16E-05]Training epoch 17:  77%|███████▋  | 261/341 [00:04<00:01, 53.92it/s, Epoch: 17, Batch: 262,Loss: -2.781,Avg.Loss: -2.558,LR: 3.15E-05]Training epoch 17:  77%|███████▋  | 262/341 [00:04<00:01, 53.92it/s, Epoch: 17, Batch: 263,Loss: -2.603,Avg.Loss: -2.558,LR: 3.15E-05]Training epoch 17:  77%|███████▋  | 263/341 [00:04<00:01, 53.92it/s, Epoch: 17, Batch: 264,Loss: -2.973,Avg.Loss: -2.560,LR: 3.14E-05]Training epoch 17:  77%|███████▋  | 264/341 [00:04<00:01, 53.92it/s, Epoch: 17, Batch: 265,Loss: -2.876,Avg.Loss: -2.561,LR: 3.14E-05]Training epoch 17:  78%|███████▊  | 265/341 [00:04<00:01, 53.92it/s, Epoch: 17, Batch: 266,Loss: -2.601,Avg.Loss: -2.561,LR: 3.13E-05]Training epoch 17:  78%|███████▊  | 266/341 [00:04<00:01, 52.89it/s, Epoch: 17, Batch: 266,Loss: -2.601,Avg.Loss: -2.561,LR: 3.13E-05]Training epoch 17:  78%|███████▊  | 266/341 [00:04<00:01, 52.89it/s, Epoch: 17, Batch: 267,Loss: -2.520,Avg.Loss: -2.561,LR: 3.12E-05]Training epoch 17:  78%|███████▊  | 267/341 [00:04<00:01, 52.89it/s, Epoch: 17, Batch: 268,Loss: -2.693,Avg.Loss: -2.561,LR: 3.12E-05]Training epoch 17:  79%|███████▊  | 268/341 [00:04<00:01, 52.89it/s, Epoch: 17, Batch: 269,Loss: -2.670,Avg.Loss: -2.562,LR: 3.11E-05]Training epoch 17:  79%|███████▉  | 269/341 [00:04<00:01, 52.89it/s, Epoch: 17, Batch: 270,Loss: -2.548,Avg.Loss: -2.562,LR: 3.11E-05]Training epoch 17:  79%|███████▉  | 270/341 [00:04<00:01, 52.89it/s, Epoch: 17, Batch: 271,Loss: -2.531,Avg.Loss: -2.562,LR: 3.10E-05]Training epoch 17:  79%|███████▉  | 271/341 [00:05<00:01, 52.89it/s, Epoch: 17, Batch: 272,Loss: -2.616,Avg.Loss: -2.562,LR: 3.10E-05]Training epoch 17:  80%|███████▉  | 272/341 [00:05<00:01, 53.79it/s, Epoch: 17, Batch: 272,Loss: -2.616,Avg.Loss: -2.562,LR: 3.10E-05]Training epoch 17:  80%|███████▉  | 272/341 [00:05<00:01, 53.79it/s, Epoch: 17, Batch: 273,Loss: -2.574,Avg.Loss: -2.562,LR: 3.09E-05]Training epoch 17:  80%|████████  | 273/341 [00:05<00:01, 53.79it/s, Epoch: 17, Batch: 274,Loss: -2.314,Avg.Loss: -2.561,LR: 3.09E-05]Training epoch 17:  80%|████████  | 274/341 [00:05<00:01, 53.79it/s, Epoch: 17, Batch: 275,Loss: -2.697,Avg.Loss: -2.562,LR: 3.08E-05]Training epoch 17:  81%|████████  | 275/341 [00:05<00:01, 53.79it/s, Epoch: 17, Batch: 276,Loss: -2.676,Avg.Loss: -2.562,LR: 3.07E-05]Training epoch 17:  81%|████████  | 276/341 [00:05<00:01, 53.79it/s, Epoch: 17, Batch: 277,Loss: -2.809,Avg.Loss: -2.563,LR: 3.07E-05]Training epoch 17:  81%|████████  | 277/341 [00:05<00:01, 53.79it/s, Epoch: 17, Batch: 278,Loss: -2.438,Avg.Loss: -2.562,LR: 3.06E-05]Training epoch 17:  82%|████████▏ | 278/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 278,Loss: -2.438,Avg.Loss: -2.562,LR: 3.06E-05]Training epoch 17:  82%|████████▏ | 278/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 279,Loss: -2.705,Avg.Loss: -2.563,LR: 3.06E-05]Training epoch 17:  82%|████████▏ | 279/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 280,Loss: -2.390,Avg.Loss: -2.562,LR: 3.05E-05]Training epoch 17:  82%|████████▏ | 280/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 281,Loss: -2.426,Avg.Loss: -2.562,LR: 3.05E-05]Training epoch 17:  82%|████████▏ | 281/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 282,Loss: -2.781,Avg.Loss: -2.563,LR: 3.04E-05]Training epoch 17:  83%|████████▎ | 282/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 283,Loss: -2.343,Avg.Loss: -2.562,LR: 3.04E-05]Training epoch 17:  83%|████████▎ | 283/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 284,Loss: -2.515,Avg.Loss: -2.562,LR: 3.03E-05]Training epoch 17:  83%|████████▎ | 284/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 284,Loss: -2.515,Avg.Loss: -2.562,LR: 3.03E-05]Training epoch 17:  83%|████████▎ | 284/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 285,Loss: -2.601,Avg.Loss: -2.562,LR: 3.02E-05]Training epoch 17:  84%|████████▎ | 285/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 286,Loss: -2.305,Avg.Loss: -2.561,LR: 3.02E-05]Training epoch 17:  84%|████████▍ | 286/341 [00:05<00:01, 54.06it/s, Epoch: 17, Batch: 287,Loss: -2.211,Avg.Loss: -2.560,LR: 3.01E-05]Training epoch 17:  84%|████████▍ | 287/341 [00:05<00:00, 54.06it/s, Epoch: 17, Batch: 288,Loss: -2.376,Avg.Loss: -2.559,LR: 3.01E-05]Training epoch 17:  84%|████████▍ | 288/341 [00:05<00:00, 54.06it/s, Epoch: 17, Batch: 289,Loss: -2.320,Avg.Loss: -2.558,LR: 3.00E-05]Training epoch 17:  85%|████████▍ | 289/341 [00:05<00:00, 54.06it/s, Epoch: 17, Batch: 290,Loss: -2.322,Avg.Loss: -2.557,LR: 3.00E-05]Training epoch 17:  85%|████████▌ | 290/341 [00:05<00:00, 55.16it/s, Epoch: 17, Batch: 290,Loss: -2.322,Avg.Loss: -2.557,LR: 3.00E-05]Training epoch 17:  85%|████████▌ | 290/341 [00:05<00:00, 55.16it/s, Epoch: 17, Batch: 291,Loss: -2.290,Avg.Loss: -2.556,LR: 2.99E-05]Training epoch 17:  85%|████████▌ | 291/341 [00:05<00:00, 55.16it/s, Epoch: 17, Batch: 292,Loss: -2.758,Avg.Loss: -2.557,LR: 2.99E-05]Training epoch 17:  86%|████████▌ | 292/341 [00:05<00:00, 55.16it/s, Epoch: 17, Batch: 293,Loss: -2.564,Avg.Loss: -2.557,LR: 2.98E-05]Training epoch 17:  86%|████████▌ | 293/341 [00:05<00:00, 55.16it/s, Epoch: 17, Batch: 294,Loss: -2.222,Avg.Loss: -2.556,LR: 2.98E-05]Training epoch 17:  86%|████████▌ | 294/341 [00:05<00:00, 55.16it/s, Epoch: 17, Batch: 295,Loss: -2.322,Avg.Loss: -2.555,LR: 2.97E-05]Training epoch 17:  87%|████████▋ | 295/341 [00:05<00:00, 55.16it/s, Epoch: 17, Batch: 296,Loss: -2.798,Avg.Loss: -2.556,LR: 2.96E-05]Training epoch 17:  87%|████████▋ | 296/341 [00:05<00:00, 55.59it/s, Epoch: 17, Batch: 296,Loss: -2.798,Avg.Loss: -2.556,LR: 2.96E-05]Training epoch 17:  87%|████████▋ | 296/341 [00:05<00:00, 55.59it/s, Epoch: 17, Batch: 297,Loss: -2.618,Avg.Loss: -2.556,LR: 2.96E-05]Training epoch 17:  87%|████████▋ | 297/341 [00:05<00:00, 55.59it/s, Epoch: 17, Batch: 298,Loss: -2.894,Avg.Loss: -2.557,LR: 2.95E-05]Training epoch 17:  87%|████████▋ | 298/341 [00:05<00:00, 55.59it/s, Epoch: 17, Batch: 299,Loss: -2.779,Avg.Loss: -2.558,LR: 2.95E-05]Training epoch 17:  88%|████████▊ | 299/341 [00:05<00:00, 55.59it/s, Epoch: 17, Batch: 300,Loss: -2.693,Avg.Loss: -2.559,LR: 2.94E-05]Training epoch 17:  88%|████████▊ | 300/341 [00:05<00:00, 55.59it/s, Epoch: 17, Batch: 301,Loss: -2.600,Avg.Loss: -2.559,LR: 2.94E-05]Training epoch 17:  88%|████████▊ | 301/341 [00:05<00:00, 55.59it/s, Epoch: 17, Batch: 302,Loss: -2.494,Avg.Loss: -2.559,LR: 2.93E-05]Training epoch 17:  89%|████████▊ | 302/341 [00:05<00:00, 55.21it/s, Epoch: 17, Batch: 302,Loss: -2.494,Avg.Loss: -2.559,LR: 2.93E-05]Training epoch 17:  89%|████████▊ | 302/341 [00:05<00:00, 55.21it/s, Epoch: 17, Batch: 303,Loss: -2.689,Avg.Loss: -2.559,LR: 2.93E-05]Training epoch 17:  89%|████████▉ | 303/341 [00:05<00:00, 55.21it/s, Epoch: 17, Batch: 304,Loss: -2.836,Avg.Loss: -2.560,LR: 2.92E-05]Training epoch 17:  89%|████████▉ | 304/341 [00:05<00:00, 55.21it/s, Epoch: 17, Batch: 305,Loss: -2.770,Avg.Loss: -2.561,LR: 2.92E-05]Training epoch 17:  89%|████████▉ | 305/341 [00:05<00:00, 55.21it/s, Epoch: 17, Batch: 306,Loss: -2.931,Avg.Loss: -2.562,LR: 2.91E-05]Training epoch 17:  90%|████████▉ | 306/341 [00:05<00:00, 55.21it/s, Epoch: 17, Batch: 307,Loss: -2.635,Avg.Loss: -2.562,LR: 2.91E-05]Training epoch 17:  90%|█████████ | 307/341 [00:05<00:00, 55.21it/s, Epoch: 17, Batch: 308,Loss: -2.665,Avg.Loss: -2.562,LR: 2.90E-05]Training epoch 17:  90%|█████████ | 308/341 [00:05<00:00, 54.96it/s, Epoch: 17, Batch: 308,Loss: -2.665,Avg.Loss: -2.562,LR: 2.90E-05]Training epoch 17:  90%|█████████ | 308/341 [00:05<00:00, 54.96it/s, Epoch: 17, Batch: 309,Loss: -2.528,Avg.Loss: -2.562,LR: 2.89E-05]Training epoch 17:  91%|█████████ | 309/341 [00:05<00:00, 54.96it/s, Epoch: 17, Batch: 310,Loss: -2.527,Avg.Loss: -2.562,LR: 2.89E-05]Training epoch 17:  91%|█████████ | 310/341 [00:05<00:00, 54.96it/s, Epoch: 17, Batch: 311,Loss: -2.765,Avg.Loss: -2.563,LR: 2.88E-05]Training epoch 17:  91%|█████████ | 311/341 [00:05<00:00, 54.96it/s, Epoch: 17, Batch: 312,Loss: -2.142,Avg.Loss: -2.561,LR: 2.88E-05]Training epoch 17:  91%|█████████▏| 312/341 [00:05<00:00, 54.96it/s, Epoch: 17, Batch: 313,Loss: -2.593,Avg.Loss: -2.562,LR: 2.87E-05]Training epoch 17:  92%|█████████▏| 313/341 [00:05<00:00, 54.96it/s, Epoch: 17, Batch: 314,Loss: -2.185,Avg.Loss: -2.560,LR: 2.87E-05]Training epoch 17:  92%|█████████▏| 314/341 [00:05<00:00, 54.59it/s, Epoch: 17, Batch: 314,Loss: -2.185,Avg.Loss: -2.560,LR: 2.87E-05]Training epoch 17:  92%|█████████▏| 314/341 [00:05<00:00, 54.59it/s, Epoch: 17, Batch: 315,Loss: -2.388,Avg.Loss: -2.560,LR: 2.86E-05]Training epoch 17:  92%|█████████▏| 315/341 [00:05<00:00, 54.59it/s, Epoch: 17, Batch: 316,Loss: -2.512,Avg.Loss: -2.560,LR: 2.86E-05]Training epoch 17:  93%|█████████▎| 316/341 [00:05<00:00, 54.59it/s, Epoch: 17, Batch: 317,Loss: -2.238,Avg.Loss: -2.559,LR: 2.85E-05]Training epoch 17:  93%|█████████▎| 317/341 [00:05<00:00, 54.59it/s, Epoch: 17, Batch: 318,Loss: -2.393,Avg.Loss: -2.558,LR: 2.85E-05]Training epoch 17:  93%|█████████▎| 318/341 [00:05<00:00, 54.59it/s, Epoch: 17, Batch: 319,Loss: -2.605,Avg.Loss: -2.558,LR: 2.84E-05]Training epoch 17:  94%|█████████▎| 319/341 [00:05<00:00, 54.59it/s, Epoch: 17, Batch: 320,Loss: -2.709,Avg.Loss: -2.559,LR: 2.84E-05]Training epoch 17:  94%|█████████▍| 320/341 [00:05<00:00, 54.43it/s, Epoch: 17, Batch: 320,Loss: -2.709,Avg.Loss: -2.559,LR: 2.84E-05]Training epoch 17:  94%|█████████▍| 320/341 [00:05<00:00, 54.43it/s, Epoch: 17, Batch: 321,Loss: -2.866,Avg.Loss: -2.560,LR: 2.83E-05]Training epoch 17:  94%|█████████▍| 321/341 [00:05<00:00, 54.43it/s, Epoch: 17, Batch: 322,Loss: -2.623,Avg.Loss: -2.560,LR: 2.83E-05]Training epoch 17:  94%|█████████▍| 322/341 [00:05<00:00, 54.43it/s, Epoch: 17, Batch: 323,Loss: -1.864,Avg.Loss: -2.558,LR: 2.82E-05]Training epoch 17:  95%|█████████▍| 323/341 [00:05<00:00, 54.43it/s, Epoch: 17, Batch: 324,Loss: -1.825,Avg.Loss: -2.555,LR: 2.81E-05]Training epoch 17:  95%|█████████▌| 324/341 [00:05<00:00, 54.43it/s, Epoch: 17, Batch: 325,Loss: -2.550,Avg.Loss: -2.555,LR: 2.81E-05]Training epoch 17:  95%|█████████▌| 325/341 [00:05<00:00, 54.43it/s, Epoch: 17, Batch: 326,Loss: -2.497,Avg.Loss: -2.555,LR: 2.80E-05]Training epoch 17:  96%|█████████▌| 326/341 [00:05<00:00, 54.33it/s, Epoch: 17, Batch: 326,Loss: -2.497,Avg.Loss: -2.555,LR: 2.80E-05]Training epoch 17:  96%|█████████▌| 326/341 [00:06<00:00, 54.33it/s, Epoch: 17, Batch: 327,Loss: -2.520,Avg.Loss: -2.555,LR: 2.80E-05]Training epoch 17:  96%|█████████▌| 327/341 [00:06<00:00, 54.33it/s, Epoch: 17, Batch: 328,Loss: -2.607,Avg.Loss: -2.555,LR: 2.79E-05]Training epoch 17:  96%|█████████▌| 328/341 [00:06<00:00, 54.33it/s, Epoch: 17, Batch: 329,Loss: -1.258,Avg.Loss: -2.551,LR: 2.79E-05]Training epoch 17:  96%|█████████▋| 329/341 [00:06<00:00, 54.33it/s, Epoch: 17, Batch: 330,Loss: -2.709,Avg.Loss: -2.552,LR: 2.78E-05]Training epoch 17:  97%|█████████▋| 330/341 [00:06<00:00, 54.33it/s, Epoch: 17, Batch: 331,Loss: -2.456,Avg.Loss: -2.552,LR: 2.78E-05]Training epoch 17:  97%|█████████▋| 331/341 [00:06<00:00, 54.33it/s, Epoch: 17, Batch: 332,Loss: -2.821,Avg.Loss: -2.552,LR: 2.77E-05]Training epoch 17:  97%|█████████▋| 332/341 [00:06<00:00, 54.17it/s, Epoch: 17, Batch: 332,Loss: -2.821,Avg.Loss: -2.552,LR: 2.77E-05]Training epoch 17:  97%|█████████▋| 332/341 [00:06<00:00, 54.17it/s, Epoch: 17, Batch: 333,Loss: -2.611,Avg.Loss: -2.553,LR: 2.77E-05]Training epoch 17:  98%|█████████▊| 333/341 [00:06<00:00, 54.17it/s, Epoch: 17, Batch: 334,Loss: -2.418,Avg.Loss: -2.552,LR: 2.76E-05]Training epoch 17:  98%|█████████▊| 334/341 [00:06<00:00, 54.17it/s, Epoch: 17, Batch: 335,Loss: -2.001,Avg.Loss: -2.550,LR: 2.76E-05]Training epoch 17:  98%|█████████▊| 335/341 [00:06<00:00, 54.17it/s, Epoch: 17, Batch: 336,Loss: -2.410,Avg.Loss: -2.550,LR: 2.75E-05]Training epoch 17:  99%|█████████▊| 336/341 [00:06<00:00, 54.17it/s, Epoch: 17, Batch: 337,Loss: -2.565,Avg.Loss: -2.550,LR: 2.75E-05]Training epoch 17:  99%|█████████▉| 337/341 [00:06<00:00, 54.17it/s, Epoch: 17, Batch: 338,Loss: -2.242,Avg.Loss: -2.549,LR: 2.74E-05]Training epoch 17:  99%|█████████▉| 338/341 [00:06<00:00, 54.19it/s, Epoch: 17, Batch: 338,Loss: -2.242,Avg.Loss: -2.549,LR: 2.74E-05]Training epoch 17:  99%|█████████▉| 338/341 [00:06<00:00, 54.19it/s, Epoch: 17, Batch: 339,Loss: -2.114,Avg.Loss: -2.548,LR: 2.74E-05]Training epoch 17:  99%|█████████▉| 339/341 [00:06<00:00, 54.19it/s, Epoch: 17, Batch: 340,Loss: -2.722,Avg.Loss: -2.548,LR: 2.73E-05]Training epoch 17: 100%|█████████▉| 340/341 [00:06<00:00, 54.19it/s, Epoch: 17, Batch: 341,Loss: -2.872,Avg.Loss: -2.549,LR: 2.72E-05]Training epoch 17: 100%|██████████| 341/341 [00:06<00:00, 54.41it/s, Epoch: 17, Batch: 341,Loss: -2.872,Avg.Loss: -2.549,LR: 2.72E-05]
Training epoch 18:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 18:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 18, Batch: 1,Loss: -2.903,Avg.Loss: -2.903,LR: 2.72E-05]Training epoch 18:   0%|          | 1/341 [00:00<00:12, 27.23it/s, Epoch: 18, Batch: 2,Loss: -2.673,Avg.Loss: -2.788,LR: 2.71E-05]Training epoch 18:   1%|          | 2/341 [00:00<00:09, 37.30it/s, Epoch: 18, Batch: 3,Loss: -2.569,Avg.Loss: -2.715,LR: 2.71E-05]Training epoch 18:   1%|          | 3/341 [00:00<00:08, 41.68it/s, Epoch: 18, Batch: 4,Loss: -2.965,Avg.Loss: -2.777,LR: 2.70E-05]Training epoch 18:   1%|          | 4/341 [00:00<00:07, 44.33it/s, Epoch: 18, Batch: 5,Loss: -2.735,Avg.Loss: -2.769,LR: 2.70E-05]Training epoch 18:   1%|▏         | 5/341 [00:00<00:07, 46.02it/s, Epoch: 18, Batch: 6,Loss: -2.803,Avg.Loss: -2.774,LR: 2.69E-05]Training epoch 18:   2%|▏         | 6/341 [00:00<00:06, 55.11it/s, Epoch: 18, Batch: 6,Loss: -2.803,Avg.Loss: -2.774,LR: 2.69E-05]Training epoch 18:   2%|▏         | 6/341 [00:00<00:06, 55.11it/s, Epoch: 18, Batch: 7,Loss: -2.524,Avg.Loss: -2.739,LR: 2.69E-05]Training epoch 18:   2%|▏         | 7/341 [00:00<00:06, 55.11it/s, Epoch: 18, Batch: 8,Loss: -2.740,Avg.Loss: -2.739,LR: 2.68E-05]Training epoch 18:   2%|▏         | 8/341 [00:00<00:06, 55.11it/s, Epoch: 18, Batch: 9,Loss: -2.874,Avg.Loss: -2.754,LR: 2.68E-05]Training epoch 18:   3%|▎         | 9/341 [00:00<00:06, 55.11it/s, Epoch: 18, Batch: 10,Loss: -2.621,Avg.Loss: -2.741,LR: 2.67E-05]Training epoch 18:   3%|▎         | 10/341 [00:00<00:06, 55.11it/s, Epoch: 18, Batch: 11,Loss: -3.207,Avg.Loss: -2.783,LR: 2.67E-05]Training epoch 18:   3%|▎         | 11/341 [00:00<00:05, 55.11it/s, Epoch: 18, Batch: 12,Loss: -2.736,Avg.Loss: -2.779,LR: 2.66E-05]Training epoch 18:   4%|▎         | 12/341 [00:00<00:06, 54.56it/s, Epoch: 18, Batch: 12,Loss: -2.736,Avg.Loss: -2.779,LR: 2.66E-05]Training epoch 18:   4%|▎         | 12/341 [00:00<00:06, 54.56it/s, Epoch: 18, Batch: 13,Loss: -2.760,Avg.Loss: -2.778,LR: 2.66E-05]Training epoch 18:   4%|▍         | 13/341 [00:00<00:06, 54.56it/s, Epoch: 18, Batch: 14,Loss: -2.818,Avg.Loss: -2.781,LR: 2.65E-05]Training epoch 18:   4%|▍         | 14/341 [00:00<00:05, 54.56it/s, Epoch: 18, Batch: 15,Loss: -2.908,Avg.Loss: -2.789,LR: 2.65E-05]Training epoch 18:   4%|▍         | 15/341 [00:00<00:05, 54.56it/s, Epoch: 18, Batch: 16,Loss: -2.854,Avg.Loss: -2.793,LR: 2.64E-05]Training epoch 18:   5%|▍         | 16/341 [00:00<00:05, 54.56it/s, Epoch: 18, Batch: 17,Loss: -2.851,Avg.Loss: -2.796,LR: 2.64E-05]Training epoch 18:   5%|▍         | 17/341 [00:00<00:05, 54.56it/s, Epoch: 18, Batch: 18,Loss: -2.455,Avg.Loss: -2.778,LR: 2.63E-05]Training epoch 18:   5%|▌         | 18/341 [00:00<00:05, 54.18it/s, Epoch: 18, Batch: 18,Loss: -2.455,Avg.Loss: -2.778,LR: 2.63E-05]Training epoch 18:   5%|▌         | 18/341 [00:00<00:05, 54.18it/s, Epoch: 18, Batch: 19,Loss: -2.929,Avg.Loss: -2.786,LR: 2.63E-05]Training epoch 18:   6%|▌         | 19/341 [00:00<00:05, 54.18it/s, Epoch: 18, Batch: 20,Loss: -3.014,Avg.Loss: -2.797,LR: 2.62E-05]Training epoch 18:   6%|▌         | 20/341 [00:00<00:05, 54.18it/s, Epoch: 18, Batch: 21,Loss: -2.651,Avg.Loss: -2.790,LR: 2.62E-05]Training epoch 18:   6%|▌         | 21/341 [00:00<00:05, 54.18it/s, Epoch: 18, Batch: 22,Loss: -2.549,Avg.Loss: -2.779,LR: 2.61E-05]Training epoch 18:   6%|▋         | 22/341 [00:00<00:05, 54.18it/s, Epoch: 18, Batch: 23,Loss: -2.715,Avg.Loss: -2.776,LR: 2.61E-05]Training epoch 18:   7%|▋         | 23/341 [00:00<00:05, 54.18it/s, Epoch: 18, Batch: 24,Loss: -2.711,Avg.Loss: -2.773,LR: 2.60E-05]Training epoch 18:   7%|▋         | 24/341 [00:00<00:06, 52.59it/s, Epoch: 18, Batch: 24,Loss: -2.711,Avg.Loss: -2.773,LR: 2.60E-05]Training epoch 18:   7%|▋         | 24/341 [00:00<00:06, 52.59it/s, Epoch: 18, Batch: 25,Loss: -2.644,Avg.Loss: -2.768,LR: 2.60E-05]Training epoch 18:   7%|▋         | 25/341 [00:00<00:06, 52.59it/s, Epoch: 18, Batch: 26,Loss: -2.516,Avg.Loss: -2.759,LR: 2.59E-05]Training epoch 18:   8%|▊         | 26/341 [00:00<00:05, 52.59it/s, Epoch: 18, Batch: 27,Loss: -2.449,Avg.Loss: -2.747,LR: 2.59E-05]Training epoch 18:   8%|▊         | 27/341 [00:00<00:05, 52.59it/s, Epoch: 18, Batch: 28,Loss: -2.527,Avg.Loss: -2.739,LR: 2.58E-05]Training epoch 18:   8%|▊         | 28/341 [00:00<00:05, 52.59it/s, Epoch: 18, Batch: 29,Loss: -2.697,Avg.Loss: -2.738,LR: 2.58E-05]Training epoch 18:   9%|▊         | 29/341 [00:00<00:05, 52.59it/s, Epoch: 18, Batch: 30,Loss: -2.724,Avg.Loss: -2.737,LR: 2.57E-05]Training epoch 18:   9%|▉         | 30/341 [00:00<00:05, 52.77it/s, Epoch: 18, Batch: 30,Loss: -2.724,Avg.Loss: -2.737,LR: 2.57E-05]Training epoch 18:   9%|▉         | 30/341 [00:00<00:05, 52.77it/s, Epoch: 18, Batch: 31,Loss: -2.490,Avg.Loss: -2.729,LR: 2.57E-05]Training epoch 18:   9%|▉         | 31/341 [00:00<00:05, 52.77it/s, Epoch: 18, Batch: 32,Loss: -2.762,Avg.Loss: -2.730,LR: 2.56E-05]Training epoch 18:   9%|▉         | 32/341 [00:00<00:05, 52.77it/s, Epoch: 18, Batch: 33,Loss: -2.869,Avg.Loss: -2.735,LR: 2.55E-05]Training epoch 18:  10%|▉         | 33/341 [00:00<00:05, 52.77it/s, Epoch: 18, Batch: 34,Loss: -2.524,Avg.Loss: -2.728,LR: 2.55E-05]Training epoch 18:  10%|▉         | 34/341 [00:00<00:05, 52.77it/s, Epoch: 18, Batch: 35,Loss: -2.275,Avg.Loss: -2.715,LR: 2.54E-05]Training epoch 18:  10%|█         | 35/341 [00:00<00:05, 52.77it/s, Epoch: 18, Batch: 36,Loss: -2.631,Avg.Loss: -2.713,LR: 2.54E-05]Training epoch 18:  11%|█         | 36/341 [00:00<00:05, 53.29it/s, Epoch: 18, Batch: 36,Loss: -2.631,Avg.Loss: -2.713,LR: 2.54E-05]Training epoch 18:  11%|█         | 36/341 [00:00<00:05, 53.29it/s, Epoch: 18, Batch: 37,Loss: -2.673,Avg.Loss: -2.712,LR: 2.53E-05]Training epoch 18:  11%|█         | 37/341 [00:00<00:05, 53.29it/s, Epoch: 18, Batch: 38,Loss: -2.508,Avg.Loss: -2.707,LR: 2.53E-05]Training epoch 18:  11%|█         | 38/341 [00:00<00:05, 53.29it/s, Epoch: 18, Batch: 39,Loss: -2.637,Avg.Loss: -2.705,LR: 2.52E-05]Training epoch 18:  11%|█▏        | 39/341 [00:00<00:05, 53.29it/s, Epoch: 18, Batch: 40,Loss: -2.834,Avg.Loss: -2.708,LR: 2.52E-05]Training epoch 18:  12%|█▏        | 40/341 [00:00<00:05, 53.29it/s, Epoch: 18, Batch: 41,Loss: -3.024,Avg.Loss: -2.716,LR: 2.51E-05]Training epoch 18:  12%|█▏        | 41/341 [00:00<00:05, 53.29it/s, Epoch: 18, Batch: 42,Loss: -2.693,Avg.Loss: -2.715,LR: 2.51E-05]Training epoch 18:  12%|█▏        | 42/341 [00:00<00:05, 53.31it/s, Epoch: 18, Batch: 42,Loss: -2.693,Avg.Loss: -2.715,LR: 2.51E-05]Training epoch 18:  12%|█▏        | 42/341 [00:00<00:05, 53.31it/s, Epoch: 18, Batch: 43,Loss: -2.261,Avg.Loss: -2.705,LR: 2.50E-05]Training epoch 18:  13%|█▎        | 43/341 [00:00<00:05, 53.31it/s, Epoch: 18, Batch: 44,Loss: -2.521,Avg.Loss: -2.701,LR: 2.50E-05]Training epoch 18:  13%|█▎        | 44/341 [00:00<00:05, 53.31it/s, Epoch: 18, Batch: 45,Loss: -2.520,Avg.Loss: -2.696,LR: 2.49E-05]Training epoch 18:  13%|█▎        | 45/341 [00:00<00:05, 53.31it/s, Epoch: 18, Batch: 46,Loss: -2.625,Avg.Loss: -2.695,LR: 2.49E-05]Training epoch 18:  13%|█▎        | 46/341 [00:00<00:05, 53.31it/s, Epoch: 18, Batch: 47,Loss: -2.926,Avg.Loss: -2.700,LR: 2.48E-05]Training epoch 18:  14%|█▍        | 47/341 [00:00<00:05, 53.31it/s, Epoch: 18, Batch: 48,Loss: -2.644,Avg.Loss: -2.699,LR: 2.48E-05]Training epoch 18:  14%|█▍        | 48/341 [00:00<00:05, 53.30it/s, Epoch: 18, Batch: 48,Loss: -2.644,Avg.Loss: -2.699,LR: 2.48E-05]Training epoch 18:  14%|█▍        | 48/341 [00:00<00:05, 53.30it/s, Epoch: 18, Batch: 49,Loss: -2.058,Avg.Loss: -2.686,LR: 2.47E-05]Training epoch 18:  14%|█▍        | 49/341 [00:00<00:05, 53.30it/s, Epoch: 18, Batch: 50,Loss: -2.873,Avg.Loss: -2.689,LR: 2.47E-05]Training epoch 18:  15%|█▍        | 50/341 [00:00<00:05, 53.30it/s, Epoch: 18, Batch: 51,Loss: -2.822,Avg.Loss: -2.692,LR: 2.46E-05]Training epoch 18:  15%|█▍        | 51/341 [00:00<00:05, 53.30it/s, Epoch: 18, Batch: 52,Loss: -2.342,Avg.Loss: -2.685,LR: 2.46E-05]Training epoch 18:  15%|█▌        | 52/341 [00:00<00:05, 53.30it/s, Epoch: 18, Batch: 53,Loss: -2.452,Avg.Loss: -2.681,LR: 2.45E-05]Training epoch 18:  16%|█▌        | 53/341 [00:01<00:05, 53.30it/s, Epoch: 18, Batch: 54,Loss: -2.790,Avg.Loss: -2.683,LR: 2.45E-05]Training epoch 18:  16%|█▌        | 54/341 [00:01<00:05, 53.38it/s, Epoch: 18, Batch: 54,Loss: -2.790,Avg.Loss: -2.683,LR: 2.45E-05]Training epoch 18:  16%|█▌        | 54/341 [00:01<00:05, 53.38it/s, Epoch: 18, Batch: 55,Loss: -2.964,Avg.Loss: -2.688,LR: 2.44E-05]Training epoch 18:  16%|█▌        | 55/341 [00:01<00:05, 53.38it/s, Epoch: 18, Batch: 56,Loss: -2.940,Avg.Loss: -2.692,LR: 2.44E-05]Training epoch 18:  16%|█▋        | 56/341 [00:01<00:05, 53.38it/s, Epoch: 18, Batch: 57,Loss: -2.566,Avg.Loss: -2.690,LR: 2.43E-05]Training epoch 18:  17%|█▋        | 57/341 [00:01<00:05, 53.38it/s, Epoch: 18, Batch: 58,Loss: -2.570,Avg.Loss: -2.688,LR: 2.43E-05]Training epoch 18:  17%|█▋        | 58/341 [00:01<00:05, 53.38it/s, Epoch: 18, Batch: 59,Loss: -2.048,Avg.Loss: -2.677,LR: 2.42E-05]Training epoch 18:  17%|█▋        | 59/341 [00:01<00:05, 53.38it/s, Epoch: 18, Batch: 60,Loss: -2.436,Avg.Loss: -2.673,LR: 2.42E-05]Training epoch 18:  18%|█▊        | 60/341 [00:01<00:05, 53.84it/s, Epoch: 18, Batch: 60,Loss: -2.436,Avg.Loss: -2.673,LR: 2.42E-05]Training epoch 18:  18%|█▊        | 60/341 [00:01<00:05, 53.84it/s, Epoch: 18, Batch: 61,Loss: -2.968,Avg.Loss: -2.678,LR: 2.41E-05]Training epoch 18:  18%|█▊        | 61/341 [00:01<00:05, 53.84it/s, Epoch: 18, Batch: 62,Loss: -2.660,Avg.Loss: -2.678,LR: 2.41E-05]Training epoch 18:  18%|█▊        | 62/341 [00:01<00:05, 53.84it/s, Epoch: 18, Batch: 63,Loss: -2.469,Avg.Loss: -2.675,LR: 2.40E-05]Training epoch 18:  18%|█▊        | 63/341 [00:01<00:05, 53.84it/s, Epoch: 18, Batch: 64,Loss: -2.105,Avg.Loss: -2.666,LR: 2.40E-05]Training epoch 18:  19%|█▉        | 64/341 [00:01<00:05, 53.84it/s, Epoch: 18, Batch: 65,Loss: -2.919,Avg.Loss: -2.670,LR: 2.40E-05]Training epoch 18:  19%|█▉        | 65/341 [00:01<00:05, 53.84it/s, Epoch: 18, Batch: 66,Loss: -1.946,Avg.Loss: -2.659,LR: 2.39E-05]Training epoch 18:  19%|█▉        | 66/341 [00:01<00:05, 54.05it/s, Epoch: 18, Batch: 66,Loss: -1.946,Avg.Loss: -2.659,LR: 2.39E-05]Training epoch 18:  19%|█▉        | 66/341 [00:01<00:05, 54.05it/s, Epoch: 18, Batch: 67,Loss: -2.450,Avg.Loss: -2.655,LR: 2.39E-05]Training epoch 18:  20%|█▉        | 67/341 [00:01<00:05, 54.05it/s, Epoch: 18, Batch: 68,Loss: -2.438,Avg.Loss: -2.652,LR: 2.38E-05]Training epoch 18:  20%|█▉        | 68/341 [00:01<00:05, 54.05it/s, Epoch: 18, Batch: 69,Loss: -1.939,Avg.Loss: -2.642,LR: 2.38E-05]Training epoch 18:  20%|██        | 69/341 [00:01<00:05, 54.05it/s, Epoch: 18, Batch: 70,Loss: -2.326,Avg.Loss: -2.637,LR: 2.37E-05]Training epoch 18:  21%|██        | 70/341 [00:01<00:05, 54.05it/s, Epoch: 18, Batch: 71,Loss: -2.598,Avg.Loss: -2.637,LR: 2.37E-05]Training epoch 18:  21%|██        | 71/341 [00:01<00:04, 54.05it/s, Epoch: 18, Batch: 72,Loss: -2.699,Avg.Loss: -2.638,LR: 2.36E-05]Training epoch 18:  21%|██        | 72/341 [00:01<00:04, 53.98it/s, Epoch: 18, Batch: 72,Loss: -2.699,Avg.Loss: -2.638,LR: 2.36E-05]Training epoch 18:  21%|██        | 72/341 [00:01<00:04, 53.98it/s, Epoch: 18, Batch: 73,Loss: -2.754,Avg.Loss: -2.639,LR: 2.36E-05]Training epoch 18:  21%|██▏       | 73/341 [00:01<00:04, 53.98it/s, Epoch: 18, Batch: 74,Loss: -2.682,Avg.Loss: -2.640,LR: 2.35E-05]Training epoch 18:  22%|██▏       | 74/341 [00:01<00:04, 53.98it/s, Epoch: 18, Batch: 75,Loss: -2.753,Avg.Loss: -2.641,LR: 2.35E-05]Training epoch 18:  22%|██▏       | 75/341 [00:01<00:04, 53.98it/s, Epoch: 18, Batch: 76,Loss: -2.569,Avg.Loss: -2.640,LR: 2.34E-05]Training epoch 18:  22%|██▏       | 76/341 [00:01<00:04, 53.98it/s, Epoch: 18, Batch: 77,Loss: -2.640,Avg.Loss: -2.640,LR: 2.34E-05]Training epoch 18:  23%|██▎       | 77/341 [00:01<00:04, 53.98it/s, Epoch: 18, Batch: 78,Loss: -2.738,Avg.Loss: -2.642,LR: 2.33E-05]Training epoch 18:  23%|██▎       | 78/341 [00:01<00:04, 55.33it/s, Epoch: 18, Batch: 78,Loss: -2.738,Avg.Loss: -2.642,LR: 2.33E-05]Training epoch 18:  23%|██▎       | 78/341 [00:01<00:04, 55.33it/s, Epoch: 18, Batch: 79,Loss: -2.452,Avg.Loss: -2.639,LR: 2.33E-05]Training epoch 18:  23%|██▎       | 79/341 [00:01<00:04, 55.33it/s, Epoch: 18, Batch: 80,Loss: -2.604,Avg.Loss: -2.639,LR: 2.32E-05]Training epoch 18:  23%|██▎       | 80/341 [00:01<00:04, 55.33it/s, Epoch: 18, Batch: 81,Loss: -2.245,Avg.Loss: -2.634,LR: 2.32E-05]Training epoch 18:  24%|██▍       | 81/341 [00:01<00:04, 55.33it/s, Epoch: 18, Batch: 82,Loss: -2.334,Avg.Loss: -2.630,LR: 2.31E-05]Training epoch 18:  24%|██▍       | 82/341 [00:01<00:04, 55.33it/s, Epoch: 18, Batch: 83,Loss: -2.749,Avg.Loss: -2.632,LR: 2.31E-05]Training epoch 18:  24%|██▍       | 83/341 [00:01<00:04, 55.33it/s, Epoch: 18, Batch: 84,Loss: -2.696,Avg.Loss: -2.633,LR: 2.30E-05]Training epoch 18:  25%|██▍       | 84/341 [00:01<00:04, 55.25it/s, Epoch: 18, Batch: 84,Loss: -2.696,Avg.Loss: -2.633,LR: 2.30E-05]Training epoch 18:  25%|██▍       | 84/341 [00:01<00:04, 55.25it/s, Epoch: 18, Batch: 85,Loss: -2.536,Avg.Loss: -2.631,LR: 2.30E-05]Training epoch 18:  25%|██▍       | 85/341 [00:01<00:04, 55.25it/s, Epoch: 18, Batch: 86,Loss: -2.633,Avg.Loss: -2.631,LR: 2.29E-05]Training epoch 18:  25%|██▌       | 86/341 [00:01<00:04, 55.25it/s, Epoch: 18, Batch: 87,Loss: -2.340,Avg.Loss: -2.628,LR: 2.29E-05]Training epoch 18:  26%|██▌       | 87/341 [00:01<00:04, 55.25it/s, Epoch: 18, Batch: 88,Loss: -2.475,Avg.Loss: -2.626,LR: 2.28E-05]Training epoch 18:  26%|██▌       | 88/341 [00:01<00:04, 55.25it/s, Epoch: 18, Batch: 89,Loss: -2.708,Avg.Loss: -2.627,LR: 2.28E-05]Training epoch 18:  26%|██▌       | 89/341 [00:01<00:04, 55.25it/s, Epoch: 18, Batch: 90,Loss: -2.818,Avg.Loss: -2.629,LR: 2.27E-05]Training epoch 18:  26%|██▋       | 90/341 [00:01<00:04, 54.76it/s, Epoch: 18, Batch: 90,Loss: -2.818,Avg.Loss: -2.629,LR: 2.27E-05]Training epoch 18:  26%|██▋       | 90/341 [00:01<00:04, 54.76it/s, Epoch: 18, Batch: 91,Loss: -2.667,Avg.Loss: -2.630,LR: 2.27E-05]Training epoch 18:  27%|██▋       | 91/341 [00:01<00:04, 54.76it/s, Epoch: 18, Batch: 92,Loss: -2.265,Avg.Loss: -2.626,LR: 2.26E-05]Training epoch 18:  27%|██▋       | 92/341 [00:01<00:04, 54.76it/s, Epoch: 18, Batch: 93,Loss: -2.399,Avg.Loss: -2.623,LR: 2.26E-05]Training epoch 18:  27%|██▋       | 93/341 [00:01<00:04, 54.76it/s, Epoch: 18, Batch: 94,Loss: -2.576,Avg.Loss: -2.623,LR: 2.25E-05]Training epoch 18:  28%|██▊       | 94/341 [00:01<00:04, 54.76it/s, Epoch: 18, Batch: 95,Loss: -2.443,Avg.Loss: -2.621,LR: 2.25E-05]Training epoch 18:  28%|██▊       | 95/341 [00:01<00:04, 54.76it/s, Epoch: 18, Batch: 96,Loss: -2.789,Avg.Loss: -2.623,LR: 2.24E-05]Training epoch 18:  28%|██▊       | 96/341 [00:01<00:04, 54.10it/s, Epoch: 18, Batch: 96,Loss: -2.789,Avg.Loss: -2.623,LR: 2.24E-05]Training epoch 18:  28%|██▊       | 96/341 [00:01<00:04, 54.10it/s, Epoch: 18, Batch: 97,Loss: -2.267,Avg.Loss: -2.619,LR: 2.24E-05]Training epoch 18:  28%|██▊       | 97/341 [00:01<00:04, 54.10it/s, Epoch: 18, Batch: 98,Loss: -2.498,Avg.Loss: -2.618,LR: 2.24E-05]Training epoch 18:  29%|██▊       | 98/341 [00:01<00:04, 54.10it/s, Epoch: 18, Batch: 99,Loss: -2.496,Avg.Loss: -2.617,LR: 2.23E-05]Training epoch 18:  29%|██▉       | 99/341 [00:01<00:04, 54.10it/s, Epoch: 18, Batch: 100,Loss: -2.929,Avg.Loss: -2.620,LR: 2.23E-05]Training epoch 18:  29%|██▉       | 100/341 [00:01<00:04, 54.10it/s, Epoch: 18, Batch: 101,Loss: -2.929,Avg.Loss: -2.623,LR: 2.22E-05]Training epoch 18:  30%|██▉       | 101/341 [00:01<00:04, 54.10it/s, Epoch: 18, Batch: 102,Loss: -2.278,Avg.Loss: -2.619,LR: 2.22E-05]Training epoch 18:  30%|██▉       | 102/341 [00:01<00:04, 53.81it/s, Epoch: 18, Batch: 102,Loss: -2.278,Avg.Loss: -2.619,LR: 2.22E-05]Training epoch 18:  30%|██▉       | 102/341 [00:01<00:04, 53.81it/s, Epoch: 18, Batch: 103,Loss: -2.578,Avg.Loss: -2.619,LR: 2.21E-05]Training epoch 18:  30%|███       | 103/341 [00:01<00:04, 53.81it/s, Epoch: 18, Batch: 104,Loss: -2.653,Avg.Loss: -2.619,LR: 2.21E-05]Training epoch 18:  30%|███       | 104/341 [00:01<00:04, 53.81it/s, Epoch: 18, Batch: 105,Loss: -2.591,Avg.Loss: -2.619,LR: 2.20E-05]Training epoch 18:  31%|███       | 105/341 [00:01<00:04, 53.81it/s, Epoch: 18, Batch: 106,Loss: -2.631,Avg.Loss: -2.619,LR: 2.20E-05]Training epoch 18:  31%|███       | 106/341 [00:01<00:04, 53.81it/s, Epoch: 18, Batch: 107,Loss: -2.790,Avg.Loss: -2.621,LR: 2.19E-05]Training epoch 18:  31%|███▏      | 107/341 [00:02<00:04, 53.81it/s, Epoch: 18, Batch: 108,Loss: -1.975,Avg.Loss: -2.615,LR: 2.19E-05]Training epoch 18:  32%|███▏      | 108/341 [00:02<00:04, 52.88it/s, Epoch: 18, Batch: 108,Loss: -1.975,Avg.Loss: -2.615,LR: 2.19E-05]Training epoch 18:  32%|███▏      | 108/341 [00:02<00:04, 52.88it/s, Epoch: 18, Batch: 109,Loss: -2.617,Avg.Loss: -2.615,LR: 2.18E-05]Training epoch 18:  32%|███▏      | 109/341 [00:02<00:04, 52.88it/s, Epoch: 18, Batch: 110,Loss: -2.529,Avg.Loss: -2.614,LR: 2.18E-05]Training epoch 18:  32%|███▏      | 110/341 [00:02<00:04, 52.88it/s, Epoch: 18, Batch: 111,Loss: -2.680,Avg.Loss: -2.615,LR: 2.17E-05]Training epoch 18:  33%|███▎      | 111/341 [00:02<00:04, 52.88it/s, Epoch: 18, Batch: 112,Loss: -2.849,Avg.Loss: -2.617,LR: 2.17E-05]Training epoch 18:  33%|███▎      | 112/341 [00:02<00:04, 52.88it/s, Epoch: 18, Batch: 113,Loss: -2.901,Avg.Loss: -2.619,LR: 2.16E-05]Training epoch 18:  33%|███▎      | 113/341 [00:02<00:04, 52.88it/s, Epoch: 18, Batch: 114,Loss: -2.663,Avg.Loss: -2.620,LR: 2.16E-05]Training epoch 18:  33%|███▎      | 114/341 [00:02<00:04, 52.33it/s, Epoch: 18, Batch: 114,Loss: -2.663,Avg.Loss: -2.620,LR: 2.16E-05]Training epoch 18:  33%|███▎      | 114/341 [00:02<00:04, 52.33it/s, Epoch: 18, Batch: 115,Loss: -2.818,Avg.Loss: -2.621,LR: 2.16E-05]Training epoch 18:  34%|███▎      | 115/341 [00:02<00:04, 52.33it/s, Epoch: 18, Batch: 116,Loss: -2.589,Avg.Loss: -2.621,LR: 2.15E-05]Training epoch 18:  34%|███▍      | 116/341 [00:02<00:04, 52.33it/s, Epoch: 18, Batch: 117,Loss: -2.861,Avg.Loss: -2.623,LR: 2.15E-05]Training epoch 18:  34%|███▍      | 117/341 [00:02<00:04, 52.33it/s, Epoch: 18, Batch: 118,Loss: -2.535,Avg.Loss: -2.622,LR: 2.14E-05]Training epoch 18:  35%|███▍      | 118/341 [00:02<00:04, 52.33it/s, Epoch: 18, Batch: 119,Loss: -2.881,Avg.Loss: -2.625,LR: 2.14E-05]Training epoch 18:  35%|███▍      | 119/341 [00:02<00:04, 52.33it/s, Epoch: 18, Batch: 120,Loss: -2.363,Avg.Loss: -2.622,LR: 2.13E-05]Training epoch 18:  35%|███▌      | 120/341 [00:02<00:04, 51.74it/s, Epoch: 18, Batch: 120,Loss: -2.363,Avg.Loss: -2.622,LR: 2.13E-05]Training epoch 18:  35%|███▌      | 120/341 [00:02<00:04, 51.74it/s, Epoch: 18, Batch: 121,Loss: -2.591,Avg.Loss: -2.622,LR: 2.13E-05]Training epoch 18:  35%|███▌      | 121/341 [00:02<00:04, 51.74it/s, Epoch: 18, Batch: 122,Loss: -2.442,Avg.Loss: -2.621,LR: 2.12E-05]Training epoch 18:  36%|███▌      | 122/341 [00:02<00:04, 51.74it/s, Epoch: 18, Batch: 123,Loss: -2.444,Avg.Loss: -2.619,LR: 2.12E-05]Training epoch 18:  36%|███▌      | 123/341 [00:02<00:04, 51.74it/s, Epoch: 18, Batch: 124,Loss: -2.666,Avg.Loss: -2.620,LR: 2.11E-05]Training epoch 18:  36%|███▋      | 124/341 [00:02<00:04, 51.74it/s, Epoch: 18, Batch: 125,Loss: -2.834,Avg.Loss: -2.621,LR: 2.11E-05]Training epoch 18:  37%|███▋      | 125/341 [00:02<00:04, 51.74it/s, Epoch: 18, Batch: 126,Loss: -2.267,Avg.Loss: -2.618,LR: 2.10E-05]Training epoch 18:  37%|███▋      | 126/341 [00:02<00:04, 51.89it/s, Epoch: 18, Batch: 126,Loss: -2.267,Avg.Loss: -2.618,LR: 2.10E-05]Training epoch 18:  37%|███▋      | 126/341 [00:02<00:04, 51.89it/s, Epoch: 18, Batch: 127,Loss: -2.518,Avg.Loss: -2.618,LR: 2.10E-05]Training epoch 18:  37%|███▋      | 127/341 [00:02<00:04, 51.89it/s, Epoch: 18, Batch: 128,Loss: -2.817,Avg.Loss: -2.619,LR: 2.09E-05]Training epoch 18:  38%|███▊      | 128/341 [00:02<00:04, 51.89it/s, Epoch: 18, Batch: 129,Loss: -2.583,Avg.Loss: -2.619,LR: 2.09E-05]Training epoch 18:  38%|███▊      | 129/341 [00:02<00:04, 51.89it/s, Epoch: 18, Batch: 130,Loss: -2.628,Avg.Loss: -2.619,LR: 2.09E-05]Training epoch 18:  38%|███▊      | 130/341 [00:02<00:04, 51.89it/s, Epoch: 18, Batch: 131,Loss: -2.663,Avg.Loss: -2.619,LR: 2.08E-05]Training epoch 18:  38%|███▊      | 131/341 [00:02<00:04, 51.89it/s, Epoch: 18, Batch: 132,Loss: -2.512,Avg.Loss: -2.619,LR: 2.08E-05]Training epoch 18:  39%|███▊      | 132/341 [00:02<00:04, 51.90it/s, Epoch: 18, Batch: 132,Loss: -2.512,Avg.Loss: -2.619,LR: 2.08E-05]Training epoch 18:  39%|███▊      | 132/341 [00:02<00:04, 51.90it/s, Epoch: 18, Batch: 133,Loss: -3.017,Avg.Loss: -2.622,LR: 2.07E-05]Training epoch 18:  39%|███▉      | 133/341 [00:02<00:04, 51.90it/s, Epoch: 18, Batch: 134,Loss: -2.808,Avg.Loss: -2.623,LR: 2.07E-05]Training epoch 18:  39%|███▉      | 134/341 [00:02<00:03, 51.90it/s, Epoch: 18, Batch: 135,Loss: -2.792,Avg.Loss: -2.624,LR: 2.06E-05]Training epoch 18:  40%|███▉      | 135/341 [00:02<00:03, 51.90it/s, Epoch: 18, Batch: 136,Loss: -2.939,Avg.Loss: -2.626,LR: 2.06E-05]Training epoch 18:  40%|███▉      | 136/341 [00:02<00:03, 51.90it/s, Epoch: 18, Batch: 137,Loss: -2.364,Avg.Loss: -2.625,LR: 2.05E-05]Training epoch 18:  40%|████      | 137/341 [00:02<00:03, 51.90it/s, Epoch: 18, Batch: 138,Loss: -2.925,Avg.Loss: -2.627,LR: 2.05E-05]Training epoch 18:  40%|████      | 138/341 [00:02<00:03, 52.10it/s, Epoch: 18, Batch: 138,Loss: -2.925,Avg.Loss: -2.627,LR: 2.05E-05]Training epoch 18:  40%|████      | 138/341 [00:02<00:03, 52.10it/s, Epoch: 18, Batch: 139,Loss: -2.676,Avg.Loss: -2.627,LR: 2.04E-05]Training epoch 18:  41%|████      | 139/341 [00:02<00:03, 52.10it/s, Epoch: 18, Batch: 140,Loss: -2.560,Avg.Loss: -2.627,LR: 2.04E-05]Training epoch 18:  41%|████      | 140/341 [00:02<00:03, 52.10it/s, Epoch: 18, Batch: 141,Loss: -2.961,Avg.Loss: -2.629,LR: 2.04E-05]Training epoch 18:  41%|████▏     | 141/341 [00:02<00:03, 52.10it/s, Epoch: 18, Batch: 142,Loss: -2.823,Avg.Loss: -2.630,LR: 2.03E-05]Training epoch 18:  42%|████▏     | 142/341 [00:02<00:03, 52.10it/s, Epoch: 18, Batch: 143,Loss: -2.257,Avg.Loss: -2.628,LR: 2.03E-05]Training epoch 18:  42%|████▏     | 143/341 [00:02<00:03, 52.10it/s, Epoch: 18, Batch: 144,Loss: -2.674,Avg.Loss: -2.628,LR: 2.02E-05]Training epoch 18:  42%|████▏     | 144/341 [00:02<00:03, 52.50it/s, Epoch: 18, Batch: 144,Loss: -2.674,Avg.Loss: -2.628,LR: 2.02E-05]Training epoch 18:  42%|████▏     | 144/341 [00:02<00:03, 52.50it/s, Epoch: 18, Batch: 145,Loss: -2.494,Avg.Loss: -2.627,LR: 2.02E-05]Training epoch 18:  43%|████▎     | 145/341 [00:02<00:03, 52.50it/s, Epoch: 18, Batch: 146,Loss: -2.378,Avg.Loss: -2.625,LR: 2.01E-05]Training epoch 18:  43%|████▎     | 146/341 [00:02<00:03, 52.50it/s, Epoch: 18, Batch: 147,Loss: -3.000,Avg.Loss: -2.628,LR: 2.01E-05]Training epoch 18:  43%|████▎     | 147/341 [00:02<00:03, 52.50it/s, Epoch: 18, Batch: 148,Loss: -2.640,Avg.Loss: -2.628,LR: 2.00E-05]Training epoch 18:  43%|████▎     | 148/341 [00:02<00:03, 52.50it/s, Epoch: 18, Batch: 149,Loss: -2.844,Avg.Loss: -2.629,LR: 2.00E-05]Training epoch 18:  44%|████▎     | 149/341 [00:02<00:03, 52.50it/s, Epoch: 18, Batch: 150,Loss: -2.884,Avg.Loss: -2.631,LR: 1.99E-05]Training epoch 18:  44%|████▍     | 150/341 [00:02<00:03, 52.62it/s, Epoch: 18, Batch: 150,Loss: -2.884,Avg.Loss: -2.631,LR: 1.99E-05]Training epoch 18:  44%|████▍     | 150/341 [00:02<00:03, 52.62it/s, Epoch: 18, Batch: 151,Loss: -2.609,Avg.Loss: -2.631,LR: 1.99E-05]Training epoch 18:  44%|████▍     | 151/341 [00:02<00:03, 52.62it/s, Epoch: 18, Batch: 152,Loss: -2.536,Avg.Loss: -2.630,LR: 1.99E-05]Training epoch 18:  45%|████▍     | 152/341 [00:02<00:03, 52.62it/s, Epoch: 18, Batch: 153,Loss: -3.033,Avg.Loss: -2.633,LR: 1.98E-05]Training epoch 18:  45%|████▍     | 153/341 [00:02<00:03, 52.62it/s, Epoch: 18, Batch: 154,Loss: -2.626,Avg.Loss: -2.633,LR: 1.98E-05]Training epoch 18:  45%|████▌     | 154/341 [00:02<00:03, 52.62it/s, Epoch: 18, Batch: 155,Loss: -2.597,Avg.Loss: -2.633,LR: 1.97E-05]Training epoch 18:  45%|████▌     | 155/341 [00:02<00:03, 52.62it/s, Epoch: 18, Batch: 156,Loss: -2.662,Avg.Loss: -2.633,LR: 1.97E-05]Training epoch 18:  46%|████▌     | 156/341 [00:02<00:03, 52.52it/s, Epoch: 18, Batch: 156,Loss: -2.662,Avg.Loss: -2.633,LR: 1.97E-05]Training epoch 18:  46%|████▌     | 156/341 [00:02<00:03, 52.52it/s, Epoch: 18, Batch: 157,Loss: -2.102,Avg.Loss: -2.630,LR: 1.96E-05]Training epoch 18:  46%|████▌     | 157/341 [00:02<00:03, 52.52it/s, Epoch: 18, Batch: 158,Loss: -2.843,Avg.Loss: -2.631,LR: 1.96E-05]Training epoch 18:  46%|████▋     | 158/341 [00:02<00:03, 52.52it/s, Epoch: 18, Batch: 159,Loss: -3.057,Avg.Loss: -2.634,LR: 1.95E-05]Training epoch 18:  47%|████▋     | 159/341 [00:03<00:03, 52.52it/s, Epoch: 18, Batch: 160,Loss: -2.774,Avg.Loss: -2.634,LR: 1.95E-05]Training epoch 18:  47%|████▋     | 160/341 [00:03<00:03, 52.52it/s, Epoch: 18, Batch: 161,Loss: -2.853,Avg.Loss: -2.636,LR: 1.95E-05]Training epoch 18:  47%|████▋     | 161/341 [00:03<00:03, 52.52it/s, Epoch: 18, Batch: 162,Loss: -2.909,Avg.Loss: -2.638,LR: 1.94E-05]Training epoch 18:  48%|████▊     | 162/341 [00:03<00:03, 53.14it/s, Epoch: 18, Batch: 162,Loss: -2.909,Avg.Loss: -2.638,LR: 1.94E-05]Training epoch 18:  48%|████▊     | 162/341 [00:03<00:03, 53.14it/s, Epoch: 18, Batch: 163,Loss: -2.149,Avg.Loss: -2.635,LR: 1.94E-05]Training epoch 18:  48%|████▊     | 163/341 [00:03<00:03, 53.14it/s, Epoch: 18, Batch: 164,Loss: -2.699,Avg.Loss: -2.635,LR: 1.93E-05]Training epoch 18:  48%|████▊     | 164/341 [00:03<00:03, 53.14it/s, Epoch: 18, Batch: 165,Loss: -2.646,Avg.Loss: -2.635,LR: 1.93E-05]Training epoch 18:  48%|████▊     | 165/341 [00:03<00:03, 53.14it/s, Epoch: 18, Batch: 166,Loss: -2.556,Avg.Loss: -2.635,LR: 1.92E-05]Training epoch 18:  49%|████▊     | 166/341 [00:03<00:03, 53.14it/s, Epoch: 18, Batch: 167,Loss: -2.633,Avg.Loss: -2.634,LR: 1.92E-05]Training epoch 18:  49%|████▉     | 167/341 [00:03<00:03, 53.14it/s, Epoch: 18, Batch: 168,Loss: -2.037,Avg.Loss: -2.631,LR: 1.91E-05]Training epoch 18:  49%|████▉     | 168/341 [00:03<00:03, 53.39it/s, Epoch: 18, Batch: 168,Loss: -2.037,Avg.Loss: -2.631,LR: 1.91E-05]Training epoch 18:  49%|████▉     | 168/341 [00:03<00:03, 53.39it/s, Epoch: 18, Batch: 169,Loss: -2.806,Avg.Loss: -2.632,LR: 1.91E-05]Training epoch 18:  50%|████▉     | 169/341 [00:03<00:03, 53.39it/s, Epoch: 18, Batch: 170,Loss: -1.999,Avg.Loss: -2.628,LR: 1.91E-05]Training epoch 18:  50%|████▉     | 170/341 [00:03<00:03, 53.39it/s, Epoch: 18, Batch: 171,Loss: -2.865,Avg.Loss: -2.630,LR: 1.90E-05]Training epoch 18:  50%|█████     | 171/341 [00:03<00:03, 53.39it/s, Epoch: 18, Batch: 172,Loss: -2.630,Avg.Loss: -2.630,LR: 1.90E-05]Training epoch 18:  50%|█████     | 172/341 [00:03<00:03, 53.39it/s, Epoch: 18, Batch: 173,Loss: -2.889,Avg.Loss: -2.631,LR: 1.89E-05]Training epoch 18:  51%|█████     | 173/341 [00:03<00:03, 53.39it/s, Epoch: 18, Batch: 174,Loss: -2.641,Avg.Loss: -2.631,LR: 1.89E-05]Training epoch 18:  51%|█████     | 174/341 [00:03<00:03, 53.20it/s, Epoch: 18, Batch: 174,Loss: -2.641,Avg.Loss: -2.631,LR: 1.89E-05]Training epoch 18:  51%|█████     | 174/341 [00:03<00:03, 53.20it/s, Epoch: 18, Batch: 175,Loss: -2.476,Avg.Loss: -2.630,LR: 1.88E-05]Training epoch 18:  51%|█████▏    | 175/341 [00:03<00:03, 53.20it/s, Epoch: 18, Batch: 176,Loss: -2.735,Avg.Loss: -2.631,LR: 1.88E-05]Training epoch 18:  52%|█████▏    | 176/341 [00:03<00:03, 53.20it/s, Epoch: 18, Batch: 177,Loss: -2.852,Avg.Loss: -2.632,LR: 1.87E-05]Training epoch 18:  52%|█████▏    | 177/341 [00:03<00:03, 53.20it/s, Epoch: 18, Batch: 178,Loss: -2.384,Avg.Loss: -2.631,LR: 1.87E-05]Training epoch 18:  52%|█████▏    | 178/341 [00:03<00:03, 53.20it/s, Epoch: 18, Batch: 179,Loss: -2.286,Avg.Loss: -2.629,LR: 1.87E-05]Training epoch 18:  52%|█████▏    | 179/341 [00:03<00:03, 53.20it/s, Epoch: 18, Batch: 180,Loss: -2.728,Avg.Loss: -2.629,LR: 1.86E-05]Training epoch 18:  53%|█████▎    | 180/341 [00:03<00:03, 52.92it/s, Epoch: 18, Batch: 180,Loss: -2.728,Avg.Loss: -2.629,LR: 1.86E-05]Training epoch 18:  53%|█████▎    | 180/341 [00:03<00:03, 52.92it/s, Epoch: 18, Batch: 181,Loss: -2.441,Avg.Loss: -2.628,LR: 1.86E-05]Training epoch 18:  53%|█████▎    | 181/341 [00:03<00:03, 52.92it/s, Epoch: 18, Batch: 182,Loss: -2.751,Avg.Loss: -2.629,LR: 1.85E-05]Training epoch 18:  53%|█████▎    | 182/341 [00:03<00:03, 52.92it/s, Epoch: 18, Batch: 183,Loss: -2.736,Avg.Loss: -2.630,LR: 1.85E-05]Training epoch 18:  54%|█████▎    | 183/341 [00:03<00:02, 52.92it/s, Epoch: 18, Batch: 184,Loss: -2.871,Avg.Loss: -2.631,LR: 1.84E-05]Training epoch 18:  54%|█████▍    | 184/341 [00:03<00:02, 52.92it/s, Epoch: 18, Batch: 185,Loss: -2.522,Avg.Loss: -2.630,LR: 1.84E-05]Training epoch 18:  54%|█████▍    | 185/341 [00:03<00:02, 52.92it/s, Epoch: 18, Batch: 186,Loss: -2.652,Avg.Loss: -2.630,LR: 1.84E-05]Training epoch 18:  55%|█████▍    | 186/341 [00:03<00:02, 53.14it/s, Epoch: 18, Batch: 186,Loss: -2.652,Avg.Loss: -2.630,LR: 1.84E-05]Training epoch 18:  55%|█████▍    | 186/341 [00:03<00:02, 53.14it/s, Epoch: 18, Batch: 187,Loss: -2.796,Avg.Loss: -2.631,LR: 1.83E-05]Training epoch 18:  55%|█████▍    | 187/341 [00:03<00:02, 53.14it/s, Epoch: 18, Batch: 188,Loss: -2.430,Avg.Loss: -2.630,LR: 1.83E-05]Training epoch 18:  55%|█████▌    | 188/341 [00:03<00:02, 53.14it/s, Epoch: 18, Batch: 189,Loss: -2.396,Avg.Loss: -2.629,LR: 1.82E-05]Training epoch 18:  55%|█████▌    | 189/341 [00:03<00:02, 53.14it/s, Epoch: 18, Batch: 190,Loss: -2.544,Avg.Loss: -2.629,LR: 1.82E-05]Training epoch 18:  56%|█████▌    | 190/341 [00:03<00:02, 53.14it/s, Epoch: 18, Batch: 191,Loss: -2.804,Avg.Loss: -2.629,LR: 1.81E-05]Training epoch 18:  56%|█████▌    | 191/341 [00:03<00:02, 53.14it/s, Epoch: 18, Batch: 192,Loss: -2.932,Avg.Loss: -2.631,LR: 1.81E-05]Training epoch 18:  56%|█████▋    | 192/341 [00:03<00:02, 53.27it/s, Epoch: 18, Batch: 192,Loss: -2.932,Avg.Loss: -2.631,LR: 1.81E-05]Training epoch 18:  56%|█████▋    | 192/341 [00:03<00:02, 53.27it/s, Epoch: 18, Batch: 193,Loss: -2.540,Avg.Loss: -2.631,LR: 1.81E-05]Training epoch 18:  57%|█████▋    | 193/341 [00:03<00:02, 53.27it/s, Epoch: 18, Batch: 194,Loss: -2.775,Avg.Loss: -2.631,LR: 1.80E-05]Training epoch 18:  57%|█████▋    | 194/341 [00:03<00:02, 53.27it/s, Epoch: 18, Batch: 195,Loss: -2.848,Avg.Loss: -2.632,LR: 1.80E-05]Training epoch 18:  57%|█████▋    | 195/341 [00:03<00:02, 53.27it/s, Epoch: 18, Batch: 196,Loss: -2.269,Avg.Loss: -2.631,LR: 1.79E-05]Training epoch 18:  57%|█████▋    | 196/341 [00:03<00:02, 53.27it/s, Epoch: 18, Batch: 197,Loss: -2.137,Avg.Loss: -2.628,LR: 1.79E-05]Training epoch 18:  58%|█████▊    | 197/341 [00:03<00:02, 53.27it/s, Epoch: 18, Batch: 198,Loss: -2.545,Avg.Loss: -2.628,LR: 1.78E-05]Training epoch 18:  58%|█████▊    | 198/341 [00:03<00:02, 53.05it/s, Epoch: 18, Batch: 198,Loss: -2.545,Avg.Loss: -2.628,LR: 1.78E-05]Training epoch 18:  58%|█████▊    | 198/341 [00:03<00:02, 53.05it/s, Epoch: 18, Batch: 199,Loss: -2.591,Avg.Loss: -2.627,LR: 1.78E-05]Training epoch 18:  58%|█████▊    | 199/341 [00:03<00:02, 53.05it/s, Epoch: 18, Batch: 200,Loss: -2.583,Avg.Loss: -2.627,LR: 1.78E-05]Training epoch 18:  59%|█████▊    | 200/341 [00:03<00:02, 53.05it/s, Epoch: 18, Batch: 201,Loss: -3.007,Avg.Loss: -2.629,LR: 1.77E-05]Training epoch 18:  59%|█████▉    | 201/341 [00:03<00:02, 53.05it/s, Epoch: 18, Batch: 202,Loss: -2.504,Avg.Loss: -2.629,LR: 1.77E-05]Training epoch 18:  59%|█████▉    | 202/341 [00:03<00:02, 53.05it/s, Epoch: 18, Batch: 203,Loss: -2.523,Avg.Loss: -2.628,LR: 1.76E-05]Training epoch 18:  60%|█████▉    | 203/341 [00:03<00:02, 53.05it/s, Epoch: 18, Batch: 204,Loss: -2.625,Avg.Loss: -2.628,LR: 1.76E-05]Training epoch 18:  60%|█████▉    | 204/341 [00:03<00:02, 53.17it/s, Epoch: 18, Batch: 204,Loss: -2.625,Avg.Loss: -2.628,LR: 1.76E-05]Training epoch 18:  60%|█████▉    | 204/341 [00:03<00:02, 53.17it/s, Epoch: 18, Batch: 205,Loss: -2.849,Avg.Loss: -2.629,LR: 1.75E-05]Training epoch 18:  60%|██████    | 205/341 [00:03<00:02, 53.17it/s, Epoch: 18, Batch: 206,Loss: -2.522,Avg.Loss: -2.629,LR: 1.75E-05]Training epoch 18:  60%|██████    | 206/341 [00:03<00:02, 53.17it/s, Epoch: 18, Batch: 207,Loss: -2.536,Avg.Loss: -2.628,LR: 1.75E-05]Training epoch 18:  61%|██████    | 207/341 [00:03<00:02, 53.17it/s, Epoch: 18, Batch: 208,Loss: -2.727,Avg.Loss: -2.629,LR: 1.74E-05]Training epoch 18:  61%|██████    | 208/341 [00:03<00:02, 53.17it/s, Epoch: 18, Batch: 209,Loss: -3.108,Avg.Loss: -2.631,LR: 1.74E-05]Training epoch 18:  61%|██████▏   | 209/341 [00:03<00:02, 53.17it/s, Epoch: 18, Batch: 210,Loss: -2.601,Avg.Loss: -2.631,LR: 1.73E-05]Training epoch 18:  62%|██████▏   | 210/341 [00:03<00:02, 53.43it/s, Epoch: 18, Batch: 210,Loss: -2.601,Avg.Loss: -2.631,LR: 1.73E-05]Training epoch 18:  62%|██████▏   | 210/341 [00:03<00:02, 53.43it/s, Epoch: 18, Batch: 211,Loss: -2.517,Avg.Loss: -2.630,LR: 1.73E-05]Training epoch 18:  62%|██████▏   | 211/341 [00:03<00:02, 53.43it/s, Epoch: 18, Batch: 212,Loss: -2.741,Avg.Loss: -2.631,LR: 1.72E-05]Training epoch 18:  62%|██████▏   | 212/341 [00:03<00:02, 53.43it/s, Epoch: 18, Batch: 213,Loss: -2.826,Avg.Loss: -2.632,LR: 1.72E-05]Training epoch 18:  62%|██████▏   | 213/341 [00:04<00:02, 53.43it/s, Epoch: 18, Batch: 214,Loss: -2.470,Avg.Loss: -2.631,LR: 1.72E-05]Training epoch 18:  63%|██████▎   | 214/341 [00:04<00:02, 53.43it/s, Epoch: 18, Batch: 215,Loss: -2.398,Avg.Loss: -2.630,LR: 1.71E-05]Training epoch 18:  63%|██████▎   | 215/341 [00:04<00:02, 53.43it/s, Epoch: 18, Batch: 216,Loss: -2.621,Avg.Loss: -2.630,LR: 1.71E-05]Training epoch 18:  63%|██████▎   | 216/341 [00:04<00:02, 52.01it/s, Epoch: 18, Batch: 216,Loss: -2.621,Avg.Loss: -2.630,LR: 1.71E-05]Training epoch 18:  63%|██████▎   | 216/341 [00:04<00:02, 52.01it/s, Epoch: 18, Batch: 217,Loss: -2.673,Avg.Loss: -2.630,LR: 1.70E-05]Training epoch 18:  64%|██████▎   | 217/341 [00:04<00:02, 52.01it/s, Epoch: 18, Batch: 218,Loss: -1.993,Avg.Loss: -2.627,LR: 1.70E-05]Training epoch 18:  64%|██████▍   | 218/341 [00:04<00:02, 52.01it/s, Epoch: 18, Batch: 219,Loss: -2.896,Avg.Loss: -2.628,LR: 1.70E-05]Training epoch 18:  64%|██████▍   | 219/341 [00:04<00:02, 52.01it/s, Epoch: 18, Batch: 220,Loss: -2.731,Avg.Loss: -2.629,LR: 1.69E-05]Training epoch 18:  65%|██████▍   | 220/341 [00:04<00:02, 52.01it/s, Epoch: 18, Batch: 221,Loss: -2.855,Avg.Loss: -2.630,LR: 1.69E-05]Training epoch 18:  65%|██████▍   | 221/341 [00:04<00:02, 52.01it/s, Epoch: 18, Batch: 222,Loss: -2.482,Avg.Loss: -2.629,LR: 1.68E-05]Training epoch 18:  65%|██████▌   | 222/341 [00:04<00:02, 50.61it/s, Epoch: 18, Batch: 222,Loss: -2.482,Avg.Loss: -2.629,LR: 1.68E-05]Training epoch 18:  65%|██████▌   | 222/341 [00:04<00:02, 50.61it/s, Epoch: 18, Batch: 223,Loss: -2.719,Avg.Loss: -2.629,LR: 1.68E-05]Training epoch 18:  65%|██████▌   | 223/341 [00:04<00:02, 50.61it/s, Epoch: 18, Batch: 224,Loss: -2.744,Avg.Loss: -2.630,LR: 1.67E-05]Training epoch 18:  66%|██████▌   | 224/341 [00:04<00:02, 50.61it/s, Epoch: 18, Batch: 225,Loss: -2.958,Avg.Loss: -2.631,LR: 1.67E-05]Training epoch 18:  66%|██████▌   | 225/341 [00:04<00:02, 50.61it/s, Epoch: 18, Batch: 226,Loss: -2.227,Avg.Loss: -2.630,LR: 1.67E-05]Training epoch 18:  66%|██████▋   | 226/341 [00:04<00:02, 50.61it/s, Epoch: 18, Batch: 227,Loss: -2.539,Avg.Loss: -2.629,LR: 1.66E-05]Training epoch 18:  67%|██████▋   | 227/341 [00:04<00:02, 50.61it/s, Epoch: 18, Batch: 228,Loss: -2.788,Avg.Loss: -2.630,LR: 1.66E-05]Training epoch 18:  67%|██████▋   | 228/341 [00:04<00:02, 49.92it/s, Epoch: 18, Batch: 228,Loss: -2.788,Avg.Loss: -2.630,LR: 1.66E-05]Training epoch 18:  67%|██████▋   | 228/341 [00:04<00:02, 49.92it/s, Epoch: 18, Batch: 229,Loss: -2.906,Avg.Loss: -2.631,LR: 1.65E-05]Training epoch 18:  67%|██████▋   | 229/341 [00:04<00:02, 49.92it/s, Epoch: 18, Batch: 230,Loss: -2.680,Avg.Loss: -2.631,LR: 1.65E-05]Training epoch 18:  67%|██████▋   | 230/341 [00:04<00:02, 49.92it/s, Epoch: 18, Batch: 231,Loss: -2.673,Avg.Loss: -2.632,LR: 1.65E-05]Training epoch 18:  68%|██████▊   | 231/341 [00:04<00:02, 49.92it/s, Epoch: 18, Batch: 232,Loss: -2.622,Avg.Loss: -2.632,LR: 1.64E-05]Training epoch 18:  68%|██████▊   | 232/341 [00:04<00:02, 49.92it/s, Epoch: 18, Batch: 233,Loss: -2.443,Avg.Loss: -2.631,LR: 1.64E-05]Training epoch 18:  68%|██████▊   | 233/341 [00:04<00:02, 49.92it/s, Epoch: 18, Batch: 234,Loss: -2.802,Avg.Loss: -2.631,LR: 1.63E-05]Training epoch 18:  69%|██████▊   | 234/341 [00:04<00:02, 49.83it/s, Epoch: 18, Batch: 234,Loss: -2.802,Avg.Loss: -2.631,LR: 1.63E-05]Training epoch 18:  69%|██████▊   | 234/341 [00:04<00:02, 49.83it/s, Epoch: 18, Batch: 235,Loss: -2.931,Avg.Loss: -2.633,LR: 1.63E-05]Training epoch 18:  69%|██████▉   | 235/341 [00:04<00:02, 49.83it/s, Epoch: 18, Batch: 236,Loss: -2.698,Avg.Loss: -2.633,LR: 1.62E-05]Training epoch 18:  69%|██████▉   | 236/341 [00:04<00:02, 49.83it/s, Epoch: 18, Batch: 237,Loss: -2.436,Avg.Loss: -2.632,LR: 1.62E-05]Training epoch 18:  70%|██████▉   | 237/341 [00:04<00:02, 49.83it/s, Epoch: 18, Batch: 238,Loss: -2.448,Avg.Loss: -2.631,LR: 1.62E-05]Training epoch 18:  70%|██████▉   | 238/341 [00:04<00:02, 49.83it/s, Epoch: 18, Batch: 239,Loss: -2.569,Avg.Loss: -2.631,LR: 1.61E-05]Training epoch 18:  70%|███████   | 239/341 [00:04<00:02, 49.83it/s, Epoch: 18, Batch: 240,Loss: -2.769,Avg.Loss: -2.632,LR: 1.61E-05]Training epoch 18:  70%|███████   | 240/341 [00:04<00:01, 50.80it/s, Epoch: 18, Batch: 240,Loss: -2.769,Avg.Loss: -2.632,LR: 1.61E-05]Training epoch 18:  70%|███████   | 240/341 [00:04<00:01, 50.80it/s, Epoch: 18, Batch: 241,Loss: -2.584,Avg.Loss: -2.632,LR: 1.60E-05]Training epoch 18:  71%|███████   | 241/341 [00:04<00:01, 50.80it/s, Epoch: 18, Batch: 242,Loss: -2.196,Avg.Loss: -2.630,LR: 1.60E-05]Training epoch 18:  71%|███████   | 242/341 [00:04<00:01, 50.80it/s, Epoch: 18, Batch: 243,Loss: -2.536,Avg.Loss: -2.629,LR: 1.60E-05]Training epoch 18:  71%|███████▏  | 243/341 [00:04<00:01, 50.80it/s, Epoch: 18, Batch: 244,Loss: -1.899,Avg.Loss: -2.626,LR: 1.59E-05]Training epoch 18:  72%|███████▏  | 244/341 [00:04<00:01, 50.80it/s, Epoch: 18, Batch: 245,Loss: -2.748,Avg.Loss: -2.627,LR: 1.59E-05]Training epoch 18:  72%|███████▏  | 245/341 [00:04<00:01, 50.80it/s, Epoch: 18, Batch: 246,Loss: -2.788,Avg.Loss: -2.627,LR: 1.58E-05]Training epoch 18:  72%|███████▏  | 246/341 [00:04<00:01, 51.00it/s, Epoch: 18, Batch: 246,Loss: -2.788,Avg.Loss: -2.627,LR: 1.58E-05]Training epoch 18:  72%|███████▏  | 246/341 [00:04<00:01, 51.00it/s, Epoch: 18, Batch: 247,Loss: -2.710,Avg.Loss: -2.628,LR: 1.58E-05]Training epoch 18:  72%|███████▏  | 247/341 [00:04<00:01, 51.00it/s, Epoch: 18, Batch: 248,Loss: -2.625,Avg.Loss: -2.628,LR: 1.58E-05]Training epoch 18:  73%|███████▎  | 248/341 [00:04<00:01, 51.00it/s, Epoch: 18, Batch: 249,Loss: -2.982,Avg.Loss: -2.629,LR: 1.57E-05]Training epoch 18:  73%|███████▎  | 249/341 [00:04<00:01, 51.00it/s, Epoch: 18, Batch: 250,Loss: -2.733,Avg.Loss: -2.630,LR: 1.57E-05]Training epoch 18:  73%|███████▎  | 250/341 [00:04<00:01, 51.00it/s, Epoch: 18, Batch: 251,Loss: -2.661,Avg.Loss: -2.630,LR: 1.56E-05]Training epoch 18:  74%|███████▎  | 251/341 [00:04<00:01, 51.00it/s, Epoch: 18, Batch: 252,Loss: -2.839,Avg.Loss: -2.631,LR: 1.56E-05]Training epoch 18:  74%|███████▍  | 252/341 [00:04<00:01, 51.38it/s, Epoch: 18, Batch: 252,Loss: -2.839,Avg.Loss: -2.631,LR: 1.56E-05]Training epoch 18:  74%|███████▍  | 252/341 [00:04<00:01, 51.38it/s, Epoch: 18, Batch: 253,Loss: -2.686,Avg.Loss: -2.631,LR: 1.56E-05]Training epoch 18:  74%|███████▍  | 253/341 [00:04<00:01, 51.38it/s, Epoch: 18, Batch: 254,Loss: -2.843,Avg.Loss: -2.632,LR: 1.55E-05]Training epoch 18:  74%|███████▍  | 254/341 [00:04<00:01, 51.38it/s, Epoch: 18, Batch: 255,Loss: -2.561,Avg.Loss: -2.631,LR: 1.55E-05]Training epoch 18:  75%|███████▍  | 255/341 [00:04<00:01, 51.38it/s, Epoch: 18, Batch: 256,Loss: -3.067,Avg.Loss: -2.633,LR: 1.54E-05]Training epoch 18:  75%|███████▌  | 256/341 [00:04<00:01, 51.38it/s, Epoch: 18, Batch: 257,Loss: -2.452,Avg.Loss: -2.632,LR: 1.54E-05]Training epoch 18:  75%|███████▌  | 257/341 [00:04<00:01, 51.38it/s, Epoch: 18, Batch: 258,Loss: -2.563,Avg.Loss: -2.632,LR: 1.54E-05]Training epoch 18:  76%|███████▌  | 258/341 [00:04<00:01, 51.74it/s, Epoch: 18, Batch: 258,Loss: -2.563,Avg.Loss: -2.632,LR: 1.54E-05]Training epoch 18:  76%|███████▌  | 258/341 [00:04<00:01, 51.74it/s, Epoch: 18, Batch: 259,Loss: -2.846,Avg.Loss: -2.633,LR: 1.53E-05]Training epoch 18:  76%|███████▌  | 259/341 [00:04<00:01, 51.74it/s, Epoch: 18, Batch: 260,Loss: -2.565,Avg.Loss: -2.633,LR: 1.53E-05]Training epoch 18:  76%|███████▌  | 260/341 [00:04<00:01, 51.74it/s, Epoch: 18, Batch: 261,Loss: -3.025,Avg.Loss: -2.634,LR: 1.52E-05]Training epoch 18:  77%|███████▋  | 261/341 [00:04<00:01, 51.74it/s, Epoch: 18, Batch: 262,Loss: -2.799,Avg.Loss: -2.635,LR: 1.52E-05]Training epoch 18:  77%|███████▋  | 262/341 [00:04<00:01, 51.74it/s, Epoch: 18, Batch: 263,Loss: -2.497,Avg.Loss: -2.634,LR: 1.52E-05]Training epoch 18:  77%|███████▋  | 263/341 [00:05<00:01, 51.74it/s, Epoch: 18, Batch: 264,Loss: -2.704,Avg.Loss: -2.635,LR: 1.51E-05]Training epoch 18:  77%|███████▋  | 264/341 [00:05<00:01, 51.96it/s, Epoch: 18, Batch: 264,Loss: -2.704,Avg.Loss: -2.635,LR: 1.51E-05]Training epoch 18:  77%|███████▋  | 264/341 [00:05<00:01, 51.96it/s, Epoch: 18, Batch: 265,Loss: -2.829,Avg.Loss: -2.635,LR: 1.51E-05]Training epoch 18:  78%|███████▊  | 265/341 [00:05<00:01, 51.96it/s, Epoch: 18, Batch: 266,Loss: -2.934,Avg.Loss: -2.636,LR: 1.50E-05]Training epoch 18:  78%|███████▊  | 266/341 [00:05<00:01, 51.96it/s, Epoch: 18, Batch: 267,Loss: -2.772,Avg.Loss: -2.637,LR: 1.50E-05]Training epoch 18:  78%|███████▊  | 267/341 [00:05<00:01, 51.96it/s, Epoch: 18, Batch: 268,Loss: -2.629,Avg.Loss: -2.637,LR: 1.50E-05]Training epoch 18:  79%|███████▊  | 268/341 [00:05<00:01, 51.96it/s, Epoch: 18, Batch: 269,Loss: -2.294,Avg.Loss: -2.636,LR: 1.49E-05]Training epoch 18:  79%|███████▉  | 269/341 [00:05<00:01, 51.96it/s, Epoch: 18, Batch: 270,Loss: -2.421,Avg.Loss: -2.635,LR: 1.49E-05]Training epoch 18:  79%|███████▉  | 270/341 [00:05<00:01, 52.43it/s, Epoch: 18, Batch: 270,Loss: -2.421,Avg.Loss: -2.635,LR: 1.49E-05]Training epoch 18:  79%|███████▉  | 270/341 [00:05<00:01, 52.43it/s, Epoch: 18, Batch: 271,Loss: -2.338,Avg.Loss: -2.634,LR: 1.49E-05]Training epoch 18:  79%|███████▉  | 271/341 [00:05<00:01, 52.43it/s, Epoch: 18, Batch: 272,Loss: -2.463,Avg.Loss: -2.633,LR: 1.48E-05]Training epoch 18:  80%|███████▉  | 272/341 [00:05<00:01, 52.43it/s, Epoch: 18, Batch: 273,Loss: -2.717,Avg.Loss: -2.633,LR: 1.48E-05]Training epoch 18:  80%|████████  | 273/341 [00:05<00:01, 52.43it/s, Epoch: 18, Batch: 274,Loss: -1.949,Avg.Loss: -2.631,LR: 1.47E-05]Training epoch 18:  80%|████████  | 274/341 [00:05<00:01, 52.43it/s, Epoch: 18, Batch: 275,Loss: -1.930,Avg.Loss: -2.628,LR: 1.47E-05]Training epoch 18:  81%|████████  | 275/341 [00:05<00:01, 52.43it/s, Epoch: 18, Batch: 276,Loss: -2.603,Avg.Loss: -2.628,LR: 1.47E-05]Training epoch 18:  81%|████████  | 276/341 [00:05<00:01, 52.71it/s, Epoch: 18, Batch: 276,Loss: -2.603,Avg.Loss: -2.628,LR: 1.47E-05]Training epoch 18:  81%|████████  | 276/341 [00:05<00:01, 52.71it/s, Epoch: 18, Batch: 277,Loss: -2.676,Avg.Loss: -2.628,LR: 1.46E-05]Training epoch 18:  81%|████████  | 277/341 [00:05<00:01, 52.71it/s, Epoch: 18, Batch: 278,Loss: -2.570,Avg.Loss: -2.628,LR: 1.46E-05]Training epoch 18:  82%|████████▏ | 278/341 [00:05<00:01, 52.71it/s, Epoch: 18, Batch: 279,Loss: -2.935,Avg.Loss: -2.629,LR: 1.45E-05]Training epoch 18:  82%|████████▏ | 279/341 [00:05<00:01, 52.71it/s, Epoch: 18, Batch: 280,Loss: -2.523,Avg.Loss: -2.629,LR: 1.45E-05]Training epoch 18:  82%|████████▏ | 280/341 [00:05<00:01, 52.71it/s, Epoch: 18, Batch: 281,Loss: -2.566,Avg.Loss: -2.629,LR: 1.45E-05]Training epoch 18:  82%|████████▏ | 281/341 [00:05<00:01, 52.71it/s, Epoch: 18, Batch: 282,Loss: -2.395,Avg.Loss: -2.628,LR: 1.44E-05]Training epoch 18:  83%|████████▎ | 282/341 [00:05<00:01, 52.11it/s, Epoch: 18, Batch: 282,Loss: -2.395,Avg.Loss: -2.628,LR: 1.44E-05]Training epoch 18:  83%|████████▎ | 282/341 [00:05<00:01, 52.11it/s, Epoch: 18, Batch: 283,Loss: -2.865,Avg.Loss: -2.629,LR: 1.44E-05]Training epoch 18:  83%|████████▎ | 283/341 [00:05<00:01, 52.11it/s, Epoch: 18, Batch: 284,Loss: -2.547,Avg.Loss: -2.628,LR: 1.43E-05]Training epoch 18:  83%|████████▎ | 284/341 [00:05<00:01, 52.11it/s, Epoch: 18, Batch: 285,Loss: -2.956,Avg.Loss: -2.630,LR: 1.43E-05]Training epoch 18:  84%|████████▎ | 285/341 [00:05<00:01, 52.11it/s, Epoch: 18, Batch: 286,Loss: -2.602,Avg.Loss: -2.629,LR: 1.43E-05]Training epoch 18:  84%|████████▍ | 286/341 [00:05<00:01, 52.11it/s, Epoch: 18, Batch: 287,Loss: -2.644,Avg.Loss: -2.630,LR: 1.42E-05]Training epoch 18:  84%|████████▍ | 287/341 [00:05<00:01, 52.11it/s, Epoch: 18, Batch: 288,Loss: -2.279,Avg.Loss: -2.628,LR: 1.42E-05]Training epoch 18:  84%|████████▍ | 288/341 [00:05<00:01, 52.16it/s, Epoch: 18, Batch: 288,Loss: -2.279,Avg.Loss: -2.628,LR: 1.42E-05]Training epoch 18:  84%|████████▍ | 288/341 [00:05<00:01, 52.16it/s, Epoch: 18, Batch: 289,Loss: -2.887,Avg.Loss: -2.629,LR: 1.42E-05]Training epoch 18:  85%|████████▍ | 289/341 [00:05<00:00, 52.16it/s, Epoch: 18, Batch: 290,Loss: -2.939,Avg.Loss: -2.630,LR: 1.41E-05]Training epoch 18:  85%|████████▌ | 290/341 [00:05<00:00, 52.16it/s, Epoch: 18, Batch: 291,Loss: -2.563,Avg.Loss: -2.630,LR: 1.41E-05]Training epoch 18:  85%|████████▌ | 291/341 [00:05<00:00, 52.16it/s, Epoch: 18, Batch: 292,Loss: -2.334,Avg.Loss: -2.629,LR: 1.40E-05]Training epoch 18:  86%|████████▌ | 292/341 [00:05<00:00, 52.16it/s, Epoch: 18, Batch: 293,Loss: -2.297,Avg.Loss: -2.628,LR: 1.40E-05]Training epoch 18:  86%|████████▌ | 293/341 [00:05<00:00, 52.16it/s, Epoch: 18, Batch: 294,Loss: -2.797,Avg.Loss: -2.628,LR: 1.40E-05]Training epoch 18:  86%|████████▌ | 294/341 [00:05<00:00, 52.02it/s, Epoch: 18, Batch: 294,Loss: -2.797,Avg.Loss: -2.628,LR: 1.40E-05]Training epoch 18:  86%|████████▌ | 294/341 [00:05<00:00, 52.02it/s, Epoch: 18, Batch: 295,Loss: -2.927,Avg.Loss: -2.629,LR: 1.39E-05]Training epoch 18:  87%|████████▋ | 295/341 [00:05<00:00, 52.02it/s, Epoch: 18, Batch: 296,Loss: -3.020,Avg.Loss: -2.631,LR: 1.39E-05]Training epoch 18:  87%|████████▋ | 296/341 [00:05<00:00, 52.02it/s, Epoch: 18, Batch: 297,Loss: -2.643,Avg.Loss: -2.631,LR: 1.39E-05]Training epoch 18:  87%|████████▋ | 297/341 [00:05<00:00, 52.02it/s, Epoch: 18, Batch: 298,Loss: -2.771,Avg.Loss: -2.631,LR: 1.38E-05]Training epoch 18:  87%|████████▋ | 298/341 [00:05<00:00, 52.02it/s, Epoch: 18, Batch: 299,Loss: -2.655,Avg.Loss: -2.631,LR: 1.38E-05]Training epoch 18:  88%|████████▊ | 299/341 [00:05<00:00, 52.02it/s, Epoch: 18, Batch: 300,Loss: -1.985,Avg.Loss: -2.629,LR: 1.37E-05]Training epoch 18:  88%|████████▊ | 300/341 [00:05<00:00, 52.94it/s, Epoch: 18, Batch: 300,Loss: -1.985,Avg.Loss: -2.629,LR: 1.37E-05]Training epoch 18:  88%|████████▊ | 300/341 [00:05<00:00, 52.94it/s, Epoch: 18, Batch: 301,Loss: -2.734,Avg.Loss: -2.630,LR: 1.37E-05]Training epoch 18:  88%|████████▊ | 301/341 [00:05<00:00, 52.94it/s, Epoch: 18, Batch: 302,Loss: -2.638,Avg.Loss: -2.630,LR: 1.37E-05]Training epoch 18:  89%|████████▊ | 302/341 [00:05<00:00, 52.94it/s, Epoch: 18, Batch: 303,Loss: -2.777,Avg.Loss: -2.630,LR: 1.36E-05]Training epoch 18:  89%|████████▉ | 303/341 [00:05<00:00, 52.94it/s, Epoch: 18, Batch: 304,Loss: -2.417,Avg.Loss: -2.629,LR: 1.36E-05]Training epoch 18:  89%|████████▉ | 304/341 [00:05<00:00, 52.94it/s, Epoch: 18, Batch: 305,Loss: -2.751,Avg.Loss: -2.630,LR: 1.35E-05]Training epoch 18:  89%|████████▉ | 305/341 [00:05<00:00, 52.94it/s, Epoch: 18, Batch: 306,Loss: -2.987,Avg.Loss: -2.631,LR: 1.35E-05]Training epoch 18:  90%|████████▉ | 306/341 [00:05<00:00, 51.13it/s, Epoch: 18, Batch: 306,Loss: -2.987,Avg.Loss: -2.631,LR: 1.35E-05]Training epoch 18:  90%|████████▉ | 306/341 [00:05<00:00, 51.13it/s, Epoch: 18, Batch: 307,Loss: -2.488,Avg.Loss: -2.631,LR: 1.35E-05]Training epoch 18:  90%|█████████ | 307/341 [00:05<00:00, 51.13it/s, Epoch: 18, Batch: 308,Loss: -2.526,Avg.Loss: -2.630,LR: 1.34E-05]Training epoch 18:  90%|█████████ | 308/341 [00:05<00:00, 51.13it/s, Epoch: 18, Batch: 309,Loss: -3.013,Avg.Loss: -2.631,LR: 1.34E-05]Training epoch 18:  91%|█████████ | 309/341 [00:05<00:00, 51.13it/s, Epoch: 18, Batch: 310,Loss: -2.643,Avg.Loss: -2.631,LR: 1.34E-05]Training epoch 18:  91%|█████████ | 310/341 [00:05<00:00, 51.13it/s, Epoch: 18, Batch: 311,Loss: -2.340,Avg.Loss: -2.631,LR: 1.33E-05]Training epoch 18:  91%|█████████ | 311/341 [00:05<00:00, 51.13it/s, Epoch: 18, Batch: 312,Loss: -2.857,Avg.Loss: -2.631,LR: 1.33E-05]Training epoch 18:  91%|█████████▏| 312/341 [00:05<00:00, 51.54it/s, Epoch: 18, Batch: 312,Loss: -2.857,Avg.Loss: -2.631,LR: 1.33E-05]Training epoch 18:  91%|█████████▏| 312/341 [00:05<00:00, 51.54it/s, Epoch: 18, Batch: 313,Loss: -2.435,Avg.Loss: -2.631,LR: 1.33E-05]Training epoch 18:  92%|█████████▏| 313/341 [00:05<00:00, 51.54it/s, Epoch: 18, Batch: 314,Loss: -2.546,Avg.Loss: -2.630,LR: 1.32E-05]Training epoch 18:  92%|█████████▏| 314/341 [00:05<00:00, 51.54it/s, Epoch: 18, Batch: 315,Loss: -2.641,Avg.Loss: -2.630,LR: 1.32E-05]Training epoch 18:  92%|█████████▏| 315/341 [00:06<00:00, 51.54it/s, Epoch: 18, Batch: 316,Loss: -2.668,Avg.Loss: -2.630,LR: 1.31E-05]Training epoch 18:  93%|█████████▎| 316/341 [00:06<00:00, 51.54it/s, Epoch: 18, Batch: 317,Loss: -2.882,Avg.Loss: -2.631,LR: 1.31E-05]Training epoch 18:  93%|█████████▎| 317/341 [00:06<00:00, 51.54it/s, Epoch: 18, Batch: 318,Loss: -2.557,Avg.Loss: -2.631,LR: 1.31E-05]Training epoch 18:  93%|█████████▎| 318/341 [00:06<00:00, 51.49it/s, Epoch: 18, Batch: 318,Loss: -2.557,Avg.Loss: -2.631,LR: 1.31E-05]Training epoch 18:  93%|█████████▎| 318/341 [00:06<00:00, 51.49it/s, Epoch: 18, Batch: 319,Loss: -2.427,Avg.Loss: -2.630,LR: 1.30E-05]Training epoch 18:  94%|█████████▎| 319/341 [00:06<00:00, 51.49it/s, Epoch: 18, Batch: 320,Loss: -2.585,Avg.Loss: -2.630,LR: 1.30E-05]Training epoch 18:  94%|█████████▍| 320/341 [00:06<00:00, 51.49it/s, Epoch: 18, Batch: 321,Loss: -2.606,Avg.Loss: -2.630,LR: 1.30E-05]Training epoch 18:  94%|█████████▍| 321/341 [00:06<00:00, 51.49it/s, Epoch: 18, Batch: 322,Loss: -3.115,Avg.Loss: -2.632,LR: 1.29E-05]Training epoch 18:  94%|█████████▍| 322/341 [00:06<00:00, 51.49it/s, Epoch: 18, Batch: 323,Loss: -2.741,Avg.Loss: -2.632,LR: 1.29E-05]Training epoch 18:  95%|█████████▍| 323/341 [00:06<00:00, 51.49it/s, Epoch: 18, Batch: 324,Loss: -2.892,Avg.Loss: -2.633,LR: 1.28E-05]Training epoch 18:  95%|█████████▌| 324/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 324,Loss: -2.892,Avg.Loss: -2.633,LR: 1.28E-05]Training epoch 18:  95%|█████████▌| 324/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 325,Loss: -2.579,Avg.Loss: -2.633,LR: 1.28E-05]Training epoch 18:  95%|█████████▌| 325/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 326,Loss: -2.895,Avg.Loss: -2.633,LR: 1.28E-05]Training epoch 18:  96%|█████████▌| 326/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 327,Loss: -2.336,Avg.Loss: -2.633,LR: 1.27E-05]Training epoch 18:  96%|█████████▌| 327/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 328,Loss: -2.838,Avg.Loss: -2.633,LR: 1.27E-05]Training epoch 18:  96%|█████████▌| 328/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 329,Loss: -2.720,Avg.Loss: -2.633,LR: 1.27E-05]Training epoch 18:  96%|█████████▋| 329/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 330,Loss: -2.509,Avg.Loss: -2.633,LR: 1.26E-05]Training epoch 18:  97%|█████████▋| 330/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 330,Loss: -2.509,Avg.Loss: -2.633,LR: 1.26E-05]Training epoch 18:  97%|█████████▋| 330/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 331,Loss: -2.893,Avg.Loss: -2.634,LR: 1.26E-05]Training epoch 18:  97%|█████████▋| 331/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 332,Loss: -2.286,Avg.Loss: -2.633,LR: 1.26E-05]Training epoch 18:  97%|█████████▋| 332/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 333,Loss: -2.883,Avg.Loss: -2.634,LR: 1.25E-05]Training epoch 18:  98%|█████████▊| 333/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 334,Loss: -3.007,Avg.Loss: -2.635,LR: 1.25E-05]Training epoch 18:  98%|█████████▊| 334/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 335,Loss: -2.871,Avg.Loss: -2.635,LR: 1.25E-05]Training epoch 18:  98%|█████████▊| 335/341 [00:06<00:00, 50.91it/s, Epoch: 18, Batch: 336,Loss: -2.581,Avg.Loss: -2.635,LR: 1.24E-05]Training epoch 18:  99%|█████████▊| 336/341 [00:06<00:00, 51.07it/s, Epoch: 18, Batch: 336,Loss: -2.581,Avg.Loss: -2.635,LR: 1.24E-05]Training epoch 18:  99%|█████████▊| 336/341 [00:06<00:00, 51.07it/s, Epoch: 18, Batch: 337,Loss: -2.174,Avg.Loss: -2.634,LR: 1.24E-05]Training epoch 18:  99%|█████████▉| 337/341 [00:06<00:00, 51.07it/s, Epoch: 18, Batch: 338,Loss: -2.928,Avg.Loss: -2.635,LR: 1.23E-05]Training epoch 18:  99%|█████████▉| 338/341 [00:06<00:00, 51.07it/s, Epoch: 18, Batch: 339,Loss: -2.885,Avg.Loss: -2.635,LR: 1.23E-05]Training epoch 18:  99%|█████████▉| 339/341 [00:06<00:00, 51.07it/s, Epoch: 18, Batch: 340,Loss: -2.861,Avg.Loss: -2.636,LR: 1.23E-05]Training epoch 18: 100%|█████████▉| 340/341 [00:06<00:00, 51.07it/s, Epoch: 18, Batch: 341,Loss: -2.613,Avg.Loss: -2.636,LR: 1.22E-05]Training epoch 18: 100%|██████████| 341/341 [00:06<00:00, 52.40it/s, Epoch: 18, Batch: 341,Loss: -2.613,Avg.Loss: -2.636,LR: 1.22E-05]
Training epoch 19:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 19:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 19, Batch: 1,Loss: -2.903,Avg.Loss: -2.903,LR: 1.22E-05]Training epoch 19:   0%|          | 1/341 [00:00<00:12, 26.92it/s, Epoch: 19, Batch: 2,Loss: -2.596,Avg.Loss: -2.750,LR: 1.22E-05]Training epoch 19:   1%|          | 2/341 [00:00<00:09, 36.69it/s, Epoch: 19, Batch: 3,Loss: -2.760,Avg.Loss: -2.753,LR: 1.21E-05]Training epoch 19:   1%|          | 3/341 [00:00<00:08, 41.84it/s, Epoch: 19, Batch: 4,Loss: -2.805,Avg.Loss: -2.766,LR: 1.21E-05]Training epoch 19:   1%|          | 4/341 [00:00<00:07, 44.94it/s, Epoch: 19, Batch: 5,Loss: -3.030,Avg.Loss: -2.819,LR: 1.21E-05]Training epoch 19:   1%|▏         | 5/341 [00:00<00:07, 46.87it/s, Epoch: 19, Batch: 6,Loss: -2.753,Avg.Loss: -2.808,LR: 1.20E-05]Training epoch 19:   2%|▏         | 6/341 [00:00<00:05, 56.14it/s, Epoch: 19, Batch: 6,Loss: -2.753,Avg.Loss: -2.808,LR: 1.20E-05]Training epoch 19:   2%|▏         | 6/341 [00:00<00:05, 56.14it/s, Epoch: 19, Batch: 7,Loss: -2.672,Avg.Loss: -2.788,LR: 1.20E-05]Training epoch 19:   2%|▏         | 7/341 [00:00<00:05, 56.14it/s, Epoch: 19, Batch: 8,Loss: -2.765,Avg.Loss: -2.785,LR: 1.20E-05]Training epoch 19:   2%|▏         | 8/341 [00:00<00:05, 56.14it/s, Epoch: 19, Batch: 9,Loss: -2.746,Avg.Loss: -2.781,LR: 1.19E-05]Training epoch 19:   3%|▎         | 9/341 [00:00<00:05, 56.14it/s, Epoch: 19, Batch: 10,Loss: -2.917,Avg.Loss: -2.795,LR: 1.19E-05]Training epoch 19:   3%|▎         | 10/341 [00:00<00:05, 56.14it/s, Epoch: 19, Batch: 11,Loss: -2.540,Avg.Loss: -2.772,LR: 1.18E-05]Training epoch 19:   3%|▎         | 11/341 [00:00<00:05, 56.14it/s, Epoch: 19, Batch: 12,Loss: -2.965,Avg.Loss: -2.788,LR: 1.18E-05]Training epoch 19:   4%|▎         | 12/341 [00:00<00:06, 54.27it/s, Epoch: 19, Batch: 12,Loss: -2.965,Avg.Loss: -2.788,LR: 1.18E-05]Training epoch 19:   4%|▎         | 12/341 [00:00<00:06, 54.27it/s, Epoch: 19, Batch: 13,Loss: -2.639,Avg.Loss: -2.776,LR: 1.18E-05]Training epoch 19:   4%|▍         | 13/341 [00:00<00:06, 54.27it/s, Epoch: 19, Batch: 14,Loss: -2.668,Avg.Loss: -2.768,LR: 1.17E-05]Training epoch 19:   4%|▍         | 14/341 [00:00<00:06, 54.27it/s, Epoch: 19, Batch: 15,Loss: -2.733,Avg.Loss: -2.766,LR: 1.17E-05]Training epoch 19:   4%|▍         | 15/341 [00:00<00:06, 54.27it/s, Epoch: 19, Batch: 16,Loss: -2.578,Avg.Loss: -2.754,LR: 1.17E-05]Training epoch 19:   5%|▍         | 16/341 [00:00<00:05, 54.27it/s, Epoch: 19, Batch: 17,Loss: -2.704,Avg.Loss: -2.751,LR: 1.16E-05]Training epoch 19:   5%|▍         | 17/341 [00:00<00:05, 54.27it/s, Epoch: 19, Batch: 18,Loss: -2.593,Avg.Loss: -2.743,LR: 1.16E-05]Training epoch 19:   5%|▌         | 18/341 [00:00<00:05, 54.20it/s, Epoch: 19, Batch: 18,Loss: -2.593,Avg.Loss: -2.743,LR: 1.16E-05]Training epoch 19:   5%|▌         | 18/341 [00:00<00:05, 54.20it/s, Epoch: 19, Batch: 19,Loss: -2.591,Avg.Loss: -2.735,LR: 1.16E-05]Training epoch 19:   6%|▌         | 19/341 [00:00<00:05, 54.20it/s, Epoch: 19, Batch: 20,Loss: -2.316,Avg.Loss: -2.714,LR: 1.15E-05]Training epoch 19:   6%|▌         | 20/341 [00:00<00:05, 54.20it/s, Epoch: 19, Batch: 21,Loss: -2.683,Avg.Loss: -2.712,LR: 1.15E-05]Training epoch 19:   6%|▌         | 21/341 [00:00<00:05, 54.20it/s, Epoch: 19, Batch: 22,Loss: -2.751,Avg.Loss: -2.714,LR: 1.15E-05]Training epoch 19:   6%|▋         | 22/341 [00:00<00:05, 54.20it/s, Epoch: 19, Batch: 23,Loss: -2.666,Avg.Loss: -2.712,LR: 1.14E-05]Training epoch 19:   7%|▋         | 23/341 [00:00<00:05, 54.20it/s, Epoch: 19, Batch: 24,Loss: -2.657,Avg.Loss: -2.710,LR: 1.14E-05]Training epoch 19:   7%|▋         | 24/341 [00:00<00:05, 54.52it/s, Epoch: 19, Batch: 24,Loss: -2.657,Avg.Loss: -2.710,LR: 1.14E-05]Training epoch 19:   7%|▋         | 24/341 [00:00<00:05, 54.52it/s, Epoch: 19, Batch: 25,Loss: -2.382,Avg.Loss: -2.696,LR: 1.14E-05]Training epoch 19:   7%|▋         | 25/341 [00:00<00:05, 54.52it/s, Epoch: 19, Batch: 26,Loss: -2.689,Avg.Loss: -2.696,LR: 1.13E-05]Training epoch 19:   8%|▊         | 26/341 [00:00<00:05, 54.52it/s, Epoch: 19, Batch: 27,Loss: -2.551,Avg.Loss: -2.691,LR: 1.13E-05]Training epoch 19:   8%|▊         | 27/341 [00:00<00:05, 54.52it/s, Epoch: 19, Batch: 28,Loss: -2.958,Avg.Loss: -2.700,LR: 1.13E-05]Training epoch 19:   8%|▊         | 28/341 [00:00<00:05, 54.52it/s, Epoch: 19, Batch: 29,Loss: -2.880,Avg.Loss: -2.707,LR: 1.12E-05]Training epoch 19:   9%|▊         | 29/341 [00:00<00:05, 54.52it/s, Epoch: 19, Batch: 30,Loss: -2.855,Avg.Loss: -2.711,LR: 1.12E-05]Training epoch 19:   9%|▉         | 30/341 [00:00<00:05, 54.55it/s, Epoch: 19, Batch: 30,Loss: -2.855,Avg.Loss: -2.711,LR: 1.12E-05]Training epoch 19:   9%|▉         | 30/341 [00:00<00:05, 54.55it/s, Epoch: 19, Batch: 31,Loss: -2.408,Avg.Loss: -2.702,LR: 1.12E-05]Training epoch 19:   9%|▉         | 31/341 [00:00<00:05, 54.55it/s, Epoch: 19, Batch: 32,Loss: -2.476,Avg.Loss: -2.695,LR: 1.11E-05]Training epoch 19:   9%|▉         | 32/341 [00:00<00:05, 54.55it/s, Epoch: 19, Batch: 33,Loss: -2.772,Avg.Loss: -2.697,LR: 1.11E-05]Training epoch 19:  10%|▉         | 33/341 [00:00<00:05, 54.55it/s, Epoch: 19, Batch: 34,Loss: -2.737,Avg.Loss: -2.698,LR: 1.11E-05]Training epoch 19:  10%|▉         | 34/341 [00:00<00:05, 54.55it/s, Epoch: 19, Batch: 35,Loss: -2.794,Avg.Loss: -2.701,LR: 1.10E-05]Training epoch 19:  10%|█         | 35/341 [00:00<00:05, 54.55it/s, Epoch: 19, Batch: 36,Loss: -2.532,Avg.Loss: -2.696,LR: 1.10E-05]Training epoch 19:  11%|█         | 36/341 [00:00<00:05, 51.79it/s, Epoch: 19, Batch: 36,Loss: -2.532,Avg.Loss: -2.696,LR: 1.10E-05]Training epoch 19:  11%|█         | 36/341 [00:00<00:05, 51.79it/s, Epoch: 19, Batch: 37,Loss: -2.837,Avg.Loss: -2.700,LR: 1.10E-05]Training epoch 19:  11%|█         | 37/341 [00:00<00:05, 51.79it/s, Epoch: 19, Batch: 38,Loss: -2.655,Avg.Loss: -2.699,LR: 1.09E-05]Training epoch 19:  11%|█         | 38/341 [00:00<00:05, 51.79it/s, Epoch: 19, Batch: 39,Loss: -2.771,Avg.Loss: -2.701,LR: 1.09E-05]Training epoch 19:  11%|█▏        | 39/341 [00:00<00:05, 51.79it/s, Epoch: 19, Batch: 40,Loss: -2.845,Avg.Loss: -2.704,LR: 1.09E-05]Training epoch 19:  12%|█▏        | 40/341 [00:00<00:05, 51.79it/s, Epoch: 19, Batch: 41,Loss: -2.742,Avg.Loss: -2.705,LR: 1.08E-05]Training epoch 19:  12%|█▏        | 41/341 [00:00<00:05, 51.79it/s, Epoch: 19, Batch: 42,Loss: -2.846,Avg.Loss: -2.709,LR: 1.08E-05]Training epoch 19:  12%|█▏        | 42/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 42,Loss: -2.846,Avg.Loss: -2.709,LR: 1.08E-05]Training epoch 19:  12%|█▏        | 42/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 43,Loss: -2.549,Avg.Loss: -2.705,LR: 1.08E-05]Training epoch 19:  13%|█▎        | 43/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 44,Loss: -2.623,Avg.Loss: -2.703,LR: 1.07E-05]Training epoch 19:  13%|█▎        | 44/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 45,Loss: -2.525,Avg.Loss: -2.699,LR: 1.07E-05]Training epoch 19:  13%|█▎        | 45/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 46,Loss: -2.436,Avg.Loss: -2.693,LR: 1.07E-05]Training epoch 19:  13%|█▎        | 46/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 47,Loss: -2.497,Avg.Loss: -2.689,LR: 1.06E-05]Training epoch 19:  14%|█▍        | 47/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 48,Loss: -2.349,Avg.Loss: -2.682,LR: 1.06E-05]Training epoch 19:  14%|█▍        | 48/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 48,Loss: -2.349,Avg.Loss: -2.682,LR: 1.06E-05]Training epoch 19:  14%|█▍        | 48/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 49,Loss: -2.923,Avg.Loss: -2.687,LR: 1.06E-05]Training epoch 19:  14%|█▍        | 49/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 50,Loss: -2.346,Avg.Loss: -2.680,LR: 1.05E-05]Training epoch 19:  15%|█▍        | 50/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 51,Loss: -2.410,Avg.Loss: -2.675,LR: 1.05E-05]Training epoch 19:  15%|█▍        | 51/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 52,Loss: -2.416,Avg.Loss: -2.670,LR: 1.05E-05]Training epoch 19:  15%|█▌        | 52/341 [00:00<00:05, 52.55it/s, Epoch: 19, Batch: 53,Loss: -2.694,Avg.Loss: -2.670,LR: 1.04E-05]Training epoch 19:  16%|█▌        | 53/341 [00:01<00:05, 52.55it/s, Epoch: 19, Batch: 54,Loss: -2.738,Avg.Loss: -2.672,LR: 1.04E-05]Training epoch 19:  16%|█▌        | 54/341 [00:01<00:05, 52.82it/s, Epoch: 19, Batch: 54,Loss: -2.738,Avg.Loss: -2.672,LR: 1.04E-05]Training epoch 19:  16%|█▌        | 54/341 [00:01<00:05, 52.82it/s, Epoch: 19, Batch: 55,Loss: -2.870,Avg.Loss: -2.675,LR: 1.04E-05]Training epoch 19:  16%|█▌        | 55/341 [00:01<00:05, 52.82it/s, Epoch: 19, Batch: 56,Loss: -2.725,Avg.Loss: -2.676,LR: 1.03E-05]Training epoch 19:  16%|█▋        | 56/341 [00:01<00:05, 52.82it/s, Epoch: 19, Batch: 57,Loss: -2.707,Avg.Loss: -2.677,LR: 1.03E-05]Training epoch 19:  17%|█▋        | 57/341 [00:01<00:05, 52.82it/s, Epoch: 19, Batch: 58,Loss: -2.635,Avg.Loss: -2.676,LR: 1.03E-05]Training epoch 19:  17%|█▋        | 58/341 [00:01<00:05, 52.82it/s, Epoch: 19, Batch: 59,Loss: -2.210,Avg.Loss: -2.668,LR: 1.02E-05]Training epoch 19:  17%|█▋        | 59/341 [00:01<00:05, 52.82it/s, Epoch: 19, Batch: 60,Loss: -2.358,Avg.Loss: -2.663,LR: 1.02E-05]Training epoch 19:  18%|█▊        | 60/341 [00:01<00:05, 53.08it/s, Epoch: 19, Batch: 60,Loss: -2.358,Avg.Loss: -2.663,LR: 1.02E-05]Training epoch 19:  18%|█▊        | 60/341 [00:01<00:05, 53.08it/s, Epoch: 19, Batch: 61,Loss: -2.946,Avg.Loss: -2.667,LR: 1.02E-05]Training epoch 19:  18%|█▊        | 61/341 [00:01<00:05, 53.08it/s, Epoch: 19, Batch: 62,Loss: -2.648,Avg.Loss: -2.667,LR: 1.01E-05]Training epoch 19:  18%|█▊        | 62/341 [00:01<00:05, 53.08it/s, Epoch: 19, Batch: 63,Loss: -2.777,Avg.Loss: -2.669,LR: 1.01E-05]Training epoch 19:  18%|█▊        | 63/341 [00:01<00:05, 53.08it/s, Epoch: 19, Batch: 64,Loss: -2.228,Avg.Loss: -2.662,LR: 1.01E-05]Training epoch 19:  19%|█▉        | 64/341 [00:01<00:05, 53.08it/s, Epoch: 19, Batch: 65,Loss: -2.533,Avg.Loss: -2.660,LR: 1.00E-05]Training epoch 19:  19%|█▉        | 65/341 [00:01<00:05, 53.08it/s, Epoch: 19, Batch: 66,Loss: -2.727,Avg.Loss: -2.661,LR: 1.00E-05]Training epoch 19:  19%|█▉        | 66/341 [00:01<00:05, 53.66it/s, Epoch: 19, Batch: 66,Loss: -2.727,Avg.Loss: -2.661,LR: 1.00E-05]Training epoch 19:  19%|█▉        | 66/341 [00:01<00:05, 53.66it/s, Epoch: 19, Batch: 67,Loss: -2.918,Avg.Loss: -2.665,LR: 9.97E-06]Training epoch 19:  20%|█▉        | 67/341 [00:01<00:05, 53.66it/s, Epoch: 19, Batch: 68,Loss: -2.055,Avg.Loss: -2.656,LR: 9.93E-06]Training epoch 19:  20%|█▉        | 68/341 [00:01<00:05, 53.66it/s, Epoch: 19, Batch: 69,Loss: -2.613,Avg.Loss: -2.655,LR: 9.90E-06]Training epoch 19:  20%|██        | 69/341 [00:01<00:05, 53.66it/s, Epoch: 19, Batch: 70,Loss: -2.967,Avg.Loss: -2.660,LR: 9.87E-06]Training epoch 19:  21%|██        | 70/341 [00:01<00:05, 53.66it/s, Epoch: 19, Batch: 71,Loss: -2.712,Avg.Loss: -2.660,LR: 9.84E-06]Training epoch 19:  21%|██        | 71/341 [00:01<00:05, 53.66it/s, Epoch: 19, Batch: 72,Loss: -2.894,Avg.Loss: -2.664,LR: 9.80E-06]Training epoch 19:  21%|██        | 72/341 [00:01<00:05, 53.45it/s, Epoch: 19, Batch: 72,Loss: -2.894,Avg.Loss: -2.664,LR: 9.80E-06]Training epoch 19:  21%|██        | 72/341 [00:01<00:05, 53.45it/s, Epoch: 19, Batch: 73,Loss: -2.613,Avg.Loss: -2.663,LR: 9.77E-06]Training epoch 19:  21%|██▏       | 73/341 [00:01<00:05, 53.45it/s, Epoch: 19, Batch: 74,Loss: -2.758,Avg.Loss: -2.664,LR: 9.74E-06]Training epoch 19:  22%|██▏       | 74/341 [00:01<00:04, 53.45it/s, Epoch: 19, Batch: 75,Loss: -2.463,Avg.Loss: -2.662,LR: 9.71E-06]Training epoch 19:  22%|██▏       | 75/341 [00:01<00:04, 53.45it/s, Epoch: 19, Batch: 76,Loss: -2.807,Avg.Loss: -2.664,LR: 9.68E-06]Training epoch 19:  22%|██▏       | 76/341 [00:01<00:04, 53.45it/s, Epoch: 19, Batch: 77,Loss: -2.719,Avg.Loss: -2.664,LR: 9.65E-06]Training epoch 19:  23%|██▎       | 77/341 [00:01<00:04, 53.45it/s, Epoch: 19, Batch: 78,Loss: -2.140,Avg.Loss: -2.658,LR: 9.61E-06]Training epoch 19:  23%|██▎       | 78/341 [00:01<00:04, 53.31it/s, Epoch: 19, Batch: 78,Loss: -2.140,Avg.Loss: -2.658,LR: 9.61E-06]Training epoch 19:  23%|██▎       | 78/341 [00:01<00:04, 53.31it/s, Epoch: 19, Batch: 79,Loss: -2.702,Avg.Loss: -2.658,LR: 9.58E-06]Training epoch 19:  23%|██▎       | 79/341 [00:01<00:04, 53.31it/s, Epoch: 19, Batch: 80,Loss: -3.011,Avg.Loss: -2.663,LR: 9.55E-06]Training epoch 19:  23%|██▎       | 80/341 [00:01<00:04, 53.31it/s, Epoch: 19, Batch: 81,Loss: -2.914,Avg.Loss: -2.666,LR: 9.52E-06]Training epoch 19:  24%|██▍       | 81/341 [00:01<00:04, 53.31it/s, Epoch: 19, Batch: 82,Loss: -2.661,Avg.Loss: -2.666,LR: 9.49E-06]Training epoch 19:  24%|██▍       | 82/341 [00:01<00:04, 53.31it/s, Epoch: 19, Batch: 83,Loss: -2.802,Avg.Loss: -2.667,LR: 9.46E-06]Training epoch 19:  24%|██▍       | 83/341 [00:01<00:04, 53.31it/s, Epoch: 19, Batch: 84,Loss: -2.814,Avg.Loss: -2.669,LR: 9.43E-06]Training epoch 19:  25%|██▍       | 84/341 [00:01<00:04, 53.82it/s, Epoch: 19, Batch: 84,Loss: -2.814,Avg.Loss: -2.669,LR: 9.43E-06]Training epoch 19:  25%|██▍       | 84/341 [00:01<00:04, 53.82it/s, Epoch: 19, Batch: 85,Loss: -2.657,Avg.Loss: -2.669,LR: 9.39E-06]Training epoch 19:  25%|██▍       | 85/341 [00:01<00:04, 53.82it/s, Epoch: 19, Batch: 86,Loss: -2.542,Avg.Loss: -2.667,LR: 9.36E-06]Training epoch 19:  25%|██▌       | 86/341 [00:01<00:04, 53.82it/s, Epoch: 19, Batch: 87,Loss: -2.902,Avg.Loss: -2.670,LR: 9.33E-06]Training epoch 19:  26%|██▌       | 87/341 [00:01<00:04, 53.82it/s, Epoch: 19, Batch: 88,Loss: -2.703,Avg.Loss: -2.670,LR: 9.30E-06]Training epoch 19:  26%|██▌       | 88/341 [00:01<00:04, 53.82it/s, Epoch: 19, Batch: 89,Loss: -2.935,Avg.Loss: -2.673,LR: 9.27E-06]Training epoch 19:  26%|██▌       | 89/341 [00:01<00:04, 53.82it/s, Epoch: 19, Batch: 90,Loss: -2.990,Avg.Loss: -2.677,LR: 9.24E-06]Training epoch 19:  26%|██▋       | 90/341 [00:01<00:04, 53.59it/s, Epoch: 19, Batch: 90,Loss: -2.990,Avg.Loss: -2.677,LR: 9.24E-06]Training epoch 19:  26%|██▋       | 90/341 [00:01<00:04, 53.59it/s, Epoch: 19, Batch: 91,Loss: -2.524,Avg.Loss: -2.675,LR: 9.21E-06]Training epoch 19:  27%|██▋       | 91/341 [00:01<00:04, 53.59it/s, Epoch: 19, Batch: 92,Loss: -2.556,Avg.Loss: -2.674,LR: 9.18E-06]Training epoch 19:  27%|██▋       | 92/341 [00:01<00:04, 53.59it/s, Epoch: 19, Batch: 93,Loss: -2.668,Avg.Loss: -2.674,LR: 9.15E-06]Training epoch 19:  27%|██▋       | 93/341 [00:01<00:04, 53.59it/s, Epoch: 19, Batch: 94,Loss: -2.793,Avg.Loss: -2.675,LR: 9.11E-06]Training epoch 19:  28%|██▊       | 94/341 [00:01<00:04, 53.59it/s, Epoch: 19, Batch: 95,Loss: -2.644,Avg.Loss: -2.675,LR: 9.08E-06]Training epoch 19:  28%|██▊       | 95/341 [00:01<00:04, 53.59it/s, Epoch: 19, Batch: 96,Loss: -2.668,Avg.Loss: -2.675,LR: 9.05E-06]Training epoch 19:  28%|██▊       | 96/341 [00:01<00:04, 52.86it/s, Epoch: 19, Batch: 96,Loss: -2.668,Avg.Loss: -2.675,LR: 9.05E-06]Training epoch 19:  28%|██▊       | 96/341 [00:01<00:04, 52.86it/s, Epoch: 19, Batch: 97,Loss: -2.531,Avg.Loss: -2.673,LR: 9.02E-06]Training epoch 19:  28%|██▊       | 97/341 [00:01<00:04, 52.86it/s, Epoch: 19, Batch: 98,Loss: -2.918,Avg.Loss: -2.676,LR: 8.99E-06]Training epoch 19:  29%|██▊       | 98/341 [00:01<00:04, 52.86it/s, Epoch: 19, Batch: 99,Loss: -2.712,Avg.Loss: -2.676,LR: 8.96E-06]Training epoch 19:  29%|██▉       | 99/341 [00:01<00:04, 52.86it/s, Epoch: 19, Batch: 100,Loss: -2.504,Avg.Loss: -2.674,LR: 8.93E-06]Training epoch 19:  29%|██▉       | 100/341 [00:01<00:04, 52.86it/s, Epoch: 19, Batch: 101,Loss: -2.300,Avg.Loss: -2.671,LR: 8.90E-06]Training epoch 19:  30%|██▉       | 101/341 [00:01<00:04, 52.86it/s, Epoch: 19, Batch: 102,Loss: -2.104,Avg.Loss: -2.665,LR: 8.87E-06]Training epoch 19:  30%|██▉       | 102/341 [00:01<00:04, 52.49it/s, Epoch: 19, Batch: 102,Loss: -2.104,Avg.Loss: -2.665,LR: 8.87E-06]Training epoch 19:  30%|██▉       | 102/341 [00:01<00:04, 52.49it/s, Epoch: 19, Batch: 103,Loss: -2.370,Avg.Loss: -2.662,LR: 8.84E-06]Training epoch 19:  30%|███       | 103/341 [00:01<00:04, 52.49it/s, Epoch: 19, Batch: 104,Loss: -2.745,Avg.Loss: -2.663,LR: 8.81E-06]Training epoch 19:  30%|███       | 104/341 [00:01<00:04, 52.49it/s, Epoch: 19, Batch: 105,Loss: -2.408,Avg.Loss: -2.661,LR: 8.78E-06]Training epoch 19:  31%|███       | 105/341 [00:01<00:04, 52.49it/s, Epoch: 19, Batch: 106,Loss: -2.370,Avg.Loss: -2.658,LR: 8.75E-06]Training epoch 19:  31%|███       | 106/341 [00:02<00:04, 52.49it/s, Epoch: 19, Batch: 107,Loss: -2.502,Avg.Loss: -2.656,LR: 8.72E-06]Training epoch 19:  31%|███▏      | 107/341 [00:02<00:04, 52.49it/s, Epoch: 19, Batch: 108,Loss: -2.602,Avg.Loss: -2.656,LR: 8.69E-06]Training epoch 19:  32%|███▏      | 108/341 [00:02<00:04, 51.33it/s, Epoch: 19, Batch: 108,Loss: -2.602,Avg.Loss: -2.656,LR: 8.69E-06]Training epoch 19:  32%|███▏      | 108/341 [00:02<00:04, 51.33it/s, Epoch: 19, Batch: 109,Loss: -2.677,Avg.Loss: -2.656,LR: 8.66E-06]Training epoch 19:  32%|███▏      | 109/341 [00:02<00:04, 51.33it/s, Epoch: 19, Batch: 110,Loss: -2.931,Avg.Loss: -2.659,LR: 8.63E-06]Training epoch 19:  32%|███▏      | 110/341 [00:02<00:04, 51.33it/s, Epoch: 19, Batch: 111,Loss: -2.265,Avg.Loss: -2.655,LR: 8.60E-06]Training epoch 19:  33%|███▎      | 111/341 [00:02<00:04, 51.33it/s, Epoch: 19, Batch: 112,Loss: -2.888,Avg.Loss: -2.657,LR: 8.57E-06]Training epoch 19:  33%|███▎      | 112/341 [00:02<00:04, 51.33it/s, Epoch: 19, Batch: 113,Loss: -2.133,Avg.Loss: -2.653,LR: 8.54E-06]Training epoch 19:  33%|███▎      | 113/341 [00:02<00:04, 51.33it/s, Epoch: 19, Batch: 114,Loss: -2.733,Avg.Loss: -2.653,LR: 8.51E-06]Training epoch 19:  33%|███▎      | 114/341 [00:02<00:04, 50.51it/s, Epoch: 19, Batch: 114,Loss: -2.733,Avg.Loss: -2.653,LR: 8.51E-06]Training epoch 19:  33%|███▎      | 114/341 [00:02<00:04, 50.51it/s, Epoch: 19, Batch: 115,Loss: -2.787,Avg.Loss: -2.654,LR: 8.48E-06]Training epoch 19:  34%|███▎      | 115/341 [00:02<00:04, 50.51it/s, Epoch: 19, Batch: 116,Loss: -2.790,Avg.Loss: -2.656,LR: 8.45E-06]Training epoch 19:  34%|███▍      | 116/341 [00:02<00:04, 50.51it/s, Epoch: 19, Batch: 117,Loss: -2.164,Avg.Loss: -2.651,LR: 8.42E-06]Training epoch 19:  34%|███▍      | 117/341 [00:02<00:04, 50.51it/s, Epoch: 19, Batch: 118,Loss: -2.391,Avg.Loss: -2.649,LR: 8.39E-06]Training epoch 19:  35%|███▍      | 118/341 [00:02<00:04, 50.51it/s, Epoch: 19, Batch: 119,Loss: -2.737,Avg.Loss: -2.650,LR: 8.36E-06]Training epoch 19:  35%|███▍      | 119/341 [00:02<00:04, 50.51it/s, Epoch: 19, Batch: 120,Loss: -2.905,Avg.Loss: -2.652,LR: 8.33E-06]Training epoch 19:  35%|███▌      | 120/341 [00:02<00:04, 51.13it/s, Epoch: 19, Batch: 120,Loss: -2.905,Avg.Loss: -2.652,LR: 8.33E-06]Training epoch 19:  35%|███▌      | 120/341 [00:02<00:04, 51.13it/s, Epoch: 19, Batch: 121,Loss: -2.716,Avg.Loss: -2.653,LR: 8.30E-06]Training epoch 19:  35%|███▌      | 121/341 [00:02<00:04, 51.13it/s, Epoch: 19, Batch: 122,Loss: -2.766,Avg.Loss: -2.653,LR: 8.27E-06]Training epoch 19:  36%|███▌      | 122/341 [00:02<00:04, 51.13it/s, Epoch: 19, Batch: 123,Loss: -2.846,Avg.Loss: -2.655,LR: 8.24E-06]Training epoch 19:  36%|███▌      | 123/341 [00:02<00:04, 51.13it/s, Epoch: 19, Batch: 124,Loss: -2.495,Avg.Loss: -2.654,LR: 8.21E-06]Training epoch 19:  36%|███▋      | 124/341 [00:02<00:04, 51.13it/s, Epoch: 19, Batch: 125,Loss: -2.643,Avg.Loss: -2.654,LR: 8.18E-06]Training epoch 19:  37%|███▋      | 125/341 [00:02<00:04, 51.13it/s, Epoch: 19, Batch: 126,Loss: -2.336,Avg.Loss: -2.651,LR: 8.15E-06]Training epoch 19:  37%|███▋      | 126/341 [00:02<00:04, 49.68it/s, Epoch: 19, Batch: 126,Loss: -2.336,Avg.Loss: -2.651,LR: 8.15E-06]Training epoch 19:  37%|███▋      | 126/341 [00:02<00:04, 49.68it/s, Epoch: 19, Batch: 127,Loss: -2.307,Avg.Loss: -2.648,LR: 8.13E-06]Training epoch 19:  37%|███▋      | 127/341 [00:02<00:04, 49.68it/s, Epoch: 19, Batch: 128,Loss: -2.597,Avg.Loss: -2.648,LR: 8.10E-06]Training epoch 19:  38%|███▊      | 128/341 [00:02<00:04, 49.68it/s, Epoch: 19, Batch: 129,Loss: -2.799,Avg.Loss: -2.649,LR: 8.07E-06]Training epoch 19:  38%|███▊      | 129/341 [00:02<00:04, 49.68it/s, Epoch: 19, Batch: 130,Loss: -2.742,Avg.Loss: -2.650,LR: 8.04E-06]Training epoch 19:  38%|███▊      | 130/341 [00:02<00:04, 49.68it/s, Epoch: 19, Batch: 131,Loss: -2.623,Avg.Loss: -2.650,LR: 8.01E-06]Training epoch 19:  38%|███▊      | 131/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 131,Loss: -2.623,Avg.Loss: -2.650,LR: 8.01E-06]Training epoch 19:  38%|███▊      | 131/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 132,Loss: -2.854,Avg.Loss: -2.651,LR: 7.98E-06]Training epoch 19:  39%|███▊      | 132/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 133,Loss: -2.593,Avg.Loss: -2.651,LR: 7.95E-06]Training epoch 19:  39%|███▉      | 133/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 134,Loss: -2.792,Avg.Loss: -2.652,LR: 7.92E-06]Training epoch 19:  39%|███▉      | 134/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 135,Loss: -2.895,Avg.Loss: -2.654,LR: 7.89E-06]Training epoch 19:  40%|███▉      | 135/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 136,Loss: -3.147,Avg.Loss: -2.657,LR: 7.87E-06]Training epoch 19:  40%|███▉      | 136/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 136,Loss: -3.147,Avg.Loss: -2.657,LR: 7.87E-06]Training epoch 19:  40%|███▉      | 136/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 137,Loss: -2.579,Avg.Loss: -2.657,LR: 7.84E-06]Training epoch 19:  40%|████      | 137/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 138,Loss: -2.951,Avg.Loss: -2.659,LR: 7.81E-06]Training epoch 19:  40%|████      | 138/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 139,Loss: -2.832,Avg.Loss: -2.660,LR: 7.78E-06]Training epoch 19:  41%|████      | 139/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 140,Loss: -2.905,Avg.Loss: -2.662,LR: 7.75E-06]Training epoch 19:  41%|████      | 140/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 141,Loss: -2.899,Avg.Loss: -2.664,LR: 7.72E-06]Training epoch 19:  41%|████▏     | 141/341 [00:02<00:04, 49.47it/s, Epoch: 19, Batch: 142,Loss: -2.792,Avg.Loss: -2.664,LR: 7.69E-06]Training epoch 19:  42%|████▏     | 142/341 [00:02<00:03, 50.12it/s, Epoch: 19, Batch: 142,Loss: -2.792,Avg.Loss: -2.664,LR: 7.69E-06]Training epoch 19:  42%|████▏     | 142/341 [00:02<00:03, 50.12it/s, Epoch: 19, Batch: 143,Loss: -2.430,Avg.Loss: -2.663,LR: 7.67E-06]Training epoch 19:  42%|████▏     | 143/341 [00:02<00:03, 50.12it/s, Epoch: 19, Batch: 144,Loss: -2.764,Avg.Loss: -2.663,LR: 7.64E-06]Training epoch 19:  42%|████▏     | 144/341 [00:02<00:03, 50.12it/s, Epoch: 19, Batch: 145,Loss: -2.831,Avg.Loss: -2.665,LR: 7.61E-06]Training epoch 19:  43%|████▎     | 145/341 [00:02<00:03, 50.12it/s, Epoch: 19, Batch: 146,Loss: -2.790,Avg.Loss: -2.666,LR: 7.58E-06]Training epoch 19:  43%|████▎     | 146/341 [00:02<00:03, 50.12it/s, Epoch: 19, Batch: 147,Loss: -2.656,Avg.Loss: -2.665,LR: 7.55E-06]Training epoch 19:  43%|████▎     | 147/341 [00:02<00:03, 50.12it/s, Epoch: 19, Batch: 148,Loss: -2.699,Avg.Loss: -2.666,LR: 7.53E-06]Training epoch 19:  43%|████▎     | 148/341 [00:02<00:03, 51.28it/s, Epoch: 19, Batch: 148,Loss: -2.699,Avg.Loss: -2.666,LR: 7.53E-06]Training epoch 19:  43%|████▎     | 148/341 [00:02<00:03, 51.28it/s, Epoch: 19, Batch: 149,Loss: -3.097,Avg.Loss: -2.669,LR: 7.50E-06]Training epoch 19:  44%|████▎     | 149/341 [00:02<00:03, 51.28it/s, Epoch: 19, Batch: 150,Loss: -2.962,Avg.Loss: -2.671,LR: 7.47E-06]Training epoch 19:  44%|████▍     | 150/341 [00:02<00:03, 51.28it/s, Epoch: 19, Batch: 151,Loss: -2.734,Avg.Loss: -2.671,LR: 7.44E-06]Training epoch 19:  44%|████▍     | 151/341 [00:02<00:03, 51.28it/s, Epoch: 19, Batch: 152,Loss: -2.260,Avg.Loss: -2.668,LR: 7.41E-06]Training epoch 19:  45%|████▍     | 152/341 [00:02<00:03, 51.28it/s, Epoch: 19, Batch: 153,Loss: -2.672,Avg.Loss: -2.668,LR: 7.39E-06]Training epoch 19:  45%|████▍     | 153/341 [00:02<00:03, 51.28it/s, Epoch: 19, Batch: 154,Loss: -2.374,Avg.Loss: -2.666,LR: 7.36E-06]Training epoch 19:  45%|████▌     | 154/341 [00:02<00:03, 52.86it/s, Epoch: 19, Batch: 154,Loss: -2.374,Avg.Loss: -2.666,LR: 7.36E-06]Training epoch 19:  45%|████▌     | 154/341 [00:02<00:03, 52.86it/s, Epoch: 19, Batch: 155,Loss: -3.086,Avg.Loss: -2.669,LR: 7.33E-06]Training epoch 19:  45%|████▌     | 155/341 [00:02<00:03, 52.86it/s, Epoch: 19, Batch: 156,Loss: -3.085,Avg.Loss: -2.672,LR: 7.30E-06]Training epoch 19:  46%|████▌     | 156/341 [00:02<00:03, 52.86it/s, Epoch: 19, Batch: 157,Loss: -2.694,Avg.Loss: -2.672,LR: 7.28E-06]Training epoch 19:  46%|████▌     | 157/341 [00:03<00:03, 52.86it/s, Epoch: 19, Batch: 158,Loss: -2.984,Avg.Loss: -2.674,LR: 7.25E-06]Training epoch 19:  46%|████▋     | 158/341 [00:03<00:03, 52.86it/s, Epoch: 19, Batch: 159,Loss: -3.163,Avg.Loss: -2.677,LR: 7.22E-06]Training epoch 19:  47%|████▋     | 159/341 [00:03<00:03, 52.86it/s, Epoch: 19, Batch: 160,Loss: -2.724,Avg.Loss: -2.677,LR: 7.19E-06]Training epoch 19:  47%|████▋     | 160/341 [00:03<00:03, 53.04it/s, Epoch: 19, Batch: 160,Loss: -2.724,Avg.Loss: -2.677,LR: 7.19E-06]Training epoch 19:  47%|████▋     | 160/341 [00:03<00:03, 53.04it/s, Epoch: 19, Batch: 161,Loss: -2.593,Avg.Loss: -2.677,LR: 7.17E-06]Training epoch 19:  47%|████▋     | 161/341 [00:03<00:03, 53.04it/s, Epoch: 19, Batch: 162,Loss: -2.964,Avg.Loss: -2.678,LR: 7.14E-06]Training epoch 19:  48%|████▊     | 162/341 [00:03<00:03, 53.04it/s, Epoch: 19, Batch: 163,Loss: -2.770,Avg.Loss: -2.679,LR: 7.11E-06]Training epoch 19:  48%|████▊     | 163/341 [00:03<00:03, 53.04it/s, Epoch: 19, Batch: 164,Loss: -1.989,Avg.Loss: -2.675,LR: 7.08E-06]Training epoch 19:  48%|████▊     | 164/341 [00:03<00:03, 53.04it/s, Epoch: 19, Batch: 165,Loss: -2.582,Avg.Loss: -2.674,LR: 7.06E-06]Training epoch 19:  48%|████▊     | 165/341 [00:03<00:03, 53.04it/s, Epoch: 19, Batch: 166,Loss: -2.944,Avg.Loss: -2.676,LR: 7.03E-06]Training epoch 19:  49%|████▊     | 166/341 [00:03<00:03, 52.91it/s, Epoch: 19, Batch: 166,Loss: -2.944,Avg.Loss: -2.676,LR: 7.03E-06]Training epoch 19:  49%|████▊     | 166/341 [00:03<00:03, 52.91it/s, Epoch: 19, Batch: 167,Loss: -2.625,Avg.Loss: -2.676,LR: 7.00E-06]Training epoch 19:  49%|████▉     | 167/341 [00:03<00:03, 52.91it/s, Epoch: 19, Batch: 168,Loss: -2.776,Avg.Loss: -2.676,LR: 6.97E-06]Training epoch 19:  49%|████▉     | 168/341 [00:03<00:03, 52.91it/s, Epoch: 19, Batch: 169,Loss: -2.639,Avg.Loss: -2.676,LR: 6.95E-06]Training epoch 19:  50%|████▉     | 169/341 [00:03<00:03, 52.91it/s, Epoch: 19, Batch: 170,Loss: -2.141,Avg.Loss: -2.673,LR: 6.92E-06]Training epoch 19:  50%|████▉     | 170/341 [00:03<00:03, 52.91it/s, Epoch: 19, Batch: 171,Loss: -2.747,Avg.Loss: -2.673,LR: 6.89E-06]Training epoch 19:  50%|█████     | 171/341 [00:03<00:03, 52.91it/s, Epoch: 19, Batch: 172,Loss: -2.471,Avg.Loss: -2.672,LR: 6.87E-06]Training epoch 19:  50%|█████     | 172/341 [00:03<00:03, 53.73it/s, Epoch: 19, Batch: 172,Loss: -2.471,Avg.Loss: -2.672,LR: 6.87E-06]Training epoch 19:  50%|█████     | 172/341 [00:03<00:03, 53.73it/s, Epoch: 19, Batch: 173,Loss: -2.463,Avg.Loss: -2.671,LR: 6.84E-06]Training epoch 19:  51%|█████     | 173/341 [00:03<00:03, 53.73it/s, Epoch: 19, Batch: 174,Loss: -2.858,Avg.Loss: -2.672,LR: 6.81E-06]Training epoch 19:  51%|█████     | 174/341 [00:03<00:03, 53.73it/s, Epoch: 19, Batch: 175,Loss: -2.698,Avg.Loss: -2.672,LR: 6.79E-06]Training epoch 19:  51%|█████▏    | 175/341 [00:03<00:03, 53.73it/s, Epoch: 19, Batch: 176,Loss: -3.125,Avg.Loss: -2.675,LR: 6.76E-06]Training epoch 19:  52%|█████▏    | 176/341 [00:03<00:03, 53.73it/s, Epoch: 19, Batch: 177,Loss: -2.411,Avg.Loss: -2.673,LR: 6.73E-06]Training epoch 19:  52%|█████▏    | 177/341 [00:03<00:03, 53.73it/s, Epoch: 19, Batch: 178,Loss: -2.525,Avg.Loss: -2.672,LR: 6.71E-06]Training epoch 19:  52%|█████▏    | 178/341 [00:03<00:03, 54.17it/s, Epoch: 19, Batch: 178,Loss: -2.525,Avg.Loss: -2.672,LR: 6.71E-06]Training epoch 19:  52%|█████▏    | 178/341 [00:03<00:03, 54.17it/s, Epoch: 19, Batch: 179,Loss: -2.821,Avg.Loss: -2.673,LR: 6.68E-06]Training epoch 19:  52%|█████▏    | 179/341 [00:03<00:02, 54.17it/s, Epoch: 19, Batch: 180,Loss: -2.907,Avg.Loss: -2.674,LR: 6.65E-06]Training epoch 19:  53%|█████▎    | 180/341 [00:03<00:02, 54.17it/s, Epoch: 19, Batch: 181,Loss: -2.660,Avg.Loss: -2.674,LR: 6.63E-06]Training epoch 19:  53%|█████▎    | 181/341 [00:03<00:02, 54.17it/s, Epoch: 19, Batch: 182,Loss: -3.029,Avg.Loss: -2.676,LR: 6.60E-06]Training epoch 19:  53%|█████▎    | 182/341 [00:03<00:02, 54.17it/s, Epoch: 19, Batch: 183,Loss: -2.983,Avg.Loss: -2.678,LR: 6.58E-06]Training epoch 19:  54%|█████▎    | 183/341 [00:03<00:02, 54.17it/s, Epoch: 19, Batch: 184,Loss: -2.766,Avg.Loss: -2.678,LR: 6.55E-06]Training epoch 19:  54%|█████▍    | 184/341 [00:03<00:02, 54.62it/s, Epoch: 19, Batch: 184,Loss: -2.766,Avg.Loss: -2.678,LR: 6.55E-06]Training epoch 19:  54%|█████▍    | 184/341 [00:03<00:02, 54.62it/s, Epoch: 19, Batch: 185,Loss: -2.903,Avg.Loss: -2.680,LR: 6.52E-06]Training epoch 19:  54%|█████▍    | 185/341 [00:03<00:02, 54.62it/s, Epoch: 19, Batch: 186,Loss: -2.567,Avg.Loss: -2.679,LR: 6.50E-06]Training epoch 19:  55%|█████▍    | 186/341 [00:03<00:02, 54.62it/s, Epoch: 19, Batch: 187,Loss: -2.793,Avg.Loss: -2.680,LR: 6.47E-06]Training epoch 19:  55%|█████▍    | 187/341 [00:03<00:02, 54.62it/s, Epoch: 19, Batch: 188,Loss: -2.635,Avg.Loss: -2.679,LR: 6.44E-06]Training epoch 19:  55%|█████▌    | 188/341 [00:03<00:02, 54.62it/s, Epoch: 19, Batch: 189,Loss: -3.070,Avg.Loss: -2.682,LR: 6.42E-06]Training epoch 19:  55%|█████▌    | 189/341 [00:03<00:02, 54.62it/s, Epoch: 19, Batch: 190,Loss: -3.161,Avg.Loss: -2.684,LR: 6.39E-06]Training epoch 19:  56%|█████▌    | 190/341 [00:03<00:02, 55.05it/s, Epoch: 19, Batch: 190,Loss: -3.161,Avg.Loss: -2.684,LR: 6.39E-06]Training epoch 19:  56%|█████▌    | 190/341 [00:03<00:02, 55.05it/s, Epoch: 19, Batch: 191,Loss: -2.410,Avg.Loss: -2.683,LR: 6.37E-06]Training epoch 19:  56%|█████▌    | 191/341 [00:03<00:02, 55.05it/s, Epoch: 19, Batch: 192,Loss: -2.801,Avg.Loss: -2.683,LR: 6.34E-06]Training epoch 19:  56%|█████▋    | 192/341 [00:03<00:02, 55.05it/s, Epoch: 19, Batch: 193,Loss: -2.483,Avg.Loss: -2.682,LR: 6.32E-06]Training epoch 19:  57%|█████▋    | 193/341 [00:03<00:02, 55.05it/s, Epoch: 19, Batch: 194,Loss: -3.078,Avg.Loss: -2.684,LR: 6.29E-06]Training epoch 19:  57%|█████▋    | 194/341 [00:03<00:02, 55.05it/s, Epoch: 19, Batch: 195,Loss: -2.908,Avg.Loss: -2.685,LR: 6.26E-06]Training epoch 19:  57%|█████▋    | 195/341 [00:03<00:02, 55.05it/s, Epoch: 19, Batch: 196,Loss: -2.835,Avg.Loss: -2.686,LR: 6.24E-06]Training epoch 19:  57%|█████▋    | 196/341 [00:03<00:02, 54.32it/s, Epoch: 19, Batch: 196,Loss: -2.835,Avg.Loss: -2.686,LR: 6.24E-06]Training epoch 19:  57%|█████▋    | 196/341 [00:03<00:02, 54.32it/s, Epoch: 19, Batch: 197,Loss: -2.454,Avg.Loss: -2.685,LR: 6.21E-06]Training epoch 19:  58%|█████▊    | 197/341 [00:03<00:02, 54.32it/s, Epoch: 19, Batch: 198,Loss: -3.131,Avg.Loss: -2.687,LR: 6.19E-06]Training epoch 19:  58%|█████▊    | 198/341 [00:03<00:02, 54.32it/s, Epoch: 19, Batch: 199,Loss: -2.438,Avg.Loss: -2.686,LR: 6.16E-06]Training epoch 19:  58%|█████▊    | 199/341 [00:03<00:02, 54.32it/s, Epoch: 19, Batch: 200,Loss: -2.805,Avg.Loss: -2.687,LR: 6.14E-06]Training epoch 19:  59%|█████▊    | 200/341 [00:03<00:02, 54.32it/s, Epoch: 19, Batch: 201,Loss: -2.639,Avg.Loss: -2.686,LR: 6.11E-06]Training epoch 19:  59%|█████▉    | 201/341 [00:03<00:02, 54.32it/s, Epoch: 19, Batch: 202,Loss: -2.219,Avg.Loss: -2.684,LR: 6.09E-06]Training epoch 19:  59%|█████▉    | 202/341 [00:03<00:02, 54.70it/s, Epoch: 19, Batch: 202,Loss: -2.219,Avg.Loss: -2.684,LR: 6.09E-06]Training epoch 19:  59%|█████▉    | 202/341 [00:03<00:02, 54.70it/s, Epoch: 19, Batch: 203,Loss: -2.727,Avg.Loss: -2.684,LR: 6.06E-06]Training epoch 19:  60%|█████▉    | 203/341 [00:03<00:02, 54.70it/s, Epoch: 19, Batch: 204,Loss: -2.662,Avg.Loss: -2.684,LR: 6.04E-06]Training epoch 19:  60%|█████▉    | 204/341 [00:03<00:02, 54.70it/s, Epoch: 19, Batch: 205,Loss: -2.597,Avg.Loss: -2.684,LR: 6.01E-06]Training epoch 19:  60%|██████    | 205/341 [00:03<00:02, 54.70it/s, Epoch: 19, Batch: 206,Loss: -2.790,Avg.Loss: -2.684,LR: 5.99E-06]Training epoch 19:  60%|██████    | 206/341 [00:03<00:02, 54.70it/s, Epoch: 19, Batch: 207,Loss: -2.594,Avg.Loss: -2.684,LR: 5.96E-06]Training epoch 19:  61%|██████    | 207/341 [00:03<00:02, 54.70it/s, Epoch: 19, Batch: 208,Loss: -2.999,Avg.Loss: -2.685,LR: 5.94E-06]Training epoch 19:  61%|██████    | 208/341 [00:03<00:02, 54.38it/s, Epoch: 19, Batch: 208,Loss: -2.999,Avg.Loss: -2.685,LR: 5.94E-06]Training epoch 19:  61%|██████    | 208/341 [00:03<00:02, 54.38it/s, Epoch: 19, Batch: 209,Loss: -3.014,Avg.Loss: -2.687,LR: 5.91E-06]Training epoch 19:  61%|██████▏   | 209/341 [00:03<00:02, 54.38it/s, Epoch: 19, Batch: 210,Loss: -2.863,Avg.Loss: -2.688,LR: 5.89E-06]Training epoch 19:  62%|██████▏   | 210/341 [00:03<00:02, 54.38it/s, Epoch: 19, Batch: 211,Loss: -3.107,Avg.Loss: -2.690,LR: 5.86E-06]Training epoch 19:  62%|██████▏   | 211/341 [00:04<00:02, 54.38it/s, Epoch: 19, Batch: 212,Loss: -3.133,Avg.Loss: -2.692,LR: 5.84E-06]Training epoch 19:  62%|██████▏   | 212/341 [00:04<00:02, 54.38it/s, Epoch: 19, Batch: 213,Loss: -2.931,Avg.Loss: -2.693,LR: 5.81E-06]Training epoch 19:  62%|██████▏   | 213/341 [00:04<00:02, 54.38it/s, Epoch: 19, Batch: 214,Loss: -2.701,Avg.Loss: -2.693,LR: 5.79E-06]Training epoch 19:  63%|██████▎   | 214/341 [00:04<00:02, 53.92it/s, Epoch: 19, Batch: 214,Loss: -2.701,Avg.Loss: -2.693,LR: 5.79E-06]Training epoch 19:  63%|██████▎   | 214/341 [00:04<00:02, 53.92it/s, Epoch: 19, Batch: 215,Loss: -2.743,Avg.Loss: -2.693,LR: 5.76E-06]Training epoch 19:  63%|██████▎   | 215/341 [00:04<00:02, 53.92it/s, Epoch: 19, Batch: 216,Loss: -2.873,Avg.Loss: -2.694,LR: 5.74E-06]Training epoch 19:  63%|██████▎   | 216/341 [00:04<00:02, 53.92it/s, Epoch: 19, Batch: 217,Loss: -2.252,Avg.Loss: -2.692,LR: 5.71E-06]Training epoch 19:  64%|██████▎   | 217/341 [00:04<00:02, 53.92it/s, Epoch: 19, Batch: 218,Loss: -2.998,Avg.Loss: -2.693,LR: 5.69E-06]Training epoch 19:  64%|██████▍   | 218/341 [00:04<00:02, 53.92it/s, Epoch: 19, Batch: 219,Loss: -1.880,Avg.Loss: -2.690,LR: 5.66E-06]Training epoch 19:  64%|██████▍   | 219/341 [00:04<00:02, 53.92it/s, Epoch: 19, Batch: 220,Loss: -2.283,Avg.Loss: -2.688,LR: 5.64E-06]Training epoch 19:  65%|██████▍   | 220/341 [00:04<00:02, 54.72it/s, Epoch: 19, Batch: 220,Loss: -2.283,Avg.Loss: -2.688,LR: 5.64E-06]Training epoch 19:  65%|██████▍   | 220/341 [00:04<00:02, 54.72it/s, Epoch: 19, Batch: 221,Loss: -3.115,Avg.Loss: -2.690,LR: 5.62E-06]Training epoch 19:  65%|██████▍   | 221/341 [00:04<00:02, 54.72it/s, Epoch: 19, Batch: 222,Loss: -2.866,Avg.Loss: -2.691,LR: 5.59E-06]Training epoch 19:  65%|██████▌   | 222/341 [00:04<00:02, 54.72it/s, Epoch: 19, Batch: 223,Loss: -2.604,Avg.Loss: -2.690,LR: 5.57E-06]Training epoch 19:  65%|██████▌   | 223/341 [00:04<00:02, 54.72it/s, Epoch: 19, Batch: 224,Loss: -2.602,Avg.Loss: -2.690,LR: 5.54E-06]Training epoch 19:  66%|██████▌   | 224/341 [00:04<00:02, 54.72it/s, Epoch: 19, Batch: 225,Loss: -2.153,Avg.Loss: -2.687,LR: 5.52E-06]Training epoch 19:  66%|██████▌   | 225/341 [00:04<00:02, 54.72it/s, Epoch: 19, Batch: 226,Loss: -2.830,Avg.Loss: -2.688,LR: 5.50E-06]Training epoch 19:  66%|██████▋   | 226/341 [00:04<00:02, 54.35it/s, Epoch: 19, Batch: 226,Loss: -2.830,Avg.Loss: -2.688,LR: 5.50E-06]Training epoch 19:  66%|██████▋   | 226/341 [00:04<00:02, 54.35it/s, Epoch: 19, Batch: 227,Loss: -3.039,Avg.Loss: -2.690,LR: 5.47E-06]Training epoch 19:  67%|██████▋   | 227/341 [00:04<00:02, 54.35it/s, Epoch: 19, Batch: 228,Loss: -2.740,Avg.Loss: -2.690,LR: 5.45E-06]Training epoch 19:  67%|██████▋   | 228/341 [00:04<00:02, 54.35it/s, Epoch: 19, Batch: 229,Loss: -2.722,Avg.Loss: -2.690,LR: 5.42E-06]Training epoch 19:  67%|██████▋   | 229/341 [00:04<00:02, 54.35it/s, Epoch: 19, Batch: 230,Loss: -2.764,Avg.Loss: -2.690,LR: 5.40E-06]Training epoch 19:  67%|██████▋   | 230/341 [00:04<00:02, 54.35it/s, Epoch: 19, Batch: 231,Loss: -2.765,Avg.Loss: -2.691,LR: 5.38E-06]Training epoch 19:  68%|██████▊   | 231/341 [00:04<00:02, 54.35it/s, Epoch: 19, Batch: 232,Loss: -2.320,Avg.Loss: -2.689,LR: 5.35E-06]Training epoch 19:  68%|██████▊   | 232/341 [00:04<00:02, 53.08it/s, Epoch: 19, Batch: 232,Loss: -2.320,Avg.Loss: -2.689,LR: 5.35E-06]Training epoch 19:  68%|██████▊   | 232/341 [00:04<00:02, 53.08it/s, Epoch: 19, Batch: 233,Loss: -2.674,Avg.Loss: -2.689,LR: 5.33E-06]Training epoch 19:  68%|██████▊   | 233/341 [00:04<00:02, 53.08it/s, Epoch: 19, Batch: 234,Loss: -2.617,Avg.Loss: -2.689,LR: 5.30E-06]Training epoch 19:  69%|██████▊   | 234/341 [00:04<00:02, 53.08it/s, Epoch: 19, Batch: 235,Loss: -2.494,Avg.Loss: -2.688,LR: 5.28E-06]Training epoch 19:  69%|██████▉   | 235/341 [00:04<00:01, 53.08it/s, Epoch: 19, Batch: 236,Loss: -2.868,Avg.Loss: -2.689,LR: 5.26E-06]Training epoch 19:  69%|██████▉   | 236/341 [00:04<00:01, 53.08it/s, Epoch: 19, Batch: 237,Loss: -2.638,Avg.Loss: -2.688,LR: 5.23E-06]Training epoch 19:  70%|██████▉   | 237/341 [00:04<00:01, 53.08it/s, Epoch: 19, Batch: 238,Loss: -3.071,Avg.Loss: -2.690,LR: 5.21E-06]Training epoch 19:  70%|██████▉   | 238/341 [00:04<00:02, 51.44it/s, Epoch: 19, Batch: 238,Loss: -3.071,Avg.Loss: -2.690,LR: 5.21E-06]Training epoch 19:  70%|██████▉   | 238/341 [00:04<00:02, 51.44it/s, Epoch: 19, Batch: 239,Loss: -2.737,Avg.Loss: -2.690,LR: 5.19E-06]Training epoch 19:  70%|███████   | 239/341 [00:04<00:01, 51.44it/s, Epoch: 19, Batch: 240,Loss: -2.394,Avg.Loss: -2.689,LR: 5.16E-06]Training epoch 19:  70%|███████   | 240/341 [00:04<00:01, 51.44it/s, Epoch: 19, Batch: 241,Loss: -2.663,Avg.Loss: -2.689,LR: 5.14E-06]Training epoch 19:  71%|███████   | 241/341 [00:04<00:01, 51.44it/s, Epoch: 19, Batch: 242,Loss: -2.923,Avg.Loss: -2.690,LR: 5.12E-06]Training epoch 19:  71%|███████   | 242/341 [00:04<00:01, 51.44it/s, Epoch: 19, Batch: 243,Loss: -2.907,Avg.Loss: -2.691,LR: 5.09E-06]Training epoch 19:  71%|███████▏  | 243/341 [00:04<00:01, 51.44it/s, Epoch: 19, Batch: 244,Loss: -2.768,Avg.Loss: -2.691,LR: 5.07E-06]Training epoch 19:  72%|███████▏  | 244/341 [00:04<00:01, 50.84it/s, Epoch: 19, Batch: 244,Loss: -2.768,Avg.Loss: -2.691,LR: 5.07E-06]Training epoch 19:  72%|███████▏  | 244/341 [00:04<00:01, 50.84it/s, Epoch: 19, Batch: 245,Loss: -2.894,Avg.Loss: -2.692,LR: 5.05E-06]Training epoch 19:  72%|███████▏  | 245/341 [00:04<00:01, 50.84it/s, Epoch: 19, Batch: 246,Loss: -2.199,Avg.Loss: -2.690,LR: 5.03E-06]Training epoch 19:  72%|███████▏  | 246/341 [00:04<00:01, 50.84it/s, Epoch: 19, Batch: 247,Loss: -2.190,Avg.Loss: -2.688,LR: 5.00E-06]Training epoch 19:  72%|███████▏  | 247/341 [00:04<00:01, 50.84it/s, Epoch: 19, Batch: 248,Loss: -2.967,Avg.Loss: -2.689,LR: 4.98E-06]Training epoch 19:  73%|███████▎  | 248/341 [00:04<00:01, 50.84it/s, Epoch: 19, Batch: 249,Loss: -2.793,Avg.Loss: -2.689,LR: 4.96E-06]Training epoch 19:  73%|███████▎  | 249/341 [00:04<00:01, 50.84it/s, Epoch: 19, Batch: 250,Loss: -3.156,Avg.Loss: -2.691,LR: 4.93E-06]Training epoch 19:  73%|███████▎  | 250/341 [00:04<00:01, 51.65it/s, Epoch: 19, Batch: 250,Loss: -3.156,Avg.Loss: -2.691,LR: 4.93E-06]Training epoch 19:  73%|███████▎  | 250/341 [00:04<00:01, 51.65it/s, Epoch: 19, Batch: 251,Loss: -2.809,Avg.Loss: -2.692,LR: 4.91E-06]Training epoch 19:  74%|███████▎  | 251/341 [00:04<00:01, 51.65it/s, Epoch: 19, Batch: 252,Loss: -2.869,Avg.Loss: -2.692,LR: 4.89E-06]Training epoch 19:  74%|███████▍  | 252/341 [00:04<00:01, 51.65it/s, Epoch: 19, Batch: 253,Loss: -2.897,Avg.Loss: -2.693,LR: 4.87E-06]Training epoch 19:  74%|███████▍  | 253/341 [00:04<00:01, 51.65it/s, Epoch: 19, Batch: 254,Loss: -2.165,Avg.Loss: -2.691,LR: 4.84E-06]Training epoch 19:  74%|███████▍  | 254/341 [00:04<00:01, 51.65it/s, Epoch: 19, Batch: 255,Loss: -2.423,Avg.Loss: -2.690,LR: 4.82E-06]Training epoch 19:  75%|███████▍  | 255/341 [00:04<00:01, 51.65it/s, Epoch: 19, Batch: 256,Loss: -2.604,Avg.Loss: -2.690,LR: 4.80E-06]Training epoch 19:  75%|███████▌  | 256/341 [00:04<00:01, 50.91it/s, Epoch: 19, Batch: 256,Loss: -2.604,Avg.Loss: -2.690,LR: 4.80E-06]Training epoch 19:  75%|███████▌  | 256/341 [00:04<00:01, 50.91it/s, Epoch: 19, Batch: 257,Loss: -2.731,Avg.Loss: -2.690,LR: 4.78E-06]Training epoch 19:  75%|███████▌  | 257/341 [00:04<00:01, 50.91it/s, Epoch: 19, Batch: 258,Loss: -2.111,Avg.Loss: -2.688,LR: 4.75E-06]Training epoch 19:  76%|███████▌  | 258/341 [00:04<00:01, 50.91it/s, Epoch: 19, Batch: 259,Loss: -2.678,Avg.Loss: -2.688,LR: 4.73E-06]Training epoch 19:  76%|███████▌  | 259/341 [00:04<00:01, 50.91it/s, Epoch: 19, Batch: 260,Loss: -2.836,Avg.Loss: -2.688,LR: 4.71E-06]Training epoch 19:  76%|███████▌  | 260/341 [00:04<00:01, 50.91it/s, Epoch: 19, Batch: 261,Loss: -2.464,Avg.Loss: -2.687,LR: 4.69E-06]Training epoch 19:  77%|███████▋  | 261/341 [00:04<00:01, 50.91it/s, Epoch: 19, Batch: 262,Loss: -3.159,Avg.Loss: -2.689,LR: 4.66E-06]Training epoch 19:  77%|███████▋  | 262/341 [00:04<00:01, 51.83it/s, Epoch: 19, Batch: 262,Loss: -3.159,Avg.Loss: -2.689,LR: 4.66E-06]Training epoch 19:  77%|███████▋  | 262/341 [00:04<00:01, 51.83it/s, Epoch: 19, Batch: 263,Loss: -2.474,Avg.Loss: -2.688,LR: 4.64E-06]Training epoch 19:  77%|███████▋  | 263/341 [00:05<00:01, 51.83it/s, Epoch: 19, Batch: 264,Loss: -2.786,Avg.Loss: -2.689,LR: 4.62E-06]Training epoch 19:  77%|███████▋  | 264/341 [00:05<00:01, 51.83it/s, Epoch: 19, Batch: 265,Loss: -2.564,Avg.Loss: -2.688,LR: 4.60E-06]Training epoch 19:  78%|███████▊  | 265/341 [00:05<00:01, 51.83it/s, Epoch: 19, Batch: 266,Loss: -2.833,Avg.Loss: -2.689,LR: 4.58E-06]Training epoch 19:  78%|███████▊  | 266/341 [00:05<00:01, 51.83it/s, Epoch: 19, Batch: 267,Loss: -2.326,Avg.Loss: -2.687,LR: 4.55E-06]Training epoch 19:  78%|███████▊  | 267/341 [00:05<00:01, 51.83it/s, Epoch: 19, Batch: 268,Loss: -2.351,Avg.Loss: -2.686,LR: 4.53E-06]Training epoch 19:  79%|███████▊  | 268/341 [00:05<00:01, 51.35it/s, Epoch: 19, Batch: 268,Loss: -2.351,Avg.Loss: -2.686,LR: 4.53E-06]Training epoch 19:  79%|███████▊  | 268/341 [00:05<00:01, 51.35it/s, Epoch: 19, Batch: 269,Loss: -2.943,Avg.Loss: -2.687,LR: 4.51E-06]Training epoch 19:  79%|███████▉  | 269/341 [00:05<00:01, 51.35it/s, Epoch: 19, Batch: 270,Loss: -3.112,Avg.Loss: -2.689,LR: 4.49E-06]Training epoch 19:  79%|███████▉  | 270/341 [00:05<00:01, 51.35it/s, Epoch: 19, Batch: 271,Loss: -2.892,Avg.Loss: -2.689,LR: 4.47E-06]Training epoch 19:  79%|███████▉  | 271/341 [00:05<00:01, 51.35it/s, Epoch: 19, Batch: 272,Loss: -2.882,Avg.Loss: -2.690,LR: 4.45E-06]Training epoch 19:  80%|███████▉  | 272/341 [00:05<00:01, 51.35it/s, Epoch: 19, Batch: 273,Loss: -2.745,Avg.Loss: -2.690,LR: 4.42E-06]Training epoch 19:  80%|████████  | 273/341 [00:05<00:01, 51.35it/s, Epoch: 19, Batch: 274,Loss: -2.942,Avg.Loss: -2.691,LR: 4.40E-06]Training epoch 19:  80%|████████  | 274/341 [00:05<00:01, 51.51it/s, Epoch: 19, Batch: 274,Loss: -2.942,Avg.Loss: -2.691,LR: 4.40E-06]Training epoch 19:  80%|████████  | 274/341 [00:05<00:01, 51.51it/s, Epoch: 19, Batch: 275,Loss: -2.858,Avg.Loss: -2.692,LR: 4.38E-06]Training epoch 19:  81%|████████  | 275/341 [00:05<00:01, 51.51it/s, Epoch: 19, Batch: 276,Loss: -2.655,Avg.Loss: -2.692,LR: 4.36E-06]Training epoch 19:  81%|████████  | 276/341 [00:05<00:01, 51.51it/s, Epoch: 19, Batch: 277,Loss: -2.310,Avg.Loss: -2.690,LR: 4.34E-06]Training epoch 19:  81%|████████  | 277/341 [00:05<00:01, 51.51it/s, Epoch: 19, Batch: 278,Loss: -2.669,Avg.Loss: -2.690,LR: 4.32E-06]Training epoch 19:  82%|████████▏ | 278/341 [00:05<00:01, 51.51it/s, Epoch: 19, Batch: 279,Loss: -2.738,Avg.Loss: -2.690,LR: 4.30E-06]Training epoch 19:  82%|████████▏ | 279/341 [00:05<00:01, 51.51it/s, Epoch: 19, Batch: 280,Loss: -2.707,Avg.Loss: -2.690,LR: 4.27E-06]Training epoch 19:  82%|████████▏ | 280/341 [00:05<00:01, 52.17it/s, Epoch: 19, Batch: 280,Loss: -2.707,Avg.Loss: -2.690,LR: 4.27E-06]Training epoch 19:  82%|████████▏ | 280/341 [00:05<00:01, 52.17it/s, Epoch: 19, Batch: 281,Loss: -2.610,Avg.Loss: -2.690,LR: 4.25E-06]Training epoch 19:  82%|████████▏ | 281/341 [00:05<00:01, 52.17it/s, Epoch: 19, Batch: 282,Loss: -3.148,Avg.Loss: -2.692,LR: 4.23E-06]Training epoch 19:  83%|████████▎ | 282/341 [00:05<00:01, 52.17it/s, Epoch: 19, Batch: 283,Loss: -2.753,Avg.Loss: -2.692,LR: 4.21E-06]Training epoch 19:  83%|████████▎ | 283/341 [00:05<00:01, 52.17it/s, Epoch: 19, Batch: 284,Loss: -2.998,Avg.Loss: -2.693,LR: 4.19E-06]Training epoch 19:  83%|████████▎ | 284/341 [00:05<00:01, 52.17it/s, Epoch: 19, Batch: 285,Loss: -2.881,Avg.Loss: -2.694,LR: 4.17E-06]Training epoch 19:  84%|████████▎ | 285/341 [00:05<00:01, 52.17it/s, Epoch: 19, Batch: 286,Loss: -2.485,Avg.Loss: -2.693,LR: 4.15E-06]Training epoch 19:  84%|████████▍ | 286/341 [00:05<00:01, 53.14it/s, Epoch: 19, Batch: 286,Loss: -2.485,Avg.Loss: -2.693,LR: 4.15E-06]Training epoch 19:  84%|████████▍ | 286/341 [00:05<00:01, 53.14it/s, Epoch: 19, Batch: 287,Loss: -2.875,Avg.Loss: -2.694,LR: 4.13E-06]Training epoch 19:  84%|████████▍ | 287/341 [00:05<00:01, 53.14it/s, Epoch: 19, Batch: 288,Loss: -2.939,Avg.Loss: -2.695,LR: 4.11E-06]Training epoch 19:  84%|████████▍ | 288/341 [00:05<00:00, 53.14it/s, Epoch: 19, Batch: 289,Loss: -2.954,Avg.Loss: -2.695,LR: 4.09E-06]Training epoch 19:  85%|████████▍ | 289/341 [00:05<00:00, 53.14it/s, Epoch: 19, Batch: 290,Loss: -2.572,Avg.Loss: -2.695,LR: 4.06E-06]Training epoch 19:  85%|████████▌ | 290/341 [00:05<00:00, 53.14it/s, Epoch: 19, Batch: 291,Loss: -2.754,Avg.Loss: -2.695,LR: 4.04E-06]Training epoch 19:  85%|████████▌ | 291/341 [00:05<00:00, 53.14it/s, Epoch: 19, Batch: 292,Loss: -3.045,Avg.Loss: -2.696,LR: 4.02E-06]Training epoch 19:  86%|████████▌ | 292/341 [00:05<00:00, 53.71it/s, Epoch: 19, Batch: 292,Loss: -3.045,Avg.Loss: -2.696,LR: 4.02E-06]Training epoch 19:  86%|████████▌ | 292/341 [00:05<00:00, 53.71it/s, Epoch: 19, Batch: 293,Loss: -2.328,Avg.Loss: -2.695,LR: 4.00E-06]Training epoch 19:  86%|████████▌ | 293/341 [00:05<00:00, 53.71it/s, Epoch: 19, Batch: 294,Loss: -2.584,Avg.Loss: -2.695,LR: 3.98E-06]Training epoch 19:  86%|████████▌ | 294/341 [00:05<00:00, 53.71it/s, Epoch: 19, Batch: 295,Loss: -2.882,Avg.Loss: -2.695,LR: 3.96E-06]Training epoch 19:  87%|████████▋ | 295/341 [00:05<00:00, 53.71it/s, Epoch: 19, Batch: 296,Loss: -2.787,Avg.Loss: -2.696,LR: 3.94E-06]Training epoch 19:  87%|████████▋ | 296/341 [00:05<00:00, 53.71it/s, Epoch: 19, Batch: 297,Loss: -2.441,Avg.Loss: -2.695,LR: 3.92E-06]Training epoch 19:  87%|████████▋ | 297/341 [00:05<00:00, 53.71it/s, Epoch: 19, Batch: 298,Loss: -2.846,Avg.Loss: -2.695,LR: 3.90E-06]Training epoch 19:  87%|████████▋ | 298/341 [00:05<00:00, 53.97it/s, Epoch: 19, Batch: 298,Loss: -2.846,Avg.Loss: -2.695,LR: 3.90E-06]Training epoch 19:  87%|████████▋ | 298/341 [00:05<00:00, 53.97it/s, Epoch: 19, Batch: 299,Loss: -2.821,Avg.Loss: -2.696,LR: 3.88E-06]Training epoch 19:  88%|████████▊ | 299/341 [00:05<00:00, 53.97it/s, Epoch: 19, Batch: 300,Loss: -2.233,Avg.Loss: -2.694,LR: 3.86E-06]Training epoch 19:  88%|████████▊ | 300/341 [00:05<00:00, 53.97it/s, Epoch: 19, Batch: 301,Loss: -2.615,Avg.Loss: -2.694,LR: 3.84E-06]Training epoch 19:  88%|████████▊ | 301/341 [00:05<00:00, 53.97it/s, Epoch: 19, Batch: 302,Loss: -2.750,Avg.Loss: -2.694,LR: 3.82E-06]Training epoch 19:  89%|████████▊ | 302/341 [00:05<00:00, 53.97it/s, Epoch: 19, Batch: 303,Loss: -3.016,Avg.Loss: -2.695,LR: 3.80E-06]Training epoch 19:  89%|████████▉ | 303/341 [00:05<00:00, 53.97it/s, Epoch: 19, Batch: 304,Loss: -1.596,Avg.Loss: -2.692,LR: 3.78E-06]Training epoch 19:  89%|████████▉ | 304/341 [00:05<00:00, 53.98it/s, Epoch: 19, Batch: 304,Loss: -1.596,Avg.Loss: -2.692,LR: 3.78E-06]Training epoch 19:  89%|████████▉ | 304/341 [00:05<00:00, 53.98it/s, Epoch: 19, Batch: 305,Loss: -2.880,Avg.Loss: -2.692,LR: 3.76E-06]Training epoch 19:  89%|████████▉ | 305/341 [00:05<00:00, 53.98it/s, Epoch: 19, Batch: 306,Loss: -2.648,Avg.Loss: -2.692,LR: 3.74E-06]Training epoch 19:  90%|████████▉ | 306/341 [00:05<00:00, 53.98it/s, Epoch: 19, Batch: 307,Loss: -2.601,Avg.Loss: -2.692,LR: 3.72E-06]Training epoch 19:  90%|█████████ | 307/341 [00:05<00:00, 53.98it/s, Epoch: 19, Batch: 308,Loss: -2.686,Avg.Loss: -2.692,LR: 3.70E-06]Training epoch 19:  90%|█████████ | 308/341 [00:05<00:00, 53.98it/s, Epoch: 19, Batch: 309,Loss: -2.578,Avg.Loss: -2.691,LR: 3.68E-06]Training epoch 19:  91%|█████████ | 309/341 [00:05<00:00, 53.98it/s, Epoch: 19, Batch: 310,Loss: -3.048,Avg.Loss: -2.693,LR: 3.66E-06]Training epoch 19:  91%|█████████ | 310/341 [00:05<00:00, 54.27it/s, Epoch: 19, Batch: 310,Loss: -3.048,Avg.Loss: -2.693,LR: 3.66E-06]Training epoch 19:  91%|█████████ | 310/341 [00:05<00:00, 54.27it/s, Epoch: 19, Batch: 311,Loss: -2.666,Avg.Loss: -2.692,LR: 3.64E-06]Training epoch 19:  91%|█████████ | 311/341 [00:05<00:00, 54.27it/s, Epoch: 19, Batch: 312,Loss: -2.895,Avg.Loss: -2.693,LR: 3.62E-06]Training epoch 19:  91%|█████████▏| 312/341 [00:05<00:00, 54.27it/s, Epoch: 19, Batch: 313,Loss: -2.329,Avg.Loss: -2.692,LR: 3.60E-06]Training epoch 19:  92%|█████████▏| 313/341 [00:05<00:00, 54.27it/s, Epoch: 19, Batch: 314,Loss: -2.391,Avg.Loss: -2.691,LR: 3.58E-06]Training epoch 19:  92%|█████████▏| 314/341 [00:05<00:00, 54.27it/s, Epoch: 19, Batch: 315,Loss: -2.820,Avg.Loss: -2.691,LR: 3.56E-06]Training epoch 19:  92%|█████████▏| 315/341 [00:05<00:00, 54.27it/s, Epoch: 19, Batch: 316,Loss: -3.146,Avg.Loss: -2.693,LR: 3.54E-06]Training epoch 19:  93%|█████████▎| 316/341 [00:05<00:00, 54.52it/s, Epoch: 19, Batch: 316,Loss: -3.146,Avg.Loss: -2.693,LR: 3.54E-06]Training epoch 19:  93%|█████████▎| 316/341 [00:05<00:00, 54.52it/s, Epoch: 19, Batch: 317,Loss: -2.594,Avg.Loss: -2.693,LR: 3.53E-06]Training epoch 19:  93%|█████████▎| 317/341 [00:06<00:00, 54.52it/s, Epoch: 19, Batch: 318,Loss: -3.020,Avg.Loss: -2.694,LR: 3.51E-06]Training epoch 19:  93%|█████████▎| 318/341 [00:06<00:00, 54.52it/s, Epoch: 19, Batch: 319,Loss: -2.915,Avg.Loss: -2.694,LR: 3.49E-06]Training epoch 19:  94%|█████████▎| 319/341 [00:06<00:00, 54.52it/s, Epoch: 19, Batch: 320,Loss: -3.206,Avg.Loss: -2.696,LR: 3.47E-06]Training epoch 19:  94%|█████████▍| 320/341 [00:06<00:00, 54.52it/s, Epoch: 19, Batch: 321,Loss: -2.938,Avg.Loss: -2.697,LR: 3.45E-06]Training epoch 19:  94%|█████████▍| 321/341 [00:06<00:00, 54.52it/s, Epoch: 19, Batch: 322,Loss: -2.749,Avg.Loss: -2.697,LR: 3.43E-06]Training epoch 19:  94%|█████████▍| 322/341 [00:06<00:00, 54.83it/s, Epoch: 19, Batch: 322,Loss: -2.749,Avg.Loss: -2.697,LR: 3.43E-06]Training epoch 19:  94%|█████████▍| 322/341 [00:06<00:00, 54.83it/s, Epoch: 19, Batch: 323,Loss: -2.802,Avg.Loss: -2.697,LR: 3.41E-06]Training epoch 19:  95%|█████████▍| 323/341 [00:06<00:00, 54.83it/s, Epoch: 19, Batch: 324,Loss: -2.907,Avg.Loss: -2.698,LR: 3.39E-06]Training epoch 19:  95%|█████████▌| 324/341 [00:06<00:00, 54.83it/s, Epoch: 19, Batch: 325,Loss: -2.982,Avg.Loss: -2.699,LR: 3.37E-06]Training epoch 19:  95%|█████████▌| 325/341 [00:06<00:00, 54.83it/s, Epoch: 19, Batch: 326,Loss: -2.923,Avg.Loss: -2.699,LR: 3.35E-06]Training epoch 19:  96%|█████████▌| 326/341 [00:06<00:00, 54.83it/s, Epoch: 19, Batch: 327,Loss: -3.050,Avg.Loss: -2.700,LR: 3.34E-06]Training epoch 19:  96%|█████████▌| 327/341 [00:06<00:00, 54.83it/s, Epoch: 19, Batch: 328,Loss: -2.806,Avg.Loss: -2.701,LR: 3.32E-06]Training epoch 19:  96%|█████████▌| 328/341 [00:06<00:00, 54.41it/s, Epoch: 19, Batch: 328,Loss: -2.806,Avg.Loss: -2.701,LR: 3.32E-06]Training epoch 19:  96%|█████████▌| 328/341 [00:06<00:00, 54.41it/s, Epoch: 19, Batch: 329,Loss: -2.963,Avg.Loss: -2.701,LR: 3.30E-06]Training epoch 19:  96%|█████████▋| 329/341 [00:06<00:00, 54.41it/s, Epoch: 19, Batch: 330,Loss: -2.539,Avg.Loss: -2.701,LR: 3.28E-06]Training epoch 19:  97%|█████████▋| 330/341 [00:06<00:00, 54.41it/s, Epoch: 19, Batch: 331,Loss: -2.774,Avg.Loss: -2.701,LR: 3.26E-06]Training epoch 19:  97%|█████████▋| 331/341 [00:06<00:00, 54.41it/s, Epoch: 19, Batch: 332,Loss: -2.586,Avg.Loss: -2.701,LR: 3.24E-06]Training epoch 19:  97%|█████████▋| 332/341 [00:06<00:00, 54.41it/s, Epoch: 19, Batch: 333,Loss: -2.535,Avg.Loss: -2.700,LR: 3.22E-06]Training epoch 19:  98%|█████████▊| 333/341 [00:06<00:00, 54.41it/s, Epoch: 19, Batch: 334,Loss: -2.912,Avg.Loss: -2.701,LR: 3.21E-06]Training epoch 19:  98%|█████████▊| 334/341 [00:06<00:00, 53.40it/s, Epoch: 19, Batch: 334,Loss: -2.912,Avg.Loss: -2.701,LR: 3.21E-06]Training epoch 19:  98%|█████████▊| 334/341 [00:06<00:00, 53.40it/s, Epoch: 19, Batch: 335,Loss: -2.842,Avg.Loss: -2.701,LR: 3.19E-06]Training epoch 19:  98%|█████████▊| 335/341 [00:06<00:00, 53.40it/s, Epoch: 19, Batch: 336,Loss: -2.506,Avg.Loss: -2.701,LR: 3.17E-06]Training epoch 19:  99%|█████████▊| 336/341 [00:06<00:00, 53.40it/s, Epoch: 19, Batch: 337,Loss: -3.127,Avg.Loss: -2.702,LR: 3.15E-06]Training epoch 19:  99%|█████████▉| 337/341 [00:06<00:00, 53.40it/s, Epoch: 19, Batch: 338,Loss: -2.885,Avg.Loss: -2.703,LR: 3.13E-06]Training epoch 19:  99%|█████████▉| 338/341 [00:06<00:00, 53.40it/s, Epoch: 19, Batch: 339,Loss: -2.711,Avg.Loss: -2.703,LR: 3.11E-06]Training epoch 19:  99%|█████████▉| 339/341 [00:06<00:00, 53.40it/s, Epoch: 19, Batch: 340,Loss: -2.702,Avg.Loss: -2.703,LR: 3.10E-06]Training epoch 19: 100%|█████████▉| 340/341 [00:06<00:00, 53.40it/s, Epoch: 19, Batch: 341,Loss: -2.841,Avg.Loss: -2.703,LR: 3.08E-06]Training epoch 19: 100%|██████████| 341/341 [00:06<00:00, 55.58it/s, Epoch: 19, Batch: 341,Loss: -2.841,Avg.Loss: -2.703,LR: 3.08E-06]Training epoch 19: 100%|██████████| 341/341 [00:06<00:00, 53.02it/s, Epoch: 19, Batch: 341,Loss: -2.841,Avg.Loss: -2.703,LR: 3.08E-06]
Training epoch 20:   0%|          | 0/341 [00:00<?, ?it/s]Training epoch 20:   0%|          | 0/341 [00:00<?, ?it/s, Epoch: 20, Batch: 1,Loss: -2.766,Avg.Loss: -2.766,LR: 3.06E-06]Training epoch 20:   0%|          | 1/341 [00:00<00:10, 33.73it/s, Epoch: 20, Batch: 2,Loss: -2.282,Avg.Loss: -2.524,LR: 3.04E-06]Training epoch 20:   1%|          | 2/341 [00:00<00:07, 45.74it/s, Epoch: 20, Batch: 3,Loss: -2.887,Avg.Loss: -2.645,LR: 3.02E-06]Training epoch 20:   1%|          | 3/341 [00:00<00:07, 47.59it/s, Epoch: 20, Batch: 4,Loss: -2.968,Avg.Loss: -2.726,LR: 3.01E-06]Training epoch 20:   1%|          | 4/341 [00:00<00:06, 49.90it/s, Epoch: 20, Batch: 5,Loss: -3.213,Avg.Loss: -2.823,LR: 2.99E-06]Training epoch 20:   1%|▏         | 5/341 [00:00<00:06, 51.06it/s, Epoch: 20, Batch: 6,Loss: -3.124,Avg.Loss: -2.873,LR: 2.97E-06]Training epoch 20:   2%|▏         | 6/341 [00:00<00:06, 49.49it/s, Epoch: 20, Batch: 7,Loss: -2.755,Avg.Loss: -2.857,LR: 2.95E-06]Training epoch 20:   2%|▏         | 7/341 [00:00<00:05, 57.61it/s, Epoch: 20, Batch: 7,Loss: -2.755,Avg.Loss: -2.857,LR: 2.95E-06]Training epoch 20:   2%|▏         | 7/341 [00:00<00:05, 57.61it/s, Epoch: 20, Batch: 8,Loss: -2.732,Avg.Loss: -2.841,LR: 2.94E-06]Training epoch 20:   2%|▏         | 8/341 [00:00<00:05, 57.61it/s, Epoch: 20, Batch: 9,Loss: -3.171,Avg.Loss: -2.878,LR: 2.92E-06]Training epoch 20:   3%|▎         | 9/341 [00:00<00:05, 57.61it/s, Epoch: 20, Batch: 10,Loss: -2.815,Avg.Loss: -2.872,LR: 2.90E-06]Training epoch 20:   3%|▎         | 10/341 [00:00<00:05, 57.61it/s, Epoch: 20, Batch: 11,Loss: -2.830,Avg.Loss: -2.868,LR: 2.88E-06]Training epoch 20:   3%|▎         | 11/341 [00:00<00:05, 57.61it/s, Epoch: 20, Batch: 12,Loss: -3.140,Avg.Loss: -2.890,LR: 2.87E-06]Training epoch 20:   4%|▎         | 12/341 [00:00<00:05, 57.61it/s, Epoch: 20, Batch: 13,Loss: -3.028,Avg.Loss: -2.901,LR: 2.85E-06]Training epoch 20:   4%|▍         | 13/341 [00:00<00:06, 52.71it/s, Epoch: 20, Batch: 13,Loss: -3.028,Avg.Loss: -2.901,LR: 2.85E-06]Training epoch 20:   4%|▍         | 13/341 [00:00<00:06, 52.71it/s, Epoch: 20, Batch: 14,Loss: -2.944,Avg.Loss: -2.904,LR: 2.83E-06]Training epoch 20:   4%|▍         | 14/341 [00:00<00:06, 52.71it/s, Epoch: 20, Batch: 15,Loss: -2.160,Avg.Loss: -2.854,LR: 2.81E-06]Training epoch 20:   4%|▍         | 15/341 [00:00<00:06, 52.71it/s, Epoch: 20, Batch: 16,Loss: -2.882,Avg.Loss: -2.856,LR: 2.80E-06]Training epoch 20:   5%|▍         | 16/341 [00:00<00:06, 52.71it/s, Epoch: 20, Batch: 17,Loss: -2.627,Avg.Loss: -2.843,LR: 2.78E-06]Training epoch 20:   5%|▍         | 17/341 [00:00<00:06, 52.71it/s, Epoch: 20, Batch: 18,Loss: -2.927,Avg.Loss: -2.847,LR: 2.76E-06]Training epoch 20:   5%|▌         | 18/341 [00:00<00:06, 52.71it/s, Epoch: 20, Batch: 19,Loss: -2.898,Avg.Loss: -2.850,LR: 2.75E-06]Training epoch 20:   6%|▌         | 19/341 [00:00<00:06, 50.97it/s, Epoch: 20, Batch: 19,Loss: -2.898,Avg.Loss: -2.850,LR: 2.75E-06]Training epoch 20:   6%|▌         | 19/341 [00:00<00:06, 50.97it/s, Epoch: 20, Batch: 20,Loss: -2.988,Avg.Loss: -2.857,LR: 2.73E-06]Training epoch 20:   6%|▌         | 20/341 [00:00<00:06, 50.97it/s, Epoch: 20, Batch: 21,Loss: -2.756,Avg.Loss: -2.852,LR: 2.71E-06]Training epoch 20:   6%|▌         | 21/341 [00:00<00:06, 50.97it/s, Epoch: 20, Batch: 22,Loss: -2.657,Avg.Loss: -2.843,LR: 2.69E-06]Training epoch 20:   6%|▋         | 22/341 [00:00<00:06, 50.97it/s, Epoch: 20, Batch: 23,Loss: -2.815,Avg.Loss: -2.842,LR: 2.68E-06]Training epoch 20:   7%|▋         | 23/341 [00:00<00:06, 50.97it/s, Epoch: 20, Batch: 24,Loss: -2.456,Avg.Loss: -2.826,LR: 2.66E-06]Training epoch 20:   7%|▋         | 24/341 [00:00<00:06, 50.97it/s, Epoch: 20, Batch: 25,Loss: -2.800,Avg.Loss: -2.825,LR: 2.64E-06]Training epoch 20:   7%|▋         | 25/341 [00:00<00:06, 50.43it/s, Epoch: 20, Batch: 25,Loss: -2.800,Avg.Loss: -2.825,LR: 2.64E-06]Training epoch 20:   7%|▋         | 25/341 [00:00<00:06, 50.43it/s, Epoch: 20, Batch: 26,Loss: -2.702,Avg.Loss: -2.820,LR: 2.63E-06]Training epoch 20:   8%|▊         | 26/341 [00:00<00:06, 50.43it/s, Epoch: 20, Batch: 27,Loss: -2.905,Avg.Loss: -2.823,LR: 2.61E-06]Training epoch 20:   8%|▊         | 27/341 [00:00<00:06, 50.43it/s, Epoch: 20, Batch: 28,Loss: -2.952,Avg.Loss: -2.828,LR: 2.59E-06]Training epoch 20:   8%|▊         | 28/341 [00:00<00:06, 50.43it/s, Epoch: 20, Batch: 29,Loss: -2.504,Avg.Loss: -2.817,LR: 2.58E-06]Training epoch 20:   9%|▊         | 29/341 [00:00<00:06, 50.43it/s, Epoch: 20, Batch: 30,Loss: -2.611,Avg.Loss: -2.810,LR: 2.56E-06]Training epoch 20:   9%|▉         | 30/341 [00:00<00:06, 50.43it/s, Epoch: 20, Batch: 31,Loss: -2.924,Avg.Loss: -2.814,LR: 2.54E-06]Training epoch 20:   9%|▉         | 31/341 [00:00<00:06, 49.47it/s, Epoch: 20, Batch: 31,Loss: -2.924,Avg.Loss: -2.814,LR: 2.54E-06]Training epoch 20:   9%|▉         | 31/341 [00:00<00:06, 49.47it/s, Epoch: 20, Batch: 32,Loss: -2.711,Avg.Loss: -2.810,LR: 2.53E-06]Training epoch 20:   9%|▉         | 32/341 [00:00<00:06, 49.47it/s, Epoch: 20, Batch: 33,Loss: -2.539,Avg.Loss: -2.802,LR: 2.51E-06]Training epoch 20:  10%|▉         | 33/341 [00:00<00:06, 49.47it/s, Epoch: 20, Batch: 34,Loss: -3.111,Avg.Loss: -2.811,LR: 2.50E-06]Training epoch 20:  10%|▉         | 34/341 [00:00<00:06, 49.47it/s, Epoch: 20, Batch: 35,Loss: -2.615,Avg.Loss: -2.806,LR: 2.48E-06]Training epoch 20:  10%|█         | 35/341 [00:00<00:06, 49.47it/s, Epoch: 20, Batch: 36,Loss: -3.067,Avg.Loss: -2.813,LR: 2.46E-06]Training epoch 20:  11%|█         | 36/341 [00:00<00:06, 49.42it/s, Epoch: 20, Batch: 36,Loss: -3.067,Avg.Loss: -2.813,LR: 2.46E-06]Training epoch 20:  11%|█         | 36/341 [00:00<00:06, 49.42it/s, Epoch: 20, Batch: 37,Loss: -2.667,Avg.Loss: -2.809,LR: 2.45E-06]Training epoch 20:  11%|█         | 37/341 [00:00<00:06, 49.42it/s, Epoch: 20, Batch: 38,Loss: -2.881,Avg.Loss: -2.811,LR: 2.43E-06]Training epoch 20:  11%|█         | 38/341 [00:00<00:06, 49.42it/s, Epoch: 20, Batch: 39,Loss: -3.129,Avg.Loss: -2.819,LR: 2.42E-06]Training epoch 20:  11%|█▏        | 39/341 [00:00<00:06, 49.42it/s, Epoch: 20, Batch: 40,Loss: -2.423,Avg.Loss: -2.809,LR: 2.40E-06]Training epoch 20:  12%|█▏        | 40/341 [00:00<00:06, 49.42it/s, Epoch: 20, Batch: 41,Loss: -2.579,Avg.Loss: -2.804,LR: 2.38E-06]Training epoch 20:  12%|█▏        | 41/341 [00:00<00:06, 49.42it/s, Epoch: 20, Batch: 42,Loss: -2.722,Avg.Loss: -2.802,LR: 2.37E-06]Training epoch 20:  12%|█▏        | 42/341 [00:00<00:05, 49.99it/s, Epoch: 20, Batch: 42,Loss: -2.722,Avg.Loss: -2.802,LR: 2.37E-06]Training epoch 20:  12%|█▏        | 42/341 [00:00<00:05, 49.99it/s, Epoch: 20, Batch: 43,Loss: -3.197,Avg.Loss: -2.811,LR: 2.35E-06]Training epoch 20:  13%|█▎        | 43/341 [00:00<00:05, 49.99it/s, Epoch: 20, Batch: 44,Loss: -2.345,Avg.Loss: -2.800,LR: 2.34E-06]Training epoch 20:  13%|█▎        | 44/341 [00:00<00:05, 49.99it/s, Epoch: 20, Batch: 45,Loss: -2.529,Avg.Loss: -2.794,LR: 2.32E-06]Training epoch 20:  13%|█▎        | 45/341 [00:00<00:05, 49.99it/s, Epoch: 20, Batch: 46,Loss: -2.747,Avg.Loss: -2.793,LR: 2.30E-06]Training epoch 20:  13%|█▎        | 46/341 [00:00<00:05, 49.99it/s, Epoch: 20, Batch: 47,Loss: -1.806,Avg.Loss: -2.772,LR: 2.29E-06]Training epoch 20:  14%|█▍        | 47/341 [00:00<00:05, 49.99it/s, Epoch: 20, Batch: 48,Loss: -2.433,Avg.Loss: -2.765,LR: 2.27E-06]Training epoch 20:  14%|█▍        | 48/341 [00:00<00:05, 50.85it/s, Epoch: 20, Batch: 48,Loss: -2.433,Avg.Loss: -2.765,LR: 2.27E-06]Training epoch 20:  14%|█▍        | 48/341 [00:00<00:05, 50.85it/s, Epoch: 20, Batch: 49,Loss: -2.953,Avg.Loss: -2.769,LR: 2.26E-06]Training epoch 20:  14%|█▍        | 49/341 [00:00<00:05, 50.85it/s, Epoch: 20, Batch: 50,Loss: -2.781,Avg.Loss: -2.769,LR: 2.24E-06]Training epoch 20:  15%|█▍        | 50/341 [00:01<00:05, 50.85it/s, Epoch: 20, Batch: 51,Loss: -2.682,Avg.Loss: -2.767,LR: 2.23E-06]Training epoch 20:  15%|█▍        | 51/341 [00:01<00:05, 50.85it/s, Epoch: 20, Batch: 52,Loss: -2.773,Avg.Loss: -2.768,LR: 2.21E-06]Training epoch 20:  15%|█▌        | 52/341 [00:01<00:05, 50.85it/s, Epoch: 20, Batch: 53,Loss: -2.557,Avg.Loss: -2.764,LR: 2.20E-06]Training epoch 20:  16%|█▌        | 53/341 [00:01<00:05, 50.85it/s, Epoch: 20, Batch: 54,Loss: -2.823,Avg.Loss: -2.765,LR: 2.18E-06]Training epoch 20:  16%|█▌        | 54/341 [00:01<00:05, 50.88it/s, Epoch: 20, Batch: 54,Loss: -2.823,Avg.Loss: -2.765,LR: 2.18E-06]Training epoch 20:  16%|█▌        | 54/341 [00:01<00:05, 50.88it/s, Epoch: 20, Batch: 55,Loss: -2.212,Avg.Loss: -2.755,LR: 2.17E-06]Training epoch 20:  16%|█▌        | 55/341 [00:01<00:05, 50.88it/s, Epoch: 20, Batch: 56,Loss: -2.889,Avg.Loss: -2.757,LR: 2.15E-06]Training epoch 20:  16%|█▋        | 56/341 [00:01<00:05, 50.88it/s, Epoch: 20, Batch: 57,Loss: -2.577,Avg.Loss: -2.754,LR: 2.14E-06]Training epoch 20:  17%|█▋        | 57/341 [00:01<00:05, 50.88it/s, Epoch: 20, Batch: 58,Loss: -2.507,Avg.Loss: -2.750,LR: 2.12E-06]Training epoch 20:  17%|█▋        | 58/341 [00:01<00:05, 50.88it/s, Epoch: 20, Batch: 59,Loss: -2.513,Avg.Loss: -2.746,LR: 2.11E-06]Training epoch 20:  17%|█▋        | 59/341 [00:01<00:05, 50.88it/s, Epoch: 20, Batch: 60,Loss: -2.935,Avg.Loss: -2.749,LR: 2.09E-06]Training epoch 20:  18%|█▊        | 60/341 [00:01<00:05, 50.29it/s, Epoch: 20, Batch: 60,Loss: -2.935,Avg.Loss: -2.749,LR: 2.09E-06]Training epoch 20:  18%|█▊        | 60/341 [00:01<00:05, 50.29it/s, Epoch: 20, Batch: 61,Loss: -2.895,Avg.Loss: -2.751,LR: 2.08E-06]Training epoch 20:  18%|█▊        | 61/341 [00:01<00:05, 50.29it/s, Epoch: 20, Batch: 62,Loss: -2.580,Avg.Loss: -2.748,LR: 2.06E-06]Training epoch 20:  18%|█▊        | 62/341 [00:01<00:05, 50.29it/s, Epoch: 20, Batch: 63,Loss: -2.952,Avg.Loss: -2.752,LR: 2.05E-06]Training epoch 20:  18%|█▊        | 63/341 [00:01<00:05, 50.29it/s, Epoch: 20, Batch: 64,Loss: -2.525,Avg.Loss: -2.748,LR: 2.03E-06]Training epoch 20:  19%|█▉        | 64/341 [00:01<00:05, 50.29it/s, Epoch: 20, Batch: 65,Loss: -2.892,Avg.Loss: -2.750,LR: 2.02E-06]Training epoch 20:  19%|█▉        | 65/341 [00:01<00:05, 50.29it/s, Epoch: 20, Batch: 66,Loss: -2.574,Avg.Loss: -2.748,LR: 2.00E-06]Training epoch 20:  19%|█▉        | 66/341 [00:01<00:05, 50.99it/s, Epoch: 20, Batch: 66,Loss: -2.574,Avg.Loss: -2.748,LR: 2.00E-06]Training epoch 20:  19%|█▉        | 66/341 [00:01<00:05, 50.99it/s, Epoch: 20, Batch: 67,Loss: -2.657,Avg.Loss: -2.746,LR: 1.99E-06]Training epoch 20:  20%|█▉        | 67/341 [00:01<00:05, 50.99it/s, Epoch: 20, Batch: 68,Loss: -2.202,Avg.Loss: -2.738,LR: 1.97E-06]Training epoch 20:  20%|█▉        | 68/341 [00:01<00:05, 50.99it/s, Epoch: 20, Batch: 69,Loss: -2.212,Avg.Loss: -2.731,LR: 1.96E-06]Training epoch 20:  20%|██        | 69/341 [00:01<00:05, 50.99it/s, Epoch: 20, Batch: 70,Loss: -2.709,Avg.Loss: -2.730,LR: 1.95E-06]Training epoch 20:  21%|██        | 70/341 [00:01<00:05, 50.99it/s, Epoch: 20, Batch: 71,Loss: -2.795,Avg.Loss: -2.731,LR: 1.93E-06]Training epoch 20:  21%|██        | 71/341 [00:01<00:05, 50.99it/s, Epoch: 20, Batch: 72,Loss: -2.905,Avg.Loss: -2.734,LR: 1.92E-06]Training epoch 20:  21%|██        | 72/341 [00:01<00:05, 51.40it/s, Epoch: 20, Batch: 72,Loss: -2.905,Avg.Loss: -2.734,LR: 1.92E-06]Training epoch 20:  21%|██        | 72/341 [00:01<00:05, 51.40it/s, Epoch: 20, Batch: 73,Loss: -2.796,Avg.Loss: -2.735,LR: 1.90E-06]Training epoch 20:  21%|██▏       | 73/341 [00:01<00:05, 51.40it/s, Epoch: 20, Batch: 74,Loss: -2.520,Avg.Loss: -2.732,LR: 1.89E-06]Training epoch 20:  22%|██▏       | 74/341 [00:01<00:05, 51.40it/s, Epoch: 20, Batch: 75,Loss: -2.130,Avg.Loss: -2.724,LR: 1.87E-06]Training epoch 20:  22%|██▏       | 75/341 [00:01<00:05, 51.40it/s, Epoch: 20, Batch: 76,Loss: -2.682,Avg.Loss: -2.723,LR: 1.86E-06]Training epoch 20:  22%|██▏       | 76/341 [00:01<00:05, 51.40it/s, Epoch: 20, Batch: 77,Loss: -2.935,Avg.Loss: -2.726,LR: 1.85E-06]Training epoch 20:  23%|██▎       | 77/341 [00:01<00:05, 51.40it/s, Epoch: 20, Batch: 78,Loss: -2.915,Avg.Loss: -2.728,LR: 1.83E-06]Training epoch 20:  23%|██▎       | 78/341 [00:01<00:05, 50.23it/s, Epoch: 20, Batch: 78,Loss: -2.915,Avg.Loss: -2.728,LR: 1.83E-06]Training epoch 20:  23%|██▎       | 78/341 [00:01<00:05, 50.23it/s, Epoch: 20, Batch: 79,Loss: -2.808,Avg.Loss: -2.729,LR: 1.82E-06]Training epoch 20:  23%|██▎       | 79/341 [00:01<00:05, 50.23it/s, Epoch: 20, Batch: 80,Loss: -2.810,Avg.Loss: -2.730,LR: 1.80E-06]Training epoch 20:  23%|██▎       | 80/341 [00:01<00:05, 50.23it/s, Epoch: 20, Batch: 81,Loss: -2.604,Avg.Loss: -2.729,LR: 1.79E-06]Training epoch 20:  24%|██▍       | 81/341 [00:01<00:05, 50.23it/s, Epoch: 20, Batch: 82,Loss: -2.798,Avg.Loss: -2.730,LR: 1.78E-06]Training epoch 20:  24%|██▍       | 82/341 [00:01<00:05, 50.23it/s, Epoch: 20, Batch: 83,Loss: -2.712,Avg.Loss: -2.729,LR: 1.76E-06]Training epoch 20:  24%|██▍       | 83/341 [00:01<00:05, 50.23it/s, Epoch: 20, Batch: 84,Loss: -2.611,Avg.Loss: -2.728,LR: 1.75E-06]Training epoch 20:  25%|██▍       | 84/341 [00:01<00:05, 49.68it/s, Epoch: 20, Batch: 84,Loss: -2.611,Avg.Loss: -2.728,LR: 1.75E-06]Training epoch 20:  25%|██▍       | 84/341 [00:01<00:05, 49.68it/s, Epoch: 20, Batch: 85,Loss: -2.786,Avg.Loss: -2.729,LR: 1.74E-06]Training epoch 20:  25%|██▍       | 85/341 [00:01<00:05, 49.68it/s, Epoch: 20, Batch: 86,Loss: -2.878,Avg.Loss: -2.730,LR: 1.72E-06]Training epoch 20:  25%|██▌       | 86/341 [00:01<00:05, 49.68it/s, Epoch: 20, Batch: 87,Loss: -2.483,Avg.Loss: -2.728,LR: 1.71E-06]Training epoch 20:  26%|██▌       | 87/341 [00:01<00:05, 49.68it/s, Epoch: 20, Batch: 88,Loss: -2.445,Avg.Loss: -2.724,LR: 1.70E-06]Training epoch 20:  26%|██▌       | 88/341 [00:01<00:05, 49.68it/s, Epoch: 20, Batch: 89,Loss: -2.736,Avg.Loss: -2.724,LR: 1.68E-06]Training epoch 20:  26%|██▌       | 89/341 [00:01<00:05, 49.53it/s, Epoch: 20, Batch: 89,Loss: -2.736,Avg.Loss: -2.724,LR: 1.68E-06]Training epoch 20:  26%|██▌       | 89/341 [00:01<00:05, 49.53it/s, Epoch: 20, Batch: 90,Loss: -2.748,Avg.Loss: -2.725,LR: 1.67E-06]Training epoch 20:  26%|██▋       | 90/341 [00:01<00:05, 49.53it/s, Epoch: 20, Batch: 91,Loss: -2.352,Avg.Loss: -2.721,LR: 1.66E-06]Training epoch 20:  27%|██▋       | 91/341 [00:01<00:05, 49.53it/s, Epoch: 20, Batch: 92,Loss: -2.738,Avg.Loss: -2.721,LR: 1.64E-06]Training epoch 20:  27%|██▋       | 92/341 [00:01<00:05, 49.53it/s, Epoch: 20, Batch: 93,Loss: -2.986,Avg.Loss: -2.724,LR: 1.63E-06]Training epoch 20:  27%|██▋       | 93/341 [00:01<00:05, 49.53it/s, Epoch: 20, Batch: 94,Loss: -2.342,Avg.Loss: -2.720,LR: 1.62E-06]Training epoch 20:  28%|██▊       | 94/341 [00:01<00:04, 49.54it/s, Epoch: 20, Batch: 94,Loss: -2.342,Avg.Loss: -2.720,LR: 1.62E-06]Training epoch 20:  28%|██▊       | 94/341 [00:01<00:04, 49.54it/s, Epoch: 20, Batch: 95,Loss: -2.755,Avg.Loss: -2.720,LR: 1.60E-06]Training epoch 20:  28%|██▊       | 95/341 [00:01<00:04, 49.54it/s, Epoch: 20, Batch: 96,Loss: -2.838,Avg.Loss: -2.721,LR: 1.59E-06]Training epoch 20:  28%|██▊       | 96/341 [00:01<00:04, 49.54it/s, Epoch: 20, Batch: 97,Loss: -3.060,Avg.Loss: -2.725,LR: 1.58E-06]Training epoch 20:  28%|██▊       | 97/341 [00:01<00:04, 49.54it/s, Epoch: 20, Batch: 98,Loss: -2.859,Avg.Loss: -2.726,LR: 1.56E-06]Training epoch 20:  29%|██▊       | 98/341 [00:01<00:04, 49.54it/s, Epoch: 20, Batch: 99,Loss: -2.555,Avg.Loss: -2.724,LR: 1.55E-06]Training epoch 20:  29%|██▉       | 99/341 [00:01<00:04, 49.54it/s, Epoch: 20, Batch: 100,Loss: -2.677,Avg.Loss: -2.724,LR: 1.54E-06]Training epoch 20:  29%|██▉       | 100/341 [00:01<00:04, 50.19it/s, Epoch: 20, Batch: 100,Loss: -2.677,Avg.Loss: -2.724,LR: 1.54E-06]Training epoch 20:  29%|██▉       | 100/341 [00:02<00:04, 50.19it/s, Epoch: 20, Batch: 101,Loss: -2.439,Avg.Loss: -2.721,LR: 1.53E-06]Training epoch 20:  30%|██▉       | 101/341 [00:02<00:04, 50.19it/s, Epoch: 20, Batch: 102,Loss: -2.803,Avg.Loss: -2.722,LR: 1.51E-06]Training epoch 20:  30%|██▉       | 102/341 [00:02<00:04, 50.19it/s, Epoch: 20, Batch: 103,Loss: -2.792,Avg.Loss: -2.723,LR: 1.50E-06]Training epoch 20:  30%|███       | 103/341 [00:02<00:04, 50.19it/s, Epoch: 20, Batch: 104,Loss: -2.925,Avg.Loss: -2.724,LR: 1.49E-06]Training epoch 20:  30%|███       | 104/341 [00:02<00:04, 50.19it/s, Epoch: 20, Batch: 105,Loss: -2.347,Avg.Loss: -2.721,LR: 1.48E-06]Training epoch 20:  31%|███       | 105/341 [00:02<00:04, 50.19it/s, Epoch: 20, Batch: 106,Loss: -2.512,Avg.Loss: -2.719,LR: 1.46E-06]Training epoch 20:  31%|███       | 106/341 [00:02<00:04, 51.21it/s, Epoch: 20, Batch: 106,Loss: -2.512,Avg.Loss: -2.719,LR: 1.46E-06]Training epoch 20:  31%|███       | 106/341 [00:02<00:04, 51.21it/s, Epoch: 20, Batch: 107,Loss: -2.990,Avg.Loss: -2.721,LR: 1.45E-06]Training epoch 20:  31%|███▏      | 107/341 [00:02<00:04, 51.21it/s, Epoch: 20, Batch: 108,Loss: -3.125,Avg.Loss: -2.725,LR: 1.44E-06]Training epoch 20:  32%|███▏      | 108/341 [00:02<00:04, 51.21it/s, Epoch: 20, Batch: 109,Loss: -2.947,Avg.Loss: -2.727,LR: 1.43E-06]Training epoch 20:  32%|███▏      | 109/341 [00:02<00:04, 51.21it/s, Epoch: 20, Batch: 110,Loss: -2.265,Avg.Loss: -2.723,LR: 1.41E-06]Training epoch 20:  32%|███▏      | 110/341 [00:02<00:04, 51.21it/s, Epoch: 20, Batch: 111,Loss: -2.784,Avg.Loss: -2.724,LR: 1.40E-06]Training epoch 20:  33%|███▎      | 111/341 [00:02<00:04, 51.21it/s, Epoch: 20, Batch: 112,Loss: -2.180,Avg.Loss: -2.719,LR: 1.39E-06]Training epoch 20:  33%|███▎      | 112/341 [00:02<00:04, 50.81it/s, Epoch: 20, Batch: 112,Loss: -2.180,Avg.Loss: -2.719,LR: 1.39E-06]Training epoch 20:  33%|███▎      | 112/341 [00:02<00:04, 50.81it/s, Epoch: 20, Batch: 113,Loss: -2.491,Avg.Loss: -2.717,LR: 1.38E-06]Training epoch 20:  33%|███▎      | 113/341 [00:02<00:04, 50.81it/s, Epoch: 20, Batch: 114,Loss: -2.926,Avg.Loss: -2.719,LR: 1.37E-06]Training epoch 20:  33%|███▎      | 114/341 [00:02<00:04, 50.81it/s, Epoch: 20, Batch: 115,Loss: -2.307,Avg.Loss: -2.715,LR: 1.35E-06]Training epoch 20:  34%|███▎      | 115/341 [00:02<00:04, 50.81it/s, Epoch: 20, Batch: 116,Loss: -2.831,Avg.Loss: -2.716,LR: 1.34E-06]Training epoch 20:  34%|███▍      | 116/341 [00:02<00:04, 50.81it/s, Epoch: 20, Batch: 117,Loss: -2.535,Avg.Loss: -2.714,LR: 1.33E-06]Training epoch 20:  34%|███▍      | 117/341 [00:02<00:04, 50.81it/s, Epoch: 20, Batch: 118,Loss: -2.808,Avg.Loss: -2.715,LR: 1.32E-06]Training epoch 20:  35%|███▍      | 118/341 [00:02<00:04, 50.82it/s, Epoch: 20, Batch: 118,Loss: -2.808,Avg.Loss: -2.715,LR: 1.32E-06]Training epoch 20:  35%|███▍      | 118/341 [00:02<00:04, 50.82it/s, Epoch: 20, Batch: 119,Loss: -2.505,Avg.Loss: -2.713,LR: 1.31E-06]Training epoch 20:  35%|███▍      | 119/341 [00:02<00:04, 50.82it/s, Epoch: 20, Batch: 120,Loss: -2.977,Avg.Loss: -2.716,LR: 1.29E-06]Training epoch 20:  35%|███▌      | 120/341 [00:02<00:04, 50.82it/s, Epoch: 20, Batch: 121,Loss: -2.686,Avg.Loss: -2.715,LR: 1.28E-06]Training epoch 20:  35%|███▌      | 121/341 [00:02<00:04, 50.82it/s, Epoch: 20, Batch: 122,Loss: -2.940,Avg.Loss: -2.717,LR: 1.27E-06]Training epoch 20:  36%|███▌      | 122/341 [00:02<00:04, 50.82it/s, Epoch: 20, Batch: 123,Loss: -2.671,Avg.Loss: -2.717,LR: 1.26E-06]Training epoch 20:  36%|███▌      | 123/341 [00:02<00:04, 50.82it/s, Epoch: 20, Batch: 124,Loss: -2.635,Avg.Loss: -2.716,LR: 1.25E-06]Training epoch 20:  36%|███▋      | 124/341 [00:02<00:04, 50.79it/s, Epoch: 20, Batch: 124,Loss: -2.635,Avg.Loss: -2.716,LR: 1.25E-06]Training epoch 20:  36%|███▋      | 124/341 [00:02<00:04, 50.79it/s, Epoch: 20, Batch: 125,Loss: -2.934,Avg.Loss: -2.718,LR: 1.24E-06]Training epoch 20:  37%|███▋      | 125/341 [00:02<00:04, 50.79it/s, Epoch: 20, Batch: 126,Loss: -2.710,Avg.Loss: -2.718,LR: 1.23E-06]Training epoch 20:  37%|███▋      | 126/341 [00:02<00:04, 50.79it/s, Epoch: 20, Batch: 127,Loss: -2.932,Avg.Loss: -2.720,LR: 1.21E-06]Training epoch 20:  37%|███▋      | 127/341 [00:02<00:04, 50.79it/s, Epoch: 20, Batch: 128,Loss: -2.487,Avg.Loss: -2.718,LR: 1.20E-06]Training epoch 20:  38%|███▊      | 128/341 [00:02<00:04, 50.79it/s, Epoch: 20, Batch: 129,Loss: -2.957,Avg.Loss: -2.720,LR: 1.19E-06]Training epoch 20:  38%|███▊      | 129/341 [00:02<00:04, 50.79it/s, Epoch: 20, Batch: 130,Loss: -2.678,Avg.Loss: -2.719,LR: 1.18E-06]Training epoch 20:  38%|███▊      | 130/341 [00:02<00:04, 51.49it/s, Epoch: 20, Batch: 130,Loss: -2.678,Avg.Loss: -2.719,LR: 1.18E-06]Training epoch 20:  38%|███▊      | 130/341 [00:02<00:04, 51.49it/s, Epoch: 20, Batch: 131,Loss: -2.780,Avg.Loss: -2.720,LR: 1.17E-06]Training epoch 20:  38%|███▊      | 131/341 [00:02<00:04, 51.49it/s, Epoch: 20, Batch: 132,Loss: -2.961,Avg.Loss: -2.722,LR: 1.16E-06]Training epoch 20:  39%|███▊      | 132/341 [00:02<00:04, 51.49it/s, Epoch: 20, Batch: 133,Loss: -2.650,Avg.Loss: -2.721,LR: 1.15E-06]Training epoch 20:  39%|███▉      | 133/341 [00:02<00:04, 51.49it/s, Epoch: 20, Batch: 134,Loss: -2.516,Avg.Loss: -2.720,LR: 1.14E-06]Training epoch 20:  39%|███▉      | 134/341 [00:02<00:04, 51.49it/s, Epoch: 20, Batch: 135,Loss: -2.714,Avg.Loss: -2.719,LR: 1.12E-06]Training epoch 20:  40%|███▉      | 135/341 [00:02<00:04, 51.49it/s, Epoch: 20, Batch: 136,Loss: -2.736,Avg.Loss: -2.720,LR: 1.11E-06]Training epoch 20:  40%|███▉      | 136/341 [00:02<00:04, 50.67it/s, Epoch: 20, Batch: 136,Loss: -2.736,Avg.Loss: -2.720,LR: 1.11E-06]Training epoch 20:  40%|███▉      | 136/341 [00:02<00:04, 50.67it/s, Epoch: 20, Batch: 137,Loss: -2.334,Avg.Loss: -2.717,LR: 1.10E-06]Training epoch 20:  40%|████      | 137/341 [00:02<00:04, 50.67it/s, Epoch: 20, Batch: 138,Loss: -2.944,Avg.Loss: -2.718,LR: 1.09E-06]Training epoch 20:  40%|████      | 138/341 [00:02<00:04, 50.67it/s, Epoch: 20, Batch: 139,Loss: -2.950,Avg.Loss: -2.720,LR: 1.08E-06]Training epoch 20:  41%|████      | 139/341 [00:02<00:03, 50.67it/s, Epoch: 20, Batch: 140,Loss: -2.862,Avg.Loss: -2.721,LR: 1.07E-06]Training epoch 20:  41%|████      | 140/341 [00:02<00:03, 50.67it/s, Epoch: 20, Batch: 141,Loss: -2.650,Avg.Loss: -2.721,LR: 1.06E-06]Training epoch 20:  41%|████▏     | 141/341 [00:02<00:03, 50.67it/s, Epoch: 20, Batch: 142,Loss: -2.811,Avg.Loss: -2.721,LR: 1.05E-06]Training epoch 20:  42%|████▏     | 142/341 [00:02<00:03, 51.06it/s, Epoch: 20, Batch: 142,Loss: -2.811,Avg.Loss: -2.721,LR: 1.05E-06]Training epoch 20:  42%|████▏     | 142/341 [00:02<00:03, 51.06it/s, Epoch: 20, Batch: 143,Loss: -2.725,Avg.Loss: -2.721,LR: 1.04E-06]Training epoch 20:  42%|████▏     | 143/341 [00:02<00:03, 51.06it/s, Epoch: 20, Batch: 144,Loss: -3.150,Avg.Loss: -2.724,LR: 1.03E-06]Training epoch 20:  42%|████▏     | 144/341 [00:02<00:03, 51.06it/s, Epoch: 20, Batch: 145,Loss: -2.722,Avg.Loss: -2.724,LR: 1.02E-06]Training epoch 20:  43%|████▎     | 145/341 [00:02<00:03, 51.06it/s, Epoch: 20, Batch: 146,Loss: -2.153,Avg.Loss: -2.720,LR: 1.01E-06]Training epoch 20:  43%|████▎     | 146/341 [00:02<00:03, 51.06it/s, Epoch: 20, Batch: 147,Loss: -2.565,Avg.Loss: -2.719,LR: 9.98E-07]Training epoch 20:  43%|████▎     | 147/341 [00:02<00:03, 51.06it/s, Epoch: 20, Batch: 148,Loss: -2.525,Avg.Loss: -2.718,LR: 9.87E-07]Training epoch 20:  43%|████▎     | 148/341 [00:02<00:03, 52.02it/s, Epoch: 20, Batch: 148,Loss: -2.525,Avg.Loss: -2.718,LR: 9.87E-07]Training epoch 20:  43%|████▎     | 148/341 [00:02<00:03, 52.02it/s, Epoch: 20, Batch: 149,Loss: -2.723,Avg.Loss: -2.718,LR: 9.77E-07]Training epoch 20:  44%|████▎     | 149/341 [00:02<00:03, 52.02it/s, Epoch: 20, Batch: 150,Loss: -3.085,Avg.Loss: -2.720,LR: 9.67E-07]Training epoch 20:  44%|████▍     | 150/341 [00:02<00:03, 52.02it/s, Epoch: 20, Batch: 151,Loss: -3.053,Avg.Loss: -2.723,LR: 9.57E-07]Training epoch 20:  44%|████▍     | 151/341 [00:02<00:03, 52.02it/s, Epoch: 20, Batch: 152,Loss: -3.075,Avg.Loss: -2.725,LR: 9.47E-07]Training epoch 20:  45%|████▍     | 152/341 [00:03<00:03, 52.02it/s, Epoch: 20, Batch: 153,Loss: -2.991,Avg.Loss: -2.727,LR: 9.37E-07]Training epoch 20:  45%|████▍     | 153/341 [00:03<00:03, 52.02it/s, Epoch: 20, Batch: 154,Loss: -2.979,Avg.Loss: -2.728,LR: 9.27E-07]Training epoch 20:  45%|████▌     | 154/341 [00:03<00:03, 51.65it/s, Epoch: 20, Batch: 154,Loss: -2.979,Avg.Loss: -2.728,LR: 9.27E-07]Training epoch 20:  45%|████▌     | 154/341 [00:03<00:03, 51.65it/s, Epoch: 20, Batch: 155,Loss: -2.837,Avg.Loss: -2.729,LR: 9.17E-07]Training epoch 20:  45%|████▌     | 155/341 [00:03<00:03, 51.65it/s, Epoch: 20, Batch: 156,Loss: -2.971,Avg.Loss: -2.731,LR: 9.07E-07]Training epoch 20:  46%|████▌     | 156/341 [00:03<00:03, 51.65it/s, Epoch: 20, Batch: 157,Loss: -3.216,Avg.Loss: -2.734,LR: 8.97E-07]Training epoch 20:  46%|████▌     | 157/341 [00:03<00:03, 51.65it/s, Epoch: 20, Batch: 158,Loss: -2.662,Avg.Loss: -2.733,LR: 8.88E-07]Training epoch 20:  46%|████▋     | 158/341 [00:03<00:03, 51.65it/s, Epoch: 20, Batch: 159,Loss: -2.887,Avg.Loss: -2.734,LR: 8.78E-07]Training epoch 20:  47%|████▋     | 159/341 [00:03<00:03, 51.65it/s, Epoch: 20, Batch: 160,Loss: -2.903,Avg.Loss: -2.735,LR: 8.68E-07]Training epoch 20:  47%|████▋     | 160/341 [00:03<00:03, 51.74it/s, Epoch: 20, Batch: 160,Loss: -2.903,Avg.Loss: -2.735,LR: 8.68E-07]Training epoch 20:  47%|████▋     | 160/341 [00:03<00:03, 51.74it/s, Epoch: 20, Batch: 161,Loss: -2.751,Avg.Loss: -2.735,LR: 8.59E-07]Training epoch 20:  47%|████▋     | 161/341 [00:03<00:03, 51.74it/s, Epoch: 20, Batch: 162,Loss: -2.881,Avg.Loss: -2.736,LR: 8.49E-07]Training epoch 20:  48%|████▊     | 162/341 [00:03<00:03, 51.74it/s, Epoch: 20, Batch: 163,Loss: -3.101,Avg.Loss: -2.738,LR: 8.40E-07]Training epoch 20:  48%|████▊     | 163/341 [00:03<00:03, 51.74it/s, Epoch: 20, Batch: 164,Loss: -2.428,Avg.Loss: -2.737,LR: 8.31E-07]Training epoch 20:  48%|████▊     | 164/341 [00:03<00:03, 51.74it/s, Epoch: 20, Batch: 165,Loss: -2.963,Avg.Loss: -2.738,LR: 8.21E-07]Training epoch 20:  48%|████▊     | 165/341 [00:03<00:03, 51.74it/s, Epoch: 20, Batch: 166,Loss: -2.559,Avg.Loss: -2.737,LR: 8.12E-07]Training epoch 20:  49%|████▊     | 166/341 [00:03<00:03, 52.53it/s, Epoch: 20, Batch: 166,Loss: -2.559,Avg.Loss: -2.737,LR: 8.12E-07]Training epoch 20:  49%|████▊     | 166/341 [00:03<00:03, 52.53it/s, Epoch: 20, Batch: 167,Loss: -2.816,Avg.Loss: -2.737,LR: 8.03E-07]Training epoch 20:  49%|████▉     | 167/341 [00:03<00:03, 52.53it/s, Epoch: 20, Batch: 168,Loss: -2.739,Avg.Loss: -2.737,LR: 7.93E-07]Training epoch 20:  49%|████▉     | 168/341 [00:03<00:03, 52.53it/s, Epoch: 20, Batch: 169,Loss: -2.865,Avg.Loss: -2.738,LR: 7.84E-07]Training epoch 20:  50%|████▉     | 169/341 [00:03<00:03, 52.53it/s, Epoch: 20, Batch: 170,Loss: -2.063,Avg.Loss: -2.734,LR: 7.75E-07]Training epoch 20:  50%|████▉     | 170/341 [00:03<00:03, 52.53it/s, Epoch: 20, Batch: 171,Loss: -2.982,Avg.Loss: -2.736,LR: 7.66E-07]Training epoch 20:  50%|█████     | 171/341 [00:03<00:03, 52.53it/s, Epoch: 20, Batch: 172,Loss: -2.658,Avg.Loss: -2.735,LR: 7.57E-07]Training epoch 20:  50%|█████     | 172/341 [00:03<00:03, 52.49it/s, Epoch: 20, Batch: 172,Loss: -2.658,Avg.Loss: -2.735,LR: 7.57E-07]Training epoch 20:  50%|█████     | 172/341 [00:03<00:03, 52.49it/s, Epoch: 20, Batch: 173,Loss: -2.466,Avg.Loss: -2.734,LR: 7.48E-07]Training epoch 20:  51%|█████     | 173/341 [00:03<00:03, 52.49it/s, Epoch: 20, Batch: 174,Loss: -2.494,Avg.Loss: -2.732,LR: 7.39E-07]Training epoch 20:  51%|█████     | 174/341 [00:03<00:03, 52.49it/s, Epoch: 20, Batch: 175,Loss: -2.617,Avg.Loss: -2.732,LR: 7.31E-07]Training epoch 20:  51%|█████▏    | 175/341 [00:03<00:03, 52.49it/s, Epoch: 20, Batch: 176,Loss: -2.889,Avg.Loss: -2.732,LR: 7.22E-07]Training epoch 20:  52%|█████▏    | 176/341 [00:03<00:03, 52.49it/s, Epoch: 20, Batch: 177,Loss: -2.673,Avg.Loss: -2.732,LR: 7.13E-07]Training epoch 20:  52%|█████▏    | 177/341 [00:03<00:03, 52.49it/s, Epoch: 20, Batch: 178,Loss: -2.799,Avg.Loss: -2.732,LR: 7.04E-07]Training epoch 20:  52%|█████▏    | 178/341 [00:03<00:03, 52.40it/s, Epoch: 20, Batch: 178,Loss: -2.799,Avg.Loss: -2.732,LR: 7.04E-07]Training epoch 20:  52%|█████▏    | 178/341 [00:03<00:03, 52.40it/s, Epoch: 20, Batch: 179,Loss: -2.513,Avg.Loss: -2.731,LR: 6.96E-07]Training epoch 20:  52%|█████▏    | 179/341 [00:03<00:03, 52.40it/s, Epoch: 20, Batch: 180,Loss: -3.170,Avg.Loss: -2.734,LR: 6.87E-07]Training epoch 20:  53%|█████▎    | 180/341 [00:03<00:03, 52.40it/s, Epoch: 20, Batch: 181,Loss: -2.861,Avg.Loss: -2.734,LR: 6.79E-07]Training epoch 20:  53%|█████▎    | 181/341 [00:03<00:03, 52.40it/s, Epoch: 20, Batch: 182,Loss: -2.279,Avg.Loss: -2.732,LR: 6.70E-07]Training epoch 20:  53%|█████▎    | 182/341 [00:03<00:03, 52.40it/s, Epoch: 20, Batch: 183,Loss: -2.214,Avg.Loss: -2.729,LR: 6.62E-07]Training epoch 20:  54%|█████▎    | 183/341 [00:03<00:03, 52.40it/s, Epoch: 20, Batch: 184,Loss: -3.077,Avg.Loss: -2.731,LR: 6.54E-07]Training epoch 20:  54%|█████▍    | 184/341 [00:03<00:03, 52.15it/s, Epoch: 20, Batch: 184,Loss: -3.077,Avg.Loss: -2.731,LR: 6.54E-07]Training epoch 20:  54%|█████▍    | 184/341 [00:03<00:03, 52.15it/s, Epoch: 20, Batch: 185,Loss: -2.548,Avg.Loss: -2.730,LR: 6.45E-07]Training epoch 20:  54%|█████▍    | 185/341 [00:03<00:02, 52.15it/s, Epoch: 20, Batch: 186,Loss: -2.954,Avg.Loss: -2.731,LR: 6.37E-07]Training epoch 20:  55%|█████▍    | 186/341 [00:03<00:02, 52.15it/s, Epoch: 20, Batch: 187,Loss: -3.038,Avg.Loss: -2.733,LR: 6.29E-07]Training epoch 20:  55%|█████▍    | 187/341 [00:03<00:02, 52.15it/s, Epoch: 20, Batch: 188,Loss: -2.640,Avg.Loss: -2.732,LR: 6.21E-07]Training epoch 20:  55%|█████▌    | 188/341 [00:03<00:02, 52.15it/s, Epoch: 20, Batch: 189,Loss: -2.736,Avg.Loss: -2.732,LR: 6.13E-07]Training epoch 20:  55%|█████▌    | 189/341 [00:03<00:02, 52.15it/s, Epoch: 20, Batch: 190,Loss: -3.054,Avg.Loss: -2.734,LR: 6.05E-07]Training epoch 20:  56%|█████▌    | 190/341 [00:03<00:02, 51.60it/s, Epoch: 20, Batch: 190,Loss: -3.054,Avg.Loss: -2.734,LR: 6.05E-07]Training epoch 20:  56%|█████▌    | 190/341 [00:03<00:02, 51.60it/s, Epoch: 20, Batch: 191,Loss: -2.685,Avg.Loss: -2.734,LR: 5.97E-07]Training epoch 20:  56%|█████▌    | 191/341 [00:03<00:02, 51.60it/s, Epoch: 20, Batch: 192,Loss: -2.993,Avg.Loss: -2.735,LR: 5.89E-07]Training epoch 20:  56%|█████▋    | 192/341 [00:03<00:02, 51.60it/s, Epoch: 20, Batch: 193,Loss: -2.838,Avg.Loss: -2.736,LR: 5.81E-07]Training epoch 20:  57%|█████▋    | 193/341 [00:03<00:02, 51.60it/s, Epoch: 20, Batch: 194,Loss: -2.756,Avg.Loss: -2.736,LR: 5.73E-07]Training epoch 20:  57%|█████▋    | 194/341 [00:03<00:02, 51.60it/s, Epoch: 20, Batch: 195,Loss: -2.837,Avg.Loss: -2.736,LR: 5.65E-07]Training epoch 20:  57%|█████▋    | 195/341 [00:03<00:02, 51.60it/s, Epoch: 20, Batch: 196,Loss: -2.687,Avg.Loss: -2.736,LR: 5.57E-07]Training epoch 20:  57%|█████▋    | 196/341 [00:03<00:02, 52.13it/s, Epoch: 20, Batch: 196,Loss: -2.687,Avg.Loss: -2.736,LR: 5.57E-07]Training epoch 20:  57%|█████▋    | 196/341 [00:03<00:02, 52.13it/s, Epoch: 20, Batch: 197,Loss: -2.647,Avg.Loss: -2.736,LR: 5.50E-07]Training epoch 20:  58%|█████▊    | 197/341 [00:03<00:02, 52.13it/s, Epoch: 20, Batch: 198,Loss: -2.887,Avg.Loss: -2.736,LR: 5.42E-07]Training epoch 20:  58%|█████▊    | 198/341 [00:03<00:02, 52.13it/s, Epoch: 20, Batch: 199,Loss: -2.777,Avg.Loss: -2.737,LR: 5.35E-07]Training epoch 20:  58%|█████▊    | 199/341 [00:03<00:02, 52.13it/s, Epoch: 20, Batch: 200,Loss: -3.039,Avg.Loss: -2.738,LR: 5.27E-07]Training epoch 20:  59%|█████▊    | 200/341 [00:03<00:02, 52.13it/s, Epoch: 20, Batch: 201,Loss: -2.753,Avg.Loss: -2.738,LR: 5.20E-07]Training epoch 20:  59%|█████▉    | 201/341 [00:03<00:02, 52.13it/s, Epoch: 20, Batch: 202,Loss: -2.417,Avg.Loss: -2.737,LR: 5.12E-07]Training epoch 20:  59%|█████▉    | 202/341 [00:03<00:02, 52.15it/s, Epoch: 20, Batch: 202,Loss: -2.417,Avg.Loss: -2.737,LR: 5.12E-07]Training epoch 20:  59%|█████▉    | 202/341 [00:03<00:02, 52.15it/s, Epoch: 20, Batch: 203,Loss: -2.789,Avg.Loss: -2.737,LR: 5.05E-07]Training epoch 20:  60%|█████▉    | 203/341 [00:03<00:02, 52.15it/s, Epoch: 20, Batch: 204,Loss: -2.518,Avg.Loss: -2.736,LR: 4.98E-07]Training epoch 20:  60%|█████▉    | 204/341 [00:04<00:02, 52.15it/s, Epoch: 20, Batch: 205,Loss: -3.065,Avg.Loss: -2.737,LR: 4.90E-07]Training epoch 20:  60%|██████    | 205/341 [00:04<00:02, 52.15it/s, Epoch: 20, Batch: 206,Loss: -2.867,Avg.Loss: -2.738,LR: 4.83E-07]Training epoch 20:  60%|██████    | 206/341 [00:04<00:02, 52.15it/s, Epoch: 20, Batch: 207,Loss: -3.059,Avg.Loss: -2.740,LR: 4.76E-07]Training epoch 20:  61%|██████    | 207/341 [00:04<00:02, 52.15it/s, Epoch: 20, Batch: 208,Loss: -2.853,Avg.Loss: -2.740,LR: 4.69E-07]Training epoch 20:  61%|██████    | 208/341 [00:04<00:02, 51.78it/s, Epoch: 20, Batch: 208,Loss: -2.853,Avg.Loss: -2.740,LR: 4.69E-07]Training epoch 20:  61%|██████    | 208/341 [00:04<00:02, 51.78it/s, Epoch: 20, Batch: 209,Loss: -2.551,Avg.Loss: -2.739,LR: 4.62E-07]Training epoch 20:  61%|██████▏   | 209/341 [00:04<00:02, 51.78it/s, Epoch: 20, Batch: 210,Loss: -3.052,Avg.Loss: -2.741,LR: 4.55E-07]Training epoch 20:  62%|██████▏   | 210/341 [00:04<00:02, 51.78it/s, Epoch: 20, Batch: 211,Loss: -2.672,Avg.Loss: -2.740,LR: 4.48E-07]Training epoch 20:  62%|██████▏   | 211/341 [00:04<00:02, 51.78it/s, Epoch: 20, Batch: 212,Loss: -3.012,Avg.Loss: -2.742,LR: 4.41E-07]Training epoch 20:  62%|██████▏   | 212/341 [00:04<00:02, 51.78it/s, Epoch: 20, Batch: 213,Loss: -2.851,Avg.Loss: -2.742,LR: 4.34E-07]Training epoch 20:  62%|██████▏   | 213/341 [00:04<00:02, 51.78it/s, Epoch: 20, Batch: 214,Loss: -2.568,Avg.Loss: -2.741,LR: 4.28E-07]Training epoch 20:  63%|██████▎   | 214/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 214,Loss: -2.568,Avg.Loss: -2.741,LR: 4.28E-07]Training epoch 20:  63%|██████▎   | 214/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 215,Loss: -2.664,Avg.Loss: -2.741,LR: 4.21E-07]Training epoch 20:  63%|██████▎   | 215/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 216,Loss: -2.739,Avg.Loss: -2.741,LR: 4.14E-07]Training epoch 20:  63%|██████▎   | 216/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 217,Loss: -2.268,Avg.Loss: -2.739,LR: 4.08E-07]Training epoch 20:  64%|██████▎   | 217/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 218,Loss: -3.138,Avg.Loss: -2.741,LR: 4.01E-07]Training epoch 20:  64%|██████▍   | 218/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 219,Loss: -2.700,Avg.Loss: -2.740,LR: 3.95E-07]Training epoch 20:  64%|██████▍   | 219/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 220,Loss: -3.113,Avg.Loss: -2.742,LR: 3.88E-07]Training epoch 20:  65%|██████▍   | 220/341 [00:04<00:02, 51.37it/s, Epoch: 20, Batch: 220,Loss: -3.113,Avg.Loss: -2.742,LR: 3.88E-07]Training epoch 20:  65%|██████▍   | 220/341 [00:04<00:02, 51.37it/s, Epoch: 20, Batch: 221,Loss: -3.009,Avg.Loss: -2.743,LR: 3.82E-07]Training epoch 20:  65%|██████▍   | 221/341 [00:04<00:02, 51.37it/s, Epoch: 20, Batch: 222,Loss: -2.804,Avg.Loss: -2.744,LR: 3.76E-07]Training epoch 20:  65%|██████▌   | 222/341 [00:04<00:02, 51.37it/s, Epoch: 20, Batch: 223,Loss: -2.087,Avg.Loss: -2.741,LR: 3.69E-07]Training epoch 20:  65%|██████▌   | 223/341 [00:04<00:02, 51.37it/s, Epoch: 20, Batch: 224,Loss: -2.776,Avg.Loss: -2.741,LR: 3.63E-07]Training epoch 20:  66%|██████▌   | 224/341 [00:04<00:02, 51.37it/s, Epoch: 20, Batch: 225,Loss: -3.194,Avg.Loss: -2.743,LR: 3.57E-07]Training epoch 20:  66%|██████▌   | 225/341 [00:04<00:02, 51.37it/s, Epoch: 20, Batch: 226,Loss: -2.833,Avg.Loss: -2.743,LR: 3.51E-07]Training epoch 20:  66%|██████▋   | 226/341 [00:04<00:02, 52.16it/s, Epoch: 20, Batch: 226,Loss: -2.833,Avg.Loss: -2.743,LR: 3.51E-07]Training epoch 20:  66%|██████▋   | 226/341 [00:04<00:02, 52.16it/s, Epoch: 20, Batch: 227,Loss: -2.784,Avg.Loss: -2.743,LR: 3.45E-07]Training epoch 20:  67%|██████▋   | 227/341 [00:04<00:02, 52.16it/s, Epoch: 20, Batch: 228,Loss: -3.161,Avg.Loss: -2.745,LR: 3.39E-07]Training epoch 20:  67%|██████▋   | 228/341 [00:04<00:02, 52.16it/s, Epoch: 20, Batch: 229,Loss: -2.960,Avg.Loss: -2.746,LR: 3.33E-07]Training epoch 20:  67%|██████▋   | 229/341 [00:04<00:02, 52.16it/s, Epoch: 20, Batch: 230,Loss: -3.189,Avg.Loss: -2.748,LR: 3.27E-07]Training epoch 20:  67%|██████▋   | 230/341 [00:04<00:02, 52.16it/s, Epoch: 20, Batch: 231,Loss: -2.579,Avg.Loss: -2.747,LR: 3.21E-07]Training epoch 20:  68%|██████▊   | 231/341 [00:04<00:02, 52.16it/s, Epoch: 20, Batch: 232,Loss: -2.811,Avg.Loss: -2.748,LR: 3.15E-07]Training epoch 20:  68%|██████▊   | 232/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 232,Loss: -2.811,Avg.Loss: -2.748,LR: 3.15E-07]Training epoch 20:  68%|██████▊   | 232/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 233,Loss: -2.524,Avg.Loss: -2.747,LR: 3.09E-07]Training epoch 20:  68%|██████▊   | 233/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 234,Loss: -3.007,Avg.Loss: -2.748,LR: 3.04E-07]Training epoch 20:  69%|██████▊   | 234/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 235,Loss: -2.543,Avg.Loss: -2.747,LR: 2.98E-07]Training epoch 20:  69%|██████▉   | 235/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 236,Loss: -2.800,Avg.Loss: -2.747,LR: 2.92E-07]Training epoch 20:  69%|██████▉   | 236/341 [00:04<00:02, 52.33it/s, Epoch: 20, Batch: 237,Loss: -2.538,Avg.Loss: -2.746,LR: 2.87E-07]Training epoch 20:  70%|██████▉   | 237/341 [00:04<00:01, 52.33it/s, Epoch: 20, Batch: 238,Loss: -2.206,Avg.Loss: -2.744,LR: 2.81E-07]Training epoch 20:  70%|██████▉   | 238/341 [00:04<00:01, 52.60it/s, Epoch: 20, Batch: 238,Loss: -2.206,Avg.Loss: -2.744,LR: 2.81E-07]Training epoch 20:  70%|██████▉   | 238/341 [00:04<00:01, 52.60it/s, Epoch: 20, Batch: 239,Loss: -2.684,Avg.Loss: -2.744,LR: 2.76E-07]Training epoch 20:  70%|███████   | 239/341 [00:04<00:01, 52.60it/s, Epoch: 20, Batch: 240,Loss: -2.921,Avg.Loss: -2.744,LR: 2.71E-07]Training epoch 20:  70%|███████   | 240/341 [00:04<00:01, 52.60it/s, Epoch: 20, Batch: 241,Loss: -3.018,Avg.Loss: -2.746,LR: 2.65E-07]Training epoch 20:  71%|███████   | 241/341 [00:04<00:01, 52.60it/s, Epoch: 20, Batch: 242,Loss: -2.709,Avg.Loss: -2.745,LR: 2.60E-07]Training epoch 20:  71%|███████   | 242/341 [00:04<00:01, 52.60it/s, Epoch: 20, Batch: 243,Loss: -2.869,Avg.Loss: -2.746,LR: 2.55E-07]Training epoch 20:  71%|███████▏  | 243/341 [00:04<00:01, 52.60it/s, Epoch: 20, Batch: 244,Loss: -2.890,Avg.Loss: -2.747,LR: 2.50E-07]Training epoch 20:  72%|███████▏  | 244/341 [00:04<00:01, 52.41it/s, Epoch: 20, Batch: 244,Loss: -2.890,Avg.Loss: -2.747,LR: 2.50E-07]Training epoch 20:  72%|███████▏  | 244/341 [00:04<00:01, 52.41it/s, Epoch: 20, Batch: 245,Loss: -2.273,Avg.Loss: -2.745,LR: 2.44E-07]Training epoch 20:  72%|███████▏  | 245/341 [00:04<00:01, 52.41it/s, Epoch: 20, Batch: 246,Loss: -3.044,Avg.Loss: -2.746,LR: 2.39E-07]Training epoch 20:  72%|███████▏  | 246/341 [00:04<00:01, 52.41it/s, Epoch: 20, Batch: 247,Loss: -3.033,Avg.Loss: -2.747,LR: 2.34E-07]Training epoch 20:  72%|███████▏  | 247/341 [00:04<00:01, 52.41it/s, Epoch: 20, Batch: 248,Loss: -2.816,Avg.Loss: -2.747,LR: 2.29E-07]Training epoch 20:  73%|███████▎  | 248/341 [00:04<00:01, 52.41it/s, Epoch: 20, Batch: 249,Loss: -2.960,Avg.Loss: -2.748,LR: 2.24E-07]Training epoch 20:  73%|███████▎  | 249/341 [00:04<00:01, 52.41it/s, Epoch: 20, Batch: 250,Loss: -2.714,Avg.Loss: -2.748,LR: 2.20E-07]Training epoch 20:  73%|███████▎  | 250/341 [00:04<00:01, 52.27it/s, Epoch: 20, Batch: 250,Loss: -2.714,Avg.Loss: -2.748,LR: 2.20E-07]Training epoch 20:  73%|███████▎  | 250/341 [00:04<00:01, 52.27it/s, Epoch: 20, Batch: 251,Loss: -2.561,Avg.Loss: -2.747,LR: 2.15E-07]Training epoch 20:  74%|███████▎  | 251/341 [00:04<00:01, 52.27it/s, Epoch: 20, Batch: 252,Loss: -2.522,Avg.Loss: -2.746,LR: 2.10E-07]Training epoch 20:  74%|███████▍  | 252/341 [00:04<00:01, 52.27it/s, Epoch: 20, Batch: 253,Loss: -2.625,Avg.Loss: -2.746,LR: 2.05E-07]Training epoch 20:  74%|███████▍  | 253/341 [00:04<00:01, 52.27it/s, Epoch: 20, Batch: 254,Loss: -2.831,Avg.Loss: -2.746,LR: 2.01E-07]Training epoch 20:  74%|███████▍  | 254/341 [00:04<00:01, 52.27it/s, Epoch: 20, Batch: 255,Loss: -2.021,Avg.Loss: -2.743,LR: 1.96E-07]Training epoch 20:  75%|███████▍  | 255/341 [00:04<00:01, 52.27it/s, Epoch: 20, Batch: 256,Loss: -2.720,Avg.Loss: -2.743,LR: 1.92E-07]Training epoch 20:  75%|███████▌  | 256/341 [00:04<00:01, 52.58it/s, Epoch: 20, Batch: 256,Loss: -2.720,Avg.Loss: -2.743,LR: 1.92E-07]Training epoch 20:  75%|███████▌  | 256/341 [00:04<00:01, 52.58it/s, Epoch: 20, Batch: 257,Loss: -2.678,Avg.Loss: -2.743,LR: 1.87E-07]Training epoch 20:  75%|███████▌  | 257/341 [00:05<00:01, 52.58it/s, Epoch: 20, Batch: 258,Loss: -2.891,Avg.Loss: -2.744,LR: 1.83E-07]Training epoch 20:  76%|███████▌  | 258/341 [00:05<00:01, 52.58it/s, Epoch: 20, Batch: 259,Loss: -2.286,Avg.Loss: -2.742,LR: 1.78E-07]Training epoch 20:  76%|███████▌  | 259/341 [00:05<00:01, 52.58it/s, Epoch: 20, Batch: 260,Loss: -2.846,Avg.Loss: -2.742,LR: 1.74E-07]Training epoch 20:  76%|███████▌  | 260/341 [00:05<00:01, 52.58it/s, Epoch: 20, Batch: 261,Loss: -2.974,Avg.Loss: -2.743,LR: 1.70E-07]Training epoch 20:  77%|███████▋  | 261/341 [00:05<00:01, 52.58it/s, Epoch: 20, Batch: 262,Loss: -2.993,Avg.Loss: -2.744,LR: 1.66E-07]Training epoch 20:  77%|███████▋  | 262/341 [00:05<00:01, 53.02it/s, Epoch: 20, Batch: 262,Loss: -2.993,Avg.Loss: -2.744,LR: 1.66E-07]Training epoch 20:  77%|███████▋  | 262/341 [00:05<00:01, 53.02it/s, Epoch: 20, Batch: 263,Loss: -2.428,Avg.Loss: -2.743,LR: 1.61E-07]Training epoch 20:  77%|███████▋  | 263/341 [00:05<00:01, 53.02it/s, Epoch: 20, Batch: 264,Loss: -2.888,Avg.Loss: -2.743,LR: 1.57E-07]Training epoch 20:  77%|███████▋  | 264/341 [00:05<00:01, 53.02it/s, Epoch: 20, Batch: 265,Loss: -2.731,Avg.Loss: -2.743,LR: 1.53E-07]Training epoch 20:  78%|███████▊  | 265/341 [00:05<00:01, 53.02it/s, Epoch: 20, Batch: 266,Loss: -2.741,Avg.Loss: -2.743,LR: 1.49E-07]Training epoch 20:  78%|███████▊  | 266/341 [00:05<00:01, 53.02it/s, Epoch: 20, Batch: 267,Loss: -2.864,Avg.Loss: -2.744,LR: 1.45E-07]Training epoch 20:  78%|███████▊  | 267/341 [00:05<00:01, 53.02it/s, Epoch: 20, Batch: 268,Loss: -2.820,Avg.Loss: -2.744,LR: 1.41E-07]Training epoch 20:  79%|███████▊  | 268/341 [00:05<00:01, 53.56it/s, Epoch: 20, Batch: 268,Loss: -2.820,Avg.Loss: -2.744,LR: 1.41E-07]Training epoch 20:  79%|███████▊  | 268/341 [00:05<00:01, 53.56it/s, Epoch: 20, Batch: 269,Loss: -2.986,Avg.Loss: -2.745,LR: 1.37E-07]Training epoch 20:  79%|███████▉  | 269/341 [00:05<00:01, 53.56it/s, Epoch: 20, Batch: 270,Loss: -2.376,Avg.Loss: -2.744,LR: 1.34E-07]Training epoch 20:  79%|███████▉  | 270/341 [00:05<00:01, 53.56it/s, Epoch: 20, Batch: 271,Loss: -2.119,Avg.Loss: -2.741,LR: 1.30E-07]Training epoch 20:  79%|███████▉  | 271/341 [00:05<00:01, 53.56it/s, Epoch: 20, Batch: 272,Loss: -2.748,Avg.Loss: -2.741,LR: 1.26E-07]Training epoch 20:  80%|███████▉  | 272/341 [00:05<00:01, 53.56it/s, Epoch: 20, Batch: 273,Loss: -2.879,Avg.Loss: -2.742,LR: 1.23E-07]Training epoch 20:  80%|████████  | 273/341 [00:05<00:01, 53.56it/s, Epoch: 20, Batch: 274,Loss: -2.884,Avg.Loss: -2.742,LR: 1.19E-07]Training epoch 20:  80%|████████  | 274/341 [00:05<00:01, 53.55it/s, Epoch: 20, Batch: 274,Loss: -2.884,Avg.Loss: -2.742,LR: 1.19E-07]Training epoch 20:  80%|████████  | 274/341 [00:05<00:01, 53.55it/s, Epoch: 20, Batch: 275,Loss: -2.669,Avg.Loss: -2.742,LR: 1.16E-07]Training epoch 20:  81%|████████  | 275/341 [00:05<00:01, 53.55it/s, Epoch: 20, Batch: 276,Loss: -2.169,Avg.Loss: -2.740,LR: 1.12E-07]Training epoch 20:  81%|████████  | 276/341 [00:05<00:01, 53.55it/s, Epoch: 20, Batch: 277,Loss: -2.860,Avg.Loss: -2.740,LR: 1.09E-07]Training epoch 20:  81%|████████  | 277/341 [00:05<00:01, 53.55it/s, Epoch: 20, Batch: 278,Loss: -2.524,Avg.Loss: -2.740,LR: 1.05E-07]Training epoch 20:  82%|████████▏ | 278/341 [00:05<00:01, 53.55it/s, Epoch: 20, Batch: 279,Loss: -2.969,Avg.Loss: -2.741,LR: 1.02E-07]Training epoch 20:  82%|████████▏ | 279/341 [00:05<00:01, 53.55it/s, Epoch: 20, Batch: 280,Loss: -2.745,Avg.Loss: -2.741,LR: 9.87E-08]Training epoch 20:  82%|████████▏ | 280/341 [00:05<00:01, 53.18it/s, Epoch: 20, Batch: 280,Loss: -2.745,Avg.Loss: -2.741,LR: 9.87E-08]Training epoch 20:  82%|████████▏ | 280/341 [00:05<00:01, 53.18it/s, Epoch: 20, Batch: 281,Loss: -2.825,Avg.Loss: -2.741,LR: 9.55E-08]Training epoch 20:  82%|████████▏ | 281/341 [00:05<00:01, 53.18it/s, Epoch: 20, Batch: 282,Loss: -2.918,Avg.Loss: -2.741,LR: 9.23E-08]Training epoch 20:  83%|████████▎ | 282/341 [00:05<00:01, 53.18it/s, Epoch: 20, Batch: 283,Loss: -2.823,Avg.Loss: -2.742,LR: 8.92E-08]Training epoch 20:  83%|████████▎ | 283/341 [00:05<00:01, 53.18it/s, Epoch: 20, Batch: 284,Loss: -2.449,Avg.Loss: -2.741,LR: 8.62E-08]Training epoch 20:  83%|████████▎ | 284/341 [00:05<00:01, 53.18it/s, Epoch: 20, Batch: 285,Loss: -2.525,Avg.Loss: -2.740,LR: 8.32E-08]Training epoch 20:  84%|████████▎ | 285/341 [00:05<00:01, 53.18it/s, Epoch: 20, Batch: 286,Loss: -2.689,Avg.Loss: -2.740,LR: 8.02E-08]Training epoch 20:  84%|████████▍ | 286/341 [00:05<00:01, 53.28it/s, Epoch: 20, Batch: 286,Loss: -2.689,Avg.Loss: -2.740,LR: 8.02E-08]Training epoch 20:  84%|████████▍ | 286/341 [00:05<00:01, 53.28it/s, Epoch: 20, Batch: 287,Loss: -2.414,Avg.Loss: -2.739,LR: 7.73E-08]Training epoch 20:  84%|████████▍ | 287/341 [00:05<00:01, 53.28it/s, Epoch: 20, Batch: 288,Loss: -2.719,Avg.Loss: -2.739,LR: 7.45E-08]Training epoch 20:  84%|████████▍ | 288/341 [00:05<00:00, 53.28it/s, Epoch: 20, Batch: 289,Loss: -2.191,Avg.Loss: -2.737,LR: 7.17E-08]Training epoch 20:  85%|████████▍ | 289/341 [00:05<00:00, 53.28it/s, Epoch: 20, Batch: 290,Loss: -2.866,Avg.Loss: -2.737,LR: 6.90E-08]Training epoch 20:  85%|████████▌ | 290/341 [00:05<00:00, 53.28it/s, Epoch: 20, Batch: 291,Loss: -2.926,Avg.Loss: -2.738,LR: 6.63E-08]Training epoch 20:  85%|████████▌ | 291/341 [00:05<00:00, 53.28it/s, Epoch: 20, Batch: 292,Loss: -1.792,Avg.Loss: -2.735,LR: 6.37E-08]Training epoch 20:  86%|████████▌ | 292/341 [00:05<00:00, 53.33it/s, Epoch: 20, Batch: 292,Loss: -1.792,Avg.Loss: -2.735,LR: 6.37E-08]Training epoch 20:  86%|████████▌ | 292/341 [00:05<00:00, 53.33it/s, Epoch: 20, Batch: 293,Loss: -2.434,Avg.Loss: -2.734,LR: 6.11E-08]Training epoch 20:  86%|████████▌ | 293/341 [00:05<00:00, 53.33it/s, Epoch: 20, Batch: 294,Loss: -2.558,Avg.Loss: -2.733,LR: 5.86E-08]Training epoch 20:  86%|████████▌ | 294/341 [00:05<00:00, 53.33it/s, Epoch: 20, Batch: 295,Loss: -2.364,Avg.Loss: -2.732,LR: 5.61E-08]Training epoch 20:  87%|████████▋ | 295/341 [00:05<00:00, 53.33it/s, Epoch: 20, Batch: 296,Loss: -2.756,Avg.Loss: -2.732,LR: 5.37E-08]Training epoch 20:  87%|████████▋ | 296/341 [00:05<00:00, 53.33it/s, Epoch: 20, Batch: 297,Loss: -2.888,Avg.Loss: -2.732,LR: 5.13E-08]Training epoch 20:  87%|████████▋ | 297/341 [00:05<00:00, 53.33it/s, Epoch: 20, Batch: 298,Loss: -3.126,Avg.Loss: -2.734,LR: 4.90E-08]Training epoch 20:  87%|████████▋ | 298/341 [00:05<00:00, 51.75it/s, Epoch: 20, Batch: 298,Loss: -3.126,Avg.Loss: -2.734,LR: 4.90E-08]Training epoch 20:  87%|████████▋ | 298/341 [00:05<00:00, 51.75it/s, Epoch: 20, Batch: 299,Loss: -2.775,Avg.Loss: -2.734,LR: 4.68E-08]Training epoch 20:  88%|████████▊ | 299/341 [00:05<00:00, 51.75it/s, Epoch: 20, Batch: 300,Loss: -2.629,Avg.Loss: -2.733,LR: 4.46E-08]Training epoch 20:  88%|████████▊ | 300/341 [00:05<00:00, 51.75it/s, Epoch: 20, Batch: 301,Loss: -2.258,Avg.Loss: -2.732,LR: 4.24E-08]Training epoch 20:  88%|████████▊ | 301/341 [00:05<00:00, 51.75it/s, Epoch: 20, Batch: 302,Loss: -2.913,Avg.Loss: -2.732,LR: 4.03E-08]Training epoch 20:  89%|████████▊ | 302/341 [00:05<00:00, 51.75it/s, Epoch: 20, Batch: 303,Loss: -2.714,Avg.Loss: -2.732,LR: 3.83E-08]Training epoch 20:  89%|████████▉ | 303/341 [00:05<00:00, 51.75it/s, Epoch: 20, Batch: 304,Loss: -3.080,Avg.Loss: -2.733,LR: 3.63E-08]Training epoch 20:  89%|████████▉ | 304/341 [00:05<00:00, 51.92it/s, Epoch: 20, Batch: 304,Loss: -3.080,Avg.Loss: -2.733,LR: 3.63E-08]Training epoch 20:  89%|████████▉ | 304/341 [00:05<00:00, 51.92it/s, Epoch: 20, Batch: 305,Loss: -2.369,Avg.Loss: -2.732,LR: 3.44E-08]Training epoch 20:  89%|████████▉ | 305/341 [00:05<00:00, 51.92it/s, Epoch: 20, Batch: 306,Loss: -2.710,Avg.Loss: -2.732,LR: 3.25E-08]Training epoch 20:  90%|████████▉ | 306/341 [00:05<00:00, 51.92it/s, Epoch: 20, Batch: 307,Loss: -3.216,Avg.Loss: -2.734,LR: 3.07E-08]Training epoch 20:  90%|█████████ | 307/341 [00:05<00:00, 51.92it/s, Epoch: 20, Batch: 308,Loss: -3.076,Avg.Loss: -2.735,LR: 2.89E-08]Training epoch 20:  90%|█████████ | 308/341 [00:05<00:00, 51.92it/s, Epoch: 20, Batch: 309,Loss: -2.779,Avg.Loss: -2.735,LR: 2.72E-08]Training epoch 20:  91%|█████████ | 309/341 [00:06<00:00, 51.92it/s, Epoch: 20, Batch: 310,Loss: -2.407,Avg.Loss: -2.734,LR: 2.55E-08]Training epoch 20:  91%|█████████ | 310/341 [00:06<00:00, 51.26it/s, Epoch: 20, Batch: 310,Loss: -2.407,Avg.Loss: -2.734,LR: 2.55E-08]Training epoch 20:  91%|█████████ | 310/341 [00:06<00:00, 51.26it/s, Epoch: 20, Batch: 311,Loss: -2.662,Avg.Loss: -2.734,LR: 2.39E-08]Training epoch 20:  91%|█████████ | 311/341 [00:06<00:00, 51.26it/s, Epoch: 20, Batch: 312,Loss: -2.664,Avg.Loss: -2.734,LR: 2.23E-08]Training epoch 20:  91%|█████████▏| 312/341 [00:06<00:00, 51.26it/s, Epoch: 20, Batch: 313,Loss: -2.811,Avg.Loss: -2.734,LR: 2.08E-08]Training epoch 20:  92%|█████████▏| 313/341 [00:06<00:00, 51.26it/s, Epoch: 20, Batch: 314,Loss: -2.620,Avg.Loss: -2.733,LR: 1.93E-08]Training epoch 20:  92%|█████████▏| 314/341 [00:06<00:00, 51.26it/s, Epoch: 20, Batch: 315,Loss: -2.599,Avg.Loss: -2.733,LR: 1.79E-08]Training epoch 20:  92%|█████████▏| 315/341 [00:06<00:00, 51.26it/s, Epoch: 20, Batch: 316,Loss: -2.617,Avg.Loss: -2.733,LR: 1.66E-08]Training epoch 20:  93%|█████████▎| 316/341 [00:06<00:00, 51.53it/s, Epoch: 20, Batch: 316,Loss: -2.617,Avg.Loss: -2.733,LR: 1.66E-08]Training epoch 20:  93%|█████████▎| 316/341 [00:06<00:00, 51.53it/s, Epoch: 20, Batch: 317,Loss: -2.413,Avg.Loss: -2.732,LR: 1.53E-08]Training epoch 20:  93%|█████████▎| 317/341 [00:06<00:00, 51.53it/s, Epoch: 20, Batch: 318,Loss: -3.079,Avg.Loss: -2.733,LR: 1.40E-08]Training epoch 20:  93%|█████████▎| 318/341 [00:06<00:00, 51.53it/s, Epoch: 20, Batch: 319,Loss: -2.613,Avg.Loss: -2.732,LR: 1.28E-08]Training epoch 20:  94%|█████████▎| 319/341 [00:06<00:00, 51.53it/s, Epoch: 20, Batch: 320,Loss: -2.586,Avg.Loss: -2.732,LR: 1.17E-08]Training epoch 20:  94%|█████████▍| 320/341 [00:06<00:00, 51.53it/s, Epoch: 20, Batch: 321,Loss: -3.109,Avg.Loss: -2.733,LR: 1.06E-08]Training epoch 20:  94%|█████████▍| 321/341 [00:06<00:00, 51.53it/s, Epoch: 20, Batch: 322,Loss: -2.495,Avg.Loss: -2.732,LR: 9.58E-09]Training epoch 20:  94%|█████████▍| 322/341 [00:06<00:00, 51.33it/s, Epoch: 20, Batch: 322,Loss: -2.495,Avg.Loss: -2.732,LR: 9.58E-09]Training epoch 20:  94%|█████████▍| 322/341 [00:06<00:00, 51.33it/s, Epoch: 20, Batch: 323,Loss: -2.662,Avg.Loss: -2.732,LR: 8.60E-09]Training epoch 20:  95%|█████████▍| 323/341 [00:06<00:00, 51.33it/s, Epoch: 20, Batch: 324,Loss: -3.058,Avg.Loss: -2.733,LR: 7.66E-09]Training epoch 20:  95%|█████████▌| 324/341 [00:06<00:00, 51.33it/s, Epoch: 20, Batch: 325,Loss: -2.612,Avg.Loss: -2.733,LR: 6.79E-09]Training epoch 20:  95%|█████████▌| 325/341 [00:06<00:00, 51.33it/s, Epoch: 20, Batch: 326,Loss: -2.948,Avg.Loss: -2.733,LR: 5.96E-09]Training epoch 20:  96%|█████████▌| 326/341 [00:06<00:00, 51.33it/s, Epoch: 20, Batch: 327,Loss: -2.800,Avg.Loss: -2.734,LR: 5.20E-09]Training epoch 20:  96%|█████████▌| 327/341 [00:06<00:00, 51.33it/s, Epoch: 20, Batch: 328,Loss: -2.650,Avg.Loss: -2.733,LR: 4.49E-09]Training epoch 20:  96%|█████████▌| 328/341 [00:06<00:00, 51.71it/s, Epoch: 20, Batch: 328,Loss: -2.650,Avg.Loss: -2.733,LR: 4.49E-09]Training epoch 20:  96%|█████████▌| 328/341 [00:06<00:00, 51.71it/s, Epoch: 20, Batch: 329,Loss: -2.757,Avg.Loss: -2.733,LR: 3.81E-09]Training epoch 20:  96%|█████████▋| 329/341 [00:06<00:00, 51.71it/s, Epoch: 20, Batch: 330,Loss: -2.936,Avg.Loss: -2.734,LR: 3.20E-09]Training epoch 20:  97%|█████████▋| 330/341 [00:06<00:00, 51.71it/s, Epoch: 20, Batch: 331,Loss: -3.005,Avg.Loss: -2.735,LR: 2.65E-09]Training epoch 20:  97%|█████████▋| 331/341 [00:06<00:00, 51.71it/s, Epoch: 20, Batch: 332,Loss: -3.125,Avg.Loss: -2.736,LR: 2.15E-09]Training epoch 20:  97%|█████████▋| 332/341 [00:06<00:00, 51.71it/s, Epoch: 20, Batch: 333,Loss: -2.587,Avg.Loss: -2.736,LR: 1.70E-09]Training epoch 20:  98%|█████████▊| 333/341 [00:06<00:00, 51.71it/s, Epoch: 20, Batch: 334,Loss: -2.776,Avg.Loss: -2.736,LR: 1.30E-09]Training epoch 20:  98%|█████████▊| 334/341 [00:06<00:00, 51.78it/s, Epoch: 20, Batch: 334,Loss: -2.776,Avg.Loss: -2.736,LR: 1.30E-09]Training epoch 20:  98%|█████████▊| 334/341 [00:06<00:00, 51.78it/s, Epoch: 20, Batch: 335,Loss: -3.121,Avg.Loss: -2.737,LR: 9.54E-10]Training epoch 20:  98%|█████████▊| 335/341 [00:06<00:00, 51.78it/s, Epoch: 20, Batch: 336,Loss: -2.848,Avg.Loss: -2.737,LR: 6.56E-10]Training epoch 20:  99%|█████████▊| 336/341 [00:06<00:00, 51.78it/s, Epoch: 20, Batch: 337,Loss: -2.822,Avg.Loss: -2.737,LR: 4.17E-10]Training epoch 20:  99%|█████████▉| 337/341 [00:06<00:00, 51.78it/s, Epoch: 20, Batch: 338,Loss: -2.889,Avg.Loss: -2.738,LR: 2.38E-10]Training epoch 20:  99%|█████████▉| 338/341 [00:06<00:00, 51.78it/s, Epoch: 20, Batch: 339,Loss: -2.944,Avg.Loss: -2.738,LR: 1.04E-10]Training epoch 20:  99%|█████████▉| 339/341 [00:06<00:00, 51.78it/s, Epoch: 20, Batch: 340,Loss: -2.781,Avg.Loss: -2.739,LR: 2.98E-11]Training epoch 20: 100%|█████████▉| 340/341 [00:06<00:00, 50.53it/s, Epoch: 20, Batch: 340,Loss: -2.781,Avg.Loss: -2.739,LR: 2.98E-11]Training epoch 20: 100%|█████████▉| 340/341 [00:06<00:00, 50.53it/s, Epoch: 20, Batch: 341,Loss: -3.505,Avg.Loss: -2.741,LR: 0.00E+00]Training epoch 20: 100%|██████████| 341/341 [00:06<00:00, 51.49it/s, Epoch: 20, Batch: 341,Loss: -3.505,Avg.Loss: -2.741,LR: 0.00E+00]
Finished training141.42813801765442Plot results
function [run_morpheus] finished in 575 ms
function [run_morpheus] finished in 507 ms
function [run_morpheus] finished in 590 ms
function [run_morpheus] finished in 476 ms
function [run_morpheus] finished in 522 ms
function [run_morpheus] finished in 504 ms
function [run_morpheus] finished in 519 ms
function [run_morpheus] finished in 521 ms
function [run_morpheus] finished in 509 ms
function [run_morpheus] finished in 482 ms
function [run_morpheus] finished in 584 ms
function [run_morpheus] finished in 519 ms
function [run_morpheus] finished in 512 ms
function [run_morpheus] finished in 511 ms
function [run_morpheus] finished in 516 ms
function [run_morpheus] finished in 516 ms
function [run_morpheus] finished in 510 ms
function [run_morpheus] finished in 499 ms
function [run_morpheus] finished in 513 ms
function [run_morpheus] finished in 481 ms
function [run_morpheus] finished in 490 ms
function [run_morpheus] finished in 494 ms
function [run_morpheus] finished in 526 ms
function [run_morpheus] finished in 524 ms
function [run_morpheus] finished in 569 ms
function [run_morpheus] finished in 528 ms
function [run_morpheus] finished in 605 ms
function [run_morpheus] finished in 500 ms
function [run_morpheus] finished in 520 ms
function [run_morpheus] finished in 535 ms
function [run_morpheus] finished in 502 ms
function [run_morpheus] finished in 529 ms
function [run_morpheus] finished in 480 ms
function [run_morpheus] finished in 497 ms
function [run_morpheus] finished in 512 ms
function [run_morpheus] finished in 677 ms
function [run_morpheus] finished in 563 ms
function [run_morpheus] finished in 490 ms
function [run_morpheus] finished in 542 ms
function [run_morpheus] finished in 509 ms
function [run_morpheus] finished in 484 ms
function [run_morpheus] finished in 503 ms
function [run_morpheus] finished in 520 ms
function [run_morpheus] finished in 492 ms
function [run_morpheus] finished in 512 ms
function [run_morpheus] finished in 512 ms
function [run_morpheus] finished in 533 ms
function [run_morpheus] finished in 502 ms
function [run_morpheus] finished in 513 ms
function [run_morpheus] finished in 531 ms
function [run_morpheus] finished in 513 ms
function [run_morpheus] finished in 529 ms
function [run_morpheus] finished in 516 ms
function [run_morpheus] finished in 563 ms
function [run_morpheus] finished in 486 ms
function [run_morpheus] finished in 504 ms
function [run_morpheus] finished in 548 ms
function [run_morpheus] finished in 552 ms
function [run_morpheus] finished in 560 ms
function [run_morpheus] finished in 537 ms
function [run_morpheus] finished in 523 ms
function [run_morpheus] finished in 537 ms
function [run_morpheus] finished in 664 ms
function [run_morpheus] finished in 507 ms
function [run_morpheus] finished in 524 ms
function [run_morpheus] finished in 569 ms
function [run_morpheus] finished in 645 ms
function [run_morpheus] finished in 575 ms
function [run_morpheus] finished in 657 ms
function [run_morpheus] finished in 608 ms
function [run_morpheus] finished in 639 ms
function [run_morpheus] finished in 573 ms
function [run_morpheus] finished in 554 ms
function [run_morpheus] finished in 531 ms
function [run_morpheus] finished in 550 ms
function [run_morpheus] finished in 521 ms
function [run_morpheus] finished in 509 ms
function [run_morpheus] finished in 491 ms
function [run_morpheus] finished in 625 ms
function [run_morpheus] finished in 536 ms
function [run_morpheus] finished in 520 ms
function [run_morpheus] finished in 517 ms
function [run_morpheus] finished in 569 ms
function [run_morpheus] finished in 624 ms
function [run_morpheus] finished in 496 ms
function [run_morpheus] finished in 484 ms
function [run_morpheus] finished in 625 ms
function [run_morpheus] finished in 506 ms
function [run_morpheus] finished in 534 ms
function [run_morpheus] finished in 490 ms
function [run_morpheus] finished in 491 ms
function [run_morpheus] finished in 517 ms
function [run_morpheus] finished in 603 ms
function [run_morpheus] finished in 540 ms
function [run_morpheus] finished in 533 ms
function [run_morpheus] finished in 571 ms
function [run_morpheus] finished in 488 ms
function [run_morpheus] finished in 500 ms
function [run_morpheus] finished in 645 ms
function [run_morpheus] finished in 566 ms
